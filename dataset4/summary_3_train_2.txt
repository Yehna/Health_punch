 Clickbait detection in tweets remains an elusive challenge. In this paper, we describe the solution for the Zingel Clickbait Detector at the Clickbait Challenge 2017, which is capable of evaluating each tweet's level of click baiting. We first reformat the regression problem as a multi-classification problem, based on the annotation scheme. To perform multi-classification, we apply a token-level, self-attentive mechanism on the hidden states of bi-directional Gated Recurrent Units , which enables the model to generate tweets' task-specific vector representations by attending to important tokens. The self-attentive neural network can be trained end-to-end, without involving any manual feature engineering. Our detector ranked $1^{st}$ in the final evaluation of Clickbait Challenge 2017. 
 Recently Convolutional Neural Networks  models have proven remarkable results for text classification and sentiment analysis. In this paper, we present our approach on the task of classifying business reviews using word embeddings on a large-scale dataset provided by Yelp: Yelp 2017 challenge dataset. We compare word-based CNN using several pre-trained word embeddings and end-to-end vector representations for text reviews classification. We conduct several experiments to capture the semantic relationship between business reviews and we use deep learning techniques that prove that the obtained results are competitive with traditional methods.  
 Processing of multi-word expressions  is a known problem for any natural language processing task. Even neural machine translation  struggles to overcome it. This paper presents results of experiments on investigating NMT attention allocation to the MWEs and improving automated translation of sentences that contain MWEs in English\Latvian and English\Czech NMT systems. Two improvement strategies were explored--- bilingual pairs of automatically extracted MWE candidates were added to the parallel corpus used to train the NMT system, and  full sentences containing the automatically extracted MWE candidates were added to the parallel corpus. Both approaches allowed to increase automated evaluation results. The best result---0.99 BLEU point increase---has been reached with the first approach, while with the second approach minimal improvements achieved. We also provide open-source software and tools used for MWE extraction and alignment inspection. 
 We describe Honk, an open-source PyTorch reimplementation of convolutional neural networks for keyword spotting that are included as examples in TensorFlow. These models are useful for recognizing ``command triggers'' in speech-based interfaces , which serve as explicit cues for audio recordings of utterances that are sent to the cloud for full speech recognition. Evaluation on Google's recently released Speech Commands Dataset shows that our reimplementation is comparable in accuracy and provides a starting point for future work on the keyword spotting task. 
 This paper describes our systems for IJCNLP 2017 Shared Task on Customer Feedback Analysis. We experimented with simple neural architectures that gave competitive performance on certain tasks. This includes shallow CNN and Bi-Directional LSTM architectures with Facebook's Fasttext as a baseline model. Our best performing model was in the Top 5  systems using the Exact-Accuracy and Micro-Average-F1 metrics for the Spanish  and French  task, and outperformed all the other models on comment  and meaningless  tags using Micro Average F1 by Tags metric  for the French task.    
 An embedding-based speaker adaptive training  approach is proposed and investigated in this paper for deep neural network acoustic modeling. In this approach, speaker embedding vectors, which are a constant given a particular speaker, are mapped through a control network to layer-dependent element-wise affine transformations to canonicalize the internal feature representations at the output of hidden layers of a main network. The control network for generating the speaker-dependent mappings is jointly estimated with the main network for the overall speaker adaptive acoustic modeling. Experiments on large vocabulary continuous speech recognition  tasks show that the proposed SAT scheme can yield superior performance over the widely-used speaker-aware training using i-vectors with speaker-adapted input features. 
 %In this paper, we introduce a novel coherence model using deep learning architecture to analyze the level of coherence in text. This model applies convolutional neural networks for learning an optimal distributional representation of input sentence, which can not only succeed in capturing semantic and syntactic information in sentence but also obtain the benefit of requiring no manual feature engineering and no external knowledge sources . More importantly, we emphasize the role of interactions between sentences by injecting relational information into final representation to learn better coherence structure of the text. We test the proposed model on a widely used ordering task. The experiment results demonstrate that our approach achieves a significantly higher accuracy in distinguishing coherent and incoherent news articles from two domains and generates the state-of-the-art performance by an average 5.3\% absolute improvement over previous work. In this paper, we propose a novel deep coherence model  using a convolutional neural network architecture to capture the text coherence. The text coherence problem is investigated with a new perspective of learning sentence distributional representation and text coherence modeling simultaneously. In particular, the model captures the interactions between sentences by computing the similarities of their distributional representations. Further, it can be easily trained in an end-to-end fashion. The proposed model is evaluated on a standard Sentence Ordering task. The experimental results demonstrate its effectiveness and promise in coherence assessment showing a significant improvement over the state-of-the-art by a wide margin. 
  Semantic Similarity between two sentences can be defined as a way to determine how related or unrelated two sentences are. The task of Semantic Similarity in terms of distributed representations can be thought to be generating sentence embeddings  which take both context and meaning of sentence in account. Such embeddings can be produced by multiple methods, in this paper we try to evaluate LSTM auto encoders for generating these embeddings. Unsupervised algorithms  just try to recreate their inputs, but they can be forced to learn order  by creating proper bottlenecks. We try to evaluate how properly can algorithms trained just on plain English Sentences learn to figure out Semantic Similarity, without giving them any sense of what meaning of a sentence is.  
 %Clickbait is  This paper presents the results of our participation in the Clickbait Detection Challenge 2017. The system relies on a fusion of  neural networks, incorporating different types of available informations.   It does not require any linguistic preprocessing, and hence generalizes more easily to new domains and languages. The final combined model achieves a mean squared error of 0.0428, an accuracy of 0.826, and a $\text{F}_1$ score of 0.564. According to the official evaluation metric the system ranked 6th of the 13 participating teams. 
 Neural network-based systems can now learn to locate the referents of words and phrases in images, answer questions about visual scenes, and execute symbolic instructions as first-person actors in partially-observable worlds. To achieve this so-called grounded language learning, models must overcome challenges that infants face when learning their first words. While it is notable that models with no meaningful prior knowledge overcome these  obstacles, researchers currently lack a clear understanding of how they do so, a problem that we attempt to address in this paper. For maximum control and generality, we focus on a simple neural network-based language learning agent, trained via policy-gradient methods, which can interpret single-word instructions in a simulated 3D world. Whilst the goal is not to explicitly model infant word learning, we take inspiration from experimental paradigms in developmental psychology and apply some of these to the artificial agent, exploring the conditions under which established human biases and learning effects emerge. We further propose a novel method for visualising semantic representations in the agent. 
 Distant Supervision for Relation Extraction uses heuristically aligned text data with an existing knowledge base as training data. The unsupervised nature of this technique allows it to scale to web-scale relation extraction tasks, at the expense of noise in the training data. Previous work has explored relationships among instances of the same entity-pair to reduce this noise, but relationships among instances across entity-pairs have not been fully exploited. We explore the use of inter-instance couplings based on verb-phrase and entity type similarities. We propose a novel technique, , which casts distant supervision using inter-instance coupling into an end-to-end neural network model.  incorporates an attention module at the instance-level to model the multi-instance nature of this problem.  outperforms existing state-of-the-art techniques on a standard benchmark dataset.   %Why are all the articles dropped? Also, skip 'deep'. It's a pretty shallow network. %Distant Supervision for Relation Extraction uses heuristically aligned text data with existing knowledge base as training data. Unsupervised nature of this technique has made it useful in web scale relation extraction. However, noise in heuristically aligned training data leads to wrong label predictions. Past works have explored relationships between mentions of the same entity-pair to reduce noise in training data, but relationships across entity-pairs have not been fully exploited. We explore the use of sentence level couplings like verb-phrase similarity, entity type similarity. We propose a novel technique to use additional coupling between sentence pairs by casting the problem as multi-task learning problem in an end-to-end deep neural network model. Results show that proposed system outperforms existing state of the art techniques.   %Distant Supervision for Relation Extraction  is a common strategy employed to vastly increase the amount of labeled data available, at the expense of noise. As a result, not all training sentences may express a relation between the entity-pair involved. Traditional learning methods treat this as a multi-instance, multi-label problem and aggregate mention-level predictions intelligently to perform RE. Relationships between mentions of the same entity-pair have been explored in the past, but relationships across entity-pairs have not been fully exploited . This works casts RE as a multi-task problem in an effort to reduce the effect of noise by exploiting this additional coupling between sentence pairs, in an end-to-end neural framework. 
 Despite the remarkable progress achieved on automatic speech recognition, recognizing far-field speeches mixed with various noise sources is still a challenging task. In this paper, we introduce novel student-teacher transfer learning, BridgeNet which can provide a solution to improve distant speech recognition. There are two key features in BridgeNet. First, BridgeNet extends traditional student-teacher frameworks by providing multiple hints from a teacher network. Hints are not limited to the soft labels from a teacher network. Teacher's intermediate feature representations can better guide a student network to learn how to denoise or dereverberate noisy input. Second, the proposed recursive architecture in the BridgeNet can iteratively improve denoising and recognition performance. %The proposed recursive architecture enables %bi-directional information flow between denoising and recognition functions by simple network %cascading. The experimental results of BridgeNet showed significant improvements in tackling the distant speech recognition problem, where it achieved up to 13.24\% relative WER reductions on AMI corpus compared to a baseline neural network without teacher's hints. 
   We propose a new statistical model suitable for machine learning of systems with long distance correlations such as natural languages.   The model is based on directed acylic graph decorated   by multi-linear tensor maps in the vertices and vector spaces in the edges,   called tensor network. Such tensor networks have been previously employed    for effective numerical computation of the renormalization group flow on the   space of effective quantum field theories and lattice models of statistical mechanics.    We provide explicit algebro-geometric analysis of the parameter moduli space for tree   graphs,  discuss model properties and applications such as statistical translation.    
 Standard deep learning systems require thousands or millions of examples to learn a concept, and cannot integrate new concepts easily. By contrast, humans have an incredible ability to do one-shot or few-shot learning. For instance, from just hearing a word used in a sentence, humans can infer a great deal about it, by leveraging what the syntax and semantics of the surrounding words tells us. Here, we draw inspiration from this to highlight a simple technique by which deep recurrent networks can similarly exploit their prior knowledge to learn a useful representation for a new word from little data. This could make natural language processing systems much more flexible, by allowing them to learn continually from the new words they encounter.  
 We explore the application of deep residual learning and dilated convolutions to the keyword spotting task, using the recently-released Google Speech Commands Dataset as our benchmark. Our best residual network  implementation significantly outperforms Google's previous convolutional neural networks in terms of accuracy. By varying model depth and width, we can achieve compact models that also outperform previous small-footprint variants. To our knowledge, we are the first to examine these approaches for keyword spotting, and our results establish an open-source state-of-the-art reference to support the development of future speech-based interfaces. 
  In this paper , we tackle Sentiment Analysis conditioned on a Topic in Twitter data using Deep Learning . We propose a 2-tier approach : In the first phase we create our own Word Embeddings and see that they do perform better than state-of-the-art embeddings when used with standard classifiers.   We then perform inference on these embeddings to learn more about a word with respect to all the topics being considered, and also the top n-influencing words for each topic.   In the second phase we use these embeddings to predict the sentiment of the tweet with respect to a given topic, and all other topics under discussion.  
 Distributed word representations have been shown to be very useful in various natural language processing  application tasks. These word vectors learned from huge corpora very often carry both semantic and syntactic information of words. However, it is well known that each individual user has his own language patterns because of different factors such as interested topics, friend groups, social activities, wording habits, etc., which may imply some kind of personalized semantics. With such personalized semantics, the same word may imply slightly differently for different users. For example, the word "Cappuccino" may imply "Leisure", "Joy", "Excellent" for a user enjoying coffee, by only a kind of drink for someone else. Such personalized semantics of course cannot be carried by the standard universal word vectors trained with huge corpora produced by many people. In this paper, we propose a framework to train different personalized word vectors for different users based on the very successful continuous skip-gram model using the social network data posted by many individual users. In this framework, universal background word vectors are first learned from the background corpora, and then adapted by the personalized corpus for each individual user to learn the personalized word vectors. We use two application tasks to evaluate the quality of the personalized word vectors obtained in this way, the user prediction task and the sentence completion task. These personalized word vectors were shown to carry some personalized semantics and offer improved performance on these two evaluation tasks. 
 Trans-dimensional random field language models  where sentences are modeled as a collection of random fields, have shown close performance with LSTM LMs in speech recognition and are computationally more efficient in inference. However, the training efficiency of neural TRF LMs is not satisfactory, which limits the scalability of TRF LMs on large training corpus. In this paper, several techniques on both model formulation and parameter estimation are proposed to improve the training efficiency and the performance of neural TRF LMs. First, TRFs are reformulated in the form of exponential tilting of a reference distribution. Second, noise-contrastive estimation  is introduced to jointly estimate the model parameters and normalization constants. Third, we extend the neural TRF LMs by marrying the deep convolutional neural network  and the bidirectional LSTM into the potential function to extract the deep hierarchical features and bidirectionally sequential features. Utilizing all the above techniques enables the successful and efficient training of neural TRF LMs on a 40x larger training set with only 1/3 training time and further reduces the WER with relative reduction of 4.7\% on top of a strong LSTM LM baseline. 
 Despite the success of sequence-to-sequence approaches in automatic speech recognition  systems, the models still suffer from several problems, mainly due to the mismatch between the training and inference conditions. In the sequence-to-sequence architecture, the model is trained to predict the grapheme of the current time-step given the input of speech signal and the ground-truth grapheme history of the previous time-steps. However, it remains unclear how well the model approximates real-world speech during inference. Thus, generating the whole transcription from scratch based on previous predictions is complicated and errors can propagate over time. Furthermore, the model is optimized to maximize the likelihood of training data instead of error rate evaluation metrics that actually quantify recognition quality. This paper presents an alternative strategy for training sequence-to-sequence ASR models by adopting the idea of reinforcement learning . Unlike the standard training scheme with maximum likelihood estimation, our proposed approach utilizes the policy gradient algorithm. We can  sample the whole transcription based on the model's prediction in the training process and  directly optimize the model with negative Levenshtein distance as the reward. Experimental results demonstrate that we significantly improved the performance compared to a model trained only with maximum likelihood estimation. 
Recurrent neural networks  have been successfully applied to various natural language processing  tasks and achieved better results than conventional methods. However, the lack of understanding of the mechanisms behind their effectiveness limits further improvements on their architectures. In this paper, we present a visual analytics method for understanding and comparing RNN models for NLP tasks. We propose a technique to explain the function of individual hidden state units based on their expected response to input texts. We then co-cluster hidden state units and words based on the expected response and visualize co-clustering results as memory chips and word clouds to provide more structured knowledge on RNNs' hidden states. We also propose a glyph-based sequence visualization based on aggregate information to analyze the behavior of an RNN's hidden state at \revise{the
 In spite of the recent success of neural machine translation  in standard benchmarks, the lack of large parallel corpora poses a major practical problem for many language pairs. There have been several proposals to alleviate this issue with, for instance, triangulation and semi-supervised learning techniques, but they still require a strong cross-lingual signal. In this work, we completely remove the need of parallel data and propose a novel method to train an NMT system in a completely unsupervised manner, relying on nothing but monolingual corpora. Our model builds upon the recent work on unsupervised embedding mappings, and consists of a slightly modified attentional encoder-decoder model that can be trained on monolingual corpora alone using a combination of denoising and backtranslation. Despite the simplicity of the approach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014 French $\rightarrow$ English and German $\rightarrow$ English translation. The model can also profit from small parallel corpora, and attains 21.81 and 15.24 points when combined with 100,000 parallel sentences, respectively. Our implementation is released as an open source project\footnote{\url{https://github.com/artetxem/undreamt}}. 
 This paper presents a new method --- adversarial advantage actor-critic , which significantly improves the efficiency of dialogue policy learning in task-completion dialogue systems. Inspired by generative adversarial networks , we train a discriminator to differentiate responses/actions generated by dialogue agents from responses/actions by experts. Then, we incorporate the discriminator as another critic into the advantage actor-critic  framework, to encourage the dialogue agent to explore state-action within the regions where the agent takes actions similar to those of the experts. Experimental results in a movie-ticket booking domain show that the proposed Adversarial A2C can accelerate policy exploration efficiently.  %When the reward function is known, the goal of reinforcement learning is to find a policy $\pi$ which can maximize the cumulative reward. While, in many of cases, the reward function is unknown, designing good reward functions is a challenging problem, and furthermore the choice of reward function will affect the policy learning. In the task-completion dialogue systems, conventional approaches for reward function are designed with domain knowledge, and also the handcrafted reward function does not leverage the experience gained online during the policy learning. In this paper, we propose an Adversarial Advantage Actor-Critic  model, which can learn a parameterized reward function with online experience, and then learn a dialogue policy with reinforcement learning in the task-completion dialogue systems. Empirical results on a  movie-ticket booking domain show that the proposed model can improve the dialogue policy learning in terms of both learning speed and performance.  
   %In this paper, we show that this equality is not suitable for summarization. %different sentences play different roles in generating a summary.  %Recently, neural networks have been shown effective in abstractive summarization.  % which have been shown effective in many tasks, such as machine translation %This framework provides fair and equal treatment to all input words so as to ensure that the encoding process is conducted fairly. Recently, encoder-decoder models are widely used in social media text summarization. However, these models sometimes select noise words in irrelevant sentences as part of a summary by error, thus declining the performance. In order to inhibit irrelevant sentences and focus on key information, we propose an effective approach by learning sentence weight distribution. In our model, we build a multi-layer perceptron to predict sentence weights. During training, we use the ROUGE score as an alternative to the estimated sentence weight, and try to minimize the gap between estimated weights and predicted weights. In this way, we encourage our model to focus on the key sentences, which have high relevance with the summary. Experimental results show that our approach outperforms baselines on a large-scale social media corpus.     
 CAPTCHAs based on reading text are susceptible to machine-learning-based attacks  due to recent significant advances in deep learning . To address this, this paper promotes image/visual captioning based CAPTCHAs, which is robust against machine-learning-based attacks. To develop image/visual-captioning-based CAPTCHAs, this paper proposes a new image captioning architecture by exploiting tensor product representations , a structured neural-symbolic framework developed in cognitive science over the past 20 years, with the aim of integrating DL with explicit language structures and rules. We call it the  . The key ideas of TPGN are: 1) unsupervised learning of  of words via a TPR-based deep neural network, and 2) integration of TPR with typical DL architectures including Long Short-Term Memory  models. The novelty of our approach lies in its ability to generate a sentence and extract partial grammatical structure of the sentence by using role-unbinding vectors, which are obtained in an unsupervised manner. Experimental results demonstrate the effectiveness of the proposed approach. 
 Online media outlets, in a bid to expand their reach and subsequently increase revenue through ad monetisation, have begun adopting clickbait techniques to lure readers to click on articles. The article fails to fulfill the promise made by the headline. Traditional methods for clickbait detection have relied heavily on feature engineering which, in turn, is dependent on the dataset it is built for. The application of neural networks for this task has only been explored partially. We propose a novel approach considering all information found in a social media post. We train a bidirectional LSTM with an attention mechanism to learn the extent to which a word contributes to the post's clickbait score in a differential manner. We also employ a Siamese net to capture the similarity between source and target information. Information gleaned from images has not been considered in previous approaches. We learn image embeddings from large amounts of data using Convolutional Neural Networks to add another layer of complexity to our model. Finally, we concatenate the outputs from the three separate components, serving it as input to a fully connected layer. We conduct experiments over a  test corpus of 19538 social media posts, attaining an F1 score of 65.37\% on the dataset bettering the previous state-of-the-art, as well as other proposed approaches, feature engineering or otherwise. 
  This paper presents the results and conclusions of our participation in the Clickbait Challenge 2017\footnote{http://www.clickbait-challenge.org/} on automatic clickbait detection in social media. We first describe linguistically-infused neural network models and identify informative representations to predict the level of clickbaiting present in Twitter posts. Our models allow to answer the question not only whether a post is a clickbait or not, but to what extent it is a clickbait post e.g., not at all, slightly, considerably, or heavily clickbaity using a score ranging from 0 to 1. We evaluate the predictive power of models trained on varied text and image representations extracted from tweets. Our best performing model that relies on the tweet text and linguistic markers of biased language extracted from the tweet and the corresponding page yields mean squared error  of 0.04, mean absolute error  of 0.16 and R2 of 0.43 on the held-out test data. For the binary classification setup , our model achieved F1 score of 0.69. We have not found that image representations combined with text yield significant performance improvement yet. Nevertheless, this work is the first to present preliminary analysis of  objects extracted using Google Tensorflow object detection API from images in clickbait vs. non-clickbait Twitter posts. Finally, we outline several steps to improve model performance as a part of the future work.   
        We present Deep Voice 3, a fully-convolutional attention-based neural text-to-speech  system. Deep Voice 3 matches state-of-the-art neural speech synthesis systems in naturalness while training an order of magnitude faster. We scale Deep Voice 3 to dataset sizes unprecedented for TTS, training on more than eight hundred hours of audio from over two thousand speakers. In addition, we identify common error modes of attention-based speech synthesis networks, demonstrate how to mitigate them, and compare several different waveform synthesis methods. We also describe how to scale inference to ten million queries per day on a single GPU server.   
  In this paper, we present a novel Deep Neural Network  derived Deep Triphone Embedding  representation, to encapsulate the discriminative information present in the adjoining speech frames while estimating the current speech frame's tied-triphone posterior probabilities. The DTEs are  generated by a training a first-stage four hidden layer DNN with $3000$ nodes in each hidden layer. This DNN is trained with the usual tied-triphone classification accuracy criterion. However, for each speech MFCC frame, we then retain the last hidden layer's  activation vector  followed by dimensionality reduction operation through Principal Component Analysis  to obtain a $300$ dimensional representation, which we term as Deep Triphone Embedding . These DTEs along with MFCC features are inputted to a second stage four hidden layer DNN, which is trained for the task of tied-triphone  classification.  Both the DNNs are trained to predict framewise tri-phoneme labels which are generated using a tied-state triphone HMM-GMM system, by performing a forced-alignment between the transcriptions and MFCC feature frames. We conduct our experiments on publicly available, large vocabulary TED-LIUM speech corpus. The results show that the proposed method of DTE provides an improvement of absolute $\mathtt{ 6.71\%}$ in phoneme recognition accuracy, when compared with a competitive baseline of Hybrid tied-state triphone HMM-DNN system. 
 Context plays an important role in human language understanding, thus it may also be useful for machines learning vector representations of language. In this paper, we explore an asymmetric encoder-decoder structure for unsupervised context-based sentence representation learning. We carefully designed experiments to show that neither an autoregressive decoder nor an RNN decoder is required. After that, we designed a model which still keeps an RNN as the encoder, while using a non-autoregressive convolutional decoder. We further combine a suite of effective designs to significantly improve model efficiency while also achieving better performance. Our model is trained on two different large unlabelled corpora, and in both cases the transferability is evaluated on a set of downstream NLP tasks. We empirically show that our model is simple and fast while producing rich sentence representations that excel in downstream tasks.  % As a result, we build an encoder-decoder architecture with an RNN encoder and an efficient CNN decoder, after showing that neither an autoregressive decoder nor an RNN decoder is required. We further combine a suite of effective designs to significantly improve model efficiency while also achieving better performance. Our model is trained on two different large unlabelled corpora, and in both cases the transferability is evaluated on a set of downstream NLP tasks. We empirically show that our model is simple and fast while producing rich sentence representations that excel in downstream tasks. 
 We propose a method, called Label Embedding Network, which can learn label representation  during the training process of deep networks. With the proposed method, the label embedding is adaptively and automatically learned through back propagation. The original one-hot represented loss function is converted into a new loss function with soft distributions, such that the originally unrelated labels have continuous interactions with each other during the training process. As a result, the trained model can achieve substantially higher accuracy and with faster convergence speed. Experimental results based on competitive tasks demonstrate the effectiveness of the proposed method, and the learned label embedding is reasonable and interpretable. The proposed method achieves comparable or even better results than the state-of-the-art systems. The source code is available at \url{https://github.com/lancopku/LabelEmb}. 
 Traditional models for question answering optimize using cross entropy loss, which encourages exact answers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate. We propose a mixed objective that combines cross entropy loss with self-critical policy learning. The objective uses rewards derived from word overlap to solve the misalignment between evaluation metric and optimization objective. In addition to the mixed objective, we improve dynamic coattention networks  with a deep residual coattention encoder that is inspired by recent work in deep self-attention and residual networks. Our proposals improve model performance across question types and input lengths, especially for long questions that requires the ability to capture long-term dependencies. On the Stanford Question Answering Dataset, our model achieves state-of-the-art results with~\emours exact match accuracy and~\fours F1, while the ensemble obtains~\emoursensemble exact match accuracy and~\foursensemble F1. 
   Most people do not interact with Semantic Web data directly. Unless they have the expertise to understand the underlying technology, they need textual or visual interfaces to help them make sense of it. We explore the problem of generating natural language summaries for Semantic Web data. This is non-trivial, especially in an open-domain context. To address this problem, we explore the use of neural networks. Our system encodes the information from a set of triples into a vector of fixed dimensionality and generates a textual summary by conditioning the output on the encoded vector. We train and evaluate our models on two corpora of loosely aligned Wikipedia snippets and DBpedia and Wikidata triples with promising results. 
 Automatic generation of paraphrases from a given sentence is an important yet challenging task in natural language processing . In this paper, we present a deep reinforcement learning approach to paraphrase generation. Specifically, we propose a new framework for the task, which consists of a generator and an evaluator, both of which are learned from data. The generator, built as a sequence-to-sequence learning model, can produce paraphrases given a sentence. The evaluator, constructed as a deep matching model, can judge whether two sentences are paraphrases of each other. The generator is first trained by deep learning and then further fine-tuned by reinforcement learning in which the reward is given by the evaluator. For the learning of the evaluator, we propose two methods based on supervised learning and inverse reinforcement learning respectively, depending on the type of available training data. Experimental results on two datasets demonstrate the proposed models  can produce more accurate paraphrases and outperform the state-of-the-art methods in paraphrase generation in both automatic evaluation and human evaluation. 
 Compared to traditional statistical machine translation , neural machine translation  often sacrifices adequacy for the sake of fluency. We propose a method to combine the advantages of traditional SMT and NMT by exploiting an existing phrase-based SMT model to compute the phrase-based decoding cost for an NMT output and then using  this cost to rerank the $n$-best NMT outputs.  The main challenge in implementing this approach is that NMT outputs may not be in the search space of the standard phrase-based decoding algorithm, because the search space of phrase-based SMT is limited by the phrase-based translation rule table. We propose a soft forced decoding algorithm, which can always successfully find a decoding path for any NMT output.  We show that using the forced decoding cost to rerank the NMT outputs can successfully improve translation  quality  on four different language pairs. 
   For machine translation to tackle discourse phenomena, models must have access to extra-sentential   linguistic context.  There has been recent interest in modelling context in neural machine   translation , but models have been principally evaluated with standard automatic metrics,   poorly adapted to evaluating discourse phenomena. In this article, we present hand-crafted,   discourse test sets, designed to test the models' ability to exploit previous source and target   sentences.  We investigate the performance of recently proposed multi-encoder NMT models trained   on subtitles for English to French. We also explore a novel way of exploiting context from the previous   sentence. Despite gains using BLEU, multi-encoder models give limited   improvement in the handling of discourse phenomena: 50\% accuracy on our coreference test set   and 53.5\% for coherence/cohesion . A simple   strategy of decoding the concatenation of the previous and current sentence leads to good   performance, and our novel strategy of multi-encoding and decoding of two   sentences leads to the best performance ,   highlighting the importance of target-side context. 
 For over a decade, machine learning has been used to extract {. Recent neural approaches do not outperform the state-of-the-art feature-based models for Opinion Role Labeling . We suspect this is due to the scarcity of labeled training data and address this issue using different multi-task learning  techniques with a related task which has substantially more data, i.e.\ Semantic Role Labeling . We show that two MTL models improve significantly over the single-task model for labeling of both holders and targets, on the development and the test sets. We found that the vanilla MTL model which makes predictions using only shared ORL and SRL features, performs the best. With deeper analysis we determine what works and what might be done to make further improvements for ORL.  
 	Reading comprehension is a challenging task, especially when executed across longer or across multiple evidence documents, where the answer is likely to reoccur. 	Existing neural architectures typically do not scale to the entire evidence, and hence, resort to selecting a single passage in the document , and carefully searching for the answer within that passage. 	However, in some cases, this strategy can be suboptimal,  since by focusing on a specific passage, it becomes difficult to leverage multiple mentions of the same answer throughout the document. 	In this work, we take a different approach by constructing lightweight models that are combined in a cascade to find the answer. 	Each submodel consists only of feed-forward networks equipped with an attention mechanism, making it trivially parallelizable. 	We show that our approach can scale to approximately an order of magnitude larger evidence documents and can aggregate information at the representation level from multiple mentions of each answer candidate across the document. 	Empirically, our approach achieves state-of-the-art performance on both the Wikipedia and web domains of the TriviaQA dataset, outperforming more complex, recurrent architectures. 
 While neural machine translation  has become the new paradigm, the parameter optimization requires large-scale parallel data which is scarce in many domains and language pairs. In this paper, we address a new translation scenario in which there only exists monolingual corpora and phrase pairs. We propose a new method towards translation with partially aligned sentence pairs which are derived from the phrase pairs and monolingual corpora. To make full use of the partially aligned corpora, we adapt the conventional NMT training method in two aspects. On one hand, different generation strategies are designed for aligned and unaligned target words. On the other hand, a different objective function is designed to model the partially aligned parts. The experiments demonstrate that our method can achieve a relatively good result in such a translation scenario, and tiny bitexts can boost translation quality to a large extent. 
 Natural language processing  models often require a massive number of parameters for word embeddings, resulting in a large storage or memory footprint. Deploying neural NLP models to mobile devices requires compressing the word embeddings without any significant sacrifices in performance. For this purpose, we propose to construct the embeddings with few basis vectors. For each word, the composition of basis vectors is determined by a hash code. To maximize the compression rate, we adopt the multi-codebook quantization approach instead of binary coding scheme. Each code is composed of multiple discrete numbers, such as $$, where the value of each component is limited to a fixed range. We propose to directly learn the discrete codes in an end-to-end neural network by applying the Gumbel-softmax trick. Experiments show the compression rate achieves $98\%$ in a sentiment analysis task and $94\% \sim 99\%$ in machine translation tasks without performance loss. In both tasks, the proposed method can improve the model performance by slightly lowering the compression rate. Compared to other approaches such as character-level segmentation, the proposed method is language-independent and does not require modifications to the network architecture. 
 We train a bank of complex filters that operates on the raw waveform and is fed into a convolutional neural network for end-to-end phone recognition. These time-domain filterbanks  are initialized as an approximation of mel-filterbanks%  % , and then fine-tuned jointly with the remaining convolutional architecture. We perform phone recognition experiments on TIMIT and show that for several architectures, models trained on TD-filterbanks consistently outperform their counterparts trained on comparable mel-filterbanks% %MFSC . We get our best performance by learning all front-end steps, from pre-emphasis up to averaging. Finally, we observe that the filters at convergence have an asymmetric impulse response, and that some of them remain almost analytic. 
 Predicting discharge medications right after a patient being admitted is an important clinical decision, which  %helps physicians plan the type of medication regimen and decide when to start or stop medications during an inpatient stay as some medications require time to add on and need to be managed in the setting of other medications.  provides physicians with guidance on what type of medication regimen to plan for and what possible changes on initial medication may occur during an inpatient stay. It also facilitates medication reconciliation process with easy detection of medication discrepancy at discharge time to improve patient safety. However, since the information available upon admission is limited and patients' condition may evolve during an inpatient stay, these predictions could be a difficult decision for physicians to make. In this work, we investigate how to leverage deep learning technologies to assist physicians in predicting discharge medications based on information documented in the admission note. We build a convolutional neural network which takes an admission note as input and predicts the medications placed on the patient at discharge time. Our method is able to distill semantic patterns from unstructured and noisy texts, and is capable of capturing the pharmacological correlations among medications. We evaluate our method on 25K patient visits and compare with 4 strong baselines. Our methods demonstrate a 20\% increase in macro-averaged F1 score than the best baseline. 
 In recent years, neural networks have proven to be effective in Chinese word segmentation. However, this promising performance relies on large-scale training data. Neural networks with conventional architectures cannot achieve the desired results in low-resource datasets due to the lack of labelled training data. In this paper, we propose a deep stacking framework to improve the performance on word segmentation tasks with insufficient data by integrating datasets from diverse domains. Our framework consists of two parts, domain-based models and deep stacking networks. The domain-based models are used to learn knowledge from different datasets. The deep stacking networks are designed to integrate domain-based models. To reduce model conflicts, we innovatively add communication paths among models and design various structures of deep stacking networks, including Gaussian-based Stacking Networks, Concatenate-based Stacking Networks, Sequence-based Stacking Networks and Tree-based Stacking Networks. We conduct experiments on six low-resource datasets from various domains. Our proposed framework shows significant performance improvements on all datasets compared with several strong baselines. 
   In this paper, we propose a novel deep neural network architecture, Sequence-to-Sequence Audio2Vec, for unsupervised learning of fixed-length vector representations of audio segments excised from a speech corpus, where the vectors contain semantic information pertaining to the segments, and are close to other vectors in the embedding space if their corresponding segments are semantically similar.   The design of the proposed model is based on the RNN Encoder-Decoder framework, and borrows the methodology of continuous skip-grams for training.   The learned vector representations are evaluated on~13 widely used word similarity benchmarks, and achieved competitive results to that of GloVe.   The biggest advantage of the proposed model is its capability of extracting semantic information of audio segments taken directly from raw speech, without relying on any other modalities such as text or images, which are challenging and expensive to collect and annotate. 
 Traditional Chinese Medicine  has accumulated a big amount of precious resource in the long history of development. TCM prescriptions that consist of TCM herbs are an important form of TCM treatment, which are similar to natural language documents, but in a weakly ordered fashion. Directly adapting language modeling style methods to learn the embeddings of the herbs can be problematic as the herbs are not strictly in order, the herbs in the front of the prescription can be connected to the very last ones. In this paper, we propose to represent TCM herbs with distributed representations via Prescription Level Language Modeling . In one of our experiments, the correlation between our calculated similarity between medicines and the judgment of professionals achieves a Spearman score of 55.35 indicating a strong correlation, which surpasses human beginners  by a big margin .  
 We propose a neural language model capable of unsupervised syntactic structure induction. The model leverages the structure information to form better semantic representations and better language modeling. Standard recurrent neural networks are limited by their structure and fail to efficiently use syntactic information. On the other hand, tree-structured recursive networks usually require additional structural supervision at the cost of human expert annotation. In this paper, We propose a novel neural language model, called the Parsing-Reading-Predict Networks , that can simultaneously induce the syntactic structure from unannotated sentences and leverage the inferred structure to learn a better language model. In our model, the gradient can be directly back-propagated from the language model loss into the neural parsing network. Experiments show that the proposed model can discover the underlying syntactic structure and achieve state-of-the-art performance on word/character-level language model tasks.   
     Inspired by the principles of speed reading, we introduce Skim-RNN, a recurrent neural network  that dynamically decides to update only a small fraction of the hidden state for relatively unimportant input tokens. Skim-RNN gives computational advantage over an RNN that always updates the entire hidden state. Skim-RNN uses the same input and output interfaces as a standard RNN and can be easily used instead of RNNs in existing models.      In our experiments, we show that Skim-RNN can achieve significantly reduced computational cost without losing accuracy compared to standard RNNs across five different natural language tasks.      In addition, we demonstrate that the trade-off between accuracy and speed of Skim-RNN can be dynamically controlled during inference time in a stable manner.     Our analysis also shows that Skim-RNN running on a single CPU offers lower latency compared to standard RNNs on GPUs. 
 Character-based neural machine translation  models alleviate out-of-vocabulary issues, learn morphology, and move us closer to completely end-to-end translation systems.  Unfortunately, they are also very brittle and easily falter when presented with noisy data.   In this paper, we confront NMT models with synthetic and natural sources of noise. We find that state-of-the-art models fail to translate even moderately noisy texts that humans have no trouble comprehending. We explore two approaches to increase model robustness: structure-invariant word representations and robust training on noisy texts. We find that a model based on a character convolutional neural network is able to simultaneously learn representations robust to multiple kinds of noise.  
 Existing approaches to neural machine translation condition each output word on previously generated outputs. We introduce a model that avoids this autoregressive property and produces its outputs in parallel, allowing an order of magnitude lower latency during inference. Through knowledge distillation, the use of input token fertilities as a latent variable, and policy gradient fine-tuning, we achieve this at a cost of as little as 2.0 BLEU points relative to the autoregressive Transformer network used as a teacher. We demonstrate substantial cumulative improvements associated with each of the three aspects of our training strategy, and validate our approach on IWSLT 2016 English--German and two WMT language pairs. By sampling fertilities in parallel at inference time, our non-autoregressive model achieves near-state-of-the-art performance of 29.8 BLEU on WMT 2016 English--Romanian.  
 Relation classification is an important semantic processing task in the field of natural language processing . In this paper, we present a novel model, Structure Regularized Bidirectional Recurrent Convolutional Neural Network, to classify the relation of two entities in a sentence, and the new dataset of Chinese Sanwen for named entity recognition and relation classification. Some state-of-the-art systems concentrate on modeling the shortest dependency path  between two entities leveraging convolutional or recurrent neural networks. We further explore how to make full use of the dependency relations information in the SDP and how to improve the model by the method of structure regularization. We propose a structure regularized model to learn relation representations along the SDP extracted from the forest formed by the structure regularized dependency tree, which benefits reducing the complexity of the whole model and helps improve the $F_{1}$ score by 10.3. Experimental results show that our method outperforms the state-of-the-art approaches on the Chinese Sanwen task and performs as well on the SemEval-2010 Task 8 dataset\footnote{The Chinese Sanwen corpus this paper developed and used will be released in the further. }.  
 Huge volumes of textual information has been produced every single day. In order to organize and understand such large datasets, in recent years, summarization techniques have become popular. These techniques aims at finding relevant, concise and non-redundant content from  such a big data. While network methods have been adopted to model texts in some scenarios, a systematic evaluation of multilayer network models in the multi-document summarization task has been limited to a few studies. Here, we evaluate the performance of a multilayer-based method to select the most relevant sentences in the context of an extractive multi document summarization  task.  In the adopted model, nodes represent sentences and  edges are created based on the number of shared words between sentences. Differently from previous studies in multi-document summarization, we make a distinction between edges linking sentences from different documents  and those connecting sentences from the same document .  As a proof of principle, our results reveal that such a discrimination between intra- and inter-layer in a multilayered representation is able to improve the quality of the generated summaries. This piece of information could be used to improve current statistical methods and related textual models. 
   Extracting relations from text corpora is an important task in text mining. It becomes particularly challenging when focusing on weakly-supervised relation extraction, that is, utilizing a few relation instances  as seeds to extract more instances from corpora. Existing distributional approaches leverage the corpus-level co-occurrence statistics of entities to predict their relations, and require large number of labeled instances to learn effective relation classifiers.  Alternatively, pattern-based approaches perform bootstrapping or apply neural networks to model the local contexts, but still rely on large number of labeled instances to build reliable models.  In this paper, we study integrating the distributional and pattern-based methods in a weakly-supervised setting, such that the two types of methods can provide complementary supervision for each other to build an effective, unified model. We propose a novel co-training framework with a distributional module and a pattern module. During training, the distributional module helps the pattern module  between the informative patterns and other patterns, and the pattern module  some highly-confident instances to improve the distributional module. The whole framework can be effectively optimized by iterating between improving the pattern module and updating the distributional module. We conduct experiments on two tasks: knowledge base completion with text corpora and corpus-level relation extraction. Experimental results prove the effectiveness of our framework in the weakly-supervised setting.  %To combine their merits and reduce the reliance on seed instances, several studies try to integrate both approaches. However, these approaches still require a lot of seeds during training, leading to unsatisfactory performance in the weakly-supervised setting. Towards better performance under limited seeds, we propose a novel framework to integrate a distributional and pattern module. During training, we encourage both modules to produce extra supervision to each other, which effectively complements the given seed instances. Specifically, the distributional module will help the pattern module  the reliable patterns from others, and the pattern module will  some highly-confident instances to guide the distributional module.  %The whole framework can be effectively optimized by iterating between improving the pattern module and updating the distributional module. We conduct experiments on two tasks: knowledge base completion and corpus-level relation extraction. Experimental results prove the effectiveness of our approach over many competitive baselines.   
     Representing the semantics of words is a long-standing problem for the natural language processing community. Most methods  compute word semantics given their textual context in large corpora. More recently, researchers attempted to integrate perceptual and visual features. Most of these works consider the visual appearance of objects to enhance word representations but they ignore the visual environment and context in which objects appear. We propose to unify text-based techniques with vision-based techniques by simultaneously leveraging textual and visual context to learn multimodal word embeddings. We explore various choices for what can serve as a visual context and present an end-to-end method to integrate visual context elements in a multimodal skip-gram model. We provide experiments and extensive analysis of the obtained results.  
  We present a document-level neural machine translation model which takes both source and target document context into account using memory networks. % We model the problem as a structured prediction problem with interdependencies among the observed and hidden variables, i.e., the source sentences and their unobserved target translations in the document.  % The resulting structured prediction problem is tackled with a neural translation model equipped with two  memory components, one each for the source and target side, to capture the documental interdependencies. % We train the model end-to-end, and propose an iterative decoding algorithm based on block coordinate descent. % Experimental results of English translations from French, German, and Estonian documents show that our model is effective in exploiting both source and target document context, and statistically significantly outperforms the previous work in terms of BLEU and METEOR.   
 Speech recognition systems have achieved high recognition performance for several tasks. However, the performance of such systems is dependent on the tremendously costly development work of preparing vast amounts of task-matched transcribed speech data for supervised training. The key problem here is the cost of transcribing speech data. The cost is repeatedly required to support new languages and new tasks. Assuming broad network services for transcribing speech data for many users, a system would become more self-sufficient and more useful if it possessed the ability to learn from very light feedback from the users without annoying them. In this paper, we propose a general reinforcement learning framework for speech recognition systems based on the policy gradient method. As a particular instance of the framework,  we also propose a hypothesis selection-based reinforcement learning method. The proposed framework provides a new view for several existing training and adaptation methods. The experimental results show that the proposed method improves the recognition performance compared to unsupervised adaptation. % for the supervised training required to support new tasks. %This method is based on selecting the best recognition hypothesis among two hypotheses, %which is a binary outcome for the system for outputting two ranked hypotheses for each input utterance. 
 Task-oriented dialogue systems can efficiently serve a large number of customers and relieve people from tedious works. However, existing task-oriented dialogue systems depend on handcrafted actions and states or extra semantic labels, which sometimes degrades user experience despite the intensive human intervention. Moreover, current user simulators have limited expressive ability so that deep reinforcement Seq2Seq models have to rely on selfplay and only work in some special cases. To address those problems, we propose a uSer and Agent Model IntegrAtion  framework inspired by an observation that the roles of the user and agent models are asymmetric. Firstly, this SAMIA framework model the user model as a Seq2Seq learning problem instead of ranking or designing rules. Then the built user model is used as a leverage to train the agent model by deep reinforcement learning. In the test phase, the output of the agent model is filtered by the user model to enhance the stability and robustness. Experiments on a real-world coffee ordering dataset verify the effectiveness of the proposed SAMIA framework. 
  Reading comprehension is a challenging task in natural language processing  %that requires a considerable set of language analysis tasks and requires a set of skills  % to be solved. While current approaches focus on solving the task as a whole, %in isolation,  in this paper, we propose to use a neural network `skill' transfer approach. We transfer knowledge from several lower-level language tasks  including %such as textual entailment, named entity recognition, paraphrase detection and question type classification %, etc.\  into the reading comprehension model. %relation classification, text classification and sequence labeling %entity extraction, paraphrasing   We conduct an %extensive  empirical evaluation and show that  transferring language skill knowledge %skills  leads to significant improvements for the task with much fewer steps compared to the baseline model. We also show that the skill transfer approach is effective even with small amounts of training data. %and in comparison to existing state-of-the-art models. Another finding of this work is that using token-wise deep label supervision for text classification improves the performance  of  %with  transfer learning.  %%%%  In this work we investigate the impact of transferring knowledge from popular supervised tasks to the task of reading comprehension. We propose method for knowledge transfer from relation classification, text classification and sequence labeling tasks. We show that these tasks have impact on training the model, early in training and leads to better overall performance compared to the model without used skill tasks. We also propose that using pre-trained skill tasks can be used for evaluation of the required knowledge for a specific dataset. 
   Supervised approaches for text summarisation suffer from the problem   of mismatch between the target labels/scores of individual sentences   and the evaluation score of the final summary. Reinforcement   learning can solve this problem by providing a learning mechanism   that uses the score of the final summary as a guide to determine the   decisions made at the time of selection of each sentence. In this   paper we present a proof-of-concept approach that applies a   policy-gradient algorithm to learn a stochastic policy using an   undiscounted reward. The method has been applied to a policy   consisting of a simple neural network and simple features. The   resulting deep reinforcement learning system is able to learn a   global policy and obtain encouraging results. 
 We introduce kbgan, an adversarial learning framework to improve the performances of a wide range of existing knowledge graph embedding models. Because knowledge graphs typically only contain positive facts, sampling useful negative training examples is a non-trivial task. Replacing the head or tail entity of a fact with a uniformly randomly selected entity is a conventional method for generating negative facts, but the majority of the generated negative facts can be easily discriminated from positive facts, and will contribute little towards the training. Inspired by generative adversarial networks , we use one knowledge graph embedding model as a negative sample generator to assist the training of our desired model, which acts as the discriminator in gans.  %The objective of the generator is to generate difficult negative samples that can maximize their likeliness determined by the discriminator, while the discriminator minimizes its training loss. This framework is independent of the concrete form of generator and discriminator, and therefore can utilize a wide variety of knowledge graph embedding models as its building blocks. In experiments, we adversarially train two translation-based models, TransE and TransD, each with assistance from one of the two probability-based models, DistMult and ComplEx. We evaluate the performances of kbgan on the link prediction task, using three knowledge base completion datasets: FB15k-237, WN18 and WN18RR. Experimental results show that adversarial training substantially improves the performances of target embedding models under various settings. 
    We consider probabilistic topic models and more recent word embedding techniques from a perspective of learning hidden semantic representations. Inspired by a striking similarity of the two approaches, we merge them and learn probabilistic embeddings with online EM-algorithm on word co-occurrence data. The resulting embeddings perform on par with Skip-Gram Negative Sampling  on word similarity tasks and benefit in the interpretability of the components. Next, we learn probabilistic document embeddings that outperform paragraph2vec on a document similarity task and require less memory and time for training. Finally, we employ multimodal Additive Regularization of Topic Models  to obtain a high sparsity and learn embeddings for other modalities, such as timestamps and categories. We observe further improvement of word similarity performance and meaningful inter-modality similarities.  
 , including global attention and local attention, plays a key role in neural machine translation . Global attention attends to all source words for word prediction. In comparison, local attention selectively looks at fixed-window source words. However, alignment weights for the current target word often decrease to the left and right by linear distance centering on the aligned source position and neglect syntax distance constraints. In this paper, we extend the local attention with syntax-distance constraint, which focuses on syntactically related source words with the predicted target word to learning a more effective context vector for predicting translation. Moreover, we further propose a double context NMT architecture, which consists of a global context vector and a syntax-directed context vector from the global attention, to provide more translation performance for NMT from source representation. The experiments on the large-scale Chinese-to-English and English-to-German translation tasks show that the proposed approach achieves a substantial and significant improvement over the baseline system. 
 Modeling natural language inference is a very challenging task. With the availability of large annotated data, it has recently become feasible to train complex models such as neural-network-based inference models, which have shown to achieve the state-of-the-art performance. Although there exist relatively large annotated data, can machines learn all knowledge needed to perform natural language inference  from these data? If not, how can neural-network-based NLI models benefit from external knowledge and how to build NLI models to leverage it? In this paper, we enrich the state-of-the-art neural natural language inference models with external knowledge. We demonstrate that the proposed models improve neural NLI models to achieve the state-of-the-art performance on the SNLI and MultiNLI datasets.  
 		Character-based sequence labeling framework is flexible and efficient for Chinese word segmentation . 		Recently, many character-based neural models have been applied to CWS. While they obtain good performance, they have two obvious weaknesses. The first is that they heavily rely on manually designed bigram feature, i.e. they are not good at capturing -gram features automatically. The second is that they make no use of full word information. For the first weakness, we propose a convolutional neural model, which is able to capture rich $n$-gram features without any feature engineering. 		For the second one, we propose an effective approach to integrate the proposed model with word embeddings. 		We evaluate the model on two benchmark datasets: PKU and MSR. Without any feature engineering, the model obtains competitive performance --- 95.7\% on PKU and 97.3\% on MSR. Armed with word embeddings, the model achieves state-of-the-art performance on both datasets --- 96.5\% on PKU and 98.0\% on MSR, without using any external labeled resource. 	
 There has been much recent work on training neural attention models at the sequence-level using either reinforcement learning-style methods or by optimizing the beam. In this paper, we survey a range of classical objective functions that have been widely used to train linear models for structured prediction and apply them to neural sequence to sequence models. Our experiments show that these losses can perform surprisingly well by slightly outperforming beam search optimization in a like for like setup. We also report new state of the art results on both IWSLT'14 German-English translation as well as Gigaword abstractive summarization.  On the large WMT'14 English-French task, sequence-level training achieves 41.5 BLEU which is on par with the state of the art.\footnote{An implementation of the losses is available as part of fairseq at:\\ \url{https://github.com/pytorch/fairseq/tree/classic_seqlevel}} 
 This paper presents a novel neural model - Dynamic Fusion Network , for machine reading comprehension . DFNs differ from most state-of-the-art models in their use of a dynamic multi-strategy attention process, in which passages, questions and answer candidates are jointly fused into attention vectors, along with a dynamic multi-step reasoning module for generating answers. With the use of reinforcement learning, for each input sample that consists of a question, a passage and a list of candidate answers, an instance of DFN with a sample-specific network architecture can be dynamically constructed by determining what attention strategy to apply and how many reasoning steps to take. Experiments show that DFNs achieve the best result reported on RACE, a challenging MRC dataset that contains real human reading questions in a wide variety of types. A detailed empirical analysis also demonstrates that DFNs can produce attention vectors that summarize information from questions, passages and answer candidates more effectively than other popular MRC models.  
   This paper describes a neural semantic parser that maps natural   language utterances onto logical forms which can be executed against   a task-specific environment, such as a knowledge base or a database,   to produce a response.  The parser generates tree-structured logical   forms with a transition-based approach which combines a generic   tree-generation algorithm with domain-general grammar defined by   the logical language.  The generation process is modeled by   structured recurrent neural networks, which provide a rich encoding   of the sentential context and generation history for making   predictions.  To tackle mismatches between natural language and   logical form tokens, various attention mechanisms are explored.   Finally, we consider different training settings for the neural   semantic parser, including  fully supervised training where   annotated logical forms are given, weakly-supervised training where   denotations are provided, and distant supervision where only   unlabeled sentences and a knowledge base are available. Experiments   across a wide range of datasets demonstrate the effectiveness of our   parser. 
 Ensemble methods are one the influential learning techniques that as a meta learning framework can easily apply to other field of machine learning. It combines several weak learners to build a new strong learner. in this paper we propose a neural network with ensemble loss function that the weight of each weak loss function is learned in training phase. Several text datasets are utilized to evaluate the performance of the proposed method.    
  Understanding procedural language requires anticipating  the causal effects of actions, even when they are not explicitly stated. In this work, we introduce Neural Process Networks  to understand procedural text through  simulation of action dynamics. Our model complements existing memory architectures with dynamic entity tracking by explicitly modeling actions as state transformers. The model updates the states of the entities by executing learned action operators. Empirical results demonstrate that our proposed model can reason about the unstated causal effects of actions, allowing it to provide more accurate contextual information for understanding and generating procedural text, all while offering more interpretable internal representations than existing alternatives.  
 Although transfer learning has been shown to be successful for tasks like object and speech recognition, its applicability to question answering~ has yet to be well-studied. In this paper, we conduct extensive experiments to investigate the transferability of knowledge learned from a source QA dataset to a target dataset using two QA models. The performance of both models on a TOEFL listening comprehension test~ and MCTest~ is significantly improved via a simple transfer learning technique from MovieQA~. In particular, one of the models achieves the state-of-the-art on all target datasets; for the TOEFL listening comprehension test, it outperforms the previous best model by 7\%. Finally, we show that transfer learning is helpful even in unsupervised scenarios when correct answers for target QA dataset examples are not available. 
  In this paper, we describe an effective convolutional neural network framework for identifying the expert in question answering community. This approach uses the convolutional neural network and combines user feature representations with question feature representations to compute scores that the user who gets the highest score is the expert on this question. Unlike prior work, this method does not measure expert based on measure answer content quality to identify the expert but only require question sentence and user embedding feature to identify the expert. Remarkably, Our model can be applied to different languages and different domains. The proposed framework is trained on two datasets, The first dataset is Stack Overflow and the second one is Zhihu. The Top-1 accuracy results of our experiments show that our framework outperforms the best baseline framework for expert identification.   
 In this paper, we propose a sequential neural encoder with latent structured description  for modeling sentences. This model introduces latent chunk-level representations into conventional sequential neural encoders, i.e., recurrent neural networks  with long short-term memory  units, to consider the compositionality of languages in semantic modeling. An SNELSD model has a hierarchical structure that includes a detection layer and a description layer. The detection layer predicts the  boundaries of latent word chunks in an input sentence and derives a chunk-level vector for each word. The description layer utilizes modified LSTM units to process these chunk-level vectors in a recurrent manner and produces sequential encoding outputs. These output vectors  are further concatenated with word vectors or the outputs of a chain LSTM encoder to obtain the final sentence representation. %which is inspired by human cognition mechanism that people tend to split sentences into several essential target-related parts while reading. %Unlike Tree-LSTM utilizing the syntactic parsing structure information, the SNELS model can learn to 'chunk' sentences into word blocks All the model parameters are learned in an end-to-end manner without a dependency on additional text chunking or syntax parsing. %In other words, it can exploit the latent structure information in sentences which is task-dependent. Further more, the SNELS has a 2-layer hierarchical chain structure, which means that it can own the comparative efficiency in computation to LSTMs models but also can utilize some structure information that flat-chain structure's LSTMs models cannot. A natural language inference  task and a sentiment analysis  task are adopted to evaluate the performance of our proposed model. The experimental results demonstrate the effectiveness of the proposed SNELSD model on exploring task-dependent chunking patterns during the semantic modeling of sentences. Furthermore, the proposed method achieves better performance than conventional chain LSTMs and tree-structured LSTMs on both tasks.  %In practical test on natural language inference  and sentiment analysis  tasks, the SNELS model can truly capture some useful and regular 'chunking' pattern that consistent to human cognition process on corresponding task in some way. Moreover, the 'chunking' pattern of SNELS on these two tasks are apparently different, which means that our SNELS can utilize the task-dependent latent structure information. Anyway, SNELS can outperform the ordinary LSTMs and Tree-LSTM models on NLI and do not show weak performance than those models on SA task. On the whole, the SNELS model is promising to be fitted to natural language processing task. 
 Dialogue Act Recognition  is a challenging problem in dialogue interpretation, which aims to attach semantic labels to utterances and characterize the speaker's intention. Currently, many existing approaches formulate the DAR problem ranging from multi-classification to structured prediction, which suffer from handcrafted feature extensions and attentive contextual structural dependencies. In this paper, we consider the problem of DAR from the viewpoint of extending richer Conditional Random Field  structural dependencies without abandoning end-to-end training. We incorporate hierarchical semantic inference with memory mechanism on the utterance modeling. We then extend structured attention network to the linear-chain conditional random field layer which takes into account both contextual utterances and corresponding dialogue acts. The extensive experiments on two major benchmark datasets Switchboard Dialogue Act  and Meeting Recorder Dialogue Act  datasets show that our method achieves better performance than other state-of-the-art solutions to the problem. It is a remarkable fact that our method is nearly close to the human annotator's performance on SWDA within 2\% gap. 
 \iffalse We investigate the problem of dynamic topic modeling where the discovered topics at each time  influence the topic discovery in the subsequent time steps in the unstructured document collections. % that captures popular topics and longer trends over time.  We introduce a novel unsupervised dynamic topic model based on %probabilistic and undirected graphical  recurrent neural network, known as RNN-RSM  with  distributional estimators conditioned on time feedback connections that is able to utilize temporal ordering of documents  by explicit latent topical dependencies over time to improve popular topic discovery,   capture better trends of the discovered topics and word usage in topics over time. Experimental results %on topic and trend detection  show that the proposed model shows better generalization, topic interpretation, evolution and trends  due to recurrent connections in estimating  joint distribution over time.  %[Our approach outperforms traditional models in classification performace, log-probability of held-out documents and/or the retrieval accuracy.] %We demonstrate the topic evolution detection by topic popularity and focus change in scientific articles over time.  We also propose to compute SPAN for popular topic-terms discovered  to show topic characterization in scientific articles over time.  \fi Dynamic topic modeling facilitates the identification of topical trends over time in temporal collections of unstructured documents.  We introduce a novel unsupervised neural dynamic topic model %based on recurrent neural network,  named as Recurrent Neural Network-Replicated Softmax Model , where the discovered topics at each time influence the topic discovery in the subsequent time steps. We account for the temporal ordering of documents by explicitly modeling a joint distribution of latent topical dependencies over time, using distributional estimators with temporal recurrent connections. Applying RNN-RSM to 19 years of articles on NLP research, we demonstrate that compared to state-of-the art topic models, RNN-RSM shows better generalization, topic interpretation, evolution and trends. We also introduce a metric  to quantify the capability of dynamic topic model to capture word evolution in topics over time. 
 Knowledge bases , both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. A popular approach to KB completion is to infer new relations by combinatory reasoning over the information found along other paths connecting a pair of entities. Given the enormous size of KBs and the exponential number of paths, previous path-based models have considered only the problem of predicting a missing relation given two entities, or evaluating the truth of a proposed triple. Additionally, these methods have traditionally used random paths between fixed entity pairs or more recently learned to pick paths between them. We propose a new algorithm, \alg, which addresses the much more difficult and practical task of answering questions where the relation is known, but only one entity. Since random walks are impractical in a setting with unknown destination and combinatorially many paths from a start node, we present a neural reinforcement learning approach which learns how to navigate the graph conditioned on the input query to find predictive paths. On a comprehensive evaluation on seven knowledge base datasets, we found \alg to be competitive with many current state-of-the-art methods.   % Empirically, this approach is competitive with many current state-of-the-art methods a\rd{nd is significantly faster than previous methods at inference time}\footnote{\url{https://github.com/shehzaadzd/MINERVA}}.   % that infers facts represented implicitly in a KB to solve a practical query answering task involving predicting which entity is the answer to a question. \alg is based on neural reinforcement learning and learns how to navigate the graph to find predictive paths. Empirically, \alg obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods. % \rd{It would be better if we can end this with a stronger punch line.} \ak{I agree -- can replace with some percentage.}  
 Though deep neural networks have great success in natural language processing, %such as machine translation and reading comprehension,  they are limited at more knowledge intensive AI tasks, such as open-domain Question Answering . Existing end-to-end deep QA models need to process the  text after observing the question, and therefore their complexity in responding a question is linear in the text size.  This is prohibitive for practical tasks such as QA from Wikipedia, a novel, or the Web. % We propose to solve this scalability issue by using symbolic meaning representations, which can be indexed and retrieved efficiently with complexity that is independent of the text size. %More specifically, we use sequence-to-sequence models to encode knowledge symbolically and generate programs to answer questions from the encoded knowledge. % %We apply our approach, called the N-Gram Machine , to the bAbI tasks~ and a special version of them  which has stories of up to 10 million sentences.  %Our experiments show that NGM can successfully solve both of these tasks accurately and efficiently. %Unlike fully differentiable memory models, NGM's time complexity and answering quality are not affected by the story length. % % The whole system of NGM is trained end-to-end with REINFORCE~. % To avoid high variance in gradient estimation, which is typical in discrete latent variable models, we use beam search instead of sampling. % To tackle the exponentially large search space, we use a stabilized auto-encoding objective and a structure tweak procedure to iteratively reduce and refine the search space. %Automatic ontology induction is a key yet unsolved problem in AI.  %We conduct experiments on the WikiMovies dataset to test NGM's ability to induce an ontology from natural language text  with only weak supervision , and correctly answer questions from the constructed ontology. % We apply our approach, called the N-Gram Machine , to three representative tasks. First as proof-of-concept, we demonstrate that NGM successfully solves the bAbI tasks of synthetic text. Second, we show that NGM scales to large corpus by experimenting on ``life-long bAbI'', a special version of bAbI that contains millions of sentences. Lastly on the WikiMovies dataset, we use NGM to induce latent structure  and answer questions from natural language Wikipedia text, with only QA pairs as weak supervision. 
 Incorporating syntactic information in Neural Machine Translation models is a method to compensate their requirement for a large amount of parallel training text, specially for low-resource language pairs. Previous works on using syntactic information provided by  parsers has been promising. In this paper, we propose a forest-to-sequence Attentional Neural Machine Translation model to make use of exponentially many parse trees of the source sentence to compensate for the parser errors. Our method represents the collection of parse trees as a packed forest, and learns a neural attentional transduction model from the forest to the target sentence. Experiments on English to German, Chinese and Persian translation show the superiority of our method over the tree-to-sequence and vanilla sequence-to-sequence neural translation models. 
 Temporal gates play a significant role in modern recurrent-based neural encoders, enabling fine-grained control over recursive compositional operations over time. In recurrent models such as the long short-term memory , temporal gates control the amount of information retained or discarded over time, not only playing an important role in influencing the learned representations but also serving as a protection against vanishing gradients. This paper explores the idea of learning temporal gates for sequence pairs , jointly influencing the learned representations in a pairwise manner. In our approach, temporal gates are learned via 1D convolutional layers and then subsequently cross applied across question and answer for joint learning. Empirically, we show that this conceptually simple sharing of temporal gates can lead to competitive performance across multiple benchmarks. Intuitively, what our network achieves can be interpreted as learning representations of question and answer pairs that are aware of what each other is remembering or forgetting, i.e., pairwise temporal gating. Via extensive experiments, we show that our proposed model achieves state-of-the-art performance on two community-based QA datasets and competitive performance on one factoid-based QA dataset.  
 Sentiment analysis is attracting more and more attentions and has become a very hot research topic due to its potential applications in personalized recommendation, opinion mining, etc. Most of the existing methods are based on either textual or visual data and can not achieve satisfactory results, as it is very hard to extract sufficient information from only one single modality data. Inspired by the observation that there exists strong semantic correlation between visual and textual data in social medias, we propose an end-to-end deep fusion convolutional neural network to jointly learn textual and visual sentiment representations from training examples. The two modality information are fused together in a pooling layer and fed into fully-connected layers to predict the sentiment polarity. We evaluate the proposed approach on two widely used data sets. Results show that our method achieves promising result compared with the state-of-the-art methods which clearly demonstrate its competency. 
 In this paper, we proposed two strategies which can be applied to a multilingual neural machine translation  system in order to better tackle zero-shot scenarios despite not having any parallel corpus.  The experiments show that they are effective in terms of both performance and computing resources, especially in multilingual translation of unbalanced data in real zero-resourced condition when they alleviate the language bias problem.  
% Biomedical named entity recognition  is a fundamental task in text mining of medical documents and has many applications. Deep learning based approaches to this task have been gaining increasing attention in recent years as their parameters can be learned end-to-end without the need for hand-engineered features. However, these approaches rely on high-quality labeled data, which is expensive to obtain. To address this issue, we investigate how to use unlabeled text data to improve the performance of NER models. Specifically, we train a bidirectional language model  on unlabeled data and transfer its weights to ``pretrain" an NER model with the same architecture as the BiLM, which results in a better parameter initialization of the NER model. We evaluate our approach on four benchmark datasets for biomedical NER and show that it leads to a substantial improvement in the F1 scores compared with the state-of-the-art approaches. We also show that BiLM weight transfer leads to a faster model training and the pretrained model requires fewer training examples to achieve a particular F1 score. 
 Contrary to most natural language processing research, which makes use of static datasets,  humans learn language interactively, grounded in an environment.  In this work we propose an interactive learning procedure called Mechanical Turker Descent  and use it to train agents to execute natural language commands grounded in a fantasy text adventure game. In MTD, Turkers { by sharing their agents' skills in the long term.  This results in a gamified, engaging experience for the Turkers and a better quality teaching signal for the agents compared to static datasets, as the Turkers naturally adapt the training data to the agent's abilities. 
 Unsupervised domain adaptation of speech signal aims at adapting a well-trained source-domain acoustic model to the unlabeled data from target domain. This can be achieved by adversarial training of deep neural network  acoustic models to learn an intermediate deep representation that is both senone-discriminative and domain-invariant. Specifically, the DNN is trained to jointly optimize the primary task of senone classification and the secondary task of domain classification with adversarial objective functions. In this work, instead of only focusing on learning a domain-invariant feature , we also characterize the difference between the source and target domain distributions by explicitly modeling the private component of each domain through a private component extractor DNN. The private component is trained to be orthogonal with the shared component and thus implicitly increases the degree of domain-invariance of the shared component. A reconstructor DNN is used to reconstruct the original speech feature from the private and shared components as a regularization. This domain separation framework is applied to the unsupervised environment adaptation task and achieved 11.08\% relative WER reduction from the gradient reversal layer training, a representative adversarial training method, for automatic speech recognition on CHiME-3 dataset. 
     Dialog response selection is an important step towards natural response generation in conversational agents. Existing work on neural conversational models mainly focuses on offline supervised learning using a large set of context-response pairs. In this paper, we focus on online learning of response selection in retrieval-based dialog systems. We propose a contextual multi-armed bandit model with a nonlinear reward function that uses distributed representation of text for online response selection. A bidirectional LSTM is used to produce the distributed representations of dialog context and responses, which serve as the input to a contextual bandit. In learning the bandit, we propose a customized Thompson sampling method that is applied to a polynomial feature space in approximating the reward. Experimental results on the Ubuntu Dialogue Corpus demonstrate significant performance gains of the proposed method over conventional linear contextual bandits. Moreover, we report encouraging response selection performance of the proposed neural bandit model using the Recall@k metric for a small set of online training samples. 
 Nowadays, it is a heated topic for many industries to build automatic question-answering  systems. A key solution to these QA systems is to retrieve from a QA knowledge base the most similar question of a given question, which can be reformulated as a paraphrase identification  or a natural language inference  problem. However, most existing models for PI and NLI have at least two problems: They rely on a large amount of labeled data, which is not always available in real scenarios, and they may not be efficient for industrial applications.  %However, most existing models for this problem heavily rely on a large amount of labeled data, which may not be always available in real scenarios. In this paper, we study transfer learning for the PI and NLI problems, aiming to propose a general framework, which can effectively and efficiently adapt the shared knowledge learned from a resource-rich source domain to a resource-poor target domain. %help improve the model performance of a resource-poor target domain. Specifically, since most existing transfer learning methods only focus on learning a shared feature space across domains while ignoring the relationship between the source and target domains, we propose to simultaneously learn shared representations and domain relationships in a unified framework. %Moreover, to encourage the shared representations to be more robust against the shift across domains, we also consider to incorporate adversarial training into our method. Furthermore, we propose an efficient and effective hybrid model by combining a sentence encoding-based method and a sentence interaction-based method as our base model. %Under the transfer learning framework, we further combine a sentence encoding-based method and a sentence interaction-based method as our basic model in order to learn rich representations for every sentence pair. Extensive experiments on both paraphrase identification and natural language inference demonstrate that our base model is efficient and has promising performance compared to the competing models, and our transfer learning method can help to significantly boost the performance. %the effectiveness and efficiency of the hybrid basic model and our transfer learning method. %and show that incorporating adversarial training into our transfer learning method can further boost the performance Further analysis shows that the inter-domain and intra-domain relationship captured by our model are insightful. Last but not least, we deploy our transfer learning model for PI into our online chatbot system, which can bring in significant improvements over our existing system.  Finally, we launch our new system on the chatbot platform Eva\footnote{\url{https://gcx.aliexpress.com/ae/evaenglish/portal.htm?pageId=195440}} in our E-commerce site AliExpress\footnote{\url{http://www.aliexpress.com/}}. 
 Prediction without justification has limited utility. Much of the success of neural models can be attributed to their ability to learn rich, dense and expressive representations. While these representations capture the underlying complexity and latent trends in the data, they are far from being interpretable. We propose a novel variant of denoising $k$-sparse autoencoders that generates highly efficient and interpretable distributed word representations , beginning with existing word representations from state-of-the-art methods like GloVe and word2vec. Through large scale human evaluation, we report that our resulting word embedddings are much more interpretable than the original GloVe and word2vec embeddings. Moreover, our embeddings outperform existing popular word embeddings on a diverse suite of benchmark downstream tasks\footnote{Our code and generated word vectors are publicly available at \url{https://github.com/harsh19/SPINE}}. 
 Word embeddings are the interface between the world of discrete units of  text processing and the continuous, differentiable world of neural networks. In  this work, we examine various random and pretrained initialization methods  for embeddings used in deep networks and their effect on the performance on  four NLP tasks with both recurrent and convolutional architectures. We confirm that pretrained embeddings are a little better than random initialization, especially considering the speed of learning. On the other hand, we do not see any significant difference between various methods of random initialization, as long as the variance is kept reasonably low. High-variance initialization prevents the network to use the space of embeddings and forces it to use other free parameters to accomplish the task. We support this hypothesis by observing the performance in learning lexical relations and by the fact that the network can learn to perform reasonably in its task even with fixed random embeddings. % To shed some light on what the embedding space represents, we test to what % extent the learned embeddings reveal selected morphological and semantic % relations between words. % %We explore the embeddings space % %aiming to answer % %the question of what they represent and if they can learn morphological or  % %semantic relations between words. % In the second part, we propose and justify a strategy for random % embeddings initialization and show that even all-zero initialization leads to a % good performance. 
 In this paper, we propose an adversarial process for abstractive text summarization, in which we simultaneously train a generative model $G$ and  a discriminative model $D$.  In particular,  we build the generator $G$ as an agent of reinforcement learning, which takes the raw text as input and predicts the abstractive summarization.  We also build a discriminator which attempts to distinguish the generated summary from the ground truth summary.  Extensive experiments demonstrate that our model achieves competitive ROUGE scores with the state-of-the-art methods on CNN/Daily Mail dataset.  Qualitatively, we show that our model is able to generate more abstractive, readable and diverse summaries\footnote{Supplemental material: http://likicode.com/textsum/}.  
 Existing neural machine translation  models generally translate sentences in isolation, missing the opportunity to take advantage of document-level information. In this work, we propose to augment NMT models with a very light-weight cache-like memory network, which stores recent hidden representations as translation history. The probability distribution over generated words is updated online depending on the translation history retrieved from the memory, endowing NMT models with the capability to dynamically adapt over time. Experiments on multiple domains with different topics and styles show the effectiveness of the proposed approach with negligible impact on the computational cost. 
 Text attribute transfer using non-parallel data requires methods that can perform disentanglement of content and linguistic attributes.  In this work, we propose multiple improvements over the existing approaches that enable the encoder-decoder framework to cope with the text attribute transfer from non-parallel data. We perform experiments on the sentiment transfer task using two datasets. For both datasets, our proposed method outperforms a strong baseline in two of the three employed evaluation metrics. % Text style transfer delves into changing linguistic attributes of the text while making sure that the content is retained. This work extends the behavior of Natural Language Generation systems to incorporate the desired style while generating the text and yet preserving the content. Our method builds upon the encoder decoder architecture that disentangles style from the content of the text. However, as we don't usually have parallel data, we propose a novel method of using collaborative classifier and various content preservation losses to solve the problem. We analyze the effectiveness of our approach using sentiment transfer tasks which uses non-parallel monolingual data. 
 		Existing neural machine translation systems do not explicitly model what has been translated and what has not during the decoding phase. 		To address this problem, we propose a novel mechanism that separates the source information into two parts: translated Past contents and untranslated Future contents, which are modeled by two additional recurrent layers. The Past and Future contents are fed to both the attention model and the decoder states, which provides NMT systems with the knowledge of translated and untranslated contents. Experimental results show that the proposed approach significantly improves the performance in Chinese-English, German-English, and English-German translation tasks. Specifically, the proposed model outperforms the conventional coverage model in terms of both the translation quality and the alignment error rate.\footnotemark[2]%\footnote{The code will be released upon the acceptance of this paper.} 	
 Deep learning methods have recently achieved great empirical success on machine translation, dialogue response generation, summarization, and other text generation tasks. At a high level, the technique has been to train end-to-end neural network models consisting of an encoder model to produce a hidden representation of the source text, followed by a decoder model to generate the target. While such models have significantly fewer pieces than earlier systems, significant tuning is still required to achieve good performance. For text generation models in particular, the decoder can behave in undesired ways, such as by generating truncated or repetitive outputs, outputting bland and generic responses, or in some cases producing ungrammatical gibberish. This paper is intended as a practical guide for resolving such undesired behavior in text generation models, with the aim of helping enable real-world applications.  \vfill 
 Intelligent code completion has become an essential research task to accelerate modern software development. To facilitate effective code completion for dynamically-typed programming languages, we apply neural language models by learning from large codebases, and develop a tailored attention mechanism for code completion. However, standard neural language models even with attention mechanism cannot correctly predict the out-of-vocabulary  words that restrict the code completion performance. In this paper, inspired by the prevalence of locally repeated terms in program source code, and the recently proposed pointer copy mechanism, we propose a pointer mixture network for better predicting OoV words in code completion. Based on the context, the pointer mixture network learns to either generate a within-vocabulary word through an RNN component, or regenerate an OoV word from local context through a pointer component. Experiments on two benchmarked datasets demonstrate the effectiveness of our attention mechanism and pointer mixture network on the code completion task. 
   We consider the task of fine-grained sentiment analysis   from the perspective of multiple instance learning . Our neural    model is trained on document sentiment labels, and learns to predict the   sentiment of text segments, i.e. sentences or elementary discourse   units , without segment-level supervision. We introduce an   attention-based polarity scoring method for identifying positive    and negative text snippets and a new dataset which we call SpoT     for evaluating MIL-style sentiment models like ours.    Experimental results demonstrate superior performance against multiple    baselines, whereas a judgement elicitation study shows that EDU-level opinion    extraction produces more informative summaries than sentence-based   alternatives.  
  Recurrent neural language models are the state-of-the-art models for language modeling. When the vocabulary size is large, the space taken to store the model parameters becomes the bottleneck for the use of recurrent neural language models. In this paper, we introduce a simple space compression method that randomly shares the structured parameters at both the input and output embedding layers of the recurrent neural language models to significantly reduce the size of model parameters, but still compactly represent the original input and output embedding layers. The method is easy to implement and tune. Experiments on several data sets show that the new method can get similar perplexity and BLEU score results while only using a very tiny fraction of parameters. 
 This paper presents a new adversarial learning method for generative conversational agents  besides a new model of GCA. Similar to previous works on adversarial learning for dialogue generation, our method assumes the GCA as a generator that aims at fooling a discriminator that labels dialogues as human-generated or machine-generated; however, in our approach, the discriminator performs token-level classification, i.e. it indicates whether the current token was generated by humans or machines. To do so, the discriminator also receives the context utterances  and the incomplete answer up to the current token as input. This new approach makes possible the end-to-end training by backpropagation. Moreover, the trained discriminator can be used to choose the best answer among the answers generated by different trained models to improve the performance even more. A self-conversation process enables to produce a set of generated data with more diversity for the adversarial training. This approach improves the performance on questions not related to the training data. Experimental results with human and adversarial evaluations show that the adversarial method yields significant performance gains over the usual teacher forcing training. 
  We investigate how neural networks can learn and process languages with hierarchical, compositional semantics.   To this end, we define the artificial task of processing nested arithmetic expressions, and study whether different types of neural networks can learn to compute their meaning.  We find that recursive neural networks can implement a generalising solution to this problem, and we visualise this solution by breaking it up in three steps: project, sum and squash.  As a next step, we investigate recurrent neural networks, and show that a gated recurrent unit, that processes its input incrementally, also performs very well on this task: the network learns to predict the outcome of the arithmetic expressions with high accuracy, although performance deteriorates somewhat with increasing length.  To develop an understanding of what the recurrent network encodes, visualisation techniques alone do not suffice. Therefore, we develop an approach where we formulate and test multiple hypotheses on the information encoded and processed by the network. For each hypothesis, we derive predictions about features of the hidden state representations at each time step, and train `diagnostic classifiers' to test those predictions.  Our results indicate that the networks follow a strategy similar to our hypothesised `cumulative strategy', which explains the high accuracy of the network on novel expressions, the generalisation to longer expressions than seen in training, and the mild deterioration with increasing length. This in turn shows that diagnostic classifiers can be a useful technique for opening up the black box of neural networks. We argue that diagnostic classification, unlike most visualisation techniques, does scale up from small networks in a toy domain, to larger and deeper recurrent networks dealing with real-life data, and may therefore contribute to a better understanding of the internal dynamics of current state-of-the-art models in natural language processing. 
 In multi-turn dialogs, natural language understanding models can introduce obvious errors by being blind to contextual information. To incorporate dialog history, we present a neural architecture with  which encode utterances differently depending on the speaker. This addresses the different extents of information available to the system - the system knows only the surface form of user utterances while it has the exact semantics of system output. We performed experiments on real user data from Microsoft Cortana, a commercial personal assistant. The result showed a significant performance improvement over the state-of-the-art slot tagging models using contextual information. 
     In this paper, we present a neural network based task-oriented dialogue system that can be optimized end-to-end with deep reinforcement learning . The system is able to track dialogue state, interface with knowledge bases, and incorporate query results into agent's responses to successfully complete task-oriented dialogues. Dialogue policy learning is conducted with a hybrid supervised and deep RL methods. We first train the dialogue agent in a supervised manner by learning directly from task-oriented dialogue corpora, and further optimize it with deep RL during its interaction with users. In the experiments on two different dialogue task domains, our model demonstrates robust performance in tracking dialogue state and producing reasonable system responses. We show that deep RL based optimization leads to significant improvement on task success rate and reduction in dialogue length comparing to supervised training model. We further show benefits of training task-oriented dialogue model end-to-end comparing to component-wise optimization with experiment results on dialogue simulations and human evaluations.  
 The structure of curriculum plays a vital role in our learning process, both as children and adults. Presenting material in ascending order of difficulty that also exploits prior knowledge can have a significant impact on the rate of learning. However, the notion of difficulty and prior knowledge differs from person to person. Motivated by the need for a personalised curriculum, we present a novel method of curriculum learning for vocabulary words in the form of visual prompts. We employ a reinforcement learning model grounded in pedagogical theories that emulates the actions of a tutor. We simulate three students with different levels of vocabulary knowledge in order to evaluate the how well our model adapts to the environment. The results of the simulation reveal that through interaction, the model is able to identify the areas of weakness, as well as push students to the edge of their ZPD. We hypothesise that these methods can also be effective in training agents to learn language representations in a simulated environment where it has previously been shown that order of words and prior knowledge play an important role in the efficacy of language learning.  
 			%We study the problem of response generation for open domain conversation in a chatbot. Existing methods rely on static vocabularies, which not only makes them vulnerable to generic patterns and irrelevant noise, but also causes a high cost in online decoding. We propose a dynamic vocabulary sequence-to-sequence  model which allows each input to possess their own vocabulary in decoding. In inference, the model dynamically allocates a vocabulary for an input through a multivariate Bernoulli distribution on the entire vocabulary which only selects a few words useful in forming relevant and informative responses, and conducts decoding only with the small vocabulary. In training, vocabulary construction and response generation are jointly learned by maximizing a lower bound of the true objective with a Monte Carlo sampling method. Because of the dynamic vocabulary mechanism, DVS2S can elude many generic patterns and irrelevant words in generation and achieve high quality response generation and efficient decoding at the same time. Experimental results on both automatic metrics and human annotations show that DVS2S can significantly outperform state-of-the-art methods in terms of response quality, but only requires 60$\%$ decoding time compared to the most efficient baseline. 			 			We study response generation for open domain conversation in chatbots. Existing methods assume that words in responses are generated from an identical vocabulary regardless of their inputs, which not only makes them vulnerable to generic patterns and irrelevant noise, but also causes a high cost in decoding. We propose a dynamic vocabulary sequence-to-sequence  model which allows each input to possess their own vocabulary in decoding. In training, vocabulary construction and response generation are jointly learned by maximizing a lower bound of the true objective with a Monte Carlo sampling method. In inference, the model dynamically allocates a small vocabulary for an input with the word prediction model, and conducts decoding only with the small vocabulary.  Because of the dynamic vocabulary mechanism, DVS2S eludes many generic patterns and irrelevant words in generation, and enjoys efficient decoding at the same time. Experimental results on both automatic metrics and human annotations show that DVS2S can significantly outperform state-of-the-art methods in terms of response quality, but only requires 60$\%$ decoding time compared to the most efficient baseline. 			 		
  Sentences in a well-formed text are connected to each other via various links to form the cohesive structure of the text. Current neural machine translation  systems translate a text in a conventional sentence-by-sentence fashion, ignoring such cross-sentence links and dependencies. This may lead to generate an incoherent target text for a coherent source text. In order to handle this issue, we propose a cache-based approach to modeling coherence for neural machine translation by capturing contextual information either from recently translated sentences or the entire document. Particularly, we explore two types of caches:  a dynamic cache, which stores words from the best translation hypotheses of preceding sentences, and a topic cache, which maintains a set of  target-side topical words that are semantically related to the document to be translated. On this basis, we build a new layer to score target words in these two caches with a cache-based neural model. Here the estimated probabilities from the cache-based neural model are combined with NMT probabilities into the final word prediction probabilities via a gating mechanism. Finally, the proposed cache-based neural model is trained jointly with NMT system in an end-to-end manner.  Experiments and analysis presented in this paper demonstrate that the proposed cache-based model achieves substantial improvements over several state-of-the-art SMT and NMT baselines. %On several NIST Chinese-English translation tasks, our experiments demonstrate that the proposed cache-based model achieves substantial improvements over several state-of-the-art SMT and NMT baselines. %This may make the translation of a sentence ambiguous or even inconsistent with the translations of neighboring sentences.  
     The goal of this paper is to learn cross-domain representations for slot filling task in spoken language understanding . Most of the recently published SLU models are domain-specific ones that work on individual task domains. Annotating data for each individual task domain is both financially costly and non-scalable. In this work, we propose an adversarial training method in learning common features and representations that can be shared across multiple domains. Model that produces such shared representations can be combined with models trained on individual domain SLU data to reduce the amount of training samples required for developing a new domain. In our experiments using data sets from multiple domains, we show that adversarial training helps in learning better domain-general SLU models, leading to improved slot filling F1 scores. We further show that applying adversarial learning on domain-general model also helps in achieving higher slot filling performance when the model is jointly optimized with domain-specific models.  
 %Training deep neural networks requires massive amounts of training data, but for many tasks only limited labeled data is available. This makes weak supervision attractive, using weak or noisy signals like the output of heuristic methods or user click-through data for training. %  %In a semi-supervised setting, we can use a large set of data with weak labels to pretrain a neural network and then fine-tune the parameters with a small amount of data with true labels.  This feels intuitively sub-optimal as these two independent stages leave the model unaware about the varying label quality.  What if we could somehow inform the model about the label quality?      In this paper, we propose a semi-supervised learning method where we train two neural networks in a multi-task fashion: a \tnet and a \cnet.  The \tnet is optimized to perform a given task and is trained using a large set of unlabeled data that are weakly annotated.  We propose to weight the gradient updates to the \tnet using the scores provided by the second \cnet, which is trained on a small amount of supervised data.  Thus we avoid that the weight updates computed from noisy labels harm the quality of the \tnet model. We evaluate our learning strategy on two different tasks: document ranking and sentiment classification. The results demonstrate that our approach not only enhances the performance compared to the baselines but also speeds up the learning process from weak labels. 
 Text-based analysis methods enable an adversary to reveal privacy relevant author attributes such as gender, age and can identify the text's author.  Such methods can compromise the privacy of an anonymous author even when the author tries to remove privacy sensitive content. % In this paper, we propose an automatic method, called Adversarial Author Attribute Anonymity Neural Translation , to combat such text-based adversaries. %  % We propose a sequence-to-sequence language model, inspired by machine translation, and an adversarial training framework to design a system which learns to transform the input text to obfuscate author attributes without paired data. % We also propose and evaluate techniques to impose constraints on our \ant  to preserve the semantics of the input text. \ant learns to make minimal changes to the input  to successfully fool author attribute classifiers, while preserving the meaning of the input text. Our experiments on two datasets and three settings show that the proposed method is effective in fooling the author attribute classifiers and thus  improves the anonymity of authors.  
 State-of-the-art results on neural machine translation often use attentional sequence-to-sequence models with some form of convolution or recursion.  propose a new architecture that avoids recurrence and convolution completely. Instead, it uses only self-attention and feed-forward layers. While the proposed architecture achieves state-of-the-art results on several machine translation tasks, it requires a large number of parameters and training iterations to converge. We propose \name, a Transformer with modified attention layers, that not only outperforms the baseline network in BLEU score but also converges $15-40\%$ faster.  Specifically, we replace the multi-head attention by multiple self-attention branches that the model learns to combine during the training process.  %RS: Not a big fan of that sentence... hard for most readers to understand... Our model improves the state-of-the-art performance by $0.5$ BLEU points on the WMT 2014 English-to-German translation task and by $0.4$ on the English-to-French translation task. %It achieves the same performance as the original Transformer network with only 30\% of its parameters. 
 Nowadays, the amount of available digital documents is rapidly growing from a variety of sources. Extracting information from these documents and finding useful information from such collections has become a challenge, which makes organizing and processing textual big data a necessity. Data mining, machine learning, and natural language processing are powerful techniques that can be used together to deal with this big challenge. Depending on the task or problem at hand, there are many different approaches that can be used. The methods available are continuously being optimized, but not all these methods have been tested and compared in a set of problems that can be solved using supervised machine learning algorithms. The question is what happens to the quality of methods if we increase the training data size from, say, 100 MB to over 1 GB? Moreover, are quality gains worth it when the rate of data processing diminishes? Can we trade quality for time efficiency and recover the quality loss by just being able to process more data?   We attempt to answer these questions in a general way for text processing tasks, considering the trade-offs involving training data size, learning time, and quality obtained. Hence, we propose a performance trade-off framework and apply it to three important text processing problems: Named Entity Recognition, Sentiment Analysis, and Document Classification. These problems were also chosen because they have different levels of object granularity: words, paragraphs, and documents. For each problem, we selected several supervised machine learning algorithms and we evaluated the trade-offs of these different methods on large publicly available data sets . We use different data subsets of increasing size ranging from 50 MB to several GB, to explore these trade-offs. For the two last problems, we consider similar algorithms with two different data sets and two different evaluation techniques, to study the impact of the data itself and the evaluation technique on the resulting trade-offs. We find that the results do not change significantly and that most of the time the best algorithms are the ones with fastest processing time. However, we also show that the results for small data  are different from the results for big data and in those cases the best algorithm is much harder to determine.  % %Future work includes to extend this analysis to other factors, more algorithms, as well as considering prediction time in the %framework.  
 		Unlike extractive summarization, abstractive summarization has to fuse different parts of the source text, which inclines to create fake facts. 		Our preliminary study reveals nearly 30\% of the outputs from a state-of-the-art neural summarization system suffer from this problem. 		While previous abstractive summarization approaches usually focus on the improvement of informativeness, we argue that faithfulness is also a vital prerequisite for a practical abstractive summarization system. 		To avoid generating fake facts in a summary, we leverage open information extraction and dependency parse technologies to extract actual fact descriptions from the source text. 		The dual-attention sequence-to-sequence framework is then proposed to force the generation conditioned on both the source text and the extracted fact descriptions. 		Experiments on the Gigaword benchmark dataset demonstrate that our model can greatly reduce fake summaries by 80\%. 		Notably, the fact descriptions also bring significant improvement on informativeness since they often condense the meaning of the source text. 	
 Deep learning has demonstrated tremendous potential for Automatic Text Scoring  tasks. In this paper, we describe a new neural architecture that enhances vanilla neural network models with auxiliary neural coherence features. Our new method proposes a new SkipFlow mechanism that models relationships between snapshots of the hidden representations of a long short-term memory  network as it reads. Subsequently, the semantic relationships between multiple snapshots are used as auxiliary features for prediction. This has two main benefits. Firstly, essays are typically long sequences and therefore the memorization capability of the LSTM network may be insufficient. Implicit access to multiple snapshots can alleviate this problem by acting as a protection against vanishing gradients. The parameters of the SkipFlow mechanism also acts as an auxiliary memory. Secondly, modeling relationships between multiple positions allows our model to learn features that represent and approximate textual coherence. In our model, we call this neural coherence features. Overall, we present a unified deep learning architecture that generates neural coherence features as it reads in an end-to-end fashion. Our approach demonstrates state-of-the-art performance on the benchmark ASAP dataset, outperforming not only feature engineering baselines but also other deep learning models.  
   We investigate the computational complexity of various problems for   simple recurrent neural networks  as formal models for    recognizing weighted languages.  We focus on the single-layer,   ReLU-activation, rational-weight RNNs with softmax, which are   commonly used in natural language processing applications.  We show   that most problems for such RNNs are undecidable, including   consistency, equivalence, minimization, and the determination of the   highest-weighted string.  However, for consistent RNNs the last   problem becomes decidable, although the solution length can surpass all computable bounds.  If additionally the string is limited to   polynomial length, the problem becomes NP-complete and APX-hard. In summary, this shows that approximations and   heuristic algorithms are necessary in practical applications of   those RNNs. 
   In this paper, we introduce an emotional speech synthesizer based on the recent end-to-end neural model, named Tacotron. Despite its benefits, we found that the original Tacotron suffers from the exposure bias problem and irregularity of the attention alignment. Later, we address the problem by utilization of context vector and residual connection at recurrent neural networks . Our experiments showed that the model could successfully generate speech for given emotion labels. 
    %In this paper,     We investigate the problem of Language-Based Image Editing . Given a source image and a natural language description, we want to generate a target image by editing the source image based on the description. We propose a generic modeling framework for two sub-tasks of LBIE: language-based image segmentation and image colorization. The framework uses recurrent attentive models to fuse image and language features. Instead of using a fixed step size, we introduce for each region of the image a termination gate to dynamically determine after each inference step whether to continue extrapolating additional information from the textual description. The effectiveness of the framework is validated on three datasets. First, we introduce a synthetic dataset, called CoSaL, to evaluate the end-to-end performance of our LBIE system. Second, we show that the framework leads to state-of-the-art performance on image segmentation on the ReferIt dataset. Third, we present the first language-based colorization result on the Oxford-102 Flowers dataset. 
 %A The visual dialog generation requires an AI agent not only to produce a correct answer for a posed question, but also to hold a meaningful dialog in conversational natural language with humans. That means a response generated from an AI cannot be a single word such as `yes/no' or a `number', it should be interesting and meaningful enough in order to consider the previous dialogs and lead to the further conversations. The standard training strategy of the language sequence generation models is maximum likelihood estimation  of the human responses, which only control the correctness of the generated sentence at the words prediction level, without considering whether the whole dialog is meaningful and more human-like. In this paper, we propose to apply the adversarial learning strategy to visual dialog generation, training a model to produce language-based response that are indistinguishable from human-generated visual dialogs. The task is reformulated as a reinforcement learning problem that we jointly train two novel sub-modules: a sequential co-attention generative model to produce response sentences with sequentially co-attended visual and dialog history informations, and a discriminator that leverages previous generator's attention memories to distinguish between the human-generated dialogues and the machine-generated ones. Our proposed model outperforms the state-of-the-art on the VisDial dataset and can produce more human-like dialogs, suggested by a human study. The Visual Dialogue task requires an agent to engage in a conversation about an image with a human.  It represents an extension of the Visual Question Answering task in that the agent needs to answer a question about an image, but it needs to do so in light of the previous dialogue that has taken place.  The key challenge in Visual Dialogue is thus maintaining a consistent, and natural dialogue while continuing to answer questions correctly.  We present a novel approach that combines Reinforcement Learning and Generative Adversarial Networks  to generate more human-like responses to questions.  The GAN helps overcome the relative paucity of training data, and the tendency of the typical MLE-based approach to generate overly terse answers.   % Critically, the GAN is tightly integrated into the attention mechanism that generates human-interpretable reasons for each answer.  This means that the discriminative model of the GAN has the task of assessing whether a candidate answer is generated by a human or not, given the provided reason.  This is significant because it drives the generative model to produce high quality answers that are well supported by the associated reasoning. % The method also generates the state-of-the-art results on the primary benchmark. %/A 
 % max 200 words A growing field in robotics and  research is  collaboration, whose target is to enable effective teamwork between humans and robots. However, in many situations human teams are still superior to  teams, primarily because human teams can easily agree on a common goal with language, and the individual members observe each other effectively, leveraging their shared motor repertoire and sensorimotor resources. This paper shows that for cognitive robots it is possible, and indeed fruitful, to combine knowledge acquired from interacting with elements of the environment~ with the probabilistic observation of another agent's actions.  We propose a model that unites ~learning robot affordances and word descriptions with ~statistical recognition of human gestures with vision sensors. We discuss theoretical motivations, possible implementations, and we show initial results which highlight that, after having acquired knowledge of its surrounding environment, a humanoid robot can generalize this knowledge to the case when it observes another agent~ performing the same motor actions previously executed during training. 
 We address the problem of bootstrapping language acquisition for an artificial system similarly to what is observed in experiments with human infants. Our method works by associating meanings to words in manipulation tasks, as a robot interacts with objects and listens to verbal descriptions of the interactions. The model is based on an affordance network, i.e., a mapping between robot actions, robot perceptions and the perceived effects of these actions upon objects. We extend the affordance model to incorporate spoken words, which allows us to ground the verbal symbols to the execution of actions and the perception of the environment. The model takes verbal descriptions of a task as the input, and uses temporal co-occurrence to create links between speech utterances and the involved objects, actions and effects. We show that the robot is able form useful word-to-meaning associations, even without considering grammatical structure in the learning process and in the presence of recognition errors. These word-to-meaning associations are embedded in the robot閳ユ獨 own understanding of its actions. Thus, they can be directly used to instruct the robot to perform tasks and also allow to incorporate context in the speech recognition task. We believe that the encouraging results with our approach may afford robots with a capacity to acquire language descriptors in their operation's environment as well as to shed some light as to how this challenging process develops with human infants. 
 Video captioning is the task of automatically generating a textual description of the actions in a video. Although previous work  has shown promising results in abstracting a coarse description of a short video, it is still very challenging to caption a video containing multiple fine-grained actions with a detailed description. This paper aims to address the challenge by proposing a novel hierarchical reinforcement learning framework for video captioning, where a high-level Manager module learns to design sub-goals and a low-level Worker module recognizes the primitive actions to fulfill the sub-goal. With this compositional framework to reinforce video captioning at different levels, our approach significantly outperforms all the baseline methods on a newly introduced large-scale dataset for fine-grained video captioning. Furthermore,  our non-ensemble model has already achieved the state-of-the-art results on the widely-used MSR-VTT dataset.  
 %The robust speech  Far-field speech recognition in noisy and reverberant conditions remains a challenging problem despite recent deep learning breakthroughs.   This problem is commonly addressed by acquiring a speech signal from multiple microphones and performing beamforming over them. %the %multichannel signals collected from the same source.  In this paper, we propose to use a recurrent neural network with long short-term memory  architecture to adaptively estimate real-time beamforming filter coefficients to cope with non-stationary environmental noise and dynamic nature of source and microphones positions which results in a set of time-varying room impulse responses. The LSTM adaptive beamformer is jointly trained with a deep LSTM acoustic model to predict senone labels. Further, we use hidden units in the deep LSTM acoustic model to assist in predicting the beamforming filter coefficients. The proposed system achieves 7.97\% absolute gain over baseline systems with no beamforming on CHiME-3 real evaluation set.  
 		Counterfactual learning is a natural scenario to improve web-based machine translation services by offline learning from feedback logged during user interactions. In order to avoid the risk of showing inferior translations to users, in such scenarios mostly exploration-free deterministic logging policies are in place. We analyze possible degeneracies of inverse and reweighted propensity scoring estimators, in stochastic and deterministic settings, and relate them to recently proposed techniques for counterfactual learning under deterministic logging.  	
 \vspace*{-0.3cm} Dialogue assistants are rapidly becoming an indispensable daily aid. To avoid the significant effort needed to hand-craft the required dialogue flow, the Dialogue Management  module can be cast as a continuous Markov Decision Process  and trained through Reinforcement Learning . Several RL models have been investigated over recent years. However, the lack of a common benchmarking framework makes it difficult to perform a fair comparison between different models and their capability to generalise to different environments. Therefore, this paper proposes a set of challenging simulated environments for dialogue model development and evaluation.  To provide some baselines, we investigate a number of representative parametric algorithms, namely deep reinforcement learning algorithms - DQN, A2C and Natural Actor-Critic  and compare them to a non-parametric model, GP-SARSA. Both the environments and policy models are implemented using the publicly available PyDial toolkit and released on-line, in order to establish a testbed framework for further experiments and to facilitate experimental reproducibility. 
 \shrink %Making use of weak or noisy signals for training deep neural networks is increasing, in particular for the tasks where an adequate amount of data with true labels is not available.  %  %In semi-supervised setting, we can use a large set of data with weak labels to pretrain a neural network and fine tune the parameters with a small amount of data with true labels. However, these two independent stages do not leverage the full capacity of clean information from true labels during pretraining. % In this paper, we propose a method for training neural networks when we have a large set of data with weak labels and a small amount of data with true labels. In our proposed model, we train two neural networks: a \tnet, the learner and a \cnet, the meta-learner.  The \tnet is optimized to perform a given task and is trained using a large set of unlabeled data that are weakly annotated. We propose to control the magnitude of the gradient updates to the \tnet using the scores provided by the second \cnet, which is trained on a small amount of supervised data. Thus we avoid that the weight updates computed from noisy labels harm the quality of the \tnet model. \shrink 
 %The robust speech  Far-field speech recognition in noisy and reverberant conditions remains a challenging problem despite recent deep learning breakthroughs.   This problem is commonly addressed by acquiring a speech signal from multiple microphones and performing beamforming over them. %the %multichannel signals collected from the same source.  In this paper, we propose to use a recurrent neural network with long short-term memory  architecture to adaptively estimate real-time beamforming filter coefficients to cope with non-stationary environmental noise and dynamic nature of source and microphones positions which results in a set of time-varying room impulse responses. The LSTM adaptive beamformer is jointly trained with a deep LSTM acoustic model to predict senone labels. Further, we use hidden units in the deep LSTM acoustic model to assist in predicting the beamforming filter coefficients. The proposed system achieves 7.97\% absolute gain over baseline systems with no beamforming on CHiME-3 real evaluation set.  
 Drilling activities in the oil and gas industry have been reported over decades for thousands of wells on a daily basis, yet the analysis of this text at large-scale for information retrieval, sequence mining, and pattern analysis is very challenging. Drilling reports contain interpretations written by drillers from noting measurements in downhole sensors and surface equipment, and can be used for operation optimization and accident mitigation. In this initial work, a methodology is proposed for automatic classification of sentences written in drilling reports into three relevant labels  for hundreds of wells in an actual field. Some of the main challenges in the text corpus were overcome, which include the high frequency of technical symbols, mistyping/abbreviation of technical terms, and the presence of incomplete sentences in the drilling reports. We obtain state-of-the-art classification accuracy within this technical language and illustrate advanced queries enabled by the tool. 
 Semantic Role Labeling  is believed to be a crucial step towards natural language understanding and has been widely studied. Recent years, end-to-end SRL with recurrent neural networks  has gained increasing attention. However, it remains a major challenge for RNNs to handle structural information and long range dependencies. In this paper, we present a simple and effective architecture for SRL which aims to address these problems. Our model is based on self-attention which can directly capture the relationships between two tokens regardless of their distance. Our single model achieves F$_1=83.4$ on the CoNLL-2005 shared task dataset and F$_1=82.7$ on the CoNLL-2012 shared task dataset, which outperforms the previous state-of-the-art results by $1.8$ and $1.0$ F$_1$ score respectively. Besides, our model is computationally efficient, and the parsing speed is 50K tokens per second on a single Titan X GPU. 
   Having a sequence-to-sequence model which can operate in an online fashion is important for streaming applications such as Voice Search.   Neural transducer is a streaming sequence-to-sequence model, but has shown a significant degradation in performance compared to non-streaming models such as Listen, Attend and Spell . In this paper, we present various improvements to NT. Specifically, we look at increasing the window over which NT computes attention, mainly by looking backwards in time so the model still remains online. In addition, we explore initializing a NT model from a LAS-trained model so that it is guided with a better alignment. Finally, we explore including stronger language models such as using wordpiece models, and applying an external LM during the beam search. On a Voice Search task, we find with these improvements we can get NT to match the performance of LAS. 
 Factored neural machine translation  is founded on the idea of using the morphological and grammatical decomposition of the words  at the output side of the neural network. This architecture addresses two well-known problems occurring in MT, namely the size of target language vocabulary and the number of unknown tokens produced in the translation. FNMT system is designed to manage larger vocabulary and reduce the training time .  Moreover, we can produce grammatically correct words that are not part of the vocabulary. FNMT model is evaluated on IWSLT'15 English to French task  and compared to the baseline word-based and BPE-based NMT systems. Promising qualitative and quantitative results  are reported.  
 We examine the problem of question answering over knowledge graphs, focusing on simple questions that can be answered by the lookup of a single fact. Adopting a straightforward decomposition of the problem into entity detection, entity linking, relation prediction, and evidence combination, we explore simple yet strong baselines. On the popular Simple\-Questions dataset, we find that basic LSTMs and GRUs plus a few heuristics yield accuracies that approach the state of the art, and techniques that do not use neural networks also perform reasonably well. These results show that gains from sophisticated deep learning techniques proposed in the literature are quite modest and that some previous models exhibit unnecessary complexity. 
 Attention mechanism has been used as an ancillary means to help RNN or CNN. However, the Transformer~ recently recorded the state-of-the-art performance in machine translation with a dramatic reduction in training time by solely using attention. Motivated by the Transformer, Directional Self Attention Network~, a fully attention-based sentence encoder, was proposed. It showed good performance with various data by using forward and backward directional information in a sentence. But in their study, not considered at all was the distance between words, an important feature when learning the local dependency to help understand the context of input text. We propose Distance-based Self-Attention Network, which considers the word distance by using a simple distance mask in order to model the local dependency without losing the ability of modeling global dependency which attention has inherent. Our model shows good performance with NLI data, and it records the new state-of-the-art result with SNLI data. Additionally, we show that our model has a strength in long sentences or documents. 
  Attention-based Encoder-Decoder has the effective architecture for neural machine translation , which typically relies on recurrent neural networks  to build the blocks that will be lately called by attentive reader during the decoding process. This design of encoder yields relatively uniform composition on source sentence, despite the gating mechanism employed in encoding RNN. On the other hand, we often hope the decoder to take pieces of source sentence at varying levels suiting its own linguistic structure: for example, we may want to take the entity name in its raw form while taking an idiom as a perfectly composed unit. Motivated by this demand, we propose Multi-channel Encoder , which enhances encoding components with different levels of composition. More specifically, in addition to the hidden state of encoding RNN, MCE takes 1) the original word embedding for raw encoding with no composition, and 2) a particular design of external memory in Neural Turing Machine  for more complex composition, while all three encoding strategies are properly blended during decoding. Empirical study on Chinese-English translation shows that our model can improve by 6.52 BLEU points upon a strong open source NMT system: DL4MT\footnote{\url{https://github.com/nyu-dl/dl4mt-tutorial}}. On the WMT14 English-French task, our single shallow system achieves BLEU=38.8, comparable with the state-of-the-art deep models.  
  In this paper, we propose a novel embedding model, named ConvKB, for  knowledge base completion. Our  model ConvKB advances  state-of-the-art models by employing a convolutional neural network, so that it can capture global relationships and transitional characteristics between entities and relations in  knowledge bases. In ConvKB, each  triple  is represented as a 3-column matrix where each column vector represents a triple element. This  3-column matrix is then fed to a convolution layer where multiple filters are operated on the matrix to generate different feature maps. These feature maps are then concatenated into a single feature vector representing the input triple. The feature vector is multiplied with a weight vector via a dot product to return a score. This score is then used to predict whether the triple is valid or not. Experiments show that ConvKB achieves better link prediction performance than previous state-of-the-art embedding models on two benchmark datasets WN18RR and FB15k-237.  
 Functionality is of utmost importance to customers when they purchase products. However, it is unclear to customers whether a product can really satisfy their needs on functions. Further, missing functions may be intentionally hidden by the manufacturers or the sellers. As a result, a customer needs to spend a fair amount of time before purchasing or just purchase the product on his/her own risk.  In this paper, we first identify a novel QA corpus that is dense on product functionality information \footnote{The annotated corpus can be found at \url{https://www.cs.uic.edu/~hxu/}.}. We then design a neural network called Semi-supervised Attention Network  to discover product functions from questions. This model leverages unlabeled data as contextual information to perform semi-supervised sequence labeling. We conduct experiments to show that the extracted function have both high coverage and accuracy, compared with a wide spectrum of baselines.     
 In this paper, we compose a new task for deep argumentative structure analysis that goes beyond shallow discourse structure analysis. The idea is that argumentative relations can reasonably be represented with a small set of predefined patterns. For example, using value judgment and bipolar causality, we can explain a support relation between two argumentative segments as follows: Segment 1 states that something is good, and Segment 2 states that it is good because it promotes something good when it happens. We are motivated by the following questions:  how do we formulate the task?,  can a reasonable pattern set be created?, and  do the patterns work? To examine the task feasibility, we conduct a three-stage, detailed annotation study using 357 argumentative relations from the argumentative microtext corpus, a small, but highly reliable corpus. We report the coverage of explanations captured by our patterns on a test set composed of 270 relations. Our coverage result of 74.6\% indicates that argumentative relations can reasonably be explained by our small pattern set. Our agreement result of 85.9\% shows that a reasonable inter-annotator agreement can be achieved. To assist with future work in computational argumentation, the annotated corpus is made publicly available. 
     Objective Develop an automatic diagnostic system which only uses textual admission information from Electronic Health Records  and assist clinicians with a timely and statistically proved decision tool. The hope is that the tool can be used to reduce mis-diagnosis.     Materials and Methods We use the real-world clinical notes from MIMIC-III, a freely available dataset consistsing of clinical data of more than forty thousand patients who stayed in intensive care units of the Beth Israel Deaconess Medical Center between 2001 and 2012 ~. We proposed a Convolutional Neural Network model to learn semantic features from unstructured textual input and automatically predict primary discharge diagnosis.   Results The proposed model achieved an overall 96.11\% accuracy and 80.48\% weighted F1 score values on 10 most frequent disease classes, significantly outperforming four strong baseline models by at least 12.7\% in weighted F1 score.  Discussion  Experimental results imply that the CNN model is suitable for supporting diagnosis decision making in the presence of complex, noisy and unstructured clinical data while at the same time using fewer layers and parameters that other traditional Deep Network models.  Conclusion Our model demonstrated capability of representing complex medical meaningful features from unstructured clinical notes and prediction power for commonly misdiagnosed frequent diseases. It can use easily adopted in clinical setting to provide timely and statistically proved decision support.     Keywords Convolutional neural network, text classification, discharge diagnosis prediction, admission information from EHRs. 
 We present a simple yet elegant solution to train a single joint model on multi-criteria corpora for Chinese Word Segmentation . Our novel design requires no private layers in model architecture, instead, introduces two artificial tokens at the beginning and ending of input sentence to specify the required target criteria. The rest of the model including Long Short-Term Memory  layer and Conditional Random Fields  layer remains unchanged and is shared across all datasets, keeping the size of parameter collection minimal and constant. On Bakeoff 2005 and Bakeoff 2008 datasets, our innovative design has surpassed both single-criterion and multi-criteria state-of-the-art learning results. To the best knowledge, our design is the first one that has achieved the latest high performance on such large scale datasets. Source codes and corpora of this paper are available on GitHub\footnote{{}}. 
 In this paper, we study the problem of mapping natural language instructions to complex spatial actions in a 3D blocks world.  We first introduce a new dataset that pairs complex 3D spatial operations to rich natural language descriptions that require complex spatial and pragmatic interpretations such as , and  .  This dataset, built on the simulation environment of , attains language that is significantly richer and more complex, while also doubling the size of the original dataset in the 2D environment with 100 new world configurations and 250,000 tokens.  In addition, we propose a new neural architecture that achieves competitive results while automatically discovering an inventory of interpretable spatial operations .  
 %Language contains information about the author's demographic attributes as well as their mental state, and the two interact with one other.    We introduce initial groundwork for estimating suicide risk and mental health in a deep learning framework. By modeling multiple conditions, the system learns to make predictions about suicide risk and mental health at a low false positive rate.  Conditions are modeled as tasks in a multi-task learning  framework, with gender prediction as an additional auxiliary task. We demonstrate the effectiveness of multi-task learning by comparison to a well-tuned single-task baseline with the same number of parameters. Our best MTL model predicts potential suicide attempt, as well as the presence of atypical mental health, with AUC $>$ 0.8.  We also find additional large improvements using multi-task learning on mental health tasks with limited training data.  
 Identifying the veracity of a news article is an interesting problem while automating this process can be a challenging task. Detection of a news article as fake is still an open question as it is contingent on many factors which the current state-of-the-art models fail to incorporate. In this paper, we explore a subtask to fake news identification, and that is stance detection. Given a news article, the task is to determine the relevance of the body and its claim. We present a novel idea that combines the neural, statistical and external features to provide an efficient solution to this problem. We compute the neural embedding from the deep recurrent model, statistical features from the weighted n-gram bag-of-words model and hand crafted external features with the help of feature engineering heuristics. Finally, using deep neural layer all the features are combined, thereby classifying the headline-body news pair as agree, disagree, discuss, or unrelated. We compare our proposed technique with the current state-of-the-art models on the fake news challenge dataset. Through extensive experiments, we find that the proposed model outperforms all the state-of-the-art techniques including the submissions to the fake news challenge.  
 The advantages of neural machine translation  have been extensively validated for offline translation of several language pairs for different domains of spoken and written language. However, research on interactive learning of NMT by adaptation to human post-edits has so far been confined to simulation experiments. We present the first user study on online adaptation of NMT to user post-edits in the domain of patent translation. Our study involves 29 human subjects  whose post-editing effort and translation quality were measured on about 4,500 interactions of a human post-editor and a machine translation system integrating an online adaptive learning algorithm. Our experimental results show a significant reduction of human post-editing effort due to online adaptation in NMT according to several evaluation metrics, including hTER, hBLEU, and KSMR. Furthermore, we found significant improvements in BLEU/TER between NMT outputs and professional translations in granted patents, providing further evidence for the advantages of online adaptive NMT in an interactive setup.  
   Aspect-based sentiment analysis  tries to predict the polarity of a given document with respect to a given aspect entity. While neural network architectures have been successful in predicting the overall polarity of sentences, aspect-specific sentiment analysis still remains as an open problem. In this paper, we propose a novel method for integrating aspect information into the neural model. More specifically, we incorporate aspect information into the neural model by modeling word-aspect relationships. Our novel model, Aspect Fusion LSTM  learns to attend based on associative relationships between sentence words and aspect which allows our model to adaptively focus on the correct words given an aspect term. This ameliorates the flaws of other state-of-the-art models that utilize naive concatenations to model word-aspect similarity. Instead, our model adopts circular convolution and circular correlation to model the similarity between aspect and words and elegantly incorporates this within a differentiable neural attention framework. Finally, our model is end-to-end differentiable and highly related to convolution-correlation  memories. Our proposed neural model achieves state-of-the-art performance on benchmark datasets, outperforming ATAE-LSTM by $4\%-5\%$ on average across multiple datasets. 
 Many recent advances in deep learning for natural language processing have come at increasing computational cost, but the power of these state-of-the-art models is not needed for every example in a dataset. We demonstrate two approaches to reducing unnecessary computation in cases where a fast but weak baseline classier and a stronger, slower model are both available. Applying an AUC-based metric to the task of sentiment classification, we find significant efficiency gains with both a probability-threshold method for reducing computational cost and one that uses a secondary decision network. } 
 Zero-shot Learners are models capable of predicting unseen classes. In this work, we propose a Zero-shot Learning approach for text categorization. Our method involves training model on a large corpus of sentences to learn the relationship between a sentence and embedding of sentence's tags. Learning such relationship makes the model generalize to unseen sentences, tags, and even new datasets provided they can be put into same embedding space. The model learns to predict whether a given sentence is related to a tag or not; unlike other classifiers that learn to classify the sentence as one of the possible classes. We propose three different neural networks for the task and report their accuracy on the test set of the dataset used for training them as well as two other standard datasets for which no retraining was done. We show that our models generalize well across new unseen classes in both cases. Although the models do not achieve the accuracy level of the state of the art supervised models, yet it evidently is a step forward towards general intelligence in natural language processing. 
 This paper presents an simple yet sophisticated approach to the challenge by Sproat and Jaitly  %todo - given a large corpus of written text aligned to its normalized spoken form, train an RNN to learn the correct normalization function. Text normalization for a token seems very straightforward without it's context. But given the context of the used token and then normalizing becomes tricky for some classes. We present a novel approach in which the prediction of our classification algorithm is used by our sequence to sequence model to predict the normalized text of the input token. Our approach takes very less time to learn and perform well unlike what has been reported by Google . We have achieved an accuracy of 97.62 which is impressive given the resources we use. Our approach is using the best of both worlds, gradient boosting - state of the art in most classification tasks and sequence to sequence learning - state of the art in machine translation. We present our experiments and report results with various parameter settings.  
 Connectionist temporal classification  is widely used for maximum likelihood learning in end-to-end speech recognition models. However, there is usually a disparity between the negative maximum likelihood and the performance metric used in speech recognition, \eg, word error rate . This results in a mismatch between the objective function and metric during training. % JB: these two sentences are mostly redundant with each other We show that the above problem can be mitigated by jointly training with maximum likelihood and policy gradient. In particular, with policy learning we are able to directly optimize on the  performance metric. We show that joint training improves relative performance by 4\% to 13\% for our end-to-end model as compared to the same model learned through maximum likelihood. The model achieves 5.53\% WER on Wall Street Journal dataset, and 5.42\% and 14.70\% on Librispeech test-clean and test-other set, respectively. 
   Recent advances in conversational systems have changed the search paradigm.   Traditionally, a user poses a query to a search engine that returns an answer based on its index, possibly leveraging external knowledge bases and conditioning the response on earlier interactions in the search session.   In a natural conversation, there is an additional source of information to take into account: utterances produced earlier in a conversation can also be referred to and a conversational IR system has to keep track of information conveyed by the user during the conversation, even if it is implicit.    We argue that the process of building a representation of the conversation can be framed as a machine reading task, where an automated system is presented with a number of statements about which it should answer questions.   The questions should be answered solely by referring to the statements provided, without consulting external knowledge.   The time is right for the information  retrieval community to embrace this task, both as a stand-alone task and integrated in a broader conversational search setting.       In this paper, we focus on machine reading as a stand-alone task and present the , an end-to-end trainable machine reading algorithm.   Its key contribution is in efficiency, achieved by having an hierarchical input encoder, iterating over the input only once. Speed is an important requirement in the setting of conversational search, as gaps between conversational turns have a detrimental effect on naturalness.     On 20 datasets commonly used for evaluating machine reading algorithms we show that the  achieves performance comparable to the state-of-the-art models, while using considerably fewer computations. 
 One of the big challenges in machine learning applications is that training data can be different from the real-world data faced by the algorithm. In language modeling, users' language  could change in a year and be completely different from what we observe in publicly available data. At the same time, public data can be used for obtaining general knowledge . We study approaches to distributed fine-tuning of a general model on user private data with the additional requirements of maintaining the quality on the general data and minimization of communication costs.  We propose a novel technique that significantly improves prediction quality on users' language compared to a general model and outperforms gradient compression methods in terms of communication efficiency. The proposed procedure is fast and leads to an almost $70\%$ perplexity reduction and $8.7$ percentage point improvement in keystroke saving rate on informal English texts. We also show that the range of tasks our approach is applicable to is not limited by language modeling only. Finally, we propose an experimental framework for evaluating differential privacy of distributed training of language models and show that our approach has good privacy guarantees. 
 Characters have commonly been regarded as the minimal processing unit in Natural Language Processing . But many non-latin languages have hieroglyphic writing systems, involving a big alphabet with thousands or millions of characters. Each character is composed of even smaller parts, which are often ignored by the previous work. In this paper, we propose a novel architecture employing two stacked Long Short-Term Memory Networks  to learn sub-character level representation and capture deeper level of semantic meanings. To build a concrete study and substantiate the efficiency of our neural architecture, we take Chinese Word Segmentation as a research case example. Among those languages, Chinese is a typical case, for which every character contains several components called radicals. Our networks employ a shared radical level embedding to solve both Simplified and Traditional Chinese Word Segmentation, without extra Traditional to Simplified Chinese conversion, in such a highly end-to-end way the word segmentation can be significantly simplified compared to the previous work. Radical level embeddings can also capture deeper semantic meaning below character level and improve the system performance of learning. By tying radical and character embeddings together, the parameter count is reduced whereas semantic knowledge is shared and transferred between two levels, boosting the performance largely. On 3 out of 4 Bakeoff 2005 datasets, our method surpassed state-of-the-art results by up to $0.4\%$. Our results are reproducible, source codes and corpora are available on GitHub\footnote{\url{ https://github.com/hankcs/sub-character-cws} }. % in supplementary material.  
 The problem of automatic accent identification is important for several applications like speaker profiling and recognition as well as for improving speech recognition systems. The accented nature of speech can be primarily attributed to the influence of the speaker's native language on the given speech recording. In this paper, we propose a novel accent identification system whose training exploits speech in native languages along with the accented speech. Specifically, we develop a deep Siamese network based model which learns the association between accented speech recordings and the native language speech recordings. The Siamese networks are trained with i-vector features extracted from the speech recordings using either an unsupervised Gaussian mixture model  or a supervised deep neural network  model. We perform several accent identification experiments using the CSLU Foreign Accented English  corpus. In these experiments, our proposed approach using deep Siamese networks yield significant relative performance improvements of 15.4\% on a 10-class accent identification task, over a baseline DNN-based classification system that uses GMM i-vectors. Furthermore, we present a detailed error analysis of the proposed accent identification system.  
 While end-to-end neural conversation models have led to promising advances in reducing hand-crafted features and errors induced by the traditional complex system architecture, they typically require an enormous amount of data due to the lack of modularity. Previous studies adopted a hybrid approach with knowledge-based components either to abstract out domain-specific information or to augment data to cover more diverse patterns. On the contrary, we propose to directly address the problem using recent developments in the space of continual learning for neural models. Specifically, we adopt a domain-independent neural conversational model and introduce a novel neural continual learning algorithm that allows a conversational agent to accumulate skills across different tasks in a data-efficient way. To the best of our knowledge, this is the first work that applies continual learning to conversation systems. We verified the efficacy of our method through a conversational skill transfer from either synthetic dialogs or human-human dialogs to human-computer conversations in a customer support domain.  
  Visual Question Answering  has attracted much attention since it offers insight into the relationships between the multi-modal analysis of images and natural language. Most of the current algorithms are incapable of answering open-domain questions that require to perform reasoning beyond the image contents. To address this issue, we propose a novel framework which endows the model capabilities in answering more complex questions by leveraging massive external knowledge with dynamic memory networks. Specifically, the questions along with the corresponding images trigger a process to retrieve the relevant information in external knowledge bases, which are embedded into a continuous vector space by preserving the entity-relation structures. Afterwards, we employ dynamic memory networks to attend to the large body of facts in the knowledge graph and images, and then perform reasoning over these facts to generate corresponding answers. Extensive experiments demonstrate that our model not only achieves the state-of-the-art performance in the visual question answering task, but can also answer open-domain questions effectively by leveraging the external knowledge.   %  
  We introduce an interactive learning framework for the development and testing of intelligent visual systems, called learning-by-asking .  We explore LBA in context of the Visual Question Answering  task. LBA differs from standard VQA training in that most questions are not observed during training time, and the learner must ask questions it wants answers to. Thus, LBA more closely mimics natural learning and has the potential to be more data-efficient than the traditional VQA setting. We present a model that performs LBA on the CLEVR dataset, and show that it automatically discovers an easy-to-hard curriculum when learning interactively from an oracle. Our LBA generated data consistently matches or outperforms the CLEVR train data and is more sample efficient. We also show that our model asks questions that generalize to state-of-the-art VQA models and to novel test time distributions. 
 Deriving event storylines is an effective summarization method to succinctly organize extensive information, which can significantly alleviate the pain of information overload. The critical challenge is the lack of widely recognized definition of storyline metric. Prior studies have developed various approaches based on different assumptions about users' interests. These works can extract interesting patterns, but their assumptions do not guarantee that the derived patterns will match users' preference. On the other hand, their exclusiveness of single modality source misses cross-modality information. This paper proposes a method, multimodal imitation learning via generative adversarial networks, to directly model users' interests as reflected by various data. In particular, the proposed model addresses the critical challenge by imitating users' demonstrated storylines. Our proposed model is designed to learn the reward patterns given user-provided storylines and then applies the learned policy to unseen data. The proposed approach is demonstrated to be capable of acquiring the user's implicit intent and outperforming competing methods by a substantial margin with a user study. 
 Learning a goal-oriented dialog policy is generally performed offline with supervised learning algorithms or online with reinforcement learning . Additionally, as companies accumulate massive quantities of dialog transcripts between customers and trained human agents, encoder-decoder methods have gained popularity as agent utterances can be directly treated as supervision without the need for utterance-level annotations. However, one potential drawback of such approaches is that they myopically generate the next agent utterance without regard for { RL method for learning from   unannotated corpora that can optimize a goal-oriented policy at both the utterance and dialog level. We introduce a novel reward function and use both on-policy and off-policy policy gradient to learn a policy offline without requiring online user interaction or an explicit state space definition. 
 %abstract of 150 to 250 words   The paper approaches the task of handwritten text recognition  with attentional encoder-decoder networks trained on sequences of characters, rather than words. We experiment on lines of text from popular handwriting datasets and compare different activation functions for the attention mechanism used for aligning image pixels and target characters. We find that softmax attention focuses heavily on individual characters, while sigmoid attention focuses on multiple characters at each step of the decoding. When the sequence alignment is one-to-one, softmax attention is able to learn a more precise alignment at each step of the decoding, whereas the alignment generated by sigmoid attention is much less precise. When a linear function is used to obtain attention weights, the model predicts a character by looking at the entire sequence of characters and performs poorly because it lacks a precise alignment between the source and target. Future research may explore HTR in natural scene images, since the model is capable of transcribing handwritten text without the need for producing segmentations or bounding boxes of text in images. % 4-6 
 Traditional neural network approaches for traffic flow forecasting are usually single task learning  models, which do not take advantage of the information provided by related tasks. In contrast to STL,  multitask learning  has the potential to improve generalization by transferring information in training signals of extra tasks. In this paper, MTL based neural networks are used for traffic flow forecasting. For neural network MTL, a backpropagation  network is constructed by incorporating traffic flows at several contiguous time instants into an output layer. Nodes in the output layer can be seen as outputs of different but closely related STL tasks. Comprehensive experiments on urban vehicular traffic flow data and comparisons with STL show that MTL in BP neural networks is a promising and effective approach for traffic flow forecasting.
 		We propose a Topic Compositional Neural Language Model , a novel method designed to simultaneously capture both the  semantic meaning and the  word-ordering structure in a document. The TCNLM learns the global semantic coherence of a document via a neural topic model, and the probability of each learned latent topic is further used to build a Mixture-of-Experts  language model, where each expert  is a recurrent neural network  that accounts for learning the local structure of a word sequence. In order to train the MoE model efficiently, a matrix factorization method is applied, by extending each weight matrix of the RNN to be an ensemble of topic-dependent weight matrices. The degree to which each member of the ensemble is used is tied to the document-dependent probability of the corresponding topics. Experimental results on several corpora show that the proposed approach outperforms both a pure RNN-based model and other topic-guided language models. Further, our model yields sensible topics, and also has the capacity to generate meaningful sentences conditioned on given topics.  	
 Chemical databases store information in text representations, and the SMILES format is a universal standard used in many cheminformatics software. Encoded in each SMILES string is structural information that can be used to predict complex chemical properties. In this work, we develop SMILES2vec, a deep RNN that automatically learns features from SMILES to predict chemical properties, without the need for additional explicit feature engineering. Using Bayesian optimization methods to tune the network architecture, we show that an optimized SMILES2vec model can serve as a general-purpose neural network for predicting distinct chemical properties including toxicity, activity, solubility and solvation energy, while also outperforming contemporary MLP neural networks that uses engineered features. Furthermore, we demonstrate proof-of-concept of interpretability by developing an explanation mask that localizes on the most important characters used in making a prediction. When tested on the solubility dataset, it identified specific parts of a chemical that is consistent with established first-principles knowledge with an accuracy of 88\%. Our work demonstrates that neural networks can learn technically accurate chemical concept and provide state-of-the-art accuracy, making interpretable deep neural networks a useful tool of relevance to the chemical industry. 
 We investigate the effect and usefulness of spontaneity  in speech in the context of emotion recognition. We hypothesize that emotional content in speech is interrelated with its spontaneity, and use spontaneity classification as an auxiliary task to the problem of emotion recognition. We propose two supervised learning settings that utilize spontaneity to improve speech emotion recognition: a hierarchical model that performs spontaneity detection before performing emotion recognition, and a multitask learning model that jointly learns to recognize both spontaneity and emotion. Through various experiments on the well-known IEMOCAP database, we show that by using spontaneity detection as an additional task, significant improvement can be achieved over emotion recognition systems that are unaware of spontaneity. We achieve state-of-the-art emotion recognition accuracy  on the IEMOCAP database outperforming several relevant and competitive baselines. 
 Chemical databases store information in text representations, and the SMILES format is a universal standard used in many cheminformatics software. Encoded in each SMILES string is structural information that can be used to predict complex chemical properties. In this work, we develop SMILES2vec, a deep RNN that automatically learns features from SMILES to predict chemical properties, without the need for additional explicit feature engineering. Using Bayesian optimization methods to tune the network architecture, we show that an optimized SMILES2vec model can serve as a general-purpose neural network for predicting distinct chemical properties including toxicity, activity, solubility and solvation energy, while also outperforming contemporary MLP neural networks that uses engineered features. Furthermore, we demonstrate proof-of-concept of interpretability by developing an explanation mask that localizes on the most important characters used in making a prediction. When tested on the solubility dataset, it identified specific parts of a chemical that is consistent with established first-principles knowledge with an accuracy of 88\%. Our work demonstrates that neural networks can learn technically accurate chemical concept and provide state-of-the-art accuracy, making interpretable deep neural networks a useful tool of relevance to the chemical industry. 
 This paper presents a new deep learning architecture for Natural Language Inference . Firstly, we introduce a new architecture where alignment pairs are compared, compressed and then propagated to upper layers for enhanced representation learning. Secondly, we adopt factorization layers for efficient and expressive compression of alignment vectors into scalar features, which are then used to augment the base word representations. The design of our approach is aimed to be conceptually simple, compact and yet powerful. We conduct experiments on three popular benchmarks, SNLI, MultiNLI and SciTail, achieving competitive performance on all. A lightweight parameterization of our model also enjoys a $\approx 3$ times reduction in parameter size compared to the existing state-of-the-art models, e.g., ESIM and DIIN, while maintaining competitive performance. Additionally, visual analysis shows that our propagated features are highly interpretable.  
 	Text representations using neural word embeddings have proven effective in many NLP applications. Recent researches adapt the traditional word embedding models to learn vectors of multiword expressions . However, these methods are limited to textual knowledge bases . In this paper, we propose a novel  and simple technique for integrating the knowledge about concepts from two large scale knowledge bases of different structure  in order to learn concept representations. We adapt the efficient skip-gram model to seamlessly learn from the knowledge in Wikipedia text and Probase concept graph. We evaluate our concept embedding models on two tasks: 1) analogical reasoning, where we achieve a state-of-the-art performance of 91\% on semantic analogies, 2) concept categorization, where we achieve a state-of-the-art performance on two benchmark datasets achieving categorization accuracy of 100\% on one and 98\% on the other. Additionally, we present a case study to evaluate our model on unsupervised argument type identification for neural semantic parsing. We demonstrate the competitive accuracy of our unsupervised method and its ability to better generalize to out of vocabulary entity mentions compared to the tedious and error prone methods which depend on gazetteers and regular expressions.   
 	Multimodal models have been proven to outperform text-based models on learning semantic word representations. Almost all previous multimodal models typically treat the representations from different modalities equally. However, it is obvious that information from different modalities contributes differently to the meaning of words. This motivates us to build a multimodal model that can dynamically fuse the semantic representations from different modalities according to different types of words. To that end, we propose three novel dynamic fusion methods to assign importance weights to each modality, in which weights are learned under the weak supervision of word association pairs. The extensive experiments have demonstrated that the proposed methods outperform strong unimodal baselines and state-of-the-art multimodal models. 
 It is a challenging and practical research problem to obtain effective compression of lengthy product titles for E-commerce. This is particularly important as more and more users browse mobile E-commerce apps and more merchants make the original product titles redundant and lengthy for Search Engine Optimization. Traditional text summarization approaches often require a large amount of preprocessing costs and do not capture the important issue of conversion rate in E-commerce. This paper proposes a novel multi-task learning approach for improving product title compression with user search log data. In particular, a pointer network-based sequence-to-sequence approach is utilized for title compression with an attentive mechanism as an extractive method and an attentive encoder-decoder approach is utilized for generating user search queries. The encoding parameters  are shared among the two tasks and the attention distributions are jointly optimized. An extensive set of experiments with both human annotated data and online deployment demonstrate the advantage of the proposed research for both compression qualities and online business values. 
 	 In supervised approaches for keyphrase extraction, a candidate phrase is encoded with a set of hand-crafted features and machine learning algorithms are trained to discriminate keyphrases from non-keyphrases. Although the manually-designed features have shown to work well in practice, feature engineering is a difficult process that requires expert knowledge and normally does not generalize well. In this paper, we present SurfKE, a feature learning framework that exploits the text itself to automatically discover patterns that keyphrases exhibit. Our model represents the document as a graph and automatically learns feature representation of phrases. The proposed model obtains remarkable improvements in performance over strong baselines.  
 This paper proposes a novel lifelong learning  approach to sentiment classification. LL mimics the human continuous learning process, i.e., retaining the knowledge learned from past tasks and use it to help future learning. In this paper, we first discuss LL in general and then LL for sentiment classification in particular. The proposed LL approach adopts a Bayesian optimization framework based on stochastic gradient descent. Our experimental results show that the proposed method outperforms baseline methods significantly, which demonstrates that lifelong learning is a promising research direction.  
 This paper presents a novel task using real user data obtained in human-machine conversation. %to improve quality of dialogue systems.  The task concerns with denotation extraction from answer hints collected interactively in a dialogue.  %\OD{Asi bych zacal tim, k cemu to je, pak co to je a potom mluvil o real user data... novel task enabling SDS to learn from users. It is concerned with denotation... Nekde na konci toho summary "We use real user data... in our experiments."} %\MV{zmeny v abstraktu nejsou povolene} %In contrast, the answer hints can be obtained quite easily in interactive learning setup as shown in~.  %Our previous work shown that the interactive collection of answer hints in a dialogue is feasible. % and suggested that it has a potential to improve the dialogue systems.  %The data we are focused on are user's answer hints in a form of natural language .  % The task is motivated by the need for large amounts of training data for question answering dialogue system development, where the data is often expensive and hard to collect.  % %The use of answer hints has a potential to ease collection of training data.  %in interactive learning setup as shown in~.  %This work focuses on processing the answer hints into denotations during a process called denotation extraction. % %The denotations have already been used in training natural language understanding components in question answering systems.  %Being able to collect annotation interactively, one could improve, for example, natural understanding components on-line. Being able to collect denotation interactively and directly from users, one could improve, for example, natural understanding components on-line and ease the collection of the training data.  %One way of using the answer hint information is by extracting denotations which are useful for several dialogue system components as was already shown in related work.   %The extracted denotations can be later used to enhance knowledge of a dialogue system and consequently improve the overall system performance. This paper also presents introductory results of evaluation of several denotation extraction models including attention-based neural network approaches. 
    Distant supervised relation extraction is an efficient approach to scale relation extraction to very large corpora, and has been widely used to find novel relational facts from plain text. Recent studies on neural relation extraction have shown great progress on this task via modeling the sentences in low-dimensional spaces, but seldom considered syntax information to model the entities. In this paper, we propose to learn syntax-aware entity embedding for neural relation extraction. First, we encode the context of entities on a dependency tree as sentence-level entity embedding based on tree-GRU. Then, we utilize both intra-sentence and inter-sentence attentions to obtain sentence set-level entity embedding over all sentences containing the focus entity pair. Finally, we combine both sentence embedding and entity embedding for relation classification. We conduct experiments on a widely used real-world dataset and the experimental results show that our model can make full use of all informative instances and achieve state-of-the-art performance of relation extraction.  
 Neural machine translation  suffers a performance deficiency when a limited vocabulary fails to cover the source or target side adequately, which happens frequently when dealing with morphologically rich languages. To address this problem, previous work focused on adjusting translation granularity or expanding the vocabulary size. However, morphological information is relatively under-considered in NMT architectures, which may further improve translation quality. We propose a novel method, which can not only reduce data sparsity but also model morphology through a simple but effective mechanism. By predicting the stem and suffix separately during decoding, our system achieves an improvement of up to 1.98 BLEU compared with previous work on English to Russian translation. Our method is orthogonal to different NMT architectures and stably gains improvements on various domains. 
	 	This paper addresses the important problem of discerning hateful content in social media. We propose a detection scheme that is an ensemble of  classifiers, and it incorporates various features associated with user-related information, such as the users' tendency towards  or . 	These data are fed as input to the above classifiers along with the word frequency vectors derived from the textual content. Our approach has been evaluated on a publicly available corpus of 16k tweets, and the results demonstrate its effectiveness in comparison to existing state of the art solutions. More specifically,  	our scheme can successfully distinguish racism and sexism messages from normal text, and achieve higher classification quality than current state-of-the-art algorithms.\\   {\bf Keywords:} Text classification, micro-blogging, hate-speech, deep learning, recurrent neural networks, Twitter. 
   Multi-relation Question Answering is a challenging task, due to the requirement of elaborated analysis on questions and reasoning over multiple fact triples in knowledge base. In this paper, we present a novel model called {\bf Interpretable Reasoning Network} that employs an interpretable, hop-by-hop reasoning process for question answering. The model dynamically decides which part of an input question should be analyzed at each hop; predicts a relation that corresponds to the current parsed results; utilizes the predicted relation to update the question representation and the state of the reasoning process; and then drives the next-hop reasoning. Experiments show that our model yields state-of-the-art results on two datasets. More interestingly, the model can offer traceable and observable intermediate predictions for reasoning analysis and failure diagnosis, thereby allowing manual manipulation in predicting the final answer. 
 % We assess the translation quality attainable by state-of-the-art neural and statistical phrase-based paradigms of  machine translation  for novels, arguably the most popular type of literary text. % To this end, for the first time we train MT systems for English-to-Catalan on large amounts of literary text   and evaluate them on a set of 12 widely known novels from the 20$^{th
 To quickly obtain new labeled data, we can choose crowdsourcing as an alternative way at lower cost in a short time. But as an exchange, crowd annotations from non-experts may be of lower quality than those from experts. In this paper, we propose an approach to performing crowd annotation learning for Chinese Named Entity Recognition  to make full use of the noisy sequence labels from multiple annotators. Inspired by adversarial learning, our approach uses a common Bi-LSTM and a private Bi-LSTM for representing annotator-generic and -specific information. The annotator-generic information is the common knowledge for entities easily mastered by the crowd. Finally, we build our Chinese NE tagger based on the LSTM-CRF model. In our experiments, we create two data sets for Chinese NER tasks from two domains. The experimental results show that our system achieves better scores than strong baseline systems.   
 Training a task-completion dialogue agent via reinforcement learning  is costly %prohibitively expensive  because it requires many interactions with real users. One common alternative is to use a user simulator. However, a user simulator usually lacks the language complexity of human interlocutors and the biases in its design may tend to degrade the agent.  %However, the discrepancy between simulator and real user inevitably makes the trained agent suboptimal. To address these issues, we present Deep Dyna-Q, which to our knowledge is the first deep RL framework that integrates planning for task-completion dialogue policy learning. %address these issues by integrating planning into dialogue policy learning via an extension of the Dyna-Q framework.  We incorporate into the dialogue agent a model of the environment, referred to as the , to mimic real user response and generate simulated experience. During dialogue policy learning, the world model is constantly updated with real user experience to approach real user behavior, and in turn, the dialogue agent is optimized using both real experience and simulated experience. The effectiveness of our approach is demonstrated on a movie-ticket booking task in both simulated and human-in-the-loop settings\footnote{The source code of this work is available at \url{https://github.com/MiuLab/DDQ}}.  
 The behavior of deep neural networks  is hard to understand. This makes it necessary to explore post hoc explanation methods. We conduct the first comprehensive evaluation of explanation methods for NLP. To this end, we design two novel evaluation paradigms that cover two important classes of NLP problems: small context and large context problems. Both paradigms require no manual annotation and are therefore broadly applicable. We also introduce LIMSSE, an explanation method inspired by LIME that is designed for NLP. We show empirically that LIMSSE, LRP and DeepLIFT are the most effective explanation methods and recommend them for explaining DNNs in NLP. 
  transfer. We explore the transferability of various layers and describe the effect of varying hyper-parameters on the transfer performance. Also, we present a comparison of accuracy value and model size against state-of-the-art methods. Finally, we derive inferences from the empirical results and provide best practices to achieve a successful positive transfer.
 \mbox{} \\ We present MILABOT: a deep reinforcement learning chatbot developed by the Montreal Institute for Learning Algorithms  for the Amazon Alexa Prize competition. MILABOT is capable of conversing with humans on popular small talk topics through both speech and text. The system consists of an ensemble of natural language generation and retrieval models, including neural network and template-based models. By applying reinforcement learning to crowdsourced data and real-world user interactions, the system has been trained to select an appropriate response from the models in its ensemble. The system has been evaluated through A/B testing with real-world users, where it performed significantly better than other systems. The results highlight the potential of coupling ensemble systems with deep reinforcement learning as a fruitful path for developing real-world, open-domain conversational agents. %Due to its machine learning architecture, the system is likely to improve with additional data. 
 %Incorporating external hand crafted features to deep models can be beneficial to natural language processing tasks such as community based question answering , sentence semantic similarity, answer sentence selection or passage sentence selection. Most of the recent works uses concatenation to combine these features to deep models which is too naive for an efficient amalgamation. In this paper, we present an efficient method to incorporate external features to deep models. Provided the neural representations of entities such as question and answer vectors in CQA tasks, we also treat the external features as an entity. The presented tensor model uses different weight matrix to capture the interaction between the entity vectors .  %Some challenging tasks associated with Community Question Answering  includes answer sentence selection, best answer selection and answer triggering. While most previous works focus on one of these tasks, very few architectures deal with all these problems simultaneously.  A major challenge to the problem of community question answering is the lexical and semantic gap between the sentence representations.  %as computed by deep models.  Some solutions to minimize this gap includes the introduction of extra parameters to deep models or augmenting the external handcrafted features. In this paper, we propose a novel attentive recurrent tensor network for solving the lexical and semantic gap in community question answering. We introduce token-level and phrase-level attention strategy that maps input sequences to the output using trainable parameters.  Further, we use the tensor parameters to introduce a 3-way interaction between question, answer and external features in vector space.  We introduce simplified tensor matrices with L2 regularization that results in smooth optimization during training. The proposed model achieves state-of-the-art performance on the task of answer sentence selection  while outperforming the current state-of-the-art on the tasks of best answer selection  and answer triggering task . 
 We present a new method for estimating vector space representations of words: embedding learning by concept induction. We test this method on a highly parallel corpus and learn semantic representations of words in 1259 different languages in a single common space. An extensive experimental evaluation on crosslingual word similarity and sentiment analysis indicates that concept-based multilingual embedding learning performs better than previous approaches. 
  Grammatical error detection and automated essay scoring are two tasks in the area of automated assessment. Traditionally these tasks have been treated independently with different machine learning models and features used for each task. In this paper, we develop a multi-task neural network model that jointly optimises for both tasks, and in particular we show that neural automated essay scoring can be significantly improved. We show that while the essay score provides little evidence to inform grammatical error detection, the essay score is highly influenced by error detection.     
 Determining whether two given questions are semantically similar is a fairly challenging task given the different structures and forms that the questions can take. In this paper, we use Gated Recurrent Units in combination with other highly used machine learning algorithms like Random Forest, Adaboost and SVM for the similarity prediction task on a dataset released by Quora, consisting of about 400k labeled question pairs. We got the best result by using the Siamese adaptation of a Bidirectional GRU with a Random Forest classifier, which landed us among the top 24\% in the competition Quora Question Pairs hosted on Kaggle. 
   We analyze the language learned by an agent trained with reinforcement learning as a component of the ActiveQA system~. In ActiveQA, question answering is framed as a reinforcement learning task in which an agent sits between the user and a black box question-answering system. The agent learns to reformulate the user's questions to elicit the optimal answers. It probes the system with many versions of a question that are generated via a sequence-to-sequence question reformulation model, then aggregates the returned evidence to find the best answer. This process is an instance of  communication. The question reformulation model must adapt its language to increase the quality of the answers returned, matching the language of the question answering system. We find that the agent does not learn transformations that align with semantic intuitions but discovers through learning classical information retrieval techniques such as tf-idf re-weighting and stemming.  
  While neural machine translation  models    provide improved translation quality in an elegant, end-to-end    framework, it is less clear what they    learn about language.    Recent work has started evaluating the quality of vector representations learned by NMT models on morphological and syntactic tasks.   In this paper, we investigate the representations learned at different layers of  NMT encoders.  We train NMT systems on parallel data and use the trained %    models to extract features for training a classifier on two tasks: part-of-speech and semantic tagging. We then measure the performance of the classifier as a proxy to the quality of the original NMT model for the given task. Our quantitative  analysis yields interesting insights regarding  representation learning in  NMT models. For instance, we find that higher layers are better at learning semantics while lower layers   tend to be  better for part-of-speech tagging. We also observe little  effect of the target language on source-side representations,  especially with higher quality NMT models.\footnote{Our code is available at \url{https://github.com/boknilev/nmt-repr-analysis}.} 
  Neural network models recently proposed for question answering  primarily focus on capturing the passage-question relation. However, they have minimal capability to link relevant facts distributed across multiple sentences which is crucial in achieving deeper understanding, such as performing multi-sentence reasoning, co-reference resolution, etc. They also do not explicitly focus on the question and answer type which often plays a critical role in QA. In this paper, we propose a novel end-to-end question-focused multi-factor attention network for answer extraction. Multi-factor attentive encoding using tensor-based transformation aggregates meaningful facts even when they are located in multiple sentences. To implicitly infer the answer type, we also propose a max-attentional question aggregation mechanism to encode a question vector based on the important words in a question. During prediction, we incorporate sequence-level encoding of the first wh-word and its immediately following word as an additional source of question type information. Our proposed model achieves significant improvements over the best prior state-of-the-art results on three large-scale challenging QA datasets, namely NewsQA, TriviaQA, and SearchQA.  
 We improve automatic correction of grammatical, orthographic, and collocation errors in text using a multilayer convolutional encoder-decoder neural network. The network is initialized with embeddings that make use of character N-gram information to better suit this task. When evaluated on common benchmark test data sets , our model substantially outperforms all prior neural approaches on this task as well as strong statistical machine translation-based systems with neural and task-specific features trained on the same data. Our analysis shows the superiority of convolutional neural networks over recurrent neural networks such as long short-term memory  networks in capturing the local context via attention, and thereby improving the coverage in correcting grammatical errors. By ensembling multiple models, and incorporating an N-gram language model and edit features via rescoring, our novel method becomes the first neural approach to outperform the current state-of-the-art statistical machine translation-based approach, both in terms of grammaticality and fluency. 
 Many recent state-of-the-art recommender systems such as D-ATT, TransNet and DeepCoNN exploit reviews for representation learning. This paper proposes a new neural architecture for recommendation with reviews. Our model operates on a multi-hierarchical paradigm and is based on the intuition that not all reviews are created equal, i.e., only a selected few are important. The importance, however, should be dynamically inferred depending on the current target. To this end, we propose a review-by-review pointer-based learning scheme that extracts important reviews from user and item reviews and subsequently matches them in a word-by-word fashion. This enables not only the most informative reviews to be utilized for prediction but also a deeper word-level interaction. Our pointer-based method operates with a gumbel-softmax based pointer mechanism that enables the incorporation of discrete vectors within differentiable neural architectures. Our pointer mechanism is co-attentive in nature, learning pointers which are co-dependent on user-item relationships. Finally, we propose a multi-pointer learning scheme that learns to combine multiple views of user-item interactions. We demonstrate the effectiveness of our proposed model via extensive experiments on 24 benchmark datasets from Amazon and Yelp. Empirical results show that our approach significantly outperforms existing state-of-the-art models, with up to $19\%$ and $71\%$ relative improvement when compared to TransNet and DeepCoNN respectively. We study the behavior of our multi-pointer learning mechanism, shedding light on `evidence aggregation' patterns in review-based recommender systems.  
 This paper presents methods to accelerate recurrent neural network based language models  for online speech recognition systems. Firstly, a lossy compression of the past hidden layer outputs  with caching is introduced in order to reduce the number of LM queries. Next, RNNLM computations are deployed in a CPU-GPU hybrid manner, which computes each layer of the model on a more advantageous platform. The added overhead by data exchanges between CPU and GPU is compensated through a frame-wise batching strategy. The performance of the proposed methods evaluated on LibriSpeech\footnote{http://www.openslr.org/12/} test sets indicates that the reduction in history vector precision improves the average recognition speed by 1.23 times with minimum degradation in accuracy. On the other hand, the CPU-GPU hybrid parallelization enables RNNLM based real-time recognition with a four times improvement in speed. 
 Many natural language processing tasks solely rely on sparse dependencies between a few tokens in a sentence. Soft attention mechanisms show promising performance in modeling local/global dependencies by soft probabilities between every two tokens, but they are not effective and efficient when applied to long sentences. By contrast, hard attention mechanisms directly select a subset of tokens but are difficult and inefficient to train due to their combinatorial nature. In this paper, we integrate both soft and hard attention into one context fusion model, ``reinforced self-attention '', for the mutual benefit of each other. In ReSA, a hard attention trims a sequence for a soft self-attention to process, while the soft attention feeds reward signals back to facilitate the training of the hard one. For this purpose, we develop a novel hard attention called ``reinforced sequence sampling '', selecting tokens in parallel and trained via policy gradient. Using two RSS modules, ReSA efficiently extracts the sparse dependencies between each pair of selected tokens. We finally propose an RNN/CNN-free sentence-encoding model, ``reinforced self-attention network '', solely based on ReSA.  It achieves state-of-the-art performance on both Stanford Natural Language Inference  and Sentences Involving Compositional Knowledge  datasets.  
 While conversing with chatbots, humans typically tend to ask many questions, a significant portion of which can be answered by referring to large-scale knowledge graphs . While Question Answering  and dialog systems have been studied independently, there is a need to study them closely to evaluate such real-world scenarios faced by bots involving both these tasks. Towards this end, we introduce the task of Complex Sequential QA which combines the two tasks of  answering factual questions through complex inferencing over a realistic-sized KG of millions of entities, and  learning to converse through a series of coherently linked QA pairs. Through a labor intensive semi-automatic process, involving in-house and crowdsourced workers, we created a dataset containing around 200K dialogs with a total of 1.6M turns. Further, unlike existing large scale QA datasets which contain simple questions that can be answered from a single tuple, the questions in our dialogs require a larger subgraph of the KG. Specifically, our dataset has questions which require logical, quantitative, and comparative reasoning as well as their combinations. This calls for models which can:  parse complex natural language questions,  use conversation context to resolve coreferences and ellipsis in utterances,  ask for clarifications for ambiguous queries, and finally  retrieve relevant subgraphs of the KG to answer such questions. However, our experiments with a combination of state of the art dialog and QA models show that they clearly do not achieve the above objectives and are inadequate for dealing with such complex real world settings. We believe that this new dataset coupled with the limitations of existing models as reported in this paper should encourage further research in Complex Sequential QA.  
 Recurrent neural networks are nowadays successfully used in an abundance of applications, going from text, speech and image processing to recommender systems. Backpropagation through time is the algorithm that is commonly used to train these networks on specific tasks. Many deep learning frameworks have their own implementation of training and sampling procedures for recurrent neural networks, while there are in fact multiple other possibilities to choose from and other parameters to tune. In existing literature this is very often overlooked or ignored. In this paper we therefore give an overview of possible training and sampling schemes for character-level recurrent neural networks to solve the task of predicting the next token in a given sequence. We test these different schemes on a variety of datasets, neural network architectures and parameter settings, and formulate a number of take-home recommendations. The choice of training and sampling scheme turns out to be subject to a number of trade-offs, such as training stability, sampling time, model performance and implementation effort, but is largely independent of the data. Perhaps the most surprising result is that transferring hidden states for correctly initializing the model on subsequences often leads to unstable training behavior depending on the dataset.    % \PACS{PACS code1 \and PACS code2 \and more} %  
 As an alternative to question answering methods based on feature engineering, deep learning approaches such as convolutional neural networks  and Long Short-Term Memory Models  have recently been proposed for semantic matching of questions and answers. To achieve good results, however, these models have been combined with additional features such as word overlap or BM25 scores. Without this combination, these models perform significantly worse than methods based on linguistic feature engineering. In this paper, we propose an attention based neural matching model for ranking short answer text.  We adopt value-shared weighting scheme instead of position-shared weighting scheme for combining different matching signals and incorporate question term importance learning using question attention network. Using the popular benchmark TREC QA data, we show that the relatively simple aNMM model can significantly outperform other neural network models that have been used for the question answering task, and is competitive with models that are combined with additional features. When aNMM is combined with additional features, it outperforms all baselines. 
  This paper is to explore the possibility to use alternative data and artificial intelligence techniques to trade stocks. The efficacy of the daily Twitter sentiment on predicting the stock return is examined using machine learning methods. Reinforcement learning is applied to generate the optimal trading policy based on the sentiment signal. The predicting power of the sentiment signal is more significant if the stock price is driven by the expectation on the company growth and when the company has a major event that draws the public attention. The optimal trading strategy based on reinforcement learning outperforms the trading strategy based on the machine learning prediction.  
 The amount of publicly available biomedical literature has been growing rapidly in recent years, yet question answering systems still struggle to exploit the full potential of this source of data. In a preliminary processing step, many question answering systems rely on retrieval models for identifying relevant documents and passages. This paper proposes a weighted cosine distance retrieval scheme based on neural network word embeddings. Our experiments are based on publicly available data and tasks from the BioASQ biomedical question answering challenge and demonstrate significant performance gains  over a wide range of state-of-the-art models.  
  The majority of existing speech emotion recognition research focuses on automatic emotion detection using training and testing data from same corpus collected under the same conditions. The performance of such systems has been shown to drop significantly in cross-corpus and cross-language scenarios. To address the problem, this paper exploits a transfer learning technique to improve the performance of speech emotion recognition systems that is novel in cross-language and cross-corpus scenarios. Evaluations on five different corpora in three different languages show that Deep Belief Networks  offer better accuracy than previous approaches on cross-corpus emotion recognition, relative to a Sparse Autoencoder and SVM baseline system. Results also suggest that using a large number of languages for training and using a small fraction of the target data in training can significantly boost accuracy compared with baseline also for the corpus with limited training examples.  
  Harassment by cyberbullies is a significant phenomenon on the social media. Existing works for cyberbullying detection have at least one of the following three bottlenecks. First, they target only one particular social media platform . Second, they address just one topic of cyberbullying. Third, they rely on carefully handcrafted features of the data. We show that deep learning based models can overcome all three bottlenecks.  Knowledge learned by these models on one dataset can be transferred to other datasets. We performed extensive experiments using three real-world datasets: Formspring , Twitter , and  Wikipedia. Our experiments provide several useful insights about cyberbullying detection. To the best of our knowledge, this is the first work that systematically analyzes cyberbullying detection on various topics across multiple SMPs using deep learning based models and transfer learning.  
 This paper investigates and evaluates support vector machine active learning algorithms for use with imbalanced datasets, which commonly arise in many applications such as information extraction applications. Algorithms based on closest-to-hyperplane selection and query-by-committee selection are combined with methods  for addressing imbalance such as positive amplification based on prevalence statistics from initial random samples.  Three algorithms  are presented and carefully evaluated on datasets for text classification and relation extraction.  The ClosestPA algorithm is shown to consistently outperform the other two in a variety of ways and insights are provided as to why this is the case. 
 When using active learning, smaller batch sizes are typically more efficient from a learning efficiency perspective. However, in practice due to speed and human annotator considerations, the use of larger batch sizes is necessary. While past work has shown that larger batch sizes decrease learning efficiency from a learning curve perspective, it remains an open question how batch size impacts methods for stopping active learning. We find that large batch sizes degrade the performance of a leading stopping method over and above the degradation that results from reduced learning efficiency.  We analyze this degradation and find that it can be mitigated by changing the window size parameter of how many past iterations of learning are taken into account when making the stopping decision. We find that when using larger batch sizes, stopping methods are more effective when smaller window sizes are used.  
 In this paper, we address referring expression comprehension: localizing an image region described by a natural language expression. While most recent work treats expressions as a single unit,  we propose to decompose them into three modular components related to subject appearance, location, and relationship to other objects. This allows us to flexibly adapt to expressions containing different types of information in an end-to-end framework. In our model, which we call the Modular Attention Network , two types of attention are utilized: language-based attention that learns the module weights as well as the word/phrase attention that each module should focus on; and visual attention that allows the subject and relationship modules to focus on relevant image components.  Module weights combine scores from all three modules dynamically to output an overall score. Experiments show that MAttNet outperforms previous state-of-the-art methods by a large margin on both bounding-box-level and pixel-level comprehension tasks. Demo\footnote{Demo: {vision2.cs.unc.edu/refer/comprehension}} and code\footnote{Code: {https://github.com/lichengunc/MAttNet}} are provided. 
 %Historical newspaper archives provide a wealth of information. They %are of particular interest to genealogists, historians and scholars %for people search -- the process of finding information about a person and reconnecting them with others they are likely to know. The goal is often to determine who knows whom and how. An important part of this research is the study of individual or collective biography, often referred to as prosopography. This involves the examination of intimate details of the experience and personal testimonies of a group of individuals, some of which may be reported at length in newspaper articles.  % or the story of one's life highlighting various aspects and describing intimate details of experience some of which may be reported in newspaper articles.%Prosopographical research has the goal of learning about patterns of relationships and activities among people through the study of collective biography.  % A people gazetteer is a dictionary of personal names each entry of which has an indexed list of newspaper articles in which it occurs. %along with a suggested  topic that best summarizes the content of the article.  %To build the People Gazetteer, the noisy text is spell corrected %using an edit distance based algorithm.  %A novel N-gram based evaluation algorithm is designed for measuring the performance of the spell corrector. Next,  %A Named Entity Recognizer is run on the text of each article to identify person entities and an LDA-based topic %detector assigns categories. Influential %people are identified in each category using the Influential Person Index .  %These authoritative people paint a picture of their time and offer new insights into historical events by revealing their personal testimony. %and information can be used to design chronological timelines of famous people in educational resources.  Prosopography is an investigation of the common characteristics of a group of people in history, by a collective study of their lives. It involves a study of biographies to solve historical problems. If such biographies are unavailable, surviving documents and secondary biographical data are used. Quantitative prosopography involves analysis of information from a wide variety of sources about ``ordinary people". In this paper, we present a machine learning framework for automatically designing a people gazetteer which forms the basis of quantitative prosopographical research. The gazetteer is learnt from the noisy text of newspapers using a Named Entity Recognizer . It is capable of identifying  people from it by making use of a custom designed Influential Person Index . Our corpus comprises of 14020 articles from a local newspaper, ``The Sun", published from New York in 1896. Some influential people identified by our algorithm include Captain Donald Hankey , Dame Nellie Melba , Hugh Allan  and Sir Hugh John McDonald .    
 Translations capture important information about languages that can be used as implicit supervision in learning linguistic properties and semantic representations. In an information-centric view, translated texts may be considered as semantic mirrors of the original text and the significant variations that we can observe across  % translations into  various languages can be used to disambiguate a given expression using the linguistic signal that is grounded in translation. Parallel corpora consisting of massive amounts of human translations with a large linguistic variation can be applied to increase abstractions and we propose the use of highly multilingual machine translation models to find language-independent meaning representations. Our initial experiments show that neural machine translation models can indeed learn in such a setup and we can show that the learning algorithm picks up information about the relation between languages in order to optimize transfer leaning with shared parameters. The model creates a continuous language space that represents relationships in terms of geometric distances, which we can visualize to illustrate how languages cluster according to language families and groups. Does this open the door for new ideas of data-driven language typology with promising models and techniques in empirical cross-linguistic research? 
 Hate speech, offensive language, sexism, racism and other types of abusive behavior have become a common phenomenon in many online social media platforms. In recent years, such diverse abusive behaviors have been manifesting with increased frequency and levels of intensity. This is due to the openness and willingness of popular media platforms, such as Twitter and Facebook, to host content of sensitive or controversial topics. However, these platforms have not adequately addressed the problem of online abusive behavior, and their responsiveness to the effective detection and blocking of such inappropriate behavior remains limited. In fact, up to now, they have entered an arms race with the perpetrators, who constantly change tactics to evade the detection algorithms deployed by these platforms. Such algorithms are typically custom-designed and tuned to detect only one specific type of abusive behavior, but usually miss other related behaviors.  In the present paper, we study this complex problem by following a more holistic approach, which considers the various aspects of  abusive behavior. To make the approach tangible, we focus on Twitter data and analyze user and textual properties from different angles of abusive posting behavior. We propose a deep learning architecture, which utilizes a wide variety of available metadata, and combines it with automatically-extracted hidden patterns within the text of the tweets, to detect multiple abusive behavioral norms which are highly inter-related. We apply this unified architecture in a seamless, transparent fashion to detect different types of abusive behavior  without the need for any tuning of the model architecture for each task. We test the proposed approach with multiple datasets addressing different and multiple abusive behaviors on Twitter. Our results demonstrate that it largely outperforms  the state-of-art methods .  
 Goal-Oriented  Dialogue Systems, colloquially known as goal oriented chatbots, help users achieve a predefined goal  within a closed domain. A first step is to understand the user's goal by using natural language understanding techniques. Once the goal is known, the bot must manage a dialogue to achieve that goal, which is conducted with respect to a learnt policy.  The success of the dialogue system depends on the quality of the policy, which is in turn reliant on the availability of high-quality training data for the policy learning method, for instance Deep Reinforcement Learning.   Due to the domain specificity, the amount of available data is typically too low to allow the training of good dialogue policies. In this paper we introduce a transfer learning method to mitigate the effects of the low in-domain data availability. Our transfer learning based approach improves the bot's success rate by $20\%$ in relative terms for distant domains and we more than double it for close domains, compared to the model without transfer learning. Moreover, the transfer learning chatbots learn the policy up to 5 to 10 times faster. Finally, as the transfer learning approach is complementary to additional processing such as warm-starting, we show that their joint application gives the best outcomes.  
 The wealth of structured  and unstructured data about the world available today presents an incredible opportunity for tomorrow's Artificial Intelligence. So far, integration of these two different modalities is a difficult process, involving many decisions concerning how best to represent the information so that it will be captured or useful, and hand-labeling large amounts of data. DeepType overcomes this challenge by explicitly integrating symbolic information into the reasoning process of a neural network with a type system. First we construct a type system, and second, we use it to constrain the outputs of a neural network to respect the symbolic structure. We achieve this by reformulating the design problem into a mixed integer problem: create a type system and subsequently train a neural network with it. In this reformulation discrete variables select which parent-child relations from an ontology are types within the type system, while continuous variables control a classifier fit to the type system. The original problem cannot be solved exactly, so we propose a 2-step algorithm: 1) heuristic search or stochastic optimization over discrete variables that define a type system informed by an Oracle and a Learnability heuristic, 2) gradient descent to fit classifier parameters. We apply DeepType to the problem of Entity Linking on three standard datasets , TAC KBP 2010) and find that it outperforms all existing solutions by a wide margin, including approaches that rely on a human-designed type system or recent deep learning-based entity embeddings, while explicitly using symbolic information lets it integrate new entities without retraining. 
  Existing text generation methods tend to produce repeated and ``boring'' expressions. To tackle this problem, we propose a new text generation model, called Diversity-Promoting Generative Adversarial Network . The proposed model assigns low reward for repeatedly generated text and high reward for ``novel" and fluent text, encouraging the generator to produce diverse and informative text. Moreover, we propose a novel language-model based discriminator, which can better distinguish novel text from repeated text without the saturation problem compared with existing classifier-based discriminators. The experimental results on review generation and dialogue generation tasks demonstrate that our model can generate substantially more diverse and informative text than existing baselines.\footnote{The code is available at  \url{https://github.com/lancopku/DPGAN}} 
  Attention-based sequence-to-sequence model has proved successful in Neural Machine Translation . However, the attention without consideration of decoding history, which includes the past information in the decoder and the attention mechanism, often causes much repetition. To address this problem, we propose the decoding-history-based Adaptive Control of Attention  for the NMT model. ACA learns to control the attention by keeping track of the decoding history and the current information with a memory vector, so that the model can take the translated contents and the current information into consideration. Experiments on Chinese-English translation and the English-Vietnamese translation have demonstrated that our model significantly outperforms the strong baselines. The analysis shows that our model is capable of generating translation with less repetition and higher accuracy. The code will be available at \url{https://github.com/lancopku} 
 This article proposes to auto-encode text at byte-level using convolutional networks with a recursive architecture. The motivation is to explore whether it is possible to have scalable and homogeneous text generation at byte-level in a non-sequential fashion through the simple task of auto-encoding. We show that non-sequential text generation from a fixed-length representation is not only possible, but also achieved much better auto-encoding results than recurrent networks. The proposed model is a multi-stage deep convolutional encoder-decoder framework using residual connections , containing up to 160 parameterized layers. Each encoder or decoder contains a shared group of modules that consists of either pooling or upsampling layers, making the network recursive in terms of abstraction levels in representation. Results for 6 large-scale paragraph datasets are reported, in 3 languages including Arabic, Chinese and English. Analyses are conducted to study several properties of the proposed model. 
 %% Text of abstract Background and Objective: Code assignment is of paramount importance in many levels in modern hospitals, from ensuring accurate billing process to creating a valid record of patient care history. However, the coding process is tedious and subjective, and it requires medical coders with extensive training. This study aims to evaluate the performance of deep-learning-based systems to automatically map clinical notes to ICD-9 medical codes. Methods: The evaluations of this research are focused on end-to-end learning methods without manually defined rules. Traditional machine learning algorithms, as well as state-of-the-art deep learning methods such as Recurrent Neural Networks and Convolution Neural Networks, were applied to the Medical Information Mart for Intensive Care  dataset. An extensive number of experiments was applied to different settings of the tested algorithm. Results: Findings showed that the deep learning-based methods outperformed other conventional machine learning methods. From our assessment, the best models could predict the top 10 ICD-9 codes with 0.6957 $F_1$ and 0.8967 accuracy and could estimate the top 10 ICD-9 categories with 0.7233 $F_1$ and 0.8588 accuracy. Our implementation also outperformed existing work under certain evaluation metrics. Conclusion: A set of standard metrics was utilized in assessing the performance of ICD-9 code assignment on MIMIC-III dataset. All the developed evaluation tools and resources are available {online}, which can be used as a baseline for further research. 
 While end-to-end neural machine translation  has achieved notable success in the past years in translating a handful of resource-rich language pairs, it still suffers from the data scarcity problem for low-resource language pairs and domains. To tackle this problem, we propose an interactive multimodal framework for zero-resource neural machine translation. Instead of being passively exposed to large amounts of parallel corpora, our learners  engage in cooperative image description games, and thus develop their own image captioning or neural machine translation model from the need to communicate in order to succeed at the game. Experimental results on the IAPR-TC12 and Multi30K datasets show that the proposed learning mechanism significantly improves over the state-of-the-art methods. 
 Sequence-to-sequence  models have played an important role in the recent success of various natural language processing methods, such as machine translation, text summarization, and speech recognition. However, current Seq2seq models have trouble preserving global latent information from a long sequence of words. Variational autoencoder  alleviates this problem by learning a continuous semantic space of the input sentence. However, it does not solve the problem completely. In this paper, we propose a new recurrent neural network -based Seq2seq model, RNN semantic variational autoencoder , to better capture the global latent information of a sequence of words. To reflect the meaning of words in a sentence properly, without regard to its position within the sentence, we construct a document information vector using the attention information between the final state of the encoder and every prior hidden state. Then, the mean and standard deviation of the continuous semantic space are learned by using this vector to take advantage of the variational method. By using the document information vector to find the semantic space of the sentence, it becomes possible to better capture the global latent feature of the sentence. Experimental results of three natural language tasks  confirm that the proposed RNN--SVAE yields higher performance than two benchmark models.  Keywords: Sequence-to-sequence learning, Recurrent neural network, Auto-encoder, Variational method, Document information vector, Natural language processing 
 We demonstrate a network visualization technique to analyze the recurrent state inside the LSTMs/GRUs used commonly in language and acoustic models. Interpreting intermediate state and network activations inside end-to-end models remains an open challenge. Our method allows users to understand exactly how much and what history is encoded inside recurrent state in grapheme sequence models. Our procedure trains multiple decoders that predict prior input history. Compiling results from these decoders, a user can obtain a signature of the recurrent kernel that characterizes its memory behavior. We demonstrate this method's usefulness in revealing information divergence in the bases of recurrent factorized kernels, visualizing the character-level differences between the memory of n-gram and recurrent language models, and extracting knowledge of history encoded in the layers of grapheme-based end-to-end ASR networks. 
 In this work we tackle the problem of sentence boundary detection applied to French as a binary classification task . We combine convolutional neural networks with subword-level information vectors, which are word embedding representations learned from Wikipedia that take advantage of the words morphology; so each word is represented as a bag of their character n-grams.  We decide to use a big written dataset  instead of standard size transcriptions to train and evaluate the proposed architectures with the intention of using the trained models in posterior real life ASR transcriptions.   Three different architectures are tested showing similar results; general accuracy for all models overpasses $0.96$. All three models have good F1 scores reaching values over $0.97$ regarding the "not sentence boundary" class. However, the "sentence boundary" class reflects lower scores decreasing the F1 metric to $0.778$ for one of the models.  Using subword-level information vectors seem to be very effective leading to conclude that the morphology of words encoded in the embeddings representations behave like pixels in an image making feasible the use of convolutional neural network architectures.  
 Distinguishing lexical relations has been a long term pursuit in natural language processing  domain. Recently, in order to detect lexical relations like hypernymy, meronymy, co-hyponymy etc., distributional semantic models are being used extensively in some form or the other. Even though a lot of efforts have been made for detecting hypernymy relation, the problem of co-hyponymy detection has been rarely investigated. In this paper, we are proposing a novel supervised model where various network measures have been utilized to identify co-hyponymy relation with high accuracy performing better or at par with the state-of-the-art models.        \\ \newline \Keywords{Co-hyponymy detection, Distributional thesaurus network, Complex network measures.
 We introduce a new type of deep contextualized word representation that models both  complex characteristics of word use , and  how these uses vary across linguistic contexts . %how complex aspects of word use  vary with the linguistic context in which the word is used . Our word vectors are learned functions of the internal states of a deep bidirectional language model , which is pre-trained on a large text corpus. %Our word vectors are linear functions of the internal states of a deep bi-directional language model, which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. %We show that these \ELMO\   representations can be easily added to existing models for six challenging NLP problems, including sentiment analysis and question answering, and that they significantly improve state-of-the-art performance levels in every case. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals. %to explain why these representations work so well in practice, which highlights the benefits of exposing the internal states of the pretrained deep networks.     %We present a general method to add context dependent word representations from a pre-trained, large scale bidirectional language model  to any supervised NLP architecture. %By allowing the supervised model to learn a weighted combination of all biLM layers, it can preferentially re-use the different types of information represented at each biLM layer in a task specific way. %This approach works well in practice, establishing %We establish six new state-of-the-art results on a diverse set of benchmark NLP tasks for textual entailment, question answering, coreference resolution, semantic role labeling, named entity extraction, and sentiment classification, in all cases significantly improving overall system performance. %We attribute the improved performance on supervised tasks to the biLM's ability to disambiguate word sense and learn basic elements of syntax. %Finally, in every considered case, the biLM outperforms contextual embeddings produced by a machine translation system.  
  In this paper, we propose a new universal machine translation approach focusing on languages with a limited amount of parallel data.  Our proposed approach utilizes a transfer-learning approach to share lexical and sentence level representations across multiple source languages into one target language. The lexical part is shared through a  Universal Lexical Representation to support multi-lingual word-level sharing. The sentence-level sharing is represented by a model of experts from all source languages that share the source encoders with all other languages. This enables the low-resource language to utilize the lexical and sentence representations of the higher resource languages.  Our approach is able to achieve 23 BLEU on Romanian-English WMT2016 using a tiny parallel corpus of 6k sentences, compared to the 18 BLEU of strong baseline system which uses multi-lingual training and back-translation. Furthermore, we show that the proposed approach can achieve almost 20 BLEU on the same dataset through fine-tuning  a pre-trained multi-lingual system in a zero-shot setting.  
  To build a satisfying chatbot that has the ability of managing a goal-oriented multi-turn dialogue, accurate modeling of human conversation is crucial. In this paper we concentrate on the task of response selection for multi-turn human-computer conversation with a given context. Previous approaches show weakness in capturing information of rare keywords that appear in either or both context and correct response, and struggle with long input sequences. We propose Cross Convolution Network  and Multi Frequency word embedding to address both problems. We train several models using the Ubuntu Dialogue dataset which is the largest freely available multi-turn based dialogue corpus. We further build an ensemble model by averaging predictions of multiple models. We achieve a new state-of-the-art on this dataset with considerable improvements compared to previous best results.    
 Multi-channel speech enhancement with ad-hoc sensors has been a challenging task. Speech model guided beamforming algorithms are able to recover natural sounding speech, but the speech models tend to be oversimplified or the inference would otherwise be too complicated. On the other hand, deep learning based enhancement approaches are able to learn complicated speech distributions and perform efficient inference, but they are unable to deal with variable number of input channels. Also, deep learning approaches introduce a lot of errors, particularly in the presence of unseen noise types and settings. We have therefore proposed an enhancement framework called \algnamens, which combines the two complementary classes of algorithms. \algname introduces a beamforming filter to produce natural sounding speech, but the filter coefficients are determined with the help of a monaural speech enhancement neural network. Experiments on synthetic and real-world data show that \algname is able to produce clean, dry and natural sounding speech, and is robust against unseen noise. 
 Traditional event detection methods heavily rely on manually engineered rich features. Recent deep learning approaches alleviate this problem by automatic feature engineering. But such efforts, like tradition methods, have so far only focused on single-token event mentions, whereas in practice events can also be a phrase. We instead use forward-backward recurrent neural networks  to detect events that can be either words or phrases. To the best our knowledge, this is one of the first efforts to handle multi-word events and also the first attempt to use RNNs for event detection. Experimental results demonstrate that FBRNN is competitive with the state-of-the-art methods on the ACE 2005 and the Rich ERE 2015 event detection tasks. 
 Argument mining is a core technology for automating argument search in large document collections. Despite its usefulness for this task, most current approaches to argument mining are designed for use only with specific text types and fall short when applied to heterogeneous texts. In this paper, we propose a new sentential annotation scheme that is reliably applicable by crowd workers to arbitrary Web texts. We source annotations for over 25,000 instances covering eight controversial topics. The results of cross-topic experiments show that our attention-based neural network generalizes best to unseen topics and outperforms vanilla BiLSTM models by 6\% in accuracy and 11\% in F-score. 
 Given a target name, which can be a product aspect or entity, identifying its aspect words and opinion words in a given corpus is a fine-grained task in target-based sentiment analysis . This task is challenging, especially when we have no labeled data and we want to perform it for any given domain. To address it, we propose a general two-stage approach. Stage one extracts/groups the target-related words  for a given target. This is relatively easy as we can apply an existing semantics-based learning technique. Stage two separates the aspect and opinion words from the grouped t-words, which is challenging because we often do not have enough word-level aspect and opinion labels. In this work, we formulate this problem in a PU learning setting and incorporate the idea of lifelong learning to solve it. Experimental results show the effectiveness of our approach.  
 Machine Learning has been the quintessential solution for many AI problems, but learning models are heavily dependent on specific training data. Some learning models can be incorporated with prior knowledge using a Bayesian setup, but these learning models do not have the ability to access any organized world knowledge on demand.  In this work, we propose to enhance learning  models with world knowledge in the form of Knowledge Graph  fact triples for Natural Language Processing  tasks. Our aim is to develop a deep learning model that can extract relevant prior support facts from knowledge graphs depending on the task using attention mechanism. We introduce a convolution-based model for learning representations of knowledge graph entity and relation clusters in order to reduce the attention space. We show that the proposed method is highly scalable to the amount of prior information that has to be processed and can be applied to any generic NLP task. Using this method we show significant improvement in performance for text classification with 20Newsgroups  \& DBPedia datasets, and natural language inference with Stanford Natural Language Inference  dataset. We also demonstrate that a deep learning model can be trained with substantially less amount of labeled training data, when it has access to organized world knowledge in the form of a knowledge base.  
 Supervised learning models are typically trained on a single dataset and the performance of these models rely heavily on the size of the dataset, i.e., amount of data available with the ground truth. Learning algorithms try to generalize solely based on the data that is presented with during the training. In this work, we propose an inductive transfer learning method that can augment learning models by infusing similar instances from different learning tasks in the Natural Language Processing  domain. We propose to use instance representations from a source dataset, without inheriting anything from the source learning model. Representations of the instances of source \& target datasets are learned, retrieval of relevant source instances is performed using soft-attention mechanism and locality sensitive hashing, and then, augmented into the model during training on the target dataset. Our approach simultaneously exploits the local instance level information as well as the macro statistical viewpoint of the dataset. Using this approach we have shown significant improvements for three major news classification datasets over the baseline. Experimental evaluations also show that the proposed approach reduces dependency on labeled data by a significant margin for comparable performance. With our proposed cross dataset learning procedure we show that one can achieve competitive/better performance than learning from a single dataset.  
  Sequence-to-sequence attentional-based neural network architectures have been shown to provide a powerful model for machine translation and speech recognition. Recently, several works have attempted to extend the models for end-to-end speech translation task. However, the usefulness of these models were only investigated on language pairs with similar syntax and word order . In this work, we focus on end-to-end speech translation tasks on syntactically distant language pairs  that require distant word reordering.  To guide the encoder-decoder attentional model to learn this difficult problem, we propose a structured-based curriculum learning strategy.  Unlike conventional curriculum learning that gradually emphasizes difficult data examples, we formalize learning strategies from easier network structures to more difficult network structures. Here, we start the training with end-to-end encoder-decoder for speech recognition or text-based machine translation task then gradually move to end-to-end speech translation task. The experiment results show that the proposed approach could provide significant improvements in comparison with the one without curriculum learning. 
  Voice cloning is a highly desired feature for personalized speech interfaces. We introduce a neural voice cloning system that learns to synthesize a person's voice from only a few audio samples. We study two approaches: speaker adaptation and speaker encoding. Speaker adaptation is based on fine-tuning a multi-speaker  generative model. Speaker encoding is based on training a separate model to directly infer a new speaker embedding, which will be applied to a multi-speaker generative model. In terms of naturalness of the speech and similarity to the original speaker, both approaches can achieve good performance, even with a few cloning audios.}  While speaker adaptation can achieve slightly better naturalness and similarity, cloning time and required memory for the speaker encoding approach are significantly less, making it more favorable for low-resource deployment.  
 Distributed representations of words learned from text have proved to be successful in various natural language processing tasks in recent times. While some methods represent words as vectors computed from text using predictive model  or dense count based model , others attempt to represent these in a distributional thesaurus network structure where the neighborhood of a word is a set of words having adequate context overlap.  Being motivated by recent surge of research in network embedding techniques , we turn a distributional thesaurus network into dense word vectors and investigate the usefulness of distributional thesaurus embedding in improving overall word representation.     %Most of the attempts are made to represent words in intensional form directly from text whereas effect of an intensional representation prepared from an extensional representation is rarely investigated. In this paper, we investigate the outcome of converting a distributional thesaurus  into dense word vectors    %To be precise, we apply several network embedding methods like  etc. on distributional thesaurus network and evaluate the  word representation against word similarity and relatedness tasks. This is the first attempt where we show that combining the proposed word representation obtained by distributional thesaurus embedding with the state-of-the-art word representations helps in improving the performance by a significant margin when evaluated against NLP tasks like word similarity and relatedness, synonym detection, analogy detection. Additionally, we show that even without using any handcrafted lexical resources we can come up with representations having comparable performance in the word similarity and relatedness tasks compared to the representations where a lexical resource has been used. 
 Time delay neural networks  are an effective acoustic model for large vocabulary speech recognition. The strength of the model can be attributed to its ability to effectively model long temporal contexts. However, current TDNN models are relatively shallow, which limits the modelling capability. This paper proposes a method of increasing the network depth by deepening the kernel used in the TDNN temporal convolutions. The best performing kernel consists of three fully connected layers with a residual  connection from the output of the first to the output of the third. The addition of spectro-temporal processing as the input to the TDNN in the form of a convolutional neural network  and a newly designed Grid-RNN was investigated. The Grid-RNN strongly outperforms a CNN if different sets of parameters for different frequency bands are used and can be further enhanced by using a bi-directional Grid-RNN. Experiments using the multi-genre broadcast  English data  show that deep kernel TDNNs reduces the word error rate  by 6\% relative and when combined with the frequency dependent Grid-RNN gives a relative WER reduction of 9\%. 
      We explore multitask models for neural translation of speech, augmenting them in order to reflect two intuitive notions. First, we introduce a model where the second task decoder receives information from the decoder of the first task, since higher-level intermediate representations should provide useful information. Second, we apply regularization that encourages transitivity and invertibility. We show that the application of these notions on jointly trained models improves performance on the tasks of low-resource speech transcription and translation. It also leads to better performance when using attention information for word discovery over unsegmented input. 
   Distributed word representations, or word vectors, have recently been applied to many tasks in natural language processing, leading to state-of-the-art performance.   A key ingredient to the successful application of these representations is to train them on very large corpora, and use these pre-trained models in downstream tasks.   In this paper, we describe how we trained such high quality word representations for 157 languages.   We used two sources of data to train these models: the free online encyclopedia Wikipedia and data from the common crawl project.   We also introduce three new word analogy datasets to evaluate these word vectors, for French, Hindi and Polish.   Finally, we evaluate our pre-trained word vectors on 10 languages for which evaluation datasets exists, showing very strong performance compared to previous models.   \\ \newline \Keywords{word vectors, word analogies, fasttext
 We present a new algorithm for identifying the transition and emission probabilities of a hidden Markov model  from the emitted data. Expectation-maximization becomes computationally prohibitive for long observation records, which are often required for identification. The new algorithm is particularly suitable for cases where the available sample size is large enough to accurately estimate second-order output probabilities, but not higher-order ones. We show that if one is only able to obtain a reliable estimate of the pairwise co-occurrence probabilities of the emissions, it is still possible to uniquely identify the HMM if the emission probability is . We apply our method to hidden topic Markov modeling, and demonstrate that we can learn topics with higher quality if documents are modeled as observations of HMMs sharing the same emission  probability, compared to the simple but widely used bag-of-words model. 
 This paper proposes a new architecture --- \fullname  --- to represent grammatical structures in deep learning models. \name exploits Tensor Product Representations , a structured neural-symbolic model developed in cognitive science, to integrate deep learning with explicit language structures and rules. The key ideas of \name are: 1) unsupervised learning of role-unbinding vectors of words via TPR-based deep neural network; 2) employing attention modules to compute TPR; and 3) integration of TPR with typical deep learning architectures including Long Short-Term Memory  and Feedforward Neural Network . The novelty of our approach lies in its ability to extract the grammatical structure of a sentence by using role-unbinding vectors, which are obtained in an unsupervised manner. This \name approach is applied to 1) image captioning, 2) part of speech  tagging, and 3) constituency parsing of a sentence. Experimental results demonstrate the effectiveness of the proposed approach.  
 This paper presents an open-source neural machine translation toolkit named CytonMT\footnote{https://github.com/arthurxlw/cytonMt}. The toolkit is built from scratch only using C++ and NVIDIA's GPU-accelerated libraries. The toolkit features training efficiency, code simplicity and translation quality. Benchmarks show that CytonMT accelerates the training speed by 64.5\% to 110.8\% on neural networks of various sizes, and achieves competitive translation quality. 
 Identifying the relationship between two articles, e.g., whether two articles published from different sources describe the same breaking news, is critical to many document understanding tasks. Existing approaches for modeling and matching sentence pairs do not perform well in matching  documents, which embody more complex interactions between the enclosed entities than a sentence does. To model article pairs, we propose the Concept Interaction Graph to represent an article as a graph of concepts. We then match a pair of articles by comparing the sentences that enclose the same concept vertex through a series of encoding techniques, and aggregate the matching signals through a graph convolutional network. %Based on the graph representation, we get local matching features on each vertex, and aggregate the vertex features though Graph Convolutional Networks to generate the matching result. To facilitate the evaluation of long article matching, we have created two datasets, each consisting of about 30K pairs of  articles covering diverse topics in the open domain. Extensive evaluations of the proposed methods on the two datasets demonstrate significant improvements over a wide range of state-of-the-art methods for natural language matching. 
 Word embedding is a useful approach to capture co-occurrence structures in large text corpora. However, in addition to the text data itself, we often have additional covariates associated with individual corpus documents---e.g. the demographic of the author, time and venue of publication---and we would like the embedding to naturally capture this information. We propose CoVeR, a new tensor decomposition model for vector embeddings with covariates. CoVeR jointly learns a  embedding for all the words as well as a weighted diagonal matrix to model how each covariate affects the base embedding. To obtain author or venue-specific embedding, for example, we can then simply multiply the base embedding by the associated transformation matrix. The main advantages of our approach are data efficiency and interpretability of the covariate transformation. Our experiments demonstrate that our joint model learns substantially better covariate-specific embeddings compared to the standard approach of learning a separate embedding for each covariate using only the relevant subset of data, as well as other related methods. Furthermore, CoVeR encourages the embeddings to be ``topic-aligned'' in that the dimensions have specific independent meanings. This allows our covariate-specific embeddings to be compared by topic, enabling downstream differential analysis. We empirically evaluate the benefits of our algorithm on datasets, and demonstrate how it can be used to address many natural questions about covariate effects.  Accompanying code to this paper can be found at http://github.com/kjtian/CoVeR. 
 Vanishing long-term gradients are a major issue in training standard recurrent neural networks , which can be alleviated by long short-term memory  models with memory cells. However, the extra parameters associated with the memory cells mean an LSTM layer has four times as many parameters as an RNN with the same hidden vector size. This paper addresses the vanishing gradient problem using a high order RNN  which has additional connections from multiple previous time steps. Speech recognition experiments using British English multi-genre broadcast  data showed that the proposed HORNN architectures for rectified linear unit and sigmoid activation functions reduced word error rates  by 4.2\% and 6.3\% over the corresponding RNNs, and gave similar WERs to a  LSTM while using only 20\%--50\% of the recurrent layer parameters and computation. 
 We propose several ways of reusing  subword embeddings and other weights in subword-aware neural language models. The proposed techniques do not benefit a competitive character-aware model, but some of them improve the performance of syllable- and morpheme-aware models while showing significant reductions in model sizes. We discover a simple hands-on principle: in a multi-layer input embedding model, layers should be tied consecutively bottom-up if reused at output. Our best morpheme-aware model with properly reused weights beats the competitive word-level model by a large margin across multiple languages and has 20\%--87\% fewer parameters.  
 % is the written explanation for the charge of a criminal case. In this paper, we propose to study the not well-studied problem of $\text{}$ $\text{}$ $\text{}$eration from the fact description in a case, which is useful for improving the interpretability of charge prediction systems and automatic legal document generation. In this work, we propose a label-conditioned sequence to sequence model with attention for $\text{}$$\text{}$$\text{}$, where an encoder reads the fact descriptions and a decoder generates the court views. To generate more class discriminative court views, we encode the charges as the labels for the corresponding fact descriptions and decode court views conditioned on the charge labels. Attention mechanism is further applied to maintain fact details in generated court views. Experimental results show the efficiency of our model and that exploiting charge labels will significantly improve the class-discriminations of generated court views.  %In this paper, we propose to study the problem of $\text{}$ $\text{}$ $\text{}$eration from the fact description in a criminal case. The task aims to improve the interpretability of charge prediction systems and benefit automatic legal document generation. We propose a label-conditioned sequence-to-sequence model with attention for this task, where an encoder reads the fact descriptions and a decoder generates the court views. To generate more charge-discriminative court views, we encode the charges as the labels for the corresponding fact descriptions, and decode court views conditioned on the charge labels. Attention mechanism is further applied to maintain fact details in generated court views. We evaluate our model on a real-world dataset and experimental results show the efficacy of our model.  %In this paper, we propose to study the problem of $\text{}$ $\text{}$ $\text{}$eration from the fact description in a criminal case, which aims to improve the interpretability of charge prediction systems and help automatic legal document generation. We formulate this task as a text-to-text natural language generation problem. Due to the non-distinctions of fact descriptions, it is hard to generate charge-discriminative court views, so we propose a label-conditioned sequence-to-sequence model with attention for this problem, where we encode the charges as the labels for the corresponding fact descriptions and decode court views conditioned on the charge labels with attention mechanism. Experimental results show the efficiency of our model and that exploiting charge labels will significantly improve the charge-discriminations of generated court views.  %In this paper, we propose to study the problem of $\text{}$ $\text{}$ $\text{}$eration from the fact description in a criminal case. The task aims to improve the interpretability of charge prediction systems and help automatic legal document generation. We formulate this task as a text-to-text natural language generation  problem. Due to the non-distinctions of fact descriptions, it is hard to generate charge-discriminative court views. In this work, we explore charge labels to tackle this issue. %In this work, we explore charge labels to generate charge-discriminative court views from non-distinct fact descriptions.  %Sequence-to-sequence model has achieved cutting-edge performances in many NLG tasks.  %Rule-based methods for NLG are manual-labor concentrated.  %To further improve the discriminations of generated court views, we propose a label-conditioned Seq2Seq model with attention for this problem, by decoding court views conditioned on charge labels. Experimental results show the efficiency of our method. %and that exploiting charge labels will significantly improve the charge-discriminations of generated court views.  In this paper, we propose to study the problem of $\text{}$ $\text{}$ $\text{}$eration from the fact description in a criminal case. The task aims to improve the interpretability of charge prediction systems and help automatic legal document generation. We formulate this task as a text-to-text natural language generation  problem. Sequence-to-sequence model has achieved cutting-edge performances in many NLG tasks. However, due to the non-distinctions of fact descriptions, it is hard for Seq2Seq model to generate charge-discriminative court views. In this work, we explore charge labels to tackle this issue. %In this work, we explore charge labels to generate charge-discriminative court views from non-distinct fact descriptions.  %Rule-based methods for NLG are manual-labor concentrated.  We propose a label-conditioned Seq2Seq model with attention for this problem, to decode court views conditioned on encoded charge labels.  Experimental results show the effectiveness of our method.\footnote{Data and codes are available at \url{https://github.com/oceanypt/Court-View-Gen}.} %and that exploiting charge labels will significantly improve the charge-discriminations of generated court views.  
   Single document summarization is the task of producing a shorter   version of a document while preserving its principal information   content.  In this paper we conceptualize extractive summarization as   a sentence ranking task and propose a novel training algorithm which   globally optimizes the ROUGE evaluation metric through a   reinforcement learning objective.  We use our algorithm to train a   neural summarization model on the CNN and DailyMail datasets and   demonstrate experimentally that it outperforms state-of-the-art   extractive and abstractive systems when evaluated automatically and   by humans.\footnote{Our code and data are available here:     \url{https://github.com/shashiongithub/Refresh}.} 
  Syntactic rules in natural language typically need to make reference to hierarchical sentence structure.  However, the simple examples that language learners receive are often equally compatible with linear rules. Children consistently ignore these linear explanations and settle instead on the correct hierarchical one. This fact has motivated the proposal that the learner's hypothesis space is constrained to include only hierarchical rules. We examine this proposal using recurrent neural networks , which are not constrained in such a way. We simulate the acquisition of question formation, a hierarchical transformation, in a fragment of English. We find that some RNN architectures tend to learn the hierarchical rule, suggesting that hierarchical cues within the language, combined with the implicit architectural biases inherent in certain RNNs, may be sufficient to induce hierarchical generalizations. The likelihood of acquiring the hierarchical generalization increased when the language included an additional cue to hierarchy in the form of subject-verb agreement, underscoring the role of cues to hierarchy in the learner's input.  Keywords:  learning bias; poverty of the stimulus; recurrent neural networks 
 The Bidirectional LSTM  RNN based speech synthesis system is among the best parametric Text-to-Speech  systems in terms of the naturalness of generated speech, especially the naturalness in prosody. However, the model complexity and inference cost of BLSTM prevents its usage in many runtime applications. Meanwhile, Deep Feed-forward Sequential Memory Networks  has shown its consistent out-performance over BLSTM in both word error rate  and the runtime computation cost in speech recognition tasks. Since speech synthesis also requires to model long-term dependencies compared to speech recognition, in this paper, we investigate the Deep-FSMN  in speech synthesis. Both objective and subjective experiments show that, compared with BLSTM TTS method, the DFSMN system can generate synthesized speech with comparable speech quality while drastically reduce model complexity and speech generation time.  
 % Multi-task learning has been a successful paradigm for sharing knowledge between tasks when training deep neural networks, especially for scenarios where there is little manually labelled training data available. This is achieved through sharing parameters of hidden layers between the main and auxiliary tasks, with separate input and output layers for each task. Tasks are typically related, but have different label spaces. % Another successful stream of research for learning from only a small set of labelled instances is semi-supervised learning. There, a small set of labelled data is used in conjunction with a larger set of unlabelled data for the same task and implicit structural assumptions or distance metrics made based on the labelled data are used to implicitly or explicitly label the unlabelled data.  % Multi-task learning and semi-supervised learning are both successful paradigms for scenarios with little labeled data. Despite advances on both sides, neither research stream is able to model transfer of annotations between disparate label spaces. % Although there have been advances on both sides, e.g. learning what parameters to share in multi-task learning, and using adversarial generative models for semi-supervised learning, neither of the research streams focuses on modelling to transfer annotations between heterogenous label spaces. % We propose to exploit similarities of tasks with different label spaces by learning to map label spaces from different tasks onto one another. Our approach extends the multi-task learning paradigm with two components: a) a jointly learned label space that allows us to learn the relationship between disparate labels of different tasks; and b) a semi-supervised function that takes auxiliary task predictions and data-specific similarity features as input and estimates a label for the target task. % Here, we argue that similarities between tasks with different label spaces can be exploited more directly by learning to map label spaces from different tasks onto one another. We propose to approach this by extending the multi-task learning paradigm with a semi-supervised function that takes predictions of auxiliary tasks as well as instance-specific and similarity features to produce a silver prediction for the target task. We learn this function together with the objective function minimising the loss over predictions for the main task akin to expectation maximisation . % We extensively evaluate our proposed framework on a variety of tasks with disparate label spaces and achieve a new state-of-the-art for XX and XX. We combine multi-task learning and semi-supervised learning by inducing a joint embedding space between disparate label spaces and learning transfer functions between label embeddings, enabling us to jointly leverage unlabelled data and auxiliary, annotated datasets. We evaluate our approach on a variety of sequence classification tasks with disparate label spaces. We outperform strong single and multi-task baselines and achieve a new state-of-the-art for topic-based sentiment analysis. 
  Flood of information is produced in a daily basis through the global internet usage arising from the online interactive communications among users. While this situation contributes significantly to the quality of human life, unfortunately it involves enormous dangers, since online texts with high toxicity can cause personal attacks, online harassment and bullying behaviors. This has triggered both industrial and research community in the last few years while there are several tries to identify an efficient model for online toxic comment prediction. However, these steps are still in their infancy and new approaches and frameworks are required.  On parallel, the data explosion that appears constantly, makes the construction of new machine learning computational tools for managing this information, an imperative need. Thankfully advances in hardware, cloud computing and big data management allow the development of Deep Learning approaches appearing  very promising performance so far. %Towards this direction are approaches based on Deep Learning technique.   For text classification in particular the use of Convolutional Neural Networks  have recently been proposed approaching text analytics in a modern manner   emphasizing in the structure of words in a document.  In this work, we employ this approach to discover toxic comments in a large pool of documents provided by a current Kaggle's competition regarding Wikipedia's talk page edits. To justify this decision we choose to compare CNNs against the traditional bag-of-words approach for text analysis combined with a selection of algorithms proven to be very effective in text classification. The reported results provide enough evidence that CNN enhance toxic comment classification reinforcing research interest towards this direction.    % Even at text classification have been proposed recently several methods based on Convolutional Neural Networks  with satisfactory results. However, is a fresh research field and there is enough space for new methodologies and frameworks. %In our work, 閳.. %Our model was applied to dataset of current year Kaggle's competition, that concerns a toxic comment classification challenge. We provided evidences that CNN model was the most efficient against other well-established classification methods.   
 		 requires AI models to comprehend data in two domains, vision and text. Current state-of-the-art models use learned attention mechanisms to extract relevant information from the input domains to answer a certain question. Thus, robust attention mechanisms are essential for powerful VQA models. In this paper, we propose a recurrent attention mechanism and show its benefits compared to the traditional convolutional approach.  We perform two ablation studies to evaluate recurrent attention. First, we introduce a baseline  model with visual attention and test the performance difference between convolutional and recurrent attention on the VQA 2.0 dataset. Secondly, we design an architecture for VQA which utilizes dual  . Using this model, we show the effect of all possible combinations of recurrent and convolutional dual attention. Our single model outperforms the first place winner on the VQA 2016 challenge and to the best of our knowledge, it is the second best performing single model on the VQA 1.0 dataset. Furthermore, our model noticeably improves upon the winner of the VQA 2017 challenge. Moreover, we experiment replacing attention mechanisms in state-of-the-art models with our  and show increased performance.  		 	
 We investigate the automatic classification of patient discharge notes into standard disease labels. We find that Convolutional Neural Networks with Attention outperform previous algorithms used in this task, and suggest further areas for improvement. 
 Adverse drug reactions  are one of the leading causes of mortality in health care. Current ADR surveillance systems are often associated with a substantial time lag before such events are officially published. On the other hand, online social media such as Twitter contain information about ADR events in real-time, much before any official reporting. Current state-of-the-art in ADR mention extraction uses Recurrent Neural Networks , which typically need large labeled corpora. Towards this end, we propose a multi-task learning based method which can utilize a similar auxiliary task  to enhance the performance of the main task, i.e., ADR extraction. Furthermore, in absence of the auxiliary task dataset, we propose a novel joint multi-task learning method to automatically generate weak supervision dataset for the auxiliary task when a large pool of unlabeled tweets is available. Experiments with $ 
 %   The growing importance of massive datasets with the advent of deep learning makes robustness to label noise a critical property for classifiers to have. Sources of label noise include automatic labeling, non-expert labeling, and label corruption by data poisoning adversaries. In the latter case, corruptions may be arbitrarily bad, even so bad that a classifier predicts the wrong labels with high confidence. To protect against such sources of noise, we leverage the fact that a small set of clean labels is often easy to procure. We demonstrate that robustness to label noise up to severe strengths can be achieved by using a set of trusted data with clean labels, and propose a loss correction that utilizes trusted examples in a data-efficient manner to mitigate the effects of label noise on deep neural network classifiers. Across vision and natural language processing tasks, we experiment with various label noises at several strengths, and show that our method significantly outperforms existing methods. The growing importance of massive datasets used for deep learning makes robustness to label noise a critical property for classifiers to have. Sources of label noise include automatic labeling, non-expert labeling, and label corruption by data poisoning adversaries. Numerous previous works assume that no source of labels can be trusted. We relax this assumption and assume that a small subset of the training data is trusted. This enables substantial label corruption robustness performance gains. In addition, particularly severe label noise can be combated by using a set of trusted data with clean labels. We utilize trusted data by proposing a loss correction technique that utilizes trusted examples in a data-efficient manner to mitigate the effects of label noise on deep neural network classifiers. Across vision and natural language processing tasks, we experiment with various label noises at several strengths, and show that our method significantly outperforms existing methods.\looseness=-1 
 \vspace*{0.3cm}  	 		  	 \tab As computing systems become increasingly advanced and as users increasingly engage themselves in technology, security has never been a greater concern. In malware detection, static analysis, the method of analyzing potentially malicious files, has been the prominent approach. This approach, however, quickly falls short as malicious programs become more advanced and adopt the capabilities of obfuscating its binaries to execute the same malicious functions, making static analysis extremely difficult for newer variants. The approach assessed in this paper is a novel dynamic malware analysis method, which may generalize better than static analysis to newer variants. Inspired by recent successes in Natural Language Processing , widely used document classification techniques were assessed in detecting malware by doing such analysis on system calls, which contain useful information about the operation of a program as requests that the program makes of the kernel. Features considered are extracted from system call traces of benign and malicious programs, and the task to classify these traces is treated as a binary document classification task of system call traces. The system call traces were processed to remove the parameters to only leave the system call function names. The features were grouped into various n-grams and weighted with Term Frequency-Inverse Document Frequency. This paper shows that Linear Support Vector Machines  optimized by Stochastic Gradient Descent and the traditional Coordinate Descent on the Wolfe Dual form of the SVM are effective in this approach, achieving a highest of 96\% accuracy with 95\% recall score. Additional contributions include the identification of significant system call sequences that could be avenues for further research.   
 	We present a neural transducer model with visual attention that learns to generate \LaTeX  ~markup of a real-world math formula given its image. Applying sequence modeling and transduction techniques that have been very successful across modalities such as natural language, image, handwriting, speech and audio; we construct an image-to-markup model that learns to produce syntactically and semantically correct \LaTeX ~markup code over 150 words long and achieves a BLEU score of 89\%; improving upon the previous state-of-art for the Im2Latex problem. We also demonstrate with heat-map visualization how attention helps in interpreting the model and can pinpoint  symbols on the image accurately despite having been trained without any bounding box data. 
     Visual Question Answering  models have struggled with counting objects in natural images so far.     We identify a fundamental problem due to soft attention in these models as a cause.     To circumvent this problem, we propose a neural network component that allows robust counting from object proposals.     Experiments on a toy task show the effectiveness of this component and we obtain state-of-the-art accuracy on the number category of the VQA v2 dataset without negatively affecting other categories, even outperforming ensemble models with our single model.     On a difficult balanced pair metric, the component gives a substantial improvement in counting over a strong baseline by 6.6\%. 
Social media, as a major platform for communication and information exchange, is a rich repository of the opinions and sentiments of 2.3 billion users about a vast spectrum of topics. To sense the whys of certain social user's demands and cultural-driven interests, however, the knowledge embedded in the 1.8 billion pictures which are uploaded daily in public profiles has just started to be exploited since this process has been typically been text-based. Following this trend on visual-based social analysis, we present a novel methodology based on Deep Learning to build a combined image-and-text based personality trait model, trained with images posted together with words found highly correlated to specific personality traits. So the key contribution here is to explore whether OCEAN personality trait modeling can be addressed based on images, here called ics}, appearing with certain tags with psychological insights. We found that there is a correlation between those posted images and their accompanying texts, which can be successfully modeled using deep neural networks for personality estimation. The experimental results are consistent with previous cyber-psychology results based on texts or images. In addition, classification results on some traits show that some patterns emerge in the set of images corresponding to a specific text, in essence to those representing an abstract concept. These results open new avenues of research for further refining the proposed personality model under the supervision of psychology experts. 	
   This document contains the instructions for preparing a camera-ready   manuscript for the proceedings of . The document itself   conforms to its own specifications, and is therefore an example of   what your manuscript should look like. These instructions should be   used for both papers submitted for review and for final versions of   accepted papers.  Authors are asked to conform to all the directions   reported in this document. 
   Learning speaker-specific features is vital in many applications like speaker recognition, diarization and speech recognition.   This paper provides a novel approach, we term Neural Predictive Coding , to learn speaker-specific characteristics in a completely unsupervised manner from large amounts of unlabeled training data that even contain many non-speech events and multi-speaker audio streams.   The NPC framework exploits the proposed short-term active-speaker stationarity hypothesis which assumes two temporally-close short speech segments  belong to the same speaker, and thus a common representation that can encode the commonalities of both the segments, should capture the vocal characteristics of that speaker.    We train a convolutional deep siamese network to produce ``speaker embeddings'' by learning to separate `same' vs `different' speaker pairs which are generated from an unlabeled data of audio streams.   Two sets of experiments are done in different scenarios to evaluate the strength of NPC embeddings and compare with state-of-the-art in-domain supervised methods.   First, two speaker identification experiments with different context lengths are performed in a scenario with comparatively limited within-speaker channel variability.   NPC embeddings are found to perform the best at short duration experiment, and they provide complementary information to i-vectors for full utterance experiments.    Second, a large scale speaker verification task having a wide range of within-speaker channel variability is adopted as an upper-bound experiment where comparisons are drawn with in-domain supervised methods. 
 Semantic composition functions have been playing a pivotal role in neural representation learning of text sequences. In spite of their success, most existing models suffer from the underfitting problem: they use the same shared compositional function on all the positions in the sequence, thereby lacking expressive power due to incapacity to capture the richness of compositionality. Besides, the composition functions of different tasks are independent and learned from scratch. In this paper, we propose a new sharing scheme of composition function across multiple tasks. Specifically, we use a shared meta-network to capture the meta-knowledge of semantic composition and generate the parameters of the task-specific semantic composition models. We conduct extensive experiments on two types of tasks, text classification and sequence tagging, which demonstrate the benefits of our approach. Besides, we show that the shared meta-knowledge learned by our proposed model can be regarded as off-the-shelf knowledge and easily transferred to new tasks. 
 Due to recent technical and scientific advances, we have a wealth of information hidden in unstructured text data such as offline/online narratives, research articles, and clinical reports. To mine these data properly, attributable to their innate ambiguity, a Word Sense Disambiguation  algorithm can avoid numbers of difficulties in Natural Language Processing  pipeline. However, considering a large number of ambiguous words in one language or technical domain, we may encounter limiting constraints for proper deployment of existing WSD models. This paper attempts to address the problem of one-classifier-per-one-word WSD algorithms by proposing a single Bidirectional Long Short-Term Memory  network which by considering senses and context sequences works on all ambiguous words collectively. Evaluated on SensEval-3 benchmark, we show the result of our model is comparable with top-performing WSD algorithms. We also discuss how applying additional modifications alleviates the model fault and the need for more training data.   
 Publications in the life sciences are characterized by a large technical vocabulary, with many lexical and semantic variations for expressing the same concept. Towards addressing the problem of relevance in biomedical literature search, we introduce a deep learning model for the relevance of a document's text to a keyword style query. Limited by a relatively small amount of training data, the model uses pre-trained word embeddings. With these, the model first computes a variable-length Delta matrix between the query and document, representing a difference between the two texts, which is then passed through a deep convolution stage followed by a deep feed-forward network to compute a relevance score. This results in a fast model suitable for use in an online search engine. The model is robust and outperforms comparable state-of-the-art deep learning approaches. 
We introduce distance entropy as a measure of homogeneity in the distribution of path lengths between a given node and its neighbours in a complex network. Distance entropy defines a new centrality measure whose properties are investigated for a variety of synthetic network models. By coupling distance entropy information with closeness centrality, we introduce a network cartography which allows one to reduce the degeneracy of ranking based on closeness alone. We apply this methodology to the empirical multiplex lexical network encoding the linguistic relationships known to English speaking toddlers. We show that the distance entropy cartography better predicts how children learn words compared to closeness centrality. Our results highlight the importance of distance entropy for gaining insights from distance patterns in complex networks.
  % Machine translation has become a popular task in machine learning for its use as a test bed for neural sequence-to-sequence models. Despite abundant recent work, there is a lack of understanding about how these models work. Practitioners have reported several unexplained observations, including the performance degradation of large beams, the under-estimation of rare words and the lack of diversity of generated hypotheses.  % In this work, we demonstrate that many of these findings are related to the inherent uncertainty of the task, due to the existence of multiple valid translations for a single source sentence, and to extrinsic uncertainty due to noisy training data of modern benchmarks. We propose tools and metrics to assess how uncertainty affects the model distribution and search strategies % used to generate translations. We show that while search works remarkably well, NMT models tend to spread too much probability mass in the hypothesis space.  % We propose tools to assess model calibration and show how to easily fix some shortcomings of current models. We release % both code and multiple human reference translations for two popular benchmarks. % Machine translation is a popular test bed for research in neural sequence-to-sequence models but despite much recent research, there is still a lack of understanding of these models. Practitioners report performance degradation with large beams, the under-estimation of rare words and a lack of diversity in the final translations. Our study relates some of these issues to the inherent uncertainty of the task, due to the existence of multiple valid translations for a single source sentence, and to the extrinsic uncertainty caused by noisy training data. We propose tools and metrics to assess how uncertainty in the data is captured by the model distribution and how it affects search strategies that generate translations. Our results show that search works remarkably well but that models tend to spread too much probability mass over the hypothesis space. Next, we propose tools to assess model calibration and show how to easily fix some shortcomings of current models. %We release both code and multiple human reference translations for two popular benchmarks. As part of this study, we release multiple human reference translations for two popular benchmarks.   
 This paper describes XNMT, the eXtensible Neural Machine Translation toolkit. XNMT distinguishes itself from other open-source NMT toolkits by its focus on modular code design, with the purpose of enabling fast iteration in research and replicable, reliable results. In this paper we describe the design of XNMT and its experiment configuration system, and demonstrate its utility on the tasks of machine translation, speech recognition, and multi-tasked machine translation/parsing. XNMT is available open-source at \url{https://github.com/neulab/xnmt}. 
  Automatic deception detection is an important task that has gained momentum in computational linguistics due to its potential applications. In this paper, we propose a simple yet tough to beat multi-modal neural model for deception detection. By combining features from different modalities such as video, audio, and text along with Micro-Expression features, we show that detecting deception in real life videos can be more accurate. Experimental results on a dataset of real-life deception videos show that our model outperforms existing techniques for deception detection with an accuracy of 96.14\% and ROC-AUC of 0.9799.  
 Monolingual data have been demonstrated to be helpful in improving translation quality of both statistical machine translation  systems and neural machine translation  systems, especially in resource-poor or domain adaptation tasks where parallel data are not rich enough. In this paper, we propose a novel approach to better leveraging monolingual data for neural machine translation by jointly learning source-to-target and target-to-source NMT models for a language pair with a joint EM optimization method. The training process starts with two initial NMT models pre-trained on parallel data for each direction, and these two models are iteratively updated by incrementally decreasing translation losses on training data. In each iteration step, both NMT models are first used to translate monolingual data from one language to the other, forming pseudo-training data of the other NMT model. Then two new NMT models are learnt from parallel data together with the pseudo training data.  Both NMT models are expected to be improved and better pseudo-training data can be generated in next step. Experiment results on Chinese-English and English-German translation tasks show that our approach can simultaneously improve translation quality of source-to-target and target-to-source models, significantly outperforming strong baseline systems which are enhanced with monolingual data for model training including back-translation.  
 %            %e2e 瀵板牓鍣哥憰渚婄礉閺勵垯绮堟稊 End-to-end  automatic speech recognition  systems directly map acoustics to words using a unified model. Previous works mostly focus on E2E training a single model which integrates acoustic and language model into a whole. Although E2E training benefits from sequence modeling and simplified decoding pipelines, large amount of transcribed acoustic data is usually required, and traditional acoustic and language modelling techniques cannot be utilized. In this paper, a novel modular training framework of E2E ASR is proposed to separately train neural acoustic and language models during training stage, while still performing end-to-end inference in decoding stage. Here, an acoustics-to-phoneme model  and a phoneme-to-word model  are trained using acoustic data and text data respectively. A phone synchronous decoding  module is inserted between A2P and P2W to reduce sequence lengths without precision loss. Finally, modules are integrated into an acoustics-to-word model  and jointly optimized using acoustic data to retain the advantage of sequence modeling. Experiments on a 300-hour Switchboard task show significant improvement over the direct A2W model. The efficiency in both training and decoding also benefits from the proposed method. % % % % %modular-trained experiments of  both ctc \& S2S 
 %	Why should anyone read the paper? In conventional supervised training, a model is trained to fit all the training examples. However, having a monolithic model may not always be the best strategy, as examples could  vary widely. % In this work, we explore a different learning protocol that treats each example as a  unique , by reducing the original learning problem to  a few-shot meta-learning scenario with the help of a domain-dependent .\footnote{The source code is available at \url{https://github.com/Microsoft/PointerSQL}.}  %	What is this paper about? %	What does distinguish this paper from the past work? %In this work, we demonstrate reducing a regular supervised learning problem to the few-shot meta-learning scenario by effectively creating  with the help of a .  %	What is the 閳ユ笩imple and strong閳 result? When evaluated on the \mbox{WikiSQL} dataset, our approach leads to faster convergence and achieves 1.1\%--5.4\% absolute accuracy gains over the non-meta-learning counterparts.  
 The performance of automatic speech recognition  systems can be significantly compromised by previously unseen conditions, which is typically due to a mismatch between training and testing distributions. In this paper, we address robustness by studying domain invariant features, such that domain information becomes transparent to ASR systems, resolving the mismatch problem.  Specifically, we investigate a recent model, called the Factorized Hierarchical Variational Autoencoder . FHVAEs learn to factorize sequence-level and segment-level attributes into different latent variables without supervision. We argue that the set of latent variables that contain segment-level information is our desired domain invariant feature for ASR. Experiments are conducted on Aurora-4 and CHiME-4, which demonstrate 41\% and 27\% absolute word error rate reductions respectively on mismatched domains. 
 %Learning rich representations from data has received much attention in recent times. %These representations are useful to understand structure in data   In this work we propose a simple and efficient framework for learning sentence representations from unlabelled data. Drawing inspiration from the distributional hypothesis and recent work on learning sentence representations, we reformulate the problem of predicting the context in which a sentence appears as a classification problem. Given a sentence and its context, a classifier distinguishes context sentences from other contrastive sentences based on their vector representations.  %We derive inspiration from the distributional hypothesis and operationalize this idea at the sentence level as a classification problem instead of a generation problem. %This allows us to learn from large scale corpora under feasible training times. %This allows us to efficiently learn different types of encoding functions to learn sentence representations - recurrent, feedforward and recursive, and we show that the model is able to learn high quality representations. This allows us to efficiently learn different types of encoding functions, and we show that the model learns high-quality sentence representations. %  % We demonstrate that our sentence representations outperform state-of-the-art methods on several downstream NLP tasks that involve understanding sentence semantics while requiring an order of magnitude less training time. We demonstrate that our sentence representations outperform state-of-the-art unsupervised and supervised representation learning methods on several downstream NLP tasks that involve understanding sentence semantics while achieving an order of magnitude speedup in training time. %achieve performance comparable to the state of the art at the expense of much lower computational and  and an order of magnitude lower time resources. %[Mention numbers]  %The purpose of this document is to provide both the basic paper template and %submission guidelines. Abstracts should be a single paragraph, between 4--6 sentences long, ideally.  Gross violations will trigger corrections at the camera-ready phase. %All trained encoders will be made available publicly for subsequent work to benefit from. 
 \renewcommand{\thefootnote}{\fnsymbol{footnote}}  %\vspace*{-0.2cm} Reinforcement learning  is a promising approach to solve dialogue policy optimisation. Traditional RL algorithms, however, fail to scale to large domains due to the curse of dimensionality. We propose a novel Dialogue Management architecture, based on Feudal RL, which decomposes the decision into two steps; a first step where a master policy selects a subset of primitive actions, and a second step where a primitive action is chosen from the selected subset. The structural information included in the domain ontology is used to abstract the dialogue state space, taking the decisions at each step using different parts of the abstracted state. This, combined with an information sharing mechanism between slots, increases the scalability to large domains. We show that an implementation of this approach, based on Deep-Q Networks, significantly outperforms previous state of the art in several dialogue domains and environments, without the need of any additional reward signal. %\footnotetext[1]{Work done while at University of Cambridge.} \renewcommand{\thefootnote}{\fnnumerals{footnote}}  %\vspace*{-0.2cm} 
 The task of Fine-grained Entity Type Classification  consists of assigning types from a hierarchy to entity mentions in text. Existing methods rely on distant supervision and are thus susceptible to noisy labels that can be { for the training sentence. Previous methods that attempt to address these issues do so with heuristics or with the help of hand-crafted features.  Instead, we propose an end-to-end solution with a neural network model that uses a variant of cross-entropy loss function to handle { ones. Also, previous work solve FETC a multi-label classification followed by ad-hoc post-processing. In contrast, our solution is more elegant: we use public word embeddings to train a single-label that jointly learns representations for entity mentions and their context. We show experimentally that our approach is robust against noise and consistently outperforms the state-of-the-art on established benchmarks for the task. 
   Recent work has shown that recurrent neural networks  can implicitly capture and exploit hierarchical information when trained to solve common natural language processing tasks  such as language modeling  and neural machine translation .   In contrast, the ability to model structured data with non-recurrent neural networks has received little attention despite their success in many NLP tasks . In this work, we compare the two architectures--- versus ---with respect to their ability to model hierarchical structure and find that recurrency is indeed important for this purpose. The code and data used in our experiments is available at {} 
 Cryptocurrencies   have  been rapidly gaining ground in use, value, and understanding among the public,  bringing  astonishing profits to investors. Unlike other money and banking systems,  most digital tokens do not require central authorities. Being decentralized  poses significant challenges for credit rating.  Most ICOs are currently not subject to government regulations, which makes  a reliable  credit rating system for ICO projects necessary and urgent.   In this paper, we introduce   \footnote{Author Contacts: \\ Jiwei Li : jiwei$\_$li@shannonai.com;  \\ William Yang Wang: william@cs.ucsb.edu \\ Will Monroe:  wmonroe4@stanford.edu\\ Arianna Yuan: xfyuan@stanford.edu }  
 Semantic parsing is the process of mapping a natural language sentence into a formal representation of its meaning. In this work we use the neural network approach to transform natural language sentence into a query to an ontology database in the SPARQL language. This method does not rely on handcraft-rules, high-quality lexicons, manually-built templates or other handmade complex structures. Our approach is based on vector space model and neural networks. The proposed model is based in two learning steps. The first step generates a vector representation for the sentence in natural language and SPARQL query. The second step uses this vector representation as input to a neural network  to generate a model able to encode natural language and decode SPARQL. 
   In this work, we propose a new language modeling paradigm that has the ability to perform both prediction and moderation of information flow at multiple granularities: . These models construct a lattice of possible paths through a sentence and marginalize across this lattice to calculate sequence probabilities or optimize parameters. This approach allows us to seamlessly incorporate linguistic intuitions -- including polysemy and existence of multi-word lexical items -- into our language model. Experiments on multiple language modeling tasks show that English neural lattice language models that utilize polysemous embeddings are able to improve perplexity by 9.95\% relative to a word-level baseline, and that a Chinese model that handles multi-character tokens is able to improve perplexity by 20.94\% relative to a character-level baseline. 
 Relation classification is an important semantic processing task in the field of natural language processing. In this paper, we propose the task of relation classification for Chinese literature text. A new dataset of Chinese literature text is constructed to facilitate the study in this task. We present a novel model, named Structure Regularized Bidirectional Recurrent Convolutional Neural Network , to identify the relation between entities.  %In addition, a new dataset of Chinese literature text for relation classification is developed.  The proposed model learns relation representations along the shortest dependency path  extracted from the structure regularized dependency tree, which has the benefits of reducing the complexity of the whole model. Experimental results show that the proposed method significantly improves the $F_{1}$ score by 10.3, and outperforms the state-of-the-art approaches on Chinese literature text\footnote{The Chinese literature text corpus, which this paper developed and used, is available at \url{https://github.com/lancopku/Chinese-Literature-NER-RE-Dataset}.}.  
 Emotions widely affect human decision-making. This fact is taken into account by affective computing with the goal of tailoring decision support to the emotional states of individuals. However, the accurate recognition of emotions within narrative documents presents a challenging undertaking due to the complexity and ambiguity of language. Performance improvements can be achieved through deep learning; yet, as demonstrated in this paper, the specific nature of this task requires the customization of recurrent neural networks with regard to bidirectional processing, dropout layers as a means of regularization, and weighted loss functions. In addition, we propose , a tailored form of transfer learning for affective computing: here the network is pre-trained for a different task , while the output layer is subsequently tuned to the task of emotion recognition. The resulting performance is evaluated in a holistic setting across 6 benchmark datasets, where we find that both recurrent neural networks and transfer learning consistently outperform traditional machine learning. Altogether, the findings have considerable implications for the use of affective computing.  
 We propose two models for a special case of authorship verification problem. The task is to investigate whether the two documents of a given pair are written by the same author. We consider the authorship verification problem for both small and large scale datasets. The underlying small-scale problem has two main challenges: First, the authors of the documents are unknown to us because no previous writing samples are available. Second, the two documents are short  and may differ considerably in the genre and/or topic. To solve it we propose transformation encoder to transform one document of the pair into the other. This document transformation generates a loss which is used as a recognizable feature to verify if the authors of the pair are identical. For the large scale problem where various authors are engaged and more examples are available with larger length, a parallel recurrent neural network is proposed. It compares the language models of the two documents. We evaluate our methods on various types of datasets including Authorship Identification datasets of PAN competition, Amazon reviews and machine learning articles. Experiments show that both methods achieve stable and competitive performance compared to the baselines. 
 Previous work has shown that it is possible to improve speech recognition by learning acoustic features from paired acoustic-articulatory data, for example by using canonical correlation analysis  or its deep extensions.  One limitation of this prior work is that the learned feature models are difficult to port to new datasets or domains, and articulatory data is not available for most speech corpora. In this work we study the problem of acoustic feature learning in the setting where we have access to an external, domain-mismatched dataset of paired speech and articulatory measurements, either with or without labels.  We develop methods for acoustic feature learning in these settings, based on deep variational CCA and extensions that use both source and target domain data and labels. Using this approach, we improve phonetic recognition accuracies on both TIMIT and Wall Street Journal and analyze a number of design choices.  
 Attention-based neural abstractive summarization systems equipped with copy mechanisms have shown promising results. Despite this success, it has been noticed that such a system generates a summary by mostly, if not entirely, copying over phrases, sentences, and sometimes multiple consecutive sentences from an input paragraph, effectively performing extractive summarization. In this paper, we verify this behavior using the latest neural abstractive summarization system - a pointer-generator network~. We propose a simple baseline method that allows us to control the amount of copying without retraining. Experiments indicate that the method provides a strong baseline for abstractive systems looking to obtain high ROUGE scores while minimizing overlap with the source article, substantially reducing the n-gram overlap with the original article while keeping within 2 points of the original model's ROUGE score. % These findings suggest that success of these models to a large extent depends on their copying behavior, which gets them high ROUGE and METEOR scores.  
 % While Wikipedia exists in $287$ languages, its content is unevenly distributed among them. % In this work, we investigate the generation of open domain Wikipedia summaries in underserved languages using structured data from Wikidata. % To this end, we propose a neural network architecture equipped with copy actions that learns to generate single-sentence and comprehensible textual summaries from Wikidata triples. % We demonstrate the effectiveness of the proposed approach by evaluating it against a set of baselines on two languages of different natures: Arabic, a morphological rich language with a larger vocabulary than English, and Esperanto, a constructed language known for its easy acquisition. % 
This paper describes the methodology followed to build a neural machine translation system in the biomedical domain for the English-Catalan language pair. This task can be considered a low-resourced task from the point of view of the domain and the language pair. To face this task, this paper reports experiments on a cascade pivot strategy through Spanish for the neural machine translation using the English-Spanish SCIELO and Spanish-Catalan El Peri\'odico database. To test the final performance of the system, we have created a new test data set for English-Catalan in the biomedical domain which is freely available on request.   \\ \newline \Keywords{Neural Machine Translation, Biomedical, English-Catalan
 In this paper, we present a kernel-based learning approach for the 2018 Complex Word Identification  Shared Task. Our approach is based on combining multiple low-level features, such as character n-grams, with high-level semantic features that are either automatically learned using word embeddings or extracted from a lexical knowledge base, namely WordNet. After feature extraction, we employ a kernel method for the learning phase. The feature matrix is first transformed into a normalized kernel matrix. For the binary classification task , we employ Support Vector Machines. For the regression task, in which we have to predict the complexity level of a word , we employ $\nu$-Support Vector Regression. We applied our approach only on the three English data sets containing documents from Wikipedia, WikiNews and News domains. Our best result during the competition was the third place on the English Wikipedia data set. However, in this paper, we also report better post-competition results. 
   Modern natural language processing  research requires writing code. Ideally this code would provide a precise definition of the approach, easy repeatability of results, and a basis for extending the research. However, many research codebases bury high-level parameters under implementation details, are challenging to run and debug, and are difficult enough to extend that they are more likely to be rewritten. This paper describes AllenNLP, a library for applying deep learning methods to NLP research, which addresses these issues with easy-to-use command-line tools, declarative configuration-driven experiments, and modular NLP abstractions.  AllenNLP has already increased the rate of research experimentation and the sharing of NLP components at the Allen Institute for Artificial Intelligence, and we are working to have the same impact across the field. 
 Automatic interpretation of the relation between the constituents of a noun compound, e.g. olive oil  and baby oil  is an important task for many NLP applications. Recent approaches are typically based on either noun-compound representations or paraphrases. While the former has initially shown promising results, recent work suggests that the success stems from memorizing single prototypical words for each relation. We explore a neural paraphrasing approach that demonstrates superior performance when such memorization is not possible. 
 Many of the leading approaches in language modeling introduce novel, complex and specialized architectures. We take existing state-of-the-art word level language models based on LSTMs and QRNNs and extend them to both larger vocabularies as well as character-level granularity. When properly tuned, LSTMs and QRNNs achieve state-of-the-art results on character-level  and word-level  datasets, respectively. Results are obtained in only 12 hours  to 2 days  using a single modern GPU. 
 Word Sense Induction  is the ability to automatically induce word senses from corpora. The WSI task was first proposed to overcome the limitations of manually annotated corpus that are required in word sense disambiguation systems. Even though several works have been proposed to induce word senses, existing systems are still very limited in the sense that they make use of structured, domain-specific knowledge sources. In this paper, we devise a method that leverages recent findings in word embeddings research to generate , which are embeddings containing information about the semantical context of a word. In order to induce senses, we modeled the set of ambiguous words as a complex network. In the generated network, two instances  are connected if the respective  are similar. Upon using well-established community detection methods to cluster the obtained , we found that the proposed method yields excellent performance for the WSI task. Our method outperformed competing algorithms and baselines, in a completely unsupervised manner and without the need of any additional structured knowledge source. 
 Text segmentation, the task of dividing a document into contiguous segments based on its semantic structure, is a longstanding challenge in language understanding. Previous work on text segmentation focused on unsupervised methods such as clustering or graph search, due to the paucity in labeled data. In this work, we formulate text segmentation as a supervised learning problem, and present a  large new dataset for text segmentation that is automatically extracted and labeled from Wikipedia. Moreover, we develop a segmentation model based on this dataset and show that it generalizes well to unseen natural text. 
   We present a simple extension of the GloVe representation learning   model that begins with general-purpose representations   and updates them based on data from a specialized domain. We show   that the resulting representations can lead to faster learning and   better results on a variety of tasks. 
 % Recurrent neural networks  based encoder-decoder architectures % have shown strong performance on sentence-level summarization.  % However, if given a long document, their performance degrades considerably due to the monolithic encoder-decoder architecture.  % In this paper, we investigate an alternative approach based on deep communicating agents that can better address the challenges of representing a long document.  %In this paper, we investigate an alternative approach to neural encoder-decoder architectures and introduce deep communicating agents to address the challenges of representing a long document.  We present deep communicating agents in an encoder-decoder architecture to address the challenges of representing a long document for abstractive summarization.  With deep communicating agents, the task of encoding a long text is divided across multiple collaborating agents, each in charge of a subsection of the input text. These encoders are connected to a single decoder, trained end-to-end using reinforcement learning to generate a focused and coherent summary.  Empirical results demonstrate that multiple communicating encoders lead to a higher quality summary compared to several strong baselines, including those based on a single encoder or multiple non-communicating encoders.  
 Text articles with false claims, especially news, have recently become aggravating for the Internet users. These articles are in wide circulation and readers face difficulty discerning fact from fiction. Previous work on credibility assessment has focused on factual analysis and linguistic features. The task's main challenge is the distinction between the features of true and false articles. In this paper, we propose a novel approach called Credibility Outcome  which aims at scoring the credibility of an article in an open domain setting.  CREDO consists of different modules for capturing various features responsible for the credibility of an article. These features includes credibility of the article's source and author, semantic similarity between the article and related credible articles retrieved from a knowledge base, and sentiments conveyed by the article. A neural network architecture learns the contribution of each of these modules to the overall credibility of an article. Experiments on Snopes dataset reveals that CREDO outperforms the state-of-the-art approaches based on linguistic features. 
 Extracting accurate attribute qualities from product titles is a vital component in delivering eCommerce customers with a rewarding online shopping experience via an enriched faceted search.  We demonstrate the potential of Deep Recurrent Networks in this domain, primarily models such as Bidirectional LSTMs and Bidirectional LSTM-CRF with or without an  mechanism. These have improved overall $F_{1}$ scores, as compared to the previous benchmarks  by at least 0.0391, showcasing an overall precision of 97.94\%, recall of 94.12\% and $F_{1}$ score of 0.9599. This has made us achieve a significant coverage of important facets or attributes of products which not only shows the efficacy of deep recurrent models over previous machine learning benchmarks but also greatly enhances the overall customer experience while shopping online.   
 Slot filling is a critical task in natural language understanding  for dialog systems. State-of-the-art approaches treat it as a sequence labeling problem and adopt such models as BiLSTM-CRF. While these models work relatively well on standard  benchmark datasets, they face challenges in the context of E-commerce where the slot labels are more informative and carry richer expressions. In this work, inspired by the unique structure of E-commerce knowledge base, we propose a novel multi-task model with cascade and residual connections, which  jointly learns segment tagging, named entity tagging and slot filling. Experiments show the effectiveness of the proposed cascade and residual structures.  Our model has a 14.6\% advantage in F1 score over the strong baseline methods on a new Chinese E-commerce shopping assistant dataset, while achieving competitive accuracies on a standard dataset.   Furthermore, online test deployed on such dominant E-commerce platform shows 130\% improvement on accuracy of understanding user utterances. Our model has already gone into production in the E-commerce platform. 
 Neural machine translation  has been a new paradigm in machine translation, and the attention mechanism has become the dominant approach with the state-of-the-art records in many language pairs. While there are variants of the attention mechanism, all of them use only temporal attention where one scalar value is assigned to one context vector  corresponding to a source word. In this paper, we propose a fine-grained  attention mechanism where each dimension of a context vector will receive a separate attention score. In experiments with the task of En-De and En-Fi translation, the fine-grained attention method improves the translation quality in terms of BLEU score.  In addition, our alignment analysis reveals how the fine-grained attention mechanism exploits the internal structure of context vectors.  
   Acoustic emotion recognition aims to categorize the affective state of the speaker and is still a difficult task for machine learning models. The difficulties come from the scarcity of training data, general subjectivity in emotion perception resulting in low annotator agreement, and the uncertainty about which features are the most relevant and robust ones for classification. In this paper, we will tackle the latter problem. Inspired by the recent success of transfer learning methods we propose a set of architectures which utilize neural representations inferred by training on large speech databases for the acoustic emotion recognition task. Our experiments on the IEMOCAP dataset show ~10\% relative improvements in the accuracy and F1-score over the baseline recurrent neural network which is trained end-to-end for emotion recognition. 
 The WASSA 2017 EmoInt shared task has the goal to predict emotion intensity values of tweet messages. Given the text of a tweet and its emotion category , the participants were asked to build a system that assigns emotion intensity values. Emotion intensity estimation is a challenging problem given the short length of the tweets, the noisy structure of the text and the lack of annotated data. To solve this problem, we developed an ensemble of two neural models, processing input on the character. and word-level with a lexicon-driven system.  The correlation scores across all four emotions are averaged to determine the bottom-line competition metric, and our system ranks place forth in full intensity range and third in 0.5-1 range of intensity among 23 systems at the time of writing .    
 The alignment of heterogeneous sequential data  is an important and challenging problem.  Standard techniques for this task, including Dynamic Time Warping  and Conditional Random Fields ,  suffer from inherent drawbacks. Mainly, the Markov assumption implies that, given the immediate past, future  alignment decisions are independent of further history. The separation between similarity computation and  alignment decision also prevents end-to-end training.  In this paper, we propose an end-to-end neural architecture where alignment actions are implemented as  moving data between stacks of Long Short-term Memory  blocks. This flexible architecture supports  a large variety of alignment tasks, including one-to-one, one-to-many, skipping unmatched elements, and   non-monotonic alignment.  Extensive experiments on semi-synthetic and real datasets show that our algorithm outperforms  state-of-the-art baselines.    
 For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as LSTMs across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at \url{http://github.com/locuslab/TCN}. 
 In this work, we first analyze the memory behavior in three recurrent neural networks  cells; namely, the simple RNN , the long short-term memory  and the gated recurrent unit , where the memory is defined as a function that maps previous elements in a sequence to the current output. Our study shows that all three of them suffer rapid memory decay. Then, to alleviate this effect, we introduce trainable scaling factors that act like an attention mechanism to adjust memory decay adaptively. The new design is called the extended LSTM .  Finally, to design a system that is robust to previous erroneous predictions, we propose a dependent bidirectional recurrent neural network . Extensive experiments are conducted on different language tasks to demonstrate the superiority of the proposed ELSTM and DBRNN solutions. The ELTSM has achieved up to 30\% increase in the labeled attachment score  as compared to LSTM and GRU in the dependency parsing  task.  Our models also outperform other state-of-the-art models such as bi-attention  and convolutional sequence to sequence   by close to 10\% in the LAS. The code is released as an open source\footnote{ https://github.com/yuanhangsu/ELSTM-DBRNN}.  
 The behavior of users in certain services could be a clue that can be used to infer their preferences and may be used to make recommendations for other services they have never used.  However, the cross-domain relationships between items and user consumption patterns are not simple, especially when there are few or no common users and items across domains.  To address this problem, we propose a content-based cross-domain recommendation method for cold-start users that does not require user- and item- overlap.  We formulate recommendation as extreme multi-class classification where labels  corresponding to the users are predicted.  With this formulation, the problem is reduced to a domain adaptation setting,  in which a classifier trained in the source domain is adapted to the target domain.  For this, we construct a neural network that combines an architecture for domain adaptation, Domain Separation Network, with a denoising autoencoder for item representation.  We assess the performance of our approach in experiments on a pair of data sets collected from movie and news services of Yahoo! JAPAN and show that our approach outperforms several baseline methods including a cross-domain collaborative filtering method. 
 We propose a novel online learning algorithm, called SpCoSLAM 2.0, for spatial concepts and lexical acquisition with high accuracy and scalability. Previously, we proposed SpCoSLAM as an online learning algorithm based on unsupervised Bayesian probabilistic model that integrates multimodal place categorization, lexical acquisition, and SLAM. However, our original algorithm had limited estimation accuracy owing to the influence of the early stages of learning, and increased computational complexity with added training data. Therefore, we introduce techniques such as fixed-lag rejuvenation to reduce the calculation time while maintaining an accuracy higher than that of the original algorithm. The results show that, in terms of estimation accuracy, the proposed algorithm exceeds the original algorithm and is comparable to batch learning. In addition, the calculation time of the proposed algorithm does not depend on the amount of training data and becomes constant for each step of the scalable algorithm. Our approach will contribute to the realization of long-term spatial language interactions between humans and robots. 
 In this paper, we present an improved feedforward sequential memory networks  architecture, namely Deep-FSMN , by introducing skip connections between memory blocks in adjacent layers. These skip connections enable the information flow across different layers and thus alleviate the gradient vanishing problem when building very deep structure. As a result, DFSMN significantly benefits from these skip connections and deep structure. We have compared the performance of DFSMN to BLSTM both with and without lower frame rate  on several large speech recognition tasks, including English and Mandarin. Experimental results shown that DFSMN can consistently outperform BLSTM with dramatic gain, especially trained with LFR using CD-Phone as modeling units. In the 2000 hours Fisher  task, the proposed DFSMN can achieve a word error rate of 9.4\% by purely using the cross-entropy criterion and decoding with a 3-gram language model, which achieves a 1.5\% absolute improvement compared to the BLSTM. In a 20000 hours Mandarin recognition task, the LFR trained DFSMN can achieve more than 20\% relative improvement compared to the LFR trained BLSTM. Moreover, we can easily design the lookahead filter order of the memory blocks in DFSMN to control the latency for real-time applications.  
 % When extracting information from handwritten documents, text transcription and named entity recognition are usually faced as separate tasks. In our work we use a single model trained for handwritten text recognition with several historical document datasets, and fine tune it with a semantically labeled dataset to perform named entity recognition in the same process. On the way we compare the performances for those tasks of models trained with different formats of ground truth data.  % { % When extracting information from handwritten documents, text transcription and named entity recognition are usually faced as separate subsequent tasks. This has the disadvantage that errors in the first module affect heavily the performance of the second module. In this work we propose to do both tasks jointly, using a single neural network with a common architecture used for plain text recognition. % We evaluate the effect on the performance for: different ways of encoding the information, doing or not transfer learning and processing at text line or region level. The results are comparable to the ones obtained on the ICDAR 2017 Information Extraction competition, even though the proposed technique does not use any language modeling. 
 Existing research studies on vision and language grounding for robot navigation focus on improving model-free deep reinforcement learning  models in synthetic environments. However, model-free DRL models do not consider the dynamics in the real-world environments, and they often fail to generalize to new scenes. In this paper, we take a radical approach to bridge the gap between synthetic studies and real-world practices---We propose a novel, planned-ahead hybrid reinforcement learning model that combines model-free and model-based reinforcement learning to solve a real-world vision-language navigation task. Our look-ahead module tightly integrates a look-ahead policy model with an environment model that predicts the next state and the reward.  Experimental results suggest that our proposed method significantly outperforms the baselines and achieves the best on the real-world Room-to-Room dataset. Moreover, our scalable method is more generalizable when transferring to unseen environments.   
 Many vision and language tasks require commonsense reasoning beyond data-driven  %bottom up  image and natural language processing. Here we adopt Visual Question Answering  as an example task, where a system is expected to answer a question in natural language about an image.  Current state-of-the-art systems attempted to solve the task using deep neural architectures and achieved promising performance. However, the resulting systems are generally opaque and they %{Somak: I changed to back to they, as it is the system that "struggles to understand", not the researchers themselves} struggle in understanding questions for which extra knowledge is required. In this paper, we present an explicit reasoning layer on top of a set of penultimate neural network based systems. The reasoning layer enables  reasoning and answering questions where additional knowledge is required, and at the same time provides an interpretable interface to the end users.  %improves performance using reasoning for several question categories.  Specifically, the reasoning layer adopts a Probabilistic Soft Logic  based engine to reason over a basket of inputs: visual relations, the semantic parse of the question, and background ontological knowledge from word2vec and ConceptNet. Experimental analysis of the answers and the key evidential predicates generated on the VQA dataset validate our approach.  
 Developing state-of-the-art approaches for specific tasks is a major driving force in our research community. Depending on the prestige of the task, publishing it can come along with a lot of visibility. The question arises how reliable are our evaluation methodologies to compare approaches?   One common methodology to identify the state-of-the-art is to partition data into a train, a development and a test set. Researchers can train and tune their approach on some part of the dataset and then select the model that worked best on the development set for a final evaluation on unseen test data. Test scores from different approaches are  compared, and performance differences are tested for statistical significance.  In this publication, we show that there is a high risk that a statistical significance in this type of evaluation is not due to a superior learning approach. Instead, there is a high risk that the difference is due to chance. For example for the CoNLL 2003 NER dataset we observed in up to 26\% of the cases type I errors  with a threshold of $p < 0.05$, i.e., falsely concluding a statistically significant difference between two identical approaches.  We prove that this evaluation setup is unsuitable to compare learning approaches. We formalize alternative evaluation setups based on score distributions.  
 We introduce a novel framework for image captioning that can produce natural language explicitly grounded in entities that object detectors find in the image.  Our approach reconciles classical slot filling approaches  with modern neural captioning approaches .  % Our approach first generates a sentence `template' with slot locations explicitly tied to specific image regions. These slots are then filled in by visual concepts identified in the regions by object detectors. The entire architecture  is end-to-end differentiable.  We verify the effectiveness of our proposed model on different image captioning tasks. On standard image captioning and novel object captioning, our model reaches state-of-the-art on both COCO and Flickr30k datasets. We also demonstrate that our model has unique advantages when the train and test distributions of scene compositions -- and hence language priors of associated captions -- are different. Code has been made available at: {https://github.com/jiasenlu/NeuralBabyTalk}. 
 %This paper describes a mapping-based framework that combines generative adversarial nets  and residual networks  to do one-channel speech dereverberation for robust speech recognition. There are four key points in this system. First, log power spectrum  is a better choice than Mel frequency cepstral coefficients  as input feature because LPS contains more information than MFCC. Second, long-short term memory which can convey long-term contextual information is more suitable than convolutional neural networks and feed-forward deep neural networks. Third, GAN combined with ResNet can make dereverberated feature more realistic and benefit both from feature mapping and mask learning. Finally, it's very import to update the parameters of generator and discriminator parameters using the same mini-batch data. By using this proposed framework, 14\%${This paper describes a mapping-based framework that combines generative adversarial nets  and residual networks  to do one-channel speech dereverberation for robust speech recognition. First, different front-end dereverberation structures are compared and long short-term memory  can achieve the best performance among feed-forward deep neural networks , convolution neural networks  and LSTM. Second, further combining ResNet with LSTM can continuously boost the performance. Finally, it's very import to update the parameters of generator and discriminator using the same mini-batch data. In summary, this proposed GAN based architecture outperform the mapping approach and 14\%$\sim$22\% relative reduction of character error rate  is achieved as compared with the DNN dereverberation baseline.} We investigate the use of generative adversarial networks  in speech dereverberation for robust speech recognition. GANs have been recently studied for speech enhancement to remove additive noises, but there still lacks of a work to examine their ability in speech dereverberation and the advantages of using GANs have not been fully established. In this paper, we provide deep investigations in the use of GAN-based dereverberation front-end in ASR. First, we study the effectiveness of different dereverberation networks  and find that LSTM leads to a significant improvement as compared with feed-forward DNN and CNN in our dataset. Second, further adding residual connections in the deep LSTMs can boost the performance as well. Finally, we find that, for the success of GAN, it is important to update the generator and the discriminator using the same mini-batch data during training. Moreover, using reverberant spectrogram as a condition to discriminator, as suggested in previous studies, may degrade the performance. In summary, our GAN-based dereverberation front-end achieves 14\%$\sim$19\% relative CER reduction as compared to the baseline DNN dereverberation network when tested on a strong multi-condition training acoustic model.   
   Various informative factors mixed in speech signals, leading to great difficulty when decoding   any of the factors.   An intuitive idea is to factorize each speech frame into individual informative factors, though it turns out to be   highly difficult. Recently, we found that speaker traits,   which were assumed to be long-term distributional properties, are actually short-time patterns, and   can be learned by a carefully designed deep neural network .   This discovery motivated a   framework that will be presented in this paper.   The proposed framework infers speech factors in a sequential   way, where factors previously inferred are used as conditional variables when inferring other factors.   We will show that this approach can effectively factorize speech signals,   and using these factors, the original speech spectrum can be recovered with a high accuracy. This factorization and   reconstruction approach provides potential values for many speech processing tasks, e.g., speaker recognition and   emotion recognition, as will be demonstrated in the paper.  
 		  		Language can be described as a network of interacting objects with different qualitative properties and complexity. These networks include semantic, syntactic, or phonological levels and have been found to provide a new picture of language complexity and its evolution. A general approach considers language from an information theory perspective that incorporates a speaker, a hearer, and a noisy channel. The later is often encoded in a matrix connecting the signals used for communication with meanings to be found in the real world. Most studies of language evolution deal in a way or another with such theoretical contraption and explore the outcome of diverse forms of selection on the communication matrix that somewhat optimizes communication. This framework naturally introduces networks mediating the communicating agents, but no systematic analysis of the underlying landscape of possible language graphs has been developed. Here we present a detailed analysis of network properties on a generic model of a communication code, which reveals a rather complex and heterogeneous morphospace of language networks. Additionally, we use curated data of English words to locate and evaluate real languages within this language morphospace. Our findings indicate a surprisingly simple structure in human language unless particles are introduced in the vocabulary, with the ability of naming any other concept. These results refine and for the first time complement with empirical data a lasting theoretical tradition around the framework of least effort language.   	
 Deep learning is still not a very common tool in speaker verification field. We study deep convolutional neural network performance % with melfilterbanks energies as an input features  in the text-prompted speaker verification task. %with random digit strings. The prompted passphrase is segmented into word states --- i.e. digits --- to test each digit utterance separately. We train a single high-level feature extractor for all states and use cosine similarity metric for scoring. The key feature of our network is the Max-Feature-Map activation function, which acts as an embedded feature selector. By using multitask learning scheme to train the high-level feature extractor we were able to surpass the classic baseline systems in terms of quality and achieved impressive results for such a novice approach, getting 2.85\% EER on the RSR2015 evaluation set. Fusion of the proposed and the baseline systems improves this result. 
 In this paper, we describe a solution to tackle a common set of challenges in e-commerce, which arise from the fact that new products are continually being added to the catalogue. The challenges involve properly personalising the customer experience, forecasting demand and planning the product range. We argue that the foundational piece to solve all of these problems is having consistent and detailed information about each product, information that is rarely available or consistent given the multitude of suppliers and types of products. We describe in detail the architecture and methodology implemented at ASOS, one of the world's largest fashion e-commerce retailers, to tackle this problem. We then show how this quantitative understanding of the products can be leveraged to improve recommendations in a  hybrid recommender system approach. 
 A lot of the recent success in natural language processing  has been driven by distributed vector representations of words trained on large amounts of text in an unsupervised manner. These representations are typically used as general purpose features for words across a range of NLP problems. However, extending this success to learning representations of sequences of words, such as sentences, remains an open problem. Recent work has explored unsupervised as well as supervised learning techniques with different training objectives to learn general purpose fixed-length sentence representations. In this work, we present a simple, effective multi-task learning framework for sentence representations that combines the inductive biases of diverse training objectives in a single model.  We train this model on several data sources with multiple training objectives on over 100 million sentences. Extensive experiments demonstrate that sharing a single recurrent sentence encoder across weakly related tasks leads to consistent improvements over previous methods. We present substantial improvements in the context of transfer learning and low-resource settings using our learned general-purpose representations.\footnote{Code will be made available at \url{https://github.com/Maluuba/gensen}} 
 User-machine interaction is crucial for information retrieval, especially for spoken content retrieval, because spoken content is difficult to browse, and speech recognition has a high degree of uncertainty. In interactive retrieval, the machine takes different actions to interact with the user to obtain better retrieval results; here it is critical to select the most efficient action.  In previous work, deep Q-learning techniques were proposed to train an interactive retrieval system but rely on a hand-crafted user simulator; building a reliable user simulator is difficult.  In this paper, we further improve the interactive spoken content retrieval  framework by proposing a learnable user simulator which is jointly trained with interactive retrieval system, making the hand-crafted user simulator unnecessary. The experimental results show that the learned simulated users not only achieve larger rewards than the hand-crafted ones but act more like real users.  %User-machine interaction is crucial for information retrieval, especially for spoken content retrieval. For text retrieval, the retrieved results are readable, so the user can easily scan through and select on a list of retrieved items. This is inaccessible for spoken content or multimedia owing to the difficulty of showing the retrieved item on the screen. Besides, due to the high degree of uncertainty for speech recognition, the first-pass retrieved results can be very noisy. One way to overcome such difficulties is through user-machine interaction. The machine takes different actions to interact with the user to obtain better retrieval results. The suitable actions depend on the retrieval system status, for example requesting for extra information from the user, returning a list of topics for user to select, etc. In our previous work, Deep-Q-Learning techniques are proposed to determine the machine actions. In an interactive spoken content retrieval system, it is impossible for machine to interact with real users and the performance of the retrieval system is affected by both user and agent. Hence, building a reliable user simulator is as challenging as building a good dialog manager. In this paper, we futher modify the framework of the spoken content retrieval system and propose a learnable user simulator which can be jointly trained with a dialog manager. Our experiment results show that the proposed method not only leads to significant performance compared with the previous user simulator and dialogur manager but act more similar to human.   
   We present Marian, an efficient and self-contained Neural Machine Translation framework with an integrated automatic differentiation engine based on dynamic computation graphs. Marian is written entirely in C++. We describe the design of the encoder-decoder framework and demonstrate that a research-friendly toolkit can achieve high training and translation speed.     
 This paper describes our NIHRIO system for SemEval-2018 Task 3 ``Irony detection in English tweets.'' We propose to use a simple neural network architecture of Multilayer Perceptron with various types of input features including: lexical, syntactic, semantic and polarity features.  Our system achieves very high performance in both subtasks of binary and multi-class irony detection in tweets. In particular, we rank \underline{third} using the {accuracy} metric and \underline{fifth} using the $F_1$ metric. Our code is available at: \url{https://github.com/NIHRIO/IronyDetectionInTwitter}. 
 In this study, we explore capsule networks with dynamic routing for text classification. We propose three strategies to stabilize the dynamic routing process to alleviate the disturbance of some noise capsules which may contain ``background'' information or have not been successfully trained. A series of experiments are conducted with capsule networks on six text classification benchmarks.  Capsule networks achieve competitive results over the compared baseline methods on 4 out of 6 datasets, which shows the effectiveness of capsule networks for text classification. We additionally show that capsule networks exhibit significant improvement when transfer single-label to multi-label text classification over the competitors. To the best of our knowledge, this is the first work that capsule networks have been empirically investigated for text modeling\footnote{Codes are publicly available at: \url{https://github.com/andyweizhao/capsule_text_classification}.}. 
 In this paper, we propose an attention-based classifier that predicts multiple emotions of a given sentence. Our model imitates human's two-step procedure of sentence understanding and it can effectively represent and classify sentences. With emoji-to-meaning preprocessing and extra lexicon utilization, we further improve the model performance. We train and evaluate our model with data provided by SemEval-2018 task 1-5, each sentence of which has several labels among 11 given emotions. Our model achieves / rank in English/Spanish respectively. % * <kindaichi7207@gmail.com> 2018-02-22T02:00:06.018Z: %  % human mechanism闉氭帾婢曠摽 闋冩﹤濮呴浛 闉氭帾绉數鍕虫緤 multiple emotion 闉 classify 闋冩﹤濮 鏀垫數鍕虫緤闇涜導濮 闈广倠鐛忛灇 闋冨嫵娈ч爟鐘芥懆 / redundant weights 鏀垫數鍕虫絻 鐗嶈導濮呯摯 鑶﹀顫 闉庡⿲娼夋棷? %  % ^ <ad26kt@gmail.com> 2018-02-22T12:13:21.542Z: %  % 闉庤啒濮㈤煾楦界亞闊 闉庡嫵顫 闉庡牔纰冩梼 閵 % % ^. 
 To provide better access of the inventory to buyers and better search engine optimization, e-Commerce websites are automatically generating millions of easily searchable browse pages. A browse page consists of a set of slot name/value pairs within a given category, grouping multiple items which share some characteristics. These browse pages require a title describing the content of the page.  Since the number of browse pages are huge, manual creation of these titles is infeasible. Previous statistical and neural approaches depend heavily on the availability of large amounts of data in a language. In this research, we apply sequence-to-sequence models to generate titles for high- \& low-resourced languages by leveraging transfer learning. We train these models on multi-lingual data, thereby creating one joint model which can generate titles in various different languages. Performance of the title generation system is evaluated on three different languages; English, German, and French, with a particular focus on low-resourced French language.    
 Word embeddings are a popular approach to unsupervised learning of word relationships that are widely used in natural language processing. In this article, we present a new set of embeddings for medical concepts learned using an extremely large collection of multimodal medical data. Leaning on recent theoretical insights, we demonstrate how an insurance claims database of 60 million members, a collection of 20 million clinical notes, and 1.7 million full text biomedical journal articles can be combined to embed concepts into a common space, resulting in the largest ever set of embeddings for 108,477 medical concepts. To evaluate our approach, we present a new benchmark methodology based on statistical power specifically designed to test embeddings of medical concepts. Our approach, called ,  attains state-of-the-art performance relative to previous methods in most instances. Finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the  embeddings.  
 One of the difficulties of neural machine translation  is the recall and appropriate translation of low-frequency words or phrases. In this paper, we propose a simple, fast, and effective method for recalling previously seen translation examples and incorporating them into the NMT decoding process. Specifically, for an input sentence, we use a search engine to retrieve sentence pairs whose source sides are similar with the input sentence, and then collect   $n$-grams that are both in the retrieved target sentences and aligned with words that match in the source sentences, which we call ``translation pieces''. We compute pseudo-probabilities for each retrieved sentence based on similarities between the input sentence and the retrieved source sentences, and use these to weight the retrieved translation pieces. Finally, an existing NMT model is used to translate the input sentence, with an additional bonus given to outputs that contain the collected translation pieces. We show our method improves NMT translation results up to 6 BLEU points on three narrow domain translation tasks where repetitiveness of the target sentences is particularly salient. It also causes little increase in the translation time, and compares favorably to another alternative retrieval-based method with respect to accuracy, speed, and simplicity of implementation. 
 In this paper, we explore the learning of neural network embeddings for natural images and speech waveforms describing the content of those images. These embeddings are learned directly from the waveforms without the use of linguistic transcriptions or conventional speech recognition technology. While prior work has investigated this setting in the monolingual case using English speech data, this work represents the first effort to apply these techniques to languages beyond English. Using  spoken captions collected in English and Hindi, we show that the same model architecture can be successfully applied to both languages. Further, we demonstrate that training a multilingual model simultaneously on both languages offers improved performance over the monolingual models. Finally, we show that these models are capable of performing semantic cross-lingual speech-to-speech retrieval. 
 Hate speech detection is a critical, yet challenging problem in Natural Language Processing . Despite the existence of numerous studies dedicated to the development of NLP hate speech detection approaches, the  %  accuracy is still poor.  The central problem is that social media posts are short and noisy, and most existing hate speech detection solutions take each post as an isolated input instance, which is likely to yield high false positive and negative rates. %  %which might not be the most ideal setting.   In this paper, we radically improve  % %Jing: yes, in the last sentence in the abstract. automated hate speech detection by presenting a novel model that leverages intra-user and inter-user representation learning for robust hate speech detection on Twitter. In addition to the target Tweet, we collect and analyze the user's historical posts to model intra-user Tweet representations. To suppress the noise in a single Tweet, we also model the similar Tweets posted by all other users with reinforced inter-user representation learning techniques. Experimentally, we show that leveraging these two representations can significantly improve the f-score of a strong bidirectional LSTM baseline model by 10.1\%. 
 % abstract In today's scenario, imagining a world without negativity is something very unrealistic, as bad NEWS spreads more virally than good ones. Though it seems impractical in real life, this could be implemented by building a system using Machine Learning and Natural Language Processing techniques in identifying the news datum with negative shade and filter them by taking only the news with positive shade  to the end user. In this work, around two lakhs datum have been trained and tested using a combination of rule-based and data driven approaches. VADER along with a filtration method has been used as an annotating tool followed by statistical Machine Learning approach that have used Document Term Matrix  and Support Vector Machine . Deep Learning algorithms then came into picture to make this system reliable  which finally ended up with Convolutional Neural Network that yielded better results than the other experimented modules. It showed up a training accuracy of 96\%, while a test accuracy of  above 85\% was obtained. 
 We investigate whether and where multi-task learning  can improve performance on  NLP problems related to argumentation mining , in particular argument component identification. Our results  show that MTL  performs particularly well  when little training data is available for the main task, a common scenario in AM.  Our findings challenge previous assumptions that conceptualizations across AM datasets are divergent and that MTL is difficult for semantic or higher-level tasks. %DELETE ME 
 In the medical domain, identifying and expanding abbreviations in clinical texts is a vital task for both better human and machine understanding. It is a challenging task because many abbreviations are ambiguous especially for intensive care medicine texts, in which phrase abbreviations are frequently used. Besides the fact that there is no universal dictionary of clinical abbreviations and no universal rules for abbreviation writing, such texts are difficult to acquire, expensive to annotate and even sometimes, confusing to domain experts. This paper proposes a novel and effective approach -- exploiting task-oriented resources to learn word embeddings for expanding abbreviations in clinical notes. We achieved 82.27\% accuracy, close to expert human performance. 
 This paper describes the participation of Amobee in the shared sentiment analysis task at SemEval 2018. We participated in all the English sub-tasks and the Spanish valence tasks. Our system consists of three parts: training task-specific word embeddings, training a model consisting of gated-recurrent-units  with a convolution neural network  attention mechanism and training stacking-based ensembles for each of the sub-tasks. Our algorithm reached 3rd and 1st places in the valence ordinal classification sub-tasks in English and Spanish, respectively.  
  Clinical Named Entity Recognition  aims to identify and classify clinical terms such as diseases, symptoms, treatments, exams, and body parts in electronic health records, which is a fundamental and crucial task for clinical and translational research. In recent years, deep neural networks have achieved significant success in named entity recognition and many other Natural Language Processing  tasks. Most of these algorithms are trained end to end, and can automatically learn features from large scale labeled datasets. However, these data-driven methods typically lack the capability of processing rare or unseen entities. Previous statistical methods and feature engineering practice have demonstrated that human knowledge can provide valuable information for handling rare and unseen cases. In this paper, we address the problem by incorporating dictionaries into deep neural networks for the Chinese CNER task. Two different architectures that extend the Bi-directional Long Short-Term Memory  neural network and five different feature representation schemes are proposed to handle the task. Computational results on the CCKS-2017 Task 2 benchmark dataset show that the proposed method achieves the highly competitive performance compared with the state-of-the-art deep learning methods.  
 Neural machine translation has achieved levels of fluency and adequacy that would have been surprising a short time ago. Output quality is extremely relevant for industry purposes, however it is equally important to produce results in the shortest time possible, mainly for latency-sensitive applications and to control cloud hosting costs. In this paper we show the effectiveness of translating with 8-bit quantization for models that have been trained using 32-bit floating point values. Results show that 8-bit translation makes a non-negligible impact in terms of speed with no degradation in accuracy and adequacy. 
 Many problems in NLP require aggregating information from multiple mentions of the same entity which may be far apart in the text. Existing Recurrent Neural Network  layers are biased towards short-term dependencies and hence not suited to such tasks. We present a recurrent layer which is instead biased towards coreferent dependencies. The layer uses coreference annotations extracted from an external system to connect entity mentions belonging to the same cluster. Incorporating this layer into a state-of-the-art reading comprehension model improves performance on three datasets -- Wikihop, LAMBADA and the bAbi AI tasks -- with large gains when training data is scarce. 
   Previously, neural methods in grammatical error correction  did not reach state-of-the-art results compared to phrase-based statistical machine translation  baselines. We demonstrate parallels between neural GEC and low-resource neural MT and successfully adapt several methods from low-resource MT to neural GEC.   We further establish guidelines for trustable results in neural GEC and propose a set of model-independent methods for neural GEC that can be easily applied in most GEC settings.   Proposed methods include adding source-side noise, domain-adaptation techniques, a GEC-specific training-objective, transfer learning with monolingual data, and ensembling of independently trained GEC models and language models.   The combined effects of these methods result in better than state-of-the-art neural GEC models that outperform previously best neural GEC systems by more than 10\% M$^2$ on the CoNLL-2014 benchmark and 5.9\% on the JFLEG test set. Non-neural state-of-the-art systems are outperformed by more than 2\% on the CoNLL-2014 benchmark and by 4\% on JFLEG. 
 We present the first real-world application of methods for improving neural machine translation  with human reinforcement, based on explicit and implicit user feedback collected on the eBay e-commerce platform. Previous work has been confined to simulation experiments, whereas in this paper we work with real logged feedback for offline bandit learning of NMT parameters. We conduct a thorough analysis of the available explicit user judgments---five-star ratings of translation quality---and show that they are not reliable enough to yield significant improvements in bandit learning. In contrast, we successfully utilize implicit task-based feedback collected in a cross-lingual search task to improve task-specific and machine translation quality metrics. 
 We investigate the effect of various dependency-based word embeddings on distinguishing between functional and domain similarity, word similarity rankings, and two downstream tasks in English. Variations include word embeddings trained using context windows from Stanford and Universal dependencies at several levels of enhancement . Results are compared to basic linear contexts and evaluated on several datasets. We found that embeddings trained with Universal and Stanford dependency contexts excel at different tasks, and that enhanced dependencies often improve performance. 
 Latent tree learning models learn to parse a sentence without syntactic supervision, and use that parse to build the sentence representation. Existing work on such models has shown that, while they perform well on tasks like sentence classification, they do not learn grammars that conform to any plausible semantic or syntactic formalism . Studying the parsing ability of such models in natural language can be challenging due to the inherent complexities of natural language, like having several valid parses for a single sentence. In this paper we introduce ListOps, a toy dataset created to study the parsing ability of latent tree models. ListOps sequences are in the style of prefix arithmetic. The dataset is designed to have a single correct parsing strategy that a system needs to learn to succeed at the task. We show that the current leading latent tree models are unable to learn to parse and succeed at ListOps. These models achieve accuracies worse than purely sequential RNNs. 
 A prerequisite for training corpus-based machine translation  systems -- either Statistical MT  or Neural MT  -- is the availability of high-quality parallel data. This is arguably more important today than ever before, as NMT has been shown in many studies to outperform SMT, but mostly when large parallel corpora are available; in cases where data is limited, SMT can still outperform  NMT.   Recently researchers have shown that back-translating monolingual data can be used to create synthetic parallel corpora, which in turn can be used in combination with authentic parallel data to train a high-quality NMT system. Given that large collections of new parallel text become available only quite rarely, backtranslation has become the norm when building state-of-the-art NMT systems, especially in resource-poor scenarios.   However, we assert that there are many unknown factors regarding the actual effects of back-translated data on the translation capabilities of an NMT model. Accordingly, in this work we investigate how using back-translated data as a training corpus -- both as a separate standalone dataset as well as combined with human-generated parallel data -- affects the performance of an NMT model. We use incrementally larger amounts of back-translated data to train a range of NMT systems for German-to-English, and analyse the resulting translation performance.  
 The performance of Neural Machine Translation  systems often suffers in low-resource scenarios where sufficiently large-scale parallel corpora cannot be obtained. Pre-trained word embeddings have proven to be invaluable for improving performance in natural language analysis tasks, which often suffer from paucity of data. However, their utility for NMT has not been extensively explored. In this work, we perform five sets of experiments that analyze when we can expect pre-trained word embeddings to help in NMT tasks. We show that such embeddings can be surprisingly effective in some cases -- providing gains of up to 20 BLEU points in the most favorable setting.% \footnote{Scripts/data to replicate experiments are available at \url{https://github.com/neulab/word-embeddings-for-nmt}} 
 The course description provided by instructors is an essential piece of information as it defines what is expected from the instructor and what he/she is going to deliver during a particular course. One of the key components of a course description is the Learning Objectives section. The contents of this section are used by program managers who are tasked to compare and match two different courses during the development of Transfer Agreements between various institutions. This research introduces the development of semantic similarity algorithms to calculate the similarity between two learning objectives of the same domain. We present a novel methodology which deals with the semantic similarity by using a previously established algorithm and integrating it with the domain corpus utilizing domain statistics. The disambiguated domain serves as a supervised learning data for the algorithm. We also introduce Bloom Index to calculate the similarity between action verbs in the Learning Objectives referring to the Bloom's taxonomy. 
 Query auto completion  systems are a standard part of search engines in industry, helping users formulate their query. Such systems update their suggestions after the user types each character, predicting the user's intent using various signals --- one of the most common being popularity. Recently, deep learning approaches have been proposed for the QAC task, to specifically address the main limitation of previous popularity-based methods: the inability to predict unseen queries. In this work we improve previous methods based on neural language modeling, with the goal of building an end-to-end system. We particularly focus on using real-world data by integrating user information for personalized suggestions when possible. We also make use of time information and study how to increase diversity in the suggestions while studying the impact on scalability. Our empirical results demonstrate a marked improvement on two separate datasets over previous best methods in both accuracy and scalability, making a step towards neural query auto-completion in production search engines.  
 Recently, neural machine translation  has emerged as a powerful alternative to conventional statistical approaches. However, its performance drops considerably in the presence of morphologically rich languages . Neural engines usually fail to tackle the large vocabulary and high out-of-vocabulary  word rate of MRLs. Therefore, it is not suitable to exploit existing word-based models to translate this set of languages. In this paper, we propose an extension to the state-of-the-art model of , which works at the character level and boosts the decoder with target-side morphological information. In our architecture, an additional morphology table is plugged into the model. Each time the decoder samples from a target vocabulary, the table sends auxiliary signals from the most relevant affixes in order to enrich the decoder's current state and constrain it to provide better predictions. We evaluated our model to translate English into German, Russian, and Turkish as three MRLs and observed significant improvements. 
     In this work, we present a hybrid learning method for training task-oriented dialogue systems through online user interactions. Popular methods for learning task-oriented dialogues include applying reinforcement learning with user feedback on supervised pre-training models. Efficiency of such learning method may suffer from the mismatch of dialogue state distribution between offline training and online interactive learning stages. To address this challenge, we propose a hybrid imitation and reinforcement learning method, with which a dialogue agent can effectively learn from its interaction with users by learning from human teaching and feedback. We design a neural network based task-oriented dialogue agent that can be optimized end-to-end with the proposed learning method. Experimental results show that our end-to-end dialogue agent can learn effectively from the mistake it makes via imitation learning from user teaching. Applying reinforcement learning with user feedback after the imitation learning stage further improves the agent's capability in successfully completing a task. 
     The end-to-end nature of neural machine translation  removes many ways of manually guiding the translation process that were available in older paradigms.     Recent work, however, has introduced a new capability:  or  decoding, a modification to beam search that forces the inclusion of pre-specified words and phrases in the output.     However, while theoretically sound, existing approaches have computational complexities that are either linear  or exponential  in the number of constraints.     We present an algorithm for lexically constrained decoding with a complexity of  in the number of constraints.     We demonstrate the algorithm's remarkable ability to properly place these constraints, and use it to explore the shaky relationship between model and BLEU scores.     Our implementation is available as part of } 
  We demonstrate that current state-of-the-art approaches to Automated Essay Scoring  are not well-suited to capturing adversarially crafted input of grammatical but incoherent sequences of sentences. We develop a neural model of local coherence that can effectively learn connectedness features between sentences, and propose a framework for integrating and jointly training the local coherence model with a state-of-the-art AES model. We evaluate our approach against a number of baselines and experimentally demonstrate its effectiveness on both the AES task and the task of flagging adversarial input, further contributing to the development of an approach that strengthens the validity of neural essay scoring models.     
 Depression is ranked as the largest contributor to global disability and is also a major reason for suicide. Still, many individuals suffering from forms of depression are not treated for various reasons. Previous studies have shown that depression also has an effect on language usage and that many depressed individuals use social media platforms or the internet in general to get information or discuss their problems. This paper addresses the early detection of depression using machine learning models based on messages on a social platform. In particular, a convolutional neural network based on different word embeddings is evaluated and compared to a classification based on user-level linguistic metadata. An ensemble of both approaches is shown to achieve state-of-the-art results in a current early detection task. Furthermore, the currently popular $ERDE$ score as metric for early detection systems is examined in detail and its drawbacks in the context of shared tasks are illustrated. A slightly modified metric is proposed and compared to the original score. Finally, a new word embedding was trained on a large corpus of the same domain as the described task and is evaluated as well. 
 		 Coherence plays a critical role in producing a high-quality summary from a document. In recent years, neural extractive summarization is becoming increasingly attractive. However, most of them ignore the coherence of summaries when extracting sentences. As an effort towards extracting coherent summaries, we propose a neural coherence model to capture the cross-sentence semantic and syntactic coherence patterns. The proposed neural coherence model obviates the need for feature engineering and can be trained in an end-to-end fashion using unlabeled data. Empirical results show that the proposed neural coherence model can efficiently capture the cross-sentence coherence patterns. Using the combined output of the neural coherence model and ROUGE package as the reward, we design a reinforcement learning method to train a proposed neural extractive summarizer which is named Reinforced Neural Extractive Summarization  model. The RNES model learns to optimize coherence and informative importance of the summary simultaneously. Experimental results show that the proposed RNES outperforms existing baselines and achieves state-of-the-art performance in term of ROUGE on CNN/Daily Mail dataset. The qualitative evaluation indicates that summaries produced by RNES are more coherent and readable. 	
 	Traditional information retrieval  impedes users with information overload from extensive result pages and the need to manually locate the desired information therein. Conversely, question-answering systems change how humans interact with information systems: users can now ask specific questions and obtain a tailored answer -- both conveniently in natural language. Despite obvious benefits, their use is often limited to an academic context, largely because of expensive domain customizations, which means that the performance in domain-specific applications often fails to meet expectations. This paper proposes cost-efficient remedies:  we leverage metadata through a filtering mechanism, which increases the precision of document retrieval, and  we develop a novel fuse-and-oversample approach for transfer learning in order to improve the performance of answer extraction. Here knowledge is inductively transferred from a related, yet different, tasks to the domain-specific application, while accounting for potential differences in the sample sizes across both tasks. The resulting performance is demonstrated with actual use cases from a finance company and the film industry, where fewer than 400 question-answer pairs had to be annotated in order to yield significant performance gains. As a direct implication to management, this presents a promising path to better leveraging of knowledge stored in information systems. 
  We propose a method for learning  representations of texts that code for distinct and complementary aspects, with the aim of affording efficient model transfer and interpretability. To induce disentangled embeddings, we propose an adversarial objective based on the similarity between triplets of documents with respect to specific aspects. Our motivating application is embedding biomedical abstracts describing clinical trials in a manner that disentangles the , , and  in a given trial. We show that our method learns representations that encode these clinically salient aspects, and that these can be effectively used to perform aspect-specific retrieval. We demonstrate that the approach generalizes beyond our motivating application in experiments on two multi-aspect review corpora.  
   Sentence simplification aims to simplify the content and structure of complex sentences, and thus make them easier to interpret for human readers, and easier to process for downstream NLP applications. %Most successful methods for the task have relied on traditional machine translation models. However,    Recent advances in neural machine translation have paved the way for novel approaches to the task. In this paper, we adapt an architecture with augmented memory capacities called Neural Semantic Encoders  for sentence simplification. Our experiments demonstrate the effectiveness of our approach on different simplification datasets, both in terms of automatic evaluation measures and human judgments.    %several neural sequence to sequence models adapted for sentence simplification utilizing different neural network architectures for the encoder and decoder, such as a memory-augmented recurrent neural network, or a tree-structured recursive neural network. Our experiments demonstrate the superiority of our approaches over the state-of-the-art simplification systems on different datasets, both in terms of automatic evaluation measures and human judgments. 
 It is often the case that the best performing language model is an ensemble of a neural language model with n-grams. In this work, we propose a method to improve how these two models are combined. By using a small network which predicts the mixture weight between the two models, we adapt  their relative importance at each time step. Because the gating network is small, it trains quickly on small amounts of held out data, and does not add overhead at scoring time. Our experiments carried out on the One Billion Word benchmark show a significant improvement over the state of the art ensemble without retraining of the basic modules. 
 We present a novel approach to learn representations for sentence-level semantic similarity using conversational data. Our method trains an unsupervised model to predict conversational input-response pairs. The resulting sentence embeddings perform well on the semantic textual similarity  benchmark and SemEval 2017's Community Question Answering  question similarity subtask. Performance is further improved by introducing multitask training combining the conversational input-response prediction task and a natural language inference task. Extensive experiments show the proposed model achieves the best performance among all neural models on the STS benchmark and is competitive with the state-of-the-art feature engineered and mixed systems in both tasks. 
 Machine translation systems achieve near human-level performance on some languages, yet their effectiveness strongly relies on the availability of large amounts of parallel sentences, which hinders their applicability to the majority of language pairs. This work investigates how to learn to translate when having access to only large monolingual corpora in each language. We propose two model variants, a neural and a phrase-based model. Both versions leverage a careful initialization of the parameters, the denoising effect of language models and automatic generation of parallel data by iterative back-translation. These models are significantly better than methods from the literature, while being simpler and having fewer hyper-parameters. On the widely used WMT'14 English-French and WMT'16 German-English benchmarks, our models respectively obtain 28.1 and 25.2 BLEU points without using a single parallel sentence, outperforming the state of the art by more than 11 BLEU points. On low-resource languages like English-Urdu and English-Romanian, our methods achieve even better results than semi-supervised and supervised approaches leveraging the paucity of available bitexts. Our code for NMT and PBSMT is publicly available.\footnote{\url{https://github.com/facebookresearch/UnsupervisedMT}}
 Sentence encoders, which produce sentence embeddings using neural networks, are typically evaluated by how well they transfer to downstream tasks. This includes semantic similarity, an important task in natural language understanding. Although there has been much work dedicated to building sentence encoders, the accompanying transfer learning techniques have received relatively little attention. In this paper, we propose a transfer learning setting specialized for semantic similarity, which we refer to as direct network transfer. Through experiments on several standard text similarity datasets, we show that applying direct network transfer to existing encoders can lead to state-of-the-art performance. Additionally, we compare several approaches to transfer sentence encoders to semantic similarity tasks, showing that the choice of transfer learning setting greatly affects the performance in many cases, and differs by encoder and dataset.  
  A number of differences have emerged between modern and classic approaches to constituency parsing in recent years, with structural components like grammars and feature-rich lexicons becoming less central while recurrent neural network representations rise in popularity. The goal of this work is to analyze the extent to which information provided directly by the model structure in classical systems is still being captured by neural methods. To this end, we propose a high-performance neural model  that is representative of recent work and perform a series of investigative experiments. We find that our model implicitly learns to encode much of the same information that was explicitly provided by grammars and lexicons in the past, indicating that this scaffolding can largely be subsumed by powerful general-purpose neural machinery.  
 Developing agents to engage in complex goal-oriented dialogues is challenging partly because the main learning signals are very sparse in long conversations.  %the dialogue policy needs to explore a large state-action space.  In this paper, we propose a divide-and-conquer approach that discovers and exploits the hidden structure of the task to enable efficient policy learning. First, given successful example dialogues, we propose the   to divide a complex goal-oriented task into a set of simpler subgoals in an  fashion. We then use these subgoals to learn a multi-level policy by hierarchical reinforcement learning. %which consists of  a top-level policy that selects among subgoals, and  a set of low-level policies that select primitive actions to accomplish subgoals.  We demonstrate our method by building a dialogue agent for the composite task of travel planning. Experiments with simulated and real users show that our approach performs competitively against a state-of-the-art method that requires human-defined subgoals.  %an agent trained with automatically discovered subgoals performs competitively against an agent with human-defined subgoals, and significantly outperforms an agent without subgoals.  Moreover, we show that the learned subgoals are often human comprehensible. 
  Learning distributed sentence representations is one of the key challenges in natural language processing. Previous work demonstrated that a recurrent neural network  based sentence encoder trained on a large collection of annotated natural language inference data, is efficient in the transfer learning to facilitate other related tasks. In this paper, we show that joint learning of multiple tasks results in better generalizable sentence representations by conducting extensive experiments and analysis comparing the multi-task and single-task learned sentence encoders. The quantitative analysis using auxiliary tasks show that multi-task learning helps to embed better semantic information in the sentence representations compared to single-task learning. In addition, we compare multi-task sentence encoders with contextualized word representations and show that combining both of them can further boost the performance of transfer learning.  
 Beam search is a widely used approximate search strategy for neural network decoders, and it generally outperforms simple greedy decoding on tasks like machine translation. However, this improvement comes at substantial computational cost. In this paper, we propose a flexible new method that allows us to reap nearly the full benefits of beam search with nearly no additional computational cost. The method revolves around a small neural network actor that is trained to observe and manipulate the hidden state of a previously-trained decoder. To train this actor network, we introduce the use of a pseudo-parallel corpus built using the output of beam search on a base model, ranked by a target quality metric like BLEU. Our method is inspired by earlier work on this problem, but requires no reinforcement learning, and can be trained reliably on a range of models. Experiments on three parallel corpora and three architectures show that the method yields substantial improvements in translation quality and speed over each base system. 
 We present a model for semantic proto-role labeling  using an adapted bidirectional LSTM encoding strategy that we call : predicate-argument structure is represented as pairs of hidden states corresponding to predicate and argument head tokens of the input sequence. We demonstrate:  state-of-the-art results in SPRL, and  that our network naturally shares parameters between  attributes, allowing for learning new attribute types with limited added supervision. 
   The encoder-decoder dialog model is one of the most prominent methods used to build dialog systems in complex domains. Yet it is limited because it cannot output interpretable actions as in traditional systems, which hinders humans from understanding its generation process. We present an unsupervised discrete sentence representation learning method that can integrate with any existing encoder-decoder dialog models for interpretable response generation. Building upon variational autoencoders , we present two novel models, DI-VAE and DI-VST that improve VAEs and can discover interpretable semantics via either auto encoding or context predicting. Our methods have been validated on real-world dialog datasets to discover semantic representations and enhance encoder-decoder models with interpretable generation.\footnote{Data and code are available at \url{https://github.com/snakeztc/NeuralDialog-LAED}.} 
 % Distributed representation plays an important role in deep learning based natural language processing.   However, the representation of a sentence often varies in different tasks, which is usually learned from scratch and suffers from the limited amounts of training data. In this paper, we claim that a good sentence representation should be invariant and can benefit the various subsequent tasks. To achieve this purpose, we propose a new scheme of information sharing for multi-task learning. More specifically, all tasks share the same sentence representation and each task can select the task-specific information from the shared sentence representation with attention mechanism. The query vector of each task's attention could be either static parameters or generated dynamically. We conduct extensive experiments on 16 different text classification tasks, which demonstrate the benefits of our architecture. %Moreover, our method can introduce a different type of task as auxiliary task and the performance can be further boosted. % 
 		We incorporate an explicit neural interlingua into a multilingual encoder-decoder neural machine translation  architecture. We demonstrate that our model learns a language-independent representation by performing direct zero-shot translation , and by using the source sentence embeddings to create an English Yelp review classifier that, through the mediation of the neural interlingua, can also classify French and German reviews. Furthermore, we show that, despite using a smaller number of parameters than a pairwise collection of bilingual NMT models, our approach produces comparable BLEU scores for each language pair in WMT15. 		 	
  % \textcolor{blue}{I would structure the overall paper differently. The way it stands right now is very similar to the other ones we have submitted in this area about DSTC6 results. Here is the general idea: We will focus on a new approach that combines retrieval based method like memnet with existing knowledge about the task. Here is a possible take:\\}  End-to-end dialog systems have become very popular because they hold the promise of learning directly from human to human dialog interaction. Retrieval and Generative methods have been explored in this area with mixed results. A key element that is missing so far, is the incorporation of a-priori knowledge about the task at hand. This knowledge may exist in the form of structured or unstructured information. As a first step towards this direction, we present a novel approach, Knowledge based end-to-end memory networks , which allows special handling of named entities for goal-oriented dialog tasks. We present results on two datasets, DSTC6 challenge dataset and dialog bAbI tasks.   
   Semantic representations have long been argued as potentially useful for enforcing meaning preservation and improving generalization performance of machine translation methods.    In this work, we are the first to incorporate information about predicate-argument structure of source sentences  into neural machine translation. We use Graph Convolutional Networks  to inject a semantic bias into sentence encoders and achieve improvements in BLEU scores over the linguistic-agnostic and syntax-aware versions on the English--German language pair.    
 We propose a graph-based mechanism to extract rich-emotion bearing patterns, which fosters a deeper analysis of online emotional expressions, from a corpus. The patterns are then enriched with word embeddings and evaluated through several emotion recognition tasks. Moreover, we conduct analysis on the emotion-oriented patterns to demonstrate its applicability and to explore its properties. Our experimental results demonstrate that the proposed techniques outperform most state-of-the-art emotion recognition techniques. 
 This article presents the SIRIUS-LTG-UiO system for the SemEval 2018 Task 7 on Semantic Relation Extraction and Classification in Scientific Papers. First we extract the shortest dependency path  between two entities, then we introduce a convolutional neural network  which takes the shortest dependency path embeddings as input and performs relation classification with differing objectives for each subtask of the shared task. This approach achieved overall F1 scores of 76.7 and 83.2 for relation classification on clean and noisy data, respectively. Furthermore, for combined relation extraction and classification on clean data, it obtained F1 scores of 37.4 and 33.6 for each phase.  Our system ranks 3rd in all three sub-tasks of the shared task. 
   Neural encoder-decoder  models  of  machine translation  have  achieved  impressive  results, while learning linguistic knowledge of both the source and target languages in an implicit end-to-end manner. We propose a framework in which our model begins learning syntax and translation interleaved, gradually putting more focus on translation. Using this approach, we achieve considerable improvements in terms of BLEU score on relatively large parallel corpus  and a low-resource  setup. 
 Till now, neural abstractive summarization methods have achieved great success for single document summarization . However, due to the lack of large scale multi-document summaries, such methods can be hardly applied to multi-document summarization . In this paper, we investigate neural abstractive methods for MDS by adapting a state-of-the-art neural abstractive summarization model for SDS. We propose an approach to extend the neural abstractive model trained on large scale SDS data to the MDS task. Our approach only makes use of a small number of multi-document summaries for fine tuning. Experimental results on two benchmark DUC datasets demonstrate that our approach can outperform a variety of baseline neural models. 
 		We study the problem of named entity recognition  from electronic medical records, which is one of the most fundamental and critical problems for medical text mining. Medical records which are written by clinicians from different specialties usually contain quite different terminologies and writing styles. The difference of specialties and the cost of human annotation makes it particularly difficult to train a universal medical NER system. In this paper, we propose a label-aware double transfer learning framework  for cross-specialty NER, so that a medical NER system designed for one specialty could be conveniently applied to another one with minimal annotation efforts. The transferability is guaranteed by two components:  we propose label-aware MMD for feature representation transfer, and  we perform parameter transfer with a theoretical upper bound which is also label aware. We conduct extensive experiments on 12 cross-specialty NER tasks. The experimental results demonstrate that La-DTL provides consistent accuracy improvement over strong baselines. Besides, the promising experimental results on non-medical NER scenarios indicate that La-DTL is potential to be seamlessly adapted to a wide range of NER tasks. 	
 Monitoring the biomedical literature for cases of Adverse Drug Reactions   is a critically important and time consuming task in pharmacovigilance. The  development of computer assisted approaches to aid this process in different  forms has been the subject of many recent works.  One particular area that has shown promise is the use of Deep Neural Networks,  in particular, Convolutional Neural Networks , for the detection of ADR  relevant sentences. Using token-level convolutions and general purpose word  embeddings, this architecture has shown good performance relative to more  traditional models as well as Long Short Term Memory  models.  In this work, we evaluate and compare two different CNN architectures using the  ADE corpus. In addition, we show that by de-duplicating the ADR relevant  sentences, we can greatly reduce overoptimism in the classification results.  Finally, we evaluate the use of word embeddings specifically developed for  biomedical text and show that they lead to a better performance in this task. 
 Though impressive results have been achieved in visual captioning, the task of generating abstract stories from photo streams is still a little-tapped problem. Different from captions, stories have more expressive language styles and contain many imaginary concepts that do not appear in the images. Thus it poses challenges to behavioral cloning algorithms. Furthermore, due to the limitations of automatic metrics on evaluating story quality, reinforcement learning methods with hand-crafted rewards also face difficulties in gaining an overall performance boost. Therefore, we propose an Adversarial REward Learning  framework to learn an implicit reward function from human demonstrations, and then optimize policy search with the learned reward function. Though automatic evaluation indicates slight performance boost over state-of-the-art  methods in cloning expert behaviors, human evaluation shows that our approach achieves significant improvement in generating more human-like stories than SOTA systems.\footnote{Code is released at } 
 Novel neural models have been proposed in recent years for learning under domain shift. Most models, however, only evaluate on a single task, on proprietary datasets, or compare to weak baselines, which makes comparison of models difficult.  In this paper, we re-evaluate classic general-purpose bootstrapping approaches in the context of neural networks under domain shifts vs. recent neural approaches and propose a novel  method that reduces the time and space complexity of classic tri-training. Extensive experiments on two benchmarks  are negative: while our novel method establishes a new state-of-the-art for sentiment analysis, it does not fare consistently the best. More importantly, we arrive at the somewhat surprising conclusion that classic tri-training, with some additions, outperforms the state of the art. We conclude that classic approaches constitute an important and strong baseline. 
 Many Natural Language Processing  tasks depend on using Named Entities  that are contained in texts and in external knowledge sources.  While this is easy for humans, the present neural methods that rely on learned word embeddings may not perform well for these NLP tasks, especially in the presence of Out-Of-Vocabulary  or rare NEs. In this paper, we propose a  %new neural method solution for this problem, and present empirical evaluations on: a) a structured Question-Answering task, b) three related Goal-Oriented dialog tasks, and c) a Reading-Comprehension task\footnote{We create extended versions of dialog bAbI tasks 1,2 and 4 and OOV versions of the CBT test set - \url{https://github.com/IBM/ne-table-datasets/}}, which show that the proposed method can be effective in dealing with both in-vocabulary and OOV NEs.  
  Current end-to-end machine reading and question answering  models are primarily based on recurrent neural networks  with attention. Despite their success, these models are often slow for both training and inference due to the sequential nature of RNNs. We propose a new Q\&A architecture called QANet, which does not require recurrent networks:  Its encoder consists exclusively of convolution and self-attention, where convolution models local interactions and self-attention models global interactions. On the SQuAD dataset, our model is 3x to 13x faster in training and 4x to 9x faster in inference, while achieving equivalent accuracy to recurrent models. The speed-up gain allows us to train the model with much more data. We hence  combine our model with data generated by backtranslation from a neural machine translation model.   On the SQuAD dataset, our single model, trained with augmented data, achieves 84.6 F1 score\footnote{While the major results presented here are those obtained in Oct 2017, our latest scores  on SQuAD leaderboard is EM/F1=82.2/88.6 for single model and EM/F1=83.9/89.7 for ensemble, both ranking No.1. Notably, the EM of our ensemble is better than the human performance .} on the test set, which is significantly better than the best published F1 score of 81.8.   
 Interacting with relational databases through natural language helps users of any background easily query and analyze a vast amount of data. This requires a system that understands users' questions and converts them to SQL queries automatically. In this paper we present a novel approach, TypeSQL, which views this problem as a slot filling task. Additionally, TypeSQL utilizes type information to better understand rare entities and numbers in natural language questions. We test this idea on the WikiSQL dataset and outperform the prior state-of-the-art by 5.5\% in much less time. We also show that accessing the content of databases can significantly improve the performance when users' queries are not well-formed. TypeSQL gets 82.6\% accuracy, a 17.5\% absolute improvement compared to the previous content-sensitive model. 
 We propose a process for investigating the extent to which sentence representations arising from neural machine translation  systems encode distinct semantic phenomena. %, by using  We use  these representations as features to train a natural language inference   classifier based on datasets recast from existing semantic annotations. In applying this process to a representative NMT system, we find its encoder appears most suited to supporting inferences at the syntax-semantics interface, as compared to %, e.g.,  anaphora resolution requiring world-knowledge. We conclude with a discussion on the merits and potential deficiencies of the existing process, and how it may be improved and extended as a broader framework for evaluating semantic coverage.\footnote{Code %and data  developed  and data used are %is  available at \url{https://github.com/boknilev/nmt-repr-analysis}.} 
 %In the past year, new sequence-to-sequence models based on convolutional %and purely attentional architectures have been shown to outperform %classical recurrent neural network based machine translation  %models. Each new architecture has distinct modeling and computational %properties, and is accompanied by a set of training techniques that are %crucial to its performance. In this paper, we tease apart training and %architectural choices of the recent models in two ways. First, we identify %several key training techniques. By applying them to RNMT, we introduce a new %recurrent model, RNMT+, that beats current state-of-the-art results on %the common WMT'14 English-to-French and WMT'14 English-to-German %benchmarks. Second, we analyze the properties of each architectural %family, and devise new hybrid models designed to combine their %strengths. This allows us to establish new state-of-the-art results, %outperforming previous best models by one BLEU point on both benchmark %datasets.  % Recent years have witnessed rapid advances in the domain of % sequence-to-sequence  modeling for Machine Translation . % The classic RNN-based approaches for MT were first out-performed by the % convolutional seq2seq model, which was again out-performed by the more % recent Transformer model.  Each new model family comes with its own % modeling and computational advantages, which are often accompanied by a % set of architectural and training techniques that are also crucial to % the model performance.  Motivated by the quest for better and more % expressive model architectures and most efficient way of training them, % we try to disentangle the performance improvement that is due to the % inherent model architecture change from that due to the accompanying % techniques. % %In this paper, we study the effect of % %several training techniques that have been used in the Transformer. % %these new techniques to RNN-based NMT models to revive them. % We apply those new architectural and training techniques to the RNN-based % models and come up with the RNMT+ model, which improves over the current % state-of-the-art approaches on both WMT'14 English-to-French and WMT'14 % English-to-German tasks. Through analyzing the properties of each model % family, we further introduce a few hybrid seq2seq model architectures % that try to combine the strength of multiple architectural families. % Our hybrid models establish new state-of-the-art results and outperform % previous best results by 1 BLEU point on both benchmark datasets.  The past year has witnessed rapid advances in sequence-to-sequence  modeling for Machine Translation . The classic RNN-based approaches to MT were first out-performed by the convolutional seq2seq model, which was then out-performed by the more recent Transformer model. Each of these new approaches consists of a fundamental architecture accompanied by a set of modeling and training techniques that are in principle applicable to other seq2seq architectures. In this paper, we tease apart the new architectures and their accompanying techniques in two ways. First, we identify several key modeling and training techniques, and apply them to the RNN architecture, yielding a new RNMT+ model that outperforms all of the three fundamental architectures on the benchmark WMT'14 English$\rightarrow$French and English$\rightarrow$German tasks. Second, we analyze the properties of each fundamental seq2seq architecture and devise new hybrid architectures intended to combine their strengths. Our hybrid models obtain further improvements, outperforming the RNMT+ model on both benchmark datasets.  
  %The purpose of this document is to provide both the basic paper template and %submission guidelines. Abstracts should be a single paragraph, between 4--6 sentences long, ideally.  Gross violations will trigger corrections at the camera-ready phase.   This paper aims at improving how machines can answer questions directly from text, with the focus of having models that can answer correctly multiple types of questions and from various types of texts, documents or even from large collections of them. % To that end, we introduce the \us model that uses a new way to relate a question to a textual context by weaving layers of recurrent networks, with the goal of making as few assumptions as possible as to how the information from both question and context should be combined to form the answer.  % We show empirically on six datasets that \us performs well in multiple conditions. For instance, it produces solid results on the very popular SQuAD dataset , solves almost all bAbI tasks  and greatly outperforms state-of-the-art methods for open domain question answering from text .    
   Subword units are an effective way to alleviate the open vocabulary   problems in neural machine translation . While sentences are   usually converted into unique subword sequences, subword segmentation   is potentially ambiguous and multiple segmentations are possible even   with the same vocabulary. The question addressed in this paper is   whether it is possible to harness the segmentation ambiguity as a   noise to improve the robustness of NMT. We present a simple   regularization method, subword regularization, which trains the model   with multiple subword segmentations probabilistically sampled during   training.  In addition, for better subword sampling, we propose a new   subword segmentation algorithm based on a unigram language model.  We   experiment with multiple corpora and report consistent improvements   especially on low resource and out-of-domain settings.  
  While neural networks have been shown to achieve impressive results for sentence-level sentiment analysis, targeted aspect-based sentiment analysis  --- extraction of fine-grained opinion polarity w.r.t.\ a pre-defined set of aspects --- remains a difficult task. Motivated by recent advances in memory-augmented models for machine reading, we propose a novel architecture, utilising external ``memory chains'' with a delayed memory update mechanism to track entities. On a TABSA task, the proposed model demonstrates substantial improvements over state-of-the-art approaches, including those using external knowledge bases.\footnote{Code available at \url{https://github.com/liufly/delayed-memory-update-entnet}.}  
 Text generation is a crucial task in NLP. Recently, several adversarial generative models have been proposed to improve the exposure bias problem in text generation. Though these models gain great success, they still suffer from the problems of reward sparsity and mode collapse. In order to address these two problems, in this paper, we employ inverse reinforcement learning  for text generation. Specifically, the IRL framework learns a reward function on training data, and then an optimal policy to maximum the expected total reward. Similar to the adversarial models, the reward and policy function in IRL are optimized alternately. Our method has two advantages:   the reward function can produce more dense reward signals.  the generation policy, trained by ``entropy regularized'' policy gradient,  encourages to generate more diversified texts. Experiment results demonstrate that our proposed method can generate higher quality texts than the previous methods. 
 	% This is the abstract 	%  How to build representation of speech sounds which is robust to within- and between-talker variation in a weakly-supervised or unsupervised setting?  	Recent studies have investigated siamese network architectures for learning invariant speech representations using same-different side information at the word level. Here we investigate systematically an often ignored component of siamese networks: the sampling procedure . We show that sampling strategies taking into account Zipf's Law, the distribution of speakers and the proportions of same and different pairs of words significantly impact the performance of the network. In particular, we show that word frequency compression improves learning across a large range of variations in number of training pairs. This effect does not apply to the same extent to the fully unsupervised setting, where the pairs of same-different words are obtained by spoken term discovery. We apply these results to pairs of words discovered using an unsupervised algorithm and show an improvement on state-of-the-art in unsupervised representation learning using siamese networks. 
  The ability to extract insights from new data sets is critical for decision making. Visual interactive tools play an important role in data exploration since they provide non-technical users with an effective way to visually compose queries and comprehend the results. Natural language has recently gained traction as an alternative query interface to databases with the potential to enable non-expert users to formulate complex questions and information needs efficiently and effectively. However, understanding natural language questions and translating them accurately to SQL is a challenging task, and thus Natural Language Interfaces for Databases  have not yet made their way into practical tools and commercial products.  In this paper, we present , a novel data exploration tool with a natural language interface.  leverages recent advances in deep models to make query understanding more robust in the following ways: First,  uses a deep model to translate natural language statements to SQL, making the translation process more robust to paraphrasing and other linguistic variations. Second, to support the users in phrasing questions without knowing the database schema and the query features,  provides a learned auto-completion model that suggests partial query extensions to users during query formulation and thus helps to write complex queries. 
 The celebrated  technique and its numerous variants achieve excellent performance on many tasks. However, many machine learning tasks have inputs naturally represented as graphs; existing Seq2Seq models face a significant challenge in achieving accurate conversion from graph form to the appropriate sequence. To address this challenge, we introduce a novel general end-to-end graph-to-sequence neural encoder-decoder model that maps an input graph to a sequence of vectors and uses an attention-based LSTM method to decode the target sequence from these vectors. Our method first generates the node and graph embeddings using an improved graph-based neural network with a novel aggregation strategy to incorporate edge direction information in the node embeddings. We further introduce an attention mechanism that aligns node embeddings and the decoding sequence to better cope with large graphs. Experimental results on bAbI, Shortest Path, and Natural Language Generation tasks demonstrate that our model achieves state-of-the-art performance and significantly outperforms existing graph neural networks, Seq2Seq, and Tree2Seq models; using the proposed bi-directional node embedding aggregation strategy, the model can converge rapidly to the optimal performance. 
    The ABSTRACT is to be in fully-justified italicized text, at the top    of the left-hand column, below the author and affiliation    information. Use the word ``Abstract'' as the title, in 12-point    Times, boldface type, centered relative to the column, initially    capitalized. The abstract is to be in 10-point, single-spaced type.    Leave two blank lines after the Abstract, then begin the main text.    Look at previous CVPR abstracts to get a feel for style and length. 
  Speech emotion recognition  is an important aspect of effective human-robot collaboration and received a lot of attention from the research community. For example, many neural network-based architectures were proposed recently and pushed the performance to a new level. However, the applicability of such neural SER models trained only on in-domain data to noisy conditions is currently under-researched. In this work, we evaluate the robustness of state-of-the-art neural acoustic emotion recognition models in human-robot interaction scenarios. We hypothesize that a robot's ego noise, room conditions, and various acoustic events that can occur in a home environment can significantly affect the performance of a model. We conduct several experiments on the iCub robot platform and propose several novel ways to reduce the gap between the model's performance during training and testing in real-world conditions. Furthermore, we observe large improvements in the model performance on the robot and demonstrate the necessity of introducing several data augmentation techniques like overlaying background noise and loudness variations to improve the robustness of the neural approaches.  
 Generative Adversarial Networks  have been promising in the field of image generation, however, they have been hard to train for language generation. GANs were originally designed to output differentiable values, so discrete language generation is challenging for them which causes high levels of instability in training GANs. Consequently, past work has resorted to pre-training with maximum-likelihood or training GANs without pretraining with a WGAN objective with a gradient penalty. In this study, we present a comparison of those approaches. Furthermore, we present the results of some experiments that indicate better training and convergence of Wasserstein GANs  when a weaker regularization term is enforcing the Lipschitz constraint.  
 \small\baselineskip=9pt  Optimization of patient throughput and wait time in emergency departments  is an important task for hospital systems. For that reason, Emergency Severity Index  system for patient triage was introduced to help guide manual estimation of acuity levels, which is used by nurses to rank the patients and organize hospital resources.  However, despite improvements that it brought to managing medical resources, such triage system greatly depends on nurse's subjective judgment and is thus prone to human errors.  Here, we  propose a novel deep model based on the word attention mechanism designed for predicting  a number of resources an ED patient would need. Our approach incorporates routinely available continuous and nominal  data with medical text  data, including patient's chief complaint, past medical history, medication list, and nurse assessment collected for     338,500 ED visits over three years in a large urban hospital. Using both structured and unstructured data, the proposed approach achieves the AUC of $\sim 88\%$ for the task of identifying resource intensive patients , and the accuracy of $\sim 44\%$ for predicting exact category of number of resources , giving an estimated lift over nurses' performance by 16\% in accuracy.  Furthermore, the attention mechanism of the proposed model provides interpretability by assigning attention scores for nurses' notes which is crucial for decision making and implementation of such approaches in the real systems working on human health. 
 The topic modeling discovers the latent topic probability of the given text documents. To generate the more meaningful topic that better represents the given document, we proposed a new feature extraction technique which can be used in the data preprocessing stage. The method consists of three steps. First, it generates the word/word-pair from every single document. Second, it applies a two-way TF-IDF algorithm to word/word-pair for semantic filtering. Third, it uses the K-means algorithm to merge the word pairs that have the similar semantic meaning.  Experiments are carried out on the Open Movie Database , Reuters Dataset and 20NewsGroup Dataset. The mean Average Precision score is used as the evaluation metric. Comparing our results with other  state-of-the-art topic models, such as Latent Dirichlet allocation and traditional Restricted Boltzmann Machines. Our proposed data  preprocessing can improve the generated topic accuracy by up to 12.99\%. 
 Existing applications include a huge amount of knowledge that is out of reach for deep neural networks. This paper presents a novel approach for integrating calls to existing applications into deep learning architectures. Using this approach, we estimate each application's functionality with an estimator, which is implemented as a deep neural network . The estimator is then embedded into a base network that we direct into complying with the application's interface during an end-to-end optimization process. At inference time, we replace each estimator with its existing application counterpart and let the base network solve the task by interacting with the existing application. Using this \textit{閳ユエstimate and Replace閳ユ method, we were able to train a DNN end-to-end with less data and outperformed a matching DNN that did not interact with the external application. 
 We investigate deep neural network performance in the text-independent speaker recognition task. % By using a statistics pooling layer we were able to train a deep speaker embedding extractor, which takes variable-length audio signals as input. ---- 鍗忚鑺 钖 钖偑瑜曢偑 锜归偑瑜嬭阿瑜嶈皭閭, 钖 瑜嬭鑺噲瑜 瑜嶉攲鑺睉鎳堣柂閭瑜 鑺鍐欐璋㈣钖灞 閿岃姊板啓璋㈣姱鍗告钖噲姊板睉 鑳 abstract. 琚樿鍐欒瑜 鑳佽姱閿岃鑺瑜 閿岃姱 钖姱鑳佹噲锜硅柂姊  We demonstrate that using angular softmax activation   at the last classification layer of a classification neural network instead of   a simple softmax activation allows to train a more generalized discriminative   speaker embedding extractor.   Cosine similarity is an effective metric for speaker verification in this embedding space.  We also address the problem of choosing an architecture for the extractor.  We found that deep networks with residual frame level connections  outperform  wide   but  relatively  shallow  architectures.  This paper also proposes several improvements for  previous DNN-based extractor systems to increase the speaker recognition accuracy. We show that the discriminatively trained similarity metric learning approach  outperforms the standard LDA-PLDA method as an embedding backend.  The results obtained on Speakers in the Wild and NIST SRE 2016 evaluation sets demonstrate robustness of the proposed systems when dealing with close to real-life conditions.   % We propose a deep neural network for extracting embeddings from variable-length utterances % to approach the speaker recognition problem. % Based on the x-vector extractor architecture, % our model is capable of capturing and better discriminating deep speaker features. % We find that deep architecture with residual connections % outperform wide but relatively shallow networks % thanks to selective layer-level context aggregation. % Embeddings are classified with PLDA and adaptive score s-normalization is used to % compensate for varying recording settings. % With a proper choice of the loss function, % our system learns to discriminate speaker features, achieving \% EER and minDCF on NIST 2016 Cantonese and SITW corpora. 
 Language recognition system is typically trained directly to optimize classification error on the target language labels, without using the external, or meta-information in the estimation of the model parameters. However labels are not independent of each other, there is a dependency enforced by, for example, the language family, which affects negatively on classification. The other external information sources  can also decrease classification accuracy. In this paper, we attempt to solve these issues by constructing a deep hierarchical neural network, where different levels of meta-information are encapsulated by attentive prediction units and also embedded into the training progress. The proposed method learns auxiliary tasks to obtain robust internal representation and to construct a variant of attentive units within the hierarchical model. The final result is the structural prediction of the target language and a closely related language family. The algorithm reflects a ``staircase'' way of learning in both its architecture and training, advancing from the fundamental audio encoding to the language family level and finally to the target language level. This process not only improves generalization but also tackles the issues of imbalanced class priors and channel variability in the deep neural network model. Our experimental findings show that the proposed architecture outperforms the state-of-the-art i-vector approaches on both small and big language corpora by a significant margin. 
                  Designing powerful tools  that support cooking activities has rapidly gained popularity due to the massive amounts of available data, as well as recent advances in machine learning that are capable of analyzing them. % that provide new, powerful tools to analyze them.         In this paper, we propose a cross-modal retrieval model aligning visual and textual data  in a shared representation space.         We describe an effective learning scheme, capable of tackling large-scale problems, and validate it on the Recipe1M dataset containing nearly 1 million picture-recipe pairs.         We show the effectiveness of our approach regarding previous state-of-the-art models and present qualitative results over computational cooking use cases.              
 Although voice conversion  algorithms have achieved remarkable success along with the development of machine learning, superior performance is still difficult to achieve when using nonparallel data. In this paper, we propose using a cycle-consistent adversarial network  for nonparallel data-based VC training. A CycleGAN is a generative adversarial network  originally developed for unpaired image-to-image translation. A subjective evaluation of inter-gender conversion demonstrated that the proposed method significantly outperformed a method based on the Merlin open source neural network speech synthesis system  and a GAN-based parallel VC system. This is the first research to show that the performance of a nonparallel VC method can exceed that of state-of-the-art parallel VC methods. 
 %Purely unsupervised domain adaptation aims at adapting a well-trained %source-domain acousitic model to the data from target domain without making %use of any labels or decoded results of the adaptation data. An effective %way to achieve this is the teacher-student  learning , %in which the senone posteriors generated by the source-domain teacher %acoustic model are used as the labels to train the target-domain student %model.   %, in which a student model %is trained with the soft labels generated by a teacher model, %of which the goal is to adapt a well-trained source-domain acousitic model %to the data from target domain with no exposure to any labels or decoded %results of the adaptation data.   The teacher-student  learning has been shown effective in unsupervised domain adaptation . It is a form of transfer learning, not in terms of the transfer of recognition decisions, but the knowledge of posteriori probabilities in the source domain as evaluated by the teacher model. It learns to handle the speaker and environment variability inherent in and restricted to the speech signal in the target domain without proactively addressing the robustness to other likely conditions. Performance degradation may thus ensue. In this work, we advance T/S learning by proposing adversarial T/S learning to explicitly achieve condition-robust unsupervised domain adaptation. In this method, a student acoustic model and a condition classifier are jointly optimized to minimize the Kullback-Leibler divergence between the output distributions of the teacher and student models, and simultaneously, to min-maximize the condition classification loss. A condition-invariant deep feature is learned in the adapted student model through this procedure. We further propose multi-factorial adversarial T/S learning which suppresses condition variabilities caused by multiple factors simultaneously. Evaluated with the noisy CHiME-3 test set, the proposed methods achieve relative word error rate improvements of 44.60\% and 5.38\%, respectively, over a clean source model and a strong T/S learning baseline model.  %With only %the unlabeled parallel adaptation data as the input, the proposed methods %achieve purely unsupervised adaptation with no exposure to any %transcription or decoded results of the adaptation data.  % The senone posteriors generated % by a source-domain teacher model are used as the labels to compute the % senone classification loss.    %With adversarial T/S learning, we perform adversarial %training of the condition classifier DNN M c and the feature %extractor LSTM M f while simultaneously minimizing the %KL divergence of the output senone posteriors between the %student and teacher LSTM acoustic models  % consisting of pairs of samples from the source and % target domains.  % Multiple dimensions of domain-invariance can be % enhanced simultaneously through this framework.   %Moreover, the %adversarial training of the acoustic model with gradient reversal layer %method  is able to achieve domain adaptation without  %any parellel data and without the transcription of the %adaptation data. In this work, we propose the adversarial teacher-student %training of the long short-term memory acoustic model  % %can also learn an intermediate %deep representation that is both senone-discriminative and %domain-invariant.   
 % Speaker-adaptive training is an effective approach to suppress the inherent % inter-speaker variability within each speech unit of the acoustic model. In this work, we % achiev  We propose a novel adversarial multi-task learning scheme, aiming at actively curtailing the inter-talker feature variability while maximizing its senone discriminability so as to enhance the performance of a deep neural network  based ASR system. We call the scheme speaker-invariant training . In SIT, a DNN acoustic model and a speaker classifier network are jointly optimized to minimize the senone  classification loss, and simultaneously mini-maximize the speaker classification loss. A speaker-invariant and senone-discriminative deep feature is learned through this adversarial multi-task learning. With SIT, a canonical DNN acoustic model with significantly reduced variance in its output probabilities is learned with no explicit speaker-independent  transformations or speaker-specific representations used in training or testing. Evaluated on the CHiME-3 dataset, the SIT achieves 4.99\% relative word error rate  improvement over the conventional SI acoustic model. With additional unsupervised speaker adaptation, the speaker-adapted  SIT model achieves 4.86\% relative WER gain over the SA SI acoustic model.  % signal in addition to the % phonetically relevant variantion sources.  
 This paper proposes a method for generating speech from filterbank mel frequency cepstral coefficients , which are widely used in speech applications, such as ASR, but are generally considered unusable for speech synthesis.  First, we predict fundamental frequency and voicing information from MFCCs with an autoregressive recurrent neural net. Second, the spectral envelope information contained in MFCCs is converted to all-pole filters, and a pitch-synchronous excitation model matched to these filters is trained. Finally, we introduce a generative adversarial network -based noise model to add a realistic high-frequency stochastic component to the modeled excitation signal. The results show that high quality speech reconstruction can be obtained, given only MFCC information at test time.  
 %The limitations of the conventional acoustic feature representations such as the lossy nature of the amplitude spectrum or the minimum phase approximation, can be overcome by using more complex algorithms or by switching to machine learning-based data agnostic approaches to acoustic modeling. In this paper, we propose a common framework in which we can fairly compare different acoustic modeling techniques and different vocoding techniques so as to properly measure the differences between the new machine learning-based techniques such as generative adversarial network-based postfiltering or Wavenet and the conventional vocoding approaches or different modeling techniques such as auto-regressive modeling. This was evaluated by means of a large scale crowdsourced evaluation, which showed how auto-regressive modeling can outperform generative adversarial networks in terms of quality and similarity, and how strong a contender Wavenet is. Recent advances in speech synthesis suggest that limitations such as the lossy nature of the amplitude spectrum with minimum phase approximation and the over-smoothing effect in acoustic modeling can be overcome by using advanced machine learning approaches. In this paper, we build a framework in which we can fairly compare new vocoding and acoustic modeling techniques with conventional approaches by means of a large scale crowdsourced evaluation. Results on acoustic models showed that generative adversarial networks and an autoregressive  model performed better than a normal recurrent network and the AR model performed best. Evaluation on vocoders by using the same AR acoustic model demonstrated that a Wavenet vocoder outperformed classical source-filter-based vocoders.  Particularly, generated speech waveforms from the combination of AR acoustic model and Wavenet vocoder achieved a similar score of speech quality to vocoded speech.  
 %闁瑥 abstract 婢额亪鏆﹂敍灞惧櫝鐟尪顩︾缓顔剧叚 -- LeeNew %%%%%%%%鐏 Recently, cycle-consistent adversarial network  has been successfully applied to voice conversion to a different speaker without parallel data, although in those approaches an individual model is needed for each target speaker. In this paper, we propose an adversarial learning framework for voice conversion, with which a single model can be trained to convert the voice to many different speakers, all without parallel data, by separating the speaker characteristics from the linguistic content in speech signals. An autoencoder is first trained to extract speaker-independent latent representations and speaker embedding separately using another auxiliary speaker classifier to regularize the latent representation. The decoder then takes the speaker-independent latent representation and the target speaker embedding as the input to generate the voice of the target speaker with the linguistic content of the source utterance. The quality of decoder output is further improved by patching with the residual signal produced by another pair of generator and discriminator. A target speaker set size of 20 was tested in the preliminary experiments, and very good voice quality was obtained. Conventional voice conversion metrics are reported. We also show that the speaker information has been properly reduced from the latent representations. %%%%%%%%鐏 %Conventional voice conversion  attempted to learn a function to transform audio from source domain to target domain, regardless using parallel or non-parallel data. In this paper, we propose a new method for VC using non-parallel data. The basic idea is to divide the linguistic content from speaker characteristics in speech. An auto-encoder is trained to extract speaker-invariant latent representation and speaker embedding using the technique of adversarial training, that is, trained another speaker classifier adversarially to regularize the latent representation. After the encoder extracting speaker-invariant latent representation of the source utterance, the decoder takes the representation and target speaker閳ユ獨 embedding as input to generate the spectra of target speaker with the linguistic content of the source utterance. The output of decoder is further patched by the output of another generator which learns with its corresponding discriminator to force the converted spectra to be more realistic.  %##########################閸欘垵鍏橀崣顖欎簰閹绘稒鍨氭稉瀣桨 %One of the advantages of our model is being able to deal with the scenario of multiple target speakers, which is a major limitation in previous research . %閹冲鈹庡鏇犳暏鐠滄牗鏋? - Lee  %The main advantages of our model besides utilizing non-parallel data are being able to generate high quality speech sounds without blurred artifacts compared to traditional statistical methods using a Gaussian mixture model ~~~, and can deal with the scenario of multiple target speakers, which is a major limitation in recent researches applying cycle-consistent adversarial network  ~~.  %##########################閸欘垵鍏橀崣顖欎簰閹绘稒鍨氭稉瀣桨 %The experiment shows that, target speaker set can be extended to up to 20 speakers. We not only evaluate our approach by traditional voice conversion metrics, also verify that the encoder distills linguistic content from speech by some experiments. %Experiments demonstrate that, the size of target speaker set, which we set to 20, does not hurt the quality of converted speech. We not only evaluate our approach by traditional voice conversion metrics on a non-parallel VC dataset, also verify that the encoder distills linguistic content from speech by some experiments.   %##########################閺堥弮鈺冩畱閻楀牊婀 %  A new method for voice conversion  is proposed. Conventional VC attempted to learn a function to transform audio from source domain to target domain, regardless using parallel or non-parallel data. But human naturally divide the information into the linguistic content and the voice of the speaker when listening to speech. We would like to model it to on VC task.     %  In this work, we try to perform VC by learning disentangle representation. The model is trained to divide the hidden representation into speaker-invariant latent representation and speaker embedding using the technique of adversarial training. That is, trained another speaker classifier adversarially to regularize the latent representation. So we can perform VC by plug target speaker's embedding on the latent representation of source utterance. Also, we utilize another GAN framework, decouple learning, to make the conversion spectra more realistic, which is a major problem in previous VC research.   %  The advantage of our model is being able to deal with the scenario of multiple target speakers, which is a major limitation in previous research. The experiment shows that, target speaker set can be extended to up to 20 speakers. We not only evaluate our approach by traditional voice conversion metrics, also proving that the intermediate representation is speaker-invariant by some experimental result.  
 %\panos{We need to rework the whole premise: what you are measuring is not entrainment. It's a divergence from the 'average' entrainment of the 'median' couples. You got all of the speaker transitions, found the average entrainment, which can be high, or low, and then you are measuring how far is yours from that. Say that 2 people in love have a really really good entrainment, and in some metric, they are a distance of 1 apart. Then the average joe talking to the random jane has 10 apart. And then people that have an argument, divorcing couples, autistic people, depressed etc have a metric of 100-1000. What you are finding is distance from 10. Not distance from 1. Hence we have to call this something else... Neural Ensemble-Entrainment Divergence? Neural Mean-Entrainment Divergence? Neural Mean-Entrainment Similarity? ... this is critical to the clarity of the paper. It is also critical for when you build a supervised model on top that tracks the direction/magnitude of this similarity via i-vectors or NMES-vectors...???}  %\panos{A second comment which is important: your metric is *not* entrainment. You can't prove that. It's a proxy metric that relates to entrainment. That should be clear throughout.  Hence important to give it a name and validate that it relates to entrainment.... say \ned or other options I wrote above}  Entrainment is a known adaptation mechanism that causes interaction participants to adapt or synchronize their acoustic characteristics. Understanding how interlocutors tend to adapt to each other's speaking style through entrainment involves measuring a range of acoustic features and comparing those via multiple signal comparison methods. In this work, we present a turn-level distance measure obtained in an unsupervised manner using a Deep Neural Network~ model, which we call \nedF . This metric establishes a framework that learns an embedding from the population-wide entrainment in an unlabeled training corpus. We use the framework for a set of acoustic features and validate the measure experimentally by showing its efficacy in distinguishing real conversations from fake ones created by randomly shuffling speaker turns. Moreover, we show real world evidence of the validity of the proposed measure. We find that high value of \ned is associated with high ratings of emotional bond in suicide assessment interviews, which is consistent with prior studies.  
 In this paper, we summarize recent progresses made in deep learning based acoustic models and the motivation and insights behind the surveyed techniques. We first discuss acoustic models that can effectively exploit variable-length contextual information, such as recurrent neural networks , convolutional neural networks , and their various combination with other models. We then describe acoustic models that are optimized end-to-end with emphasis on feature representations learned jointly with rest of the system, the connectionist temporal classification  criterion, and the attention-based sequence-to-sequence model. We further illustrate robustness issues in speech recognition systems, and discuss acoustic model adaptation, speech enhancement and separation, and robust training strategies. We also cover modeling techniques that lead to more efficient decoding and discuss possible future directions in acoustic model research. \footnote{This is an updated version with latest literature until ICASSP2018 of the paper: Dong Yu and Jinyu Li, ``Recent Progresses in Deep Learning based Acoustic Models,'' vol.4, no.3, IEEE/CAA Journal of Automatica Sinica, 2017.}  
   Traditional Neural machine translation   involves a fixed training procedure where each sentence is sampled once during each epoch. In reality, some sentences are well-learned during the initial few epochs; however, using this approach, the well-learned sentences would continue to be trained along with those sentences that were not well learned for 10-30 epochs, which results in a wastage of time. Here, we propose an efficient method to dynamically sample the sentences in order to accelerate the NMT training. In this approach, a weight is assigned to each sentence based on the measured difference between the training costs of two iterations. Further, in each epoch, a certain percentage of sentences are dynamically sampled according to their weights. Empirical results based on the NIST Chinese-to-English and the WMT English-to-German tasks show that the proposed method can significantly accelerate the NMT training and improve the NMT performance. 
  Target-oriented sentiment classification aims at classifying sentiment polarities over individual opinion targets in a sentence. RNN with attention seems a good fit for the characteristics of this task, and indeed it achieves the state-of-the-art performance. After re-examining the drawbacks of attention mechanism and the obstacles that block CNN to perform well in this classification task, we propose a new model to overcome these issues. Instead of attention, our model employs a CNN layer to extract salient features from the transformed word representations originated from a bi-directional RNN layer. Between the two layers, we propose a component to  generate target-specific representations of words in the sentence, meanwhile incorporate a mechanism for preserving the original contextual information from the RNN layer. Experiments show that our model achieves a new state-of-the-art performance on a few benchmarks.\footnote{Our code is open-source and available at \url{https://github.com/lixin4ever/TNet}}     %show that our model can dominate state-of-the-art methods with promising improvements.  %, and case studies are presented to show how the model overcomes the obstacles.  
 We introduce a novel architecture for dependency parsing:  .  Combining pointer networks~ with an internal stack, the proposed model first reads and encodes the whole sentence, then builds the dependency tree top-down  in a depth-first fashion.  The stack tracks the status of the depth-first search and the pointer networks select one child for the word at the top of the stack at each step.  The StackPtr parser benefits from the information of the whole sentence and all previously derived subtree structures, and removes the left-to-right restriction in classical transition-based parsers. Yet, the number of steps for building any  parse tree is linear in the length of the sentence just as other transition-based parsers, yielding an efficient decoding algorithm with $O$ time complexity.  We evaluate our model on 29 treebanks spanning 20 languages and different dependency annotation schemas, and achieve state-of-the-art performance on 21 of them. 
   In neural machine translation , researchers face the challenge of un-seen  words translation. To solve this, some researchers propose the splitting of western languages such as English and German into sub-words or compounds. In this paper, we try to address this OOV issue and improve the NMT adequacy with a harder language Chinese whose characters are even more sophisticated in composition. We integrate the Chinese radicals into the NMT model with different settings to address the unseen words challenge in Chinese to English translation. On the other hand, this also can be considered as semantic part of the MT system since the Chinese radicals usually carry the essential meaning of the words they are constructed in. Meaningful radicals and new characters can be integrated into the NMT systems with our models. We use an attention-based NMT system as a strong baseline system. The experiments on standard Chinese-to-English NIST translation shared task data 2006 and 2008 show that our designed models outperform the baseline model in a wide range of state-of-the-art evaluation metrics including LEPOR, BEER, and CharacTER, in addition to BLEU and NIST scores, especially on the adequacy-level translation. We also have some interesting findings from the results of our various experiment settings about the performance of words and characters in Chinese NMT, which is different with other languages. For instance, the fully character level NMT may perform well or the state of the art in some other languages as researchers demonstrated recently, however, in the Chinese NMT model, word boundary knowledge is important for the model learning. \footnote{* parallel authors, ranked by alphabet order. In Proceeding of ESSLLI2018, Sofia, Bulgaria} %\footnote{* parallel authors, ranked by alphabet decreasing order}   
   Every person speaks or writes their own flavor of their native language, influenced by a number of factors: the content they tend to talk about, their gender, their social status, or their geographical origin.   When attempting to perform Machine Translation , these variations have a significant effect on how the system should perform translation, but this is not captured well by standard one-size-fits-all models.   In this paper, we propose a simple and parameter-efficient adaptation technique that only requires adapting the bias of the output softmax to each particular user of the MT system, either directly or through a factored approximation.   Experiments on TED talks in three languages demonstrate improvements in translation accuracy, and better reflection of speaker traits in the target text. 
 Neural machine translation  has been accelerated by deep learning neural networks over statistical-based approaches, due to the plethora and programmability of commodity heterogeneous computing architectures such as FPGAs and GPUs and the massive amount of training corpuses generated from news outlets, government agencies and social media.  Training a learning classifier for neural networks entails tuning hyper-parameters that would yield the best performance.  Unfortunately, the number of parameters for machine translation include discrete categories as well as continuous options, which makes for a combinatorial explosive problem. This research explores optimizing hyper-parameters when training deep learning neural networks for machine translation.  Specifically, our work investigates training a language model with Marian NMT.  Results compare NMT under various hyper-parameter settings across a variety of modern GPU architecture generations in single node and multi-node settings, revealing insights on which hyper-parameters matter most in terms of performance, such as words processed per second, convergence rates, and translation accuracy, and provides insights on how to best achieve high-performing NMT systems.  
 Mining electronic health records for patients who satisfy a set of predefined criteria is known in medical informatics as phenotyping. Phenotyping has numerous applications such as outcome prediction, clinical trial recruitment, and retrospective studies. Supervised machine learning for phenotyping typically relies on sparse patient representations such as bag-of-words. We consider an alternative that involves learning patient representations. We develop a neural network model for learning patient representations and show that the learned representations are general enough to obtain state-of-the-art performance on a standard comorbidity detection task. 
  We propose a novel coherence model for written asynchronous conversations , and show its applications in coherence assessment and thread reconstruction tasks. We conduct our research in two steps. First, we propose improvements to the recently proposed neural entity grid model by lexicalizing its entity transitions. Then, we extend the model to asynchronous conversations by incorporating the underlying conversational structure in the entity grid representation and feature computation. Our model achieves state of the art results on standard coherence assessment tasks in monologue and conversations outperforming existing models.  We also demonstrate its effectiveness in reconstructing thread structures.    % and  %A further evaluation demonstrates the utility of our neural coherence model for the task of thread reconstruction in forum conversation.     
 We present an approach to neural machine translation  that supports multiple domains in a single model and allows switching between the domains when translating. The core idea is to treat text domains as distinct languages and use multilingual NMT methods to create multi-domain translation systems; we show that this approach results in significant translation quality gains over fine-tuning. We also explore whether the knowledge of pre-specified text domains is necessary; turns out that it is after all, but also that when it is not known quite high translation quality can be reached, and even higher than with known domains in some cases. 
 		We propose a method that can leverage unlabeled data to learn a matching model for response selection in retrieval-based chatbots. The  method employs a sequence-to-sequence architecture  model as a weak annotator to judge the matching degree of unlabeled pairs, and then performs learning with both the weak signals and the unlabeled data. Experimental results on two public data sets indicate that matching models get  significant improvements when they are learned with the proposed method.  	
 %  Creating an intelligent conversational system that understands vision and language is one of the ultimate goals in Artificial Intelligence ~. Extensive research has focused on vision-to-language generation, however, limited research has touched on combining these two modalities in a goal-driven dialog context. We propose a multimodal hierarchical reinforcement learning framework that dynamically integrates vision and language for task-oriented visual dialog. The framework jointly learns the multimodal dialog state representation and the hierarchical dialog policy to improve both dialog task success and efficiency. We also propose a new technique, state adaptation, to integrate context awareness in the dialog state representation. We evaluate the proposed framework and the state adaptation technique in an image guessing game and achieve promising results. %We demonstrate the benefits of using hierarchical  takes multimodal dialog state to strategically coordinate between question selection and image guessing.  %We demonstrate that the proposed framework enables the agent to be  and also efficient in decision-making.the dynamic multimodal state-action space in contextally aware of the visual dialog task 
 Word embedding is a key component in many downstream applications in processing natural languages. Existing approaches often assume the existence of a large collection of text for learning effective word embedding. However, such a corpus may not be available for some low-resource languages. In this paper, we study how to effectively learn a word embedding model on a corpus with only a few million tokens. In such a situation, the co-occurrence matrix is  sparse as the co-occurrences of many word pairs are unobserved. In contrast to existing approaches often only sample a few unobserved word pairs as negative samples, we argue that the zero entries in the co-occurrence matrix also provide valuable information. We then design a Positive-Unlabeled Learning  approach to factorize the co-occurrence matrix and validate the proposed approaches in four different languages.  %The experimental results demonstrate that the proposed approach achieves  %better performance compared to existing approaches with a small amount of training text. % by encoding the co-occurrence information in a matrix.}     % Word embedding has been used as a key component in many downstream applications involving processing natural languages.  % Existing approaches often train word embedding based on co-occurrence information on a large collection of text.  % However, such corpus may not be available for low resource languages.  % In this paper, we study how to train word vectors with only a few million tokens. % We model the training of word embedding as a matrix completion problem by encoding the co-occurrence information in a matrix. % We argue that the zero terms in the co-occurrence matrix  provide valuable information for learning good word vectors.  % Based on this intuition, we propose a PU-Learning approach that learns word embedding from both positive and all unobserved terms in the co-occurrence matrix.  % Experimental results show that our approach requires less amount of training text to learn a reasonable semantic representation of words.   
 Understanding customer sentiments is of paramount importance in marketing strategies today. Not only will it give companies an insight as to how customers perceive their products and/or services, but it will also give them an idea on how to improve their offers. This paper attempts to understand the correlation of different variables in customer reviews on a women clothing e-commerce, and to classify each review whether it recommends the reviewed product or not and whether it consists of positive, negative, or neutral sentiment. To achieve these goals, we employed univariate and multivariate analyses on dataset features except for review titles and review texts, and we implemented a bidirectional recurrent neural network  with long-short term memory unit  for recommendation and sentiment classification. Results have shown that a recommendation is a strong indicator of a positive sentiment score, and vice-versa. On the other hand, ratings in product reviews are fuzzy indicators of sentiment scores. We also found out that the bidirectional LSTM was able to reach an F1-score of 0.88 for recommendation classification, and 0.93 for sentiment classification. 
   Despite the impressive quality improvements yielded by neural machine translation  systems, controlling their translation output to adhere to user-provided terminology constraints remains an open problem. We describe our approach to constrained neural decoding based on finite-state machines and multi-stack decoding which supports target-side constraints as well as constraints with corresponding aligned input text spans. We demonstrate the performance of our framework on multiple translation tasks and motivate the need for constrained decoding with attentions as a means of reducing misplacement and duplication when translating user constraints. 
 %Optimizing sequence scores such as ROUGE, BLEU, or CIDEr as approximators of textual quality has become common in many text generation tasks, yielding marked improvements on the same quantitative measures. In tasks with no quantitative score that is strongly correlated with generation quality, however, no good reward function exists to be optimized directly.   %Training criteria for text generation models remain to be an open research question. Commonly used scores such as ROUGE, BLEU, or CIDEr are based on n-gram patterns, providing only a limited and myopic perspective of the overall text quality. As a result, while models trained to optimize directly for these measures can make marked improvements on the same measures, they may not necessarily lead to better quality in terms of overall coherence or discourse structure.  %However, it is not trivial to design an automatic measure  %In this work, we introduce a method for pretraining a neural reward function using sentence-level temporal ordering patterns in the training set. When a generator is trained with this reward function, its produced generations exhibit more temporally coherent and less repetitive sentences than models trained with only cross-entropy or reinforced with other scores. We show the effect of our method on the recipe generation task. In this paper, we investigate the use of discourse-aware rewards with reinforcement learning to guide a model to generate long, coherent text. In particular, we propose to learn neural rewards to model cross-sentence ordering as a means to approximate desired discourse structure. Empirical results demonstrate that a generator trained with the learned reward produces more coherent and less repetitive text than models trained with cross-entropy or with reinforcement learning with commonly used scores as rewards.   
 Word embeddings have been widely used in sentiment classification because of their efficacy for semantic representations of words. Given reviews from different domains, some existing methods for word embeddings exploit sentiment information, but they cannot produce domain-sensitive embeddings. On the other hand, some other existing methods can generate domain-sensitive word embeddings, but they cannot distinguish words with similar contexts but opposite sentiment polarity. We propose a new method for learning domain-sensitive and sentiment-aware embeddings that simultaneously capture the information of sentiment semantics and domain sensitivity of individual words. Our method can automatically determine and produce domain-common embeddings and domain-specific embeddings. The differentiation of domain-common and domain-specific words enables the advantage of data augmentation of common semantics from multiple domains and capture the varied semantics of specific words from different domains at the same time. Experimental results show that our model provides an effective way to learn domain-sensitive and sentiment-aware word embeddings which benefit sentiment classification at both sentence level and lexicon term level. 
   %Almost all state-of-the-art sequence labeling systems use Conditional Random Fields  to model word-level information.   %Neural networks with a conditional random field  output layer have been proposed to deal with the sequence labeling tasks in natural language processing.   %On the other hand, semi-Markov conditional random field  models have shown better performance than conventional CRFs in the tasks of assigning labels to segments by extracting features from and describing transitions between segments instead of words.   This paper proposes hybrid semi-Markov conditional random fields  for neural sequence labeling in natural language processing.   Based on conventional conditional random fields , SCRFs have been designed for the tasks of assigning labels to segments by extracting features from and describing transitions between segments instead of words.   %However, in segment-level sequence labeling tasks, segment-level information has a clearer and more intuitive meaning.   In this paper, we improve the existing SCRF methods by employing word-level and segment-level information simultaneously.   First, word-level labels are utilized to derive the segment scores in SCRFs.   Second, a CRF output layer and an SCRF output layer are integrated into an unified neural network and trained jointly.   %Semi-Markov Conditional Random Fields  was proposed to model segment-level information directly.   %In this paper, we assume that word-level information is helpful to model segment-level information.   %And we introduce hybrid semi-Markov Conditional Random Fields , which can employ word- and segment-level information simultaneously.   %Besides, taking account of the ability of CRFs modeling word-level information, we combine CRFs and HSCRFs to train the whole model.   Experimental results on CoNLL 2003 named entity recognition  shared task show that our model achieves state-of-the-art performance   when no external knowledge is used\footnote{The code of our models is available at \url{http://github.com/ZhixiuYe/HSCRF-pytorch}}. 
 As more and more academic papers are being submitted to conferences and journals, evaluating all these papers by professionals is time-consuming and can cause inequality due to the personal factors of the reviewers. In this paper, in order to assist professionals in evaluating academic papers, we propose a novel task: automatic academic paper rating , which automatically determine whether to accept academic papers. We build a new dataset for this task and propose a novel modularized hierarchical convolutional neural network to achieve automatic academic paper rating. Evaluation results show that the proposed model outperforms the baselines by a large margin. The dataset and code are available at \url{https://github.com/lancopku/AAPR} 
 Recurrent neural networks  have represented for years the state of the art in neural machine translation. Recently, new architectures have been proposed, which can  leverage parallel computation on GPUs better than classical RNNs. Faster training and inference combined with different sequence-to-sequence modeling also lead to performance improvements. While the new models completely depart from the original recurrent architecture, we decided to investigate how to make RNNs more efficient. In this work, we propose a new recurrent NMT architecture, called Simple Recurrent NMT, built on a class of fast and weakly-recurrent units that use layer normalization and multiple attentions.  Our experiments on the WMT14 English-to-German and WMT16 English-Romanian benchmarks show that our model represents a valid alternative to LSTMs, as it can achieve better results at a significantly lower computational cost. 
 We present a set of experiments to demonstrate that deep recurrent neural networks  learn internal representations that capture soft hierarchical notions of syntax from highly varied supervision. We consider four syntax tasks at different depths of the parse tree; for each word, we predict its part of speech as well as the first , second  and third level  constituent labels that appear above it. These predictions are made from representations produced at different depths in networks that are pretrained with one of four objectives: dependency parsing, semantic role labeling, machine translation, or language modeling. In every case, we find a correspondence between network depth and syntactic depth, suggesting that a soft syntactic hierarchy emerges. This effect is robust across all conditions, indicating that the models encode significant amounts of syntax even in the absence of an explicit syntactic training supervision. 
 %}  Neural machine translation requires large amounts of parallel training text to learn a reasonable-quality translation model.  % This is particularly inconvenient for language pairs for which enough parallel text is not available.  % In this paper, we use monolingual linguistic resources in the source side to  address this challenging problem based on a multi-task learning approach.  % More specifically, we {scaffold}  the machine translation task on auxiliary tasks including  semantic parsing, syntactic parsing, and named-entity recognition.  % This effectively injects  semantic and/or syntactic knowledge into the translation model,  which would otherwise require a large amount of training bitext. % We empirically evaluate and show the effectiveness of our multi-task learning approach on three translation tasks:  English-to-French, English-to-Farsi, and English-to-Vietnamese.  
 Conventional Open Information Extraction  systems are usually built on hand-crafted patterns from other NLP tools such as syntactic parsing, yet they face problems of error propagation. In this paper, we propose a neural Open IE approach with an encoder-decoder framework. Distinct from existing methods, the neural Open IE approach learns highly confident arguments and relation tuples bootstrapped from a state-of-the-art Open IE system. An empirical study on a large benchmark dataset shows that the neural Open IE system significantly outperforms several baselines, while maintaining comparable computational efficiency.  
 In this work we focus on confidence modeling for neural semantic parsers which are built upon sequence-to-sequence models. We outline three major causes of uncertainty, and design various metrics to quantify these factors. These metrics are then used to estimate confidence scores that indicate whether model predictions are likely to be correct. Beyond confidence estimation, we identify which parts of the input contribute to uncertain predictions allowing users to interpret their model, and verify or refine its input. Experimental results show that our confidence model significantly outperforms a widely used method that relies on posterior probability, and improves the quality of interpretation compared to simply relying on attention scores. 
 We explore : creative systems that can build coherent and fluent passages of text about a topic. We collect a large dataset of 300K human-written stories paired with writing prompts from an online forum. Our dataset enables hierarchical story generation, where the model first generates a premise, and then transforms it into a passage of text. We gain further improvements with a novel form of model fusion that improves the relevance of the story to the prompt, and adding a new gated multi-scale self-attention mechanism to model long-range context. Experiments show large improvements over strong baselines on both automated and human evaluations. Human judges prefer stories generated by our approach to those from a strong non-hierarchical model by a factor of two to one. 
 Asking good questions in large-scale, open-domain conversational systems is quite significant yet rather untouched.  This task, substantially different from traditional question generation, requires to question not only with various patterns but also on diverse and relevant topics. We observe that a good question is a natural composition of {, and ordinary words.  Interrogatives lexicalize the pattern of questioning, topic words address the key information for topic transition in dialogue, and ordinary words play syntactical and grammatical roles in making a natural sentence.  We devise two typed decoders  in which a type distribution over the three types is estimated and used to modulate the final generation distribution. Extensive experiments show that the typed decoders outperform state-of-the-art baselines and can generate more meaningful questions. 
 %A sentence can be translated into more than one correct sentences, which have different syntax structures and expressions but share the same meaning.  %However, most of the existing neural machine translation only regards the translated sentences appeared in the training dataset as the target sentences, which brings harm to the generalization of the models.  %However, due to the limitation of the training datasets, we can not have more reference translated sentences to train the neural machine translation model.%, which may bring harm to the generalization of the models. %Since the multiple correct translations share similar bag-of-words, it is possible to regard the bag-of-words of one translation as the approximate representation of the multiple translations. %In this paper, we propose an approach to train the model with the targets of the both the sentences and the bag-of-words. %We evaluate our model on the Chinese-English translation dataset, and experiments show our model outperforms the strong baselines. %Experiments show that our model outperforms the strong baselines, which demonstrate the effectiveness of our proposed approach.  A sentence can be translated into more than one correct sentences.  However, most of the existing neural machine translation models only use one of the correct translations as the targets, and the other correct sentences are punished as the incorrect sentences in the training stage.  Since most of the correct translations for one sentence share the similar bag-of-words, it is possible to distinguish the correct translations from the incorrect ones by the bag-of-words.  In this paper, we propose an approach that uses both the sentences and the bag-of-words as targets in the training stage, in order to encourage the model to generate the potentially correct sentences that are not appeared in the training set.  We evaluate our model on a Chinese-English translation dataset, and experiments show our model outperforms the strong baselines by the BLEU score of 4.55.\footnote{The code is available at \url{https://github.com/lancopku/bag-of-words}}  
 Coreference resolution aims to identify in a text all mentions that refer to the same real-world entity. The state-of-the-art end-to-end neural coreference model considers all text spans in a document as potential mentions and learns to link an antecedent for each possible mention. In this paper, we propose to improve the end-to-end coreference resolution system by  using a biaffine attention model to get antecedent scores for each possible mention, and  jointly optimizing the mention detection accuracy and the mention clustering log-likelihood given the mention cluster labels. Our model achieves the state-of-the-art performance on the CoNLL-2012 Shared Task English test set. 
 Children learning their first language face multiple problems of induction: how to learn the meanings of words, and how to build meaningful phrases from those words according to syntactic rules. % They also learn overhypotheses that constrain word meanings in different semantic classes, along with the syntactic features that pick out those semantic classes. We consider how children might solve these problems efficiently by solving them { %Keywords: %language acquisition, word learning, overhypotheses, Bayesian modeling, semantic parsing, combinatory categorial grammar 
       The goal of sentiment-to-sentiment ``translation'' is to change the underlying sentiment of a sentence while keeping its content. The main challenge is the lack of parallel data. To solve this problem, we propose a cycled reinforcement learning method that enables training on unpaired data by collaboration between a neutralization module and an emotionalization module. We evaluate our approach on two review datasets, Yelp and Amazon. Experimental results show that our approach significantly outperforms the state-of-the-art systems. Especially, the proposed method substantially improves the content preservation performance. The BLEU score is improved from 1.64 to 22.46 and from 0.56 to 14.06 on the two datasets, respectively.\footnote{The released code can be found in https://github.com/lancopku/unpaired-sentiment-translation}   
 Pitch accent detection often makes use of both acoustic and lexical features based on the fact that pitch accents tend to correlate with certain words. In this paper, we extend a pitch accent detector that involves a convolutional neural network to include word embeddings, which are state-of-the-art vector representations of words. We examine the effect these features have on within-corpus and cross-corpus experiments on three English datasets. The results show that while word embeddings can improve the performance in corpus-dependent experiments, they also have the potential to make generalization to unseen data more challenging. 
 % Fast and accurate similarity search, from a large set of documents, is key to many information retrieval systems. Semantic hashing has become a powerful paradigm for fast similarity search in many information retrieval systems. While fairly successful, previous techniques generally require two-stage training, and the binary constraints are handled . In this paper, we present an  Neural Architecture for Semantic Hashing , where the binary hashing codes are treated as  latent variables. A neural variational inference framework is proposed for training, where gradients are directly backpropagated through the discrete latent variable to optimize the hash function. We also draw connections between proposed method and , which provides a theoretical foundation for the effectiveness of the proposed framework. Experimental results on three public datasets demonstrate that our method significantly outperforms several state-of-the-art models on both  and  scenarios. 
 Furui first demonstrated that the identity of both consonant and vowel can be perceived from the C-V transition; later, Stevens proposed that acoustic landmarks are the primary cues for speech perception, and that steady-state regions are secondary or supplemental.  Acoustic landmarks are perceptually salient, even in a language one doesn't speak, and it has been demonstrated that non-speakers of the language can identify features such as the primary articulator of the landmark.  These factors suggest a strategy for developing language-independent automatic speech recognition: landmarks can potentially be learned once from a suitably labeled corpus and rapidly applied to many other languages. This paper proposes enhancing the cross-lingual portability of a neural network by using landmarks as the secondary task in multi-task learning . The network is trained in a well-resourced source language with both phone and landmark labels , then adapted to an under-resourced target language with only word labels .  Landmark-tasked MTL reduces source-language phone error rate by 2.9\% relative, and reduces target-language word error rate by 1.9\%-5.9\% depending on the amount of target-language training data.  These results suggest that landmark-tasked MTL causes the DNN to learn hidden-node features that are useful for cross-lingual adaptation. % * <boonpang.lim@gmail.com> 2017-10-27T18:00:11.065Z: %  % > Acoustic Landmarks have been shown to be able to improve classical frame-synchronous HMM-based speech recognition. However, as they are somewhat language-universal, their characteristics can potentially be learnt once from a suitably labeled corpus, then rapidly applied to other many other languages in a scalable fashion. Earlier works tend to use approaches that add on significantly to the overall complexity of the system. In this work, we demonstrate that we can distill this knowledge into a landmark detection model and transfer it to improve the speech recognition performance of a completely different language, without increasing the complexity at decode time. Furthermore, the landmarks themselves provide complementary information to the original source language as well. Our experiments demonstrate a relative 3\% improvement in both the monolingual and cross-lingual landmark transfer settings -- fully  supporting our hypothesis of landmarks having useful and complementary information to phone labels, even across different languages. % I'm seeing three points that are interesting. Only thing I find really novel , is the application to the Iban corpus - this shows that the landmark detectors really have the potential to be language universal. % i) Transfer of landmark information from one language to another. This I feel is novel.   % ii) use of landmark information in a way that do not increase the decoding complexity. This is interesting but not that novel because it is just a natural feature of the multi-task learning approach. % iii) Use of landmarks for speech recognition - by itself is not novel because it has been done using different methods. %  %  % ^. %NB: by addons I think you mean TANDEM?  %Acoustic Landmark have been shown to benefit classical frame synchronous speech processing systems in many studies. However, these studies usually require extra add-ons to the original ASR system. In our work we explored using Landmark to improving the Acoustic Model quality directly through Multi-task Learning. Our experiments demonstrated ASR, jointly trained with Landmark information, reduced decoding error rate up to 3\% on multiple corpus. We also showed that Landmark detectors trained in English  can be applied cross-lingual to other language . This demonstrates Landmark's potential to complement the building of speech processing systems for under-resource languages.  
 This paper presents the first study aimed at capturing stylistic similarity between words in an unsupervised manner. We propose extending the continuous bag of words  model~ to learn style-sensitive word vectors using a wider context window under the assumption that the style of all the words in an utterance is consistent. % construct a novel style-sensitive word vector predicting the target word for given nearby and wider contexts % under the assumption that the style of all the words in an utterance is consistent. In addition, we introduce a novel task to predict lexical stylistic similarity and to create a benchmark dataset for this task. Our experiment with this dataset supports our assumption and demonstrates that the proposed extensions contribute to the acquisition of style-sensitive word embeddings. % an evaluation dataset with human judgments on the stylistic similarity between word pairs. %We calculate the correlation with human judgments for stylistic similarity. % Experimental results illustrate the significance of capturing the stylistic similarity. 
 %Supervise learning is an effective method for building natural language processing  models. The success of many natural language processing  tasks is bound by the number and quality of annotated data, but there is often a shortage of such training data. In this paper, we ask the question: ``Can we combine a neural network  with regular expressions  to improve supervised learning for \NLP?". In answer, we develop novel methods to exploit the rich expressiveness of \REs at different levels within a \NN, showing that the combination significantly enhances the learning effectiveness when a small number of training examples are available. We evaluate our approach by applying it to spoken language understanding for intent detection and slot filling. Experimental results show that our approach is highly effective in exploiting the available training data, giving a clear boost to the \RE-unaware \NN.    %\z{Check the  abstract and title.}  %Combining neural networks  and human-generated rules can reduce the number of training examples required for learning an effective %model, and can possibly produce better results than pure empirical methods. Specifically, we investigate the methods of combining \NN %with regular expression , which is one of the most commonly used rules in natural language processing. We experiment our method in %intent detection and slot filling settings with different amounts of training data, and the experimental results show that our methods %give clear boost to the baseline \NN model by combining with \RE. Besides, we also give systematical analysis on the working scenario of %each method, and on the influence of the complexity of the \RE as well.  
 Despite their local fluency, long-form text generated from RNNs is often generic, repetitive, and even self-contradictory.  We propose a unified learning framework that collectively addresses all the above issues by composing a committee of discriminators that can guide a base RNN generator towards more globally coherent generations. More concretely, discriminators each specialize in a different principle of communication, such as Grice's maxims, and are collectively combined with the base RNN generator through a composite decoding objective.   Human evaluation demonstrates that text generated by our model is preferred over that of baselines by a large margin, significantly enhancing the overall coherence, style, and information of the generations. 
 Small perturbations in the input can severely distort intermediate representations and thus impact translation quality of neural machine translation  models.  In this paper, we propose to improve the robustness of NMT models with adversarial stability training.  The basic idea is to make both the encoder and decoder in NMT models robust against input perturbations by enabling them to behave similarly for the original input and its perturbed counterpart. Experimental results on Chinese-English, English-German and English-French translation tasks show that our approaches can not only achieve significant improvements over strong NMT systems but also improve the robustness of NMT models. 
 Recent approaches for dialogue act recognition have shown that context from preceding utterances is important to classify the subsequent one.  It was shown that the performance improves rapidly when the context is taken into account.  We propose an utterance-level attention-based bidirectional recurrent neural network  model to analyze the importance of preceding utterances to classify the current one.  In our setup, the BiRNN is given the input set of current and preceding utterances.  Our model outperforms previous models that use only preceding utterances as context on the used corpus.  %We show again that considering the context helps to improve the performance since the preceding utterances provide a significant amount of pragmatic information in conversation.  Another contribution of our research is a mechanism to discover the amount of information in each utterance to classify the subsequent one and to show that context-based learning not only improves the performance but also achieves higher confidence in the recognition of dialogue acts.  We use character- and word-level features to represent the utterances. The results are presented for character and word feature representations and as an ensemble model of both representations.  %Our model uses only the preceding utterances as context and achieves state-of-the-art results on the SwDA corpus. We found that when classifying short utterances, the closest preceding utterances contribute to a higher degree.   
 Dialogue act recognition is an important part of natural language understanding. %However, the classification process was considered to recognize the dialogue act at utterance-level. %We argue that the dialogue act is a context-sensitive concept, and the approach used to evaluate or recognize should consider when it comes to model them. We investigate the way dialogue act corpora are annotated and the learning approaches used so far. We find that the dialogue act is context-sensitive within the conversation for most of the classes. %And very few did this way, but they were technical contributions and did not do the discussion of discourse compositionality. Nevertheless, previous models of dialogue act classification work on the utterance-level and only very few consider context. We propose a novel context-based learning method to classify dialogue acts using a character-level language model utterance representation, and we notice significant improvement. We evaluate this method on the Switchboard Dialogue Act corpus, and our results show that the consideration of the preceding utterances as a a context of the current utterance improves dialogue act detection. \\ \newline \Keywords{Dialogue Acts Detection, Recurrent Neural Networks, Context-based Learning
 Recent work has managed to learn cross-lingual word embeddings without parallel data by mapping monolingual embeddings to a shared space through adversarial training. However, their evaluation has focused on favorable conditions, using comparable corpora or closely-related languages, and we show that they often fail in more realistic scenarios. This work proposes an alternative approach based on a fully unsupervised initialization that explicitly exploits the structural similarity of the embeddings, and a robust self-learning algorithm that iteratively improves this solution. Our method succeeds in all tested scenarios and obtains the best published results in standard datasets, even surpassing previous supervised systems. Our implementation is released as an open source project at \url{https://github.com/artetxem/vecmap}. 
   We report on our experiments to train deep neural networks   that automatically translate informalized \LaTeX{}-written Mizar   texts into the formal Mizar language. To the best of our knowledge, this is the first time when neural networks have been adopted in the formalization of mathematics.   Using Luong et al.'s neural machine translation model , we tested our aligned informal-formal corpora against various hyperparameters and evaluated their results.   Our experiments show that our best performing model configurations are able to generate correct Mizar statements on 65.73\% of the inference data,  with the union of all models covering 79.17\%. These results indicate that formalization through artificial neural network is a promising approach for automated formalization of mathematics.   We present several case studies to illustrate our results. 
 Semantic  Similarity  is  an  important  application  which  finds  it閳ユ獨  use  in  many  downstream  NLP applications.  Though the task is mathematically defined, semantic similarity閳ユ獨 essence is to capture the  notions  of  similarity  impregnated  in  humans.   Machines  use  some  heuristics  to  calculate  the similarity between words, but these are typically corpus dependent or are useful for specific domains.The difference between Semantic Similarity and Semantic Relatedness motivates the development of new algorithms. \newline For  a  human,  the  word  閳ユ竷ar閳  and  閳ユ笧oad閳  are  probably  as  related  as  閳ユ竷ar閳  and  閳ユ競us閳.   But this may not be the case for computational methods.  Ontological methods are good at encoding Semantic Similarity and Vector Space models are better at encoding Semantic Relatedness.  There is a dearth of methods which leverage ontologies to create better vector representations. \newline The  aim  of  this  proposal  is  to  explore  in  the  direction  of  a  hybrid  method  which  combines statistical/vector space methods like Word2Vec and Ontological methods like WordNet to leverage the advantages provided by both.  
   Online petitions are a cost-effective way for  citizens to collectively engage with policy-makers in a democracy. Predicting the popularity of a petition --- commonly measured by its signature count --- based on its textual content has utility for policy-makers as well as those posting the petition. In this work, we model this task using CNN regression with an auxiliary ordinal regression objective.  We  demonstrate the effectiveness of our proposed approach using UK and US government petition datasets.\footnote{ The code and data from this paper are available from   \url{http://github.com/shivashankarrs/Petitions}}  %In this work, we address the task of predicting  popularity of petitions --- measured by the signature count, given its text.   %In this work, we employ a CNN based deep Poisson regression model for predicting  popularity of petitions --- measured by the signature count, given its text. We also study the utility of an auxiliary ordinal-regression objective in order to handle the skew in count distribution further. Finally, we evaluate the use of custom features in addition to latent features given by the deep model. We  demonstrate the effectiveness of our proposed approach using the UK government online petitions dataset.    
 Many research fields codify their findings in standard formats, often by reporting correlations between quantities of interest. But the space of all testable correlates is far larger than scientific resources can currently address, so the ability to accurately predict correlations would be useful to plan research and allocate resources. Using a dataset of approximately 170,000 correlational findings extracted from leading social science journals, we show that a trained neural network can accurately predict the reported correlations using only the text descriptions of the correlates. %. Accurate predictive models such as these can guide scientists towards promising untested correlates, better quantify the information gained from new findings, and has implications for moving artificial intelligence systems from predicting structures to predicting relationships in the real world. 
 User Simulators are one of the major tools that enable offline training of task-oriented dialogue systems. For this task the Agenda-Based User Simulator  is often used. The ABUS is based on hand-crafted rules and its output is in semantic form. Issues arise from both properties such as limited diversity and the inability to interface a text-level belief tracker. This paper introduces the Neural User Simulator  whose behaviour is learned from a corpus and which generates natural language, hence needing a less labelled dataset than simulators generating a semantic output. In comparison to much of the past work on this topic, which evaluates user simulators on corpus-based metrics, we use the NUS to train the policy of a reinforcement learning based Spoken Dialogue System. The NUS is compared to the ABUS by evaluating the policies that were trained using the simulators. Cross-model evaluation is performed i.e. training on one simulator and testing on the other. Furthermore, the trained policies are tested on real users. In both evaluation tasks the NUS outperformed the ABUS. 
 The use of future contextual information is typically shown to be helpful for acoustic modeling. However, for the recurrent neural network , it's not so easy to model the future temporal context effectively, meanwhile keep lower model latency. In this paper, we attempt to design a RNN acoustic model that being capable of utilizing the future context effectively and directly, with the model latency and computation cost as low as possible. The proposed model is based on the minimal gated recurrent unit  with an input projection layer inserted in it. Two context modules,  and , are specifically designed for this architecture to model the future context. Experimental results on the Switchboard task and an internal Mandarin ASR task show that, the proposed model performs much better than long short-term memory  and mGRU models, whereas enables online decoding with a maximum latency of 170 ms. This model even outperforms a very strong baseline, TDNN-LSTM, with smaller model latency and almost half less parameters.  
 Aspect based sentiment analysis  can provide more detailed information than general sentiment analysis, because it aims to predict the sentiment polarities of the given aspects or entities in text. We summarize previous approaches into two subtasks: aspect-category sentiment analysis  and aspect-term sentiment analysis . Most previous approaches employ long short-term memory and attention mechanisms to predict the sentiment polarity of the concerned targets, which are often complicated and need more training time. We propose a model based on convolutional neural networks and gating mechanisms, which is more accurate and efficient. First, the novel Gated Tanh-ReLU Units can selectively output the sentiment features according to the given aspect or entity. The architecture is much simpler than attention layer used in the existing models. Second, the computations of our model could be easily parallelized during training, because convolutional layers do not have time dependency as in LSTM layers, and gating units also work independently. The experiments on SemEval datasets demonstrate the efficiency and effectiveness of our models.} 
 Neural machine translation  systems have recently obtained state-of-the art in many machine translation systems between popular language pairs because of the availability of data. For low-resourced language pairs, there are few researches in this field due to the lack of bilingual data. In this paper, we attempt to build the first NMT systems  for a low-resourced language pairs:Japanese-Vietnamese. We have also shown significant improvements when combining advanced methods to reduce the adverse impacts of data sparsity and improve the quality of NMT systems. In addition, we proposed a variant of Byte-Pair Encoding algorithm to perform effective word segmentation for Vietnamese texts and alleviate the rare-word problem that persists in NMT systems. 
 Multi-view learning can provide self-supervision when different views are available of the same data. The distributional hypothesis provides another form of useful self-supervision from adjacent sentences which are plentiful in large unlabelled corpora. Motivated by the asymmetry in the two hemispheres of the human brain as well as the observation that different learning architectures tend to emphasise different aspects of sentence meaning, we create a unified multi-view sentence representation learning framework, in which, one view encodes the input sentence with a Recurrent Neural Network , and the other view encodes it with a simple linear model, and the training objective is to maximise the agreement specified by the adjacent context information between two views.  We show that, after training, the vectors produced from our multi-view training provide improved representations over the single-view training, and the combination of different views gives further representational improvement and demonstrates solid transferability on standard downstream tasks. 
 %Software vulnerabilities are becoming more and more prevalent, necessitating approaches which can automatically detect and repair the vulnerabilities. We would like to leverage Neural Machine Translation techniques to tackle this problem since token and compiled representations of source code share many similarities to natural language. However, these systems require data to have a one-to-one pairing between input an output data which is not always easy to obtain, particularly in large software corpora. As such, we propose a system that is able to handle data without this pairing by using an adversarial discriminator to train our Neural Machine Translation system, and show that it is able to correct known security vulnerabilities in sample source code.   %Neural Machine Translation systems have proven to be effective techniques for error correction tasks. One issue with these systems is that they require one-to-one pairing between input and output data, which is not always easy to obtain. We propose a system that handles cases where one-to-one pairing is not available by utilizing an adversarial discriminator to train our Neural Machine Translation system. We then discuss in detail issues related to the use of an adversarial discriminator on discrete data, and propose a network we found to best solve this issue. Finally, we explore the addition two novel loss functions to our NMT system which ensure it correctly maps from its input to its target domain. We then apply this system to the problem of automatic repair of vulnerabilities in software and show that we are able to repair a significant number of known vulnerabilities in a given benchmark data set. { NEED TO POLISH A BIT.}   Motivated by the problem of automated repair of software vulnerabilities, we propose an adversarial learning approach that maps from one discrete source domain to another target domain without requiring paired labeled examples or source and target domains to be bijections. We demonstrate that the proposed adversarial learning approach is an effective technique for repairing software vulnerabilities, performing close to seq2seq approaches that require labeled pairs. The proposed Generative Adversarial Network approach is application-agnostic in that it can be applied to other problems similar to code repair, such as grammar correction or sentiment translation.  
 We propose a new deep neural network model and its training scheme for text classification. Our model Sequence-to-convolution Neural Networks consists of two blocks: Sequential Block that summarizes input texts and Convolution Block that receives summary of input and classifies it to a label. Seq2CNN is trained end-to-end to classify various-length texts without preprocessing inputs into fixed length.  We also present Gradual Weight Shift method that stabilize training. GWS is applied to our model's loss function.  We compared our model with word-based TextCNN trained with different data preprocessing methods. We obtained significant improvement in classification accuracy over word-based TextCNN without any ensemble or data augmentation. Code is available at {https://github.com/tgisaturday/Seq2CNN}.   
 We propose a novel two-layered attention network based on Bidirectional Long Short-Term Memory for sentiment analysis. The novel two-layered attention network takes advantage of the external knowledge bases to improve the sentiment prediction. It uses the Knowledge Graph Embedding generated using the WordNet. We build our model by combining the two-layered attention network with the supervised model based on Support Vector Regression using a Multilayer Perceptron network for sentiment analysis. We evaluate our model on the benchmark dataset of SemEval 2017 Task 5. Experimental results show that the proposed model surpasses the top system of SemEval 2017 Task 5. The model performs significantly better by improving the state-of-the-art system at SemEval 2017 Task 5 by 1.7 and 3.7 points for sub-tracks 1 and 2 respectively. 
 In this paper, we present a state-of-the-art model and introduce a new dataset for grounded language learning.  Our goal is to develop a model that can learn to follow new instructions given prior instruction-perception-action examples.  We based our work on the SAIL dataset which consists of navigational instructions and actions in a maze-like environment.  The new model we propose achieves the best results to date on the SAIL dataset by using an improved perceptual component that can represent relative positions of objects.  We also analyze the problems with the SAIL dataset regarding its size and balance.  We argue that performance on a small, fixed-size dataset is no longer a good measure to differentiate state-of-the-art models. We introduce SAILx, a synthetic dataset generator, and perform experiments where the size and balance of the dataset are controlled. 
 Word Sense Disambiguation  aims to identify the correct meaning of polysemous words in the particular context. %Lexical resources like WordNet is of great help for WSD, which are widely used in knowledge-based methods. %Lexical resources like WordNet which are widely used in knowledge-based methods are of great help for WSD. Lexical resources like WordNet which are proved to be of great help for WSD in the knowledge-based methods. However, previous neural networks for WSD always rely on massive labeled data , %almost only model the context of word %and treat each sense of word as an independent one-hot vector, %their learning processes usually rely on massive labeled context only %the classifier  is concerned with a single word %they train a classifier for each word individually %and treat each sense label as independent and meaningless one-hot vectors, ignoring lexical resources like glosses . %In this paper, we propose GAS, an end-to-end \uline{ugmented W\uline{: an end-to-end \uline{ugmented \uline{etwork which jointly encodes the context and glosses of the target word. Therefore, we propose GAS: a \uline{ugmented W\uline{loss-\uline{a}ugmented W\uline{S}D into a Question Answering  task. %%we propose an end-to-end WSD system which jointly encodes context and sense definition  which share between different word types. %%Our method utilizes a memory network to integrate context embedding with sense embedding, %%QAWSD, regarding the glosses as input and the context as question, utilizes an improved dynamic memory network which jointly encode context and gloss for predicting the sense of word. The experimental results show that our model outperforms the state-of-the-art systems on several English all-words WSD datasets \footnote{Our code and data are available at \url{https://github.com/jimiyulu/WSD_MemNN}}. %%We evaluate our approach on multiple standard datasets, %%reporting state-of-the-art performance, especially on words which lack labeled context. %%reporting state-of-the-art performance. 
 In NMT, words are sometimes dropped from the source or  generated repeatedly in the translation.   We explore novel strategies to address the coverage problem that %do not change the model architecture, but  change only the attention transformation. %Coverage is an important problem in NMT, where words are sometimes dropped from the source or are generated repeatedly in the translation.   %Coverage is a well known problem in NMT, where information in the source is either dropped or words are repeated in the generated translations.  %We explore novel strategies that do not change the model architecture, but only the attention transformation.  %We propose a novel approach that does not change the model architecture, but only the attention transformation.   Our approach allocates fertilities to source words, used to bound the attention each word can receive.  We experiment with various sparse and constrained attention transformations and propose a new one, constrained sparsemax,  shown to be differentiable and sparse.  %propose a novel approach to ensure adequate coverage of the source sentence by assigning attention budgets to the cumulative attention probabilities of the source words.  Empirical evaluation is %Experiments are  provided in three languages pairs. 
 Cross-lingual information extraction  is an important and challenging task, especially in low resource scenarios. To tackle this challenge, we propose a training method, called Halo, which enforces the local region of each hidden state of a neural model to only generate target tokens with the same semantic structure tag. This simple but powerful technique enables a neural model to learn semantics-aware representations that are robust to noise, without introducing any extra parameter, thus yielding better generalization in both high and low resource settings. 
  Sentence pair modeling is critical for many NLP tasks, such as paraphrase identification, semantic textual similarity, and natural language inference. Most state-of-the-art neural models for these tasks rely on pretrained word embedding and compose sentence-level semantics in varied ways; however, few works have attempted to verify whether we really need pretrained embeddings in these tasks. In this paper, we study how effective subword-level  representations are in sentence pair modeling. Though it is well-known that subword models are effective in tasks with single sentence input, including language modeling and machine translation, they have not been systematically studied in sentence pair modeling tasks where the semantic and string similarities between texts matter. Our experiments show that subword models without any pretrained word embedding can achieve new state-of-the-art results on two social media datasets and competitive results on news data for paraphrase identification.   
 Natural language generators for task-oriented dialogue must effectively realize system dialogue actions and their associated semantics. In many applications, it is also desirable for generators to control the style of an utterance. To date, work on task-oriented neural generation has primarily focused on semantic fidelity rather than achieving stylistic goals, while work on style has been done in contexts where it is difficult to measure content preservation.  Here we present three different sequence-to-sequence models and carefully test how well they disentangle content and style.  We use a statistical generator, {\sc Personage}, to synthesize a new corpus of over 88,000 restaurant domain utterances whose style varies according to models of personality, giving us total control over both the semantic content and the stylistic variation in the training data. We then vary the amount of explicit stylistic supervision given to the three models. We show that our most explicit model can simultaneously achieve high fidelity to both semantic and stylistic goals: this model adds a context vector of 36 stylistic parameters as input to the hidden state of the encoder at each time step, showing the  benefits of explicit stylistic supervision, even when the amount of training data is large.  
 Learning sentence vectors that generalise well is a challenging task. In this paper we compare three methods of learning phrase embeddings: 1) Using LSTMs, 2) using recursive nets, 3) A variant of the method 2 using the POS information of the phrase. We train our models on dictionary definitions of words to obtain a reverse dictionary application similar to Felix et al. . To see if our embeddings can be transferred to a new task we also train and test on the rotten tomatoes dataset . We train keeping the sentence embeddings fixed as well as with fine tuning. 
 For tasks like code synthesis from natural language, code retrieval, and code summarization, data-driven models have shown great promise. However, creating these models require parallel data between natural language  and code with fine-grained alignments. \SO  is a promising source to create such a data set: the questions are diverse and most of them have corresponding answers with high quality code snippets. However, existing heuristic methods  are limited both in their coverage and the correctness of the NL-code pairs obtained. In this paper, we propose a novel method to mine high-quality aligned data from SO using two sets of features: hand-crafted features considering the structure of the extracted snippets, and correspondence features obtained by training a probabilistic model to capture the correlation between NL and code using neural networks. These features are fed into a classifier that determines the quality of mined NL-code pairs. Experiments using Python and Java as test beds show that the proposed method greatly expands coverage and accuracy over existing mining methods, even when using only a small number of labeled examples. Further, we find that reasonable results are achieved even when training the classifier on one language and testing on another, showing promise for scaling NL-code mining to a wide variety of programming languages beyond those for which we are able to annotate data. % \gn{This doesn't stress the nice programming-language-independent characteristics very much.} 
   Using a sequence-to-sequence framework, many neural conversation models for chit-chat succeed in naturalness of the response. Nevertheless, the neural conversation models tend to give generic responses which are not specific to given messages, and it still remains as a challenge. To alleviate the tendency, we propose a method to promote message-relevant and diverse responses for neural conversation model by using self-attention, which is time-efficient as well as effective. Furthermore, we present an investigation of why and how effective self-attention is in deep comparison with the standard dialogue generation. The experiment results show that the proposed method improves the standard dialogue generation in various evaluation metrics. 
 During the last years, there has been a lot of interest in achieving some kind of complex reasoning using deep neural networks. To do that, models like Memory Networks  have combined external memory storages and attention mechanisms. These architectures, however, lack of more complex reasoning mechanisms that could allow, for instance, relational reasoning. Relation Networks , on the other hand, have shown outstanding results in relational reasoning tasks. Unfortunately, their computational cost grows quadratically with the number of memories, something prohibitive for larger problems. To solve these issues, we introduce the Working Memory Network, a MemNN architecture with a novel working memory storage and reasoning module. Our model retains the relational reasoning abilities of the RN while reducing its computational complexity from quadratic to linear. We tested our model on the text QA dataset bAbI and the visual QA dataset NLVR. In the jointly trained bAbI-10k, we set a new state-of-the-art, achieving a mean error of less than 0.5\%. Moreover, a simple ensemble of two of our models solves all 20 tasks in the joint version of the benchmark.    
 %Neural network models have been succesfully applied to domains that require substantial generalisation skills, but the type of generalisation that they exhibit differa from the generalisation behaviour of humans. While neural network models have been successfully applied to domains that require substantial generalisation skills, recent studies have implied that they struggle when solving the task they are trained on requires inferring its underlying compositional structure. In this paper, we introduce Attentive Guidance, a mechanism to direct a sequence to sequence model equipped with attention to find more compositional solutions. We test it on two tasks, devised precisely to assess the compositional capabilities of neural models, and we show that vanilla sequence to sequence models with attention overfit the training distribution, while the guided versions come up with compositional solutions that fit the training and testing distributions almost equally well. Moreover, the learned solutions generalise even in cases where the training and testing distributions strongly diverge. In this way, we demonstrate that sequence to sequence models are capable of finding compositional solutions without requiring extra components. These results helps to disentangle the causes for the lack of systematic compositionality in neural networks, which can in turn fuel future work.  %  
  This paper describes the submissions to the efficiency track for GPUs at the Workshop for Neural Machine Translation and Generation by members of the University of Edinburgh, Adam Mickiewicz University, Tilde and University of Alicante. We focus on efficient implementation of the recurrent deep-learning model as implemented in Amun, the fast inference engine for neural machine translation. We improve the performance with an efficient mini-batching algorithm, and by fusing the softmax operation with the k-best extraction algorithm. Submissions using Amun were first, second and third fastest in the GPU efficiency track.   
 Distant supervision has become the standard method for relation extraction. However, even though it is an efficient method, it does not come at no cost---The resulted distantly-supervised training samples are often very noisy. To combat the noise, most of the recent state-of-the-art approaches focus on selecting one-best sentence or calculating soft attention weights over the set of the sentences of one specific entity pair. However, these methods are suboptimal, and the {\bfseries false positive} problem is still a key stumbling bottleneck for the performance. We argue that those incorrectly-labeled candidate sentences must be treated with a hard decision, rather than being dealt with soft attention weights. To do this, our paper describes a radical solution---We explore a deep reinforcement learning strategy to generate the false-positive indicator, where we automatically recognize false positives for each relation type without any supervised information. Unlike the removal operation in the previous studies, we redistribute them into the negative examples. The experimental results show that the proposed strategy significantly improves the performance of distant supervision comparing to state-of-the-art systems. 
 	 Neural Machine Translation  has drawn much attention due to its promising translation performance recently. However, several studies indicate that NMT often generates fluent but unfaithful translations. In this paper, we propose a method to alleviate this problem by using a phrase table as recommendation memory. The main idea is to add bonus to words worthy of recommendation, so that NMT can make correct predictions. Specifically, we first derive a prefix tree to accommodate all the candidate target phrases by searching the phrase translation table according to the source sentence. Then, we construct a recommendation word set by matching between candidate target phrases and previously translated target words by NMT. After that, we determine the specific bonus value for each recommendable word by using the attention vector and phrase translation probability. Finally, we  integrate this bonus value into NMT to improve the translation results. The extensive experiments demonstrate that the proposed methods obtain remarkable improvements over the strong attention-based NMT.  
 Learning high-quality domain word embeddings is important for achieving good performance in many NLP tasks. General-purpose embeddings trained on large-scale corpora are often sub-optimal for domain-specific applications. However,  domain-specific tasks often do not have large in-domain corpora for training high-quality domain embeddings. %Although cross-domain embedding methods exist that can leverage general-purpose embeddings to help improve domain-specific embeddings, domain word vectors that have meaning conflicts with the general-purpose embeddings cannot be improved.  In this paper, we propose a novel lifelong learning setting for domain embedding. That is, when performing the new domain embedding, the system has seen many past domains, and it tries to expand the new in-domain corpus by exploiting the corpora from the past domains via meta-learning. The proposed meta-learner characterizes the similarities of the contexts of the same word in many domain corpora, which helps retrieve relevant data from the past domains to expand the new domain corpus. Experimental results show that domain embeddings produced from such a process improve the performance of the downstream tasks. % We also demonstrate that general-purpose embeddings trained from a large corpus are sub-optimal for domain-specific applications. 
   Neural machine translation  has a drawback in that can generate only high-frequency words owing to the computational costs of the softmax function in the output layer.\\%31   In Japanese-English NMT, Japanese predicate conjugation causes an increase in vocabulary size. For example, one verb can have as many as 19 surface varieties. In this research, we focus on predicate conjugation for compressing the vocabulary size in Japanese. The vocabulary list is filled with the various forms of verbs. We propose methods using predicate conjugation information without discarding linguistic information. The proposed methods can generate low-frequency words and deal with unknown words. Two methods were considered to introduce conjugation information: the first considers it as a token  and the second considers it as an embedded vector .\\%63   The results using these methods demonstrate that the vocabulary size can be compressed by approximately 86.1\%  and the NMT models can output the words not in the training data set. Furthermore, BLEU scores improved by 0.91 points in Japanese-to-English translation, and 0.32 points in English-to-Japanese translation with ASPEC.\\%56,181<200  
   Standard machine translation systems   process sentences in isolation and hence ignore extra-sentential information, even though extended context can both prevent mistakes in ambiguous cases and improve translation coherence. We introduce a context-aware neural machine translation model   designed in such way that the flow of information from   the extended context to the translation model can be controlled and analyzed.   %Specifically, the information from the context can only pass can only pass through a single layer of attention computation.    We experiment with an English-Russian subtitles dataset,   and observe that much of what is captured by our model % in this layer    deals with improving pronoun translation. We measure correspondences between induced attention distributions and coreference relations and observe that the model implicitly captures anaphora. It is consistent with gains for sentences where pronouns need to be gendered in translation.    Beside improvements in anaphoric cases, the model also improves in overall BLEU, both over its context-agnostic version  and over simple concatenation of the context and source sentences .      %The model also improves over its context-agnostic version  and over simple concatentation of the context and the source sentence. While inspecting the , we notice that much of what is captured in this layer deals with improving      %Standard machine translation systems   %process sentences in isolation and hence ignore extra-sentential information, even though extended context can both prevent mistakes in ambiguous cases and improve translation coherence. In this study we design a context-aware neural machine translation model in such way that it both benefits from the extended context  and the flow of information from   %the source sentences to the translation model can be controlled and analyzed.    %In our extension of the state-of-the-art Transformer model~, the information from the source sentence can only pass through a single layer of attention computation. While inspecting this layer, we notice that much of what is captured in this layer deals with improving    %pronoun translation. %This is also consistent with our error analysis which   %confirm improvements in    %We isolate anaphoric cases, measure correspondences between induced attention distributions and coreference relations. We observe that the model implicitly captures co-reference phenomena. This is consistent with larger gains for sentences where pronouns need to be gendered in translation.              %We introduce a modification of the state-of-the-art Transformer model which relies on additional inter-sentential context. In our model, a source sentence and a context sentence are first encoded independently, and then a single attention layer is used to produce a context-aware representation of the source sentence. This restricted interaction between source and context encoders makes it possible to analyze the flow of information between the encoders, and gain insights into what types of contextual information are exploited by the translation model. We experiment with an English-Russian parallel corpus  and observe an 0.7 improvement in overall BLEU from using the extended context. When analyzing sources for this improvement, we observe that co-reference is one of important phenomena implicitly captured by the model. For example, knowing antecedents of English gender-neutral pronouns such as `it', `you' and `yours' helps to produce fluent translation of sentences containing these pronouns. When we isolate anaphoric cases, as predicted by an automatic co-reference systems, we can see even more substantial improvements in performance, confirming our qualitative analysis. 
 The word order between source and target languages significantly influences the translation quality in machine translation. Preordering can effectively address this problem.閵哖revious preordering methods require a manual feature design, making language dependent design costly. In this paper, we propose a preordering method with a recursive neural network that learns features from raw inputs. Experiments show that the proposed method achieves comparable gain in translation quality to the state-of-the-art method but without a manual feature design. 
 \fontsize{10}{12}.  We propose an encoder-decoder style neural network-based argument generation model enriched with externally retrieved evidence from Wikipedia.  Our model first generates a set of talking point phrases as intermediate representation, followed by a separate decoder producing the final argument based on both input and the keyphrases.  Experiments on a large-scale dataset collected from Reddit show that our model constructs arguments with more topic-relevant content than a popular sequence-to-sequence generation model according to both automatic evaluation and human assessments.  
 This paper describes the Duluth UROP systems that participated in SemEval--2018 Task 2, Multilingual Emoji Prediction. We relied on a variety of ensembles made up of classifiers  using Naive Bayes, Logistic Regression, and Random Forests. We used unigram and bigram features and tried to offset the skewness of the data through the use of oversampling. Our task evaluation  results place us 19th of 48 systems in the English evaluation, and 5th of 21 in the Spanish. After the evaluation we realized that some simple changes to preprocessing could significantly improve our results. After making these changes we attained results that would have placed us sixth in the English evaluation, and second in the Spanish. 
 Forum threads are lengthy and rich in content. Concise thread summaries will benefit both newcomers seeking information and those who participate in the discussion. Few studies, however, have examined the task of forum thread summarization. In this work we make the first attempt to adapt the hierarchical attention networks for thread summarization. The model draws on the recent development of neural attention mechanisms to build sentence and thread representations and use them for summarization. Our results indicate that the proposed approach can outperform a range of competitive baselines. Further, a redundancy removal step is crucial for achieving outstanding results.  % Online discussion forums embody large amounts of information within discussion threads, forcing users to endure the time consuming process of reading an entire thread to comprehend the ongoing discussion.  % This study aims to create an automatic text summarizer for online forums.  % We present a preliminary study of Hierarchical Attention Networks  as an extractive summarizer, inspired by deep neural networks.  % The HAN model classifies each sentence to determine whether or not it is part of the summary.  % Further, the attention mechanism in HAN enables indication of salience of words or sentences.  % Our results indicate that it is possible to obtain a performance comparably similar to several baseline methods.  % Additionally, we contribute 600 more threads to the original forum thread dataset collected by Bhatia in 2014. 
  Website privacy policies are too long to read and difficult to understand. The over-sophisticated language makes privacy notices to be less effective than they should be. People become even less willing to share their personal information when they perceive the privacy policy as vague. This paper focuses on decoding vagueness from a natural language processing perspective. While thoroughly identifying the vague terms and their linguistic scope remains an elusive challenge, in this work we seek to learn vector representations of words in privacy policies using deep neural networks. The vector representations are fed to an interactive visualization tool  to test on their ability to discover syntactically and semantically related vague terms. The approach holds promise for modeling and understanding language vagueness.  
 	This paper describes a hypernym discovery system for our participation in the SemEval-2018 Task 9, which aims to discover the best  candidate hypernyms for input concepts or entities, given the search space of a pre-defined vocabulary. We introduce a neural network architecture for the concerned task and empirically study various neural network models to build the representations in latent space for words and phrases. The evaluated models include convolutional neural network, long-short term memory network, gated recurrent unit and recurrent convolutional neural network. We also explore different embedding methods, including word embedding and sense embedding for better performance.   	
 We investigate the incorporation of character-based word representations into a standard CNN-based relation extraction model. %.  We experiment with two common neural architectures,  %Convolutional Neural Networks  and Long Short-Term Memory ,  CNN and LSTM,  to learn word vector representations from character embeddings. Through a task on the BioCreative-V CDR corpus, extracting relationships between chemicals and diseases, we show that models exploiting the character-based word representations improve on models that do not  use this information, obtaining state-of-the-art result relative to previous neural approaches. 
     We present a study on reinforcement learning  from human bandit feedback for sequence-to-sequence learning, exemplified by the task of bandit neural machine translation . We investigate the reliability of human bandit feedback, and analyze the influence of reliability on the learnability of a reward estimator, and the effect of the quality of reward estimates on the overall RL task. Our analysis of cardinal  and ordinal  feedback shows that their intra- and inter-annotator $\alpha$-agreement is comparable. Best reliability is obtained for standardized cardinal feedback, and cardinal feedback is also easiest to learn and generalize from. Finally, improvements of over 1 BLEU can be obtained by integrating a regression-based reward estimator trained on cardinal feedback for 800 translations into RL for NMT. This shows that RL is possible even from small amounts of fairly reliable human feedback, pointing to a great potential for applications at larger scale. 
 Convolutional neural networks are modern models that are very efficient in  many classification tasks. They were originally created for image processing purposes. Then some trials were performed to use them in different domains like natural language processing. The artificial intelligence systems  are very often based on embedded systems with constraints on memory, power consumption etc. Therefore convolutional neural network because of its memory capacity should be reduced to be mapped to given hardware.     In this paper, results are presented of compressing the efficient convolutional neural networks for sentiment analysis. The main steps are quantization and pruning processes. The method responsible for mapping compressed network to FPGA and results of this implementation are presented. The described simulations showed that 5-bit width is enough to have no drop in accuracy from floating point version of the network. Additionally, significant memory footprint reduction was achieved .  
   Machine translation systems require semantic knowledge and grammatical understanding.  Neural machine translation  systems often assume this information is captured by an attention mechanism and a decoder that ensures fluency.  Recent work has shown that incorporating explicit syntax alleviates the burden of modeling both types of knowledge.  However, requiring parses is expensive and does not explore the question of what syntax a model needs during translation.  To address both of these issues we introduce a model that simultaneously translates while inducing dependency trees.  In this way, we leverage the benefits of structure while investigating what syntax NMT must induce to maximize performance.  We show that our dependency trees are 1. language pair dependent and 2. improve translation quality. 
 % btzhang version The task of multi-image cued story generation, such as visual storytelling dataset  challenge, is to compose multiple coherent sentences from a given sequence of images.  The main difficulty is how to generate image-specific sentences within the context of overall images.  Here we propose a deep learning network model, GLAC Net, that generates visual stories by combining global-local  attention and context cascading mechanisms.  The model incorporates two levels of attention, i.e., overall encoding level and image feature level, to construct image-dependent sentences. While standard attention configuration needs a large number of parameters, the GLAC Net implements them in a very simple way via hard connections from the outputs of encoders or image features onto the sentence generators.  The coherency of the generated story is further improved by conveying  the information of the previous sentence to the next sentence serially.  We evaluate the performance of the GLAC Net on the visual storytelling dataset  and achieve very competitive results compared to the state-of-the-art techniques. Our code and pre-trained models are available here\footnote{\url{https://github.com/tkim-snu/GLACNet}}.  % == Previous version %Multi-image-cued story generation task is to generate multiple-sentence stories from the given sequence of images. %It is so challenging that it needs generating appropriate sentences on each image within the overall context. %In this work, we propose deep learning models to generate story-like sentences from the given image sequence with global-local  attention and context cascading mechanism. %For image-specific appropriateness of them, we develop dual resolution-level attentions on overall encoding level and image feature level. %While standard attention configuration needs large number of parameters, we implement them in a very simple way via hard connections from the outputs of encoders or image features onto the sentence generators. %To improve the coherency, we design models to convey the information of the previous sentence to the next sentence generation serially. %We perform experiments with visual storytelling dataset , they show competitive results with the state-of-the-arts. %It shows the effectiveness of our models.  
 	Despite impressive progress in high-resource settings, Neural Machine Translation  still struggles in low-resource and out-of-domain scenarios, often failing to match the quality of phrase-based translation. 	We propose a novel technique that combines back-translation and multilingual NMT to improve performance in these difficult cases. 	Our technique trains a single model for both directions of a language pair, allowing us to back-translate source or target monolingual data without requiring an auxiliary model. 	We then continue training on the augmented parallel data, enabling a cycle of improvement for a single model that can incorporate any source, target, or parallel data to improve both translation directions. 	As a byproduct, these models can reduce training and deployment costs significantly compared to uni-directional models. 	Extensive experiments show that our technique outperforms standard back-translation in low-resource scenarios, improves quality on cross-domain tasks, and effectively reduces costs across the board. 
  In this paper, we propose several advances to the existing Neural Belief Tracking  framework . Firstly, we show that the  can be learned automatically, eliminating the last rule-based component from this statistical Dialogue State Tracking  framework. Subsequently, we investigate several different NBT model setups to facilitate the training of  which can operate over different dialogue domains and different languages. In our evaluation over several DST datasets, we show that this model achieves competitive performance and provides a robust framework for bootstrapping DST models for new domains/languages.      
 Sentence matching is widely used in various natural language tasks such as natural language inference, paraphrase identification, and question answering. For these tasks, understanding logical and semantic relationship between two sentences is required but it is yet challenging. Although attention mechanism is useful to capture the semantic relationship and to properly align the elements of two sentences, previous methods of attention mechanism simply use a summation operation which does not retain original features enough. Inspired by DenseNet, a densely connected convolutional network, we propose a densely-connected co-attentive recurrent neural network, each layer of which uses concatenated information of attentive features as well as hidden features of all the preceding recurrent layers. It enables preserving the original and the co-attentive feature information from the bottommost word embedding layer to the uppermost recurrent layer. To alleviate the problem of an ever-increasing size of feature vectors due to dense concatenation operations, we also propose to use an autoencoder after dense concatenation. We evaluate our proposed architecture on highly competitive benchmark datasets related to sentence matching. Experimental results show that our architecture, which retains recurrent and attentive features, achieves state-of-the-art performances for  %all   the tasks. 
  We investigate the use of different syntactic dependency representations in a neural relation classification task and compare the CoNLL, Stanford Basic and Universal Dependencies schemes. We further compare with a syntax-agnostic approach and perform an error analysis in order to gain a better understanding of the results. 
   OpenNMT is an open-source toolkit for neural machine translation   .  The system prioritizes efficiency, modularity, and   extensibility with the goal of supporting NMT research into model   architectures, feature representations, and source modalities, while   maintaining competitive performance and reasonable training   requirements. The toolkit consists of modeling and translation   support, as well as detailed pedagogical documentation about the   underlying techniques. OpenNMT has been used in several production   MT systems, modified for numerous research papers, and is   implemented across several deep learning frameworks. 
 We propose a lightly-supervised approach for information extraction, in particular named entity classification, which combines the benefits of traditional bootstrapping, i.e., use of limited annotations and interpretability of extraction patterns, with the robust learning approaches proposed in representation learning. Our algorithm iteratively learns custom embeddings for both the multi-word entities to be extracted and the patterns that match them from a few example entities per category. We demonstrate that this representation-based  approach outperforms three other state-of-the-art bootstrapping approaches on two datasets: CoNLL-2003 and OntoNotes.  Additionally, using these embeddings, our approach outputs a globally-interpretable model consisting of a  decision list, by ranking patterns based on their proximity to the average entity embedding in a given class. We show that this interpretable model performs close to our complete bootstrapping model, proving  that representation learning can be used to produce interpretable models with small loss in performance.  
   We propose an adversarial learning approach for generating multi-turn dialogue responses.   Our proposed framework, hredGAN, is based on conditional generative adversarial   networks . The GAN's generator is a modified hierarchical recurrent encoder-decoder network     and the discriminator is a word-level bidirectional RNN that shares context and word embeddings with the generator.    During inference, noise samples conditioned on the dialogue history are used to perturb   the generator's latent space to generate several possible responses.    The final response is the one ranked best by the discriminator. The hredGAN shows improved performance    over existing methods:  it generalizes better than    networks trained using only the log-likelihood criterion, and  it generates longer,    more informative and more diverse responses with high utterance and topic relevance even    with limited training data. This improvement is demonstrated on the Movie triples and   Ubuntu dialogue datasets using both automatic and human evaluations. 
     In this work, we propose an adversarial learning method for reward estimation in reinforcement learning  based task-oriented dialog models. Most of the current RL based task-oriented dialog systems require the access to a reward signal from either user feedback or user ratings. Such user ratings, however, may not always be consistent or available in practice. Furthermore, online dialog policy learning with RL typically requires a large number of queries to users, suffering from sample efficiency problem. To address these challenges, we propose an adversarial learning method to learn dialog rewards directly from dialog samples. Such rewards are further used to optimize the dialog policy with policy gradient based RL. In the evaluation in a restaurant search domain, we show that the proposed adversarial dialog learning method achieves advanced dialog success rate comparing to strong baseline methods. We further discuss the covariate shift problem in online adversarial dialog learning and show how we can address that with partial access to user feedback. 
 We present an empirical analysis of the state-of-the-art systems for referring expression recognition -- the task of identifying the object in an image referred to by a natural language expression -- with the goal of gaining insight into how these systems reason about language and vision. Surprisingly, we find strong evidence that even sophisticated and linguistically-motivated models for this task may ignore the linguistic structure, instead relying on shallow correlations introduced by unintended biases in the data selection and annotation process. For example, we show that a system trained and tested on the input image  can achieve a precision of 71.2\% in top-2 predictions. Furthermore, a system that predicts only the  given the input can achieve a precision of 84.2\% in top-2 predictions. These surprisingly positive results for what should be deficient prediction scenarios suggest that careful analysis of what our models are learning -- and further, how our data is constructed -- is critical as we seek to make substantive progress on grounded language tasks. 
 Lack of text data has been the major issue on code-switching language modeling. In this paper, we introduce multi-task learning based language model which shares syntax representation of languages to leverage linguistic information and tackle the low resource data issue. Our model jointly learns both language modeling and Part-of-Speech tagging on code-switched utterances. In this way, the model is able to identify the location of code-switching points and improves the prediction of next word. Our approach outperforms standard LSTM based language model, with an improvement of 9.7\% and 7.4\% in perplexity on SEAME Phase I and Phase II dataset respectively.  
 This paper describes the submissions of the ``Marian'' team to the WNMT 2018 shared task. We investigate combinations of teacher-student training, low-precision matrix products, auto-tuning and other methods to optimize the Transformer model on GPU and CPU. By further integrating these methods with the new averaging attention networks, a recently introduced faster Transformer variant, we create a number of high-quality, high-performance models on the GPU and CPU, dominating the Pareto frontier for this shared task. 
 We examine how various types of noise in the parallel training data impact the quality of neural machine translation systems. We create five types of artificial noise and analyze how they degrade performance in neural and statistical machine translation. We find that neural models are generally more harmed by noise than statistical models. For one especially egregious type of noise they learn to just copy the input sentence. 
 This paper investigates the ability of artificial neural networks to judge the grammatical acceptability of a sentence, with the goal of testing their linguistic competence.   We introduce the Corpus of Linguistic Acceptability , a set of 10,657 English sentences labeled as grammatical or ungrammatical from published linguistics literature. As baselines, we train several recurrent neural network models on acceptability classification, and find that our models outperform unsupervised models by Lau et al.~ on CoLA.  Error-analysis on specific grammatical phenomena reveals that both Lau et al.'s models and ours learn systematic generalizations like subject-verb-object order. However, all models we test perform far below human level on a wide range of grammatical constructions.  
     Multi-relational semantic similarity datasets define the semantic relations between two short texts in multiple ways, e.g., similarity, relatedness, and so on. Yet, all the systems to date designed to capture such relations target one relation at a time. We propose a multi-label transfer learning approach based on LSTM to make predictions for several relations simultaneously and aggregate the losses to update the parameters. This multi-label regression approach jointly learns the information provided by the multiple relations, rather than treating them as separate tasks. Not only does this approach outperform the single-task approach and the traditional multi-task learning approach, but it also achieves state-of-the-art performance on all but one relation of the Human Activity Phrase dataset. 
 	 Intelligent personal assistant systems with either text-based or voice-based conversational interfaces are becoming increasingly popular around the world. Retrieval-based conversation models have the advantages of returning fluent and informative responses. Most existing studies in this area are on open domain ``chit-chat'' conversations or task / transaction oriented conversations. More research is needed for information-seeking conversations. There is also a lack of modeling external knowledge beyond the dialog utterances among current conversational models. In this paper, we propose a learning framework on the top of deep neural matching networks that leverages external knowledge for response ranking in information-seeking conversation systems. We  incorporate external knowledge into deep neural models with pseudo-relevance feedback and QA correspondence knowledge distillation. Extensive experiments with three information-seeking conversation data sets including both open benchmarks and commercial data show that, our methods outperform various baseline methods including several deep text matching models and the state-of-the-art method on response selection in multi-turn conversations. We also perform analysis over different response types, model variations and ranking examples. Our models and research findings provide new insights on how to utilize external knowledge with deep neural models for response selection and have implications for the design of the next generation of information-seeking conversation systems. 
 We propose an end-to-end model based on convolutional and recurrent neural networks for speech enhancement. Our model is purely data-driven and does not make any assumptions about the type or the stationarity of the noise. In contrast to existing methods that use multilayer perceptrons , we employ both convolutional and recurrent neural network architectures. Thus, our approach allows us to exploit local structures in both the frequency and temporal domains. By incorporating prior knowledge of speech signals into the design of model structures, we build a model that is more data-efficient and achieves better generalization on both seen and unseen noise. Based on experiments with synthetic data, we demonstrate that our model outperforms existing methods, improving PESQ by up to 0.6 on seen noise and 0.64 on unseen noise.  
 Generating images from natural language is one of the primary applications of recent conditional generative models. Besides testing our ability to model conditional, highly dimensional distributions, text to image synthesis has many exciting and practical applications such as photo editing or computer-aided content creation. Recent progress has been made using Generative Adversarial Networks . This material starts with a gentle introduction to these topics and discusses the existent state of the art models. Moreover, I propose Wasserstein GAN-CLS, a new model for conditional image generation based on the Wasserstein distance which offers guarantees of stability. Then, I show how the novel loss function of Wasserstein GAN-CLS can be used in a Conditional Progressive Growing GAN. In combination with the proposed loss, the model boosts by $7.07\%$ the best Inception Score  of the models which use only the sentence-level visual semantics. The only model which performs better than the Conditional Wasserstein Progressive growing GAN is the recently proposed AttnGAN which uses word-level visual semantics as well. 
 Understanding and following directions provided by humans can enable robots to navigate effectively in unknown situations. We present \net,~ an end-to-end differentiable neural architecture for learning multi-modal navigation policies. \net~ maps natural language instructions as well as visual and depth inputs to locomotion primitives. \net~ processes instructions using an attention mechanism conditioned on its visual and depth input to focus on the relevant parts of the command while performing the navigation task. Deep reinforcement learning  a sparse reward learns simultaneously the state representation, the attention function, and control policies. We evaluate our agent on a dataset of complex natural language directions that guide the agent through a rich and realistic dataset of simulated homes. We show that the \net~ agent learns to execute previously unseen instructions described with a similar vocabulary, and successfully navigates along paths not encountered during training. The agent shows 30\% improvement over a baseline model without the attention mechanism, with \devsuccess~ success rate at novel instructions. 
 During time-critical situations such as natural disasters, rapid classification of data posted on social networks by affected people is useful for humanitarian organizations to gain situational awareness and to plan response efforts. However, the scarcity of labeled data in the early hours of a crisis hinders machine learning tasks thus delays crisis response. In this work, we propose to use an inductive semi-supervised technique to utilize unlabeled data, which is often abundant at the onset of a crisis event, along with fewer labeled data. Specifically, we adopt a graph-based deep learning framework to learn an inductive semi-supervised model. We use two real-world crisis datasets from Twitter to evaluate the proposed approach. Our results show significant improvements using unlabeled data as compared to only using labeled data. 
 Attention networks in multimodal learning provide an efficient way to utilize given visual information selectively.  However, the computational cost to learn attention distributions for every pair of multimodal input channels is prohibitively expensive. To solve this problem, co-attention builds two separate attention distributions for each modality neglecting the interaction between multimodal inputs. In this paper, we propose bilinear attention networks  that find bilinear attention distributions to utilize given vision-language information seamlessly. BAN considers bilinear interactions among two groups of input channels, while low-rank bilinear pooling extracts the joint representations for each pair of channels. Furthermore, we propose a variant of multimodal residual networks to exploit eight-attention maps of the BAN efficiently. We quantitatively and qualitatively evaluate our model on visual question answering  and Flickr30k Entities datasets, showing that BAN significantly outperforms previous methods and achieves new state-of-the-arts on both datasets. 
  Recently, Visual Question Answering  has emerged as one of the most significant tasks in multimodal learning as it requires understanding both visual and textual modalities. Existing methods mainly rely on extracting image and question features to learn their joint feature embedding via multimodal fusion or attention mechanism. Some recent studies utilize external VQA-independent models to detect candidate entities or attributes in images, which serve as semantic knowledge complementary to the VQA task. However, these candidate entities or attributes might be unrelated to the VQA task and have limited semantic capacities. To better utilize semantic knowledge in images, we propose a novel framework to learn visual relation facts for VQA. Specifically, we build up a Relation-VQA  dataset based on the Visual Genome dataset via a semantic similarity module, in which each data consists of an image, a corresponding question, a correct answer and a supporting relation fact. A well-defined relation detector is then adopted to predict visual question-related relation facts. We further propose a multi-step attention model composed of visual attention and semantic attention sequentially to extract related visual knowledge and semantic knowledge. We conduct comprehensive experiments on the two benchmark datasets, demonstrating that our model achieves state-of-the-art performance and verifying the benefit of considering visual relation facts.     
 In the past few years, consumer review sites have become the main target of , where fictitious opinions or reviews are deliberately written to sound authentic. Most of the existing work to detect the deceptive reviews focus on building supervised classifiers based on syntactic and lexical patterns of an opinion. With the successful use of Neural Networks on various classification applications, in this paper, we propose  a system that for the first time augments and adopts Generative Adversarial Networks  for a text classification task, in particular, detecting deceptive reviews.  %we propose an approach called  that augments Generative Adversarial Networks  to detect deceptive opinion spam. %In this paper, we propose an approach based on the Generative Adversarial Networks , which we call .   Unlike standard GAN models which have a single Generator and Discriminator model,  uses two discriminator models and one generative model. The generator is modeled as a stochastic policy agent in reinforcement learning , and the discriminators use Monte Carlo search algorithm to estimate and pass the intermediate action-value as the RL reward to the generator.  Providing the generator model with two discriminator models avoids the mod collapse issue by learning from both distributions of truthful and deceptive reviews. Indeed, our experiments show that using two discriminators provides  high stability, which is a known issue for GAN architectures.  While  is built upon a , known for less accuracy, our evaluation results on a dataset of TripAdvisor hotel reviews show the same performance in terms of accuracy as of the state-of-the-art approaches that apply supervised machine learning.  These results indicate that GANs can be effective for text classification tasks. Specifically,  is effective at detecting deceptive reviews. 
 % In this paper, we propose the Interactive Text2Pickup  network for human-robot collaboration which enables an effective interaction with a human user despite the ambiguity in user's commands.  % We focus on the task where a robot is expected to pick up an object instructed by a human,  and to interact with the human when the given instruction is vague. %  The proposed network understands the command from the human user and estimates the position of the desired object first. % To handle the inherent ambiguity in human language commands, a suitable question which can resolve the ambiguity is generated. % The user's answer to the question is combined with the initial command and given back to the network, resulting in more accurate estimation. % The experiment results show that given unambiguous commands, the proposed method can estimate the position of the requested object with an accuracy of 98.49\% based on our test dataset. % Given ambiguous language commands, we show that the accuracy of the pick up task increases by 1.94 times after incorporating the information obtained from the interaction.   
  The number of missing people  greatly increases in recent years.  It is a serious worldwide problem, and finding the missing people consumes a large amount of social resources. In tracking and finding these missing people, timely data gathering and analysis actually play an important role. %It is a worldwide problem, which has a negative impact on the society and consumes a large amount of social properties and resources.  %The difficulty in solving the problem is the ability to get and analyze the data timely.  With the development of social media, information about missing people can get propagated through the web very quickly, which provides a promising way to solve the problem. The information in online social media is usually of heterogeneous categories, involving both complex social interactions and textual data of diverse structures. Effective fusion of these different types of information for addressing the missing people identification problem can be a great challenge. %it provides a novel way to help solve the problem of missing people through detecting and analyzing a large amount of missing people related information.  %Existing supervised learning methods cannot be directly applied to this problem due to the distinct characteristics of the social media data. First, the complex word embedding features make the textual information form a complex data structure, which is difficult for traditional learning algorithms to effectively handle. %Second, complex social interactions with high-dimensional feature space present great computational challenges. In the meanwhile, multi-instance learning provides a good way to help analyze the distinct characteristics of the social media data. And social sciences theories such as homophily have been well established and achieved success in various social media mining applications.  Motivated by the multi-instance learning problem and existing social science theory of ``homophily'', in this paper, we propose a novel $r$-instance  learning model. In the model, textual content information is analyzed in a new perspective based on the complex data structure, which is derived from word embedding methods. Together with the structural information, the textual information is fused in a unified way in the RI learning model based on a new mathematical optimization framework. %, which analyzes the content in a novel perspective and incorporates the content and structure information into a unified model for the missing people problem. %In particular, a new mathematical optimization framework is proposed to integrate the network structure into content modeling. Experimental results on a real-world dataset demonstrate the effectiveness of our proposed framework in detecting missing people information. 
   What is an effective expression that draws laughter from human beings? In the present paper, in order to consider this question from an academic standpoint, we generate an image caption that draws a ``laugh" by a computer. A system that outputs funny captions based on the image caption proposed in the computer vision field  is constructed. Moreover, we also propose the Funny Score, which flexibly gives weights according to an evaluation database. The Funny Score more effectively brings out  ``laughter" to optimize a model. In addition, we build a self-collected BoketeDB, which contains a theme  and funny caption  posted on ``Bokete", which is an image Ogiri\footnote{Ogiri is a simple game that involves providing funny answers to themes.} website. In an experiment, we use BoketeDB to verify the effectiveness of the proposed method by comparing the results obtained using the proposed method and those obtained using MS COCO Pre-trained CNN+LSTM, which is the baseline and idiot created by humans. We refer to the proposed method, which uses the BoketeDB pre-trained model, as the Neural Joking Machine . %We display the results of NJM to evaluations and prominent image databases acquired by ``Bokete" posting.  
  The AI2 Reasoning Challenge , a new benchmark dataset for question answering  has been recently released. ARC only contains natural science questions authored for human exams, which are hard to answer and require advanced logic reasoning. On the ARC Challenge Set, existing state-of-the-art QA systems fail to significantly outperform random baseline, reflecting the difficult nature of this task. In this paper, we propose a novel framework for answering science exam questions, which mimics human solving process in an open-book exam. To address the reasoning challenge, we construct contextual knowledge graphs respectively for the question itself and supporting sentences. Our model learns to reason with neural embeddings of both knowledge graphs. Experiments on the ARC Challenge Set show that our model outperforms the previous state-of-the-art QA systems.  
  In this paper, an architecture based on Long Short-Term Memory Networks has been proposed for the text-independent scenario which is aimed to capture the temporal speaker-related information by operating over traditional speech features. For speaker verification, at first, a background model must be created for speaker representation. Then, in enrollment stage, the speaker models will be created based on the enrollment utterances. For this work, the model will be trained in an end-to-end fashion to combine the first two stages. The main goal of end-to-end training is the model being optimized to be consistent with the speaker verification protocol. The end-to-end training jointly learns the background and speaker models by creating the representation space. The LSTM architecture is trained to create a discrimination space for validating the match and non-match pairs for speaker verification. The proposed architecture demonstrate its superiority in the text-independent compared to other traditional methods.   
 The fundamental frequency  contour of speech is a key aspect to represent speech prosody that finds use in speech and spoken language analysis such as voice conversion and speech synthesis as well as speaker and language identification.   This work proposes new methods to estimate the $F0$ contour of speech using deep neural networks  and recurrent neural networks . They are trained using supervised learning with the ground truth of $F0$ contours. The latest prior research addresses this problem first as a frame-by-frame-classification problem followed by sequence tracking using deep neural network hidden Markov model  hybrid architecture. This study, however, tackles the problem as a regression problem instead, in order to obtain $F0$ contours with higher frequency resolution from clean and noisy speech.  Experiments using  corpus contaminated with additive noise  show the proposed method improves gross pitch error  by more than 25 \% at signal-to-noise ratios  between -10 dB and +10 dB as compared with one of the most noise-robust $F0$ trackers, PEFAC. Furthermore, the performance on fine pitch error  is improved by approximately 20 \% against a state-of-the-art DNN-HMM-based approach. 
 Children speech recognition is challenging mainly due to the inherent high variability in children's physical and articulatory characteristics and expressions. This variability manifests in both acoustic constructs and linguistic usage due to the rapidly changing developmental stage in children's life. Part of the challenge is due to the lack of large amounts of available children speech data for efficient modeling.  This work attempts to address the key challenges using transfer learning from adult's models to children's models in a Deep Neural Network  framework for children's Automatic Speech Recognition  task evaluating on multiple children's speech corpora with a large vocabulary. The paper presents a systematic and an extensive analysis of the proposed transfer learning technique considering the key factors affecting children's speech recognition from prior literature. %This paper presents a systematic and an extensive analysis of children's speech in context of Automatic Speech Recognition  in a Deep Neural Network  transfer learning framework.  are presented on  comparisons of earlier GMM-HMM and the newer DNN Models,  effectiveness of standard adaptation techniques versus transfer learning,  various adaptation configurations in tackling the variabilities present in children speech, in terms of  acoustic spectral variability, and  pronunciation variability and linguistic constraints. Our  spans over  number of DNN model parameters ,  amount of adaptation data,  ages of children,  age dependent-independent adaptation.  Finally, we provide  on  the favorable strategies over various aforementioned - analyzed parameters, and  potential future research directions and relevant challenges/problems persisting in DNN based ASR for children's speech.  %In this paper, we present a deep neural network transfer learning method from adult acoustic models to children models for speech recognition. The study addresses tackling the variabilities present in children speech  in terms of acoustic spectral variability, and  in terms of pronunciation variability and linguistic constraints. It further addresses the issue of data sparsity in the children's domain. An extensive analysis is carried out to assess the adaptation performance based on amount of children's data versus the number of DNN model parameters. We demonstrate the effectiveness of the proposed technique on a large vocabulary continuous speech recognition. Results suggest that the proposed technique provides significant improvements over traditional ASR systems trained on children speech. 
 Feed-forward networks are widely used in cross-modal applications to bridge modalities by mapping distributed vectors of one modality to the other, or to a shared space. The predicted vectors are then used to perform e.g., retrieval or labeling. Thus, the success of the whole system relies on the ability of the mapping to make the neighborhood structure  of the predicted vectors akin to that of the target vectors. However, whether this is achieved has not been investigated yet. Here, we propose a new similarity measure and two ad hoc experiments to shed light on this issue. In three cross-modal benchmarks we learn a large number of language-to-vision and vision-to-language neural network mappings  using a rich diversity of image and text features and loss functions. Our results reveal that, surprisingly, the neighborhood structure of the predicted vectors consistently resembles more that of the input vectors than that of the target vectors. In a second experiment, we further show that untrained nets do not significantly disrupt the neighborhood  structure of the input vectors. 
  %During the last decade, the fields of signal processing have drastically improved with deep learning. However areas of affecting computing such as the emotional speech synthesis or emotion recognition from spoken language remains challenging.  %In this paper, we investigate the possibility to use a neural Automatic Speech Recognition  as a feature extractor for emotion recognition. The mapping modeled by the ASR between audio and text modalities of spoken language contains useful features for emotion representation. We show that these features perform better than the eGeMAPS feature set to predict valence and arousal emotional dimensions. We also present a exploratory study on the relationship between first layers  and last layers  of the neural ASR and valence/arousal.  During the last decade, the applications of signal processing have drastically improved with deep learning. However areas of affecting computing such as emotional speech synthesis or emotion recognition from spoken language remains challenging. In this paper, we investigate the use of a neural Automatic Speech Recognition  as a feature extractor for emotion recognition.  We show that these features outperform the eGeMAPS feature set to predict the valence and arousal emotional dimensions, which means that the audio-to-text mapping learned by the ASR system contains information related to the emotional dimensions in spontaneous speech. We also examine the relationship between first layers  and last layers  of the ASR and valence/arousal. 
   The process of translation is ambiguous, in that there are typically many valid translations for a given sentence.   This gives rise to significant variation in parallel corpora, however, most current models of machine translation do not account for this variation, instead treating the problem as a deterministic process.   To this end, we present a deep generative model of machine translation which incorporates a chain of latent variables, in order to account for local lexical and syntactic variation in parallel corpora. %  There is lots of variation in machine translation training data because %  a source sentence has several adequate translations. While this fact % is acknowledged by the community in the design of multi-reference evaluation % metrics, little effort has been invested into modelling this variation.   % We present a stochastic decoder for neural machine translation  that   % contains a continuous latent variable for each target word.   % The model is a stochastic recurrent neural network    % that is implemented as a deep generative model . Through the latent variables   % it is able to capture variation   % at the word level and thus account for local lexical and syntactic variation   % in the translation data.   We provide an in-depth analysis of the pitfalls encountered in   variational inference for training deep generative models.    Experiments on several different language pairs demonstrate   that the model   consistently improves over strong baselines. 
 Multimodal sensory data resembles the form of information perceived by humans for learning, and are easy to obtain in large quantities. Compared to unimodal data, synchronization of concepts between modalities in such data provides supervision for disentangling the underlying explanatory factors of each modality. Previous work leveraging multimodal data has mainly focused on retaining only the modality-invariant factors while discarding the rest.  In this paper, we present a partitioned variational autoencoder  and several training objectives to learn disentangled representations, which encode not only the shared factors, but also modality-dependent ones, into separate latent variables. Specifically, PVAE integrates a variational inference framework and a multimodal generative model that partitions the explanatory factors and conditions only on the relevant subset of them for generation. We evaluate our model on two parallel speech/image datasets, and demonstrate its ability to learn disentangled representations by qualitatively exploring within-modality and cross-modality conditional generation with semantics and styles specified by examples. For quantitative analysis, we evaluate the classification accuracy of automatically discovered semantic units. Our PVAE can achieve over 99\% accuracy on both modalities.  
 %% Text of abstract We perform text normalization, i.e. the transformation of words from the written to the spoken form, using a memory augmented neural network. With the addition of dynamic memory access and storage mechanism, we present a neural architecture that will serve as a language-agnostic text normalization system while avoiding the kind of unacceptable errors made by the LSTM-based recurrent neural networks. By successfully reducing the frequency of such mistakes, we show that this novel architecture is indeed a better alternative. Our proposed system requires significantly lesser amounts of data, training time and compute resources. Additionally, we perform data up-sampling, circumventing the data sparsity problem in some semiotic classes, to show that sufficient examples in any particular class can improve the performance of our text normalization system. Although a few occurrences of these errors still remain in certain semiotic classes, we demonstrate that memory augmented networks with meta-learning capabilities can open many doors to a superior text normalization system. 
 Sequence to sequence learning models still require several days to reach state of the art performance on large benchmark datasets using a single machine. This paper  shows that reduced precision and large batch training can speedup training by nearly 5x on a single 8-GPU machine with careful tuning and implementation.\footnote{Our implementation is available at:\\  \url{https://www.github.com/pytorch/fairseq}} % \url{https://github.com/pytorch/fairseq}} On WMT'14 English-German translation, we match the accuracy of  in under 5 hours when training on 8 GPUs and we obtain a new state of the art of 29.3 BLEU after training for 85 minutes on 128 GPUs. We further improve these results to 29.8 BLEU by training on the much larger Paracrawl dataset. On the WMT'14 English-French task, we obtain a state-of-the-art BLEU of 43.2 in 8.5 hours on 128 GPUs. %We also report results training on the very large Paracrawl dataset. % Our improvements also benefit accuracy and we redefine the state-of-the-art to 43.2 BLEU on the popular WMT'14 English-French benchmark in under 9 hours on 128 GPUs. We also report results training on the very large Paracrawl dataset.  %On a single machine, we  
 Neural machine translation  is a deep learning based approach for machine translation, which yields the state-of-the-art translation performance in scenarios where large-scale parallel corpora are available. Although the high-quality and domain-specific translation is crucial in the real world, domain-specific corpora are usually scarce or nonexistent, and thus vanilla NMT performs poorly in such scenarios. Domain adaptation that leverages both out-of-domain parallel corpora as well as monolingual corpora for in-domain translation, is very important for domain-specific translation. In this paper, we give a comprehensive survey of the state-of-the-art domain adaptation techniques for NMT. 
 Recently, neural machine translation has achieved remarkable progress by introducing well-designed deep neural networks into its encoder-decoder framework. % From the optimization perspective,  residual connections are adopted to improve learning performance for both encoder and decoder in most of these deep architectures, and advanced attention connections are applied as well.  % Inspired by the success of the DenseNet model in computer vision problems, in this paper, we propose a densely connected NMT architecture  that is able to train more efficiently for NMT.  % The proposed DenseNMT not only allows dense connection in creating new features for both encoder and decoder, but also uses the dense attention structure to improve attention quality.  % Our experiments on multiple datasets show that  DenseNMT structure is more competitive and efficient.  
   In this paper, we present a neural model for generating short stories from image sequences, which extends the image description model by Vinyals et al.~.    This extension relies on an encoder LSTM to compute a context vector of each story from the image sequence.    This context vector is used as the first state of multiple independent decoder LSTMs, each of which generates the portion of the story corresponding to each image in the sequence by taking the image embedding as the first input.    Our model showed competitive results with the METEOR metric and human ratings in the internal track of the Visual Storytelling Challenge 2018. 
 %As the development of social networks, fake news greatly emerges for commercial and political purposes. People can also reach fake news easily and unboundedly share the content without third party filtering, fact-checking, or editorial judgment. Before the France national elections and the United States president election in 2016, fake news spread widely on social networks, such as the Facebook and the news website. The fake news are probably published to smear the opponents or support certain campaigner. The misleading or wrong information in fake news are always written to inflame sentiment, and could cause great influence on voters. Hence, it's essential to identify these fake news timely and accurately to prevent and reduce the harm. However, it's a very challenging task mainly because fake news are written by humans, which are hard for traditional machine learning methods to capture the abnormality and inconsistent facts in fake news. In this paper, we put great efforts on analyzing the fake news data. Many useful explicit features are extracted from both texts and images. We also exploit multiple convolutional layers to learn the latent features from texts and images. Finally, we integrate the explicit and latent features into a unified space to model the real and fake news information. Then we propose a convolutional neural network model to identify the fake news from tens of thousands of news. The integrable and compatible model performs very well. The experimental results show that our model outperforms many competitive baseline methods. With the development of social networks, fake news for various commercial and political purposes has been appearing in large numbers and gotten widespread in the online world. With deceptive words, people can get infected by the fake news very easily and will share them without any fact-checking. For instance, during the 2016 US president election, various kinds of fake news about the candidates widely spread through both official news media and the online social networks. These fake news is usually released to either smear the opponents or support the candidate on their side. The erroneous information in the fake news is usually written to motivate the voters' irrational emotion and enthusiasm. Such kinds of fake news sometimes can bring about devastating effects, and an important goal in improving the credibility of online social networks is to identify the fake news timely. In this paper, we propose to study the ``fake news detection'' problem. Automatic fake news identification is extremely hard, since pure model based fact-checking for news is still an open problem, and few existing models can be applied to solve the problem. With a thorough investigation of a fake news data, lots of useful explicit features are identified from both the text words and images used in the fake news. Besides the explicit features, there also exist some hidden patterns in the words and images used in fake news, which can be captured with a set of latent features extracted via the multiple convolutional layers in our model. A model named as TI-CNN  is proposed in this paper. By projecting the explicit and latent features into a unified feature space, TI-CNN is trained with both the text and image information simultaneously. Extensive experiments carried on the real-world fake news datasets have demonstrate the effectiveness of TI-CNN in solving the fake new detection problem. 
 Attention is typically used to select informative sub-phrases that are used for prediction. This paper investigates the novel use of attention as a form of feature augmentation, i.e, casted attention. We propose Multi-Cast Attention Networks , a new attention mechanism and general model architecture for a potpourri of ranking tasks in the conversational modeling and question answering domains. Our approach performs a series of soft attention operations, each time casting a scalar feature upon the inner word embeddings. The key idea is to provide a real-valued hint  to a subsequent encoder layer and is targeted at improving the representation learning process. There are several advantages to this design, e.g., it allows an arbitrary number of attention mechanisms to be casted, allowing for multiple attention types  and attention variants  to be executed simultaneously. This not only eliminates the costly need to tune the nature of the co-attention layer, but also provides greater extents of explainability to practitioners. Via extensive experiments on four well-known benchmark datasets, we show that MCAN achieves state-of-the-art performance. On the Ubuntu Dialogue Corpus, MCAN outperforms existing state-of-the-art models by $9\%$. MCAN also achieves the best performing score to date on the well-studied TrecQA dataset. 
 In this paper, we propose a method for obtaining sentence level embeddings in documents. While the problem of obtaining word level embeddings is very well studied, in this paper we propose a novel method for obtaining sentence level embeddings. This is obtained by a simple method in the context of solving the paraphrase generation task.  If we use a sequential encoder-decoder model for generating paraphrase, we would like the generated paraphrase to be semantically close to the original sentence. One way to ensure this is by adding constraints for true paraphrase embeddings to be close and unrelated paraphrase candidate sentence embeddings to be far. This is ensured by using a sequential pair-wise discriminator that shares weights with the encoder that is trained with a suitable loss function. Our loss function penalizes paraphrase sentence embedding distances from being far. This loss is used in combination with a  sequential encoder-decoder network. Our method is also validated by evaluating the embedding thus obtained for a sentiment analysis task. The proposed method results in semantic embeddings and outperforms the state-of-the-art on the paraphrase generation and sentiment analysis task on standard datasets. These results are also shown to be statistically significant.  %In this paper, we propose a method for obtaining sentence level embeddings in documents. While the problem of obtaining word level embeddings is very well studied, in this paper we propose a novel method for obtaining sentence level embeddings. This is obtained by a simple method in the context of solving the paraphrase generation task. If we use a sequential encoder-decoder model for generating paraphrases, we need to ensure that our embeddings are closer to the true paraphrase embeddings and farther from the unrelated ones. % If we use a sequential encoder-decoder model for generating paraphrase, one way to ensure the solution of the problem is by ensuring that true paraphrase embeddings are close and unrelated paraphrase candidate sentences are far. %This is done by using a sequential pair-wise discriminator that shares weights with the encoder and is trained with a loss function that penalizes paraphrase distances from being larger. This method is further validated by evaluating the embedding thus obtained on a sentiment analysis task. The proposed method results in semantic embeddings and outperforms the state-of-the-art on the paraphrase generation and sentiment analysis task on standard datasets. These results are also shown to be statistically significant. 
 Latent tree learning models represent sentences by composing their words according to an induced parse tree, all based on a downstream task. These models often outperform baselines which use  syntax trees to drive the composition order. This work contributes  a new latent tree learning model based on shift-reduce parsing, with competitive downstream performance and non-trivial induced trees, and  an analysis of the trees learned by our shift-reduce model and by a chart-based model. 
   Extraction of missing attribute values is to find values describing   an attribute of interest from a free text input. Most past related   work on extraction of missing attribute values work with a closed   world assumption with the possible set of values known   beforehand, or use dictionaries of values and hand-crafted features. How can we discover new attribute values that we have   never seen before? Can we do this with limited human annotation or   supervision? We study this problem in the context of product   catalogs that often have missing values for many attributes of   interest.    In this work, we leverage product profile information such as titles   and descriptions to discover missing values of product   attributes. We develop a novel deep tagging model OpenTag for this   extraction problem with the following contributions:  we   formalize the problem as a sequence tagging task, and propose a   joint model exploiting recurrent neural networks  to capture context and semantics, and   Conditional Random Fields  to enforce tagging consistency;    we develop a novel attention mechanism to provide interpretable   explanation for our model's decisions;  we propose a novel   sampling strategy exploring active learning to reduce the burden of   human annotation. OpenTag does not use any dictionary or hand-crafted features as in prior works. Extensive experiments in real-life datasets in   different domains show that OpenTag with our active learning strategy discovers new attribute   values from as few as $150$ annotated samples  with a high F-score of $83\%$,   outperforming state-of-the-art models.    
 Instructional Systems Design is the practice of creating of instructional experiences that make the acquisition of knowledge and skill more efficient, effective, and appealing~. %Most large institutions invest in resources to ensure their workforce possesses the necessary skills to do their jobs effectively. %In addition to the costs incurred in facilitating training, costs associated with sourcing and preparation of course material are also significant. Course designers can spend hours sifting through poorly catalogued resources that vary in format, content, and style. %Depending on the nature of the course material being prepared, up to 30\% of the cost can be associated with sourcing and organizing reference data that has been validated by subject matter experts for use in the preparation of course material.  %Depending on the nature of the course being prepared, Specifically in designing courses, an hour of training material can require between 30 to 500 hours of effort in sourcing and organizing reference data for use in just the preparation of course material. In this paper, we present the first system of its kind that helps reduce the effort associated with sourcing reference material and course creation. We present algorithms for document chunking and automatic generation of learning objectives from content, creating descriptive content metadata to improve content-discoverability. Unlike existing methods, the learning objectives generated by our system incorporate pedagogically motivated Bloom's verbs. We demonstrate the usefulness of our methods using real world data from the banking industry and through a live deployment at a large pharmaceutical company.  %. We also present details of a live deployment of our solution at a large pharmaceutical company.% Our cloud based solution enables efficient document retrieval which helps reduce the number of time consuming reviews required with subject-matter experts.  %instruction designers to search for reference material effectively.  %e present detailed experiments for each of our sub-systems using real world data from two industries - banking and pharmaceutical. %To the best of our knowledge we are the first to develop a  % and to the best  our knowledge we are the first to enable an automated   We develop methods for automatically segmenting existing course material and generating course objectives that can help instructional designers utilize existing resources better.  We demonstrate the usefulness of our methods using real courses from the Banking and Pharmaceutical industry.   
 Learning social media content is the basis of many real-world applications, including information retrieval and recommendation systems, among others. In contrast with previous works that focus mainly on single modal or bi-modal learning, we propose to learn social media content by fusing \underline{j}ointly \underline{t}extual, \underline{a}coustic, and \underline{v}isual information . Effective strategies are proposed to extract fine-grained features of each modality, that is, attBiGRU and DCRNN. We also introduce cross-modal fusion and attentive pooling techniques to integrate multi-modal information comprehensively. Extensive experimental evaluation conducted on real-world datasets demonstrates our proposed model outperforms the state-of-the-art approaches by a large margin. 
   This document contains the instructions for preparing a paper submitted   to COLING-2018 or accepted for publication in its proceedings. The document itself   conforms to its own specifications, and is therefore an example of   what your manuscript should look like. These instructions should be   used for both papers submitted for review and for final versions of   accepted papers. Authors are asked to conform to all the directions   reported in this document. 
 Most Semantic Role Labeling  approaches are supervised methods which require a significant amount of annotated corpus, and the annotation requires linguistic expertise. In this paper, we propose a Multi-Task Active Learning framework for Semantic Role Labeling with Entity Recognition  as the auxiliary task to alleviate the need for extensive data and use additional information from ER to help SRL. We evaluate our approach on Indonesian conversational dataset. Our experiments show that multi-task active learning can outperform single-task active learning method and standard multi-task learning. According to our results, active learning is more efficient by using 12\% less of training data compared to passive learning in both single-task and multi-task setting. We also introduce a new dataset for SRL in Indonesian conversational domain to encourage further research in this area\footnote{request to {research@kata.ai}}. 
 We introduce a scalable Bayesian preference learning method for identifying convincing arguments in the absence of gold-standard ratings or rankings. In contrast to previous work, we avoid the need for separate methods to perform quality control on training data, predict rankings and perform pairwise classification. Bayesian approaches are an effective solution when faced with sparse or noisy training data,  but have not previously been used to identify convincing arguments. One issue is scalability, which we address by developing a  stochastic variational inference method for Gaussian process  preference learning. We show how our method can be applied to predict argument convincingness from crowdsourced data,  outperforming the previous state-of-the-art, particularly when trained with small amounts of unreliable data.   We demonstrate how the Bayesian approach enables more effective active learning, thereby reducing the amount of data required to identify convincing arguments for new users and domains. While word embeddings are principally used with neural networks, our results show that word embeddings in combination with linguistic features also benefit GPs when predicting argument convincingness. 
   Understanding Affect from video segments has brought researchers from the language, audio and video domains together. Most of the current multimodal research in this area deals with various techniques to fuse the modalities, and mostly treat the segments of a video independently. Motivated by the work of  and , we present Relational Tensor Network architecture where we use the inter-modal interactions within a segment and also consider the sequence of segments in a video to model the inter-segment inter-modal interactions. We also generate rich representations of text and audio modalities by leveraging richer audio and linguistic context alongwith fusing fine-grained knowledge based polarity scores from text. We present the results of our model on CMU-MOSEI dataset and show that our model outperforms many baselines and state of the art methods for sentiment classification and emotion recognition.     
   This document describes the findings of the Second Workshop on Neural Machine Translation and Generation, held in concert with the annual conference of the Association for Computational Linguistics .   First, we summarize the research trends of papers presented in the proceedings, and note that there is particular interest in linguistic structure, domain adaptation, data augmentation, handling inadequate resources, and analysis of models.   Second, we describe the results of the workshop's shared task on efficient neural machine translation , where participants were tasked with creating NMT systems that are both accurate and efficient. 
     In this paper, we describe TextEnt, a neural network model that learns distributed representations of entities and documents directly from a knowledge base .     Given a document in a KB consisting of words and entity annotations, we train our model to predict the entity that the document describes and map the document and its target entity close to each other in a continuous vector space.     Our model is trained using a large number of documents extracted from Wikipedia.     The performance of the proposed model is evaluated using two tasks, namely fine-grained entity typing and multiclass text classification.     The results demonstrate that our model achieves state-of-the-art performance on both tasks.     The code and the trained representations are made available online for further academic research.   
 Multilingual machine translation addresses the task of translating between multiple source and target languages. We propose task-specific attention models, a simple but effective technique for improving the quality of sequence-to-sequence neural multilingual translation. Our approach seeks to retain as much of the parameter sharing generalization of NMT models as possible, while still allowing for language-specific specialization of the attention model to a particular language-pair or task. Our experiments on four languages of the Europarl corpus show that using a target-specific model of attention provides consistent gains in translation quality for all possible translation directions, compared to a model in which all parameters are shared. We observe improved translation quality even in the  low-resource zero-shot translation directions for which the model never saw explicitly paired parallel data. 
 Reading comprehension models are based on recurrent neural networks that sequentially process the document tokens. As interest turns to answering more complex questions over longer documents, sequential reading of large portions of text becomes a substantial bottleneck. Inspired by how humans use document structure, we propose a novel framework for reading comprehension. We represent documents as trees,  and model an agent that learns to interleave quick navigation through the document tree with more expensive answer extraction. %and model an agent that navigates through the tree to find relevant parts of the document before answering the question.  To encourage exploration of the document tree, we propose a new algorithm, based on Deep Q-Network , which strategically samples tree nodes at training time.  Empirically we find our algorithm  improves question answering performance compared to DQN and a strong information-retrieval  baseline, and that ensembling our model with the IR baseline results in further gains in performance. %Empirically, we find our algorithm  significantly improves navigation in documents compared to DQN both quantitatively and qualitatively. Moreover, ensembling our approach with an information-retrieval  method leads to substantial gains over the ensemble components.  
 Neural network models have shown promising results for text classification. However, these solutions are limited by their dependence on the availability of annotated data.   The prospect of leveraging resource-rich languages to enhance the text classification of resource-poor languages is fascinating. The performance on resource-poor languages can significantly improve if the resource availability constraints can be offset. To this end, we present a twin Bidirectional Long Short Term Memory  network with shared parameters consolidated by a contrastive loss function . The model learns the representation of resource-poor and resource-rich sentences in a common space by using the similarity between their assigned annotation tags. Hence, the model projects sentences with similar tags closer and those with different tags farther from each other. We evaluated our model on the classification tasks of sentiment analysis and emoji prediction for resource-poor languages - Hindi and Telugu and resource-rich languages - English and Spanish. Our model significantly outperforms the state-of-the-art approaches in both the tasks across all metrics. 
   We propose to learn acoustic word embeddings with temporal context for query-by-example  speech search. The temporal context includes the leading and trailing word sequences of a word. We assume that there exist spoken word pairs in the training database. We pad the word pairs with their original temporal context to form fixed-length speech segment pairs. We obtain the acoustic word embeddings through a deep convolutional neural network  which is trained on the speech segment pairs with a triplet loss. By shifting a fixed-length analysis window through the search content, we obtain a running sequence of embeddings. In this way, searching for the spoken query is equivalent to the matching of acoustic word embeddings. The experiments show that our proposed acoustic word embeddings learned with temporal context are effective in QbE speech search. They outperform the state-of-the-art frame-level feature representations and reduce run-time computation since no dynamic time warping is required in QbE speech search. We also find that it is important to have sufficient speech segment pairs to train the deep CNN for effective acoustic word embeddings. 
 We propose an ``end-to-end'' character-based recurrent neural network that extracts disease named entities from a Japanese medical text and simultaneously judges its modality as either positive or negative; i.e., the mentioned disease or symptom is affirmed or negated. The motivation to adopt neural networks is to learn effective lexical and structural representation features for Entity Recognition and also for Positive/Negative classification from an annotated corpora without explicitly providing any rule-based or manual feature sets. We confirmed the superiority of our method over previous char-based CRF or SVM methods in the results. 
  %Simultaneous translation poses significant unique challenges %as compared to normal machine translation. In this work, we propose several modifications to the existing Neural Machine translation framework to enable decoding without waiting for the entire source sequence. Our proposed methods achieve a loss of less than 2 BLEU points with a moderate delay in translation in four language pairs. We also propose changes to the training mechanism to further improve simultaneous translation performance, however these changes did not improve the quality. Although the new training methods do not improve existing performance, they   %In this paper   We address the problem of simultaneous translation by modifying the Neural MT decoder to operate with dynamically built encoder and attention. We propose a tunable agent which decides the best segmentation strategy for a user-defined BLEU loss and Average Proportion  constraint. Our agent outperforms previously proposed Wait-if-diff and Wait-if-worse agents  on BLEU with a lower latency. Secondly we proposed data-driven changes to Neural MT training to better match the incremental decoding framework.   
   A great proportion of sequence-to-sequence  models for Neural Machine Translation  adopt Recurrent Neural Network  to generate translation word by word following a sequential order. As the studies of linguistics have proved that language is not linear word sequence but sequence of complex structure, translation at each step should be conditioned on the whole target-side context. To tackle the problem, we propose a new NMT model that decodes the sequence with the guidance of its structural prediction of the context of the target sequence. Our model generates translation based on the structural prediction of the target-side context so that the translation can be freed from the bind of sequential order. Experimental results demonstrate that our model is more competitive compared with the state-of-the-art methods, and the analysis reflects that our model is also robust to translating sentences of different lengths and it also reduces repetition with the instruction from the target-side context for decoding.   % Human evaluation also shows that the translation of our model is more accurate and coherent, and also closer to the human translation. 
 Deep neural network models for Chinese zero pronoun resolution learn semantic information for zero pronoun and candidate antecedents, but tend to be short-sighted---they often make local decisions. They typically predict coreference chains between the zero pronoun and one single candidate antecedent one link at a time, while overlooking their long-term influence on future decisions. Ideally, modeling useful information of preceding potential antecedents is critical when later predicting zero pronoun-candidate antecedent pairs. In this study, we show how to integrate local and global decision-making by exploiting deep reinforcement learning models. With the help of the reinforcement learning agent, our model learns the policy of selecting antecedents in a sequential manner, where useful information provided by earlier predicted antecedents could be utilized for making later coreference decisions. Experimental results on OntoNotes 5.0 dataset show that our technique surpasses the state-of-the-art models. 
 Automatic resolution of rumours is a challenging task that can be broken down into smaller components that make up a pipeline, including rumour detection, rumour tracking and stance classification, leading to the final outcome of determining the veracity of a rumour. In previous work, these steps in the process of rumour verification have been developed as separate components where the output of one feeds into the next. We propose a multi-task learning approach that allows joint training of the main and auxiliary tasks, improving the  performance of rumour verification. We examine the connection between the dataset properties and the outcomes of the multi-task learning models used. 
 In this work, we propose a novel constituency parsing scheme. The model predicts a vector of real-valued scalars, named syntactic distances, for each split position in the input sentence. The syntactic distances specify the order in which the split points will be selected, recursively partitioning the input, in a top-down fashion. %The structure of the grammar tree is determined by the ranking induced by the syntactic distances. Compared to traditional shift-reduce parsing schemes, our approach is free from the potential problem of compounding errors, while being faster and easier to parallelize. Our model achieves competitive performance amongst single model, discriminative parsers in the PTB dataset and outperforms previous models in the CTB dataset. 
 Multilingual topic models enable crosslingual tasks by extracting consistent topics from multilingual corpora. Most models require parallel or comparable training corpora, which limits their ability to generalize. In this paper, we first demystify the knowledge transfer mechanism behind multilingual topic models by defining an alternative but equivalent formulation. Based on this analysis, we then relax the assumption of training data required by most existing models, creating a model that only requires a dictionary for training. Experiments show that our new method effectively learns coherent multilingual topics from partially and fully incomparable corpora with limited amounts of dictionary resources. 
 In this paper, we analyze several neural network designs  for sentence pair modeling and compare their performance extensively across eight datasets, including paraphrase identification, semantic textual similarity, natural language inference, and question answering tasks. Although most of these models have claimed state-of-the-art performance, the original papers often reported on only one or two selected datasets. We provide a systematic study and show that  encoding contextual information by LSTM and inter-sentence interactions are critical,  Tree-LSTM does not help as much as previously claimed but surprisingly improves performance on Twitter datasets,  the Enhanced Sequential Inference Model  is the best so far for larger datasets, while the Pairwise Word Interaction Model  achieves the best performance when less data is available. We release our implementations as an open-source toolkit. 
 Generating natural language requires conveying content in an appropriate style. We explore two related tasks on generating text of varying formality: monolingual formality transfer and formality-sensitive machine translation. We propose to solve these tasks jointly using multi-task learning, and show that our models achieve state-of-the-art performance for formality transfer and are able to perform formality-sensitive translation without being explicitly trained on style-annotated translation examples.  
 	Classic pipeline models for task-oriented dialogue system require explicit modeling the dialogue states and hand-crafted action spaces to query a domain-specific knowledge base. Conversely, sequence-to-sequence models learn to map dialogue history to the response in current turn without explicit knowledge base querying. In this work, we propose a novel framework that leverages the advantages of classic pipeline and sequence-to-sequence models. Our framework models a dialogue state as a fixed-size distributed representation and use this representation to query a knowledge base via an attention mechanism. Experiment on Stanford Multi-turn Multi-domain Task-oriented Dialogue Dataset shows that our framework significantly outperforms other sequence-to-sequence based baseline models on both automatic and human evaluation. 
 Neural machine translation  systems are usually trained on a large amount of bilingual sentence pairs and translate one sentence at a time, ignoring inter-sentence information. This may make the translation of a sentence ambiguous or even inconsistent with the translations of neighboring sentences. In order to handle this issue, we propose an inter-sentence gate model that uses the same encoder to encode two adjacent sentences and controls the amount of information flowing from the preceding sentence to the translation of the current sentence with an inter-sentence gate. In this way, our proposed model can capture the connection between sentences and fuse recency from neighboring sentences into neural machine translation. On several NIST Chinese-English translation tasks, our experiments demonstrate that the proposed inter-sentence gate model achieves substantial improvements over the baseline. 
   We investigate the design challenges of constructing effective and efficient neural sequence labeling systems, by reproducing twelve neural sequence labeling models, which include most of the state-of-the-art structures, and conduct a systematic model comparison on three benchmarks . Misconceptions and inconsistent conclusions in existing literature are examined and clarified under statistical experiments. In the comparison and analysis process, we reach several practical conclusions which can be useful to practitioners. 
 We introduce a novel meme generation system, which given any image can produce a humorous and relevant caption. Furthermore, the system can be conditioned on not only an image but also a user-defined label relating to the meme template, giving a handle to the user on meme content. The system uses a pretrained Inception-v3 network to return an image embedding which is passed to an attention-based deep-layer LSTM model producing the caption - inspired by the widely recognized Show and Tell Model. We implement a modified beam search to encourage diversity in the captions. We evaluate the quality of our model using perplexity and human assessment on both the quality of memes generated and whether they can be differentiated from real ones. Our model produces original memes that cannot on the whole be differentiated from real ones. \url{https://github.com/alpv95/MemeProject} 
 In this paper we formalize the problem automatic fill-in-the-blank question generation using two standard NLP machine learning schemes, proposing concrete deep learning models for each. We present an empirical study based on data obtained from a language learning platform showing that both of our proposed settings offer promising results. 
 We describe a neural network-based system for text-to-speech  synthesis that is able to generate speech audio in the voice of different speakers, including those unseen during training. Our system consists of three independently trained components: [] , trained on a speaker verification task using an independent dataset of noisy speech without transcripts from thousands of speakers, to generate a fixed-dimensional embedding vector from only seconds of reference speech from a target speaker;  based on Tacotron~2 that generates a mel spectrogram from text, conditioned on the speaker embedding;  that converts the mel spectrogram into time domain waveform samples.  We demonstrate that the proposed model is able to transfer the knowledge of speaker variability learned by the discriminatively-trained speaker encoder to the multispeaker TTS task, and is able to synthesize natural speech from speakers unseen during training. We quantify the importance of training the speaker encoder on a large and diverse speaker set in order to obtain the best generalization performance. Finally, we show that randomly sampled speaker embeddings can be used to synthesize speech in the voice of novel speakers dissimilar from those used in training, indicating that the model has learned a high quality speaker representation. 
 	Encoder-decoder based Sequence to Sequence learning  has made remarkable progress in recent years. Different network architectures have been used in the encoder/decoder. Among them, Convolutional Neural Networks  and Self Attention Networks  are the prominent ones. The two architectures achieve similar performances but use very different ways to encode and decode context: CNN use convolutional layers to focus on the local connectivity of the sequence, while SAN uses self-attention layers to focus on global semantics. In this work we propose Double Path Networks for Sequence to Sequence learning , which leverage the advantages of both models by using double path information fusion. During the encoding step, we develop a double path architecture to maintain the information coming from different paths with convolutional layers and self-attention layers separately. To effectively use the encoded context, we develop a cross attention module with gating and use it to automatically pick up the information needed during the decoding step. By deeply integrating the two paths with cross attention, both types of information are combined and well exploited. Experiments show that our proposed method can significantly improve the performance of sequence to sequence learning over state-of-the-art systems. 
 We introduce Generative Neural Machine Translation , a latent variable architecture which is designed to model the semantics of the source and target sentences. We modify an encoder-decoder translation model by adding a latent variable as a language agnostic representation which is encouraged to learn the meaning of the sentence. GNMT achieves competitive BLEU scores on pure translation tasks, and is superior when there are missing words in the source sentence. We augment the model to facilitate multilingual translation and semi-supervised learning without adding parameters. This framework significantly reduces overfitting when there is limited paired data available, and is effective for translating between pairs of languages not seen during training. 
   In this paper, we apply different NMT models to the problem of historical spelling normalization for five languages: English, German, Hungarian, Icelandic, and Swedish. The NMT models are at different levels, have different attention mechanisms, and different neural network architectures. Our results show that NMT models are much better than SMT models in terms of character error rate. The vanilla RNNs are competitive to GRUs/LSTMs in historical spelling normalization. Transformer models perform better only when provided with more training data. We also find that subword-level models with a small subword vocabulary are better than character-level models for low-resource languages. In addition, we propose a hybrid method which further improves the performance of historical spelling normalization.  
 Building multi-turn information-seeking conversation systems is an important and challenging research topic. Although several advanced neural text matching models have been proposed for this task, they are generally not efficient for industrial applications. Furthermore, they rely on a large amount of labeled data, which may not be available in real-world applications. To alleviate these problems, we study transfer learning for multi-turn information seeking conversations in this paper. We first propose an efficient and effective multi-turn conversation model based on convolutional neural networks. After that, we extend our model to adapt the knowledge learned from a resource-rich domain to enhance the performance. Finally, we deployed our model in an industrial chatbot called AliMe Assist} and observed a significant improvement over the existing online model. 
  %OK  With the development of several multilingual datasets used for semantic parsing, recent research efforts have looked into the problem of learning semantic parsers in a multilingual setup . However, how to improve the performance of a monolingual semantic parser for a specific language by leveraging data annotated in different languages remains a research question that is under-explored. In this work, we present a study to show how learning distributed representations of the logical forms from data annotated in different languages can be used for improving the performance of a monolingual semantic parser. We extend two existing monolingual semantic parsers to incorporate such cross-lingual distributed logical representations as features. Experiments show that our proposed approach is able to yield improved semantic parsing results on the standard multilingual GeoQuery dataset.  % In this paper, we propose to enrich feature learning in discriminative semantic parsing by including semantic embedding learnt from multiple different languages. % We extend an existing discriminative parser based on the neural hybrid trees by incorporating the cross-lingual semantic embedding as continuous features.  
   This paper presents two ways of dealing with scarce data in semantic decoding using N-Best speech recognition hypotheses. First, we learn features by using a deep learning architecture in which the weights for the unknown and known categories are jointly optimised. Second, an unsupervised method is used for further tuning the weights.  Sharing weights injects prior knowledge to unknown categories. The unsupervised tuning  improves the  F-Measure when recognising nearly zero-shot data on the DSTC3 corpus. This unsupervised method can be applied subject to two assumptions: the rank of the class marginal is assumed to be known and the class-conditional scores of the classifier are assumed to follow a Gaussian distribution.   
   A major proportion of a text summary includes important entities found in the original text. These entities build up the topic of the summary. Moreover, they hold commonsense information once they are linked to a knowledge base. Based on these observations, this paper investigates the usage of linked entities to guide the decoder of a neural text summarizer to generate concise and better summaries. To this end, we leverage on an off-the-shelf entity linking system  to extract linked entities and propose Entity2Topic , a module easily attachable to a sequence-to-sequence model that transforms a list of entities into a vector representation of the topic of the summary. Current available ELS's are still not sufficiently effective, possibly introducing unresolved ambiguities and irrelevant entities. We resolve the imperfections of the ELS by  encoding entities with selective disambiguation, and  pooling entity vectors using firm attention. By applying E2T to a simple sequence-to-sequence model with attention mechanism as base model, we see significant improvements of the performance in the Gigaword  and CNN  summarization datasets by at least 2 ROUGE points. 
 Parallel sentence extraction is a task addressing the data sparsity problem found in multilingual natural language processing applications. We propose a bidirectional recurrent neural network based approach to extract parallel sentences from collections of multilingual texts. Our experiments with noisy parallel corpora show that we can achieve promising results against a competitive baseline by removing the need of specific feature engineering or additional external resources. To justify the utility of our approach, we extract sentence pairs from Wikipedia articles to train machine translation systems and show significant improvements in translation performance. 
   This paper describes NCRF++, a toolkit for neural sequence labeling. NCRF++ is designed for quick implementation of different neural sequence labeling models with a CRF inference layer. It provides users with an inference for building the custom model structure through configuration file with flexible neural feature design and utilization. Built on PyTorch\footnote{\url{http://pytorch.org/}}, the core operations are calculated in batch, making the toolkit efficient with the acceleration of GPU. It also includes the implementations of most state-of-the-art neural sequence labeling models such as LSTM-CRF, facilitating reproducing and refinement on those methods.  
 %Gating is a key technology used for integrating information from multiple sources in solving the  gradient vanishing problem by long short-term memory  model, which recently has also been applied to highway network, gated recurrent unit , and quasi-recurrent neural network  etc.  Gating is a key technique used for integrating information from multiple sources by long short-term memory  models and has recently also been applied to other models such as the highway network. Although gating is powerful, it is rather expensive in terms of both computation and storage as each gating unit uses a separate full weight matrix. This issue can be severe since several gates can be used together in e.g. an LSTM cell. This paper proposes a semi-tied unit  approach to solve this efficiency issue, which uses one shared weight matrix to replace those in all the units in the same layer. The approach is termed ``semi-tied'' since extra parameters are used to separately scale each of the shared output values.  These extra scaling factors are associated with the network activation functions and result in the use of parameterised sigmoid, hyperbolic tangent, and rectified linear unit functions. Speech recognition experiments using British English multi-genre broadcast data showed that using STUs can reduce the calculation and storage cost  by a factor of  three for highway networks and four for LSTMs, while giving similar word error rates to the original models.  
 Generative Adversarial Networks  have gained a lot of attention from machine learning community due to their ability to learn and mimic an input data distribution. GANs consist of a discriminator and a generator working in tandem playing a min-max game to learn a target underlying data distribution; when fed with data-points sampled from a simpler distribution . Once trained, they allow synthetic generation of examples sampled from the target distribution. We investigate the application of GANs to generate synthetic feature vectors used for speech emotion recognition. Specifically, we investigate two  set ups:  a vanilla GAN that learns the distribution of a lower dimensional representation of the actual higher dimensional feature vector and,  a conditional GAN that learns the distribution of the higher dimensional feature vectors conditioned on the labels or the emotional class to which it belongs. As a potential practical application of these synthetically generated samples, we measure any improvement in a classifier's performance when the synthetic data is used along with real data for training. We perform cross validation analyses followed by a cross-corpus study. 
 Model compression is essential for serving large deep neural nets on devices with limited resources or applications that require real-time responses. As a case study, a state-of-the-art neural language model usually consists of one or more recurrent layers sandwiched between an embedding layer used for representing input tokens and a softmax layer for generating output tokens. For problems with a very large vocabulary size, the embedding and the softmax matrices can account for more than half of the model size. For instance, the bigLSTM model achieves state-of-the-art performance on the One-Billion-Word  dataset with around 800k vocabulary, and its word embedding and softmax matrices use more than 6GBytes space, and are responsible for over 90\% of the model parameters. In this paper, we propose GroupReduce, a novel compression method for neural language models, based on vocabulary-partition  based low-rank matrix approximation and the inherent frequency distribution of tokens . The experimental results show our method can significantly outperform traditional compression methods such as low-rank approximation and pruning. On the OBW dataset, our method achieved 6.6 times compression rate for the embedding and softmax matrices, and when combined with quantization, our method can achieve 26 times compression rate, which translates to a factor of 12.8 times compression for the entire model with very little degradation in perplexity.       %Depending on the vocabulary size, the embedding and softmax matrices can account for around 80-90\% of the   %For problems with a very large vocabulary size, the embedding and the softmax matrices can account for more than half of the model size. For instance, the bigLSTM model achieves state-of-the-art performance on the One-Billion-Word  dataset with around 800k vocabulary, and its word embedding and softmax matrices use more than 6GBytes space, and are responsible for over 90\% of the model parameters.   %For advanced NLP problems, a neural language model usually consists of recurrent layers , an embedding matrix for representing input tokens, and a softmax layer for generating output tokens.     %Depending on the vocabulary size, the embedding and soft-max matrices can account for xx-yy% of the total number of parameters in the model.  %This paper proposes GroupReduce, a compression method for embedding and soft-max layers that relies on a block-level weighted low-rank approximation for these weight matrices, respectively. We start by grouping words into c blocks based on their frequency in the training data and then re-parameterizing the weights in each block using a low-rank matrix approximation method. This block-level low-rank approximation is optimized as a whole by weighting each block according to the frequencies of words within that block.     %Experimental results show that our method significantly outperforms traditional compression methods such as low-rank approximation and pruning. On the SOTA LM for the One Billion Words Benchmark GroupReduce achieves a factor of 6.6 compression for the embedding and soft-max matrices which translates to a factor of Z compression for the entire model with very little degradation in perplexity. On the EnDe SOTA NMT model we experimented with GroupReduce achieves a factor of Y compression for the embedding and soft-max matrices which translates to a factor of X compression for the entire model with very little degradation in BLEU score."   %    %We start by grouping words into $c$ blocks based on their frequency in the training data and then re-parameterizing the weights in each block using a low-rank matrix approximation method. This block-level low-rank approximation is optimized as a whole by weighting each block according to the frequencies of words within that block.           
  Recently, neural machine translation  has been extended to multilinguality, that is to handle more than one translation direction with a single system. Multilingual NMT showed competitive performance against pure bilingual systems. Notably, in low-resource settings, it proved to work effectively and efficiently, thanks to  shared representation space that is forced across languages and induces a sort of transfer-learning. Furthermore, multilingual NMT enables so-called zero-shot inference across language pairs never seen at training time.   Despite the increasing interest in this framework, an in-depth analysis of what a multilingual NMT model is capable of and what it is not is still missing.    Motivated by this, our work ~provides a quantitative and comparative analysis of the translations produced by bilingual, multilingual and zero-shot systems;  ~investigates the translation quality of two of the currently dominant neural architectures in MT, which are the Recurrent and the Transformer ones; and ~quantitatively explores how the closeness between languages influences the zero-shot translation. Our analysis leverages multiple professional post-edits of automatic translations by several different systems and focuses both on automatic standard metrics  and on widely used error categories, which are lexical, morphology, and word order errors.  
  We empirically investigate learning from partial feedback in neural machine translation , when partial feedback is collected by asking users to highlight a correct chunk of a translation.  %We discuss the appropriateness of chunk-level vs. sentence-level feedback.  We propose a simple and effective way of utilizing such feedback in NMT training.  We demonstrate how the common machine translation problem of domain mismatch between training and deployment can be reduced %,  without using any in-domain data and  solely based on chunk-level user feedback. We conduct a series of simulation experiments to test the effectiveness of the proposed method.  Our results show that chunk-level feedback outperforms sentence based feedback by up to 2.61\% BLEU absolute. % We observe a relative improvement of 18.6\% and 7\% in terms of BLEU compared to  simple baseline system and an improved system by sentence-level feedback, respectively. % vs. % Machine Translation systems often need to be deployed in a domain for which little or no parallel data is available,  but a quick user feedback is available. This feedback is usually provided at sentence level, however, a translation often contains both correct and incorrect parts. We propose to collect partial feedback by asking users to highlight the correctly translated part. We demonstrate a simple way to integrate partial feedback in the NMT training and show that it outperforms sentence based feedback by up to 2.61 BLEU. 
     In this paper, we have investigated recurrent deep neural networks  in combination with regularization techniques as dropout, zoneout, and regularization post-layer. As a benchmark, we chose the TIMIT phone recognition task due to its popularity and broad availability in the community. It also simulates a low-resource scenario that is helpful in minor languages. Also, we prefer the phone recognition task because it is much more sensitive to an acoustic model quality than a large vocabulary continuous speech recognition task. In recent years, recurrent DNNs pushed the error rates in automatic speech recognition down. But, there was no clear winner in proposed architectures. The dropout was used as the regularization technique in most cases, but combination with other regularization techniques together with model ensembles was omitted. However, just an ensemble of recurrent DNNs performed best and achieved an average phone error rate from 10 experiments 14.84~\%  on core test set that is slightly lower then the best-published PER to date, according to our knowledge. Finally, in contrast of the most papers, we published the open-source scripts to easily replicate the results and to help continue the development.                
 In this paper, we present a novel model for entity disambiguation that combines both local contextual information and global evidences through Limited Discrepancy Search . Given an input document, we start from a complete solution constructed by a local model and conduct a search in the space of possible corrections to improve the local solution from a global view point. Our search utilizes a heuristic function to focus more on the least confident local decisions and a pruning function to score the global solutions based on their local fitness and the global coherences among the predicted entities. Experimental results on CoNLL 2003 and TAC 2010 benchmarks verify the effectiveness of our model. 
  Online news media sometimes use misleading headlines to lure users to open the news article. These catchy headlines that attract users but disappointed them at the end, are called Clickbaits. Because of the importance of automatic clickbait detection in online medias, lots of machine learning methods were proposed and employed to find the clickbait headlines.   In this research, a model using deep learning methods is proposed to find the clickbaits in Clickbait Challenge 2017閳ユ獨 dataset. The proposed model gained the first rank in the Clickbait Challenge 2017 in terms of Mean Squared Error. Also, data analytics and visualization techniques are employed to explore and discover the provided dataset to get more insight from the data.  
  Effectively using full syntactic parsing information in Neural Networks  to solve relational tasks, e.g., question similarity, is still an open problem. In this paper, we propose to inject structural representations in NNs by \Ni learning an SVM model using Tree Kernels  on relatively few pairs of questions  as gold standard  training data is typically scarce, \Nii predicting labels on a very large corpus of question pairs, and \Niii pre-training NNs on such large corpus. The results on Quora and SemEval question similarity datasets show that NNs trained with our approach can learn more accurate models, especially after fine tuning on  GS.%, suggesting an intuitive assimilation of syntactic information. %: surprisingly, they also outperform TKs, without using any gold data.  % structural information if they are provided with enough labelled data; and  the latter can be produced in a weakly format using automatic classifiers-based on Tree kernels, which can capture question syntax very effectively.   %In this paper we propose a new approach for learning structural representation for QA task, e.g.,  detecting question-question similarity. More particularly, we first train an SVM with Tree Kernels  on relatively few pairs of questions  as training data is typically scarce. This way we learn structural representation of questions. Then we use such a model for predicting labels on a a very large corpus of question pairs. After that, we use this automatic labeled dataset as pre-training data for learning a Neural Network  models for predicting question-question similarity. %The results show that NNs can  learn structural information if they are provided with enough labelled data; and  the latter can be produced in a weakly format using automatic classifiers-based on Tree kernels, which can capture question syntax very effectively.  
 An intuitive way for a human to write paraphrase sentences is to replace words or phrases in the original sentence with their corresponding synonyms and make necessary changes to ensure the new sentences are fluent and grammatically correct. We propose a novel approach to modeling the process with dictionary-guided editing networks which effectively conduct rewriting on the source sentence to generate paraphrase sentences. It jointly learns the selection of the appropriate word level and phrase level paraphrase pairs in the context of the original sentence from an off-the-shelf dictionary as well as the generation of fluent natural language sentences.  %It explicitly learns both word deletion and insertion operations with attention mechanisms under the sequence-to-sequence framework. %Text editing for natural language generation is to utilize a sentence as the prototype, then revise it to generalize to a new sentence. There are two basic operations word deletion and word insertion in text editing. In this paper, we propose a novel neural model for text editing.  %Our model explicitly learns both word deletion and insertion operations with attention mechanism upon sequence-to-sequence model. Assume that there is a word or phrase dictionary, which contains words that may be deleted and corresponding to-be-added words. In the decoder of our model, we apply an edit attention mechanism generate sentences and align to-be-deleted words in the dictionary jointly. %Our model is applied to paraphrase generation task.  Specifically, the system retrieves a set of word level and phrase level paraphrased pairs derived from the Paraphrase Database  for the original sentence, which is used to guide the decision of which the words might be deleted or inserted with the soft attention mechanism under the sequence-to-sequence framework. %Then, in our generative model, we use the original sentence a prototype and retrieved paraphrased pairs to generate a new semantically equivalent sentence. We conduct experiments on two benchmark datasets for paraphrase generation, namely the MSCOCO and Quora dataset. The evaluation results demonstrate that our dictionary-guided editing networks outperforms the baseline methods. %and the editing attention mechanism significantly improves the performance of our model.	 		
  Incorporating prior knowledge like lexical constraints into the model's output to generate meaningful and coherent sentences has many applications in dialogue system, machine translation, image captioning, etc. However, existing RNN-based models incrementally generate sentences from left to right via beam search, which makes it difficult to directly introduce lexical constraints into the generated sentences. In this paper, we propose a new algorithmic framework, dubbed BFGAN, to address this challenge. Specifically, we employ a backward generator and a forward generator to generate lexically constrained sentences together, and use a discriminator to guide the joint training of two generators by assigning them reward signals. Due to the difficulty of BFGAN training, we propose several training techniques to make the training process more stable and efficient. Our extensive experiments on two large-scale datasets with human evaluation demonstrate that BFGAN has significant improvements over previous methods. 
 With the increasing number of texts made available on the Internet, many applications have relied on text mining tools to tackle a diversity of problems. A relevant model to represent texts is the so-called word adjacency  representation, which is known to capture mainly syntactical features of texts.In this study, we introduce a novel network representation that considers the semantic similarity between paragraphs. Two main properties of paragraph networks are considered:  their ability to incorporate characteristics that can discriminate real from artificial, shuffled manuscripts and  their ability to capture syntactical and semantic textual features. Our results revealed that real texts are organized into communities, which turned out to be an important feature for discriminating them from artificial texts. Interestingly, we have also found that, differently from traditional co-occurrence networks, the adopted representation is able to capture semantic features. Additionally, the proposed framework was employed to analyze the Voynich manuscript, which was found to be compatible with texts written in natural languages. Taken together, our findings suggest that the proposed methodology can be combined with traditional network models to improve text classification tasks. 
 Deep learning has improved performance on many natural language processing  tasks individually. However, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task. We introduce the 's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy. Though designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting.  We also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for \chal. 
  %NLP systems are increasingly being deployed and appreciated with relatively little attention to their vulnerabilities. We propose an efficient method to generate adversarial examples that would trick a deep character-aware model. We ask the question, ``How easy is it for an NLP system to break?'' Our experiments demonstrate that deep character-based models for text classification and machine translation are very brittle, and would behave undesirably after just a few character manipulations. We then ask the question, ``How expensive is it to break a model?'' We devise a novel fast gradient-based optimization method, which, given a budget of $r$ manipulations, requires an $\mathcal{O}$ number of queries to the model.    Evaluating on adversarial examples has become a standard procedure to measure robustness of deep learning models. Due to the difficulty of creating white-box adversarial examples for discrete text input, most analyses of the robustness of NLP models have been done through black-box adversarial examples.   We investigate adversarial examples for character-level neural machine translation , and contrast black-box adversaries with a novel white-box adversary, which employs differentiable string-edit operations to rank adversarial changes. We propose two novel types of attacks which aim to remove or change a word in a translation, rather than simply break the NMT. We  demonstrate that white-box adversarial examples are significantly stronger than their black-box counterparts in different attack scenarios, which show more serious vulnerabilities than previously known.  In addition, after performing adversarial training, which takes only 3 times longer than regular training, we can improve the model's robustness significantly. %We analyze the properties of these examples, and show that employing these adversarial examples in training can improve test-time accuracy on clean examples, as well as defend the models against adversarial examples.   %We further analyze the properties of these examples and whether or not examples designed to deceive one model are effective against another.  %Adversarial examples are synthetic examples, which are often constructed by manipulating real-world examples in order to make a classifier believe they belong to an incorrect class with high confidence . %Research on adversarial examples for neural nets has largely focused on image data, with relatively little work on textual data. %Research on adversarial examples for neural nets has largely focused on image data, with relatively little work on textual data.  
 	   Generating character-level features is an important step for achieving good results in various natural language processing tasks. To alleviate the need for human labor in generating hand-crafted features, methods that utilize neural architectures such as Convolutional Neural Network  or Recurrent Neural Network  to automatically extract such features have been proposed and have shown great results. However, CNN generates position-independent features, and RNN is slow since it needs to process the characters sequentially. In this paper, we propose a novel method of using a densely connected network to automatically extract character-level features. The proposed method does not require any language or task specific assumptions, and shows robustness and effectiveness while being faster than CNN- or RNN-based methods. Evaluating this method on three sequence labeling tasks - slot tagging, Part-of-Speech  tagging, and Named-Entity Recognition  - we obtain state-of-the-art performance with a 96.62 F1-score and 97.73\% accuracy on slot tagging and POS tagging, respectively, and comparable performance to the state-of-the-art 91.13 F1-score on NER.  
 	Answering questions from university admission exams  is a challenging AI task since it requires effective representation to capture complicated semantic relations between questions and answers. In this work, we propose a hybrid neural model for deep question-answering task from history examinations. Our model employs a cooperative gated neural network to retrieve answers with the assistance of extra labels given by a neural turing machine labeler. Empirical study shows that the labeler works well with only a small training dataset and the gated mechanism is good at fetching the semantic representation of lengthy answers. Experiments on question answering demonstrate the proposed model obtains substantial performance gains over various neural model baselines in terms of multiple evaluation metrics. 
    Resources for the non-English languages are scarce and this paper addresses this problem in the context of machine translation, by automatically extracting parallel sentence pairs from the multilingual articles available on the Internet. In this paper, we have used an end-to-end Siamese bidirectional recurrent neural network to generate parallel sentences from comparable multilingual articles in Wikipedia.  Subsequently, we have showed that using the harvested dataset improved BLEU scores on both NMT and phrase-based SMT systems for the low-resource language pairs: English--Hindi and English--Tamil, when compared to training exclusively on the limited bilingual corpora collected for these language pairs. 
  This work addresses challenges arising from extracting entities from textual data, including the high cost of data annotation, model accuracy, selecting appropriate evaluation criteria, and the overall quality of annotation. We present a framework that integrates Entity Set Expansion  and Active Learning  methods to reduce the annotation cost of sparse data and provide an online evaluation method as feedback. This incremental and interactive learning framework allows for rapid annotation while maintaining high accuracy.  We evaluate our framework on three publicly available datasets and show that it drastically reduces the cost of sparse entity annotation by an average of 45\% to 85\% while reaching 1.0 and 0.9 F-Score, respectively. Moreover, the method exhibited robust performance across all datasets.  
  Many NLP applications can be framed as a graph-to-sequence learning problem. Previous work proposing neural architectures on this setting obtained promising results compared to grammar-based approaches but still rely on linearisation heuristics and/or standard recurrent networks to achieve the best performance. In this work, we propose a new model that encodes the full structural information contained in the graph. Our architecture couples the recently proposed Gated Graph Neural Networks with an input transformation that allows nodes and edges to have their own hidden representations, while tackling the parameter explosion problem present in previous work. Experimental results show that our model outperforms strong baselines in generation from AMR graphs and syntax-based neural machine translation.   % %  %  
 In automatic speech recognition  systems, recurrent neural network language models  are used to rescore a word lattice or N-best hypotheses list. Due to the expensive training, the RNNLM's vocabulary set accommodates only small shortlist of most frequent words. This leads to suboptimal performance if an input speech contains many out-of-shortlist  words.  An effective solution is to increase the shortlist size and retrain the entire network which is highly inefficient. Therefore, we propose an efficient method to expand the shortlist set of a pretrained RNNLM without incurring expensive retraining and using additional training data. Our method exploits the structure of RNNLM which can be decoupled into three parts: input projection layer, middle layers, and output projection layer. Specifically, our method expands the word embedding matrices in projection layers and keeps the middle layers unchanged. In this approach, the functionality of the pretrained RNNLM will be correctly maintained as long as OOS words are properly modeled in two embedding spaces. We propose to model the OOS words by borrowing linguistic knowledge from appropriate in-shortlist words. Additionally, we propose to generate the list of OOS words to expand vocabulary in unsupervised manner by automatically extracting them from ASR output.   hypotheses list. %produced by count-based \mbox{$n$-gram} language model at the decoding stage. %In ASR, they are employed at the rescoring stage to rescore the word lattice or \mbox{$N$-best} hypotheses list. %produced at the decoding stage by count-based \mbox{$n$-gram} language models. Due to the expensive training process, the RNNLM's vocabulary set accommodates only small shortlist of most frequent words. This leads to suboptimal performance if an input speech contains many out-of-shortlist  words.  An effective solution is to increase the shortlist size and retrain the entire network which is highly ineffective. Therefore, we propose an efficient method to expand the shortlist set of a pretrained RNNLM without incurring expensive retraining and using additional training data.  %unsupervised manner where the list of out-of-shortlist words for inclusion are automatically extracted from the word lattice. %Different from traditional approaches, our method doesn't require expensive retraining nor additional training data. %Our method doesn't require expensive retraining nor additional training data.  Our method exploits the structure of RNNLM which can be decoupled into three parts: 1) input projection layer, 2) middle layers and 3) output projection layer. Specifically, our method expands the word embedding matrices in input and output projection layers, and keeps the middle layers unchanged. In this approach, the functionality of the pretrained RNNLM will be correctly maintained as long as OOS words are correctly modeled in two embedding spaces. We propose to model the OOS words by borrowing linguistic knowledge from appropriate in-shortlist words. %As a result, the vocabulary coverage of pretrained RNNLM will be expanded, while the functionality of the model is correctly maintained. Additionally, we propose to generate the list of OOS words for inclusion into shortlist in unsupervised manner by automatically extracting them from ASR output.  We evaluated our method on $N$-best rescoring task for the state-of-the-art TED talks ASR system. The experiment results show that vocabulary expanded RNNLM achieves $4\%$ relative word error rate improvement over the conventional RNNLM. Compared to the strong Kneser-Ney smoothed 5-gram model used to rescore the word lattice, our model achieved $7\%$ relative word error rate improvement. \fi 
 % Human language emerges with grounded semantics, within which a large proportion of words are visually-grounded. % Despite the great success brought by distributional textual embedding learning, how to efficiently ground texts especially \wrt visual domain  receives little attention. We study the problem of grounding distributional representations of texts on the visual domain, namely visual-semantic embeddings . Begin with an insightful adversarial attack on VSE embeddings, we show the limitation of current frameworks and image-text datasets  both quantitatively and qualitatively. The large gap between the number of possible constitutions of real-world semantics and the size of parallel data, to a large extent, restricts the model to establish the link between textual semantics and visual concepts. We alleviate this problem by augmenting the MS-COCO image captioning datasets with textual contrastive adversarial samples. These samples are synthesized using linguistic rules and the WordNet knowledge base. The construction procedure is both syntax- and semantics-aware. The samples enforce the model to ground learned embeddings to concrete concepts within the image. This simple but powerful technique brings a noticeable improvement over the baselines on a diverse set of downstream tasks, in addition to defending known-type adversarial attacks. We release the codes at \url{https://github.com/ExplorerFreda/VSE-C}. 
 Research on question answering with knowledge base has recently seen an increasing use of deep architectures. In this extended abstract, we study the application of the neural machine translation paradigm for question parsing. We employ a sequence-to-sequence model to learn graph patterns in the \sparql graph query language and their compositions. Instead of inducing the programs through question-answer pairs, we expect a semi-supervised approach, where alignments between questions and queries are built through templates. We argue that the coverage of language utterances can be expanded using late notable works in natural language generation. 
 Large scale veterinary clinical records can become a powerful resource for patient care and research. However clinicians lack the time and resource to annotate patient records with standard medical diagnostic codes and most veterinary visits are captured in free text notes. The lack of standard coding makes it challenging to use the clinical data to improve patient care.  %Clinicians lack the time and expertise to annotate patient records with standard medical diagnostic codes and in certain situations, a robust medical coding workforce is lacking in order to provide these annotations. The field of clinical veterinary practice is one such example and visits are largely captured in un-annotated free text notes. The lack of standard coding makes it challenging to  to improve patient care.  .  DeepTag is trained on a newly curated dataset of 112,558 veterinary notes manually annotated by experts. DeepTag extends multi-task LSTM with an improved hierarchical objective that captures the semantic structures between diseases. To foster human-machine collaboration, DeepTag also learns to abstain in examples when it is uncertain and defers them to human experts, resulting in improved performance. DeepTag accurately infers disease codes from free text even in challenging cross-hospital settings where the text comes from different clinical settings than the ones used for training. It enables automated disease annotation across a broad range of clinical diagnoses with minimal pre-processing. The technical framework in this work can be applied  in other medical domains that currently lack medical coding resources.  %We used techniques developed in multi-task learning literature to augment our loss function by leveraging natural hierarchies between disease codes, where we observed cross-domain improvements. We also investigate out-of-domain generalization problem for our text processing system in this domain. To foster human-machine collaboration, we also augmented the system with the ability to learn to abstain examples with high degree of uncertainty and defer them to human experts, resulting in improved performance of the model. % \james{We trained our model on an expert curated dataset of X clinical notes.}  %\paragraph{Conclusions} %The multi-label classification disease tagger developed in this work  allows for disease annotation from free text across a broad range of clinical diagnoses without domain-expert rule-based labeling or a high degree of pre-processing. Technical innovations from this work extend into other medical domains that also suffer from under-resourced medical coding infrastructure, namely loss augmentation leveraged on the coding hierarchy, as well as building a model that learns to abstain on examples when the model is not confident.  This allows the system to be augmented by human annotations for cases in which the correct categorization unclear, taking advantage of both human domain expertise and machine learning. 
 This paper analyses the contribution of language metrics and, potentially, of linguistic structures, to classify French learners of English according to levels of the Common European Framework of Reference for Languages . The purpose is to build a model for the prediction of learner levels as a function of language complexity features. We used the EFCAMDAT corpus , a database of one million written assignments by learners. After applying language complexity metrics on the texts, we built a representation matching the language metrics of the texts to their assigned CEFRL levels. Lexical and syntactic metrics were computed with LCA and LSA  and koRpus . Several supervised learning models were built by using Gradient Boosted Trees and Keras Neural Network methods and by contrasting pairs of CEFRL levels. Results show that it is possible to implement pairwise distinctions, especially for levels ranging from A1 to B1 . Model explanation reveals significant linguistic features for the predictiveness in the corpus. Word tokens and word types appear to play a significant role in determining levels. This shows that levels are highly dependent on specific semantic profiles.  %Section 1 describes the syntactic and lexical metrics used as predictors in the classification task.  Section 2 reports the results with an elastic net. Section 3 compares the results with an LSTM model. Section 4 describes methods aimed at discriminating criterial features, especially the role of frequency.   %This paper is a bird's eye view on learner corpus research  and machine learning . We sum up a certain number of methods that have been tested in the investigation of learner data. Specialist in LCR try to pinpoint the criterial features  ~ for each level of proficiency as defined by the Common European Framework of Reference for Languages . We showcase several methods involving ML which have borne on three types of data: carefully annotated learner data in terms of errors, POS  tagged data, and raw data. We mostly describe written data, but recordings offer the same kind of possibilities, even though the processing of raw files is not so satisfactory besides specifically home-designed language models for English.   %RQ: do we get the best results on raw data, parsed data pos-tagged data or error-annotated data?  %size of the data for credibility??? 
   The IJCAI--18 Proceedings will be printed from electronic   manuscripts submitted by the authors. The electronic manuscript will   also be included in the online version of the proceedings. This paper   provides the style instructions. 
   Spoken language understanding is one of the key factors in a dialogue system, and a context in a conversation plays an important role to understand the current utterance.    In this work, we demonstrate the importance of context within the dialogue for neural network models through an online web interface live demo.    We developed two different neural models: a model that does not use context and a context-based model.    The no-context model classifies dialogue acts at an utterance-level whereas the context-based model takes some preceding utterances into account.   We make these trained neural models available as a live demo called Discourse-Wizard using a modular server architecture.    The live demo provides an easy to use interface for conversational analysis and for discovering deep discourse structures in a conversation.   
 In this paper, we examine the use case of general adversarial networks  in the field of marketing. In particular, we analyze how GAN models can replicate text patterns from successful product listings on Airbnb, a peer-to-peer online market for short-term apartment rentals. To do so, we define the Diehl-Martinez-Kamalu  loss function as a new class of functions that forces the model閳ユ獨 generated output to include a set of user-defined keywords. This allows the general adversarial network to recommend a way of rewording the phrasing of a listing description to increase the likelihood that it is booked. Although we tailor our analysis to Airbnb data, we believe this framework establishes a more general model for how generative algorithms can be used to produce text samples for the purposes of marketing.    
     This paper proposes a novel framework for recurrent neural networks  inspired by the human memory models in the field of cognitive neuroscience to enhance information processing and transmission between adjacent RNNs閳 units. The proposed framework for RNNs consists of three stages that is working memory, forget, and long-term store. The first stage includes taking input data into sensory memory and transferring it to working memory for preliminary treatment. And the second stage mainly focuses on proactively forgetting the secondary information rather than the primary in the working memory. And finally, we get the long-term store normally using some kind of RNN閳ユ獨 unit. Our framework, which is generalized and simple, is evaluated on 6 datasets which fall into 3 different tasks, corresponding to text classification, image classification and language modelling. Experiments reveal that our framework can obviously improve the performance of traditional recurrent neural networks. And exploratory task shows the ability of our framework of correctly forgetting the secondary information. 
 Software Categorization is the task of organizing software into groups that broadly describe the behavior of the software, such as ``editors'' or ``science.''  Categorization plays an important role in several maintenance tasks, such as repository navigation and feature elicitation.  Current approaches attempt to cast the problem as text classification, to make use of the rich body of literature from the NLP domain.  However, as we will show in this paper, text classification algorithms are generally not applicable off-the-shelf to source code; we found that they work well when high-level project descriptions are available, but suffer very large performance penalties when classifying source code and comments only.  We propose a set of adaptations to a state-of-the-art neural classification algorithm, and perform two evaluations: one with reference data from Debian end-user programs, and one with a set of C/C++ libraries that we hired professional programmers to annotate.  We show that our proposed approach achieves performance exceeding that of previous software classification techniques as well as a state-of-the-art neural text classification technique. 
 Sentiment classification involves quantifying the affective reaction of a human to a document, media item or an event. Although researchers have investigated several methods to reliably infer sentiment from lexical, speech and body language cues, training a model with a small set of labeled datasets is still a challenge. For instance, in expanding sentiment analysis to new languages and cultures, it may not always be possible to obtain comprehensive labeled datasets. In this paper, we investigate the application of semi-supervised and transfer learning methods to improve performances on low resource sentiment classification tasks. We experiment with extracting dense feature representations, pre-training and manifold regularization in enhancing the performance of sentiment classification systems. Our goal is a coherent implementation of these methods and we evaluate the gains achieved by these methods in matched setting involving training and testing on a single corpus setting as well as two cross corpora settings. In both the cases, our experiments demonstrate that the proposed methods can significantly enhance the model performance against a purely supervised approach, particularly in cases involving a handful of training data.  
  Comments in software are critical for  maintenance and reuse. But apart from prescriptive advice, there is little practical support or quantitative understanding of what makes a comment useful. In this paper, we introduce the task of identifying comments which are uninformative about  the code they are meant to document. To address this problem,  we introduce the   notion of comment entailment from code, high entailment   indicating that a comment's natural  language semantics can be inferred directly from the  code.  Although not all entailed comments are low quality, comments that are too easily inferred, for example, comments that restate the code, are widely discouraged by authorities on software style. Based on this, we develop a tool called \theAcro which scores method-level comments for redundancy. Highly redundant  comments can then be expanded or alternately removed by the developer.  \theAcro uses deep language models to exploit large software corpora  without requiring expensive manual annotations of entailment.  We show that \theAcro can perform the comment entailment task with  good agreement with human judgements.  % , yielding % over 80\% agreement. Our findings also have  implications for documentation tools. For example, we find that common tags in Javadoc are at least   from code than non-Javadoc sentences, suggesting that Javadoc tags  are less informative than more free-form comments.  %%  We introduce a new task of quantifying the extent to which a comment %% is predictable from the code it is meant to describe. More specifically %% we propose machine learning models which predict the degree to which  %% a piece of code entail the comment surround it. By this notion of %% entailment, we also obtain a facility for predicting those comments which  %% are not entailed by the code. These comments may be viewed as adding additional  %% information and therefore of greater use. Our models on a setup of comment %% entailment from methods show that certain Javadoc statements are easier than  %% others to predict. The results point towards a scenario where models will %% become better at automatically predicting the directly entailing elements of  %% a code snippet. A developer will need to add only those additional facets of  %% information to place a code in context.    
       Visual question answering  requires joint comprehension of images and natural language questions, where     many questions can't be directly or clearly answered from visual content but require reasoning from structured human knowledge with confirmation from visual content.     This paper proposes visual knowledge memory network  to address this issue, which seamlessly incorporates structured human knowledge and deep visual features into memory networks in an end-to-end learning framework.     Comparing to existing methods for leveraging external knowledge for supporting VQA, this paper stresses more on two missing mechanisms.     First is the mechanism for integrating visual contents with knowledge facts.     VKMN handles this issue by embedding knowledge triples  and deep visual features jointly into the visual knowledge features.     Second is the mechanism for handling multiple knowledge facts expanding from question and answer pairs.     VKMN stores joint embedding using key-value pair structure in the memory networks so that it is easy to handle multiple facts.     Experiments show that the proposed method achieves promising results on both VQA v1.0 and v2.0 benchmarks, while outperforms state-of-the-art methods on the knowledge-reasoning related questions. 
     Deep neural networks  have achieved impressive predictive performance due to their ability to learn complex, non-linear relationships between variables. However, the inability to effectively visualize these relationships has led to DNNs being characterized as black boxes and consequently limited their applications. To ameliorate this problem, we introduce the use of hierarchical interpretations to explain DNN predictions through our proposed method: agglomerative contextual decomposition . Given a prediction from a trained DNN, ACD produces a hierarchical clustering of the input features, along with the contribution of each cluster to the final prediction. This hierarchy is optimized to identify clusters of features that the DNN learned are predictive. We introduce ACD using examples from Stanford Sentiment Treebank and ImageNet, in order to diagnose incorrect predictions, identify dataset bias, and extract polarizing phrases of varying lengths. Through human experiments, we demonstrate that ACD enables users both to identify the more accurate of two DNNs and to better trust a DNN's outputs. We also find that ACD's hierarchy is largely robust to adversarial perturbations, implying that it captures fundamental aspects of the input and ignores spurious noise. 
 Learning multimodal representations is a fundamentally complex research problem due to the presence of multiple heterogeneous sources of information. Although the presence of multiple modalities provides additional valuable information, there are two key challenges to address when learning from multimodal data: 1) models must learn the complex intra-modal and cross-modal interactions for prediction and 2) models must be robust to unexpected missing or noisy modalities during testing. In this paper, we propose to optimize for a joint generative-discriminative objective across multimodal data and labels. We introduce a model that factorizes representations into two sets of independent factors: multimodal discriminative and modality-specific generative factors. Multimodal discriminative factors are shared across all modalities and contain joint multimodal features required for discriminative tasks such as sentiment prediction. Modality-specific generative factors are unique for each modality and contain the information required for generating data. Experimental results show that our model is able to learn meaningful multimodal representations that achieve state-of-the-art or competitive performance on six multimodal datasets. Our model demonstrates flexible generative capabilities by conditioning on independent factors and can reconstruct missing modalities without significantly impacting performance. Lastly, we interpret our factorized representations to understand the interactions that influence multimodal learning. 
 Current approaches to speech emotion recognition focus on speech features that can capture the emotional content of a speech signal. Mel Frequency Cepstral Coefficients  are one of the most commonly used representations for audio speech recognition and classification. This paper proposes Gammatone Frequency Cepstral Coefficients  as a potentially better representation of speech signals for emotion recognition. The effectiveness of MFCC and GFCC representations are compared and evaluated over emotion and intensity classification tasks with fully connected and recurrent neural network architectures. The results provide evidence that GFCCs outperform MFCCs in speech emotion recognition. 
 This work presents a hierarchical deep learning natural language parser for fashion. Our proposal intends not only to recognize fashion-domain entities but also to expose syntactic and morphologic insights. We leverage the usage of an architecture of specialist models, each one for a different task . Such architecture renders a hierarchical model able to capture the nuances of the fashion language. The natural language parser is able to deal with textual ambiguities which are left unresolved by our currently existing solution. Our empirical results establish a robust baseline, which justifies the use of hierarchical architectures of deep learning models while opening new research avenues to explore. 
 In this paper we present a new method for text-independent speaker verification that combines segmental dynamic time warping  and the d-vector approach. The d-vectors, generated from a feed forward deep neural network trained to distinguish between speakers, are used as features to  perform alignment and hence calculate the overall distance between the enrolment and test utterances. We present results on the NIST 2008 data set for speaker verification where the proposed method outperforms the conventional i-vector baseline with PLDA scores and outperforms d-vector approach with local distances based on cosine and PLDA scores. Also score combination with the i-vector/PLDA baseline leads to significant gains over both methods. 
 We introduce TextWorld, a sandbox learning environment for the training and evaluation of RL agents on text-based games. TextWorld is a Python library that handles interactive play-through of text games, as well as backend functions like state tracking and reward assignment. It comes with a curated list of games whose features and challenges we have analyzed. More significantly, it enables users to handcraft or automatically generate new games. Its generative mechanisms give precise control over the difficulty, scope, and language of constructed games, and can be used to relax challenges inherent to commercial text games like partial observability and sparse rewards. By generating sets of varied but similar games, TextWorld can also be used to study generalization and transfer learning. We cast text-based games in the Reinforcement Learning formalism, use our framework to develop a set of benchmark games, and evaluate several baseline agents on this set and the curated list.  %  
 Many structured prediction problems  are ambiguous, with multiple outputs being `correct' for an input --  supervision from neighboring examples.  We first study the properties of our developed method in a controlled toy setup before reporting results on  multi-label classification and two image-grounded sequence modeling tasks -- captioning and question generation.  We evaluate using standard task-specific metrics and measures of output diversity,  finding consistent improvements over standard maximum likelihood training and other baselines. 
 In domain classification for spoken dialog systems, correct detection of out-of-domain  utterances is crucial because it reduces confusion and unnecessary interaction costs between users and the systems. Previous work usually utilizes OOD detectors that are trained separately from in-domain  classifiers, and confidence thresholding for OOD detection given target evaluation scores. In this paper, we introduce a neural joint learning model for domain classification and OOD detection, where dynamic class weighting is used during the model training to satisfice a given OOD false acceptance rate  while maximizing the domain classification accuracy. Evaluating on two domain classification tasks for the utterances from a large spoken dialogue system, we show that our approach significantly improves the domain classification performance with satisficing given target FARs. 
 Automatic post-editing  systems aim to correct the systematic errors made by machine translators. In this paper, we propose a neural APE system that encodes the source  and machine translated  sentences with two separate encoders, but leverages a shared attention mechanism to better understand how the two inputs contribute to the generation of the post-edited  sentences. Our empirical observations have showed that when the mt is incorrect, the attention shifts weight toward tokens in the src sentence to properly edit the incorrect translation. The model has been trained and evaluated on the official data from the WMT16 and WMT17 APE IT domain English-German shared tasks. Additionally, we have used the extra 500K artificial data provided by the shared task. Our system has been able to reproduce the accuracies of systems trained with the same data, while at the same time providing better interpretability. 
 %A new whole-sentence language model - %neural trans-dimensional random field language model , %where sentences are modeled as a collection of random fields, %and the potential function is defined by a neural network, %has been introduced and successfully trained by noise-contrastive estimation . %In this paper, we extend NCE and propose dynamic noise-contrastive estimation  to solve the two problems observed in training neural TRF LMs with NCE. %First, a dynamic noise distribution is introduced and trained simultaneously to converge to the data distribution. This helps to significantly cut down the noise sample number used in NCE and reduce the training cost. %Second, DNCE discriminates between sentences generated from the noise distribution and sentences generated from the interpolation of the data distribution and the noise distribution. %This alleviates the overfitting problem caused by the sparseness of the training set. %With DNCE, we can successfully and efficiently train neural TRF LMs on large corpus  with large vocabulary . %We evaluate the neural TRF LMs and the DNCE method in term of rescoring error rates for speech recognition on three different datasets - Penn Treebank corpus, HKUST Chinese dataset and Google one-billion word benchmark. %These experiments demonstrate the language independence and scalability in applying neural TRF LMs. %Neural TRF LMs perform as good as LSTM LMs with less parameters and being 5x$\sim$114x faster in rescoring sentences. Interpolating neural TRF LMs with LSTM LMs and n-gram LMs can further reduce the error rates. A new whole-sentence language model - neural trans-dimensional random field language model , where sentences are modeled as a collection of random fields, and the potential function is defined by a neural network, has been introduced and successfully trained by noise-contrastive estimation . In this paper, we extend NCE and propose dynamic noise-contrastive estimation  to solve the two problems observed in NCE training. First, a dynamic noise distribution is introduced and trained simultaneously to converge to the data distribution. This helps to significantly cut down the noise sample number used in NCE and reduce the training cost. Second, DNCE discriminates between sentences generated from the noise distribution and sentences generated from the interpolation of the data distribution and the noise distribution. This alleviates the overfitting problem caused by the sparseness of the training set. With DNCE, we can successfully and efficiently train neural TRF LMs on large corpus  with large vocabulary . Neural TRF LMs perform as good as LSTM LMs with less parameters and being 5x$\sim$114x faster in rescoring sentences. Interpolating neural TRF LMs with LSTM LMs and n-gram LMs can further reduce the error rates. 
 We have three contributions in this work:  1. We explore the utility of a stacked denoising autoencoder and a paragraph vector model to learn task-independent dense patient representations directly from clinical notes. To analyze if these representations are transferable across tasks, we evaluate them in multiple supervised setups to predict patient mortality, primary diagnostic and procedural category, and gender. We compare their performance with sparse representations obtained from a bag-of-words model. We observe that the learned generalized representations significantly outperform the sparse representations when we have few positive instances to learn from, and there is an absence of strong lexical features. 2. We compare the model performance of the feature set constructed from a bag of words to that obtained from medical concepts. In the latter case, concepts represent problems, treatments, and tests. We find that concept identification does not improve the classification performance. 3. We propose novel techniques to facilitate model interpretability. To understand and interpret the representations, we explore the best encoded features within the patient representations obtained from the autoencoder model. Further, we calculate feature sensitivity across two networks to identify the most significant input features for different classification tasks when we use these pretrained representations as the supervised input. We successfully extract the most influential features for the pipeline using this technique. 
 % Multilingual Speech Recognition is one of the most costly AI problems, because each language  and even different accents require their own acoustic models to obtain best recognition performance.  Even though they all use the same phoneme symbols, each language and accent imposes its own coloring or 閳ユ涪wang閳.  Many adaptive approaches have been proposed, but they require further training, additional data and generally are inferior to monolingually trained models.  In this paper, we propose a different approach that uses a large multilingual model that is  by the codes generated by an ancillary network that learns to code useful differences between the 閳ユ涪wangs閳 or human language.   We use Meta-Pi networks  to have one network  gate the activity of neurons in another .  Our results show that during recognition multilingual Meta-Pi networks quickly adapt to the proper language coloring without retraining or new data, and perform better than monolingually trained networks. The model was evaluated by training acoustic modeling nets and modulating language code nets jointly and optimize them for best recognition performance.    % 
 Copying mechanism shows effectiveness in sequence-to-sequence based neural network models for text generation tasks, such as abstractive sentence summarization and question generation.  However, existing works on modeling copying or pointing mechanism only considers single word copying from the source sentences.  In this paper, we propose a novel copying framework, named Sequential Copying Networks , which not only learns to copy single words, but also copies sequences from the input sentence. It leverages the pointer networks to explicitly select a sub-span from the source side to target side, and integrates this sequential copying mechanism to the generation process in the encoder-decoder paradigm. Experiments on abstractive sentence summarization and question generation tasks show that the proposed \ourModel{} can copy meaningful spans and outperforms the baseline models. 
 Sentence scoring and sentence selection are two main steps in extractive document summarization systems. However, previous works treat them as two separated subtasks. In this paper, we present a novel end-to-end neural network framework for extractive document summarization by jointly learning to score and select sentences. It first reads the document sentences with a hierarchical encoder to obtain the representation of sentences. Then it builds the output summary by extracting sentences one by one. Different from previous methods, our approach integrates the selection strategy into the scoring model, which directly predicts the relative importance given previously selected sentences. Experiments on the CNN/Daily Mail dataset show that the proposed framework significantly outperforms the state-of-the-art extractive summarization models. 
   What makes some types of languages more probable than others?   For instance, we know that almost all spoken languages contain the   vowel phoneme /i/; why should that be? The field of linguistic typology   seeks to answer these questions and, thereby, divine the   mechanisms that underlie human language. In our work,   we tackle the problem of vowel system typology, i.e.,   we propose a generative probability model of which vowels a language contains.   In contrast to previous work, we work directly with the acoustic   information---the first two formant values---rather than modeling discrete sets of phonemic symbols . We develop a novel generative   probability model and report results based on a corpus of 233 languages. 
 Using natural language to give instructions to robots is challenging, since natural language understanding is still largely an open problem. In this paper we address this problem by restricting our attention to commands modeled as one action, plus arguments . For action detection  and slot filling various architectures of Recurrent Neural Networks and Long Short Term Memory  networks were evaluated, having LSTMs achieved a superior accuracy. As the action requested may not fall within the robot閳ユ獨 capabilities, a Support Vector Machine is used to determine whether it is or not. For the input of the neural networks, several word embedding algorithms were compared. Finally, to implement the system in a robot, a ROS package is created using a SMACH state machine. The proposed system is then evaluated both using well-known datasets and benchmarks in the context of domestic service robots.  
 		We present NMT-Keras, a flexible toolkit for training deep learning models, which puts a particular emphasis on the development of advanced applications of neural machine translation systems, such as interactive-predictive translation protocols and long-term adaptation of the translation system via continuous learning. 		NMT-Keras is based on an extended version of the popular Keras library, and it runs on Theano and TensorFlow. State-of-the-art neural machine translation models are deployed and used following the high-level framework provided by Keras. 		Given its high modularity and flexibility, it also has been extended to tackle different problems, such as image and video captioning, sentence classification and visual question answering. 	
 This paper describes our system  submitted to the  CoNLL 2018 shared task on Multilingual Parsing from Raw Text to  Universal Dependencies. We base our submission on Stanford's winning system for the CoNLL 2017 shared task and make two effective extensions:  1) incorporating deep contextualized word embeddings into both the part of speech tagger and dependency parser; 2) ensembling parsers trained with different initialization. We also explore different ways of concatenating treebanks for further improvements. Experimental results on the development data show the effectiveness of our methods. In the final evaluation, our system was ranked first according to LAS  and outperformed the other systems by a large margin.  
 Recurrent neural networks have been the dominant models for many speech and language processing tasks. However, we understand little about the behavior and the class of functions recurrent networks can realize. Moreover, the heuristics used during training complicate the analyses. In this paper, we study recurrent networks' ability to learn long-term dependency in the context of speech recognition. We consider two decoding approaches, online and batch decoding, and show the classes of functions to which the decoding approaches correspond. We then draw a connection between batch decoding and a popular training approach for recurrent networks, truncated backpropagation through time. Changing the decoding approach restricts the amount of past history recurrent networks can use for prediction, allowing us to analyze their ability to remember. Empirically, we utilize long-term dependency in subphonetic states, phonemes, and words, and show how the design decisions, such as the decoding approach, lookahead, context frames, and consecutive prediction, characterize the behavior of recurrent networks. Finally, we draw a connection between Markov processes and vanishing gradients. These results have implications for studying the long-term dependency in speech data and how these properties are learned by recurrent networks. 
  % A sonnet rhymes and each line follows an alternating stress pattern  % .  In this paper, we propose a joint architecture  that captures language, rhyme and meter for sonnet modelling.  We assess  the quality of generated poems using crowd and expert judgements.  The  stress and rhyme models perform very well, as generated poems are  largely indistinguishable from human-written poems.  Expert evaluation,  however, reveals that a vanilla language model captures meter implicitly,  and that machine-generated poems still underperform in terms of  readability and emotion. Our research shows the importance expert  evaluation for poetry generation, and that future research should look  beyond rhyme/meter and focus on poetic language.   
  Can advances in NLP help advance cognitive modeling? We examine the role of artificial neural networks, the current state of the art in many common NLP tasks, by returning to a classic case study.  In 1986, Rumelhart and McClelland famously introduced a neural architecture that learned to transduce English verb stems to their past tense forms. Shortly thereafter,  presented a comprehensive rebuttal of many of Rumelhart and McClelland's claims. Much of the force of their attack centered on the empirical inadequacy of the  model.  Today, however, that model is severely outmoded. We show that the Encoder-Decoder network architectures used  in modern NLP systems obviate most of Pinker and Prince's criticisms without requiring any simplification of the past tense mapping problem.  We suggest that the empirical performance of modern networks warrants a re{\"e}xamination of their utility in linguistic and cognitive modeling.  
 Deep learning approaches for sentiment classification do not fully exploit sentiment linguistic knowledge. In this paper, we propose a Multi-sentiment-resource Enhanced Attention Network  to alleviate the problem by integrating three kinds of sentiment linguistic knowledge  into the deep neural network via attention mechanisms. By using various types of sentiment resources, MEAN utilizes sentiment-relevant information from different representation sub-spaces, which makes it more effective to capture the overall semantics of the sentiment, negation and intensity words for sentiment prediction. The experimental results demonstrate that MEAN has robust superiority over strong competitors. 
   Implicit discourse relation recognition is a challenging task as the relation prediction without explicit connectives   in discourse parsing needs understanding of text spans and   cannot be easily derived from   surface features from the input sentence pairs.   Thus, properly representing the text is very crucial to this task.   In this paper, we propose a model augmented with different grained text representations,   including character, subword, word, sentence, and sentence pair levels.   The proposed deeper model is evaluated on the benchmark treebank and achieves   state-of-the-art accuracy with greater than 48\% in 11-way and $F_1$ score greater than 50\% in 4-way classifications   for the first time according to our best knowledge. 
     Deep learning techniques have recently shown to be successful in many natural language processing tasks forming state-of-the-art systems.     They require, however, a large amount of annotated data which is often missing. 	This paper explores the use of domain-adversarial learning as a regularizer to avoid overfitting when training domain invariant features for deep, complex neural networks in low-resource and zero-resource settings in new target domains or languages. In case of new languages, we show that monolingual word vectors can be directly used for training without prealignment.  Their projection into a common space can be learnt ad-hoc at training time reaching the final performance of pretrained multilingual word vectors.   	 	    NLP  
 In neural machine translation , the most common practice is to stack a number of recurrent or feed-forward layers in the encoder and the decoder. As a result, the addition of each new layer improves the translation quality significantly. However, this also leads to a significant increase in the number of parameters. In this paper, we propose to share parameters across all the layers thereby leading to a recurrently stacked NMT model. We empirically show that the translation quality of a model that recurrently stacks a single layer 6 times is comparable to the translation quality of a model that stacks 6 separate layers. We also show that using pseudo-parallel corpora by back-translation leads to further significant improvements in translation quality.  
  Chinese word segmentation  is an important task for Chinese NLP. Recently, many neural network based methods have been proposed for CWS. % Recently, many neural network based methods have been proposed for Chinese word segmentation. However, these methods require a large number of labeled sentences for model training, and usually cannot utilize the useful information in Chinese dictionary. In this paper, we propose two methods to exploit the dictionary information for CWS. % In this paper, we propose two methods to exploit the dictionary information for Chinese word segmentation. The first one is based on pseudo labeled data generation, and the second one is based on multi-task learning. The experimental results on two benchmark datasets validate that our approach can effectively improve the performance of Chinese word segmentation, especially when training data is insufficient.   
   Previous work has shown that neural encoder-decoder speech recognition can be improved with hierarchical multitask learning, where auxiliary tasks are added at intermediate layers of a deep encoder.     We explore the effect of hierarchical multitask learning in the context of connectionist temporal classification -based speech recognition, and investigate several aspects of this approach.    Consistent with previous work, we observe performance improvements on telephone conversational speech  recognition  when training a subword-level CTC model with an auxiliary phone loss at an intermediate layer.     We analyze the effects of a number of experimental variables ,  performance in lower-resource settings, and the relationship between    pretraining and multitask learning. We observe that the hierarchical multitask approach improves over standard multitask training in our higher-data experiments, while in the low-resource settings standard multitask training works well.  The best results are obtained by combining hierarchical multitask learning and pretraining, which improves word error rates by 3.4\% absolute on the Eval2000 test sets. 
 Can language analysis reveal the underlying social power relations that exist between participants of an interaction? Prior work within NLP has shown promise in this area, but the performance of automatically predicting power relations using NLP analysis of social interactions remains wanting. In this paper, we present a novel neural architecture that captures manifestations of power within individual emails which are then aggregated in an order-preserving way in order to infer the direction of power between pairs of participants in an email thread. We obtain an accuracy of 80.4\%, a 10.1\% improvement over state-of-the-art methods, in this task. We further apply our model to the task of predicting power relations between individuals based on the entire set of messages exchanged between them; here also, our model significantly outperforms the 70.0\% accuracy using prior state-of-the-art techniques, obtaining an accuracy of 83.0\%. 
  % We improve the performance and scalability of a standard neural BiLSTM+CRF NER tagger for morphologically rich languages.    Previous studies have shown that linguistic features of a word such as possession, genitive or other grammatical cases can be employed in word representations of a    named entity recognition  tagger   %\textcolor{red}{composed of a bidirectional long short-term memory coupled with a conditional random field }\todo{bu cikabilir belki}     to improve the performance for morphologically rich languages.    However, these taggers require external morphological disambiguation  tools to function which are hard to obtain or non-existent for many languages.   % There is also the problem of portability as freely available morphological disambiguator software are mostly distributed for differing operating environments and hardware.   In this work, we propose a model which alleviates the need for such disambiguators by jointly learning    NER and MD taggers in languages for which one can provide a list of candidate morphological analyses.   We show that this can be done independent of the morphological annotation schemes, which differ among languages.  Our experiments employing three different model architectures that join these two tasks show that joint learning improves NER performance.  Furthermore, the morphological disambiguator's performance is shown to be competitive. 
  Coronary artery disease  is one of the leading causes of cardiovascular disease deaths. CAD condition progresses rapidly, if not diagnosed and treated at an early stage may eventually lead to an irreversible state of the heart muscle death. Invasive coronary arteriography is the gold standard technique for CAD diagnosis. Coronary arteriography texts describe which part has stenosis and how much stenosis is in details. It is crucial to conduct the severity classification of CAD. In this paper, we employ a recurrent capsule network  to extract semantic relations between clinical named entities in Chinese coronary arteriography texts, through which we can automatically find out the maximal stenosis for each lumen to inference how severe CAD is according to the improved method of Gensini. Experimental results on the corpus collected from Shanghai Shuguang Hospital show that our proposed method achieves an accuracy of 97.0\% in the severity classification of CAD.  
      Determining the correct form of a verb in context requires an understanding of the syntactic structure of the sentence. Recurrent neural networks have been shown to perform this task with an error rate comparable to humans, despite the fact that they are not designed with explicit syntactic representations. To examine the extent to which the syntactic representations of these networks are similar to those used by humans when processing sentences, we compare the detailed pattern of errors that RNNs and humans make on this task. Despite significant similarities , the error patterns differed in important ways. In particular, in complex sentences with relative clauses error rates increased in RNNs but decreased in humans. Furthermore, RNNs showed a cumulative effect of attractors but humans did not. We conclude that at least in some respects the syntactic representations acquired by RNNs are fundamentally different from those used by humans.  Keywords:  Psycholinguistics; syntax; recurrent neural networks; agreement attraction 
 %This paper proposes multiple novel ways to perform automatic speech recognition using different sets of target units in end-to-end models.  %Deep Neural Networks are known to be good intermediate representation learners.    %This paper have two major contributions.  First, by providing intermediate supervision in the proposed architecture, units of higher level of abstraction get improvements by exploiting the intrinsic compositionality using lower level of abstraction.  %\footnote{Recipie will be released as open-source software upon acceptance of the paper.}. % Todo: I would remove the footnote. If you want to keep it, move it to the main body of text somehwere.   %TODO:  In Automatic Speech Recognition, it is still challenging to learn useful intermediate representations when using high-level  target units such as words. For that reason, when only a few hundreds of hours of training data are available, character or phoneme-based systems tend to outperform word-based systems. In this paper, we show how Hierarchical Multitask Learning can encourage the formation of useful intermediate representations. We achieve this by performing Connectionist Temporal Classification at different levels of the network with targets of different granularity. Our model thus performs predictions in multiple scales for the same input. On the standard 300h Switchboard training setup, our hierarchical multitask architecture demonstrates improvements over singletask architectures with the same number of parameters. Our model obtains 14.0\% Word Error Rate on the Switchboard subset of the Eval2000 test set without any decoder or language model, outperforming the current state-of-the-art on non-autoregressive Acoustic-to-Word models.   %We hypothesize that using intermediate representations as auxiliary supervision at lower levels of deep networks may be a good way of combining the advantages of end-to-end training and more traditional pipeline approaches. 
 % abstract             Clinical text classification is an important problem in medical natural language processing.             Existing studies have conventionally focused on rules or knowledge sources-based feature engineering, but only a few have exploited effective feature learning capability of deep learning methods.              In this study, we propose a novel approach which combines rule-based features and knowledge-guided deep learning techniques for effective disease classification.              Critical Steps of our method include identifying trigger phrases, predicting classes with very few examples using trigger phrases and training a convolutional neural network with word embeddings and Unified Medical Language System  entity embeddings.             We evaluated our method on the 2008 Integrating Informatics with Biology and the Bedside  obesity challenge.             The results show that our method outperforms the state of the art methods.         
 %Shared, multilingual representations, offer intriguing possibilities for the Intelligence Community, in addressing cyber threat in a multitude of languages.   The multilingual nature of the Internet increases complications in the cybersecurity community's ongoing efforts to strategically mine threat intelligence from OSINT data on the web. OSINT sources such as social media, blogs, and dark web vulnerability markets exist in diverse languages and hinder security analysts, who are unable to draw conclusions from intelligence in languages they don't understand. Although third party translation engines are growing stronger, they are unsuited for private security environments. First, sensitive intelligence is not a permitted input to third party engines due to privacy and confidentiality policies. In addition, third party engines produce generalized translations that tend to lack exclusive cybersecurity terminology. In this paper, we address these issues and describe our system that enables threat intelligence understanding across unfamiliar languages. We create a neural network based system that takes in cybersecurity data in a different language and outputs the respective English translation.  The English translation can then be understood by an analyst, and can also serve as input to an AI based cyber-defense system that can take mitigative action. As a proof of concept, we have created a pipeline which takes Russian threats and generates its corresponding English, RDF, and vectorized representations. Our network optimizes translations on specifically, cybersecurity data.  % We have created a multilingual translation architecture that utilizes word embeddings created from Russian and English threat intelligence data in a neural machine translation network that translates and maps Russian cyber embeddings to their English counterparts.   %In regards to explicitly cybersecurity data rather than general data, our translation systems performs better than third party engines. %We also demonstrate that our system optimizes translation results for security related tasks, in comparison to other translation systems. 
 Machine comprehension question answering, which finds an answer to the question given a passage, involves high-level reasoning processes of understanding and tracking the relevant contents across various semantic units such as words, phrases, and sentences in a document. This paper proposes the novel question-aware sentence gating networks that directly incorporate the sentence-level information into word-level encoding processes. To this end, our model first learns question-aware sentence representations and then dynamically combines them with word-level representations, resulting in semantically meaningful word representations for QA tasks. Experimental results demonstrate that our approach consistently improves the accuracy over existing baseline approaches on various QA datasets and bears the wide applicability to other neural network-based QA models.   
 Offline handwritten text recognition from images is an important problem for enterprises attempting to digitize large volumes of handmarked scanned documents/reports. Deep recurrent models such as Multi-dimensional LSTMs  have been shown to yield superior performance over traditional Hidden Markov Model based approaches that suffer from the Markov assumption and therefore lack the representational power of RNNs. In this paper we introduce a novel approach that combines a deep convolutional network with a recurrent Encoder-Decoder network to map an image to a sequence of characters corresponding to the text present in the image. The entire model is trained end-to-end using Focal Loss , an improvement over the standard Cross-Entropy loss that addresses the class imbalance problem, inherent to text recognition. To enhance the decoding capacity of the model, Beam Search algorithm is employed which searches for the best sequence out of a set of hypotheses based on a joint distribution of individual characters. Our model takes as input a downsampled version of the original image thereby making it both computationally and memory efficient. The experimental results were benchmarked against two publicly available datasets, IAM and RIMES. We surpass the state-of-the-art word level accuracy on the evaluation set of both datasets by $3.5\%$ \& $1.1\%$, respectively.    
   % In this paper we argue that since the beginning of computational linguistics there has been a strong connection between logic and machine learning. First, there is something logical about language or linguistic about logic. Second, we argue that rather than distinguishing between logic and machine learning, a more useful distinction is between   Natural language processing  can be done using either top-down  and bottom-up  approaches, which we call  and  respectively. The approaches are frequently considered to stand in opposition to each other. Examining some   recent approaches in deep learning we argue that deep neural networks   incorporate both perspectives and, furthermore, that leveraging this aspect of deep learning may help in solving complex problems within language technology, such as modelling language and perception in the domain of spatial cognition. %  this is the reason for their very successful adoption to solve several problems within language technology. 
 Discovering whether words are semantically related and identifying the specific semantic relation that holds between them is of crucial importance for NLP as it is essential for tasks like query expansion in IR. Within this context, different methodologies have been proposed that either exclusively focus on a single lexical relation  or learn specific classifiers capable of identifying multiple semantic relations . In this paper, we propose another way to look at the problem that relies on the multi-task learning paradigm. In particular, we want to study whether the learning process of a given semantic relation  can be improved by the concurrent learning of another semantic relation . Within this context, we particularly examine the benefits of semi-supervised learning where the training of a prediction function is performed over few labeled data jointly with many unlabeled ones. Preliminary results based on simple learning strategies and state-of-the-art distributional feature representations show that concurrent learning can lead to improvements in a vast majority of tested situations.       
 We present a deep generative model of bilingual sentence pairs for machine translation. The model generates source and target sentences jointly from a shared latent representation and is parameterised by neural networks. We perform efficient training using amortised variational inference and reparameterised gradients. Additionally, we discuss the statistical implications of joint modelling and propose an efficient approximation to maximum a posteriori decoding for fast test-time predictions. We demonstrate the effectiveness of our model in three machine translation scenarios: in-domain training, mixed-domain training, and learning from a mix of gold-standard and synthetic data. Our experiments show consistently that our joint formulation outperforms conditional modelling  in all such scenarios. % 
 Sequence labelling is the task of assigning categorical labels to a data sequence. In Natural Language Processing, sequence labelling can be applied to various fundamental problems, such as Part of Speech  tagging, Named Entity Recognition , and Chunking. In this study, we propose a method to add various linguistic features to the neural sequence framework to improve sequence labelling. Besides word level knowledge, sense embeddings are added to provide semantic information. Additionally, selective readings of character embeddings are added to capture contextual as well as morphological features for each word in a sentence. Compared to previous methods, these added linguistic features allow us to design a more concise model and perform more efficient training. Our proposed architecture achieves state of the art results on the benchmark datasets of POS, NER, and chunking. Moreover, the convergence rate of our model is significantly better than the previous state of the art models. 
  Over the last several years, the field of natural language processing has been propelled forward by an explosion in the use of deep learning models. This survey provides a brief introduction to the field and a quick overview of deep learning architectures and methods. It then sifts through the plethora of recent studies and summarizes a large assortment of relevant contributions. Analyzed research areas include several core linguistic processing issues in addition to a number of applications of computational linguistics. A discussion of the current state of the art is then provided along with recommendations for future research in the field.  
 Convolutional neural network  and recurrent neural network  models have become the mainstream methods for relation classification. We propose a unified architecture, which exploits the advantages of CNN and RNN simultaneously, to identify medical relations in clinical records, with only word embedding features. Our model learns phrase-level features through a CNN layer, and these feature representations are directly fed into a bidirectional gated recurrent unit  layer to capture long-term feature dependencies. We evaluate our model on two clinical datasets, and experiments demonstrate that our model performs significantly better than previous single-model methods on both datasets. 
 In neural machine translation , the computational cost at the output layer increases with the size of the target-side vocabulary.  Using a limited-size vocabulary instead may cause a significant decrease in translation quality. This trade-off is derived from a softmax-based loss function that handles in-dictionary words independently, in which word similarity is not considered. In this paper, we propose a novel NMT loss function that includes word similarity in forms of distances in a word embedding space. The proposed loss function encourages an NMT decoder to generate words close to their references in the embedding space; this helps the decoder to choose similar acceptable words when the actual best candidates are not included in the vocabulary due to its size limitation. In experiments using ASPEC Japanese-to-English and IWSLT17 English-to-French data sets, the proposed method showed improvements against a standard NMT baseline in both data sets; especially with IWSLT17 En-Fr, it achieved up to +1.72 in BLEU and +1.99 in METEOR. When the target-side vocabulary was very limited to 1,000 words, the proposed method demonstrated a substantial gain, +1.72 in METEOR with ASPEC Ja-En. 
 We present a new recurrent neural network topology to enhance state-of-the-art machine learning systems by incorporating a broader context. Our approach overcomes recent limitations with extended narratives through a multi-layered computational approach to generate an abstract context representation. Therefore, the developed system captures the narrative on word-level, sentence-level, and context-level. Through the hierarchical set-up, our proposed model summarizes the most salient information on each level and creates an abstract representation of the extended context. We subsequently use this representation to enhance neural language processing systems on the task of semantic error detection.   To show the potential of the newly introduced topology, we compare the approach against a context-agnostic set-up including a standard neural language model and a supervised binary classification network. The performance measures on the error detection task show the advantage of the hierarchical context-aware topologies, improving the baseline by 12.75\% relative for unsupervised models and 20.37\% relative for supervised models. 
 		Manually labeled corpora are expensive to create and often not available for low-resource languages or domains. Automatic labeling approaches are an alternative way to obtain labeled data in a quicker and cheaper way. However, these labels often contain more errors which can deteriorate a classifier's performance when trained on this data. We propose a noise layer that is added to a neural network architecture. This allows modeling the noise and train on a combination of clean and noisy data. We show that in a low-resource NER task we can improve performance by up to 35\% by using additional, noisy data and handling the noise. 		 	
 For a company looking to provide delightful user experiences, it is of paramount importance to take care of any customer issues. This paper proposes COTA, a system to improve speed and reliability of customer support for end users through automated ticket classification and answers selection for support representatives. Two machine learning and natural language processing techniques are demonstrated: one relying on feature engineering  and the other exploiting raw signals through deep learning architectures . COTA v1 employs a new approach that converts the multi-classification task into a ranking problem, demonstrating significantly better performance in the case of thousands of classes. For COTA v2, we propose an Encoder-Combiner-Decoder, a novel deep learning architecture that allows for heterogeneous input and output feature types and injection of prior knowledge through network architecture choices. This paper compares these models and their variants on the task of ticket classification and answer selection, showing model COTA v2 outperforms COTA v1, and analyzes their inner workings and shortcomings. Finally, an A/B test is conducted in a production setting validating the real-world impact of COTA in reducing issue resolution time by 10 percent without reducing customer satisfaction.  
  In early years, text classification is typically accomplished by feature-based machine learning models; recently, deep neural networks, as a powerful learning machine, make it possible to work with raw input as the text stands. However, exiting end-to-end neural networks lack explicit interpretation of the prediction. In this paper, we propose a novel framework, \jumper, inspired by the cognitive process of text reading, that models text classification as a sequential decision process. Basically, \jumperb is a neural system that scans a piece of text sequentially and makes classification decisions at the time it wishes. Both the classification result and when to make the classification are part of the decision process, which is controlled by a policy network and trained with reinforcement learning. Experimental results show that a properly trained \jumperb has  the following properties:  It can make decisions whenever the evidence is enough,  therefore reducing total text reading by 30閳40\% and often finding the key rationale of prediction.  It achieves classification accuracy better than or comparable to state-of-the-art models in several benchmark and industrial datasets. 
 %Our industrial data in ticketing system is comprised of subject, description and solution pairs of variable-length sequences, %  where the subject is a short text but description and solution  % are multi-sentences.  The goal of our industrial ticketing system is to retrieve a relevant solution for an input query,  by matching with historical tickets stored in knowledge base.  A query is comprised of subject and description, while a historical ticket consists of subject, description and solution.   To retrieve a relevant solution, we use textual similarity paradigm to learn similarity in the query and historical tickets.  The task is challenging due to significant term mismatch in the query and ticket pairs of asymmetric lengths, where subject is a short text  but description and solution are multi-sentence texts.  %The goal is to retrieval an optimal solution from the historical tickets for the input query.   We present a novel Replicated Siamese LSTM model to learn similarity in asymmetric text pairs, that  gives 22\% and 7\% gain  for retrieval task, respectively over unsupervised and supervised baselines. We also show that the topic and distributed semantic features for short and long texts improved both similarity learning and retrieval.%with the ticketing system.  %We present an extension of Siamese Long Short-Term %Memory  networks for semantic similarity  %learning in sentence pairs to subject-description-solution text pairs, incorporating    %the pairwise similarities in multi-level  and/or   %cross-level   texts.   %We propose a cross-level neural similarity learning in asymmetric text pairs via Siamese LSTM and supplement the similarity metric   %with distributed and topic semantics for short and long texts via multi-channel input.   %We propose a novel multi-channel neural architecture for scoring similarity between paragraph pairs, instead of %a single %  sentence pairs.    %We also supplement the similarity metric with word and sentence sequences representations from word embeddings,   %along with their latent vectors.  %The architecture is introduced in Intelligence Ticketing System   %to investigate its capabilities for similarity learning     %in descriptions of tickets\footnote{tickets and Issues  used interchangeably}, leveraging subjects and solutions. We present an improved performance in    %retrieval of similar issues and recommendation of solution for the reporting issues.   % evaluated using various information retrieval metrics. 
 Deep reinforcement learning has recently shown many impressive successes. However, one major obstacle towards applying such methods to real-world problems is their lack of data-efficiency. To this end, we propose the Bottleneck Simulator: a model-based reinforcement learning method which combines a learned, factorized transition model of the environment with rollout simulations to learn an effective policy from few examples. The learned transition model employs an abstract, discrete  state, which increases sample efficiency by reducing the number of model parameters and by exploiting structural properties of the environment. %, mediating the transitions between successive full states of the process. We provide a mathematical analysis of the Bottleneck Simulator in terms of fixed points of the learned policy, which reveals how performance is affected by four distinct sources of error: an error related to the abstract space structure, an error related to the transition model estimation variance, an error related to the transition model estimation bias, and an error related to the transition model class bias. Finally, we evaluate the Bottleneck Simulator on two natural language processing tasks:  a text adventure game and a real-world, complex dialogue response selection task. On both tasks, the Bottleneck Simulator yields excellent performance beating competing approaches. 
 Search typically relies on keyword queries, but these are often semantically ambiguous.  We propose to overcome this by offering users natural language questions, based on their keyword queries, to disambiguate their intent.  This keyword-to-question task may be addressed using neural machine translation techniques.  Neural translation models, however, require massive amounts of training data , which is unavailable for this task.  The main idea of this paper is to generate large amounts of synthetic training data from a small seed set of hand-labeled keyword-question pairs.  Since natural language questions are available in large quantities, we develop models to automatically generate the corresponding keyword queries.  Further, we introduce various filtering mechanisms to ensure that synthetic training data is of high quality.  We demonstrate the feasibility of our approach using both automatic and manual evaluation. This is an extended version of the article published with the same title in the Proceedings of ICTIR'18.  
 %% Text of abstract Measuring similarities between strings is central for many established and fast growing research areas including information retrieval, biology, and natural language processing. The traditional approach for string similarity measurements is to define a metric over a word space that quantifies and sums up the differences between characters in two strings. The state-of-the-art in the area has, surprisingly, not evolved much during the last few decades. The majority of the metrics are based on a simple comparison between character and character distributions without consideration for the context of the words. This paper proposes a string metric that encompasses similarities between strings based on  the character similarities between the words including. Non-Standard and standard spellings of the same words, and  the context of the words. Our proposal is a neural network composed of a denoising autoencoder and what we call a context encoder specifically designed to find similarities between the words based on their context. The experimental results show that the resulting metrics succeeds in 85.4\% of the cases in finding the correct version of a non-standard spelling among the closest words, compared to 63.2\% with the established Normalised-Levenshtein distance. Besides, we show that words used in similar context are with our approach calculated to be similar than words with different contexts, which is a desirable property missing in established string metrics.  
 Herein, we generate pseudo-features based on the multivariate probability distributions obtained from the feature maps in layers of trained deep neural networks. Further, we augment the minor-class data based on these generated pseudo-features to overcome the imbalanced data problems.  The proposed method, i.e., cavity filling, improves the deep learning capabilities in several problems because all the real-world data are observed to be imbalanced.  %We synthesis imbalanced data from ImageNet, and our proposed method improves accuracy from $42.96\%$ to $46.39\%$. %\footnote{The code will be available at  {\url{https://goo.gl/SPsSDh}}.  The presentation slides are available at this {{URL}} in English and at this {{URL}} in Japanese.}.  
 This paper examines to what degree current deep learning architectures for image caption generation capture spatial language. On the basis of the evaluation of examples of generated captions from the literature we argue that systems capture  objects are in the image data but not  these objects are located: the captions generated by these systems are the output of a language model conditioned on the output of an object detector that cannot capture fine-grained location information. Although language models provide useful knowledge for image captions, we argue that deep learning image captioning architectures should also model geometric relations between objects.  
 Knowledge graphs have emerged as an important model for studying complex multi-relational data. This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources. An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications. To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage entity linkage and build an efficient multi-task training procedure. Experiments on link prediction and entity linkage demonstrate substantial improvements over the state-of-the-art relational learning approaches.  
 Extracting textual features from tweets is a challenging process due to the noisy nature of the content and the weak signal of most of the words used. In this paper, we propose using singular value decomposition  with clustering to enhance the signals of the textual features in the tweets to improve the correlation with events. The proposed technique applies SVD to the time series vector for each feature to factorize the matrix of feature/day counts, in order to ensure the independence of the feature vectors. Afterwards, the K-means clustering is applied to build a look-up table that maps members of each cluster to the cluster-centroid. The lookup table is used to map each feature in the original data to the centroid of its cluster, then we calculate the sum of the term frequency vectors of all features in each cluster to the term-frequency-vector of the cluster centroid. To test the technique we calculated the correlations of the cluster centroids with the golden standard record  vector before and after summing the vectors of the cluster members to the centroid-vector. The proposed method is applied to multiple correlation techniques including the Pearson, Spearman, distance correlation and Kendal Tao. The experiments have also considered the different word forms and lengths of the features including keywords, n-grams, skip-grams and bags-of-words. The correlation results are enhanced significantly as the highest correlation scores have increased from 0.3 to 0.6, and the average correlation scores have increased from 0.3 to 0.4.   
 %Nowadays, editors tend to separate different subtopics of a long Wikipedia article into multiple { assumption, which requires each entity  to be described solely by one article. %These techniques include but are not limited to knowledge base construction, cross-lingual knowledge alignment, semantic search and data lineage of Wikipedia entities. %Thus, sub-article matching is highly desired for Wikipedia, which helps restore the scattered pieces of knowledge to whole views, and better support the above Wikipedia-based techniques. %In this paper, we propose a neural article pair model to address the sub-article matching problem. %The model adopts a hierarchical learning structure that combines variants of neural document encoders with a comprehensive set of explicit features. %To generalize the problem, a large dataset is created via massive crowdsourcing and strategic rules. %The proposed model achieves promising results of cross-validation and significantly outperforms previous approaches on the large dataset. %Serving of the proposed model on the entire English Wikipedia also indicates it to be beneficial to the construction of a large-scale knowledge base by effectively extracting a vast collection of main and sub-article pairs. %
 The fundamental frequency  represents pitch in speech that determines prosodic characteristics of speech and is needed in various tasks for speech analysis and synthesis. Despite decades of research on this topic, $F0$ estimation at low signal-to-noise ratios  in unexpected noise conditions remains difficult. This work proposes a new approach to noise robust $F0$ estimation using a recurrent neural network  trained in a supervised manner. Recent studies employ deep neural networks  for $F0$ tracking as a frame-by-frame classification task into quantised frequency states but we propose  instead to achieve both noise robustness and accurate estimation with increased frequency resolution.  Experimental results with  corpus contaminated by additive noise  demonstrate that the proposed method improves gross pitch error  rate and fine pitch error  by more than 35 \% at SNRs between -10 dB and +10 dB compared with well-known noise robust $F0$ tracker, PEFAC. Furthermore, the proposed method also outperforms state-of-the-art DNN-based approaches by more than 15 \% in terms of both FPE and GPE rate over the preceding SNR range. 
 In this paper, we investigate the use of adversarial learning for unsupervised adaptation to unseen recording conditions, more specifically, single microphone far-field speech.  We adapt neural networks based acoustic models trained with close-talk clean speech to the new recording conditions using untranscribed adaptation data.  Our experimental results on Italian SPEECON data set show that our proposed method achieves 19.8\% relative word error rate  reduction compared to the unadapted models. Furthermore, this adaptation method is beneficial even when performed on data from another language  giving 12.6\% relative WER reduction. 
Humans read by making a sequence of fixations and   saccades. They often skip words, without apparent detriment to   understanding. We offer a novel explanation for skipping: readers   optimize a tradeoff between performing a language-related task and   fixating as few words as possible. We propose a neural architecture   that combines an attention module    and a task module . We show that our model   predicts human skipping behavior, while also modeling reading times   well, even though it skips 40\% of the input. A key prediction of   our model is that different reading tasks should result in different   skipping behaviors. We confirm this prediction in an eye-tracking   experiment in which participants answers questions about a text. We   are able to capture these experimental results using the our model,   replacing the memorization module with a task module that performs   neural question answering.
 Through the development of neural machine translation, the quality of machine translation systems has been improved significantly. By exploiting advancements in deep learning, systems are now able to better approximate the complex mapping from source sentences to target sentences. But with this ability, new challenges also arise. An example is the translation of partial sentences in low-latency speech translation. Since the model has only seen complete sentences in training, it will always try to generate a complete sentence, though the input may only be a partial sentence.  We show that NMT systems can be adapted to scenarios where no task-specific training data is available. Furthermore, this is possible without losing performance on the original training data. We achieve this by creating artificial data and by using multi-task learning. After adaptation, we are able to reduce the number of corrections displayed during incremental output construction by 45\%, without a decrease in translation quality. 
 Speech recognition is a { symbols to construct competing hypotheses, feasible and efficient sequence discriminative training approaches are proposed for acoustic KWS. Experiments showed that the  proposed approaches obtained consistent and significant improvement in both fixed vocabulary and unrestricted KWS tasks, compared to previous frame-level deep learning based acoustic KWS methods. %In addition, even in fixed vocabulary KWS experiments, the proposed unrestricted KWS approach also significantly outperformed the state-of-the-art fixed vocabulary KWS approach.    %can be trained with sequence prediction criteria using exactly the %same lattice-based methods that have been developed for Gaussian %mixture HMMs, and that using a sequence prediction criterion in %training leads to considerably better performance %In connectionist temporal classification  framework, the implicit competing hypothesis modeling problem based on $\tt blank$ is solved by further introduction of non-keyword model units.  %Acoustic models used in deep learning based keyword spotting  are usually trained with %a frame level cross-entropy error criterion.  %As automatic speech recognition  is inherently a sequence %classification problem, applying sequence level criteria in the acoustic modeling has achieved great successes, especially in the  large vocabulary continuous speech recognition . %The paper aims to improve deep learning based KWS by sequence discriminate training.   %In contrast, Gaussian %mixture HMM systems are discriminatively trained using sequence based criteria, such as minimum phone error or maximum mutual information, that are more directly related to speech recognition accuracy.   
 % % % % % % % % %  % % % % % % % % %  % In this work, we focus on a lightweight convolutional architecture that creates fixed-size vector embeddings of sentences.  Such representations are useful for building NLP systems, including conversational agents. Our work derives from a recently proposed recursive convolutional  architecture for auto-encoding text paragraphs at byte level. We propose alternations that significantly reduce training time, the number of parameters,  and improve auto-encoding accuracy. Finally, we evaluate the representations created by our model on tasks from SentEval benchmark suite, and show that it can serve as a better, yet fairly low-resource alternative to popular bag-of-words embeddings.  
 Recurrent neural networks  are temporal networks and cumulative in nature that have shown promising results   in various natural language processing tasks. Despite their success, it still remains a challenge to understand their hidden behavior.    In this work, we analyze and interpret the cumulative nature of  RNN via a proposed technique named as {: ``{How an RNN accumulates or builds semantics during its sequential processing for a given text example and expected response}"   {".   We analyse the sensitiveness of RNNs about different inputs to check the increase or decrease in prediction scores and further extract  the saliency patterns learned by the network. % for each category in the data.  We employ two relation classification datasets: SemEval 10 Task 8 and TAC KBP Slot Filling to  explain RNN predictions via the {.    %and  % %We then perform  %Sensitivity analysis via distortion, where we identify the impact of word order in the sentence and saliency pattern to  %check the increase or decrease in prediction scores when changed.    %We extract the saliency patterns for each category in the data.  \iffalse In this work, we analyse recurrent neural networks  to interpret their learning and decision making via pattern extraction.  We show that RNNs accumulate the semantic meaning of a sentence by recursively learning over sequence of words and detect  saliency pattern for the target task.  We propose a method, named as Layer-wIse Semantic Accumulation  to show RNN's semantic accumulation behavior  and extract representative patterns learned in decision making over 3 different NLP tasks: relation classification , sentiment analysis   and document categorization .   \fi  
 Training deep recurrent neural network  architectures is complicated due to the increased network complexity. This disrupts the learning of higher order abstracts using deep RNN. In case of feed-forward networks training deep structures is simple and faster while learning long-term temporal information is not possible. In this paper we propose a residual memory neural network  architecture to model short-time dependencies using deep feed-forward layers having residual and time delayed connections. The residual connection paves way to construct deeper networks by enabling unhindered flow of gradients and the time delay units capture temporal information with shared weights. The number of layers in RMN signifies both the hierarchical processing depth and temporal depth. The computational complexity in training RMN is significantly less when compared to deep recurrent networks. RMN is further extended as bi-directional RMN  to capture both past and future information. Experimental analysis is done on AMI corpus to substantiate the capability of RMN in learning long-term information and hierarchical information. Recognition performance of RMN trained with 300 hours of Switchboard corpus is compared with various state-of-the-art LVCSR systems. The results indicate that RMN and BRMN gains 6 \% and 3.8 \% relative improvement over LSTM and BLSTM networks. 
   This document contains the instructions for preparing a paper submitted   to COLING-2018 or accepted for publication in its proceedings. The document itself   conforms to its own specifications, and is therefore an example of   what your manuscript should look like. These instructions should be   used for both papers submitted for review and for final versions of   accepted papers. Authors are asked to conform to all the directions   reported in this document. 
 Domain Adaptation arises when we aim at learning from source domain a model that can perform acceptably well on a different target domain. It is especially crucial for Natural Language Generation  in Spoken Dialogue Systems when there are sufficient annotated data in the source domain, but there is a limited labeled data in the target domain. How to effectively utilize as much of existing abilities from source domains is a crucial issue in domain adaptation.  In this paper, we propose an adversarial training procedure to train a Variational encoder-decoder based language generator via multiple adaptation steps. In this procedure, a model is first trained on a source domain data and then fine-tuned on a small set of target domain utterances under the guidance of two proposed critics.   Experimental results show that the proposed method can effectively leverage the existing knowledge in the source domain to adapt to another related domain by using only a small amount of in-domain data.  
 Clinicians spend a significant amount of time inputting free-form textual notes into Electronic Health Records  systems. Much of this documentation work is seen as a burden, reducing time spent with patients and contributing to clinician burnout. With the aspiration of AI-assisted note-writing, we propose a new language modeling task predicting the content of notes conditioned on past data from a patient's medical record, including patient demographics, labs, medications, and past notes. We train generative models using the public, de-identified MIMIC-III dataset and compare generated notes with those in the dataset on multiple measures. We find that much of the content can be predicted, and that many common templates found in notes can be learned. We discuss how such models can be useful in supporting assistive note-writing features such as error-detection and auto-complete. 
 % One of the main challenges in ranking is embedding the query and document pairs into a joint % feature space that can then be fed to a learning-to-rank algorithm. It is common to perform intensive feature engineering that encode the similarity in the pair to achieve this representation. Recently, deep-learning solutions have shown that this representation can be achieved by only learning it from data and reaching superior results in ranking. However, those models perform poorly on longer texts or on texts with a significant part of irrelevant information or which are grammatically incorrect. To overcome this limitation, we present the use of attention mechanisms which help the model learn on which words and phrases to focus on when building the mutual representation. We show superior results on several real-world question-answer ranking datasets and provide visualization of the attention mechanism that provides more insight to how those mechanisms work. %Replaced by Eugene One of the main challenges in ranking is embedding the query and document pairs into a joint feature space, which can then be fed to a learning-to-rank algorithm. To achieve this representation, the conventional state of the art approaches perform extensive feature engineering that encode the similarity of the query-answer pair. Recently, deep-learning solutions have shown that it is possible to achieve comparable performance, in some settings, by learning the similarity representation directly from data. Unfortunately, previous models perform poorly on longer texts, or on texts with significant portion of irrelevant information, or which are grammatically incorrect. To overcome these limitations, we propose a novel ranking algorithm for question answering, \NAME, which uses an attention mechanism to learn on which words and phrases to focus when building the mutual representation. We demonstrate superior ranking performance on several real-world question-answer ranking datasets, and provide visualization of the attention mechanism to offer more insights into how our models of attention could benefit ranking for difficult question answering challenges. 
 In this paper, we describe a tool for debugging the output and attention weights of neural machine translation  systems and for improved estimations of confidence about the output based on the attention. The purpose of the tool is to help researchers and developers find weak and faulty example translations that their NMT systems produce without the need for reference translations. Our tool also includes an option to directly compare translation outputs from two different NMT engines or experiments. In addition, we present a demo website of our tool with examples of good and bad translations: \url{http://attention.lielakeda.lv}.  
   %% Place your abstract here This paper presents our latest investigation on Densely Connected Convolutional Networks  for acoustic modelling  in automatic speech recognition. DenseN-ets are very deep, compact convolutional neural networks, which have demonstrated incredible improvements over the state-of-the-art results on several data sets in computer vision. Our experimental results show that DenseNet can be used for AM significantly outperforming other neural-based models such as DNNs, CNNs, VGGs. Furthermore, results on Wall Street Journal revealed that with only a half of the training data DenseNet was able to outperform other models trained with the full data set by a large margin. 
 We replicate a variation of the image captioning architecture by , then introduce dropout during inference mode to simulate the effects of neurodegenerative diseases like Alzheimer's disease  and Wernicke's aphasia . We evaluate the effects of dropout on language production by measuring the KL-divergence of word frequency distributions and other linguistic metrics as dropout is added. We find that the generated sentences most closely approximate the word frequency distribution of the training corpus when using a moderate dropout of 0.4 during inference. 
 Knowledge Graph Embedding  aims to represent entities and relations of knowledge graph in a low-dimensional continuous vector space. Recent works focus on incorporating structural knowledge with additional information, such as entity descriptions, relation paths and so on. However, common used additional information usually contains plenty of noise, which makes it hard to learn valuable representation. In this paper, we propose a new kind of additional information, called entity neighbors, which contain both semantic and topological features about given entity. We then develop a deep memory network model to encode information from neighbors. Employing a gating mechanism, representations of structure and neighbors are integrated into a joint representation. The experimental results show that our model outperforms existing KGE methods utilizing entity descriptions and achieves state-of-the-art metrics on 4 datasets. 
 Current state-of-the-art machine translation systems are based on encoder-decoder architectures, that first encode the input sequence, and then generate an output sequence based on the input encoding. Both are interfaced with an attention mechanism that recombines a fixed encoding of the source tokens based on the decoder state. We propose an alternative approach which instead relies on a single 2D convolutional neural network across both sequences. Each layer of our network re-codes source tokens on the basis of the output sequence produced so far. Attention-like properties are therefore pervasive throughout the network. Our model yields results that are competitive with state-of-the-art encoder-decoder systems, while being conceptually simpler and having fewer parameters. 
 Deep learning models have achieved remarkable success in natural language inference  tasks. While these models are widely explored, they are hard to interpret and it is often unclear how and why they actually work. In this paper, we take a step toward explaining such deep learning based models through a case study on a popular neural model for NLI. In particular, we propose to interpret the intermediate layers of NLI models by visualizing the saliency of attention and LSTM gating signals. We present several examples for which our methods are able to reveal interesting insights and identify the critical information contributing to the model decisions.  	
  Generating natural questions from an image is a semantic task that requires using visual and language modality to learn multimodal representations. Images can have multiple visual and language contexts that are relevant for generating questions namely places, captions, and tags. In this paper, we propose the use of exemplars for obtaining the relevant context. %Rather than relying on explicit context tags obtained through exemplars, we consider implicit context obtained by learning an embedding.  We obtain this by using a Multimodal Differential Network to produce natural and engaging questions. The generated questions show a remarkable similarity to the natural questions as validated by a human study.  % Ablation studies show that the proposed architecture is most suited for the question generation task. Further, we observe that the proposed approach substantially improves over state-of-the-art benchmarks on the quantitative metrics .  
 Named entity recognition  is used to identify relevant entities in text. A bidirectional LSTM  encoder with a neural conditional random fields  decoder  is the state of the art methodology. In this work, we have done an analysis of several methods that intend to optimize the performance of networks based on this architecture, which in some cases encourage overfitting avoidance. These methods target exploration of parameter space, regularization of LSTMs and penalization of confident output distributions. Results show that the optimization methods improve the performance of the biLSTM-CRF NER baseline system, setting a new state of the art performance for the \connll Spanish set with an F1 of 87.18.  
 		 Although Neural Machine Translation  has achieved remarkable progress in the past several years, most NMT systems still suffer from a fundamental shortcoming as in other sequence generation tasks: errors made early in generation process are fed as inputs to the model and can be quickly amplified, harming subsequent sequence generation. To address this issue, we propose a novel model regularization method for NMT training, which aims to improve the agreement between translations generated by left-to-right  and right-to-left  NMT decoders. This goal is achieved by introducing two Kullback-Leibler divergence regularization terms into the NMT training objective to reduce the mismatch between output probabilities of L2R and R2L models. In addition, we also employ a joint training strategy to allow L2R and R2L models to improve each other in an interactive update process. Experimental results show that our proposed method significantly outperforms state-of-the-art baselines on Chinese-English and English-German translation tasks. 		 
 Humans can imagine a scene from a sound. We want machines to do so by using conditional generative adversarial networks . By applying the techniques including spectral norm, projection discriminator and auxiliary classifier, compared with naive conditional GAN, the model can generate images with better quality in terms of both subjective and objective evaluations. Almost three-fourth of people agree that our model have the ability to generate images related  to sounds. By inputting different volumes of the same sound, our model output different scales of changes based on the volumes, showing that our model truly knows the relationship between sounds and images to some extent. 
  In this paper, we introduce an embedding model, named CapsE, exploring a capsule network to model relationship triples . Our CapsE represents each triple as a 3-column matrix where each column vector represents the embedding of an element in the triple. This 3-column matrix is then fed to a convolution layer where multiple filters are operated to generate different feature maps. These feature maps are reconstructed into corresponding capsules which are then routed to another capsule to produce a continuous vector. The length of this vector is used to measure the plausibility score of the triple. Our proposed CapsE obtains better performance than previous state-of-the-art embedding models for knowledge graph completion on two benchmark datasets WN18RR and FB15k-237, and outperforms strong search personalization baselines on SEARCH17.  % Categories and Subject Descriptors: [Search and Ranking]: Retrieval Models and Ranking. % Keywords: Search Personalization; Capsule Network; Embeddings; CapsNet; Query Logs; Re-ranking.  
 The most approaches to Knowledge Base Question Answering are based on semantic parsing. In this paper, we address the problem of learning vector representations for complex semantic parses that consist of multiple entities and relations. Previous work largely focused on selecting the correct semantic relations for a question and disregarded the structure of the semantic parse: the connections between entities and the directions of the relations. We propose to use Gated Graph Neural Networks to encode the graph structure of the semantic parse.  We show on two data sets that the graph networks outperform all baseline models that do not explicitly model the structure. The error analysis confirms that our approach can successfully  process complex  semantic parses.  
 PatternAttribution is a recent method, introduced in the vision domain, that explains classifications of deep neural networks. We demonstrate that it also generates meaningful interpretations in the language domain. 
   This paper examines the problem of adapting neural machine translation systems to new, low-resourced languages  as  and  as possible.   We propose methods based on starting with massively multilingual ``seed models'', which can be trained ahead-of-time, and then continuing training on data related to the LRL.   We contrast a number of strategies, leading to a novel, simple, yet effective method of ``similar-language regularization'', where we jointly train on both a LRL of interest and a similar high-resourced language to prevent over-fitting to small LRL data.   Experiments demonstrate that massively multilingual models, even without any explicit adaptation, are surprisingly effective, achieving BLEU scores of up to 15.5 with  data from the LRL, and that the proposed similar-language regularization method improves over other adaptation methods by 1.7 BLEU points average over 4 LRL settings.\footnote{Code to reproduce experiments at \url{https://github.com/neubig/rapid-adaptation}} 
 Character-level models of tokens have been shown to be  effective at dealing with within-token noise and out-of-vocabulary words.  However, they often still rely on correct token boundaries.   In this paper, we propose  to eliminate the need for tokenizers with an end-to-end character-level semi-Markov conditional random field. It uses neural networks for its character and segment representations. We demonstrate its effectiveness in multilingual settings and when token boundaries are noisy: It matches state-of-the-art part-of-speech taggers for various languages and significantly outperforms them on a noisy English version of a benchmark dataset. Our code and the noisy dataset are publicly available at \url{http://cistern.cis.lmu.de/semiCRF}. 
 Computing universal distributed representations of sentences is a fundamental task in natural language processing. We propose ConsSent, a simple yet surprisingly powerful unsupervised method to learn such representations by enforcing consistency constraints on sequences of tokens. We consider two classes of such constraints -- sequences that form a sentence and between two sequences that form a sentence when merged. We learn sentence encoders by training them to distinguish between consistent and inconsistent examples, the latter being generated by randomly perturbing consistent examples in six different ways. Extensive evaluation on several transfer learning and linguistic probing tasks shows improved performance over strong unsupervised and supervised baselines, substantially surpassing them in several cases. Our best results are achieved by  training sentence encoders in a multitask setting and by an ensemble of encoders trained on the individual tasks. 
 Ensembling word embeddings to improve distributed word representations has shown good success for natural language processing tasks in recent years. These approaches either carry out straightforward mathematical operations over a set of vectors or use unsupervised learning to find a lower-dimensional representation. This work compares meta-embeddings trained for different losses, namely loss functions that account for angular distance between the reconstructed embedding and the target and those that account normalized distances based on the vector length. We argue that meta-embeddings are better to treat the ensemble set equally in unsupervised learning as the respective quality of each embedding is unknown for upstream tasks prior to meta-embedding. We show that normalization methods that account for this such as cosine and KL-divergence objectives outperform meta-embedding trained on standard $ word similarity and relatedness datasets and find it outperforms existing meta-learning strategies.   \iffalse This work introduces a novel cosine-based loss for improved word meta-embeddings to account for angle differences during reconstruction, showing the best overall performance on various word similarity tasks. We compare this approach with $\ell_1$, $\ell_2$ and KL divergence objective functions. Secondly, we train an autoencoder to predict a target word embedding from a set of source word embedding and use the resulting latent representation as a word-meta embedding. This is also compared against all existing methods for meta-embeddings. \fi 
 	This paper tackles the problem of disentangling the latent variables of style and content in language models. 	We propose a simple yet effective approach, which incorporates auxiliary multi-task and adversarial objectives, for label prediction and bag-of-words prediction, respectively. 	We show, both qualitatively and quantitatively, that the style and content are indeed disentangled in the latent space. 	This disentangled latent representation learning method is applied to style transfer on non-parallel corpora. 	We achieve substantially better results in terms of transfer accuracy, content preservation and language fluency, in comparison to previous state-of-the-art approaches.\footnote{Our code is publicly available at \url{https://github.com/vineetjohn/linguistic-style-transfer}} 	% \footnote{\url{https://github.com/vineetjohn/linguistic-style-transfer}}. 
  LSTMs and other RNN variants have shown strong performance on character-level language modeling. These models are typically trained using truncated backpropagation through time, and it is common to assume that their success stems from their ability to remember long-term contexts. In this paper, we show that a deep  transformer model  with fixed context outperforms RNN variants by a large margin, achieving state of the art on two popular benchmarks: 1.13 bits per character on \texteight{} and 1.06 on . To get good results at this depth, we show that it is important to add auxiliary losses, both at intermediate network layers and intermediate sequence positions.  
 Structural planning is important for producing long sentences, which is a missing part in current language generation models. In this work, we add a planning phase in neural machine translation to control the coarse structure of output sentences. The model first generates some planner codes, then predicts real output words conditioned on them. The codes are learned to capture the coarse structure of the target sentence. In order to obtain the codes, we design an end-to-end neural network with a discretization bottleneck, which predicts the simplified part-of-speech tags of target sentences. Experiments show that the translation performance are generally improved by planning ahead. We also find that translations with different structures can be obtained by manipulating the planner codes. 
  This paper investigates data-driven segmentation using Re-Pair or Byte Pair Encoding-techniques. In contrast to previous work which has primarily been focused on subword units for machine translation, we are interested in the general properties of such segments above the word level. We call these segments r-grams, and discuss their properties and the effect they have on the token frequency distribution. The proposed approach is evaluated by demonstrating its viability in embedding techniques, both in monolingual and multilingual test settings. We also provide a number of qualitative examples of the proposed methodology, demonstrating its viability as a language-invariant segmentation procedure.  
   We study cross-lingual sequence tagging with little or no labeled data   in the target language.  Adversarial training has   previously been shown to be effective for training cross-lingual sentence   classifiers. However, it is not clear if language-agnostic   representations enforced by an adversarial language discriminator   will also enable effective transfer for token-level prediction   tasks.  Therefore, we experiment with different types of adversarial training   on two tasks: dependency parsing and sentence compression.  We show that adversarial training   consistently leads to improved cross-lingual performance on each   task compared to a conventionally trained baseline. 
 The rise of social media is enabling people to freely express their opinions about products and services. The aim of sentiment analysis is to automatically determine subject's sentiment  towards a particular aspect such as topic, product, movie, news etc. Deep learning has recently emerged as a powerful machine learning technique to tackle a growing demand of accurate sentiment analysis. However, limited work has been conducted to apply deep learning algorithms to languages other than English, such as Persian. In this work, two deep learning models ) are developed and applied to a novel Persian movie reviews dataset. The proposed deep learning models are analyzed and compared with the the state-of-the-art shallow multilayer perceptron  based machine learning model. Simulation results demonstrate the enhanced performance of deep learning over state-of-the-art MLP.    
   Huge numbers of new words emerge every day, leading to a great need for representing them with semantic meaning that is understandable to NLP systems. Sememes are defined as the minimum semantic units of human languages, the combination of which can represent the meaning of a word. Manual construction of sememe based knowledge bases is time-consuming and labor-intensive. Fortunately, communities are devoted to composing the descriptions of words in the wiki websites. In this paper, we explore to automatically predict lexical sememes based on the descriptions of the words in the wiki websites. We view this problem as a weakly ordered multi-label task and propose a  Label Distributed seq2seq model  with a novel soft loss function to solve the problem. In the experiments, we take a real-world sememe knowledge base HowNet and the corresponding descriptions of the words in Baidu Wiki\footnote{\url{https://baike.baidu.com/}} for training and evaluation. The results show that our LD-seq2seq model not only beats all the baselines significantly on the test set, but also outperforms amateur human annotators in a random subset of the test set.  
 By representing a text by a set of words and their co-occurrences, one obtains a word-adjacency network being a reduced representation of a given language sample. In this paper, the possibility of using network representation to extract information about individual language styles of literary texts is studied. By determining selected quantitative characteristics of the networks and applying machine learning algorithms, it is possible to distinguish between texts of different authors. Within the studied set of texts, English and Polish, a properly rescaled weighted clustering coefficients and weighted degrees of only a few nodes in the word-adjacency networks are sufficient to obtain the authorship attribution accuracy over 90\%. A correspondence between the text authorship and the word-adjacency network structure can therefore be found. The network representation allows to distinguish individual language styles by comparing the way the authors use particular words and punctuation marks. The presented approach can be viewed as a generalization of the authorship attribution methods based on simple lexical features.  Additionally, other network parameters are studied, both local and global ones, for both the unweighted and weighted networks. Their potential to capture the writing style diversity is discussed; some differences between languages are observed. 
 Sequence generative adversarial networks  have been used to improve conditional sequence generation tasks, for example, chit-chat dialogue generation. To stabilize the training of SeqGAN, Monte Carlo tree search  or reward at every generation step  is used to evaluate the goodness of a generated subsequence. MCTS is computationally intensive, but the performance of REGS is worse than MCTS. In this paper,  we propose stepwise GAN , in which the discriminator is modified to automatically assign scores quantifying the goodness of each subsequence at every generation step. StepGAN  has significantly less computational costs than MCTS. We demonstrate that StepGAN outperforms previous GAN-based methods on both  synthetic experiment and chit-chat dialogue generation. 
 We present path2vec, a new approach for learning graph embeddings that relies on structural measures of pairwise node similarities. The model learns representations for nodes in a dense space that approximate a given user-defined graph distance measure, such as e.g. the shortest path distance or distance measures that take information beyond the graph structure into account. Evaluation of the proposed model on semantic similarity and word sense disambiguation tasks, using various WordNet-based similarity measures, show that our approach yields competitive results, outperforming strong graph embedding baselines. The model is computationally efficient, being orders of magnitude faster than the direct computation of graph-based distances. 
 Recursive Neural Network , a type of models which compose words or phrases recursively over syntactic tree structures, has been proven to have superior ability to obtain sentence representation for a variety of NLP tasks. However, RecNN is born with a thorny problem that a shared compositional function for each node of trees can't capture the complex semantic compositionality so that the expressive power of model is limited. In this paper, in order to address this problem, we propose Tag-Guided HyperRecNN/TreeLSTM , which introduces hypernetwork into RecNNs to take as inputs Part-of-Speech  tags of word/phrase and generate the semantic composition parameters dynamically. Experimental results on five datasets for two typical NLP tasks show proposed models both obtain significant improvement compared with RecNN and TreeLSTM consistently. Our TG-HTreeLSTM outperforms all existing RecNN-based models and achieves or is competitive with state-of-the-art on four sentence classification benchmarks. The effectiveness of our models is also demonstrated by qualitative analysis. 
 In this paper, we present a recipe for building a good Arabic-English neural machine translation. We compare neural systems with traditional  phrase-based systems using various parallel corpora including UN, ISI  and Ummah. We also investigate the importance of special preprocessing  of the Arabic script. The presented results are based on test sets from  NIST MT 2005 and 2012. The best neural system produces a gain of +13 BLEU  points compared to an equivalent simple phrase-based system in NIST MT12 test set. Unexpectedly, we find that tuning a model trained on the whole  data using a small high quality corpus like Ummah gives a substantial  improvement . We also find that training a neural system with a small Arabic-English corpus is competitive to a traditional phrase-based system.  
  Prevalent models based on artificial neural network  for sentence classification often classify sentences in isolation without considering the context in which sentences appear. This hampers the traditional sentence classification approaches to the problem of sequential sentence classification, where structured prediction is needed for better overall classification performance. In this work, we present a hierarchical sequential labeling network to make use of the contextual information within surrounding sentences to help classify the current sentence. Our model outperforms the state-of-the-art results by 2\%-3\% on two benchmarking datasets for sequential sentence classification in medical scientific abstracts.  % * <mattmcdermott8@gmail.com> 2018-05-21T15:21:48.653Z: %  % > models based on artificial neural network  % Either "Prevalent artificial neural network  models" or "Prevalent models based on artificial neural network*s* " -- if you use ANN as an adjective it would be singular, but "based on" generally requires plurals, I think. %  % ^. % * <mattmcdermott8@gmail.com> 2018-05-17T15:05:00.477Z: %  % > from % maybe 'within' fits better? %  % ^ <jindi930617@gmail.com> 2018-05-18T20:29:29.831Z. % * <mattmcdermott8@gmail.com> 2018-05-17T15:04:47.761Z: %  % > context % contextual, as it is an adjective here. %  % ^ <jindi930617@gmail.com> 2018-05-18T20:29:44.748Z. % * <mattmcdermott8@gmail.com> 2018-05-17T15:04:08.009Z: %  % > structured % Do you mean 'contextual'? If not, what do you mean by 'structured'? %  % ^ <jindi930617@gmail.com> 2018-05-18T20:37:17.034Z. % * <mattmcdermott8@gmail.com> 2018-05-17T15:03:54.048Z: %  % > quality of classification % maybe just 'performance'? %  % ^ <jindi930617@gmail.com> 2018-05-18T20:31:20.622Z. % * <mattmcdermott8@gmail.com> 2018-05-17T15:02:02.437Z: %  % > makes % I think 'leaves' is more appropriate with 'short-handed' e.g., not 'you made me short handed' but 'you left me short handed' %  % You could also just say 'This characteristic hampers/hinders/hurts tranditional sentence classification approaches for the problem of...' %  % ^ <jindi930617@gmail.com> 2018-05-18T20:39:00.495Z. % * <mattmcdermott8@gmail.com> 2018-05-17T15:01:47.564Z: %  % > individually % maybe 'in isolation'? %  % ^ <jindi930617@gmail.com> 2018-05-18T20:40:01.998Z. % * <mattmcdermott8@gmail.com> 2018-05-17T15:01:28.462Z: %  % > prevalent models based on artificial neural networks  % artificial neural network  models %  % ^ <jindi930617@gmail.com> 2018-05-18T20:40:16.261Z.    
  To deploy a spoken language understanding  model to a new language, language transferring is desired to avoid the trouble of acquiring and labeling a new big SLU corpus. Translating the original SLU corpus into the target language is an attractive strategy. However, SLU corpora consist of  plenty of semantic labels , which general-purpose translators cannot handle well, not to mention additional culture differences.  This paper focuses on the language transferring task given a tiny in-domain parallel SLU corpus. The in-domain parallel corpus can be used as the first adaptation on the general translator. But more importantly, we show how to use reinforcement learning  to further finetune the adapted translator, where translated sentences with more proper slot tags receive higher rewards.  We evaluate our approach on Chinese to English language transferring for SLU systems. The experimental results show that the generated English SLU corpus via adaptation and reinforcement learning gives us over 97\% in the slot F1 score and over 84\% accuracy in domain classification. It demonstrates the effectiveness of the proposed language transferring method.  Compared with naive translation, our proposed method improves domain classification accuracy by relatively 22\%, and the slot filling F1 score by relatively more than 71\%. 
 Recurrent Neural Networks  have been proven to be effective in modeling sequential data and they have been applied to boost a variety of tasks such as document classification, speech recognition and machine translation. Most of existing RNN models have been designed for sequences assumed to be identically and independently distributed . However, in many real-world applications, sequences are naturally linked. For example, web documents are connected by hyperlinks; and genes interact with each other. On the one hand, linked sequences are inherently not i.i.d., which poses tremendous challenges to existing RNN models. On the other hand, linked sequences offer link information in addition to the sequential information, which enables unprecedented opportunities to build advanced RNN models. In this paper, we study the problem of RNN for linked sequences. In particular, we introduce a principled approach to capture link information and propose a linked Recurrent Neural Network , which models sequential and link information coherently. We conduct experiments on real-world datasets from multiple domains and the experimental results validate the effectiveness of the proposed framework.  
  Generating a text abstract from a set of documents remains a challenging task. The neural encoder-decoder framework has recently been exploited to summarize single documents, but its success can in part be attributed to the availability of large parallel data automatically acquired from the Web. In contrast, parallel data for multi-document summarization are scarce and costly to obtain. There is a pressing need to adapt an encoder-decoder model trained on single-document summarization data to work with multiple-document input. In this paper, we present an initial investigation into a novel adaptation method. It exploits the maximal marginal relevance method to select representative sentences from multi-document input, and leverages an abstractive encoder-decoder model to fuse disparate sentences to an abstractive summary.  The adaptation method is robust and itself requires no training data.  Our system compares favorably to state-of-the-art extractive and abstractive approaches judged by automatic metrics and human assessors.   
 This paper describes SentencePiece, a language-independent subword tokenizer and detokenizer designed for Neural-based text processing, including Neural Machine Translation. It provides open-source C++ and Python implementations for subword units.  While existing subword segmentation tools assume that the input is pre-tokenized into word sequences, SentencePiece can train subword models directly from raw sentences, which allows us to make a purely end-to-end and language independent system. We perform a validation experiment of NMT on English-Japanese machine translation, and find that it is possible to achieve comparable accuracy to direct subword training from raw sentences. We also compare the performance of subword training and segmentation with various configurations.  SentencePiece is available under the Apache 2 license at %{\url{https://github.com/google/sentencepiece}}. \url{https://github.com/google/sentencepiece}. 
 Task-oriented dialog systems are becoming pervasive, and many companies heavily rely on them to complement human agents for customer service in call centers. With globalization, the need for providing cross-lingual customer support becomes more urgent than ever. However, cross-lingual support poses great challenges---it requires a large amount of additional annotated data from native speakers. In order to bypass the expensive human annotation and achieve the first step towards the ultimate goal of building a universal dialog system, we set out to build a cross-lingual state tracking framework. Specifically, we assume that there exists a source language with dialog belief tracking annotations while the target languages have no annotated dialog data of any form. Then, we pre-train a state tracker for the source language as a teacher, which is able to exploit easy-to-access parallel data. We then distill and transfer its own knowledge to the student state tracker in target languages. We specifically discuss two types of common parallel resources: bilingual corpus and bilingual dictionary, and design different transfer learning strategies accordingly. Experimentally, we successfully use English state tracker as the teacher to transfer its knowledge to both Italian and German trackers and achieve promising results. 
 Neural Machine Translation  systems are known to degrade when confronted with noisy data, especially when the system is trained only on clean data. In this paper, we show that augmenting training data with sentences containing artificially-introduced grammatical errors can make the system more robust to such errors. In combination with an automatic grammar error correction system, we can recover $1.9$ BLEU out of $3.1$ BLEU lost due to grammatical errors. We also present a set of Spanish translations of the JFLEG grammar error correction corpus, which allows for testing NMT robustness to real grammatical errors. 
 State-of-the-art systems in deep question answering proceed as follows: ~an initial document retrieval selects relevant documents, which ~are then processed by a neural network in order to extract the final answer. Yet the exact interplay between both components is poorly understood, especially concerning the number of candidate documents that should be retrieved. We show that choosing a static number of documents -- as used in prior research -- suffers from a noise-information trade-off and yields suboptimal results. As a remedy, we propose an adaptive document retrieval model. This learns the optimal candidate number for document retrieval, conditional on the size of the corpus and the query. We report extensive experimental results showing that our adaptive approach outperforms state-of-the-art methods on multiple benchmark datasets, as well as in the context of corpora with variable sizes. 
   Extracting relations is critical for knowledge base completion and construction in which distant supervised methods are widely used to extract relational facts automatically with the existing knowledge bases. However, the automatically constructed datasets comprise amounts of low-quality sentences containing noisy words, which is neglected by current distant supervised methods resulting in unacceptable precisions. To mitigate this problem, we propose a novel word-level distant supervised approach for relation extraction. We first build Sub-Tree Parse  to remove noisy words that are irrelevant to relations. Then we construct a neural network inputting the subtree while applying the entity-wise attention to identify the important semantic features of relational words in each instance. To make our model more robust against noisy words, we initialize our network with a priori knowledge learned from the relevant task of entity classification by transfer learning. We conduct extensive experiments using the corpora of New York Times  and Freebase. Experiments show that our approach is effective and improves the area of Precision/Recall  from 0.35 to 0.39 over the state-of-the-art work. 
 We study the problem of generating keyphrases that summarize the key points for a given document. While sequence-to-sequence  models have achieved remarkable performance on this task , model training often relies on large amounts of labeled data, which is only applicable to resource-rich domains. In this paper, we propose semi-supervised keyphrase generation methods by leveraging both labeled data and large-scale unlabeled samples for learning. Two strategies are proposed. First, unlabeled documents are first tagged with synthetic keyphrases obtained from unsupervised keyphrase  methods or a self-learning algorithm, and then combined with labeled samples for training. Furthermore, we investigate a multi-task learning framework to jointly learn to generate keyphrases as well as the titles of the articles.  Experimental results show that our semi-supervised learning-based methods outperform a state-of-the-art model trained with labeled data only.  
  In this paper, we study the product title summarization problem in E-commerce applications for display on mobile devices. Comparing with conventional sentence summarization, product title summarization has some extra and essential constraints. For example, factual detail errors or loss of the key information are intolerable for E-commerce applications. Therefore, we abstract two more constraints for product title summarization: [label=]  To address these issues, we propose a novel multi-source pointer network by adding a new knowledge encoder for pointer network. The first constraint is handled by pointer mechanism, generating the short title by copying words from the source title. For the second constraint, we restore the key information by copying words from the knowledge encoder with the help of the soft gating mechanism. For evaluation, we build a large collection of real-world product titles along with human-written short titles.  Experimental results demonstrate that our model significantly outperforms the other baselines.% and is very close to humans on ROUGE and METEOR scores. Finally, online deployment of our proposed model has yielded a significant business impact, as measured by the click-through rate. 
   Extractive summarization models require sentence-level labels, which   are usually created heuristically    given that most summarization datasets only have document-summary   pairs. Since these labels might be suboptimal, we propose a latent   variable extractive model where sentences are viewed as latent   variables and sentences with activated variables are used to infer   gold summaries. During training the loss comes  from   gold summaries. Experiments on the CNN/Dailymail dataset show that   our model improves over a strong extractive baseline trained on   heuristically approximated labels and also performs competitively to   several recent models. 
 While current state-of-the-art NMT models, such as RNN seq2seq and Transformers, possess a large number of parameters, they are still shallow in comparison to convolutional models used for both text and vision applications. In this work we attempt to train significantly  deeper Transformer and Bi-RNN encoders for machine translation.  We propose a simple modification to the attention mechanism that eases the optimization of deeper models, and results in consistent gains of 0.7-1.1 BLEU on the benchmark WMT'14 English-German and WMT'15 Czech-English tasks for both architectures. 
     Generative Adversarial Networks  have shown great capacity on image generation, in which a discriminative model guides the training of a generative model to construct images that resemble real images.      Recently, GANs have been extended from generating images to generating sequences .      Existing GANs on sequence generation mainly focus on general sequences, which are grammar-free.      In many real-world applications, however, we need to generate sequences in a formal language with the constraint of its corresponding grammar.     For example, to test the performance of a database, one may want to generate a collection of SQL queries, which are not only similar to the queries of real users, but also follow the SQL syntax of the target database.     Generating such sequences is highly challenging because both the generator and discriminator of GANs need to consider the structure of the sequences and the given grammar in the formal language. To address these issues,      we study the problem of syntax-aware sequence generation with GANs, in which a collection of real sequences and a set of pre-defined grammatical rules are given to both discriminator and generator.     We propose a novel GAN framework, namely TreeGAN, to incorporate a given Context-Free Grammar  into the sequence generation process.      In TreeGAN, the generator employs a recurrent neural network  to construct a parse tree.     Each generated parse tree can then be translated to a valid sequence of the given grammar.     The discriminator uses a tree-structured RNN to distinguish the generated trees from real trees.     We show that TreeGAN can generate sequences for any CFG and its generation fully conforms with the given syntax.      Experiments on synthetic and real data sets demonstrated that TreeGAN significantly improves the quality of the sequence generation in context-free languages. 
   Weakly-supervised semantic parsers are trained on   utterance-denotation pairs, treating logical forms as latent.  The   task is challenging due to the large search space and spuriousness   of logical forms. In this paper we introduce a neural parser-ranker   system for weakly-supervised semantic parsing.   The parser generates candidate tree-structured logical forms from utterances using clues of denotations.   These candidates are then ranked based on two criterion:    their likelihood of executing to the correct denotation, and their   agreement with the utterance semantics.    We present a scheduled training procedure to balance the contribution of the two objectives.   Furthermore, we propose to use a neurally encoded lexicon to inject prior   domain knowledge to the model.   Experiments on three Freebase   datasets demonstrate the effectiveness of our semantic parser,   achieving results within the state-of-the-art range.    
 Entity Linking  is an essential task for semantic text understanding and information extraction. Popular methods separately address the Mention Detection  and Entity Disambiguation  stages of EL, without leveraging their mutual dependency. We here propose the first neural end-to-end EL system that jointly discovers and links entities in a text document. The main idea is to consider all possible spans as potential mentions and learn contextual similarity scores over their entity candidates that are useful for both MD and ED decisions. Key components are context-aware mention embeddings, entity embeddings and a probabilistic mention - entity map, without demanding other engineered features. Empirically, we show that our end-to-end method significantly outperforms popular systems on the Gerbil platform when enough training data is available. Conversely, if testing datasets follow different annotation conventions compared to the training set , our ED model coupled with a traditional NER system offers the best or second best EL accuracy. 
 Sequence-to-Sequence models were introduced to tackle many real-life problems like machine translation, summarization, image captioning, etc. The standard optimization algorithms are mainly based on example-to-example matching like maximum likelihood estimation, which is known to suffer from data sparsity problem. Here we present an alternate view to explain sequence-to-sequence learning as a distribution matching problem, where each source or target example is viewed to represent a local latent distribution in the source or target domain. Then, we interpret sequence-to-sequence learning as learning a transductive model to transform the source local latent distributions to match their corresponding target distributions. In our framework, we approximate both the source and target latent distributions with recurrent neural networks . During training, the parallel augmenters learn to better approximate the local latent distributions, while the sequence prediction model learns to minimize the KL-divergence of the transformed source distributions and the approximated target distributions. This algorithm can alleviate the data sparsity issues in sequence learning by locally augmenting more unseen data pairs and increasing the model's robustness. Experiments conducted on machine translation and image captioning consistently demonstrate the superiority of our proposed algorithm over the other competing algorithms.  
 %We introduce a novel neural structure, visual attention grounding, to utilize parallel vision information for machine translation. The visual attention grounding mechanism links the visual semantics in the image with the corresponding textual semantics. So the model jointly optimizes the learning of a visual-language shared embedding and translating between languages.  We introduce a novel multimodal machine translation model that utilizes parallel visual and textual information. Our model jointly optimizes the learning of a shared visual-language embedding and a translator. The model leverages a visual attention grounding mechanism that links the visual semantics with the corresponding textual semantics. Our approach achieves competitive state-of-the-art results on the Multi30K and the Ambiguous COCO datasets. We also collected a new multilingual multimodal product description dataset to simulate a real-world international online shopping scenario.  On this dataset, our visual attention grounding model outperforms other methods by a large margin. %\yj{[YJ: but this isn't true for METEOR, right?]} %Because product descriptions are usually lengthy and our model is good at utilizing visual semantic attention to compensate the loss of distant textual history in sequence models.  
    In this paper, we propose to extend the recently introduced  model-agnostic meta-learning algorithm~ for low-resource neural machine translation . We frame low-resource translation as a meta-learning problem, and we learn to adapt to low-resource languages based on multilingual high-resource language tasks. We use the universal lexical representation~ to overcome the input-output mismatch across different languages. We evaluate the proposed meta-learning strategy using eighteen European languages  as source tasks and five diverse languages  as target tasks. We show that the proposed approach significantly outperforms the multilingual, transfer learning based approach~ and enables us to train a competitive NMT system with only a fraction of training examples. For instance, the proposed approach can achieve as high as 22.04 BLEU on Romanian-English WMT'16 by seeing only 16,000 translated words .  
  Deep learning has emerged as a versatile tool for a wide range of NLP tasks, due to its superior capacity in representation learning. But its applicability is limited by the reliance on annotated examples, which are difficult to produce at scale. Indirect supervision has emerged as a promising direction to address this bottleneck, either by introducing labeling functions to automatically generate noisy examples from unlabeled text, or by imposing constraints over interdependent label decisions. A plethora of methods have been proposed, each with respective strengths and limitations. Probabilistic logic offers a unifying language to represent indirect supervision, but end-to-end modeling with probabilistic logic is often infeasible due to intractable inference and learning. In this paper, we propose deep probabilistic logic  as a general framework for indirect supervision, by composing probabilistic logic with deep learning. DPL models label decisions as latent variables, represents prior knowledge on their relations using weighted first-order logical formulas, and alternates between learning a deep neural network for the end task and refining uncertain formula weights for indirect supervision, using variational EM. This framework subsumes prior indirect supervision methods as special cases, and enables novel combination via infusion of rich domain and linguistic knowledge. Experiments on biomedical machine reading demonstrate the promise of this approach.  
   This paper addresses a relatively new task: prediction of  ASR performance on unseen broadcast programs.  In a previous paper, we presented an ASR performance prediction system using CNNs that encode both text  and speech, in order to predict word error rate.  This work is  dedicated to the analysis of speech signal embeddings and text embeddings learnt by the CNN while training  our prediction model. We try to better understand which information is captured by the deep model and its relation with different conditioning factors. It is shown that hidden layers convey a clear signal about speech style, accent and broadcast type. We then try to leverage these 3 types of information at training time through multi-task learning. Our experiments show that this allows to train slightly more efficient ASR performance prediction systems that - in addition - simultaneously tag the analyzed utterances according to their speech style, accent and broadcast program origin.  
 Existing approaches to neural machine translation are typically autoregressive models. While these models attain state-of-the-art translation quality, they are suffering from low parallelizability and thus slow at decoding long sequences. In this paper, we propose a novel model for fast sequence generation --- the semi-autoregressive Transformer . The SAT keeps the autoregressive property in global but relieves in local and thus is able to produce multiple successive words in parallel at each time step. Experiments conducted on English-German and Chinese-English translation tasks show that the SAT achieves a good balance between translation quality and decoding speed. On WMT'14 English-German translation, the SAT achieves 5.58$\times$ speedup while maintains 88\% translation quality, significantly better than the previous non-autoregressive methods. When produces two words at each time step, the SAT is almost lossless . 
  Clinical Named Entity Recognition  aims to identify and classify clinical terms such as diseases, symptoms, treatments, exams, and body parts in electronic health records, which is a fundamental and crucial task for clinical and translation research. In recent years, deep learning methods have achieved significant success in CNER tasks. However, these methods depend greatly on Recurrent Neural Networks , which maintain a vector of hidden activations that are propagated through time, thus causing too much time to train models. In this paper, we propose a Residual Dilated Convolutional Neural Network with Conditional Random Field  to solve it. Specifically, Chinese characters and dictionary features are first projected into dense vector representations, then they are fed into the residual dilated convolutional neural network to capture contextual features. Finally, a conditional random field is employed to capture dependencies between neighboring tags. Computational results on the CCKS-2017 Task 2 benchmark dataset show that our proposed RD-CNN-CRF method competes favorably with state-of-the-art RNN-based methods both in terms of computational performance and training time.  
  In this paper we describe our system designed for the WASSA 2018 Implicit Emotion Shared Task , which obtained 2$^{\text{nd}}$ place out of 30 teams with a test macro F1 score of $0.710$. The system is composed of a single pre-trained ELMo layer for encoding words, a Bidirectional Long-Short Memory Network BiLSTM for enriching word representations with context, a max-pooling operation for creating sentence representations from them, and a Dense Layer for projecting the sentence representations into label space. Our official submission was obtained by ensembling 6 of these models initialized with different random seeds. The code for replicating this paper is available at \url{https://github.com/jabalazs/implicit_emotion}.  
  The encode-decoder framework has shown recent success in image captioning. Visual attention, which is good at detailedness, and semantic attention, which is good at comprehensiveness, have been separately proposed to ground the caption on the image. In this paper, we propose the Stepwise Image-Topic Merging Network  that makes use of the two kinds of attention at the same time. At each time step when generating the caption, the decoder adaptively merges the attentive information in the extracted topics and the image according to the generated context, so that the visual information and the semantic information can be effectively combined. The proposed approach is evaluated on two benchmark datasets and reaches the state-of-the-art performances.\footnote{\ The code is available at \url{https://github.com/lancopku/simNet}} 
 We propose a machine reading comprehension model based on the compare-aggregate framework with two-staged attention that achieves state-of-the-art results on the MovieQA question answering dataset. To investigate the limitations of our model as well as the behavioral difference between convolutional and recurrent neural networks, we generate adversarial examples to confuse the model and compare to human performance. Furthermore, we assess the generalizability of our model by analyzing its differences to human inference, drawing upon insights from cognitive science.  
    We introduce , a new single-document   summarization task which does not favor extractive strategies and   calls for an abstractive modeling approach. The idea is to create a   short, one-sentence news summary answering the question ``What is   the article about?''. We collect a real-world, large scale dataset   for this task by harvesting online articles from the British   Broadcasting Corporation . We propose a novel abstractive model   which is conditioned on the article's topics and based entirely on   convolutional neural networks.  We demonstrate experimentally that   this architecture captures long-range dependencies in a document and   recognizes pertinent content, outperforming an oracle extractive   system and state-of-the-art abstractive approaches when evaluated   automatically and by humans.\footnote{Our dataset, code, and demo     are available at: \url{https://github.com/shashiongithub/XSum}.}  %  This abstractive model is better in modeling long-range %  dependencies in the document and recognizing pertinent content. We %  demonstrate experimentally that our model outperforms an oracle %  extractive system and state-of-the-art abstractive systems when %  evaluated automatically and by humans. 
 %Motivated by the way of human acquiring the ability of answering, which is explicitly split into two steps: understanding the language and then learning to map,   Generating semantically coherent responses is still a major challenge in dialogue generation. Different from conventional text generation tasks, the mapping between inputs and responses in conversations is more complicated, which highly demands the understanding of utterance-level semantic dependency, a relation between the whole meanings of inputs and outputs. To address this problem, we propose an Auto-Encoder Matching   model to learn such  dependency. The model contains two auto-encoders and one mapping module. The auto-encoders learn the semantic representations of inputs and responses, and the mapping module learns to connect the utterance-level representations. Experimental results from automatic and human evaluations demonstrate that our model is capable of generating responses of high coherence and fluency compared to baseline models.\footnote{The code is available at \url{https://github.com/lancopku/AMM}}   %However, state-of-the-art methods are mainly based on attention mechanism and only expert in capturing local and word-to-word dependencies, thus leading to incoherent responses.   % Compared to state-of-the-art methods, our method largely improves the coherence performance according to human evaluation and automatic evaluation.   %Therefore, most current attention-based methods achieves an unsatisfying performance in promoting coherence. To address this problem, we propose a unsupervised-assistance method.          
 In order to extract the best possible performance from asynchronous stochastic gradient descent one must increase the mini-batch size and scale the learning rate accordingly. In order to achieve further speedup we introduce a technique that delays gradient updates  effectively increasing the mini-batch size. Unfortunately with the increase of mini-batch size we worsen the stale gradient problem in asynchronous stochastic gradient descent  which makes the model convergence poor. We introduce local optimizers which mitigate the stale gradient problem and together with fine tuning our momentum we are able to train a shallow machine translation system 27\% faster than an optimized baseline with negligible penalty in BLEU. %Further using our methods we are able to train a deep NMT system 23\% than the baseline and reach better model cross-entropy. 
 Recently, non-recurrent architectures  have outperformed RNNs in neural machine translation. CNNs and self-attentional networks can connect distant words via shorter network paths than RNNs, and it has been speculated that this improves their ability to model long-range dependencies. However, this theoretical argument has not been tested empirically, nor have alternative explanations for their strong performance been explored in-depth. We hypothesize that the strong performance of CNNs and self-attentional networks could also be due to their ability to extract semantic features from the source text, and we evaluate RNNs, CNNs and self-attention networks on two tasks: subject-verb agreement  and word sense disambiguation . Our experimental results show that: 1) self-attentional networks and CNNs do not outperform RNNs in modeling subject-verb agreement over long distances; 2) self-attentional networks perform distinctly better than RNNs and CNNs on word sense disambiguation.   
 We propose a large margin criterion for training neural language models. Conventionally, neural language models are trained by minimizing perplexity  on grammatical sentences.  However, we demonstrate that PPL may not be the best metric to optimize in some tasks, and further propose a large margin formulation. The proposed method aims to enlarge the  between the ``good" and ``bad" sentences in a task-specific sense. It is trained end-to-end and can be widely applied to tasks that involve re-scoring of generated text. Compared with minimum-PPL training, our method gains up to 1.1 WER reduction for speech recognition and 1.0 BLEU increase for machine translation. 
 LSTMs are powerful tools for modeling contextual information, as evidenced by their success at the task of language modeling. However, modeling contexts in very high dimensional space can lead to poor generalizability. We introduce the Pyramidal Recurrent Unit , which enables learning representations in high dimensional space with more generalization power and fewer parameters. PRUs replace the linear transformation in LSTMs with more sophisticated interactions including pyramidal and grouped linear transformations. This architecture gives strong results on word-level language modeling while reducing the number of parameters significantly. In particular, PRU improves the perplexity of a recent state-of-the-art language model  by up to 1.3 points while learning 15-20\% fewer parameters. For similar number of model parameters, PRU outperforms all previous RNN models that exploit different gating mechanisms and transformations. We provide a detailed examination of the PRU and its behavior on the language modeling tasks. Our code is open-source and available at \url{https://sacmehta.github.io/PRU/}. 
 Knowledge graphs  are the key components of various natural language processing applications. To further expand KGs' coverage, previous studies on knowledge graph completion usually require a large number of training instances for each relation. However, we observe that long-tail relations are actually more common in KGs and those newly added relations often do not have many known triples for training. In this work, we aim at predicting new facts under a challenging setting where only one training instance is available. We propose a one-shot relational learning framework, which utilizes the knowledge extracted by embedding models and learns a matching metric by considering both the learned embeddings and one-hop graph structures.  Empirically, our model yields considerable performance improvements over existing embedding models, and also eliminates the need of re-training the embedding models when dealing with newly added relations.\footnote{Code and datasets could be found at \url{https://github.com/xwhan/One-shot-Relational-Learning}.}  %   We also introduce two newly constructed datasets for one-shot learning on KGs.\william{The abstract is very head-heavy at this time. It talks too much about the background and other people's work. You might need to readjust accordingly.} 
 This paper presents a model for disfluency detection in spontaneous speech transcripts called . The model uses a Noisy Channel Model  to generate $n$-best candidate disfluency analyses and a Long Short-Term Memory  language model to score the underlying fluent sentences of each analysis. The LSTM language model scores, along with other features, are used in a MaxEnt reranker to identify the most plausible analysis. We show that using an LSTM language model in the reranking process of noisy channel disfluency model improves the state-of-the-art in disfluency detection. 
 In recent years, the natural language processing community has moved away from task-specific feature engineering, i.e., researchers discovering ad-hoc feature representations for various tasks, in favor of general-purpose methods that learn the input representation by themselves. However, state-of-the-art approaches to disfluency detection in spontaneous speech transcripts currently still depend on an array of hand-crafted features, and other representations derived from the output of pre-existing systems such as language models or dependency parsers. As an alternative, this paper proposes a simple yet effective model for automatic disfluency detection, called an auto-correlational neural network . The model uses a convolutional neural network  and augments it with a new auto-correlation operator at the lowest layer that can capture the kinds of ``rough copy'' dependencies that are characteristic of repair disfluencies in speech. In experiments, the ACNN model outperforms the baseline CNN on a disfluency detection task with a 5\% increase in f-score, which is close to the previous best result on this task\footnote{\url{https://github.com/pariajm/deep-disfluency-detector}}. 	   
  % Unsupervised learning of linguistic structure is typically addressed by standard generative models. These models often make rigid independence assumptions, which stands in stark contrast to flexible neural nets in supervised NLP applications. However, encoding probabilistic symbolic structure in neural nets for unsupervised learning is quite challenging. In this work, we propose a general approach to combine the complementary strength of structured probabilistic generative models and flexible neural networks. In our approach, a specially designed invertible neural net is cascaded to standard generative model to obtain a new generative model that allows for joint training with exact log-likelihood computation and exact inference.  Unsupervised learning of syntactic structure is typically performed using generative models with discrete latent variables and multinomial parameters. In most cases, these models have not leveraged continuous word representations. In this work, we propose a novel generative model that jointly learns discrete syntactic structure and continuous word representations in an unsupervised fashion by cascading an invertible neural network with a structured generative prior. We show that the invertibility condition allows for efficient exact inference and marginal likelihood computation in our model so long as the prior is well-behaved.  % From the representation perspective, we also show that our approach is equivalent to mapping observed word embeddings to a new space that is more appropriate for symbolic model to learn syntactic structures. % We apply our method to Hidden Markov Model and Dependency Model with Valence~ respectively,  In experiments we instantiate our approach with both Markov and tree-structured priors, evaluating on two tasks: part-of-speech  induction, and unsupervised dependency parsing without gold POS annotation. On the Penn Treebank, our Markov-structured model surpasses state-of-the-art results on POS induction. Similarly, we find that our tree-structured model achieves state-of-the-art performance on unsupervised dependency parsing for the difficult training condition where neither gold POS annotation nor punctuation-based constraints are available.\footnote{Code is available at {https://github.com/jxhe/struct-learning-with-flow}.}  % improves over standard generative baselines by a large margin. In the POS induction, our approach surpasses the state-of-the-art performance. In the unsupervised dependency parsing, our approach achieves the state-of-the-art results for the specific training condition where neither gold POS annotation or punctuation-based constraints are used. %without using rich features or strong linguistically-informed priors. 
   Recent work on abstractive summarization has made progress with neural encoder-decoder architectures. However, such models are often challenged due to their lack of explicit semantic modeling of the source document and its summary.   In this paper, we extend previous work on abstractive summarization using Abstract Meaning Representation  with a neural language generation stage which we guide using the source document.    We demonstrate that this guidance improves summarization results by 7.4 and 10.5 points in ROUGE-2 using gold standard AMR parses and parses obtained from an off-the-shelf parser respectively. We also find that the summarization performance using the latter is 2 ROUGE-2 points higher than that of a well-established neural encoder-decoder approach trained on a larger dataset. Code is available at \url{https://github.com/sheffieldnlp/AMR2Text-summ}   
   In this work, we propose a new model for aspect-based sentiment analysis.   In contrast to previous approaches, we jointly model the detection of aspects and the classification of their polarity in an end-to-end trainable neural network.   We conduct experiments with different neural architectures and word representations on the recent GermEval 2017 dataset.   We were able to show considerable performance gains by using the joint modeling approach in all settings compared to pipeline approaches.   The combination of a convolutional neural network and fasttext embeddings outperformed the best submission of the shared task in 2017, establishing a new state of the art.% for aspect-based sentiment analysis on German social media texts. 
   This document contains the instructions for preparing a camera-ready   manuscript for the proceedings of . The document itself   conforms to its own specifications, and is therefore an example of   what your manuscript should look like. These instructions should be   used for both papers submitted for review and for final versions of   accepted papers.  Authors are asked to conform to all the directions   reported in this document. 
 Most textual entailment models focus on lexical gaps between the premise text and the hypothesis, but rarely on knowledge gaps. We focus on filling these knowledge gaps in the Science Entailment task, by leveraging an external structured knowledge base  of science facts.  Our new architecture combines standard neural entailment models with a knowledge lookup module. To facilitate this lookup, we propose a fact-level decomposition of the hypothesis, and verifying the resulting sub-facts against both the textual premise and the structured KB.  Our model, \modular, learns to aggregate predictions from these heterogeneous data formats. On the SciTail dataset, \modular outperforms a simpler combination of the two predictions by 3\% and the base entailment model by 5\%. 
   This article deals with adversarial attacks   towards   deep learning systems for Natural Language Processing ,   in the context of privacy protection.   We study a specific type of attack:   an attacker eavesdrops on the hidden representations   of a neural text classifier and tries to recover   information about the input text.   Such scenario may arise in situations when   the computation of a neural network is   shared across multiple devices, e.g.\ some hidden   representation is computed by a user's device   and sent to a cloud-based model.   We measure the privacy of a hidden representation   by the ability of an attacker to predict accurately   specific private information from it   and characterize the tradeoff between the privacy and the utility   of neural representations.   Finally, we propose several defense methods based on modified   training objectives and show that they improve the privacy   of neural representations. 
 This paper studies semantic parsing for interlanguage , aligned to their corrections by native speakers  L2-L1 parallel sentences.}), taking semantic role labeling  as a case task and learner Chinese as a case language.    We first manually annotate the semantic roles for a set of learner texts to derive a gold standard for automatic SRL.    Based on the new data, we then evaluate three off-the-shelf SRL systems, i.e., the PCFGLA-parser-based, neural-parser-based and neural-syntax-agnostic systems, to gauge how successful SRL for learner Chinese can be.   We find two non-obvious facts: 1) the L1-sentence-trained systems performs rather badly on the L2 data;    2) the performance drop from the L1 data to the L2 data of the two parser-based systems is much smaller,    indicating the importance of syntactic parsing in SRL for interlanguages.   Finally, the paper introduces a new agreement-based model to explore the semantic coherency information in the large-scale L2-L1 parallel data.   We then show such information is very effective to enhance SRL for learner texts.   Our model achieves an F-score of 72.06, which is a 2.02 point improvement over the best baseline.  
 This paper presents a Discriminative Deep Dyna-Q  approach to improving the effectiveness and robustness of Deep Dyna-Q , a recently proposed framework that extends the Dyna-Q algorithm to integrate planning for task-completion dialogue policy learning. To obviate DDQ's high dependency on the quality of simulated experiences, we incorporate an RNN-based discriminator in D3Q to differentiate simulated experience from real user experience in order to control the quality of training data. Experiments show that D3Q significantly outperforms DDQ by controlling the quality of simulated experience used for planning. The effectiveness and robustness of D3Q is further demonstrated in a domain extension setting, where the agent's capability of adapting to a changing environment is tested.\footnote{The source code is available at \url{https://github.com/MiuLab/D3Q}.} 
   Split and rephrase is the task of breaking down a sentence into shorter ones that together convey the same meaning. We extract a rich new dataset for this task by mining Wikipedia's edit history: WikiSplit contains one million naturally occurring sentence rewrites, providing sixty times more distinct split examples and a ninety times larger vocabulary than the WebSplit corpus introduced by  as a benchmark for this task. Incorporating \mbox{WikiSplit} as training data produces a model with qualitatively better predictions that score 32 BLEU points above the prior best result on the WebSplit benchmark. 
 Open-domain question answering remains a challenging task as it requires models that are capable of understanding questions and answers, collecting useful information, and reasoning over evidence. Previous work typically formulates this task as a reading comprehension or entailment problem given evidence retrieved from search engines. However, existing techniques struggle to retrieve indirectly related evidence when no directly related evidence is provided, especially for complex questions where it is hard to parse precisely what the question asks. In this paper we propose a retriever-reader model that learns to attend on essential terms during the question answering process. We build  an essential term selector which first identifies the most important words in a question, then reformulates the query and searches for related evidence; and  an enhanced reader that distinguishes between essential terms and distracting words to predict the answer. We evaluate our model on multiple open-domain multiple-choice QA datasets, notably performing at the level of the state-of-the-art on the AI2 Reasoning Challenge  dataset. 
 Neural text generation, including neural machine translation, image captioning, and summarization, has been quite successful % has attracted much attention  recently. However, during training time,  typically only one reference is considered for each example, even though there are often multiple references available, e.g., 4 references in NIST MT evaluations, and 5 references in image captioning data. %% the generation model only  %% takes one gold reference into consideration while sometimes there are other multiple high qualities,  %% human-annotated references which can be used,  %% e.g., translation from Chinese to English has 5 English  %% references; image captioning datasets often have the number of references from 5 to 50. In this paper,  We first investigate several different ways of utilizing multiple human references during training. But more importantly, we then propose an algorithm to generate  exponentially many pseudo-references  by first compressing existing human references into lattices and then traversing them to generate new pseudo-references. % by traversing through the lattices. %language lattice based on .  These approaches lead to substantial improvements over strong baselines in both machine translation  and image captioning . 
 Beam search is widely used in neural machine translation, and usually improves translation quality compared to greedy search. It has been widely observed that, however, beam sizes larger than 5 hurt translation quality. %lead to worse translation quality. We explain why this happens, and propose several methods to address this problem. Furthermore, we discuss the optimal stopping criteria for these methods. Results show that our hyperparameter-free methods outperform the widely-used hyperparameter-free heuristic of length normalization by +2.0 BLEU, and achieve the best results among all methods on Chinese-to-English translation. 
 	Network embeddings, which learn low-dimensional representations for each vertex in a large-scale network, have received considerable attention in recent years. 	% has become a powerful paradigm for network analysis. 	For a wide range of applications, vertices in a network are typically accompanied by rich textual information such as user profiles, paper abstracts, . 	We propose to incorporate semantic features into network embeddings by matching important words between text sequences for all pairs of vertices. 	% Word-Alignment-based Network Embedding   	We introduce a  alignment framework that measures the compatibility of embeddings between word pairs, and then adaptively accumulates these alignment features with a simple yet effective aggregation function. 	% The edges between vertices are leveraged as supervision information to ensure that, given text sequences for two vertices, those vital word-by-word pairs are assigned higher weights than the irrelevant ones. 	In experiments, we evaluate the proposed framework on three real-world benchmarks for downstream tasks, including link prediction and multi-label vertex classification. 	Results demonstrate that our model outperforms state-of-the-art network embedding methods by a large margin. 
 Neural networks with tree-based sentence encoders have shown better results on many downstream tasks. Most of existing tree-based encoders adopt  syntactic parsing trees as the explicit structure prior.  To study the effectiveness of different tree structures, we replace the parsing trees with trivial trees  in the encoders.  Though trivial trees contain no syntactic information,  those encoders get competitive or even better results on all of the ten downstream tasks we investigated.  This surprising result indicates that explicit syntax guidance may not be the main contributor to the superior performances of tree-based neural sentence modeling. Further analysis show that tree modeling gives better results when crucial words are closer to the final representation. Additional experiments give more clues on how to design an effective tree-based encoder. Our code is open-source and available at \url{https://github.com/ExplorerFreda/TreeEnc}.  
 We present end-to-end neural models for detecting metaphorical word use in context. We show that relatively standard BiLSTM models which operate on complete sentences work well in this setting, in comparison to previous work that used more restricted forms of linguistic context.  These models establish a new state-of-the-art on existing verb metaphor detection benchmarks, and show strong performance on jointly predicting the metaphoricity of all words in a running text.  
 We propose to achieve explainable neural machine translation  by changing the output representation to explain itself. We present a novel approach to NMT which generates the target sentence by monotonically walking through the source sentence. Word reordering is modeled by operations which allow setting markers in the target sentence and move a target-side write head between those markers. In contrast to many modern neural models, our system emits explicit word alignment information which is often crucial to practical machine translation as it improves explainability. Our technique can outperform a plain text system in terms of BLEU score under the recent Transformer architecture on Japanese-English and Portuguese-English, and is within 0.5 BLEU difference on Spanish-English.  % 200 words abstract, 8 pages 
 We investigate the effects of multi-task learning using the recently introduced task of semantic tagging. We employ semantic tagging as an auxiliary task for three different NLP tasks: part-of-speech tagging, Universal Dependency parsing, and Natural Language Inference. We compare full neural network sharing, partial neural network sharing, and what we term the learning what to share setting where negative transfer between tasks is less likely. Our findings show considerable improvements for all tasks, particularly in the learning what to share setting, which shows consistent gains across all tasks.  
   While neural networks have shown impressive performance on large datasets, applying these models to tasks where little data is available remains a challenging problem.   In this paper we propose to use feature transfer in a zero-shot experimental setting on the task of semantic parsing.    We first introduce  a new method for learning the shared space between multiple domains based on the prediction of the domain label for each example.    Our experiments support the superiority of this method in a zero-shot experimental setting in terms of accuracy metrics compared to state-of-the-art techniques.   In the second part of this paper we study the impact of individual domains and examples on semantic parsing performance.   We use influence functions to this aim and investigate the sensitivity of domain-label classification loss on each example.    Our findings reveal that cross-domain adversarial attacks identify useful examples for training even from the domains the least similar to the target domain. Augmenting our training data with these influential examples further boosts our accuracy at both the token and the sequence level.       %   , and machine translation. 
 Most research in reading comprehension has focused on answering questions based on individual documents or even single paragraphs. We introduce a neural model which integrates and reasons relying on information spread within documents and across multiple documents. We frame it as an inference problem on a graph. Mentions of entities are nodes of this graph while edges encode relations between different mentions . Graph convolutional networks  are applied to these graphs and trained to perform multi-step reasoning. Our Entity-GCN method is scalable and compact, and it achieves state-of-the-art results on a multi-document question answering dataset, WikiHop~. 
 It has been argued that humans rapidly adapt their lexical and syntactic expectations to match the statistics of the current linguistic context. We provide further support to this claim by showing that the addition of a simple adaptation mechanism to a neural language model improves our predictions of human reading times compared to a non-adaptive model. We analyze the performance of the model on controlled materials from psycholinguistic experiments and show that it adapts not only to lexical items but also to abstract syntactic structures. 
 Answering compositional questions requiring multi-step reasoning is challenging. We introduce an end-to-end differentiable model for interpreting questions about a knowledge graph , which is inspired by formal approaches to semantics. Each span of text is represented by a denotation in a KG and a vector that captures ungrounded aspects of meaning. Learned composition modules recursively combine constituent spans, culminating in a grounding for the complete sentence which answers the question. For example, to interpret ``'', the model represents ``'' as a set of KG entities and ``'' as a trainable ungrounded vector---and then uses this vector to parameterize a composition function that performs a complement operation. For each sentence, we build a parse chart subsuming all possible parses, allowing the model to jointly learn both the composition operators and output structure by gradient descent from end-task supervision. The model learns a variety of challenging semantic operators, such as quantifiers, disjunctions and composed relations, and infers latent syntactic structure.  It also generalizes well to longer questions than seen in its training data, in contrast to RNN, its tree-based variants, and semantic parsing baselines. 
   Translating characters instead of words or word-fragments has the   potential to simplify the processing pipeline for neural machine   translation , and improve results by eliminating   hyper-parameters and manual feature engineering. However, it results   in longer sequences in which each symbol contains less information,   creating both modeling and computational challenges. In this paper,   we show that the modeling problem can be solved by standard   sequence-to-sequence architectures of sufficient depth, and that   deep models operating at the character level outperform identical   models operating over word fragments. This result implies that   alternative architectures for handling character input are better   viewed as methods for reducing computation time than as improved   ways of modeling longer sequences. From this perspective, we   evaluate % and extend several previous proposals for character-level   several techniques for character-level   NMT, verify that they do not match the performance of our deep   character baseline model, and evaluate the performance versus   computation time tradeoffs they offer. Within this framework, we   also perform the first evaluation for NMT of conditional computation   over time, in which the model learns which timesteps can be skipped,   rather than having them be dictated by a fixed schedule specified   before training begins. 
 In a dialog, there can be multiple valid next utterances at any point. The present end-to-end neural methods for dialog do not take this into account. They learn with the assumption that at any time there is only one correct next utterance. In this work, we focus on this problem in the goal-oriented dialog setting where there are different paths to reach a goal. We propose a new method, that uses a combination of supervised learning and reinforcement learning approaches to address this issue. We also propose a new and more effective testbed, permuted-bAbI dialog tasks \footnote{permuted-bAbI-dialog-tasks - \url{https://github.com/IBM/permuted-bAbI-dialog-tasks}} by introducing multiple valid next utterances to the original-bAbI dialog tasks, which allows evaluation of goal-oriented dialog systems in a more realistic setting. We show that there is a significant drop in performance of existing end-to-end neural methods from 81.5\% per-dialog accuracy on original-bAbI dialog tasks to 30.3\% on permuted-bAbI dialog tasks. We also show that our proposed method improves the performance and achieves 47.3\% per-dialog accuracy on permuted-bAbI dialog tasks.  
 A substantial thread of recent work on latent tree learning has attempted to develop neural network models with parse-valued latent variables and train them on non-parsing tasks, in the hope of having them discover interpretable tree structure. In a recent paper,  introduce such a model and report near-state-of-the-art results on the target task of language modeling, and the first strong latent tree learning result on  constituency parsing.  In an attempt to reproduce these results, we discover issues that make the original results hard to trust, including tuning and even training on what is effectively the test set. Here, we attempt to reproduce these results in a fair experiment and to extend them to two new datasets. We find that the results of this work are robust: All variants of the model under study outperform all latent tree learning baselines, and perform competitively with symbolic grammar induction systems. We find that this model represents the first empirical success for latent tree learning, and that neural network language modeling warrants further study as a setting for grammar induction.  % Our findings are both encouraging and puzzling: We are unable to reproduce the main parsing result of that work under the conditions the paper describes, even using the authors' original code. We also find that the model's performance on language modeling and parsing are not well correlated and that the model must be tuned for parsing on a labeled validation set. However, we find that tuning it in this way and giving it access to a larger parsed corpus allows it to succeed impressively, yielding dramatic improvements in latent tree learning, and discovering plausible structure at both the phrase and clause levels.  % However, we fail to achieve good performance in both tasks simultaneously.   %We investigate the Parsing-Reading-Predict Networks , a neural language model recently introduced at ICLR that is capable of grammar induction. As the PRPN is claimed to achieve near the state-of-the art performance in both language modeling and parsing, we analyze the tree structures it produces and how well its language modeling performance relates to the performance of grammar induction.  % The PRPN trained on Penn Treebank's Wall Street Journal section  receives poor parsing F1 score and language modeling performance on WSJ. Training the PRPN on a larger dataset gives almost 20\% improvement in parsing performance on WSJ, achieving state-of-the-art F1 score among the latent tree learning models, though its language modeling performance declines proportionally. We conclude that PRPN do not achieve good results in both parsing and language modeling simultaneously. Nonetheless, PRPN is a promising model for grammar induction, as it significantly outperforms the strong unsupervised and latent tree learning baselines when it is trained on enough data. 
 We study two problems in neural machine translation . First, in beam search, whereas a wider beam should in principle help translation, it often hurts NMT. Second, NMT has a tendency to produce translations that are too short. Here, we argue that these problems are closely related and both rooted in label bias. We show that correcting the brevity problem almost eliminates the beam problem; we  compare some commonly-used methods for doing this, finding that a simple per-word reward works well; and we introduce a simple and quick way to tune this reward using the perceptron algorithm. 
 Active learning identifies data points to label that are expected to be the most useful in improving a supervised model. Opportunistic active learning incorporates active learning into interactive tasks that constrain possible queries during interactions.  Prior work has shown that opportunistic active learning can be used to improve grounding of natural language descriptions in an interactive object retrieval task. %Prior work on opportunistic active learning has used a heuristic strategy to demonstrate the efficacy of opportunistic active learning.  % In this work, we learn a policy for such an object retrieval task that trades off between completing the current interaction, and improving its model either for current or future interactions.  In this work, we use reinforcement learning for such an object retrieval task, to learn a policy that effectively trades off task completion with model improvement that would benefit future tasks.  
  The performance of automatic speech recognition systems can be improved by adapting an acoustic model to compensate for the mismatch between training and testing conditions, for example by adapting to unseen speakers. The success of speaker adaptation methods relies on selecting weights that are suitable for adaptation and using good adaptation schedules to update these weights in order not to overfit to the adaptation data. In this paper we investigate a principled way of adapting all the weights of the acoustic model using a meta-learning. We show that the meta-learner can learn to perform supervised and unsupervised speaker adaptation and that it outperforms a strong baseline adapting LHUC parameters when adapting a DNN AM with 1.5M parameters. We also report initial experiments on adapting TDNN AMs, where the meta-learner achieves comparable performance with LHUC.  
 We introduce a novel multi-source technique for incorporating source syntax into neural machine translation using linearized parses. This is achieved by employing separate encoders for the sequential and parsed versions of the same source sentence; the resulting representations are then combined using a hierarchical attention mechanism. The proposed model improves over both seq2seq and parsed baselines by over 1 BLEU on the WMT17 English$\rightarrow$German task. Further analysis shows that our multi-source syntactic model is able to translate successfully without any parsed input, unlike standard parsed methods. In addition, performance does not deteriorate as much on long sentences as for the baselines. 
 As neural networks have dominated the state-of-the-art results in a wide range of NLP tasks, it attracts considerable attention to improve the performance of neural models by integrating symbolic knowledge. Different from existing works, this paper investigates the combination of these two powerful paradigms from the knowledge-driven side. We propose Neural Rule Engine , which can learn knowledge explicitly from logic rules and then generalize them implicitly with neural networks. NRE is implemented with neural module networks in which each module represents an action of a logic rule. The experiments show that NRE could greatly improve the generalization abilities of logic rules with a significant increase in recall. Meanwhile, the precision is still maintained at a high level. 
 We reassess a recent study~ that claimed that machine translation  has reached human parity for the translation of news from Chinese into English, using pairwise ranking and considering three variables that were not taken into account in that previous study: the language in which the source side of the test set was originally written, the translation proficiency of the evaluators, and the provision of inter-sentential context. If we consider only original source text %\textcolor{blue}{and judgments by professional translators} , then we find evidence showing that human parity has not been achieved. We compare the judgments of professional translators against those of non-experts and discover that those of the experts result in higher inter-annotator agreement and better discrimination between human and machine translations. In addition, we analyse the human translations of the test set and identify important translation issues. Finally, based on these findings, we provide a set of recommendations for future human evaluations of MT. 
 In this paper, we introduce the task of automatically generating text to describe the differences between two similar images.  We collect a new dataset by crowd-sourcing difference descriptions for pairs of image frames extracted from video-surveillance footage. Annotators were asked to succinctly describe  the differences in a short paragraph. As a result, our novel dataset provides an opportunity to explore models that %learn using pragmatic constraints,  align language and vision, and capture visual salience. The dataset may also be a useful benchmark for coherent multi-sentence generation.  We perform %also propose a neural model for generating descriptions based on  a first-pass visual analysis that exposes clusters of differing pixels as a proxy for object-level differences. We propose a model that captures visual salience by using a latent variable to align clusters of differing pixels with output sentences. %capture visual salience. We find that, for both single-sentence generation and as well as multi-sentence generation, the proposed model outperforms the models that use attention alone. 
 This study considers the task of machine reading at scale  wherein, given a question, a system first performs the information retrieval  task of finding relevant passages in a knowledge source and then carries out the reading comprehension  task of extracting an answer span from the passages. Previous MRS studies, in which the IR component was trained without considering answer spans, struggled to accurately find a small number of relevant passages from a large set of passages. In this paper, we propose a simple and effective approach that incorporates the IR and RC tasks by using supervised multi-task learning in order that the IR component can be trained by considering answer spans. Experimental results on the standard benchmark, answering SQuAD questions using the full Wikipedia as the knowledge source, showed that our model achieved state-of-the-art performance. Moreover, we thoroughly evaluated the individual contributions of our model components with our new Japanese dataset and SQuAD. The results showed significant improvements in the IR task and provided a new perspective on IR for RC: it is effective to teach which part of the passage answers the question rather than to give only a relevance score to the whole passage. 
 	Tying the weights of the target word embeddings with the target word classifiers of neural machine translation models leads to faster training and often to better translation quality. Given the success of this parameter sharing, we investigate other forms of sharing in between no sharing and hard equality of parameters.  In particular, we propose a structure-aware output layer which   captures the semantic structure of the output space of words within a joint input-output embedding. The model is a  generalized form of weight tying   which shares parameters but allows learning a more flexible relationship with input word embeddings and allows the effective capacity of the output layer to be controlled.   In addition, the model shares weights across output classifiers and translation contexts which allows it to better leverage prior knowledge about them.   Our evaluation on English-to-Finnish and English-to-German datasets shows the effectiveness of the method against strong encoder-decoder baselines trained with or without weight tying. 
 We employ imitation learning to train a neural transition-based string transducer for morphological tasks such as inflection                           % over edit actions generation and lemmatization. Previous approaches to training this type of model either rely on an external character aligner for the production of gold action sequences, which results in a suboptimal model due to the                % learning unwarranted dependence on a single gold action sequence despite                 % and error propagation spurious ambiguity, or require warm starting with an MLE model. Our approach only requires a simple expert policy, eliminating                               % @TODO costing actions the need for a character aligner or warm start. It also addresses familiar MLE training biases and leads to strong and state-of-the-art performance on several benchmarks.%\footnote{}                                                          % We will make our implementation available. %\blindtext 
 This article describes the Aalto University entry to the WMT18 News Translation Shared Task. We participate in the multilingual subtrack with a system trained under the constrained condition to translate from English to both Finnish and Estonian. The system is based on the Transformer model. We focus on improving the consistency of morphological segmentation for words that are similar orthographically, semantically, and distributionally; such words include etymological cognates, loan words, and proper names. For this, we introduce Cognate Morfessor, a multilingual variant of the Morfessor method. We show that our approach improves the translation quality particularly for Estonian, which has less resources for training the translation model. %We participate in the multilingual subtrack %with a system trained to translate from English to both Finnish and Estonian. %Our submission falls under the constrained condition. 
 Attention mechanisms in biological perception are thought to select subsets of perceptual information for more sophisticated processing which would be prohibitive to perform on all sensory inputs. In computer vision, however, there has been relatively little exploration of  attention, where some information is selectively ignored, in spite of the success of  attention, where information is re-weighted and aggregated, but never filtered out. Here, we introduce  a new approach for hard attention and find it achieves very competitive performance on a recently-released visual question answering datasets, equalling and in some cases surpassing similar soft attention architectures while entirely ignoring some features. Even though the hard attention mechanism is thought to be non-differentiable,  we found that the feature magnitudes correlate with semantic relevance, and provide a useful signal for our mechanism's attentional selection criterion. Because hard attention selects important features of the input information, it can also be more efficient than analogous soft attention mechanisms. This is especially important for recent approaches that use  operations, whereby computational and memory costs are quadratic in the size of the set of features.   
 This study evaluates the performances of an LSTM network for detecting and extracting the intent and content of commands for a financial chatbot. It presents two techniques, sequence to sequence learning and Multi-Task Learning, which might improve on the previous task.  
 Learning disentangled representations of high-dimensional data is currently an active research area. However, compared to the field of computer vision, less work has been done for speech processing. In this paper, we provide a review of two representative efforts on this topic and propose the novel concept of fine-grained disentangled speech representation learning.  
 Context information around words helps in determining their actual meaning, for example ``networks" used  in contexts of {.  Generative topic models infer topic-word distributions, taking no or only little context into account.  Here, we extend a neural autoregressive topic model to exploit the full context information around words in a document in a language modeling fashion.  This results in an improved performance in terms of generalization,  interpretability and applicability.  We apply our modeling approach to seven data sets from various domains and demonstrate  % on five data sets  that our approach consistently outperforms state-of-the-art generative topic models.  % needs some more work, motivation not entirely clear, start with topic models  With the learned representations, we show on an average a gain of $9.6$\%  in precision  at retrieval fraction $0.02$ and $7.2$\%  in $F1$ for text categorization.  
  Binary code analysis allows analyzing binary code without  having access to the corresponding source code.  %It is widely used for vulnerability  %discovery, malware dissection, attack investigation, %performance diagnosis,  %etc. %In many cases, e.g., when analyzing closed-source software, legacy executables, %and malware, the source code is not available, and binary code analysis becomes  %the only feasible approach.  %Today, binary code analysis becomes more important than ever.  % for identifying malware, detecting code plagiarism, and finding vulnerabilities.  A binary, after disassembly, is expressed in an . This inspires us to approach binary analysis by leveraging ideas and techniques from  , a fruitful area focused on processing text  of various natural languages. We notice that binary code analysis and NLP share  many analogical topics, such as semantics extraction, classification, and code/text comparison. This work \zedit{thus borrows} ideas \zedit{from NLP} to  address two important code  similarity comparison problems.  Given a pair of basic blocks \zedit{of} different  instruction set architectures , determining whether their semantics \zedit{is} similar;  and  given a piece of code of interest, determining if it is \zedit{} in  another piece of code of a different ISA. The solutions to these  two problems have many applications, such as cross-architecture vulnerability discovery and code plagiarism detection.   Despite the evident importance of Problem I, existing solutions are  either inefficient or imprecise. Inspired by Neural Machine Translation , which  is a new approach that tackles text across natural languages very well, we regard , and propose a novel  deep learning approach to solving \zedit{Problem I},  attaining high efficiency and precision.  \zedit{Many solutions have been proposed to determine whether two pieces of code, e.g., functions, are equivalent , which is different from Problem II .  Resolving the cross-architecture code  containment problem is a new and more challenging endeavor. Employing our technique for cross-architecture basic-block comparison, we propose the first  solution to Problem II.} We implement a prototype system \tool and perform  a comprehensive evaluation. A comparison between our approach and existing approaches to Problem I shows  that our system outperforms them in terms of accuracy, efficiency and scalability.  The case studies \zedit{applying} the system demonstrate that our solution to Problem II is effective. Moreover, this research showcases how to apply ideas and techniques from NLP to large-scale  binary code analysis.  
 Inducing sparseness while training neural networks has been shown to yield models with a lower memory footprint but similar effectiveness to dense models. However, sparseness is typically induced starting from a dense model, and thus this advantage does not hold during training.  We propose techniques to enforce sparseness upfront in recurrent sequence models for NLP applications, to also benefit training. First, in language modeling, we show how to increase hidden state sizes in recurrent layers without increasing the number of parameters, leading to more expressive models. Second, for sequence labeling, we show that word embeddings with predefined sparseness lead to similar performance as dense embeddings, at a fraction of the number of trainable parameters. 
   %We propose a novel approach for learning bilingual embeddings given monolingual embeddings and a bilingual dictionary. Our approach uses polar factorization of the  linear transformation matrix to:  learn rotations of each languages' embeddings to a common latent space, and  learn a similarity metric in the latent vector space to model similarities between embeddings in this space. We use Reimannian optimization to efficiently learn the polar factorization. We show that our approach outperforms previous  approaches on the bilingual lexicon induction and cross-lingual word similarity tasks. Since we represent the rotated embeddings in a common vector space, our approach can easily represent multiple languages in a single vector space. We also show that these multilingual embeddings can be learnt jointly given  bilingual dictionaries for multiple   language pairs. We demonstrate the effectiveness of the multilingual embeddings in one zeroshot word translation setting: word translation using these multilingual embeddings is better than word translation using a pivot language when no source-target  bilingual dictionary is available, but source-pivot and pivot-target bilingual dictionaries are available.   We propose a novel geometric approach for learning bilingual mappings given monolingual embeddings and a bilingual dictionary. Our approach  {decouples} the source-to-target language transformation into  language-specific rotations on the original embeddings to align them in a common, latent space, and  a  language-independent similarity metric in this common space to better model the similarity between the embeddings. Overall, we pose the bilingual mapping problem {as a classification problem} on smooth Riemannian manifolds. Empirically, our approach outperforms previous approaches on the bilingual lexicon induction and cross-lingual word similarity tasks.   We next generalize our framework to represent multiple languages in a common latent space. Language-specific rotations for all the languages and a common similarity metric in the latent space are learned jointly from bilingual dictionaries for multiple language pairs. We illustrate the effectiveness of joint learning for multiple languages in an indirect word translation setting.  
 We investigated the impact of noisy linguistic features on the performance of a Japanese speech synthesis system based on neural network that uses WaveNet vocoder. We compared an ideal system that uses manually corrected linguistic features including phoneme and prosodic information in training and test sets against a few other systems that use corrupted linguistic features. Both subjective and objective results demonstrate that corrupted linguistic features, especially those in the test set, affected the ideal system's performance significantly in a statistical sense due to a mismatched condition between the training and test sets.  Interestingly, while an utterance-level Turing test showed that listeners had a difficult time differentiating synthetic speech from natural speech, it further indicated that adding noise to the linguistic features in the training set can partially reduce the effect of the mismatch, regularize the model, and help the system perform better when linguistic features of the test set  are noisy. 
 In automatic speech processing systems, speaker diarization is a crucial front-end component to separate segments from different speakers. Inspired by the recent success of deep neural networks  in semantic inferencing, triplet loss-based architectures have been successfully used for this problem. However, existing work utilizes conventional i-vectors as the input representation and builds simple fully connected networks for metric learning, thus not fully leveraging the modeling power of DNN architectures. This paper investigates the importance of learning effective representations from the sequences directly in metric learning pipelines for speaker diarization. More specifically, we propose to employ attention models to learn embeddings and the metric jointly in an end-to-end fashion. Experiments are conducted on the CALLHOME conversational speech corpus. The diarization results demonstrate that, besides providing a unified model, the proposed approach achieves improved performance when compared against existing approaches.  
 Accurate time-series forecasting is vital for numerous areas of application such as transportation, energy, finance, economics, etc. However, while modern techniques are able to explore large sets of temporal data to build forecasting models, they typically neglect valuable information that is often available under the form of unstructured text. Although this data is in a radically different format, it often contains contextual explanations for many of the patterns that are observed in the temporal data. In this paper, we propose two deep learning architectures that leverage word embeddings, convolutional layers and attention mechanisms for combining text information with time-series data. We apply these approaches for the problem of taxi demand forecasting in event areas. Using publicly available taxi data from New York, we empirically show that by fusing these two complementary cross-modal sources of information, the proposed models are able to significantly reduce the error in the forecasts.  
 The growing need to analyze large collections of documents has led to great developments in topic modeling. Since documents are frequently associated with other related variables, such as labels or ratings, much interest has been placed on supervised topic models. However, the nature of most annotation tasks, prone to ambiguity and noise, often with high volumes of documents, deem learning under a single-annotator assumption unrealistic or unpractical for most real-world applications. In this article, we propose two supervised topic models, one for classification and another for regression problems, which account for the heterogeneity and biases among different annotators that are encountered in practice when learning from crowds. We develop an efficient stochastic variational inference algorithm that is able to scale to very large datasets, and we empirically demonstrate the advantages of the proposed model over state-of-the-art approaches. 
  \vspace*{-.5em}  \textcolor{black}{Level assessment for foreign language students is necessary for putting them in the right level group, furthermore, interviewing students is a very time-consuming task, so we propose to automate the evaluation of speaker fluency level by implementing machine learning techniques. This work presents an audio processing system capable of classifying the level of fluency of non-native English speakers using five different machine learning models. As a first step, we have built our own dataset, which consists of labeled audio conversations in English between people ranging in different fluency domains/classes . We segment the audio conversations into 5s non-overlapped audio clips to perform feature extraction on them. We start by extracting Mel cepstral coefficients from the audios, selecting 20 coefficients is an appropriate quantity for our data. We thereafter extracted zero-crossing rate, root mean square energy and spectral flux features, proving that this improves model performance. Out of a total of 1424 audio segments, with 70\% training data and 30\% test data, one of our trained models  achieved a classification accuracy of 94.39\%, whereas the other four models passed an 89\% classification accuracy threshold.}{\small \par}  
   Measuring domain relevance of data and identifying or selecting well-fit domain data for machine   translation  is a well-studied topic, but denoising is not yet. Denoising   is concerned with a different type of data quality and   tries to reduce the negative impact of data noise on MT training, in particular, neural MT    training. This paper generalizes methods for measuring and selecting data for domain MT and   applies them to denoising NMT training.  The proposed approach uses trusted data and a   denoising curriculum realized by online data selection. Intrinsic and extrinsic evaluations of   the approach show its significant effectiveness for NMT to train on data with severe noise. % and that it actually can be more effective than its counterpart for domain MT. 
 In neural text generation such as neural machine translation, summarization, and image captioning, beam search is widely used to improve the output text quality. However, %unlike traditional beam search in statistical MT or incremental parsing, in the neural generation setting, hypotheses can finish in different steps, which makes it difficult to decide when to end beam search to ensure optimality. We propose a provably optimal beam search algorithm that will always return the optimal-score complete hypothesis , and finish as soon as the optimality is established . To counter neural generation's tendency for shorter hypotheses, we also introduce a bounded length reward mechanism which allows  a modified version of our beam search algorithm to remain optimal. Experiments on neural machine translation  demonstrate that our principled beam search algorithm leads to improvement in BLEU score over previously proposed alternatives. 
 Neural machine translation usually adopts autoregressive models and suffers from exposure bias as well as the consequent error propagation problem. Many previous works have discussed the relationship between error propagation and the   problem. In this paper, we conduct a series of analyses to deeply understand this problem and get several interesting findings.  The role of error propagation on accuracy drop is overstated in the literature, although it indeed contributes to the accuracy drop problem.  Characteristics of a language play a more important role in causing the accuracy drop: the left part of the translation result in a right-branching language  is more likely to be more accurate than its right part, while the right part is more accurate for a left-branching language . Our discoveries are confirmed on different model structures including Transformer and RNN, and in other sequence generation tasks such as text summarization.   
  This paper describes the Microsoft submission to the WMT2018 news translation shared task. We  participated in one language direction -- English-German. Our system follows current best-practice and combines state-of-the-art models with new data filtering  and sentence weighting methods. We trained fairly standard Transformer-big models with an updated version of Edinburgh's training scheme for WMT2017 and experimented with different filtering schemes for Paracrawl. According to automatic metrics  we reached the highest score for this subtask with a nearly 2 BLEU point margin over the next strongest system. Based on human evaluation we ranked first among constrained systems.  We believe this is mostly caused by our data filtering/weighting regime. 
     We propose a novel model for Neural Machine Translation . Different from the conventional method, our model can predict the future text length and words at each decoding time step so that the generation can be helped with the information from the future prediction. With such information, the model does not stop generation without having translated enough content. Experimental results demonstrate that our model can significantly outperform the baseline models. Besides, our analysis reflects that our model is effective in the prediction of the length and words of the untranslated content.      
 %Recent works in machine translation have begun to explore document translation, however, translating online multi-speaker conversations is still an open problem. %In this work, we explore Bilingual Multi-Speaker Machine Translation and investigate effective neural architectures for this task that exploit both source and target-side conversation histories. Furthermore, we propose to use a dataset extracted from Europarl v7 and OpenSubtitles2016 in order to initiate evaluation for this task. %Our experiments on four language-pairs confirm the significance of leveraging conversation history while translating a bilingual multi-speaker conversation in terms of BLEU and manual evaluation.  %\andre{I think we need to tweak the abstract a bit. Here's my proposal:  Recent works in neural machine translation have begun to explore document translation. However, translating online multi-speaker conversations is still an open problem. In this work, we propose the task of translating Bilingual Multi-Speaker Conversations, and explore neural architectures which exploit both source and target-side conversation histories for this task. To initiate an evaluation for this task, we introduce datasets extracted from Europarl v7 and OpenSubtitles2016. Our experiments on four language-pairs confirm the significance of leveraging conversation history, both in terms of BLEU and manual evaluation.%} 
 Transfer learning has been proven as an effective technique for neural machine translation under low-resource conditions.  Existing methods require a common target language, language relatedness,  or specific training tricks and regimes.  We present a simple transfer learning method, where  we first train a ``parent'' model for a high-resource language pair and then continue the training on a low-resource pair only by replacing the training corpus. This ``child'' model performs significantly better than the baseline trained for low-resource pair only. We are the first to show this for targeting different languages, and we observe the improvements even for unrelated languages with different alphabets.  
 We design and build the first neural temporal dependency parser. It utilizes a neural ranking model with minimal feature engineering, and parses time expressions and events in a text into a temporal dependency tree structure. We evaluate our parser on two domains: news reports and narrative stories. In a parsing-only evaluation setup where gold time expressions and events are provided, our parser reaches 0.81 and 0.70 f-score on unlabeled and labeled parsing respectively, a result that is very competitive against alternative approaches. In an end-to-end evaluation setup where time expressions and events are automatically recognized, our parser beats two strong baselines on both data domains. Our experimental results and discussions shed light on the nature of temporal dependency structures in different domains and provide insights that we believe will be valuable to future research in this area. 
  The advent of social media in recent years has fed into some highly undesirable phenomena such as proliferation of offensive language, hate speech, sexist remarks, etc. on the Internet. In light of this, there have been several efforts to automate the detection and moderation of such abusive content. However, deliberate obfuscation of words by users to evade detection poses a serious challenge to the effectiveness of these efforts. The current state of the art approaches to abusive language detection, based on recurrent neural networks, do not explicitly address this problem and resort to a generic oov  embedding for unseen words. However, in using a single embedding for all unseen words we lose the ability to distinguish between obfuscated and non-obfuscated or rare words. In this paper, we address this problem by designing a model that can compose embeddings for unseen words. We experimentally demonstrate that our approach significantly advances the current state of the art in abuse detection on datasets from two different domains, namely Twitter and Wikipedia talk page. 
 Data augmentation seeks to manipulate the available data for training to improve the generalization ability of models. We investigate two data augmentation proxies, permutation and flipping, for neural dialog response selection task on various models over multiple datasets, including both Chinese and English languages. Different from standard data augmentation techniques, our method combines the original and synthesized data for prediction. Empirical results show that our approach can gain 1 to 3 recall-at-1 points over baseline models in both full-scale and small-scale settings. 
 We consider the cross-domain sentiment classification problem, where a sentiment classifier is to be learned from a source domain and to be generalized to a target domain.  Our approach explicitly minimizes the distance between the source and the target instances in an embedded feature space. With the difference between source and target minimized, we then exploit additional information from the target domain by consolidating the idea of semi-supervised learning, for which, we jointly employ two regularizations -- entropy minimization and self-ensemble bootstrapping -- to incorporate the unlabeled target data for classifier refinement. Our experimental results demonstrate that the proposed approach can better leverage unlabeled data from the target domain and achieve substantial improvements over baseline methods in various experimental settings.  
 In recent years, we have seen deep learning and distributed representations of words and sentences make impact on a number of natural language processing tasks, such as similarity, entailment and sentiment analysis. Here we introduce a new task: understanding of mental health concepts derived from Cognitive Behavioural Therapy . We define a mental health ontology based on the CBT principles, annotate a large corpus where this phenomena is exhibited and perform understanding using deep learning and distributed representations. Our results show that the performance of deep learning models combined with word embeddings or sentence embeddings significantly outperform non-deep-learning models in this difficult task. This understanding module will be an  essential component of a statistical dialogue system delivering therapy.  %In the last decade we have seen machine learning make a significant impact on dialogue research.  %We can now make fully statistical end-to-end dialogue systems that can operate in a limited domain, for instance restaurant information or bus timetables. These techniques are part of a user-in-the-loop framework where the system can be quickly deployed and then continuously learn from interaction with real users. It is now time to address the challenge of building the next generation of spoken dialogue systems.  A particular application where a significantly increased level of complexity is needed is a mental health application. Such an application necessitates a sophisticated natural language understanding unit. In this work, we present a mental health ontology based on cognitive behavioural therapy  principles and a natural language understanding unit developed using deep learning algorithms, that can classify text according to that ontology. 
 In this paper, we introduce Adversarial-and-attention Network  for Machine Reading Comprehension. This model extends existing approaches from two perspectives. First, adversarial training is applied to several target variables within the model, rather than only to the inputs or embeddings. We control the norm of adversarial perturbations according to the norm of original target variables, so that we can jointly add perturbations to several target variables during training. As an effective regularization method, adversarial training improves robustness and generalization of our model. Second, we propose a multi-layer attention network utilizing three kinds of high-efficiency attention mechanisms. Multi-layer attention conducts interaction between question and passage within each layer, which contributes to reasonable representation and understanding of the model. Combining these two contributions, we enhance the diversity of dataset and the information extracting ability of the model at the same time. Meanwhile, we construct A3Net for the WebQA dataset. Results show that our model outperforms the state-of-the-art models . %  
 In this paper we present our approach to tackle the Implicit Emotion Shared Task  organized as part of WASSA 2018 at EMNLP 2018. Given a tweet, from which a certain word has been removed, we are asked to predict the emotion of the missing word. In this work, we experiment with neural Transfer Learning  methods.  Our models are based on LSTM networks, augmented with a self-attention mechanism. We use the weights of various pretrained models,  for initializing specific layers of our networks. We leverage a big collection of unlabeled Twitter messages, for pretraining word2vec word embeddings and a set of diverse language models. Moreover, we utilize a sentiment analysis dataset for pretraining a model, which encodes emotion related information. The submitted model consists of an ensemble of the aforementioned TL models. Our team ranked  out of 30 participants, achieving an $F_{1}$ score of 0.703.   %     First, we train a model in a Twitter sentiment analysis dataset. %     We also leverage a huge collection of unlabeled Twitter messages, by training word embeddings and employing a language model in order to capture the compositionality of language. Transferring knowledge from a language model creates emotionally richer word representations, which are then used to handle this classification task, which is essentially a cloze test. %     We transfer knowledge not only from pretrained word embeddings, but also   % We propose a model based on the ensembling of state-of-the-art Transfer Learning  methods.  % We experiment with 3 TL approaches, all of which share the same attentive LSTM-based architecture.  	 % The first model employs TL of pretrained word embeddings, while the second leverages a classifier pretrained on a similar task. Our biggest contribution lies in the third model, which transfers knowledge from language models pretrained on manually-collected unlabeled Twitter corpora,  in order to obtain emotionally richer word representations.     %     Our system includes 3 pretrained models, all of which were fine-tuned on the target task. %     For the first model, we trained word2vec word embeddings on a 550M Twitter corpus.  %     For the second, we applied transfer learning of a pretrained attentive bi-LSTM classifier on a sentiment classification task.  %     Our biggest contribution lies in the third model, in which we applied transfer learning of pretrained language models on manually-collected unlabeled Twitter corpora to obtain emotionally richer word representations.   
   Neural Conversation Models or chatbots tend to generate safe, generic and uninteresting responses to almost all inputs due to the limitations of Likelihood based decoding objective. To fix this, we hypothesize that in a natural conversations, an individual always have a { at the back of the mind. Following this intuition we propose two new constraints on decoding objective which help in generating more content relevant responses with the help of a Syntax-Topic model   and Sentence embeddings . By analyzing our results with automatic metrics and human evaluation we conclude that our model indeed generates content rich responses and outperforms other previous works. 
 A novel graph-to-tree conversion mechanism called the deep-tree generation  algorithm is first proposed to predict text data represented by graphs. The DTG method can generate a richer and more accurate representation for nodes  in graphs.  It adds flexibility in exploring the vertex neighborhood information to better reflect the second order proximity and homophily equivalence in a graph. Then, a Deep-Tree Recursive Neural Network  method is presented and used to classify vertices that contains text data in graphs.  To demonstrate the effectiveness of the DTRNN method, we apply it to three real-world graph datasets and show that the DTRNN method outperforms several state-of-the-art benchmarking methods.  
 Natural language generators for task-oriented dialog should be able to vary the style of the output utterance while still effectively realizing the system dialog actions and their associated semantics. While the use of neural generation for training the response generation component of conversational agents promises to simplify the process of producing high quality responses in new domains, to our knowledge, there has been very little investigation of neural generators for task-oriented dialog that can vary their response style, and we know of no experiments on models that can generate responses that are different in style from those seen during training, while still maintaining semantic fidelity to the input meaning representation.  Here, we show that a model that is trained to achieve a single stylistic personality target can produce outputs that combine stylistic targets. We carefully evaluate the multivoice outputs for both semantic fidelity and for similarities to and differences from the linguistic features that characterize the original training style. We show that contrary to our predictions, the learned models do not always simply interpolate model parameters, but rather produce styles that are distinct, and novel from the personalities they were trained on. 
 In this paper, we present the system we have used for the Implicit WASSA 2018 Implicit Emotion Shared Task. The task is to predict the emotion of a tweet of which the explicit mentions of emotion terms have been removed. The idea is to come up with a model which has the ability to implicitly identify the emotion expressed given the context words. We have used a Gated Recurrent Neural Network  and a Capsule Network based model for the task. Pre-trained word embeddings have been utilized to incorporate contextual knowledge about words into the model. GRU layer learns latent representations using the input word embeddings. Subsequent  Capsule Network layer learns high-level features from that hidden representation. The proposed model managed to achieve a macro-F1 score of 0.692. 
  Search-oriented conversational systems rely on information needs expressed in natural language . We focus here on the understanding of NL expressions for building keyword-based queries. We propose a  reinforcement-learning-driven translation model framework  able to 1) learn the translation from NL expressions to queries in a supervised way, and, 2) to overcome the lack of large-scale dataset by framing the translation model as a word selection approach and injecting relevance feedback in the learning process. Experiments are carried out on two TREC datasets and outline the effectiveness of our approach. 
 In this paper, we describe the system submitted for the shared task on Social Media Mining for Health Applications by the team Light. Previous works demonstrate that LSTMs have achieved remarkable performance in natural language processing tasks. We deploy an ensemble of two LSTM models. The first one is a pretrained language model appended with a classifier and takes words as input, while the second one is a LSTM model with an attention unit over it which takes character tri-gram as input. We call the ensemble of these two models: Neural-DrugNet. Our system ranks 2nd in the second shared task: Automatic classification of posts describing medication intake.  
 		Neural Machine Translation  can be improved by including document-level contextual information. For this purpose, we propose a hierarchical attention model to capture the context in a structured and dynamic manner. The model is integrated in the original NMT architecture as another level of abstraction, conditioning on the NMT model's own previous hidden states. Experiments show that hierarchical attention significantly improves the BLEU score over a strong NMT baseline with the state-of-the-art in context-aware methods, and that both the encoder and decoder benefit from context in complementary ways. 	
 A major obstacle in reinforcement learning-based sentence generation is the large action space whose size is equal to the vocabulary size of the target-side language. To improve the efficiency of reinforcement learning, we present a novel approach for reducing the action space based on dynamic vocabulary prediction. Our method first predicts a fixed-size small vocabulary for each input to generate its target sentence. The input-specific vocabularies are then used at supervised and reinforcement learning steps, and also at test time. In our experiments on six machine translation and two image captioning datasets, our method achieves faster reinforcement learning  with less GPU memory  than the full-vocabulary counterpart. We also show that our method more effectively receives rewards with fewer iterations of supervised pre-training.  
   The addition of syntax-aware decoding in Neural Machine Translation    systems requires an effective tree-structured neural network, a syntax-aware   attention model and a language generation model that is sensitive to sentence   structure.   %Recent approaches resort to sequential decoding by adding additional neural   %network units to capture bottom-up structural information, or serialising   %structured data into sequence.   We exploit a top-down tree-structured model called DRNN  first proposed by Alvarez-Melis and Jaakola  to create   an NMT model called Seq2DRNN that combines a sequential encoder with   tree-structured decoding augmented with a syntax-aware attention model.   Unlike previous approaches to syntax-based NMT which use dependency parsing   models our method uses constituency parsing which we argue provides useful   information for translation.   In addition, we use the syntactic structure of the sentence to add new   connections to the tree-structured decoder neural network .   We compare our NMT model with sequential and state of the art syntax-based   NMT models and show that our model produces more fluent translations with   better reordering.   Since our model is capable of doing translation and constituency parsing at   the same time we also compare our parsing accuracy against other neural   parsing models. 
 Multi-hop reading comprehension focuses on one type of factoid question, where a system needs to properly integrate multiple pieces of evidence to correctly answer a question.  Previous work approximates global evidence with local coreference information, encoding coreference chains with DAG-styled GRU layers within a gated-attention reader. However, coreference is limited in providing information for rich inference. We introduce a new method for better connecting global evidence, which forms more complex graphs compared to DAGs. To perform evidence integration on our graphs, we investigate two recent graph neural networks, namely graph convolutional network  and graph recurrent network . Experiments on two standard datasets show that richer global information leads to better answers. Our method performs better than all published results on these datasets. 
 Most existing recursive neural network  architectures utilize only the structure of parse trees, ignoring syntactic tags which are provided as by-products of parsing.  We present a novel RvNN architecture that can provide dynamic compositionality by considering comprehensive syntactic information derived from both the structure and linguistic tags.  Specifically, we introduce a structure-aware tag representation constructed by a separate tag-level tree-LSTM.  With this, we can control the composition function of the existing word-level tree-LSTM by augmenting the representation as a supplementary input to the gate functions of the tree-LSTM.  In extensive experiments, we show that models built upon the proposed architecture obtain superior or competitive performance on several sentence-level tasks such as sentiment analysis and natural language inference when compared against previous tree-structured models and other sophisticated neural models. 
 We propose an unsupervised method to obtain cross-lingual embeddings without any parallel data or pre-trained word embeddings. The proposed model, which we call multilingual neural language models, takes sentences of multiple languages as an input. The proposed model contains bidirectional LSTMs that perform as forward and backward language models, and these networks are shared among all the languages. The other parameters, i.e. word embeddings and linear transformation between hidden states and outputs, are specific to each language. The shared LSTMs can capture the common sentence structure among all languages. Accordingly, word embeddings of each language are mapped into a common latent space, making it possible to measure the similarity of words across multiple languages. We evaluate the quality of the cross-lingual word embeddings on a word alignment task. Our experiments demonstrate that our model can obtain cross-lingual embeddings of much higher quality than existing unsupervised models when only a small amount of monolingual data  are available, or the domains of monolingual data are different across languages. 
 Neural question generation  is the task of generating a question from a given passage with deep neural networks. Previous NQG models suffer from a problem that a significant proportion of the generated questions include words in the question target, resulting in the generation of unintended questions. In this paper, we propose answer-separated seq2seq, which better utilizes the information from both the passage and the target answer. By replacing the target answer in the original passage with a special token, our model learns to identify which interrogative word should be used.  We also propose a new module termed keyword-net, which helps the model better capture the key information in the target answer and generate an appropriate question. Experimental results demonstrate that our answer separation method significantly reduces the number of  improper questions which include answers. Consequently, our model significantly outperforms previous state-of-the-art NQG models.  %\textcolor{blue}{Neural question generation  is an emerging task of generating a question related to the given passage and the target answer with deep neural networks. We find that previous NQG models have a critical issue that many of generated questions include the answer words, resulting in the unintended questions. In this paper, we propose an answer separation technique for NQG that encodes the given passage and answer words separately. Specifically, by substituting answer words with a special token, our NQG model clearly identifies where the questioning part is. We also propose a keyword-net module to capture the key information in the separated answer words during the question generation. Experimental results corroborate that our answer separation method plays crucial role in generating plausible questions. Consequently, our NQG model significantly outperforms previous state-of-the-art NQG models.}  %We further use a retrieval style word generator to capture the word semantics during decoding % as well as answers are not included in generated questions with the proposed model. % In addition, we show the answer separation's actual impact on question generation. 
   This document contains the instructions for preparing a camera-ready   manuscript for the proceedings of . The document itself   conforms to its own specifications, and is therefore an example of   what your manuscript should look like. These instructions should be   used for both papers submitted for review and for final versions of   accepted papers.  Authors are asked to conform to all the directions   reported in this document. 
 A novel logographic subword model is proposed to reinterpret logograms as abstract subwords for neural machine translation. Our approach drastically reduces the size of an artificial neural network, while maintaining comparable BLEU scores as those attained with the baseline RNN and CNN seq2seq models. The smaller model size also leads to shorter training and inference time. Experiments demonstrate that in the tasks of English-Chinese/Chinese-English translation, the reduction of those aspects can be from $11\%$ to as high as $77\%$. Compared to previous subword models, abstract subwords can be applied to various logographic languages. Considering most of the logographic languages are ancient and very low resource languages, these advantages are very desirable for archaeological computational linguistic applications such as a resource-limited offline hand-held Demotic-English translator.  
 Question Generation is the task of automatically creating questions from textual input. In this work we present a new Attentional Encoder--Decoder Recurrent Neural Network model for automatic question generation. Our model incorporates linguistic features and an additional sentence embedding to capture meaning at both sentence and word levels. The linguistic features are designed to capture information related to named entity recognition, word case, and entity coreference resolution.  In addition our model uses a copying mechanism and a special answer signal that enables generation of numerous diverse questions on a given sentence.  Our model achieves state of the art results of 19.98 Bleu\_4 on a benchmark Question Generation dataset, outperforming all previously published results by a significant margin. A human evaluation also shows that the added features improve the quality of the generated questions. 
 Topic models are evaluated based on their ability to describe documents well  and to produce topics that carry coherent semantic meaning. In topic modeling so far, perplexity is a direct optimization target. However, topic coherence, owing to its challenging computation, is not optimized for and is only evaluated after training. In this work, under a neural variational inference framework, we propose methods to incorporate a topic coherence objective into the training process. We demonstrate that such a coherence-aware topic model exhibits a similar level of perplexity as baseline models but achieves substantially higher topic coherence. 
 		Recent neural models for data-to-text generation are mostly based on data-driven end-to-end training over encoder-decoder networks. 		Even though the generated texts are mostly fluent and informative, they often generate descriptions that are not consistent with the input structured data. 		This is a critical issue especially in domains that require inference or calculations over raw data. 		In this paper, we attempt to improve the fidelity of neural data-to-text generation by utilizing pre-executed symbolic operations. 		We propose a framework called Operation-guided Attention-based sequence-to-sequence network , with a specifically designed gating mechanism as well as a quantization module for operation results to utilize information from pre-executed operations. 		Experiments on two sports datasets show our proposed method clearly improves the fidelity of the generated texts to the input structured data. 	
 To improve the training efficiency of hierarchical recurrent models without compromising their performance, we propose a strategy named as ``the lower the simpler'', which is to simplify the baseline models by making the lower layers simpler than the upper layers. We carry out this strategy to simplify two typical hierarchical recurrent models, namely Hierarchical Recurrent Encoder-Decoder  and R-NET, whose basic building block is GRU. Specifically, we propose Scalar Gated Unit , which is a simplified variant of GRU, and use it to replace the GRUs at the middle layers of HRED and R-NET. Besides, we also use Fixed-size Ordinally-Forgetting Encoding , which is an efficient encoding method without any trainable parameter, to replace the GRUs at the bottom layers of HRED and R-NET. The experimental results show that the simplified HRED and the simplified R-NET contain significantly less trainable parameters, consume significantly less training time, and achieve slightly better performance than their baseline models. 
 Responses in task-oriented dialogue systems often realize multiple propositions whose ultimate form depends on the use of sentence planning and discourse structuring operations. For example a recommendation may consist of an explicitly evaluative utterance e.g. {, that combines multiple propositions into a single phrase.  While neural generation methods integrate sentence planning and surface realization in one end-to-end learning framework, previous work has not shown that neural generators can:  perform common sentence planning and discourse structuring operations; % such as distributive aggregation { can the model generate from a meaning representation specifying bad food and service?   We systematically create large training corpora that exhibit particular sentence planning operations and then test neural models to see what they learn.  We compare models without explicit latent variables for sentence planning with ones that provide explicit supervision during training. We show that only the models with additional supervision can reproduce sentence planning and discourse operations and generalize to situations unseen in training. 
      This paper presents a language-independent deep learning architecture adapted to the task of multiword expression  identification. We employ a neural architecture comprising of convolutional and recurrent layers with the addition of an optional CRF layer at the top.    This system participated in the open track of the Parseme shared task on automatic identification of verbal MWEs due to the use of pre-trained wikipedia word embeddings. It outperformed all participating systems in both open and closed tracks with the overall macro-average MWE-based F1 score of 58.09 averaged among all languages.   A particular strength of the system is its superior performance on unseen data entries. 
 Multi-label text classification  aims to assign multiple labels to each sample in the dataset. The labels usually have internal correlations. However, traditional methods tend to ignore the correlations between labels. In order to capture the correlations between labels, the sequence-to-sequence  model views the MLTC task as a sequence generation problem, which achieves excellent performance on this task. However, the Seq2Seq model is not suitable for the MLTC task in essence. The reason is that it requires humans to predefine the order of the output labels, while some of the output labels in the MLTC task are essentially an unordered set rather than an ordered sequence. This conflicts with the strict requirement of the Seq2Seq model for the label order. In this paper, we propose a novel sequence-to-set framework utilizing deep reinforcement learning, which not only captures the correlations between labels, but also reduces the dependence on the label order. Extensive experimental results show that our proposed method outperforms the competitive baselines by a large margin.  
 Neural machine translation  models are usually trained with the word-level loss using the teacher forcing algorithm, which not only evaluates the translation improperly but also suffers from exposure bias. Sequence-level training under the reinforcement framework can mitigate the problems of the word-level loss, but its performance is unstable due to the high variance of the gradient estimation. On these grounds, we present a method with a differentiable sequence-level training objective based on probabilistic n-gram matching which can avoid the reinforcement framework. In addition, this method performs greedy search in the training which uses the predicted words as context just as at inference to alleviate the problem of exposure bias. Experiment results on the NIST Chinese-to-English translation tasks show that our method significantly outperforms the reinforcement-based algorithms and achieves an improvement of 1.5 BLEU points on average over a strong baseline system.  
  Neural machine translation  has significantly improved the quality of automatic translation models. One of the main challenges in current systems is the translation of rare words. We present a generic approach to address this weakness by having external models annotate the training data as~Experts, and control the model-expert interaction with a pointer network and reinforcement learning. Our experiments using phrase-based models to simulate Experts to complement neural machine translation models show that the model can be trained to copy the annotations into the output consistently. We demonstrate the benefit of our proposed framework in out-of-domain translation scenarios with only lexical resources, improving more than 1.0 BLEU point in both translation directions English$\rightarrow$Spanish and German$\rightarrow$English.   
     Generating structured query language  from natural language is an emerging research topic. This paper presents a new learning paradigm from indirect supervision of the answers to natural language questions, instead of SQL queries. This paradigm facilitates the acquisition of training data due to the abundant resources of question-answer pairs for various domains in the Internet, and expels the difficult SQL annotation job. An end-to-end neural model integrating with reinforcement learning is proposed to learn SQL generation policy within the answer-driven learning paradigm. The model is evaluated on datasets of different domains, including movie and academic publication.  Experimental results show that our model outperforms the baseline models. 
 This paper describes our submission to \udst{}. We have extended an LSTM-based neural network designed for sequence tagging to additionally generate character-level sequences. The network was jointly trained to produce lemmas, part-of-speech tags and morphological features. Sentence segmentation, tokenization and dependency parsing were handled by UDPipe 1.2 baseline. The results demonstrate the viability of the proposed multitask architecture, although its performance still remains far from state-of-the-art.  
 Despite the success achieved on various natural language processing tasks, word embeddings are difficult to interpret due to the dense vector representations. This paper focuses on interpreting the embeddings for various aspects, including sense separation in the vector dimensions and definition generation. Specifically, given a context together with a target word, our algorithm first projects the target word embedding to a high-dimensional sparse vector and picks the specific dimensions that can best explain the semantic meaning of the target word by the encoded contextual information, where the sense of the target word can be indirectly inferred. Finally, our algorithm applies an RNN to generate the textual definition of the target word in the human readable form, which enables direct interpretation of the corresponding word embedding.  This paper also introduces a large and high-quality context-definition dataset that consists of sense definitions together with multiple example sentences per  polysemous word, which is a valuable resource for definition modeling~ and word sense disambiguation. The conducted experiments show the superior performance in BLEU score and the human evaluation test. 
 Capturing the semantic relations of words in a vector space contributes to many natural language processing tasks. One promising approach exploits lexico-syntactic patterns as features of word pairs. In this paper, we propose a novel model of this pattern-based approach, neural latent relational analysis . NLRA can generalize co-occurrences of word pairs and lexico-syntactic patterns, and obtain embeddings of the word pairs that do not co-occur. This overcomes the critical data sparseness problem encountered in previous pattern-based models. Our experimental results on measuring relational similarity demonstrate that NLRA outperforms the previous pattern-based models. In addition, when combined with a vector offset model, NLRA achieves a performance comparable to that of the state-of-the-art model that exploits additional semantic relational data. 
 This work investigates the alignment problem in state-of-the-art multi-head attention models based on the transformer architecture. We demonstrate that alignment extraction in transformer models can be improved by augmenting an additional alignment head to the multi-head source-to-target attention component. This is used to compute sharper  attention weights. We describe how to use the alignment head to achieve competitive performance. To study the effect of adding the alignment head, we simulate a dictionary-guided translation task, where  the user wants to guide translation using pre-defined dictionary entries. Using the proposed approach, we achieve up to $3.8$\% BLEU improvement when using the dictionary, in comparison to $2.4$\% BLEU in the baseline case. We also propose alignment 	pruning to speed up decoding in alignment-based neural machine translation , which speeds up translation by a factor of $1.8$ without loss in translation performance. We carry out experiments on the shared WMT 2016 English$\to$Romanian news task and the BOLT Chinese$\to$English discussion forum task.  
  Automatic evaluation of semantic rationality is an important yet challenging task, and current automatic techniques cannot well identify whether a sentence is semantically rational. The methods based on the language model do not measure the sentence by rationality but by commonness. The methods based on the similarity with human written sentences will fail if human-written references are not available. In this paper, we propose a novel model called Sememe-Word-Matching Neural Network  to tackle semantic rationality evaluation by taking advantage of sememe knowledge base HowNet. The advantage is that our model can utilize a proper combination of sememes to represent the fine-grained semantic meanings of a word within the specific contexts. We use the fine-grained semantic representation to help the model learn the semantic dependency among words. To evaluate the effectiveness of the proposed model, we build a large-scale rationality evaluation dataset. Experimental results on this dataset show that the proposed model outperforms the competitive baselines with a 5.4\% improvement in accuracy.   
 Sequential neural networks models are powerful tools in a variety of Natural Language Processing  tasks. The sequential nature of these models raises the questions: to what extent can these models implicitly learn hierarchical structures typical to human language, and what kind of grammatical phenomena can they acquire?  We focus on the task of agreement prediction in Basque, as a case study for a task that requires implicit understanding of sentence structure and the acquisition of a complex but consistent morphological system. Analyzing experimental results from two syntactic prediction tasks -- verb number prediction and suffix recovery -- we find that sequential models perform worse on agreement prediction in Basque than one might expect on the basis of a previous agreement prediction work in English. Tentative findings based on diagnostic classifiers suggest the network makes use of local heuristics as a proxy for the hierarchical structure of the sentence. We propose the Basque agreement prediction task as challenging benchmark for models that attempt to learn regularities in human language.  
  In this submission I report work in progress on learning simplified interpreted languages by means of recurrent models. The data is constructed to reflect core properties of natural language as modeled in formal syntax and semantics: recursive syntactic structure and compositionality. Preliminary results suggest that LSTM networks do generalise to compositional interpretation, albeit only in the most favorable learning setting, with a well-paced curriculum, extensive training data, and left-to-right  composition.  
   Songs can be well arranged by professional music curators to form a riveting   playlist that creates engaging listening experiences. However, it is   time-consuming for curators to timely rearrange these playlists for   fitting trends in future.   By exploiting the techniques of deep learning and reinforcement learning,   in this paper, we consider music playlist generation as a language modeling problem   and solve it by the proposed attention language model with policy gradient.   We develop a systematic and interactive approach   so that the resulting playlists can be tuned flexibly according to user preferences.   Considering a playlist as a sequence of words,   we first train our attention RNN language model on   baseline recommended playlists.   By optimizing suitable imposed reward functions,   the model is thus refined for corresponding preferences.   The experimental results demonstrate that our approach   not only generates coherent playlists automatically   but is also able to flexibly recommend personalized playlists   for diversity, novelty and freshness. 
  Dialogue systems are usually built on either generation-based or retrieval-based approaches,   yet they do not benefit from the advantages of different models. In this paper,   we propose a Retrieval-Enhanced Adversarial Training  method for neural response generation.   Distinct from existing approaches, the REAT method leverages an encoder-decoder framework in terms of an adversarial training paradigm,   while taking advantage of N-best response candidates from a retrieval-based system to construct the discriminator.   An empirical study on a large scale public available benchmark dataset shows that the REAT method significantly outperforms the vanilla Seq2Seq model as well as the conventional adversarial training approach. 
 Word  embeddings have been widely adopted across several NLP applications. Most existing word embedding methods utilize  of a word to learn its embedding. While there have been some attempts at utilizing  of a word, such methods result in an explosion of the vocabulary size. In this paper, we overcome this problem by proposing \method{}, a flexible Graph Convolution  based method for learning word embeddings. \method{} utilizes the dependency context of a word without increasing the vocabulary size. %However, most word embedding methods operate at word-level and solely rely on sequential context.  %and do not provide a framework for incorporating word relationships like hypernym, synonym  in a principled manner. %While there exist approaches for utilizing signals from semantic knowledge sources, all of them deal with each word in isolation.  %In this paper, we propose \method{}, a Graph Convolution based approach which utilizes dependency context for learning meaningful word representation. Unlike previous methods, \method{} operates at sentence-level and efficiently incorporates dependency context without increasing the vocabulary size %To the best of our knowledge, this is the first approach which effectively incorporates word relationships via Graph Convolutional Networks for learning word representations.  Word embeddings learned by \method{} outperform existing methods on various intrinsic and extrinsic tasks and provide an advantage when used with ELMo.  %\method{} is also able to incorporate  %We also propose \methodside{}, an effective framework for incorporating  %diverse semantic relationships between words to further enhance learned word representations.  We also propose \methodside{}, an effective framework for incorporating diverse semantic knowledge for further enhancing learned word representations.  %We make \method{}'s source code We make the source code of both models available to encourage reproducible research.  %Through extensive experiments on various intrinsic and extrinsic tasks, we demonstrate \method{}'s effectiveness over existing word embedding approaches.  
 % We propose Emo2Vec, a vector embedding space, able to effectively represent word emotion semantics leveraging multi-task training. Five affect-related tasks are utilized, including sentiment/emotion classification, sarcasm detection, stress detection, abusive language classification, and personality recognition. We empirically show how Emo2Vec leverages multi-task training to learn a generalized emotion representation with small training corpora. In addition, Emo2Vec outperforms existing affect-related embeddings on more than ten different datasets. By combining Emo2Vec with GloVe, logistic regression can achieve competitive performances to several state-of-the-art results. Lastly, visualization of learned vectors shows that words with similar emotion are clustered together.  In this paper, we propose Emo2Vec which encodes emotional semantics into vectors. We train Emo2Vec by multi-task learning six different emotion-related tasks, including emotion/sentiment analysis, sarcasm classification, stress detection, abusive language classification, insult detection, and personality recognition. Our evaluation of Emo2Vec shows that it outperforms existing affect-related representations, such as Sentiment-Specific Word Embedding and DeepMoji embeddings with much smaller training corpora. When concatenated with GloVe, Emo2Vec achieves competitive performances to state-of-the-art results on several tasks using a simple logistic regression classifier. % Finally, we visualize the learned vectors, showing that Emo2Vec can cluster words with similar emotion together.    % small datasets. combining them compared to billions of tweets.  % generalized is important?  % multi-task is good  % Emo2Vec is good   % figure   
   plays an important role in current speech processing systems, including  .  SAD is particularly difficult in environments with acoustic noise. A practical solution is to incorporate visual information, increasing the robustness of the SAD approach. An audiovisual system has the advantage of being robust to different speech modes  or background noise. Recent advances in audiovisual speech processing using deep learning have opened opportunities to capture in a principled way the temporal relationships between acoustic and visual features. This study explores this idea proposing a   framework for SAD. The approach models the temporal dynamic of the sequential audiovisual data, improving the accuracy and robustness of the proposed SAD system. Instead of estimating hand-crafted features, the study investigates an end-to-end training approach, where acoustic and visual features are directly learned from the raw data during training. The experimental evaluation considers a large audiovisual corpus with over 60.8 hours of recordings, collected from 105 speakers. The results demonstrate that the proposed framework leads to absolute improvements up to 1.2\% under practical scenarios over a VAD baseline using only audio implemented with  . The proposed approach achieves 92.7\% F1-score when it is evaluated using the sensors from a portable tablet under noisy acoustic environment, which is only 1.0\% lower than the performance obtained under ideal conditions . 
 Transferring representations from large supervised tasks to downstream tasks has shown promising results in AI fields such as Computer Vision and Natural Language Processing . In parallel, the recent progress in Machine Translation  has enabled one to train multilingual Neural MT  systems that can translate between multiple languages and are also capable of performing zero-shot translation. However, little attention has been paid to leveraging representations learned by a multilingual NMT system to enable zero-shot multilinguality in other NLP tasks. In this paper, we demonstrate a simple framework, a multilingual Encoder-Classifier, for cross-lingual transfer learning by reusing the encoder from a multilingual NMT system and stitching it with a task-specific classifier component. Our proposed model achieves significant improvements in the English setup on three benchmark tasks - Amazon Reviews, SST and SNLI. Further, our system can perform classification in a new language for which no classification data was seen during training, showing that zero-shot classification is possible and remarkably competitive. In order to understand the underlying factors contributing to this finding, we conducted a series of analyses on the effect of the shared vocabulary, the training data type for NMT, classifier complexity, encoder representation power, and model generalization on zero-shot performance. Our results provide strong evidence that the representations learned from multilingual NMT systems are widely applicable across languages and tasks. 
 Article comments can provide supplementary opinions and facts for readers, thereby increase the attraction and engagement of articles. Therefore, automatically commenting is helpful in improving the activeness of the community, such as online forums and news websites. Previous work shows that training an automatic commenting system requires large parallel corpora. Although part of articles are naturally paired with the comments on some websites, most articles and comments are unpaired on the Internet. To fully exploit the unpaired data, we completely remove the need for parallel data and propose a novel unsupervised approach to train an automatic article commenting model, relying on nothing but unpaired articles and comments. Our model is based on a retrieval-based commenting framework, which uses news to retrieve comments based on the similarity of their topics. The topic representation is obtained from a neural variational topic model, which is trained in an unsupervised manner. We evaluate our model on a news comment dataset. Experiments show that our proposed topic-based approach significantly outperforms previous lexicon-based models. The model also profits from paired corpora and achieves state-of-the-art performance under semi-supervised scenarios. 
  To better understand the effectiveness of continued training,  we analyze the major components of a neural machine translation system  and consider each component's contribution to, and capacity for, domain adaptation.  We find that freezing any single component  during continued training has minimal impact on performance,  and that performance is surprisingly good  when a single component is adapted while holding the rest of the model fixed.  We also find that continued training does not move the model very far from the out-of-domain model,  compared to a sensitivity analysis metric,  suggesting that the out-of-domain model can provide a good generic initialization for the new domain.   
 In this paper, we present a method of automatic catchphrase extracting from legal case documents. We utilize deep neural networks for constructing scoring model of our extraction system. We achieve comparable performance with systems using corpus-wide and citation information which we do not use in our system.   	extbf{Keywords: catchphrase generation, legal case documents, convolutional neural networks} 
 The automation of text summarisation of biomedical publications is a pressing need due to the plethora of information available on-line. This paper explores the impact of several supervised machine learning approaches for extracting multi-document summaries for given queries. In particular, we compare classification and regression approaches for query-based extractive summarisation using data provided by the BioASQ Challenge. We tackled the problem of annotating sentences for training classification systems and show that a simple annotation approach outperforms regression-based summarisation. 
   This document contains the instructions for preparing a camera-ready   manuscript for the proceedings of . The document itself   conforms to its own specifications, and is therefore an example of   what your manuscript should look like. These instructions should be   used for both papers submitted for review and for final versions of   accepted papers.  Authors are asked to conform to all the directions   reported in this document. 
  One of the biggest challenges of end-to-end language generation from meaning representations in dialogue systems is making the outputs more natural and varied. Here we take a large corpus of 50K crowd-sourced utterances in the restaurant domain and develop text analysis methods that systematically characterize types of sentences in the training data. We then automatically label the training data to allow us to conduct two kinds of experiments with a neural generator. First, we test the effect of training the system with different stylistic partitions and quantify the effect of smaller, but more stylistically controlled training data. Second, we propose a method of labeling the style variants during training, and show that we can modify the style of the generated utterances using our stylistic labels. We contrast and compare these methods that can be used with any existing large corpus, showing how they vary in terms of semantic quality and stylistic control.  
 The use of connectionist approaches in conversational agents has been progressing rapidly due to the availability of large corpora. However current generative dialogue models often lack coherence and are content poor. This work proposes an architecture to incorporate unstructured knowledge sources to enhance the next utterance prediction in chit-chat type of generative dialogue models. We focus on Sequence-to-Sequence  conversational agents trained with the Reddit News dataset, and consider incorporating external knowledge from  Wikipedia summaries as well as from the NELL knowledge base. Our experiments show faster training time and improved perplexity when leveraging external knowledge.  
   Text classification is an important and classical problem in natural language processing. There have been a number of studies that applied convolutional neural networks  to classification. However, only a limited number of studies have explored the more flexible graph convolutional neural networks  for the task. In this work, we propose to use graph convolutional networks for text classification. We build a single text graph for a corpus based on word co-occurrence and document word relations, then learn a Text Graph Convolutional Network  for the corpus. Our Text GCN is initialized with one-hot representation for word and document, it then jointly learns the embeddings for both words and documents, as supervised by the known class labels for documents. Our experimental results on multiple benchmark datasets demonstrate that a vanilla Text GCN without any external word embeddings or knowledge outperforms state-of-the-art methods for text classification. On the other hand, Text GCN also learns predictive word and document embeddings. In addition, experimental results show that the improvement of Text GCN over state-of-the-art comparison methods become more prominent as we lower the percentage of training data, suggesting the robustness of Text GCN to less training data in text classification. % * <yuan.hypnos.luo@gmail.com> 2018-09-05T22:53:12.966Z: %  % > Our Text GCN is initialized with one-hot representation for word and document, it then jointly learns the embeddings for both words and documents, as supervised by the known class labels for documents. Our experimental results on multiple benchmark datasets demonstrate that a vanilla Text GCN without any external word embeddings or knowledge outperform state-of-the-art methods for text classification. On the other hand, Text GCN also learns predictive word and document embeddings. In addition, experimental results show that the improvement of Text GCN over state-of-the-art comparison methods become more prominent as we lower the percentage of training data, suggesting the robustness of Text GCN to less training data in text classification. % probably need to enumerate a few numbers  here. %  % ^. 
  All known natural language determiners are conservative. Psycholinguistic experiments indicate that children exhibit a corresponding learnability bias when faced with the task of learning new determiners. However, recent work indicates that this bias towards conservativity is not observed during the training stage of artificial neural networks. In this work, we investigate whether the learnability bias exhibited by children is in part due to the distribution of quantifiers in natural language. We share results of five experiments, contrasted by the distribution of conservative vs. non-conservative determiners in the training data. We demonstrate that the aquisitional issues with non-conservative quantifiers can not be explained by the distribution of natural language data, which favors conservative quantifiers. This finding indicates that the bias in language acquisition data might be innate or representational.  
 In sentiment analysis  of product reviews, both user and product information are proven to be useful. Current tasks handle user profile and product information in a unified model which may not be able to learn salient features of users and products effectively.  In this work, we propose a dual user and product memory network  model to learn user profiles and product reviews using separate memory networks. Then, the two representations are used jointly for sentiment prediction. The use of separate models aims to capture user profiles and product information more effectively. Compared to state-of-the-art unified prediction models, the evaluations on three benchmark datasets, IMDB, Yelp13, and Yelp14, show that our dual learning model gives performance gain of 0.6\%, 1.2\%, and 0.9\%, respectively. The improvements are also deemed very significant measured by p-values.  
  or { or {.   Due to the limited word occurrences or context in short text  and data sparsity in a corpus of few documents, the application of topics models is challenging on such texts.   Therefore,   we propose a simple and efficient way of incorporating  external knowledge encoded in neural autoregressive topic models: we use embeddings as a distributional prior. The proposed variants are named as {.   We present novel neural autoregressive topic model variants that consistently outperform state-of-the-art generative topic models  in terms of generalization, interpretability  and applicability  over 7 long-text and 8 short-text datasets  from various domains.  %demonstrate improved performance  %TO DO:  %This results in an improved performance in terms of generalization,  %interpretability  and applicability . %TO DO: We apply our modeling approach to seven data sets from various domains and demonstrate  % on five data sets  %that our approach consistently outperforms state-of-the-art generative topic models.  % needs some more work, motivation not entirely clear, start with topic models  TO DO: With the learned representations, we show on an average a gain of $9.6$\%  in precision  at retrieval fraction $0.02$ and $7.2$\%  in $F1$ for text categorization.  \fi  We address two challenges in topic models:   Context information around words helps in determining their actual meaning, e.g., ``networks'' used  in the contexts {.  Generative topic models infer topic-word distributions, taking no or only little context into account.  Here, we extend a neural autoregressive topic model to exploit the full context information around words  in a document in a language modeling fashion. The proposed model is named as { and iDocNADEe.   We present novel neural autoregressive topic model variants that consistently outperform state-of-the-art generative topic models  in terms of generalization, interpretability  and applicability  over 7 long-text and 8 short-text datasets  from diverse domains.   
  In this paper, we empirically evaluate the utility of transfer and multi-task learning on a challenging semantic classification task: semantic interpretation of noun--noun compounds. Through a comprehensive series of experiments and in-depth error analysis, we show that transfer learning via parameter initialization and multi-task learning via parameter sharing can help a neural classification model generalize over a highly skewed distribution of relations. Further, we demonstrate how dual annotation with two distinct sets of relations over the same set of compounds can be exploited to improve the overall accuracy of a neural classifier and its \fone scores on the less frequent, but more difficult relations.   
 Growing amount of comments make online discussions difficult to moderate by human moderators only. Antisocial behavior is a common occurrence that often discourages other users from participating in discussion. We propose a neural network based method that partially automates the moderation process. It consists of two steps. First, we detect inappropriate comments for moderators to see. Second, we highlight inappropriate parts within these comments to make the moderation faster. We evaluated our method on data from a major Slovak news discussion platform. 
  We propose a multi-task learning framework to learn a joint Machine Reading Comprehension  model that can be applied to a wide range of MRC tasks in different domains.   Inspired by recent ideas of data selection in machine translation, we develop a novel sample re-weighting scheme to assign sample-specific weights to the loss.   %Key to the proposed method is to learn robust and general contextual representations with the help of out-domain data in the multi-task framework.  Empirical study shows that our approach can be applied to many existing MRC models. Combined with contextual representations from pre-trained language models , we achieve new state-of-the-art results on a set of MRC benchmark datasets. We release our code at \url{https://github.com/xycforgithub/MultiTask-MRC}. %\footnote{We release our code at: \url{https://github.com/xycforgithub/MultiTask-MRC}.} %Empirical study of multi-task MRC model shows that the proposed approach is orthogonal to the existing pre-trained representation models,  such as word embedding and language models. Experiments on the Stanford Question Answering Dataset , the Microsoft MAchine Reading COmprehension Dataset , NewsQA and other datasets show that our multi-task learning approach achieves significant improvement over state-of-the-art models in most existing MRC tasks.  % We propose a multi-task learning approach to jointly train a Machine Reading Comprehension  model on multiple datasets across different domains. Key to the proposed method is to learn robust and general contextual representations with help of out-domain data in the multi-task framework preventing the overfitting issue. This trick is also orthogonal to most existing representation approaches such as word embedding and language models. Experiments on SQuAD, MS MARCO, NewsQA and other datasets show that MT-MRC achieves significant improvement over state-of-the-art models in most existing MRC tasks.  % {JJ:  % In this work, we propose a single Multi-Task MRC  model jointly trained on multiple datasets for Machine Reading Comprehension . Our model can learn a robust contextual representation via attention, which can generalize better on unseen samples by leveraging multi-task datasets to reduce inductive bias. The additional information learned from out-domain datasets is also orthogonal to most existing representation approaches such as word embedding and language models. Experiments on SQuAD, MS MARCO, NewsQA and other datasets show that MT-MRC achieves significant improvement over  state-of-the-art models in most existing MRC tasks. % }   % {Yelong: In this work, we propose an multi-task learning appraoch to jointly train several different domains of MRC datasets with one model.  }  % Although many datasets have been collected for machine reading comprehension , they are typically small in size, and different in domains and sources. We propose a multi-task learning  approach across domains to utilize these abundant resources: By using MTL, our model learns a more robust attention mechanism  that generalizes better on unseen samples. The additional information from out-domain datasets is orthogonal to existing methods that use upper-stream tasks, like word embedding and language models. Experiments show that MTL brings a large performance boost on state-of-art models of MRC, and surpasses human performance on SQuAD and NewsQA dataset. % Data augmentation is the central of many modern machine reading comprehension  systems; to overcome deficiency of training data, existing methods adopt large-scale corpus like language modeling and back translation to augment the training data. We introduce an orthogonal method of multi-task learning for MRC, that uses multiple existing MRC datasets to boost the performance of MRC systems. Experiments on SQuAD, NewsQA and MS Marco shows that multi-task learning achieves over 1.5\% increase on performance, and that the method brings similar amount of improvement when combined with ELMo. We give two methods to further improve the performance of multi-task learning: i) Using a mixture ratio between datasets for a target dataset; ii) Insert a highway network between layers to evaluate neuron importance. We also present negative transfer phenomenon using the Who-Did-What dataset. 
  Recent work has shown how to learn better visual-semantic embeddings by leveraging image descriptions in more than one language. Here, we investigate in detail which conditions affect the performance of this type of grounded language learning model. We show that multilingual training improves over bilingual training, and that low-resource languages benefit from training with higher-resource languages. We demonstrate that a multilingual model can be trained equally well on either translations or comparable sentence pairs, and that annotating the same set of images in multiple language enables further improvements via an additional caption-caption ranking objective.  
 The present paper surveys neural approaches to conversational AI that have been developed in the last few years. We group conversational systems into three categories:  question answering agents,  task-oriented dialogue agents, and  chatbots. For each category, we present a review of state-of-the-art neural approaches, draw the connection between them and traditional %symbolic  approaches, and discuss the progress that has been made and challenges still being faced, using specific systems and models as case studies.\footnote{We are grateful to the anonymous reviewers, Chris Brockett, Asli Celikyilmaz, Yu Cheng, Bill Dolan, Pascale Fung, Zhe Gan, Sungjin Lee, Jinchao Li, Xiujun Li, Bing Liu, Andrea Madotto, Rangan Majumder, Alexandros Papangelis, Olivier Pietquin, Chris Quirk, Alan Ritter, Paul Smolensky, Alessandro Sordoni, Yang Song, Hisami Suzuki,  Wei Wei, Tal Weiss, Kun Yuan, and Yizhe Zhang for their helpful comments and suggestions on earlier versions of this paper.} 
     Previous research on word embeddings has shown that sparse representations, which can be either learned on top of     existing dense embeddings or obtained through model constraints during training time, have the benefit of increased     interpretability properties: to some degree, each dimension can be understood by a human and associated with a     recognizable feature in the data.     In this paper, we transfer this idea to sentence embeddings and explore several approaches to obtain a sparse     representation.     We further introduce a novel, quantitative and automated evaluation metric for sentence embedding interpretability,     based on topic coherence methods.     We observe an increase in interpretability compared to dense models, on a dataset of movie dialogs and on the scene     descriptions from the MS COCO dataset. 
 Problems at the intersection of language and vision, like visual question answering, have recently been gaining a lot of attention in the field of multi-modal machine learning as computer vision research moves beyond traditional recognition tasks. There has been recent success in visual question answering using deep neural network models which use the linguistic structure of the questions to dynamically instantiate network layouts. In the process of converting the question to a network layout, the question is simplified, which results in loss of information in the model. In this paper, we enrich the image information with textual data using image captions and external knowledge bases to generate more coherent answers. We achieve 57.1\% overall accuracy on the test-dev open-ended questions from the visual question answering  real image dataset. 
 Neural state-of-the-art sequence-to-sequence  models often do not perform well for small training sets. We address paradigm completion, the morphological task of, given a partial paradigm,  generating all missing forms. We propose two new methods for  the minimal-resource setting:   :  Since we assume only few paradigms available for training, neural seq2seq models are able to capture relationships between paradigm cells, but are tied to the idiosyncracies of the training set. Paradigm transduction mitigates this problem by exploiting the input subset of inflected forms at test time.   : Multi-source models which learn to automatically select one or  multiple sources to predict a target inflection do not perform well in the minimal-resource setting.  SHIP is an alternative to identify a reliable source if training data is limited. On a 52-language benchmark dataset,  we outperform the previous state of the art by up to $9.71\%$ absolute accuracy. 
 Neural cache language models  extend the idea of regular cache language models by making the cache probability dependent on the similarity between the current context and the context of the words in the cache. We make an extensive comparison of `regular' cache models with neural cache models, both in terms of perplexity and WER after rescoring first-pass ASR results. Furthermore, we propose two extensions to this neural cache model that make use of the content value/information weight of the word: firstly, combining the cache probability and LM probability with an information-weighted interpolation and secondly, selectively adding only content words to the cache. We obtain a 29.9\%/32.1\%  relative improvement in perplexity with respect to a baseline LSTM LM on the WikiText-2 dataset, outperforming previous work on neural cache LMs. Additionally, we observe significant WER reductions with respect to the baseline model on the WSJ ASR task. 
 Although end-to-end neural text-to-speech  methods  are proposed and achieve state-of-the-art performance, they still suffer from two problems: 1) low efficiency during training and inference; 2) hard to model long dependency using current recurrent neural networks . Inspired by the success of Transformer network in neural machine translation , in this paper, we introduce and adapt the multi-head attention mechanism to replace the RNN structures and also the original attention mechanism in Tacotron2. With the help of multi-head self-attention, the hidden states in the encoder and decoder are constructed in parallel, which improves training efficiency. Meanwhile, any two inputs at different times are connected directly by a self-attention mechanism, which solves the long range dependency problem effectively. Using phoneme sequences as input, our Transformer TTS network generates mel spectrograms, followed by a WaveNet vocoder to output the final audio results. Experiments are conducted to test the efficiency and performance of our new network. For the efficiency, our Transformer TTS network can speed up the training about 4.25 times faster compared with Tacotron2. For the performance, rigorous human tests show that our proposed model achieves state-of-the-art performance  and is very close to human quality . 
 In this paper we proposed an end-to-end short utterances speech language identification approach based on a Long Short Term Memory   neural network which is special suitable for SLD  application in intelligent vehicles. Features used for LSTM learning are generated by a transfer learning method. Bottle-neck features of a deep neural network  which are trained for mandarin acoustic-phonetic classification are used for LSTM training. In order to improve the SLD accuracy of short utterances a phase vocoder based time-scale modification method is used to reduce and increase speech rated of the test utterance. By splicing the normal, speech rate reduced and increased utterances, we can extend  length of test utterances so as to improved improved the performance of the SLD system. The experimental results on AP17-OLR database shows that the proposed methods can improve the performance of SLD, especially on short utterance with 1s and 3s durations. 
  We address jointly two important tasks for Question Answering in community forums: given a new question, \Ni , and \Nii .  We further use an auxiliary task to complement the previous two, i.e.,~\Niii . We use deep neural networks  to learn meaningful task-specific embeddings, which we then incorporate into a conditional random field  model for the multitask setting, performing joint learning over a complex graph structure. While DNNs alone achieve competitive results when trained to produce the embeddings, the CRF, which makes use of the embeddings and the dependencies between the tasks, improves the results significantly and consistently across a variety of evaluation metrics, thus showing the complementarity of DNNs and structured learning.  
 This paper presents an extension of the Stochastic Answer Network , one of the state-of-the-art machine reading comprehension models, to be  able to judge whether a question is unanswerable or not.  The extended SAN contains two components: a span detector and a binary classifier for judging whether the question is unanswerable, and both components are jointly optimized. Experiments show that SAN achieves the results competitive to the state-of-the-art on Stanford Question Answering Dataset  2.0. To facilitate the research on this field, we release our code: {https://github.com/kevinduh/san\_mrc}. 
 This work deals with non-native children's speech and investigates both multi-task and transfer learning approaches to adapt a multi-language Deep Neural Network  to speakers, specifically children,  learning a foreign language.  The application scenario is characterized by young students learning English and German and reading sentences in these second-languages, as well as in their mother language. The paper analyzes and discusses techniques for training effective DNN-based acoustic models starting from children native speech and performing adaptation with limited non-native audio material.  A multi-lingual model is adopted as baseline, where a common phonetic lexicon,  defined in terms of the units of the International Phonetic Alphabet , is shared across the three languages at hand ; DNN adaptation methods based on transfer learning are evaluated on significant non-native evaluation sets.     Results show that the resulting non-native models allow a significant improvement with respect to a mono-lingual system adapted to speakers of the target language.     
 Predicting context-dependent and non-literal utterances like sarcastic and ironic expressions still remains a challenging task in NLP, as it goes beyond linguistic patterns, encompassing common sense and shared knowledge as crucial components. To capture complex morpho-syntactic features that can usually serve as indicators for irony or sarcasm across dynamic contexts, we propose a model that uses character-level vector representations of words, based on ELMo. We test our model on 7 different datasets derived from 3 different data sources, providing state-of-the-art performance in 6 of them, and otherwise offering competitive results.  
 %Recently, researchers have found that deep LSTMs trained on tasks like machine translation learn substantial syntactic and semantic information about their input sentences, including part-of-speech . Recent work using auxiliary prediction task classifiers to investigate the properties of LSTM representations has begun to shed light on why pretrained representations, like ELMo  and CoVe , are so beneficial for neural language understanding models. %%%There is mounting evidence that pretrained representations, like ELMo  and CoVe , can be extremely valuable for neural network language understanding models.  %%%We still, though, do not yet have a clear understanding of how the choice of pretraining objective affects the type of linguistic information that models learn. We still, though, do not yet have a clear understanding of how the choice of pretraining objective affects the type of linguistic information that models learn. %but we do not yet have a clear understanding of how the choice of pretraining objective affects the type of linguistic information that models learn. %With this in mind, we compare four objectives---language modeling, translation, skip-thought, and autoencoding---on their ability to induce syntactic and part-of-speech information, holding constant the genre and quantity of training data. With this in mind, we compare four objectives---language modeling, translation, skip-thought, and autoencoding---on their ability to induce syntactic and part-of-speech information.  We make a fair comparison between the tasks by holding constant the quantity and genre of the training data, as well as the LSTM architecture. We find that representations from language models consistently perform best on our syntactic auxiliary prediction tasks, even when trained on relatively small amounts of data. These results suggest that language modeling may be the best data-rich pretraining task for transfer learning applications requiring syntactic information. We also find that the representations from randomly-initialized, frozen LSTMs perform strikingly well on our syntactic auxiliary tasks, but this effect disappears when the amount of training data for the auxiliary tasks is reduced. 
 Neural language models  exist in an accuracy--efficiency tradeoff space where better perplexity typically comes at the cost of greater computation complexity. In a software keyboard application on mobile devices, this translates into higher power consumption and shorter battery life. This paper represents the first attempt, to our knowledge, in exploring accuracy--efficiency tradeoffs for NLMs. Building on quasi-recurrent neural networks , we apply pruning techniques to provide a ``knob'' to select different  operating points. In addition, we propose a simple technique to recover some perplexity using a negligible amount of memory.  Our empirical evaluations consider both perplexity as well as  energy consumption on a Raspberry Pi, where we demonstrate which methods provide the best perplexity--power consumption operating point. At one operating point, one of the techniques is able to provide energy savings of 40\% over the state of the art with only a 17\% relative increase in perplexity.       
 In this paper, we introduce Iterative Text Summarization , an iteration-based model for supervised extractive text summarization, inspired by the observation that it is often necessary for a human to read an article multiple times in order to fully understand and summarize its contents. Current summarization approaches read through a document only once to generate a document representation, resulting in a sub-optimal representation. To address this issue we introduce a model which iteratively polishes the document representation on many passes through the document. As part of our model, we also introduce a selective reading mechanism that decides more accurately the extent to which each sentence in the model should be updated. Experimental results on the CNN/DailyMail and DUC2002 datasets demonstrate that our model significantly outperforms state-of-the-art extractive systems when evaluated by machines and by humans. 
 Language-modeling--based approaches to story plot generation attempt to construct a plot by sampling from a language model  to predict the next character, word, or sentence to add to the story. LM techniques lack the ability to receive guidance from the user to achieve a specific goal, resulting in stories that don't have a clear sense of progression and lack coherence. We present a reward-shaping technique that analyzes a story corpus and produces intermediate rewards that are backpropagated into a pre-trained LM in order to guide the model towards a given goal. Automated evaluations show our technique can create a model that generates story plots which consistently achieve a specified goal. Human-subject studies show that the generated stories have more plausible event ordering than baseline plot generation techniques. 
 We present an operational component of a real-world patient triage system. Given a specific patient presentation, the system is able to assess the level of medical urgency and issue the most appropriate recommendation in terms of best point of care and time to treat. We use an attention-based convolutional neural network architecture trained on 600,000 doctor notes in German. We compare two approaches, one that uses the full text of the medical notes and one that uses only a selected list of  medical entities extracted from the text.  These approaches achieve 79\% and 66\% precision, respectively, but on a confidence threshold of 0.6, precision increases to 85\% and 75\%, respectively. In addition, a method to detect warning symptoms is implemented to render the classification task transparent from a medical perspective. The method is based on the learning of attention scores and a method of automatic validation using the same data.  
 We introduce adaptive input representations for neural language modeling which extend the adaptive softmax of  to input representations of variable capacity. There are several choices on how to factorize the input and output layers, and whether to model words, characters or sub-word units.  We perform a systematic comparison of popular choices for a self-attentional architecture. Our experiments show that models equipped with adaptive embeddings are more than twice as fast to train than the popular character input CNN while having a lower number of parameters. On the \wiki{} benchmark we achieve 18.7 perplexity, an improvement of 10.5 perplexity compared to the previously best published result and on the \gbw{} benchmark, we achieve 23.02 perplexity.\footnote{Code and pre-trained models available at \url{http://github.com/pytorch/fairseq}} 
  Recursive neural networks have widely been used by researchers to handle applications with recursively or hierarchically structured data. However, embedded control flow deep learning frameworks such as TensorFlow, Theano, Caffe2, and MXNet fail to efficiently represent and execute such neural networks, due to lack of support for recursion. In this paper, we add recursion to the programming model of existing frameworks by complementing their design with recursive execution of dataflow graphs as well as additional APIs for recursive definitions. Unlike iterative implementations, which can only understand the topological index of each node in recursive data structures, our recursive implementation is able to exploit the recursive relationships between nodes for efficient execution based on parallel computation. We present an implementation on TensorFlow and evaluation results with various recursive neural network models, showing that our recursive implementation not only conveys the recursive nature of recursive neural networks better than other implementations, but also uses given resources more effectively to reduce training and inference time.  
   In the sentence classification task, context formed from sentences   adjacent to the sentence being classified can provide important   information for classification. This context is, however, often   ignored. Where methods do make use of context, only small amounts are   considered, making it difficult to scale. We present a   new method for sentence classification, Context-LSTM-CNN, that makes use of   potentially large contexts. The method also utilizes long-range dependencies   within the sentence being classified, using an LSTM, and short-span features, using a stacked   CNN.  Our experiments demonstrate that this approach consistently improves   over previous methods on two different datasets. 
 Recent advances in deep learning have brought to the fore models that can make multiple computational steps in the service of completing a task; these are capable of describing long-term dependencies in sequential data. Novel recurrent attention models over possibly large external memory modules constitute the core mechanisms that enable these capabilities. Our work addresses learning subtler and more complex underlying temporal dynamics in language modeling tasks that deal with sparse sequential data. To this end, we improve upon these recent advances, by adopting concepts from the field of Bayesian statistics, namely variational inference. Our proposed approach consists in treating the network parameters as latent variables with a prior distribution imposed over them. Our statistical assumptions go beyond the standard practice of postulating Gaussian priors. Indeed, to allow for handling outliers, which are prevalent in long observed sequences of multivariate data, multivariate $t$-exponential distributions are imposed. On this basis, we proceed to infer corresponding posteriors; these can be used for inference and prediction at test time, in a way that accounts for the uncertainty in the available sparse training data. Specifically, to allow for our approach to best exploit the merits of the $t$-exponential family, our method considers a new $t$-divergence measure, which generalizes the concept of the Kullback-Leibler divergence. We perform an extensive experimental evaluation of our approach, using challenging language modeling benchmarks, and illustrate its superiority over existing state-of-the-art techniques. 
 With online calendar services gaining popularity worldwide, calendar data has become one of the richest context sources for understanding human behavior. However, event scheduling is still time-consuming even with the development of online calendars. Although machine learning based event scheduling models have automated scheduling processes to some extent, they often fail to understand subtle user preferences and complex calendar contexts with event titles written in natural language. In this paper, we propose Neural Event Scheduling Assistant  which learns user preferences and understands calendar contexts, directly from raw online calendars for fully automated and highly effective event scheduling. We leverage over 593K calendar events for NESA to learn scheduling personal events, and we further utilize NESA for multi-attendee event scheduling. NESA successfully incorporates deep neural networks such as Bidirectional Long Short-Term Memory, Convolutional Neural Network, and Highway Network for learning the preferences of each user and understanding calendar context based on natural languages. The experimental results show that NESA significantly outperforms previous baseline models in terms of various evaluation metrics on both personal and multi-attendee event scheduling tasks. Our qualitative analysis demonstrates the effectiveness of each layer in NESA and learned user preferences. % * <susanniekim@gmail.com> 2018-05-21T14:50:44.842Z: %  % >  have automated scheduling processes % can automatically schedule events? %  % ^ <dweller92@naver.com> 2018-05-22T13:41:22.389Z: %  % I prefer as it is. % % ^ <dweller92@naver.com> 2018-05-22T14:34:49.312Z. % * <susanniekim@gmail.com> 2018-05-18T15:45:15.527Z: %  % >  contexts based on natural languages. % how can context be based on nat lang?  uc  %  % ^ <krth32@gmail.com> 2018-05-20T05:59:17.332Z: %  % contexts have event titles written in natural languages. How about "contexts based on natural languages in those event titles"? %  % ^ <susanniekim@gmail.com> 2018-05-21T14:47:00.014Z: %  % check now please  % but is it contexts or events with titles? or data?  %  % ^ <dweller92@naver.com> 2018-05-22T13:42:55.633Z: %  % contexts are made up of events, and events contain event titles, and the titles contain natural language.  Current version is fine. % % ^ <dweller92@naver.com> 2018-05-22T14:35:12.994Z. % * <susanniekim@gmail.com> 2018-05-18T15:36:30.563Z: %  % > learn scheduling personal events % uc to schedule per events? %  % ^ <krth32@gmail.com> 2018-05-20T06:05:00.115Z: %  % "personal" is intended for first-person perspective, and the attendee is alone. Would "private" or "individual" be better instead of "personal"? %  % ^ <susanniekim@gmail.com> 2018-05-21T14:54:54.681Z: %  % personal wasn't the issue.  % it's 'learn sched.' that is uc do you mean we train NESA on 593K events? %   % % ^ <dweller92@naver.com> 2018-05-22T13:44:17.794Z: %  % yes, we use 593K events to make NESA learn to schedule personal events. added 'for NESA' %  % ^ <susanniekim@gmail.com> 2018-05-22T17:47:29.050Z: %  % do you mean  NESA  trains  on 593K events to learn how to sched? % % ^ <krth32@gmail.com> 2018-05-23T02:52:13.138Z: %  % in an academical term, "learning" consists of training, validation, and testing % % ^. 
  Medical image analysis practitioners have embraced big data methodologies. This has created a need for large annotated datasets. The source of big data is typically large image collections and clinical reports recorded for these images. In many cases, however, building algorithms aimed at segmentation and detection of disease requires a training dataset with markings of the areas of interest on the image that match with the described anomalies. This process of annotation is expensive and needs the involvement of clinicians. In this work we propose two separate deep neural network architectures for automatic marking of a region of interest  on the image best representing a finding location, given a textual report or a set of keywords. One architecture consists of LSTM and CNN components and is trained end to end with images, matching text, and markings of ROIs for those images. The output layer estimates the coordinates of the vertices of a polygonal region. The second architecture uses a network pre-trained on a large dataset of the same image types for learning feature representations of the findings of interest. We show that for a variety of findings from chest X-ray images, both proposed architectures learn to estimate the ROI, as validated by clinical annotations. There is a clear advantage obtained from the architecture with pre-trained imaging network. The centroids of the ROIs marked by this network were on average at a distance equivalent to 5.1\% of the image width from the centroids of the ground truth ROIs.   
 We explore several new models for document relevance ranking,  building upon the Deep Relevance Matching Model  of . Unlike \drmm, which uses   context-insensitive encodings of terms and query-document term interactions, we inject rich context-sensitive encodings throughout our models, inspired by \pacrr's  convolutional $n$-gram matching features, but extended in several ways including  multiple views of query and document inputs.  We test our models on datasets from the  and \trecrob 2004 , showing they outperform \bmtf-based baselines, \drmm, and \pacrr.\\ 
 Visual dialog entails answering a series of questions grounded in an image,  using dialog history as context. In addition to the challenges found in visual question answering , which can be seen as one-round dialog, visual dialog encompasses several more. We focus on one such problem called visual coreference resolution that involves determining which words, typically noun phrases and pronouns,  co-refer to the same entity/object instance in an image. This is crucial, especially for pronouns , as the dialog agent must first link it to a previous coreference , and only then can rely on the visual grounding of the coreference `boat' to reason about the pronoun `it'. Prior work  models visual coreference resolution either  implicitly via a memory network over history, or   at a coarse level for the entire question; and not explicitly at a phrase level of granularity. In this work, we propose a neural module network architecture for visual dialog by introducing two novel modules---Refer and Exclude---that perform explicit, grounded, coreference resolution at a finer word level. We demonstrate the effectiveness of our model on MNIST Dialog, a visually  simple yet coreference-wise complex dataset, by achieving near perfect accuracy, and on VisDial, a large and challenging visual dialog dataset on real images, where our model  outperforms other approaches, and is more interpretable, grounded, and  consistent qualitatively. 
  There are three modalities in the reading comprehension setting: question, answer and context. The task of question answering or question generation aims to infer an answer or a question when given the counterpart based on context. We present a novel two-way neural sequence transduction model that connects three modalities, allowing it to learn two tasks simultaneously and mutually benefit one another. During training, the model receives question-context-answer triplets as input and captures the cross-modal interaction via a hierarchical attention process. Unlike previous joint learning paradigms that leverage the duality of question generation and question answering at data level, we solve such dual tasks at the architecture level by mirroring the network structure and partially sharing  components at different layers. This enables the knowledge to be transferred from one task to another, helping the model to find a general representation for each modality. The evaluation on four public datasets shows that our dual-learning model outperforms the mono-learning counterpart as well as the state-of-the-art joint models on both question answering and question generation tasks. % our model receives question-context-answer triplets as input and captures the cross-modal interaction via a hierarchical attention process.  %  We consider question generation and question answering as two strongly correlated tasks and equally important to the reading comprehension ability. To exploit the duality of two tasks,   % Previous machine reading models focus on filling the answer modality by modeling the question-context interaction.  
  Relational database management systems  are powerful because they are able to optimize and answer queries against any relational database. A natural language interface  for a database, on the other hand, is tailored to support that specific database. In this work, we introduce a general purpose transfer-learnable NLI with the goal of learning one model that can be used as NLI for any relational database. We adopt the data management principle of separating data and its schema, but with the additional support for the idiosyncrasy and complexity of natural languages. Specifically, we introduce an automatic annotation mechanism that separates the schema and the data, where the schema also covers knowledge about natural language. Furthermore, we propose a customized sequence model that translates annotated natural language queries to SQL statements. We show in experiments that our approach outperforms previous NLI methods on the WikiSQL dataset and the model we learned can be applied to another benchmark dataset OVERNIGHT without retraining.  %However, state-of-the-art natural language interfaces  for databases are often tailored to support specific datasets and applications.  % In this work, we introduce a general purpose transfer-learnable NLI.  % First, we adopt the data management principle of separating data and its schema, so that our model only relies on the schema and the statistics of the data instead of the % data itself when translating natural language statements to SQL queries. % Furthermore, given a database with entities or properties that the model has not seen before, we expand the schema of the database to include a Transfer Descriptor  that describes how people talk about such entities and their properties.  % We show that our general purpose NLI is able to achieve high accuracy for databases across multiple domains.  
 Encoder-decoder models for unsupervised sentence representation learning using the distributional hypothesis effectively constrain the learnt representation of a sentence to only that needed to reproduce the next sentence. While the decoder is important to constrain the representation, these models tend to discard the decoder after training since only the encoder is needed to map the input sentence into a vector representation. However, parameters learnt in the decoder also contain useful information about the language. In order to utilise the decoder after learning, we present two types of decoding functions whose inverse can be easily derived without expensive inverse calculation. Therefore, the inverse of the decoding function serves as another encoder that produces sentence representations. We show that, with careful design of the decoding functions, the model learns good sentence representations, and the ensemble of the representations produced from the encoder and the inverse of the decoder demonstrate even better generalisation ability and solid transferability. 
 		This paper analyzes the behavior of stack-augmented recurrent neural network  models. Due to the architectural similarity between stack RNNs and pushdown transducers, we train stack RNN models on a number of tasks, including string reversal, context-free language modelling, and cumulative XOR evaluation. Examining the behavior of our networks, we show that stack-augmented RNNs can discover intuitive stack-based strategies for solving our tasks. However, stack RNNs are more difficult to train than classical architectures such as LSTMs. Rather than employ stack-based strategies, more complex networks often find approximate solutions by using the stack as unstructured memory.  	
 Research on link prediction in knowledge graphs has mainly focused on static multi-relational data. In this work we consider temporal knowledge graphs where relations between entities may only hold for a time interval or a specific point in time. In line with previous work on static knowledge graphs, we propose to address this problem by learning latent entity and relation type representations. To incorporate temporal information, we utilize recurrent neural networks to learn time-aware representations of relation types which can be used in conjunction with existing latent factorization methods. The proposed approach is shown to be robust to common challenges in real-world KGs: the sparsity and heterogeneity of temporal expressions. Experiments show the benefits of our approach on four temporal KGs. The data sets are available under a permissive BSD-3 license\footnote{https://github.com/nle-ml/mmkb}. %We show the benefits of learning time-aware representations in \transE and \distM in three temporal KGs. 
 We propose a novel Wasserstein method with a distillation mechanism, yielding joint learning of word embeddings and topics.  The proposed method is based on the fact that the Euclidean distance between word embeddings may be employed as the underlying distance in the Wasserstein topic model.  The word distributions of topics, their optimal transports to the word distributions of documents, and the embeddings of words are learned in a unified framework.  When learning the topic model, we leverage a distilled underlying distance matrix to update the topic distributions and smoothly calculate the corresponding optimal transports.  Such a strategy provides the updating of word embeddings with robust guidance, improving the  algorithmic convergence.  As an application, we focus on patient admission records, in which the proposed method embeds the codes of diseases and procedures and learns the topics of admissions, obtaining superior performance on clinically-meaningful disease network construction, mortality prediction as a function of admission codes, and procedure recommendation. 
 Machine understanding of questions is tightly related to recognition of articulation in the context of the computational capabilities of an underlying processing algorithm. In this paper a mathematical model to capture and distinguish the latent structure in the articulation of questions is presented. We propose an objective-driven approach to represent this latent structure and show that such an approach is beneficial when examples of complementary objectives are not available. We show that the latent structure can be represented as a system that maximizes a cost function related to the underlying objective. Further, we show that the optimization formulation can be approximated to building a memory of patterns represented as a trained neural auto-encoder. Experimental evaluation using many clusters of questions, each related to an objective, shows 80\% recognition accuracy and negligible false positive across these clusters of questions. We then extend the same memory to a related task where the goal is to iteratively refine a dataset of questions based on the latent articulation. We also demonstrate a refinement scheme called $K$-fingerprints, that achieves nearly 100\% recognition with negligible false positive across the different clusters of questions.  
 We propose a triad-based neural network system that generates affinity scores between entity mentions for coreference resolution. The system simultaneously accepts three mentions as input, taking mutual dependency and logical constraints of all three mentions into account, and thus makes more accurate predictions than the traditional pairwise approach. Depending on system choices, the affinity scores can be further used in clustering or mention ranking. Our experiments show that a standard hierarchical clustering using the scores produces state-of-art results with gold mentions on the English portion of CoNLL 2012 Shared Task. The model does not rely on many handcrafted features and is easy to train and use. The triads can also be easily extended to polyads of higher orders. To our knowledge, this is the first neural network system to model mutual dependency of more than two members at mention level.      %  We propose a triad-based neural network system to generate affinity scores between entity mentions used in coreference resolution. The system simultaneously accepts three mentions as input, taking mutual dependency and logical constraints of all three mentions into account, and thus makes more accurate predictions than the traditional pairwise approach. In order to perform coreference resolution, the affinity scores can be further used in clustering or mention ranking, depending on the choice of system. Our experiments show a standard hierarchical clustering using the scores already produces state-of-art results with { metrics on the English portion of CoNLL 2012 Shared Task. The model does not rely on many handcrafted features and is easy to train and use. If needed, the triads can extend to polyads of higher orders too. To our knowledge, it is the first neural network system to model mutual dependency of more than two members at mention level. 
 Learning visual feature representations for video analysis is a daunting task that requires a large amount of training samples and a proper generalization framework. Many of the current state of the art methods for video captioning and movie description rely on simple encoding mechanisms through recurrent neural networks to encode temporal visual information extracted from video data. In this paper, we introduce a novel multitask encoder-decoder framework for automatic semantic description and captioning of video sequences. In contrast to current approaches, our method relies on distinct decoders that train a visual encoder in a multitask fashion. Our system does not depend solely on multiple labels and allows for a lack of training data working even with datasets where only one single annotation is viable per video. Our method shows improved performance over current state of the art methods in several metrics on multi-caption and single-caption datasets. To the best of our knowledge, our method is the first method to use a multi-task approach for encoding video features. Our method demonstrates its robustness on the Large Scale Movie Description Challenge  2017 where our method won the movie description task and its results were ranked among other competitors as the most helpful for the visually impaired.   
 Despite recent progress in computer vision, fine-grained interpretation of satellite images remains challenging because of a lack of labeled training data. %, especially in the developing world.  To overcome this limitation, we propose using Wikipedia as a previously untapped source of rich, georeferenced textual information with global coverage. % We construct a novel large-scale, multi-modal dataset by pairing geo-referenced Wikipedia articles with satellite imagery of their corresponding locations. To prove the efficacy of this dataset, we focus on the African continent and train a deep network to classify images based on labels extracted from articles. We then fine-tune the model on a human-annotated dataset and demonstrate that this weak form of supervision %enables the network to learn useful representations which  can drastically reduce the quantity of human-annotated labels and time required for downstream tasks.  %We believe that this novel combination of crowdsourced annotations from Wikipedia and satellite images will enable new advances and have the potential to complement other open data sources such as OSM to learn textual and temporal representation. % %State-of-the-art deep learning models need large-scale high quality datasets to deliver high accuracy. On the other hand, building large-scale datasets are both time-consuming and costly. In this direction, weakly supervised and unsupervised learning have become an attractive research domain to reduce the need to collect large-scale high quality dataset. In a recent work,  performs large-scale pre-training on Instagram images labeled with user hashtags. Pre-training on such low quality large-scale dataset boosts the ImageNet top-1 classification performance by $5\%$. Inspired by this work, we explore training a deep learning model on a large-scale satellite dataset labeled by Wikipedia articles. At the second phase, we then quantify the learned representations on a high quality human labeled dataset. This way, the amount of high quality data required to achieve reasonable accuracy on high quality dataset is reduced, thanks to large-scale pre-training on a dataset with Wikipedia labels. Also, to the best of our knowledge, this is the first time Wikipedia is explored to perform learning on satellite images. We believe that it can be highly useful to complement OSM data source in terms of learning textual and temporal features in an area. 
 This paper studies the consistency of the kernel-based neural ranking model , a recent state-of-the-art neural IR model, which  is important for reproducible research and deployment in the industry.  We find that K-NRM has low variance on relevance-based metrics across experimental trials.  In spite of this low variance in overall performance, different trials produce different document rankings for individual queries. The main source of variance in our experiments was found to be different latent matching patterns captured by K-NRM. In the IR-customized word embeddings learned by K-NRM, the query-document word pairs follow two different matching patterns that are equally effective, but align word pairs differently in the embedding space. The different latent matching patterns enable a simple yet effective approach to construct ensemble rankers, which improve K-NRM's effectiveness and generalization abilities. 
 Cross-situational word learning, wherein a learner combines information about possible meanings of a word across multiple exposures, has previously been shown to be a very powerful strategy to acquire a large lexicon in a short time. However, this success may derive from idealizations that are made when modeling the word-learning process. In particular, an earlier model assumed that a learner could perfectly recall all previous instances of a word's use and the inferences that were drawn about its meaning. In this work, we relax this assumption and determine the performance of a model cross-situational learner who forgets word-meaning associations over time. Our main finding is that it is possible for this learner to acquire a human-scale lexicon by adulthood with word-exposure and memory-decay rates that are consistent with empirical research on childhood word learning, as long as the degree of referential uncertainty is not too high or the learner employs a mutual exclusivity constraint. Our findings therefore suggest that successful word learning does not necessarily demand either highly accurate long-term tracking of word and meaning statistics or hypothesis-testing strategies. 
 We propose Neural Entity Reasoner , a framework to introduce global consistency of recognized entities into Neural Reasoner over Named Entity Recognition  task. Given an input sentence, the NE-Reasoner layer can infer over multiple entities to increase the global consistency of output labels, which then be transfered into entities for the input of next layer.  NE-Reasoner inherits and develops some features from Neural Reasoner 1) a symbolic memory, allowing it to exchange entities between layers. 2) the specific interaction-pooling mechanism, allowing it to connect each local word to multiple global entities, and 3) the deep architecture, allowing it to bootstrap the recognized entity set from coarse to fine. Like human beings, NE-Reasoner is able to accommodate ambiguous words and Name Entities that rarely or never met before. Despite the symbolic information the model introduced, NE-Reasoner can still be trained effectively in an end-to-end manner via parameter sharing strategy. NE-Reasoner can outperform conventional NER models in most cases on both English and Chinese NER datasets.  For example, it achieves state-of-art on CoNLL-2003 English NER dataset.   %to the entity missing is a general problem, especially when the model reads a context pattern or a word that not appears too much in training dataset.  But there is a relationship among the output results of different position words within a document, such as when an entity appears multiple times, all the results should be consistent.  However, most of current methods rely on global memory which saved in the parameters of model, but can not remember whether a word used to be an entity in other place of the same document.  
  We built models with Logistic Regression and linear Support Vector Machines on  a large dataset consisting of regular news articles and news from satirical websites, and showed that such linear classifiers on a corpus with about 60,000 articles can perform with a precision of 98.7\%  and a recall of 95.2\% on a random test set  of the news.    On the other hand, when testing the classifier on ``publication sources'' which are completely unknown during training, only an accuracy of 88.2\% and an F1-score of 76.3\% are achieved.  As another result, we showed that the same algorithm can distinguish between news written by the news agency itself and paid articles from customers. Here the results had an accuracy of 99\%. 
   This document contains the instructions for preparing a camera-ready   manuscript for the proceedings of ACL 2018. The document itself   conforms to its own specifications, and is therefore an example of   what your manuscript should look like. These instructions should be   used for both papers submitted for review and for final versions of   accepted papers.  Authors are asked to conform to all the directions   reported in this document. 
 Despite deep recurrent neural networks  demonstrate strong performance in text classification, training RNN models are often expensive and requires an extensive collection of annotated data which may not be available. To overcome the data limitation issue, existing approaches leverage either pre-trained word embedding or sentence representation to lift the burden of training RNNs from scratch. In this paper, we show that jointly learning sentence representations from multiple text classification tasks and combining them with pre-trained word-level and sentence level encoders result in robust sentence representations that are useful for transfer learning. Extensive experiments and analyses using a wide range of transfer and linguistic tasks endorse the effectiveness of our approach. % \NoteKW{Do you still of auxiliary tasks?} % Extensive experiments and quantitative analysis using transfer and auxiliary tasks validate the proposed approach.  
 Despite many recent advances for the design of dialogue systems, a true bottleneck remains the acquisition of data required to train its components. Unlike many other language processing applications, dialogue systems require interactions with users, therefore it is complex to develop them with pre-recorded data. Building on previous works, on-line learning is pursued here as a most convenient way to address the issue. Data collection, annotation and use in learning algorithms are performed in a single process. The main difficulties are then: to bootstrap an initial basic system, and to control the level of additional cost on the user side. Considering that well-performing solutions can be used directly off the shelf for speech recognition and synthesis, the study is focused on learning the spoken language understanding and dialogue management modules only. Several variants of joint learning are investigated and tested with user trials to confirm that the overall on-line learning can be obtained after only a few hundred training dialogues and can overstep an expert-based system. 
 Enormous online textual information provides intriguing opportunities for understandings of social and economic semantics. In this paper, we propose a novel text regression model based on a conditional generative adversarial network , with an attempt to associate textual data and social outcomes in a semi-supervised manner. Besides promising potential of predicting capabilities, our superiorities are twofold:  the model works with unbalanced datasets of limited labelled data, which align with real-world scenarios; and  predictions are obtained by an end-to-end framework, without explicitly selecting high-level representations. Finally we point out related datasets for experiments and future research directions. 
   This paper presents an extensive comparative study of four neural   network models, including feed-forward networks, convolutional   networks, recurrent networks and long short-term memory networks, on   two sentence classification datasets of English and Vietnamese   text. We show that on the English dataset, the convolutional network   models without any feature engineering outperform some competitive   sentence classifiers with rich hand-crafted linguistic features. We   demonstrate that the GloVe word embeddings are consistently better than   both Skip-gram word embeddings and word count vectors. We also show the   superiority of convolutional neural network models on a Vietnamese   newspaper sentence dataset over strong baseline models. Our   experimental results suggest some good practices for applying neural   network models in sentence classification. 
 It is common that entity mentions can contain other mentions recursively. This paper introduces a scalable transition-based method to model the nested structure of mentions. We first map a sentence with nested mentions to a designated forest where each mention corresponds to a constituent of the forest. Our shift-reduce based system then learns to construct the forest structure in a bottom-up manner through an action sequence whose maximal length is guaranteed to be  three times of the sentence length. Based on Stack-LSTM which is employed to efficiently and effectively represent the states of the system in a continuous space, our system is further incorporated with a character-based component to capture letter-level patterns. Our model achieves the state-of-the-art results on ACE datasets, showing its effectiveness in detecting nested mentions.\footnote{We make our implementation available at \url{https://github.com/berlino/nest-trans-em18}.}  % Empirical results on three standard datasets show that our model achieves significant improvements compared with the state-of-the-art approaches 
 This study proposes a novel way of identifying the sentiment of the phrases used in the legal domain. The added complexity of the language used in law, and the inability of the existing systems to accurately predict the sentiments of words in law are the main motivations behind this study. This is a transfer learning approach, which can be used for other domain adaptation tasks as well. The proposed methodology achieves an improvement of over 6\% compared to the source model's accuracy in the legal domain. 
 Negation scope has been annotated in several English and Chinese corpora, and highly accurate models for this task in these languages have been learned from these annotations. Unfortunately, annotations are not available in other languages. Could a model that detects negation scope be applied to a language that it hasn閳ユ獩 been trained on? We develop neural models that learn from cross-lingual word embeddings or universal dependencies in English, and test them on Chinese, showing that they work surprisingly well. We find that modeling syntax is helpful even in monolingual settings and that cross-lingual word embeddings help relatively little, and we analyze cases that are still difficult for this task. 
   English. This paper reports on a set of experiments with different word embeddings to initialize a state-of-the-art Bi-LSTM-CRF network for event detection and classification in Italian, following the EVENTI evaluation exercise. The network obtains a new state-of-the-art result by improving the F1 score for detection of 1.3 points, and of 6.5 points for classification, by using a single step approach. The results also provide further evidence that embeddings have a major impact on the performance of such architectures. 
 This paper demonstrates that word sense disambiguation  can improve neural machine translation  by widening the source context considered when modeling the senses of potentially ambiguous words.  We first introduce three adaptive clustering algorithms for WSD, based on $k$-means, Chinese restaurant processes, and random walks, which are then applied to large word contexts represented in a low-rank space and evaluated on SemEval shared-task data.  We then learn word vectors jointly with sense vectors defined by our best WSD method, within a state-of-the-art NMT system.  We show that the concatenation of these vectors, and the use of a sense selection mechanism based on the weighted average of sense vectors, outperforms several baselines including sense-aware ones.  This is demonstrated by translation on five language pairs.  The improvements are above one BLEU point over strong NMT baselines, +4\% accuracy over all ambiguous nouns and verbs, or +20\% when scored manually over several challenging words. 
 Auto-encoders compress input data into a latent-space representation and reconstruct the original data from the representation.  This latent representation is not easily interpreted by humans. In this paper, we propose training an auto-encoder that encodes input text into human-readable sentences, and unpaired abstractive summarization is thereby achieved. The auto-encoder is composed of a generator and a reconstructor. The generator encodes the input text into a shorter word sequence, and the reconstructor recovers the generator input from the generator output. To make the generator output human-readable, a discriminator restricts the output of the generator to resemble human-written sentences. By taking the generator output as the summary of the input text, abstractive summarization is achieved without document-summary pairs as training data. Promising results are shown on both English and Chinese corpora. 
 Learning a matching function between two text sequences is a long standing problem in NLP research. This task enables many potential applications such as question answering and paraphrase identification. This paper proposes Co-Stack Residual Affinity Networks , a new and universal neural architecture for this problem. CSRAN is a deep architecture, involving stacked  recurrent encoders. Stacked/Deep architectures are traditionally difficult to train, due to the inherent weaknesses such as difficulty with feature propagation and vanishing gradients. CSRAN incorporates two novel components to take advantage of the stacked architecture. Firstly, it introduces a new bidirectional alignment mechanism that learns affinity weights by fusing sequence pairs across stacked hierarchies. Secondly, it leverages a multi-level attention refinement component between stacked recurrent layers. The key intuition is that, by leveraging information across all network hierarchies, we can not only improve gradient flow but also improve overall performance. We conduct extensive experiments on six well-studied text sequence matching datasets, achieving state-of-the-art performance on all. 
 Previous traditional approaches to unsupervised Chinese word segmentation  can be roughly classified into discriminative and generative models. The former uses the carefully designed goodness measures for candidate segmentation, while the latter focuses on finding the optimal segmentation of the highest generative probability. However, while there exists a trivial way to extend the discriminative models into neural version by using neural language models, those of generative ones are non-trivial. In this paper, we propose the segmental language models  for CWS. Our approach explicitly focuses on the segmental nature of Chinese, as well as preserves several properties of language models. In SLMs, a context encoder encodes the previous context and a segment decoder generates each segment incrementally. As far as we know, we are the first to propose a neural model for unsupervised CWS and achieve competitive performance to the state-of-the-art statistical models on four different datasets from SIGHAN 2005 bakeoff. 
 	The task of event detection involves identifying and categorizing event triggers. 	Contextual information has been shown effective on the task. 	However, existing methods which utilize contextual information only process the context once. We argue that the context can be better exploited by processing the context multiple times, allowing the model to perform complex reasoning and to generate better context representation, 	thus improving the overall performance. 	Meanwhile, dynamic memory network  has demonstrated promising capability in capturing contextual 	information and has been applied successfully to various tasks. 	In light of the multi-hop mechanism of the DMN to model the context, we propose the trigger detection dynamic memory network  	to tackle the event detection problem. We performed a five-fold cross-validation on the ACE-2005 dataset and experimental results show that the multi-hop mechanism does improve the performance and the proposed model achieves best $F_1$ score compared to the state-of-the-art methods. 
 We explore active learning~ for improving the accuracy of new domains in a natural language understanding~ system. We propose an algorithm called Majority-CRF that uses an ensemble of classification models to guide the selection of relevant utterances, as well as a sequence labeling model to help prioritize informative examples. Experiments with three domains show that Majority-CRF achieves 6.6\%-9\% relative error rate reduction compared to random sampling with the same annotation budget, and statistically significant improvements compared to other AL approaches. Additionally, case studies with human-in-the-loop AL on six new domains show 4.6\%-9\% improvement on an existing NLU system. 
  This work investigates an alternative model for neural machine translation  and proposes a novel architecture, where we employ a multi-dimensional long short-term memory  for translation modeling. In the \mbox{state-of-the-art} methods, source and target sentences are treated as one-dimensional sequences over time, while we view translation as a two-dimensional  mapping using an \mbox{MDLSTM} layer to define the correspondence between source and target words. We extend beyond the current sequence to sequence backbone NMT models to a 2D structure in which the source and target sentences are aligned with each other in a 2D grid. Our proposed topology shows consistent improvements over attention-based sequence to sequence model on two WMT 2017 tasks, German$\leftrightarrow$English. 
 Morphological declension, which aims to inflect nouns to indicate number, case and gender, is an important task in natural language processing . This research proposal seeks to address the degree to which Recurrent Neural Networks  are efficient in learning to decline noun cases. Given the challenge of data sparsity in processing morphologically rich languages and also, the flexibility of sentence structures in such languages, we believe that modeling morphological dependencies can improve the performance of neural network models. It is suggested to carry out various experiments to understand the interpretable features that may lead to a better generalization of the learned models on cross-lingual tasks.    % have been successfully applied to various tasks in natural language processing.   %Given the challenge of RNNs in learning non-sequential data and its reliance on annotated resources for supervised learning, modifying current networks or designing new models for capturing morphological structure is proposed.   
 This paper presents a neural network classifier approach to  detecting both within- and cross-document event coreference effectively using only event mention based features. Our approach does not  rely on any event argument features such as semantic roles or spatiotemporal arguments.  Experimental results on the ECB+ dataset show that our approach produces $F_1$ scores  that significantly outperform the state-of-the-art methods for both within-document  and cross-document event coreference resolution when we use $B^3$ and $CEAF_e$ evaluation measures, but  gets  worse $F_1$ score with the $MUC$ measure. However, when we use the $CoNLL$ measure, which is the average of these three scores, our approach has slightly  better $F_1$ for within-document event coreference resolution but is  significantly better for cross-document event coreference resolution.   
       Text simplification  can be viewed as monolingual translation task, translating between text variations within a single language. Recent neural TS models draw on insights from neural machine translation to learn lexical simplification and content reduction using encoder-decoder model. But different from neural machine translation, we cannot obtain enough ordinary and simplified sentence pairs for TS, which are expensive and time-consuming to build. Target-side simplified sentences plays an important role in boosting fluency for statistical TS, and we investigate the use of simplified sentences to train, with no changes to the network architecture. We propose to pair simple training sentence with a synthetic ordinary sentence via back-translation, and treating this synthetic data as additional training data. We train encoder-decoder model using synthetic sentence pairs and original sentence pairs, which can obtain substantial improvements on the available WikiLarge data and WikiSmall data compared with the state-of-the-art methods.   
  Past work in relation extraction mostly focuses on binary relation between entity pairs . Recently, the NLP community has gained interest in relation extraction in entity pairs .  In this paper, we propose a novel architecture for this task: inter-sentential dependency-based neural networks . iDepNN models the shortest and augmented dependency paths via recurrent and recursive neural networks to extract relationships within  and across  sentence boundaries.  Compared to SVM and neural network baselines, iDepNN is more robust to false positives in relationships spanning sentences.  We evaluate our models on four datasets from newswire  and medical  domains that achieve state-of-the-art performance and show a better balance in precision and recall for inter-sentential relationships.  We perform better than 11 teams participating in  % We rank at the top out of 11 teams participated in  the BioNLP shared task 2016  and achieve a gain of $5.2$\%  in $F_1$ over the winning team.   We also release the cross-sentence annotations for MUC6. 
 Sentence splitting is a major simplification operator. Here we present a simple and efficient splitting algorithm based on an automatic semantic parser. After splitting, the text is amenable for further fine-tuned simplification operations. In particular, we show that neural Machine Translation can be effectively used in this situation. Previous application of Machine Translation for simplification suffers from a considerable disadvantage in that they are over-conservative, often failing to modify the source in any way. Splitting based on semantic parsing, as proposed here, alleviates this issue.  Extensive automatic and human evaluation shows that the proposed method compares favorably to the state-of-the-art in combined lexical and structural simplification.  
  Most existing studies in text-to-SQL tasks do not require generating complex SQL queries with multiple clauses or sub-queries, and generalizing to new, unseen databases. In this paper we propose SyntaxSQLNet, a syntax tree network to address the complex and cross-domain text-to-SQL generation task. SyntaxSQLNet employs a SQL specific syntax tree-based decoder with SQL generation path history and table-aware column attention encoders. We evaluate SyntaxSQLNet on the Spider text-to-SQL task, which contains databases with multiple tables and complex SQL queries with multiple SQL clauses and nested queries. We use a database split setting where databases in the test set are unseen during training. Experimental results show that SyntaxSQLNet can handle a significantly greater number of complex SQL examples than prior work, outperforming the previous state-of-the-art model by 7.3\% in exact matching accuracy. We also show that SyntaxSQLNet can further improve the performance by an additional 7.5\% using a cross-domain augmentation method, resulting in a 14.8\% improvement in total. To our knowledge, we are the first to study this complex and cross-domain text-to-SQL task.\footnote{Code available at {https://github.com/taoyds/syntaxsql}} %\url{https://github.com/taoyds/syntaxsql}  %This work thus marks an important milestone for developing expressive and generalized text-to-SQL models.  % They fail to parse the meaning of sentences and generalize to unseen programs and datasets. % \textcolor{red}{change the following? Focus on methodology}  % Using a dataset with complex ,,,  % One of the biggest problems in this research area is the lack of a large corpus that contains a large amount of different programs and datasets because both collecting datasets and labelling programs are extremely time-consuming and require certain knowledge backgrounds. To address such issues, we introduce a large semantic parsing and text-to-SQL corpus including about 200 databases and more than 10,000 human labeled complex SQL queries to the research community. Further, we define a more realistic semantic parsing/text-to-SQL task based on this new dataset. We experiment with various current state-of-art models, and show the task present a strong challenge for future research. they aren閳ユ獩 creating datasets that can be solved without any understanding. 
 Abstractive summarization has been studied using neural sequence transduction methods with datasets of large, paired document-summary examples. However, such datasets are rare and the models trained from them do not generalize to other domains. Recently, some progress has been made in learning sequence-to-sequence mappings with only unpaired examples.  In our work, we consider the setting where there are only documents  with no summaries provided, and propose an end-to-end, neural model architecture to perform unsupervised abstractive summarization. Our proposed model consists of an auto-encoder where the mean of the representations of the input reviews decodes to a reasonable summary-review while not relying on any review-specific features. We consider variants of the proposed architecture and perform an ablation study to show the importance of specific components.  We show through automated metrics and human evaluation that the generated summaries are highly abstractive, fluent, relevant, and representative of the average sentiment of the input reviews. Finally, we collect a reference evaluation dataset and show that our model outperforms a strong extractive baseline. 
 The current success of deep neural networks  in an increasingly broad range of tasks involving artificial intelligence strongly depends on the quality and quantity of labeled training data. In general, the scarcity of labeled data, which is often observed in many natural language processing tasks, is one of the most important issues to be addressed. Semi-supervised learning  is a promising approach to overcoming this issue by incorporating a large amount of unlabeled data. In this paper, we propose a novel scalable method of SSL for text classification tasks. The unique property of our method, Mixture of Expert/Imitator Networks, is that imitator networks learn to ``imitate'' the estimated label distribution of the expert network over the unlabeled data, which potentially contributes a set of features for the classification. Our experiments demonstrate that the proposed method consistently improves the performance of several types of baseline DNNs. We also demonstrate that our method has the more data, better performance property with promising scalability to the amount of unlabeled data. 
 %Extractive models demonstrate a limitation when it comes to paraphrasing and grammaticality, leading to the need for abstractive summarization methods. Though previously considered a task too challenging,  %\fontsize{10}{12} Sequence-to-sequence  neural models have been actively investigated for abstractive summarization.  %Nevertheless, existing neural abstractive systems frequently generate redundant or factually incorrect summaries, suggesting a crucial lack of semantic understanding.  Nevertheless, existing neural abstractive systems frequently generate factually incorrect summaries and are vulnerable to adversarial information, suggesting a crucial lack of semantic understanding.  In this paper, we propose a novel semantic-aware neural abstractive summarization model that learns to generate high quality summaries through semantic interpretation over salient content.  A novel evaluation scheme with adversarial samples is introduced to measure how well a model identifies off-topic information, where our model yields significantly better performance than the popular pointer-generator summarizer. Human evaluation also confirms that our system summaries are uniformly more informative and faithful as well as less redundant than the seq2seq model. %and even ranked higher than human written abstracts for informativeness in 25\% of the evaluations.    %Evaluation on large-scale news corpora shows that our model yields significantly more abstractive summaries than the state-of-the-art pointer-generator summarizer with comparable or better ROUGE and METEOR scores. Our model is also significantly more adept at handling irrelevant information than the state-of-the-art.   % Sequence-to-sequence-based neural models have been widely investigated for abstractive text summarization. Nevertheless, existing neural abstractive systems frequently generate nonsensical or factually incorrect summaries, suggesting a crucial lack of semantic understanding.  % In this paper, we propose a novel semantic-aware neural abstractive summarization model that learns to generate high quality summaries through semantic interpretation over salient content. % %semantic interpretation over salient content as well as high quality summaries.  % Evaluation on large-scale news corpora shows that our model yields significantly more abstractive summaries than the state-of-the-art pointer-generator summarizer with comparable or better ROUGE and METEOR scores. Our model is also significantly more adept at handling irrelevant information than the state-of-the-art.   %The recent success of neural sequence-to-sequence models has led to a renewed interest in abstractive summarization. However, existing neural abstractive systems often generate unimportant or factually incorrect summaries, suggesting a crucial lack of semantic understanding. Furthermore, current abstractive summarization techniques still underperform extractive ones, and state-of-the-art hybrid extractive-abstractive systems learn to produce predominantly extractive summaries. In this paper, we propose a novel semantic-aware neural abstractive summarization model that learns semantic understanding explicitly through a multi-task learning framework. We also introduce a novel dual attention mechanism and a reranking based beam search decoder that aids in the reinforcement of semantic information. Our results on the NYT and CNN/Daily Mail corpus show that our model is able to maintain comparable results to the state-of-the-art while producing more abstractive summaries. 
 Pronouns are frequently omitted in pro-drop languages, such as Chinese, generally leading to significant challenges with respect to the production of complete translations. Recently,~ proposed a novel reconstruction-based approach to alleviating dropped pronoun  translation problems for neural machine translation models.  In this work, we improve the original model from two perspectives.  First, we employ a shared reconstructor to better exploit encoder and decoder representations. Second, we jointly learn to translate and predict DPs in an end-to-end manner, to avoid the errors propagated from an external DP prediction model. Experimental results show that our approach significantly improves both translation performance and DP prediction accuracy.   . In this paper, we further investigate to jointly translate and generate dropped pronouns with a shared reconstruction model. The shared reconstruction model  In order to alleviate error propagation, we integrate the DP position instead of DP word as the auxiliary information into NMT model. And then learn to recover DP word during reconstructing DP position and then jointly learn DP generation  and then ask NMT model to jointly learn DP generation. Experiments on Chinese--English dialogue translation task show that our model improve translation performance over the best reconstruction model, which demonstrate that our proposed models have remarkable ability to properly learn DP knowledge.  \fi 
  Neural Image Captioning  or neural caption generation has attracted a lot of attention over the last few years. Describing an image with a natural language has been an emerging challenge in both fields of computer vision and language processing. Therefore a lot of research has focused on driving this task forward with new creative ideas. So far, the goal has been to maximize scores on automated metric and to do so, one has to come up with a plurality of new modules and techniques. Once these add up, the models become complex and resource-hungry. In this paper, we take a small step backwards in order to study an architecture with interesting trade-off between performance and computational complexity. To do so, we tackle every component of a neural captioning model and propose one or more solution that lightens the model overall. Our ideas are inspired by two related tasks: Multimodal and Monomodal Neural Machine Translation. 
  Recent research efforts have shown that neural architectures can be effective in conventional information extraction tasks such as named entity recognition, yielding state-of-the-art results on standard newswire datasets. However, despite significant resources required for training such models, the performance of a  model trained on one domain typically degrades dramatically when applied to a different domain, yet extracting entities from new emerging domains such as social media can be of significant interest.  In this paper, we empirically investigate effective methods for conveniently adapting an existing, well-trained neural NER model for a new domain. Unlike existing approaches, we propose lightweight yet effective methods for performing domain adaptation for neural models. Specifically, we introduce adaptation layers on top of existing neural architectures, where no re-training using the source domain data is required. We conduct extensive empirical studies and show that our approach significantly outperforms state-of-the-art methods.\let\thefootnote\relax\footnote{Accepted as a long paper in EMNLP 2018 .}  
 	We address the problem of efficient acoustic-model refinement  using semi-supervised and active learning for a low resource Indian language, wherein the low resource constraints are having i) a small labeled corpus from which to train a baseline `seed' acoustic model, and ii) a large training corpus without orthographic labeling or from which to perform a data selection for manual labeling at low costs. The proposed semi-supervised learning decodes the unlabeled large training corpus using the seed model and through various protocols, selects the decoded utterances with high reliability using confidence levels  and iterative bootstrapping. The proposed active learning protocol uses confidence level based metric to select the decoded utterances from the large unlabeled corpus for further labeling. The semi-supervised learning protocols can offer a WER reduction, from a poorly trained seed model, by as much as 50\% of the best WER-reduction realizable from the seed model's WER, if the large corpus were labeled and used for acoustic-model training. The active learning protocols allow that only 60\% of the entire training corpus be manually labeled, to reach the same performance as the entire data. 
 An automated approach to text readability assessment is essential to a language and can be a powerful tool for improving the understandability of texts written and published in that language. However, the Persian language, which is spoken by over 110 million speakers\footnote{閳ユ阀ersian language,閳 Sep 2018. [Online]. Available:https://en.wikipedia.org/wiki/Persian\_language}, lacks such a system. Unlike other languages such as English, French, and Chinese, minimal research studies have been conducted to develop an accurate and reliable text readability assessment system for the Persian language.  In the present research, the first Persian dataset for text readability assessment was gathered, and the first model for Persian text readability assessment using machine learning was introduced. The experiments revealed that this model was accurate and could assess the readability of Persian texts with a high degree of confidence. The results of this study can be used in several applications such as medical and educational text readability evaluation and have the potential to be the cornerstone of future studies in Persian text readability assessment. 
 Generative Adversarial Networks  have experienced a recent surge in popularity,  performing competitively in a variety of tasks, especially in computer vision. %and are currently used extensively in computer vision. %and have been applied with success, especially in computer vision.  However, GAN training has shown limited success in natural language processing. This is largely because sequences of text are discrete, and thus gradients cannot propagate from the discriminator to the generator. Recent solutions use reinforcement learning to propagate approximate gradients to the generator, but this is inefficient to train. We propose to utilize an autoencoder to learn a low-dimensional representation of sentences. A GAN is then trained to generate its own vectors in this space, which decode to realistic utterances. We report both random and interpolated samples from the generator. Visualization of sentence vectors indicate our model correctly learns the latent space of the autoencoder. Both human ratings and BLEU scores show that our model generates realistic text against competitive baselines.  
 %Named entity recognition  plays a vital role for information extraction and have been wildly studied.  Recently, neural networks have shown promising results for named entity recognition , which needs a number of labeled data to for model training. When meeting a new domain  for NER, there is no or a few labeled data, which makes domain NER much more difficult. As NER has been researched for a long time, some similar domain already has well labelled data . Therefore, in this paper, we focus on domain NER by studying how to utilize the labelled data from such similar source domain for the new target domain. We design a kernel function based instance transfer strategy by getting similar labelled sentences from a source domain. Moreover, we propose an enhanced recurrent neural network  by adding an additional layer that combines the source domain labelled data into traditional RNN structure. Comprehensive experiments are conducted on two datasets. The comparison results among HMM, CRF and RNN show that RNN performs bette than others. When there is no labelled data in domain target, compared to directly using the source domain labelled data without selecting transferred instances, our enhanced RNN approach gets improvement from 0.8052 to 0.9328 in terms of F1 measure. %Supervised learning algorithm is run when using different train data sizes. The experimental results show that it is not necessary to use whole labelled data, even small part of labelled data can also get comparative performance. Moreover, we co-train our ERNN model with the traditional CRF to make use of unlabelled data from both source domain and target domain. When there is no labelled data in domain target, compared to directly using the source domain labelled data without selecting transferred instances, our approach gets improvement from 0.8052 to 0.9328 in terms of F1 measure. %Finally, a semi-supervised learning strategy, i.e. co-training, is adopted to leverage the large unannotated target domain data.  
 User profiling means exploiting the technology of machine learning to predict attributes of users, such as demographic attributes, hobby attributes, preference attributes, etc. It's a powerful data support of precision marketing. Existing methods mainly study network behavior, personal preferences, post texts to build user profile. Through our data analysis of micro-blog, we find that females show more positive and have richer emotions than males in online social platform. This difference is very conducive to the distinction between genders.  Therefore, we argue that sentiment context is important as well for user profiling.This paper focuses on exploiting microblog user posts to predict one of the demographic labels: gender. We propose a Sentiment Representation Learning based Multi-Layer Perceptron model to classify gender. First we build a sentiment polarity classifier in advance by training Long Short-Term Memory model on e-commerce review corpus. Next we transfer sentiment representation to a basic MLP network. Last we conduct experiments on gender classification by sentiment representation. Experimental results show that our approach can improve gender classification accuracy by 5.53\%, from 84.20\% to 89.73\%.   
   Idioms pose problems to almost all Machine Translation systems. This type of language is very frequent in day-to-day language use and cannot be simply ignored. The recent interest in memory augmented models in the field of Language Modelling has aided the systems to achieve good results by bridging long-distance dependencies. In this paper we explore the use of such techniques into a Neural Machine Translation system to help in translation of idiomatic language. 
   Neural machine translation  is notoriously sensitive to noises, but noises are almost inevitable in practice. One special kind of noise is the , where words are replaced by other words with similar pronunciations.\footnote{In this paper,  the word ``homophone" is loosely used to represent characters or words with similar pronunciations.} We propose to improve the robustness of NMT to homophone noises by 1) jointly embedding both textual and phonetic information of source sentences,   and 2) augmenting the training dataset with homophone noises.   Interestingly, to achieve better translation quality and more robustness, we found that most  weights should be put on the phonetic rather than textual information.  Experiments show that our method not only significantly improves the robustness of NMT to homophone noises,  but also surprisingly improves the translation quality on some clean test sets. 
  translation systems translate from multiple languages to a single target language. By using information from these multiple sources, these systems achieve large gains in accuracy. To train these systems, it is necessary to have corpora with parallel text in multiple sources and the target language. However, these corpora are rarely complete in practice due to the difficulty of providing human translations in  of the relevant languages. In this paper, we propose a data augmentation approach to fill such incomplete parts using multi-source neural machine translation . In our experiments, results varied over different language combinations but significant gains were observed when using a source language similar to the target language. 
 %This is the paper's abstract \ldots %
 The advent of representation learning methods enabled large performance gains on various language tasks, alleviating the need for manual feature engineering. While engineered representations are usually based on some linguistic understanding and are therefore more interpretable, learned representations are harder to interpret. Empirically studying the complementarity of both approaches can provide more linguistic insights that would help reach a better compromise between interpretability and performance. We present INFODENS, a framework for studying learned and engineered representations of text in the context of text classification tasks. It is designed to simplify the tasks of feature engineering as well as provide the groundwork for extracting learned features and combining both approaches. INFODENS is flexible, extensible, with a short learning curve, and is easy to integrate with many of the available and widely used natural language processing tools. 
 Automatic understanding of domain specific texts in order to extract useful relationships for later use is a non-trivial task. One such relationship would be between railroad accidents' causes and their correspondent descriptions in reports. From~2001 to 2016 rail accidents in the U.S. cost more than}.\\ 
 Recent work has shown that the encoder-decoder attention mechanisms in neural machine translation  are different from the word alignment in statistical machine translation. In this paper, we focus on analyzing encoder-decoder attention mechanisms, in the case of word sense disambiguation  in NMT models. We hypothesize that attention mechanisms pay more attention to context tokens when translating ambiguous words. We explore the attention distribution patterns when translating ambiguous nouns. Counter-intuitively, we find that attention mechanisms are likely to distribute more attention to the ambiguous noun itself rather than context tokens, in comparison to other nouns. We conclude that attention mechanism is not the main mechanism used by NMT models to incorporate contextual information for WSD. The experimental results suggest that NMT models learn to encode contextual information necessary for WSD in the encoder hidden states. For the attention mechanism in Transformer models, we reveal that the first few layers gradually learn to ``align'' source and target tokens and the last few layers learn to extract features from the related but unaligned context tokens.  
     Large parallel corpora that are automatically obtained from the web, documents or elsewhere often exhibit many corrupted parts that are bound to negatively affect the quality of the systems and models that learn from these corpora. This paper describes frequent problems found in data and such data affects neural machine translation systems, as well as how to identify and deal with them. The solutions are summarised in a set of scripts that remove problematic sentences from input corpora. 
 In neural machine translation , it is has become standard to translate using subword units to allow for an open vocabulary and improve accuracy on infrequent words. Byte-pair encoding  and its variants are the predominant approach to generating these subwords, as they are unsupervised, resource-free, and empirically effective. However, the  of these subword units is a hyperparameter to be tuned for each language and task, using methods such as grid search. Tuning may be done inexhaustively or skipped entirely due to resource constraints, leading to sub-optimal performance. In this paper, we propose a method to automatically tune this parameter using only one training pass. We incrementally introduce new vocabulary online based on the held-out validation loss, beginning with smaller, general subwords and adding larger, more specific units over the course of training. Our method matches the results found with grid search, optimizing segmentation granularity without any additional training time. We also show benefits in training efficiency and performance improvements for rare words due to the way embeddings for larger units are incrementally constructed by combining those from smaller units.% 
 I present here an experimental system for identifying and annotating metaphor  in corpora. It is designed to plug in to    Metacorps, an experimental web app for annotating metaphor. As Metacorps users annotate metaphors, the system will use user annotations as training data. When the system is  confident, it will suggest an identification and an annotation. Once approved by the user, this becomes more training data. This naturally allows for transfer learning, where the system can, with some known degree of reliability, classify one class of metaphor after only being trained on another class of metaphor. For example, in our metaphorical violence project, metaphors may be classified by the network they were observed on, the grammatical subject or object of the violence metaphor, or the violent word used . 
 The ability to infer persona from dialogue can have applications in areas ranging from computational narrative analysis to personalized dialogue generation. We introduce neural models to learn persona embeddings in a supervised character trope classification task. The models encode dialogue snippets from IMDB into representations that can capture the various categories of film characters.  The best-performing models use a multi-level attention mechanism over a set of utterances. We also utilize prior knowledge in the form of textual descriptions of the different tropes. We apply the learned embeddings to find similar characters across different movies, and cluster movies according to the distribution of the embeddings. The use of short conversational text as input, and the ability to learn from prior knowledge using memory, suggests these methods could be applied to other domains. 
 Recently, due to the increasing popularity of social media, the necessity for extracting information from informal text types, such as microblog texts, has gained significant attention. In this study, we focused on the Named Entity Recognition  problem on informal text types for Turkish. We utilized a semi-supervised learning approach based on neural networks. We applied a fast unsupervised method for learning continuous representations of words in vector space. We made use of these obtained word embeddings, together with language independent features that are engineered to work better on informal text types, for generating a Turkish NER system on microblog texts. We evaluated our Turkish NER system on Twitter messages and achieved better F-score performances than the published results of previously proposed NER systems on Turkish tweets. Since we did not employ any language dependent features, we believe that our method can be easily adapted to microblog texts in other morphologically rich languages. \\  \newline  \Keywords{Named Entity Recognition, Turkish NER, Twitter
   Entity typing  is the problem of assigning labels to given entity mentions in a sentence. Existing works for ET require knowledge about the domain and target label set for a given test instance.  ET in the absence of such knowledge is a novel problem that we address as ET in the wild. We hypothesize that the solution to this problem is to build supervised models that generalize better on the ET task as a whole, rather than a specific dataset. In this direction, we propose a Collective Learning Framework , which enables learning from diverse datasets in a unified way.  The CLF first creates a unified hierarchical label set  and a label mapping by aggregating label information from all available datasets. Then it builds a single neural network classifier using UHLS, label mapping and a partial loss function. The single classifier predicts the finest possible label across all available domains even though these labels may not be present in any domain-specific dataset. We also propose a set of evaluation schemes and metrics to evaluate the performance of models in this novel problem.  Extensive experimentation on seven diverse real-world datasets demonstrates the efficacy of our CLF. 
 %Morphological tagging still remains a largely unsolved task especially in the case of morphologically rich languages, where the number of tags is enormous. Neural morphological tagging has been regarded as an extension to POS tagging task, treating each morphological tag as a monolithic label and ignoring its internal structure. We propose to view morphological tags as composite labels and explicitly model their internal structure in a neural sequence tagger. For this, we explore three different neural architectures and compare their performance with both CRF and simple neural multiclass baselines. We evaluate our models on 49 languages and show that the neural architecture that models the morphological labels as sequences of morphological category values performs significantly better than both baselines establishing state-of-the-art results in morphological tagging for most languages.\footnote{The source code is available at \\ }} %all neural models outperform a competitive CRF baseline by a large margin. %Among neural models, the sequence model achieves an overall best performance establishing state-of-the-art results in morphological tagging for most languages. 
 In a world of proliferating data, the ability to rapidly summarize text is growing in importance. Automatic summarization of text can be thought of as a sequence to sequence problem. Another area of natural language processing that solves a sequence to sequence problem is machine translation, which is rapidly evolving due to the development of attention-based encoder-decoder networks. This work applies these modern techniques to abstractive summarization. We perform analysis on various attention mechanisms for summarization with the goal of developing an approach and architecture aimed at improving the state of the art. In particular, we modify and optimize a translation model with self-attention for generating abstractive sentence summaries. The effectiveness of this base model along with attention variants is compared and analyzed in the context of standardized evaluation sets and test metrics. However, we show that these metrics are limited in their ability to effectively score abstractive summaries, and propose a new approach based on the intuition that an abstractive model requires an abstractive evaluation. 
  We explore whether it is possible to build lighter parsers, that are statistically equivalent to their corresponding standard version, for a wide set of languages showing different structures and morphologies. As testbed, we use the Universal Dependencies and transition-based dependency parsers trained on feed-forward networks. For these, most existing research assumes  embedded features and relies on pre-computation tricks to obtain speed-ups. We explore how these features and their size can be reduced and whether this translates into speed-ups with a negligible impact on accuracy. The experiments show that  features can be removed for the majority of treebanks without a significant  las difference. They also show how the size of the embeddings can be notably reduced.   
 Recognising dialogue acts  is important for many natural language processing tasks such as dialogue generation and intention recognition. In this paper, we propose a dual-attention hierarchical recurrent neural network for DA classification. Our model is partially inspired by the observation that conversational utterances are normally associated with both a DA and a topic, where the former captures the social act and the latter describes the subject matter. However, such a dependency between DAs and topics has not been utilised by most existing systems for DA classification. With a novel dual task-specific attention mechanism, our model is able, for utterances, to capture information about both DAs and topics, as well as information about the interactions between them. Experimental results show that by modelling topic as an auxiliary task, our model can significantly improve DA classification, yielding better or comparable performance to the state-of-the-art method on three public datasets.  
 We tackle  by comparing entities in short sentences with \wikidata{} graphs.  Creating a context vector from graphs through deep learning is a challenging problem that has never been applied to .  Our main contribution is to present an experimental study of recent neural techniques, as well as a discussion about which graph features are most important for the disambiguation task.  In addition, a new dataset  is created to allow a clean and scalable evaluation of  with \wikidata{} entries, and to be used as a reference in future research. In the end our results show that a  encoding of the graph triplets performs best, improving upon the baseline models and scoring an \rm{F1} value of $91.6\%$ on the \wikidatadisamb{} test set \footnote{ The dataset and the code for this paper can be found at \url{https://github.com/contextscout/ned-graphs} %The dataset and the code for this paper will be released after the double-blind review process. } . 
 Convolutional neural networks have been successfully applied to various NLP tasks. However, it is not obvious whether they model different linguistic patterns such as negation, intensification, and clause compositionality to help the decision-making process.  In this paper, we apply visualization techniques to observe how the model can capture different linguistic features and how these features can affect the performance of the model. Later on, we try to identify the model errors and their sources. We believe that interpreting CNNs is the first step to understand the underlying semantic features which can raise awareness to further improve the performance and explainability of CNN models. 
 % Recurrent neural network  models are widely used for processing sequential data governed by a latent tree structure.  % Previous work shows that RNN models  based models) could learn to exploit the underlying tree structure. % However, its performance consistently lags behind that of tree-based models.  % % on tasks that explicitly require an understanding of latent structure. % This work proposes a new inductive bias , which enforces an order of updating frequencies between hidden state neurons.  % We show that the ordered neurons could explicitly integrate the latent tree structure into recurrent models.  % To this end, we propose a new RNN unit: ON-LSTM, which achieve good performances on four different tasks: language modeling, unsupervised parsing, targeted syntactic evaluation, and logical inference. Natural language is hierarchically structured: smaller units  are nested within larger units . When a larger constituent ends, all of the smaller constituents that are nested within it must also be closed. While the standard LSTM architecture allows different neurons to track information at different time scales, it does not have an explicit bias towards modeling a hierarchy of constituents. This paper proposes to add such an inductive bias by~ the neurons; a vector of master input and forget gates ensures that when a given neuron is updated, all the neurons that follow it in the ordering are also updated. Our novel recurrent architecture,  LSTM , achieves good performance on four different tasks: language modeling, unsupervised parsing, targeted syntactic evaluation, and logical inference\footnote{The code can be found at \url{https://github.com/yikangshen/Ordered-Neurons}.}. 
   The task of linearization is to find a grammatical order given a set of words.   Traditional models use statistical methods.   Syntactic linearization systems, which generate a sentence along with its syntactic tree, have shown state-of-the-art performance.   Recent work shows that a multi-layer LSTM language model outperforms competitive statistical syntactic linearization systems without using syntax.   In this paper, we study neural syntactic linearization, building a transition-based syntactic linearizer leveraging a feed forward neural network, observing significantly better results compared to LSTM language models on this task. 
 Neural network models have been very successful in natural language inference, with the best models reaching 90\% accuracy in some benchmarks. However, the success of these models turns out to be largely benchmark specific. We show that models trained on a natural language inference dataset drawn from one benchmark fail to perform well in others, even if the notion of inference assumed in these benchmarks is the same or similar. We train six high performing neural network models on different datasets and show that each one of these has problems of generalizing when we replace the original test set with a test set taken from another corpus designed for the same task. In light of these results, we argue that most of the current neural network models are not able to generalize well in the task of natural language inference. We find that using large pre-trained language models helps with transfer learning when the datasets are similar enough. Our results also highlight that the current NLI datasets do not cover the different nuances of inference extensively enough.  
        In this paper, we describe a general framework: Parameters Read-Write Networks  to systematically analyze current neural models for multi-task learning, in which we find that existing models expect to disentangle features into different spaces while features learned in practice are still entangled in shared space,  leaving potential hazards for other training or unseen tasks.     We propose to alleviate this problem by incorporating an inductive bias into the process of multi-task learning, that each task can keep informed of not only the knowledge stored in other tasks but the way how other tasks maintain their knowledge.     In practice, we achieve above inductive bias by allowing different tasks to communicate by passing both hidden variables and gradients explicitly.     Experimentally, we evaluate proposed methods on three groups of tasks and two types of settings . Quantitative and qualitative results show their effectiveness.    
 Most previous work on neural text generation from graph-structured  data relies on standard sequence-to-sequence methods. These approaches linearise the input graph to be fed to a recurrent neural network. In this paper, we propose an alternative encoder based on graph  convolutional networks that directly exploits the input structure. We report results on two graph-to-sequence datasets that empirically  show the benefits of explicitly encoding the input graph structure.\footnote{Code and data available at \url{github.com/diegma/graph-2-text}.}  
 %Neural machine translation  systems have demonstrated their effectiveness and capacity in many language pairs. Deep neural networks have attracted huge attention from researchers and have been widely applied in NMT because of their ability to model complex functions and capture complicated linguistic structures. Typically, state-of-the-art NMT systems have encoder and decoder with multiple layers. Although deep architecture have proven to be effective and useful, we argue that one common drawback of these models is that they only utilize the information in the top layer. Recently, several studies have indicated that different layers can capture diverse information. In this paper, we propose several strategies to combine the information across layers, from simple linear combination to deep, nonlinear layer aggregation. By augmenting the state-of-the-art architecture with deeper aggregation, we manage to learn better representations and get better translation quality for NMT systems. Experimental results on WMT14 English$\Rightarrow$German and WMT17 Chinese$\Rightarrow$English datasets demonstrate the necessity of fusing layers and the effectiveness of our proposed approaches.  Advanced neural machine translation  models generally implement encoder and decoder as multiple layers, which allows systems to model complex functions and capture complicated linguistic structures. However, only the top layers of encoder and decoder are leveraged in the subsequent process, which misses the opportunity to exploit the useful information embedded in other layers. In this work, we propose to simultaneously expose all of these signals with layer aggregation and multi-layer attention mechanisms. In addition, we introduce an auxiliary regularization term to encourage different layers to capture diverse information. Experimental results on widely-used WMT14 English$\Rightarrow$German and WMT17 Chinese$\Rightarrow$English translation data demonstrate the effectiveness and universality of the proposed approach.  % However, we argue that one common drawback of these deep models is that they only utilize the information in the top layer. Inspired by the recent studies which have indicated that different layers can capture diverse information, in this paper, we propose several strategies to combine the information across layers, from simple linear combination to deep nonlinear layer aggregation. By augmenting the state-of-the-art architecture with deeper aggregation, we manage to learn better representations and get better translation quality for NMT systems. Experimental results on WMT14 English$\Rightarrow$German and WMT17 Chinese$\Rightarrow$English datasets demonstrate the necessity of fusing layers and the effectiveness of our proposed approaches. 
 Self-attention networks have proven to be of profound value for its strength of capturing global dependencies. In this work, we propose to model localness for self-attention networks, which enhances the ability of capturing useful local context. We cast localness modeling as a learnable Gaussian bias, which indicates the central and scope of the local region to be paid more attention. The bias is then incorporated into the original attention distribution to form a revised distribution. To maintain the strength of capturing long distance dependencies %while and enhance the ability of capturing short-range dependencies, we only apply localness modeling to lower layers of self-attention networks. Quantitative and qualitative analyses on Chinese$\Rightarrow$English and English$\Rightarrow$German translation tasks %on different language pairs  demonstrate the effectiveness and universality of the proposed approach. 
 Building large-scale datasets for training code-switching language models is challenging and very expensive. To alleviate this problem using parallel corpus has been a major workaround. However, existing solutions use linguistic constraints which may not capture the real data distribution. In this work, we propose a novel method for learning how to generate code-switching sentences from parallel corpora. Our model uses a Seq2Seq model in combination with pointer networks to align and choose words from the monolingual sentences and form a grammatical code-switching sentence. In our experiment, we show that by training a language model using the augmented sentences we improve the perplexity score by $10\%$ compared to the LSTM baseline.  
     % Human translators are able to correct their translation by very simple supervision, such as one word or one phrase. Nowadays, Neural Machine Translation  achieves great success in producing fluent translations. But their ability to incorporate external information or supervision has not been fully explored, especially for the cases where the external information is short and simple. In this paper, we propose a mechanism with word discriminators, which helps the NMT system to  distinguish the useful external information from the noisy one and to assist the translation at the right position.      % In general, our approach could be used in many cases where outside information is provided, such as incorporating statistical machine translation results or revising from human interactions.     % %Our approach consists of two components. A Word Identifier first discriminates whether the words in external information are useful or not. During decoding stage, an Incoporater incorporates the time-dependent predictive information from external stream with the original NMT output to perform a better word generation.      % Empirical evaluation shows that the proposed approach could dynamically adapt the useful part of the external information while prevent the harmful impact from the irrelevant noisy words or segments, which leads to significant improvement from the original translation.          % 11-23     % Neural Machine Translation  achieves great success in producing fluent translations. But it is widely observed that NMT still suffers from inadequacy and incorrectness. Inspired by human translators who are able to deliberate their translation by the aid of external resources , some previous work gains promising results by incorporating NMT models with external information, such as human interactive input, output from SMT or similar sentences from training corpus. However, it is inevitable for the given external information to contain noisy parts, which will potentially damage the original performance of translation. In this work, we propose a framework that aims to de-noise whatever external input. It helps the NMT system to distinguish the useful information from the noisy one, leading NMT model to better leverage the outside resources.          % Empirical evaluation shows that the proposed approach could dynamically adopt the useful parts while prevent the harmful impact from the irrelevant noise, where the external information is either synthetic data, bilingual dictionary or SMT result, which leads to significant improvement from the original translation.          % Existing Neural Machine Translation  models generally produce fluent translations, but still suffers from inadequacy and incorrectness, which is non-trivial to tackle by only learning from corpus. Incorporating NMT model with external information, besides source and target sentences , is a natural idea which gains promising results in previous work.       Previous studies show that incorporating external information could improve the translation quality of Neural Machine Translation  systems. However, there are inevitably noises in the external information, severely reducing the benefit that the existing methods could receive from the incorporation. % However, these methods will inevitably suffer from the noises in the external information, which may severely reduce the benefit.  To tackle the problem, this study pays special attention to the discrimination of the noises during the incorporation. We argue that there exist two kinds of noise in this external information, i.e. global noise and local noise, which affect the translations for the whole sentence and for some specific words, respectively.  % To tackle the problem, this study pays special attention to the discrimination of noises during the incorporation. % Accordingly, we propose a general framework with two separate word discriminators \ZZX{noise discriminating} for the global and local noises, respectively, so that the external information could be better leveraged.  Accordingly, we propose a general framework that learns to jointly discriminate both the global and local noises, so that the external information could be better leveraged.  Our model is trained on the dataset derived from the original parallel corpus without any external labeled data or annotation. % Empirical evaluation shows that being trained by the dataset sampled from the original parallel corpus without any extra labeled data or annotation,  % Our model could make better use of external information in various real-world scenarios, language pairs, and neural architectures, leading to significant improvements over the original translation. Experimental results in various real-world scenarios, language pairs, and neural architectures indicate that discriminating noises contributes to significant improvements in translation quality by being able to better incorporate the external information, even in very noisy conditions.      
 We propose a new approach to natural language understanding in which we consider the input text as an image and apply 2D Convolutional Neural Networks to learn the local and global semantics of the sentences from the variations of the visual patterns of words. Our approach demonstrates that it is possible to get semantically meaningful features from images with text without using optical character recognition and sequential processing pipelines, techniques that traditional Natural Language Understanding algorithms require. To validate our approach, we present results for two applications: text classification and dialog modeling. Using a 2D Convolutional Neural Network, we were able to outperform the state-of-art accuracy results of non-Latin alphabet-based text classification and achieved promising results for eight text classification datasets. Furthermore, our approach outperformed the memory networks when using out of vocabulary entities from task 4 of the bAbI dialog dataset. 
 Knowledge bases  are paramount in NLP. We employ  for increasing accuracy and coverage of entity type information in KBs. We rely on two : language and representation. For  language, we consider high-resource and low-resource languages from Wikipedia. For representation, we consider representations based  on the context distribution of the entity , on the entity's name  and on its description in Wikipedia. The two metaviews language and representation can be freely combined: each pair of language and representation  is a distinct view. Our experiments on entity typing with fine-grained classes demonstrate the effectiveness of multiview learning. We release MVET, a large multiview -- and, in particular, multilingual -- entity typing dataset we created. Mono- and multilingual fine-grained entity typing systems can be evaluated on this dataset. 
  In Natural Language Processing , it is important to detect the relationship between two sequences or to generate a sequence of tokens given another observed sequence. We call the type of problems on modelling sequence pairs as sequence to sequence  mapping problems.  A lot of research has been devoted to finding ways of tackling these problems, with traditional approaches relying on a combination of hand-crafted features, alignment models, segmentation heuristics, and external linguistic resources. Although great progress has been made, these traditional approaches suffer from various drawbacks, such as complicated pipeline, laborious feature engineering, and the difficulty for domain adaptation. Recently, neural networks emerged as a promising solution to many problems in NLP, speech recognition, and computer vision. Neural models are powerful because they can be trained end to end, generalise well to unseen examples, and the same framework can be easily adapted to a new domain.  The aim of this thesis is to advance the state-of-the-art in seq2seq mapping problems with neural networks.  We explore solutions from three major aspects: investigating neural models for representing sequences, modelling interactions between sequences, and using unpaired data to boost the performance of neural models. For each aspect, we propose novel models and evaluate their efficacy on various tasks of seq2seq mapping.  Chapter \ref{ch:nn} covers the relevant literature on neural networks. Following this, in Chapter \ref{ch:sentence_model} we explore the usefulness of distributed sentence models in seq2seq mapping problems by testing them in the task of answer sentence selection. We also empirically compare the performance of distributed sentence models based on different types of neural networks. Chapter \ref{ch:ssnt} presents a neural sequence transduction model that learns to alternate between encoding and decoding segments of the input as it is read. The model not only outperforms the encoder-decoder model significantly on various tasks such as machine translation and sentence summarisation, but also is capable of predicting outputs online during decoding. In Chapter \ref{ch:noisy_channel}, we propose to incorporate abundant unpaired data using the noisy channel model---with the component models parameterised by recurrent neural networks---and present a tractable and effective beam search decoder.   
 One of the major downsides of Deep Learning is its supposed need for vast amounts of training data. As such, these techniques appear ill-suited for NLP areas where annotated data is limited, such as less-resourced languages or emotion analysis, with its many nuanced and hard-to-acquire annotation formats. We conduct a questionnaire study indicating that indeed the vast majority of researchers in emotion analysis deems neural models inferior to traditional machine learning when training data is limited. In stark contrast to those survey results, we provide empirical evidence for English, Polish, and Portuguese that commonly used neural architectures can be trained on surprisingly few observations, outperforming $n$-gram based ridge regression on only 100 data points. Our analysis suggests that high-quality, pre-trained word embeddings are a main factor for achieving those results. 
   `No' belongs to the first ten words used by children and embodies the first active form of linguistic negation. Despite its early occurrence the details of its    acquisition process remain largely unknown. The circumstance that `no' cannot be construed as a label for perceptible objects or events puts it outside of the    scope of most modern accounts of language acquisition.   Moreover, most symbol grounding architectures will struggle to ground the word due to its non-referential character.   In an experimental study involving the child-like humanoid robot iCub that was designed to illuminate the acquisition process of negation    words the robot is deployed in several rounds of speech-wise unconstrained interaction with na\"{i}ve participants acting as its language teachers.   The results corroborate the hypothesis that affect or volition plays a pivotal role in the socially distributed acquisition process. Negation words are    prosodically salient within prohibitive utterances and negative intent interpretations such that they can be easily isolated from the teacher's speech signal.    These words subsequently may be grounded in negative affective states. However, observations of the nature of prohibitive acts and the temporal relationships between    its linguistic and extra-linguistic components raise serious questions over the suitability of Hebbian-type algorithms for language grounding. 
 We consider the problem of automatically generating textual paraphrases with modified attributes or properties,  focusing on the setting without parallel data~. This setting poses challenges for evaluation. We show that the metric of post-transfer classification accuracy is insufficient on its own, and propose additional metrics based on semantic preservation and fluency as well as a way to combine them into a single overall score.  We contribute new loss functions and training strategies to address the different metrics.  Semantic preservation is addressed by adding a cyclic consistency loss and a loss based on paraphrase pairs,  while fluency is improved by integrating losses based on style-specific language models.  We experiment with a Yelp sentiment dataset and a new literature dataset that we propose, using multiple models that extend prior work . We demonstrate that our metrics correlate well with human judgments, at both the  sentence-level and system-level. Automatic and manual evaluation also show large improvements over the baseline method of . We hope that our proposed metrics can speed up system development for new textual transfer tasks while also encouraging the  community to address our three complementary aspects of transfer quality.  
 We carry out experiments with deep learning models of summarization across the domains of news, personal stories, meetings, and medical articles in order to understand how content selection is performed. We find that many sophisticated features of state of the art extractive summarizers do not improve performance over simpler models. These results suggest that it is easier to create a summarizer for  a new domain than previous work suggests and bring into question the benefit of deep learning models for summarization for those domains that do have massive datasets . At the same time, they suggest important questions for new research in summarization; namely,  new forms of sentence representations or external knowledge sources are needed that are better suited to the summarization task.  
 We propose a methodology for estimating human behaviors in psychotherapy sessions using mutli-label and multi-task learning paradigms. We discuss the problem of behavioral coding in which data of human interactions is the annotated with labels to describe relevant human behaviors of interest. We describe two related, yet distinct, corpora consisting of therapist client interactions in psychotherapy sessions. We experimentally compare the proposed learning approaches for estimating behaviors of interest in these datasets. Specifically, we compare single and multiple label learning approaches, single and multiple task learning approaches, and evaluate the performance of these approaches when incorporating turn context. We demonstrate the prediction performance gains which can be achieved by using the proposed paradigms and discuss the insights these models provide into these complex interactions. 
 % novel additions and alterations Recent papers in neural machine translation have proposed the strict use of attention mechanisms over previous standards such as recurrent and convolutional neural networks . We propose that by running traditionally stacked encoding branches from encoder-decoder attention-focused architectures in parallel, that even more sequential operations can be removed from the model and thereby decrease training time. In particular, we modify the recently published attention-based architecture called Transformer by Google, by replacing sequential attention modules with parallel ones, reducing the amount of training time and substantially improving BLEU scores at the same time. Experiments over the English to German and English to French translation tasks show that our model establishes a new state of the art. 
 Producing a large amount of annotated speech data for training ASR systems remains difficult for more than 95\% of languages all over the world which are low-resourced. However, we note human babies start to learn the language by the sounds of a small number of exemplar words without hearing a large amount of data. We initiate some preliminary work in this direction in this paper. Audio Word2Vec is used to obtain embeddings of spoken words which carry phonetic information extracted from the signals. An autoencoder is used to generate embeddings of text words based on the articulatory features for the phoneme sequences. Both sets of embeddings for spoken and text words describe similar phonetic structures among words in their respective latent spaces. A mapping relation from the audio embeddings to text embeddings actually gives the word-level ASR. This can be learned by aligning a small number of spoken words and the corresponding text words in the embedding spaces. In the initial experiments only 200 annotated spoken words and one hour of speech data without annotation gave a word accuracy of 27.5\%, which is low but a good starting point. 
 Neural methods have had several recent successes in semantic parsing, though they have yet to face the challenge of producing meaning representations based on formal semantics. We present a sequence-to-sequence neural semantic parser that is able to produce Discourse Representation Structures  for English sentences with high accuracy, outperforming traditional DRS parsers. To facilitate the learning of the output, we represent DRSs as a sequence of flat clauses and introduce a method to verify that produced DRSs are well-formed and interpretable. We compare models using characters and words as input and see  that the former performs better than the latter. We show that eliminating variable names from the output using De Bruijn-indices increases parser performance.  Adding silver training data boosts performance even further. 
 Recent work achieved remarkable results in training neural machine translation  systems in a fully unsupervised way, with new and dedicated architectures that rely on monolingual corpora only. In this work, we propose to define unsupervised NMT  as NMT trained with the supervision of synthetic bilingual data. Our approach straightforwardly enables the use of state-of-the-art architectures proposed for supervised NMT by replacing human-made bilingual data with synthetic bilingual data for training. We propose to initialize the training of UNMT with synthetic bilingual data generated by unsupervised statistical machine translation . The UNMT system is then incrementally improved using back-translation. Our preliminary experiments show that our approach achieves a new state-of-the-art for unsupervised machine translation on the WMT16 German--English news translation task, for both translation directions. 
   In evidence-based medicine , defining a clinical question in terms of the specific patient problem aids the  physicians to efficiently identify appropriate  resources  and  search  for  the  best  available  evidence  for medical treatment. In order to formulate a well-defined, focused clinical question, a framework called PICO is widely used, which identifies the sentences in a given medical text that belong to the four components typically reported in clinical trials: Participants/Problem , Intervention , Comparison  and Outcome . In this work, we propose a novel deep learning model for recognizing PICO elements in  biomedical  abstracts.  Based  on  the  previous  state-of-the-art  bidirectional long-short term memory  plus conditional random field  architecture,   we  add  another  layer  of  biLSTM  upon  the  sentence representation vectors so that the contextual information from surrounding sentences can be gathered to help infer the interpretation of the current one. In addition, we propose two  methods  to  further  generalize  and improve the  model:  adversarial  training  and unsupervised pre-training over large corpora.   We tested our proposed approach over two benchmark datasets. One is the PubMed-PICO dataset, where our best results outperform the previous best by 5.5\%, 7.9\%, and 5.8\% for P, I, and O elements in terms of F1 score, respectively. And for the other dataset named NICTA-PIBOSO, the improvements for P/I/O elements are 2.4\%, 13.6\%, and 1.0\% in F1 score, respectively. Overall, our proposed deep learning model can obtain unprecedented PICO element detection accuracy while avoiding the need for any manual feature selection.  
 The scarcity of labeled training data across many languages is a significant roadblock for multilingual neural language processing. We approach the lack of in-language training data using sentence embeddings that map text written in different languages, but with similar meanings, to nearby embedding space representations. The representations are produced using a dual-encoder based model trained to maximize the representational similarity between sentence pairs drawn from parallel data. The representations are enhanced using multitask training and unsupervised monolingual corpora. The effectiveness of our multilingual sentence embeddings are assessed on a comprehensive collection of monolingual, cross-lingual, and zero-shot/few-shot learning tasks. 
 In relation extraction with distant supervision, noisy labels make it difficult to train quality models. Previous neural models addressed this problem using an attention mechanism that attends to sentences that are likely to express the relations. We improve such models by combining the distant supervision data with an additional directly-supervised data, which we use as supervision for the attention weights. % We find that joint training on both types of supervision improves the model's ability to identify noisy sentences. We find that joint training on both types of supervision leads to a better model because it improves the model's ability to identify noisy sentences. In addition, we find that sigmoidal attention weights with max pooling achieves better performance over the commonly used weighted average attention in this setup.  Our proposed method\footnote{\url{https://github.com/allenai/comb_dist_direct_relex/}} achieves a new state-of-the-art result on the widely used FB-NYT dataset. %   
   Standard evaluations of deep learning models for semantics   using naturalistic corpora are limited in what they can tell us   about the fidelity of the learned representations, because the   corpora rarely come with good measures of semantic   complexity. To overcome this limitation, we present a method   for generating data sets of multiply-quantified natural language   inference  examples in which semantic complexity can be   precisely characterized, and we use this method to show that a   variety of common architectures for NLI inevitably fail to encode   crucial information; only a model with forced lexical alignments   avoids this damaging information loss. 
 We propose an attentive neural network for the task of named entity recognition in Vietnamese. The proposed attentive neural model makes use of character-based language models and word embeddings to encode words as vector representations. A neural network architecture of encoder, attention, and decoder layers is then utilized to encode knowledge of input sentences and to label entity tags. The experimental results show that the proposed attentive neural network achieves the state-of-the-art results on the benchmark named entity recognition datasets in Vietnamese in comparison to both hand-crafted features based models and neural models. 
 One of the first steps in the utterance interpretation pipeline of many task-oriented conversational AI systems is to identify user intents and the corresponding slots. Since data collection for machine learning models for this task is time-consuming, it is desirable to make use of existing data in a high-resource language to train models in low-resource languages. However, development of such models has largely been hindered by the lack of multilingual training data. In this paper, we present a new data set of 57k annotated utterances in English , Spanish  and Thai  across the domains weather, alarm, and reminder. We use this data set to evaluate three different cross-lingual transfer methods:  translating the training data,  using cross-lingual pre-trained embeddings, and  a novel method of using a multilingual machine translation encoder as contextual word representations. We find that given several hundred training examples in the the target language, the latter two methods outperform translating the training data. Further, in very low-resource settings, multilingual contextual word representations give better results than using cross-lingual static embeddings. We also compare the cross-lingual methods to using monolingual resources in the form of contextual ELMo representations and find that given just small amounts of target language data, this method outperforms all cross-lingual methods, which highlights the need for more sophisticated cross-lingual methods.  
 This paper is concerned with the training of recurrent neural networks as goal-oriented dialog agents using reinforcement learning. Training such agents with policy gradients typically requires a large amount of samples. However, the collection of the required data in form of conversations between chat-bots and human agents is time-consuming and expensive.  To mitigate this problem, we describe an efficient policy gradient method using positive memory retention, which significantly increases the sample-efficiency.  %The method memorizes and reuses past positive trajectories within each epoch to update the target policy network safely with a bounded importance weight proposal.  %Furthermore, a probability updating trick is utilized to tackle high variance problems introduced by importance sampling.  %Memory retention is automatically decided based on an early stopping mechanism.  We show that our method is 10 times more sample-efficient than policy gradients in extensive experiments on a new synthetic number guessing game. Moreover, in a real-word visual object discovery game, the proposed method is twice as sample-efficient as policy gradients and shows state-of-the-art performance.  %Our work demonstrates that policy gradient can successfully be trained using past trajectories in dialog settings. 
 \vspace*{-.2cm}  \vspace*{-.2cm} 
 Deep learning methods are often difficult to apply in the legal domain due to the large amount of labeled data required by deep learning methods. A recent new trend in the deep learning community is the application of multi-task models that enable single deep neural networks to perform more than one task at the same time, for example classification and translation tasks. These powerful novel models are capable of transferring knowledge among different tasks or training sets and therefore could open up the legal domain for many deep learning applications. In this paper, we investigate the transfer learning capabilities of such a multi-task model on a classification task on the publicly available Kaggle toxic comment dataset for classifying illegal comments and we can report promising results. 
 Allowing humans to interactively train artificial agents to understand language instructions is desirable for both practical and scientific reasons.  Though, given  the lack of sample efficiency in current learning methods, reaching this goal may require substantial research efforts. We introduce the BabyAI research platform, with the goal of supporting investigations towards including humans in the loop for grounded language learning. The BabyAI platform comprises an extensible suite of 19 levels of increasing difficulty.  Each level gradually leads the agent towards acquiring a combinatorially rich synthetic language, which is a proper subset of English. The platform also provides a hand-crafted bot agent, which simulates a human teacher.  We report estimated amount of supervision required for training neural reinforcement and behavioral-cloning agents on some BabyAI levels. We put forward strong evidence that current deep learning methods are not yet sufficiently sample-efficient in the context of learning a language with compositional properties. 
 Mainstream captioning models often  follow a sequential structure to generate captions, leading to issues such as introduction of irrelevant semantics, lack of diversity in the generated captions, and inadequate generalization performance.  % In this paper, we present an alternative paradigm for image captioning, which factorizes the captioning procedure into two stages:  extracting an  semantic representation from the given image; and  constructing the caption based on a recursive  procedure in a bottom-up manner. % Compared to conventional ones, our paradigm better preserves the semantic content  through an explicit factorization of semantics and syntax. By using the compositional generation procedure, caption construction follows a recursive structure, which naturally fits the properties of human language. Moreover,  the proposed compositional procedure requires less data to train, generalizes better, and yields more diverse captions. 
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  We present a modular approach for learning policies for navigation     over long planning horizons from language input. Our hierarchical policy     operates at multiple timescales, where the higher-level master policy proposes     subgoals to be executed by specialized \subpolicies. Our choice of subgoals     is compositional and semantic,  benchmark in House3D~,     requiring navigating diverse realistic indoor environments, our approach     outperforms prior work by a significant margin, both in terms of navigation     and question answering.  
 Question answering  has significantly benefitted from deep learning techniques in recent years. However, domain-specific QA remains a challenge due to the significant amount of data required to train a neural network. This paper studies the answer sentence selection task in the Bible domain and answer questions by selecting relevant verses from the Bible. For this purpose, we create a new dataset \BibleQA\ based on bible trivia questions and propose three neural network models for our task. We pre-train our models on a large-scale QA dataset, \SQuAD, and investigate the effect of transferring weights on model accuracy. Furthermore, we also measure the model accuracies with different answer context lengths and different Bible translations. We affirm that transfer learning has a noticeable improvement in the model accuracy. We achieve relatively good results with shorter context lengths, whereas longer context lengths decreased model accuracy. We also find that using a more modern Bible translation in the dataset has a positive effect on the task.  
 Neural language models have been widely used in various NLP tasks, including machine translation, next word prediction and conversational agents. However, it is challenging to deploy these models on mobile devices due to their slow prediction speed, where the bottleneck is to compute top candidates in the softmax layer. In this paper, we introduce a novel softmax layer approximation algorithm by exploiting the clustering structure of context vectors. Our algorithm uses a light-weight screening model to predict a much smaller set of candidate words based on the given context, and then conducts an exact softmax only within that subset. Training such a procedure end-to-end is challenging as traditional clustering methods are discrete and non-differentiable, and thus unable to be used with back-propagation in the training process. Using the Gumbel softmax, we are able to train the screening model end-to-end on the training set to exploit data distribution. The algorithm achieves an order of magnitude faster inference than the original softmax layer for predicting top-$k$ words in various tasks such as beam search in machine translation or next words prediction. For example, for machine translation task on German to English dataset with around 25K vocabulary, we can achieve 20.4 times speed up with 98.9\% precision@1 and 99.3\% precision@5 with the original softmax layer prediction, while state-of-the-art ~ only achieves 6.7x speedup with 98.7\% precision@1 and 98.1\% precision@5 for the same task. 
 MAC Net  is a compositional attention network designed for Visual Question Answering. We propose a modified MAC net architecture for Natural Language Question Answering. Question Answering typically requires Language Understanding and multi-step Reasoning. MAC net's unique architecture - the separation between memory and control, facilitates data-driven iterative reasoning. This makes it an ideal candidate for solving tasks that involve logical reasoning. Our experiments with 20 bAbI tasks, demonstrate the value of MAC net as a data-efficient and interpretable architecture for Natural Language Question Answering. The transparent nature of MAC net provides a highly granular view of the reasoning steps taken by the network in answering a query. 
 Recurrent Neural Network  has been successfully applied in many sequence learning problems. Such as handwriting recognition, image description, natural language processing and video motion analysis. After years of development, researchers have improved the internal structure of the RNN and introduced many variants. Among others, Gated Recurrent Unit  is one of the most widely used RNN model. However, GRU lacks the capability of adaptively paying attention to certain regions or locations, so that it may cause information redundancy or loss during leaning. In this paper, we propose a RNN model, called Recurrent Attention Unit , which seamlessly integrates the attention mechanism into the interior of GRU by adding an attention gate. The attention gate can enhance GRU's ability to remember long-term memory and help memory cells quickly discard unimportant content. RAU is capable of extracting information from the sequential data by adaptively selecting a sequence of regions or locations and pay more attention to the selected regions during learning. Extensive experiments on image classification, sentiment classification and language modeling show that RAU consistently outperforms GRU and other baseline methods.  
 Used for simple commands recognition on devices from smart routers to mobile phones, keyword spotting systems are everywhere. Ubiquitous as well are web applications, which have grown in popularity and complexity over the last decade with significant improvements in usability under cross-platform conditions. However, despite their obvious advantage in natural language interaction, voice-enabled web applications are still far and few between. In this work, we attempt to bridge this gap by bringing keyword spotting capabilities directly into the browser. To our knowledge, we are the first to demonstrate a fully-functional implementation of convolutional neural networks in pure JavaScript that runs in any standards-compliant browser. We also apply network slimming, a model compression technique, to explore the accuracy--efficiency tradeoffs, reporting latency measurements on a range of devices and software. Overall, our robust, cross-device implementation for keyword spotting realizes a new paradigm for serving neural network applications, and one of our slim models reduces latency by 66\% with a minimal decrease in accuracy of 4\% from 94\% to 90\%.  
 The goal of this work is to develop a meeting transcription system that can recognize speech even when  utterances of different speakers are overlapped.  While speech overlaps have been regarded as a major obstacle in accurately transcribing meetings,  a traditional beamformer with a single output has been exclusively used  because previously proposed speech separation techniques have critical constraints for application to real meetings.  This paper proposes a new signal processing module, called an unmixing transducer, and describes its implementation using a windowed BLSTM.  The unmixing transducer has a fixed number, say $J$, of output channels, where $J$ may be different from the number of meeting attendees, and  transforms an input multi-channel acoustic signal into $J$  time-synchronous audio streams.  Each utterance in the meeting  is separated and emitted from one of the output channels.  Then, each output signal can be simply fed to a speech recognition back-end for segmentation and transcription.  Our meeting transcription system using the unmixing transducer outperforms a system based on a state-of-the-art neural mask-based beamformer by 10.8\%.  Significant improvements are observed in overlapped segments.  To the best of our knowledge,  this is the first report that applies overlapped speech recognition to unconstrained real meeting audio. 
   We propose a practical approach based on federated learning to solve out-of-domain issues with continuously running embedded speech-based models such as wake word detectors. We conduct an extensive empirical study of the federated averaging algorithm for the ``Hey Snips'' wake word based on a crowdsourced dataset that mimics a federation of wake word users.  We empirically demonstrate that using an adaptive averaging strategy inspired from Adam in place of standard weighted model averaging highly reduces the number of communication rounds required to reach our target performance. The associated upstream communication costs per user are estimated at 8 MB, which is a reasonable in the context of smart home voice assistants. Additionally, the dataset used for these experiments is being open sourced with the aim of fostering further transparent research in the application of federated learning to speech data.    
 This paper proposes a new loss using short-time Fourier transform  spectra for the aim of training a high-performance neural speech waveform model that predicts raw continuous speech waveform samples directly. Not only amplitude spectra but also phase spectra obtained from generated speech waveforms are used to calculate the proposed loss. We also mathematically show that training of the waveform model on the basis of the proposed loss can be interpreted as maximum likelihood training that assumes the amplitude and phase spectra of generated speech waveforms following Gaussian and von Mises distributions, respectively. Furthermore, this paper presents a simple network architecture as the speech waveform model, which is composed of uni-directional long short-term memories  and an auto-regressive structure. Experimental results showed that the proposed neural model synthesized high-quality speech waveforms. 
 The standard approach to mitigate errors made by an automatic speech recognition system is to use confidence scores associated with each predicted word. In the simplest case, these scores are word posterior probabilities whilst more complex schemes utilise bi-directional recurrent neural network  models. A number of upstream and downstream applications, however, rely on confidence scores assigned not only to 1-best hypotheses but to all words found in confusion networks or lattices. These include but are not limited to speaker adaptation, semi-supervised training and information retrieval. Although word posteriors could be used in those applications as confidence scores, they are known to have reliability issues. To make improved confidence scores more generally available, this paper shows how BiRNNs can be extended from 1-best sequences to confusion network and lattice structures. Experiments are conducted using one of the Cambridge University submissions to the IARPA OpenKWS 2016 competition. The results show that confusion network and lattice-based BiRNNs can provide a significant improvement in confidence estimation. 
 The standard approach to assess reliability of automatic speech transcriptions is through the use of confidence scores.  If accurate, these scores provide a flexible mechanism to flag  transcription errors for upstream and downstream applications.  One challenging type of errors that recognisers make are  deletions. These errors are not accounted for by  the standard confidence estimation schemes and are hard  to rectify in the upstream and downstream processing. High  deletion rates are prominent in limited resource  and highly mismatched training/testing conditions studied  under IARPA Babel and Material programs.  This paper looks at the use of bidirectional recurrent neural networks to yield confidence estimates in predicted  as well as deleted words. Several simple schemes are examined  for combination. To assess usefulness of this  approach, the combined confidence score is examined for  untranscribed data selection that favours transcriptions with  lower deletion errors. Experiments are conducted using IARPA  Babel/Material program languages. %The abstract should appear at the top of the left-hand column of text, about %0.5 inch  below the title area and no more than 3.125 inches  in %length.  Leave a 0.5 inch  space between the end of the abstract and the %beginning of the main text.  The abstract should contain about 100 to 150 %words, and should be identical to the abstract text submitted electronically %along with the paper cover sheet.  All manuscripts must be in English, printed %in black ink. 
 An attacker may use a variety of techniques to fool an automatic speaker verification system into accepting them as a genuine user.  Anti-spoofing methods meanwhile aim to make the system robust against such attacks. The ASVspoof 2017 Challenge focused specifically on replay attacks, with the intention of measuring the limits of replay attack detection as well as developing countermeasures against them. In this work, we propose our replay attacks detection system - Attentive Filtering Network, which is composed of an attention-based filtering mechanism that enhances feature representations in both the frequency and time domains, and a ResNet-based classifier. We show that the network enables us to visualize the automatically acquired feature representations that are helpful for spoofing detection. Attentive Filtering Network attains an evaluation EER of 8.99$\%$ on the ASVspoof 2017 Version 2.0 dataset. With system fusion, our best system further obtains a 30$\%$ relative improvement over the ASVspoof 2017 enhanced baseline system.  % ALBERTO -- I did some minor writing modifications and I removed citations: The abstract is supposed to be publishable stand-alone. % ALBERTO proposal -- I would add 1 or 2 sentences about the proposed method. Right now the abstract is too general: any paper related with ASVspoof could fit in it changing one sentence.   
 We introduce a new method \ourmethod\ for learning knowledge graph embeddings that effectively captures contextual cues and dependencies among entities and relations. First, we note that short paths on knowledge graphs comprising of chains of entities and relations can encode valuable information regarding their contextual usage. We operationalize this notion by representing knowledge graphs not as a collection of triples but as a collection of entity-relation chains, and learn embeddings for entities and relations using deep neural models that capture such contextual usage. In particular, our model is based on Bi-Directional LSTMs and learn deep representations of entities and relations from constructed entity-relation chains. We show that these representations can very easily be incorporated into existing models to significantly advance the state of the art on several knowledge graph prediction tasks like link prediction, triple classification, and missing relation type prediction .   
     Research has shown that neural models implicitly encode linguistic features, but there has been no research showing  these encodings arise as the models are trained. We present the first study on the learning dynamics of neural language models, using a simple and flexible analysis method called Singular Vector Canonical Correlation Analysis , which enables us to compare learned representations across time and across models, without the need to evaluate directly on annotated data. We probe the evolution of syntactic, semantic, and topic representations and find that part-of-speech is learned earlier than topic; that recurrent layers become more similar to those of a tagger during training; and embedding layers less similar. Our results and methods could inform better learning algorithms for NLP models, possibly to incorporate linguistic information more effectively.     % Using this method, we identify differences in how locally-informed patterns  and globally-informed patterns  are learned over the course of training.      % We also analyze differences between different modules in how they relate to various tag structures over time. 
 The encoder-decoder is the typical framework for Neural Machine Translation , and different structures have been developed for improving the translation performance. Transformer is one of the most promising structures, which can leverage the self-attention mechanism to capture the semantic dependency from global view. However, it cannot distinguish the relative position of different tokens very well, such as the tokens located at the left or right of the current token, and cannot focus on the local information around the current token either. To alleviate these problems, we propose a novel attention mechanism named Hybrid Self-Attention Network  which accommodates some specific-designed masks for self-attention network to extract various semantic, such as the global/local information, the left/right part context. Finally, a squeeze gate is introduced to combine different kinds of SANs for fusion. Experimental results on three machine translation tasks show that our proposed framework outperforms the Transformer baseline significantly and achieves superior results over state-of-the-art NMT systems. 
 When reading a text, it is common to become stuck on unfamiliar words and phrases, such as polysemous words with novel senses, rarely used idioms, internet slang, or emerging entities. If we humans cannot figure out the meaning of those expressions from the immediate  context, we consult dictionaries for definitions or search documents or the web to find other  context to help in interpretation. Can machines help us do this work? Which type of context is more important for machines to solve the problem? To answer these questions, we undertake a task of describing a given phrase in natural language based on its local and global contexts. To solve this task, we propose a neural description model that consists of two context encoders and a description decoder. In contrast to the existing methods for non-standard English explanation~ and definition generation~, our model appropriately takes important clues from  local and global contexts. Experimental results on three existing datasets  and a dataset newly created from Wikipedia demonstrate the effectiveness of our method over previous work. 
 Cross-lingual word embeddings aim to capture common linguistic regularities of different languages, which benefit various downstream tasks ranging from machine translation to transfer learning. Recently, it has been shown that these embeddings can be effectively learned by aligning two disjoint monolingual vector spaces through a linear transformation . In this work, we focus on learning such a word mapping without any supervision signal. Most previous work of this task adopts parametric metrics to measure distribution differences, which typically requires a sophisticated alternate optimization process, either in the form of  or intermediate . This alternate optimization process is relatively hard and unstable. In order to avoid such sophisticated alternate optimization, we propose to learn unsupervised word mapping by directly maximizing the mean discrepancy between the distribution of transferred embedding and target embedding. Extensive experimental results show that our proposed model outperforms competitive baselines by a large margin.  
 In this study, we  first investigate a novel capsule network with dynamic routing for linear time Neural  Machine Translation , referred as CapsNMT. CapsNMT uses an aggregation mechanism to map the source sentence into a matrix with pre-determined size, and then applys a deep LSTM network to decode the target sequence from the source representation. Unlike the previous work  to store the  source sentence with a passive and bottom-up way, the dynamic routing policy encodes the source sentence with an iterative process to decide the credit attribution between nodes from lower and higher layers. CapsNMT has two core properties: it runs in time that is linear in the length of the sequences and provides a more flexible way to aggregate the part-whole information of the source sentence. On WMT14 English-German task and a larger WMT14 English-French task, CapsNMT achieves comparable results with the Transformer system. We also devise  new hybrid architectures intended to combine the strength of CapsNMT and the RNMT model. Our hybrid models obtain state-of-the-arts results on both benchmark datasets. To the best of our knowledge, this is the first work that capsule networks have been empirically investigated for  sequence to sequence problems.\footnote{The work is partially done when the first author worked at Tencent.} 
  Suggestion mining is increasingly becoming an important task along with sentiment analysis. In today's cyberspace world, people not only express their sentiments and dispositions towards some entities or services, but they also spend considerable time sharing their experiences and advice to fellow customers and the product/service providers with two-fold agenda: helping fellow customers who are likely to share a similar experience, and motivating the producer to bring specific changes in their offerings which would be more appreciated by the customers.  %The processing and natural language understanding of the recommendations, tips, feedback and suggestions emanating from users in online media thus has multiple use cases for both the fellow users as well as the product/service providers.  In our current work, we propose a hybrid deep learning model to identify whether a review text contains any suggestion. The model %for classifying a review text into whether that  employs semi-supervised learning to leverage the useful information from the large amount of unlabeled data. %algorithm to extract the mentions of suggestions from the customer reviews. We evaluate the performance of our proposed model on a benchmark customer review dataset, comprising of the reviews of Hotel and Electronics domains. Our proposed approach shows the F-scores of $65.6\%$ and $65.5\%$ for the Hotel and Electronics review datasets, respectively. These performances are significantly better compared to %Our experimental results show the significant performance gains over the  the existing state-of-the-art system. %the  % We make a comparative analysis of the the performance of deep learning architectures enhanced with simple Semi Supervised Learning algorithm like self training against the existing state of the art,    %We make a comparative analysis of our system%\footnote{We specifically only extracted the mentions of suggestions from customers to other fellow customers} performance with the existing state of the art work. %We achieved the F-scores of  $65.6\%$ and $65.5\%$ for the Hotel and Electronics review datasets respectively. Our experimental results show the significant performance gains over the existing state-of-the-art-work. % , and we also perform a comprehensive analysis for demonstrating the superiority of our methods. 
 Transfer learning approaches for Neural Machine Translation  trains a NMT model on an assisting language-target language pair  which is later fine-tuned for the source language-target language pair of interest , with the target language being the same. In many cases, the assisting language has a different word order from the source language. We show that divergent word order adversely limits the benefits from transfer learning when little to no parallel corpus between the source and target language is available. To bridge this divergence, we propose to pre-order the assisting language sentences to match the word order of the source language and train the parent model. Our experiments on many language pairs show that bridging the word order gap leads to major improvements in the translation quality in extremely low-resource scenarios. 
  We propose Dual-CES -- a novel unsupervised, query-focused, multi-document extractive summarizer. Dual-CES is designed to better handle the tradeoff between saliency and focus in summarization. To this end, Dual-CES employs a two-step dual-cascade optimization approach with saliency-based pseudo-feedback distillation. Overall, Dual-CES significantly outperforms all other state-of-the-art unsupervised alternatives.  Dual-CES is even shown to be able to outperform strong supervised summarizers. 
 Sequence generation with reinforcement learning  has received significant attention recently. However, a challenge with such methods is the sparse-reward problem in the RL training process, in which a scalar guiding signal is often only available after an entire sequence has been generated. This type of sparse reward tends to ignore the global structural information of a sequence, causing generation of sequences that are semantically inconsistent. In this paper, we present a model-based RL approach to overcome this issue. Specifically, we propose a novel guider network to model the sequence-generation environment, which can assist next-word prediction and provide intermediate rewards for generator optimization. Extensive experiments show that the proposed method leads to improved performance for both unconditional and conditional sequence-generation tasks. 
    Building an accurate automatic speech recognition  system requires a large dataset that contains many hours of labeled speech samples produced by a diverse set of speakers. The lack of such open free datasets is one of the main issues preventing advancements in ASR research. To address this problem, we propose to augment a natural speech dataset with synthetic speech. We train very large end-to-end neural speech recognition models using the LibriSpeech dataset augmented with synthetic speech. These new models achieve state of the art Word Error Rate  for character-level based models without an external language model.     
  Machine translation systems based on deep neural networks are expensive to train. Curriculum learning aims to address this issue by choosing the order in which samples are presented during training to help train better models faster. We adopt a probabilistic view of curriculum learning, which lets us flexibly evaluate the impact of curricula design, and perform an extensive exploration on a German-English translation task. Results show that it is possible to improve convergence time at no loss in translation quality. However, results are highly sensitive to the choice of sample difficulty criteria, curriculum schedule and other hyperparameters. %when training until convergence, curriculum learning shows little benefit over the baseline random ordering. % \marine{Updated abstract} 
 We address the problem of abstractive summarization in two directions: proposing a novel dataset and a new model. First, we collect Reddit TIFU dataset, consisting of 120K posts from the online discussion forum Reddit. We use such informal crowd-generated posts as text source, in contrast with existing datasets that mostly use formal documents as source such as news articles. Thus, our dataset could less suffer from some biases that key sentences usually locate at the beginning of the text and favorable summary candidates are already inside the text in similar forms.  Second, we propose a novel abstractive summarization model named multi-level memory networks ,  equipped with multi-level memory to store the information of text from different levels of abstraction. With quantitative evaluation and user studies via Amazon Mechanical Turk, we show the Reddit TIFU dataset is highly abstractive and the MMN outperforms the state-of-the-art summarization models. 
 We investigate the impact of search strategies in neural dialogue modeling. We first compare two standard search algorithms, greedy and beam search, as well as our newly proposed iterative beam search which produces a more diverse set of candidate responses. We evaluate these strategies in realistic full conversations with humans and propose a model-based Bayesian calibration to address annotator bias. These conversations are analyzed using two automatic metrics: log-probabilities assigned by the model and utterance diversity. Our experiments reveal that better search algorithms lead to higher rated conversations. However, finding the optimal selection mechanism  to choose from a more diverse set of candidates is still an open question.  
 In recent years, we have witnessed a dramatic shift towards techniques driven by neural networks for a variety of NLP tasks. Undoubtedly, neural language models  have reduced perplexity by impressive amounts. This progress, however, comes at a substantial cost in performance, in terms of inference latency and energy consumption, which is particularly of concern in deployments on mobile devices. This paper, which examines the quality--performance tradeoff of various language modeling techniques, represents to our knowledge the first to make this observation. We compare state-of-the-art NLMs with ``classic'' Kneser-Ney  LMs in terms of energy usage, latency, perplexity, and prediction accuracy using two standard benchmarks. On a Raspberry Pi, we find that orders of increase in  latency and energy usage correspond to less change in  perplexity, while the difference is much less pronounced on  a desktop.  
 In Word Sense Disambiguation , the predominant approach generally involves a supervised system trained on sense annotated corpora. The limited quantity of such corpora however restricts the coverage and the performance of these systems. In this article, we propose a new method that solves these issues by taking advantage of the knowledge present in WordNet, and especially the hypernymy and hyponymy relationships between synsets, in order to reduce the number of different sense tags that are necessary to disambiguate all words of the lexical database. Our method leads to state of the art results on most WSD evaluation tasks, while improving the coverage of supervised systems, reducing the training time and the size of the models, without additional training data. In addition, we exhibit results that significantly outperform the state of the art when our method is combined with an ensembling technique and the addition of the WordNet Gloss Tagged as training corpus. % 
  The overall objective of `social' dialogue systems is to support engaging, entertaining, and lengthy conversations on a wide variety of topics, including social chit-chat. Apart from raw dialogue data, user-provided ratings are the most common signal used to train such systems to produce engaging responses. In this paper we show that social dialogue systems can be trained effectively from raw unannotated data. Using a dataset of real conversations collected in the 2017 Alexa Prize challenge, we developed a neural ranker\footnote{Code and trained models are available at \url{https://github.com/WattSocialBot/alana_learning_to_rank}} for selecting `good' system responses to user utterances, i.e.\ responses which are likely to lead to long and engaging conversations. We show that  our neural ranker consistently outperforms several strong baselines when trained to optimise for user ratings;  when trained on larger amounts of data and only using conversation length as the objective, the ranker performs better than the one trained using ratings~-- ultimately reaching a Precision@1 of $0.87$. This advance will make data collection for social conversational agents simpler and less expensive in the future. 
 This paper carries out an empirical analysis of various dropout techniques for language modelling, such as Bernoulli dropout, Gaussian dropout, Curriculum Dropout, Variational Dropout and Concrete Dropout. Moreover, we propose an extension of variational dropout to concrete dropout and curriculum dropout with varying schedules. We find these extensions to perform well when compared to standard dropout approaches, particularly variational curriculum dropout with a linear schedule. Largest performance increases are made when applying dropout on the decoder layer. Lastly, we analyze where most of the errors occur at test time as a post-analysis step to determine if the well-known problem of compounding errors is apparent and to what end do the proposed methods mitigate this issue for each dataset. We report results on a 2-hidden layer LSTM, GRU and Highway network with embedding dropout, dropout on the gated hidden layers and the output projection layer for each model. We report our results on Penn-TreeBank and WikiText-2 word-level language modelling datasets, where the former reduces the long-tail distribution through preprocessing and one which preserves rare words in the training and test set.    \iffalse Dropout has shown to be critical for effectively regularizing neural language models and improving out-of-sample performance. Recent work has focused solely on reporting empirical results for different regularization and optimization techniques.   suggest that using a time-fixed concrete dropout mask where the dropout probability is learned during training, results in performance improvements for  The performance gains are primarily from applying this on the decoder layer, which has the effect of mitigating compounding errors. \fi   \iffalse Learning dropout rates via a continuous relaxation over the weights allows the dropout rate to be updated. This means that it can be used to respond to compounding errors in language models.  along with their weight dropping counterparts. We also include batch and weight normalization for comparison as this can also be interpreted as activation or weight dropping. \fi    
  This paper explores the problem of ranking short social media posts with respect to user queries using neural networks. Instead of starting with a complex architecture, we proceed from the bottom up and examine the effectiveness of a simple, word-level Siamese architecture augmented with attention-based mechanisms for capturing semantic ``soft'' matches between query and post tokens.  Extensive experiments on datasets from the TREC Microblog Tracks show that our simple models not only achieve better effectiveness  than existing approaches that are far more complex or exploit a more diverse set of relevance signals, but are also much faster. Implementations of our samCNN~ models are shared with the community to support future work.\footnote{\url{https://github.com/Impavidity/samCNN}} 
  Sequence-to-Sequence  models have witnessed a notable success in generating natural conversational exchanges. Notwithstanding the syntactically well-formed responses generated by these neural network models, they are prone to be acontextual, short and generic. In this work, we introduce a Topical Hierarchical Recurrent Encoder Decoder , a novel, fully data-driven, multi-turn response generation system intended to produce contextual and topic-aware responses. Our model is built upon the basic Seq2Seq model by augmenting it with a hierarchical joint attention mechanism that incorporates topical concepts and previous interactions into the response generation. To train our model, we provide a clean and high-quality conversational dataset mined from Reddit comments. We evaluate THRED on two novel automated metrics, dubbed Semantic Similarity and Response Echo Index, as well as with human evaluation.  Our experiments demonstrate that the proposed model is able to generate more diverse and contextually relevant responses compared to the strong baselines. 
 Both research and commercial machine translation have so far neglected the importance of properly handling the spelling, lexical and grammar divergences occurring among language varieties. Notable cases are standard national varieties such as Brazilian and European Portuguese, and Canadian and European French, which popular online machine translation services are not keeping distinct. We show that an evident side effect of modeling such varieties as unique classes is the generation of inconsistent translations. In this work, we investigate the problem of training neural machine translation from English to specific pairs of language varieties, assuming both labeled and unlabeled parallel texts, and low-resource conditions. We report experiments from English to two pairs of dialects, European-Brazilian Portuguese and European-Canadian French, and two pairs of standardized varieties, Croatian-Serbian and Indonesian-Malay. We show significant BLEU score improvements over baseline systems when translation into similar languages is learned as a multilingual task with shared representations.   
 Although neural machine translation has made significant progress recently, how to integrate multiple overlapping, arbitrary prior knowledge sources remains a challenge. In this work, we propose to use posterior regularization to provide a general framework for integrating prior knowledge into neural machine translation. We represent prior knowledge sources as features in a log-linear model, which guides the learning process of the neural translation model. Experiments on Chinese-English translation show that our approach leads to significant improvements. \footnote{The source code is available at \url{https://github.com/Glaceon31/PR4NMT.git}} 
 Natural language processing is heavily Anglo-centric, while the demand for models that work in languages other than English is greater than ever. Yet, the task of transferring a model from one language to another can be expensive in terms of annotation costs, engineering time and effort. In this paper, we present a general framework for easily and effectively transferring neural models from English to other languages. The framework, which relies on task representations as a form of weak supervision, is model and task agnostic, meaning that many existing neural architectures can be ported to other languages with minimal effort. The only requirement is unlabeled parallel data, and a loss defined over task representations. We evaluate our framework by transferring an English sentiment classifier to three different languages. On a battery of tests, we show that our models outperform a number of strong baselines and rival state-of-the-art results, which rely on more complex approaches and significantly more resources and data. Additionally, we find that the framework proposed in this paper is able to capture semantically rich and meaningful representations across languages, despite the lack of direct supervision. 
 We  propose a method to transfer knowledge across neural machine translation  models by means of a shared dynamic vocabulary. Our approach allows to extend an initial model for a given language pair to cover new languages  by adapting its vocabulary  as long as new data become available . The parameter transfer mechanism is evaluated in two scenarios: i) to adapt a trained single language NMT system to work with a new language pair and  ii) to continuously add new language pairs to grow to a multilingual NMT system. In both the scenarios our goal is to improve the translation performance, while minimizing the training convergence time. Preliminary experiments spanning five languages with different training data sizes  show a significant performance gain ranging from +$3.85$ up to +$13.63$ BLEU in different language directions.     
 % Neural machine translation  models learn representations containing substantial linguistic information. However, it is not clear if such information is fully distributed or if some of it  can be attributed to individual neurons.  We develop  unsupervised methods for discovering important neurons in NMT models. Our methods rely on the intuition that different models   learn similar properties, and do not require any costly external supervision.  We show experimentally that translation quality depends on the discovered neurons,  and find that many of them capture common linguistic phenomena.  Finally, we show how to control NMT translations in predictable ways, by modifying  activations of  individual neurons.     % 
 In this paper we address a task of {, a representative phrases  %in plain text  %for a particular relation.  %%%%%%%%%%%%%%%% %Despite the fact that relation mentions can be valuable for many NLP applications such as relation extraction and question answering, detecting relation mentions remains several challenges.  Despite its significance and value in many downstream applications, %including relation extraction and question answering this task is less studied on noisy data. %%% %The major challenge is caused by the lack of word-level annotation, which is expected to specify phrases that mention the relation. The task is even more challenging when handling noisy sentences that do not describe the relation at all. The major challenges exists in 1) the lack of annotation on mention phrases, and more severely, 2) handling noisy sentences which do not express a relation at all. %% To address the two challenges, we formulate the task as a semi-Markov decision process and propose a novel hierarchical reinforcement learning model. Our model consists of a top-level sentence selector to remove noisy sentences, a low-level mention extractor to extract relation mentions, and a reward estimator to provide signals to guide data denoising and mention extraction without explicit annotations.  		%% Experimental results show that our model is effective to extract relation mentions from noisy data.  
  Clickbaits are catchy headlines that are frequently used by social media outlets in order to allure its viewers into clicking them and thus leading them to dubious content. Such venal schemes thrive on exploiting the curiosity of naive social media users, directing traffic to web pages that won't be visited otherwise. In this paper, we propose a novel, semi-supervised classification based approach, that employs attentions sampled from a Gumbel-Softmax distribution to distill contexts that are fairly important in clickbait detection. An additional loss over the attention weights is used to encode prior knowledge. Furthermore, we propose a confidence network that enables learning over weak labels and improves robustness to noisy labels. We show that with merely 30\% of strongly labeled samples we can achieve over 97\% of the accuracy, of current state of the art methods in clickbait detection.   
  A ubiquitous task in processing electronic medical data is the assignment of standardized codes representing diagnoses and/or procedures to free-text documents such as medical reports. This is a difficult natural language processing task that requires parsing long, heterogeneous documents and selecting a set of appropriate codes from tens of thousands of possibilities---many of which have very few positive training samples. We present a deep learning system that advances the state of the art for the MIMIC-III dataset, achieving a new best micro F1-measure of 55.85\%, significantly outperforming the previous best result . We achieve this through a number of enhancements, including two major novel contributions: multi-view convolutional channels, which effectively learn to adjust kernel sizes throughout the input; and attention regularization, mediated by natural-language code descriptions, which helps overcome sparsity for thousands of uncommon codes. These and other modifications are selected to address difficulties inherent to both automated coding specifically and deep learning generally. Finally, we investigate our accuracy results in detail to individually measure the impact of these contributions and point the way towards future algorithmic improvements. 
 Implicit discourse relation classification is one of the most difficult steps in discourse parsing. The difficulty stems from the fact that the coherence relation must be inferred based on the content of the discourse relational arguments. Therefore, an effective encoding of the relational arguments is of crucial importance.    We here propose a new model for implicit discourse relation classification, which consists of a classifier, and a sequence-to-sequence model which is trained to generate a representation of the discourse relational arguments by trying to predict the relational arguments including a suitable implicit  connective. Training is possible because such implicit connectives have been annotated as part of the PDTB corpus. Along with a memory network, our model could generate more refined representations for the task. And on the now standard 11-way classification, our method outperforms the previous state of the art systems on the PDTB benchmark on multiple settings including cross validation.   %   Using cross-validation, we show that further improvements can be obtained by using additional data from explicitated connectives during translation. 
 Extreme multi-label text classification  is an important problem in the  era of { .  
  For many text classification tasks, there is a major problem posed by the lack of labeled data in a target domain. Although classifiers for a target domain can be trained on labeled text data from a related source domain, the accuracy of such classifiers is usually lower in the cross-domain setting. Recently, string kernels have obtained state-of-the-art results in various text classification tasks such as native language identification or automatic essay scoring. Moreover, classifiers based on string kernels have been found to be robust to the distribution gap between different domains. In this paper, we formally describe an algorithm composed of two simple yet effective transductive learning approaches to further improve the results of string kernels in cross-domain settings. %The first approach is based on interpreting the pairwise string kernel similarities between samples in the training set and samples in the test set as features. Our second approach is a simple self-training method based on two learning iterations. In the first iteration, a classifier is trained on the training set and tested on the test set, as usual. In the second iteration, a number of test samples  are added to the training set for another round of training.  By adapting string kernels to the test set without using the ground-truth test labels, we report significantly better accuracy rates in cross-domain English polarity classification. \vspace*{-0.2cm}  
    RNN language models have achieved state-of-the-art results on various tasks, but what exactly they are representing about syntax is as yet unclear. Here we investigate whether RNN language models learn humanlike word order preferences in syntactic alternations. We collect language model surprisal scores for controlled sentence stimuli exhibiting major syntactic alternations in English: heavy NP shift, particle shift, the dative alternation, and the genitive alternation. We show that RNN language models reproduce human preferences in these alternations based on NP length, animacy, and definiteness. We collect human acceptability ratings for our stimuli, in the first acceptability judgment experiment directly manipulating the predictors of syntactic alternations. We show that the RNNs' performance is similar to the human acceptability ratings and is not matched by an $n$-gram baseline model. Our results show that RNNs learn the abstract features of weight, animacy, and definiteness which underlie soft constraints on syntactic alternations.    
 Pattern-based labeling methods have achieved promising results in alleviating the inevitable labeling noises of distantly supervised neural relation extraction. However, these methods require significant expert labor to write relation-specific patterns, which makes them too sophisticated to generalize quickly. To ease the labor-intensive workload of pattern writing and enable the quick generalization to new relation types, we propose a neural pattern diagnosis framework, DIAG-NRE, that can automatically summarize and refine high-quality relational patterns from noise data with human experts in the loop. To demonstrate the effectiveness of DIAG-NRE, we apply it to two real-world datasets and present both significant and interpretable improvements over state-of-the-art methods. Source codes and data can be found at \url{https://github.com/thunlp/DIAG-NRE}. % \footnote{Codes and data can be found at \url{https://github.com/dolphin-zs/DIAG-NRE}.} 
 In this paper, we propose  Neural Phrase-to-Phrase Machine Translation . Our model uses a phrase attention mechanism to discover relevant input  segments that are used by a decoder to generate output  phrases. We also design an efficient dynamic programming algorithm to decode segments that allows the model to be trained faster than the existing neural phrase-based machine translation method by . Furthermore, our method can naturally integrate with external phrase dictionaries during decoding. Empirical experiments show that our method achieves comparable performance with the state-of-the art methods on benchmark datasets. However, when the training and testing data are from different distributions or domains, our method performs better. 
 This paper describes the CIS slot filling system for the TAC Cold Start evaluations 2015. It extends and improves the system we have built for the evaluation last year. This paper mainly describes the changes to our last year's system. Especially, it focuses on the coreference and classification component. For coreference, we have performed several analysis and prepared a resource to simplify our end-to-end system and improve its runtime. For classification,  we propose to use neural networks. We have trained convolutional and recurrent neural networks and combined them with traditional evaluation methods,  namely patterns and support vector machines. Our runs for the 2015 evaluation have been designed to directly assess the effect of each network on the end-to-end performance of the system. The CIS system achieved rank 3 of all slot filling systems participating in the task. 
 We consider the problem of learning knowledge graph  embeddings for entity alignment . Current methods  use the embedding models mainly focusing on triple-level learning, which lacks the ability of capturing long-term dependencies existing in KGs. Consequently, the embedding-based EA methods heavily rely on the amount of prior  alignment, due to the identity information in the prior alignment cannot be efficiently propagated from one KG to another. In this paper, we propose RSN4EA , which leverages biased random walk sampling for generating long paths across KGs and models the paths with a novel recurrent skipping network . RSN integrates the conventional recurrent neural network  with residual learning and can largely improve the convergence speed and performance with only a few more parameters. We evaluated RSN4EA on a series of datasets constructed from real-world KGs. Our experimental results showed that it outperformed a number of state-of-the-art embedding-based EA methods and also achieved comparable performance for KG completion. 
 Keyword Spotting  provides the start signal of ASR problem, and thus it is essential to ensure a high recall rate. However, its real-time property requires low computation complexity. This contradiction inspires people to find a suitable model which is small enough to perform well in multi environments.  To deal with this contradiction, we implement the Hierarchical Neural Network, which is proved to be effective in many speech recognition problems. HNN outperforms traditional DNN and CNN even though its model size and computation complexity are slightly less. Also, its simple topology structure makes easy to deploy on any device.  
  Sentence embedding is an effective feature representation for most deep learning-based NLP tasks. One prevailing line of methods is using recursive latent tree-structured networks to embed sentences with task-specific structures. However, existing models have no explicit mechanism to emphasize task-informative words in the tree structure. To this end, we propose an Attentive Recursive Tree model , where the words are dynamically located according to their importance in the task. Specifically, we construct the latent tree for a sentence in a proposed important-first strategy, and place more attentive words nearer to the root; thus, AR-Tree can inherently emphasize important words during the bottom-up composition of the sentence embedding. We propose an end-to-end reinforced training strategy for AR-Tree, which is demonstrated to consistently outperform, or be at least comparable to, the state-of-the-art sentence embedding methods on three sentence understanding tasks. 
   Code-switching is about dealing with alternative languages in speech or text. It is partially speaker-dependent and domain-related, so completely explaining the phenomenon by linguistic rules is challenging. Compared to most monolingual tasks, insufficient data is an issue for code-switching. To mitigate the issue without expensive human annotation, we proposed an unsupervised method for code-switching data augmentation. By utilizing a generative adversarial network, we can generate intra-sentential code-switching sentences from monolingual sentences. We applied the proposed method on two corpora, and the result shows that the generated code-switching sentences improve the performance of code-switching language models. 
 We propose DeepChannel, a robust, data-efficient, and interpretable neural model for extractive document summarization.  Given any document-summary pair, we estimate a salience score, which is modeled using an attention-based deep neural network, to represent the salience degree of the summary for yielding the document. We devise a contrastive training strategy to learn the salience estimation network, and then use the learned salience score as a guide and iteratively extract the most salient sentences from the document as our generated summary. In experiments, our model not only achieves state-of-the-art ROUGE scores on CNN/Daily Mail dataset, but also shows strong robustness in the out-of-domain test on DUC2007 test set.  Moreover, our model reaches a ROUGE-1 F-1 score of 39.41 on CNN/Daily Mail test set with merely $1 / 100$ training set, demonstrating a tremendous data efficiency.  
  We describe the Universitat d'Alacant submissions to the word- and sentence-level machine translation  quality estimation  shared task at WMT 2018. Our approach to word-level MT QE builds on previous work to mark the words in the machine-translated sentence as OK or BAD, and is extended to determine if a word or sequence of words need to be inserted in the gap after each word. Our sentence-level submission simply uses the edit operations predicted by the word-level approach to approximate TER. The method presented ranked first in the sub-task of identifying insertions in gaps for three out of the six datasets, and second in the rest of them. 
 Rapidly developed neural models have achieved competitive performance in Chinese word segmentation  as their traditional counterparts. However, most of methods encounter the computational inefficiency especially for long sentences because of the increasing model complexity and slower decoders. This paper presents a simple neural segmenter which directly labels the gap existence between adjacent characters to alleviate the existing drawback. Our segmenter is fully end-to-end and capable of performing segmentation very fast. We also show a performance difference with different tag sets. The experiments show that our segmenter can provide comparable performance with state-of-the-art. 
 Long short-term memory  units recently experienced much attention due to their performance in various natural language processing tasks. While LSTMs are designed to capture sequential correlations, language is composed of tree structures. In this study, we address the question, if LSTMs can learn hierarchical structures. We evaluate this with a bracket prediction task with two types of brackets. Although there are only 4 rules in this context-free grammar , this language is as hard to capture as any CFG. We observe that the model requires exponential memory, while theoretically sub-linear memory would suffice. And still the model does more than memorizing the input. It learns effectively how to distinguish between relevant and irrelevant information. Additionally, we observe, that the model does not generalize well. This lets us conclude, that LSTMs cannot learn the underlying rules and it is suggested, that the good overall performance is reached by an efficient way of evaluating nuisance variables. LSTMs are a way to quickly reach good results for natural language tasks, but to understand and generate natural language, one has to explore other concepts, which can make use of the structural nature of natural language. 
 Although promising results have been achieved in video captioning, existing models are limited to the fixed inventory of activities in the training corpus, and do not generalize to open vocabulary scenarios. Here we introduce a novel task, , that aims at describing out-of-domain videos of unseen activities.  Videos of different activities usually require different captioning strategies in many aspects, i.e. word selection, semantic construction, and style expression etc, which poses a great challenge to depict novel activities without paired training data. But meanwhile, similar activities share some of those aspects in common.  Therefore, We propose a principled Topic-Aware Mixture of Experts  model for zero-shot video captioning, which learns to compose different experts based on different topic embeddings, implicitly transferring the knowledge learned from seen activities to unseen ones. Besides, we leverage external topic-related text corpus to construct the topic embedding for each activity, which embodies the most relevant semantic vectors within the topic. Empirical results not only validate the effectiveness of our method in utilizing semantic knowledge for video captioning, but also show its strong generalization ability when describing novel activities.\footnote{Code is released at \url{ https://github.com/eric-xw/Zero-Shot-Video-Captioning}} 
