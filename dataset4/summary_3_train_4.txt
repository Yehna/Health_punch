 Generating formal-language programs represented by relational tuples, such as Lisp programs or mathematical operations, to solve problems stated in natural language is a challenging task because it requires explicitly capturing discrete symbolic structural information implicit in the input.  However, most general neural sequence models do not explicitly capture such structural information, limiting their performance on these tasks.  In this paper, we propose a new encoder-decoder model based on a structured neural representation, {}ensor Product Representations }, for mapping Natural-language problems to Formal-language solutions, called TP-N2F.  The encoder of TP-N2F employs TPR `binding' to encode natural-language symbolic structure in vector space and the decoder uses TPR `unbinding' to generate, in symbolic space, a sequential program represented by relational tuples, each consisting of a relation  and a number of arguments.  TP-N2F considerably outperforms LSTM-based seq2seq models on two benchmarks and creates new state-of-the-art results.  Ablation studies show that improvements can be attributed to the use of structured TPRs explicitly in both the encoder and decoder.  Analysis of the learned structures shows how TPRs enhance the interpretability of TP-N2F.  %Program synthesis represented by relational tuples, such as Lisp programs or mathematical operations, from natural-language input is a challenging task because it requires explicitly capturing discrete symbolic structural information implicit in the input. Most state-of-the-art neural sequence models do not explicitly capture such structural information, limiting their performance on these tasks. In this paper, we propose a new encoder-decoder model based on Tensor Product Representations  for formal-language program synthesis from natural-language, called . The encoder of TP-N2F employs TPR `binding' to encode natural-language symbolic structure in vector space and the decoder uses TPR `unbinding' to generate, in symbolic space, a sequential program represented by relational tuples, each consisting of a relation  and a number of arguments. TP-N2F considerably outperforms LSTM-based seq2seq models on two benchmarks and creates new state-of-the-art results. Ablation studies show that improvements can be attributed to the use of TPRs in both the encoder and decoder. Analysis of the learned role-filler structures shows how TPRs enhance the interpretability of TP-N2F.  
 Recently, researches have explored the graph neural network  techniques on text classification, since GNN does well in handling complex structures and preserving global information.  However, previous methods based on GNN are mainly faced with the practical problems of fixed corpus level graph structure which do not support online testing and high memory consumption.  To tackle the problems, we propose a new GNN based model that builds graphs for each input text with global parameters sharing instead of a single graph for the whole corpus. This method removes the burden of dependence between an individual text and entire corpus which support online testing, but still preserve global information. Besides, we build graphs by much smaller windows in the text, which not only extract more local features but also significantly reduce the edge numbers as well as memory consumption.  Experiments show that our model outperforms existing models on several text classification datasets even with consuming less memory.    
   Neural networks are known to be data hungry and domain sensitive, but it is nearly impossible to obtain large quantities of labeled data for every domain we are interested in.   This necessitates the use of domain adaptation strategies.    One common strategy encourages generalization by aligning the global distribution statistics between source and target domains, but one drawback is that the statistics of different domains or tasks are inherently divergent, and smoothing over these differences can lead to sub-optimal performance.    In this paper, we propose the framework of {.} 
  Leveraging the visual modality effectively for Neural Machine Translation  remains an open problem in computational linguistics. Recently,  posit that the observed gains are limited mainly due to the very simple, short, repetitive sentences of the Multi30k dataset , which renders the source text sufficient for context. In this work, we further investigate this hypothesis on a new large scale multimodal Machine Translation  dataset, How2, which has 1.57 times longer mean sentence length than Multi30k and no repetition. We propose and evaluate three novel fusion techniques, each of which is designed to ensure the utilization of visual context at different stages of the Sequence-to-Sequence transduction pipeline, even under full linguistic context. However, we still obtain only marginal gains under full linguistic context and posit that visual embeddings extracted from deep vision models  do not lend themselves to increasing the discriminativeness between the vocabulary elements at token level prediction in NMT. We demonstrate this qualitatively by analyzing attention distribution and quantitatively through Principal Component Analysis, arriving at the conclusion that it is the quality of the visual embeddings rather than the length of sentences, which need to be improved in existing MMT datasets.  
     Recent advances in reinforcement learning have shown its potential to tackle complex real-life tasks. However, as the dimensionality of the task increases, reinforcement learning methods tend to struggle. To overcome this, we explore methods for representing the semantic information embedded in the state. While previous methods focused on information in its raw form , we propose to represent the state using natural language. Language can represent complex scenarios and concepts, making it a favorable candidate for representation. Empirical evidence, within the domain of ViZDoom, suggests that natural language based agents are more robust, converge faster and perform better than vision based agents, showing the benefit of using natural language representations for reinforcement learning.      
 Neural Machine Translation  models have been proved strong when translating clean texts, but they are very sensitive to noise in the input. Improving NMT models robustness can be seen as a form of ``domain'' adaption to noise. The recently created Machine Translation on Noisy Text task corpus provides noisy-clean parallel data for a few language pairs, but this data is very limited in size and diversity. The state-of-the-art approaches are heavily dependent on large volumes of back-translated data.  This paper has two main contributions: Firstly, we propose new data augmentation methods to extend limited noisy data and further improve NMT robustness to noise while keeping the models small. Secondly, we explore the effect of utilizing noise from external data in the form of speech transcripts and show that it could help robustness. 
  Semantic role labeling  involves extracting propositions  from natural language sentences. State-of-the-art SRL models rely on powerful encoders  and do not model non-local interaction between arguments. We propose a new approach to modeling these interactions while maintaining efficient inference. Specifically, we use  Capsule Networks : each proposition is encoded as a tuple of  capsules, one capsule per argument type . These tuples serve as embeddings of entire propositions.   In every network layer, the capsules interact with each other and with representations of words in the sentence.  Each iteration results in updated proposition embeddings and updated predictions about the SRL structure. Our model substantially outperforms the non-refinement baseline model on all 7 CoNLL-2019 languages and achieves state-of-the-art results on 5 languages  for dependency SRL. We analyze the types of mistakes corrected by the refinement procedure. For example,  each role is typically  filled with at most one argument. Whereas enforcing this approximate constraint is not useful with the modern SRL system, iterative procedure corrects the mistakes by capturing this intuition in a flexible and context-sensitive way.\footnote{Code:  https://github.com/DalstonChen/CapNetSRL.}       %Previous state-of-the-art dependency semantic role labeling models have limited interactions between arguments, leading to independent argument prediction. In this paper, we employ capsule network to encode the interactions between arguments for each predicate. We represent each argument role candidate as a capsule to encode more information. Capsules interact and collaborate from each other via capsule network layer. To better incorporate more interaction globally, we further introduce a global node to capture more high level signals and each capsule exchanges information with global node. Experiment results show the effectiveness of our model. 
    Named Entity Recognition  and Relation Extraction  are essential tools in distilling knowledge from biomedical literature. This paper presents our findings from participating in BioNLP Shared Tasks 2019. We addressed Named Entity Recognition including nested entities extraction, Entity Normalization and Relation Extraction. Our proposed approach of Named Entities can be generalized to different languages and we have shown it's effectiveness for English and Spanish text. We investigated linguistic features, hybrid loss including ranking and Conditional Random Fields , multi-task objective and token-level ensembling strategy to improve NER. We employed dictionary based fuzzy and semantic search to perform Entity Normalization. Finally, our RE system employed Support Vector Machine  with linguistic features.      Our NER submission  ranked first in { and showed competitive performance on {. Our RE system ranked first in the {.    
   We propose algorithms to train production-quality n-gram   language models using federated learning. Federated learning is a distributed   computation platform that can be used to train global models for portable   devices such as smart phones. Federated learning is especially relevant for   applications handling privacy-sensitive data, such as virtual keyboards,   because training is performed without the users' data ever leaving their   devices. While the principles of federated learning are fairly generic, its   methodology assumes that the underlying models are neural networks. However,   virtual keyboards are typically powered by n-gram language models for latency   reasons.    We propose to train a recurrent neural network language model using   the decentralized FederatedAveraging algorithm and to   approximate this federated model server-side with an n-gram model   that can be deployed to devices for fast inference. Our technical   contributions include ways of handling large vocabularies,   algorithms to correct capitalization errors in user data, and   efficient finite state transducer algorithms to convert word   language models to word-piece language models and vice versa. The   n-gram language models trained with federated learning are compared   to n-grams trained with traditional server-based algorithms using   A/B tests on tens of millions of users of a virtual keyboard.   Results are presented for two languages, American English and   Brazilian Portuguese. This work demonstrates that high-quality   n-gram language models can be trained directly on client mobile   devices without sensitive training data ever leaving the devices. 
 Among the six challenges of neural machine translation  coined by , rare-word problem is considered the most severe one, especially in translation of low-resource languages. In this paper, we propose three solutions to address the rare words in  neural machine translation  systems. First, we enhance source context to predict the target words by connecting directly the source embeddings to the output of the attention component in NMT. Second, we propose an algorithm to learn morphology of unknown words for English in supervised way in order to minimize the adverse effect of rare-word problem. Finally, we exploit synonymous relation from the WordNet to overcome out-of-vocabulary  problem of NMT. We evaluate our approaches on two low-resource language pairs: English-Vietnamese and Japanese-Vietnamese. In our experiments, we have achieved significant improvements of up to roughly +1.0 BLEU points in both language pairs.  
 Generative seq2seq dialogue systems are trained to predict the next word in dialogues that have already occurred. They can learn from large unlabeled conversation datasets, build a deep understanding of conversational context, and generate a wide variety of responses. This flexibility comes at the cost of control. Undesirable responses in the training data will be reproduced by the model at inference time, and longer generations often don't make sense. Instead of generating responses one word at a time, we train a classifier to choose from a predefined list of full responses. The classifier is trained on  pairs, where each response class is a noisily labeled group of interchangeable responses. At inference, we generate the exemplar response associated with the predicted response class. Experts can edit and improve these exemplar responses over time without retraining the classifier or invalidating old training data.  Human evaluation of 775 unseen doctor/patient conversations shows that this tradeoff improves responses. Only 12\% of our discriminative approach's responses are worse than the doctor's response in the same conversational context, compared to 18\% for the generative model. The discriminative model trained without any manual labeling of response classes achieves equal performance to the generative model. 
 In Natural Language Generation , End-to-End  systems trained through deep learning have recently gained a strong interest. Such deep models need a large amount of carefully annotated data to reach satisfactory performance. However, acquiring such datasets for every new NLG application is a tedious and time-consuming task. In this paper, we propose a semi-supervised deep learning scheme that can learn from non-annotated data and annotated data when available. It uses an NLG and a Natural Language Understanding  sequence-to-sequence models which are learned jointly to compensate for the lack of annotation. Experiments on two benchmark datasets show that, with limited amount of annotated data, the method can achieve very competitive results while not using any pre-processing or re-scoring tricks. These findings open the way to the exploitation of non-annotated datasets which is the current bottleneck for the E2E NLG system development to new applications. 
     The evolution of the information and communication technologies has dramatically      increased the number of people with access to the Internet, which has changed the     way the information is consumed.      As a consequence of the above, fake news have become one of the major concerns because     its potential to destabilize governments, which makes them a potential danger to     modern society. An example of this can be found in the US. electoral campaign,     where the term ``fake news'' gained great notoriety due to the influence     of the hoaxes in the final result of these.      In this work the feasibility of applying deep learning techniques to discriminate fake     news on the Internet using only their text is studied. In order to accomplish that, three     different neural network architectures are proposed, one of them based on BERT, a     modern language model created by Google which achieves state-of-the-art results. 
 Manually labelling large collections of text data is a time-consuming and expensive task, but one that is necessary to support machine learning based on text datasets.  has been shown to be an effective way to alleviate some of the effort required in utilising large collections of unlabelled data for machine learning tasks without needing to fully label them. The representation mechanism used to represent text documents when performing active learning, however, has a significant influence on how effective the process will be. While simple vector representations such as  have been shown to be an effective way to represent documents during active learning, the emergence of representation mechanisms based on the  prevalent in neural network research  offer a promising, and as yet not fully explored, alternative. This paper describes a large-scale evaluation of the effectiveness of different text representation mechanisms for active learning across 8 datasets from varied domains. This evaluation shows that using representations based on modern word embeddings, especially BERT, which have not yet been widely used in active learning, achieves a significant improvement over more commonly used vector representations like bag-of-words.   
 Understanding and extracting of information from large documents, such as business opportunities, academic articles, medical documents and technical reports, poses challenges not present in short documents. Such large documents may be multi-themed, complex, noisy and cover diverse topics. We describe a framework that can analyze large documents and help people and computer systems locate desired information in them. We aim to automatically identify and classify different sections of documents and understand their purpose within the document. A key contribution of our research is modeling and extracting the logical and semantic structure of electronic documents using deep learning techniques. We evaluate the effectiveness and robustness of our framework through extensive experiments on two collections: more than one million scholarly articles from arXiv and a collection of requests for proposal documents from government sources.   
 In this work, we explore the usefulness of target factors in neural machine translation  beyond their original purpose of predicting word lemmas and their inflections, as proposed by Garc\'ia-Mart\'inez et al.~. For this, we introduce three novel applications of the factored output architecture: In the first one, we use a factor to explicitly predict the word case separately from the target word itself. This allows for information to be shared between different casing variants of a word. In a second task, we use a factor to predict when two consecutive subwords have to be joined, eliminating the need for  target subword joining markers. The third task is the prediction of special tokens of the operation sequence NMT model  of Stahlberg et al.~. Automatic evaluation on English$\to$German and English$\to$Turkish tasks showed that integration of such auxiliary prediction tasks into NMT is at least as good as the standard NMT approach. For the OSNMT, we observed a significant improvement in BLEU over the baseline OSNMT implementation due to a reduced output sequence length that resulted from the introduction of the target factors.  
 We consider a document classification problem where document labels are absent but only relevant keywords of a target class and unlabeled documents are given. Although heuristic methods based on pseudo-labeling have been considered, theoretical understanding of this problem has still been limited. Moreover, previous methods cannot easily incorporate well-developed techniques in supervised text classification. In this paper, we propose a theoretically guaranteed learning framework that is simple to implement and has flexible choices of models, e.g., linear models or neural networks. We demonstrate how to optimize the area under the receiver operating characteristic curve  effectively and also discuss how to adjust it to optimize other well-known evaluation metrics such as the accuracy and $\mathrm{F}_{1}$-measure. Finally, we show the effectiveness of our framework using benchmark datasets. 
 Sexism, an injustice that subjects women and girls to enormous suffering, manifests in blatant as well as subtle ways. In the wake of growing documentation of experiences of sexism on the web, the automatic categorization of accounts of sexism has the potential to assist social scientists and policy makers in studying and countering sexism better. The existing work on sexism classification, which is different from sexism detection, has certain limitations in terms of the categories of sexism used and/or whether they can co-occur. To the best of our knowledge, this is the first work on the multi-label classification of sexism of any kind, and we contribute the largest dataset for sexism categorization. We develop a neural solution for this multi-label classification that can combine sentence representations obtained using models such as BERT with distributional and linguistic word embeddings using a flexible, hierarchical architecture involving recurrent components and optional convolutional ones. Further, we leverage unlabeled accounts of sexism to infuse domain-specific elements into our framework. The best proposed method outperforms several deep learning as well as traditional machine learning baselines by an appreciable margin. % , producing an instance F1 of 0.756 and a macro F1 of 0.684.  % , an accuracy of 0.635,, and a micro F1 of 0.715 % by the survivors themselves and observers % \todo{NC: When u say visually illustrate - do you mean show the attention weights ?. Wee can skip this sentence and have the accuarcy value obtained here. }We also visually illustrate how our solution weighs words and sentences for categorizing sexism instances.  % We create a dataset containing over 13000 sexism instances, annotated with one or more of $23$ well-defined categories by $10$ judges recruited by a social scientist. 
 Recognizing emotions in conversations is a challenging task due to the presence of contextual dependencies governed by self- and inter-personal influences. Recent approaches have focused on modeling these dependencies primarily via supervised learning. However, purely supervised strategies demand large amounts of annotated data, which is lacking in most of the available corpora in this task. To tackle this challenge, we look at transfer learning approaches as a viable alternative. Given the large amount of available conversational data, we investigate whether generative conversational models can be leveraged to transfer affective knowledge for detecting emotions in context. We propose an approach, TL-ERC, where we pre-train a hierarchical dialogue model on multi-turn conversations  and then transfer its parameters to a conversational emotion classifier . In addition to the popular practice of using pre-trained sentence encoders, our approach also incorporates recurrent parameters that model inter-sentential context across the whole conversation. Based on this idea, we perform several experiments across multiple datasets and find improvement in performance and robustness against limited training data. TL-ERC also achieves better validation performances in significantly fewer epochs. Overall, we infer that knowledge acquired from dialogue generators can indeed help recognize emotions in conversations. 
 	We consider the problem of conversational question answering over a large-scale knowledge base. To handle huge entity vocabulary of a large-scale knowledge base, recent neural semantic parsing based approaches usually decompose the task into several subtasks and then solve them sequentially, which leads to following issues: 1) errors in earlier subtasks will be propagated and negatively affect downstream ones; and 2) each subtask cannot naturally share supervision signals with others. To tackle these issues, we propose an innovative multi-task learning framework where a pointer-equipped semantic parsing model is designed to resolve coreference in conversations, and naturally empower joint learning with a novel type-aware entity detection model. The proposed framework thus enables shared supervisions and alleviates the effect of error propagation. Experiments on a large-scale conversational question answering dataset containing 1.6M question answering pairs over 12.8M entities show that the proposed framework improves overall F1 score from 67\% to 79\% compared with previous state-of-the-art work.  
 Large language models can produce powerful contextual representations that lead to improvements across many NLP tasks. Since these models are typically guided by a sequence of learned self attention mechanisms and may comprise undesired inductive biases, it is paramount to be able to explore what the attention has learned. While static analyses of these models lead to targeted insights, interactive tools are more dynamic and can help humans better gain an intuition for the model-internal reasoning process. We present exBERT, an interactive tool named after the popular BERT language model, that provides insights into the meaning of the contextual representations by matching a human-specified input to similar contexts in a large annotated dataset. By aggregating the annotations of the matching similar contexts, exBERT helps intuitively explain what each attention-head has learned.  
 We present the first dataset targeted at end-to-end NLG in Czech in the restaurant domain, along with several strong baseline models using the sequence-to-sequence approach.  While non-English NLG is under-explored in general, Czech, as a morphologically rich language, makes the task even harder: Since Czech requires inflecting named entities, delexicalization or copy mechanisms do not work out-of-the-box and lexicalizing the generated outputs is non-trivial.   In our experiments, we present two different approaches to this this problem:  using a neural language model to select the correct inflected form while lexicalizing,  a two-step generation setup: our sequence-to-sequence model generates an interleaved sequence of lemmas and morphological tags, which are then inflected by a morphological generator. 
 We propose vq-wav2vec to learn discrete representations of audio segments through a wav2vec-style self-supervised context prediction task. The algorithm uses either a Gumbel-Softmax or online k-means clustering to quantize the dense representations. Discretization enables the direct application of algorithms from the NLP community which require discrete inputs. Experiments show that BERT pre-training achieves a new state of the art on TIMIT phoneme classification and WSJ speech recognition.\footnote{The code will be made available at \url{http://github.com/pytorch/fairseq}.} 
   How does knowledge of one language's morphology influence learning of inflection rules in a second one? In order to investigate this question in artificial neural network models, we perform experiments with a sequence-to-sequence architecture, which we train on different combinations of eight source and three target languages. A detailed analysis of the model outputs suggests the following conclusions:  if source and target language are closely related, acquisition of the target language's inflectional morphology constitutes an easier task for the model;  knowledge of a prefixing  language makes acquisition of a suffixing  language's morphology more challenging; and  surprisingly, a source language which exhibits an agglutinative morphology simplifies learning of a second language's inflectional morphology, independent of their relatedness. 
 % This document is a model and instructions for \LaTeX. % This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes,  % or Math in Paper Title or Abstract. % 
 Various deep learning algorithms have been developed to analyze different types of clinical data including clinical text classification, and extracting information from 閳ユree text閳 and so on. However, automate the keyword extraction from the clinical notes is still  challenging. The challenges includes dealing with noisy clinical notes which contains various abbreviations, possible typos and unstructured sentences. The objective of this research is to investigate the attention-based deep learning models to classify the de-identified clinical progress notes extracted from a real-world EHR system. The attention-based deep learning models can be used to interpret the models and understand the critical words that drive the correct or incorrect classification of the clinical progress notes. The attention-based models in this research are capable of presenting the human interpretable text classification models. The results show that the fine-tuned BERT with attention layer can achieve a high classification accuracy of 97.6\%, which is higher than the baseline fine-tuned BERT classification model. In this research, we also demonstrate that the attention-based models can identify relevant keywords that are strongly related to the clinical progress note categories. 
   In this paper, we propose the use of in-training matrix factorization to reduce the model size for neural machine translation. Using in-training matrix factorization, parameter matrices may be decomposed into the products of smaller matrices, which can compress large machine translation architectures by vastly reducing the number of learnable parameters. We apply in-training matrix factorization to different layers of standard neural architectures and show that in-training factorization is capable of reducing nearly 50\% of learnable parameters without any associated loss in BLEU score. Further, we find that in-training matrix factorization is especially powerful on embedding layers, providing a simple and effective method to curtail the number of parameters with minimal impact on model performance, and, at times, an increase in performance. 
 Predicting patient mortality is an important and challenging problem in the healthcare domain, especially for intensive care unit  patients. Electronic health notes serve as a rich source for learning patient representations, that can facilitate effective risk assessment. However, a large portion of clinical notes are unstructured and also contain domain specific terminologies, from which we need to extract structured information. In this paper, we introduce an embedding framework to learn semantically-plausible distributed representations of clinical notes that exploits the semantic correspondence between the unstructured texts and their corresponding structured knowledge, known as semantic frame, in a hierarchical fashion. Our approach integrates text modeling and semantic correspondence learning into a single model that comprises 1) an unstructured embedding module that makes use of self-similarity matrix representations in order to inject structural regularities of different segments inherent in clinical texts to promote local coherence, 2) a structured embedding module to embed the semantic frames  with deep ConvNet and 3) a hierarchical semantic correspondence module that embeds by enhancing the interactions between text-semantic frame embedding pairs at multiple levels . Evaluations on multiple embedding benchmarks on post-discharge intensive care patient mortality prediction tasks demonstrate its effectiveness compared to approaches that do not exploit the semantic interactions between structured and unstructured information present in clinical notes. 
   Neural sequence-to-sequence models, particularly the Transformer,   are the state of the art in machine translation.   Yet these neural networks are very   sensitive to architecture and hyperparameter settings.    Optimizing these settings by grid or random search is computationally expensive because it requires many training runs. In this paper, we incorporate architecture search into a single training run through , which uses regularization to delete neurons in a network over the course of training. On very low-resource language pairs, we show that auto-sizing can improve BLEU scores by up to 3.9 points while removing one-third of the parameters from the model.  
 Word-embeddings are vital components of Natural Language Processing  models and have been extensively explored. However, they consume a lot of memory which poses a challenge for edge deployment. Embedding matrices, typically, contain most of the parameters for language models and about a third for machine translation systems. In this paper, we propose Distilled Embedding, an  embedding compression method based on low-rank matrix decomposition and knowledge distillation. First, we initialize the weights of our decomposed matrices by learning to reconstruct the full pre-trained word-embedding and then fine-tune end-to-end, employing knowledge distillation on the factorized embedding. We conduct extensive experiments with various compression rates on machine translation and language modeling, using different data-sets with a shared word-embedding matrix for both embedding and vocabulary projection matrices. We show that the proposed technique is simple to replicate, with one fixed parameter controlling compression size, has higher BLEU score on translation and lower perplexity on language modeling compared to complex, difficult to tune state-of-the-art methods. 
   Neural Machine Translation  models generally perform translation using a fixed-size lexical vocabulary, which is an important bottleneck on their generalization capability and overall translation quality. The standard approach to overcome this limitation is to segment words into subword units, typically using some external tools with arbitrary heuristics, resulting in vocabulary units not optimized for the translation task. Recent studies have shown that the same approach can be extended to perform NMT directly at the level of characters, which can deliver translation accuracy on-par with subword-based models, on the other hand, this requires relatively deeper networks. In this paper, we propose a more computationally-efficient solution for character-level NMT which implements a hierarchical decoding architecture where translations are subsequently generated at the level of words and characters. We evaluate different methods for open-vocabulary NMT in the machine translation task from English into five languages with distinct morphological typology, and show that the hierarchical decoding model can reach higher translation accuracy than the subword-level NMT model using significantly fewer parameters, while demonstrating better capacity in learning longer-distance contextual and grammatical dependencies than the standard character-level NMT model. \\  % ABSTRACT < 200 WORDS 
 %We propose a novel algorithm to compute label embedding directly from word embedding for semantic role labelling . An attention-based RNN architecture can then be used together with label embedding to learn associations between word and label vectors as in other proposed architecture such as Jordan network, yet with far fewer trainable parameters. We validate the approach using the ATIS and MEDIA datasets and show that slightly better performance can be achieved compared with the baseline approach, even when reduced versions of the training data are used. %--LFD We propose an architecture to jointly learn word and label embeddings for slot filling in spoken language understanding. The proposed approach encodes labels using a combination of word embeddings and straightforward word-label association from the training data. Compared to the state-of-the-art methods, our approach does not require label embeddings as part of the input and therefore lends itself nicely to a wide range of model architectures. In addition, our architecture computes contextual distances between words and labels to avoid adding contextual windows, thus reducing memory footprint. We validate the approach on established spoken dialogue datasets and show that it can achieve state-of-the-art performance with much fewer trainable parameters. 
 In this paper, we present a study of the recent advancements which have helped bring Transfer Learning to NLP through the use of semi-supervised training. We discuss cutting-edge methods and architectures such as BERT, GPT, ELMo, ULMFit among others. Classically, tasks in natural language processing have been performed through rule-based and statistical methodologies. However, owing to the vast nature of natural languages these methods do not generalise well and failed to learn the nuances of language. Thus machine learning algorithms such as Naive Bayes and decision trees coupled with traditional models such as Bag-of-Words and N-grams were used to usurp this problem. Eventually, with the advent of advanced recurrent neural network architectures such as the LSTM, we were able to achieve state-of-the-art performance in several natural language processing tasks such as text classification and machine translation.  We talk about how Transfer Learning has brought about the well-known ImageNet moment for NLP. Several advanced architectures such as the Transformer and its variants have allowed practitioners to leverage knowledge gained from unrelated task to drastically fasten convergence and provide better performance on the target task. This survey represents an effort at providing a succinct yet complete understanding of the recent advances in natural language processing using deep learning in with a special focus on detailing transfer learning and its potential advantages. 
     % This paper reports experiments done for document level translation study done at Qwant Research.          % 6 to 10 pages max.     In  Machine Translation,  considering  the  document as a whole can help to resolve ambiguities and inconsistencies. In this paper, we propose a simple yet promising approach to add contextual information in  Neural  Machine  Translation. We present a method to add source context that capture the whole document with accurate boundaries, taking every word into account.      We provide this additional information to a Transformer model and study the impact of our method on three language pairs.     The proposed approach obtains promising results in the English-German, English-French and French-English document-level translation tasks.      We observe interesting cross-sentential behaviors where the model learns to use document-level information to improve translation coherence.      %Experiments show improvements up to 1.81 BLEU in the low-ressource French-English language pair among three test sets. 
  %Integrating external knowledge graphs into dialogue systems is a challenging task.  Non-goal oriented, generative dialogue systems lack the ability to generate answers with grounded facts. A knowledge graph can be considered an abstraction of the real world consisting of well-grounded facts. %\todo{What is the problem and why is it required? Proposal: Non-goal driven dialogue systems lack the ability to generate answers with grounded facts. On the other hand side research about modeling world knowledge in graph structures has undergone significant improvements recently. In this paper we address focus on a combination of both approaches by integrating additional knowledge graphs into non-goal driven dialogues.   }.  This paper addresses the problem of generating well-grounded responses by integrating knowledge graphs into the dialogue system's response generation process, in an end-to-end manner. A dataset for non-goal oriented dialogues is proposed in this paper in the domain of soccer, conversing on different clubs and national teams along with a knowledge graph for each of these teams. A novel neural network architecture is also proposed as a baseline on this dataset, which can integrate knowledge graphs into the response generation process, producing well articulated, knowledge grounded responses. Empirical evidence suggests that the proposed model performs better than other state-of-the-art models for knowledge graph integrated dialogue systems. %\todo{Be more to the point. What exactly are you doing and what%The model is empirically evaluated against other state-of-the-art systems for knowledge graph integration into dialogue systems. %We also propose a novel, neural network based model for better integration of the knowledge graph, present in the form of knowledge graphs, into the response generation process.  do the results show?}     
 We introduce a relational graph neural network with bi-directional attention mechanism and hierarchical representation  learning for open-domain question answering task. Our model can learn contextual representation by jointly learning and  updating the query, knowledge graph, and document representations. The experiments suggest that our model achieves  state-of-the-art on the WebQuestionsSP benchmark.   
 		For conversational AI and virtual assistants to communicate with humans in a realistic way, they must exhibit human characteristics such as expression of emotion and personality. Current attempts toward constructing human-like dialogue agents have presented significant difficulties. We propose Human Level Attributes  based on tropes as the basis of a method for learning dialogue agents that can imitate the personalities of fictional characters. Tropes are characteristics of fictional personalities that are observed recurrently and determined by viewers' impressions. By combining detailed HLA data with dialogue data for specific characters, we present a dataset, HLA-Chat, that models character profiles and gives dialogue agents the ability to learn characters' language styles through their HLAs. We then introduce a three-component system, ALOHA , that combines character space mapping, character community detection, and language style retrieval to build a character  specific language model. Our preliminary experiments demonstrate that two variations of ALOHA, combined with our proposed dataset, can outperform baseline models at identifying the correct dialogue responses of chosen target characters, and are stable regardless of the character's identity, the genre of the show, and the context of the dialogue. 	
 We show state-of-the-art word representation learning methods maximize an objective function that is a  lower bound on the mutual information between different parts of a word sequence . %and they can be seen as instances of contrastive learning. Our formulation provides an alternative perspective that unifies classical word embedding models   and modern contextual embeddings . In addition to enhancing  our theoretical understanding of these methods, our derivation leads to a principled framework that can be used to  construct new self-supervised tasks. We provide an example by drawing inspirations from related methods  based on mutual information maximization that have been successful in computer vision,  and introduce a simple self-supervised objective	 that maximizes the mutual information between a global sentence representation and $n$-grams in the sentence. %In addition to facilitating the creation of new self-supervised tasks, Our analysis offers a holistic view of representation learning methods to transfer knowledge and translate  progress across multiple domains . %We believe that the mutual information maximization  %framework provides a principled  %foundation to design better  %self-supervised language tasks. 
   A quality abstractive summary should not only copy salient source texts as summaries but should also tend to generate new conceptual words to express concrete details. Inspired by the popular pointer generator sequence-to-sequence model, this paper presents a concept pointer network for improving these aspects of abstractive summarization. The network leverages knowledge-based, context-aware conceptualizations to derive an extended set of candidate concepts. The model then points to the most appropriate choice using both the concept set and original source text. This joint approach generates abstractive summaries with higher-level semantic concepts. The training model is also optimized in a way that adapts to different data, which is based on a novel method of distantly-supervised learning guided by reference summaries and testing set. Overall, the proposed approach provides statistically significant improvements over several state-of-the-art models on both the DUC-2004 and Gigaword datasets.  A human evaluation of the model's abstractive abilities also supports the quality of the summaries produced within this framework.  
   Representation learning is a key element of state-of-the-art deep learning approaches. It enables to transform raw data into structured vector space embeddings. Such embeddings are able to capture the distributional semantics of their context, e.g.\ by word windows on natural language sentences, graph walks on knowledge graphs or convolutions on images. So far, this context is manually defined, resulting in heuristics which are solely optimized for computational performance on certain tasks like link-prediction. However, such heuristic models of context are fundamentally different to how humans capture information. For instance, when reading a multi-modal webpage  humans do not perceive all parts of a document equally: Some words and parts of images are skipped, others are revisited several times which makes the perception trace highly non-sequential;  humans construct meaning from a document's content by shifting their attention between text and image, among other things, guided by layout and design elements.    In this paper we empirically investigate the difference between human perception and context heuristics of basic embedding models. We conduct eye tracking experiments to capture the underlying characteristics of human perception of media documents containing a mixture of text and images. Based on that, we devise a prototypical computational perception-trace model, called CMPM. We evaluate empirically how CMPM can improve a basic skip-gram embedding approach. Our results suggest, that even with a basic human-inspired computational perception model, there is a huge potential for improving embeddings since such a model does inherently capture multiple modalities, as well as layout and design elements. 
   Natural question generation  aims to generate questions from a passage and an answer. In this paper, we propose a novel reinforcement learning  based graph-to-sequence  model for QG. Our model consists of a Graph2Seq generator where a novel Bidirectional Gated Graph Neural Network is proposed to embed the passage, and a hybrid evaluator with a mixed objective combining both cross-entropy and RL losses to ensure the generation of syntactically and semantically valid text. The proposed model outperforms previous state-of-the-art methods by a large margin on the SQuAD dataset.    
 Sememes, the minimum semantic units of human languages, have been successfully utilized in various natural language processing applications.  However, most existing studies exploit sememes in specific tasks and few efforts are made to utilize sememes more fundamentally.  In this paper, we propose to incorporate sememes into recurrent neural networks  to improve their sequence modeling ability, which is beneficial to all kinds of downstream tasks.  We design three different sememe incorporation methods and employ them in typical RNNs including LSTM, GRU and their bidirectional variants. In evaluation, we use several benchmark datasets involving PTB and WikiText-2 for language modeling, SNLI for natural language inference and another two datasets for sentiment analysis and paraphrase detection. Experimental results show evident and consistent improvement of our sememe-incorporated models compared with vanilla RNNs, which proves the effectiveness of our sememe incorporation methods.  Moreover, we find the sememe-incorporated models have higher robustness and outperform adversarial training in defending adversarial attack. %And we also conduct a case study to demonstrate the usefulness of sememes. All the code and data of this work can be obtained at \url{https://github.com/thunlp/SememeRNN}.  
 Implicit discourse relation classification is of great importance for discourse parsing, but remains a challenging problem due to the absence of explicit discourse connectives communicating these relations. Modeling the semantic interactions between the two arguments of a relation has proven useful for detecting implicit discourse relations. However, most previous approaches model such semantic interactions from a shallow interactive level, which is inadequate on capturing enough semantic information. In this paper, we propose a novel and effective Semantic Graph Convolutional Network  to enhance the modeling of inter-argument semantics on a deeper interaction level for implicit discourse relation classification. We first build an interaction graph over representations of the two arguments, and then automatically extract in-depth semantic interactive information through graph convolution. Experimental results on the English corpus PDTB and the Chinese corpus CDTB both demonstrate the superiority of our model to previous state-of-the-art systems.   % We observe that candidate answers especially the correct ones always contain abundant background information related to the question, which can be effective evidence to help distinguish candidates. Therefore, we propose to accumulate such evidence as an expansion of the question to address the sparse-matching problem. Specifically, we present a multi-step ranker, where we accumulate reliable evidence from potentially correct candidate answers step by step and utilize it to rank the candidate answer. The step-by-step mechanism effectively avoids noisy information from incorrect candidates. Experiments on three benchmarks, namely WikiQA, SelQA, and SemEval-2016, show that our approach outperforms existing methods which do not rely on external resources.  
 We propose a novel paradigm of semi-supervised learning  閳 the semi-supervised multiple representation behavior learning . SSMRBL aims to tackle the difficulty of learning a grammar for natural language parsing where the data are natural language texts and the `labels' for marking data are parsing trees and/or grammar rule pieces. We call such `labels' as compound structured labels which require a hard work for training. SSMRBL is an incremental learning process that can learn more than one representation, which is an appropriate solution for dealing with the scarce of labeled training data in the age of big data and with the heavy workload of learning compound structured labels. We also present a typical example of SSMRBL, regarding behavior learning in form of a grammatical approach towards domain-based multiple text summarization . DBMTS works under the framework of rhetorical structure theory . SSMRBL includes two representations: text embedding  and grammar model . The first representation was learned as embedded digital vectors called impacts in a low dimensional space. The grammar model was learned in an iterative way. Then an automatic domain-oriented multi-text summarization approach was proposed based on the two representations discussed above. Experimental results on large-scale Chinese dataset SogouCA indicate that the proposed method brings a good performance even if only few labeled texts are used for training with respect to our defined automated metrics. 
     The use of the internet as a fast medium of spreading fake news reinforces the need for computational tools that combat it. 	Techniques that train fake news classifiers exist, but they all assume an abundance of resources including large labeled datasets and expert-curated corpora, which low-resource languages may not have.  	In this work, we make two main contributions: 	First, we alleviate resource scarcity by constructing the first expertly-curated benchmark dataset for fake news detection in Filipino, which we call ``Fake News Filipino.''     Second, we benchmark Transfer Learning  techniques and show that they can be used to train robust fake news classifiers from little data, achieving 91\% accuracy on our fake news dataset, reducing the error by 14\% compared to established few-shot baselines.     Furthermore, lifting ideas from multitask learning,  we show that augmenting transformer-based transfer techniques with auxiliary language modeling losses improves their performance by adapting to writing style.     Using this, we improve TL performance by 4-6\%, achieving an accuracy of 96\% on our best model.     Lastly, we show that our method generalizes well to different types of news articles, including political news, entertainment news, and opinion articles.  \\ \newline \Keywords{Statistical and Machine Learning Methods, Language Modelling, Document Classification and Text Categorization
 Entity Coreference Resolution is the task of resolving all mentions in a document that refer to the same real world entity and is considered as one of the most difficult tasks in natural language understanding. It is of great importance for downstream natural language processing tasks such as entity linking, machine translation, summarization, chatbots, etc. This work aims to give a detailed review of current progress on solving Coreference Resolution using neural-based approaches. It also provides a detailed appraisal of the datasets and evaluation metrics in the field, as well as the subtask of Pronoun Resolution that has seen various improvements in the recent years. We highlight the advantages and disadvantages of the approaches, the challenges of the task, the lack of agreed-upon standards in the task and propose a way to further expand the boundaries of the field.  
  This paper presents the CUNLP submission for the NLP4IF 2019 shared-task on Fine-Grained Propaganda Detection. Our system finished 5th out of 26 teams on the sentence-level classification task and 5th out of 11 teams on the fragment-level classification task based on our scores on the blind test set. We present our models, a discussion of our ablation studies and experiments, %feature selection and fine-tuning a pre-trained neural models   and an analysis of our performance on all eighteen propaganda techniques present in the corpus of the shared task. 
 % 200/200 words limit Recent breakthroughs in deep learning often rely on representation learning and knowledge transfer. In particular, readily available models pre-trained on large datasets are key for the efficient transfer of knowledge. They can be applied as feature extractors for data preprocessing, fine-tuned to perform a variety of tasks, or used for computing feature losses in the training of deep learning systems. While applications of transfer learning are common in the fields of computer vision and natural language processing, audio- and speech processing are surprisingly lacking readily available and transferable models. Here, we introduce speechVGG, a flexible, transferable feature extractor tailored for integration with deep learning frameworks for speech processing. Our transferable model adopts the classic VGG-16 architecture and is trained on a spoken word classification task. We demonstrate the application of the pre-trained model in four speech processing tasks, including speech enhancement, language identification, speech, noise and music classification, and speaker identification. Each time, we compare the performance of our approach to existing baselines. Our results confirm that the representation of natural speech captured using speechVGG is transferable and generalizable across various speech processing problems and datasets. Notably, relatively simple applications of our pre-trained model are capable of achieving competitive results.  
  A Dialogue State Tracker  is a key component in a dialogue system aiming at estimating the beliefs of possible user goals at each dialogue turn. Most of the current DST trackers make use of recurrent neural networks and are based on complex architectures that manage several aspects of a dialogue, including the user utterance, the system actions, and the slot-value pairs defined in a domain ontology. However, the complexity of such neural architectures incurs into a considerable latency in the dialogue state prediction, which limits the deployments of the models in real-world applications, particularly when task scalability  is a crucial factor. In this paper, we propose an innovative neural model for dialogue state tracking, named Global encoder and Slot-Attentive decoders , which can predict the dialogue state with a very low latency time, while maintaining high-level performance.  We report experiments on three different languages  of the WOZ2.0 dataset, and show that the proposed approach provides competitive advantages over state-of-art DST systems, both in terms of accuracy and in terms of time complexity for predictions, being over 15 times faster than the other systems.  
   Neural machine translation models have shown to achieve high quality when trained  and fed with well structured and punctuated input texts. Unfortunately, the latter condition is not met in  spoken language translation, where the input is generated by an automatic speech recognition  system. In this paper, we study how to adapt a strong NMT system to make it robust to typical ASR errors. As in our application scenarios transcripts might be post-edited by human experts, we propose adaptation strategies to train a single system that can translate either clean or noisy input with no supervision on the input type. Our experimental results on a public speech translation data set show that adapting a model on a significant amount of parallel data including ASR transcripts is beneficial with test data of the same type, but produces a small degradation when translating clean text. Adapting on both clean and noisy variants of the same data leads to the best results on both input types. 
 We tackle the nested and overlapping event detection task and propose a novel search-based neural network  structured prediction model that treats the task as a search problem on a relation graph of trigger-argument structures.  Unlike existing structured prediction tasks such as dependency parsing, the task targets to detect DAG structures, which constitute events, from the relation graph. We define actions to construct events and use all the beams in a beam search to detect all event structures that may be overlapping and nested. The search process constructs events in a bottom-up manner while modelling the global properties for nested and overlapping structures simultaneously using neural networks. We show that the model achieves performance comparable to the state-of-the-art model Turku Event Extraction System  on the BioNLP Cancer Genetics  Shared Task 2013 without the use of any syntactic and hand-engineered features. Further analyses on the development set show that our model is more computationally efficient while yielding higher F1-score performance. 
 Deep acoustic models typically receive features in the first layer of the network, and process increasingly abstract representations in the subsequent layers. Here, we propose to feed the input features at multiple depths in the acoustic model. As our motivation is to allow acoustic models to re-examine their input features in light of partial hypotheses we introduce intermediate model heads and loss function. We study this architecture in the context of deep Transformer networks, and we use an attention mechanism over both the previous layer activations and the input features. To train this model's intermediate output hypothesis, we apply the objective function at each layer right before feature re-use. We find that the use of such iterated loss significantly improves performance by itself, as well as enabling input feature re-use. We present results on both Librispeech, and a large scale video dataset, with relative improvements of 10 - 20\% for Librispeech and 3.2 - 13\% for videos. %OLD: Deep acoustic models typically receive features in the first layer of the network, and process increasingly abstract representations in the subsequent layers. This work is motivated by a desire to allow such a network to re-examine the original features in light of partial hypotheses, thus enabling an analysis that may better differentiate the specific sounds that are likely, and allow the network to adapt to ambient noise. This requires the model to produce partial hypothesis earlier, and thus we introduce intermediate heads and loss function. We study this architecture in the context of deep Transformer networks, and find that re-presenting the input features at a middle layer can noticeably improve performance. This secondary analysis is enabled through an attention model that has access both to previous-layer activations and the raw features. To implement this model, we apply the objective function at the intermediate layer prior to feature re-use, to encourage the development of phonetically relevant hypotheses. We find that the use of intermediate loss in the middle of the Transformer layers significantly improves performance by itself, as well as enabling the secondary feature analysis. We present results on both Librispeech, and a large scale video dataset, observing 8 to 20\% relative improvements. 
 % 鐟曚椒绮爎eviewer閻ㄥ嫯顫楁惔锕佸啳妾婚敍灞肩瑝閼崇晫娲块幒顧痭 this paper, we present an XLNet-like pretraining scheme... 閸ョ姳璐熷▽鈩冩箒娴滆櫣鐓￠柆鎻Net-like閺勵垯绮堟稊鍫滅鐟楀尅绱檡hhuang閿涘绱濋幍娴犮儱澧犻棃銏ゆ付鐟曚胶鐣濋崡鏇氱矙缂佸秳绔存稉濯侺Net娴ｆ粈璐熸潻鍥ㄦ诞 Self-attention network  can benefit significantly from the bi-directional representation learning through unsupervised pretraining paradigms such as BERT and XLNet. In this paper, we present an XLNet-like pretraining scheme ``Speech-XLNet'' to learn speech representations with self-attention networks .  %First, we find that by shuffling the speech frame orders, the permutation in Speech-XLNet serves as a strong regularizer to encourage the SAN to make inferences by focusing on global structures through its attention weights. Second, Speech-XLNet also allows the model to explore the bi-directional contexts while maintaining autoregressive training manner. Third, visualization results further prove that our method can help to generalize better with more flat and wider optima compared with training from scratch.  % 鐏忔垹鏁elp to閿涘矁袙闁插﹤甯崶鐘侯洣閻╁瓨鍩呮禍鍡楃秼娑撳秷顩﹂悽鈺砳th xxx Firstly, we find that by shuffling the speech frame orders, Speech-XLNet serves as a strong regularizer which encourages the SAN network to make inferences by focusing on global structures through its attention weights. Secondly, Speech-XLNet also allows the model to explore bi-directional context information while maintaining the autoregressive training manner. Visualization results show that our approach can generalize better with more flattened and widely distributed optimas compared to the conventional approach. Experimental results on TIMIT demonstrate that Speech-XLNet greatly improves hybrid SAN/HMM in terms of both convergence speed and recognition accuracy. Our best systems achieve a relative improvement of 15.2\% on the TIMIT task. Besides, we also apply our pretrained model to an End-to-End SAN with WSJ dataset and WER is reduced by up to 68\% when only a few hours of transcribed data is used. %reduce WER by up to 68\% when only a few hours of transcribed data is available. % and閸氬酣娼扮亸浠嬪櫤鐠虹喍绔存稉顏勭暚閺佹潙褰炵涙劘灞肩瑝閺勵垯绔存稉顏嗗繁閻椒瀵岀拠顓犳畱閸斻劏鐦 
 The recent advances introduced by neural machine translation  are rapidly expanding the application fields of machine translation, as well as reshaping the quality level to be targeted. In particular, if translations have to fit some given layout, quality should not only be measured in terms of adequacy and fluency, but also length.  Exemplary cases are the translation of document files, subtitles, and scripts for dubbing, where the output length should ideally be as close as possible to the length of the input text. This paper addresses for the first time, to the best of our knowledge, the problem of controlling the output length in NMT.   We investigate two methods for biasing the output length with a transformer architecture: i) conditioning the output to a given target-source length-ratio class  and ii) enriching the transformer positional embedding with length information. Our experiments show that both methods can induce the network to generate shorter translations,  as well as acquiring interpretable linguistic skills. 
  Recent dialogue approaches operate by reading each word in a conversation history, and aggregating accrued dialogue information into a single state. This fixed-size vector is not expandable and must maintain a consistent format over time. Other recent approaches exploit an attention mechanism to extract useful information from past conversational utterances, but this introduces an increased computational complexity. In this work, we explore the use of the Neural Turing Machine  to provide a more permanent and flexible storage mechanism for maintaining dialogue coherence. Specifically, we introduce two separate dialogue architectures based on this NTM design. The first design features a sequence-to-sequence architecture with two separate NTM modules, one for each participant in the conversation. The second memory architecture incorporates a single NTM module, which stores parallel context information for both speakers. This second design also replaces the sequence-to-sequence architecture with a neural language model, to allow for longer context of the NTM and greater understanding of the dialogue history. We report perplexity performance for both models, and compare them to existing baselines.  
  % put your abstract here! Many recent works have discussed the propensity, or lack thereof, for emergent languages to exhibit properties of natural languages. A favorite in the literature is learning compositionality. We note that most of those works have focused on communicative bandwidth as being of primary importance. While important, it is not the only contributing factor. In this paper, we investigate the learning biases that affect the efficacy and compositionality in multi-agent communication. Our foremost contribution is to explore how the capacity of a neural network impacts its ability to learn a compositional language. We additionally introduce a set of evaluation metrics with which we analyze the learned languages. Our hypothesis is that there should be a specific range of model capacity and channel bandwidth that induces compositional structure in the resulting language and consequently encourages systematic generalization. While we empirically see evidence for the bottom of this range, we curiously do not find evidence for the top part of the range and believe that this is an open question for the community.\footnote{Code is available at \url{https://github.com/backpropper/cbc-emecom}.} 
  % HACK Named Entity Recognition  is a key component in NLP systems for question answering, information retrieval, relation extraction, etc. NER systems have been studied and developed widely for decades, but accurate systems using deep neural networks  have only been introduced in the last few years. We present a comprehensive survey of deep neural network architectures for NER, and contrast them with previous approaches to NER based on feature engineering and other supervised or semi-supervised learning algorithms. Our results highlight the improvements achieved by neural networks, and show how incorporating some of the lessons learned from past work on feature-based NER systems can yield further improvements. 
 Modern Automatic Speech Recognition  systems primarily rely on scores from an Acoustic Model  and a Language Model  to rescore the $N$-best lists. With the abundance of recent natural language processing advances, the information utilized by current ASR for evaluating the linguistic and semantic legitimacy of the $N$-best hypotheses is rather limited. In this paper, we propose a novel   mechanism, which is specialized for utilizing a wide range of textual information from the state-of-the-art NLP models and automatically deciding their weights to rescore the $N$-best lists for ASR systems. Specifically, we incorporate features including BERT sentence embedding, topic vector, and perplexity scores produced by $n$-gram LM, topic modeling LM, BERT LM and RNNLM to train a rescoring model. We conduct extensive experiments based on a public dataset, and experimental results show that L2RS outperforms not only traditional rescoring methods but also its deep neural network counterparts by a substantial improvement of 20.67\% in terms of NDCG@10. L2RS paves the way for developing more effective rescoring models for ASR. 
 Event detection , a sub-task of event extraction, involves identifying triggers and categorizing event mentions. Existing methods primarily rely upon supervised learning and require large-scale labeled event datasets which are unfortunately not readily available in many real-life applications. In this paper, we consider and reformulate the ED task with limited labeled data as a  problem. We propose a , which exploits  to not only learn better prototypes for event types, but also produce more robust sentence encodings for event mentions. Differing from vanilla prototypical networks simply computing event prototypes by averaging, which only consume event mentions once, our model is more robust and is capable of distilling contextual information from event mentions for multiple times due to the multi-hop mechanism of DMNs. The experiments show that DMB-PN not only deals with sample scarcity better than a series of baseline models but also performs more robustly when the variety of event types is relatively large and the instance quantity is extremely small. 
 Multiple-Choice Reading Comprehension  requires the model to read the passage and question, and select the correct answer among the given options. Recent state-of-the-art models have achieved impressive  performance on multiple MCRC datasets. However, such performance may not reflect the model's true ability of language understanding and reasoning.  % In this work, we aim to investigate two critical research problems: 1) How does BERT achieve high performance on MCRC datasets? and 2) What is needed to perform well on MCRC datasets?  In this work, we adopt two approaches to investigate what BERT learns from MCRC datasets: 1) an un-readable data attack, in which we add keywords to confuse BERT, leading to a significant performance drop; and 2) an un-answerable data training, in which we train BERT on partial or shuffled input. Under un-answerable data training, BERT achieves unexpectedly high performance.  Based on our experiments on the 5 key MCRC datasets --- RACE, MCTest, MCScript, MCScript2.0, DREAM --- we observe that 1) fine-tuned BERT mainly learns how keywords lead to correct prediction, instead of learning semantic understanding and reasoning; and 2) BERT does not need correct syntactic information to solve the task; 3) there exists artifacts in these datasets such that they can be solved even without the full context. 
 Preventable adverse events as a result of medical errors present a growing concern in the healthcare system. As drug-drug interactions  may lead to preventable adverse events, being able to extract DDIs from drug labels into a machine-processable form is an important step toward effective dissemination of drug safety information. Herein, we tackle the problem of jointly extracting drugs and their interactions, including interaction , from drug labels. Our deep learning approach entails composing various intermediate representations, including graph-based context derived using graph convolutions  with a novel attention-based gating mechanism , which are combined in meaningful ways to predict on all subtasks jointly. Our  model is trained and evaluated on the 2018 TAC DDI corpus. Our GCA model in conjunction with transfer learning performs at 39.20\% F1 and 26.09\% F1 on entity recognition  and relation extraction  respectively on the first official test set and at 45.30\% F1 and 27.87\% F1 on ER and RE respectively on the second official test set corresponding to an improvement over our prior best results by up to 6 absolute F1 points. After controlling for available training data, the proposed model exhibits state-of-the-art performance for this task. %Preventable adverse events as a result of medical errors present a growing concern in the healthcare system. As drug-drug interactions  may lead to preventable adverse events, being able to extract DDIs from drug labels into a machine-processable form is an important step toward effective dissemination of drug safety information. In this study, we tackle the problem of jointly extracting drugs and their interactions, including interaction , from drug labels. Our deep learning approach entails composing various intermediate representations including sequence and graph based context, where the latter is derived using graph convolutions  with a novel attention-based gating mechanism . These representations are then composed in meaningful ways to handle all subtasks jointly. To overcome scarcity in training data, we additionally propose transfer learning by pre-training on related DDI data. Our  model is trained and evaluated on the 2018 TAC DDI corpus. Our GCA model in conjunction with transfer learning performs at 39.20\% F1 and 26.09\% F1 on entity recognition  and relation extraction  respectively on the first official test set and at 45.30\% F1 and 27.87\% F1 on ER and RE respectively on the second official test set corresponding to an improvement over our prior best results by up to 6 absolute F1 points. After controlling for available training data, our model exhibits state-of-the-art performance by improving over the next comparable best outcome by roughly three F1 points in ER and 1.5 F1 points in RE evaluation across two official test sets. 
  Morphological tagging is challenging for morphologically rich languages due to the large target space and the need for more training data to minimize model sparsity. Dialectal variants of morphologically rich languages suffer more as they tend to be more noisy and have less resources. In this paper we explore the use of multitask learning and adversarial training to address morphological richness and dialectal variations in the context of full morphological tagging. We use multitask learning for joint morphological modeling for the features within two dialects, and as a knowledge-transfer scheme for cross-dialectal modeling. We use adversarial training to learn dialect invariant features that can help the knowledge-transfer scheme from the high to low-resource variants.  We work with two dialectal variants: Modern Standard Arabic  and Egyptian Arabic  as a case study. Our models achieve state-of-the-art results for both. Furthermore, adversarial training provides more significant improvement when using smaller training datasets in particular.   
 In this paper we propose a Sequential Representation Quantization AutoEncoder  to learn from primarily unpaired audio data and produce sequences of representations very close to phoneme sequences of speech utterances. This is achieved by proper temporal segmentation to make the representations phoneme-synchronized, and proper phonetic clustering to have total number of distinct representations close to the number of phonemes. Mapping between the distinct representations and phonemes is learned from a small amount of annotated paired data. Preliminary experiments on LJSpeech demonstrated the learned representations for vowels have relative locations in latent space in good parallel to that shown in the IPA vowel chart defined by linguistics experts. With less than 20 minutes of annotated speech, our method outperformed existing methods on phoneme recognition and is able to synthesize intelligible speech that beats our baseline model. 
   This document describes the findings of the Third Workshop on Neural Generation and Translation, held in concert with the annual conference of the Empirical Methods in Natural Language Processing .   First, we summarize the research trends of papers presented in the proceedings.   Second, we describe the results of the two shared tasks 1) efficient neural machine translation  where participants were tasked with creating NMT systems that are both accurate and efficient, and  2) document-level generation and translation  where participants were tasked with developing systems that generate summaries from structured data, potentially with assistance from text in another language. 
     We consider the situation in which a user has collected a small set of documents on a cohesive topic, and they want to retrieve additional documents on this topic from a large collection. Information Retrieval  solutions treat the document set as a query, and look for similar documents in the collection. We propose to extend the IR approach by treating the problem as an instance of positive-unlabeled  learning---i.e., learning binary classifiers from only positive  and unlabeled  data.     Utilizing PU learning for text with big neural networks is a largely unexplored field. We discuss various challenges in applying PU learning to the setting, showing that the standard implementations of state-of-the-art PU solutions fail.      We propose solutions for each of the challenges and empirically validate them with ablation tests. We demonstrate the effectiveness of the new method using a series of experiments of retrieving PubMed abstracts adhering to fine-grained topics, showing improvements over the common IR solution and other baselines. 
 Clinical notes contain an extensive record of a patient's health status, such as smoking status or the presence of heart conditions. However, this detail is not replicated within the structured data of electronic health systems.  Phenotyping, the extraction of patient conditions from free clinical text, is a critical task which supports a variety of downstream applications such as decision support and secondary use of medical records.  Previous work has resulted in systems which are high performing but require hand engineering, often of rules .  Recent work in pretrained contextualized language models  have enabled advances in representing text for a variety of tasks.  We therefore explore several architectures for modeling phenotyping that rely solely on BERT representations of the clinical note, removing the need for manual engineering. We find these architectures are competitive with or outperform existing state of the art methods on two phenotyping tasks.  
     Most neural machine translation systems still translate sentences in isolation. To make further progress, a promising     line of research additionally considers the surrounding context in order to provide the model potentially missing source-side information, as well as to maintain a coherent output. One difficulty in training such larger-context  machine translation systems is that context may be missing from many parallel examples. To circumvent this issue, two-stage approaches, in which sentence-level translations are post-edited in context, have recently been proposed. In this paper, we instead consider the viability of filling in the missing context. In particular, we consider three distinct approaches to generate the missing context: using random contexts, applying a copy heuristic or generating it with a language model. In particular, the copy heuristic significantly helps with lexical coherence, while using completely random contexts hurts performance on many long-distance linguistic phenomena. We also validate the usefulness of tagged back-translation. In addition to improving BLEU scores as expected, using back-translated data helps larger-context machine translation systems to better capture long-range phenomena.     % or retrieving similar sentence pairs.  
 Recently BERT has been adopted in state-of-the-art text summarization models for document encoding. However, such BERT-based extractive models use the sentence as the minimal selection unit, which often results in redundant or uninformative phrases in the generated summaries.  As BERT is pre-trained on sentence pairs, not documents, the long-range dependencies between sentences are not well captured. % method To address these issues, we present a graph-based discourse-aware neural summarization model - DiscoBert.  By utilizing discourse segmentation to extract discourse units  as candidates, DiscoBert provides a fine-grained granularity for extractive selection, which helps reduce redundancy in extracted summaries.  Based on this, two discourse graphs are further proposed:  RST Graph based on RST discourse trees; and  Coreference Graph based on coreference mentions in the document. DiscoBert first encodes the extracted discourse units with BERT, and then uses a graph convolutional network to capture the long-range dependencies among discourse units through the constructed graphs. Experimental results on two popular summarization datasets demonstrate that DiscoBert outperforms state-of-the-art methods by a significant margin.  
 This paper proposes a deep neural network model for jointly modeling Natural Language Understanding and Dialogue Management in goal-driven dialogue systems. There are three parts in this model. A Long Short-Term Memory  at the bottom of the network encodes utterances in each dialogue turn into a turn embedding. Dialogue embeddings are learned by a LSTM at the middle of the network, and updated by the feeding of all turn embeddings. The top part is a forward Deep Neural Network which converts dialogue embeddings into the Q-values of different dialogue actions. The cascaded LSTMs based reinforcement learning network is jointly optimized by making use of the rewards received at each dialogue turn as the only supervision information. There is no explicit NLU and dialogue states in the network. Experimental results show that our model outperforms both traditional Markov Decision Process  model and single LSTM with Deep Q-Network on meeting room booking tasks. Visualization of dialogue embeddings illustrates that the model can learn the representation of dialogue states.   
 %Personalized dialogue systems have received increasing attention recently. Existing personalized dialogue models tend to employ the meta-learning framework that first finds the initial parameters, then fine-tunes on a few personal utterances. However, fine-tuning can only make slight changes to the initial parameters, resulting in similar dialogue models for different tasks. In this paper, we propose to customize a dialogue model with unique network structures for each user. Concretely, we introduce a private network to the dialogue model, whose structure will evolve during training to better capture the unique characteristics of the user. The private network is only trained on the corpora of the corresponding user, and similar users can share partial private module for data reuse purpose. Experiment results show that our algorithm excels all the baselines in terms of personality, quality, and diversity measurement. %However, . and generation models are less vulnerable to input changes due to the discrete nature of the language data. As a result, meta-learning based methods tend to produce similar dialogues models for different tasks.   Training the generative models with minimal corpus is one of the critical challenges for building open-domain dialogue systems. Existing methods tend to use the meta-learning framework which pre-trains the parameters on all non-target tasks then fine-tunes on the target task. However, fine-tuning distinguishes tasks from the parameter perspective but ignores the model-structure perspective, resulting in similar dialogue models for different tasks. In this paper, we propose an algorithm that can customize a unique dialogue model for each task in the few-shot setting. In our approach, each dialogue model consists of a shared module, a gating module, and a private module. The first two modules are shared among all the tasks, while the third one will differentiate into different network structures to better capture the characteristics of the corresponding task. The extensive experiments on two datasets show that our method outperforms all the baselines in terms of task consistency, response quality, and diversity.      
         In this paper, we report improved results of the Fake News Challenge Stage 1  stance detection task.         This gain in performance is due to the generalization power of large language models based on Transformer         architecture, invented, trained and publicly released over the last two years.         Specifically  we improved the  best performing model adding BERT sentence embedding of input sequences         as a model feature,  we fine-tuned BERT, XLNet, and RoBERTa transformers on  extended dataset and         obtained state-of-the-art results on  task.     
 %[DONE] We propose a multi-scale octave convolution layer to learn robust speech representations efficiently. %with a more efficient CNN design.  Octave convolutions were introduced by Chen et al~ in the computer vision field to reduce the spatial redundancy of the feature maps by decomposing the output of a convolutional layer into feature maps at two different spatial resolutions, one octave apart. This approach improved the efficiency as well as the accuracy of the CNN models. The accuracy gain was attributed to the enlargement of the receptive field in the original input space. We argue that octave convolutions likewise improve the robustness of learned representations due to the use of average pooling in the lower resolution group, acting as a low-pass filter. We test this hypothesis by evaluating on two noisy speech corpora -- Aurora-4 and AMI. We extend the octave convolution concept to multiple resolution groups and %we reduce the spatial resolution by using  multiple octaves.  %By doing this, we aim to further improve the robustness of learned representations while also reducing the computational cost.  To  %improve the explainability of our models and to  evaluate the robustness of the inferred representations, we report the similarity between clean and noisy encodings using an affine projection loss as a proxy robustness measure. The results show that proposed method reduces the WER by up to 6.6\% relative for Aurora-4 and 3.6\% for AMI, while improving the computational efficiency of the CNN acoustic models.  
   Standard neural machine translation  is on the assumption of document-level context independent. Most existing document-level NMT methods only focus on briefly introducing document-level information but fail to concern about selecting the most related part inside document context. The capacity of memory network for detecting the most relevant part of the current sentence from the memory provides a natural solution for the requirement of modeling document-level context by document-level NMT. In this work, we propose a Transformer NMT system with associated memory network  to both capture the document-level context and select the most salient part related to the concerned translation from the memory. Experiments on several tasks show that the proposed method significantly improves the NMT performance over strong Transformer baselines and other related studies. 
 Recently, generative adversarial networks  have gathered a lot of interest. Their efficiency in generating unseen samples of high quality, especially images, has improved over the years. In the field of Natural Language Generation , the use of the adversarial setting to generate meaningful sentences has shown to be difficult for two reasons: the lack of existing architectures to produce realistic sentences and the lack of evaluation tools. In this paper, we propose an adversarial architecture related to the conditional GAN  that generates sentences according to a given image . This attempt is the first that uses no pre-training or reinforcement methods. We also explain why our experiment settings can be safely evaluated and interpreted for further works. 
 In many review classification applications, a fine-grained analysis of the reviews is desirable, because different segments   of a review may focus on different aspects of the entity in question.  However, training supervised models for segment-level classification requires segment labels, which may be more difficult or expensive to obtain than review labels.  In this paper, we employ Multiple Instance Learning  and use only weak supervision in the form of a single label per review. First, we show that when inappropriate MIL aggregation functions are used, then MIL-based networks are outperformed by simpler baselines. Second, we propose a new aggregation function based on the sigmoid attention mechanism and show that our proposed model outperforms the state-of-the-art models for segment-level sentiment classification .  Finally, we highlight the importance of fine-grained predictions in an important public-health application: finding actionable reports of foodborne illness. We show that our model achieves 48.6\% higher recall compared to previous models, thus increasing the chance of identifying previously unknown foodborne outbreaks. 
 Recent advances in reading comprehension have resulted in  models that surpass human performance when the answer is contained in a single, continuous passage of text. However, complex Question Answering  typically requires multi-hop reasoning -- i.e. the integration of supporting facts from different sources, to infer the correct answer.  This paper proposes Document Graph Network , a message passing architecture for the identification of supporting facts over a graph-structured representation of text.  The evaluation on HotpotQA shows that DGN obtains competitive results when compared to a reading comprehension baseline operating on raw text, confirming the relevance of structured representations for supporting multi-hop reasoning.  
   We propose a deep factorization model for typographic analysis that disentangles  from . Specifically, a variational inference procedure factors each training glyph into the combination of a character-specific content embedding and a latent font-specific style variable. The underlying generative model combines these factors through an asymmetric transpose convolutional process to generate the image of the glyph itself. When trained on corpora of fonts, our model learns a manifold over font styles that can be used to analyze or reconstruct new, unseen fonts. On the task of reconstructing missing glyphs from an unknown font given only a small number of observations, our model outperforms both a strong nearest neighbors baseline and a state-of-the-art discriminative model from prior work.  
 Very deep CNNs achieve state-of-the-art results in both computer vision and speech recognition, but are difficult to train.  The most popular way to train very deep CNNs is to  use shortcut connections  together with batch normalization . Inspired by Self-Normalizing Neural Networks, we propose  the self-normalizing deep CNN  based acoustic model topology, by removing the SC/BN and replacing the typical RELU activations with scaled exponential linear unit  in ResNet-50.  SELU activations make the network self-normalizing and remove the need for both shortcut connections and batch normalization.  Compared to ResNet-50, we can achieve the same or lower  word error rate   while boosting both training and inference speed by 60\%-80\%. We also explore other model inference optimization schemes to further reduce latency for production use.   
 Traditional sequence-to-sequence  models and other variations of the attention-mechanism such as hierarchical attention have been applied to the text summarization problem. Though there is a hierarchy in the way humans use language by forming paragraphs from sentences and sentences from words, hierarchical models have usually not worked that much better than their traditional seq2seq counterparts. This effect is mainly because either the hierarchical attention mechanisms are too sparse using hard attention or noisy using soft attention. In this paper, we propose a method based on extracting the highlights of a document; a key concept that is conveyed in a few sentences. In a typical text summarization dataset consisting of documents that are 800 tokens in length , capturing long-term dependencies is very important, e.g., the last sentence can be grouped with the first sentence of a document to form a summary.  LSTMs  proved useful for machine translation. However, they often fail to capture long-term dependencies while modeling long sequences. To address these issues, we have adapted Neural Semantic Encoders  to text summarization, a class of memory-augmented neural networks by improving its functionalities and proposed a novel hierarchical NSE that outperforms similar previous models significantly. The quality of summarization was improved by augmenting linguistic factors, namely lemma, and Part-of-Speech  tags, to each word in the dataset for improved vocabulary coverage and generalization. The hierarchical NSE model on factored dataset outperformed the state-of-the-art by nearly 4 ROUGE points. We further designed and used the first GPU-based self-critical Reinforcement Learning model. 
 Human behavior refers to the way humans act and interact. Understanding human behavior is a cornerstone of observational practice, especially in psychotherapy. An important cue of behavior analysis is the dynamical changes of emotions during the conversation. Domain experts integrate emotional information in a highly nonlinear manner, thus, it is challenging to explicitly quantify the relationship between emotions and behaviors.  In this work, we employ deep transfer learning to analyze their inferential capacity and contextual importance. We first train a network to quantify emotions from acoustic signals and then use information from the emotion recognition network as features for behavior recognition. We treat this emotion-related information as behavioral primitives and further train higher level layers towards behavior quantification. Through our analysis, we find that emotion-related information is an important cue for behavior recognition. Further, we investigate the importance of emotional-context in the expression of behavior by constraining  the neural networks' contextual view of the data. This demonstrates that the sequence of emotions is critical in behavior expression. To achieve these frameworks we employ hybrid architectures of convolutional networks and recurrent networks to extract emotion-related behavior primitives and facilitate automatic behavior recognition from speech. 
 The goal of representation learning of knowledge graph is to encode both entities and relations into a low-dimensional embedding spaces. Many recent works have demonstrated the benefits of knowledge graph embedding on knowledge graph completion task, such as relation extraction. However, we observe that: 1) existing method just take direct relations between entities into consideration and fails to express high-order structural relationship between entities; 2) these methods just leverage relation triples of KGs while ignoring a large number of attribute triples that encoding rich semantic information. To overcome these limitations, this paper propose a novel knowledge graph embedding method, named , which is inspired by the recent developments of graph convolutional networks . KANE can capture both high-order structural and attribute information of KGs in an efficient, explicit and unified manner under the graph convolutional networks framework. Empirical results on three datasets show that KANE significantly outperforms seven state-of-arts methods. Further analysis verify the efficiency of our method and the benefits brought by the attention mechanism. 
 We propose a neural network architecture for learning vector representations of hotels. Unlike previous works, which typically only use user click information for learning item embeddings, we propose a framework that combines several sources of data, including user clicks, hotel attributes , amenity information , and geographic information.  During model training, a joint embedding is learned from all of the above information. We show that including structured attributes  about hotels enables us to make better predictions in a downstream task than when we rely exclusively on click data. We train our embedding model on more than 40 million user click sessions from a leading online travel platform, and learn embeddings for more than one million hotels.  Our final learned embeddings integrate distinct sub-embeddings  for user clicks, hotel attributes, and geographic information,  providing an interpretable representation that can be used flexibly depending on the application. We show empirically that our model generates high-quality representations that boost the performance of a hotel recommendation system in addition to other applications.  An important advantage of the proposed neural model is that it addresses the cold-start problem for hotels with insufficient historical click information by incorporating additional hotel attributes which are available for all hotels.  
 Vision and language tasks have benefited from attention. There have been a number of different attention models proposed. However, the scale at which attention needs to be applied has not been well examined. Particularly, in this work we propose a new method Granular Multi-modal Attention, where we aim to particularly address the question of the right granularity at which one needs to attend while solving Visual Dialog task. The proposed method shows improvement in both image and text attention networks. We then propose a granular Multi-modal Attention network that jointly attends on the image and text granules and shows the best performance. With this work, we observe that obtaining granular attention and doing exhaustive Multi-modal Attention appears to be the best way to attend while solving visual dialog. %Vision and language tasks have benefited from attention. There have been a number of different attention models proposed. In this paper, we evaluate these for the task of visual dialog. We then propose a new method that we term Granular attention that aims at attending at a semantic `granule' for the visual dialog task. This shows improvement in both image and text attention networks. We then propose a granular Multi-modal Attention network that jointly attends on the image and text granules and shows the best performance. With this work, we observe that obtaining semantic granules and doing exhaustive Multi-modal Attention appears to be the best way to attend while solving visual dialog. 
 In order to successfully perform tasks specified by natural language instructions, an artificial agent operating in a visual world needs to map words, concepts, and actions from the instruction to visual elements in its environment. This association is termed as Task-Oriented Grounding. In this work, we propose a novel Dynamic Attention Network architecture for the efficient multi-modal fusion of text and visual representations which can generate a robust definition of state for the policy learner. Our model assumes no prior knowledge from visual and textual domains and is an end to end trainable. For a 3D visual world where the observation changes continuously, the attention on the visual elements tends to be highly co-related from one-time step to the next. We term this as "Dynamic Attention". In this work, we show that Dynamic Attention helps in achieving grounding and also aids in the policy learning objective. Since most practical robotic applications take place in the real world where the observation space is continuous, our framework can be used as a generalized multi-modal fusion unit for robotic control through natural language.  We show the effectiveness of using 1D convolution over Gated Attention Hadamard product on the rate of convergence of the network. We demonstrate that the cell-state of a Long Short Term Memory  is a natural choice for modeling Dynamic Attention and show through visualization that the generated attention is very close to how humans tend to focus on the environment. 
 Tone is a prosodic feature used to distinguish words in many languages, some of which are endangered and scarcely documented. In this work, we use unsupervised representation learning to identify probable clusters of syllables that share the same phonemic tone. Our method extracts the pitch for each syllable, then trains a convolutional autoencoder to learn a low-dimensional representation for each contour. We then apply the mean shift algorithm to cluster tones in high-density regions of the latent space. Furthermore, by feeding the centers of each cluster into the decoder, we produce a prototypical contour that represents each cluster. We apply this method to spoken multi-syllable words in Mandarin Chinese and Cantonese and evaluate how closely our clusters match the ground truth tone categories. Finally, we discuss some difficulties with our approach, including contextual tone variation and allophony effects. 
 Transient loud intrusions, often occurring in noisy environments, can completely overpower speech signal and lead to an inevitable loss of information. While existing algorithms for noise suppression can yield impressive results, their efficacy remains limited for very low signal-to-noise ratios or when parts of the signal are missing. To address these limitations, here we propose an end-to-end framework for speech inpainting, the context-based retrieval of missing or severely distorted parts of time-frequency representation of speech. The framework is based on a convolutional U-Net trained via deep feature losses, obtained using speechVGG, a deep speech feature extractor pre-trained on an auxiliary word classification task. Our evaluation results demonstrate that the proposed framework can recover large portions of missing or distorted time-frequency representation of speech, up to 400 ms and 3.2 kHz in bandwidth. In particular, our approach provided a substantial increase in STOI \& PESQ objective metrics of the initially corrupted speech samples. Notably, using deep feature losses to train the framework led to the best results, as compared to conventional approaches. 
 How can neural networks perform so well on compositional tasks even though they lack explicit compositional representations? We use a novel analysis technique called ROLE to show that recurrent neural networks perform well on such tasks by converging to solutions which implicitly represent symbolic structure. This method uncovers a symbolic structure which, when properly embedded in vector space, closely approximates the encodings of a standard seq2seq network trained to perform the compositional SCAN task. We verify the causal importance of the discovered symbolic structure by showing that, when we systematically manipulate hidden embeddings based on this symbolic structure, the model's output is changed in the way predicted by our analysis. 
 In this paper, we propose a two-step training procedure for source separation via a deep neural network. In the first step we learn a transform  to a latent space where masking-based separation performance using oracles is optimal. For the second step, we train a separation module that operates on the previously learned space. In order to do so, we also make use of a scale-invariant signal to distortion ratio  loss function that works in the latent space, and we prove that it lower-bounds the SI-SDR in the time domain. We run various sound separation experiments that show how this approach can obtain better performance as compared to systems that learn the transform and the separation module jointly. The proposed methodology is general enough to be applicable to a large class of neural network end-to-end separation systems. %Single-channel sound source separation has greatly benefited from modern deep learning approaches that utilize a mask-based architecture which is trained end-to-end using a time-domain loss. In essence, the mixture signal is passed through an encoder in order to get a latent representation and then the separation module estimates some masks that correspond to each sound source. The masked latent representations are translated to time-domain signals through a linear decoder. In this work, we propose a general two-step training framework of all these mask based architectures. First we train the encoder and decoder parts individually in order to find the latent representation of the mixture and the clean sources which serve as targets. In the second step we train the separation module to reconstruct these latent targets by forcing them to maximize scale-invariant signal to distortion ratio  on the latent domain. We prove that this measure lower bounds the time-domain SI-SDR separation performance by  that lower bounds the  which consists of individually parts  that instead of using short-time Fourier transform  %Recent works propose to utilize a mask  %Still praying to Paris. 
% Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing . The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.\footnote{\label{fn:oss}\url{https://github.com/google-research/text-to-text-transfer-transformer}} 
 Traditional event detection classifies a word or a phrase in a given sentence for a set of predefined event types. The limitation of such predefined set is that it prevents the adaptation of the event detection models to new event types. We study a novel formulation of event detection that describes types via several keywords to match the contexts in documents. This facilitates the operation of the models to new types. We introduce a novel feature-based attention mechanism for convolutional neural networks for event detection in the new formulation. Our extensive experiments demonstrate the benefits of the new formulation for new type extension for event detection as well as the proposed attention mechanism for this problem.  
   In this paper, we proposed to apply meta learning approach for low-resource automatic speech recognition . We formulated ASR for different languages as different tasks, and meta-learned the initialization parameters from many pretraining languages to achieve fast adaptation on unseen target language, via recently proposed model-agnostic meta learning algorithm . We evaluated the proposed approach using six languages as pretraining tasks and four languages as target tasks. Preliminary results showed that the proposed method, MetaASR, significantly outperforms the state-of-the-art multitask pretraining approach on all target languages with different combinations of pretraining languages. In addition, since MAML's model-agnostic property, this paper also opens new research direction of applying meta learning to more speech-related applications. 
 Generated hateful and toxic content by a portion of users in social media is a rising phenomenon that motivated researchers to dedicate substantial efforts to the challenging direction of hateful content identification. We not only need an efficient automatic hate speech detection model based on advanced machine learning and natural language processing, but also a sufficiently large amount of annotated data to train a model. The lack of a sufficient amount of labelled hate speech data, along with the existing biases, has been the main issue in this domain of research. To address these needs, in this study we introduce a novel transfer learning approach based on an existing pre-trained language model called BERT . More specifically, we investigate the ability of BERT at capturing hateful context within social media content by using new fine-tuning methods based on transfer learning. To evaluate our proposed approach, we use two publicly available datasets that have been annotated for racism, sexism, hate, or offensive content on Twitter. The results show that our solution obtains considerable performance on these datasets in terms of precision and recall in comparison to existing approaches. Consequently, our model can capture some biases in data annotation and collection process and can potentially lead us to a more accurate model. 	  
 Suicide is a critical issue in modern society. Early detection and prevention of suicide attempts should be addressed to save people's life.  Current suicidal ideation detection methods include clinical methods based on the interaction between social workers or experts and the targeted individuals and machine learning techniques with feature engineering or deep learning for automatic detection based on online social contents.  This paper is the first survey that comprehensively introduces and discusses the methods from these categories. Domain-specific applications of suicidal ideation detection are reviewed according to their data sources, i.e., questionnaires, electronic health records, suicide notes, and online user content. Several specific tasks and datasets are introduced and summarized to facilitate further research.  Finally, we summarize the limitations of current work and provide an outlook of further research directions. 
 Manipulating data, such as weighting data examples or augmenting with new instances, has been increasingly used to improve model training. Previous work has studied various rule- or learning-based approaches designed for specific types of data manipulation. In this work, we propose a new method that supports learning different manipulation schemes with the same gradient-based algorithm. Our approach builds upon a recent connection of supervised learning and reinforcement learning , and adapts an off-the-shelf reward learning algorithm from RL for joint data manipulation learning and model training. Different parameterization of the ``data reward'' function instantiates different manipulation schemes. We showcase data augmentation that learns a text transformation network, and data weighting that dynamically adapts the data sample importance. Experiments show the resulting algorithms significantly improve the image and text classification performance in low data regime and class-imbalance problems. %\footnote{Code available at https://github.com/tanyuqian/learning-data-manipulation}. %in the presence of very limited or imbalanced data labels. % bert, text/image % gradient descent 
 % The classification of textual data often yields important information. Most  classifiers work in a closed world setting where the classifier is trained on a known corpus, and then it is tested on unseen examples that belong to one of the classes seen during training. Despite the usefulness of this design, often there is a need to classify unseen examples that { % 
 The task of learning a sentiment classification model that adapts well to any target domain, different from the source domain, is a challenging problem. Majority of the existing approaches focus on learning a common representation by leveraging both source and target data during training. In this paper, we introduce a two-stage training procedure that leverages weakly supervised datasets for developing simple lift-and-shift-based predictive models without being exposed to the target domain during the training phase. Experimental results show that transfer with weak supervision from a source domain to various target domains provides performance very close to that obtained via supervised training on the target domain itself. 
 With the information explosion of news articles, personalized news recommendation has become important for users to quickly find news that they are interested in. Existing methods on news recommendation mainly include collaborative filtering methods which rely on direct user-item interactions and content based methods  which characterize the content of user reading history. Although these methods have achieved good performances, they still suffer from data sparse problem, since most of them  fail to extensively exploit high-order structure information  %  in news recommendation systems.  In this paper, we  propose  to build a heterogeneous graph  to explicitly model the interactions among users, news and latent topics. The incorporated topic information would help indicate a user's interest and alleviate the sparsity of user-item interactions. Then we take advantage of graph neural networks to learn  user and news representations that encode high-order structure information by  propagating embeddings over the graph.  The learned user embeddings with complete historic user clicks capture the users' long-term interests. We also consider a user's short-term interest using the recent  reading history with an attention based LSTM model. Experimental results on real-world datasets  show that our proposed model significantly outperforms  state-of-the-art methods  on news recommendation.   
     Task-oriented dialog presents a difficult challenge encompassing multiple problems including multi-turn language understanding and generation, knowledge retrieval and reasoning, and action prediction. Modern dialog systems typically begin by converting conversation history to a symbolic object referred to as {: a single neural network model that takes conversation history and an external knowledge source as input and jointly produces both text response and action to be taken by the system as output. The model learns to reason on the provided knowledge source with weak supervision signal coming from the text generation and the action prediction tasks, hence removing the need for belief state annotations. In the MultiWOZ dataset, we study the effect of distant supervision, and the size of knowledge base on model performance. We find that the Neural Assistant without belief states is able to incorporate external knowledge information achieving higher factual accuracy scores compared to Transformer. In settings comparable to reported baseline systems, Neural Assistant when provided with oracle belief state significantly improves language generation performance.     
   % Alex: In the abstract, I think we should stress more the advantages of melgan compared to other competing techniques. I think that the three messages should be a) we managed to train GAN for audio effectively for the first time, b) we have SOTA for mel inversion, c) our model is much faster than competition Previous works  have found that generating coherent raw audio waveforms with GANs is challenging. In this paper, we show that it is possible to train GANs reliably to generate high quality coherent waveforms by introducing a set of architectural changes and simple training techniques. Subjective evaluation metric  shows the effectiveness of the proposed approach for high quality mel-spectrogram inversion. To establish the generality of the proposed techniques, we show qualitative results of our model in speech synthesis, music domain translation and unconditional music synthesis. We evaluate the various components of the model through ablation studies and suggest a set of guidelines to design general purpose discriminators and generators for conditional sequence synthesis tasks. Our model is non-autoregressive, fully convolutional, with significantly fewer parameters than competing models and generalizes to unseen speakers for mel-spectrogram inversion. Our pytorch implementation runs at more than 100x faster than realtime on GTX 1080Ti GPU and more than 2x faster than real-time on CPU, without any hardware specific optimization tricks.  
 Transformer with self-attention has achieved great success in the area of nature language processing. Recently, there have been a few studies on transformer for end-to-end speech recognition, while its application for hybrid acoustic model is still very limited. In this paper, we revisit the transformer-based hybrid acoustic model, and propose a model structure with interleaved self-attention and 1D convolution, which is proven to have faster convergence and higher recognition accuracy. We also study several aspects of the transformer model, including the impact of the positional encoding feature, dropout regularization, as well as training with and without time restriction. We show competitive recognition results on the public Librispeech dataset when compared to the Kaldi baseline at both cross entropy training and sequence training stages. For reproducible research, we release our source code and recipe within the PyKaldi2 toolbox. 
 We present Mockingjay as a new speech representation learning approach, where bidirectional Transformer encoders are pre-trained on a large amount of unlabeled speech. Previous speech representation methods learn through conditioning on past frames and predicting information about future frames. Whereas Mockingjay is designed to predict the current frame through jointly conditioning on both past and future contexts.  The Mockingjay representation improves performance for a wide range of downstream tasks, including phoneme classification, speaker recognition, and sentiment classification on spoken content, while outperforming other approaches.  Mockingjay is empirically powerful and can be fine-tuned with downstream models, with only 2 epochs we further improve performance dramatically. In a low resource setting with only 0.1\% of labeled data, we outperform the result of Mel-features that uses all 100\% labeled data.    %the proposed representation can significantly benefit downstream tasks that require human labels and supervised training.%闁瑥褰為弰顖氼樋妞佹娈 
 Relation extraction  seeks to detect and classify semantic relationships between entities, which provides useful information for many NLP applications.  Since the state-of-the-art RE models require large amounts of manually annotated data and language-specific resources to achieve high accuracy, it is very challenging to transfer an RE model of a resource-rich language to a resource-poor language. In this paper, we propose a new approach for cross-lingual RE model transfer based on bilingual word embedding mapping. It projects word embeddings from a target language to a source language, so that a well-trained source-language neural network RE model can be directly applied to the target language. Experiment results show that the proposed approach achieves very good performance for a number of target languages on both in-house and open datasets, using a small bilingual dictionary with only 1K word pairs. 
  %Submitted Abstract %Despite the recent success of deep neural networks in various spheres of Artificial Intelligence, their interpretability remains a challenge. We analyze the representations learned by neural machine translation  models at various levels of granularity and evaluate their quality through relevant extrinsic properties. More precisely, we seek answers to the following questions:  How accurately is word-morphology captured within the learned representations?  Do the representations capture long-range syntactic dependencies? and  Do the representations capture lexical semantics? We conduct a thorough investigation along several parameters:  Which layers in the architecture capture each of these linguistic phenomena;  How does the choice of translation unit  impact the linguistic properties captured by the underlying representations?  Do the encoder and decoder learn differently and independently? iv) Do the representations learned from multilingual NMT models, capture same amount of linguistic information as their bilingual counterparts? Our data-driven, quantitative evaluation illuminates important aspects in NMT models and their ability to capture various linguistic phenomena. We show that deep NMT models learn a non-trivial amount of linguistic information. Notable findings include the following observations: i) Word morphology is captured at the lower layers of the model;  In contrast, lexical semantics or non-local syntactic and semantic dependencies are better represented at the higher layers of the model;  Representations learned using characters are more informed about word morphology compared to those learned using subword units; and  Representations learned from multilingual models are richer compared to the bilingual models.   %Deep Neural Networks  have quickly become the predominant approach to all artificial intelligence  tasks including Machine Translation . %In contrast to their traditional counterparts, deep neural networks are trained in an end-to-end fashion. This provides a simple yet elegant process that gives model full flexibility to optimize for the desired task.  %However, despite the recent success of these models, their interpretability %of the DNN models  Despite the recent success of deep neural networks in %the field of  natural language processing  and other spheres of artificial intelligence , their interpretability remains a challenge. %and their ``black-box'' nature presents a significant barrier in understanding and predicting model's behavior.  %There have been several efforts to debug the process and to diagnose what is learned within intermediate representations of these models.  %In this paper, we  We analyze the representations learned by neural machine translation  models at various levels of granularity and %empirically  evaluate their quality %of the representations  through relevant extrinsic properties. %, %that are  %important for the task of machine translation.  In particular, we seek answers to the following questions:  How accurately is word-structure captured within the learned representations, %a property that is especially important when  which is an important aspect in translating %languages with rich  morphologically-rich languages?  %if the models are able to  Do the representations capture long-range dependencies, and effectively handle  syntactically divergent languages?  Do the representations capture lexical semantics? %and how does the model map a sequence of subword units to a meaning representation?  We conduct a thorough investigation along several parameters:  Which layers in the architecture capture each of these linguistic phenomena;  How does the choice of translation unit  impact the linguistic properties captured by the underlying representations?  Do the encoder and decoder learn differently and independently?  Do the representations learned by multilingual NMT models capture the same amount of linguistic information as their bilingual counterparts? %and v) how robust they are towards noise, such as spelling errors in the input. %State-of-the-art NMT systems address data-sparsity using subword or character units. However,  %All previous work on interpreting deep NLP models, analyzed word-based representations only. We perform a qualitative comparison of the representations learned %when the NMT models are trained using words/character or BPE-based subword units, in terms of morphology, syntax and semantics. We additionally analyze how robust these representations are towards noise, such as spelling errors in the input.  %Our methodology is simple but effective. We generate feature representations from different components of a trained model and use the activations to train an auxiliary classification task . The quality of the trained classifier is considered a proxy for judging the quality of the representations, with respect to the auxiliary task.   Our data-driven, quantitative evaluation illuminates important aspects in NMT models and their ability to capture various linguistic phenomena. We show that deep NMT models trained in an end-to-end fashion, without being provided any direct supervision during the %initial  training process, learn a non-trivial amount of linguistic information. Notable findings include the following observations: i) Word morphology and part-of-speech information are captured at the lower layers of the model;  In contrast, %global %high level  %properties such as  lexical semantics or non-local syntactic and semantic dependencies are better represented at the higher layers of the model;  Representations learned using characters are more informed about word-morphology compared to those learned using subword units; and  Representations learned by multilingual models are richer compared to  bilingual models. %\todo{YB: I'm wondering if we should add more observations to be more complete, or alternatively not give any specific observations in the abstract. ND: I think it would be sufficient to highlight only important results. But feel free to add any other finding that you think is interesting enough}  %; and  and are more robust in sparse %and noisy data conditions, v) subword units provide a good balance between handling word-morphology  and capturing non-local dependencies .  
 Social media currently provide a window on our lives, making it possible to learn how people from different places, with different backgrounds, ages, and genders use language. In this work we exploit a newly-created Arabic dataset with ground truth age and gender labels to learn these attributes both individually and in a multi-task setting at the sentence level. Our models are based on variations of deep bidirectional neural networks. More specifically, we build models with gated recurrent units and bidirectional encoder representations from transformers . We show the utility of multi-task learning  on the two tasks and identify task-specific attention as a superior choice in this context. We also find that a single-task BERT model outperform our best MTL models on the two tasks. We report tweet-level accuracy of 51.43\% for the age task  and 65.30\% on the gender task , both of which outperforms our baselines with a large margin. Our models are language-agnostic, and so can be applied to other languages.  
  This work introduces a machine translation task where the output is aimed at audiences of different levels of target language proficiency. We collect a high quality dataset of news articles available in English and Spanish, written for diverse grade levels and propose a method to align segments across comparable bilingual articles. The resulting dataset makes it possible to train multi-task sequence-to-sequence models that translate Spanish into English targeted at an easier reading grade level than the original Spanish. We show that these multi-task models outperform pipeline approaches that translate and simplify text independently.  
   Deep learning models have achieved state-of-the-art performances on many relation extraction datasets. A common element in these deep learning models involves the pooling mechanisms where a sequence of hidden vectors is aggregated to generate a single representation vector, serving as the features to perform prediction for RE. Unfortunately, the models in the literature tend to employ different strategies to perform pooling for RE, leading to the challenge to determine the best pooling mechanism for this problem, especially in the biomedical domain. In order to answer this question, in this work, we conduct a comprehensive study to evaluate the effectiveness of different pooling mechanisms for the deep learning models in biomedical RE. The experimental results suggest that dependency-based pooling is the best pooling strategy for RE in the biomedical domain, yielding the state-of-the-art performance on two benchmark datasets for this problem. 
  %閻ｃ儳鏆愰弨閫涚啊娑撴稉  End-to-end speech recognition systems have achieved competitive results compared to traditional systems. However, the complex transformations involved between layers given highly variable acoustic signals are hard to analyze. In this paper, we present our ASR probing model, which synthesizes speech from hidden representations of end-to-end ASR to examine the information maintain after each layer calculation.  Listening to the synthesized speech, we observe gradual removal of speaker variability and noise as the layer goes deeper, which aligns with the previous studies on how deep network functions in speech recognition.  This paper is the first study analyzing the end-to-end speech recognition model by demonstrating what each layer hears.  Speaker verification and speech enhancement measurements on synthesized speech are also conducted to confirm our observation further.    % we examine the information lost after each layer calculation in end-to-end ASR, by reconstructing input speech from hidden representations.   %Empirical results show that reconstructed speech reveal properties of hidden layers, %we examine what kind of information is lost after each %Deep layers  %We synthesize speech from intermediate representations of ASR. Properties of synthesized speech revealed information present in hidden layers, which is consistent with earlier findings. %we propose a straightforward approach to examine what kind of information is kept in each layers of end-to-end ASR models. information left in hidden layers %However, little is understood about the computation involved in the underlying acoustic-to-phonetic transformation given highly variable acoustic signal.  %that directly transcribe speech to text without any pre-defined alignments % and examine how information irrelevant to linguistic content, e.g. speaker, noise,  is eliminated in different model architectures. 
 In this paper, we address customer review understanding problems by using supervised machine learning approaches, in order to achieve a fully automatic review aspects categorisation and sentiment analysis. In general, such supervised learning algorithms require domain-specific expert knowledge for generating high quality labeled training data, and the cost of labeling can be very high. To achieve an in-production customer review machine learning enabled analysis tool with only a limited amount of data and within a reasonable training data collection time, we propose to use pre-trained language representation to boost model performance and active learning framework for accelerating the iterative training process. The results show that with integration of both components, the fully automatic review analysis can be achieved at a much faster pace.   
     We investigate two specific manifestations of compositionality in Neural Machine Translation  :  Productivity - the ability of the model to extend its predictions beyond the observed length in training data and  Systematicity - the ability of the model to systematically recombine known parts and rules. We evaluate a standard Sequence to Sequence model on tests designed to assess these two properties in NMT. We quantitatively demonstrate that inadequate temporal processing, in the form of poor encoder representations is a bottleneck for both Productivity and Systematicity. Motivated by the anslysis, we propose a simple pre-training mechanism which leads to a significant improvement in BLEU scores. 
 % DONE 缂佺喍绔寸拠瀛樼《 L2R forward; R2L backward % DONE latter or right ? % DONE 鐠囷妇绮忕憴锝夊櫞unbalanced translation % DONE agreement regularization閻ㄥ嫯顕╁▔ Generally, Neural Machine Translation models generate target words in a left-to-right  manner and fail to exploit any future  semantics information, which usually produces an unbalanced translation. Recent works attempt to utilize the right-to-left  decoder in bidirectional decoding to alleviate this problem. In this paper, we propose a novel Dynamic Interaction Module  to dynamically exploit target semantics from R2L translation for enhancing the L2R translation quality. Different from other bidirectional decoding approaches, DIM firstly extracts helpful target information through addressing and reading operations, then updates target semantics for tracking the interactive history. Additionally, we further introduce an agreement regularization term into the training objective to narrow the gap between L2R and R2L translations. Experimental results on NIST Chinese$\Rightarrow$English and WMT'16 English$\Rightarrow$Romanian translation tasks show that our system achieves significant improvements over baseline systems, which also reaches comparable results compared to the state-of-the-art Transformer model with much fewer parameters of it. 
 {In recent years, Deep Learning  models are becoming important due to their demonstrated success at overcoming complex learning problems. DL models have been applied effectively for different Natural Language Processing  tasks such as part-of-Speech  tagging and Machine Translation . Disease Named Entity Recognition  is a crucial task which aims at extracting disease Named Entities  from text. In this paper, a DL model for Disease-NER using dictionary information is proposed and evaluated on National Center for Biotechnology Information  disease corpus and BC5CDR dataset. Word embeddings trained over general domain texts as well as biomedical texts have been used to represent input to the proposed model. This study also compares two different Segment Representation  schemes, namely IOB2 and IOBES for Disease-NER. The results illustrate that using dictionary information, pre-trained word embeddings, character embeddings and CRF with global score improves the performance of Disease-NER system.} 
   In this paper, we focus on extracting interactive argument pairs from two posts with opposite stances to a certain topic. Considering opinions are exchanged from different perspectives of the discussing topic, we study the discrete representations for arguments to capture varying aspects in argumentation languages . Moreover, we utilize hierarchical structure to model post-wise information incorporating contextual knowledge. Experimental results on the large-scale dataset collected from  show that our proposed framework can significantly outperform the competitive baselines. Further analyses reveal why our model yields superior performance and prove the usefulness of our learned representations. 
 Textual entailment is a fundamental task in natural language processing. % .  Most approaches for solving this problem use only the textual content present in training data.  A few approaches have shown that information from external knowledge sources like knowledge graphs  can add value, in addition to the textual content, by providing background knowledge that may be critical for a task. However, the proposed models do not fully exploit the information in the usually large and noisy KGs, and it is not clear how it can be effectively encoded to be useful for entailment. We present an approach that complements text-based entailment models with information from KGs by ~using Personalized PageRank to generate contextual subgraphs with reduced noise and ~encoding these subgraphs using graph convolutional networks to capture the structural and semantic information in KGs. We evaluate our approach on multiple textual entailment datasets and show that the use of external knowledge helps the model to be robust and improves prediction accuracy. This is particularly evident in the challenging BreakingNLI dataset, where we see an absolute improvement of 5-20\% over multiple text-based entailment models. 
 This paper shows that pretraining  multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed \xlmr, significantly outperforms multilingual BERT  on a variety of cross-lingual benchmarks, including +14.6\% average accuracy on XNLI, +13\% average F1 score on MLQA, and +2.4\% F1 score on NER. \xlmr performs particularly well on low-resource languages, improving 15.7\% in XNLI accuracy for Swahili and 11.4\% for Urdu over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between  positive transfer and capacity dilution and  the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing per-language performance; \xlmr is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code, data and models publicly available.{\let\thefootnote\relax\footnotetext{@fb.com}}}\footnote{\url{https://github.com/facebookresearch/}} 
 Multi-paragraph reasoning is indispensable for open-domain question answering , which receives less attention in the current OpenQA systems. In this work, we propose a knowledge-enhanced graph neural network , which performs reasoning over multiple paragraphs with entities. To explicitly capture the entities' relatedness, KGNN utilizes relational facts in knowledge graph to build the entity graph. The experimental results show that KGNN outperforms in both distractor and full wiki settings than baselines methods on HotpotQA dataset. And our further analysis illustrates KGNN is effective and robust with more retrieved paragraphs.    
 Automatic question generation aims at the generation of questions from a context, with the corresponding answers being sub-spans of the given passage. Whereas, most of the methods mostly rely on heuristic rules to generate questions, more recently also neural network approaches have been proposed. In this work, we propose a variant of the self-attention Transformer network architectures model to generate meaningful and diverse questions. To this end, we propose an easy to use model consisting of the conjunction of the Transformer decoder GPT-2~ model with Transformer encoder BERT~ for the downstream task for question answering. The model is trained in an end-to-end fashion, where the language model is trained to produce a question-answer-aware input representation that facilitates to generate an answer focused question. Our result of neural question generation from text on the SQuAD 1.1 dataset~ suggests that our method can produce semantically correct and diverse questions. Additionally, we assessed the performance of our proposed method for the downstream task of question answering. The analysis shows that our proposed generation \& answering collaboration framework relatively improves both tasks and is particularly powerful in the semi-supervised setup. The results further suggest a robust and comparably lean pipeline %that %renders explicit terms such as domain adaption between generated and human questions unnecessary, facilitating  facilitating question generation in the small-data regime. 
  Most of the existing pre-trained language representation models neglect to consider the linguistic knowledge of texts, which can promote language understanding in NLP tasks. To benefit the downstream tasks in sentiment analysis, we propose a novel language representation model called SentiLARE, which introduces word-level linguistic knowledge including part-of-speech tag and sentiment polarity  into pre-trained models. We first propose a context-aware sentiment attention mechanism to acquire the sentiment polarity of each word with its part-of-speech tag by querying SentiWordNet. Then, we devise a new pre-training task called label-aware masked language model to construct knowledge-aware language representation. Experiments show that SentiLARE obtains new state-of-the-art performance on a variety of sentiment analysis tasks\footnote{The data, codes, and model parameters are available at \url{https://github.com/thu-coai/SentiLARE}.}.   
 This paper explores domain adaptation for enabling question answering  systems to answer questions posed against documents in new specialized domains. Current QA systems using deep neural network  technology have proven effective for answering general purpose factoid-style questions. However, current general purpose DNN models tend to be ineffective for use in new specialized domains. This paper explores the effectiveness of transfer learning techniques for this problem. In experiments on question answering in the  automobile manual domain we demonstrate that standard DNN transfer learning techniques work surprisingly well in adapting DNN models to a new domain using limited amounts of annotated training data in the new domain. 
  Deep energy-based models are powerful, but pose challenges for learning and inference~.     developed an efficient framework for energy-based models by training ``inference networks'' to approximate structured inference instead of using gradient descent.    However, their alternating optimization approach suffers from instabilities during training, requiring additional loss terms and careful hyperparameter tuning. In this paper, we contribute several strategies to stabilize and improve this joint training of energy functions and inference networks for structured prediction. We design a compound objective to jointly train both cost-augmented and test-time inference networks along with the energy function. We propose joint    parameterizations for the inference networks that encourage them to capture complementary functionality during learning. We empirically validate our strategies on two sequence labeling tasks, showing easier paths to strong performance than prior work, as well as further improvements with global energy terms. 
 Submodularity is desirable for a variety of objectives in content selection where the current neural encoder-decoder framework is inadequate. However, it has so far not been explored in the neural encoder-decoder system for text generation. {In this work,} we define diminishing attentions with submodular functions and in turn, prove the submodularity of the effective neural coverage.  The greedy algorithm approximating the solution to the submodular maximization problem is not suited to attention score optimization in auto-regressive generation. Therefore instead of following how submodular function has been widely used, we propose a simplified yet {principled} solution. The resulting attention module offers an architecturally simple  and empirically effective method to improve the coverage of neural text generation. We run experiments on three {directed} text generation tasks with different levels of recovering rate, across two modalities, three {different} neural model architectures and two training strategy variations. The results and {analyses} demonstrate that our method generalizes well across these settings, produces texts of good quality and outperforms state-of-the-art baselines.  
  QA classification system maps questions asked by humans to an appropriate answer category. A sound question classification  system model is the pre-requisite of a sound QA system. This work demonstrates phases of assembling a QA type classification model. We present a comprehensive comparison  among some machine learning based approaches used in QC for Bengali language.     
 Knowledge Graph Completion  has been proposed to improve Knowledge Graphs by filling in missing connections via link prediction or relation extraction. One of the main difficulties for KGC is a low resource problem. Previous approaches assume sufficient training triples to learn versatile vectors for entities and relations, or a satisfactory number of labeled sentences to train a competent relation extraction model. However, low resource relations are very common in KGs, and those newly added relations often do not have many known samples for training. In this work, we aim at predicting new facts under a challenging setting where only limited training instances are available. We propose a general framework called , which utilizes an adversarial procedure to help adapt knowledge/features learned from high resource relations to different but related low resource relations. Specifically, the framework takes advantage of a relation discriminator to distinguish between samples from different relations, and help learn relation-invariant features more transferable from source relations to target relations. Experimental results show that the proposed approach outperforms previous methods regarding low resource settings for both link prediction and relation extraction. 
 Translating text that diverges from the training domain is a key challenge for machine translation. Domain robustness---the generalization of models to unseen test domains---is low for both statistical  and neural machine translation . In this paper, we study the performance of SMT and NMT models on out-of-domain test sets. We find that in unknown domains, SMT and NMT suffer from very different problems: SMT systems are mostly adequate but not fluent, while NMT systems are mostly fluent, but not adequate. For NMT, we identify such hallucinations  as a key reason for low domain robustness. To mitigate this problem, we empirically compare methods that are reported to improve adequacy or in-domain robustness in terms of their effectiveness at improving domain robustness. In experiments on German$\to$English OPUS data, and German$\to$Romansh  we find that several methods improve domain robustness. While those methods do lead to higher BLEU scores overall, they only slightly increase the adequacy of translations compared to SMT. % We find that in unknown domains, SMT systemsmostly lack fluency, while NMT systems lack adequacy.   %Translating text that diverges from the training domain is a key challenge for neural machine translation . Domain robustness---the generalization of models to unseen test domains---is low compared to statistical machine translation. %In this paper, we investigate the performance of NMT on out-of-domain test sets, and ways to improve it. %We observe that hallucination  is common in out-of-domain settings, and investigate ways to mitigate this problem. We empirically compare methods that are reported to improve adequacy , out-of-domain translation , or robustness against adversarial examples , as well as noisy channel models, in terms of their effectiveness at improving domain robustness. %In experiments on German$\to$English OPUS data, and German$\to$Romansh, a low-resource scenario, we find that several methods improve domain robustness. Reconstruction stands out as a method that not only improves automatic scores, but also shows improvements in a manual assessment of adequacy, albeit at some loss in fluency. 
 %   Neural Machine Translation  can be improved by taking document-level context information into consideration. However, previous work usually focuses on limited contexts because of degraded performance on larger contexts. In this paper, we investigate document-level NMT using large contexts with three main contributions:  Different from previous work which pertrained models on large-scale sentence-level parallel corpora, we make use of pretrained language models, specifically BERT , which are trained on monolingual documents;  We propose context manipulation methods to control the influence of large contexts, which lead to comparable results on systems using small and large contexts;  We introduce a multi-task training for regularization to avoid models overfitting our training corpora, which further improves our systems together with a deeper encoder. Experiments are conducted on the widely used IWSLT data sets with three language pairs, i.e., Chinese--English, French--English and Spanish--English. Results show that our systems are significantly better than three previously reported document-level systems.    Previous work on document-level NMT usually focuses on limited contexts because of degraded performance on larger contexts. In this paper, we investigate on using large contexts with three main contributions:  Different from previous work which pertrained models on large-scale sentence-level parallel corpora, we use pretrained language models, specifically BERT , which are trained on monolingual documents;  We propose context manipulation methods to control the influence of large contexts, which lead to comparable results on systems using small and large contexts;  We introduce a multi-task training for regularization to avoid models overfitting our training corpora, which further improves our systems together with a deeper encoder. Experiments are conducted on the widely used IWSLT data sets with three language pairs, i.e., Chinese--English, French--English and Spanish--English. Results show that our systems are significantly better than three previously reported document-level systems. 
 Based on recent advances in natural language modeling and those in text generation capabilities, we propose a novel data augmentation method for text classification tasks. We use a powerful pre-trained neural network model to artificially synthesize new labeled data for supervised learning. We mainly focus on cases with scarce labeled data. Our method, referred to as \term{language-model-based data augmentation }, involves fine-tuning a state-of-the-art language generator to a specific task through an initial training phase on the existing  labeled data. Using the fine-tuned model and given a class label, new sentences for the class are generated. Our process then filters these new sentences by using a classifier trained on the original data.  In a series of experiments, we show that LAMBADA improves classifiers閳 performance on a variety of datasets. Moreover, LAMBADA significantly improves upon the state-of-the-art techniques for data augmentation, specifically those applicable to text classification tasks with little data. % For instance, we achieve absolute improvement of { X on Y task and Z on T} task.  % Furthermore, we show that our new approach is able to promote classifier accuracy and achieve superior results even over naive semi-supervised approaches. 
 Despite the success of neural machine translation , simultaneous neural machine translation , the task of translating in real time before a full sentence has been observed, remains challenging due to the syntactic structure difference and simultaneity requirements. In this paper, we propose a general framework for adapting neural machine translation to translate simultaneously. Our framework contains two parts: prefix translation that utilizes a consecutive NMT model to translate source prefixes and a stopping criterion that determines when to stop the prefix translation. Experiments on three translation corpora and two language pairs show the efficacy of the proposed framework on balancing the quality and latency in adapting NMT to perform simultaneous translation.  
 The Transformer translation model employs residual connection and layer normalization to ease the optimization difficulties caused by its multi-layer encoder/decoder structure. Previous research shows that even with residual connection and layer normalization, deep Transformers still have difficulty in training, and particularly Transformer models with more than 12 encoder/decoder layers fail to converge. In this paper, we first empirically demonstrate that a simple modification made in the official implementation, which changes the computation order of residual connection and layer normalization, can significantly ease the optimization of deep Transformers. We then compare the subtle differences in computation order in considerable detail, and present a parameter initialization method that leverages the Lipschitz constraint on the initialization of Transformer parameters that effectively ensures training convergence. In contrast to findings in previous research we further demonstrate that with Lipschitz parameter initialization, deep Transformers with the  computation order can converge, and obtain significant BLEU improvements with up to 24 layers. In contrast to previous research which focuses on deep encoders, our approach additionally enables Transformers to also benefit from deep decoders. 
  We explore the abilities of character recurrent neural network  for hashtag segmentation. Our approach to the task is the following: we generate synthetic training dataset according to frequent  $n$-grams that satisfy predefined morpho-syntactic patterns to avoid any manual annotation. The active learning strategy limits the training dataset and selects informative training subset. The approach does not require any language-specific settings and is compared for two languages, which differ in inflection degree.    
 We introduce three memory-augmented Recurrent Neural Networks  and explore their capabilities on a series of simple language modeling tasks whose solutions require stack-based mechanisms. We provide the first demonstration of neural networks recognizing the generalized Dyck languages, which express the core of what it means to be a language with hierarchical structure. Our memory-augmented architectures are easy to train in an end-to-end fashion and can learn the Dyck languages over as many as six parenthesis-pairs, in addition to two deterministic palindrome languages and the string-reversal transduction task, by emulating pushdown automata. Our experiments highlight the increased modeling capacity of memory-augmented models over simple RNNs, while inflecting our understanding of the limitations of these models.  
 We propose a novel text generation task, namely -driven Question Generation. We start from the observation that the Question Generation task has traditionally been considered as the dual problem of Question Answering, hence tackling the problem of generating a question given the text that contains its answer. Such questions can be used to evaluate machine reading comprehension. However, in real life, and especially in conversational settings, humans tend to ask questions %based on a previous piece of information  with the goal of  their knowledge and/or  aspects of previously gathered information. We refer to these inquisitive questions as -driven: these questions are generated with the goal of obtaining new information  which is not present in the input text. In this work, we experiment on this new task using a conversational Question Answering  dataset; further, since the majority of QA dataset are not built in a conversational manner, we describe a methodology to derive data for this novel task from non-conversational QA data. We investigate several automated metrics to measure the different properties of , and experiment different approaches on the -driven Question Generation task, including model pre-training and reinforcement learning. Finally, we report a qualitative evaluation of the generated outputs.   
 Training dialog policies for speech-based virtual assistants requires a plethora of conversational data.  The data collection phase is often expensive and time consuming due to human involvement.  To address this issue, a common solution is to build user simulators for data generation.  For the successful deployment of the trained policies into real world domains, it is vital that the user simulator mimics realistic conditions.  In particular, speech-based assistants are heavily affected by automatic speech recognition and language understanding errors, hence the user simulator should be able to simulate similar errors.  In this paper, we review the existing error simulation methods that induce errors at audio, phoneme, text, or semantic level;  and conduct detailed comparisons between the audio-level and text-level methods.  In the process, we improve the existing text-level method by introducing confidence score prediction and out-of-vocabulary word mapping.  We also explore the impact of audio-level and text-level methods on learning a simple clarification dialog policy to recover from errors to provide insight on future improvement for both approaches. 
 In this work, we present several deep learning models for the automatic diacritization of Arabic text. Our models are built using two main approaches, viz. Feed-Forward Neural Network  and Recurrent Neural Network , with several enhancements such as 100-hot encoding, embeddings, Conditional Random Field  and Block-Normalized Gradient . The models are tested on the only freely available benchmark dataset and the results show that our models are either better or on par with other models, which require language-dependent post-processing steps, unlike ours. Moreover, we show that diacritics in Arabic can be used to enhance the models of NLP tasks such as Machine Translation  by proposing the   approach. 
 Automatic post-editing , which aims to correct errors in the output of machine translation systems in a post-processing step, is an important task in natural language processing. While recent work has achieved considerable performance gains by using neural networks, how to model the copying mechanism for APE remains a challenge. In this work, we propose a new method for modeling copying for APE. To better identify translation errors, our method learns the representations of source sentences and system outputs in an interactive way. These representations are used to explicitly indicate which words in the system outputs should be copied, which is useful to help CopyNet  better generate post-edited translations. Experiments on the datasets of the WMT 2016-2017 APE shared tasks show that our approach outperforms all best published results. \footnote{The source code is available at \url{https://github.com/THUNLP-MT/L2Copy4APE}} 
 Neural machine translation systems tend to fail on less decent inputs despite its significant efficacy, which may significantly harm the credibility of these systems閳ユ攩athoming how and when neural-based systems fail in such cases is critical for industrial maintenance. Instead of collecting and analyzing bad cases using limited handcrafted error features, here we investigate this issue by generating adversarial examples via a new paradigm based on reinforcement learning. Our paradigm could expose pitfalls for a given performance metric, e.g., BLEU, and could target any given neural machine translation architecture. We conduct experiments of adversarial attacks on two mainstream neural machine translation architectures, RNN-search, and Transformer. The results show that our method efficiently produces stable attacks with meaning-preserving adversarial examples. We also present a qualitative and quantitative analysis for the preference pattern of the attack, demonstrating its capability of pitfall exposure. 
  Recent work has highlighted the advantage of jointly learning grounded sentence representations  from multiple languages.  However, the data used in these studies has  been limited to an  scenario: the same images annotated with sentences  in multiple languages. We focus on the more realistic   scenario in which there is no overlap between the images in multilingual image--caption datasets. We confirm that training with aligned data results in better grounded sentence representations than training with  data, as measured by image--sentence retrieval performance. %, which may be caused by the lack of coherence between the disjoint data sets.  %\todo{The problem that we solve is not cross-domain is just the lack %of alignment.} In order to close this gap in performance, we propose a  method to generate   English--German--image triplets from the disjoint sets. The method works by first training a model on the  disjoint data, and then creating new triples across datasets using sentence similarity  under the learned model. Experiments show that pseudopairs improve image--sentence retrieval performance compared to disjoint training,  %both when  and  sets are available,  %or when there are only  sets,  despite requiring no external data or models.  However, we do find that using an external machine translation model  to generate the synthetic data sets results in better performance. 
     Generating relevant responses in a dialog is challenging, and requires not only proper modeling of context in the conversation,     but also being able to generate fluent sentences during inference.     In this paper, we propose a two-step framework based on generative adversarial nets for generating conditioned responses.     Our model first learns a meaningful representation of sentences by autoencoding, and then learns to map an input query to the response representation, which is in turn decoded as a response sentence.     Both quantitative and qualitative evaluations show that our model generates more fluent, relevant, and diverse responses than existing state-of-the-art methods.\footnote{The code is available at \url{https://github.com/vikigenius/conditional_text_generation}}        This work is licensed under a Creative Commons       Attribution 4.0 International License.      License details:      \url{http://creativecommons.org/licenses/by/4.0/}. } 
     Large-scale pre-trained language model such as BERT has achieved great success in language understanding tasks. However, it remains an open question how to utilize BERT for language generation. In this paper, we present a novel approach, Conditional Masked Language Modeling , to enable the finetuning of BERT on target generation tasks. The finetuned BERT  is exploited as extra supervision to improve conventional Seq2Seq models  for better text generation performance.     By leveraging BERT's idiosyncratic bidirectional nature, distilling knowledge learned in BERT can encourage auto-regressive Seq2Seq models to plan ahead, imposing global sequence-level supervision for coherent text generation.     Experiments show that the proposed approach significantly outperforms strong Transformer baselines on multiple language generation tasks such as machine translation and text summarization.     Our proposed model also achieves new state of the art on IWSLT German-English and English-Vietnamese MT datasets.\footnote{Code is available at {https://github.com/ChenRocks/Distill-BERT-Textgen}.} 
 %Attention mechanisms have improved the performance of NLP tasks while providing for appearance of model interpretability.  Attention mechanisms have improved the performance of NLP tasks while allowing models to remain explainable. Self-attention is currently widely used, however interpretability is difficult due to the numerous attention distributions. Recent work has shown that model representations can benefit from label-specific information, while facilitating interpretation of predictions. We introduce the Label Attention Layer: a new form of self-attention where attention heads represent labels. We test our novel layer by running constituency and dependency parsing experiments and show our new model obtains new state-of-the-art results for both tasks on both the Penn Treebank  and Chinese Treebank. Additionally, our model requires fewer self-attention layers compared to existing work. Finally, we find that the Label Attention heads learn relations between syntactic categories and show pathways to analyze errors. 
 This paper presents some preliminary investigations of a new co-attention mechanism in neural transduction models. We propose a paradigm, termed Two-Headed Monster , which consists of two symmetric encoder modules and one decoder module connected with co-attention. As a specific and concrete implementation of THM, Crossed Co-Attention Networks  are designed based on the Transformer model. We demonstrate CCNs on WMT 2014 EN-DE and WMT 2016 EN-FI translation tasks and our model outperforms the strong Transformer baseline by 0.51  and 0.74  BLEU points on EN-DE and by 0.17  and 0.47  BLEU points on EN-FI. 
  % asterisk footnote with equal contribution {1} \renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext{Denotes equal contribution.} {0}  %Crowdsourced data, such as the corpus for the End-to-End NLG Challenge , often includes texts whose semantics do not completely match the included meaning representation . %, forcing systems trained on this data to learn content planning and generation jointly.   %This paper investigates the impact of semantic noise on state-of-the-art neural generation systems. Neural natural language generation  systems are known for their pathological outputs, i.e.\ generating text which is unrelated to the input specification. %In this paper, we explore the impact of noise in the training data.  In this paper, we show the impact of semantic noise on state-of-the-art NNLG models which implement different semantic control mechanisms. We find that cleaned data can improve semantic correctness by up to 97\%, while maintaining fluency.  We also find that the most common error is omitting information, rather than hallucination.   %  We confirm %show  that exactly matching MRs and texts %can  % lead to more reliable, fact-accurate NLG system outputs. %  In doing so, we also present and release a cleaned version of the E2E Corpus based on heuristic semantic filtering to correct the MRs with respect to the texts they accompany. %: adding and removing elements from the MR based on the text.   %In addition to showing the impact of this improved dataset on several neural generation models, we argue that this dataset enables future research into human-like content selection for the restaurant recommendation domain.   %We find that these improved MRs result in reduced semantic errors for two neural NLG systems using different forms of semantic control and argue that the dataset will prove useful for researchers seeking to separate content selection from other aspects of NLG. 
 	Learned dynamic weighting of the conditioning signal  has  	been shown to improve neural language generation in a variety of  	settings. The weights applied when generating a particular output  	sequence have also been viewed as providing a potentially explanatory  	insight into the internal workings of the generator. In this paper, we  	reverse the direction of this connection and ask whether through the  	control of the attention of the model we can control its output.  	Specifically, we take a standard neural image captioning model that uses  	attention, and fix the attention to pre-determined areas in the image.  	We evaluate whether the resulting output is more likely to mention the  	class of the object in that area than the normally generated caption.  	We introduce three effective methods to control the attention and find 	that these are producing expected results in up to 28.56\% of the cases.  
  Answering complex questions involving multiple entities and relations is a challenging task.  Logically, the answer to a complex question should be derived by decomposing the complex question into multiple simple sub-questions and then answering those sub-questions.  %Previous methods usually decompose %and derive an answer to the original question from the decomposed pieces, then compute the sub-questions in an arbitrary order.  Existing work has followed this strategy but has not attempted to optimize the order how those sub-questions are answered. As a result, the sub-questions are answered in an arbitrary order, leading to larger search space and higher risk of missing an answer.   %However, there could be multiple correct computation orders, each possibly leading to different performance. Sub-questions have different search space and knowledge utility, thus having different risk of wrong predictions and clarification effects. Wrong middle results and less informative answers could hurt performance due to error accumulation. An optimized answering order could help alleviate this issue via prioritizing more informative, less risky sub-questions.  In this paper, we propose a novel reinforcement learning  approach to answering complex questions that can learn a policy to dynamically decide which sub-question should be answered at each state of reasoning. We leverage the expected value-variance criterion to enable the learned policy to balance between the risk and utility of answering a sub-question. Experiment results show that the RL approach can substantially improve the optimality of ordering the sub-questions, leading to improved accuracy of question answering. The proposed method for learning to order sub-questions is general and can thus be potentially combined with many existing ideas for answering complex questions to enhance their performance.  %proposed our approach is not only effective for answering complex questions on a knowledge graph but can also provide an explanation of the answer given.  
 In end-to-end dialogue modeling and agent learning, it is important to  effectively learn knowledge from data, and  fully utilize heterogeneous information, e.g., dialogue act flow and utterances. However, the majority of existing methods cannot simultaneously satisfy the two conditions. For example, rule definition and data labeling during system design take too much manual work, and sequence-to-sequence methods only model one-side utterance information. In this paper, we propose a novel joint end-to-end model by multi-task representation learning, which can capture the knowledge from heterogeneous information through automatically learning knowledgeable low-dimensional embeddings from data, named with DialogAct2Vec. The model requires little manual work for intervention in system design and we find that the multi-task learning can greatly improve the effectiveness of representation learning. Extensive experiments on a public dataset for restaurant reservation show that the proposed method leads to significant improvements against the state-of-the-art baselines on both the act prediction task and utterance prediction task. 
   Medical relation extraction discovers relations between entity mentions in text, such as research articles.   For this task, dependency syntax has been recognized as a crucial source of features.   Yet in the medical domain, 1-best parse trees suffer from relatively low accuracies, diminishing their usefulness.   We investigate a method to alleviate this problem by utilizing dependency forests.   Forests contain many possible decisions and therefore have higher recall but more noise compared with 1-best outputs.   A graph neural network is used to represent the forests, automatically distinguishing the useful syntactic information from parsing noise.   Results on two biomedical benchmarks show that our method outperforms the standard tree-based methods, giving the state-of-the-art results in the literature. 
 Negation is an important characteristic of language, and a major component of information extraction from text. This subtask is of considerable importance to the biomedical domain. Over the years, multiple approaches have been explored to address this problem: Rule-based systems, Machine Learning classifiers, Conditional Random Field models, CNNs and more recently BiLSTMs. In this paper, we look at applying Transfer Learning to this problem. First, we extensively review previous literature addressing Negation Detection and Scope Resolution across the 3 datasets that have gained popularity over the years: the BioScope Corpus, the Sherlock dataset, and the SFU Review Corpus. We then explore the decision choices involved with using BERT, a popular transfer learning model, for this task, and report state-of-the-art results for scope resolution across all 3 datasets. Our model, referred to as NegBERT, achieves a token level F1 score on scope resolution of 92.36 on the Sherlock dataset, 95.68 on the BioScope Abstracts subcorpus, 91.24 on the BioScope Full Papers subcorpus, 90.95 on the SFU Review Corpus, outperforming the previous state-of-the-art systems by a significant margin. We also analyze the model閳ユ獨 generalizability to datasets on which it is not trained. \\ \newline \Keywords{Negation, Scope Resolution, Transfer Learning
 End-to-end Speech Translation  models have several advantages such as lower latency, smaller model size, and less error compounding over conventional pipelines that combine Automatic Speech Recognition  and text Machine Translation  models. However, collecting large amounts of parallel data for ST task is more difficult compared to the ASR and MT tasks. Previous studies have proposed the use of transfer learning approaches to overcome the above difficulty. These approaches benefit from weakly supervised training data, such as ASR speech-to-transcript or MT text-to-text translation pairs.  However, the parameters in these models are updated independently of each task, which may lead to sub-optimal solutions. In this work, we adopt a meta-learning algorithm to train a modality agnostic multi-task model that transfers knowledge from source tasks=ASR+MT  to target task=ST where ST task severely lacks data. In the meta-learning phase, the parameters of the model are exposed to vast amounts of speech transcripts  and text translations . During this phase, parameters are updated in such a way to understand speech, text representations,  the relation between them, as well as act as a good initialization point for the target ST task. We evaluate the proposed meta-learning approach for ST tasks on English-German  and English-French  language pairs from the Multilingual Speech Translation Corpus . Our method outperforms the previous transfer learning approaches and sets new state-of-the-art results for En-De and En-Fr ST tasks by obtaining 9.18, and 11.76 BLEU point improvements, respectively. 
  Neural dependency parsing has proven very effective, achieving state-of-the-art results on numerous domains and languages. Unfortunately, it requires large amounts of labeled data, that is costly and laborious to create. In this paper we propose a self-training algorithm that alleviates this annotation bottleneck by training a parser on its own output. Our Deep Contextualized Self-training  algorithm utilizes representation models trained on sequence labeling tasks that are derived from the parser's output when applied to unlabeled data, and integrates these models with the base parser through a gating mechanism.  We conduct experiments across multiple languages, both in low resource in-domain and in cross-domain setups, and demonstrate that DCST substantially outperforms traditional self-training as well as recent semi-supervised training methods. \footnote{Our code is publicly available at \url{https://github.com/rotmanguy/DCST}.} \footnote{This paper was accepted to TACL in September 2019. } 
  Novel contexts may often arise in complex querying scenarios such as in evidence-based medicine  involving biomedical literature, that may not explicitly refer to entities or canonical concept forms occurring in any fact- or rule-based knowledge source such as an ontology like the UMLS. Moreover, hidden associations between candidate concepts meaningful in the current context, may not exist within a single document, but within the collection, via alternate lexical forms. %Our objective therefore, is to implicitly learn and encode the novel contexts that may relate two or more documents by learning the best possible intrinsic document representations, incorporating both local contextual information on word usage occurring within a document, as well as global information on term usage occurring across the document collection.  %We aim to achieve this by using word embeddings trained on the whole corpus in our models, within a novel sequence-to-set pipeline,  that offers a generic paradigm for unsupervised semantic tagging of documents in any domain.  Thus, to predict such semantically related concept tags, and inspired by the recent success of sequence-to-sequence neural models in delivering the state-of-the-art in a wide range of NLP tasks, %and building upon the successes of previous neural generalized language model--based methods,  we develop a novel sequence-to-set framework with neural attention for learning document representations that can effect term transfer within the corpus, for semantically tagging a large collection of documents.   We demonstrate that our proposed method can be effective in both a supervised multi-label classification setup for text categorization, as well as in a unique unsupervised setting with no human-annotated document labels that uses no external knowledge resources and only corpus-derived term statistics to drive the training. Further, we show that semi-supervised training using our architecture on large amounts of unlabeled data can augment performance on the text categorization task when limited labeled data is available. % We evaluate our method on supervised, semi-supervised and unsupervised setups of semantic tagging of documents via multi-label classification from document collections having various levels of human-derived tag labels.  Our approach to generate document encodings employing our sequence-to-set models for inference of semantic tags, gives to the best of our knowledge, the state-of-the-art for both, the unsupervised query expansion task for the TREC CDS 2016 challenge dataset when evaluated on an Okapi BM25--based document retrieval system; and also over the MLTM baseline , for both supervised and semi-supervised multi-label prediction tasks on the del.icio.us and Ohsumed datasets. We will make our code and data publicly available.  %We evaluate our framework on the TREC 2016 clinical decision support challenge dataset having no human-derived document labels for the unsupervised task; on a collection of tagged documents from the del.icio.us folksonomy for the supervised task; as well as a tagged collection of medline abstracts from the Ohsumed dataset for the semi-supervised task, using only a fraction of the labeled data for training and majority of the data without human-annotated tags. %, evaluating the inferred semantic tags from this setup via complex query reformulation of clinical queries in this same dataset, in a pseudo-relevance feedback-based query expansion setting.  %Our approach to generate document encodings employing our sequence-to-set models for inference of semantic tags, gives to the best of our knowledge, the state-of-the-art when evaluated on the TREC challenge dataset query expansion, on top of a standard Okapi BM25--based document retrieval system for the unsupervised task, and statistically significant AUC over the baseline, for both the supervised and semi-supervised tasks for the del.icio.us and Ohsumed datasets.  
  %Speech signal is a rich source of speaker information specifically, speaker's identity, which poses severe privacy threat to end users of automatic speech recognition  systems. Previous studies leverage homomorphic encryption and bit string comparison based techniques to preserve the privacy of user. However, such methods add computational overhead to the system and reduce its efficiency. In this paper, we propose to combine speaker-adversarial loss with connectionist temporal classification  and attention loss in an end-to-end ASR framework which implicitly removes speaker's identity from the learnt representation. We also conduct closed- and open-set speaker identification experiments over representations extracted from ASR, with and without adversarial loss, to measure the anonymization achieved using proposed approach in terms of speaker identification accuracy, verfication equal error rate  and ASR word error rate . The results indicate that the adversarial training makes the encoded representation speaker-invariant and reduces the capability of speaker identification significantly without any loss of ASR performance.  Automatic speech recognition  is a key technology in many services and applications. This typically requires user devices to send their speech data to the cloud for ASR decoding. As the speech signal carries a lot of information about the speaker, this raises serious privacy concerns. As a solution, an encoder may reside on each user device which performs local computations to anonymize the representation. In this paper, we focus on the protection of speaker identity and study the extent to which users can be recognized based on the encoded representation of their speech as obtained by a deep encoder-decoder architecture trained for ASR. Through speaker identification and verification experiments on the Librispeech corpus with open and closed sets of speakers, we show that the representations obtained from a standard architecture still carry a lot of information about speaker identity. We then propose to use adversarial training to learn representations that perform well in ASR while hiding speaker identity. Our results demonstrate that adversarial training dramatically reduces the closed-set classification accuracy, but this does not translate into increased open-set verification error hence into increased protection of the speaker identity in practice. We suggest several possible reasons behind this negative result.  % methods to ascertain that speaker's identity can be derived from encoded representation learnt during end-to-end ASR and study adversarial training based approach to remove factors contributing towards speaker's identity thereby anonymizing the representations. We show that adversarial training makes the encoded representation speaker-invariant and reduces the capability of speaker identification significantly in open- and closed-set verification.  %We conduct experiments over Librispeech corpus and present our results with respect to speaker identification accuracy, verfication equal error rate and ASR word error rate.    
 Most existing deep multi-task learning models are based on parameter sharing, such as hard sharing, hierarchical sharing, and soft sharing. How choosing a suitable sharing mechanism depends on the relations among the tasks, which is not easy since it is difficult to understand the underlying shared factors among these tasks. In this paper, we propose a novel parameter sharing mechanism, named . Given multiple tasks, our approach automatically finds a sparse sharing structure. We start with an over-parameterized base network, from which each task extracts a subnetwork. The subnetworks of multiple tasks are partially overlapped and trained in parallel. We show that both hard sharing and hierarchical sharing can be formulated as particular instances of the sparse sharing framework. We conduct extensive experiments on three sequence labeling tasks. Compared with single-task models and three typical multi-task learning baselines, our proposed approach achieves consistent improvement while requiring fewer parameters. 
     Supervised training of neural models to duplicate question detection in community Question Answering  requires large amounts of labeled question pairs,      which are costly to obtain.     %     To minimize this cost, recent works thus often used alternative methods, e.g., adversarial domain adaptation. %     In this work, we propose two novel methods:  the automatic generation of duplicate questions, and  weak supervision using the title and body of a question. We show that both can achieve improved performances even though they do not require any labeled data. We provide comprehensive comparisons of popular training strategies,     which provides important insights on how to best train models in different scenarios. %     We show that our proposed approaches are more effective in many cases because they can utilize larger amounts of unlabeled data from \cqa forums.     Finally, we also show that our proposed approach for weak supervision with question title and body information is also an effective method to train \cqa answer selection models without direct answer supervision.      % %     %     % %     % % % % % % % % % % %   % % % % %  
   Modeling semantic plausibility requires commonsense knowledge about   the world and has been used as a testbed for exploring various knowledge representations.    Previous work has focused specifically   on modeling physical plausibility and shown that distributional   methods fail when tested in a supervised setting. At the same time,   distributional models, namely large pretrained language models, have led to improved results for   many natural language understanding tasks. In this work, we show   that these pretrained language models are in fact effective at   modeling physical plausibility in the supervised setting. We   therefore present the more difficult problem of learning to model   physical plausibility directly from text. We create a training set   by extracting attested events from a large corpus, and we provide a   baseline for training on these attested events in a self-supervised   manner and testing on a physical plausibility task. We believe results   could be further improved by injecting explicit commonsense knowledge   into a distributional model. 
 Recurrent Neural Networks  are known as powerful models for handling sequential data, and especially widely utilized in various natural language processing tasks. In this paper, we propose Contextual Recurrent Units  for enhancing local contextual representations in neural networks. The proposed CRU injects convolutional neural networks  into the recurrent units to enhance the ability to model the local context and reducing word ambiguities even in bi-directional RNNs. We tested our CRU model on sentence-level and document-level modeling NLP tasks: sentiment classification and reading comprehension. Experimental results show that the proposed CRU model could give significant improvements over traditional CNN or RNN models, including bidirectional conditions, as well as various state-of-the-art systems on both tasks, showing its promising future of extensibility to other NLP tasks as well. 
  Perhaps the simplest type of multilingual transfer learning is instance-based transfer learning, in which data from the target language and the auxiliary languages are pooled, and a single model is learned from the pooled data.  It is not immediately obvious when instance-based transfer learning will improve performance in this multilingual setting: for instance, a plausible conjecture is this kind of transfer learning would help only if the  auxiliary languages were very similar to the target. Here we show that at large scale, this method is surprisingly effective, leading to positive transfer on all of the 35 target languages and two tasks tested.  We analyze this improvement and argue that the most natural explanation, namely direct vocabulary overlap between languages, only partially explains the performance gains: in fact, we demonstrate  target-language improvement can occur after adding data from an auxiliary language with no vocabulary in common with the target. This surprising result is due to the effect of transitive vocabulary overlaps between pairs of auxiliary and target languages.  
   Learning word representations has garnered greater attention in the recent past due to its diverse text applications. Word embeddings encapsulate the syntactic and semantic regularities of sentences. Modelling word embedding as multi-sense gaussian mixture distributions, will additionally capture uncertainty and polysemy of words.  We propose to learn the Gaussian mixture representation of words using a Kullback-Leibler  divergence based objective function. The KL divergence based energy function provides a better distance metric which can effectively capture entailment and distribution similarity among the words. Due to the intractability of KL divergence for Gaussian mixture, we go for a KL approximation between Gaussian mixtures. We perform qualitative and quantitative experiments on benchmark word similarity and entailment datasets which demonstrate the effectiveness of the proposed approach.\\ 
 Recent state-of-the-art language models utilize a two-phase training procedure comprised of  unsupervised pre-training on unlabeled text, and  fine-tuning for a specific supervised task. More recently, many studies have been focused on trying to improve these models by enhancing the pre-training phase, either via better choice of hyperparameters or by leveraging an improved formulation. However, the pre-training phase is computationally expensive and often done on private datasets. In this work, we present a method that leverages BERT's fine-tuning phase to its fullest, by applying an extensive number of parallel classifier heads, which are enforced to be orthogonal, while adaptively eliminating the weaker heads during training. Our method allows the model to converge to an optimal number of parallel classifiers, depending on the given dataset at hand.   We conduct an extensive inter- and intra-dataset evaluations, showing that our method improves the robustness of BERT, sometimes leading to a +9\% gain in accuracy. These results highlight the importance of a proper fine-tuning procedure, especially for relatively smaller-sized datasets. Our code is attached as supplementary and our models will be made completely public.%{ consider changing the focus for the robustness} 
 The impressive performance of neural networks on natural language processing tasks attributes to their ability to model complicated word and phrase compositions. To explain how the model handles semantic compositions, we study hierarchical explanation of neural network predictions. We identify non-additivity and context independent importance attributions within hierarchies as two desirable properties for highlighting word and phrase compositions. We show some prior efforts on hierarchical explanations, e.g. contextual decomposition,   do not satisfy the desired properties mathematically, leading to inconsistent explanation quality in different models. In this paper, we start by proposing a formal and general way to quantify the importance of each word and phrase. Following the formulation, we propose Sampling and Contextual Decomposition  algorithm and Sampling and Occlusion  algorithm. Human and metrics evaluation on both LSTM models and BERT Transformer models on multiple datasets show that our algorithms outperform prior hierarchical explanation algorithms. Our algorithms help to visualize semantic composition captured by models, extract classification rules and improve human trust of models\footnote{Project page:}. 
   In recent literature, contextual pretrained Language Models   demonstrated their potential in generalizing the knowledge to several Natural Language Processing  tasks including supervised Word Sense Disambiguation , a challenging problem in the field of Natural Language Understanding . %The goal of this task is to distinguish the various meanings of words based only on their respective contexts .%   However, word representations from these models are still very dense, costly in terms of memory footprint, as well as minimally interpretable.  In order to address such issues, we propose a new supervised biologically inspired technique for transferring large pre-trained language model representations into a compressed representation, for the case of WSD.   %Our approach takes ELMo contextualized word embeddings as input to a deep autoencoder used to learn sparse representations of the words in a latent space. These sparse representations are then provided to a sparse associative memory , which should result in different activations for words used in different contexts.%  Our produced representation contributes to increase the general interpretability of the framework and to decrease memory footprint, while enhancing performance.     
 Distant Supervised Relation Extraction  is usually formulated as a problem of classifying a bag of sentences that contain two query entities, into the predefined relation classes. Most existing methods consider those relation classes as distinct semantic categories while ignoring their potential connection to query entities.  In this paper, we propose to leverage this connection to improve the relation extraction accuracy. Our key ideas are twofold:  For sentences belonging to the same relation class, the expression style, i.e. words choice, can vary according to the query entities. To account for this style shift, the model should adjust its parameters in accordance with entity types.   Some relation classes are semantically similar, and the entity types appear in one relation may also appear in others. Therefore, it can be trained cross different relation classes and further enhance those classes with few samples, i.e., long-tail classes.   To unify these two arguments, we developed a novel Dynamic Neural Network for Relation Extraction . The network adopts a novel dynamic parameter generator that dynamically generates the network parameters according to the query entity types and relation classes. By using this mechanism, the network can simultaneously handle the style shift problem and enhance the prediction accuracy for long-tail classes. Through our experimental study, we demonstrate the effectiveness of the proposed method and show that it can achieve superior performance over the state-of-the-art methods. 
 Generating multiple categories of texts is a challenging task and draws more and more attention. Since generative adversarial nets  have shown competitive results on general text generation, they are extended for category text generation in some previous works. However, the complicated model structures and learning strategies limit their performance and exacerbate the training instability. This paper proposes a category-aware GAN  which consists of an efficient category-aware model for category text generation and a hierarchical evolutionary learning algorithm for training our model. The category-aware model directly measures the gap between real samples and generated samples on each category, then reducing this gap will guide the model to generate high-quality category samples. The Gumbel-Softmax relaxation further frees our model from complicated learning strategies for updating CatGAN on discrete data. Moreover, only focusing on the sample quality normally leads the mode collapse problem, thus a hierarchical evolutionary learning algorithm is introduced to stabilize the training procedure and obtain the trade-off between quality and diversity while training CatGAN. Experimental results demonstrate that CatGAN outperforms most of the existing state-of-the-art methods.  
   Bootstrapping natural language understanding  systems with minimal training data is a fundamental challenge of extending digital assistants like Alexa and Siri to a new language.   A common approach that is adapted in digital assistants when responding to a user query is to process the input in a pipeline manner where the first task is to predict the domain, followed by the inference of intent and slots.   However, this cascaded approach instigates error propagation and prevents information sharing among these tasks.   Further, the use of words as the atomic units of meaning as done in many studies might lead to coverage problems for morphologically rich languages such as German and French when data is limited.   We address these issues by introducing a character-level unified neural architecture for joint modeling of the domain, intent, and slot classification.   We compose word-embeddings from characters and jointly optimize all classification tasks via multi-task learning.   In our results, we show that the proposed architecture is an optimal choice for bootstrapping NLU systems in low-resource settings thus saving time, cost and human effort. 
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    %Knowledge graph learning is challenging as it requires strong modeling power,    %formulates and learns the formation of the relations among entities, and thus, knowledge.    %   Knowledge graph learning plays a critical role in integrating domain-specific    knowledge bases when deploying machine learning and data mining models in practice.    Existing methods on knowledge graph learning primarily focus on modeling   the relations among entities as translations among the relations and entities,    %   and many of these methods are not able to handle zero-shot problems, when   new entities emerge.    %   In this paper, we present a new convolutional neural network -based   %dual-chain model, in which relations among entities are captured via 1D CNN   %over their embeddings. A secondary chain of learning is conducted simultaneously   %to reduce overfitting and improve performance.   dual-chain model.   %   Different from translation based methods, in our model,   interactions among relations and entities are directly captured via CNN   over their embeddings. Moreover, %inspired by ComplEx ,    a secondary chain of learning is conducted simultaneously to incorporate additional   information and to enable better performance.   %   We also present an extension of this model, which incorporates descriptions   of entities and learns a second set of entity embeddings from the descriptions.   As a result, the extended model is able to effectively handle zero-shot problems.   %   We conducted comprehensive experiments, comparing our methods with 15   methods on 8 benchmark datasets.   %   Extensive experimental results demonstrate that our proposed methods achieve or    outperform the state-of-the-art results on knowledge graph learning, and outperform   other methods on zero-shot problems. In addition, our methods applied to real-world    biomedical data are able to produce results that conform to expert domain knowledge.  % 
         Despite the success of attention-based neural models for natural          language generation and classification tasks, they are unable to  capture the discourse structure of larger documents. We hypothesize that  explicit discourse representations have utility for NLP tasks over  longer documents or document sequences, which sequence-to-sequence  models are unable to capture. For abstractive summarization, for  instance, conventional neural models simply match source documents and  the summary in a latent space without explicit representation of text  structure or relations. In this paper, we propose to use neural  discourse representations obtained from a rhetorical structure theory   parser to enhance document representations. Specifically, document  representations are generated for discourse spans, known as the  elementary discourse units . We empirically investigate the  benefit of the proposed approach on two different tasks: abstractive  summarization and popularity prediction of online petitions. We find  that the proposed approach leads to improvements in all cases. 		 	
 We study textual autocomplete---the task of predicting a full sentence from a partial sentence---as a human-machine communication game.  Specifically, we consider three competing goals for effective communication: use as few tokens as possible , transmit sentences faithfully , and be learnable to humans .  We propose an unsupervised approach which tackles all three desiderata by constraining the communication scheme to \ti{keywords} extracted from a source sentence for interpretability and optimizing the efficiency-accuracy tradeoff. Our experiments show that this approach results in an autocomplete system that is 52\% more accurate at a given efficiency level compared to baselines, is robust to user variations, and saves time by nearly 50\% compared to typing full sentences. 
 Recurrent neural networks  have been widely used to deal with sequence learning problems. The input-dependent transition function, which folds new observations into hidden states to sequentially construct fixed-length representations of arbitrary-length sequences, plays a critical role in RNNs. Based on single space composition, transition functions in existing RNNs often have difficulty in capturing complicated long-range dependencies. In this paper, we introduce a new {one {\bf U}nit  for RNNs. The key idea is to design a transition function that is capable of modeling multiple space composition. The MZU consists of three components: zone generation, zone composition, and zone aggregation. Experimental results on multiple datasets of the character-level language modeling task and the aspect-based sentiment analysis task demonstrate the superiority of the MZU. 
  Student's feedback is an important source of collecting students閳 opinions to improve quality of training activities. Implementing sentiment analysis into student feedback data, we can determine sentiments polarities which express all problems in the institution since changes necessary will be applied to improve the quality of teaching and learning. This study focused on the machine learning and natural language processing techniques  on the Vietnamese Students' Feedback Corpus collected from a university. The final results were compared and evaluated to find the most effective model based on different evaluation criteria. The experimental results show that Bi-Directional Long Short-Term Memory algorithm outperformed than three other algorithms in term of the F1-score measurement with 92.0\% on the sentiment classification task and 89.6\% on the topic classification task. In addition, we developed a sentiment analysis application analyzing student feedback. The application will help the institution to recognize students' opinions about a problem and identify shortcomings that still exist. With the use of this application, the institution can propose an appropriate method to improve the quality of training activities in the future.  
In recent years, Vietnamese Named Entity Recognition  systems have had a great breakthrough when using Deep Neural Network methods. This paper describes the primary errors of the state-of-the-art NER systems on Vietnamese language. After conducting experiments on BLSTM-CNN-CRF and BLSTM-CRF models with different word embeddings on the Vietnamese NER dataset. This dataset is provided by VLSP in 2016 and used to evaluate most of the current Vietnamese NER systems. We noticed that BLSTM-CNN-CRF gives better results, therefore, we analyze the errors on this model in detail. Our error-analysis results provide us thorough insights in order to increase the performance of NER for the Vietnamese language and improve the quality of the corpus in the future works. 
 Existing deep active learning algorithms achieve impressive sampling efficiency on natural language processing tasks. However, they exhibit several weaknesses in practice, including  inability to use uncertainty sampling with black-box models,  lack of robustness to labeling noise, and  lack of transparency. In response, we propose a transparent batch active sampling framework by estimating the error decay curves of multiple feature-defined subsets of the data.  Experiments on four named entity recognition  tasks demonstrate that the proposed methods significantly outperform diversification-based methods for black-box NER taggers, and can make the sampling process more robust to labeling noise when combined with uncertainty-based methods. Furthermore, the analysis of experimental results sheds light on the weaknesses of different active sampling strategies, and when traditional uncertainty-based or diversification-based methods can be expected to work well.  % \PACS{PACS code1 \and PACS code2 \and more} %  
 		The dominant graph-to-sequence transduction models employ graph neural networks for graph representation learning, where the structural information is reflected by the receptive field of neurons. Unlike graph neural networks that restrict the information exchange between immediate neighborhood, we propose a new model, known as Graph Transformer, that uses explicit relation encoding and allows direct communication between two distant nodes. It provides a more efficient way for global graph structure modeling. Experiments on the applications of text generation from Abstract Meaning Representation  and syntax-based neural machine translation show the superiority of our proposed model. Specifically, our model achieves 27.4 BLEU on LDC2015E86 and 29.7 BLEU on LDC2017T10 for AMR-to-text generation, outperforming the state-of-the-art results by up to 2.2 points. On the syntax-based translation tasks, our model establishes new single-model state-of-the-art BLEU scores, 21.3 for English-to-German and 14.1 for English-to-Czech, improving over the existing best results, including ensembles, by over 1 BLEU. 	
   The ability to efficiently detect the software protections used is at a prime to facilitate the selection and application of adequate deobfuscation techniques.    We present a novel approach that combines semantic reasoning techniques with ensemble learning classification for the purpose of providing a static detection framework for obfuscation transformations.  By contrast to existing work, we provide a methodology that can detect multiple layers of obfuscation, without depending on knowledge of the underlying functionality of the training-set used.    We also extend our work to detect constructions of obfuscation transformations, thus providing a fine-grained methodology.   To that end, we provide several studies for the best practices of the use of machine learning techniques for a scalable and efficient model.  According to our experimental results and evaluations on obfuscators such as Tigress and OLLVM, our models have up to 91\% accuracy on state-of-the-art obfuscation transformations.  Our overall accuracies for their constructions are up to 100\%. % Our approach underlines the efficiency of semantic reasoning combined with advanced machine learning techniques, such as ensemble learning and multi-label with multi-output classification models. 
  In this paper, we study automatic question generation, the task of creating questions from corresponding text passages where some certain spans of the text can serve as the answers.  We propose an Extended Answer-aware Network  which is trained with Word-based Coverage Mechanism  and decodes with Uncertainty-aware Beam Search . The EAN represents the target answer by its surrounding sentence with an encoder,  and incorporates the information of the extended answer into paragraph representation with gated paragraph-to-answer attention to tackle the problem of the inadequate representation of the target answer. To reduce undesirable repetition, the WCM penalizes repeatedly attending to the same words at different time-steps in the training stage. The UBS aims to seek a better balance between the model confidence in copying words from an input text paragraph and the confidence in generating words from a vocabulary. We conduct experiments on the SQuAD dataset, and the results show our approach achieves significantly performance improvement. 
 In this work, we demonstrate a Chinese classical poetry generation system called Deep Poetry. Existing systems for Chinese classical poetry generation are mostly template-based and very few of them can accept multi-modal input. Unlike previous systems, Deep Poetry uses neural networks that are trained on over 200 thousand poems and 3 million ancient Chinese prose. Our system can accept plain text, images or artistic conceptions as inputs to generate Chinese classical poetry. More importantly, users are allowed to participate in the process of writing poetry by our system. For the user's convenience, we deploy the system at the WeChat applet platform, users can use the system on the mobile device whenever and wherever possible. The demo video of this paper is available at \url{https://youtu.be/jD1R_u9TA3M}. 
 We study pseudo-labeling for the semi-supervised training of ResNet, Time-Depth Separable ConvNets, and Transformers for speech recognition, with either CTC or Seq2Seq loss functions. We perform experiments on the standard \librispeech~dataset, and leverage additional unlabeled data from \librivox~through pseudo-labeling. We show that while Transformer-based acoustic models have superior performance with the supervised dataset alone, semi-supervision improves all models across architectures and loss functions and bridges much of the performance gaps between them. In doing so, we reach a new state-of-the-art for end-to-end acoustic models decoded with an external language model in the standard supervised learning setting, and a new absolute state-of-the-art with semi-supervised training. Finally, we study the effect of leveraging different amounts of unlabeled audio, propose several ways of evaluating the characteristics of unlabeled audio which improve acoustic modeling, and show that acoustic models trained with more audio rely less on external language models. 
 Memory Networks have emerged as effective models to incorporate Knowledge Bases  into neural networks. By storing KB embeddings into a memory component, these models can learn meaningful representations that are grounded to external knowledge. However, as the memory unit becomes full, the oldest memories are replaced by newer representations.   In this paper, we question this approach and provide experimental evidence that conventional Memory Networks store highly correlated vectors during training. While increasing the memory size mitigates this problem, this also leads to overfitting as the memory stores a large number of training latent representations. To address these issues, we propose a novel regularization mechanism named memory dropout which 1) Samples a single latent vector from a distribution of redundant memories. 2) Ages redundant memories thus increasing their probability of overwriting them during training. This fully differentiable technique allows us to achieve state-of-the-art response generation in the Stanford Multi-Turn Dialogue and Cambridge Restaurant datasets.  
 In reading comprehension, generating sentence-level distractors is a significant task, which requires a deep understanding of the article and question. The traditional entity-centered methods can only generate word-level or phrase-level distractors. Although recently proposed neural-based methods like sequence-to-sequence  model show great potential in generating creative text, the previous neural methods for distractor generation ignore two important aspects. First, they didn't model the interactions between the article and question, making the generated distractors tend to be too general or not relevant to question context. Second, they didn't emphasize the relationship between the distractor and article, making the generated distractors not semantically relevant to the article and thus fail to form a set of meaningful options. To solve the first problem, we propose a co-attention enhanced hierarchical architecture to better capture the interactions between the article and question, thus guide the decoder to generate more coherent distractors. To alleviate the second problem, we add an additional semantic similarity loss to push the generated distractors more relevant to the article. Experimental results show that our model outperforms several strong baselines on automatic metrics, achieving state-of-the-art performance. Further human evaluation indicates that our generated distractors are more coherent and more educative compared with those distractors generated by baselines.  
 As an efficient model for knowledge organization, the knowledge graph has been widely adopted in several fields, e.g., biomedicine, sociology, and education. And there is a steady trend of learning embedding representations of knowledge graphs to facilitate knowledge graph construction and downstream tasks. In general, knowledge graph embedding techniques aim to learn vectorized representations which preserve the structural information of the graph. And conventional embedding learning models rely on structural relationships among entities and relations. However, in educational knowledge graphs, structural relationships are not the focus. Instead, rich literals of the graphs are more valuable. In this paper, we focus on this problem and propose a novel model for embedding learning of educational knowledge graphs. Our model considers both structural and literal information and jointly learns embedding representations. Three experimental graphs were constructed based on an educational knowledge graph which has been applied in real-world teaching. We conducted two experiments on the three graphs and other common benchmark graphs. The experimental results proved the effectiveness of our model and its superiority over other baselines when processing educational knowledge graphs.  % \PACS{PACS code1 \and PACS code2 \and more} %  
 Identifying new user intents is an essential task in the dialogue system. However, it is hard to get satisfying clustering results since the definition of intents is strongly guided by prior knowledge. Existing methods incorporate prior knowledge by intensive feature engineering, which not only leads to overfitting but also makes it sensitive to the number of clusters. In this paper, we propose constrained deep adaptive clustering with cluster refinement , an end-to-end clustering method that can naturally incorporate pairwise constraints as prior knowledge to guide the clustering process.  Moreover, we refine the clusters by forcing the model to learn from the high confidence assignments. After eliminating low confidence assignments, our approach is surprisingly insensitive to the number of clusters.  Experimental results on the three benchmark datasets show that our method can yield significant improvements over strong baselines. \footnote{The code is available at https://github.com/thuiar/CDAC-plus} 
 Representation learning on a knowledge graph  is to embed entities and relations of a KG into low-dimensional continuous vector spaces. Early KG embedding methods only pay attention to structured information encoded in triples, which would cause limited performance due to the structure sparseness of KGs. Some recent attempts consider paths information to expand the structure of KGs but lack explainability in the process of obtaining the path representations. In this paper, we propose a novel Rule and Path-based Joint Embedding  scheme, which takes full advantage of the explainability and accuracy of logic rules, the generalization of KG embedding as well as the supplementary semantic structure of paths. Specifically, logic rules of different lengths  in the form of Horn clauses are first mined from the KG and elaborately encoded for representation learning. Then, the rules of length 2 are applied to compose paths accurately while the rules of length 1 are explicitly employed to create semantic associations among relations and constrain relation embeddings. Moreover, the confidence level of each rule is also considered in optimization to guarantee the availability of applying the rule to representation learning. Extensive experimental results illustrate that RPJE outperforms other state-of-the-art baselines on KG completion task, which also demonstrate the superiority of utilizing logic rules as well as paths for improving the accuracy and explainability of representation learning. 
 Graph neural networks  have emerged as a powerful paradigm for embedding-based entity alignment due to their capability of identifying isomorphic subgraphs. However, in real knowledge graphs , the counterpart entities usually have non-isomorphic neighborhood structures, which easily causes GNNs to yield different representations for them. To tackle this problem, we propose a new KG alignment network, namely AliNet, aiming at mitigating the non-isomorphism of neighborhood structures in an end-to-end manner. As the direct neighbors of counterpart entities are usually dissimilar due to the schema heterogeneity, AliNet introduces distant neighbors to expand the overlap between their neighborhood structures. It employs an attention mechanism to highlight helpful distant neighbors and reduce noises. Then, it controls the aggregation of both direct and distant neighborhood information using a gating mechanism. We further propose a relation loss to refine entity representations. We perform thorough experiments with detailed ablation studies and analyses on five entity alignment datasets, demonstrating the effectiveness of AliNet. 
 We propose a system to develop a basic automatic speech recognizer for Cantonese, a low-resource language, through transfer learning of Mandarin, a high-resource language. We take a time-delayed neural network trained on Mandarin, and perform weight transfer of several layers to a newly initialized model for Cantonese. We experiment with the number of layers transferred, their learning rates, and pretraining i-vectors. Key findings are that this approach allows for quicker training time with less data. We find that for every epoch, log-probability is smaller for transfer learning models compared to a Cantonese-only model. The transfer learning models show slight improvement in CER. 
 Previous works related to automatic personality recognition focus on using traditional classification models with linguistic features. However, attentive neural networks with contextual embeddings, which have achieved huge success in text classification, are rarely explored for this task. In this project, we have two major contributions. First, we create the first dialogue-based personality dataset, \verb|FriendsPersona| , by annotating 5 personality traits of speakers from Friends TV Show through crowdsourcing. Second, we present a novel approach to automatic personality recognition using pre-trained contextual embeddings  and attentive neural networks. Our models largely improve the state-of-art results on the monologue Essays dataset by 2.49\%, and establish a solid benchmark on our \verb|FriendsPersona|. By comparing results in two datasets, we demonstrate the challenges of modeling personality in multi-party dialogue.  
    Non-Autoregressive Neural Machine Translation  achieves significant decoding speedup through generating target words independently and simultaneously. However, in the context of non-autoregressive translation, the word-level cross-entropy loss cannot model the target-side sequential dependency properly, leading to its weak correlation with the translation quality. As a result, NAT tends to generate influent translations with over-translation and under-translation errors. In this paper, we propose to train NAT to minimize the Bag-of-Ngrams  difference between the model output and the reference sentence. The bag-of-ngrams training objective is differentiable and can be efficiently calculated, which encourages NAT to capture the target-side sequential dependency and correlates well with the translation quality. We validate our approach on three translation tasks and show that our approach largely outperforms the NAT baseline by about 5.0 BLEU scores on WMT14 En$\leftrightarrow$De and about 2.5 BLEU scores on WMT16 En$\leftrightarrow$Ro.  } 
 % In this work, we rethink a fundamental question: ``Is attention really all you need?''.   % Although self-attention has achieved superior results on sequence to sequence learning tasks over convolutional models, the  self-attention mechanism alone is still weak in long sequence modeling.  % % The global attention map is too dispersed to capture valuable information. In such case, the local/token features that are also significant to sequence modeling are omitted to some extent.  % In this work we refuse to make choices in self-attention and convolution, and explore parallel multi-scale representation learning on sequence data. We propose a new module, Parallel  MUlti-Scale attEntion .  The new module combines convolution and self-attention in  one  module for sequence to sequence learning. It first encodes the input into hidden representations, and then performs  self-attention and convolution transformations at the same hidden space in parallel. % Experimental results show that  % the proposed model achieves substantial performance improvements over Transformer, especially on long sequences, and outperforms all previous models with the comparable model size and the same training data  on three main machine translation tasks. To be specific, we achieve a BLEU score of 36.3 on IWSLT De-En,  29.9 on WMT14 En-De, and 43.5 on WMT14 En-Fr.  % In addition, it also opens a new direction on parallel sequence representation learning, which leads to efficient training and inference.  % MUSE has potential for accelerating training and inference.  In sequence to sequence learning, the self-attention mechanism proves to be highly effective, and achieves significant improvements in many tasks. However, the self-attention mechanism is not without its own flaws. Although self-attention can model extremely long dependencies, the attention in deep layers tends to over-concentrate on a single token, leading to insufficient use of local information and difficultly in representing long sequences. In this work, we explore parallel multi-scale representation learning on sequence data, striving to capture both long-range and short-range language structures. To this end, we propose the Parallel  MUlti-Scale attEntion  and MUSE-simple. MUSE-simple contains the basic idea of parallel multi-scale sequence representation learning, and it encodes the sequence in parallel, in terms of different scales with the help from self-attention,  and pointwise transformation. MUSE builds on MUSE-simple and explores  combining convolution and self-attention for learning sequence representations from more different scales. We focus on machine translation and the proposed approach achieves substantial performance improvements over Transformer, especially on long sequences. More importantly, we find that although conceptually simple, its success in practice requires intricate considerations, and the multi-scale attention must build on unified semantic space. Under common setting, the proposed model achieves substantial performance and outperforms all previous models on three main machine translation tasks. In addition, MUSE has potential for accelerating inference due to its parallelism. Code will be available at \url{https://github.com/lancopku/MUSE}.    % to making significant progress in sequence to sequence learning by building a simple and effective multi-scale attention module  % pushes the state-of-the-art from 35.7 to 36.3 on IWSLT 2014  German to English translation task,  from 30.6 to 31.3 on  IWSLT 2015 English to Vietnamese translation task.  We also reach the state-of-the-art performance on  WMT 2014 English to French translation dataset, with a BLEU score of 43.5 and BLEU score of 29.9 on WMT 2014  English to German translation dataset.  %  In this work, we present a new module that can learn sequential representations at multi scale in parallel. Specifically, it includes a encoder layer and  a decoder layer, and we perform attention, convolution, and non-linearity transformations in parallel at the hidden layer, this module leads to greater parallelism and shorter training and inference time.  % %  Although attention have achieved promising results on a variety of natural language processing tasks, we find that attention is still weak in long sentence modeling.  The global attention map is too dispersed to capture valuable information. % Experimental results show that the proposed model achieves substantial performance improvements over Transformer, especially on long sequences, and pushes the state-of-the-art from 35.6 to 36.3 on IWSLT 2014  German to English translation task,  from 30.6 to 31.3 on  IWSLT 2015 English to Vietnamese translation task. We also reach the state-of-the-art performance on  WMT 2014 English to French translation dataset, with a BLEU score of 43.5.  %  , with only 10\% parameter increase.    %Transformer and Transformer-based models have achieved state-of-the-art results on many natural language processing tasks. The success of Transformer is inseparable with a deep structure where different layers capture multi-grained features, enabling the model with strong capacity. However, the powerful learning ability makes it easy to memory training data by rote while the generalization performance is harmed to some extent.  To address this problem, we propose to build a wide Transformer network by leveraging the power of the structure ensemble to improve the robustness. To be specific, the proposed framework parallels the self-attention module with new modules at each layer to increase the diversity of structures. Experimental results show that without any increase of parameters, the proposed framework can outperform state-of-the-art approaches by a large margin even with a simple feed-forward structure. It demonstrates the effectiveness of structure ensemble on the generalization ability. Based on this finding, we further propose a method by concatenating the self-attention mechanism with multiple convolutional modules with different kernels, which pushes the state-of-the-art from XX to XX on XX,  XX to XX on XX.     
 In this paper, we present a method for learning discrete linguistic units by incorporating vector quantization layers into neural models of visually grounded speech. We show that our method is capable of capturing both word-level and sub-word units, depending on how it is configured. What differentiates this paper from prior work on speech unit learning is the choice of training objective. Rather than using a reconstruction-based loss, we use a discriminative, multimodal grounding objective which forces the learned units to be useful for semantic image retrieval. We evaluate the sub-word units on the ZeroSpeech 2019 challenge, achieving a 27.3\% reduction in ABX error rate over the top-performing submission, while keeping the bitrate approximately the same. We also present experiments demonstrating the noise robustness of these units. Finally, we show that a model with multiple quantizers can simultaneously learn phone-like detectors at a lower layer and word-like detectors at a higher layer. We show that these detectors are highly accurate, discovering 279 words with an F1 score of greater than 0.5. 
 Robust language processing systems are becoming increasingly important given the recent awareness of dangerous situations where brittle machine learning models can be easily broken with the presence of noises. In this paper, we introduce a robust word recognition framework that captures multi-level sequential dependencies in noised sentences.  The proposed framework employs a sequence-to-sequence model over characters of each word, whose output is given to a word-level bi-directional recurrent neural network. We conduct extensive experiments to verify the effectiveness of the framework. The results show that the proposed framework outperforms state-of-the-art methods by a large margin and they also suggest that character-level dependencies can play an important role in word recognition. The code of the proposed framework and the major experiments are publicly available\footnote{\url{https://github.com/DSE-MSU/MUDE}}. 
 Community question answering  gains increasing popularity in both academy and industry recently. However, the redundancy and lengthiness issues of crowdsourced answers limit the performance of answer selection and lead to reading difficulties and misunderstandings for community users. To solve these problems, we tackle the tasks of answer selection and answer summary generation in CQA with a novel joint learning model. Specifically, we design a question-driven pointer-generator network, which exploits the correlation information between question-answer pairs to aid in attending the essential information when generating answer summaries. Meanwhile, we leverage the answer summaries to alleviate noise in original lengthy answers when ranking the relevancy degrees of question-answer pairs. In addition, we construct a new large-scale CQA corpus, WikiHowQA, which contains long answers for answer selection as well as reference summaries for answer summarization. The experimental results show that the joint learning method can effectively address the answer redundancy issue in CQA and achieves state-of-the-art results on both answer selection and text summarization tasks. Furthermore, the proposed model is shown to be of great transferring ability and applicability for resource-poor CQA tasks, which lack of reference answer summaries. 
   Recent NLP studies reveal that substantial linguistic information can be attributed to single neurons, i.e., individual dimensions of the representation vectors.  We hypothesize that modeling strong interactions among neurons helps to better capture complex information by composing the linguistic properties embedded in individual neurons.  Starting from this intuition, we propose a novel approach to compose representations learned by different components in neural machine translation ,  based on modeling strong interactions among neurons in the representation vectors. Specifically, we leverage bilinear pooling to model pairwise multiplicative interactions among individual neurons, and a low-rank approximation to make the model computationally feasible. We further propose extended bilinear pooling to incorporate first-order representations. Experiments on WMT14 English$\Rightarrow$German and English$\Rightarrow$French translation tasks show that our model consistently improves performances over the SOTA Transformer baseline. Further analyses demonstrate that our approach indeed captures more syntactic and semantic information as expected. 
 The key challenge of multi-domain translation lies in simultaneously encoding both the general knowledge shared across domains and the particular knowledge distinctive to each domain in a unified model. Previous work shows that the standard neural machine translation  model, trained on mixed-domain data, generally captures the general knowledge, but misses the domain-specific knowledge. In response to this problem, we augment NMT model with additional {.} 
 Image captioning can be improved if the structure of the graphical representations can be formulated with conceptual positional binding. In this work, we have introduced a novel technique for caption generation using the neural-symbolic encoding of the scene-graphs, derived from regional visual information of the images and we call it Tensor Product Scene-Graph-Triplet Representation .  While, most of the previous works concentrated on identification of the object features in images, we introduce a neuro-symbolic embedding that can embed identified relationships among different regions of the image into concrete forms, instead of relying on the model to compose for any/all combinations. These neural symbolic representation helps in better definition of the neural symbolic space for neuro-symbolic attention and can be transformed to better captions. With this approach, we introduced two novel architectures  for comparison and experiment result demonstrates that our approaches outperformed the other models, and generated captions are more comprehensive and natural.   
 In this work we have analyzed a novel concept of sequential binding based learning capable network based on the coupling of recurrent units with Bayesian prior definition. The coupling structure encodes to generate efficient tensor representations that can be decoded to generate efficient sentences and can describe certain events. These descriptions are derived from structural representations of visual features of images and media. An elaborated study of the different types of coupling recurrent structures are studied and some insights of their performance are provided. Supervised learning performance for natural language processing is judged based on statistical evaluations, however, the truth is perspective, and in this case the qualitative evaluations reveal the real capability of the different architectural strengths and variations.  Bayesian prior definition of different embedding helps in better characterization of the sentences based on the natural language structure related to parts of speech and other semantic level categorization in a form which is machine interpret-able and inherits the characteristics of the Tensor Representation binding and unbinding based on the mutually orthogonality. Our approach has surpassed some of the existing basic works related to image captioning.  
 Although $n$-gram language models  have been outperformed by the state-of-the-art neural LMs, they are still widely used in speech recognition due to its high efficiency in inference. In this paper, we demonstrate that $n$-gram LM can be improved by neural LMs through a text generation based data augmentation method. In contrast to previous approaches, we employ a large-scale general domain pre-training followed by in-domain fine-tuning strategy to construct deep Transformer based neural LMs. Large amount of in-domain text data is generated with the well trained deep Transformer to construct new $n$-gram LMs, which are then interpolated with baseline $n$-gram systems. Empirical studies on different speech recognition tasks show that the proposed approach can effectively improve recognition accuracy. In particular, our proposed approach brings significant relative word error rate reduction up to $6.0\%$ for domains with limited in-domain data.  
 Joint extraction of entities and relations has received significant attention due to its potential of providing higher performance for both tasks. Among existing methods,  % CopyRE is promising because it is not affected by the notorious overlapping relation problem and its low computational burden is low.  CopyRE is effective and novel, which uses a sequence-to-sequence framework and copy mechanism to directly generate the relation triplets. However, it suffers from two fatal problems. The model is extremely weak at differing the head and tail entity, resulting in inaccurate entity extraction. It also cannot predict multi-token entities . To address these problems, we give a detailed analysis of the reasons behind the inaccurate entity extraction problem, and then propose a simple but extremely effective model structure to solve this problem. In addition, we propose a multi-task learning framework equipped with copy mechanism, called CopyMTL, to allow the model to predict multi-token entities. Experiments reveal the problems of CopyRE and show that our model achieves significant improvement over the current state-of-the-art method by 9\% in NYT and 16\% in WebNLG . Our code is available at \url{https://github.com/WindChimeRan/CopyMTL}  %   Joint extraction of entities and relations has received significant attention owing to its potential to provide higher performance. Of all different ways to solve this task, CopyRE is promising because it is not haunted by the notorious overlapping relation problem while keeping a low computational burden. However, it suffers from two other fatal problems:  %   %  the decoded entities are inaccurate, which become the bottleneck of the whole model;  %    CopyRE cannot distinguish head and tail entities, resulting in inaccurate entities extraction. %    the decoder can only predict one token of the entity, which is far from real-world usage.  %   We analyze the reasons behind the inaccurate entity copying problems, then propose a simple but extremely effective model structure to solve the first problem. For the second problem, we propose a multi-task %   learning framework, called CopyMTL, to complete the entity span. Experiments reveal the problems of CopyRE and show that our proposed approach achieves significant improvement over the current state-of-the-art method by 9\% in NYT and 16\% in WebNLG .   
 Answering questions that require multi-hop reasoning at web-scale necessitates retrieving multiple evidence documents, one of which often has little lexical or semantic relationship to the question. This paper introduces a new graph-based recurrent retrieval approach that learns to retrieve reasoning paths over the Wikipedia graph to answer multi-hop open-domain questions.  Our retriever model trains a recurrent neural network that learns to sequentially retrieve evidence paragraphs in the reasoning path by conditioning on the previously retrieved documents.  Our reader model ranks the reasoning paths and extracts the answer span included in the best reasoning path. Experimental results show state-of-the-art results in three open-domain QA datasets, showcasing the effectiveness and robustness of our method. Notably, our method achieves significant improvement in HotpotQA, outperforming the previous best model by more than 14 points.\footnote{Our code and data id available at \url{https://github.com/AkariAsai/learning_to_retrieve_reasoning_paths}.}  
   In this paper, we study the problem of enabling neural machine translation  to reuse previous translations from similar examples in target prediction. Distinguishing reusable translations from noisy segments and learning to reuse them in NMT are non-trivial. To solve these challenges, we propose an Example-Guided NMT  framework with two models:  a noise-masked encoder model that masks out noisy words according to word alignments and encodes the noise-masked sentences with an additional example encoder and  an auxiliary decoder model that predicts reusable words via an auxiliary decoder sharing parameters with the primary decoder. We define and implement the two models with the state-of-the-art Transformer. Experiments show that the noise-masked encoder model allows NMT to learn useful information from examples with low fuzzy match scores  while the auxiliary decoder model is good for high-FMS examples. More experiments on Chinese-English, English-German and English-Spanish translation demonstrate that the combination of the two EGNMT models can achieve improvements of up to +9 BLEU points over the baseline system and +7 BLEU points over a two-encoder Transformer. 
  In this paper we present a model for unsupervised topic discovery in texts corpora. The proposed model uses documents, words, and topics lookup table embedding as neural network model parameters to build probabilities of words given topics, and probabilities of topics given documents. These probabilities are used to recover by marginalization probabilities of words given documents. For very large corpora where the number of documents can be in the order of billions, using a neural auto-encoder based document embedding is more scalable then using a lookup table embedding as classically done. We thus extended the lookup based document embedding model to continuous auto-encoder based model. Our models are trained using probabilistic latent semantic analysis  assumptions. We evaluated our models on six datasets with a rich variety of contents. Conducted experiments demonstrate that the proposed neural topic models are very effective in capturing relevant topics. Furthermore, considering perplexity metric, conducted evaluation benchmarks show that our topic models outperform latent Dirichlet allocation  model which is classically used to address topic discovery tasks.  
 Emotional language generation is one of the keys to human-like artificial intelligence. Humans use different type of emotions depending on the situation of the conversation. Emotions also play an important role in mediating the engagement level with conversational partners. However, current conversational agents do not effectively account for emotional content in the language generation process. %In order for the current conversational agents to be more human like generating affective dialogues with regards to the situation is important.  To address this problem, we develop a language modeling approach that generates affective content when the dialogue is situated in a given context. We use the recently released Empathetic-Dialogues corpus to build our models. Through detailed experiments, we find that our approach outperforms the state-of-the-art method on the perplexity metric by about 5 points and achieves a higher BLEU metric score.  
  Language acquisition is the process of learning words from the surrounding scene. We introduce a meta-learning framework that  word representations from unconstrained scenes. We leverage the natural compositional structure of language to create training episodes that cause a meta-learner to learn strong policies for language acquisition. Experiments on two datasets show that our approach is able to more rapidly acquire novel words as well as more robustly generalize to unseen compositions, significantly outperforming established baselines. A key advantage of our approach is that it is data efficient, allowing representations to be learned from scratch without language pre-training. Visualizations and analysis suggest visual information helps our approach learn a rich cross-modal representation from minimal examples.  
 Credit attribution is the task of associating individual parts in a document with their most appropriate class labels. It is an important task with applications to information retrieval and text summarization. When labeled training data is available, traditional approaches for sequence tagging can be used for credit attribution. However, generating such labeled datasets is expensive and time-consuming. In this paper, we present , a neural-network-based approach, that instead of using sentence-level labeled data, uses the set of class labels that are associated with an entire document as a source of distant-supervision. CAWA combines an attention mechanism with a multilabel classifier into an end-to-end learning framework to perform credit attribution. CAWA labels the individual sentences from the input document using the resultant attention-weights. CAWA improves upon the state-of-the-art credit attribution approach by not constraining a sentence to belong to just one class, but modeling each sentence as a distribution over all classes, leading to better modeling of semantically-similar classes. Experiments on the credit attribution task on a variety of datasets show that the sentence class labels generated by CAWA outperform the competing approaches. Additionally, on the multilabel text classification task, CAWA performs better than the competing credit attribution approaches\footnote{Our code and data are available at https://github.com/gurdaspuriya/cawa.}.  
 We propose an approach towards natural language generation using bidirectional encoder-decoder which incorporates external rewards through reinforcement learning . We use attention mechanism and maximum mutual information as initial objective function using RL.  %We use an AlphaGo-style strategy with a general policy, which is then tuned using policy gradient method. %Two of our internal rewards, viz. Ease of Answering and Semantic Coherence are based on prior state-of-the-art. Another internal reward, Emotional Intelligence, is computed by minimizing affective dissonance between the source and generated response.  Using a two-part training scheme, we train an external reward analyzer to predict the external rewards and then use the predicted rewards to maximize the expected rewards . We evaluate the system on two standard dialogue corpora - Cornell Movie Dialog Corpus and Yelp Restaurant Review Corpus. We report standard evaluation metrics including BLEU, ROUGE-L and perplexity as well as human evaluation to validate our approach. 
 While neural machine translation  has achieved state-of-the-art translation performance, it is unable to capture the alignment between the input and output during the translation process. The lack of alignment in NMT models leads to three problems: it is hard to  interpret the translation process,  impose lexical constraints, and  impose structural constraints. To alleviate these problems, we propose to introduce explicit phrase alignment into the translation process of arbitrary NMT models. The key idea is to build a search space similar to that of phrase-based statistical machine translation for NMT where phrase alignment is readily available. We design a new decoding algorithm that can easily impose lexical and structural constraints. Experiments show that our approach makes the translation process of NMT more interpretable without sacrificing translation quality. In addition, our approach achieves significant improvements in lexically and structurally constrained translation tasks. 
 %閸氬本妾紙鏄徢旈妵顖涙瀮閵囶喖鍙嗛崝娑栦捍缁插倷绨￠妵娆嶅犻崜宥冧紑閵囨縿浼勯弬鍥ヤ紕缂堟槒菙閵堟帡鏋婃慨瀣ㄤ粴閵堝鍋妶骞垮仐閵囇佷簵閵堝绱 Simultaneous machine translation is a variant of machine translation that starts the translation process before the end of an input. %閵囨挶浼勯妶瑁ゅ仯閵堫垬浠归妵顖滅倳鐟峰磭绨挎惔锔轰缓鐟峰啿鍤妵淇变还閵囶噣浜濆鑸垫闂佹挶浜撮妷鍫涘劯閵夌鍎旈妶顏傚劆閵囶噣鏋规穱鍌樹紑閵囧倶鍊為敍灞诲仭閵堝箍鍎愰妷鐘板Σ瀣様閵囨瑣鍊犻梾娑栦紑閵囶垳鐐曠懛鐐藉扮悰灞讳簽閵堣￥鍋嗛妷鐔村厒閵堣埇鍊伴柆鈺佸瀼閵囶偅鐒欑规哎浠氶妶瀣箑鐟曚降浜撮妵鍌樺犻敍 This task faces a trade-off between translation accuracy and latency. We have to determine when we start the translation for observed inputs so far, to achieve good practical performance. %閺堫剛鐖虹粚韬蹭还閵囶垽绱濋妷瀣ㄥ劚閵夌鍎甸妷顐ｎ熂濮婃壆鐐曠懛鐐戒紑閵囧ǹ浜滈妵锔轰壕閵囶喛菙閸戞亽鍋妶銈冨劔閵夌偨鍋橀妶鎺椾患韫囨粎娈戦妵顐ｇ剻鐎规哎浠氶妶瀣煙濞夋洏鍊伴幓鎰攳閵囨瑣鍊犻敍 In this work, we propose a neural machine translation method to determine this timing in an adaptive manner. %閹绘劖顢嶉幍瀣《閵囇佷紖閻╊喚娈戠懛鐟剧偛浼岄妵顔跨嵁瑜版瑣浼鐟峰啿鍤妶鎺曨攽閵堝繈浠鹃妵鍕敩閵堝繈鍊為妵顐㈠毉閸旀稏浠氶妶瀣ㄤ户閵堜降浼勯妷掳鍋妷鍫涘厳閵堫垬鍏 閳ユwait 閳 閵堟帟鎷烽崝鐘粣閿涘本鎮曟径閬嶆灩閺佽埇浠洪妵妞间桓Connectionist Temporal Classification閿涘湑TC閿涘浠洪崨绗轰紗閵堝被鍊犻妶鈧劮閵堟番鍎堕妶鎭掑劕閵堟帞娲伴惃鍕灩閺佽埇浼鐏忓骸鍙嗛妵娆嶅犻敍 The proposed method introduces a special token 閳ユwait 閳, which is generated when the translation model chooses to read the next input token instead of generating an output token. It also introduces an objective function to handle the ambiguity in wait timings that can be optimized using an algorithm called Connectionist Temporal Classification . %CTC閵囶偁鍊涢妵锝冧桓 缁侯喚纾╅妵娆嶅犻妵銊︻劀鐟欙絿閮撮崚妞间缓娑撻懛娣粴閵堝鍊涢妵鍡愪痪閳ユwait '閵堟帒鎯堥妶缁鍨崗銊ｄ桓 閵囶偄顕抽妵妞间桓閺堥柆鈺佸閵堟帟顢戦妵鍡愪壕閵囥劊浠圭紙鏄徢旈妷鈧剳閵夘偁浠虹懛鍐插毉閵堣￥鍋嗛妷鐔村厒閵堟澘鍩楀掳鍊伴崥灞炬閵囶偅娓堕柆鈺佸閵囨瑣鍊犻妵鎾变缓閵囧被浠归妵宥忕礉閵囨洏鍊濋妵顐デ旈崙鎭掑仾閵堛們鍎妷鐐藉仒閵堟帡浠艰箛婊呮畱閵囶偅鐒欑规哎浠氶妶瀣ㄤ壕閵囥劊鍊愰崣顖濆厴閵囥劊浠鹃妶瀣剁礋 The use of CTC enables the optimization to consider all possible output sequences including 閳ユwait ' that are equivalent to the reference translations and to choose the best one adaptively. %閵囦勘浠ч敍灞讳壕閵囶喓鍎妷鍥ュ劮閵堟帟瀚崇懢鐐罕閵堝妫╅張顒冪嵁閵囨悶浼勯崥灞炬缂堟槒菙閵堣￥鍋ｉ妶顖樹紑鐎典勘浠愰妵锕備患閻€劊浠愰敍灞讳虎閵囶喚鐐曠懛宕囩ゼ閺嬫嚎浼勭划鎯у閵堝嫬鏅辨い宀鍋ｉ妵顐犱槐閵囧嫨浠稿婊嗏棧閵囨瑣鍊犻敍 We apply the proposed method into simultaneous translation from English to Japanese and investigate its performance and remaining problems. 
 As one of the major sources in speech variability, accents have posed a grand challenge to the robustness of speech recognition systems. In this paper, our goal is to build a unified end-to-end speech recognition system that generalizes well across accents. For this purpose, we propose a novel pre-training framework AIPNet based on generative adversarial nets  for accent-invariant representation learning: Accent Invariant Pre-training Networks. We pre-train AIPNet to disentangle accent-invariant and accent-specific characteristics from acoustic features through adversarial training on accented data for which transcriptions are not necessarily available. We further fine-tune AIPNet by connecting the accent-invariant module with an attention-based encoder-decoder model for multi-accent speech recognition. In the experiments, our approach is compared against four baselines including both accent-dependent and accent-independent models. Experimental results on $9$ English accents show that the proposed approach outperforms all the baselines by $2.3\sim4.5\%$ relative reduction on average WER when transcriptions are available in all accents and by $1.6\sim6.1\%$ relative reduction when transcriptions are only available in US accent.  %Accents have long been a major variety in speech signals and brought a big challenge to automatic speech recognition . The goal of this paper is to build a single sequence-to-sequence ASR model that can learn acoustic representations that is both accent-invariant and linguistically discriminative so as to increase the robustness to different accents. On the other hand, it has been shown in many applications that pre-training can bring performance improvement. We design a pre-training method inspired from Generative Adversarial Networks  to perform disentanglement of linguistic and accent information without transcriptions.  After pre-training, linguistic representations are used to train ASR and further fine-tune the model. Since the pre-training does not need the transcriptions of speech, our approach can be further extended into a semi-supervised setting, in which only a small portion of data has transcriptions. Furthermore, our approach can be integrated with other semi-supervised techniques to further improve the performance. In this work, we use a classic semi-supervised method, pseudo-labeling, to demonstrate it. The experimental results show our approach can prevent overfitting in the semi-supervised setting, and improve the WER of some accents, whose training data does not have transcriptions, from 31.8 to 25.9. 
 The exponential rise of social media and digital news in the past decade has had the unfortunate consequence of escalating what the United Nations has called a global topic of concern: the growing prevalence of disinformation\footnote{\url{https://www.ohchr.org/EN/NewsEvents/Pages/DisplayNews.aspx?NewsID=21287&LangID=E}}. Given the complexity and time-consuming nature of combating disinformation through human assessment, one is motivated to explore harnessing AI solutions to automatically assess news articles for the presence of disinformation. A valuable first step towards automatic identification of disinformation is stance detection, where given a claim and a news article, the aim is to predict if the article agrees, disagrees, takes no position, or is unrelated to the claim. Existing approaches in literature have largely relied on hand-engineered features or shallow learned representations  to encode the claim-article pairs, which can limit the level of representational expressiveness needed to tackle the high complexity of disinformation identification. In this work, we explore the notion of harnessing large-scale deep bidirectional transformer language models for encoding claim-article pairs in an effort to construct state-of-the-art stance detection geared for identifying disinformation. Taking advantage of bidirectional cross-attention between claim-article pairs via pair encoding with self-attention, we construct a large-scale language model for stance detection by performing transfer learning on a RoBERTa deep bidirectional transformer language model, and were able to achieve state-of-the-art performance  on the Fake News Challenge Stage 1  benchmark. These promising results serve as motivation for harnessing such large-scale language models as powerful building blocks for creating effective AI solutions to combat disinformation. 
 For sequence models with large vocabularies, a majority of network parameters lie in the input and output layers. In this work, we describe a new method, \arch, for learning deep token representations efficiently. Our architecture uses a hierarchical structure with novel skip-connections which allows for the use of low dimensional input and output layers, reducing total parameters and training time while delivering similar or better performance versus existing methods. \arch~can be incorporated easily in new or existing sequence models. Compared to state-of-the-art methods including adaptive input representations, this technique results in a 6\% to 20\% drop in perplexity. On WikiText-103, \arch~reduces the total parameters of Transformer-XL by half with minimal impact on performance. On the Penn Treebank, \arch~improves AWD-LSTM by 4 points with a 17\% reduction in parameters, achieving comparable performance to state-of-the-art methods with fewer parameters. For machine translation, \arch~improves the efficiency of the Transformer model by about $1.4$ times while delivering similar performance. 
 We present a novel approach to improve the performance of distant supervision relation extraction with Positive and Unlabeled  Learning. This approach first applies reinforcement learning to decide whether a sentence is positive to a given relation, and then positive and unlabeled bags are constructed. In contrast to most previous studies, which mainly use selected positive instances only, we make full use of unlabeled instances and propose two new representations for positive and unlabeled bags. These two representations are then combined in an appropriate way to make bag-level prediction. Experimental results on a widely used real-world dataset demonstrate that this new approach indeed achieves significant and consistent improvements as compared to several competitive baselines. 	 	%	Positive sentence selection based on reinforcement learning has been used to address the wrong labeling problem in distantly supervised learning. 	%%	Although distantly supervised learning is capable of scaling relation extraction to very large corpora and has been widely used to find novel relational facts from text, it inevitably accompanies with wrong labeling problem. 	%%	To address this problem, 	%%	positive sentence selection based on reinforcement learning has been used in distantly supervised learning. 	%%	researchers turn to building a sentence selector to select positive sentences from noisy data. 	%	However, previous studies mainly train the final relation extraction model on the positive sentences. %focus on relation classification at sentence-level and train the model only on the positive sentences. 	%	%In this paper, we propose a reinforcement learning-based approach for relation extraction at bag-level. 	%	In this paper, we propose a approach which makes full use of both positive and unlabeled instances predicted by a sentence selector. 	%	We first apply reinforcement learning to build the instance selector which decides whether a sentence is positive  to a given relation, and then a new bag-level classifier is trained on both positive and unlabeled instances for relation extraction. Different from the previous studies, this work utilizes unlabeled instances to help train the relation classifier. 	%	Experimental results on a widely used real-world dataset verify that our proposed model achieves significant and consistent improvements as compared with several competitive baselines. 
 Recently, Chinese word segmentation  methods using neural networks have made impressive progress. Most of them regard the CWS as a sequence labeling problem which construct models based on local features rather than considering global information of input sequence. In this paper, we cast the CWS as a sequence translation problem and propose a novel sequence-to-sequence CWS model with an attention-based encoder-decoder framework. The model captures the global information from the input and directly outputs the segmented sequence. It can also tackle other NLP tasks with CWS jointly in an end-to-end mode. Experiments on Weibo, PKU and MSRA benchmark datasets show that our approach has achieved competitive performances compared with state-of-the-art methods. Meanwhile, we successfully applied our proposed model to jointly learning CWS and Chinese spelling correction, which demonstrates its applicability of multi-task fusion.  
 Most studies on text classification are focused on the English language. However, short texts such as SMS are influenced by regional languages. This makes the automatic text classification task challenging due to the multilingual, informal, and noisy nature of language in the text. In this work, we propose a novel multi-cascaded deep learning model called  for bilingual SMS classification. McM exploits $n$-gram level information as well as long-term dependencies of text for learning. Our approach aims to learn a model without any code-switching indication, lexical normalization, language translation, or language transliteration. The model relies entirely upon the text as no external knowledge base is utilized for learning. For this purpose, a $12$ class bilingual text dataset is developed from SMS feedbacks of citizens on public services containing mixed Roman Urdu and English languages. Our model achieves high accuracy for classification on this dataset and outperforms the previous model for multilingual text classification, highlighting language independence of McM.   
 %Retrieving biomedical articles to providing useful precision-medicine related information to clinicians treating patients with cancer is an effective way for precision medicine.  Effective biomedical literature retrieval  plays a central role in precision medicine informatics. In this paper, we propose GRAPHENE, which is a deep learning based framework for precise BLR. GRAPHENE consists of three main different modules 1) graph-augmented document representation learning; 2) query expansion and representation learning and 3) learning to rank biomedical articles. The graph-augmented document representation learning module constructs a document-concept graph containing biomedical concept nodes and document nodes so that global biomedical related concept from external knowledge source can be captured, which is further connected to a BiLSTM so both local and global topics can be explored. Query expansion and representation learning module expands the query with abbreviations and different names, and then builds a CNN-based model to convolve the expanded query and obtain a vector representation for each query. Learning to rank minimizes a ranking loss between biomedical articles with the query to learn the retrieval function. Experimental results on applying our system to TREC Precision Medicine track data are provided to demonstrate its effectiveness. %Furthermore, it can retrieve those biomedical articles which are quite related to query but do not share the same or similar topics with the query. The results also demonstrate that our model improves previous deep neural retrieval models which represent the document with textual information only, suggesting the necessity of encoding external knowledge into document representation.  
 We implement a Tensor Train layer in the TensorFlow Neural Machine Translation  model using the t3f library. We perform training runs on the IWSLT English-Vietnamese '15 and WMT German-English '16 datasets with learning rates $$, maximum ranks $$ and a range of core dimensions. We compare against a target BLEU test score of 24.0, obtained by our benchmark run. For the IWSLT English-Vietnamese training, we obtain BLEU test/dev scores of 24.0/21.9 and 24.2/21.9 using core dimensions $ \times $ with learning rate 0.0012 and rank distributions $$ and $$ respectively. These runs use 113\% and 397\% of the flops of the benchmark run respectively. We find that, of the parameters surveyed, a higher learning rate and more `rectangular' core dimensions generally produce higher BLEU scores. For the WMT German-English dataset, we obtain BLEU scores of 24.0/23.8 using core dimensions $ \times $ with learning rate 0.0012 and rank distribution $$. We discuss the potential for future optimization and application of Tensor Train decomposition to other NMT models. 
 The goal of this work is to segment the objects in an image that are referred to by a sequence of linguistic descriptions . We propose a deep neural network with recurrent layers that output a sequence of binary masks, one for each referring expression provided by the user. The recurrent layers in the architecture allow the model to condition each predicted mask on the previous ones, from a spatial perspective within the same image. Our multimodal approach uses off-the-shelf architectures to encode both the image and the referring expressions. The visual branch provides a tensor of pixel embeddings that are concatenated with the phrase embeddings produced by a language encoder. Our experiments on the RefCOCO dataset for still images indicate how the proposed architecture successfully exploits the sequences of referring expressions to solve a pixel-wise task of instance segmentation. %reduce the stress of individuals with dementia and the burden on their caregivers  
 Autonomous reinforcement learning agents, like children, do not have access to predefined goals and reward functions. They must discover potential goals, learn their own reward functions and engage in their own learning trajectory. Children, however, benefit from exposure to language, helping to organize and mediate their thought. We propose LE2 , a learning algorithm leveraging intrinsic motivations and natural language  interactions with a descriptive social partner . Using NL descriptions from the SP, it can learn an NL-conditioned reward function to formulate goals for intrinsically motivated goal exploration and learn a goal-conditioned policy. By exploring, collecting descriptions from the SP and jointly learning the reward function and the policy, the agent grounds NL descriptions into real behavioral goals. From simple goals discovered early to more complex goals discovered by experimenting on simpler ones, our agent autonomously builds its own behavioral repertoire. This naturally occurring curriculum is supplemented by an active learning curriculum resulting from the agent's intrinsic motivations. Experiments are presented with a simulated robotic arm that interacts with several objects including tools. 
 The areas of machine learning and knowledge discovery in databases have considerably matured in recent years. In this article, we briefly review recent developments as well as classical algorithms that stood the test of time. Our goal is to provide a general introduction into  different tasks such as learning from tabular data, behavioral data, or textual data, with a particular focus on actual and potential applications in behavioral sciences. The supplemental appendix to the article also provides practical guidance for using the methods by pointing the reader to proven software implementations.  The focus is on R, but we also cover some libraries in other programming languages as well as systems with easy-to-use graphical interfaces.   
 Recent trends of incorporating attention mechanisms in vision have led researchers to reconsider the supremacy of convolutional layers as a primary building block. Beyond helping CNNs to handle long-range dependencies,  showed that attention can completely replace convolution and achieve state-of-the-art performance on vision tasks. % This raises the question: do learned attention layers operate similarly to convolutional layers? This work provides evidence that attention layers can perform convolution and, indeed, they often learn to do so in practice. Specifically, we prove that a multi-head self-attention layer with sufficient number of heads is at least as expressive as any convolutional layer. % Our numerical experiments then show that self-attention layers attend to pixel-grid patterns similarly to CNN layers, corroborating our analysis. % Our code is publicly available\footnote{Code: \githuburl{}. Website: .}. 
 Neural Machine Translation has lately gained a lot of ``attention" with the advent of more and more sophisticated but drastically improved models. Attention mechanism has proved to be a boon in this direction by providing weights to the input words, making it easy for the decoder to identify words representing the present context. But by and by, as newer attention models with more complexity came into development, they involved large computation, making inference slow. In this paper, we have modelled the attention network using techniques resonating with social choice theory. Along with that, the attention mechanism, being a Markov Decision Process, has been represented by reinforcement learning techniques. Thus, we propose to use an election method , fine-tuned using Q-learning, as a replacement for attention networks. The inference time for this network is less than a standard Bahdanau translator, and the results of the translation are comparable. This not only experimentally verifies the claims stated above but also helped provide a faster inference. 
 Deep learning methods have revolutionized speech recognition, image recognition, and natural language processing since 2010. Each of these tasks involves a single modality in their input signals. However, many applications in the artificial intelligence field involve multiple modalities. Therefore, it is of broad interest to study the more difficult and complex problem of modeling and learning across multiple modalities. In this paper, we provide a technical review of available models and learning methods for multimodal intelligence. The main focus of this review is the combination of vision and natural language modalities, which has become an important topic in both the computer vision and natural language processing research communities.   This review provides a comprehensive analysis of recent works on multimodal deep learning from three perspectives: learning multimodal representations, fusing multimodal signals at various levels, and multimodal applications. Regarding multimodal representation learning, we review the key concepts of embedding, which unify multimodal signals into a single vector space and thereby enable cross-modality signal processing. We also review the properties of many types of embeddings that are constructed and learned for general downstream tasks. Regarding multimodal fusion, this review focuses on special architectures for the integration of representations of unimodal signals for a particular task. Regarding applications, selected areas of a broad interest in the current literature are covered, including image-to-text caption generation, text-to-image generation, and visual question answering. We believe that this review will facilitate future studies in the emerging field of multimodal intelligence for related communities. 
 In this paper, we focus on learning low-dimensional embeddings for nodes in graph-structured data. To achieve this, we propose Caps2NE -- a new unsupervised embedding model leveraging a network of two capsule layers. Caps2NE induces a routing process to aggregate feature vectors of context neighbors of a given target node at the first capsule layer, then feed these features into the second capsule layer to infer a plausible embedding for the target node. Experimental results show that our proposed Caps2NE obtains state-of-the-art performances on benchmark datasets for the node classification task. Our code is available at: \url{https://github.com/daiquocnguyen/Caps2NE}.  
 	This work investigates if the current neural architectures are adequate for 	learning symbolic rewriting. Two kinds of data sets are proposed for this 	research -- one based on automated proofs and the other being a synthetic 	set of polynomial terms. The experiments with use of the current neural 	machine translation models are performed and its results are discussed. 	Ideas for extending this line of research are proposed, and its relevance 	is motivated. 
 Most of the existing question answering models can be largely compiled into two categories: i) open domain question answering models that answer generic questions and use large-scale knowledge base along with the targeted web-corpus retrieval and ii) closed domain question answering models that address focused questioning area and use complex deep learning models. Both the above models derive answers through textual comprehension methods. Due to their inability to capture the pedagogical meaning of textual content, these models are not appropriately suited to the educational field for pedagogy. In this paper, we propose an on-the-fly conceptual network model that incorporates educational semantics. The proposed model preserves correlations between conceptual entities by applying intelligent indexing algorithms on the concept network so as to improve answer generation. This model can be utilized for building interactive conversational agents for aiding classroom learning.   % .  
 Multimodalities provide promising performance than unimodality in most tasks. However, learning the semantic of the representations from multimodalities efficiently is extremely challenging. To tackle this, we propose the Transformer based Cross-modal Translator  to learn unimodal sequence representations by translating from other related multimodal sequences on a supervised learning method. Combined TCT with Multimodal Transformer Network , we evaluate MTN-TCT on the video-grounded dialogue which uses multimodality. The proposed method reports new state-of-the-art performance on video-grounded dialogue which indicates representations learned by TCT are more semantics compared to directly use unimodality. 
   Recently, a lot of techniques were developed to sparsify the weights of neural networks and to remove networks' structure units, e.\,g.\, neurons. We adjust the existing sparsification approaches to the gated recurrent architectures. Specifically, in addition to the sparsification of  weights and neurons, we propose sparsifying the preactivations of gates. This makes some gates constant and simplifies LSTM structure. We test our approach on the text classification and language modeling tasks. We observe that the resulting structure of gate sparsity depends on the task and connect the learned structure to the specifics of the particular tasks. Our method also improves neuron-wise compression of the model in most of the tasks. 
 Online Social Networks~ evolve through two pervasive behaviors: follow and unfollow, % which respectively signify relationship creation and relationship dissolution. % Researches on social network evolution mainly focus on the follow behavior, while the unfollow behavior has largely been ignored. % Mining unfollow behavior is challenging because user's decision on unfollow is not only affected by the simple combination of user's attributes like informativeness and reciprocity, % but also affected by the complex interaction among them. % Meanwhile, prior datasets seldom contain sufficient records for inferring such complex interaction. % To address these issues, we first construct a large-scale real-world Weibo\footnote{https://www.weibo.com/} dataset, % which records detailed post content and relationship dynamics of 1.8 million Chinese users. % Next, we define user's attributes as two categories: spatial attributes~ and temporal attributes~. Leveraging the constructed dataset, we systematically study how the interaction effects between user's spatial and temporal attributes contribute to the unfollow behavior. % Afterwards, we propose a novel unified model with heterogeneous information~ for unfollow prediction. % Specifically, our UMHI model: 1) captures user's spatial attributes through social network structure; % 2) infers user's temporal attributes through user-posted content and unfollow history; % and 3) models the interaction between spatial and temporal attributes by the nonlinear MLP layers. % Comprehensive evaluations on the constructed dataset demonstrate that the proposed UMHI model outperforms baseline methods by 16.44\% on average in terms of precision. % In addition, factor analyses verify that both spatial attributes and temporal attributes are essential for mining unfollow behavior. % 
 Different from Visual Question Answering task that requires to answer only one question about an image, Visual Dialogue involves multiple questions which cover a broad range of visual content that could be related to any objects, relationships or semantics. The key challenge in Visual Dialogue task is thus to learn a more comprehensive and semantic-rich image representation which may have adaptive attentions on the image for variant questions. In this research, we propose a novel model to depict an image from both visual and semantic perspectives. Specifically, the visual view helps capture the appearance-level information, including objects and their relationships, while the semantic view enables the agent to understand high-level visual semantics from the whole image to the local regions. Futhermore, on top of such multi-view image features, we propose a feature selection framework which is able to adaptively capture question-relevant information hierarchically in fine-grained level. The proposed method achieved state-of-the-art results on benchmark Visual Dialogue datasets. More importantly, we can tell which modality  has more contribution in answering the current question by visualizing the gate values. It gives us insights in understanding of human cognition in Visual Dialogue. 
  Artificial neural networks  have become the mainstream acoustic modeling technique for large vocabulary automatic speech recognition . A conventional ANN features a multi-layer architecture that requires massive amounts of computation. The brain-inspired spiking neural networks  closely mimic the biological neural networks and can operate on low-power neuromorphic hardware with spike-based computation. Motivated by their unprecedented energy-efficiency and rapid information processing capability, we explore the use of SNNs for speech recognition. In this work, we use SNNs for acoustic modeling and evaluate their performance on several large vocabulary recognition scenarios. The experimental results demonstrate competitive ASR accuracies to their ANN counterparts, while require significantly reduced computational cost and inference time. Integrating the algorithmic power of deep SNNs with energy-efficient neuromorphic hardware, therefore, offer an attractive solution for ASR applications running locally on mobile and embedded devices.  \tiny  
 Despite the improvements in perception accuracies brought about via deep learning, developing systems combining accurate visual perception with the ability to reason over the visual percepts remains extremely challenging. A particular application area of interest from an accessibility perspective is that of reasoning over statistical charts such as bar and pie charts. To this end, we formulate the problem of reasoning over statistical charts  as a classification task using MAC-Networks to give answers from a predefined vocabulary of generic answers. Additionally, we enhance the capabilities of MAC-Networks to give chart-specific answers to open-ended questions by replacing the classification layer by a regression layer to localize the textual answers present over the images. We call our network , and demonstrate its efficacy on predicting both in vocabulary and out of vocabulary answers. To test our methods, we generated our own dataset of statistical chart images and corresponding question answer pairs. Results show that ChartNet consistently outperform other state-of-the-art methods on reasoning over these questions and may be a viable candidate for applications containing images of statistical charts.   %This paper leverages some of the recent work done in Visual Reasoning via MAC-Networks, and attempts to apply these methods to reason over statistical charts. To test our methods, we generated our own dataset of statistical chart images and corresponding question answer pairs. Results show that MAC-Networks consistently outperform other state-of-the-art methods on reasoning over these questions and may be viable candidates for application containing images of statistical charts. 
 Knowledge graph embedding, which aims to represent entities and relations as low dimensional vectors , has been shown to be a powerful technique for predicting missing links in knowledge graphs. Existing knowledge graph embedding models mainly focus on modeling relation patterns such as symmetry/antisymmetry, inversion, and composition. However, many existing approaches fail to model semantic hierarchies, which are common in real-world applications. To address this challenge, we propose a novel knowledge graph embedding model---namely, Hierarchy-Aware Knowledge Graph Embedding ---which maps entities into the polar coordinate system. HAKE is inspired by the fact that concentric circles in the polar coordinate system can naturally reflect the hierarchy. Specifically, the radial coordinate aims to model entities at different levels of the hierarchy, and entities with smaller radii are expected to be at higher levels; the angular coordinate aims to distinguish entities at the same level of the hierarchy, and these entities are expected to have roughly the same radii but different angles. Experiments demonstrate that HAKE can effectively model the semantic hierarchies in knowledge graphs, and significantly outperforms existing state-of-the-art methods on benchmark datasets for the link prediction task.  
 This paper presents a simple yet effective method to achieve prosody transfer from a reference speech signal to synthesized speech. The main idea is to incorporate well-known acoustic correlates of prosody such as pitch and loudness contours of the reference speech into a modern neural text-to-speech  synthesizer such as Tacotron2 .  More specifically, a small set of acoustic features are extracted from reference audio and then used to condition a TC2 synthesizer. The trained model is evaluated using subjective listening tests and a novel objective evaluation of prosody transfer is proposed. Listening tests show that the synthesized speech is rated as highly natural and that prosody is successfully transferred from the reference speech signal to the synthesized signal. 
 Including diverse voices in political decision-making strengthens our democratic institutions. Within the Canadian political system, there is gender inequality across all levels of elected government. Online abuse, such as hateful tweets, leveled at women engaged in politics contributes to this inequity, particularly tweets focusing on their gender. In this paper, we present ParityBOT: a Twitter bot which counters abusive tweets aimed at women in politics by sending supportive tweets about influential female leaders and facts about women in public life. ParityBOT is the first artificial intelligence-based intervention aimed at affecting online discourse for women in politics for the better. The goal of this project is to: $1$) raise awareness of issues relating to gender inequity in politics, and $2$) positively influence public discourse in politics. The main contribution of this paper is a scalable model to classify and respond to hateful tweets with quantitative and qualitative assessments. The ParityBOT abusive classification system was validated on public online harassment datasets. We conclude with analysis of the impact of ParityBOT, drawing from data gathered during interventions in both the $2019$ Alberta provincial and $2019$ Canadian federal elections.  % ParityBOT  is a Twitter bot that detects problematic or abusive tweets mentioning nominated women during specific election periods in specific jurisdictions and posts counteractive messages of support in the @ParityBOT Twitter account timeline, that include encouragement, facts, and positivity . The system scores each tracked tweet with a likelihood of abuse using features from machine learning text analysis models. The ParityBot abusive classification system was validated on online harassment datasets from previous research. The system was live for the 2019 Alberta Provincial Election, and is currently running for the 2019 Canadian Federal Election. Quantitative analysis of the ParityBot is presented by analysing the problem as a binary decision classification problem. Qualitative assessment by subject matter experts is included as this is a significant social issue and human expert opinions are critical to understanding and affecting real change. The paper concludes with a discussion of the scalability of such a system, and provides several conclusions which are supported by the underlying research.  
 In this work we propose a novel end-to-end imitation learning approach which combines natural language, vision, and motion information to produce an abstract representation of a task, which in turn is used to synthesize specific motion controllers at run-time. This multimodal approach enables generalization to a wide variety of environmental conditions and allows an end-user to direct a robot policy through verbal communication.  We empirically validate our approach with an extensive set of simulations and show that it achieves a high task success rate over a variety of conditions while remaining amenable to probabilistic interpretability. 
 Generating paraphrases that are lexically similar but semantically different is a challenging task. Paraphrases of this form can be used to augment data sets for various NLP tasks such as machine reading comprehension and question answering with non-trivial negative examples. In this article, we propose a deep variational model to generate paraphrases conditioned on a label that specifies whether the paraphrases are semantically related or not.  We also present new training recipes and KL regularization techniques that improve the performance of variational paraphrasing models. Our proposed model demonstrates promising results in enhancing the generative power of the model by employing label-dependent generation on paraphrasing datasets. 
 Vision-and-Language Navigation  is a challenging task in which an agent needs to follow a language-specified path to reach a target destination.  In this paper, we strive for the creation of an agent able to tackle three key issues: multi-modality, long-term dependencies, and adaptability towards different locomotive settings. To that end, we devise ``Perceive, Transform, and Act'' : a fully-attentive VLN architecture that leaves the recurrent approach behind and the first Transformer-like architecture incorporating three different modalities -- natural language, images, and discrete actions for the agent control. In particular, we adopt an early fusion strategy to merge lingual and visual information efficiently in our encoder. We then propose to refine the decoding phase with a late fusion extension between the agent's history of actions and the perception modalities. We experimentally validate our model on two datasets and two different action settings. PTA surpasses previous state-of-the-art architectures for low-level VLN on R2R and achieves the first place for both setups in the recently proposed R4R benchmark. Our code is publicly available at \url{https://github.com/aimagelab/perceive-transform-and-act}. 
 There are massive amounts of textual data residing in data\-bases, valuable for many machine learning  tasks. Since ML techniques depend on numerical input representations, word embeddings are increasingly utilized to convert symbolic representations such as text into meaningful numbers. However, a na\"ive one-to-one mapping of each word in a database to a word embedding vector is not sufficient and would lead to poor accuracies in ML tasks. Thus, we argue to additionally incorporate the information given by the database schema into the embedding, e.g. which words appear in the same column or are related to each other. In this paper, we therefore propose  , a novel approach to learn numerical representations of text values in databases, capturing the best of both worlds, the rich information encoded by word embeddings and the relational information encoded by database tables. We formulate relation retrofitting as a learning problem and present an efficient algorithm solving it. We investigate the impact of various hyperparameters on the learning problem and derive good settings for all of them. Our evaluation shows that the proposed embeddings are ready-to-use for many ML tasks such as classification and regression and even outperform state-of-the-art techniques in integration tasks such as null value imputation and link prediction. 
 While end-to-end learning has become a trend in deep learning, the model architecture is often designed to incorporate domain knowledge. We propose a novel convolutional recurrent neural network  architecture with temporal feedback connections, inspired by the feedback pathways from the brain to ears in the human auditory system. The proposed architecture uses a hidden state of the RNN module at the previous time to control the sensitivity of channel-wise feature activations in the CNN blocks at the current time, which is analogous to the mechanism of the outer hair-cell. We apply the proposed model to keyword spotting where the speech commands have sequential nature. We show the proposed model consistently outperforms the compared model without temporal feedback for different input/output settings in the CRNN framework. We also investigate the details of the performance improvement by conducting a failure analysis of the keyword spotting task and a visualization of the channel-wise feature scaling in each CNN block.   %In the proposed temporal feedback CRNN , a hidden state of the previous time step is fed into convolutional blocks in the current time step and used for channel-wise feature scaling after extracting local features. The results demonstrate the effectiveness of temporal feedbacks on keywords spotting achieving state-of-the-art performance.% In addition, we show that a typical many-to-one RNN in classification tasks, which have a single label for a sequential input, is not always effective with outperforming results of many-to-many RNNs. Furthermore, with failure analysis comparing TF-CRNNs to plain CRNNs, we show that temporal feedbacks help distinguish keywords with similar pronunciations, for example, ``learn" versus ``nine". Finally, an analysis of temporal feedbacks is provided to understand the behaviors of them. The analysis demonstrates that the feedbacks tend to be used to normalize input signals in the earlier blocks and process discriminatively in the last block.  
 % Motivation Keyword Spotting  enables speech-based user interaction on smart devices. % Problem statement Always-on and battery-powered application scenarios for smart devices put constraints on hardware resources and power consumption, while also demanding high accuracy as well as real-time capability. Previous architectures first extracted acoustic features and then applied a neural network to classify keyword probabilities, optimizing towards memory footprint and execution time. %Previous architectures performed KWS from MFCC features and optimized towards memory footprint and execution time.  % * What did we do? Compared to previous publications, we took additional steps to reduce power and memory consumption without reducing classification accuracy. % * how did we do it? Power-consuming audio preprocessing and data transfer steps are eliminated by directly classifying from raw audio. For this, our end-to-end architecture extracts spectral features using parametrized Sinc-convolutions. Its memory footprint is further reduced by grouping depthwise separable convolutions. %Grouped depth-wise separable convolutions further reduce is memory footprint. % * What is new? Our network achieves the competitive accuracy of $96.4\%$ on Google's Speech Commands test set with only $62$k parameters. % Es fehlt hier der Vergleich f鐪塺 das state-of-the-art, z.B. "an absolute improvement of $0.3\%$ in comparison with a same-size ResNet model." 
   This work presents a large-scale audio-visual speech recognition   system based on a recurrent neural network transducer    architecture. To support the development of such a system, we built   a large audio-visual  dataset of segmented utterances extracted   from YouTube public videos, leading to 31k hours of audio-visual   training content. The performance of an audio-only, visual-only, and   audio-visual system are compared on two large-vocabulary test sets:   a set of utterance segments from public YouTube videos called \ytdev   and the publicly available \lrsted set. To highlight the   contribution of the visual modality, we also evaluated the   performance of our system on the \ytdev set artificially corrupted   with background noise and overlapping speech. To the best   of our knowledge, our system significantly improves the   state-of-the-art on the \lrsted set.  > 6  PAGES USED} } \fi 
  Voice conversion  is a task to transform a person's voice to different style while conserving linguistic contents. Previous state-of-the-art on VC is based on sequence-to-sequence  model, which could mislead linguistic information. There was an attempt to overcome it by using textual supervision, it requires explicit alignment which loses the benefit of using seq2seq model. In this paper, a voice converter using multitask learning with text-to-speech  is presented. The embedding space of seq2seq-based TTS has abundant information on the text. The role of the decoder of TTS is to convert embedding space to speech, which is same to VC. In the proposed model, the whole network is trained to minimize loss of VC and TTS. VC is expected to capture more linguistic information and to preserve training stability by multitask learning. Experiments of VC were performed on a male Korean emotional text-speech dataset, and it is shown that multitask learning is helpful to keep linguistic contents in VC.  
 This paper focuses on the problem of query by example spoken term detection  in zero-resource scenario. State-of-the-art approaches primarily rely on dynamic time warping  based template matching techniques using phone posterior or bottleneck features extracted from a deep neural network . We use both monolingual and multilingual bottleneck features, and show that multilingual features perform increasingly better with more training languages.  Previously, it has been shown that the DTW based matching can be replaced with a CNN based matching while using posterior features. Here, we show that the CNN based matching outperforms DTW based matching using bottleneck features as well. In this case, the feature extraction and pattern matching stages of our QbE-STD system are optimized independently of each other. We propose to integrate these two stages in a fully neural network based end-to-end learning framework to enable joint optimization of those two stages simultaneously. The proposed approaches are evaluated on two challenging multilingual datasets: Spoken Web Search 2013 and Query by Example Search on Speech Task 2014, demonstrating in each case significant improvements.  %space of phone posteriors is highly structured, as a union of low-dimensional subspaces. To exploit the temporal and sparse structure of the speech data, we investigate here three different QbE-STD systems based on sparse model recovery. More specifically, we use query examples to model the query subspace using dictionary for sparse coding. Reconstruction errors calculated using sparse representation of feature vectors are then used to characterize the underlying subspaces. The first approach uses these reconstruction errors in a dynamic programming framework to detect the spoken query, resulting in a much faster search compared to standard template matching. The other two methods aim at merging template matching and sparsity based approaches to further improve the performance. The first one proposes to regularize the template matching local distances using sparse reconstruction errors. The second approach aims at using the sparse reconstruction errors to rescore  the template matching likelihood. Experiments on two different databases  show that the proposed hybrid systems perform better than a highly competitive QbE-STD baseline system.  
 Neural machine translation models usually adopt the teacher forcing strategy for training which requires the predicted sequence matches ground truth word by word and forces the probability of each prediction to approach a 0-1 distribution. However, the strategy casts all the portion of the distribution to the ground truth word and ignores other words in the target vocabulary even when the ground truth word cannot dominate the distribution. To address the problem of teacher forcing, we propose a method to introduce an evaluation module to guide the distribution of the prediction. The evaluation module accesses each prediction from the perspectives of fluency and faithfulness to encourage the model to generate the word which has a fluent connection with its past and future translation and meanwhile tends to form a translation equivalent in meaning to the source.  The experiments on multiple translation tasks show that our method can achieve significant improvements over strong baselines. 
 We propose a novel model for a topic-aware chatbot by combining the traditional Recurrent Neural Network  encoder-decoder model with a topic attention layer based on Nonnegative Matrix Factorization . After learning topic vectors from an auxiliary text corpus via NMF, the decoder is trained so that it is more likely to sample response words from the most correlated topic vectors. One of the main advantages in our architecture is that the user can easily switch the NMF-learned topic vectors so that the chatbot obtains desired topic-awareness. We demonstrate our model by training on a single conversational data set which is then augmented with topic matrices learned from different auxiliary data sets. We show that our topic-aware chatbot not only outperforms the non-topic counterpart, but also that each topic-aware model qualitatively and contextually gives the most relevant answer depending on the topic of question.  
 The sequence-to-sequence  model generates target words iteratively given the previously observed words during decoding process, which results in the loss of the holistic semantics in the target response and the complete semantic relationship between responses and dialogue histories. In this paper, we propose a generic diversity-promoting joint network, called Holistic Semantic Constraint Joint Network , enhancing the global sentence information, and then regularizing the objective function with penalizing the low entropy output. Our network introduces more target information to improve diversity, and captures direct semantic information to better constrain the relevance simultaneously. Moreover, the proposed method can be easily applied to any Seq2Seq structure. Extensive experiments on several dialogue corpuses show that our method effectively improves both semantic consistency and diversity of generated responses, and achieves better performance than other competitive methods. 
 This study focuses on a reverse question answering  procedure, in which machines proactively raise questions and humans supply the answers. This procedure exists in many real human-machine interaction applications. However, a crucial problem in human-machine interaction is answer understanding. The existing solutions have relied on mandatory option term selection to avoid automatic answer understanding. However, these solutions have led to unnatural human-computer interaction and negatively affected user experience. To this end, the current study proposes a novel deep answer understanding network, called AntNet, for reverse QA. The network consists of three new modules, namely, skeleton attention for questions, relevance-aware representation of answers, and multi-hop based fusion. As answer understanding for reverse QA has not been explored, a new data corpus is compiled in this study. Experimental results indicate that our proposed network is significantly better than existing methods and those modified from classical natural language processing deep models. The effectiveness of the three new modules is also verified. 
 The recognition of emotion and dialogue acts enriches conversational analysis and help to build natural dialogue systems. Emotion interpretation makes us understand feelings and dialogue acts reflect the intentions and performative functions in the utterances. However, most of the textual and multi-modal conversational emotion corpora contain only emotion labels but not dialogue acts. To address this problem, we propose to use a pool of various recurrent neural models trained on a dialogue act corpus, with and without context.  These neural models annotate the emotion corpora with dialogue act labels, and an ensemble annotator extracts the final dialogue act label. We annotated two accessible multi-modal emotion corpora: IEMOCAP and MELD.  We analyzed the co-occurrence of emotion and dialogue act labels and discovered specific relations. For example, \textit{Accept/Agree
 Automated ICD coding, which assigns the International Classification of Disease codes to patient visits, has attracted much research attention since it can save time and labor for billing. The previous state-of-the-art model utilized one convolutional layer to build document representations for predicting ICD codes. However, the lengths and grammar of text fragments, which are closely related to ICD coding, vary a lot in different documents. Therefore, a flat and fixed-length convolutional architecture may not be capable of learning good document representations. In this paper, we proposed a Multi-Filter Residual Convolutional Neural Network  for ICD coding. The innovations of our model are two-folds: it utilizes a multi-filter convolutional layer to capture various text patterns with different lengths and a residual convolutional layer to enlarge the receptive field. We evaluated the effectiveness of our model on the widely-used MIMIC dataset. On the full code set of MIMIC-III, our model outperformed the state-of-the-art model in 4 out of 6 evaluation metrics. On the top-50 code set of MIMIC-III and the full code set of MIMIC-II, our model outperformed all the existing and state-of-the-art models in all evaluation metrics. The code is available at https://github.com/foxlf823/Multi-Filter-Residual-Convolutional-Neural-Network.  
 Building conversational speech recognition systems for new languages is constrained by the availability of utterances capturing user-device interactions. Data collection is expensive and limited by speed of manual transcription. In order to address this, we advocate the use of neural machine translation as a data augmentation technique for bootstrapping language models. Machine translation  offers a systematic way of incorporating collections from mature, resource-rich conversational systems that may be available for a different language. However, ingesting raw translations from a general purpose MT system may not be effective owing to the presence of named entities, intra sentential code-switching and the domain mismatch between the conversational data being translated and the parallel text used for MT training. To circumvent this, we explore following domain adaptation techniques:  sentence embedding based data selection for MT training,  model finetuning, and  rescoring and filtering translated hypotheses. Using Hindi language as the experimental testbed, we supplement transcribed collections with translated US English utterances. We observe a relative word error rate reduction of 7.8-15.6\%, depending on the bootstrapping phase. Fine grained analysis reveals that translation particularly aids the interaction scenarios underrepresented in the transcribed data. 
 Despite the excellent performance of black box approaches to modeling sentiment and emotion, lexica  that characterize different emotions are indispensable to the NLP community because they allow for interpretable and robust predictions. Emotion analysis of text is increasing in popularity in NLP; however, manually creating lexica for psychological constructs such as empathy has proven difficult. This paper automatically creates empathy word ratings from document-level ratings. The underlying problem of learning word ratings from higher-level supervision has to date only been addressed in an {\em ad hoc
 		Named entity recognition  plays an important role in text-based information retrieval. In this paper, we combine Bidirectional Long Short-Term Memory   with Conditional Random Field   to create a novel deep learning model for the NER problem. Each word as input of the deep learning model is represented by a Word2vec-trained vector. A word embedding set trained from about one million articles in 2018 collected through a Vietnamese news portal . In addition, we concatenate a Word2Vec-trained vector with semantic feature vector  tagging, chunk-tag) and hidden syntactic feature vector  to achieve the  result in Vietnamese NER system. The result was conducted on the data set VLSP2016  competition. 	
         %Most news articles already have corresponding headlines.          %Thus, individual writers prefer neural headline editing models over headline generation models.          %They want the model to help editing their original headline to be more attractive instead of creating a new one.         Many social media news writers are not professionally trained.          Therefore, social media platforms have to hire professional editors to adjust amateur headlines to attract more readers.          We propose to automate this headline editing process through neural network models to provide more immediate writing support for these social media news writers.         To train such a neural headline editing model, we collected a dataset which contains articles with original headlines and professionally edited headlines.         However, it is expensive to collect a large number of professionally edited headlines.         To solve this low-resource problem, we design an encoder-decoder model which leverages large scale pre-trained language models.         We further improve the pre-trained model's quality by introducing a headline generation task as an intermediate task before the headline editing task.         Also, we propose Self Importance-Aware  loss to address the different levels of editing in the dataset by down-weighting the importance of easily classified tokens and sentences.         With the help of Pre-training, Adaptation, and SIA, the model learns to generate headlines in the professional editor's style.         Experimental results show that our method significantly improves the quality of headline editing comparing against previous methods.     
  The use of Deep Neural Network architectures for Language Modeling has recently seen a tremendous increase in interest in the field of NLP with the advent of transfer learning and the shift in focus from rule-based and predictive models  to generative or  models to solve the long-standing problems in NLP like Information Extraction or Question Answering. While this shift has worked greatly for languages lacking in inflectional morphology, such as English, challenges still arise when trying to build similar systems for morphologically-rich languages, since their individual words shift forms in context more often . In this paper we investigate the extent to which these new  or  techniques can serve to alleviate the type-token ratio disparity in morphologically rich languages. We apply an off-the-shelf neural language modeling library to the newly introduced  task of unsupervised inflection generation in the nominal domain of three morphologically rich languages: Romanian, German, and Finnish. We show that this neural language model architecture can successfully generate the full inflection table of nouns without needing any pre-training on large, wikipedia-sized corpora, as long as the model is shown enough inflection examples. In fact, our experiments show that pre-training hinders the generation performance. % \Keywords{computational morphology, inflection learning, deep neural networks}  
 Pre-training and fine-tuning have achieved great success in natural language process field.  The standard paradigm of exploiting them includes two steps: first, pre-training a model, e.g. BERT, with a large scale unlabeled monolingual data. Then, fine-tuning the pre-trained model with labeled data from downstream tasks.  However, in neural machine translation , we address the problem that the training objective of the bilingual task is far different from the monolingual pre-trained model. This gap leads that only using fine-tuning in NMT can not fully utilize prior language knowledge.  In this paper, we propose an Apt framework for acquiring knowledge from pre-trained model to NMT. The proposed approach includes two modules: 1). a dynamic fusion mechanism to fuse task-specific features adapted from general knowledge into NMT network, 2). a knowledge distillation paradigm to learn language knowledge continuously during the NMT training process. The proposed approach could integrate suitable knowledge from pre-trained models to improve the NMT. Experimental results on WMT English to German, German to English and Chinese to English machine translation tasks show that our model outperforms strong baselines and the fine-tuning counterparts. 
 In this work, we tackle the problem of structured text generation, specifically academic paper generation in \LaTeX{}, inspired by the surprisingly good results of basic character-level language models. Our motivation is using more recent and advanced methods of language modeling on a more complex dataset of \LaTeX{} source files to generate realistic academic papers. Our first contribution is preparing a dataset with \LaTeX{} source files on recent open-source computer vision papers. Our second contribution is experimenting with recent methods of language modeling and text generation such as Transformer and Transformer-XL to generate consistent \LaTeX{} code. We report cross-entropy and bits-per-character  results of the trained models, and we also discuss interesting points on some examples of the generated \LaTeX{} code.  
 The field of machine translation , the automatic translation of written text from one natural language into another, has experienced a major paradigm shift in recent years. Statistical MT, which mainly relies on various count-based models and which used to dominate MT research for decades, has largely been superseded by neural machine translation , which tackles translation with a single neural network. In this work we will trace back the origins of modern NMT architectures to word and sentence embeddings and earlier examples of the encoder-decoder network family. We will conclude with a survey of recent trends in the field. 
 Knowledge-graph-based reasoning has drawn a lot of attention due to its interpretability. However, previous methods suffer from the incompleteness of the knowledge graph, namely the interested link or entity that can be missing in the knowledge graph. Also, most previous models assume the distance between the target and source entity is short, which is not true on a real-world KG like Freebase. The sensitivity to the incompleteness of KG and the incapability to capture the long-distance link between entities have limited the performance of these models on large KG. In this paper, we propose a model that leverages the text corpus to cure such limitations, either the explicit or implicit missing links. We model the question answering on KG as a cooperative task between two agents, a knowledge graph reasoning agent and an information extraction agent. Each agent learns its skill to complete its own task, hopping on KG or select knowledge from the corpus, via maximizing the reward for correctly answering the question. The reasoning agent decides how to find an equivalent path for the given entity and relation. The extraction agent provide shortcut for long-distance target entity or provide missing relations for explicit missing links with messages from the reasoning agent. Through such cooperative reward design, our model can augment the incomplete KG strategically while not introduce much unnecessary noise that could enlarge the search space and lower the performance. 
 Story generation is an important natural language processing task that aims to generate coherent stories automatically. While the use of neural networks has proven effective in improving story generation, how to learn to generate an explainable high-level plot still remains a major challenge. In this work, we propose a latent variable model for neural story generation. The model treats an outline, which is a natural language sentence explainable to humans, as a latent variable to represent a high-level plot that bridges the input and output. We adopt an external summarization model to guide the latent variable model to learn how to generate outlines from training data. Experiments show that our approach achieves significant improvements over state-of-the-art methods in both automatic and human evaluations. 
 Microblogs are widely used to express people閳ユ獨 opinions and feelings in daily life. Sentiment analysis  can timely detect personal sentiment polarities through analyzing text. Deep learning approaches have been broadly used in SA but still have not fully exploited syntax information. In this paper, we propose a syntax-based graph convolution network  model to enhance the understanding of diverse grammatical structures of Chinese microblogs. In addition, a pooling method based on percentile is proposed to improve the accuracy of the model. In experiments, for Chinese microblogs emotion classification categories including happiness, sadness, like, anger, disgust, fear, and surprise, the F-measure of our model reaches 82.32\% and exceeds the state-of-the-art algorithm by 5.90\%. The experimental results show that our model can effectively utilize the information of dependency parsing to improve the performance of emotion detection. What is more, we annotate a new dataset for Chinese emotion classification, which is open to other researchers.  % \PACS{PACS code1 \and PACS code2 \and more} %  
This article compares two multimodal resources that consist of diagrams which describe topics in elementary school natural sciences. Both resources contain the same diagrams and represent their structure using graphs, but differ in terms of their annotation schema and how the annotations have been created -- depending on the resource in question -- either by crowd-sourced workers or trained experts. This article reports on two experiments that evaluate how effectively crowd-sourced and expert-annotated graphs can represent the multimodal structure of diagrams for representation learning using various graph neural networks. The results show that the identity of diagram elements can be learned from their layout features, while the expert annotations provide better representations of diagram types. \\ \newline \Keywords{multimodality, diagrams, graph neural networks, annotation, crowd-sourcing
 Information extraction  aims to produce structured information from an input text, e.g., Named Entity Recognition and Relation Extraction. Various attempts have been proposed for IE via feature engineering or deep learning. However, most of them fail to associate the complex relationships inherent in the task itself, which has proven to be especially crucial. For example, the relation between 2 entities is highly dependent on their entity types. These dependencies can be regarded as complex constraints that can be efficiently expressed as logical rules. To combine such logic reasoning capabilities with learning capabilities of deep neural networks, we propose to integrate logical knowledge in the form of first-order logic into a deep learning system, which can be trained jointly in an end-to-end manner. The integrated framework is able to enhance neural outputs with knowledge regularization via logic rules, and at the same time update the weights of logic rules to comply with the characteristics of the training data. We demonstrate the effectiveness and generalization of the proposed model on multiple IE tasks. 
   This document contains the instructions for preparing a camera-ready   manuscript for the proceedings of ACL-2015. The document itself   conforms to its own specifications, and is therefore an example of   what your manuscript should look like. These instructions should be   used for both papers submitted for review and for final versions of   accepted papers.  Authors are asked to conform to all the directions   reported in this document. 
      Sequence-level knowledge distillation  is a model compression technique that leverages large, accurate teacher models to train smaller, under-parameterized student models.   Why does pre-processing MT data with SLKD help us train smaller   models? We test the common hypothesis that SLKD addresses a capacity   deficiency in students by ``simplifying'' noisy data points and find it unlikely in our case.   Models trained on concatenations of original and  ``simplified''   datasets generalize just as well as baseline SLKD.  We then propose an alternative hypothesis under the lens of data augmentation and regularization.   We try various augmentation strategies and observe that dropout regularization can become unnecessary. Our methods achieve BLEU gains of 0.7-1.2 on TED Talks.   
Distributed representations of medical concepts have been used to support downstream clinical tasks recently. Electronic Health Records  capture different aspects of patients' hospital encounters and serve as a rich source for augmenting clinical decision making by learning robust medical concept embeddings. However, the same medical concept can be recorded in different modalities  --- with each capturing salient information unique to that modality --- and a holistic representation calls for relevant feature ensemble from all information sources. We hypothesize that representations learned from heterogeneous data types would lead to performance enhancement on various clinical informatics and predictive modeling tasks. To this end, our proposed approach makes use of \textit{meta-embeddings
   Over 800 languages are spoken across West Africa. Despite the obvious diversity among people who speak these languages, one language significantly unifies them all - West African Pidgin English. There are at least 80 million speakers of West African Pidgin English. However, there is no known natural language processing  work on this language. In this work, we perform the first NLP work on the most popular variant of the language, providing three major contributions. First, the provision of a Pidgin corpus of over 56000 sentences, which is the largest we know of. Secondly, the training of the first ever cross-lingual embedding between Pidgin and English. This aligned embedding will be helpful in the performance of various downstream tasks between English and Pidgin. Thirdly, the training of an Unsupervised Neural Machine Translation model between Pidgin and English which achieves BLEU scores of 7.93 from Pidgin to English, and 5.18 from English to Pidgin. In all, this work greatly reduces the barrier of entry for future NLP works on West African Pidgin English. 
   Relation extraction is the task of determining the relation between two entities in a sentence. Distantly-supervised models are popular for this task. However, sentences can be long and two entities can be located far from each other in a sentence. The pieces of evidence supporting the presence of a relation between two entities may not be very direct, since the entities may be connected via some indirect links such as a third entity or via co-reference. Relation extraction in such scenarios becomes more challenging as we need to capture the long-distance interactions among the entities and other words in the sentence. Also, the words in a sentence do not contribute equally in identifying the relation between the two entities. To address this issue, we propose a novel and effective attention model which incorporates syntactic information of the sentence and a multi-factor attention mechanism. Experiments on the New York Times corpus show that our proposed model outperforms prior state-of-the-art models. 
 Automatic dialogue evaluation plays a crucial role in open-domain dialogue research. Previous works train neural networks with limited annotation for conducting automatic dialogue evaluation, which would naturally affect the evaluation fairness as dialogue systems close to the scope of training corpus would have more preference than the other ones. In this paper, we study alleviating this problem from the perspective of continual learning: given an existing neural dialogue evaluator and the next system to be evaluated, we fine-tune the learned neural evaluator by selectively forgetting/updating its parameters, to jointly fit dialogue systems have been and will be evaluated. Our motivation is to seek for a life-long and low-cost automatic evaluation for dialogue systems, rather than to reconstruct the evaluator over and over again. Experimental results show that our continual evaluator achieves comparable performance with reconstructing new evaluators, while requires significantly lower resources.  
 As a special machine translation task, dialect translation has two main characteristics: 1) lack of parallel training corpus; and 2) possessing similar grammar between two sides of the translation.  In this paper, we investigate how to exploit the commonality and diversity between dialects thus to build unsupervised translation models merely accessing to monolingual data. Specifically, we leverage pivot-private embedding, layer coordination, as well as parameter sharing to sufficiently model commonality and diversity among source and target, ranging from lexical, through syntactic, to semantic levels.   In order to examine the effectiveness of the proposed models, we collect 20 million monolingual corpus for each of Mandarin and Cantonese, which are official language and the most widely used dialect in China.  Experimental results reveal that our methods outperform rule-based simplified and traditional Chinese conversion and conventional unsupervised translation models over 12 BLEU scores.   
 Neural machine translation  models have achieved state-of-the-art translation quality with a large quantity of parallel corpora available. However, their performance suffers significantly when it comes to domain-specific translations, in which training data are usually scarce. In this paper, we present a novel NMT model with a new word embedding transition technique for fast domain adaption. We propose to split parameters in the model into two groups: model parameters and meta parameters. The former are used to model the translation while the latter are used to adjust the representational space to generalize the model to different domains. We mimic the domain adaptation of the machine translation model to low-resource domains using multiple translation tasks on different domains. A new training strategy based on meta-learning is developed along with the proposed model to update the model parameters and meta parameters alternately. %yiq: alternatively? Experiments on datasets of different domains showed substantial improvements of NMT performances on a limited amount of data. 
 % \linenumbers Evaluating the readability of a text can significantly facilitate the precise expression of information in a written form. The formulation of text readability assessment demands the identification of meaningful properties of the text and correct conversion of features to the right readability level. Sophisticated features and models are being used to evaluate the comprehensibility of texts accurately. Still, these models are challenging to implement, heavily language-dependent, and do not perform well on short texts. \\ Deep reinforcement learning models are demonstrated to be helpful in further improvement of state-of-the-art text readability assessment models. The main contributions of the proposed approach are the automation of feature extraction, loosening the tight language dependency of text readability assessment task, and efficient use of text by finding the minimum portion of a text required to assess its readability. The experiments on Weebit, Cambridge Exams, and Persian readability datasets display the model's state-of-the-art precision, efficiency, and the capability to be applied to other languages. 
 %The Entity Linking  approaches have been a long-standing research field and find applicability in various use cases such as semantic search, text annotation, question answering, etc. Although effective and robust, current approaches are still limited to particular knowledge repositories  or specific knowledge graphs .   The collaborative knowledge graphs such as Wikidata excessively rely on the crowd to author the information. Since the crowd is not bound to a standard protocol for assigning entity titles, the knowledge graph is populated by non-standard, noisy, long or even sometimes awkward titles. The issue of long, implicit, and nonstandard entity representations is a challenge in Entity Linking  approaches for gaining high precision and recall. Underlying KG in general is the source of target entities for EL approaches, however, it often contains other relevant information, such as aliases of entities . EL models usually ignore such readily available entity attributes. In this paper, we examine the role of knowledge graph context on an attentive neural network approach for entity linking on Wikidata. Our approach contributes by exploiting the sufficient context from a KG as a source of background knowledge, which is then fed into the neural network. This approach demonstrates merit to address challenges associated with entity titles . Our experimental study shows $\approx$8\% improvements over the baseline approach, and significantly outperform an end to end approach for Wikidata entity linking.  %This work opens a new direction for the research community to pay attention to developing context-aware EL approaches for  collaborative knowledge graphs.  
 Current approaches to machine translation  either translate sentences in isolation, disregarding the context they appear in, or model context at the level of the full document, without a notion of any internal structure the document may have. In this work we consider the fact that documents are rarely homogeneous blocks of text, but rather consist of parts covering different topics. Some documents, such as biographies and encyclopedia entries, have highly predictable, regular structures in which sections are characterised by different topics. We draw inspiration from \newcite{lw2014
 The cost to train machine learning models has been increasing exponentially , making exploration and research into the correct features and architecture a costly or intractable endeavor at scale. However, using a technique named ``surgery'' OpenAI Five was continuously trained to play the game DotA 2 over the course of 10 months through 20 major changes in features and architecture. Surgery transfers trained weights from one network to another after a selection process to determine which sections of the model are unchanged and which must be re-initialized. In the past, the selection process relied on heuristics, manual labor, or pre-existing boundaries in the structure of the model, limiting the ability to salvage experiments after modifications of the feature set or input reorderings.  We propose a solution to automatically determine which components of a neural network model should be salvaged and which require retraining. We achieve this by allowing the model to operate over discrete sets of features and use set-based operations to determine the exact relationship between inputs and outputs, and how they change across tweaks in model architecture. In this paper, we introduce the methodology for enabling neural networks to operate on sets, derive two methods for detecting feature-parameter interaction maps, and show their equivalence. We empirically validate that we can surgery weights across feature and architecture changes to the OpenAI Five model. 
 % the structure and content of natural language referring expressions change through continued interaction. %While such adaptation has been demonstrated under a variety of conditions, p Here we draw upon recent advances in natural language processing to provide a finer-grained characterization of the dynamics of this learning process. We release an open corpus  of extended dyadic interactions in a classic repeated reference game task where pairs of participants had to coordinate on how to refer to initially difficult-to-describe tangram stimuli. We find that different pairs discover a wide variety of idiosyncratic but efficient and stable solutions to the problem of reference. Furthermore, these conventions are shaped by the communicative context: words that are more discriminative in the initial context  are more likely to persist through the final repetition. Finally, we find systematic structure in how a speaker's referring expressions become more efficient over time: syntactic units drop out in clusters following positive feedback from the listener, eventually leaving short labels containing open-class parts of speech. These findings provide a higher resolution look at the quantitative dynamics of  convention formation and support further development of computational models of learning in communication. %: based on a shared history of usage, words systematically acquire new meaning to support more efficient communication with a partner.  % Please include a maximum of seven keywords 
 Sentence ordering is to restore the original paragraph from a set of sentences. It involves capturing global dependencies among sentences regardless of their input order. In this paper, we propose a novel and flexible graph-based neural sentence ordering model, which adopts graph recurrent network  to accurately learn semantic representations of the sentences.  Instead of assuming connections between all pairs of input sentences, we use entities that are shared among multiple sentences to make more expressive graph representations with less noise. Experimental results show that our proposed model outperforms the existing state-of-the-art systems on several benchmark datasets, demonstrating the effectiveness of our model. We also conduct a thorough analysis on how entities help the performance.  Our code is available at https://github.com/DeepLearnXMU/NSEG.git. 
 		 Previous studies on the domain adaptation for neural machine translation  mainly focus on the one-pass transferring out-of-domain translation knowledge to in-domain NMT model. In this paper,  we argue that such a strategy fails to fully extract the domain-shared translation knowledge,  and repeatedly utilizing corpora of different domains can lead to better distillation of domain-shared translation knowledge. To this end,  we propose an iterative dual domain adaptation framework for NMT. Specifically, we first pre-train in-domain and out-of-domain NMT models using their own training corpora respectively,  and then iteratively perform bidirectional translation knowledge transfer  based on knowledge distillation until the in-domain NMT model convergences. Furthermore,  we extend the proposed framework to the scenario of multiple out-of-domain training corpora, where the above-mentioned transfer is performed sequentially between the in-domain and each out-of-domain NMT models in the ascending order of their domain similarities. Empirical results on Chinese-English and English-German translation tasks demonstrate the effectiveness of our framework. 
 Machine translation  is an important task in natural language processing  as it automates the translation process and reduces the reliance on human translators. %For any machine translation task, we are given a set of sentences in the source language and the goal is to generate their translations in the target language.  With the resurgence of neural networks, the translation quality surpasses that of the translations obtained using statistical techniques for most language-pairs. Up until a few years ago, almost all of the neural translation models translated sentences , without incorporating the wider  and inter-dependencies among the sentences.   % We provide an organisation of the literature based on novelties in modelling and architectures as well as training and decoding strategies.  %  % %While most works focus onarchitecturesto better model the inter-dependencies among the document sentences , a few focus on bettertraininganddecodingstrategies .6We also present the relevant works which focused on document-level NMTin recent shared tasks % %\reza{We first define the problem and then discuss the literature in document-level neural machine translation in detail by focusing on works which use the wider context explicitly in the form of context sentences or discourse aspects pertaining to the whole document.}  In addition, we  cover evaluation strategies that have been introduced to account for the improvements in document MT, including automatic metrics and discourse-targeted test sets. We conclude by presenting possible avenues for future exploration in this research field. 
 Simile recognition is to detect simile sentences and to extract simile components, i.e., {. It involves two subtasks: {.   Recent work has shown that standard multitask learning is effective for Chinese simile recognition, but it is still uncertain whether the mutual effects between the subtasks have been well captured by simple parameter sharing. We propose a novel cyclic multitask learning framework for neural simile recognition, which stacks the subtasks and makes them into a loop by connecting the last to the first. It iteratively performs each subtask, taking the outputs of the previous subtask as additional inputs to the current one, so that the interdependence between the subtasks can be better explored. Extensive experiments show that our framework significantly outperforms the current state-of-the-art model and our carefully designed baselines, and the gains are still remarkable using BERT. Source Code of this paper are available on https://github.com/DeepLearnXMU/Cyclic. %Code will be released  %at http://www.github.com/  %upon acceptance. 
 This paper describes our approach in DSTC 8 Track 4: Schema-Guided Dialogue State Tracking. The goal of this task is to predict the intents and slots in each user turn to complete the dialogue state tracking  based on the information provided by the task's schema. Different from traditional stage-wise DST, we propose an end-to-end DST system to avoid error accumulation between the dialogue turns. The DST system consists of a machine reading comprehension  model for non-categorical slots and a Wide \& Deep model for categorical slots. As far as we know, this is the first time that MRC and Wide \& Deep model are applied to DST problem in a fully end-to-end way. Experimental results show that our framework achieves an excellent performance on the test dataset including 50\% zero-shot services with a joint goal accuracy of 0.8652 and a slot tagging F1-Score of 0.9835. 
    Deep learning methods that extract answers for non-factoid questions    from QA sites are seen as critical since they can assist users in    reaching their next decisions through conversations with AI systems.    The current methods, however, have the following two problems:     They can not understand the ambiguous use of words in the questions    as word usage can strongly depend on the context . As a result, the accuracies of    their answer selections are not good enough.   The current methods    can only { new ones.  Thus, they can not answer the    questions that are somewhat different with those stored in QA sites.     Our solution, Neural Answer Construction Model, tackles these    problems as it:    %     Incorporates the biases of semantics behind questions     into word embeddings while    also computing them regardless of the semantics.  As a result, it can    extract answers that suit the contexts of words used in the question    as well as following the common usage of words across semantics. This improves    the accuracy of answer selection.   Uses biLSTM to compute the embeddings of    questions as well as those of the sentences often used to form    answers . It then simultaneously    learns the optimum combination of those sentences as well as the    closeness between the question and those sentences.  As a result, our    model can construct an answer that corresponds to the situation    that underlies the question; it fills the gap between answer selection    and generation and is the first model to move beyond the current    simple answer selection model for non-factoid QAs.  Evaluations using    datasets created for love advice stored in the Japanese QA site,    Oshiete goo, indicate that our model achieves 20 \% higher accuracy    in answer creation than the strong baselines.  Our model is    practical and has already been applied to the love advice service in    Oshiete goo. 
  Authorship identification is a process in which the author of a text is identified. Most known literary texts can easily be attributed to a certain author because they are, for example, signed. Yet sometimes we find unfinished pieces of work or a whole bunch of manuscripts with a wide variety of possible authors. In order to assess the importance of such a manuscript, it is vital to know who wrote it. In this work, we aim to develop a machine learning framework to effectively determine authorship. We formulate the task as a single-label multi-class text categorization problem and propose a supervised machine learning framework incorporating stylometric features. This task is highly interdisciplinary in that it takes advantage of machine learning, information retrieval, and natural language processing. We present an approach and a model which learns the differences in writing style between $50$ different authors and is able to predict the author of a new text with high accuracy. The accuracy is seen to increase significantly after introducing certain linguistic stylometric features along with text features.\\~\\  \- key words --- author identification, stylometry, text mining, multi-class classification, information retrieval, natural language processing, machine learning  
 This paper presents a hybrid machine learning method of classifying residential requests in natural language to responsible departments that provide timely responses back to residents under the vision of digital government services in smart cities. Residential requests in natural language descriptions cover almost every aspect of a city's daily operation. Hence the responsible departments are fine-grained to even the level of local communities. There are no specific general categories or labels for each request sample. This causes two issues for supervised classification solutions, namely 1) the request sample data is unbalanced and 2) lack of specific labels for training. To solve these issues, we investigate a hybrid machine learning method that generates meta-class labels by means of unsupervised clustering algorithms; applies two-word embedding methods with three classifiers ; and selects the best performing classifier as the classification result. We demonstrate our approach performing better classification tasks compared two benchmarking machine learning models, Naive Bayes classifier and a Multiple Layer Perceptron . In addition, the hierarchical classification method provides insights into the source of classification errors.  
 Authorship attribution is the process of identifying the author of a text.  Classification-based approaches work well for small numbers of candidate authors, but only similarity-based methods are applicable for larger numbers of authors or for authors beyond the training set.  While deep learning methods have been applied to classification-based approaches, applications to similarity-based applications have been limited, and most similarity-based methods only embody static notions of similarity.  Siamese networks have been used to develop learned notions of similarity in one-shot image tasks, and also for tasks of mostly semantic relatedness in NLP.  We examine their application to the stylistic task of authorship attribution on datasets with large numbers of authors, looking at multiple energy functions and neural network architectures, and show that they can substantially outperform both classification- and existing similarity-based approaches.  We also find an unexpected relationship between choice of energy function and number of authors, in terms of performance. 
 This short example shows a contrived example on how to format the authors' information for {. 
   Multimodal analysis that uses numerical time series and textual corpora as input data sources is becoming a promising approach, especially in the financial industry. However, the main focus of such analysis has been on achieving high prediction accuracy while little effort has been spent on the important task of understanding the association between the two data modalities. Performance on the time series hence receives little explanation though human-understandable textual information is available. In this work, we address the problem of given a numerical time series, and a general corpus of textual stories collected in the same period of the time series, the task is to timely discover a succinct set of textual stories associated with that time series. Towards this goal, we propose a novel multi-modal neural model called \verb"MSIN" that jointly learns both numerical time series and categorical text articles in order to unearth the association between them. Through \text{multiple} steps of data interrelation between the two data modalities, \verb"MSIN" learns to focus on a small subset of text articles that best align with the performance in the time series. This succinct set is timely discovered and presented as recommended documents, acting as automated information filtering, for the given time series. We empirically evaluate the performance of our model on discovering relevant news articles for two stock time series from Apple and Google companies, along with the daily news articles collected from the Thomson Reuters over a period of seven consecutive years. The experimental results demonstrate that \verb"MSIN" achieves up to 84.9\% and 87.2\% in recalling the ground truth articles respectively to the two examined time series, far more superior to state-of-the-art algorithms that rely on conventional attention mechanism in deep learning. 
 Multilingual neural machine translation  has recently been investigated from different aspects  and in different settings . This paper concentrates on a deep understanding of multilingual NMT and conducts a comprehensive study on a multilingual dataset with more than 20 languages. Our results show that  low-resource language pairs benefit much from multilingual training, while rich-resource language pairs may get hurt under limited model capacity and training with similar languages benefits more than dissimilar languages;  fine-tuning performs better than training from scratch in the one-to-many setting  while training from scratch performs better in the many-to-one setting;  the bottom layers of the encoder and top layers of the decoder capture more language specific information, and just fine-tuning these parts can achieve good accuracy for low-resource language pairs;  direct translation is better than pivot translation when the source language is similar to the target language , even when the size of direct training data is much smaller;  given a fixed training data budget, it is better to introduce more languages into multilingual training for zero-shot translation.   %Multilingual neural machine translation  has recently been investigated from different aspects  and in different settings . This paper concerns on a deep understanding of multilingual NMT and conducts a comprehensive study on a multilingual dataset with more than 50 languages. Our results show that  with enough model capacity, both rich-resource and low-resource languages benefit from multilingual training, while low-resource language benefits more than rich-resource one and training with similar languages benefits more than dissimilar languages;  fine-tuning performs better than training low- and rich-resource languages together from scratch in the one-to-many setting  while training from scratch performs better in the many-to-one setting;  the lower layers of the encoder and higher layers of the decoder capture more about the language specific features, and just fine-tuning these parts can achieve good accuracy for low-resource translation;  direct translation is better than pivot translation when the source language is similar to the target language , even when the direct training data is much smaller;  language diversity is important to zero-shot translation.   %Multilingual neural machine translation , which handles multiple languages together, has attracted a lot of attention recently due to its simplification of the offline training process, reducing online maintenance cost, enhancing low resource translation and enabling zero-shot translation. There are a variety of works on multilingual NMT, including model design, transfer learning, low-resource, and zero-shot learning. However, there are still many research questions to investigate, from which kind of languages should be trained together to how to enable zero-shot translation. In this paper, we conduct a comprehensive study on multilingual NMT, trying to answer these questions, and thus helping us better understand the problem in multilingual NMT. Specifically, we conduct an experimental analysis of a multilingual dataset with more than 50 languages, which covers varieties of multilingual settings. We get several interesting findings that include language and model component sharing, multilingual training and fine-tuning, pivot and direct translation, and zero-shot translation. Several future research works on multilingual NMT are further pointed out. Our study in this work can give helpful suggestions and inspire other researchers to conduct more valuable works for multilingual NMT.  
 Automated multi-document extractive text summarization is a widely studied research problem in the field of natural language understanding. Such extractive mechanisms compute in some form the worthiness of a sentence to be included into the summary. While the conventional approaches rely on human crafted document-independent features to generate a summary, we develop a data-driven novel summary system called HNet, which exploits the various semantic and compositional aspects latent in a sentence to capture document independent features. The network learns sentence representation in a way that, salient sentences are closer in the vector space than non-salient sentences. This semantic and compositional feature vector is then concatenated with the document-dependent features for sentence ranking. Experiments on the DUC benchmark datasets  indicate that our model shows significant performance gain of around 1.5-2 points in terms of ROUGE score compared with the state-of-the-art baselines.  
 State-of-the-art Transformer-based neural machine translation  systems still follow a standard encoder-decoder framework, in which source sentence representation can be well done by an encoder with self-attention mechanism. Though Transformer-based encoder may effectively capture general information in its resulting source sentence representation, the backbone information, which stands for the gist of a sentence, is not specifically focused on. In this paper, we propose an explicit sentence compression method to enhance the source sentence representation for NMT. In practice, an explicit sentence compression goal used to learn the backbone information in a sentence. We propose three ways, including backbone source-side fusion, target-side fusion, and both-side fusion, to integrate the compressed sentence into NMT. Our empirical tests on the WMT English-to-French and English-to-German translation tasks show that the proposed sentence compression method significantly improves the translation performances over strong baselines. 
   This paper\footnote{Generated audio samples are available online\url{https://lukewys.github.io/files/ISMIR2019-audio-sample.html}.} presents a method that generates expressive singing voice of Peking opera. The synthesis of expressive opera singing usually requires pitch contours to be extracted as the training data, which relies on techniques and is not able to be manually labeled. With the Duration Informed Attention Network , this paper makes use of musical note instead of pitch contours for expressive opera singing synthesis. The proposed method enables human annotation being combined with automatic extracted features to be used as training data thus the proposed method gives extra flexibility in data collection for Peking opera singing synthesis. Comparing with the expressive singing voice of Peking opera synthesised by pitch contour based system, the proposed musical note based system produces comparable singing voice in Peking opera with expressiveness in various aspects. 
 This document is a model and instructions for \LaTeX. This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes,  or Math in Paper Title or Abstract. 
 To transcribe spoken language to written medium, most alphabets enable an unambiguous sound-to-letter rule. However, some writing systems have distanced themselves from this simple concept and little work exists on measuring such distance. In this study, we use an \gls{ann} model to evaluate the transparency between written words and their pronunciation, hence its name \gls{oteann}. Based on datasets derived from Wikimedia dictionaries, we trained and tested this model to score the percentage of correct  predictions in phoneme-to-grapheme and grapheme-to-phoneme translation tasks. The scores obtained on 17 orthographies were in line with the estimations of other studies. Interestingly, the model also provided insight into typical mistakes made by learners who only consider the phonemic rule in reading and writing. 
 Learning the underlying patterns in data goes beyond instance-based generalization to external knowledge represented in structured graphs or networks. Deep learning that primarily constitutes neural computing stream in AI has shown significant advances in probabilistically learning latent patterns using a multi-layered network of computational nodes .  Structured knowledge that underlies symbolic computing approaches and often supports reasoning, has also seen significant growth in recent years, in the form of broad-based  and domain, industry or application specific knowledge graphs. A common substrate with careful integration of the two will raise opportunities to develop neuro-symbolic learning approaches for AI, where conceptual and probabilistic representations are combined. As the incorporation of external knowledge will aid in supervising the learning of features for the model, deep infusion of representational knowledge from knowledge graphs within hidden layers will further enhance the learning process. Although much work remains, we believe that knowledge graphs will play an increasing role in developing hybrid neuro-symbolic intelligent systems  as well as in building explainable AI systems for which knowledge graphs will provide scaffolding for punctuating neural computing. In this position paper, we describe our motivation for such a neuro-symbolic approach and framework that combines knowledge graph and neural networks.   
  For sales and marketing organizations within large enterprises, identifying and understanding new markets, customers and partners is a key challenge. Intel閳ユ獨 Sales and Marketing Group  faces similar challenges while growing in new markets and domains and evolving its existing business. In today's complex technological and commercial landscape, there is need for intelligent automation supporting a fine-grained understanding of businesses in order to help SMG sift through millions of companies across many geographies and languages and identify relevant directions.   We present a system developed in our company that mines millions of public business web pages, and extracts a faceted customer representation. We focus on two key customer aspects that are essential for finding relevant opportunities: industry segments  and functional roles .   To address the challenge of labeled data collection, we enrich our data with external information gleaned from Wikipedia, and develop a semi-supervised multi-label, multi-lingual deep learning model that parses customer website texts and classifies them into their respective facets. Our system scans and indexes companies as part of a large-scale knowledge graph that currently holds tens of millions of connected entities with thousands being fetched, enriched and connected to the graph by the hour in real time, and also supports knowledge and insight discovery. In experiments conducted in our company, we are able to significantly boost the performance of sales personnel in the task of discovering new customers and commercial partnership opportunities. 
  The usage of neural network models puts multiple objectives in conflict with each other: Ideally we would like to create a neural model that is effective, efficient, and interpretable at the same time. However, in most instances we have to choose which property is most important to us. We used the opportunity of the TREC 2019 Deep Learning track to evaluate the effectiveness of a balanced neural re-ranking approach. We submitted results of the TK  model: a neural re-ranking model for ad-hoc search using an efficient contextualization mechanism. TK employs a very small number of lightweight Transformer layers to contextualize query and document word embeddings. To score individual term interactions, we use a document-length enhanced kernel-pooling, which enables users to gain insight into the model.   Our best result for the passage ranking task is: 0.420 MAP, 0.671 nDCG, 0.598 P@10 . Our best result for the document ranking task is: 0.271 MAP, 0.465 nDCG, 0.730 P@10 .  
 In this paper, we reproduce the experiments of \newcite{artetxe-etal-2018-robust
 Singing voice conversion is to convert a singer's voice to another one's voice without changing singing content. Recent work shows that unsupervised singing voice conversion can be achieved with an autoencoder-based approach . However, the converted singing voice can be easily out of key, showing that the existing approach cannot model the pitch information precisely. In this paper, we propose to advance the existing unsupervised singing voice conversion method proposed in  to achieve more accurate pitch translation and flexible pitch manipulation. Specifically, the proposed PitchNet added an adversarially trained pitch regression network to enforce the encoder network to learn pitch invariant phoneme representation, and a separate module to feed pitch extracted from the source audio to the decoder network.  % At the inference stage of voice conversion, the extracted pitch from source audio can be easily modified to generate singing of different pitch levels.      % % We extract pitch information additionally and inject it into the decoder network while a pitch regression network is employed to force the encoder to separate pitch information out of the latent space of the autoencoder.  Our evaluation shows that the proposed method can greatly improve the quality of the converted singing voice . We also demonstrate that the pitch of converted singing can be easily controlled during generation by changing the levels of the extracted pitch before passing it to the decoder network. 
 We propose a scalable Bayesian preference learning method  for jointly predicting the preferences of individuals as well as the consensus of a crowd  from pairwise labels. Peoples' opinions often differ greatly, making it difficult to predict their preferences from small amounts of personal data. Individual biases also make it harder to infer the consensus of a crowd when there are few labels per item. %In applications such as recommendation it is also necessary to predict the preferences of individual annotators or users.  %and identify common preferences between users. % use of the latent factors  %We address these challenges by combining matrix factorization to model individual preferences with  %Gaussian processes to integrate user and item features. By taking a Bayesian approach, our model We address these challenges by combining matrix factorisation with  Gaussian processes, using a Bayesian approach to account for uncertainty arising from noisy and sparse data. Our method exploits input features, such as text embeddings and user metadata, to predict preferences for new items and users that are not in the training set. As previous solutions based on Gaussian processes do not scale to  large numbers of users, items or pairwise labels,  we propose a stochastic variational inference approach that limits computational and memory costs. Our experiments on a recommendation task show that our method is competitive with previous approaches despite our scalable inference approximation. We demonstrate the method's scalability on a natural language processing task  with thousands of users and items, and show  improvements over the state of the art on this task. %by modelling the preferences of individual members of the crowd. %We also show how to  %that robustness to %able to learn the effective number of components required to model the data and %choosing more latent components than required, %apply gradient-based optimization to length-scale hyper-parameters to improve performance. We make our software publicly available for future  work}. %We show how to make collaborative preference learning work at scale and how it can be used to learn %a target preference function from crowdsourced data or other noisy preference labels.  %The collaborative model captures the reliability of each worker or data source and models their biases and error rates.  %It uses latent factors to share information between similar workers and a target preference function. %We devise an SVI inference schema to enable the model to scale to real-world datasets. %Experiments compare results using standard variational inference, laplace approximation and SVI. %On real-world data we show the benefit of the personalised model over a GP preference learning approach  %that treats all labels as coming from the same source, %as well as established alternative methods and classifier baselines. %We show that the model is able to identify a number of latent features for the workers and for textual arguments. 
 %  in the line of In this paper we share several experiments   trying to automatically translate informal mathematics into formal mathematics. In our context informal mathematics refers to human-written mathematical sentences in the LaTeX format; and formal mathematics refers to statements in the Mizar language. We conducted our experiments against three established neural network-based machine translation models that are known to deliver competitive results on translating between natural languages. To train these models we also prepared four informal-to-formal datasets. We compare and analyze our results according to whether the model is supervised or unsupervised. In order to augment the data available for auto-formalization and improve the results, we develop a custom type-elaboration mechanism and integrate it in the supervised translation. %For the supervised model, in particular, we extend it with a data-augmentation technique using custom type-elaboration. % tool. %We believe that our exploration effort will eventually lead to a large formally verified mathematics database, and the insights gained from achieving this will also have far-reaching implications in program verification. %\todo{stats?} 
 Searching through networks of documents is an important task. A promising path to improve the performance of information retrieval systems in this context is to leverage dense node and content representations learned with embedding techniques. However, these techniques cannot learn representations for documents that are either isolated or whose content is missing. % To tackle this issue, assuming that the topology of the network and the content of the documents correlate, we propose to estimate the missing node representations from the available content representations, and conversely. Inspired by recent advances in machine translation, we detail in this paper how to learn a linear transformation from a set of aligned content and node representations. The projection matrix is efficiently calculated in terms of the singular value decomposition.   % %This approach proves relevant, as evidenced by the quality of the alignment of the node representations with the projected content representations.  The usefulness of the proposed method is highlighted by the improved ability to predict the neighborhood of nodes whose links are unobserved based on the projected content representations, and to retrieve similar documents when content is missing, based on the projected node representations. %That shows it is indeed possible to gain structural knowledge about a node, solely from its content. 
 Value alignment is a property of an intelligent agent indicating that it can only pursue goals and activities that are beneficial to humans. Traditional approaches to value alignment use imitation learning or preference learning to infer the values of humans by observing their behavior. We introduce a complementary technique in which a value-aligned prior is learned from naturally occurring stories which encode societal norms. Training data is sourced from the children's educational comic strip, \GG{}. In this work, we train multiple machine learning models to classify natural language descriptions of situations found in the comic strip as normative or non-normative by identifying if they align with the main characters' behavior. We also report the models' performance when transferring to two unrelated tasks with little to no additional training on the new task.  % Values are abstract, internal concepts of what is important, good or bad. Individuals' values are unobservable but norm adherence can give insight into an agent's values \& beliefs. Norms are socially-enforced standards and patterns of expected behavior. They can be observed through action and dialogue; techniques like inverse reinforcement learning can learn goals  from an agent's behavior. Stories provide a large quantity of parsable text embodying various human behaviors. We hypothesize that stories represent a strong prior for norm classification. We demonstration that deep reinforcement learning architectures, specifically transformers, have high transferability when classifying sequences of normative and non-normative narrative text. By fine-tuning a transformer on two decades of the Goofus \& Gallant  comic, it can identify normative behavior in an unrelated text corpora. For testing, two unrelated datasets containing short text sequences are used: Plotto plot conflicts and sentences in sci-fi visual media plot summaries. The BERT model, in particular, achieves transfer accuracy significantly higher than state-of-the-art binary classification methods. Both transformer-based models, BERT and XLNet, demonstrate SoTA performance on two transfer tasks.  
 Short text clustering has far-reaching effects on semantic analysis, showing its importance for multiple applications such as corpus summarization and information retrieval. However, it inevitably encounters the severe sparsity of short text representations, making the previous clustering approaches still far from satisfactory. In this paper, we present a novel attentive representation learning model for shot text clustering, wherein cluster-level attention is proposed to capture the correlations between text representations and cluster representations. Relying on this, the representation learning and clustering for short texts are seamlessly integrated into a unified model. To further ensure robust model training for short texts, we apply adversarial training to the unsupervised clustering setting, by injecting perturbations into the cluster representations. The model parameters and perturbations are optimized alternately through a minimax game. Extensive experiments on four real-world short text datasets demonstrate the superiority of the proposed model over several strong competitors, verifying that robust adversarial training yields substantial performance gains. 
 %Recent progress in deep neural network based source separation has advanced the state of the performance  Deep learning methods have brought substantial advancements in speech separation .  Nevertheless, it remains challenging to deploy deep-learning-based models on edge devices. Thus, identifying an effective way to compress these large models without hurting SS performance has become an important research topic. Recently, TasNet and Conv-TasNet have been proposed. They achieved state-of-the-art results on several standardized SS tasks. Moreover, their low latency natures make them definitely suitable for real-time on-device applications. In this study, we propose two parameter-sharing schemes to lower the memory consumption on TasNet and Conv-TasNet. Accordingly, we derive a novel so-called MiTAS . Our experimental results first confirmed the robustness of our MiTAS on two types of perturbations in mixed audio. We also designed a series of ablation experiments to analyze the relation between SS performance and the amount of parameters in the model. The results show that MiTAS is able to reduce the model size by a factor of four while maintaining comparable SS performance with improved stability as compared to TasNet and Conv-TasNet.  %. Comparing with STFT based systems, the latency of TasNet can be as low as 5ms [4], This suggests that MiTAS is more suitable for real-time low latency applications. % We present two parameter-sharing schemes to lower the memory consumption of TasNet and Conv Tasnet. These models achieve state-of-the-art results on separation task. Besides, its low latency nature makes it perfect for real-time on-device application.   %besides  %which is realtime model makes it perfect for on-device application.  %we test the models on two kinds of perturbations in mix audio to evaluate robustness of the models. %considerable?   
 Over the last years, a great success of deep neural networks  has been witnessed in computer vision and other fields. However, performance and power constraints make it still challenging to deploy DNNs on mobile devices due to their high computational complexity. Binary neural networks  have been demonstrated as a promising solution to achieve this goal by using bit-wise operations to replace most arithmetic operations. Currently, existing GPU-accelerated implementations of BNNs are only tailored for desktop platforms. Due to architecture differences, mere porting of such implementations to mobile devices yields suboptimal performance or is impossible in some cases. In this paper, we propose PhoneBit, a GPU-accelerated BNN inference engine for Android-based mobile devices that fully exploits the computing power of BNNs on mobile GPUs. PhoneBit provides a set of operator-level optimizations including locality-friendly data layout, bit packing with vectorization and layers integration for efficient binary convolution. We also provide a detailed implementation and parallelization optimization for PhoneBit to optimally utilize the memory bandwidth and computing power of mobile GPUs. We evaluate PhoneBit with AlexNet, YOLOv2 Tiny and VGG16 with their binary version. Our experiment results show that PhoneBit can achieve significant speedup and energy efficiency compared with state-of-the-art frameworks for mobile devices.    
 This report discusses three submissions based on the Duet architecture to the Deep Learning track at TREC 2019. For the document retrieval task, we adapt the Duet model to ingest a ``multiple field'' view of documents---we refer to the new architecture as Duet with Multiple Fields . A second submission combines the DuetMF model with other neural and traditional relevance estimators in a learning-to-rank framework and achieves improved performance over the DuetMF baseline. For the passage retrieval task, we submit a single run based on an ensemble of eight Duet models. 
 Despite the recent successes of deep neural networks, it remains challenging to achieve high precision keyword spotting task  on resource-constrained devices. In this study, we propose a novel context-aware and compact architecture for keyword spotting task. Based on residual connection and bottleneck structure, we design a compact and efficient network for KWS task. To leverage the long range dependencies and global context of the convolutional feature maps, the graph convolutional network is introduced to encode the non-local relations. By evaluated on the Google Speech Command Dataset, the proposed method achieves state-of-the-art performance and outperforms the prior works by a large margin with lower computational cost.  %The results show our small-footprint model outperforms the prior works by a large margin with small memory footprint and computation cost.   %Despite the recent successes of deep neural networks, it remains challenging to achieve high precision for the keyword spotting task  on resource constrained devices. In this paper, we propose a novel CNN-based framework for keyword spotting task. We incorporate the bottleneck structure and residual connections to build a compact and efficient network . To leverage the long range dependencies and global context of the convolutional feature maps for KWS problem, we compute a context-sensitive feature representation for each location by propagating the message with self-attention mechanism. We evaluate our method by extensive experiments on the Google Speech Command Dataset. Our best model achieves state-of-the-art performence on this task. What's more, our compact small foot-print model outperforms the prior works by a large margin even with less complexity. 
 Recent advancements in language representation models such as BERT have led to a rapid improvement in numerous natural language processing tasks. However, language models usually consist of a few hundred million trainable parameters with embedding space distributed across multiple layers, thus making them challenging to be fine-tuned for a specific task or to be transferred to a new domain. To determine whether there are task-specific neurons that can be exploited for unsupervised transfer learning, we introduce a method for selecting the most important neurons to solve a specific classification task. This algorithm is further extended to multi-source transfer learning by computing the importance of neurons for several single-source transfer learning scenarios between different subsets of data sources. Besides, a task-specific fingerprint for each data source is obtained based on the percentage of the selected neurons in each layer. We perform extensive experiments in unsupervised transfer learning for sentiment analysis, natural language inference and sentence similarity, and compare our results with the existing literature and baselines. Significantly, we found that the source and target data sources with higher degrees of similarity between their task-specific fingerprints demonstrate a better transferability property. We conclude that our method can lead to better performance using just a few hundred task-specific and interpretable neurons.  
  We study the problem of emergent communication, in which language arises because speakers and listeners must communicate information in order to solve tasks. In temporally extended reinforcement learning domains, it has proved hard to learn such communication without centralized training of agents, due in part to a difficult joint exploration problem. We introduce inductive biases for positive signalling and positive listening, which ease this problem. In a simple one-step environment, we demonstrate how these biases ease the learning problem. We also apply our methods to a more extended environment, showing that agents with these inductive biases achieve better performance, and analyse the resulting communication protocols. 
 Historical palm-leaf manuscript and early paper documents from Indian subcontinent form an important part of the world's literary and cultural heritage. Despite their importance, large-scale annotated Indic manuscript image datasets do not exist. To address this deficiency, we introduce Indiscapes, the first ever dataset with multi-regional layout annotations for historical Indic manuscripts. To address the challenge of large diversity in scripts and presence of dense, irregular layout elements , we adapt a Fully Convolutional Deep Neural Network architecture for fully automatic, instance-level spatial layout parsing of manuscript images. We demonstrate the effectiveness of proposed architecture on images from the Indiscapes dataset. For annotation flexibility and keeping the non-technical nature of domain experts in mind, we also contribute a custom, web-based GUI annotation tool and a dashboard-style analytics portal. Overall, our contributions set the stage for enabling downstream applications such as OCR and word-spotting in historical Indic manuscripts at scale.  
 Altering the content of an image with photo editing tools is a tedious task for an inexperienced user. Especially, when modifying the visual attributes of a specific object in an image without affecting other constituents such as background etc. To simplify the process of image manipulation and to provide more control to users, it is better to utilize a simpler interface like natural language. Therefore, in this paper, we address the challenge of manipulating images using natural language description. We propose the Two-sidEd Attentive conditional Generative Adversarial Network  to generate semantically manipulated images while preserving other contents such as background intact. TEA-cGAN uses fine-grained attention both in the generator and discriminator of Generative Adversarial Network  based framework at different scales. Experimental results show that TEA-cGAN which generates 128 $\times$ 128 and 256 $\times$ 256 resolution images outperforms existing methods on CUB and Oxford-102 datasets both quantitatively and qualitatively. 
 In this paper we investigate the problem of automatically naming pieces of assembly code. Where by naming we mean assigning to an assembly function a string of words that would likely be assigned by a human reverse engineer.  We formally and precisely define the framework in which our investigation takes place. That is we define the problem, we provide reasonable justifications for the choices that we made for the design of training and the tests. We performed an analysis on a large real-world corpora constituted by nearly 9 millions of functions taken from more than 22k softwares. In such framework we test baselines coming from the field of Natural Language Processing .  Interestingly, our evaluation shows promising results beating the state-of-the-art and reaching good performance. We investigate the applicability of tine-tuning . Such technique is popular and well-known in the NLP field.  Our results confirm that fine-tuning is effective even when neural networks are applied to binaries. We show that a model, pre-trained on the aforementioned corpora, when fine-tuned has higher performances on specific domains .      
 Many machine learning projects for new application areas involve teams of humans who label data for a particular purpose, from hiring crowdworkers to the paper's authors labeling the data themselves. Such a task is quite similar to  structured content analysis, which is a longstanding methodology in the social sciences and humanities, with many established best practices. In this paper, we investigate to what extent a sample of machine learning application papers in social computing --- specifically papers from ArXiv and traditional publications performing an ML classification task on Twitter data --- give specific details about whether such best practices were followed. Our team conducted multiple rounds of structured content analysis of each paper, making determinations such as: Does the paper report who the labelers were, what their qualifications were, whether they independently labeled the same items, whether inter-rater reliability metrics were disclosed, what level of training and/or instructions were given to labelers, whether compensation for crowdworkers is disclosed, and if the training data is publicly available.  We find a wide divergence in whether such practices were followed and documented. Much of machine learning research and education focuses on what is done once a ``gold standard'' of training data is available, but we discuss issues around the equally-important aspect of whether such data is reliable in the first place. 
 Neural ranking models are traditionally trained on a series of random batches, sampled uniformly from the entire training set. Curriculum learning has recently been shown to improve neural models' effectiveness by sampling batches non-uniformly, going from easy to difficult instances during training. In the context of neural Information Retrieval~ curriculum learning has not been explored yet, and so it remains unclear  how to  of training instances and   from easy to difficult instances during training. To address both challenges and determine whether curriculum learning is beneficial for neural ranking models, we need large-scale datasets and a retrieval task that allows us to conduct a wide range of experiments. For this purpose, we resort to the task of : ranking responses given the conversation history. In order to deal with challenge , we explore  to measure the difficulty of conversations based on different input spaces. To address challenge  we evaluate different , which determine the velocity in which we go from easy to difficult instances. We find that, overall, by just intelligently sorting the training data  we can improve the retrieval effectiveness by up to 2\%\footnote{The source code is available at.}.   
 We describe  the use of Non-Negative Matrix Factorization   and Latent Dirichlet Allocation  algorithms to perform topic mining and labelling applied to retail customer communications in attempt to characterize the subject of customers inquiries.    In this paper we compare both algorithms in the topic mining performance and propose methods to assign topic subject labels in an automated way. 
 In this paper we consider the problem of solving semantic tasks such as `Visual Question Answering' , where one aims to answers related to an image and `Visual Question Generation' , where one aims to generate a natural question pertaining to an image. Solutions for VQA and VQG tasks have been proposed using variants of encoder-decoder deep learning based frameworks that have shown impressive performance. Humans however often show generalization by relying on exemplar based approaches. For instance, the work by Tversky and Kahneman  suggests that humans use exemplars when making categorizations and decisions. In this work we propose incorporation of exemplar based approaches towards solving these problems. Specifically, we incorporate exemplar based approaches and show that an exemplar based module can be incorporated in almost any of the deep learning architectures proposed in literature and the addition of such a block results in improved performance for solving these tasks. Thus, just as incorporation of attention is now considered de facto useful for solving these tasks, similarly, incorporating exemplars also can be considered to improve any proposed architecture for solving this task. We provide extensive empirical analysis for the same through various architectures, ablations and state of the art comparisons.   %In this paper, we aim to answer questions based on images when provided with a dataset of question-answer pairs for a number of images during training. A number of methods have focused on solving this problem by using image-based attention. This is done by focusing on a specific part of the image while answering the question. Humans also do so when solving this problem. However, the regions that the previous systems focus on are not correlated with the regions that humans focus on. The accuracy is limited due to this drawback. In this paper, we propose to solve this problem by using an exemplar-based method. We obtain one or more supporting and opposing exemplars to obtain a differential attention region. This differential attention is closer to human attention than other image-based attention methods. It also helps in obtaining improved accuracy when answering questions. The method is evaluated on challenging benchmark datasets. We perform better than other image-based attention methods and are competitive with other states of the art methods that focus on both image and questions.    %Generating natural questions from an image is a semantic task that requires using visual and language modality to learn multimodal representations. Images can have multiple visual and language contexts that are relevant for generating questions namely places, captions, and tags. In this paper, we propose the use of exemplars for obtaining the relevant context. We obtain this by using a Multimodal Differential Network to produce natural and engaging questions. The generated questions show a remarkable similarity to the natural questions as validated by a human study. Further, we observe that the proposed approach substantially improves over state-of-the-art benchmarks on the quantitative metrics  
 We propose an algorithm that is capable of synthesizing high quality target speaker's singing voice given only their normal speech samples. The proposed algorithm first integrate speech and singing synthesis into a unified framework, and learns universal speaker embeddings that are shareable between speech and singing synthesis tasks. Specifically, the speaker embeddings learned from normal speech via the speech synthesis objective are shared with those learned from singing samples via the singing synthesis objective in the unified training framework. This makes the learned speaker embedding a transferable representation for both speaking and singing. We evaluate the proposed algorithm on singing voice conversion task where the content of original singing is covered with the timbre of another speaker's voice learned purely from their normal speech samples. Our experiments indicate that the proposed algorithm generates high-quality singing voices that sound highly similar to target speaker閳ユ獨 voice given only his or her normal speech samples. We believe that proposed algorithm will open up new opportunities for singing synthesis and conversion for broader users and applications. 
 In the task of factoid question answering over knowledge base, many questions have more than one plausible interpretation. Previous works on SimpleQuestions assume only one interpretation as the ground truth for each question, so they lack the ability to answer ambiguous questions correctly. In this paper, we present a new way to utilize the dataset that takes into account the existence of ambiguous questions. Then we introduce a simple and effective model which combines local knowledge subgraph with attention mechanism. Our experimental results show that our approach achieves outstanding performance in this task. 
 Recommender systems are designed to help mitigate information overload users experience during online shopping. Recent work explores neural language models to learn user and item representations from user reviews and combines such representations with rating information. Most existing convolutional-based neural models take pooling immediately after convolution, and loses the interaction information between latent dimension of convolutional feature vectors along the way. Moreover, these models usually take all feature vectors at higher levels as equal, and do not take into consideration that some features are more relevant to this specific user-item context. To bridge these gaps, this paper proposes a convolutional quantum-like language model with mutual-attention for rating prediction . By introducing a quantum-like density matrix layer, interactions between latent dimensions of convolutional feature vectors are well captured. With the attention weights learned from the mutual-attention layer, final representations of a user and an item absorb information from both itself and its counterparts for making rating prediction. Experiments on two large datasets show that our model outperforms multiple state-of-the-art CNN-based models. We also perform ablation test to analyze the independent effects of the two components of our model. Moreover, we conduct a case study and present visualizations of the quantum probabilistic distributions in one user and one item review document to show that the learned distributions capture meaningful information about this user and item, and can be potentially used as textual profiling of the user and item. 
 Today social media has become the primary source for news. Via social media platforms, fake news travel at unprecedented speeds, reach global audiences and put users and communities at great risk. Therefore, it is extremely important to detect fake news as early as possible. Recently, deep learning based approaches have shown improved performance in fake news detection. However, the training of such models requires a large amount of labeled data, but manual annotation is time-consuming and expensive. Moreover, due to the dynamic nature of news, annotated samples may become outdated quickly and cannot represent the news articles on newly emerged events. Therefore, how to obtain fresh and high-quality labeled samples is the major challenge in employing deep learning models for fake news detection.  In order to tackle this challenge, we propose a reinforced weakly-supervised fake news detection framework, i.e., {WeFEND}, which can leverage users' reports as weak supervision to enlarge the amount of training data for fake news detection. The proposed framework consists of three main components: the annotator, the reinforced selector and the fake news detector. The annotator can automatically assign  weak labels for unlabeled news based on users' reports. The reinforced selector using reinforcement learning techniques chooses high-quality samples from the weakly labeled data and filters out those low-quality ones that may degrade the detector's prediction performance. The fake news detector aims to identify fake news based on the news content. We tested the proposed framework on a large collection of news articles published via WeChat official accounts and associated user reports. Extensive experiments on this dataset show that the proposed {WeFEND} model achieves the best performance compared with the state-of-the-art methods. 
 % abstract Background %if any Patients increasingly turn to search engines and online content before, or in place of, talking with a health professional. Low quality health information, which is common on the internet, presents risks to the patient in the form of misinformation and a possibly poorer relationship with their physician. To address this, the DISCERN criteria  are used to evaluate the quality of online health information. However, patients are unlikely to take the time to apply these criteria to the health websites they visit.   Methods %if any We built an automated implementation of the DISCERN instrument  using machine learning models. We compared the performance of a traditional model  with that of a hierarchical encoder attention-based neural network  model using two language embeddings, BERT and BioBERT.  Results %if any The HEA BERT and BioBERT models achieved average F1-macro scores across all criteria of 0.75 and 0.74, respectively, outperforming the Random Forest model .  % Similarly, as measured by F1-micro, HEA BERT and BioBERT scored on average 0.80 and 0.81 vs. 0.76 for the Random Forest model.  Overall, the neural network based models achieved 81\% and 86\% average accuracy at 100\% and 80\% coverage, respectively, compared to 94\% manual rating accuracy. The attention mechanism implemented in the HEA architectures not only provided 'model explainability' by identifying reasonable supporting sentences for the documents fulfilling the Brief DISCERN criteria, but also boosted F1 performance by 0.05 compared to the same architecture without an attention mechanism.   Conclusions %if any Our research suggests that it is feasible to automate online health information quality assessment, which is an important step towards empowering patients to become informed partners in the healthcare process.   
 While billions of non-English speaking users rely on search engines every day, the problem of ad-hoc information retrieval is rarely studied for non-English languages.  This is primarily due to a lack of data set that are suitable to train ranking algorithms.  In this paper, we tackle the lack of data by leveraging pre-trained multilingual language models to transfer a retrieval system trained on English collections to non-English queries and documents.  Our model is evaluated in a zero-shot setting, meaning that we use them to predict relevance scores for query-document pairs in languages never seen during training.   Our results show that the proposed approach can significantly outperform unsupervised retrieval techniques for Arabic, Chinese Mandarin, and Spanish. We also show that augmenting the English training collection with some examples from the target language can sometimes improve performance.  
  We propose a novel approach to semi-supervised automatic speech recognition . We first exploit a large amount of unlabeled audio data via representation learning, where we reconstruct a temporal slice of filterbank features from past and future context frames. The resulting deep contextualized acoustic representations  are then used to train a CTC-based end-to-end ASR system using a smaller amount of labeled audio data. In our experiments, we show that  systems trained on DeCoAR consistently outperform ones trained on conventional filterbank features, giving 42\% and 19\% relative improvement over the baseline on WSJ eval92 and LibriSpeech test-clean, respectively. Our approach can drastically reduce the amount of labeled data required; unsupervised training on LibriSpeech then supervision with 100 hours of labeled data achieves performance on par with training on all 960 hours directly. Pre-trained models and code will be released online.  
 DeepMine is a speech database in Persian and English designed to build and evaluate text-dependent, text-prompted, and text-independent speaker verification, as well as Persian speech recognition systems. It contains more than 1850 speakers and 540 thousand recordings overall, more than 480 hours of speech are transcribed. It is the first public large-scale speaker verification database in Persian, the largest public text-dependent and text-prompted speaker verification database in English, and the largest public evaluation dataset for text-independent speaker verification. It has a good coverage of age, gender, and accents.  % We provide several evaluation protocols for each part of the database to allow for research on different aspects of speaker verification. We also provide the results of several experiments that can be considered as baselines: HMM-based i-vectors for text-dependent speaker verification, and HMM-based as well as state-of-the-art deep neural network based ASR. We demonstrate that the database can serve for training robust ASR models. 
   We introduce a novel sequence-to-sequence  voice conversion  model based on the Transformer architecture with text-to-speech  pretraining. Seq2seq VC models are attractive owing to their ability to convert prosody. While seq2seq models based on recurrent neural networks  and convolutional neural networks  have been successfully applied to VC, the use of the Transformer network, which has shown promising results in various speech processing tasks, has not yet been investigated. Nonetheless, their data-hungry property and the mispronunciation of converted speech make seq2seq models far from practical. To this end, we propose a simple yet effective pretraining technique to transfer knowledge from learned TTS models, which benefit from large-scale, easily accessible TTS corpora. VC models initialized with such pretrained model parameters are able to generate effective hidden representations for high-fidelity, highly intelligible converted speech. Experimental results show that such a pretraining scheme can facilitate data-efficient training and outperform an RNN-based seq2seq VC model in terms of intelligibility, naturalness, and similarity. 
 Word embedding is an essential building block for deep learning methods for natural language processing. Although word embedding has been extensively studied over the years, the problem of how to effectively embed numerals, a special subset of words, is still underexplored. Existing word embedding methods do not learn numeral embeddings well because there are an infinite number of numerals and their individual appearances in training corpora are highly scarce. In this paper, we propose two novel numeral embedding methods that can handle the out-of-vocabulary  problem for numerals. We first induce a finite set of prototype numerals using either a self-organizing map or a Gaussian mixture model. We then represent the embedding of a numeral as a weighted average of the prototype number embeddings. Numeral embeddings represented in this manner can be plugged into existing word embedding learning approaches such as skip-gram for training. We evaluated our methods and showed its effectiveness on four intrinsic and extrinsic tasks: word similarity, embedding numeracy, numeral prediction, and sequence labeling.  
  We present a novel architectural scheme to tackle the abstractive summarization problem based on the CNN/DM dataset [1]  which fuses Reinforcement Learning  with UniLM, which is a pre-trained Deep Learning Model, to solve various natural language tasks. We have tested the limits of learning fine-grained attention in Transfomers [3] to improve the summarization quality. UniLM applies attention to the entire token space in a global fashion. We propose DR.SAS which applies the Actor Critic  algorithm [2] to learn a dynamic self-attention distribution over the tokens to reduce redundancy and generate factual and coherent summaries to improve the quality of summarization.  After performing hyperparameter tuning, we achieved better ROUGE results compared to the baseline. Our model tends to be more extractive/factual yet coherent in details because of optimization over ROUGE rewards. We present detailed error analysis with examples of strengths and limitations of our model. Our codebase will be publicly available on our github   
 We present an attention-based ranking framework for learning to order sentences given a paragraph. Our framework is built on a bidirectional sentence encoder and a self-attention based transformer network to obtain an input order invariant representation of paragraphs. Moreover, it allows seamless training using a variety of ranking based loss functions, such as pointwise, pairwise, and listwise ranking. We apply our framework on two tasks: Sentence Ordering and Order Discrimination. Our framework outperforms various state-of-the-art methods on these tasks on a variety of evaluation metrics. We also show that it achieves better results when using pairwise and listwise ranking losses, rather than the pointwise ranking loss, which suggests that incorporating relative positions of two or more sentences in the loss function contributes to better learning. 
  		Nowadays, an abundance of short text is being generated that uses nonstandard writing styles influenced by regional languages. Such informal and code-switched content are under-resourced in terms of labeled datasets and language models even for popular tasks like sentiment classification. In this work, we  present a labeled dataset called MultiSenti for sentiment classification of code-switched informal short text,  explore the feasibility of adapting resources from a resource-rich language for an informal one, and  propose a deep learning-based model for sentiment classification of code-switched informal short text. We aim to achieve this without any lexical normalization, language translation, or code-switching indication. The performance of the proposed models is compared with three existing multilingual sentiment classification models. The results show that the proposed model performs better in general and adapting character-based embeddings yield equivalent performance while being computationally more efficient than training word-based domain-specific embeddings. 	
   We present a survey on multilingual neural machine translation , which has gained a lot of traction in the recent years. MNMT has been useful in improving translation quality as a result of translation knowledge transfer \REVISE{}. MNMT is more promising and interesting than its statistical machine translation counterpart because end-to-end modeling and distributed representations open new avenues for research on machine translation. Many approaches have been proposed in order to exploit multilingual parallel corpora for improving translation quality. However, the lack of a comprehensive survey makes it difficult to determine which approaches are promising and hence deserve further exploration. In this paper, we present an in-depth survey of existing literature on MNMT. We first categorize various approaches based on their central use-case and then further categorize them based on resource scenarios, underlying modeling principles, \REVISE{core-issues and challenges}. Wherever possible we address the strengths and weaknesses of several techniques by comparing them with each other. We also discuss the future directions that MNMT research might take. This paper is aimed towards both, beginners and experts in NMT. We hope this paper will serve as a starting point as well as a source of new ideas for researchers and engineers interested in MNMT. 
 Neural machine translation  has achieved impressive performance on machine translation task in recent years. However, in consideration of efficiency, a limited-size vocabulary that only contains the top-N highest frequency words are employed for model training, which leads to many rare and unknown words. It is rather difficult when translating from the low-resource and morphologically-rich agglutinative languages, which have complex morphology and large vocabulary. In this paper, we propose a morphological word segmentation method on the source-side for NMT that incorporates morphology knowledge to preserve the linguistic and semantic information in the word structure while reducing the vocabulary size at training time. It can be utilized as a preprocessing tool to segment the words in agglutinative languages for other natural language processing  tasks. Experimental results show that our morphologically motivated word segmentation method is better suitable for the NMT model, which achieves significant improvements on Turkish-English and Uyghur-Chinese machine translation tasks on account of reducing data sparseness and language complexity. 
    Speaker verification can be formulated as a representation learning task, where speaker-discriminative embeddings are extracted from utterances of variable lengths. Momentum Contrast  is a recently proposed unsupervised representation learning framework,  and has shown its effectiveness for learning good feature representation for downstream vision tasks. In this work, we apply MoCo to learn speaker embedding from speech segments. We explore MoCo for both unsupervised learning and pretraining settings. In the unsupervised scenario, embedding is learned by MoCo from audio data without using any speaker specific information. On a large scale dataset with $2,500$ speakers, MoCo can achieve EER $4.275\%$ trained unsupervisedly, and the EER can decrease further to $3.58\%$ if extra unlabelled data are used. In the pretraining scenario, encoder trained by MoCo is used to initialize the downstream supervised training. With finetuning on the MoCo trained model, the equal error rate  reduces $13.7\%$ relative   compared to a carefully tuned baseline training from scratch. Comparative study confirms the effectiveness of MoCo learning good speaker embedding. 
 	Target-oriented opinion words extraction  is a new subtask of ABSA, which aims to extract the corresponding opinion words for a given opinion target in a sentence. Recently, neural network methods have been applied to this task and achieve promising results. However, the difficulty of annotation causes the datasets of TOWE to be insufficient, which heavily limits the performance of neural models. By contrast, abundant review sentiment classification data are easily available at online review sites. These reviews contain substantial latent opinions information and semantic patterns. In this paper, we propose a novel model to transfer these opinions knowledge from resource-rich review sentiment classification datasets to low-resource task TOWE. To address the challenges in the transfer process, we design an effective transformation method to obtain latent opinions, then integrate them into TOWE. Extensive experimental results show that our model achieves better performance compared to other state-of-the-art methods and significantly outperforms the base model without transferring opinions knowledge. Further analysis validates the effectiveness of our model. 
 Large-scale knowledge graphs  are shown to become more important in current information systems. To expand the coverage of KGs, previous studies on knowledge graph completion need to collect adequate training instances for newly-added relations. In this paper, we consider a novel formulation, zero-shot learning, to free this cumbersome curation. For newly-added relations, we attempt to learn their semantic features from their text descriptions and hence recognize the facts of unseen relations with no examples being seen. For this purpose, we leverage Generative Adversarial Networks  to establish the connection between text and knowledge graph domain: The generator learns to generate the reasonable relation embeddings merely with noisy text descriptions. Under this setting, zero-shot learning is naturally converted to a traditional supervised classification task. Empirically, our method is model-agnostic that could be potentially applied to any version of KG embeddings, and consistently yields performance improvements on NELL and Wiki dataset. 
% Previous data-driven work investigating  the types and distributions of discourse relation signals, including discourse markers such as `however' or phrases such as `as a result' has focused on the relative frequencies of signal words within and outside text from each discourse relation. Such approaches do not allow us to quantify the signaling strength of individual instances of a signal on a scale , to assess the distribution of ambiguity for signals, or to identify words that hinder discourse relation identification in context . In this paper we present a data-driven approach to signal detection using a distantly supervised neural network and develop a metric, ${\Delta}_s$ , to quantify signaling strength. Ranging between -1 and 1 and relying on recent advances in contextualized words embeddings, the metric represents each word's positive or negative contribution to the identifiability of a relation in specific instances in context. Based on an English corpus annotated for discourse relations using Rhetorical Structure Theory and signal type annotations anchored to specific tokens, our analysis examines the reliability of the metric, the places where it overlaps with and differs from human judgments, and the implications for identifying features that neural models may need in order to perform better on automatic discourse relation classification.  %Older version: Previous research has studied the types and distributions of linguistic means used to signal coherence relations such as `cause' or `contrast' in frameworks such as Rhetorical Structure Theory  or the Penn Discourse Treebank . While signaling devices have been studied in both of these frameworks, PDTB has been primarily focused on explicit signals, especially discourse markers  such as connectives, and flat discourse structures  while work on unrestricted signaling devices in hierarchical RST trees has largely sidestepped recognizing the locus of non-DM signaling devices focusing instead on the distribution of signal types . In this paper, we develop and evaluate an annotation scheme for unrestricted discourse signals anchored to tokens in text, and evaluate a distantly supervised neural network architecture for the detection and ranking of such anchored signals, within the framework of RST. Our work develops a taxonomy of signal anchor configurations in text, a computational metric for signal strength based on permutation importance, and a concept of negative signals or `distractors'. We show that machine learning models overlap with human annotator intuitions and extend our understanding of discourse relation cues in an open-ended framework, while also revealing weaknesses in current neural representations for discourse processing. 
 %% Text of abstract In recent years, deep learning has achieved great success in many natural language processing tasks including named entity recognition. The shortcoming is that a large amount of manually-annotated data is usually required. Previous studies have demonstrated that active learning could elaborately reduce the cost of data annotation, but there is still plenty of room for improvement. In real applications we found existing uncertainty-based active learning strategies have two shortcomings. Firstly, these strategies prefer to choose long sequence explicitly or implicitly, which increase the annotation burden of annotators. Secondly, some strategies need to invade the model and modify to generate some additional information for sample selection, which will increase the workload of the developer and increase the training/prediction time of the model. In this paper, we first examine traditional active learning strategies in a specific case of BiLstm-CRF that has widely used in named entity recognition on several typical datasets. Then we propose an uncertainty-based active learning strategy called Lowest Token Probability  which combines the input and output of CRF to select informative instance. LTP is simple and powerful strategy that does not favor long sequences and does not need to invade the model. We test LTP on multiple datasets, and the experiments show that LTP performs slightly better than traditional strategies with obviously less annotation tokens on both sentence-level accuracy and entity-level F1-score. 
  Learners that are exposed to the same training data might generalize differently due to differing inductive biases.  In neural network models, inductive biases could in theory arise from any aspect of the model architecture.  We investigate which architectural factors   affect the generalization behavior of neural sequence-to-sequence models trained on two syntactic tasks, English question formation and English tense reinflection.   For both tasks, the training set is consistent with a generalization based on hierarchical structure and a generalization based on linear order.  All architectural factors that we investigated qualitatively affected how models generalized, including factors with no clear connection to hierarchical structure. For example, LSTMs and GRUs displayed qualitatively different inductive biases. However, the only factor that consistently contributed a hierarchical bias across tasks was the use of a tree-structured model rather than a model with sequential recurrence, suggesting that human-like syntactic generalization requires architectural syntactic structure.  
 Language modeling tasks, in which words, or word-pieces, are predicted on the basis of a local context, have been very effective for learning word embeddings and context dependent representations of phrases. Motivated by the observation that efforts to code world knowledge into machine readable knowledge bases or human readable encyclopedias tend to be entity-centric, we investigate the use of a fill-in-the-blank task to learn context independent representations of entities from the text contexts in which those entities were mentioned. We show that large scale training of neural models allows us to learn high quality entity representations, and we demonstrate successful results on four domains:  existing entity-level typing benchmarks, including a 64\% error reduction over previous work on TypeNet ;  a novel few-shot category reconstruction task;  existing entity linking benchmarks, where we match the state-of-the-art on CoNLL-Aida without linking-specific features and obtain a score of 89.8\% on TAC-KBP 2010 without using any alias table, external knowledge base or in domain training data and  answering trivia questions, which uniquely identify entities. Our global entity representations encode fine-grained type categories, such as , and can answer trivia questions such as  
 While neural network-based models have achieved impressive performance on a large body of NLP tasks, the generalization behavior of different models remains poorly understood: Does this excellent performance imply a perfect generalization model, or are there still some limitations? In this paper, we take the NER task as a testbed to analyze the generalization behavior of existing models from different perspectives and characterize the differences of their generalization abilities through the lens of our proposed measures, which guides us to better design models and training methods. Experiments with in-depth analyses diagnose the bottleneck of existing neural NER models in terms of breakdown performance analysis, annotation errors, dataset bias, and category relationships, which suggest directions for improvement. We have released the datasets:  for the future research at our project page: \url{http://pfliu.com/InterpretNER/}. \footnote{As a by-product of this paper, we have open-sourced a project that involves a comprehensive summary of recent NER papers and classifies them into different research topics: \url{https://github.com/pfliu-nlp/Named-Entity-Recognition-NER-Papers}.}. 
 In this paper, we explore the robustness of the Multi-Task Deep Neural Networks  against non-targeted adversarial attacks across Natural Language Understanding  tasks as well as some possible ways to defend against them. Liu et al., have shown that the Multi-Task Deep Neural Network , due to the regularization effect produced when training as a result of it's cross task data, is more robust than a vanilla BERT model trained only on one task . We further show that although the MT-DNN has generalized better, making it easily transferable across domains and tasks, it can still be compromised as after only 2 attacks  the accuracy drops by 42.05\% and 32.24\% for the SNLI and SciTail tasks. Finally, we propose a domain agnostic defense which restores the model's accuracy  as opposed to a general-purpose defense or an off-the-shelf spell checker. 
 Widespread adoption of electronic health records  has fueled the development of using machine learning to build prediction models for various clinical outcomes. This process is often constrained by having a relatively small number of patient records for training the model. We demonstrate that using patient representation schemes inspired from techniques in natural language processing can increase the accuracy of clinical prediction models by transferring information learned from the entire patient population to the task of training a specific model, where only a subset of the population is relevant. Such patient representation schemes enable a 3.5\% mean improvement in AUROC on five prediction tasks compared to standard baselines, with the average improvement rising to 19\% when only a small number of patient records are available for training the clinical prediction model. 
  Language models are generally employed to estimate the probability distribution of various linguistic units, making them one of the fundamental parts of natural language processing. Applications of language models include a wide spectrum of tasks such as text summarization, translation and classification. For a low resource language like Bengali, the research  in this area so far can be considered to be narrow at the very least, with some traditional count based models being proposed. This paper attempts to address the issue and proposes a continuous-space neural language model, or more specifically an ASGD weight-dropped LSTM language model, along with techniques to efficiently train it for Bengali Language. The performance analysis with some currently existing count based models illustrated in this paper also shows that the proposed architecture outperforms its counterparts by achieving an inference perplexity as low as 51.2 on the held out data set for Bengali.  
 Unstructured information in electronic health records provide an invaluable resource for medical research. To protect the confidentiality of patients and to conform to privacy regulations, de-identification methods automatically remove personally identifying information from these medical records. However, due to the unavailability of labeled data, most existing research is constrained to English medical text and little is known about the generalizability of de-identification methods across languages and domains. In this study, we construct a varied dataset consisting of the medical records of 1260 patients by sampling data from 9 institutes and three domains of Dutch healthcare. We test the generalizability of three de-identification methods across languages and domains. Our experiments show that an existing rule-based method specifically developed for the Dutch language fails to generalize to this new data. Furthermore, a state-of-the-art neural architecture performs strongly across languages and domains, even with limited training data. Compared to feature-based and rule-based methods the neural method requires significantly less configuration effort and domain-knowledge. We make all code and pre-trained de-identification models available to the research community, allowing practitioners to apply them to their datasets and to enable future benchmarks. 
 To predict the next most likely participant to interact in a multi-party conversation is a difficult problem. In a text-based chat group, the only information available is the sender, the content of the text and the dialogue history. In this paper we present our study on how these information can be used on the prediction task through a corpus and architecture that integrates turn-taking classifiers based on Maximum Likelihood Expectation , Convolutional Neural Networks  and Finite State Automata . The corpus is a synthetic adaptation of the Multi-Domain Wizard-of-Oz dataset  to a multiple travel service-based bots scenario with dialogue errors and was created to simulate user's interaction and evaluate the architecture. We present experimental results which show that the CNN approach achieves better performance than the baseline with an accuracy of 92.34\%, but the integrated solution with MLE, CNN and FSA achieves performance even better, with 95.65\%. 
   Neural conversation systems generate responses based on the sequence-to-sequence  paradigm.  Typically, the model is equipped with a single set of learned parameters to generate responses for given input contexts.   When confronting diverse conversations, its adaptability is rather limited and the model is hence prone to generate generic responses.  In this work, we propose an {eural {, which manages various conversations with conversation-specific parameterization.  For each conversation, the model generates parameters of the encoder-decoder by referring to the input context.  In particular, we propose two adaptive parameterization mechanisms: a context-aware and a topic-aware parameterization mechanism.  The context-aware parameterization directly generates the parameters by capturing local semantics of the given context.  The topic-aware parameterization enables parameter sharing among conversations with similar topics by first inferring the latent topics of the given context and then generating the parameters with respect to the distributional topics.  Extensive experiments conducted on a large-scale real-world conversational dataset show that our model achieves superior performance in terms of both quantitative metrics and human evaluations.  
 Named Entity Recognition  from social media posts is a challenging task. User generated content that forms the nature of social media, is noisy and contains grammatical and linguistic errors. This noisy content makes it much harder for tasks such as named entity recognition. We propose two novel deep learning approaches utilizing multimodal deep learning and Transformers. Both of our approaches use image features from short social media posts to provide better results on the NER task. On the first approach, we extract image features using InceptionV3 and use fusion to combine textual and image features. This presents more reliable name entity recognition when the images related to the entities are provided by the user. On the second approach, we use image features combined with text and feed it into a BERT like Transformer. The experimental results, namely, the precision, recall and F1 score metrics show the superiority of our work compared to other state-of-the-art NER solutions. 
 Learning suitable and well-performing dialogue behaviour in statistical spoken dialogue systems has been in the focus of research for many years. While most work which is based on reinforcement learning employs an objective measure like task success for modelling the reward signal, we use a reward based on user satisfaction estimation. We propose a novel estimator and show that it outperforms all previous estimators while learning temporal dependencies implicitly. Furthermore, we apply this novel user satisfaction estimation model live in simulated experiments where the satisfaction estimation model is trained on one domain and applied in many other domains which cover a similar task. We show that applying this model results in higher estimated satisfaction, similar task success rates and a higher robustness to noise. 
 This paper demonstrates that multilingual denoising pre-training produces significant performance gains across a wide variety of machine translation  tasks. We present mBART -- a sequence-to-sequence denoising auto-encoder pre-trained on large-scale monolingual corpora in many languages using the BART objective~.  mBART is the first method for pre-training a  complete sequence-to-sequence model by denoising  full texts in multiple languages, while previous approaches have focused only on the encoder, decoder, or reconstructing parts of the text.  %\mike{I think the previous sentence needs work} Pre-training a complete model allows it to be directly fine tuned for supervised  and unsupervised machine translation, with no task-specific modifications. We demonstrate that adding mBART initialization produces performance gains in all but the highest-resource settings, including up to 12 BLEU points for low resource MT and over 5 BLEU points for many document-level and unsupervised models. We also show it also enables new types of transfer to language pairs with no bi-text or that were not in the pre-training corpus, and present extensive analysis of which factors contribute the most to effective pre-training.  
 This short example shows a contrived example on how to format the authors' information for {. 
 Consider a natural language sentence describing a specific step in a food recipe. In such instructions, recognizing actions  and the resulting changes in the state of the ingredients  is a challenging task. One way to cope with this challenge is to explicitly model a simulator module that applies actions to entities and predicts the resulting outcome . However, such a model can be unnecessarily complex. In this paper, we propose a simplified neural network model that separates action recognition and state change prediction, while coupling the two through a novel loss function.  This allows learning to indirectly influence each other. Our model, although simpler, achieves higher state change prediction performance ) and takes fewer samples to train ). 
 % This work presents an exploration and imitation-learning-based agent capable of state-of-the-art performance in playing text-based computer games. Text-based computer games describe their world to the player through natural language and expect the player to interact with the game using text. These games are of interest as they can be seen as a testbed for language understanding, problem-solving, and language generation by artificial agents. Moreover, they provide a learning environment in which these skills can be acquired through interactions with an environment rather than using fixed corpora.  One aspect that makes these games particularly challenging for learning agents is the combinatorially large action space. Existing methods for solving text-based games are limited to games that are either very simple or have an action space restricted to a predetermined set of admissible actions. In this work, we propose to use the exploration approach of Go-Explore~ for solving text-based games. More specifically, in an initial exploration phase, we first extract trajectories with high rewards, after which we train a policy to solve the game by imitating these trajectories. Our experiments show that this approach outperforms existing solutions in solving text-based games, and it is more sample efficient in terms of the number of interactions with the environment. Moreover, we show that the learned policy can generalize better than existing solutions to unseen games without using any restriction on the action space. 
 Conversational agents such as Cortana, Alexa and Siri are continuously working on increasing their capabilities by adding new domains. The support of a new domain includes the design and development of a number of NLU components for domain classification, intents classification and slots tagging . Each component only performs well when trained on a large amount of labeled data. Second, these components are deployed on limited-memory devices which requires some model compression. Third, for some domains such as the health domain, it is hard to find a single training data set that covers all the required slot types. To overcome these mentioned problems, we present a multi-task transformer-based neural architecture for slot tagging. We consider the training of a slot tagger using multiple data sets covering different slot types as a multi-task learning problem. The experimental results on the biomedical domain have shown that the proposed approach outperforms the previous state-of-the-art systems for slot tagging on the different benchmark biomedical datasets in terms of  efficiency and effectiveness. The output slot tagger can be used by the conversational agent to better identify entities in the input utterances. 
 % In this paper,  The main contribution of this work is a We propose  max pooling loss and its application to keyword spotting systems. The proposed approach jointly trains an encoder  and a decoder  in a semi-supervised manner. The proposed new loss function allows training a model to detect parts and whole of a keyword, without strictly depending on frame-level labeling from LVCSR , making further optimization possible. The proposed system outperforms the baseline keyword spotting model in  due to increased optimizability. Further, it can be more easily adapted for on-device learning applications due to reduced dependency on LVCSR.
 A short and simple text carrying no emotion can represent some strong emotions when reading along with its context, i.e., the same sentence can express extreme anger as well as happiness depending on its context. In this paper, we propose a Contextual Affect Detection  framework which learns the inter-dependence of words in a sentence, and at the same time the inter-dependence of sentences in a dialogue. Our proposed CAD framework is based on a Gated Recurrent Unit , which is further assisted by contextual word embeddings and other diverse hand-crafted feature sets. Evaluation and analysis suggest that our model outperforms the state-of-the-art methods by 5.49\% and 9.14\% on Friends and EmotionPush dataset, respectively.    %  
 Attention-based encoder-decoder neural network models have recently shown promising results in goal-oriented dialogue systems. However, these models struggle to reason over and incorporate state-full knowledge while preserving their end-to-end text generation functionality. Since such models can greatly benefit from user intent and knowledge graph integration, in this paper we propose an RNN-based end-to-end encoder-decoder architecture which is trained with joint embeddings of the knowledge graph and the corpus as input. The model provides an additional integration of user intent along with text generation, trained with multi-task learning paradigm along with an additional regularization technique to penalize generating the wrong entity as output. The model further incorporates a Knowledge Graph entity lookup during inference to guarantee the generated output is state-full based on the local knowledge graph provided. We finally evaluated the model using the BLEU score,  empirical evaluation depicts that our proposed architecture can aid in the betterment of task-oriented dialogue system`s performance.     
 Unsupervised speech representation learning has shown remarkable success at finding representations that correlate with phonetic structures and improve downstream speech recognition performance. However, most research has been focused on evaluating the representations in terms of their ability to improve the performance of speech recognition systems on read English . This evaluation methodology overlooks two important desiderata that speech representations should have: robustness to domain shifts and transferability to other languages. In this paper we learn representations from up to 8000 hours of diverse and noisy speech data and evaluate the representations by looking at their robustness to domain shifts and their ability to improve recognition performance in many languages. We find that our representations confer significant robustness advantages to the resulting recognition systems: we see significant improvements in out-of-domain transfer relative to baseline feature sets and the features likewise provide improvements in 25 phonetically diverse languages including tonal languages and low-resource languages.    
     Most combinations of NLP tasks and language varieties lack in-domain examples for supervised training because of the paucity of annotated data. How can neural models make sample-efficient generalizations from task--language combinations with available data to low-resource ones? In this work, we propose a Bayesian generative model for the space of neural parameters. We assume that this space can be factorized into latent variables for each language and each task. We infer the posteriors over such latent variables based on data from seen task--language combinations through variational inference. This enables zero-shot classification on unseen combinations at prediction time. For instance, given training data for named entity recognition  in Vietnamese and for part-of-speech  tagging in Wolof, our model can perform accurate predictions for NER in Wolof.      In particular, we experiment with a typologically diverse sample of 33 languages from 4 continents and 11 families, and show that our model yields comparable or better results than state-of-the-art, zero-shot cross-lingual transfer methods.      Moreover, we demonstrate that approximate Bayesian model averaging results in smoother predictive distributions, whose entropy inversely correlates with accuracy. Hence, the proposed framework also offers robust estimates of prediction uncertainty.     Our code is located at \rurl{github.com/cambridgeltl/parameter-factorization}. 
The tiled convolutional neural network  has been applied only to computer vision for learning invariances. We adjust its architecture to NLP to improve the extraction of the most salient features for sentiment analysis. Knowing that the major drawback of the TCNN in the NLP field is its inflexible filter structure, we propose a novel architecture called hybrid tiled convolutional neural network  that applies a filter only on the words that appear in similar contexts and on their neighbouring words . The experiments on the IMDB movie reviews dataset demonstrate the effectiveness of the HTCNN that has a higher level of performance of more than 3\% and 1\% respectively than both the convolutional neural network  and the TCNN. These results are confirmed by the SemEval-2017 dataset where the recall of the HTCNN model exceeds by more than six percentage points the recall of its simple variant, CNN.   	
 Recent research has achieved impressive results on understanding and improving source code by building up on machine-learning techniques developed for natural languages. % A significant advancement in natural-language understanding has come with the development of pre-trained contextual embeddings, such as BERT, which can be fine-tuned for downstream tasks with less labeled data and training budget, while achieving better accuracies. % However, there is no attempt yet to obtain a high-quality contextual embedding of source code, and to evaluate it on multiple program-understanding tasks simultaneously; that is the gap that this paper aims to mitigate. % Specifically, first, we curate a massive, deduplicated corpus of 7.4M Python files from GitHub, which we use to pre-train \BERTforCode, an open-sourced code-understanding BERT model; and, second, we create an open-sourced benchmark that comprises five classification tasks and one program-repair task, akin to code-understanding tasks proposed in the literature before. % We fine-tune \BERTforCode on our benchmark tasks, and compare the resulting models to different variants of Word2Vec token embeddings, BiLSTM and Transformer models, as well as published state-of-the-art models, showing that \BERTforCode outperforms them all, even with shorter training, and with fewer labeled examples. % Future work on source-code embedding can benefit from reusing our benchmark, and from comparing against \BERTforCode models as a strong baseline. 
 We describe a method for training accurate Transformer machine-translation models to run inference using 8-bit integer  hardware matrix multipliers, as opposed to the more costly single-precision floating-point  hardware. Unlike previous work, which converted only 85 Transformer matrix multiplications to INT8,  leaving 48 out of 133 of them in FP32 because of unacceptable accuracy loss,  we convert them all to INT8 without compromising accuracy. Tested on the newstest2014 English-to-German translation task, our INT8 Transformer Base and Transformer Big models yield BLEU scores that are 99.3\% to 100\% relative to those of the corresponding FP32 models. Our approach converts all matrix-multiplication tensors from an existing FP32 model into INT8 tensors  by automatically making range-precision trade-offs during training. To demonstrate the robustness of this approach, we also include results from INT6 Transformer models. 
 To combat fake news, researchers mostly focused on detecting fake news and journalists built and maintained fact-checking sites . However, fake news dissemination has been greatly promoted via social media sites, and these fact-checking sites have not been fully utilized. To overcome these problems and complement existing methods against fake news, in this paper we propose a deep-learning based fact-checking URL recommender system to mitigate impact of fake news in social media sites such as Twitter and Facebook. In particular, our proposed framework consists of a multi-relational attentive module and a heterogeneous graph attention network to learn complex/semantic relationship between user-URL pairs, user-user pairs, and URL-URL pairs. Extensive experiments on a real-world dataset show that our proposed framework outperforms eight state-of-the-art recommendation models, achieving at least 3$\sim$5.3\% improvement. 
 Document network embedding aims at learning representations for a structured text corpus i.e. when documents are linked to each other. Recent algorithms extend network embedding approaches by incorporating the text content associated with the nodes in their formulations. In most cases, it is hard to interpret the learned representations. Moreover, little importance is given to the generalization to new documents that are not observed within the network. In this paper, we propose an interpretable and inductive document network embedding method.  % We introduce a novel mechanism, the Topic-Word Attention , that generates document representations based on the interplay between word and topic representations. We train these word and topic vectors through our general model, Inductive Document Network Embedding , by leveraging the connections in the document network. Quantitative evaluations show that our approach achieves state-of-the-art performance on various networks and we qualitatively show that our model produces meaningful and interpretable representations of the words, topics and documents.   
    The ABSTRACT is to be in fully-justified italicized text, at the top    of the left-hand column, below the author and affiliation    information. Use the word ``Abstract'' as the title, in 12-point    Times, boldface type, centered relative to the column, initially    capitalized. The abstract is to be in 10-point, single-spaced type.    Leave two blank lines after the Abstract, then begin the main text.    Look at previous CVPR abstracts to get a feel for style and length. 
 Visual-semantic embedding enables various tasks such as image-text retrieval, image captioning, and visual question answering. The key to successful visual-semantic embedding is to express visual and textual data properly by accounting for their intricate relationship. While previous studies have achieved much advance by encoding the visual and textual data into a joint space where similar concepts are closely located, they often represent data by a single vector ignoring the presence of multiple important components in an image or text. Thus, in addition to the joint embedding space, we propose a novel multi-head self-attention network to capture various components of visual and textual data by attending to important parts in data. Our approach achieves the new state-of-the-art results in image-text retrieval tasks on MS-COCO and Flicker30K datasets. Through the visualization of the attention maps that capture distinct semantic components at multiple positions in the image and the text, we demonstrate that our method achieves an effective and interpretable visual-semantic joint space. 
 Video captioning is an advanced multi-modal task which aims to describe a video clip using a natural language sentence.  The encoder-decoder framework is the most popular paradigm for this task in recent years.  However, there exist some problems in the decoder of a video captioning model.  We make a thorough investigation into the decoder and adopt three techniques to improve the performance of the model.  First of all, a combination of variational dropout and layer normalization is embedded into a recurrent unit to alleviate the problem of overfitting.  Secondly, a new online method is proposed to evaluate the performance of a model on a validation set so as to select the best checkpoint for testing.  Finally, a new training strategy called professional learning is proposed which uses the strengths of a captioning model and bypasses its weaknesses.  It is demonstrated in the experiments on Microsoft Research Video Description Corpus  and MSR-Video to Text  datasets that  our model has achieved the best results evaluated by BLEU, CIDEr, METEOR and ROUGE-L metrics  with significant gains of up to 18\% on MSVD and 3.5\% on MSR-VTT compared with the previous state-of-the-art models. 
  We present Regularized Linear Embedding , a novel method that projects a collection of linked documents  into a pretrained word embedding space. In addition to the textual content, we leverage a matrix of pairwise similarities providing complementary information . We first build a simple word vector average for each document, and we use the similarities to alter this average representation. The document representations can help to solve many information retrieval tasks, such as recommendation, classification and clustering. We demonstrate that our approach outperforms or matches existing document network embedding methods on node classification and link prediction tasks. Furthermore, we show that it helps identifying relevant keywords to describe document classes.   
 A person ontology comprising concepts, attributes and relationships of people has a number of applications in data protection, de-identification, population of knowledge graphs for business intelligence and fraud prevention. While artificial neural networks have led to improvements in Entity Recognition, Entity Classification, and Relation Extraction, creating an ontology largely remains a manual process, because it requires a fixed set of semantic relations between concepts. In this work, we present a system for automatically populating a person ontology graph from unstructured data using neural models for Entity Classification and Relation Extraction. We introduce a new dataset for these tasks and discuss our results. 
 Generating natural questions from an image is a semantic task that requires using vision and language modalities to learn multimodal representations. Images can have multiple visual and language cues such as places, captions, and tags. In this paper, we propose a principled deep Bayesian learning framework that combines these cues to produce natural questions. We observe that with the addition of more cues and by minimizing uncertainty in the among cues, the Bayesian network becomes more confident. We propose a Minimizing Uncertainty of Mixture of Cues , that minimizes uncertainty present in a mixture of  cues experts for generating  probabilistic questions. This is a Bayesian framework and the results show a remarkable similarity to natural questions as validated by a human study. We observe that with the addition of more cues and by minimizing uncertainty among the cues, the Bayesian framework becomes more confident. Ablation studies of our model indicate that a subset of cues is inferior at this task and hence the principled fusion of cues is preferred. Further, we observe that the proposed approach substantially improves over state-of-the-art benchmarks on the quantitative metrics . Here we provide project link for Deep Bayesian VQG \url{https://delta-lab-iitk.github.io/BVQG/}. 
  Interactive Fiction games are text-based simulations in which an agent interacts with the world purely through natural language. They are ideal environments for studying how to extend reinforcement learning agents to meet the challenges of natural language understanding, partial observability, and action generation in combinatorially-large text-based action spaces.  %Current reinforcement learning agents use very restricted discrete or continuous actions and are unable to scale to the combinatorially-sized natural language action space. We present KG-A2C\footnote{Code available at \url{https://github.com/rajammanabrolu/KG-A2C}}, an agent that builds a dynamic knowledge graph while exploring and generates actions using a template-based action space. We contend that the dual uses of the knowledge graph to reason about game state and to constrain natural language generation are the keys to scalable exploration of combinatorially large natural language actions. Results across a wide variety of IF games show that KG-A2C outperforms current IF agents despite the exponential increase in action space size.  
 Recent findings in neuroscience suggest that the human brain represents information in a geometric structure . In order to communicate, we flatten the complex representation of entities and their attributes into a single word or a sentence. In this paper we use graph convolutional networks to support the evolution of language and cooperation in multi-agent systems. Motivated by an image-based referential game, we propose a graph referential game with varying degrees of complexity, and we provide strong baseline models that exhibit desirable properties in terms of language emergence and cooperation. We show that the emerged communication protocol is robust, that the agents uncover the true factors of variation in the game, and that they learn to generalize beyond the samples encountered during training. 
 Natural Language Processing  and especially natural language text analysis have seen great advances in recent times. Usage of deep learning in text processing has revolutionized the techniques for text processing and achieved remarkable results. Different deep learning architectures like CNN, LSTM, and very recent Transformer have been used to achieve state of the art results variety on NLP tasks. In this work, we survey a host of deep learning architectures for text classification tasks. The work is specifically concerned with the classification of Hindi text. The research in the classification of morphologically rich and low resource Hindi language written in Devanagari script has been limited due to the absence of large labeled corpus. In this work, we used translated versions of English data-sets to evaluate models based on CNN, LSTM and Attention. Multilingual pre-trained sentence embeddings based on BERT and LASER are also compared to evaluate their effectiveness for the Hindi language. The paper also serves as a tutorial for popular text classification techniques.   
 Visual Question Answering  concerns providing answers to Natural Language questions about images. Several deep neural network approaches have been proposed to model the task in an end-to-end fashion. Whereas the task is grounded in visual processing, if the question focuses on events described by verbs, the language understanding component becomes crucial. Our hypothesis is that models should be aware of verb semantics, as expressed via semantic role labels, argument types, and/or frame elements. Unfortunately, no VQA dataset exists that includes verb semantic information. Our first contribution is a new VQA dataset  that we built by taking advantage of the imSitu annotations. The imSitu dataset consists of images manually labeled with semantic frame elements, mostly taken from FrameNet. Second, we propose a multitask CNN-LSTM VQA model that learns to classify the answers as well as the semantic frame elements. Our experiments show that semantic frame element classification helps the VQA system avoid inconsistent responses and improves performance. 
 Teacher-student  has shown to be effective for domain adaptation of deep neural network acoustic models in hybrid speech recognition systems. In this work, we extend the T/S learning to large-scale unsupervised domain adaptation of an attention-based end-to-end  model through two levels of knowledge transfer: teacher's token posteriors as soft labels and one-best predictions as decoder guidance. %to improve its performance on target domain data.  %To further enhance the capability of CT/S in large-scale knowledge transfer,  To further improve T/S learning with the help of ground-truth labels, we propose  adaptive T/S  learning. Instead of conditionally choosing from either the teacher's soft token posteriors or the one-hot ground-truth label,  % conditioned on the correctness of the teacher's decision,  in AT/S, the student always learns from both the teacher and the ground truth with a pair of adaptive weights assigned to the soft and one-hot labels quantifying the confidence on each of the knowledge sources. The confidence scores are dynamically estimated at each decoder step as a function of the soft and one-hot labels. With 3400 hours parallel close-talk and far-field Microsoft Cortana data for domain adaptation, T/S and AT/S achieve 6.3\% and 10.3\% relative word error rate improvement over a strong E2E model trained with the same amount of far-field data. 
 An effective approach for voice conversion  is to disentangle linguistic content from other components in the speech signal. The effectiveness of variational autoencoder  based VC , for instance, strongly relies on this principle. In our prior work, we proposed a cross-domain VAE-VC  framework, which utilized acoustic features of different properties, to improve the performance of VAE-VC. We believed that the success came from more disentangled latent representations. In this paper, we extend the CDVAE-VC framework by incorporating the concept of adversarial learning, in order to further increase the degree of disentanglement, thereby improving the quality and similarity of converted speech. More specifically, we first investigate the effectiveness of incorporating the generative adversarial networks  with CDVAE-VC. Then, we consider the concept of domain adversarial training and add an explicit constraint to the latent representation, realized by a speaker classifier, to explicitly eliminate the speaker information that resides in the latent code. Experimental results confirm that the degree of disentanglement of the learned latent representation can be enhanced by both GANs and the speaker classifier. Meanwhile, subjective evaluation results in terms of quality and similarity scores demonstrate the effectiveness of our proposed methods. 
 Despite the growing interest in unsupervised learning, extracting meaningful knowledge from unlabelled audio remains an open challenge.  To take a step in this direction, we recently proposed a problem-agnostic speech encoder , that combines a convolutional encoder followed by multiple neural networks, called workers, tasked to solve self-supervised problems . PASE was shown to capture relevant speech information, including speaker voice-print and phonemes. This paper proposes PASE+, an improved version of PASE for robust speech recognition in noisy and reverberant environments. To this end, we employ an online speech distortion module, that contaminates the input signals with a variety of random disturbances. We then propose a revised encoder that better learns short- and long-term speech dynamics with an efficient combination of recurrent and convolutional networks. Finally, we refine the set of workers used in self-supervision to encourage better cooperation.  Results on TIMIT, DIRHA and CHiME-5 show that PASE+ significantly outperforms both the previous version of PASE as well as common acoustic features. Interestingly, PASE+ learns transferable representations suitable for highly mismatched acoustic conditions.   
  % We describe the design of a voice trigger detection system for smart speakers. In contrast to portable battery powered devices, smart speakers are always powered on and therefore the design of the trigger detectors is not severely constrained by considerations of computation and power limits. However, these detectors must operate in extremely challenging acoustic environments. We employ a two-stage cascaded architecture where a DNN-HMM system is always running and listening for the trigger phrase. If a detection is made at this stage, the candidate audio segment is further re-scored by larger, more complex models to verify that the segment contains the trigger phrase. In this study, we focus our attention on the architecture and design of these second-pass detectors. We describe in detail the data processing pipeline for training, details of the training algorithm and finally we use multi-task learning to adapt a general acoustic model to the task of recognising a specific trigger phrase using relatively small amounts of specific training data.   We describe the design of a voice trigger detection system for smart speakers. In this study, we address two major challenges. The first is that the detectors are deployed in complex acoustic environments with external noise and loud playback by the device itself. Secondly, collecting training examples for a specific keyword or trigger phrase is challenging resulting in a scarcity of trigger phrase specific training data. We describe a two-stage cascaded architecture where a low-power detector is always running and listening for the trigger phrase. If a detection is made at this stage, the candidate audio segment is re-scored by larger, more complex models to verify that the segment contains the trigger phrase. In this study, we focus our attention on the architecture and design of these second-pass detectors. We start by training a general acoustic model that produces phonetic transcriptions given a large labelled training dataset. Next, we collect a much smaller dataset of examples that are challenging for the baseline system. We then use multi-task learning to train a model to simultaneously produce accurate phonetic transcriptions on the larger dataset  discriminate between true and easily confusable examples using the smaller dataset. Our results demonstrate that the proposed model reduces errors by half compared to the baseline in a range of challenging test conditions  requiring extra parameters.    %We describe in detail the data processing pipeline for training, the training algorithm and the evaluation setup for comparing these models. We the %We then use multi-task learning to address the mismatch between the training and test objectives. Our results demonstrate that the multi-task trained models yield significant improvements over the baseline in a range of test conditions with the addition of a small amount of training data.  %Our results demonstrate that the models trained with the multi-task setup yield significant improvements over the baseline detectors  
  Automatic speech transcription and speaker recognition are usually treated as separate tasks even though they are interdependent. In this study, we investigate training a single network to perform both tasks jointly. We train the network in a supervised multi-task learning setup, where the speech transcription branch of the network is trained to minimise a phonetic connectionist temporal classification  loss while the speaker recognition branch of the network is trained to label the input sequence with the correct label for the speaker. We present a large-scale empirical study where the model is trained using several thousand hours of labelled training data for each task. We evaluate the speech transcription branch of the network on a voice trigger detection task while the speaker recognition branch is evaluated on a speaker verification task. Results demonstrate that the network is able to encode both phonetic  speaker information in its learnt representations while yielding accuracies at least as good as the baseline models for each task, with the same number of parameters as the independent models.   
 Voice-triggered smart assistants often rely on detection of a trigger-phrase before they start listening for the user request. Mitigation of false triggers is an important aspect of building a privacy-centric non-intrusive smart assistant. In this paper, we address the task of false trigger mitigation  using a novel approach based on analyzing automatic speech recognition  lattices using graph neural networks . The proposed approach uses the fact that decoding lattice of a falsely triggered audio exhibits uncertainties in terms of many alternative paths and unexpected words on the lattice arcs as compared to the lattice of a correctly triggered audio. A pure trigger-phrase detector model doesn't fully utilize the intent of the user speech whereas by using the complete decoding lattice of user audio, we can effectively mitigate speech not intended for the smart assistant. We deploy two variants of GNNs in this paper based on 1) graph convolution layers and 2) self-attention mechanism respectively. Our experiments demonstrate that GNNs are highly accurate in FTM task by mitigating $\sim$87\% of false triggers at 99\% true positive rate . Furthermore, the proposed models are fast to train and efficient in parameter requirements. 
 Domain-adapted sentiment classification refers to training on a labeled source domain to well infer document-level sentiment on an unlabeled target domain. Most existing relevant models involve a feature extractor and a sentiment classifier, where the feature extractor works towards learning domain-invariant features from both domains, and the sentiment classifier is trained only on the source domain to guide the feature extractor. As such, they lack a mechanism to use sentiment polarity lying in the target domain. To improve domain-adapted sentiment classification by learning sentiment from the target domain as well, we devise a novel deep adversarial mutual learning approach involving two groups of feature extractors, domain discriminators, sentiment classifiers, and label probers. The domain discriminators enable the feature extractors to obtain domain-invariant features. Meanwhile, the label prober in each group explores document sentiment polarity of the target domain through the sentiment prediction generated by the classifier in the peer group, and guides the learning of the feature extractor in its own group. The proposed approach achieves the mutual learning of the two groups in an end-to-end manner.  Experiments on multiple public datasets indicate our method obtains the state-of-the-art performance, validating the effectiveness of mutual learning through label probers. 
 Second language  speech is often labeled with the native, phone categories. However, in many cases, it is difficult to decide on a categorical phone that an L2 segment belongs to. These segments are regarded as non-categories. Most existing approaches for Mispronunciation Detection and Diagnosis  are only concerned with categorical errors, i.e. a phone category is inserted, deleted or substituted by another. However, non-categorical errors are not considered. To model these non-categorical errors, this work aims at exploring non-categorical patterns to extend the categorical phone set. We apply a phonetic segment classifier to generate segmental phonetic posterior-grams  to represent phone segment-level information. And then we explore the non-categories by looking for the SPPGs with more than one peak. Compared with the baseline system, this approach explores more non-categorical patterns, and also perceptual experimental results show that the explored non-categories are more accurate with increased confusion degree by 7.3\% and 7.5\% under two different measures. Finally, we preliminarily analyze the reason behind those non-categories. 
 Named entity recognition is one of the tasks of natural language processing. In view of the problem that the traditional character representation ability is weak and the neural network method is unable to capture the important sequence information. An self-attention-based bidirectional gated recurrent unit and capsule network for NER is proposed. This model generates character vectors through bidirectional encoder representation of transformers pre-trained model. BiGRU is used to capture sequence context features, and self-attention mechanism is proposed to give different focus on the information captured by hidden layer of BiGRU. Finally, we propose to use CapsNet for entity recognition. We evaluated the recognition performance of the model on two datasets. Experimental results show that the model has better performance without relying on external dictionary information. 
 Hate-speech detection on social network language has become one of the main researching fields recently due to the spreading of social networks like Facebook and Twitter. In Vietnam, the threat of offensive and harassment cause bad impacts for online user.  The VLSP - Shared task about Hate Speech Detection on social networks showed many proposed approaches for detecting whatever comment is clean or not. However, this problem still needs further researching. Consequently, we compare traditional machine learning and deep learning on a large dataset about the user's comments on social network in Vietnamese and find out what is the advantage and disadvantage of each model by comparing their accuracy on F1-score, then we pick two models in which has highest accuracy in traditional machine learning models and deep neural models respectively. Next, we compare these two models capable of predicting the right label by referencing their confusion matrices and considering the advantages and disadvantages of each model. Finally, from the comparison result, we propose our ensemble method that concentrates the abilities of traditional methods and deep learning methods. 
 News in social media such as Twitter has been generated in high volume and speed. However, very few of them are labeled  by professionals in near real time. In order to achieve timely detection of fake news in social media,  a novel framework of two-path deep semi-supervised learning is proposed where one path is for supervised learning and the other is for unsupervised learning. The supervised learning path learns on the limited amount of labeled data while the unsupervised learning path is able to learn on a huge amount of unlabeled data. Furthermore, these two paths implemented with convolutional neural networks  are  jointly optimized to complete semi-supervised learning.  In addition, we build a shared CNN to extract the low level features on both labeled data and unlabeled data to feed them into these two paths. To verify this framework, we implement a Word CNN based semi-supervised learning model and test it on two datasets, namely, LIAR and PHEME. Experimental results demonstrate that the model built on the proposed framework can recognize fake news  effectively with very few labeled data. 
   Spoken dialogue systems typically use one or several  ASR sequence for inferring the semantic meaning and tracking the state of the dialogue However, ASR graphs, such as confusion networks , provide a compact representation of a richer hypothesis space than a top-N ASR list. In this paper, we study the benefits of using confusion networks with a  neural dialogue state tracker . We encode the 2-dimensional confnet into a 1-dimensional sequence of embeddings using a confusion network encoder which can be used with any DST system. Our confnet encoder is plugged into  the  `Global-locally Self-Attentive Dialogue State Tacker'  model for DST and obtains significant improvements in both accuracy and inference time compared to using top-N ASR hypotheses. 
 We present Contextual Discourse Vectors , a distributed document representation for efficient answer retrieval from long healthcare documents. Our approach is based on structured query tuples of entities and aspects from free text and medical taxonomies. Our model leverages a dual encoder architecture with hierarchical LSTM layers and multi-task training to encode the position of clinical entities and aspects alongside the document discourse. We use our continuous representations to resolve queries with short latency using approximate nearest neighbor search on sentence level. We apply the CDV model for retrieving coherent answer passages from nine English public health resources from the Web, addressing both patients and medical professionals. Because there is no end-to-end training data available for all application scenarios, we train our model with self-supervised data from Wikipedia. We show that our generalized model significantly outperforms several state-of-the-art baselines for healthcare passage ranking and is able to adapt to heterogeneous domains without additional fine-tuning. 
 Fake news is dramatically increased in social media in recent years. This has prompted the need for effective fake news detection algorithms. Capsule neural networks have been successful in computer vision and are receiving attention for use in Natural Language Processing . This paper aims to use capsule neural networks in the fake news detection task. We use different embedding models for news items of different lengths. Static word embedding is used for short news items, whereas non-static word embeddings that allow incremental up-training and updating in the training phase are used for medium length or large news statements. Moreover, we apply different levels of n-grams for feature extraction. Our proposed architectures are evaluated on two recent well-known datasets in the field, namely  ISOT and LIAR. The results show encouraging performance, outperforming the state-of-the-art methods by  7.8\% on ISOT and  3.1\% on the validation set, and 1\% on the test set of the LIAR dataset. 
 Target-guided open-domain conversation aims to proactively and naturally guide a dialogue agent or human to achieve specific goals, topics or keywords during open-ended conversations. Existing methods mainly rely on single-turn data-driven learning and simple target-guided strategy without considering semantic or factual knowledge relations among candidate topics/keywords. This results in poor transition smoothness and low success rate. In this work, we adopt a structured approach that controls the intended content of system responses by introducing coarse-grained keywords, attains smooth conversation transition through turn-level supervised learning and knowledge relations between candidate keywords, and drives an conversation towards an specified target with discourse-level guiding strategy. Specially, we propose a novel dynamic knowledge routing network  which considers semantic knowledge relations among candidate keywords for accurate next topic prediction of next discourse. With the help of more accurate keyword prediction, our keyword-augmented response retrieval module can achieve better retrieval performance and more meaningful conversations. Besides, we also propose a novel dual discourse-level target-guided strategy to guide conversations to reach their goals smoothly with higher success rate. Furthermore, to push the research boundary of target-guided open-domain conversation to match real-world scenarios better, we introduce a new large-scale Chinese target-guided open-domain conversation dataset  crawled from Sina Weibo. Quantitative and human evaluations show our method can produce meaningful and effective target-guided conversations, significantly improving over other state-of-the-art methods by more than 20\% in success rate and more than 0.6 in average smoothness score. 
 % %, a language evolution procedure }\mattcomment{maybe directly cite the work ?} The principle of compositionality, which enables natural language to represent complex concepts via a structured combination of simpler ones, allows us to convey an open-ended set of messages using a limited vocabulary. If compositionality is indeed a natural property of language, we may expect it to appear in communication protocols that are created by neural agents in language games. In this paper, we propose an effective neural iterated learning  algorithm that, when applied to interacting neural agents, facilitates the emergence of a more structured type of language. Indeed, these languages provide learning speed advantages to neural agents during training, which can be incrementally amplified via NIL. We provide a probabilistic model of NIL and an explanation of why the advantage of compositional language exist. Our experiments confirm our analysis, and also demonstrate that the emerged languages largely improve the generalizing power of the neural agent communication. 
 Are nearby places  described by related words? % In this article we transfer this research question in the field of lexical encoding of geographic information onto the level of intertextuality. % To this end, we explore Volunteered Geographic Information  to model texts addressing places at the level of cities or regions with the help of so-called topic networks. % This is done to examine how language encodes and networks geographic information on the aboutness level of texts. % Our hypothesis is that the networked thematizations of places are similar -- regardless of their distances and the underlying communities of authors. % To investigate this we introduce Multiplex Topic Networks , which we automatically derive from Linguistic Multilayer Networks  as a novel model, especially of thematic networking in text corpora. % Our study shows a Zipfian organization of the thematic universe in which geographical places  are located in online communication. % We interpret this finding in the context of cognitive maps, a notion which we extend by so-called thematic maps. % According to our interpretation of this finding, the organization of thematic maps as part of cognitive maps results from a tendency of authors to generate shareable content that ensures the continued existence of the underlying media. % We test our hypothesis by example of special wikis and extracts of Wikipedia. % In this way we come to the conclusion: % Places, whether close to each other or not, are located in neighboring places that span similar subnetworks in the topic universe. % \\ Keywords: Volunteered Geographic Information, Cognitive Maps, Multiplex Topic Networks, Linguistic Multilayer Networks 
 A key property of linguistic conventions is that they hold over an entire community of speakers, allowing us to communicate efficiently even with people we have never met before. At the same time, much of our language use is partner-specific: we know that words may be understood differently by different people based on our shared history. This poses a challenge for accounts of convention formation. Exactly how do agents make the inferential leap to community-wide expectations while maintaining partner-specific knowledge? We propose a hierarchical Bayesian model to explain how speakers and listeners solve this inductive problem. To evaluate our model's predictions, we conducted an experiment where participants played an extended natural-language communication game with different partners in a small community. We examine several measures of generalization and find key signatures of both partner-specificity and community convergence that distinguish our model from alternatives. These results suggest that partner-specificity is not only compatible with the formation of community-wide conventions, but may facilitate it when coupled with a powerful inductive mechanism.  Keywords: learning; communication; coordination 
 The increasing computational and memory complexities of deep neural networks have made it difficult to deploy them on low-resource electronic devices . Practitioners have developed numerous model compression methods to address these concerns, but few have condensed input representations themselves. In this work, we propose a fast, accurate, and lightweight convolutional representation that can be swapped into any neural model and compressed significantly  with a negligible reduction in performance. In addition, we show gains over recurrent representations when considering resource-centric metrics  on a Samsung Galaxy S9. 
 One of the most complex syntactic representations  used in computational linguistics and NLP are discontinuous constituent trees, crucial for representing all grammatical phenomena of languages such as German. Recent advances in dependency parsing have shown that Pointer Networks excel in efficiently  parsing syntactic relations between words in a sentence. This kind of sequence-to-sequence models achieve outstanding accuracies in building non-projective dependency trees, but its potential has not been proved yet on a more difficult task. We propose a novel neural network architecture that, by means of Pointer Networks, is able to generate the most accurate discontinuous constituent representations to date, even without the need of Part-of-Speech tagging information. To do so, we internally model discontinuous constituent structures as augmented non-projective  dependency structures. The proposed approach achieves state-of-the-art results on  the two widely-used NEGRA and TIGER benchmarks,  outperforming previous work by a wide margin. 
 With the rapid proliferation of online media sources and published news, headlines have become increasingly important for attracting readers to news articles, since users may be overwhelmed with the massive information. In this paper, we generate inspired headlines that preserve the nature of news articles and catch the eye of the reader simultaneously. The task of inspired headline generation can be viewed as a specific form of Headline Generation  task, with the emphasis on creating an attractive headline from a given news article. To generate inspired headlines, we propose a novel framework called \frameworkfull\ . \framework~exploits the extractive-abstractive architecture with 1) Popular Topic Attention  for guiding the extractor to select the attractive sentence from the article and 2) a popularity predictor for guiding the abstractor to rewrite the attractive sentence. Moreover, since the sentence selection of the extractor is not differentiable, techniques of reinforcement learning  are utilized to bridge the gap with rewards obtained from a popularity score predictor. Through quantitative and qualitative experiments, we show that the proposed \framework~significantly outperforms the state-of-the-art headline generation models in terms of attractiveness evaluated by both human  and the predictor , while the faithfulness of \framework~is also comparable to the state-of-the-art generation model. 
  has been demonstrated effective in generating persona consistent responses by utilizing predefined natural language user persona descriptions . However, the predefined user persona descriptions are usually short and limited to only a few descriptive words, which makes it hard to correlate them with the dialogues. As a result, existing methods either fail to use the persona description or use them improperly when generating persona consistent responses. To address this, we propose a neural topical expansion framework, namely , which is able to extend the predefined user persona description with semantically correlated content before utilizing them to generate dialogue responses.  consists of two main modules: persona exploration and persona exploitation. The former learns to extend the predefined user persona description by mining and correlating with existing dialogue corpus using a variational auto-encoder  based topic model. The latter learns to generate persona consistent responses by utilizing the predefined and extended user persona description. In order to make persona exploitation learn to utilize user persona description more properly, we also introduce two persona-oriented loss functions:  loss and  loss which respectively supervise persona selection in encoder and decoder. Experimental results show that our approach outperforms state-of-the-art baselines, in terms of both automatic and human evaluations.  
 The task of text classification is usually divided into two stages: {.  In this standard formalization, categories are merely represented as indexes in the label vocabulary, and  the model lacks for explicit instructions on what to classify.   Inspired by the current trend of formalizing NLP problems as question answering tasks, we propose a new framework for text classification, in which each  category    label is associated with a category description.  Descriptions are generated by hand-crafted templates or using abstractive/extractive models   from   reinforcement learning. The concatenation of the description and the text is fed to the classifier to decide whether or not the current label should be assigned to the text.   The proposed strategy forces the model to  attend to the most salient texts with respect to the label description, which can be regarded as a hard version of attention, leading to better performances.  We  observe significant performance boosts over strong baselines on a wide range of   text classification  tasks including single-label classification, multi-label classification and multi-aspect sentiment analysis.  
 Maximum Mutual information , which models the bidirectional dependency  between responses  and contexts , i.e.,  the forward probability $\log p$ and the backward probability $\log p$,  has been widely used as the  objective in the  
  We present a novel approach to efficiently learn a simultaneous translation model with coupled programmer-interpreter policies.  First, we present an algorithmic oracle to produce oracle \mre/\mwr actions for  training bilingual sentence-pairs using the notion of word alignments.  This oracle actions are designed to capture  enough information from the partial input before writing the output.  Next, we perform a coupled scheduled sampling to effectively mitigate the exposure bias when learning both policies jointly with imitation learning.  Experiments on six language-pairs show our method outperforms strong baselines in terms of translation  quality while keeping the translation delay low.  
  Data is being produced in larger quantities than ever before in human history. It's only natural to expect a rise in demand for technology that aids humans in sifting through and analyzing this inexhaustible supply of information. This need exists in the market research industry, where large amounts of consumer  research data is collected through video recordings. At present, the standard method for analyzing video data is human labor. Market researchers manually review the vast majority of consumer research video in order to identify relevant portions - highlights. The industry state of the art turnaround ratio is $ 
  Automated evaluation of open domain natural language generation  models remains a challenge and widely used metrics such as BLEU and Perplexity can be misleading in some cases. In our paper, we propose to evaluate natural language generation models by learning to compare a pair of generated sentences by fine-tuning BERT, which has been shown to have good natural language understanding ability. We also propose to evaluate the model-level quality of NLG models with sample-level comparison results with skill rating system. While able to be trained in a fully self-supervised fashion, our model can be further fine-tuned with a little amount of human preference annotation to better imitate human judgment. In addition to evaluating trained models, we propose to apply our model as a performance indicator during training for better hyperparameter tuning and early-stopping. We evaluate our approach on both story generation and chit-chat dialogue response generation. Experimental results show that our model correlates better with human preference compared with previous automated evaluation approaches. Training with the proposed metric yields better performance in human evaluation, which further demonstrates the effectiveness of the proposed model.  
 There has been a long recognition that discrete features  and neural network based features have complementary strengths for language models . Improved performance can be obtained by model interpolation, which is, however, a sub-optimal two-step integration of discrete and neural features. The trans-dimensional random field  framework has the potential advantage of being able to flexibly integrate a richer set of features. However, either discrete or neural features are used alone in previous TRF LMs. This paper develops a mixed-feature TRF LM and demonstrates its advantage in integrating discrete and neural features. Various LMs are trained over PTB and Google one-billion-word datasets, and evaluated in N-best list rescoring experiments for speech recognition. Among all single LMs , the mixed-feature TRF LMs perform the best, improving over both discrete TRF LMs and neural TRF LMs alone, and also being significantly better than LSTM LMs.  Compared to interpolating two separately trained models with discrete and neural features respectively,  the performance of mixed-feature TRF LMs matches the best interpolated model, and with simplified one-step training process and reduced training time.   
     Multi-task learning  is an effective method for learning related tasks, but designing MTL models necessitates deciding which and how many parameters should be task-specific, as opposed to shared between tasks. We investigate this issue for the problem of jointly learning named entity recognition  and relation extraction  and propose a novel neural architecture that allows for deeper task-specificity than does prior work. In particular, we introduce additional task-specific bidirectional RNN layers for both the NER and RE tasks and tune the number of shared and task-specific layers separately for different datasets. We achieve state-of-the-art  results for both tasks on the ADE dataset; on the CoNLL04 dataset, we achieve SOTA results on the NER task and competitive results on the RE task while using an order of magnitude fewer trainable parameters than the current SOTA architecture. An ablation study confirms the importance of the additional task-specific layers for achieving these results. Our work suggests that previous solutions to joint NER and RE undervalue task-specificity and demonstrates the importance of correctly balancing the number of shared and task-specific parameters for MTL approaches in general.  
 Semantic parsing is the task of obtaining machine-interpretable representations from natural language text. We consider one such formal representation - First-Order Logic  and explore the capability of neural models in parsing English sentences to FOL. We model FOL parsing as a sequence to sequence mapping task where given a natural language sentence, it is encoded into an intermediate representation using an LSTM followed by a decoder which sequentially generates the predicates in the corresponding FOL formula. We improve the standard encoder-decoder model by introducing a variable alignment mechanism that enables it to align variables across predicates in the predicted FOL. We further show the effectiveness of predicting the category of FOL entity - Unary, Binary, Variables and Scoped Entities, at each decoder step as an auxiliary task on improving the consistency of generated FOL. We perform rigorous evaluations and extensive ablations. We also aim to release our code as well as large scale FOL dataset along with models to aid further research in logic-based parsing and inference in NLP. 
     Though early successes of Statistical Machine Translation  systems are attributed in part to the explicit modelling of the interaction between any two source and target units, e.g., alignment, the recent Neural Machine Translation  systems resort to the attention which partially encodes the interaction for efficiency. In this paper, we employ  that fully accounts for each possible interaction. We sidestep the inefficiency issue by refining representations with the proposed efficient attention operation. The resulting  models offer a new Sequence-to-Sequence modelling paradigm besides the Encoder-Decoder framework and outperform the Transformer baseline in either the small scale IWSLT14 German-English, English-German and IWSLT15 Vietnamese-English or the large scale NIST12 Chinese-English translation tasks by about 1 BLEU point. We also propose a systematic model scaling approach, allowing the Reformer model to beat the state-of-the-art Transformer in IWSLT14 German-English and NIST12 Chinese-English with about 50\% fewer parameters. The code is publicly available at \url{https://github.com/lyy1994/reformer}.   
 		Neural machine translation systems require a number of stacked layers for deep models. But the prediction depends on the sentence representation of the top-most layer with no access to low-level representations. This makes it more difficult to train the model and poses a risk of information loss to prediction. In this paper, we propose a multi-layer representation fusion  approach to fusing stacked layers. In particular, we design three fusion functions to learn a better representation from the stack. Experimental results show that our approach yields improvements of 0.92 and 0.56 BLEU points over the strong Transformer baseline on IWSLT German-English and NIST Chinese-English MT tasks respectively. The result is new state-of-the-art in German-English translation. 		 	
 The recently proposed BERT~ has shown great power on a variety of natural language understanding tasks, such as text classification, reading comprehension, etc. However, how to effectively apply BERT to neural machine translation  lacks enough exploration. While BERT is more commonly used as fine-tuning instead of contextual embedding for downstream language understanding tasks, in NMT, our preliminary exploration of using BERT as contextual embedding is better than using for fine-tuning. This motivates us to think how to better leverage BERT for NMT along this direction. We propose a new algorithm named BERT-fused model, in which we first use BERT to extract representations for an input sequence, and then the representations are fused with each layer of the encoder and decoder of the NMT model through attention mechanisms. We conduct experiments on supervised , semi-supervised and unsupervised machine translation, and achieve state-of-the-art results on seven benchmark datasets. Our code is available at  \url{https://github.com/bert-nmt/bert-nmt}.  %The recently proposed BERT~ has shown great power on a variety of natural language understanding tasks, such as text classification, reading comprehension, etc. However, how to effectively apply BERT to neural machine translation  lacks enough exploration. While it was shown that BERT is better to be used as fine-tuning instead of contextual embeddings for downstream language understanding tasks, in contrast, our preliminary exploration using BERT as contextual embeddings is better than used as fine-tuning for NMT. This motivates us to think how to better leverage BERT for NMT. We propose a new algorithm named BERT-fused model, in which we first uses BERT to extract representations for a input sequence, and then the representations are fused with each layer of the encoder and decoder of the NMT model through the attention mechanism. We conduct experiments on supervised , semi-supervised and unsupervised machine translation, and achieve state-of-the-art results on seven benchmark datasets. Our code is available at Github through the anonymous link \url{https://github.com/bert-nmt/bert-nmt}.  
 In recent years, natural language processing  has got great development with deep learning techniques. In the sub-field of machine translation, a new approach named Neural Machine Translation  has emerged and got massive attention from both academia and industry. However, with a significant number of researches proposed in the past several years, there is little work in investigating the development process of this new technology trend. This literature survey traces back the origin and principal development timeline of NMT, investigates the important branches, categorizes different research orientations, and discusses some future research trends in this field. 
 One of the obstacles of abstractive summarization is the presence of various potentially correct predictions.  Widely used objective functions for supervised learning, such as cross-entropy loss, cannot handle alternative answers effectively.  Rather, they act as a training noise.  In this paper, we propose Semantic Similarity strategy that can consider semantic meanings of generated summaries while training.  Our training objective includes maximizing semantic similarity score which is calculated by an additional layer that estimates semantic similarity between generated summary and reference summary. By leveraging pre-trained language models, our model achieves a new state-of-the-art performance, ROUGE-L score of 41.5 on CNN/DM dataset.  To support automatic evaluation, we also conducted human evaluation and received higher scores relative to both baseline and reference summaries. 
 We present {\DNAME}\footnote{The complete name of our toolkit is $MT^2$-DNN , but we use MT-DNN for sake of simplicity.}, an open-source natural language understanding  toolkit that makes it easy for researchers and developers to train customized deep learning models. Built upon PyTorch and Transformers, {\DNAME} is designed to facilitate rapid customization for a broad spectrum of NLU tasks, using a variety of objectives  and text encoders .  A unique feature of {\DNAME} is its built-in support for robust and transferable learning using the adversarial multi-task learning paradigm. %with an easy-to-configure list of related tasks. To enable efficient production deployment, {\DNAME} supports multi-task knowledge distillation, which can substantially compress a deep neural model without significant performance drop. We demonstrate the effectiveness of {\DNAME} on a wide range of NLU applications across general and biomedical domains.  The software and pre-trained models will be publicly available at {https://github.com/namisan/mt-dnn}.  
 This short example shows a contrived example on how to format the authors' information for {. 
 The meaning of a natural language utterance is largely determined from its syntax and words. Additionally, there is evidence that humans process an utterance by separating knowledge about the lexicon from syntax knowledge. Theories from semantics and neuroscience claim that complete word meanings are not encoded in the representation of syntax. In this paper, we propose neural units that can enforce this constraint over an LSTM encoder and decoder. We demonstrate that our model achieves competitive performance across a variety of domains including semantic parsing, syntactic parsing, and English to Mandarin Chinese translation. In these cases, our model outperforms the standard LSTM encoder and decoder architecture on many or all of our metrics. To demonstrate that our model achieves the desired separation between the lexicon and syntax, we analyze its weights and explore its behavior when different neural modules are damaged. When damaged, we find that the model displays the knowledge distortions that aphasics are evidenced to have. \footnote{The code, trained models, tokenized data, and supplemental information about the training, can be found at: NOT INCLUDED IN DRAFT SUBMISSION}  Keywords:  natural language processing; adversarial neural networks; machine translation; aphasia; neural attention 
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % DO NOT MODIFY THIS ABSTRACT %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Playing text-based games requires skills in processing natural language and sequential decision making.  Achieving human-level performance on text-based games remains an open challenge, and prior research has largely relied on hand-crafted structured representations and heuristics. % to enable good performance. In this work, we investigate how an agent can plan and generalize in text-based games using graph-structured representations learned end-to-end from raw text. We propose a novel graph-aided transformer agent  that infers and updates latent belief graphs during planning to enable effective action selection by capturing the underlying game dynamics. \ours is trained using a combination of reinforcement and self-supervised learning. Our work demonstrates that the learned graph-based representations help agents converge to better policies than their text-only counterparts and facilitate effective generalization across game configurations. Experiments on 500+ unique games from the TextWorld suite show that our best agent outperforms text-based baselines by an average of 24.2\%. 
 			Targeted sentiment classification predicts the sentiment polarity on given target mentions in input texts. 			Dominant methods employ neural networks for encoding the input sentence and extracting relations between target mentions and their contexts. 			Recently, graph neural network has been investigated for integrating dependency syntax for the task, achieving the state-of-the-art results. 			However, existing methods do not consider dependency label information, which can be intuitively useful. 			To solve the problem, we investigate a novel relational graph attention network that integrates typed syntactic dependency information. 			Results on standard benchmarks show that our method can effectively leverage label information for improving targeted sentiment classification performances. 			Our final model significantly outperforms state-of-the-art syntax-based approaches. 		
  %Compared to sentence-level controlled text generation, such as text style transfer, document-scale text generation is of higher practical use and more challenging. In this paper, we focus on a new practical task,  document-scale text content manipulation, which is the opposite of text style transfer and aims to preserve text styles while altering the content. In detail, the input is a set of structured records and a reference text for describing another recordset.  The output is a summary that accurately describes the partial content in the source recordset with the same writing style of the reference. The task is unsupervised due to lack of parallel data, and is challenging to select suitable records and style words from bi-aspect inputs respectively and generate a high-fidelity long document. %specifying which contents are to be verbalized in the document. To tackle those problems, we first build a dataset based on a basketball game report corpus as our testbed, and present an unsupervised neural model with interactive attention mechanism, which is used for learning the semantic relationship between records and reference texts to achieve better content transfer and better style preservation. %, which is considered to imitate the human-like writing process that gradually selects the information by comparing the matching degree of bi-aspect inputs while writing the summary. In addition, we also explore the effectiveness of the back-translation in our task for constructing some pseudo-training pairs. %extend the training strategy with back-translation in order to construct some pseudo-training pairs to further improve model performance  %ensure style words are not missed when rewriting texts. %we also explore the effectiveness of the back-translation for this task. Empirical results show superiority of our approaches over competitive methods, and the models also yield a new state-of-the-art result on a sentence-level dataset. \footnote{Our code and data are available at: https://github.com/syw1996/SCIR-TG-Data2text-Bi-Aspect}  
 Audio-Visual Scene-Aware Dialog  is an extension from Video Question Answering  whereby the dialogue agent is required to generate natural language responses to address user queries and carry on conversations.  This is a challenging task as it consists of video features of multiple modalities, including text, visual, and audio features.  The agent also needs to learn semantic dependencies among user utterances and system responses to make coherent conversations with humans.  In this work, we describe our submission to the AVSD track of the 8th Dialogue System Technology Challenge.  We adopt dot-product attention to combine text and non-text features of input video.  We further enhance the generation capability of the dialogue agent by adopting pointer networks to point to tokens from multiple source sequences in each generation step.  Our systems achieve high performance in automatic metrics and obtain 5th and 6th place in human evaluation among all submissions. 
 Emotion-cause pair extraction , as an emergent natural language processing task, aims at jointly investigating emotions and their underlying causes in documents. It extends the previous emotion cause extraction  task, yet without requiring a set of pre-given emotion clauses as in ECE. Existing approaches to ECPE generally adopt a two-stage method, i.e.,  emotion and cause detection, and then  pairing the detected emotions and causes.  Such pipeline method, while intuitive, suffers from two critical issues, including error propagation across stages that may hinder the effectiveness, and high computational cost that would limit the practical application of the method. To tackle these issues, we propose a multi-task learning model that can extract emotions, causes and emotion-cause pairs simultaneously in an end-to-end manner. Specifically, our model regards pair extraction as a link prediction task, and learns to link from emotion clauses to cause clauses, i.e., the links are directional. Emotion extraction and cause extraction are incorporated into the model as auxiliary tasks, which further boost the pair extraction. Experiments are conducted on an ECPE benchmarking dataset. The results show that our proposed model outperforms a range of state-of-the-art approaches. 
   Event detection , a key subtask of information extraction, aims to recognize instances of specific event types in text. %     Previous studies on the task have verified the effectiveness of integrating syntactic dependency into graph convolutional networks. % However, these methods usually ignore dependency label information, which conveys rich and useful linguistic knowledge for ED. %  In this paper, we propose a novel architecture named Edge-Enhanced Graph Convolution Networks , which simultaneously exploits syntactic structure and typed dependency label information to perform ED. %  Specifically, an edge-aware node update module is designed to generate expressive word representations by aggregating syntactically-connected words through specific dependency types.  % % 缁楊兛绨╂稉顏勭安鐠囥儰璐熸禍鍡楄鐞涖儳顑囩粭顑跨娑擃亞娈戠紓铏瑰仯....XXX 娑撳秷顕氶弰顖氳嫙閸掓娈戦崗宕囬兇閿涘牆褰ч張澶岊儑娑撻柈銊ュ瀻娑旂喐妲窫Dge-EnhanceXXX) Furthermore, to fully explore clues hidden in dependency edges, a node-aware edge update module is introduced, which refines the relation representations with contextual information. %Furthermore, a node-aware edge update module is implemented to refine the relation representations between words with contextual information, so that clues hidden from dependency relations can be fully explored. % These two modules are complementary to each other and work in a mutual promotion way.  % We conduct experiments on the widely used ACE2005 dataset and the results show significant improvement over competitive baseline methods\footnote{Source code of this paper could be obtained from https://github.com/cuishiyao96/eegcned}. 
 Text classification is one of the most important and fundamental tasks in natural language processing.   Performance of this task mainly dependents on text representation learning. Currently, most existing learning frameworks mainly focus on encoding local contextual information between words.  These methods always neglect to exploit global clues, such as label information,  for encoding text information. In this study, we propose a label-guided learning framework {\bf LguidedLearn} for text representation and classification. Our method is novel but simple that we only insert a label-guided encoding layer into the commonly used text representation learning schemas.  That label-guided layer performs label-based attentive encoding to map the universal text embedding  into different label spaces, resulting in label-wise embeddings.  In our proposed framework, the label-guided layer can be easily and directly applied with a contextual encoding method to perform jointly learning.  Text information is encoded based on both the local contextual information and the global label clues. Therefore, the obtained text embeddings are more robust and discriminative for text classification.  Extensive experiments are conducted on benchmark datasets to illustrate the effectiveness of our proposed method. 
 We explore a keyword-based spoken language understanding system, in which the intent of the user can directly be derived from the detection of a sequence of keywords in the query. In this paper, we focus on an open-vocabulary keyword spotting method, allowing the user to define their own keywords without having to retrain the whole model. We describe the different design choices leading to a fast and small-footprint system, able to run on tiny devices, for any arbitrary set of user-defined keywords, without training data specific to those keywords. The model, based on a quantized long short-term memory~ neural network, trained with connectionist temporal classification~, weighs less than 500KB. Our approach takes advantage of some properties of the predictions of CTC-trained networks to calibrate the confidence scores and implement a fast detection algorithm. The proposed system outperforms a standard keyword-filler model approach. 
 Lexical relations describe how concepts are semantically related, in the form of relation triples. The accurate prediction of lexical relations between concepts is challenging, due to the sparsity of patterns indicating the existence of such relations. We propose the Knowledge-Enriched Meta-Learning  framework to address lexical relation classification. In KEML, the LKB-BERT  model is first presented to learn concept representations from text corpora, with rich lexical knowledge injected by distant supervision. A probabilistic distribution of auxiliary tasks is defined to increase the model's ability to recognize different types of lexical relations. We further propose a neural classifier integrated with special relation recognition cells, in order to combine meta-learning over the auxiliary task distribution and supervised learning for LRC. %combine a  process over  to train the neural lexical relation classifier. Experiments over multiple datasets show KEML outperforms state-of-the-art methods. 
  Pre-trained language models  have achieved remarkable success in varieties of NLP tasks.  However, these models usually consist of hundreds of millions of parameters which brings challenges for fine-tuning and online serving in real-life applications  due to latency and capacity constraints.  In this work, we present a simple and effective approach to compress large Transformer~ based pre-trained models, termed as deep self-attention distillation. The small model  is trained by deeply mimicking the self-attention module, which plays a vital role in Transformer networks, of the large model .  Specifically, we propose distilling the self-attention module of the last Transformer layer of the teacher, which is effective and flexible for the student.  Furthermore, we introduce the scaled dot-product between values in the self-attention module as the new deep self-attention knowledge, in addition to the attention distributions  that have been used in existing works. Moreover, we show that introducing a teacher assistant~ also helps the distillation of large pre-trained Transformer models. Experimental results demonstrate that our monolingual model\footnote{The code and models are publicly available at.} outperforms state-of-the-art baselines in different parameter size of student models.  In particular, it retains more than $99\%$ accuracy on SQuAD 2.0 and several GLUE benchmark tasks using $50\%$ of the Transformer parameters and computations of the teacher model.  % We also apply deep self-attention distillation to multilingual pre-trained models and obtain competitive results. We also obtain competitive results in applying deep self-attention distillation to multilingual pre-trained models.  
 Automatic phonemic transcription tools are useful for low-resource language documentation. However, due to the lack of training sets, only a tiny fraction of languages have phonemic transcription tools. Fortunately, multilingual acoustic modeling provides a solution given limited audio training data. A  more challenging problem is to build phonemic transcribers for languages with zero training data. The difficulty of this task is that phoneme inventories often differ between the training languages and the target language, making it infeasible to recognize unseen phonemes. In this work, we address this problem by adopting the idea of zero-shot learning. Our model is able to recognize unseen phonemes in the target language without any training data. In our model, we decompose phonemes into corresponding articulatory attributes such as vowel and consonant. Instead of predicting phonemes directly, we first predict distributions over articulatory attributes, and then compute phoneme distributions with a customized acoustic model. We evaluate our model by training it using 13 languages and testing it using 7 unseen languages. We find that it achieves 7.7\% better phoneme error rate on average over a standard multilingual model. 
 % We present neural machine translation models inspired by echo state network , in which the encoder and decoder are randomly generated and fixed throughout training. We study several variations of ESN extended to sequence-to-sequence models, and show that even though the majority of model weights are randomized and non-trainable, they can still perform reasonably well on machine translation tasks. Moreover, due to the extremely simple procedure of building such a model, only one random seed needs to be stored offline, from which 80\% \todob{confirm} of the model weights can be populated upon run-time. This offers a novel approach for sequence model compression. % 
 \label{abstract} With the development of feed-forward models, the default model for sequence modeling has gradually evolved to replace recurrent networks. Many powerful feed-forward models based on convolutional networks and attention mechanisms were proposed and show more potential to handle sequence modeling tasks. We wonder that is there an architecture that can not only achieve an approximate substitution of recurrent networks but also absorb the advantages of feed-forward models. So we propose an exploratory architecture referred to Temporal Convolutional Attention-based Network  which combines temporal convolutional network and attention mechanism. TCAN includes two parts, one is Temporal Attention  which captures relevant features inside the sequence, the other is Enhanced Residual  which extracts the shallow layer's important information and transfers to deep layers. We improve the state-of-the-art results of bpc/perplexity to 26.92 on word-level PTB, 1.043 on character-level PTB, and 6.66 on WikiText-2.  
 Unsupervised neural machine translation  has recently attracted great interest in the machine translation community. The main advantage of the UNMT lies in its easy collection of required large training text sentences while with only a slightly worse performance than supervised neural machine translation which requires expensive annotated translation pairs on some translation tasks. In most studies, the UMNT is trained with clean data without considering its robustness to the noisy data. However, in real-world scenarios, there usually exists noise in the collected input sentences which degrades the performance of the translation system since the UNMT is sensitive to the small perturbations of the input sentences. In this paper, we first time explicitly take the noisy data into consideration to improve the robustness of the UNMT based systems. First of all, we clearly defined two types of noises in training sentences, i.e., word noise and word order noise, and empirically investigate its effect in the UNMT, then we propose adversarial training methods with denoising process in the UNMT. Experimental results on several language pairs show that our proposed methods substantially improved the robustness of the conventional UNMT systems in noisy scenarios. 
 Existing neural machine translation  systems utilize sequence-to-sequence neural networks to generate target translation word by word, and then make the generated word at each time-step and the counterpart in the references as consistent as possible. However, the trained translation model tends to focus on ensuring the accuracy of the generated target word at the current time-step and does not consider its future cost which means the expected cost of generating the subsequent target translation . To respond to this issue, we propose a simple and effective method to model the future cost of each target word for NMT systems. In detail, a time-dependent future cost is estimated based on the current generated target word and its contextual information to boost the training of the NMT model. Furthermore, the learned future context representation at the current time-step is used to help the generation of the next target word in the decoding. Experimental results on three widely-used translation datasets, including the WMT14 German-to-English, WMT14 English-to-French, and WMT17 Chinese-to-English, show that the proposed approach achieves significant improvements over strong Transformer-based NMT baseline. 
 Twitter is a web application playing dual roles of online social networking and micro-blogging. The popularity and open structure of Twitter have attracted a large number of automated programs, known as bots. Legitimate bots generate a large amount of benign contextual content, i.e., tweets delivering news and updating feeds, while malicious bots spread spam or malicious contents. To assist human users in identifying who they are interacting with, this paper focuses on the classification of human and spambot accounts on Twitter, by employing recurrent neural networks, specifically bidirectional Long Short-term Memory , to efficiently capture features across tweets. To the best of our knowledge, our work is the first that develops a recurrent neural model with word embeddings to distinguish Twitter bots from human accounts, that requires no prior knowledge or assumption about users' profiles, friendship networks, or historical behavior on the target account. Moreover, our model does not require any handcrafted features. The preliminary simulation results are very encouraging. Experiments on the cresci-2017 dataset show that our approach can achieve competitive performance compared with existing state-of-the-art bot detection systems. 
  Humans reason with concepts and metaconcepts: we recognize { from visual input; we also understand that they {, we generalize to the fact that cube and sphere also { we can understand a new color purple, which resembles the hue of the cubes instead of the shape of them. Evaluation on both synthetic and real-world datasets validates our claims.  %    % 
 Despite strong performance on a variety of tasks, neural sequence models trained with maximum likelihood have been shown to exhibit issues such as length bias and degenerate repetition.  We study the related issue of receiving infinite-length sequences from a recurrent language model  when using common decoding algorithms.  To analyze this issue, we first define inconsistency of a decoding algorithm, meaning that the algorithm can yield an infinite-length sequence that has zero probability under the model. We prove that commonly used incomplete decoding algorithms -- greedy search, beam search, top-$k$ sampling, and nucleus sampling -- are inconsistent, despite the fact that recurrent language models are trained to produce sequences of finite length. Based on these insights, we propose two remedies which  address inconsistency: consistent variants of top-$k$ and nucleus sampling, and a self-terminating recurrent language model. Empirical results show that inconsistency occurs in practice, and that the proposed methods prevent inconsistency. 
 %In this paper, we use frequency aligned network for robust multi-channel automatic speech recognition  that is beneficial in challenging noisy environment.  Conventional speech enhancement technique such as beamforming has known benefits for far-field speech recognition. Our own work in frequency-domain multi-channel acoustic modeling has shown additional improvements by training a spatial filtering layer jointly within an acoustic model. In this paper, we further develop this idea and use frequency aligned network for robust multi-channel automatic speech recognition . Unlike an affine layer in the frequency domain, the proposed frequency aligned component prevents one frequency bin influencing other frequency bins. We show that this modification not only reduces the number of parameters in the model but also significantly and improves the ASR performance. We investigate effects of frequency aligned  network through ASR experiments on the real-world far-field data where users are interacting with an ASR system in uncontrolled acoustic environments. We show that our multi-channel acoustic model with a frequency aligned network shows up to 18\%  relative reduction in word error rate. 
 To date, most state-of-the-art sequence modeling architectures use attention to build generative models for language based tasks. Some of these models use all the available sequence tokens to generate an attention distribution which results in time complexity of $O$. Alternatively, they utilize depthwise convolutions with $\softmax$ normalized kernels of size $k$ acting as a limited-window self-attention, resulting in time complexity of $O$. In this paper, we introduce Time-aware Large Kernel  Convolutions, a novel adaptive convolution operation that learns to predict the size of a summation kernel instead of using a fixed-sized kernel matrix. This method yields a time complexity of $O$, effectively making the sequence encoding process linear to the number of tokens. We evaluate the proposed method on large-scale standard machine translation, abstractive summarization and language modeling datasets and show that TaLK Convolutions constitute an efficient improvement over other attention/convolution based approaches. 
  Parkinson's disease patients develop different speech impairments that affect their communication capabilities. The automatic assessment of the speech of the patients allows the development of computer aided tools to support the diagnosis and the evaluation of the disease severity.  This paper introduces a methodology to classify Parkinson's disease from speech in three different languages: Spanish, German, and Czech. The proposed approach considers convolutional neural networks trained with time frequency representations and a transfer learning strategy among the three languages.  The transfer learning scheme aims to improve the accuracy of the models when the weights of the neural network are initialized with utterances from a different language than the used for the test set. The results suggest that the proposed strategy improves the accuracy of the models in up to 8\% when the base model used to initialize the weights of the classifier is robust enough. In addition, the results obtained after the transfer learning are in most cases more balanced in terms of specificity-sensitivity than those trained without the transfer learning strategy.     
 %The explosive growth of fake news has eroded the credibility of medias and governments. Fake news detection has become an urgent task. Current fake news detection methods rely heavily on textual information by learning the style of writing of the extracted news content or the knowledge inside. However, malicious entities can disguise the writing style to bypass the language model and invalidate the simple text-based model. In fact, fake news does not exist independently in the form of an article, like news creators and news subjects relating to news articles also exist in the media. News articles along with other related components like news creators and news subjects can be modeled as a heterogeneous information network . In this paper, we focus on studying the HIN-based fake news detection problem. We propose a novel fake news detection framework, namely Hierarchical Graph Attention Network , which employs a novel hierarchical attention mechanism to perform node representation learning in the HIN and then detects fake news by classifying news article nodes. This method can effectively learn information from different types of related nodes through the node-level and schema-level attention. Experiments with two real-world fake news datasets show that our model can outperform text-based models and other network-based models. Besides, the experiments also demonstrate the expandability and generalizability of {\our} for graph representation learning and other node classification-related applications in heterogeneous graphs.  % The viral spread of fake news has caused great social harm, making fake news detection an urgent task. Current fake news detection methods rely heavily on text information by learning the extracted news content or writing style of internal knowledge. However, deliberate rumors can mask writing style, bypassing language models and invalidating simple text-based models. In fact, news articles and other related components  can be modeled as a heterogeneous information network . In this paper, we propose a novel fake news detection framework, namely Hierarchical Graph Attention Network, which uses a novel hierarchical attention mechanism to perform node representation learning in HIN, and then detects fake news by classifying news article nodes. Experiments on two real-world fake news datasets show that {\our} can outperform text-based models and other network-based models. In addition, the experiment proved the expandability and generalizability of {\ our} for graph representation learning and other node classification related applications in heterogeneous graphs. 
 Mutation testing can be used to assess the fault-detection capabilities of a given test suite. To this aim, two characteristics of mutation testing frameworks are of paramount importance:  they should generate mutants that are representative of real faults; and  they should provide a  complete tool chain able to automatically generate, inject, and test the mutants. To address the first point, we recently proposed an approach using a Recurrent Neural Network  Encoder-Decoder architecture to learn mutants from $ \url{https://sites.google.com/view/learning-mutation/deepmutation} 
   We demonstrate how a sampling-based robotic planner can be augmented to learn   to understand a sequence of natural language commands in a continuous   configuration space to move and manipulate objects.   %   Our approach combines a deep network structured according to the parse of a   complex command that includes objects, verbs, spatial relations, and   attributes, with a sampling-based planner, RRT.   %   A recurrent hierarchical deep network controls how the planner explores the   environment, determines when a planned path is likely to achieve a goal, and   estimates the confidence of each move to trade off exploitation and   exploration between the network and the planner.   %   Planners are designed to have near-optimal behavior when information about the   task is missing, while networks learn to exploit observations which are   available from the environment, making the two naturally complementary.   %   Combining the two enables generalization to new maps, new kinds of obstacles,   and more complex sentences that do not occur in the training set.   %   Little data is required to train the model despite it jointly acquiring a CNN   that extracts features from the environment as it learns the meanings of   words.   %   The model provides a level of interpretability through the use of attention   maps allowing users to see its reasoning steps despite being an end-to-end   model.   %   This end-to-end model allows robots to learn to follow natural language   commands in challenging continuous environments.   % This model provides a new capability for robots to learn to follow a wide   % range of natural language commands in a challenging continuous environment   % while generalizing to new maps and obstacles by combining planning with deep   % networks. 
 Recently we see a rising number of methods in the field of eXplainable Artificial Intelligence. To our surprise, their development is driven by model developers rather than a study of needs for human end users. The analysis of needs, if done, takes the form of an A/B test rather than a study of open questions. To answer the question ``What would a human operator like to ask the ML model?'' we propose a conversational system explaining decisions of the predictive model. In this experiment, we developed a chatbot called \verb'dr_ant' to talk about machine learning model trained to predict survival odds on Titanic. People can talk with \verb'dr_ant' about different aspects of the model to understand the rationale behind its predictions. Having collected a corpus of 1000+ dialogues, we analyse the most common types of questions that users would like to ask. To our knowledge, it is the first study which uses a conversational system to collect the needs of human operators from the interactive and iterative dialogue explorations of a predictive model.   
 % In this moment, the level of speaker recognition technology is showing impressive results. The results of the NIST SRE  competitions in recent years show that the quality of verification, achieved using approaches based on deep neural networks, is continuously growing. However, the practical applications of speaker recognition technology, which requires a fast and high-quality response of the system for short utterances in difficult noise conditions when using a distant microphone, give new challenges for developers. In this paper, we consider approaches that can improve the quality of the speaker verification system at the far-field microphone in the presence of interference and noise, and that can reduce quality of degradation for short-time utterances. The neural network architectures based on TDNN  and ResNet  blocks is applied in this work. It should be noted that the use of ResNet architectures, during processing of short-time and long-time utterance, allows significantly to improve the quality of the verification system compared to system based on x-vector approach. In this paper, we describe quality change of the verification system in relation to the use of various types of speech activity detectors, various embedding-extractors and their training procedures, adaptation and score normalization methods, and different scoring models. The verification system results for short-time and long-time utterances are presented. In our experiments, we used publicly available data and verification protocols for the VoxCeleb1, VoxCeleb2, and VOiCES datasets. We used EER  and minDCF  quality metrics in order to present our results. % 
 %v2 Most neural networks utilize the same amount of compute for every example independent of the inherent complexity of the input. Further, methods that adapt the amount of computation to the example focus on finding a fixed inference-time computational graph per example, ignoring any external computational budgets or varying inference time limitations. In this work, we utilize conditional computation to make neural sequence models  more efficient and computation-aware during inference. %v1 %Most neural networks utilize the same amount of compute for every example, independent of the inherent complexity of the input or any external computational budgets or limitations. In this work, we explore conditional computation as a tool to make neural sequence models more efficient and computation-aware during inference. We first modify the Transformer architecture, making each set of operations conditionally executable depending on the output of a learned control network. We then train this model in a multi-task setting, where each task corresponds to a particular computation budget. This allows us to train a single model that can be controlled to operate on different points of the computation-quality trade-off curve, depending on the available computation budget at inference time. We evaluate our approach on two tasks:  WMT English-French Translation and  Unsupervised representation learning . Our experiments demonstrate that the proposed Conditional Computation Transformer  is competitive with vanilla Transformers when allowed to utilize its full computational budget, while improving significantly over computationally equivalent baselines when operating on smaller computational budgets. 
 It is known that Recurrent Neural Networks  can remember, in their hidden layers, part of the semantic information expressed by a sequence  that is being processed. Different types of recurrent units have been designed to enable RNNs to remember information over longer time spans. However, the memory abilities of different recurrent units are still theoretically and empirically unclear, thus limiting the development of more effective and explainable RNNs. To tackle the problem, in this paper, we identify and analyze the internal and external factors that affect the memory ability of RNNs, and propose a Semantic Euclidean Space to represent the semantics expressed by a sequence. Based on the Semantic Euclidean Space, a series of evaluation indicators are defined to measure the memory abilities of different recurrent units and analyze their limitations. These evaluation indicators also provide a useful guidance to select suitable sequence lengths for different RNNs during training. 
 Computational models of emergent communication in agent populations are currently gaining interest in the machine learning community due to recent advances in Multi-Agent Reinforcement Learning . Current contributions are however still relatively disconnected from the earlier theoretical and computational literature aiming at understanding how language might have emerged from a prelinguistic substance. The goal of this paper is to position recent MARL contributions within the historical context of language evolution research, as well as to extract from this theoretical and computational background a few challenges for future research.  
   This paper considers the task of matching images and sentences by learning a visual-textual embedding space for cross-modal retrieval. Finding such a space is a challenging task since the features and representations of text and image are not comparable. In this work, we introduce an end-to-end deep multimodal convolutional-recurrent network for learning both vision and language representations simultaneously to infer image-text similarity. The model learns which pairs are a match  and which ones are a mismatch  using a hinge-based triplet ranking. To learn about the joint representations, we leverage our newly extracted collection of tweets from Twitter. The main characteristic of our dataset is that the images and tweets are not standardized the same as the benchmarks. Furthermore, there can be a higher semantic correlation between the pictures and tweets contrary to benchmarks in which the descriptions are well-organized. Experimental results on MS-COCO benchmark dataset show that our model outperforms certain methods presented previously and has competitive performance compared to the state-of-the-art. The code and dataset have been made available publicly. 
   Real-world data often presents itself in the form of a network.   Examples include social networks, citation networks, biological networks, and knowledge graphs.   In their simplest form, networks represent real-life entities  as nodes,   and describe them in terms of their relations with other entities by means of edges between these nodes.   This can be valuable for a range of purposes from the study of information diffusion   to bibliographic analysis, bioinformatics research, and question-answering.    The quality of networks is often problematic though, affecting downstream tasks.   This paper focuses on the common problem where a node in the network   in fact corresponds to multiple real-life entities.   In particular, we introduce ,   an algorithm based on network embedding for node disambiguation.   Given a network,  identifies nodes that correspond to multiple entities,   for subsequent splitting.   Extensive experiments on twelve benchmark datasets demonstrate that  is substantially and uniformly more accurate for ambiguous node identification compared to the existing state-of-the-art, at a comparable computational cost, while less optimal for determining the best way to split ambiguous nodes.  
 Code summarization generates brief natural language description given a source code snippet, while code retrieval fetches relevant source code given a natural language query. Since both tasks aim to model the association between natural language and programming language, recent studies have combined these two tasks to improve their performance. However, researchers have yet been able to effectively leverage the intrinsic connection between the two tasks as they train these tasks in a separate or pipeline manner, which means their performance can not be well balanced. In this paper, we propose a novel end-to-end model for the two tasks by introducing an additional code generation task. More specifically, we explicitly exploit the probabilistic correlation between code summarization and code generation with dual learning, and utilize the two encoders for code summarization and code generation to train the code retrieval task via multi-task learning. We have carried out extensive experiments on an existing dataset of SQL and Python, and results show that our model can significantly improve the results of the code retrieval task over the-state-of-art models, as well as achieve competitive performance in terms of BLEU score for the code summarization task. 
 Music that is generated by recurrent neural networks often lacks a sense of direction and coherence. We therefore propose a two-stage LSTM-based model for lead sheet generation, in which the harmonic and rhythmic templates of the song are produced first, after which, in a second stage, a sequence of melody notes is generated conditioned on these templates. A subjective listening test shows that our approach outperforms the baselines and increases perceived musical coherence.   
 Learning to navigate in a visual environment following natural-language instructions is a challenging task, because the multimodal inputs to the agent are highly variable, and the training data on a new task is often limited. We present the first pre-training and fine-tuning paradigm for vision-and-language navigation  tasks. By training on a large amount of image-text-action triplets in a self-supervised learning manner, the pre-trained model provides generic representations of visual environments and language instructions. It can be easily used as a drop-in for existing VLN frameworks, leading to the proposed agent \footnote{\fullname}. It learns more effectively in new tasks and generalizes better in a previously unseen environment. The performance is validated on three VLN tasks. On the Room-to-Room~ benchmark, our model improves the state-of-the-art from 47\% to 51\% on success rate weighted by path length. Further, the learned representation is transferable to other VLN tasks. On two recent tasks, vision-and-dialog navigation~ and ``Help, Anna!''~, the proposed  leads to significant improvement over existing methods, achieving a new state of the art. 
  	Taking full advantage of the information from both vision and language is critical for the video captioning task. Existing models lack adequate visual representation due to the neglect of interaction between object, and sufficient training for content-related words due to long-tailed problems. In this paper, we propose a complete video captioning system including both a novel model and an effective training strategy. Specifically, we propose an object relational graph  based encoder, which captures more detailed interaction features to enrich visual representation. Meanwhile, we design a teacher-recommended learning  method to make full use of the successful external language model  to integrate the abundant linguistic knowledge into the caption model. The ELM generates more semantically similar word proposals which extend the ground-truth words used for training to deal with the long-tailed problem. Experimental evaluations on three benchmarks: MSVD, MSR-VTT and VATEX show the proposed ORG-TRL system achieves state-of-the-art performance. Extensive ablation studies and visualizations illustrate the effectiveness of our system.   
Early rumor detection  on social media platform is very challenging when limited, incomplete and noisy information is available. Most of the existing methods have largely worked on event-level detection that requires the collection of posts relevant to a specific event and relied only on user-generated content. They are not suitable for detecting rumor sources in the very early stages, before an event unfolds and becomes widespread. In this paper, we address the task of ERD at the message level. We present a novel hybrid neural network architecture, which combines a task-specific character-based bidirectional language model and stacked Long Short-Term Memory  networks to represent textual contents and social-temporal contexts of input source tweets, for modelling propagation patterns of rumors in the early stages of their development. We apply multi-layered attention models to jointly learn attentive context embeddings over multiple context inputs. Our experiments employ a stringent leave-one-out cross-validation  evaluation set-up on seven publicly available real-life rumor event data sets. Our models achieve state-of-the-art performance for detecting unseen rumors on large augmented data which covers more than 12 events and 2,967 rumors. An ablation study is conducted to understand the relative contribution of each component of our proposed model.  \\ \newline \Keywords{Early Rumor Detection, Social Media, Recurrent Neural Network, Attention Mechanism, Context Modeling
 We propose a tensor-to-vector regression approach to multi-channel speech enhancement in order to address the issue of input size explosion and hidden-layer size expansion. The key idea is to cast the conventional deep neural network  based vector-to-vector regression formulation under a tensor-train network  framework.  TTN is a recently emerged solution for compact representation of deep models with fully connected hidden layers. Thus TTN maintains DNN's expressive power yet involves a much smaller amount of trainable parameters. Furthermore, TTN can handle a multi-dimensional tensor input by design, which exactly matches the desired setting in multi-channel speech enhancement.  We first provide a theoretical extension from DNN to TTN based regression. Next, we show that TTN can attain speech enhancement quality comparable with that for DNN but with much fewer parameters, e.g., a reduction from 27 million to only 5 million parameters is observed in a single-channel scenario.  TTN  also improves PESQ over DNN from 2.86 to 2.96 by slightly increasing the number of trainable parameters. Finally, in 8-channel conditions, a PESQ of 3.12 is achieved using 20 million parameters for TTN, whereas a DNN with 68 million parameters can only attain a PESQ of 3.06. Code is available online\footnote{https://github.com/uwjunqi/Tensor-Train-Neural-Network}.  
 The state-of-art approach for  speaker verification  consists of a neural network based embedding extractor along with a backend generative model such as the Probabilistic Linear Discriminant Analysis .  In this work, we propose a neural network approach  for backend modeling in speaker recognition. The likelihood ratio score of the generative PLDA model is posed as a discriminative similarity function and the learnable parameters of the score function are optimized using a verification cost. The proposed model, termed as neural PLDA , is initialized using the generative PLDA model parameters. The loss function for the NPLDA model is an approximation of the minimum detection cost function . The speaker recognition experiments using the NPLDA model are performed on the speaker verificiation task in the VOiCES datasets as well as the SITW challenge dataset. In these experiments, the NPLDA model optimized using the proposed loss function improves significantly over the state-of-art PLDA based speaker verification system. 
 Neural networks using numerous text data have been successfully applied to a variety of tasks. While massive text data is usually compressed using techniques such as grammar compression, almost all of the previous machine learning methods assume already decompressed sequence data as their input. In this paper, we propose a method to directly apply neural sequence models to text data compressed with grammar compression algorithms without decompression. To encode the unique symbols that appear in compression rules, we introduce composer modules to incrementally encode the symbols into vector representations. Through experiments on real datasets, we empirically showed that the proposal model can achieve both memory and computational efficiency while maintaining moderate performance. 
 We propose a method to reduce false voice triggers of a speech-enabled personal assistant by post-processing the hypothesis lattice of a server-side large-vocabulary continuous speech recognizer  via a neural network. We first discuss how an estimate of the posterior probability of the trigger phrase can be obtained from the hypothesis lattice using known techniques to perform detection, then investigate a statistical model that processes the lattice in a more explicitly data-driven, discriminative manner. We propose using a Bidirectional Lattice Recurrent Neural Network  for the task, and show that it can significantly improve detection accuracy over using the 1-best result or the posterior. 
  Current state-of-the-art neural dialogue systems are mainly data-driven and are trained on human-generated responses.  However, due to the subjectivity and open-ended nature of human conversations, the complexity of training dialogues varies greatly.   The noise and uneven complexity of query-response pairs impede the learning efficiency and effects of the neural dialogue generation models.   What is more, so far, there are no unified dialogue complexity measurements, and the dialogue complexity embodies multiple aspects of attributes---specificity, repetitiveness, relevance, etc.  Inspired by human behaviors of learning to converse, where children learn from easy dialogues to complex ones and dynamically adjust their learning progress, in this paper, we first analyze five dialogue attributes to measure the dialogue complexity in multiple perspectives on three publicly available corpora.  Then, we propose an adaptive multi-curricula learning framework to schedule a committee of the organized curricula.  The framework is established upon the reinforcement learning paradigm, which automatically chooses different curricula at the evolving learning process according to the learning status of the neural dialogue generation model.  Extensive experiments conducted on five state-of-the-art models demonstrate its learning efficiency and effectiveness with respect to 13 automatic evaluation metrics and human judgments. 
 Natural Language Processing  helps empower intelligent machines by enhancing a better understanding of the human language for linguistic-based human-computer communication. Recent developments in computational power and the advent of large amounts of linguistic data have heightened the need and demand for automating semantic analysis using data-driven approaches. The utilization of data-driven strategies is pervasive now due to the significant improvements demonstrated through the usage of deep learning methods in areas such as Computer Vision, Automatic Speech Recognition, and in particular, NLP. This survey categorizes and addresses the different aspects and applications of NLP that have benefited from deep learning. It covers core NLP tasks and applications, and describes how deep learning methods and models advance these areas.~We further analyze and compare different approaches and state-of-the-art models. 
 Spoken language understanding  is a key component of task-oriented dialogue systems. SLU parses natural language user utterances into semantic frames. Previous work has shown that incorporating context information significantly improves SLU performance for multi-turn dialogues. However, collecting a large-scale human-labeled multi-turn dialogue corpus for the target domains is complex and costly. To reduce dependency on the collection and annotation effort, we propose a Context Encoding Language Transformer  model facilitating exploiting various context information for SLU. We explore different transfer learning approaches to reduce dependency on data collection and annotation. In addition to unsupervised pre-training using large-scale general purpose unlabeled corpora, such as Wikipedia, we explore unsupervised and supervised adaptive training approaches for transfer learning to benefit from other in-domain and out-of-domain dialogue corpora. Experimental results demonstrate that the proposed model with the proposed transfer learning approaches achieves significant improvement on the SLU performance over state-of-the-art models on two large-scale single-turn dialogue benchmarks and one large-scale multi-turn dialogue benchmark. 
 Conversational emotion recognition  has attracted increasing interests in the natural language processing  community. Different from the vanilla emotion recognition, effective speaker-sensitive utterance representation is one major challenge for CER.    In this paper, we exploit speaker identification  as an auxiliary task to enhance the utterance representation in conversations. By this method, we can learn better speaker-aware contextual representations from the additional SI corpus. Experiments on two benchmark datasets demonstrate that the proposed architecture is highly effective for CER, obtaining new state-of-the-art results on two datasets. 
 %\boldmath Text categorization is the task of assigning labels to documents written in a natural language, and it has numerous real-world applications including sentiment analysis as well as traditional topic assignment tasks. In this paper, we propose 5 different configurations for the semantic matrix-based memory neural network with end-to-end learning manner and evaluate our proposed method on two corpora of news articles . The best performance of our proposed method outperforms the baseline VDCNN models on the text classification task and gives a faster speed for learning semantics. Moreover, we also evaluate our model on small scale datasets. The results show that our proposed method can still achieve better results in comparison to VDCNN on the small scale dataset. This paper is to appear in the Proceedings of the 2020 IEEE 14th International Conference on Semantic Computing , San Diego, California, 2020.  
 The main source of information regarding ancient Mesopotamian history and culture are clay cuneiform tablets. Despite being an invaluable resource, many tablets are fragmented leading to missing information. Currently these missing parts are manually completed by experts. In this work we investigate the possibility of assisting scholars and even automatically completing the breaks in ancient Akkadian texts from Achaemenid period Babylonia by modelling the language using recurrent neural networks.  
 Neural conversational models learn to generate responses by taking into account the dialog history. These models are typically optimized over the query-response pairs with a maximum likelihood estimation objective. However, the query-response tuples are naturally loosely coupled, and there exist multiple responses that can respond to a given query, which leads the conversational model learning burdensome. Besides, the general dull response problem is even worsened when the model is confronted with meaningless response training instances. Intuitively, a high-quality response not only responds to the given query but also links up to the future conversations, in this paper, we leverage the query-response-future turn triples to induce the generated responses that consider both the given context and the future conversations. To facilitate the modeling of these triples, we further propose a novel encoder-decoder based generative adversarial learning framework, Posterior Generative Adversarial Network , which consists of a forward and a backward generative discriminator to cooperatively encourage the generated response to be informative and coherent by two complementary assessment perspectives. Experimental results demonstrate that our method effectively boosts the informativeness and coherence of the generated response on both automatic and human evaluation, which verifies the advantages of considering two assessment perspectives. 
 %% Text of abstract The noetic end-to-end response selection challenge as one track in the 7th Dialog System Technology Challenges  aims to push the state of the art of utterance classification for real world goal-oriented dialog systems, for which participants need to select the correct next utterances from a set of candidates for the multi-turn context. This paper presents our systems that are ranked top 1 on both datasets under this challenge, one focused and small  and the other more diverse and large . Previous state-of-the-art models use hierarchy-based  neural networks to explicitly model the interactions among different turns' utterances for context modeling. In this paper, we investigate a sequential matching model based only on chain sequence for multi-turn response selection. Our results demonstrate that the potentials of sequential matching approaches have not yet been fully exploited in the past for multi-turn response selection.  In addition to ranking top 1 in the challenge, the proposed model outperforms all previous models, including state-of-the-art hierarchy-based models, on two large-scale public multi-turn response selection benchmark datasets.  
 %A troubling trend in recent years has been the growth in the amount of misinformation spread online. In order to simultaneously combat this and study methods in natural language processing, the task of automatically finding and verifying check-worthy claims online has become a popular area of research.   As the first step of automatic fact checking, claim check-worthiness detection is a critical component of fact checking systems. There are multiple lines of research which study this problem: check-worthiness ranking from political speeches and debates, rumour detection on Twitter, and citation needed detection from Wikipedia.  To date, there has been no structured comparison of these various tasks to understand their relatedness, and no investigation into whether or not a unified approach to all of them is achievable. %However, no work has been done to date which compares and contrasts these variants of check-worthiness, trying to develop a unified approach. %which studies check-worthiness detection as a whole using data from each of these different domains.  %Given this, we asked the following primary research question in this work: are these all variants of the same task, and if so how can a machine determine fact check-worthy statements across these tasks?  In this work, we illuminate a central challenge in claim check-worthiness detection underlying all of these tasks, being that they hinge upon detecting both how factual a sentence is, as well as how likely a sentence is to be believed without verification. As such, annotators only mark those instances they judge to be clear-cut check-worthy. Our best performing method is a unified approach which automatically corrects for this using a variant of positive unlabelled learning that finds instances which were incorrectly labelled as not check-worthy. In applying this, we outperform the state of the art in two of the three tasks studied for claim check-worthiness detection in English.    %We demonstrate that core similarities exist between the tasks by developing a method that effectively improves machine understanding of fact check-worthiness in the domains of both Wikipedia citation need and Twitter rumours. Our method is based on Positive Unlabelled  learning, which enables learning generalizable features from the natural claim-like text of Wikipedia, motivated by the fact that ``all material in Wikipedia articles must be verifiable.'' Our contributions include a method to support check-worthiness detection across tasks, results demonstrating that different check-worthiness detection tasks share fundamental similarities and thus data from each can support each other, and results highlighting limitations in transferring knowledge to political debates and speeches, emphasizing differences in how labelled data was obtained in that domain compared to Twitter rumours and Wikipedia citations.  %While results in the domain of check-worthiness from political speeches are negative, we argue that the labels in this data diverge from general check-worthiness detection, demonstrating that our method highly ranks check-worthy statements which were labelled as not check-worthy.  %While results in the domain of check-worthiness from political speeches are negative, we argue that this task diverges from the core task of finding all check-worthy claims due to the way in which labels were collected, demonstrating that statements which are highly ranked by our method are still claim-like despite being labelled as non-claims.  %and under: can a large labelled corpus of citation need data from Wikipedia be used to transfer knowledge to downstream claim detection tasks? We found that by treating Wikipedia citations as a set of labelled claims and unlabelled data and using positive unlabelled  learning, we were able to significantly improve performance on the downstream task of rumour detection on Twitter. In addition, we found that PU learning improves performance for in-domain citation need detection. 
 Learning what to share between tasks has become a topic of great importance, as strategic sharing of knowledge has been shown to improve downstream task performance. This is particularly important for multilingual applications, as most languages in the world are under-resourced. Here, we consider the setting of training models on multiple different languages at the same time, when little or no data is available for languages other than English. %when English training data, but little or no in-language data is available. %for languages other than English. We show that this challenging setup can be approached using meta-learning: in addition to training a source language model, another model learns to select which training instances are the most beneficial to the first. We experiment using standard supervised, zero-shot cross-lingual, as well as few-shot cross-lingual settings for different natural language understanding tasks . Our extensive experimental setup demonstrates the consistent effectiveness of meta-learning for a total of 15 languages. We improve upon the state-of-the-art for zero-shot and few-shot NLI  and QA . %\todo{I added the MultiNLI dataset here. Please validate that the sentence is correct!} A comprehensive error analysis indicates that the correlation of typological features between languages can partly explain when parameter sharing learned via meta-learning is beneficial. 
  Named Entity Recognition  has greatly advanced by the introduction of deep neural architectures. However, the success of these methods depends on large amounts of training data.  The scarcity of publicly-available human-labeled datasets has resulted in limited evaluation of existing NER systems, as is the case for Danish. This paper studies the effectiveness of cross-lingual transfer for Danish, evaluates its complementarity to limited gold data, and sheds light on performance of Danish NER.  
 The goal of this work is to improve the performance of a neural named entity recognition system by adding input features that indicate a word is part of a name included in a gazetteer. This article describes how to generate gazetteers from the Wikidata knowledge graph as well as how to integrate the information into a neural NER system. %and use the lists %to improve a neural named entity recognition system by adding an input feature that indicates that a word matches a gazetteer name. %We empirically show that these enhancements offer performance gains in two distinct languages: a high-resource, word-based language, English; a high-resource, character-based language, Chinese; and a lower-resource, morphological  language, Russian. We also present a newly annotated Russian NER corpus from Reddit that is tagged with 4 core types and 8 additional types and present a baseline score. %IF RUSSIAN DOESN'T SHOW AN IMPROVEMENT Experiments reveal that the approach yields performance gains in two distinct languages: a high-resource, word-based language, English and a high-resource, character-based language, Chinese. Experiments were also performed in a low-resource language, Russian on a newly annotated Russian NER corpus from Reddit tagged with four core types and twelve extended types. This article reports  a baseline score. It is a longer version of a paper in the 33rd FLAIRS conference . 
 With the maturity and popularity of dialogue systems, detecting user's unknown intent in dialogue systems has become an important task. It is also one of the most challenging tasks since we can hardly get examples, prior knowledge or the exact numbers of unknown intents.  In this paper, we propose SofterMax and deep novelty detection , a simple yet effective post-processing method for detecting unknown intent in dialogue systems based on pre-trained deep neural network classifiers. Our method can be flexibly applied on top of any classifiers trained in deep neural networks without changing the model architecture. We calibrate the confidence of the softmax outputs to compute the calibrated confidence score  and use it to calculate the decision boundary for unknown intent detection. Furthermore, we feed the feature representations learned by the deep neural networks into traditional novelty detection algorithm to detect unknown intents from different perspectives. Finally, we combine the methods above to perform the joint prediction. Our method classifies examples that differ from known intents as unknown and does not require any examples or prior knowledge of it.  We have conducted extensive experiments on three benchmark dialogue datasets. The results show that our method can yield significant improvements compared with the state-of-the-art baselines\footnote{The code will be available at https://github.com/tnlin/SMDN}.  
 In large-scale domain classification, an utterance can be handled by multiple domains with overlapped capabilities. However, only a limited number of ground-truth domains are provided for each training utterance in practice while knowing as many as correct target labels is helpful for improving the model performance.  In this paper, given one ground-truth domain for each training utterance, we regard domains consistently predicted with the highest confidences as additional pseudo labels for the training. In order to reduce prediction errors due to incorrect pseudo labels, we leverage utterances with negative system responses to decrease the confidences of the incorrectly predicted domains. Evaluating on user utterances from an intelligent conversational system, we show that the proposed approach significantly improves the performance of domain classification with hypothesis reranking. 
 Stickers with vivid and engaging expressions are becoming increasingly popular in online messaging apps, and some works are dedicated to automatically select sticker response by matching text labels of stickers with previous utterances. However, due to their large quantities, it is impractical to require text labels for the all stickers. %  however, it is not straightforward to think of a proper sticker and find it from an ever-expanding pool of stickers. Hence, in this paper, we propose to recommend an appropriate sticker to user based on multi-turn dialog context history without any external labels. Two main challenges are confronted in this task. One is to learn semantic meaning of stickers without corresponding text labels. Another challenge is to jointly model the candidate sticker with the multi-turn dialog context. To tackle these challenges, we propose a   model. Specifically, SRS first employs a convolutional based sticker image encoder and a self-attention based multi-turn dialog encoder to obtain the representation of stickers and utterances. Next, deep interaction network is proposed to conduct deep matching between the sticker with each utterance in the dialog history. SRS then learns the short-term and long-term dependency between all interaction results by a fusion network to output the the final matching score. To evaluate our proposed method, we collect a large-scale real-world dialog dataset with stickers from one of the most popular online chatting platform. Extensive experiments conducted on this dataset show that our model achieves the state-of-the-art performance for all commonly-used metrics. Experiments also verify the effectiveness of each component of SRS. To facilitate further research in sticker selection field, we release this dataset of 340K multi-turn dialog and sticker pairs\footnote{\url{https://github.com/gsh199449/stickerchat}}. 
 % Current reading comprehension models generalise well to in-distribution test sets, yet perform poorly on adversarially selected inputs. % Most prior work on adversarial inputs studies oversensitivity: semantically invariant text perturbations that cause a model's prediction to change when it should not. % In this work we focus on the complementary problem: excessive prediction undersensitivity, where input text is meaningfully changed but the model's prediction does not, even though it should.  % We formulate a noisy adversarial attack which searches among semantic variations of the question for which a model erroneously predicts the same answer, and with even higher probability. % Despite comprising unanswerable questions, both  and  models are vulnerable to this attack. % This indicates that although accurate, models tend to rely on spurious patterns and do not fully consider the information specified in a question. % We experiment with data augmentation and adversarial training as defences, and find that both substantially decrease vulnerability to attacks on held out data, as well as held out attack spaces. % Addressing undersensitivity also improves results on AddSent and AddOneSent, and models furthermore generalise better when facing train/evaluation distribution mismatch:  % they are less prone to overly rely on predictive cues present only in the training set, and outperform a conventional model by as much as 10.9\%~F$_1$. 
  Social media generates an enormous amount of data on a daily basis but it is very challenging to effectively utilize the data without annotating or labeling it according to the target application. We investigate the problem of localized flood detection using the social sensing model  in order to provide an efficient, reliable and accurate flood text classification model with minimal labeled data. This study is important since it can immensely help in providing the flood-related updates and notifications to the city officials for emergency decision making, rescue operations, and early warnings, etc. We propose to perform the text classification using the inductive transfer learning method i.e pre-trained language model ULMFiT and fine-tune it in order to effectively classify the flood-related feeds in any new location. Finally, we show that using very little new labeled data in the target domain we can successfully build an efficient and high performing model for flood detection and analysis with human-generated facts and observations from Twitter.  
      Sequence to sequence models attempt to capture the correlation between all the words in the input and output sequences. While this is quite useful for machine translation where the correlation among the words is indeed quite strong, it becomes problematic for conversation modelling where the correlation is often at a much abstract level. In contrast, humans tend to focus on the essential concepts discussed in the conversation context and generate responses accordingly. In this paper, we attempt to mimic this response generating mechanism by learning the essential concepts in the context and response in an unsupervised manner. The proposed model, referred to as Mask \& Focus maps the input context to a sequence of concepts which are then used to generate the response concepts. Together, the context and the response concepts generate the final response. In order to learn context concepts from the training data automatically, we  words in the input and observe the effect of masking on response generation. We train our model to learn those response concepts that have high mutual information with respect to the context concepts, thereby guiding the model to  on the context concepts. Mask \& Focus achieves significant improvement over the existing baselines in several established metrics for dialogues. %In our experimental results on Ubuntu Dialogue Corpus and Technical Support Dataset, we observe a significant improvement in several established metrics for dialogues. 
 		We develop a chatbot using Deep Bidirectional Transformer models   to handle client questions in financial investment customer service. The bot can recognize 381 intents, and decides when to say I don't know and escalates irrelevant/uncertain questions to human operators. Our main novel contribution is the discussion about uncertainty measure for BERT, where three different approaches are systematically compared on real problems. We investigated two uncertainty metrics, information entropy and variance of dropout sampling in BERT, followed by mixed-integer programming to optimize decision thresholds. Another novel contribution is the usage of BERT as a language model in automatic spelling correction. Inputs with accidental spelling errors can significantly decrease intent classification performance. The proposed approach combines probabilities from masked language model and word edit distances to find the best corrections for misspelled words. The chatbot and the entire conversational AI system are developed using open-source tools, and deployed within our company's intranet. The proposed approach can be useful for industries seeking similar in-house solutions in their specific business domains. We share all our code and a sample chatbot built on a public dataset on Github.      	
    Multiple-choice Machine Reading Comprehension  is an important and challenging Natural Language Understanding  task, in which a machine must choose the answer to a question from a set of choices, with the question placed in context of text passages or dialog. In the last a couple of years the NLU field has been revolutionized with the advent of models based on the Transformer architecture, which are pretrained on massive amounts of unsupervised data and then fine-tuned for various supervised learning NLU tasks. Transformer models have come to dominate a wide variety of leader-boards in the NLU field; in the area of MRC, the current state-of-the-art model on the DREAM dataset  fine tunes Albert, a large pretrained Transformer-based model, and additionally combines it with an extra layer of multi-head attention between context and question-answer~. The purpose of this note is to document a new state-of-the-art result in the DREAM task, which is accomplished by, additionally, performing multi-task learning on two MRC multi-choice reading comprehension tasks .    
   Mirroring is the behavior in which one person subconsciously imitates the gesture, speech pattern, or attitude of another . In conversations, mirroring often signals the speakers' enjoyment and engagement in their communication. In chatbots, methods have been proposed to add personas to the chatbots and to train them to speak or to shift their dialogue style to that of the personas. However, they often require a large dataset consisting of dialogues of the target personalities to train. In this work, we explore a method that can learn to mirror the speaking styles of a person incrementally. Our method extracts n-grams that capture a person's speaking styles and uses the n-grams to create patterns for transforming sentences to the person's speaking styles. Our experiments show that our method is able to capture patterns of speaking style that can be used to transform regular sentences into sentences with the target style.  
  Multi-role dialogue understanding comprises a wide range of diverse tasks such as question answering, act classification, dialogue summarization etc. While dialogue corpora are abundantly available, labeled data, for specific learning tasks, can be highly scarce and expensive. In this work, we investigate dialogue context representation learning with various types unsupervised pretraining tasks where the training objectives are given naturally according to the nature of the utterance and the structure of the multi-role conversation. Meanwhile, in order to locate essential information for dialogue summarization/extraction, the pretraining process enables external knowledge integration. The proposed fine-tuned pretraining mechanism is comprehensively evaluated via three different dialogue datasets along with a number of downstream dialogue-mining tasks. Result shows that the proposed pretraining mechanism significantly contributes to all the downstream tasks without discrimination to different encoders.  %we enable the pretraining process by learning from other knowledge resources in order to solve the problem of information abbreviation in the dialogue system. Our pretraining mechanism is fine-tuned and evaluated on three different dialogue datasets with a set of downstream dialogue tasks. Evaluation shows that our pretraining mechanism contributes to significant performance improvement on all downstream tasks without discrimination to different encoders.}            
 This document contains the instructions for preparing a manuscript for the proceedings of EMNLP 2020. The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like. These instructions should be used for both papers submitted for review and for final versions of accepted papers. Authors are asked to conform to all the directions reported in this document. 
     Artificial neural networks are a state-of-the-art solution for many problems in natural language processing. What can we learn about language and meaning from the way artificial neural networks represent it?     Word representations obtained from the  variant of the word2vec model exhibit interesting semantic properties. 	This is usually explained by referring to the general distributional hypothesis, which states that 	the meaning of the word is given by the contexts where it occurs. We propose a more 	specific approach based on Frege's holistic and functional approach to meaning. Taking 	Tugendhat's formal reinterpretation of Frege's work as a starting point, we demonstrate that it is analogical to the process of training the  model and offers a possible explanation 	of its semantic properties. 
  How do children learn correspondences between the language and the world from noisy, ambiguous, naturalistic input? One hypothesis is via cross-situational learning: tracking words and their possible referents across multiple situations allows learners to disambiguate correct word-referent mappings . However, previous models of cross-situational word learning operate on highly simplified representations, side-stepping two important aspects of the actual learning problem. First, how can word-referent mappings be learned from raw inputs such as images? Second, how can these learned mappings generalize to novel instances of a known word? In this paper, we present a neural network model trained from scratch via self-supervision that takes in raw images and words as inputs, and show that it can learn word-referent mappings from fully ambiguous scenes and utterances through cross-situational learning. In addition, the model generalizes to novel word instances, locates referents of words in a scene, and shows a preference for mutual exclusivity.  Keywords:  cross-situational word learning; word learning; deep learning; self-supervised learning; multi-modal learning 
 As an essential step towards computer creativity, automatic poetry generation has gained increasing attention these years. Though recent neural models make prominent progress in some criteria of poetry quality, generated poems still suffer from the problem of poor diversity. Related literature researches show that different factors, such as life experience, historical background, etc., would influence composition styles of poets, which considerably contributes to the high diversity of human-authored poetry. Inspired by this, we propose , a novel model that absorbs multiple factors to create various styles and promote diversity. Based on a semi-supervised variational autoencoder, our model disentangles the latent space into some subspaces, with each conditioned on one influence factor by adversarial training. In this way, the model learns a controllable latent variable to capture and mix generalized factor-related properties. Different factor mixtures lead to diverse styles and hence further differentiate generated poems from each other. Experiment results on Chinese poetry demonstrate that MixPoet improves both diversity and quality against three state-of-the-art models. 
   This paper explores the use of Deep Learning methods for automatic estimation of quality of human translations.  Automatic estimation can provide useful feedback for translation teaching, examination and quality control.  Conventional methods for solving this task rely on manually engineered features and external knowledge.  This paper presents an end-to-end neural model without feature engineering, incorporating a cross attention mechanism to detect which parts in sentence pairs are most relevant for assessing quality.  Another contribution concerns of prediction of fine-grained scores for measuring different aspects of translation quality. Empirical results on a large human annotated dataset show that the neural model outperforms feature-based methods significantly.  The dataset and the tools are available.   \\ \newline \Keywords{human translation quality estimation, sentence-level, attention mechanism, neural networks
 We address the issue of having a limited number of annotations for stance classification in a new domain, by adapting out-of-domain classifiers with domain adaptation. Existing approaches often align different domains in a single, global feature space , which may fail to fully capture the richness of the languages used for expressing stances, leading to reduced adaptability on stance data. In this paper, we identify two major types of stance expressions that are linguistically distinct, and we propose a tailored dual-view adaptation network  to adapt these expressions across domains. The proposed model first learns a separate view for domain transfer in each expression channel and then selects the best adapted parts of both views for optimal transfer. We find that the learned view features can be more easily aligned and more stance-discriminative in either or both views, leading to more transferable overall features after combining the views. Results from extensive experiments show that our method can enhance the state-of-the-art single-view methods in matching stance data across different domains, and that it consistently improves those methods on various adaptation tasks. 
  When learning a language, people can quickly expand their understanding of the unknown content by using compositional skills, such as from two words ``go" and ``fast" to a new phrase ``go fast." In recent work of , modern Sequence-to-Sequence  Recurrent Neural Networks  can make powerful zero-shot generalizations in specifically controlled experiments. However, there is a missing regarding the property of such strong generalization and its precise requirements. This paper explores this positive result in detail and defines this pattern as the synonymous generalization, an ability to recognize an unknown sequence by decomposing the difference between it and a known sequence as corresponding existing synonyms. To better investigate it, I introduce a new environment called Colorful Extended Cleanup World , which consists of complex commands paired with logical expressions. While demonstrating that sequential RNNs can perform synonymous generalizations on foreign commands, I conclude their prerequisites for success. I also propose a data augmentation method, which is successfully verified on the Geoquery  dataset, as a novel application of synonymous generalization for real cases.  
   Mental health poses a significant challenge for an individual's well-being. Text analysis of rich resources, like social media, can contribute to deeper understanding of illnesses and provide means for their early detection. We tackle a challenge of detecting social media users' mental status through deep learning-based models, moving away from traditional approaches to the task. In a binary classification task on predicting if a user suffers from one of nine different disorders, a hierarchical attention network outperforms previously set benchmarks for four of the disorders. Furthermore, we explore the limitations of our model and analyze phrases relevant for classification by inspecting the model's word-level attention weights.    %Traditional NLP approaches have fair success in detecting mental disorders of social media users.   %In this study, we employ hierarchical attention network for predicting mental status of Reddit users, labeled with one or more of the nine different disorders.   %In a binary classification task, we outperform previously set benchmarks for four of the disorders.    
 Abstractive text summarization is a challenging task, and one need to design a mechanism to effectively extract salient information from the source text and then generate a summary. A parsing process of the source text contains critical syntactic or semantic structures, which is useful to generate more accurate summary. However, modeling a parsing tree for text summarization is not trivial due to its non-linear structure and it is harder to deal with a document that includes multiple sentences and their parsing trees. In this paper, we propose to use a graph to connect the parsing trees from the sentences in a document and utilize the stacked graph convolutional networks  to learn the syntactic representation for a document. The selective attention mechanism is used to extract salient information in semantic and structural aspect and generate an abstractive summary. We evaluate our approach on the CNN/Daily Mail text summarization dataset. The experimental results show that the proposed GCNs based selective attention approach outperforms the baselines and achieves the state-of-the-art performance on the dataset. % We evaluate the approach on the IEMOCAP dataset and the experimental results show the advantage of the proposed approach. 
 With growing amounts of available textual data, development of algorithms capable of automatic analysis, categorization and summarization of these data has become a necessity. In this research we present a novel algorithm for keyword identification, i.e., an extraction of one or multi-word phrases representing key aspects of a given document, called Transformer-based Neural Tagger for Keyword IDentification . By adapting the transformer architecture for a specific task at hand and leveraging language model pretraining on a domain specific corpus, the model is capable of overcoming deficiencies of both supervised and unsupervised state-of-the-art approaches to keyword extraction by offering competitive and robust performance on a variety of different datasets while requiring only a fraction of manually labeled data required by the best performing systems. This study also offers thorough error analysis with valuable insights into the inner workings of the model and an ablation study measuring the influence of specific components of the keyword identification workflow on the overall performance.  
  Medical named entity recognition  has wide applications in intelligent healthcare. Sufficient labeled data is critical for training accurate medical NER model. However, the labeled data in a single medical platform is usually limited. Although labeled datasets may exist in many different medical platforms, they cannot be directly shared since medical data is highly privacy-sensitive. In this paper, we propose a privacy-preserving medical NER method based on federated learning, which can leverage the labeled data in different platforms to boost the training of medical NER model and remove the need of exchanging raw data among different platforms. Since the labeled data in different platforms usually has some differences in entity type and annotation criteria, instead of constraining different platforms to share the same model, we decompose the medical NER model in each platform into a shared module and a private module. The private module is used to capture the characteristics of the local data in each platform, and is updated using local labeled data. The shared module is learned across different medical platform to capture the shared NER knowledge. Its local gradients from different platforms are aggregated to update the global shared module, which is further delivered to each platform to update their local shared modules. Experiments on three publicly available datasets validate the effectiveness of our method.  
 	 Existing aspect based sentiment analysis  approaches leverage various neural network models to extract the aspect sentiments via learning aspect-specific feature representations. However, these approaches heavily rely on manual tagging of user reviews according to the predefined aspects as the input, a laborious and time-consuming process. Moreover, the underlying methods do not explain how and why the opposing aspect level polarities in a user review lead to the overall polarity. In this paper, we tackle these two problems by designing and implementing a new Multiple-Attention Network  approach for more powerful ABSA without the need for aspect tags using two new tag-free data sets crawled directly from TripAdvisor . With the Self- and Position-Aware attention mechanism, MAN is capable of extracting both aspect level and overall sentiments from the text reviews using the aspect level and overall customer ratings, and it can also detect the vital aspect leading to the overall sentiment polarity among different aspects via a new aspect ranking scheme. We carry out extensive experiments to demonstrate the strong performance of MAN compared to other state-of-the-art ABSA approaches and the explainability of our approach by visualizing and interpreting attention weights in case studies.   % which is called cold-start problem % Aspect based sentiment analysis  arises as an important task in Natural Language Processing. Aspect-based sentiment analysis  arises as a powerful Natural Language Processing  technique to detect aspect level and overall polarities. However, most approaches are supervised learning in the sense that review texts need to be manually tagged with predefined aspects and labeled with customer ratings. The aspect tagging is a laborious and time-consuming process, substantially limiting our capability of training powerful ABSA models for more detailed and accurate analysis of semantic information behind the texts. As such most of the existing ABSA works rely on a few tagged user review data sets to demonstrate utilities and evaluate performance, which does not permit an automatic ABSA for practical deployment, which is also called cold-start problem here. Moreover, these approaches often do not explain how and why the opposing aspect level polarities in a user review lead to the overall polarity. In this paper, we tackle the problem using a weakly supervised approach by eliminating the requirement of tedious aspect tagging from training user reviews. With an attention mechanism, our weakly supervised ABSA  model exploits the aspect and overall ratings coming with each user review crawled directly from TripAdvisor  to learn the weighted contribution of each word to each aspect level and overall polarities, enabling automatic end-to-end text analytic with minimum external supervision. Using an aspect ranking scheme, our WSABSA is fully explainable by detecting the vital aspect level polarities leading to the overall polarity. We carry out extensive experiments to demonstrate the power of our WSABSA approach compared to other state-of-the-art ABSA approaches. By visualizing attention weights and aspect weights from two examples, we demonstrate the explainability of our WSABSA model.   
 Data augmentation promises to alleviate data scarcity. This is most important in cases where the initial data is in short supply. This is, for existing methods, also where augmenting is the most difficult, as learning the full data distribution is impossible. For natural language, sentence editing offers a solution - relying on small but meaningful changes to the original ones. Learning which changes are meaningful also requires large amounts of training data. We thus aim to learn this in a source domain where data is abundant and apply it in a different, target domain, where data is scarce - cross-domain augmentation.  We create the Edit-transformer, a Transformer-based sentence editor that is significantly faster than the state of the art and also works cross-domain.  We argue that, due to its structure, the Edit-transformer is better suited for cross-domain environments than its edit-based predecessors. We show this performance gap on the Yelp-Wikipedia domain pairs.  Finally, we show that due to this cross-domain performance advantage, the Edit-transformer leads to meaningful performance gains in several downstream tasks. 
 %Many Nigerian languages have   Using the new JW300 public dataset, we trained and evaluated baseline translation models for four widely spoken languages: \d{\`E}d{\'o}, {\'E}s{\'a}n, Urhobo and Isoko. Trained models, code and datasets have been open-sourced to advance future research efforts on Edoid language technology.\\  %Given the empowering potential of language technology, we investigate the feasibility of Neural Machine Translation  for speakers of Edoid languages of Southern Nigeria. %
 Text summarization aims to generate a headline or a short summary consisting of the major information of the source text. Recent studies employ the sequence-to-sequence framework to encode the input with a neural network and generate abstractive summary. However, most studies feed the encoder with the semantic word embedding but ignore the syntactic information of the text. Further, although previous studies proposed the selective gate to control the information flow from the encoder to the decoder, it is static during the decoding and cannot differentiate the information based on the decoder states. In this paper, we propose a novel neural architecture for document summarization. Our approach has the following contributions: first, we incorporate syntactic information such as constituency parsing trees into the encoding sequence to learn both the semantic and syntactic information from the document, resulting in more accurate summary; second, we propose a dynamic gate network to select the salient information based on the context of the decoder state, which is essential to document summarization. The proposed model has been evaluated on CNN/Daily Mail summarization datasets and the experimental results show that the proposed approach outperforms baseline approaches. 
 Multi-class text classification is one of the key problems in machine learning and natural language processing. Emerging neural networks deal with the problem using a multi-output softmax layer and achieve substantial progress, but they do not explicitly learn the correlation among classes. In this paper, we use a multi-task framework to address multi-class classification, where a multi-class classifier and multiple binary classifiers are trained together. Moreover, we employ adversarial training to distinguish the class-specific features and the class-agnostic features. The model benefits from better feature representation. We conduct experiments on two large-scale multi-class text classification tasks and demonstrate that the proposed architecture outperforms baseline approaches. 
 Text matching is a core natural language processing research problem. How to retain sufficient information on both content and structure information is one important challenge. In this paper, we present a neural approach for general-purpose text matching with deep mutual information estimation incorporated. Our approach, Text matching with Deep Info Max , is integrated with a procedure of unsupervised learning of representations by maximizing the mutual information between text matching neural network's input and output. We use both global and local mutual information to learn text representations. We evaluate our text matching approach on several tasks including natural language inference, paraphrase identification, and answer selection. Compared to the state-of-the-art approaches, the experiments show that our method integrated with mutual information estimation learns better text representation and achieves better experimental results of text matching tasks without exploiting pretraining on external data. 
 We report our experiments in building a domain-specific Tigrinya-to-English neural machine translation system. We use transfer learning from other Ge'ez script languages and report an improvement of 1.3 BLEU points over a classic neural baseline. We publish our development pipeline as an open-source library and also provide a demonstration application. 
 Transformers have recently taken the centre stage in language modeling after LSTM's were considered the dominant model architecture for a long time. In this project, we investigate the performance of the Transformer architectures-BERT and Transformer-XL for the language modeling task. We use a sub-word model setting with the Finnish language and compare it to the previous State of the art  LSTM model. BERT achieves a pseudo-perplexity score of 14.5, which is a first such measure achieved as far as we know. Transformer-XL improves upon the perplexity score to 73.58 which is 27\% better than the LSTM model.   
 Sentiment Analysis is an important algorithm in Natural Language Processing which is used to detect sentiment within some text. In our project, we had chosen to work on analyzing reviews of various drugs which have been reviewed in form of texts and have also been given a rating on a scale from 1-10. We had obtained this data set from UCI machine learning repository which had 2 data sets: train and test . We had split the number rating for the drug into three classes in general: positive , negative  or neutral. There are multiple reviews for the drugs which belong to the similar condition and we decided to investigate how the reviews for different conditions use different words impact the ratings of the drugs. Our intention was mainly to implement supervised machine learning classification algorithms which predicts the class of the rating using the textual review. We had primarily implemented different embeddings such as Term Frequency Inverse Document Frequency  and the Count Vectors . We had trained models on the most popular conditions such as "Birth Control", "Depression" and "Pain" within the data set and obtained good results while predicting on the test data sets.  
In Multi-Label Text Classification , one sample can belong to more than one class. It is observed that most MLTC tasks, there are dependencies or correlations among labels. Existing methods tend to ignore the relationship among labels. In this paper, a graph attention network-based model is proposed to capture the attentive dependency structure among the labels. The graph attention network uses a feature matrix and a correlation matrix to capture and explore the crucial dependencies between the labels and generate classifiers for the task. The generated classifiers are applied to sentence feature vectors obtained from the text feature extraction network to enable end-to-end training. Attention allows the system to assign different weights to neighbor nodes per label, thus allowing it to learn the dependencies among labels implicitly. The results of the proposed model are validated on five real-world MLTC datasets. The proposed model achieves similar or better performance compared to the previous state-of-the-art models.
   Deep-agent communities developing their own language-like   communication protocol are a hot  topic in   AI. Such agents could be very useful in machine-machine and   human-machine interaction scenarios long before they have evolved a   protocol as complex as human language. Here, I propose a small   set of priorities we should focus on, if we want to get as fast as   possible to a stage where deep agents speak a useful   . 
 Social media, especially Twitter, is being increasingly used for research with predictive analytics.  In social media studies, natural language processing  techniques are used in conjunction with expert-based, manual and qualitative analyses.  However, social media data are unstructured and must undergo complex manipulation for research use.  The manual annotation is the most resource and time-consum-ing process that multiple expert raters have to reach consensus on every item, but is essential to create gold-standard datasets for training NLP-based machine learning classifiers.  To reduce the burden of the manual annotation, yet maintaining its reliability, we devised a crowdsourcing pipeline combined with active learning strategies.  We demonstrated its effectiveness through a case study that identifies job loss events from individual tweets.  We used Amazon Mechanical Turk platform to recruit annotators from the Internet and designed a number of quality control measures to assure annotation accuracy.  We evaluated 4 different active learning strategies .  The active learning strategies aim at reducing the number of tweets needed to reach a desired performance of automated classification.  Results show that crowdsourcing is useful to create high-quality annotations and active learning helps in reducing the number of required tweets, although there was no substantial difference among the strategies tested.   
 Nigerian Pidgin is arguably the most widely spoken language in Nigeria. Variants of this language are also spoken across West and Central Africa, making it a very important language. This work aims to establish supervised and unsupervised neural machine translation  baselines between English and Nigerian Pidgin. We implement and compare NMT models with different tokenization methods, creating a solid foundation for future works.  
 %Different from traditional sentence-level Relation Extraction , document-level RE is more difficult and practical, which requires model to have the ability of reasoning and aggregating.  %Naturally, documents contain different granularity of information: entity , sentence and document. %Thus how to obtain and aggregate this information with different granularity is challenging but important for document-level RE. Document-level RE requires reading, inferring and aggregating over multiple sentences. From our point of view, it is necessary for document-level RE to take advantage of multi-granularity inference information: entity level, sentence level and document level.  Thus, how to obtain and aggregate the inference information with different granularity is challenging for document-level RE,  which has not been considered by previous work. In this paper, we propose a Hierarchical Inference Network  to make full use of the abundant information from entity level, sentence level and document level. Translation constraint and bilinear transformation are applied to target entity pair in multiple subspaces to get entity-level inference information. Next, we model the inference between entity-level information and sentence representation to achieve sentence-level inference information. Finally, a hierarchical aggregation approach is adopted to obtain the document-level inference information. In this way, our model can effectively aggregate inference information from these three different granularities. Experimental results show that our method achieves state-of-the-art performance on the large-scale DocRED dataset. We also demonstrate that using BERT representations can further substantially boost the performance.    
 In zero-resource settings where transcribed speech audio is unavailable, unsupervised feature learning is essential for downstream speech processing tasks. Here we compare two recent methods for frame-level acoustic feature learning. For both methods, unsupervised term discovery is used to find pairs of word examples of the same unknown type. Dynamic programming is then used to align the feature frames between each word pair, serving as weak top-down supervision for the two models. For the correspondence autoencoder , matching frames are presented as input-output pairs. The Triamese network uses a contrastive loss to reduce the distance between frames of the same predicted word type while increasing the distance between negative examples. For the first time, these feature extractors are compared on the same discrimination tasks using the same weak supervision pairs. We find that, on the two datasets considered here, the CAE outperforms the Triamese network. However, we show that a new hybrid correspondence-Triamese approach , consistently outperforms both the CAE and Triamese models in terms of average precision and ABX error rates on both English and Xitsonga evaluation data. 
 Pre-trained neural language models bring significant improvement for various NLP tasks, by fine-tuning the models on task-specific training sets. During fine-tuning, the parameters are initialized from pre-trained models directly, which ignores how the learning process of similar NLP tasks in different domains is correlated and mutually reinforced. In this paper, we propose an effective learning procedure named  , serving as a meta-learner to solve a group of similar NLP tasks for neural language models. Instead of simply multi-task training over all the datasets, MFT only learns from typical instances of various domains to acquire highly transferable knowledge. It further encourages the language model to encode domain-invariant representations by optimizing a series of novel domain corruption loss functions. After MFT,  the model can be fine-tuned for each domain with better parameter initialization and higher generalization ability. We implement MFT upon BERT to solve several multi-domain text mining tasks. Experimental results confirm the effectiveness of MFT and its usefulness for few-shot learning. 
   Document-level machine translation incorporates inter-sentential dependencies into the translation of a source sentence. In this paper, we propose a new framework to model cross-sentence dependencies by training neural machine translation   to predict both the target translation  and  surrounding sentences of a source sentence. By enforcing the NMT model to predict source context, we want the model to learn ``contextualized'' source sentence representations that capture document-level dependencies on the source side. We further propose two different methods to learn and integrate such contextualized sentence embeddings into NMT: a joint training method that jointly trains an NMT model with the source context prediction model and a pre-training \& fine-tuning method that pretrains the source context prediction model on a large-scale monolingual document corpus and then fine-tunes it with the NMT model.   Experiments on Chinese-English  and English-German translation show that both methods can substantially improve the translation quality  over a strong document-level Transformer baseline.  
     Fully data driven Chatbots for non-goal oriented dialogues are known to suffer from inconsistent behaviour across their turns, stemming from a general difficulty in controlling parameters like their assumed background personality and knowledge of facts.     One reason for this is the relative lack of labeled data from which personality consistency and fact usage could be learned together with dialogue behaviour. To address this, we introduce a new labeled dialogue dataset in the domain of movie discussions, where every dialogue is based on pre-specified facts and opinions. We thoroughly validate the collected dialogue for adherence of the participants to their given fact and opinion profile, and find that the general quality in this respect is high. This process also gives us an additional layer of annotation that is potentially useful for training models. We introduce as a baseline an end-to-end trained self-attention decoder model trained on this data and show that it is able to generate opinionated responses that are judged to be natural and knowledgeable and show attentiveness. \\ \newline \Keywords{Non-Goal Driven Dialogues, Opinionated Discussions, Deep Neural Networks
 Disaster prediction is one of the most critical tasks towards disaster surveillance and preparedness.  Existing technologies employ different machine learning approaches to predict incoming disasters from historical environmental data.  However, for short-term disasters , historical data alone has a limited prediction capability. Therefore, additional sources of warnings are required for accurate prediction.  %In the last decade, social media has proved to be a functional source of information and an effective platform for crisis communication.  We consider social media as a supplementary source of knowledge in addition to historical environmental data.  However, social media posts  is very informal and contains only limited content.  To alleviate these limitations, we propose the combination of semantically-enriched word embedding model to represent entities in tweets with their semantic representations computed with the traditional .  Moreover, we study how the correlation between social media posts and typhoons magnitudes  -in terms of volume and sentiments of tweets-. Based on these insights, we propose an end-to-end based framework that learns from disaster-related tweets and environmental data to improve typhoon intensity prediction. This paper is an extension of our work originally published in K-CAP 2019~. We extended this paper by building our framework with state-of-the-art deep neural models, updated our dataset with new typhoons and their tweets to-date and benchmark our approach against recent baselines in disaster prediction.  Our experimental results show that our approach outperforms the accuracy of the state-of-the-art baselines in terms of F1-score with  improvement compared with last experiments.  %  %\todo{present social media users as human sensors ?} 
 It is now established that modern neural language models can be successfully trained on multiple languages simultaneously without changes to the underlying architecture, providing an easy way to adapt a variety of NLP models to low-resource languages. But what kind of knowledge is really shared among languages within these models? Does multilingual training mostly lead to an alignment of the lexical representation spaces or does it also enable the sharing of purely grammatical knowledge? %And what are the optimal training conditions for different kinds of cross-lingual transfer? In this paper we dissect different forms of cross-lingual transfer and look for its most determining factors, %This paper answer these questions  using a variety of models and probing tasks. We find that exposing our LMs to a related language does not always increase grammatical knowledge in the target language, and that optimal conditions for lexical-semantic transfer may not be optimal for syntactic transfer. 
 With the explosion of online news, personalized news recommendation becomes increasingly important for online news platforms to help their users find interesting information. Existing news recommendation methods achieve personalization by building accurate news representations from news content and user representations from their direct interactions with news , while ignoring the high-order relatedness between users and news. Here we propose a news recommendation method which can enhance the representation learning of users and news by modeling their relatedness in a graph setting. In our method, users and news are both viewed as nodes in a bipartite graph constructed from historical user click behaviors. For news representations, a transformer architecture is first exploited to build news semantic representations. Then we combine it with the information from neighbor news in the graph via a graph attention network. For user representations, we not only represent users from their historically clicked news, but also attentively incorporate the representations of their neighbor users in the graph. %Experiments were conducted on a large-scale real-world dataset. %The improved performances validate the effectiveness of our proposed method Improved performances on a large-scale real-world dataset validate the effectiveness of our proposed method. 
 % %Speakers of different languages must %attend to and encode strikingly %different aspects of the world in %order to use their language %correctly %~. One %such difference is related to the %way gender is expressed in a %language. Saying ``I am happy'' in %English, does not encode any %additional knowledge of the speaker %that uttered the sentence. However, %many other languages do have %grammatical gender systems and so %such knowledge would be encoded. In %order to correctly translate such a %sentence into, say, French, the %inherent gender information needs to %be retained/recovered. The same %sentence would become either ``Je %suis heureux'', for a male speaker %or ``Je suis heureuse'' for a female %one. Apart from morphological %agreement, demographic factors % also influence %our use of language in terms of word %choices or even on the level of %syntactic %constructions~. %We integrate gender information into %NMT systems. Our contribution is %two-fold:  the compilation of %large datasets with speaker %information for 20 language pairs, %and  a simple set of experiments %that incorporate gender information %into NMT for multiple language %pairs. Our experiments show that %adding a gender feature to an NMT %system significantly improves the %translation quality for some %language pairs.  %
 Neural-symbolic computing has now become the subject of interest of both  academic and industry research laboratories.  Graph Neural Networks  have been widely used in relational and symbolic domains, with widespread application of GNNs in combinatorial optimization, constraint satisfaction, relational reasoning and other scientific domains. The need for improved explainability, interpretability and trust of AI systems in general demands principled methodologies, as suggested by neural-symbolic computing.  In this paper, we review the state-of-the-art on the use of GNNs as a model of neural-symbolic computing. This includes the application of GNNs in several  domains as well as their relationship to current developments in neural-symbolic computing.  
 The abstract should summarize the contents of the paper. LNCS guidelines indicate it should be at least 70 and at most 150 words. It should be set in 9-point font size and should be inset 1.0~cm from the right and left margins. \dots  
 This paper presents a practical approach to fine-grained information extraction. Through plenty of authors閳 experiences in practically applying information extraction to business process automation, there can be found a couple of fundamental technical challenges:  the availability of labeled data is usually limited and  highly detailed classification is required. The main idea of our proposal is to leverage the concept of transfer learning, which is to reuse the pre-trained model of deep neural networks, with a combination of common statistical classifiers to determine the class of each extracted term. To do that, we first exploit BERT to deal with the limitation of training data in real scenarios, then stack BERT with Convolutional Neural Networks to learn hidden representation for classification. To validate our approach, { 
 Entity summarization has been a prominent task over knowledge graphs. While existing methods are mainly unsupervised, we present DeepLENS, a simple yet effective deep learning model where we exploit textual semantics for encoding triples and we score each candidate triple based on its interdependence on other triples. DeepLENS significantly outperformed existing methods on a public benchmark.  %  
 %Recent years have seen an increasing emphasis on information security, and various encryption methods have been proposed. %However, for symmetric encryption methods, the well-known encryption techniques still rely on the key space to guarantee security and suffer from frequent key updating. %Aiming to solve those problems, this paper proposes a novel symmetry-key method for text encryption based on deep learning called TEDL, where the secret key includes hyperparameters in deep learning model and the core step of encryption is transforming input data into weights trained under hyperparameters.  %Firstly, both communication parties establish a word vector table by training a deep learning model according to specified hyperparameters. %Then, a self-update codebook is constructed on the word vector table with the SHA-256 function and other tricks.  %When communication starts, encryption and decryption are equivalent to indexing and inverted indexing on the codebook, respectively, thus achieving the transformation between plaintext and ciphertext.  %Results of experiments and relevant analyses show that TEDL performs well for security, efficiency, generality, and has a lower demand for the frequency of key redistribution.  %Especially, as a supplement to current encryption methods, the time-consuming process of constructing a codebook increases the difficulty of brute-force attacks, meanwhile, it does not degrade the efficiency of communications. Recent years have seen an increasing emphasis on information security, and various encryption methods have been proposed. However, for symmetric encryption methods, the well-known encryption techniques still rely on the key space to guarantee security and suffer from frequent key updating. Aiming to solve those problems, this paper proposes a novel text encryption method based on deep learning called TEDL, where the secret key includes hyperparameters in deep learning model and the core step of encryption is transforming input data into weights trained under hyperparameters. Firstly, both communication parties establish a word vector table by training a deep learning model according to specified hyperparameters. Then, a self-update codebook is constructed on the word vector table with the SHA-256 function and other tricks. When communication starts, encryption and decryption are equivalent to indexing and inverted indexing on the codebook, respectively, thus achieving the transformation between plaintext and ciphertext. Results of experiments and relevant analyses show that TEDL performs well for security, efficiency, generality, and has a lower demand for the frequency of key redistribution. Especially, as a supplement to current encryption methods, the time-consuming process of constructing a codebook increases the difficulty of brute-force attacks while not degrade the communication efficiency. 
 Path-based relational reasoning over knowledge graphs has become increasingly popular due to a variety of downstream applications such as question answering in dialogue systems, fact prediction, and recommender systems. In recent years, reinforcement learning  has provided solutions that are more interpretable and explainable than other deep learning models. However, these solutions still face several challenges, including large action space for the RL agent and accurate representation of entity neighborhood structure.  We address these problems by introducing a type-enhanced RL agent that uses the local neighborhood information for efficient path-based reasoning over knowledge graphs. Our solution uses graph neural network  for encoding the neighborhood information and utilizes entity types to prune the action space. Experiments on real-world dataset show that our method outperforms state-of-the-art RL methods and discovers more novel paths during the training procedure. 
  The Deep Learning Track is a new track for TREC 2019, with the goal of studying ad hoc ranking in a large data regime. It is the first track with large human-labeled training sets, introducing two sets corresponding to two tasks, each with rigorous TREC-style blind evaluation and reusable test sets. The document retrieval task has a corpus of 3.2 million documents with 367 thousand training queries, for which we generate a reusable test set of 43 queries. The passage retrieval task has a corpus of 8.8 million passages with 503 thousand training queries, for which we generate a reusable test set of 43 queries. This year 15 groups submitted a total of 75 runs, using various combinations of deep learning, transfer learning and traditional IR ranking methods. Deep learning runs significantly outperformed traditional IR runs. Possible explanations for this result are that we introduced large training data and we included deep models trained on such data in our judging pools, whereas some past studies did not have such training data or pooling.  %The passage retrieval task has 503 thousand training queries and 43 test queries, against a corpus of 8.8 million passages.  %The document retrieval task has 367 thousand training queries and 43 test queries, against a corpus of 3.2 million documents for which we have title, URL and body text.  %There were 15 groups with a total of 75 runs across both tasks.   %PREVIOUS: %The Deep Learning Track studies and evaluates ad hoc information retrieval in a large data regime, with hundreds of thousands of training queries.  %The passage retrieval task has 503 thousand training queries and 43 test queries, against a corpus of 8.8 million passages.  %The document retrieval task has 367 thousand training queries and 43 test queries, against a corpus of 3.2 million documents for which we have title, URL and body text.  %There were 15 groups with a total of 75 runs across both tasks. %The best-performing runs by a considerable margin tended to use ,lBERT, which is consistent with public leaderboards on ranking and related tasks. %More years and more runs would be needed to draw firmer conclusions, but for this year's runs deep learning and transfer learning approaches outperformed traditional IR approaches. %More work would be needed for a detailed study of training set size and performance.  %The TREC 2019 Deep Learning track is the first iteration of an effort to create a focused benchmark with rigorous blind evaluation of retrieval methods under the large training data regime. %The track introduces two large labeled training sets to TREC containing hundreds of thousands of labeled training queries---sufficient for learning complex representations of text---for a document retrieval task and a passage retrieval task. %Two corresponding collections containing approximately 3.2 million documents and 8.8 million passages are also released as part of this benchmarking effort. %The data for both tasks are derived from the original Microsoft MAchine Reading COmprehension  dataset. %Retrieval runs are evaluated using manual relevance assessments collected by the National Institute of Standards and Technology  after all runs have been submitted. %A total of 15 teams participated in the track in 2019, with an aggregate of 75 runs submitted across the two tasks. %Among the submitted runs deep learning methods---especially those based on unsupervised deep neural language models like BERT---significantly outperform traditional retrieval methods. %We conclude, based on the dramatic improvements from BERT-based models, that the first TREC deep learning track coincides with the ``Year of the BERT''. %Finally, analysis of evaluation results also indicate reasonable agreement between MS MARCO-style leaderboard-based evaluation and NIST-style ``blind'' evaluation.  %Deep learning methods, where a computational model learns complex representations from large-scale datasets, have yielded dramatic improvements over state-of-the-art in speech recognition and computer vision . %Although there has been significant interest in deep learning for adhoc ranking, there have been two key missing ingredients. %One is the lack of a large training set with at least hundreds of thousands of labeled training queries, sufficient for representation learning. %The other is the lack of a shared benchmark, in the absence of which existing published work in the area have employed a variety of proprietary and synthetic datasets.  %Besides the key question of how best to leverage a large labeled set to improve ranking, there are other fundamental research questions that this track aims to investigate---including whether recent deep learning models have significantly improved over traditional retrieval methods, such as pseudo-relevance feedback.  
 One usage of medical ultrasound imaging is to visualize and characterize human tongue shape and motion during a real-time speech to study healthy or impaired speech production. Due to the low-contrast characteristic and noisy nature of ultrasound images, it might require expertise for non-expert users to recognize tongue gestures in applications such as visual training of a second language. Moreover, quantitative analysis of tongue motion needs the tongue dorsum contour to be extracted, tracked, and visualized. Manual tongue contour extraction is a cumbersome, subjective, and error-prone task. Furthermore, it is not a feasible solution for real-time applications. \\ The growth of deep learning has been vigorously exploited in various computer vision tasks, including ultrasound tongue contour tracking. In the current methods, the process of tongue contour extraction comprises two steps of image segmentation and post-processing. This paper presents a new novel approach of automatic and real-time tongue contour tracking using deep neural networks. In the proposed method, instead of the two-step procedure, landmarks of the tongue surface are tracked. This novel idea enables researchers in this filed to benefits from available previously annotated databases to achieve high accuracy results. Our experiment disclosed the outstanding performances of the proposed technique in terms of generalization, performance, and accuracy.   
 		Self-attention  network has shown profound value in image captioning. In this paper, we improve SA from two aspects to promote the performance of image captioning. First, we propose Normalized Self-Attention , a reparameterization of SA that brings the benefits of normalization inside SA. While normalization is previously only applied outside SA, we introduce a novel normalization method and demonstrate that it is both possible and beneficial to perform it on the hidden activations inside SA. Second, to compensate for the major limit of Transformer that it fails to model the geometry structure of the input objects, we propose a class of Geometry-aware Self-Attention  that extends SA to explicitly and efficiently consider the relative geometry relations between the objects in the image. To construct our image captioning model, we combine the two modules and apply it to the vanilla self-attention network. We extensively evaluate our proposals on MS-COCO image captioning dataset and superior results are achieved when comparing to state-of-the-art approaches. Further experiments on three challenging tasks, \ie video captioning, machine translation, and visual question answering, show the generality of our methods.  	
 Compared to consumer lending, Micro, Small and Medium Enterprise  credit risk modelling is particularly challenging, as, often, the same sources of information are not available. Therefore, it is standard policy for a loan officer to provide a textual loan assessment to mitigate limited data availability. In turn, this statement is analysed by a credit expert alongside any available standard credit data. In our paper, we exploit recent advances from the field of Deep Learning and Natural Language Processing , including the BERT  model, to extract information from 60000 textual assessments provided by a lender. We consider the performance in terms of the AUC  and Brier Score metrics and find that the text alone is surprisingly effective for predicting default. However, when combined with traditional data, it yields no additional predictive capability, with performance dependent on the text's length. Our proposed deep learning model does, however, appear to be robust to the quality of the text and therefore suitable for partly automating the mSME lending process. We also demonstrate how the content of loan assessments influences performance, leading us to a series of recommendations on a new strategy for collecting future mSME loan assessments. 
  We introduce a new way of learning to encode position information for non-recurrent models, such as Transformer models. Unlike RNN and LSTM, which contain inductive bias by loading the input tokens sequentially, non-recurrent models are less sensitive to position. The main reason is that position information among input units is not inherently encoded, i.e., the models are permutation equivalent; this problem justifies why all of the existing models are accompanied by a sinusoidal encoding/embedding layer at the input. However, this solution has clear limitations: the sinusoidal encoding is not flexible enough as it is manually designed and does not contain any learnable parameters, whereas the position embedding restricts the maximum length of input sequences. It is thus desirable to design a new position layer that contains learnable parameters to adjust to different datasets and different architectures. At the same time, we would also like the encodings to extrapolate in accordance with the variable length of inputs. In our proposed solution, we borrow from the recent Neural ODE approach, which may be viewed as a versatile continuous version of a ResNet. This model is capable of modeling many kinds of dynamical systems. We model the evolution of encoded results along position index by such a dynamical system, thereby overcoming the above limitations of existing methods. We evaluate our new position layers on a variety of neural machine translation and language understanding tasks, the experimental results show consistent improvements over the baselines. 
 The collection and examination of social media has become a useful mechanism for studying the mental activity and behavior tendencies of users. Through the analysis of collected Twitter data, models were developed for classifying drug-related tweets. Using topic pertaining keywords, such as slang and methods of drug consumption, a set of tweets was generated. Potential candidates were then preprocessed resulting in a dataset of 3,696,150 rows. The classification power of multiple methods was compared including support vector machines , XGBoost, and convolutional neural network  based classifiers. Rather than simple feature or attribute analysis, a deep learning approach was implemented to screen and analyze the tweets' semantic meaning. The two CNN-based classifiers presented the best result when compared against other methodologies. The first was trained with 2,661 manually labeled samples, while the other included synthetically generated tweets culminating in 12,142 samples. The accuracy scores were 76.35\% and 82.31\%, with an AUC of 0.90 and 0.91. Additionally, association rule mining showed that commonly mentioned drugs had a level of correspondence with frequently used illicit substances, proving the practical usefulness of the system. Lastly, the synthetically generated set provided increased scores, improving the classification capability and proving the worth of this methodology. 
  As we navigate our cultural environment, we learn cultural biases, like those around gender, social class, health, and body weight. It is unclear, however, exactly how public culture becomes private culture. In this paper, we provide a theoretical account of such cultural learning. We propose that neural word embeddings provide a parsimonious and cognitively plausible model of the representations learned from natural language. Using neural word embeddings, we extract cultural schemata about body weight from New York Times articles. We identify several cultural schemata that link obesity to gender, immorality, poor health, and low socioeconomic class. Such schemata may be subtly but pervasively activated in public culture; thus, language can chronically reproduce biases. Our findings reinforce ongoing concerns that machine learning can also encode, and reproduce, harmful human biases.  
 The task of Knowledge Graph Completion~ aims to automatically infer the missing fact information in Knowledge Graph .  %Based on  known fact information in KG, various methods have been developed in the literature by adopting different technical solutions.  In this paper, we take a new perspective that aims to  leverage rich user-item interaction data  for improving the KGC task. Our work is inspired by the observation that many KG entities correspond to online items in application systems.  However, the two kinds of data sources have very different intrinsic characteristics, and it is likely to hurt the original  performance using simple fusion strategy.  To address this challenge, we propose a novel adversarial learning approach by leveraging user interaction data for the KGC task.  Our generator is  isolated from user interaction data, and serves to improve the performance of the discriminator.  The discriminator takes the learned useful information from user interaction data as input, and gradually enhances the evaluation capacity in order to identify the fake samples generated by the generator. To discover implicit entity preference of users, we  design an elaborate collaborative learning algorithms based on graph neural networks, which will be jointly optimized with the discriminator. Such an approach is effective to alleviate the issues about data heterogeneity and semantic complexity for the KGC task. Extensive experiments on three real-world datasets have demonstrated the effectiveness of our approach on the KGC task. The source code is publicly available at \textcolor{blue}{https://github.com/RUCAIBox/UPGAN}. 
 This paper leverages the graph-to-sequence method in neural text-to-speech , which maps the graph embedding of the input sequence to spectrograms. The graphical inputs consist of node and edge representations constructed from input texts. The encoding of these graphical inputs incorporates syntax information by a GNN encoder module. Besides, applying the encoder of GraphTTS as a graph auxiliary encoder  can analyse prosody information from the semantic structure of texts. This can remove the manual selection of reference audios process and makes prosody modelling an end-to-end procedure. Experimental analysis shows that GraphTTS outperforms the state-of-the-art sequence-to-sequence models by 0.24 in Mean Opinion Score . GAE can adjust the pause, ventilation and tones of synthesised audios automatically. This experimental conclusion may give some inspiration to researchers working on improving speech synthesis prosody. 
 %Speaker diarization is the process of determining ``who spoke when'', by partitioning an audio recording into homogeneous segments according to the speaker's identity. The most common approach to speaker diarization is clustering of speaker embeddings. However, the clustering-based approach has a number of problems; i.e.,  it is not optimized to minimize diarization errors directly,  it cannot handle speaker overlaps correctly, and  it has trouble adapting their speaker embedding models to real audio recordings with speaker overlaps. To solve these problems, we propose the End-to-End Neural Diarization , in which a neural network directly outputs speaker diarization results given a multi-speaker recording. To realize such an end-to-end model, we formulate the speaker diarization problem as a multi-label classification problem and introduce a permutation-free objective function to directly minimize diarization errors. Besides its end-to-end simplicity, the EEND method can explicitly handle speaker overlaps during training and inference. Just by feeding multi-speaker recordings with corresponding speaker segment labels, our model can be easily adapted to real conversations. We evaluated our method on simulated speech mixtures and real conversation datasets. The results showed that the EEND method outperformed the state-of-the-art x-vector clustering-based method, while it correctly handled speaker overlaps. We explored the neural network architecture for the EEND method, and found that the self-attention-based neural network was the key to achieving excellent performance. In contrast to conditioning the network only on its previous and next hidden states, as is done using bidirectional long short-term memory , self-attention is directly conditioned on all the frames. By visualizing the attention weights, we show that self-attention captures global speaker characteristics in addition to local speech activity dynamics, making it especially suitable for dealing with the speaker diarization problem.  
 In this paper we investigate the GMM-derived  features for adaptation of deep neural network  acoustic models.  The adaptation of the DNN trained on GMMD features is done through the maximum a posteriori  adaptation of the auxiliary GMM model used for GMMD feature extraction. We explore fusion of the adapted GMMD features with conventional features, such as bottleneck and MFCC features, in two different neural network architectures: DNN and time-delay neural network . We analyze and compare different types of adaptation techniques such as i-vectors and feature-space adaptation techniques based on maximum likelihood linear regression  with the proposed adaptation approach, and explore their complementarity using various types of fusion such as feature level, posterior level, lattice level and others in order to discover the best possible way of combination. Experimental results on the TED-LIUM corpus show that the proposed adaptation technique can be effectively integrated into DNN and TDNN setups at different levels and provide additional gain in recognition performance: up to $6\%$ of relative word error rate reduction  over the strong feature-space adaptation techniques based on maximum likelihood linear regression  speaker adapted DNN baseline, and up to $18\%$ of relative WERR in comparison with a speaker independent  DNN baseline model, trained on conventional features.  For TDNN models the proposed approach achieves up to $26\%$ of relative WERR in comparison with a SI baseline,  and up $13\%$  in comparison with the model adapted by using i-vectors.  The analysis of the adapted GMMD features from various points of view demonstrates their effectiveness at different levels. 
 In recent years, the amount of Cyber Security data generated in the form of unstructured texts, for example, social media resources, blogs, articles, and so on has exceptionally increased. Named Entity Recognition  is an initial step towards converting this unstructured data into structured data which can be used by a lot of applications. The existing methods on NER for Cyber Security data are based on rules and linguistic characteristics. A Deep Learning  based approach embedded with Conditional Random Fields  is proposed in this paper. Several DL architectures are evaluated to find the most optimal architecture. The combination of Bidirectional Gated Recurrent Unit , Convolutional Neural Network , and CRF performed better compared to various other DL frameworks on a publicly available benchmark dataset. This may be due to the reason that the bidirectional structures preserve the features related to the future and previous words in a sequence.   
 In recent days, the amount of Cyber Security text data shared via social media resources mainly Twitter has increased. An accurate analysis of this data can help to develop cyber threat situational awareness framework for a cyber threat. This work proposes a deep learning based approach for tweet data analysis. To convert the tweets into numerical representations, various text representations are employed. These features are feed into deep learning architecture for optimal feature extraction as well as classification. Various hyperparameter tuning approaches are used for identifying optimal text representation method as well as optimal network parameters and network structures for deep learning models. For comparative analysis, the classical text representation method with classical machine learning algorithm is employed. From the detailed analysis of experiments, we found that the deep learning architecture with advanced text representation methods performed better than the classical text representation and classical machine learning algorithms. The primary reason for this is that the advanced text representation methods have the capability to learn sequential properties which exist among the textual data and deep learning architectures learns the optimal features along with decreasing the feature size.   
   Translation models based on hierarchical phrase-based statistical machine translation  have shown better performances than the non-hierarchical phrase-based counterparts for some language pairs. The standard approach to HSMT learns and apply a synchronous context-free grammar with a single non-terminal. The hypothesis behind the grammar refinement algorithm presented in this work is that this single non-terminal is overloaded, and insufficiently discriminative, and therefore, an adequate split of it into more specialised symbols could lead to improved models. This paper presents a method to learn synchronous context-free grammars with a huge number of initial non-terminals, which are then grouped via a clustering algorithm. Our experiments show that the resulting smaller set of non-terminals correctly capture the contextual information that makes it possible to statistically significantly improve the BLEU score of the standard HSMT approach. 
   We consider direct modeling of underlying stock value movement sequences over time in the news-driven stock movement prediction.   A recurrent state transition model is constructed, which better captures a gradual process of stock movement continuously by modeling the correlation between past and future price movements.   By separating the effects of news and noise, a noisy random factor is also explicitly fitted based on the recurrent states.   Results show that the proposed model outperforms strong baselines.   Thanks to the use of attention over news events, our model is also more explainable.   To our knowledge, we are the first to explicitly model both events and noise over a fundamental stock value state for news-driven stock movement prediction. 
  The training of deep-learning-based text classification models relies heavily on a huge amount of annotation data, which is difficult to obtain. When the labeled data is scarce, models tend to struggle to achieve satisfactory performance. However, human beings can distinguish new categories very efficiently with few examples. This is mainly due to the fact that human beings can leverage knowledge obtained from relevant tasks. Inspired by human intelligence, we propose to introduce external knowledge into few-shot learning to imitate human knowledge. A novel parameter generator network is investigated to this end, which is able to use the external knowledge to generate relation network parameters. Metrics can be transferred among tasks when equipped with these generated parameters, so that similar tasks use similar metrics while different tasks use different metrics. Through experiments, we demonstrate that our method outperforms the state-of-the-art few-shot text classification models. 
   Aspect-based sentiment analysis  mainly involves three subtasks: aspect term extraction, opinion term extraction and aspect-level sentiment classification, which are typically handled separately or  jointly. However, the semantic interrelationships among all the three subtasks are not well exploited in previous approaches, which restricts their performance. Additionally, the linguistic knowledge from document-level labeled sentiment corpora is usually used in a coarse way for the ABSA. To address these issues, we propose a novel Iterative Knowledge Transfer Network  for the end-to-end ABSA. For one thing, to fully exploit the semantic correlations among the three aspect-level subtasks for mutual promotion, the IKTN transfers the task-specific knowledge from any two of the three subtasks to another one by leveraging a specially-designed routing algorithm, that is, any two of the three subtasks will help the third one. Besides, the IKTN discriminately transfers the document-level linguistic knowledge, i.e., domain-specific and sentiment-related knowledge, to the aspect-level subtasks to benefit the corresponding ones. Experimental results on three benchmark datasets demonstrate the effectiveness of our approach, which significantly outperforms existing state-of-the-art methods.   %\footnote{We will release our code on Github upon acceptance.} 
   The NOESIS II challenge, as the Track 2 of the 8th Dialogue System Technology Challenges , is the extension of DSTC 7.   This track incorporates new elements that are vital for the creation of a deployed task-oriented dialogue system.   %Three dialogue challenges are explored this year: next utterance selection, task success, and conversation disentanglement.   This paper describes our systems that are evaluated on all subtasks under this challenge.   We study the problem of employing pre-trained attention-based network for multi-turn dialogue systems.   Meanwhile, several adaptation methods are proposed to adapt the pre-trained language models for multi-turn dialogue systems, in order to keep the intrinsic property of dialogue systems.   In the released evaluation results of Track 2 of DSTC 8, our proposed models ranked fourth in subtask 1, third in subtask 2, and first in subtask 3 and subtask 4 respectively. 
 We study multi-turn response generation for open-domain dialogues. The existing state-of-the-art addresses the problem with deep neural architectures. While these models improved response quality, their complexity also hinders the application of the models in real systems.  In this work, we pursue a model that has a simple structure yet can effectively leverage conversation contexts for response generation. To this end, we propose four auxiliary tasks including word order recovery, utterance order recovery, masked word recovery, and masked utterance recovery, and optimize the objectives of these tasks together with maximizing the likelihood of generation. By this means, the auxiliary tasks that relate to context understanding can guide the learning of the generation model to achieve a better local optimum. Empirical studies with three benchmarks indicate that our model can significantly outperform state-of-the-art generation models in terms of response quality on both automatic evaluation and human judgment, and at the same time enjoys a much faster decoding process.    
   Current summarization systems only produce plain, factual headlines, but do not meet the practical needs of creating memorable titles to increase exposure. We propose a new task, Stylistic Headline Generation , to enrich the headlines with three style options , in order to attract more readers. With no style-specific article-headline pair , our method TitleStylist generates style-specific headlines by combining the summarization and reconstruction tasks into a multitasking framework. We also introduced a novel parameter sharing scheme to further disentangle the style from the text. Through both automatic and human evaluation, we demonstrate that TitleStylist can generate relevant, fluent headlines with three target styles: humor, romance, and .}  
 % please re-write according to comments from Stanford students %Graph Neural Networks  have shown strong ability to learn non-Euclidean relational information and to reason over long range of context.  Recently Graph Neural Network  has been applied successfully to various NLP tasks that require reasoning, such as multi-hop machine reading comprehension. %Existing GNNs assumes the initial node features on the graph are vectors of a fixed dimension. In this paper, we consider a novel case where reasoning is needed over graphs built from sequences, i.e. graph nodes with sequence data. Existing GNN models fulfill this goal by first summarizing the node sequences into fixed-dimensional vectors, then applying GNN on these vectors. To avoid information loss inherent in the early summarization and make sequential labeling tasks on GNN output feasible, we propose a new type of GNN called Graph Sequential Network , which features a new message passing algorithm based on co-attention between a node and each of its neighbors. We validate the proposed GSN on two NLP tasks: interpretable multi-hop reading comprehension on HotpotQA and graph based fact verification on FEVER. Both tasks require reasoning over multiple documents or sentences. Our experimental results show that the proposed GSN attains better performance than the standard GNN based methods. 
 We introduce Talk to Papers\footnote{\url{https://ask.soco.ai}}, which exploits the recent open-domain question answering  techniques to improve the current experience of academic search. It's designed to enable researchers to use natural language queries to find precise answers and extract insights from a massive amount of academic papers. We present a large improvement over classic search engine baseline on several standard QA datasets, and provide the community a collaborative data collection tool to curate the first natural language processing research QA dataset via a community effort. 
 With the abundance of automatic meeting transcripts, meeting summarization is of great interest to both participants and other parties. Traditional methods of summarizing meetings depend on complex multi-step pipelines that make joint optimization intractable. Meanwhile, there are a handful of deep neural models for text summarization and dialogue systems. However, the semantic structure and styles of meeting transcripts are quite different from articles and conversations. In this paper, we propose a novel abstractive summary network that adapts to the meeting scenario. We design a hierarchical structure to accommodate long meeting transcripts and a role vector to depict the difference among speakers. Furthermore, due to the inadequacy of meeting summary data, we pretrain the model on large-scale news summary data. Empirical results show that our model outperforms previous approaches in both automatic metrics and human evaluation. For example, on ICSI dataset, the ROUGE-1 score increases from 34.66\% to 46.28\%.%\footnote{Code will be released on publication.}  
   We explore ways of incorporating bilingual dictionaries to enable semi-supervised neural machine translation. Conventional back-translation methods have shown success in leveraging target side monolingual data. However, since the quality of back-translation models is tied to the size of the available parallel corpora, this could adversely impact the synthetically generated sentences in a low resource setting. We propose a simple data augmentation technique to address both this shortcoming. We incorporate widely available bilingual dictionaries that yield word-by-word translations to generate synthetic sentences. This automatically expands the vocabulary of the model while maintaining high quality content.  Our method shows an appreciable improvement in performance over strong baselines. 
 Exploiting a common language as an auxiliary for better translation has a long tradition in machine translation and lets supervised learning-based machine translation enjoy the enhancement delivered by the well-used pivot language in the absence of a source language to target language parallel corpus. The rise of unsupervised neural machine translation  almost completely relieves the parallel corpus curse, though UNMT is still subject to unsatisfactory performance due to the vagueness of the clues available for its core back-translation training.  Further enriching the idea of pivot translation by extending the use of parallel corpora beyond the source-target paradigm, we propose a new reference language-based framework for UNMT, RUNMT, in which the reference language only shares a parallel corpus with the source, but this corpus still indicates a signal clear enough to help the reconstruction training of UNMT through a proposed reference agreement mechanism. Experimental results show that our methods improve the quality of UNMT over that of a strong baseline that uses only one auxiliary language, demonstrating the usefulness of the proposed reference language-based UNMT and establishing a good start for the community.  
 %   Generalization to unseen instances is our eternal pursuit for all data-driven models. Statistical learning theory provides error bounds for models with rigorous constraints which can hardly be applied to realistic situations like neural machine translation. % %   Moreover, theory focuses on average-case guarantee instead of worst-case, which could rise obstacles at deployment time due to safety consideration. %   In this paper, we alleviate this gap between theory and practice for the task of machine translation through principled fine-grained generalization study on every previously unseen instance. We propose to detect generalization barriers within an unseen instance, i.e. the sub-structures of the source input. A principled definition of generalization barriers is given to guide the design of an approximate definition, based on which we can tractably evaluate the detected barriers. This definition also naturally induces a detection algorithm when we have access to the golden reference. Then, a simple and efficient unsupervised detection method is proposed and compared with heuristic baselines under the evaluation. %   To understand the what and why questions of the detected barriers, we conduct descriptive analyses through several linguistic dimensions and causal analyses in terms of the model and the training corpus.   %% guanlin's original version % Generalization to unseen instances is our % eternal pursuit for all data-driven models. % However, for realistic task like machine translation, % traditional average sense generalization measure provides % poor understanding of the fine-grained generalization ability % of the model especially under trustworthy consideration. % In this paper, we attempt to better understand % the model's generalization ability % by identifying a pervasive phenomenon named % generalization barriers which are sub-structures of any unseen % input sentence % that cause the degradation of generalization. % We give exact and approximate definitions % of generalization barriers and investigate three simple methods % for their detection based on the search-aware estimated word risks % through conterfactual generation. % We then conduct extensive analyses on those detected generalization % barrier words on the Zh$\Leftrightarrow$En % NIST benchmark from various perspectives. % Potential usage of the detected barrier words % are discussed as well.  Generalization to unseen instances is our eternal pursuit for all data-driven models. However, for realistic task like machine translation, the traditional approach measuring generalization in an average sense provides poor understanding for the fine-grained generalization ability. % especially under trustworthy consideration. As a remedy, this paper attempts to identify and understand generalization barrier words within an unseen input sentence that cause the degradation of fine-grained generalization. We propose a principled definition of generalization barrier words and a modified version which is tractable in computation. Based on the modified one, we propose three simple methods for barrier detection by the search-aware risk estimation through counterfactual generation. We then conduct extensive analyses on those detected generalization barrier words on both Zh$\Leftrightarrow$En NIST benchmarks from various perspectives. Potential usage of the detected barrier words is also discussed.  
 Despite the great success of NMT, there still remains a severe challenge: it is hard to interpret the internal dynamics during its training process.  In this paper we propose to understand learning dynamics of NMT by using a recent proposed technique named Loss Change Allocation ~. As LCA requires calculating the gradient on an entire dataset for each update, we instead present an approximate to put it into practice in NMT scenario. %motivated by the lesson from sgd. Our simulated experiment shows that such approximate calculation is efficient and is empirically proved to deliver consistent results to the brute-force implementation. In particular, extensive experiments on two standard translation benchmark datasets reveal some valuable findings. 
  We cast neural machine translation  as a classification task in an autoregressive setting and analyze the limitations of both classification and autoregression components. Classifiers are known to perform better with balanced class distributions during training. Since the Zipfian nature of languages causes imbalanced classes, we explore its effect on NMT.  We analyze the effect of various vocabulary sizes on NMT performance on multiple languages with many data sizes, and reveal an explanation for why certain vocabulary sizes are better than others.\footnote{Tools, configurations, system outputs, and analyses are at {https://github.com/thammegowda/005-nmt-imbalance}}  
 We propose the new problem of learning to recover reasoning chains from weakly supervised signals, i.e., the question-answer pairs. We propose a cooperative game approach to deal with this problem, in which how the evidence passages are selected and how the selected passages are connected are handled by two models that cooperate to select the most confident chains from a large set of candidates . For evaluation, we created benchmarks based on two multi-hop QA datasets, HotpotQA and MedHop; and hand-labeled reasoning chains for the latter.  The experimental results demonstrate the effectiveness of our proposed approach. 
 		Response selection plays a vital role in building retrieval-based conversation systems. Despite that response selection is naturally a learning-to-rank problem, most prior works take a point-wise view and train binary classifiers for this task: each response candidate is labeled either relevant  or irrelevant . On the one hand, this formalization can be sub-optimal due to its ignorance of the diversity of response quality. On the other hand, annotating grayscale data for learning-to-rank can be prohibitively expensive and challenging. In this work, we show that grayscale data can be automatically constructed without human effort. Our method employs off-the-shelf response retrieval models and response generation models as automatic grayscale data generators. With the constructed grayscale data, we propose multi-level ranking objectives for training, which can  teach a matching model to capture more fine-grained context-response relevance difference and  reduce the train-test discrepancy in terms of distractor strength. Our method is simple, effective, and universal. Experiments on three benchmark datasets and four state-of-the-art matching models show that the proposed approach brings significant and consistent performance improvements. 	
 Open relation extraction is the task of extracting open-domain relation facts from natural language sentences. Existing works either utilize heuristics or distant-supervised annotations to train a supervised classifier over pre-defined relations, or adopt unsupervised methods with additional assumptions that have less discriminative power. In this work, we propose a self-supervised framework named {\modelname}, which exploits weak, self-supervised signals by leveraging large pretrained language model for adaptive clustering on contextualized relational features, and bootstraps the self-supervised signals by improving contextualized features in relation classification. Experimental results on three datasets show the effectiveness and robustness of {\modelname} on open-domain Relation Extraction when comparing with competitive baselines. Source code is available\footnote{\url{https://github.com/THU-BPM/SelfORE}\\\phantom{00} $^\dagger$Corresponding Authors.}. 
  We explore the utilities of explicit negative examples in training neural language models.   Negative examples here are incorrect words in a sentence, such as {.  Neural language models are commonly trained only on positive examples, a set of sentences in the training data, but recent studies suggest that the models trained in this way are not capable of robustly handling complex syntactic constructions, such as long-distance agreement.  In this paper, we first demonstrate that appropriately using negative examples about particular constructions  will boost the model's robustness on them in English, with a negligible loss of perplexity.  The key to our success is an additional margin loss between the log-likelihoods of a correct word and an incorrect word.  We then provide a detailed analysis of the trained models.  One of our findings is the difficulty of object-relative clauses for RNNs.  We find that even with our direct learning signals the models still suffer from resolving agreement across an object-relative clause.  Augmentation of training sentences involving the constructions somewhat helps, but the accuracy still does not reach the level of subject-relative clauses.  Although not directly cognitively appealing, our method can be a tool to analyze the true architectural limitation of neural models on challenging linguistic constructions. 
 Existing data augmentation approaches for neural machine translation  have predominantly relied on back-translating in-domain  monolingual corpora. These methods suffer from issues associated with a domain information gap, which leads to translation errors for low frequency and out-of-vocabulary terminology. This paper proposes a dictionary-based data augmentation  method for cross-domain NMT. DDA synthesizes a domain-specific dictionary with general domain corpora to automatically generate a large-scale pseudo-IND parallel corpus. The generated pseudo-IND data can be used to enhance a general domain trained baseline. The experiments show that the DDA-enhanced NMT models demonstrate consistent significant improvements, outperforming the baseline models by 3.75-11.53 BLEU. The proposed method is also able to further improve the performance of the back-translation based and IND-finetuned NMT models. The improvement is associated with the enhanced domain coverage produced by DDA. 
 	%The development of automatic summarization systems is constrained by the limited paired training data. 	In this paper, we propose a method for automatically constructing a passage-to-summary dataset by mining the Wikipedia page revision histories. 	%In particular, the method mines the article passages and the introduction sentences which are added to the pages simultaneously. 	In particular, the method mines the main body passages  and the introduction sentences which are added to the pages simultaneously. 	The constructed dataset contains more than one hundred thousand passage-summary pairs. 	The quality analysis shows that it is promising that the dataset can be used as a training and validation set for passage summarization. 	We validate and analyze the performance of various summarization systems on the proposed dataset. 	The dataset will be available online at \url{https://res.qyzhou.me/}. 	 
 Current state-of-the-art neural dialogue models learn from human conversations following the data-driven paradigm. As such, a reliable training corpus is the crux of building a robust and well-behaved dialogue model. However, due to the open-ended nature of human conversations, the quality of user-generated training data varies greatly, and effective training samples are typically insufficient while noisy samples frequently appear. This impedes the learning of those data-driven neural dialogue models. Therefore, effective dialogue learning requires not only more reliable learning samples, but also fewer noisy samples. In this paper, we propose a data manipulation framework to proactively reshape the data distribution towards reliable samples by augmenting and highlighting effective learning samples as well as reducing the effect of inefficient samples simultaneously. In particular, the data manipulation model selectively augments the training samples and assigns an importance weight to each instance to reform the training data.  Note that, the proposed data manipulation framework is fully data-driven and learnable. It not only manipulates training samples to optimize the dialogue generation model, but also learns to increase its manipulation skills through gradient descent with validation samples. Extensive experiments show that our framework can improve the dialogue generation performance with respect to various automatic evaluation metrics and human judgments. 
 %Natural language inference  is an increasingly important task for natural language understanding, which requires one to infer whether one sentence entails another. We assess whether systems trained under a common-sense NLI framework can generalize the notion of textual entailment to pragmatic inferences about a speaker's communicative intensions, which are needed for implicatures and presuppositions. We create an Implicature and Presupposition diagnostic dataset , consisting of 32,000 semi-automatically generated sentence pairs. Our resource can be seamlessly integrated into classic three-way NLI modeling efforts. %We train three model  on NLI and test on \DATASET.  %We find that BERT learns to make pragmatic inferences. BERT reliably treats implicatures triggered by ``some" and numerals as entailments. For some presupposition triggers such as , BERT reliably recognizes the presupposition as an entailment even when the trigger is embedded under an operator that cancels classical entailments, such as negation. We conclude that NLI training does encourage models to learn some pragmatic reasoning.   %We find that models fail to understand entailment-canceling operators , and do generally poorly when embedded.      Natural language inference  is an increasingly important task for natural language understanding, which requires one to infer whether a sentence entails another. However, the ability of NLI models to make pragmatic inferences remains understudied.  We create an Implicature and Presupposition diagnostic dataset , consisting of $>$25k semi-automatically generated sentence pairs illustrating well-studied pragmatic inference types. We use \DATASET to evaluate whether BERT, InferSent, and BOW NLI models trained on MultiNLI  learn to make pragmatic inferences. Although MultiNLI appears to contain very few pairs illustrating these inference types, we find that BERT learns to draw pragmatic inferences. It reliably treats scalar implicatures triggered by ``some" as entailments. For some presupposition triggers like , BERT reliably recognizes the presupposition as an entailment, even when the trigger is embedded under an entailment canceling operator like negation. BOW and InferSent show weaker evidence of pragmatic reasoning. We conclude that NLI training encourages models to learn some, but not all, pragmatic inferences. 
 %   This document contains the instructions for preparing a paper submitted %   to COLING-2020 or accepted for publication in its proceedings. The document itself %   conforms to its own specifications, and is therefore an example of %   what your manuscript should look like. These instructions should be %   used for both papers submitted for review and for final versions of %   accepted papers. Authors are asked to conform to all the directions %   reported in this document. % 
 Self-supervised neural machine translation  jointly learns to identify and select suitable training data from comparable  corpora and to translate, in a way that the two tasks support each other in a virtuous circle. In this study, we provide an in-depth analysis of the sampling choices the \ssnmt\ model makes during training. We show how, without it having been told to do so, the model self-selects samples of increasing \Ni complexity and \Nii task-relevance in combination with \Niii performing a denoising curriculum. We observe that the dynamics of the mutual-supervision signals of both system internal representation types are vital for the extraction and translation performance.  We show that in terms of the Gunning-Fog Readability index, \ssnmt\ starts extracting and learning from Wikipedia data suitable for high school students and quickly moves towards content suitable for first year undergraduate students. 
     Online Continual Learning  studies learning over a continuous     data stream without observing any single example more than once, a setting     that is closer to the experience of humans and systems that must learn     ``on-the-wild''.     Yet, commonly available benchmarks are far from these real world     conditions, because they explicitly signal different tasks, lack latent     similarity structure or assume temporal independence between different     examples.     Here, we propose a new benchmark for OCL based on language modelling in     which input alternates between different languages and domains without any     explicit delimitation.     Additionally, we propose new metrics to study catastrophic forgetting in     this setting and evaluate multiple baseline models based on compositions of     experts.     Finally, we introduce a simple gating technique that learns the latent     similarities between different inputs, improving the performance of a     Products of Experts model. 
 Dialogue state tracking  aims at estimating the current dialogue state given all the preceding conversation. For multi-domain DST, the data sparsity problem is a major obstacle due to increased numbers of state candidates and dialogue lengths. To encode the dialogue context efficiently, we utilize the previous dialogue state  and the current dialogue utterance as the input for DST. To consider relations among different domain-slots, the schema graph involving prior knowledge is exploited. In this paper, a novel context and schema fusion network is proposed to encode the dialogue context and schema graph by using internal and external attention mechanisms. Experiment results show that our approach can outperform strong baselines, and the previous state-of-the-art method  can also be improved by our proposed schema graph.  %Experiment results show that our approach can obtain new state-of-the-art performance of the open-vocabulary DST on both MultiWOZ 2.0 and MultiWOZ 2.1 benchmarks.  %Exist- ing approaches generally predict the value for each slot inde- pendently and do not consider slot relations, which may ag- gravate the data sparsity problem.  
 While models have reached superhuman performance on popular question answering  datasets such as SQuAD, they have yet to outperform humans on the task of question answering itself. In this paper, we investigate if models are learning reading comprehension from QA datasets by evaluating BERT-based models across five datasets. We evaluate models on their generalizability to out-of-domain examples, responses to missing or incorrect data, and ability to handle question variations. We find that no single dataset is robust to all of our experiments and identify shortcomings in both datasets and evaluation methods. Following our analysis, we make recommendations for building future QA datasets that better evaluate the task of question answering through reading comprehension. We also release  code to convert QA datasets to a shared format for easier experimentation at \url{https://github.com/amazon-research/qa-dataset-converter}. 
 Attention mechanism plays a dominant role in the sequence generation models and has been used to improve the performance of machine translation and abstractive text summarization.  Different from neural machine translation, in the task of text summarization, salience estimation for words, phrases or sentences is a critical component, since the output summary is a distillation of the input text.    Although the typical attention mechanism can conduct text fragment selection from the input text conditioned on the decoder states, there is still a gap to conduct direct and effective salience detection. To bring back direct salience estimation for summarization with neural networks, we propose a Multi-Attention Learning framework which contains two new attention learning components for salience estimation: supervised attention learning and unsupervised attention learning. We regard the attention weights as the salience information, which means that the semantic units with large attention value will be more important.  The context information obtained based on the estimated salience is incorporated with the typical attention mechanism in the decoder to conduct summary generation.  Extensive experiments on some benchmark datasets in different languages demonstrate the effectiveness of the proposed framework for the task of abstractive summarization. 
 Abstract. Deep learning based models have surpassed classical machine learning based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this paper, we provide a comprehensive review of more than 150 deep learning based models for text classification developed in recent years, and discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification.  Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and discuss future research directions. 
  Training large language representation models has become a standard in the natural language processing community. This allows for fine tuning on any number of specific tasks, however, these large high capacity models can continue to train on domain specific unlabeled data to make initialization even more robust for supervised tasks. We demonstrate that in practice these pre-trained models present performance deterioration in the form of catastrophic forgetting when evaluated on tasks from a general domain such as GLUE. In this work we propose CALM, Continuous Adaptive Learning for Language Modeling: techniques to render models which retain knowledge across multiple domains. With these methods, we are able to reduce the performance gap across supervised tasks introduced by task specific models which we demonstrate using a continual learning setting in biomedical and clinical domains.  % Training large language representation models has become a standard in the natural language processing community. % This allows for fine tuning on any number of specific tasks,  % %  % however, these large high capacity models can continue to train on domain specific unlabeled data to make the initialization even more robust. % % Such domains include clinical and bio-medical data which have proven to yield state-of-the-art results in their respective domains. % We demonstrate that in practice training on domain specific data presents deterioration in model performance in the form of catastrophic forgetting when evaluated on the GLUE benchmark.  % % Our work studies several mitigation techniques to render a model which retains knowledge across multiple domains.  % In this work we propose incorporating several continual learning techniques to render models which retain knowledge across multiple domains.  % % \parrycomment{while performing well on new domains} % %  % With these methods we are able to reduce the performance gap introduced by task specific models which we demonstrate using a continual learning setting in the biomedical domains. 
 	In Transformer-based neural machine translation , the positional encoding mechanism helps the self-attention networks to learn the source representation with order dependency, which makes the Transformer-based NMT achieve state-of-the-art results for various translation tasks. 	However, Transformer-based NMT only adds representations of positions sequentially to word vectors in the input sentence and does not explicitly consider reordering information in this sentence. 	In this paper, we first empirically investigate the relationship between source reordering information and translation performance. 	The empirical findings show that the source input with the target order learned from the bilingual parallel dataset can substantially improve translation performance. 	Thus, we propose a novel reordering method to explicitly model this reordering information for the Transformer-based NMT. 	The empirical results on the WMT14 English-to-German, WAT ASPEC Japanese-to-English, and WMT17 Chinese-to-English translation tasks show the effectiveness of the proposed approach. 
 Fine-tuning pre-trained generative language models to down-stream language generation tasks has shown promising results. % However, this comes with the cost of having a single, large model for each task, which is not ideal in low-memory/power scenarios . %  In this paper, we propose an effective way to fine-tune multiple down-stream generation tasks simultaneously using a single, large pre-trained model.  % The experiments on five diverse language generation tasks show that by just using an additional 2-3\% parameters for each task, our model can maintain or even improve the performance of fine-tuning the whole model}.   
   There are several approaches for improving neural machine translation for low-resource languages:   Monolingual data can be exploited via pretraining or data augmentation;   Parallel corpora on related language pairs can be used via parameter sharing or transfer learning in multilingual models;   Subword segmentation and regularization techniques can be applied to ensure high coverage of the vocabulary.   We review these approaches in the context of an asymmetric-resource one-to-many translation task,   in which the pair of target languages are related,   with one being a very low-resource and the other a higher-resource language.   We test various methods on three artificially restricted translation tasks---English to Estonian  and Finnish , English to Slovak and Czech, English to Danish and Swedish---and one real-world task, Norwegian to North S璋﹎i and Finnish.   The experiments show positive effects especially for scheduled multi-task learning, denoising autoencoder, and subword sampling. % Include keywords, PACS and mathematical subject classification numbers as needed.  % \PACS{PACS code1 \and PACS code2 \and more} %  
 In this paper, we propose a neural architecture and a set of training methods for ordering events by predicting temporal relations. Our proposed models receive a pair of events within a span of text as input and they identify temporal relations  between them. Given that a key challenge with this task is the scarcity of annotated data, our models rely on either pretrained representations , transfer and multi-task  learning , and self-training techniques. Experiments on the MATRES dataset of English documents establish a new state-of-the-art on this task.  % %KM - Once results are in, would be good to say here which approach is better. 
 Traditionally, industry solutions for building a task-oriented dialog system have relied on helping dialog authors define rule-based dialog managers, represented as dialog flows. While dialog flows are intuitively interpretable and good for simple scenarios, they fall short of performance in terms of the flexibility needed to handle complex dialogs. On the other hand, purely machine-learned models can handle complex dialogs, but they are considered to be black boxes and require large amounts of training data.  In this demonstration, we showcase , a machine teaching tool for building dialog managers. It combines the best of both approaches by  enabling dialog authors to create a dialog flow using familiar tools,  converting the dialog flow into a parametric model , and allowing dialog authors to improve the dialog manager  over time by leveraging user-system dialog logs as training data through a machine teaching interface. 
     This paper introduces and evaluates two novel Hierarchical Attention Network models  - i) Hierarchical Pruned Attention Networks, which remove the irrelevant words and sentences from the classification process in order to reduce potential noise in the document classification accuracy and ii) Hierarchical Sparsemax Attention Networks, which replace the Softmax function used in the attention mechanism with the Sparsemax , capable of better handling importance distributions where a lot of words or sentences have very low probabilities. Our empirical evaluation on the IMDB Review for sentiment analysis datasets shows both approaches to be able to match the results obtained by the current state-of-the-art . All our source code is made available at \url{https://github.com/jmribeiro/dsl-project}. 
 	Unsupervised neural machine translation  that relies solely on massive monolingual corpora has achieved remarkable results in several translation tasks.  However, in real-world scenarios, massive monolingual corpora do not exist for some extremely low-resource languages such as Estonian, and UNMT systems usually perform poorly when  there is not an adequate training corpus for one language.  In this paper, we first define and analyze the unbalanced training data scenario for UNMT. Based on this scenario, we propose UNMT self-training mechanisms to train a robust UNMT system and improve its performance in this case. Experimental results on several language pairs show that the proposed methods substantially outperform conventional UNMT systems.  
 Text generation has made significant advances in the last few years. Yet, evaluation metrics have lagged behind, as the most popular choices  may correlate poorly with human judgments. We propose \BLEURT, a learned evaluation metric based on BERT that can model human judgments with a few thousand possibly biased training examples. A key aspect of our approach is a novel pre-training scheme that uses millions of synthetic examples to help the model generalize. \BLEURT{} provides state-of-the-art results on the last three years of the WMT Metrics shared task and the WebNLG Competition dataset. In contrast to a vanilla BERT-based approach, it yields superior results even when the training data is scarce and out-of-distribution. 
 Both human and machine translation play a central role in cross-lingual transfer learning: many multilingual datasets have been created through professional translation services, and using machine translation to translate either the test set or the training set is a widely used transfer technique. In this paper, we show that such translation process can introduce subtle artifacts that have a notable impact in existing cross-lingual models. For instance, in natural language inference, translating the premise and the hypothesis independently can reduce the lexical overlap between them, which current models are highly sensitive to. We show that some previous findings in cross-lingual transfer learning need to be reconsidered in the light of this phenomenon. Based on the gained insights, we also improve the state-of-the-art in XNLI for the translate-test and zero-shot approaches by 4.3 and 2.8 points, respectively. 
 Humans  carry   ~, or propositional beliefs about generic concepts. Such  associations are crucial for  understanding natural language. We construct a diagnostic set of word prediction prompts   to evaluate  whether recent neural contextualized language models trained on large text corpora capture STAs. Our prompts are based on human responses in a psychological study of conceptual associations. We find  models to be profoundly effective at retrieving concepts given associated properties. Our results demonstrate empirical evidence that stereotypic conceptual representations are captured in neural models  derived from semi-supervised linguistic exposure.  Keywords:  language models; deep neural networks; concept representations; norms; semantics 
 Neural Machine Translation  methodologies have burgeoned from using simple feed-forward architectures to the state of the art; viz. BERT model. The use cases of NMT models have been broadened from just language translations to conversational agents , abstractive text summarization, image captioning, etc. which have proved to be a gem in their respective applications.  This paper aims to study the major trends in Neural Machine Translation, the state of the art models in the domain and a high level comparison between them. 
 With the advent of powerful neural language models over the last few years, research attention has increasingly focused on what aspects of language they represent that make them so successful. Several testing methodologies have been developed to probe models' syntactic representations. One popular method for determining a model's ability to induce syntactic structure trains a model on strings generated according to a template then tests the model's ability to distinguish such strings from superficially similar ones with different syntax. We illustrate a fundamental problem with this approach by reproducing positive results from a recent paper with two non-syntactic baseline language models: an n-gram model and an LSTM model trained on scrambled inputs. 
 We present the Neural Covidex, a search engine that exploits the latest neural ranking architectures to provide information access to the COVID-19 Open Research Dataset curated by the Allen Institute for AI. This web application exists as part of a suite of tools that we have developed over the past few weeks to help domain experts tackle the ongoing global pandemic. We hope that improved information access capabilities to the scientific literature can inform evidence-based decision making and insight generation. This paper describes our initial efforts and offers a few thoughts about lessons we have learned along the way. 
 This paper focuses on how to extract opinions over each Persian sentence-level text. Deep learning models provided a new way to boost the quality of the output. However, these architectures need to feed on big annotated data as well as an accurate design. To best of our knowledge, we do not merely suffer from lack of well-annotated Persian sentiment corpus, but also a novel model to classify the Persian opinions in terms of both multiple and binary classification. So in this work, first we propose two novel deep learning architectures comprises of bidirectional LSTM and CNN. They are a part of a deep hierarchy designed precisely and also able to classify sentences in both cases. Second, we suggested three data augmentation techniques for the low-resources Persian sentiment corpus. Our comprehensive experiments on three baselines and two different neural word embedding methods show that our data augmentation methods and intended models successfully address the aims of the research. 
 Pre-training text representations has recently been shown to significantly improve the state-of-the-art in many natural language processing tasks. The central goal of pre-training is to learn text representations that are useful for subsequent tasks. However, existing approaches are optimized by minimizing a proxy objective, such as the negative log likelihood of language modeling. In this work,  we introduce a learning algorithm which directly optimizes model's ability to learn text representations for effective learning of downstream tasks. We show that there is an intrinsic connection between multi-task pre-training and model-agnostic meta-learning with a sequence of meta-train steps. The standard multi-task learning objective adopted in BERT is a special case of our learning algorithm where the depth of meta-train is zero.  We study the problem in two settings: unsupervised pre-training and supervised pre-training with different pre-training objects to verify the generality of our approach. %Furthermore, we show that our algorithm can be applied to various model architectures. % Our learning algorithm supports various base neural architectures, including recurrent-based models like ELMo  and attention-based model like BERT . %including both language modeling and clustering embeddings, automatically from unsupervised data, and run model-agnostic meta-learning over these tasks.  %Pre-trained models are applied in %We conduct experiments on the biLSTM-based architecture ELMo and transformer-based architecture BERT.  Experimental results show that our algorithm brings improvements and learns better initializations for a variety of downstream tasks. 
Machine translation  is a technique that leverages computers to translate human languages automatically. Nowadays, neural machine translation  which models direct mapping between source and target languages with deep neural networks has achieved a big breakthrough in translation performance and become the {\em de facto
 In this paper, we present \ds{}, an Arabic COVID-19 Twitter dataset that spans one year, covering the period from 27$^{th}$ of January 2020 till 31$^{st}$ of January 2021. \ds{} is the  publicly-available Arabic Twitter dataset covering COVID-19 pandemic that includes about 2.7M tweets  alongside the  of the most-popular subset of them . The propagation networks include both retweets and conversational threads . \ds{} is designed to enable research under several domains including natural language processing, information retrieval, and social computing%, among others . Preliminary analysis shows that \ds{} captures rising discussions associated with the first reported cases of the disease as they appeared in the Arab world. In addition to the source tweets and propagation networks, we also release the search queries and language-independent crawler used to collect the tweets to encourage the curation of similar datasets.  
 Knowledge graph  question generation  aims to generate natural language questions from KGs and target answers. Previous works mostly focus on a simple setting which is to generate questions from a single KG triple. In this work, we focus on a more realistic setting where we aim to generate questions from a KG subgraph and target answers. In addition, most of previous works built on either RNN-based or Transformer-based models to encode a linearized KG sugraph, which totally discards the explicit structure information of a KG subgraph. To address this issue, we propose to apply a bidirectional Graph2Seq model to encode the KG subgraph. Furthermore, we enhance our RNN decoder with node-level copying mechanism to allow directly copying node attributes from the KG subgraph to the output question. Both automatic and human evaluation results demonstrate that our model achieves new state-of-the-art scores, outperforming existing methods by a significant margin on two QG benchmarks. Experimental results also show that our QG model can consistently benefit the Question Answering  task as a mean of data augmentation. 
  This paper seeks to develop a deeper understanding of the fundamental properties of neural text generations models. The study of artifacts that emerge in machine generated text as a result of modeling choices is a nascent research area. Previously, the extent and degree to which these artifacts surface in generated text has not been well studied. In the spirit of better understanding generative text models and their artifacts, we propose the new task of distinguishing which of several variants of a given model generated a piece of text, and we conduct an extensive suite of diagnostic tests to observe whether modeling choices  leave detectable artifacts in the text they generate. Our key finding, which is backed by a rigorous set of experiments, is that such artifacts are present and that different modeling choices can be inferred by observing the generated text alone. This suggests that neural text generators may be more sensitive to various modeling choices than previously thought. 
 This document contains the instructions for preparing a manuscript for the proceedings of ACL 2020. The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like. These instructions should be used for both papers submitted for review and for final versions of accepted papers. Authors are asked to conform to all the directions reported in this document. 
 Representation learning is a critical ingredient for natural language processing systems.  Recent Transformer language models like BERT learn powerful textual representations, but these models are targeted towards token- and sentence-level training objectives and do not leverage information on inter-document relatedness, which limits their document-level representation power. For applications on scientific documents, such as classification and recommendation, the embeddings power strong performance on end tasks. We propose }  
 Many large-scale knowledge graphs are now available and ready to provide semantically structured information that is regarded as an important resource for question answering and decision support tasks. However, they are built on rigid symbolic frameworks which makes them hard to be used in other intelligent systems. We present a learning method using generative adversarial architecture designed to embed the entities and relations of the knowledge graphs into a continuous vector space. A generative network  takes two elements of a  triple as input and generates the vector representation of the missing element. A discriminative network  scores a triple to distinguish a positive triple from those generated by GN. The training goal for GN is to deceive DN to make wrong classification. When arriving at a convergence, GN recovers the training data and can be used for knowledge graph completion, while DN is trained to be a good triple classifier. Unlike few previous studies based on generative adversarial architectures, our GN is able to generate unseen instances while they just use GN to better choose negative samples  for DN. Experiments demonstrate our method can improve classical relational learning models  with a significant margin on both the link prediction and triple classification tasks. 
 Lack of specialized data makes building a multi-domain neural machine translation tool challenging. Although emerging literature dealing with low resource languages starts to show promising results, most state-of-the-art models used millions of sentences. Today, the majority of multi-domain adaptation techniques are based on complex and sophisticated architectures that are not adapted for real-world applications. So far, no scalable method is performing better than the simple yet effective mixed-finetuning, i.e finetuning a generic model with a mix of all specialized data and generic data. In this paper, we propose a new training pipeline where knowledge distillation and multiple specialized teachers allow us to efficiently finetune a model without adding new costs at inference time. Our experiments demonstrated that our training pipeline allows improving the performance of multi-domain translation over finetuning in configurations with 2, 3, and 4 domains by up to 2 points in BLEU.  
 Neural data-to-text generation models have achieved significant advancement in recent years. However, these models have two shortcomings: the generated texts tend to miss some vital information, and they often generate descriptions that are not consistent with the structured input data. To alleviate these problems, we propose a {ynamic content { for abbreviation. The NDP can utilize the previously generated text to dynamically select the appropriate entry from the given structured data. We further design a reconstruction mechanism with a novel objective function that can reconstruct the whole entry of the used data sequentially from the hidden states of the decoder, which aids the accuracy of the generated text. Empirical results show that the NDP achieves superior performance over the state-of-the-art on ROTOWIRE dataset, in terms of relation generation , content selection , content ordering  and BLEU metrics. The human evaluation result shows that the texts generated by the proposed NDP are better than the corresponding ones generated by NCP in most of time. And using the proposed reconstruction mechanism, the fidelity of the generated text can be further improved significantly. 
 Mental health is a critical issue in modern society; mental disorders could sometimes turn to suicidal ideation without effective treatment. Early detection of mental disorders and suicidal ideation from social content provides a potential way for effective social intervention. Classifying suicidal ideation and other mental disorders, however, is a challenging task as they share quite similar patterns in language usage and sentimental polarity. This paper enhances text representation with lexicon-based sentiment scores and latent topics and proposes using relation networks to detect suicidal ideation and mental disorders with related risk indicators. The relation module is further equipped with the attention mechanism to prioritize more important relational features. Through experiments on three real-world datasets, our model outperforms most of its counterparts. 
 A longstanding goal in NLP is to compute global sentence representations. Such representations would be useful for sample-efficient semi-supervised learning and controllable text generation. To learn to represent global and local information separately,  proposed to train a sequence-to-sequence model with the variational auto-encoder  objective. What precisely is encoded in these latent variables expected to capture global features? We measure which words benefit most from the latent information by decomposing the reconstruction loss per position in the sentence. Using this method, we see that VAEs are prone to memorizing the first words and the sentence length, drastically limiting their usefulness. To alleviate this, we propose variants based on bag-of-words assumptions and language model pretraining. These variants learn latents that are more global: they are more predictive of topic or sentiment labels, and their reconstructions are more faithful to the labels of the original documents. 
 Many data sets  exist parallelly in multiple languages. They all cover the same content, but the linguistic differences make it impossible to use traditional, bag-of-word-based topic models. Models have to be either single-language or suffer from a huge, but extremely sparse vocabulary. Both issues can be addressed by transfer learning. In this paper, we introduce a zero-shot cross-lingual topic model. Our model learns topics on one language , and predicts them for unseen documents in different languages . We evaluate the quality of the topic predictions for the same document in different languages. Our results show that the transferred topics are coherent and stable across languages, which suggests exciting future research directions. 
     Exponential growths of social media and micro-blogging sites not only provide platforms for empowering freedom of expressions and individual voices but also enables people to express anti-social behaviour like online harassment, cyberbullying, and hate speech. Numerous works have been proposed to utilize these data for social and anti-social behaviours analysis, document characterization, and sentiment analysis by predicting the contexts mostly for highly resourced languages such as English. However, there are languages that are under-resources, e.g., South Asian languages like Bengali, Tamil, Assamese, Telugu that lack of computational resources for the natural language processing tasks. In this paper\footnote{This paper is under review in the Journal of Natural Language Engineering.}, we provide several classification benchmarks for Bengali, an under-resourced language. We prepared three datasets of expressing hate, commonly used topics, and opinions for hate speech detection, document classification, and sentiment analysis, respectively. We built the largest Bengali word embedding models to date based on 250 million articles, which we call BengFastText. We perform three different experiments, covering document classification, sentiment analysis, and hate speech detection. We incorporate word embeddings into a Multichannel Convolutional-LSTM~ network for predicting different types of hate speech, document classification, and sentiment analysis. Experiments demonstrate that BengFastText can capture the semantics of words from respective contexts correctly. Evaluations against several baseline embedding models, e.g., Word2Vec and GloVe yield up to 92.30\%, 82.25\%, and 90.45\% F1-scores in case of document classification, sentiment analysis, and hate speech detection, respectively during 5-fold cross-validation tests. 
 Active learning for sentence understanding aims at discovering informative unlabeled data for annotation and therefore reducing the demand for labeled data.  We argue that the typical uncertainty sampling method for active learning is time-consuming and can hardly work in real-time, which may lead to ineffective sample selection.  We propose adversarial uncertainty sampling in discrete space  to retrieve informative unlabeled samples more efficiently. \method maps sentences into latent space generated by the popular pre-trained language models, and discover informative unlabeled text samples for annotation via adversarial attack.  The proposed approach is extremely efficient compared with traditional uncertainty sampling with more than 10x speedup.  Experimental results on five datasets show that \method outperforms strong baselines on effectiveness. 
  Even though BERT achieves successful performance improvements in various supervised learning tasks, applying BERT for unsupervised tasks still holds a limitation that it requires repetitive inference for computing contextual language representations. To resolve the limitation, we propose a novel deep bidirectional language model called Transformer-based Text Autoencoder . The T-TA computes contextual language representations without repetition and has benefits of the deep bidirectional architecture like BERT. In run-time experiments on CPU environments, the proposed T-TA performs over six times faster than the BERT-based model in the reranking task and twelve times faster in the semantic similarity task. Furthermore, the T-TA shows competitive or even better accuracies than those of BERT on the above tasks\footnote{Code is available at https://github.com/joongbo/tta}.  
  Despite the recent progress, little is known about the features captured by state-of-the-art neural relation extraction  models. Common methods encode the source sentence, conditioned on the entity mentions, before classifying the relation. However, the complexity of the task makes it difficult to understand how encoder architecture and supporting linguistic knowledge affect the features learned by the encoder. We introduce 14 probing tasks targeting linguistic properties relevant to RE, and we use them to study representations learned by more than 40 different encoder architecture and linguistic feature combinations trained on two datasets, TACRED and SemEval 2010 Task 8. We find that the bias induced by the architecture and the inclusion of linguistic features are clearly expressed in the probing task performance. For example, adding contextualized word representations greatly increases performance on probing tasks with a focus on named entity and part-of-speech information, and yields better results in RE. In contrast, entity masking improves RE, but considerably lowers performance on entity type related probing tasks.        
   Keyphrase generation  aims to summarize the main ideas of a document into a set of keyphrases. A new setting is recently introduced into this problem, in which, given a document, the model needs to predict a set of keyphrases and simultaneously determine the appropriate number of keyphrases to produce. Previous work in this setting employs a sequential decoding process to generate keyphrases. However, such a decoding method ignores the intrinsic hierarchical compositionality existing in the keyphrase set of a document. Moreover, previous work tends to generate duplicated keyphrases, which wastes time and computing resources. To overcome these limitations, we propose an exclusive hierarchical decoding framework that includes a hierarchical decoding process and either a soft or a hard exclusion mechanism. The hierarchical decoding process is to explicitly model the hierarchical compositionality of a keyphrase set. Both the soft and the hard exclusion mechanisms keep track of previously-predicted keyphrases within a window size to enhance the diversity of the generated keyphrases. Extensive experiments on multiple KG benchmark datasets demonstrate the effectiveness of our method to generate less duplicated and more accurate keyphrases\footnote{Our code is available at \url{https://github.com/Chen-Wang-CUHK/ExHiRD-DKG}.}. 
 Online reviews are an important source of feedback for understanding customers. In this study, we follow novel approaches that target this absence of actionable insights by classifying reviews as defect reports and requests for improvement. Unlike traditional classification methods based on expert rules, we reduce the manual labour by employing a supervised system that is capable of learning lexico-semantic patterns through genetic programming. Additionally, we experiment with a distantly-supervised SVM that makes use of noisy labels generated by patterns. Using a real-world dataset of app reviews, we show that the automatically learned patterns outperform the manually created ones, to be generated. Also the distantly-supervised SVM models are not far behind the pattern-based solutions, showing the usefulness of this approach when the amount of annotated data is limited.    
 Off-topic spoken response detection, the task aiming at predicting whether a response is off-topic for the corresponding prompt, is important for an automated speaking assessment system. %Most models have been concentrated on the seen prompts in training data, while few has been focused on the unseen prompts. In many real-world educational applications, off-topic spoken response detectors are required to achieve high recall for off-topic responses not only on seen prompts but also on prompts that are unseen during training. In this paper, we propose a novel approach for off-topic spoken response detection with high off-topic recall on both seen and unseen prompts. We introduce a new model, Gated Convolutional Bidirectional Attention-based Model , which applies bi-attention mechanism and convolutions to extract topic words of prompts and key-phrases of responses, and introduces gated unit and residual connections between major layers to better represent the relevance of responses and prompts. Moreover, a new negative sampling method is proposed to augment training data. Experiment results demonstrate that our novel approach can achieve significant improvements in detecting off-topic responses with extremely high on-topic recall, for both seen and unseen prompts. 
     Document editing has become a pervasive component of the production of information, with version control systems enabling edits to be efficiently stored and applied. In light of this, the task of learning distributed representations of edits has been recently proposed.  With this in mind, we propose a novel approach that employs variational inference to learn a continuous latent space of vector representations to capture the underlying semantic information with regard to the document editing process. We achieve this by introducing a latent variable to explicitly model the aforementioned features. This latent variable is then combined with a document representation to guide the generation of an edited version of this document. Additionally, to facilitate standardized automatic evaluation of edit representations, which has heavily relied on direct human input thus far, we also propose a suite of downstream tasks, PEER, specifically designed to measure the quality of edit representations in the context of natural language processing. 
  We propose a geometric framework for learning meta-embeddings of words from different embedding sources. Our framework transforms the embeddings into a common latent space, where, for example, simple averaging of different embeddings  is more amenable. The proposed latent space arises from two particular geometric transformations - the orthogonal rotations and the Mahalanobis metric scaling. Empirical results on several word similarity and word analogy benchmarks illustrate the efficacy of the proposed framework.  
 		Most existing approaches for goal-oriented dialogue policy learning used reinforcement learning, which focuses on the target agent policy and simply treat the opposite agent policy as part of the environment. While in real-world scenarios, the behavior of an opposite agent often exhibits certain patterns or underlies hidden policies, which can be inferred and utilized by the target agent to facilitate its own decision making. This strategy is common in human mental simulation by first imaging a specific action and the probable results before really acting it. We therefore propose an opposite behavior aware framework for policy learning in goal-oriented dialogues. We estimate the opposite agent's policy from its behavior and use this estimation to improve the target agent by regarding it as part of the target policy. We evaluate our model on both cooperative and competitive dialogue tasks, showing superior performance over state-of-the-art baselines. 	
      Attentional, RNN-based encoder-decoder architectures have achieved impressive performance on abstractive summarization of news articles. However, these methods fail to account for long term dependencies within the sentences of a document. This problem is exacerbated in multi-document summarization tasks such as summarizing the popular opinion in threads present in community question answering  websites such as Yahoo! Answers and Quora. These threads contain answers which often overlap or contradict each other. In this work, we present a hierarchical encoder based on structural attention to model such inter-sentence and inter-document dependencies. We set the popular pointer-generator architecture and some of the architectures derived from it as our baselines and show that they fail to generate good summaries in a multi-document setting. We further illustrate that our proposed model achieves significant improvement over the baselines in both single and multi-document summarization settings -- in the former setting, it beats the best baseline by 1.31 and 7.8 ROUGE-1 points on CNN and CQA datasets, respectively; in the latter setting, the performance is further improved by   1.6 ROUGE-1 points on the CQA dataset. 
 The advent of context-aware NMT has resulted in promising improvements in the overall translation quality and specifically in the translation of discourse phenomena such as pronouns. Previous works have mainly focused on the use of past sentences as context with a focus on anaphora translation. In this work, we investigate the effect of future sentences as context by comparing the performance of a contextual NMT model trained with the future context to the one trained with the past context. Our experiments and evaluation, using generic and pronoun-focused automatic metrics, show that the use of future context not only achieves significant improvements over the context-agnostic Transformer, but also demonstrates comparable and in some cases improved performance over its counterpart trained on past context. We also perform an evaluation on a targeted cataphora test suite and report significant gains over the {context-agnostic} Transformer in terms of BLEU. 
 Static knowledge graph has been incorporated extensively into sequence-to-sequence framework for text generation. While effectively representing structured context, static knowledge graph failed to represent knowledge evolution, which is required in modeling dynamic events. In this paper, an automatic commenting task is proposed for long novels, which involves understanding context of more than tens of thousands of words. To model the dynamic storyline, especially the transitions of the characters and their relations, Evolutionary Knowledge Graph  is proposed and learned within a multi-task framework. Given a specific passage to comment, sequential modeling is used to incorporate historical and future embedding for context representation. Further, a graph-to-sequence model is designed to utilize the EKG for comment generation. %a graph convolutional network is designed to include the evolution of related entities. Our model is especially powerful in capturing the unexpected but relevant changes which are quite common in drama storylines. Extensive experimental results show that our EKG-based method is superior to several strong baselines on both automatic and human evaluations.  %Article commenting methods have been extensively studied, but are difficult to model super-long context. In this paper, we address the full-length novel commenting problem. The huge challenges are posed in this scenario because of the evolution of entities and their relations within the novel context. Thus, we propose an evolutionary knowledge graph  to model the temporal transitions of the entities  and relations . The node and edge embeddings are pre-trained under a multi-task framework in order to obtain semantic consistency and capture temporal information simultaneously. Then graph convolutional networks are employed to aggregate the structured knowledge from the proposed EKG and further improve the quality of novel commenting. We also contribute a large-scale novel dataset with auto-annotated graphs and millions of real comments from well-known Chinese novel websites. Experimental results show that our model can achieve state-of-the-art performance in both automatic and manual evaluations. 
   The majority of existing methods for fake news detection universally focus on learning and fusing various features for detection. However, the learning of various features is independent, which leads to a lack of cross-interaction fusion between features on social media, especially between posts and comments. Generally, in fake news, there are emotional associations and semantic conflicts between posts and comments. How to represent and fuse the cross-interaction between both is a key challenge. In this paper, we propose Adaptive Interaction Fusion Networks  to fulfill cross-interaction fusion among features for fake news detection. In AIFN, to discover semantic conflicts, we design gated adaptive interaction networks  to capture adaptively similar semantics and conflicting semantics between posts and comments. To establish feature associations, we devise semantic-level fusion self-attention networks  to enhance semantic correlations and fusion among features. Extensive experiments on two real-world datasets, i.e., RumourEval and PHEME, demonstrate that AIFN achieves the state-of-the-art performance and boosts accuracy by more than 2.05\% and 1.90\%, respectively. 
 	% Relation ties閻ㄥ嫬鐣炬稊澶涚礉鏉╂瑤绔撮崣銉ょ瑝閺閫涚啊 	Relation ties, defined as the correlation and mutual exclusion between different relations, are critical for distant supervised relation extraction. 	% 娴犮儱绶氶弬瑙勭《閻ㄥ嫬浠涘▔ 	Existing approaches model this property by greedily learning local dependencies. 	% 閹诲繗鍫梻顕顣 	However, they are essentially limited by failing to capture the global topology structure of relation ties.  	As a result, they may easily fall into a locally optimal solution. 	% 娑撹桨绨＄憴锝呭枀鏉╂瑤绔村Ο鈥崇烽敍灞惧灉娴狀剙鐔煎娴滃棗绨辨禒鎴濆 	To solve this problem, in this paper, we propose a novel force-directed graph based relation extraction model to comprehensively learn relation ties. 	% 閸忚渹缍嬮弶銉嚛 	Specifically, 	% 閹存垳婊戞＃鏍у帥鐏忓棗鍙х化璁崇闂傚娈戦懕鏃傞兇閺嬪嫬缂撻幋鎰瀵姴娴 	we first build a graph according to the global co-occurrence of relations. 	% 閻掕泛鎮楅敍灞惧灉娴狀剙鐔烘暏 	Then, we borrow the idea of Coulomb's Law from physics and introduce the concept of attractive force and repulsive force to this graph to learn correlation and mutual exclusion between relations. 	% 閺堥崥 	Finally, the obtained relation representations are applied as an inter-dependent relation classifier. 	% 鐎圭偤鐛欑拠浣规 	Experimental results on a large scale benchmark dataset demonstrate that our model is capable of modeling global relation ties and significantly outperforms other baselines.  	Furthermore, the proposed force-directed graph can be used as a module to augment existing relation extraction systems and improve their performance. 	% 缁楊兛绨╂稉顏勭湴闂 	%and can indeed acquire the implicit connections between relations.  	 	 	 
 Unsupervised neural machine translation  has recently achieved remarkable results for several language pairs. However, it can only translate between a single language pair and cannot produce translation results for multiple language pairs at the same time. That is, research on  multilingual UNMT  has  been limited. In this paper, we empirically introduce a simple method to translate between thirteen languages using a single encoder and a single decoder, making use of multilingual data to improve UNMT for all language pairs. On the basis of the empirical findings, we propose two knowledge distillation methods to further enhance multilingual UNMT performance. Our experiments on a dataset with English translated to and from  twelve other languages  show remarkable results, surpassing strong unsupervised individual baselines while achieving promising performance between non-English language pairs in zero-shot translation scenarios and alleviating poor performance in low-resource language pairs.   
 Sentiment analysis is crucial for the advancement of artificial intelligence . Sentiment understanding can help AI to replicate human language and discourse.  Studying the formation and response of sentiment state from well-trained Customer Service Representatives  can help make the interaction between humans and AI more intelligent.   In this paper,  a sentiment analysis pipeline is first carried out with respect to real-world multi-party conversations--that is, service calls. Based on the acoustic and linguistic features extracted from the source information,  a novel aggregated method for voice sentiment recognition framework is built. Each party's sentiment pattern during the communication is investigated along with the interaction sentiment pattern between all parties.                 % {\bf Keywords:} Bimodal sentiment analysis, speaker diarization,  sequence models, conversation, active learning              
   This paper studies the practicality of the current state-of-the-art unsupervised methods in neural machine translation .   In ten translation tasks with various data settings, we analyze the conditions under which the unsupervised methods fail to produce reasonable translations.   We show that their performance is severely affected by linguistic dissimilarity and domain mismatch between source and target monolingual data.   Such conditions are common for low-resource language pairs, where unsupervised learning works poorly.   In all of our experiments, supervised and semi-supervised baselines with 50k-sentence bilingual data outperform the best unsupervised results.   Our analyses pinpoint the limits of the current unsupervised NMT and also suggest immediate research directions. 
  The task of concept prerequisite chain learning is to automatically determine the existence of prerequisite relationships among concept pairs. In this paper, we frame learning prerequisite relationships among concepts as an unsupervised task with no access to labeled concept pairs during training. We propose a model called the Relational-variational Graph AutoEncoder  to predict concept relations within a graph consisting of concept and resource nodes. Results show that our unsupervised approach outperforms graph-based semi-supervised methods and other baseline methods by up to 9.77\% and 10.47\% in terms of prerequisite relation prediction accuracy and F1 score. Our method is notably the first graph-based model that attempts to make use of deep learning representations for the task of unsupervised prerequisite learning. We also expand an existing corpus which totals $1,717$ English Natural Language Processing -related lecture slide files and manual concept pair annotations over $322$ topics.  
 Learning disentangled representations of real-world data is a challenging open problem. Most previous methods have focused on either supervised approaches which use attribute labels or unsupervised approaches that manipulate the factorization in the latent space of models such as the variational autoencoder  by training with task-specific losses. In this work, we propose polarized-VAE, an approach that disentangles select attributes in the latent space based on proximity measures reflecting the similarity between data points with respect to these attributes. % In this work we propose polarized-VAE - a novel approach that uses the similarity of input data points, in terms of different attributes, to disentangle them into different subspaces in the learnt latent representation with the help of proximity functions.%  We apply our method to disentangle the semantics and syntax of sentences and carry out transfer experiments. Polarized-VAE outperforms the VAE baseline and is competitive with state-of-the-art approaches, while being more a general framework that is applicable to other attribute disentanglement tasks. 
   Modern deep neural networks achieve impressive performance in engineering applications that require extensive linguistic skills, such as machine translation. This success has sparked interest in probing whether these models are inducing human-like grammatical knowledge from the raw data they are exposed to, and, consequently, whether they can shed new light on long-standing debates concerning the innate structure necessary for language acquisition. In this article, we survey representative studies of the syntactic abilities of deep networks, and discuss the broader implications that this work has for theoretical linguistics. %Abstract text, approximately 150 words.  
 Recent studies have shown remarkable success in end-to-end task-oriented dialog system.  However, most neural models rely on large training data, which are only available for a certain number of task domains, such as navigation and scheduling.  This makes it difficult to scalable for a new domain with limited labeled data.  However, there has been relatively little research on how to effectively use data from all domains to improve the performance of each domain and also unseen domains.  To this end, we investigate methods that can make explicit use of domain knowledge and introduce a shared-private network to learn shared and specific knowledge. In addition, we propose a novel Dynamic Fusion Network  which automatically exploit the relevance between the target domain and each domain. Results show that our model outperforms existing methods on multi-domain dialogue, giving the state-of-the-art in the literature.  Besides, with little training data, we show its transferability by outperforming prior best model by 13.9\% on average. 
 		Deep reinforcement learning is a promising approach to training a dialog manager, but current methods struggle with the large state and action spaces of multi-domain dialog systems. Building upon Deep Q-learning from Demonstrations , an algorithm that scores highly in difficult Atari games, we leverage dialog data to guide the agent to successfully respond to a user's requests. We make progressively fewer assumptions about the data needed, using labeled, reduced-labeled, and even unlabeled data to train expert demonstrators. 		We introduce Reinforced Fine-tune Learning, an extension to DQfD, enabling us to overcome the domain gap between the datasets and the environment. 		Experiments in a challenging multi-domain dialog system framework validate our approaches, and get high success rates even when trained on out-of-domain data. 	
 The  has been extensively explored by psychologists, educationalists and cognitive scientists alike. In the context of Intelligent Tutoring Systems, modelling the forgetting curve for each user and knowledge component  should enable us to develop optimal revision strategies that counteract memory decay and ensure long-term retention. In this study we explore a variety of forgetting curve models incorporating psychological and linguistic features, and we use these models to predict the probability of word recall by learners of English as a second language. We evaluate the impact of the models and their features using data from an online vocabulary teaching platform and find that word complexity is a highly informative feature which may be successfully learned by a neural network model.    
 Thai is a low-resource language, so it is often the case that data is not available in sufficient quantities to train an Neural Machine Translation  model which perform to a high level of quality. In addition, the Thai script does not use white spaces to delimit the boundaries between words, which adds more complexity when building sequence to sequence models. In this work, we explore how to augment a set of English--Thai parallel data by replicating sentence-pairs with different word segmentation methods on Thai, as training data for NMT model training. Using different merge operations of Byte Pair Encoding, different segmentations of Thai sentences can be obtained. The experiments show that combining these datasets, performance is improved for NMT models trained with a dataset that has been split using a supervised splitting tool. \\ \newline \Keywords{Machine Translation, Word Segmentation, Thai Language
   Fine-tuning of pre-trained transformer networks such as BERT yield state-of-the-art results for text classification tasks.   Typically, fine-tuning is performed on task-specific training datasets in a supervised manner.   One can also fine-tune in unsupervised manner beforehand by further pre-training the masked language modeling  task.   Hereby, in-domain data for unsupervised MLM resembling the actual classification target dataset allows for domain adaptation of the model.   In this paper, we compare current pre-trained transformer networks with and without MLM fine-tuning on their performance for offensive language detection.    Our MLM fine-tuned RoBERTa-based classifier officially ranks 1st in the SemEval 2020 Shared Task~12 for the English language. Further experiments with the ALBERT model even surpass this result. 
 This paper solves the fake news detection problem under a more realistic scenario on social media. Given the source short-text tweet and the corresponding sequence of retweet users without text comments, we aim at predicting whether the source tweet is fake or not, and generating explanation by highlighting the evidences on suspicious retweeters and the words they concern. We develop a novel neural network-based model, Graph-aware Co-Attention Networks , to achieve the goal. Extensive experiments conducted on real tweet datasets exhibit that GCAN can significantly outperform state-of-the-art methods by 16\% in accuracy on average. In addition, the case studies also show that GCAN can produce reasonable explanations.  
  Text style transfer aims to paraphrase a sentence in one style  into another style while preserving content. Due to lack of parallel training data, state-of-art methods are unsupervised and rely on large datasets that share content. Furthermore, existing methods have been applied on  very limited categories of styles such as positive/negative and formal/informal.  In this work, we develop a meta-learning framework  to transfer between any kind of  text styles, including personal writing styles that are more  fine-grained, share less content and have much smaller training data. %personal writing styles. Noticing that in this way, there naturally exists  %as many style pairs as possible with each having a limited data size,  %we apply meta-learning framework in a multi-task scheme.  While state-of-art models fail in the few-shot style transfer task,  our framework effectively utilizes information from other styles to  improve both language fluency and style transfer accuracy.   
 Natural language understanding  converts sentences into structured semantic forms. The paucity of annotated training samples is still a fundamental challenge of NLU. To solve this data sparsity problem, previous work based on semi-supervised learning mainly focuses on exploiting unlabeled sentences. In this work, we introduce a dual task of NLU, semantic-to-sentence generation , and propose a new framework for semi-supervised NLU with the corresponding dual model. The framework is composed of dual pseudo-labeling and dual learning method, which enables an NLU model to make full use of data  through a closed-loop of the primal and dual tasks. By incorporating the dual task, the framework can exploit pure semantic forms as well as unlabeled sentences, and further improve the NLU and SSG models iteratively in the closed-loop. The proposed approaches are evaluated on two public datasets . Experiments in the semi-supervised setting show that our methods can outperform various baselines significantly, and extensive ablation studies are conducted to verify the effectiveness of our framework. Finally, our method can also achieve the state-of-the-art performance on the two datasets in the supervised setting. 
 Aspect-based sentiment analysis aims to determine the sentiment polarity towards a specific aspect in online reviews.~Most recent efforts adopt attention-based neural network models to implicitly connect aspects with opinion words. However, due to the complexity of language and the existence of multiple aspects in a single sentence, these models often confuse the connections. In this paper, we address this problem by means of effective encoding of syntax information. Firstly, we define a unified aspect-oriented dependency tree structure rooted at a target aspect by reshaping and pruning an ordinary dependency parse tree. Then, we propose a relational graph attention network  to encode the new tree structure for sentiment prediction.~Extensive experiments are conducted on the SemEval 2014 and Twitter datasets, and the experimental results confirm that the connections between aspects and opinion words can be better established with our approach, and the performance of the graph attention network  is significantly improved as a consequence. 
 		To better tackle the named entity recognition  problem on languages with little/no labeled data, cross-lingual NER must effectively leverage knowledge learned from source languages with rich labeled data.  		Previous works on cross-lingual NER are mostly based on label projection with pairwise texts or direct model transfer.  		However, such methods either are not applicable if the labeled data in the source languages is unavailable, or do not leverage information contained in unlabeled data in the target language. 		%However, label-projection based methods are not applicable if the labeled data in the source languages is unavailable due to privacy issues; and direct model-transfer based methods do not leverage information contained in unlabeled data in the target language. 		%However, these methods either require pairwise texts and cannot be deployed if the source labeled data have privacy requirements, or do not explore the information contained in the easy-to-access unlabeled data of the target language.  		In this paper, we propose a teacher-student learning method to address such limitations, where NER models in the source languages are used as teachers to train a student model on unlabeled data in the target language. The proposed method works for both single-source and multi-source cross-lingual NER.  		For the latter, we further propose a similarity measuring method to better weight the supervision from different teacher models.  		Extensive experiments for 3 target languages on benchmark datasets well demonstrate that our method outperforms existing state-of-the-art methods for both single-source and multi-source cross-lingual NER. 	
 This paper describes the ICS PAS system which took part in CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. The~system consists of jointly trained tagger, lemmatizer, and dependency parser which are based on features extracted by a~biLSTM network. The~system uses both fully connected and dilated convolutional neural architectures. The~novelty of our approach is the~use of an~additional loss function, which reduces the~number of cycles in the~predicted dependency graphs, and the~use of self-training to increase the~system performance. The~proposed system, i.e. ICS PAS , ranked 3th/4th in the~official evaluation\footnote{\url{http://universaldependencies.org/conll18/results.html}} obtaining the~following overall results: 73.02 , 60.25  and 64.44 .  
 Recent algorithms in machine translation have included a value network to assist the policy network when deciding which word to output at each step of the translation. The addition of a value network helps the algorithm perform better on evaluation metrics like the BLEU score. After training the policy and value networks in a supervised setting, the policy and value networks can be jointly improved through common actor-critic methods. The main idea of our project is to instead leverage Monte-Carlo Tree Search  to search for good output words with guidance from a combined policy and value network architecture in a similar fashion as AlphaZero . This network serves both as a local and a global look-ahead reference that uses the result of the search to improve itself. Experiments using the IWLST14 German to English translation dataset show that our method outperforms the actor-critic methods used in recent machine translation papers. Full code for this work is available at \url{https://github.com/chenziku/NMT-MCTS}.  
 Deep pretrained language models have achieved great success in the way of pretraining first and then fine-tuning. But such a sequential transfer learning paradigm often confronts the catastrophic forgetting problem and leads to sub-optimal performance. To fine-tune with less forgetting, we propose a recall and learn mechanism, which adopts the idea of multi-task learning and jointly learns pretraining tasks and downstream tasks.  Specifically, we propose a Pretraining Simulation mechanism to recall the knowledge from pretraining tasks without data, and an Objective Shifting mechanism to focus the learning on downstream tasks gradually. Experiments show that our method achieves state-of-the-art performance on the GLUE benchmark.  Our method also enables BERT-base to achieve better performance than directly fine-tuning of BERT-large. Further, we provide the open-source RecAdam optimizer, which integrates the proposed mechanisms into Adam optimizer, to facility the NLP community.\footnote{https://github.com/Sanyuan-Chen/RecAdam}    
 This paper proposes a simple and effective algorithm for incorporating lexical constraints in neural machine translation. Previous work either required re-training existing models with the lexical constraints or incorporating them during beam search decoding with significantly higher computational overheads. Leveraging the flexibility and speed of a recently proposed Levenshtein Transformer model , our method injects terminology constraints at inference time without any impact on decoding speed. Our method does not require any modification to the training procedure and can be easily applied at runtime with custom dictionaries. Experiments on English-German WMT datasets show that our approach improves an unconstrained baseline and previous approaches. 
 This paper proposes the problem of Deep Question Generation , which aims to generate complex questions that require reasoning over multiple pieces of information of the input passage.  In order to capture the global structure of the document and facilitate reasoning, we propose a novel framework which first constructs a semantic-level graph for the input document and then encodes the semantic graph by introducing an attention-based GGNN . Afterwards, we fuse the document-level and graph-level representations to perform joint training of content selection and question decoding.  On the HotpotQA deep-question centric dataset, our model greatly improves performance over questions requiring reasoning over multiple facts, leading to state-of-the-art performance. The code is publicly available at % MinCR: consider forking into WING-NUS and using that as the listed URL for better long-term viability \url{https://github.com/WING-NUS/SG-Deep-Question-Generation}.  
  In recent years, there has been an increasing interest in the application of Artificial Intelligence 閳 and especially Machine Learning 閳 to the field of Sustainable Development . % However, until now, NLP has not been systematically applied in this context. % In this paper, we show the high potential of NLP to enhance project sustainability. % In particular, we focus on the case of  community profiling in developing countries, where, in contrast to the developed world, a notable data gap exists. % Here, NLP could help to address the cost and time barrier of structuring qualitative data that prohibits its widespread use and associated benefits. %\textcolor{red}{Technological NLP-based improvements may allow to overcome such present limitations?} % %We propose the new Automatic User-Perceived Value classification task, which is an extreme multi-class multi-label classification problem. We propose the new extreme multi-class multi-label Automatic User-Perceived Value classification task. %which is an extreme %multi-class % classification problem. % We release Stories2Insights , an expert-annotated dataset of interviews carried out in Uganda, we provide a detailed corpus analysis, and we implement a number of strong neural baselines to address the task. % Experimental results show that the problem is challenging, and leaves considerable room for future research at the intersection of NLP and SD. % %WE hope it will raise interest from the NLP community.  %This is the first time that NLP the sustainable project application. This is important as to date  % %inaccessibility of data due to high cost from timely data analysis processes.  % %We have presented the first task combining NLP and SD, Automatic UPV Classification: %we provided S2I, an annotated corpus for the task; %we proposed a number of neural architectures obtaining satisfactory results w     
 Learning continuous representations from unlabeled textual data has been increasingly studied for benefiting semi-supervised learning. Although it is relatively easier to interpret discrete representations, due to the difficulty of training, learning discrete representations for unlabeled textual data has not been widely explored. This work proposes TIGAN that learns to encode texts into two disentangled representations, including a discrete code and a continuous noise, where the discrete code represents interpretable topics, and the noise controls the variance within the topics. The discrete code learned by TIGAN can be used for unsupervised text classification. Compared to other unsupervised baselines, the proposed TIGAN achieves superior performance on six different corpora. Also, the performance is on par with a recently proposed weakly-supervised text classification method. The extracted topical words for representing latent topics show that TIGAN learns coherent and highly interpretable topics. 
 Machine translation  systems translate text between different languages by automatically learning in-depth knowledge of bilingual lexicons, grammar and semantics from the training examples. Although neural machine translation  has led the field of MT, we have a poor understanding on how and why it works. In this paper, we bridge the gap by assessing the bilingual knowledge learned by NMT models with phrase table -- an interpretable table of bilingual lexicons. We extract the phrase table from the training examples that a NMT model correctly predicts. Extensive experiments on widely-used datasets show that the phrase table is reasonable and consistent against language pairs and random seeds. Equipped with the interpretable phrase table, we find that NMT models learn patterns from simple to complex and distill essential bilingual knowledge from the training examples. We also revisit some advances that potentially affect the learning of bilingual knowledge , and report some interesting findings. We believe this work opens a new angle to interpret NMT with statistic models, and provides empirical supports for recent advances in improving NMT models.   
 We propose to cast  the task of morphological inflection---mapping a lemma to an indicated inflected form---for  resource-poor languages as a meta-learning problem. Treating each language as a separate task, we use data from high-resource source languages to learn a set of model parameters that can serve as a strong initialization point for fine-tuning on a resource-poor target language. Experiments with two model architectures on $29$ target languages from $3$ families show that our suggested approach outperforms all baselines. In particular, it obtains a $31.7\%$ higher absolute accuracy than a previously proposed cross-lingual transfer model and outperforms the previous state of the art by $1.7\%$ absolute accuracy on average over languages. 
 Nowadays, offensive content in social media has become a serious problem, and automatically detecting offensive language is an essential task. In this paper, we build an offensive language detection system, which combines multi-task learning with BERT-based models. % Transfer learning and multi-task learning are two major techniques that are widely employed in machine learning fields.  Using a pre-trained language model such as BERT, we can effectively learn the representations for noisy text in social media. Besides, to boost the performance of offensive language detection, we leverage the supervision signals from other related tasks. % In the task of Multilingual Offensive Language Identification in Social Media, we propose to use both techniques to make use of pre-trained feature representations and better leverage the information in the hierarchical dataset.  In the OffensEval-2020 competition, our model achieves 91.51\% F1 score in English Sub-task A, which is comparable to the first place . An empirical analysis is provided to explain the effectiveness of our approaches. % Our contribution is two-fold. Firstly, we propose a multi-task transfer learning model for this problem and we provide an empirical analysis to explain why this method is very effective. Secondly, the model achieves a performance  comparable to the first place  in the competition with only the OLID dataset. 
 Recently, many methods discover effective evidence from reliable sources by appropriate neural networks for explainable claim verification, which has been widely recognized. However, in these methods, the discovery process of evidence is nontransparent and unexplained. Simultaneously, the discovered evidence only roughly aims at the interpretability of the whole sequence of claims but insufficient to focus on the false parts of claims. In this paper, we propose a Decision Tree-based Co-Attention model  to discover evidence for explainable claim verification. Specifically, we first construct Decision Tree-based Evidence model  to select comments with high credibility as evidence in a transparent and interpretable way. Then we design Co-attention Self-attention networks  to make the selected evidence interact with claims, which is for 1) training DTE to determine the optimal decision thresholds and obtain more powerful evidence; and 2) utilizing the evidence to find the false parts in the claim. Experiments on two public datasets, RumourEval and PHEME, demonstrate that DTCA not only provides explanations for the results of claim verification but also achieves the state-of-the-art performance, boosting the F1-score by 3.11\%, 2.41\%, respectively. 
 		 Verifying the correctness of a textual statement requires not only semantic reasoning about the meaning of words, but also symbolic reasoning about logical operations like count, superlative, aggregation, etc. In this work, we propose \modelname, a neural network approach capable of leveraging logical operations for fact checking. It achieves the state-of-the-art performance on TABFACT, a large-scale, benchmark dataset built for verifying a textual statement with semi-structured tables. This is achieved by a graph module network built upon the Transformer-based architecture. With a textual statement and a table as the input, \modelname \ automatically derives a program  of the statement in a semantic parsing manner. A heterogeneous graph is then constructed to capture not only the structures of the table and the program, but also the connections between inputs with different modalities. Such a graph reveals the related contexts of each word in the statement, the table and the program. The graph is used to obtain graph-enhanced contextual representations of words in Transformer-based architecture. After that, a program-driven module network is further introduced to exploit the hierarchical structure of the program, where semantic compositionality is dynamically modeled along the program structure with a set of function-specific modules. Ablation experiments suggest that both the heterogeneous graph and the module network are important to obtain strong results. 	
 The celebrated Seq2Seq technique and its numerous variants achieve excellent performance on many tasks such as neural machine translation, semantic parsing, and math word problem solving. However, these models either only consider input objects as sequences while ignoring the important structural information for encoding, or they simply treat output objects as sequence outputs instead of structural objects for decoding. In this paper, we present a novel Graph-to-Tree Neural Networks, namely Graph2Tree consisting of a graph encoder and a hierarchical tree decoder, that encodes an augmented graph-structured input and decodes a tree-structured output. In particular, we investigated our model for solving two problems, neural semantic parsing and math word problem. Our extensive experiments demonstrate that our Graph2Tree model outperforms or matches the performance of other state-of-the-art models on these tasks. 
      Generative Adversarial Networks  for text generation have recently received many criticisms, as they perform worse than their MLE counterparts .     We suspect previous text GANs' inferior performance is due to the lack of a reliable guiding signal in their discriminators.     % Ours     To address this problem, we propose a generative adversarial imitation learning framework for text generation that uses large pre-trained language models to provide more reliable reward guidance.     % Details     As previous text GANs suffer from high variance of gradients,     we apply contrastive discriminator, and proximal policy optimization  to stabilize and improve text generation performance.     % Results     For evaluation, we conduct experiments on a diverse set of unconditional and conditional text generation tasks.     Experimental results show that TextGAIL achieves better performance in terms of both quality and diversity than the MLE baseline.     We also validate our intuition that TextGAIL's discriminator demonstrates the capability of providing reasonable rewards with an additional task.  
 A large number of significant assets are available online in English, which is frequently translated into native languages to ease the information sharing among local people who are not much familiar with English. However, manual translation is a very tedious, costly, and time-taking process. To this end, machine translation is an effective approach to convert text to a different language without any human involvement. Neural machine translation  is one of the most proficient translation techniques amongst all existing machine translation systems. In this paper, we have applied NMT on two of the most morphological rich Indian languages, i.e. English-Tamil and English-Malayalam. We proposed a novel NMT model using Multihead self-attention along with pre-trained Byte-Pair-Encoded  and MultiBPE embeddings to develop an efficient translation system that overcomes the OOV  problem for low resourced morphological rich Indian languages which do not have much translation available online. We also collected corpus from different sources, addressed the issues with these publicly available data and refined them for further uses. We used the BLEU score for evaluating our system performance. Experimental results and survey confirmed that our proposed translator  outperforms Google translator  respectively. \\ \newline \Keywords{Multihead self-attention, Byte-Pair-Encodding, MultiBPE, low-resourced, Morphology, Indian Languages
 Text classification is fundamental in natural language processing , and Graph Neural Networks  are recently applied in this task. However, the existing graph-based works can neither capture the contextual word relationships within each document nor fulfil the inductive learning of new words. In this work, to overcome such problems, we propose TextING\footnote{https://github.com/CRIPAC-DIG/TextING} for inductive text classification via GNN. We first build individual graphs for each document and then use GNN to learn the fine-grained word representations based on their local structures, which can also effectively produce embeddings for unseen words in the new document. Finally, the word nodes are incorporated as the document embedding. Extensive experiments on four benchmark datasets show that our method outperforms state-of-the-art text classification methods.  
 Quality estimation  for tasks involving language data is hard owing to numerous aspects of natural language like variations in paraphrasing, style, grammar, etc. There can be multiple answers with varying levels of acceptability depending on the application at hand. In this work, we look at estimating quality of translations for video subtitles. We show how existing QE methods are inadequate and propose our method \our~as a system to estimate quality of translation given subtitles data for a pair of languages. %We introduce DeepQE as a novel system for translation quality estimation  in absence of reference texts for video subtitles.  %We explain the problems with conventional binary classification and scoring approaches for QE; we describe how our method overcomes those problems.  We rely on various data augmentation strategies for automated labelling and synthesis for training.  %We define a third category of translations  besides Good and Bad translations and show our system's efficiency to distinguish them.  We create a hybrid network which learns semantic and syntactic features of bilingual data and compare it with only-LSTM and only-CNN networks.  Our proposed network outperforms them by significant margin. % We define a new category of translations: Loose translation and show our system's efficiency to distinguish between Loose and Good or Bad translations. Finally, we present ``Translation Embedding" that encapsulate the knowledge of bilingual translation relation between two sentences. 
 Named entity recognition is an important task in natural language processing. It is very well studied for rich language, but still under explored for low-resource languages. The main reason is that the existing techniques required a lot of annotated data to reach good performance. Recently, a new distributional representation of words has been proposed to project named entities from a rich language to a low-resource one. This representation has been coupled to a neural network in order to project named entities from English to Ewondo, a Bantu language spoken in Cameroon. Although the proposed method reached appreciable results, the size of the used neural network was too large compared to the size of the dataset. Furthermore the impact of the model parameters has not been studied. In this paper, we show experimentally that the same results can be obtained using a smaller neural network. We also emphasize the parameters that are highly correlated to the network performance. This work is a step forward to build a reliable and robust network architecture for named entity projection in low resource languages. 
 Word sense disambiguation tries to learn the appropriate sense of an ambiguous word in a given context.  The existing pre-trained language methods and the methods based on multi-embeddings of word did not explore the power of the unsupervised word embedding sufficiently.   In this paper, we discuss a capsule network-based approach, taking advantage of capsule閳ユ獨 potential for recognizing highly overlapping features and dealing with segmentation. We propose a {}sule network-based method to {}ompose the unsupervised word {}mbedding of an ambiguous word in{} context specific {}ense embedding, called CapsDecE2S.  In this approach, the unsupervised ambiguous embedding is fed into capsule network to produce its multiple morpheme-like vectors, which are defined as the basic semantic language units of meaning.  With attention operations, CapsDecE2S integrates the word context to reconstruct the multiple morpheme-like vectors into the context-specific sense embedding. To train CapsDecE2S, we propose a sense matching training method. In this method, we convert the sense learning into a binary classification that explicitly learns the relation between senses by the label of matching and non-matching. The CapsDecE2S was experimentally evaluated on two sense learning tasks, i.e., word in context and word sense disambiguation. Results on two public corpora Word-in-Context and English all-words Word Sense Disambiguation show that, the CapsDecE2S model achieves the new state-of-the-art for the word in context and word sense disambiguation tasks. 
 Given an untrimmed video and a text query, natural language video localization  is to locate a matching span from the video that semantically corresponds to the query. Existing solutions formulate NLVL either as a ranking task and apply multimodal matching architecture, or as a regression task to directly regress the target video span. In this work, we address NLVL task with a span-based QA approach by treating the input video as text passage. We propose a video span localizing network , on top of the standard span-based QA framework, to address NLVL. The proposed VSLNet tackles the differences between NLVL and span-based QA through a simple yet effective query-guided highlighting  strategy. The QGH guides VSLNet to search for matching video span within a highlighted region. Through extensive experiments on three benchmark datasets, we show that the proposed VSLNet outperforms the state-of-the-art methods; and adopting span-based QA framework is a promising direction to solve NLVL.\footnote{https://github.com/IsaacChanghau/VSLNet}  
 We present the task of modeling information propagation in literature, in which we seek to identify pieces of information passing from character $A$ to character $B$ to character $C$, only given a description of their activity in text. We describe a new pipeline for measuring information propagation in this domain and publish a new dataset for speaker attribution, enabling the evaluation of an important component of this pipeline on a wider range of literary texts than previously studied.  Using this pipeline, we analyze the dynamics of information propagation in over 5,000 works of English fiction, finding that information flows through characters that fill structural holes connecting different communities, and that characters who are women are depicted as filling this role much more frequently than characters who are men.  
 Much progress has been made in text summarization, fueled by neural architectures using large-scale training corpora. However, in the news domain, neural models easily overfit by leveraging position-related features due to the prevalence of the inverted pyramid writing style. In addition, there is an unmet need to generate a variety of summaries for different users. In this paper, we propose a neural framework that can flexibly control summary generation by introducing a set of sub-aspect functions . These sub-aspect functions are regulated by a set of control codes to decide which sub-aspect to focus on during summary generation. We demonstrate that extracted summaries with minimal position bias is comparable with those generated by standard models that take advantage of position preference. We also show that news summaries generated with a focus on diversity can be more preferred by human raters. These results suggest that a more flexible neural summarization framework providing more control options could be desirable in tailoring to different user preferences, which is useful since it is often impractical to articulate such preferences for different applications a priori. 
  Recent work on the interpretability of deep neural language models has concluded that many properties of natural language syntax are encoded in their representational spaces. However, such studies often suffer from limited scope by focusing on a single language and a single linguistic formalism. In this study, we aim to investigate the extent to which the semblance of syntactic structure captured by language models adheres to a surface-syntactic or deep syntactic style of analysis, and whether the patterns are consistent across different languages.  We apply a probe for extracting directed dependency trees  to BERT and ELMo models trained on 13 different languages, probing for two different syntactic annotation styles: Universal Dependencies , prioritizing deep syntactic relations, and Surface-Syntactic Universal Dependencies , focusing on surface structure. We find that both models exhibit a preference for UD over SUD --- with interesting variations across languages and layers --- and that the strength of this preference is correlated with differences in tree shape. %between the different representations. %suggesting that these models capture predicate-argument structure to a larger extent than surface structure.   
 Exposing diverse subword segmentations to neural machine translation  models often improves the robustness of machine translation as NMT models can experience various subword candidates. However, the diversification of subword segmentations mostly relies on the pre-trained subword language models from which erroneous segmentations of unseen words are less likely to be sampled. In this paper, we present \Ours~ to study whether gradient signals during training can be a substitute criterion for exposing diverse subword segmentations. We experimentally show that our model-based adversarial samples effectively encourage NMT models to be less sensitive to segmentation errors and improve the performance of NMT models in low-resource and out-domain datasets. 
 Recent research in neural machine translation has explored flexible generation orders, as an alternative to left-to-right generation. However, training non-monotonic models brings a new complication: how to search for a good ordering when there is a combinatorial explosion of orderings arriving at the same final result? Also, how do these automatic orderings compare with the actual behaviour of human translators? Current models rely on manually built biases or are left to explore all possibilities on their own. In this paper, we analyze the orderings produced by human post-editors and use them to train an automatic post-editing system. We compare the resulting system with those trained with left-to-right  and random post-editing orderings. We observe that humans tend to follow a nearly left-to-right order, but with interesting deviations, such as preferring to start by correcting punctuation or verbs.  
 Few-shot relation classification seeks to classify incoming query instances after meeting  only few support instances. % during testing. This ability is gained by training with large amount of in-domain annotated data.  In this paper, we tackle an even harder problem by further limiting the amount of data available at training time.  %In this paper,  We propose a few-shot learning framework for %sentence-based  relation classification, which is particularly powerful when the training data is very small. In this framework, models not only strive to classify query instances, but also seek  underlying knowledge about the support instances to obtain better instance representations. %models are trained not only by queries but also the support instances. The framework also includes a method for aggregating cross-domain knowledge into models by  open-source task enrichment. Additionally, we construct a brand new dataset: the TinyRel-CM dataset, a few-shot relation  classification dataset in health domain with purposely small training data and challenging relation classes. Experimental results demonstrate that our framework brings performance gains for most underlying classification models, %\KZ{I think you are talking about underlying classification models?} outperforms the state-of-the-art results given small training data,  %,  and achieves competitive results with sufficiently large training data. %. %on TinyRel-CM dataset and achieves competitive results on %the FewRel dataset , especially when extremely small amount of training data is given. % \KZ{Don't mention MESDA everywhere, but only when you need to refer to it succinctly.} 
   \indent Data augmentation is an effective performance enhancement in neural machine translation  by generating additional bilingual data.  In this paper, we propose a novel data augmentation enhancement strategy for neural machine translation. Different from existing data augmentation methods which simply choose words with the same probability across different sentences for modification, we set sentence-specific probability for word selection by considering their roles in sentence. We use dependency parse tree of input sentence as an effective clue to determine selecting probability for every words in each sentence.  Our proposed method is evaluated on WMT14 English-to-German dataset and IWSLT14 German-to-English dataset.  The result of extensive experiments show our proposed syntax-aware data augmentation method may effectively boost existing sentence-independent methods for significant translation performance improvement. 
 % 1. Fine-tune Recently, fine-tuning pre-trained language models  to downstream cross-lingual tasks has shown promising results. % 2. Problem However, the fine-tuning process inevitably changes the parameters of the pre-trained model and weakens its cross-lingual ability, which leads to sub-optimal performance. % 3. Continual Learning To alleviate this problem, we leverage continual learning to preserve the original cross-lingual ability of the pre-trained model when we fine-tune it to downstream tasks. % 4. Results The experimental result shows that our fine-tuning methods can better preserve the cross-lingual ability of the pre-trained model in a sentence retrieval task. Our methods also achieve better performance than other fine-tuning baselines on the zero-shot cross-lingual part-of-speech tagging and named entity recognition tasks.  
 In this work, we aim at equipping pre-trained language models with structured knowledge. We present two self-supervised tasks learning over raw text with the guidance from knowledge graphs.  Building upon entity-level masked language models, our first contribution is an entity masking scheme that exploits relational knowledge underlying the text. This is fulfilled by using a linked knowledge graph to select informative entities and then masking their mentions. In addition we use knowledge graphs to obtain distractors for the masked entities, and propose a novel distractor-suppressed ranking objective which is optimized jointly with masked language model. In contrast to existing paradigms, our approach uses knowledge graphs implicitly, only during pre-training, to inject language models with structured knowledge via learning from raw text. It is more efficient than retrieval-based methods that perform entity linking and integration during finetuning and inference, and generalizes more effectively than the methods that directly learn from concatenated graph triples. Experiments show that our proposed model achieves improved performance on five benchmark datasets, including question answering and knowledge base completion tasks.  
 % As globalization advances, there are more people spontaneously speaking more than one language, and mixing them.  An increasing number of people in the world today speak a mixed-language as a result of being multilingual. However, building a speech recognition system for code-switching remains difficult due to the availability of limited resources and the expense and significant effort required to collect mixed-language data. We therefore propose a new learning method, meta-transfer learning, to transfer learn on a code-switched speech recognition system in a low-resource setting by judiciously extracting information from high-resource monolingual datasets. Our model learns to recognize individual languages, and transfer them so as to better recognize mixed-language speech by conditioning the optimization on the code-switching data. Based on experimental results, our model outperforms existing baselines on speech recognition and language modeling tasks, and is faster to converge. 
 The success of deep learning methods hinges on the availability of large training datasets annotated for the task of interest. In contrast to human intelligence, these methods lack versatility and struggle to learn and adapt quickly to new tasks, where labeled data is scarce. Meta-learning aims to solve this problem by training a model on a large number of few-shot tasks, with an objective to learn new tasks quickly from a small number of examples. In this paper, we propose a meta-learning framework for few-shot word sense disambiguation , where the goal is to learn to disambiguate unseen words from only a few labeled instances. Meta-learning approaches have so far been typically tested in an $N$-way, $K$-shot classification setting where each task has $N$ classes with $K$ examples per class. Owing to its nature, WSD deviates from this controlled setup and requires the models to handle a large number of highly unbalanced classes. We extend several popular meta-learning approaches to this scenario, and analyze their strengths and weaknesses in this new challenging setting. 
 Deep-learning models for language generation tasks tend to produce repetitive output. Various methods have been proposed to encourage lexical diversity during decoding, but this often comes at a cost to the perceived fluency and adequacy of the output. In this work, we propose to ameliorate this cost by using an Imitation Learning approach to explore the level of diversity that a language generation model can safely produce. Specifically, we augment the decoding process with a meta-classifier trained to distinguish which words at any given timestep will lead to high-quality output. We focus our experiments on concept-to-text generation where models are sensitive to the inclusion of irrelevant words due to the strict relation between input and output. Our analysis shows that previous methods for diversity underperform in this setting, while human evaluation suggests that our proposed method achieves a high level of diversity with minimal effect to the output's fluency and adequacy.  
 Relation extraction  consists in categorizing the relationship between entities in a sentence. A recent paradigm to develop relation extractors is Distant Supervision , which allows the automatic creation of new datasets by taking an alignment between a text corpus and a Knowledge Base . KBs can sometimes also provide additional information to the RE task. One of the methods that adopt this strategy is the RESIDE model, which proposes a distantly-supervised neural relation extraction using side information from KBs.  Considering that this method outperformed state-of-the-art baselines, in this paper, we propose a related approach to RESIDE also using additional side information, but simplifying the sentence encoding with BERT embeddings. Through experiments, we show the effectiveness of the proposed method in Google Distant Supervision and Riedel datasets concerning the BGWA and RESIDE baseline methods. Although Area Under the Curve is decreased because of unbalanced datasets, P@N results have shown that the use of BERT as sentence encoding allows superior performance to baseline methods.         
 Interpretable rationales for model predictions play a critical role in practical applications. In this study, we develop models possessing interpretable inference process for structured prediction. Specifically, we present a method of instance-based learning that learns similarities between spans. At inference time, each span is assigned a class label based on its similar spans in the training set, where it is easy to understand how much each training instance contributes to the predictions. Through empirical analysis on named entity recognition, we demonstrate that our method enables to build models that have high interpretability without sacrificing performance. 
 Generating qualitative responses has always been a challenge for human-computer dialogue systems. Existing dialogue systems generally derive from either retrieval-based or generative-based approaches, both of which have their own pros and cons. Despite the natural idea of an ensemble model of the two, existing ensemble methods only focused on leveraging one approach to enhance another, we argue however that they can be further  enhanced with a proper training strategy. In this paper, we propose ensembleGAN, an adversarial learning framework for enhancing a retrieval-generation ensemble model in open-domain conversation scenario. It consists of a language-model-like generator, a ranker generator, and one ranker discriminator. Aiming at generating responses that approximate the ground-truth and receive high ranking scores from the discriminator, the two generators learn to generate improved highly relevant responses and competitive unobserved candidates respectively, while the discriminative ranker is trained to identify true responses from adversarial ones, thus featuring the merits of both generator counterparts. The experimental results on a large short-text conversation data demonstrate the effectiveness of the ensembleGAN by the amelioration on both human and automatic evaluation metrics. %While an ensemble model of the two usually outperforms either one 
 We propose transfer learning as a method for analyzing the encoding of grammatical structure in neural language models. We train LSTMs on non-linguistic data and evaluate their performance on natural language to assess which kinds of data induce generalizable structural features that LSTMs can use for natural language.  We find that training on non-linguistic data with latent structure  improves test performance on natural language, despite no overlap in surface form or vocabulary. To pinpoint the kinds of abstract structure that models may be encoding to lead to this improvement, we run similar experiments with two artificial parentheses languages: one which has a hierarchical recursive structure, and a control which has paired tokens but no recursion. Surprisingly, training a model on either of these artificial languages leads to the same substantial gains when testing on natural language. Further experiments on transfer between natural languages controlling for vocabulary overlap show that zero-shot performance on a test language is highly correlated with typological syntactic similarity to the training language, suggesting that representations induced by pre-training correspond to the cross-linguistic syntactic properties. Our results provide insights into the ways that neural models represent abstract syntactic structure, and also about the kind of structural inductive biases which allow for natural language acquisition. \footnote{We release code to construct the corpora and run our experiments at \url{https://github.com/toizzy/tilt-transfer}} 
   We address whether neural models for Natural Language Inference  can learn the compositional interactions between lexical entailment and negation, using four methods: the behavioral evaluation methods of  challenge test sets and  systematic generalization tasks, and the structural evaluation methods of  probes and  interventions. To facilitate this holistic evaluation, we present Monotonicity NLI , a new naturalistic dataset focused on lexical entailment and negation. In our behavioral evaluations, we find that models trained on general-purpose NLI datasets fail systematically on \MoNLI\ examples containing negation, but that \MoNLI\ fine-tuning addresses this failure. In our structural evaluations, we look for evidence that our top-performing BERT-based model has learned to implement the monotonicity algorithm behind \MoNLI. Probes yield evidence consistent with this conclusion, and our intervention experiments bolster this, showing that the causal dynamics of the model mirror the causal dynamics of this algorithm on subsets of \MoNLI. This suggests that the BERT model at least partially embeds a theory of lexical entailment and negation at an algorithmic level. 
 Transformer hugely benefits from its key design of the multi-head self-attention network , which extracts information from various perspectives through transforming the given input into different subspaces. However, its simple linear transformation aggregation strategy may still potentially fail to fully capture deeper contextualized information. In this paper, we thus propose the capsule-Transformer, which extends the linear transformation into a more general capsule routing algorithm by taking SAN as a special case of capsule network. So that the resulted capsule-Transformer is capable of obtaining a better attention distribution representation of the input sequence via information aggregation among different heads and words. Specifically, we see groups of attention weights in SAN as low layer capsules. By applying the iterative capsule routing algorithm they can be further aggregated into high layer capsules which contain deeper contextualized information. Experimental results on the widely-used machine translation datasets show our proposed capsule-Transformer outperforms strong Transformer baseline significantly. 
 We present NUBIA, a methodology to build automatic evaluation metrics for text generation using only machine learning models as core components. A typical NUBIA model is composed of three modules: a neural feature extractor, an aggregator and a calibrator. We demonstrate an implementation of NUBIA which outperforms metrics currently used to evaluate machine translation, summaries and slightly exceeds/matches state of the art metrics on correlation with human judgement on the WMT segment-level Direct Assessment task, sentence-level ranking and image captioning evaluation. The model implemented is modular, explainable and set to continuously improve over time. 
  % Motivation Word alignment was once a core unsupervised learning task in natural language processing because of its essential role in training statistical machine translation  models. Although unnecessary for training neural MT models, word alignment still plays an important role in interactive applications of neural machine translation, such as annotation transfer and lexicon injection.  While statistical MT methods have been replaced by neural approaches with superior performance, the twenty-year-old GIZA++ toolkit remains a key component of state-of-the-art word alignment systems.  Prior work on neural word alignment has only been able to outperform GIZA++ by using its output during training. We present the first end-to-end neural word alignment method that consistently outperforms GIZA++ on three data sets.  Our approach repurposes a Transformer model trained for supervised translation to also serve as an unsupervised word alignment model in a manner that is tightly integrated and does not affect translation quality.  
 % Natural language understanding  and natural language generation  are both critical research topics in NLP field. In modular dialogue systems, natural language understanding  and natural language generation  are two critical components, where NLU extracts the semantics from the given texts and NLG is to construct corresponding natural language sentences based on the input semantic representations. %The goal of NLU is to extract the core semantic concept from the given utterances, while NLG is the opposite, of which the goal is to construct corresponding sentences based on given semantic representation.  However, the dual property between understanding and generation has been rarely explored. The prior work~ is the first attempt that utilized the duality between NLU and NLG to improve the performance via a dual supervised learning framework. However, the prior work still learned both components in a  manner, instead, % This paper proposes a new learning framework for language understanding and generation on top of dual supervised learning, providing a way to exploit the duality. % This paper proposed a general learning framework exploiting such duality, providing a way to jointly learn language understanding and generation and flexibility of incorporating supervised and unsupervised learning  this paper introduces a general learning framework to effectively exploit such duality, providing flexibility of incorporating both  and  learning algorithms to train language understanding and generation models in a joint fashion.  The benchmark experiments demonstrate that the proposed approach is capable of boosting the performance of both NLU and NLG.\footnote{The source code is available at: \url{https://github.com/MiuLab/DuaLUG}.} 
 %Neural machine translation  models do not work well when large training data is not available in the target domain. % The standard approach to this problem is to build a small amount of parallel data in the target domain and perform domain adaptation from a source domain where a massive amount of parallel data is available.  %However, such a source domain is not necessarily similar to the target domain. % ynaga; 閵嚶板楅妵锝冧缓闁姰浜滈妵銊ｄ壕閵堝秲浜遍妶澶婎潗閵堜降浠搁妵濞夸簻閵囷负浣虹ゼ鐠滄牓浠规禒鏍ヤ紕閵堣￥鍋ｉ妶顖樹紑閵堝倷濞囬妵鍫涘犻妵鐐缓缁诲浜介妶; 鐎靛嫨鍊為柆鎾变粣閵囶亗浜滈妵褏鍟婂鏂讳紑閼冲本娅欓妶鎺撴祲閵 %% ynaga \yn{Neural network methods  % for natural language processing % are data-hungry, and  exhibit strong performance only in a few  resource-rich domains. % The Practitioners therefore employ domain adaptation from resource-rich domains that are, in most cases, distant from the target domain.} Domain adaptation between distant domains , however, cannot be performed effectively due to % because of  mismatches in vocabulary;  % subword-based 閵囩姰浠虹悰銊╂桨閻ㄥ嫨浼閵 encounter 閵囨ぜ浠鹃妵鍕╀紕閵 it will encounter many  %% ynaga % unknown  domain-specific words  and words whose meanings shift across domains . In this study, aiming to solve these vocabulary mismatches in  % ynaga; distant 閵囥劊浠遍妵鎴欏犻妵銊у濞堝ǹ鍋欓妷绗哄仯閵堟帗澹夐妵锝冧桓閵囧嫨鍊犻妶鍫涗簽閵囶偉顩伴妵鍫涘犻妵鎴欎患閵嗕降鍎旈妷掳鍋嗛妷鎶戒患韫囨嚎浠归妵顖氱枀闂呮稏浼閵囶垬浜楅妶瀣ㄤ簵閵 % distant domain adaptation for neural machine translation , we propose vocabulary adaptation,  a simple method for effective fine-tuning that adapts embedding layers in a given pre-trained nmt model to the target domain. Prior to fine-tuning, our method replaces the embedding layers of the nmt model by projecting general word embeddings induced from monolingual data in a target domain onto a source-domain embedding space. Experimental results %on distant domain adaptation for  English-to-Japanese translation and German-to-English translation  indicate that our method improves the performance of conventional fine-tuning by 3.86 and 3.28 bleu points in En$\rightarrow$Ja  and De$\rightarrow$En translation, respectively. 
 Despite its original goal to jointly learn to align and translate, prior researches suggest that Transformer captures poor word alignments through its attention mechanism. In this paper, we show that attention weights \textrm{DO} capture accurate word alignments and propose two novel word alignment induction methods \textproc{Shift-Att} and \textproc{Shift-AET}. The main idea is to induce alignments at the step when the to-be-aligned target token is the decoder input rather than the decoder output as in previous work. \textproc{Shift-Att} is an interpretation method that induces alignments from the attention weights of Transformer and does not require parameter update or architecture change. \textproc{Shift-AET} extracts alignments from an additional alignment module which is tightly integrated into Transformer and trained in isolation with supervision from symmetrized \textproc{Shift-Att} alignments. Experiments on three publicly available datasets demonstrate that both methods perform better than their corresponding neural baselines and \textproc{Shift-AET} significantly outperforms \textproc{GIZA++} by 1.4-4.8 AER points.\footnote{Code can be found at \url{https://github.com/sufe-nlp/transformer-alignment}.}   
 Despite the success of language models using neural networks, it remains unclear to what extent neural models have the generalization ability to perform inferences. In this paper, we introduce a method for evaluating whether neural models can learn \todo{systematicity of monotonicity inference} in natural language, namely, the regularity for performing arbitrary inferences with generalization on composition. We consider four aspects of monotonicity inferences and test whether the models can systematically interpret \todo{lexical and logical phenomena} on different training/test splits. A series of experiments show that three neural models systematically draw inferences on unseen combinations of lexical and logical phenomena when the syntactic structures of the sentences are similar between the training and test sets. However, the performance of the models significantly decreases when the structures are slightly changed in the test set while retaining all vocabularies and constituents already appearing in the training set. This indicates that the generalization ability of neural models is limited to cases where the syntactic structures are nearly the same as those in the training set.  
 Prosody is a rich information source in natural language, serving as a marker for phenomena such as contrast.  In order to make this information available to downstream tasks, we need a way to detect prosodic events in speech. We propose a new model for pitch accent detection, inspired by the work of , who presented a CNN-based model for this task.  Our model makes greater use of context by using full utterances as input and adding an LSTM layer. We find that these innovations lead to an improvement from 87.5 percent to 88.7 percent accuracy on pitch accent detection on American English speech in the Boston University Radio News Corpus, a state-of-the-art result. We also find that a simple baseline  that just predicts a pitch accent on every content word yields 82.2 percent accuracy, and we suggest that this is the appropriate baseline for this task. Finally, we conduct ablation tests that show pitch is the most important acoustic feature for this task and this corpus. 
   Suspense is a crucial ingredient of narrative fiction, engaging readers and making stories compelling. While there is a vast   theoretical literature on suspense, it is computationally not well   understood. We compare two ways for modelling suspense: surprise, a   backward-looking measure of how unexpected the current state is   given the story so far; and uncertainty reduction, a forward-looking   measure of how unexpected the continuation of the story is.  Both   can be computed either directly over story representations or over   their probability distributions. We propose a hierarchical language   model that encodes stories and computes surprise and uncertainty   reduction. Evaluating against short stories annotated with human   suspense judgements, we find that uncertainty reduction over   representations is the best predictor, resulting in near human   accuracy. We also show that uncertainty reduction can be used to   predict suspenseful events in movie synopses. 
 Achieving satisfying performance in machine translation on domains for which there is no training data is challenging. Traditional domain adaptation is not suitable for addressing such zero-resource domains because it relies on in-domain parallel data. We show that document-level context can be used to capture domain generalities when in-domain parallel data is not available. We present two document-level Transformer models which are capable of using large context sizes and we compare these models against strong Transformer baselines. We obtain improvements for the two zero-resource domains we study. We additionally present experiments showing the usefulness of large context when modeling multiple domains at once. 
 The scarcity of large parallel corpora is an important obstacle for neural machine translation. A common solution is to exploit the knowledge of language models  trained on abundant monolingual data. In this work, we propose a novel approach to incorporate a \lm as prior in a neural translation model~. Specifically, we add a regularization term, which pushes the output distributions of the \tm to be probable under the \lm prior, while avoiding wrong predictions when the \tm ``disagrees'' with the \lm. This objective relates to knowledge distillation, where the \lm can be viewed as teaching the \tm about the target language. The proposed approach does not compromise decoding speed, because the \lm is used only at training time,  unlike previous work that requires it during inference. We present an analysis on the effects that different methods have on the distributions of the \tm. Results on two low-resource machine translation datasets show clear improvements even with limited monolingual data. 
 We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world's languages. However, we argue that a scenario without  parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological  issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for  different types of research in this area  and argue for comparable evaluation of these models.  
 We describe a method for developing broad-coverage semantic dependency parsers for languages for which no semantically annotated resource is available. We leverage a multitask learning framework coupled with an annotation projection method. We transfer supervised semantic dependency parse annotations from a rich-resource language to a low-resource language through parallel data, and train a semantic parser on projected data. We make use of supervised syntactic parsing as an auxiliary task in a multitask learning framework, and show that with different multitask learning settings, we consistently improve over the single-task baseline. In the setting in which English is the source, and Czech is the target language, our best multitask model improves the labeled F1 score over the single-task baseline by $1.8$ in the in-domain SemEval data~, as well as $2.5$ in the out-of-domain test set. Moreover, we observe that syntactic and semantic dependency direction match is an important factor in improving the results. 
 Attribution methods assess the contribution of inputs to the model prediction. One way to do so is {: the fact that an input can be dropped does not mean that the model `knows' it can be dropped. The resulting pruning is over-aggressive and does not reflect how the model arrives at the prediction. To deal with these challenges, we introduce Differentiable Masking. DiffMask learns to mask-out subsets of the input while maintaining differentiability. The decision to include or disregard an input token is made with a simple model based on intermediate hidden layers of the analyzed model. First, this makes the approach efficient because we predict rather than search. Second, as with probing classifiers, this reveals what the network `knows' at the corresponding layers. This lets us not only plot attribution heatmaps but also analyze how decisions are formed across network layers. We use DiffMask to study BERT models on sentiment classification and question answering.\footnote{Source code available at \url{https://github.com/nicola-decao/diffmask}} 
 % Entity Matching  refers to the problem of deciding whether two data entries refer to the same real-world entity. %and more generally, it refers to the problem of %determining matching data entries in different %datasets.  %Given an input of two structured data items,  %Entity Matching  decides whether the two items %refer to the same real-world entity.  %As one of the most fundamental tasks in data %integration, %EM has a wide range of applications from entity %similarity search to %joining/merging database tables from different %sources. %Existing solutions for EM include both rule-based %and learning-based methods %with the recently proposed deep-learning-based %methods delivering %the state-of-the-art  matching qualities. %However, the success of these models requires a %significant amount of training data %and they lack the ability of learning beyond the %training data.  We present  pre-trained on large text corpora  already significantly improves the matching quality and outperforms previous state-of-the-art , by up to \rev{29\%} of F1 score on benchmark datasets.  We also developed three optimization techniques to further improve  allows domain knowledge to be injected by highlighting important pieces of input information that may be of interest when making matching decisions.  also summarizes strings that are too long so that only the essential information is retained and used for EM.  %These two techniques help  to pay attention to the right information when making entity matching decisions. Finally,  adapts a SOTA technique on data augmentation for text to EM to augment the training data with  examples. This way,  is forced to learn ``harder'' to improve the model's matching capability. The optimizations we developed  further boost the performance of . Perhaps more surprisingly,  we establish that  can achieve the previous SOTA results with at most half the number of labeled data.  Finally, we demonstrate \system's effectiveness on a real-world large-scale EM task. On matching two company datasets consisting of 789K and 412K records, \system\ achieves a high F1 score of 96.5\%. 
 We propose Pixel-BERT to align image pixels with text by deep multi-modal transformers that jointly learn visual and language embedding in a unified end-to-end framework.  %we propose CNN-based Visual Encoder and combine BERT  in an end-to-end manner  We aim to build a more accurate and thorough connection between image pixels and language semantics directly from image and sentence pairs instead of using region-based image features as the most recent vision and language tasks. Our Pixel-BERT which aligns semantic connection in pixel and text level solves the limitation of task-specific visual representation for vision and language tasks. It also relieves the cost of bounding box annotations and overcomes the imbalance between semantic labels in visual task and language semantic.  To provide a better representation for down-stream tasks, we pre-train a universal end-to-end model with image and sentence pairs from Visual Genome dataset and MS-COCO dataset.  % TODO We propose to use a random pixel sampling mechanism to enhance the robustness of visual representation and to apply the Masked Language Model and Image-Text Matching as pre-training tasks.  %To provide a better representation for down-stream tasks, we pre-train a universal end-to-end model with image and sentence pairs from Visual Genome Dataset and MSCOCO dataset.  Extensive experiments on downstream tasks with our pre-trained model show that our approach achieves state-of-the-art results in downstream tasks, including Visual Question Answering , image-text retrieval, Natural Language for Visual Reasoning for Real . Particularly, we boost the performance of a single model in VQA task by 2.17 points compared with SOTA under fair comparison.   
   Source code summarizing is a task of writing short, natural language descriptions of source code behaviour during run time. Such summaries are extremely useful for software development and maintenance but are expensive to manually author, hence it is done for small fraction of the code that is produced and is often ignored. Automatic code documentation can possibly solve this at a low cost. This is thus an emerging research field with further applications to program comprehension, and software maintenance. Traditional methods often relied on cognitive models that were built in the form of templates and by heuristics and had varying degree of adoption by the developer community. But with recent advancements, end to end data-driven approaches based on neural techniques have largely overtaken the traditional techniques. Much of the current landscape employs neural translation based architectures with recurrence and attention which is resource and time intensive training procedure. In this paper, we employ neural techiques to solve the task of source code summarizing and specifically compare NMT based techniques to more simplified and appealing Transformer architecture on a dataset of Java methods and comments. We bring forth an argument to dispense the need of recurrence in the training procedure.  To the best of our knowledge, transformer based models have not been used for the task before. With supervised samples of more than 2.1m  comments and code, we reduce the training time by more than 50\% and achieve the BLEU score of 17.99 for the test set of examples.     
 In training deep learning networks, the optimizer and related learning rate are often used without much thought or with minimal tuning, even though it is crucial in ensuring a fast convergence to a good quality minimum of the loss function that can also generalize well on the test dataset. Drawing inspiration from the successful application of cyclical learning rate policy for computer vision related convolutional networks and datasets, we explore how cyclical learning rate can be applied to train transformer-based neural networks for neural machine translation. From our carefully designed experiments, we show that the choice of optimizers and the associated cyclical learning rate policy can have a significant impact on the performance. In addition, we establish guidelines when applying cyclical learning rates to neural machine translation tasks. Thus with our work, we hope to raise awareness of the importance of selecting the right optimizers and the accompanying learning rate policy, at the same time, encourage further research into easy-to-use learning rate policies.  
 Automatic source code summarization is the task of generating natural language descriptions for source code. Automatic code summarization is a rapidly expanding research area, especially as the community has taken greater advantage of advances in neural network and AI technologies. In general, source code summarization techniques use the source code as input and outputs a natural language description. Yet a strong consensus is developing that using structural information as input leads to improved performance. The first approaches to use structural information flattened the AST into a sequence. Recently, more complex approaches based on random AST paths or graph neural networks have improved on the models using flattened ASTs. However, the literature still does not describe the using a graph neural network together with source code sequence as separate inputs to a model. Therefore, in this paper, we present an approach that uses a graph-based neural architecture that better matches the default structure of the AST to generate these summaries. We evaluate our technique using a data set of 2.1 million Java method-comment pairs and show improvement over four baseline techniques, two from the software engineering literature, and two from machine learning literature. 
 Current multilingual vision-language models either require a large number of additional parameters for each supported language, or suffer performance degradation as languages are added. In this paper, we propose a Scalable Multilingual Aligned Language Representation  that supports many languages with few model parameters without sacrificing downstream task performance. SMALR learns a fixed size language-agnostic representation for most words in a multilingual vocabulary, keeping language-specific features for just a few. We use a masked cross-language modeling loss to align features with context from other languages. Additionally, we propose a cross-lingual consistency module that ensures predictions made for a query and its machine translation are comparable. The effectiveness of SMALR is demonstrated with ten diverse languages, over twice the number supported in vision-language tasks to date. We evaluate on multilingual image-sentence retrieval and outperform prior work by 3-4\% with less than 1/5th the training parameters compared to other word embedding methods.   
   In this paper, we formulate the challenge of re-conceptualising the language game experimental paradigm in the framework of multi-agent reinforcement learning . If successful, future language game experiments will benefit from the rapid and promising methodological advances in the MARL community, while future MARL experiments on learning emergent communication will benefit from the insights and results gained from language game experiments. We strongly believe that this cross-pollination has the potential to lead to major breakthroughs in the modelling of how human-like languages can emerge and evolve in multi-agent systems. 
 In many applications labeled data is not readily available, and needs to be collected via pain-staking human supervision. We propose a rule-exemplar method for collecting human supervision to combine the efficiency of rules with the quality of instance labels. The supervision is coupled such that it is both natural for humans and synergistic for learning. We propose a training algorithm that jointly denoises rules via latent coverage variables, and trains the model through a soft implication loss over the coverage and label variables. The denoised rules and trained model are used jointly for inference. Empirical evaluation on five different tasks shows that  our algorithm is more accurate than several existing methods of learning from a mix of clean and noisy supervision, and  the coupled rule-exemplar supervision is effective in denoising rules. \let\thefootnote\relax\footnotetext{Code and datasets available at \url{https://github.com/awasthiabhijeet/Learning-From-Rules}}  
  Hate speech detection is a challenging problem with most of the datasets available in only one language: English. In this paper, we conduct a large scale analysis of multilingual hate speech in 9 languages from 16 different sources. We observe that in low resource setting, simple models such as LASER embedding with logistic regression performs the best, while in high resource setting BERT based models perform better. In case of zero-shot classification, languages such as Italian and Portuguese achieve good results. Our proposed framework could be used as an efficient solution for low-resource languages. These models could also act as good baselines for future multilingual hate speech detection tasks. We have made our code and experimental settings public\footnote{\url{https://github.com/punyajoy/DE-LIMIT}} for other researchers.  %  
  Recently, the bidirectional encoder representations from transformers  model has attracted much attention in the field of natural language processing, owing to its high performance in language understanding-related tasks. The BERT model learns language representation that can be adapted to various tasks via pre-training using a large corpus in an unsupervised manner. This study proposes the language and action learning using multimodal BERT  model that enables the learning of language and actions by 1) extending the BERT model to multimodal representation and 2) integrating it with reinforcement learning. To verify the proposed model, an experiment is conducted in a grid environment that requires language understanding for the agent to act properly. As a result, the lamBERT model obtained higher rewards in multitask settings and transfer settings when compared to other models, such as the convolutional neural network-based model and the lamBERT model without pre-training.   
       Social networks are evolving to engage their users more by providing them with more functionalities. One of the most attracting ones is streaming. Users may broadcast part of their daily lives to thousands of others world-wide and interact with them in real-time. Unfortunately, this feature is reportedly exploited for grooming. In this work, we provide the first in-depth analysis of this problem for social live streaming services. More precisely, using a dataset that we collected, we identify predatory behaviours and grooming on chats that bypassed the moderation mechanisms of the LiveMe, the service under investigation. Beyond the traditional text approaches, we also investigate the relevance of emojis in this context, as well as the user interactions through the gift mechanisms of LiveMe. Finally, our analysis indicates the possibility of grooming towards minors, showing the extent of the problem in such platforms.   
  Numerous recent works have proposed pretraining generic visio-linguistic representations and then finetuning them for downstream vision and language tasks. While architecture and objective function design choices have received attention, the choice of pretraining datasets has received little attention. In this work, we question some of the default choices made in literature. For instance, we systematically study how varying similarity between the pretraining dataset domain  and the downstream domain affects performance. Surprisingly, we show that automatically generated data in a domain closer to the downstream task  is a better choice for pretraining than ``natural'' data but of a slightly different domain . On the other hand, some seemingly reasonable choices of pretraining datasets were found to be entirely ineffective for some downstream tasks. This suggests that despite the numerous recent efforts, vision \& language pretraining does not quite work ``out of the box'' yet. Overall, as a by-product of our study, we find that simple design choices in pretraining can help us achieve close to state-of-art results on downstream tasks without any architectural changes.     language, multimodal transformers, multimodal pretraining} 
%   <- trailing '%' for backward compatibility of .sty file We present \appname, a low-code Python library that makes machine learning more accessible and easier to apply. As a wrapper to TensorFlow and many other libraries , it is designed to make sophisticated, state-of-the-art machine learning models simple to build, train, inspect, and apply by both beginners and experienced practitioners.  Featuring modules that support text data , vision data ,  graph data , and tabular data, \appname presents a simple unified interface enabling one to quickly solve a wide range of tasks in as little as three or four ``commands'' or lines of code.  
 Social media has been on the vanguard of political information diffusion in the 21st century. Most studies that look into disinformation, political influence and fake-news focus on mainstream social media platforms. This has inevitably made English an important factor in our current understanding of political activity on social media.  As a result, there has only been a limited number of studies into a large portion of the world, including the largest, multilingual and multicultural democracy: India.  In this paper we present our characterisation of a multilingual social network in India called ShareChat. We collect an exhaustive dataset across 72 weeks before and during the Indian general elections of 2019, across 14 languages. We investigate the cross lingual dynamics by clustering visually similar images together, and exploring how they move across language barriers. We find that Telugu, Malayalam, Tamil and Kannada languages tend to be dominant in soliciting political images , and posts from Hindi have the largest cross-lingual diffusion across ShareChat .  In the case of images containing text that cross language barriers, we see that language translation is used to widen the accessibility.  That said, we find cases where the same image is associated with very different text . This initial characterisation paves the way for more advanced pipelines to understand the dynamics of fake and political content in a multi-lingual and non-textual setting.  
 Internet forums and public social media, such as online healthcare forums, provide a convenient channel for users  concerned about health issues to discuss and share information with each other. In late December 2019, an outbreak of a novel coronavirus  was reported, and, due to the rapid spread of the virus in other parts of the world, the World Health Organization declared a state of emergency. In this paper, we used automated extraction of COVID-19--related discussions from social media and a natural language process  method based on topic modeling to uncover various issues related to COVID-19 from public opinions. Moreover, we also investigate how to use LSTM recurrent neural network for sentiment classification of COVID-19 comments. Our findings shed light on the importance of using public opinions and suitable computational techniques to understand issues surrounding COVID-19 and to guide related decision-making.  %In this paper, we propose a neural network model that also incorporates user behavioral information within a given document . The neural network used in this paper is a Convolutional Neural Network . The system is evaluated on two datasets provided by the SemEval-2016 Workshop. The proposed model outperforms current baseline models , which shows that going beyond the content of a document  is beneficial in sentiment classification, because it provides the classifier with a deep understanding of the task.    % \PACS{PACS code1 \and PACS code2 \and more} %  
 Designing effective neural networks is fundamentally important in deep multimodal learning. Most existing works focus on a single task and design neural architectures manually, which are highly task-specific and hard to generalize to different tasks. In this paper, we devise a generalized deep multimodal neural architecture search  framework for various multimodal learning tasks. Given multimodal input, we first define a set of primitive operations, and then construct a deep encoder-decoder based unified backbone, where each encoder or decoder block corresponds to an operation searched from a predefined operation pool. On top of the unified backbone, we attach task-specific heads to tackle different multimodal learning tasks. By using a gradient-based NAS algorithm, the optimal architectures for different tasks are learned efficiently. Extensive ablation studies, comprehensive analysis, and comparative experimental results show that the obtained MMnasNet significantly outperforms existing state-of-the-art approaches across three multimodal learning tasks , including visual question answering, image-text matching, and visual grounding. 
  Prior work in standardized science exams requires support from large text corpus, such as targeted science corpus from Wikipedia or SimpleWikipedia. However, retrieving knowledge from the large corpus is time-consuming and questions embedded in complex semantic representation may interfere with retrieval. Inspired by the dual process theory in cognitive science, we propose a MetaQA framework, where system 1 is an intuitive meta-classifier and system 2 is a reasoning module. Specifically, our method based on meta-learning method and large language model BERT, which can efficiently solve science problems by learning from related example questions without relying on external knowledge bases. We evaluate our method on AI2 Reasoning Challenge , and the experimental results show that meta-classifier yields considerable classification performance on emerging question types. The information provided by meta-classifier significantly improves the accuracy of reasoning module from $46.6\%$ to $64.2\%$, which has a competitive advantage over retrieval-based QA methods.   
   Using attention weights to identify information that is important for models' decision making is a popular approach to interpret attention-based neural networks, which is commonly realized via creating a heat-map for each single document based on attention weights. However, this interpretation method is fragile. In this paper, we propose a corpus-level explanation approach, which aims to capture causal relationships between keywords and model predictions via learning importance of keywords for predicted labels across a training corpus based on attention weights.  Using this idea as the fundamental building block, we further propose a concept-based explanation method that can automatically learn higher level concepts and their importance to model prediction task. Our concept-based explanation method is built upon a novel Abstraction-Aggregation Network, which can automatically cluster important keywords during an end-to-end training process. We apply these methods to the document classification task and show that they are powerful in extracting semantically meaningful keywords and concepts. Our consistency analysis results based on an attention-based Na\"ive Bayes Classifier also demonstrate these keywords and concepts are important for model predictions. 
 Manually labelling large collections of text data is a time-consuming and expensive task, but one that is necessary to support machine learning based on text datasets.  has been shown to be an effective way to alleviate some of the effort required in utilising large collections of unlabelled data for machine learning tasks without needing to fully label them. The representation mechanism used to represent text documents when performing active learning, however, has a significant influence on how effective the process will be. While simple vector representations such as  and embedding-based representations based on techniques such as  have been shown to be an effective way to represent documents during active learning, the emergence of representation mechanisms based on the pre-trained transformer-based neural network models popular in natural language processing research  offer a promising, and as yet not fully explored, alternative. This paper describes a comprehensive evaluation of the effectiveness of representations based on pre-trained transformer-based language models for active learning. This evaluation shows that  transformer-based models, especially BERT-like models, that have not yet been widely used in active learning, achieve a significant improvement over more commonly used vector representations like bag-of-words or other classical word embeddings like word2vec. This paper also investigates the effectiveness of representations based on variants of BERT such as Roberta, DistilBert, and Albert as well as comparing the effectiveness of  the ``[CLS]'' token representation and the aggregated representation that can be generated using BERT-like models. Finally, we propose an approach to tune the representations generated by BERT-like transformer models during the active learning process, . Our experiments show that the limited label information acquired in active learning can not only be used for training a classifier but can also adaptively improve the embeddings generated by the BERT-like language models as well. 
  In recent years, the emerging topics of recommender systems that take advantage of natural language processing techniques have attracted much attention, and one of their applications is the Conversational Recommender System . Unlike traditional recommender systems with content-based and collaborative filtering approaches, CRS learns and models user's preferences through interactive dialogue conversations. In this work, we provide a summarization on the recent evolution of CRS, where deep learning approaches are applied to CRS and have produced fruitful results. We first analyze the research problems and present key challenges in the development of Deep Conversational Recommender Systems , then present the current state of the field taken from the most recent researches, including the most common deep learning models that benefit DCRS. Finally, we discuss future directions of this vibrant area.  
 Visual dialog is a challenging vision-language task in which a series of questions visually grounded by a given image are answered. To resolve the visual dialog task, a high-level understanding of various multimodal inputs  is required. Specifically, it is necessary for an agent to 1) determine the semantic intent of question and 2) align question-relevant textual and visual contents among heterogeneous modality inputs. In this paper, we propose Multi-View Attention Network , which leverages multiple views about heterogeneous inputs based on attention mechanisms. MVAN effectively captures the question-relevant information from the dialog history with two complementary modules , and builds multimodal representations through sequential alignment processes . Experimental results on VisDial v1.0 dataset show the effectiveness of our proposed model, which outperforms the previous state-of-the-art methods with respect to all evaluation metrics.
  In this paper, we focus on automatic disease diagnosis with reinforcement learning  methods in task-oriented dialogues setting. Different from conventional RL tasks, the action space for disease diagnosis  is inevitably large, especially when the number of diseases increases. However, existing approaches to this problem employ a flat RL policy, which typically works well in simple tasks but has significant challenges in complex scenarios like disease diagnosis. Towards this end, we propose to integrate a hierarchical policy of two levels into the dialogue policy learning. The high level policy consists of a model named master that is responsible for triggering a model in low level, the low level policy consists of several symptom checkers and a disease classifier. Experimental results on both self-constructed real-world and synthetic datasets demonstrate that our hierarchical framework achieves higher accuracy in disease diagnosis compared with existing systems. Besides, the datasets \footnote{http://www.sdspeople.fudan.edu.cn/zywei/data/Fudan-Medical-Dialogue2.0} and codes\footnote{https://github.com/nnbay/MeicalChatbot-HRL} are all available now. 
 A major obstacle to the wide-spread adoption of neural retrieval models is that they require large supervised training sets to surpass traditional term-based techniques, which are constructed from raw corpora. In this paper, we propose an approach to zero-shot learning for passage retrieval that uses synthetic question generation to close this gap. The question generation system is trained on general domain data, but is applied to documents in the targeted domain. This allows us to create arbitrarily large, yet noisy, question-passage relevance pairs that are domain specific. Furthermore, when this is coupled with a simple hybrid term-neural model, first-stage retrieval performance can be improved further.  Empirically, we show that this is an effective strategy for building neural passage retrieval models in the absence of large training corpora. Depending on the domain, this technique can even approach the accuracy of supervised models. 
 Open-domain dialogue generation suffers from the data insufficiency problem due to the vast size of potential responses. In this paper, we propose to explore potential responses by counterfactual reasoning. Given an observed response, the counterfactual reasoning model automatically infers the outcome of an alternative policy that could have been taken. The resulting counterfactual response synthesized in hindsight is of higher quality than the response synthesized from scratch.  Training on the counterfactual responses under the adversarial learning framework helps to explore the high-reward area of the potential response space. An empirical study on the DailyDialog dataset shows that our approach significantly outperforms the HRED model as well as the conventional adversarial learning approaches. 
 Speaker extraction aims to mimic humans' selective auditory attention by extracting a target speaker's voice from a multi-talker environment. It is common to perform the extraction in frequency-domain, and reconstruct the time-domain signal from the extracted magnitude and estimated phase spectra. However, such an approach is adversely affected by the inherent difficulty of phase estimation. Inspired by Conv-TasNet, we propose a time-domain speaker extraction network  that converts the mixture speech into multi-scale embedding coefficients instead of decomposing the speech signal into magnitude and phase spectra. In this way, we avoid phase estimation. The SpEx network consists of four network components, namely speaker encoder, speech encoder, speaker extractor, and speech decoder. Specifically, the speech encoder converts the mixture speech into multi-scale embedding coefficients, the speaker encoder learns to represent the target speaker with a speaker embedding. The speaker extractor takes the multi-scale embedding coefficients and target speaker embedding as input and estimates a receptive mask. Finally, the speech decoder reconstructs the target speaker's speech from the masked embedding coefficients. We also propose a multi-task learning framework and a multi-scale embedding implementation. Experimental results show that the proposed SpEx achieves 37.3\%, 37.7\% and 15.0\% relative improvements over the best baseline in terms of signal-to-distortion ratio , scale-invariant SDR , and perceptual evaluation of speech quality  under an open evaluation condition.  
  We investigate whisper-to-natural-speech conversion using sequence-to-sequence approach by proposing modified transformer architecture. We investigate different features like mel frequency cepstral coefficients and smoothed spectral features. The proposed networks are trained end-to-end using supervised approach for feature-to-feature transformation. Further, We also investigate the effectiveness of embedded auxillary decoder used after N encoder sub-layers, and is trained with the frame-level objective function for identifying source phoneme labels. We show results on wTIMIT and CHAINS datasets by measuring word error rate using end-to-end ASR and also BLEU scores for the generated speech. In addition, we  measure spectral shape of it by measuring formant distributions w.r.t. the reference speech, as formant divergence metric. We have found whisper-to-natural converted speech formants probability distribution is similar to the groundtruth distribution. To the authors' best knowledge, this is the first time modified transformer has been applied for whisper-to-natural-speech conversion and vice versa. 
 % Teacher-student  learning has shown to be effective for domain % adaptaion. One shortcoming is that T/S learning requires the  We propose a novel neural label embedding  scheme for the domain adaptation of a deep neural network  acoustic model with  data samples from source and target domains.  With NLE method, we distill the knowledge from a powerful source-domain DNN into a dictionary of label embeddings, or -vectors, one for each senone class.  %Each -vector is a representation of the output  %distributions of the source-domain DNN given input features with a common %senone label and is  Each -vector is a representation of the senone-specific output  distributions of the source-domain DNN and is learned to minimize the average $L_2$, Kullback-Leibler  or symmetric KL distance to the output vectors with the same label through simple averaging or standard back-propagation.  % During adaptation, the one-hot labels of the target-domain data %are first translated to the corresponding -vectors based on the dictionary and %the NLEs are  During adaptation, the -vectors serve as the soft targets to train the target-domain model with cross-entropy loss. % between the NLE and posterior vectors of the class.  NLE is Without parallel data constraint as in the teacher-student learning, NLE is specially suited for the situation where the paired target-domain data cannot be simulated from the source-domain data. We adapt a 6400 hours multi-conditional US English acoustic model to each of the 9 accented English  and kids' speech . NLE achieves up to 14.1\% relative word error rate reduction over direct re-training with one-hot labels.  
 This paper proposes a neural network based speech separation method using spatially distributed microphones. Unlike with traditional microphone array settings, neither the number of microphones nor their spatial arrangement is known in advance, which hinders the use of conventional multi-channel speech separation neural networks based on fixed size input.  %While this poses challenges to neural network modeling,  %it also creates an opportunity for separation performance improvement because a broader acoustic space can be captured.  To overcome this,  a novel network architecture is proposed that interleaves inter-channel processing layers and temporal processing layers.  The inter-channel processing layers apply a self-attention mechanism along the channel dimension to exploit the information obtained with a varying number of microphones.  The temporal processing layers are based on a bidirectional long short term memory  model and applied to each channel independently.  The proposed network leverages information across time and space  by stacking these two kinds of layers alternately.  Our network estimates time-frequency  masks for each speaker,  which are then used to generate enhanced speech signals either with TF masking or beamforming.  Speech recognition experimental results show that the proposed method significantly outperforms baseline multi-channel speech separation systems.  
  In many settings it is important for one to be able to understand  a model made a particular prediction. In NLP this often entails extracting snippets of an input text `responsible for' corresponding model output; when such a snippet comprises tokens that indeed informed the model's prediction, it is a  explanation. In some settings, faithfulness may be critical to ensure transparency.  proposed a model to produce faithful rationales for neural text classification by defining independent snippet extraction and prediction modules. However, the discrete selection over input tokens performed by this method complicates training, leading to high variance and requiring careful hyperparameter tuning. We propose a simpler variant of this approach that provides faithful explanations by construction. In our scheme, named \methodname{}, arbitrary feature importance scores  are used to induce binary labels over token inputs, which an extractor can be trained to predict. An independent classifier module is then trained exclusively on snippets provided by the extractor; these snippets thus constitute faithful explanations, even if the classifier is arbitrarily complex. In both automatic and manual evaluations we find that variants of this simple framework yield predictive performance superior to `end-to-end' approaches, while being more general and easier to train.\footnote{Code is available at \url{https://github.com/successar/FRESH}} 
  A standard approach to evaluating language models analyzes how models assign probabilities to valid versus invalid syntactic constructions . Our work uses ambiguous relative clause attachment to extend such evaluations to cases of multiple simultaneous valid interpretations,  where stark grammaticality differences are absent.  We compare model performance in English and Spanish to show that non-linguistic biases in RNN LMs advantageously overlap with syntactic structure in English but not Spanish. Thus, English  models may appear to acquire human-like syntactic preferences, while models  trained on Spanish fail to acquire comparable human-like preferences. We conclude by relating these results to broader concerns about the relationship between comprehension  and production , suggesting that necessary linguistic biases are not present in the training signal at all.  
  We evaluate machine comprehension models' robustness to noise and adversarial attacks by performing novel perturbations at the character, word, and sentence level. We experiment with different amounts of perturbations to examine model confidence and misclassification rate, and contrast model performance in adversarial training with different embedding types on two benchmark datasets. We demonstrate improving model performance with ensembling. Finally, we analyze factors that effect model behavior under adversarial training and develop a model to predict model errors during adversarial attacks. 
  Sequential fine-tuning and multi-task learning are methods aiming to incorporate knowledge from multiple tasks; however, they suffer from catastrophic forgetting and difficulties in dataset balancing.  To address these shortcomings, we propose , a new two stage learning algorithm that leverages knowledge from multiple tasks. First, in the knowledge extraction stage we learn task specific parameters called adapters, that encapsulate the task-specific information. We then combine the adapters in a separate knowledge composition step.  We show that by separating the two stages, i.e., knowledge extraction and knowledge composition, the classifier can effectively exploit the representations learned from multiple tasks in a non-destructive manner. We empirically evaluate  AdapterFusion on 16 diverse NLU tasks, and find that it effectively combines various types of knowledge at different layers of the model. We show that our approach  outperforms traditional strategies such as full  fine-tuning as well as multi-task learning. Our code and adapters are available at {AdapterHub.ml}.  
 Every day, more people are becoming infected and dying from exposure to COVID-19. Some countries in Europe like Spain, France, the UK and Italy have suffered particularly badly from the virus. Others such as Germany appear to have coped extremely well. Both health professionals and the general public are keen to receive up-to-date information on the effects of the virus, as well as treatments that have proven to be effective. In cases where language is a barrier to access of pertinent information, machine translation  may help people assimilate information published in different languages. Our MT systems trained on COVID-19 data are freely available for anyone to use to help translate information published in German, French, Italian, Spanish into English, as well as the reverse direction. 
 The aim of all Question Answering  systems is to be able to generalize to unseen questions. Current supervised methods are reliant on expensive data annotation. Moreover, such annotations can introduce unintended annotator bias which makes systems focus more on the bias than the actual task. In this work, we propose Knowledge Triplet Learning , a self-supervised task over knowledge graphs. We propose heuristics to create synthetic graphs for commonsense and scientific knowledge.  We propose methods of how to use KTL to perform zero-shot QA and our experiments show considerable improvements over large pre-trained transformer models.  
 Emotion-controllable response generation is an attractive and valuable task that aims to make open-domain conversations more empathetic and engaging. Existing methods mainly enhance the emotion expression by adding regularization terms to standard cross-entropy loss and thus influence the training process. However, due to the lack of further consideration of content consistency, the common problem of response generation tasks, safe response, is intensified. Besides, query emotions that can help model the relationship between query and response are simply ignored in previous models, which would further hurt the coherence. To alleviate these problems, we propose a novel framework named Curriculum Dual Learning  which extends the emotion-controllable response generation to a dual task to generate emotional responses and emotional queries alternatively. CDL utilizes two rewards focusing on emotion and content to improve the duality. Additionally, it applies curriculum learning to gradually generate high-quality responses based on the difficulties of expressing various emotions. Experimental results show that CDL significantly outperforms the baselines in terms of coherence, diversity, and relation to emotion factors. 
     Neural Machine Translation  models are sensitive to small perturbations in the input. Robustness to such perturbations is typically measured using translation quality metrics such as BLEU on the noisy input. This paper proposes additional metrics which measure the relative degradation and changes in translation when small perturbations are added to the input. We focus on a class of models employing subword regularization to address robustness and perform extensive evaluations of these models using the robustness measures proposed. Results show that our proposed metrics reveal a clear trend of improved robustness to perturbations when subword regularization methods are used. 
    We propose a self-supervised method to solve  and  problems. Our approach exploits the characteristic structure of training corpora related to so-called ``trigger'' words, which are responsible for flipping the answer in pronoun disambiguation.   We achieve such commonsense reasoning by constructing pair-wise contrastive auxiliary predictions. To this end, we leverage a  regularized by a  margin. Our architecture is based on the recently introduced transformer networks, BERT, that exhibits strong performance on many NLP benchmarks. Empirical results show that our method alleviates the limitation of current supervised approaches for commonsense reasoning. This study opens up avenues for exploiting inexpensive self-supervision to achieve performance gain in commonsense reasoning tasks. \footnote{Code available at \url{https://github.com/SAP-samples/acl2020-commonsense/}}   
 %KN: I removed robust and interpretable from here since it is too repetitive with the 4th sentence further down. Learning representations of spatial references in natural language is a key challenge in tasks like autonomous navigation and robotic manipulation. % Recent work has investigated various neural architectures for learning multi-modal representations for spatial concepts. % However, the lack of explicit reasoning over entities makes such approaches vulnerable to noise in input text or state observations. % In this paper, we develop effective models for understanding spatial references in text that are robust and interpretable, without sacrificing performance. % We design a text-conditioned relation network whose parameters are dynamically computed with a cross-modal attention module to capture fine-grained spatial relations between entities.  % This design choice provides interpretability of learned intermediate outputs. % Experiments across three tasks demonstrate that our model achieves superior performance, with a 17\% improvement in predicting goal locations and a 15\% improvement in robustness compared to state-of-the-art systems. % %KN: I changed this because EMNLP requires code submission through supplementary material zip file, along with appendix. %\footnote{Code and data are provided in supplementary material. %} \footnote{Code is available at \url{https://sites.google.com/view/robust-relation-net/home}. } 
 Neural module networks  are a popular approach for modeling compositionality: they achieve high accuracy when applied to problems in language and vision, while  reflecting the compositional structure of the problem in the network architecture. However, prior work implicitly assumed that the structure of the network modules, describing the abstract reasoning process, provides a faithful explanation of the model's reasoning; that is, that all modules perform their intended behaviour. In this work, we propose and conduct a systematic evaluation of the intermediate outputs of NMNs on  and \drop{}, two datasets which require composing multiple reasoning steps. We find that the intermediate outputs differ from the expected output, illustrating that the network structure does not provide a faithful explanation of model behaviour. To remedy that, we train the model with auxiliary supervision and propose particular choices for module architecture that yield much better faithfulness, at a minimal cost to accuracy. 
 This document contains the instructions for preparing a manuscript for the proceedings of ACL 2020. The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like. These instructions should be used for both papers submitted for review and for final versions of accepted papers. Authors are asked to conform to all the directions reported in this document. 
 % Compared to humans' continual language acquisition, offline training of neural language models  demands large memory. Humans acquire language continually with much more limited access to data samples at a time, as compared to contemporary NLP systems. % In this paper,  To study this human-like language acquisition ability, we present \vcoll, a visually grounded language learning task, which simulates the continual acquisition of compositional phrases from streaming visual scenes. In the task, models are trained on a paired image-caption stream which has shifting object distribution; while being constantly evaluated by a visually-grounded masked language prediction task on held-out test sets. % on a regular test set and a held-out test set containing novel phrases of encountered words. \vcoll{} compounds the challenges of continual learning  and compositional generalization . To facilitate research on \vcoll{}, we construct two datasets, COCO-shift and Flickr-shift,  % which have non-stationary data-stream,  and benchmark them using different continual learning methods. % Different from  % image-classification benchmarks, % Experiments on \vcoll{} reveal that gains from % state-of-art continual learning algorithms in the image classification task fail to generalize on both regular and novel composition splits. % This suggests composition brings in additional challenges for continual learning. % show very similar performance to a simple experience replay baseline, and perform poorly novel compositions suggesting the challenge is far from solved. Results reveal that SoTA continual learning approaches provide little to no improvements on \vcoll{}, since storing examples of all possible compositions is infeasible. % which suggests learning compositions is significantly tougher than image-classification since storing . % Experiments revealthat gains from state-of-the-art continual learning algorithms on image-classification tasks fail to transfer, % to \vcoll,  % which suggests composition brings in additional challenges for continual learning. We conduct further ablations and analysis to guide future work}. % on continual learning and composition generalization. % and substantially lower than offline-training,    % continual learning benchmarks using  % We find that unlike image-classification, state-of-art continual algorithms have very similar performance  % experiment with visual-language transformers  % Experiments is far from solved,  % and poses new problems than existing continual learning benchmarks.  
 We address a challenging and practical task of labeling questions in speech in real time during telephone calls to emergency medical services in English, which embeds within a broader decision support system for emergency call-takers. We propose a novel multimodal approach to real-time sequence labeling in speech. Our model treats speech and its own textual representation as two separate modalities or views, as it jointly learns from streamed audio and its noisy transcription into text via automatic speech recognition. Our results show significant gains of jointly learning from the two modalities when compared to text or audio only, under adverse noise and limited volume of training data. The results generalize to medical symptoms detection where we observe a similar pattern of improvements with multimodal learning. 
 We propose to train a non-autoregressive machine translation model to minimize the energy defined by a pretrained autoregressive model. In particular, we view our non-autoregressive translation system as an inference network  trained to minimize the autoregressive  teacher energy.  This contrasts with the popular approach of training a non-autoregressive model on a distilled corpus consisting of the beam-searched outputs of such a teacher model.  Our approach, which we call } 
 Zero-shot transfer learning for multi-domain dialogue state tracking can allow us to handle new domains without incurring the high cost of data acquisition.  This paper proposes new zero-short transfer learning technique for dialogue state tracking where the in-domain training data are all synthesized from an abstract dialogue model and the ontology of the domain. %This paper proposes augmenting zero-shot training with synthesized dialogues for new domains, using a domain-independent dialogue model, and a few domain templates   %derived from studying a few real conversations.   %We use domain-independent templates to specify the correspondence between natural language utterances and transitions of abstract dialogues; we use domain-dependent templates to supply the vocabulary of the domain.  We can automatically synthesize dialogues to cover the space of dialogues of a new domain by applying a sampling of these templates.  We show that data augmentation through synthesized data can improve the accuracy of zero-shot learning for both the TRADE model and the BERT-based SUMBT model on the MultiWOZ 2.1 dataset. We show training with only synthesized in-domain data on the SUMBT model can reach about 2/3 of the accuracy obtained with the full training dataset.   We improve the zero-shot learning state of the art on average across domains by 21\%. % The improvement obtained ranges from 3\% to 30\% on different domains .   
 Confidence calibration, which aims to make model predictions equal to the true correctness measures, is important for neural machine translation  because it is able to offer useful indicators of translation errors in the generated output. % by LY While prior studies have shown that NMT models trained with label smoothing are well-calibrated on the ground-truth training data, we find that miscalibration still remains a severe challenge for NMT during inference due to the discrepancy between training and inference. % by LY By carefully designing experiments on three language pairs, our work provides in-depth analyses of the correlation between calibration and translation performance as well as linguistic properties of miscalibration and reports a number of interesting findings that might help humans better analyze, understand and improve NMT models. % by LY Based on these observations, we further propose a new graduated label smoothing method that can improve both inference calibration and translation performance..} % by LY 
 Self-attention networks  with selective mechanism has produced substantial improvements in various NLP tasks by concentrating on a subset of input words. However, the underlying reasons for their strong performance have not been well explained.  In this paper, we bridge the gap by assessing the strengths of selective SANs , which are implemented with a flexible and universal Gumbel-Softmax.  Experimental results on several representative NLP tasks, including natural language inference, semantic role labelling, and machine translation, show that SSANs consistently outperform the standard SANs. Through well-designed probing experiments, we empirically validate that the improvement of SSANs can be attributed in part to mitigating two commonly-cited weaknesses of SANs: {. Specifically, the selective mechanism improves SANs by paying more attention to content words that contribute to the meaning of the sentence. The code and data are released at {\url{https://github.com/xwgeng/SSAN}}. 
 Aspect Based Sentiment Analysis  is the task of identifying sentiment polarity of a text given another text segment or aspect. In ABSA, a text can have multiple sentiments depending upon each aspect. Aspect Term Sentiment Analysis  is a subtask of ABSA, in which aspect terms are contained within the given sentence. Most of the existing approaches proposed for ATSA, incorporate aspect information through a different subnetwork thereby overlooking the advantage of aspect terms' presence within the sentence. In this paper, we propose a model that leverages the positional information of the aspect. The proposed model introduces a decay mechanism based on position. This decay function mandates the contribution of input words for ABSA. The contribution of a word declines as farther it is positioned from the aspect terms in the sentence. The performance is measured on two standard datasets from SemEval 2014 Task 4. In comparison with recent architectures, the effectiveness of the proposed model is demonstrated.   
 The neural attention model has achieved great success in data-to-text generation tasks.  Though usually excelling at producing fluent text, it suffers from the problem of information missing, repetition and ``hallucination''.  Due to the black-box nature of the neural attention architecture, avoiding these problems in a systematic way is non-trivial.  To address this concern, we propose to explicitly segment target text into fragment units and align them with their data correspondences.  The segmentation and correspondence are jointly learned as latent variables without any human annotations.  We further impose a soft statistical constraint to regularize the segmental granularity.  The resulting architecture maintains the same expressive power as neural attention models, while being able to generate fully interpretable outputs with several times less computational cost.  On both E2E and WebNLG benchmarks, we show the proposed model consistently outperforms its neural attention counterparts. 
 We present Neural Machine Translation  training using document-level metrics with batch-level documents. Previous sequence-objective approaches to NMT training focus exclusively on sentence-level metrics like sentence BLEU which do not correspond to the desired evaluation metric, typically document BLEU. Meanwhile research into document-level NMT training focuses on data or model architecture rather than training procedure. We find that each of these lines of research has a clear space in it for the other, and propose merging them with a scheme that allows a document-level evaluation metric to be used in the NMT training objective.  We first sample pseudo-documents from sentence samples. We then approximate the expected document BLEU gradient with Monte Carlo sampling for use as a cost function in Minimum Risk Training . This two-level sampling procedure gives NMT performance gains over sequence MRT and maximum-likelihood training. We demonstrate that training is more robust for document-level metrics than with sequence metrics. We further demonstrate improvements on NMT with TER and Grammatical Error Correction  using GLEU, both metrics used at the document level for evaluations.  
  Recently many efforts have been devoted to interpreting the black-box NMT models, but little progress has been made on metrics to evaluate explanation methods. Word Alignment Error Rate can be used as such a metric that matches human understanding, however, it can not measure explanation methods on those target words that are not aligned to any source word. This paper thereby makes an initial attempt to evaluate explanation methods from an alternative viewpoint.  To this end, it proposes a principled metric based on fidelity in regard to the predictive behavior of the NMT model.  As the exact computation for this metric is intractable, we employ an efficient approach as its approximation. % On six standard translation tasks, we quantitatively evaluate several explanation methods in terms of the proposed metric and we reveal some valuable findings for these explanation methods in our experiments. 
 This document contains the instructions for preparing a manuscript for the proceedings of ACL 2020. The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like. These instructions should be used for both papers submitted for review and for final versions of accepted papers. Authors are asked to conform to all the directions reported in this document. 
 Conversational search plays a vital role in conversational information seeking.  As queries in information seeking dialogues are ambiguous for traditional ad-hoc information retrieval  systems due to the coreference and omission resolution problems inherent in natural language dialogue, resolving these ambiguities is crucial.  In this paper, we tackle conversational passage retrieval , an important component of conversational search, by addressing query ambiguities with query reformulation integrated into a multi-stage ad-hoc IR system. Specifically, we propose two conversational query reformulation  methods:  term importance estimation and  neural query rewriting. For the former, we expand conversational queries using important terms extracted from the conversational context with frequency-based signals. For the latter, we reformulate conversational queries into natural, standalone, human-understandable queries with a pretrained sequence-to-sequence model. Detailed analyses of the two CQR methods are provided quantitatively and qualitatively, explaining their advantages, disadvantages, and distinct behaviors. Moreover, to leverage the strengths of both CQR methods, we propose combining their output with reciprocal rank fusion, yielding state-of-the-art retrieval effectiveness, 30\% improvement in terms of NDCG@3 compared to the best submission of TREC CAsT 2019. 
  We investigate how automated, data-driven, personalized feedback in a large-scale intelligent tutoring system  improves student learning outcomes. We propose a machine learning approach to generate personalized feedback, which takes individual needs of students into account. We utilize state-of-the-art machine learning and natural language processing techniques to provide the students with personalized hints, Wikipedia-based explanations, and mathematical hints. Our model is used in Korbit,\footnote{\url{https://www.korbit.ai}} a large-scale dialogue-based ITS with thousands of students launched in 2019, and we demonstrate that the personalized feedback leads to considerable improvement in student learning outcomes and in the subjective evaluation of the feedback. %Intelligent tutoring systems  have been shown to be highly effective at promoting learning as compared to other computer-based instructional approaches. %However, many ITS rely heavily on expert design and hand-crafted rules. %This makes them difficult to build and transfer across domains, and limits their potential efficacy. %In this paper, we investigate how automated, data-driven, personalized feedback in a large-scale intelligent tutoring system  improves student learning outcomes. %Firstly, we propose a machine learning approach to generate personalized feedback in an automated way, which takes individual needs of students into account, while alleviating the need of expert intervention and design of hand-crafted rules. %We utilize state-of-the-art machine learning and natural language processing techniques to provide the students with personalized feedback along three different dimensions: personalized hints and explanations, Wikipedia-based explanations, and mathematical hints. %Secondly, we demonstrate that the personalized feedback leads to improved learning gains in practice: our personalized feedback model is used in Korbit,\footnote{\url{https://www.korbit.ai}} a large-scale dialogue-based ITS with over $5,000$ students launched in 2019. %We present the results of experiments with students and show that the automated, data-driven, personalized feedback leads to considerable improvement in student learning outcomes and in the subjective evaluation of the feedback.    %  
 Due to its great importance in deep natural language understanding and various down-stream applications, text-level parsing of discourse rhetorical structure  has been drawing more and more attention in recent years. However, all the previous studies on text-level discourse parsing adopt bottom-up approaches, which much limit the DRS determination on local information and fail to well benefit from global information of the overall discourse. In this paper, we justify from both computational and perceptive points-of-view that the top-down architecture is more suitable for text-level DRS parsing. On the basis, we propose a top-down neural architecture toward text-level DRS parsing. In particular, we cast discourse parsing as a recursive split point ranking task, where a split point is classified to different levels according to its rank and the elementary discourse units  associated with it are arranged accordingly. In this way, we can determine the complete DRS as a hierarchical tree structure via an encoder-decoder with an internal stack. Experimentation on both the English RST-DT corpus and the Chinese CDTB corpus shows the great effectiveness of our proposed top-down approach towards text-level DRS parsing. 
 			Speech directed to children differs from adult-directed speech in linguistic aspects such as repetition, word choice, and sentence length, as well as in aspects of the speech signal itself, such as prosodic and phonemic variation. Human language acquisition research indicates that child-directed speech helps language learners. This study explores the effect of child-directed speech when learning to extract semantic information from speech directly. We compare the task performance of models trained on adult-directed speech  and child-directed speech . We find indications that CDS helps in the initial stages of learning, but eventually, models trained on ADS reach comparable task performance, and generalize better. The results suggest that this is at least partially due to linguistic rather than acoustic properties of the two registers, as we see the same pattern when looking at models trained on acoustically comparable synthetic speech.  		 	
   The tasks of aspect identification and term extraction remain challenging in natural language processing. While supervised methods achieve high scores, it is hard to use them in real-world applications due to the lack of labelled datasets. Unsupervised approaches outperform these methods on several tasks, but it is still a challenge to extract both an aspect and a corresponding term, particularly in the multi-aspect setting. In this work, we present a novel unsupervised neural network with convolutional multi-attention mechanism, that allows extracting pairs  simultaneously, and demonstrate the effectiveness on the real-world dataset. We apply a special loss aimed to improve the quality of multi-aspect extraction. The experimental study demonstrates, what with this loss we increase the precision not only on this joint setting but also on aspect prediction only. 
 Multi-task learning  has achieved remarkable success in natural language processing applications. In this work, we study a multi-task learning model with multiple decoders on varieties of biomedical and clinical natural language processing tasks such as text similarity, relation extraction, named entity recognition, and text inference. Our empirical results demonstrate that the MTL fine-tuned models outperform state-of-the-art transformer models  by 2.0\% and 1.3\% in biomedical and clinical domains, respectively. Pairwise MTL further demonstrates more details about which tasks can improve or decrease others. This is particularly helpful in the context that researchers are in the hassle of choosing a suitable model for new problems. The code and models are publicly available at \url{https://github.com/ncbi-nlp/bluebert}. 
 Task-oriented dialog systems rely on dialog state tracking  to monitor the user's goal during the course of an interaction. Multi-domain and open-vocabulary settings complicate the task considerably and demand scalable solutions. In this paper we present a new approach to DST which makes use of various copy mechanisms to fill slots with values. Our model has no need to maintain a list of candidate values. Instead, all values are extracted from the dialog context on-the-fly. A slot is filled by one of three copy mechanisms:  Span prediction may extract values directly from the user input;  a value may be copied from a system inform memory that keeps track of the system's inform operations;  a value may be copied over from a different slot that is already contained in the dialog state to resolve coreferences within and across domains. Our approach combines the advantages of span-based slot filling methods with memory methods to avoid the use of value picklists altogether. We argue that our strategy simplifies the DST task while at the same time achieving state of the art performance on various popular evaluation sets including MultiWOZ 2.1, where we achieve a joint goal accuracy beyond 55\%. 
 Functional Distributional Semantics provides a linguistically interpretable framework for distributional semantics, by representing the meaning of a word as a function , instead of a vector. However, the large number of latent variables means that inference is computationally expensive, and training a model is therefore slow to converge. In this paper, I introduce the Pixie Autoencoder, which augments the generative model of Functional Distributional Semantics with a graph-convolutional neural network to perform amortised variational inference. This allows the model to be trained more effectively, achieving better results on two tasks , and outperforming BERT, a large pre-trained language model. 
   Dialogue engines that incorporate different types of agents to converse with humans are popular.    However, conversations are dynamic in the sense that a selected response will change the conversation on-the-fly, influencing the subsequent utterances in the conversation, which makes the response selection a challenging problem.     We model the problem of selecting the best response from a set of responses generated by a heterogeneous set of dialogue agents by taking into account the conversational history, and propose a  method.    The proposed method is trained to predict a coherent set of responses within a single conversation, considering its own predictions via a curriculum training mechanism.     Our experimental results show that the proposed method can accurately select the most appropriate responses, thereby significantly improving the user experience in dialogue systems. 
 Unsupervised machine translation  has recently achieved impressive results with monolingual corpora only.  However, it is still challenging to associate source-target sentences in the latent space. As people speak different languages biologically share similar visual systems, the potential of achieving better alignment through visual content is promising yet under-explored in unsupervised multimodal MT . In this paper, we investigate how to utilize visual content for disambiguation and promoting latent space alignment in unsupervised MMT. Our model employs multimodal back-translation and features pseudo visual pivoting in which we learn a shared multilingual visual-semantic embedding space and incorporate visually-pivoted captioning as additional weak supervision. The experimental results on the widely used Multi30K dataset show that the proposed model significantly improves over the state-of-the-art methods and generalizes well when the images are not available at the testing time. 
 Neural machine translation  needs large parallel corpora for state-of-the-art translation quality. Low-resource NMT is typically addressed by transfer learning which leverages large monolingual or parallel corpora for pre-training. Monolingual pre-training approaches such as MASS  are extremely effective in boosting NMT quality for languages with small parallel corpora. However, they do not account for linguistic information obtained using syntactic analyzers which is known to be invaluable for several Natural Language Processing  tasks. To this end, we propose JASS, Japanese-specific Sequence to Sequence, as a novel pre-training alternative to MASS for NMT involving Japanese as the source or target language. JASS is joint BMASS  and BRSS  pre-training which focuses on Japanese linguistic units called bunsetsus. In our experiments on ASPEC Japanese--English and News Commentary Japanese--Russian translation we show that JASS can give results that are competitive with if not better than those given by MASS. Furthermore, we show for the first time that joint MASS and JASS pre-training gives results that significantly surpass the individual methods indicating their complementary nature. We will release our code, pre-trained models and bunsetsu annotated data as resources for researchers to use in their own NLP tasks. \\ \newline \Keywords{pre-training, neural machine translation, bunsetsu, low resource
 In encoder-decoder neural models, multiple encoders are in general used to represent the contextual information in addition to the individual sentence. In this paper, we investigate multi-encoder approaches in document-level neural machine translation . Surprisingly, we find that the context encoder does not only encode the surrounding sentences but also behaves as a noise generator. This makes us rethink the real benefits of multi-encoder in context-aware translation - some of the improvements come from robust training. We compare several methods that introduce noise and/or well-tuned dropout setup into the training of these encoders. Experimental results show that noisy training plays an important role in multi-encoder-based NMT, especially when the training data is small. Also, we establish a new state-of-the-art on IWSLT Fr-En task by careful use of noise generation and dropout methods. 
Generative feature matching network  is an approach for training state-of-the-art implicit generative models for images by performing moment matching on features from pre-trained neural networks. In this paper, we present new GFMN formulations that are effective for sequential data. Our experimental results show the effectiveness of the proposed method, SeqGFMN, for three distinct generation tasks:%unconditional text generation, %class-conditional text generation,  %and unsupervised text style transfer. %SeqGFMN is stable to train and outperforms various adversarial approaches for text generation and text style transfer. %
 In recent years there has been a burgeoning interest in the use of computational methods to distinguish between elicited speech samples produced by patients with dementia, and those from healthy controls. The difference between perplexity estimates from two neural language models  - one trained on transcripts of speech produced by healthy participants and the other trained on transcripts from patients with dementia - as a single feature for diagnostic classification of unseen transcripts has been shown to produce state-of-the-art performance. However, little is known about why this approach is effective, and on account of the lack of case/control matching in the most widely-used evaluation set of transcripts , it is unclear if these approaches are truly diagnostic, or are sensitive to other variables. In this paper, we interrogate neural LMs trained on participants with and without dementia using synthetic narratives previously developed to simulate progressive semantic dementia by manipulating lexical frequency. We find that perplexity of neural LMs is strongly and differentially associated with lexical frequency, and that a mixture model resulting from interpolating control and dementia LMs improves upon the current state-of-the-art for models trained on transcript text exclusively.  
   Showing items that do not match search query intent degrades customer experience in e-commerce. These mismatches result from counterfactual biases of the ranking algorithms toward noisy behavioral signals such as clicks and purchases in the search logs. Mitigating the problem requires a large labeled dataset, which is expensive and time-consuming to obtain.  In this paper, we develop a deep, end-to-end model that learns to effectively classify mismatches and to generate hard mismatched examples to improve the classifier. We train the model end-to-end by introducing a latent variable into the cross-entropy loss that alternates between using the real and generated samples. This not only makes the classifier more robust but also  boosts the overall ranking performance. Our model achieves a relative gain compared to baselines by over $26\%$ in F-score, and over $17 \%$ in Area Under PR curve. On live search traffic, our model gains significant improvement in multiple countries.  
 The standard training algorithm in neural machine translation  suffers from exposure bias, and alternative algorithms have been proposed to mitigate this. However, the practical impact of exposure bias is under debate. In this paper, we link exposure bias to another well-known problem in NMT, namely the tendency to generate hallucinations under domain shift. In experiments on three datasets with multiple test domains, we show that exposure bias is partially to blame for hallucinations, and that training with Minimum Risk Training, which avoids exposure bias, can mitigate this. Our analysis explains why exposure bias is more problematic under domain shift, and also links exposure bias to the beam search problem, i.e.\ performance deterioration with increasing beam size. Our results provide a new justification for methods that reduce exposure bias: even if they do not increase performance on in-domain test sets, they can increase model robustness to domain shift. 
 We apply a generative segmental model of task structure, guided by narration, to action segmentation in video. We focus on unsupervised and weakly-supervised settings where no action labels are known during training. Despite its simplicity, our model performs competitively with previous work on a dataset of naturalistic instructional videos. Our model allows us to vary the sources of supervision used in training, and we find that both task structure and narrative language provide large benefits in segmentation quality. {https://github.com/dpfried/action-segmentation}. } 
  %As new state-of-the-art language models  continue to be released with impressive frequency, \todo{our methods of evaluating these models have largely remained the same}.\pengcomment{State-of-the-art neural models have achieved impressive perplexity results on major language modelling benchmarks, but it remains unclear whether optimizing for low perplexity leads to better syntactic generalization. Despite a growing body of works on targeted linguistic evaluation, we still lack systematic assessments due to  a lack of standardization across published test suites and controlled comparion across models.  Here we present a scaled-up and controlled ... }   While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites.  We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size , we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance. %We find that model architecture clearly influences syntactic generalization performance: Transformer models and models with explicit hierarchical structure reliably outperform pure sequence models in their predictions. In contrast, we find no clear influence of the scale of training data on these syntactic generalization tests across tested models. We also find no clear relation between a model's perplexity and its syntactic generalization performance. .} %\todo{[cut last sentence?]} Our results demonstrate that sustained effort to scale up and carefully control targeted evaluation can lead to more robust and empirically-grounded understanding of recent gains made in natural language processing.   %A growing body of work advocates that assessment of LMs should include both information-theoretic metrics, such as perplexity, as well as targeted linguistic evaluation. However, developing a robust benchmark for measuring LMs' syntactic capabilities is hampered by a lack of standardization across published test suites. Furthermore, existing targeted evaluation studies do not perform a controlled comparison between model inductive bias and training data size. We present a scaled-up and controlled pipeline for targeted syntactic evaluation using 34 test suites across 16 combinations of model architecture and training datasets, which we release along with this paper. We find that model architecture accounts for larger gains in targeted evaluation scores than training data size, with models afforded structural supervision during training outperforming purely sequence models. Our results demonstrate that sustained effort to scale up and carefully control targeted evaluation can lead to more robust and empirically-grounded understanding of recent gains made in natural language processing.  % A growing body of work advocates that assessment of neural language models should include both information-theoretic metrics, such as perplexity, as well as targeted linguistic evaluation. However, progress towards developing a benchmark for neural language models' syntactic capabilities is hampered by a lack of standardization across published test suites and no controlled comparison between model inductive bias and training data size. We present a scaled-up and controlled pipeline for targeted syntactic evaluation, on 34 targeted test suites across 16 model-architecture$\times$training-data-size combinations, which we release along with this paper. We find that model architecture accounts for larger gains in targeted evaluation scores than training data size, with models afforded structural supervision during training outperforming purely sequence models. As state-of-the-art neural LMs continue to be released with impressive frequency, our results demonstrate that sustained effort to scale up and carefully control targeted evaluation can lead to more robust and empirically-grounded understanding of recent gains made in natural language processing.  
 As a key component in a dialogue system, dialogue state tracking plays an important role. It is very important for dialogue state tracking to deal with the problem of unknown slot values. As far as we known, almost all existing approaches depend on pointer mechanism to solve the unknown slot value problem. These pointer mechanism-based methods usually have a hidden assumption that there is at most one out-of-vocabulary word in an unknown slot value because of the character of a pointer mechanism. However, often, there are multiple out-of-vocabulary words in an unknown slot value, and it makes the existing methods perform bad. To tackle the problem, in this paper, we propose a novel Context-Sensitive Generation network  which can facilitate the representation of out-of-vocabulary words when generating the unknown slot value. Extensive experiments show that our proposed method performs better than the state-of-the-art baselines. 
 The field of machine translation has progressed tremendously in recent years. Even though the translation quality has improved significantly, current systems are still unable to produce uniformly acceptable machine translations for the variety of possible use cases. In this work, we put machine translation in a cross-lingual pipeline and introduce downstream tasks to define task-specific acceptability of machine translations. This allows us to leverage parallel data to automatically generate acceptability annotations on a large scale, which in turn help to learn acceptability detectors for the downstream tasks. We conduct experiments to demonstrate the effectiveness of our framework for a range of downstream tasks and translation models. 
 Adversarial training is a technique of improving model performance by involving adversarial examples in the training process. In this paper, we investigate adversarial training with multiple adversarial examples to benefit the relation extraction task. We also apply adversarial training technique in semi-supervised scenarios to utilize unlabeled data. The evaluation results on protein-protein interaction and protein subcellular localization task illustrate adversarial training provides improvement on the supervised model, and is also effective on involving unlabeled data in the semi-supervised training case. In addition, our method achieves state-of-the-art performance on two benchmarking datasets. 
 Often in language and other areas of cognition, whether two components of an object are identical or not determine whether it is well formed. We call such constraints identity effects. When developing a system to learn well-formedness from examples, it is easy enough to build in an identify effect. But can identity effects be learned from the data without explicit guidance? We provide a simple framework in which we can rigorously prove that {algorithms satisfying simple criteria} cannot make the correct inference. We then show that a broad class of algorithms including deep neural networks with standard architecture and training with backpropagation satisfy our criteria, . Finally, we demonstrate our theory with computational experiments {in which we explore the effect of different input encodings on the ability of algorithms to generalize to novel inputs}.     Keywords:  identity effects, machine learning, neural networks, generalization 
 Dialogue policy optimization often obtains feedback until task completion in task-oriented dialogue systems.  This is insufficient for training intermediate dialogue turns since supervision signals  are only provided at the end of dialogues. To address this issue, reward learning has been introduced to learn from state-action pairs of an optimal policy to provide turn-by-turn rewards.  This approach requires complete state-action annotations of human-to-human dialogues , which is labor intensive.  To overcome this limitation, we propose a novel reward learning approach for semi-supervised policy learning. The proposed approach learns a dynamics model as the reward function which models dialogue progress  based on expert demonstrations, either with or without annotations. The dynamics model computes rewards by predicting whether the dialogue progress is consistent with expert demonstrations. We further propose to learn action embeddings for a better generalization of the reward function. The proposed approach outperforms competitive policy learning baselines on MultiWOZ, a benchmark multi-domain dataset.    
 % \footnote{email: huangjunheng@baidu.com, panlu01@baidu.com} Comment generation, a new and challenging task in Natural Language Generation , attracts a lot of attention in recent years. However, comments generated by previous work tend to lack pertinence and diversity. In this paper, we propose a novel generation model based on Topic-aware Pointer-Generator Networks , which can utilize the topic information hidden in the articles to guide the generation of pertinent and diversified comments. Firstly, we design a keyword-level and topic-level encoder attention mechanism to capture topic information in the articles. Next, we integrate the topic information into pointer-generator networks to guide comment generation. Experiments on a large scale of comment generation dataset show that our model produces the valuable comments and outperforms competitive baseline models significantly.  % we synthesize topic information by a LDA model and an extractive model. Next, we integrate the topic information into pointer-generator networks to guide comment generation. Experiments on a large scale of comment generation dataset show that our model produces the multiple valuable comments and outperforms competitive baseline models significantly.   % Comment generation, a new and challenging task in Natural Language Generation , attracts a lot of attention in recent years. Comments generated by previous works tend to lack informativeness and diversity. In this work, we propose a novel generation model based on Topic-aware Pointer-Generator Networks , which focuses on constructing multiple topic-aware information in articles to guide informative and diversified comments generation. In detail, we design a method for building training dataset. Then, we propose a word-level and a topic-level encoder attention mechanisms to capture the topic-aware information in the article. Finally, we leverage the topic-aware information to guide comment generation. Experiments on a large scale comments dataset show that our model produces the multiple high-quality comments and achieves the state-of-the-art performance. 
 	Most image captioning models are autoregressive, \ie they generate each word by conditioning on previously generated words, which leads to heavy latency during inference. Recently, non-autoregressive decoding has been proposed in machine translation to speed up the inference time by generating all words in parallel. Typically, these models use the word-level cross-entropy loss to optimize each word independently. However, such a learning process fails to consider the sentence-level consistency, thus resulting in inferior generation quality of these non-autoregressive models. In this paper, we propose a Non-Autoregressive Image Captioning  model with a novel training paradigm: Counterfactuals-critical Multi-Agent Learning . CMAL formulates NAIC as a multi-agent reinforcement learning system where positions in the target sequence are viewed as agents that learn to cooperatively maximize a sentence-level reward. Besides, we propose to utilize massive unlabeled images to boost captioning performance. Extensive experiments on MSCOCO image captioning benchmark show that our NAIC model achieves a performance comparable to state-of-the-art autoregressive models, while brings $13.9\times$ decoding speedup.  
 Curriculum Learning  is the idea that learning on a training set sequenced or ordered in a manner where samples range from easy to difficult, results in an increment in performance over otherwise random ordering. The idea parallels cognitive science's theory of how human brains learn, and that learning a difficult task can be made easier by phrasing it as a sequence of easy to difficult tasks. This idea has gained a lot of traction in machine learning and image processing for a while and recently in Natural Language Processing . In this paper, we apply the ideas of curriculum learning, driven by SentiWordNet in a sentiment analysis setting. In this setting, given a text segment, our aim is to extract its sentiment or polarity. SentiWordNet is a lexical resource with sentiment polarity annotations. By comparing performance with other curriculum strategies and with no curriculum, the effectiveness of the proposed strategy is presented. Convolutional, Recurrence, and Attention-based architectures are employed to assess this improvement. The models are evaluated on a standard sentiment dataset, Stanford Sentiment Treebank. These authors have contributed equally to this work}   
 Over the last few years two promising research directions in low-resource neural machine translation  have emerged. The first focuses on utilizing high-resource languages to improve the quality of low-resource languages via multilingual NMT. The second direction employs monolingual data with self-supervision to pre-train translation models, followed by fine-tuning on small amounts of supervised data. In this work, we join these two lines of research and demonstrate the efficacy of monolingual data with self-supervision in multilingual NMT. We offer three major results:  Using monolingual data significantly boosts the translation quality of low-resource languages in multilingual models.  Self-supervision improves zero-shot translation quality in multilingual models.  Leveraging monolingual data with self-supervision provides a viable path towards adding new languages to multilingual models, getting up to 33 BLEU on WMT ro-en translation without any parallel data or back-translation. 
 Generating multi-sentence descriptions for videos is one of the most challenging captioning tasks due to its high requirements for not only visual relevance but also discourse-based coherence across the sentences in the paragraph.  Towards this goal, we propose a new approach called Memory-Augmented Recurrent Transformer , which uses a memory module to augment the transformer architecture.  The memory module generates a highly summarized memory state from the video segments and the sentence history so as to help better prediction of the next sentence , thus encouraging coherent paragraph generation.  Extensive experiments, human evaluations, and qualitative analyses on two popular datasets ActivityNet Captions and YouCookII show that MART generates more coherent and less repetitive paragraph captions than baseline methods, while maintaining relevance to the input video events.\footnote{All code is available open-source at \url{https://github.com/jayleicn/recurrent-transformer}} 
 The abstract of a scientific paper distills the contents of the paper into a short paragraph. In the biomedical literature, it is customary to structure an abstract into discourse categories like BACKGROUND, OBJECTIVE, METHOD, RESULT, and CONCLUSION, but this segmentation is uncommon in other fields like computer science. Explicit categories could be helpful for more granular, that is, discourse-level search and recommendation. The sparsity of labeled data makes it challenging to construct supervised machine learning solutions for automatic discourse-level segmentation of abstracts in non-bio domains. In this paper, we address this problem using transfer learning. In particular, we define three discourse categories -- BACKGROUND, TECHNIQUE, OBSERVATION -- for an abstract because these three categories are the most common. We train a deep neural network on structured abstracts from PubMed, then fine-tune it on a small hand-labeled corpus of computer science papers. We observe an accuracy of $75\%$ on the test corpus. We perform an ablation study to highlight the roles of the different parts of the model. Our method appears to be a promising solution to the automatic segmentation of abstracts, where the labeled data is sparse. 
       %Many of the foundational techniques that underlie modern computational linguistics make two fundamental assumptions:  that many words consist of only one morpheme and  that techniques that work well on English and other widely used European languages will also work across typologically diverse languages of the world. A major component of the second assumption is the notion that words  serve as the primary meaning-bearing units within a sentence.  Many techniques in modern computational linguistics and natural language processing  make the assumption that approaches that work well on English and other widely used European  languages are ``language agnostic'' -- that is that they will also work across the typologically diverse languages of the world. % In high-resource languages, especially those that are analytic rather than synthetic, a common approach is to treat morphologically-distinct variants of a common root  as completely independent word types.  % Doing so relies on two main assumptions: that there exist a limited number of morphological inflections for any given root, and that most or all of those variants will appear in a large enough corpus  so that the model can adequately learn statistics about each variant. % Approaches like stemming, lemmatization, morphological analysis, subword segmentation, or other normalization techniques are frequently used when either of those assumptions are likely to be violated, particularly in the case of synthetic languages like Czech and Russian that have more inflectional morphology than English.  Within the NLP literature, agglutinative languages like Finnish and Turkish are commonly held up as extreme examples of morphological complexity that challenge common modelling assumptions.  Yet, when considering all of the world閳ユ獨 languages, Finnish and Turkish are closer to the average case in terms of synthesis. % When we consider polysynthetic languages , even approaches like stemming, lemmatization, or subword modelling may not suffice. %be fatally flawed. % These languages have very high numbers of hapax legomena , underscoring the need for appropriate morphological handling of words, without which there is no hope for a model to capture enough statistical information about those words. % Moreover, many of these languages have only very small text corpora, substantially magnifying these challenges.  To this end, we examine the current state-of-the-art in language modelling, machine translation, and predictive text completion in the context of four polysynthetic languages: Guaran閾,   %
     In this study, we reported our exploration of Text-To-Speech without Text  in the Zero Resource Speech Challenge 2020, in which participants proposed an end-to-end, unsupervised system that learned speech recognition and TTS together.     We addressed the challenge using biologically/psychologically motivated modules of Artificial Neural Networks , with a particular interest in unsupervised learning of human language as a biological/psychological problem.     The system first processes Mel Frequency Cepstral Coefficient  frames with an Echo-State Network , and simulates computations in cortical microcircuits.     The outcome is discretized by our original Variational Autoencoder  that implements the Dirichlet-based Bayesian clustering widely accepted in computational linguistics and cognitive science.     The discretized signal is then reverted into sound waveform via a neural-network implementation of the source-filter model for speech production. 
 Structural heterogeneity between knowledge graphs is an outstanding challenge for entity alignment. This paper presents Neighborhood Matching Network , a novel entity alignment framework for tackling the structural heterogeneity challenge. NMN estimates the similarities between entities to capture both the topological structure and the neighborhood difference. It provides two innovative components for better learning representations for entity alignment. It first uses a novel graph sampling method to distill a discriminative neighborhood for each entity. It then adopts a cross-graph neighborhood matching module to jointly encode the neighborhood difference for a given entity pair. Such strategies allow NMN to effectively construct matching-oriented entity representations while ignoring noisy neighbors that have a negative impact on the alignment task. Extensive experiments performed on three entity alignment datasets show that NMN can well estimate the neighborhood similarity in more tough cases and significantly outperforms 12 previous state-of-the-art methods.  
 This paper proposes Dynamic Memory Induction Networks  for few-shot text classification. The model utilizes dynamic routing to provide more flexibility to memory-based few-shot learning in order to better adapt the support sets, which is a critical capacity of few-shot classification models. Based on that, we further develop  induction models with query information, aiming to enhance the generalization ability of meta-learning. The proposed model achieves new state-of-the-art results on the miniRCV1 and ODIC dataset, improving the best performance  by 2$\sim$4$\%$. Detailed analysis is further performed to show the effectiveness of each component. 
 Natural Questions is a new challenging machine reading comprehension benchmark with two-grained answers, which are a long answer  and a short answer .  Despite the effectiveness of existing methods on this benchmark, they treat these two sub-tasks individually during training while ignoring their dependencies. To address this issue, we present a novel multi-grained machine reading comprehension framework that focuses on modeling documents at their hierarchical nature, which are different levels of granularity: documents, paragraphs, sentences, and tokens. We utilize graph attention networks to obtain different levels of representations so that they can be learned simultaneously. The long and short answers can be extracted from paragraph-level representation and token-level representation, respectively. In this way, we can model the dependencies between the two-grained answers to provide evidence for each other. We jointly train the two sub-tasks, and our experiments show that our approach significantly outperforms previous systems at both long and short answer criteria.  % At the time of submission , our ensemble model has achieved the state-of-the-art results on both long answer and short answer leaderboard of Natural Questions, which are F1 scores of 74.5\% and 58.7\% respectively.  % Our ensemble model also surpasses single human performance on the development dataset at both long and short answer criteria.  % We present a novel multi-grained machine reading comprehension framework that focuses on modeling long documents at different levels of granularities: documents, paragraphs, sentences, and tokens. % % Motivated by strong representation learning ability of graph neural networks,  % We utilize graph attention networks on top of BERT to jointly capture different levels of information and structural features of the document. % %for multi-granularity answers so that different levels of information can be considered. % To verify our method, we conduct our experiment on Natural Questions, a new challenging machine reading comprehension benchmark for its long evidence documents and two-level answers. % % We jointly train long answer selection and short answer extraction. % % At inference, a pipeline framework, which first select a long answer % % and then extract short answer within this long answer is applied.\whycomments{reconsideration}. % We jointly train the two sub-tasks and our experiment shows that our approach significantly outperforms baseline systems by a large margin. % At the time of submission , our ensemble model has achieved the state-of-the-art results on both long answer and short answer leaderboard of Natural Questions, which are F1 scores of 74.5\% and 58.7\% respectively. Our ensemble model also surpasses single human performance on the development dataset at both long and short answer criteria. % % To the best of our knowledge, our model is the first model that surpasses single human performance on the development dataset at both long and short answer criteria. 
 Hate speech detection is a critical problem in social media platforms, being often accused for enabling the spread of hatred and igniting physical violence. Hate speech detection requires overwhelming resources including high-performance computing for online posts and tweets monitoring as well as thousands of human experts for daily screening of suspected posts or tweets. Recently, Deep Learning -based solutions have been proposed for automatic detection of hate speech, using modest-sized training datasets of few thousands of hate speech sequences. While these methods perform well on the specific datasets, their ability to detect new hate speech sequences is limited and has not been investigated. Being a data-driven approach, it is well known that DL surpasses other methods whenever a scale-up in train dataset size and diversity is achieved. Therefore, we first present a dataset of 1 million realistic hate and non-hate sequences, produced by a deep generative language model. We further utilize the generated dataset to train a well-studied DL-based hate speech detector, and demonstrate consistent and significant performance improvements across five public hate speech datasets. Therefore, the proposed solution enables high sensitivity detection of a very large variety of hate speech sequences, paving the way to a fully automatic solution.  
 		 		The PICO framework  is usually used to formulate evidence in the medical domain. The major task of PICO extraction is to extract sentences from medical literature and classify them into each class. However, in most circumstances, there will be more than one evidences in an extracted sentence even it has been categorized to a certain class. In order to address this problem, we propose a step-wise disease Named Entity Recognition  extraction and PICO identification method. With our method, sentences in paper title and abstract are first classified into different classes of PICO, and medical entities are then identified and classified into P and O. Different kinds of deep learning frameworks are used and experimental results show that our method will achieve high performance and fine-grained extraction results comparing with conventional PICO extraction works. 		 	
 Recent advances in neural machine translation  have led to state-of-the-art results for many European-based translation tasks. However, despite these advances, there is has been little focus in applying these methods to African languages. In this paper, we seek to address this gap by creating an NMT benchmark BLEU score between English and the ten remaining official languages in South Africa. 
 Algorithmic bias has the capacity to amplify and perpetuate societal bias, and presents profound ethical implications for society. Gender bias in algorithms has been identified in the context of employment advertising and recruitment tools, due to their reliance on underlying language processing and recommendation algorithms. Attempts to address such issues have involved testing learned associations, integrating concepts of fairness to machine learning, and performing more rigorous analysis of training data. Mitigating bias when algorithms are trained on textual data is particularly challenging given the complex way gender ideology is embedded in language. This paper proposes a framework for the identification of gender bias in training data for machine learning. The work draws upon gender theory and sociolinguistics to systematically indicate levels of bias in textual training data and associated neural word embedding models, thus highlighting pathways for both removing bias from training data and critically assessing its impact in the context of search and recommender systems.   %historical data that conveys biases in terms of imbalances and inequalities. These hidden biases are unfortunately captured in the learned patterns, and often emphasized in the results these algorithms provide to users. When a bias affects a sensitive attribute of a user, such as their gender or religion, the inequalities that are reinforced by search and recommendation algorithms even lead to severe societal consequences, like users discrimination.  %taken from into %Machine learning has the capacity to profoundly influence gender equality in society. Increasingly, everyday applications are incorporating machine learning technologies that categorise individuals and form generalisations from large collections of data. If the data explicitly or inadvertently captures existing inequalities or a world-view that is misaligned with societal goals, then the resulting applications may perpetuate gender bias .     
 We present a method for combining multi-agent communication and traditional data-driven approaches to natural language learning, with an end goal of teaching agents to communicate with humans in natural language.  Our starting point is a language model that has been trained on generic, not task-specific language data. We then place this model in a multi-agent self-play environment that generates task-specific rewards used to adapt or modulate the model, turning it into a task-conditional language model. We introduce a new way for combining the two types of learning based on the idea of reranking language model samples, and show that this method outperforms others in communicating with humans in a visual referential communication task. Finally, we present a taxonomy of different types of language drift that can occur alongside a set of measures to detect them. 
 Sequence labeling systems should perform reliably not only under ideal conditions but also with corrupted inputs---as these systems often process user-generated text or follow an error-prone upstream component. To this end, we formulate the noisy sequence labeling problem, where the input may undergo an unknown noising process and  propose two Noise-Aware Training  objectives that improve robustness of sequence labeling performed on perturbed input: Our data augmentation method trains a neural model using a mixture of clean and noisy samples, whereas our stability training algorithm encourages the model to create a noise-invariant latent representation. We employ a vanilla noise model at training time. For evaluation, we use both the original data and its variants perturbed with real OCR errors and misspellings. Extensive experiments on English and German named entity recognition benchmarks confirmed that NAT consistently improved robustness of popular sequence labeling models, preserving accuracy on the original input. We make our code and data publicly available for the research community.  
 Videos uploaded on social media are often accompanied with textual descriptions. In building automatic speech recognition  systems for videos, we can exploit the contextual information provided by such video metadata. In this paper, we explore ASR lattice rescoring by selectively attending to the video descriptions.  We first use an attention based method to extract contextual vector representations of video metadata, and use these representations as part of the inputs to a neural language model during lattice rescoring.  Secondly, we propose a hybrid pointer network approach to explicitly interpolate the word probabilities of the word occurrences in metadata.  We perform experimental evaluations on both language modeling and ASR tasks,  and demonstrate that both proposed methods provide performance improvements by selectively leveraging the video metadata.  % auto-captioning system.   `pointer mechanism' % which explicitly boost the word probability if the word occurs in the text description.  to improve language models %  English and Spanish video ASR,  can outperform the n-gram and LSTM baseline  
 The usage of transformers has grown from learning about language semantics to forming meaningful visiolinguistic representations. These architectures are often over-parametrized, requiring large amounts of computation. In this work, we extend adaptive approaches to learn more about model interpretability and computational efficiency. Specifically, we study attention spans, sparse, and structured dropout methods to help understand how their attention mechanism extends for vision and language tasks. We further show that these approaches can help us learn more about how the network perceives the complexity of input sequences, sparsity preferences for different modalities, and other related phenomena. 
   Entity linking, the task of mapping textual mentions to known   entities, has recently been tackled using contextualized neural   networks. We address the question whether these results --- reported   for large, high-quality datasets such as Wikipedia --- transfer to   practical business use cases, where labels are scarce, text is   low-quality, and terminology is highly domain-specific.    Using an entity linking model based on BERT, a popular transformer   network in natural language processing, we show that a neural   approach outperforms and complements hand-coded heuristics, with   improvements of about 20\% top-1 accuracy. Also, the benefits of   transfer learning on a large corpus are demonstrated, while   fine-tuning proves difficult. Finally, we compare different   BERT-based architectures and show that a simple sentence-wise   encoding  offers a fast yet efficient search in   practice. 
 Named entity recognition  is an extensively studied task that extracts and classifies named entities in a text. NER is crucial not only in downstream language processing applications such as relation extraction and question answering but also in large scale big data operations such as real-time analysis of online digital media content. Recent research efforts on Turkish, a less studied language with morphologically rich nature, have demonstrated the effectiveness of neural architectures on well-formed texts and yielded state-of-the art results by formulating the task as a sequence tagging problem. In this work, we empirically investigate the use of recent neural architectures  proposed for Turkish NER tagging in the same setting. Our results demonstrate that transformer-based networks which can model long-range context overcome the limitations of BiLSTM networks where different input features at the character, subword, and word levels are utilized. We also propose a transformer-based network with a conditional random field  layer that leads to the state-of-the-art result  on a common dataset. Our study contributes to the literature that quantifies the impact of transfer learning on processing morphologically rich languages.       
  This paper presents research uncovering systematic gender bias in the representation of political leaders in the media, using artificial intelligence. Newspaper coverage of Irish ministers over a fifteen year period  was gathered and analysed with natural language processing techniques and machine learning. Findings demonstrate evidence of gender bias in the portrayal of female politicians, the kind of policies they were associated with and how they were evaluated in terms of their performance as political leaders. This paper also sets out a methodology whereby media content may be analysed on a large scale utilising techniques from artificial intelligence within a theoretical framework founded in gender theory and feminist linguistics.    
 Identifying controversial posts on social media is a fundamental task for mining public sentiment, assessing the influence of events, and alleviating the polarized views. However, existing methods fail to 1) effectively incorporate the semantic information from content-related posts; 2) preserve the structural information for reply relationship modeling; 3) properly handle posts from topics dissimilar to those in the training set. To overcome the first two limitations, we propose \underline{T}opic-\underline{P}ost-\underline{C}omment \underline{G}raph \underline{C}onvolutional \underline{N}etwork , which integrates the information from the graph structure and content of topics, posts, and comments for post-level controversy detection. As to the third limitation, we extend our model to Disentangled TPC-GCN , to disentangle topic-related and topic-unrelated features and then fuse dynamically. Extensive experiments on two real-world datasets demonstrate that our models outperform existing methods. Analysis of the results and cases proves that our models can integrate both semantic and structural information with significant generalizability. 
 Recently, open domain multi-turn chatbots have attracted much interest from lots of researchers in both academia and industry. The dominant retrieval-based methods use context-response matching mechanisms for multi-turn response selection. Specifically, the state-of-the-art methods perform the context-response matching by word or segment similarity. However, these models lack a full exploitation of the sentence-level semantic information, and make simple mistakes that humans can easily avoid. In this work, we propose a matching network, called sequential sentence matching network , to use the sentence-level semantic information to address the problem. Firstly and most importantly, we find that by using the sentence-level semantic information, the network successfully addresses the problem and gets a significant improvement on matching, resulting in a state-of-the-art performance. Furthermore, we integrate the sentence matching we introduced here and the usual word similarity matching reported in the current literature, to match at different semantic levels. Experiments on three public data sets show that such integration further improves the model performance. 
 In this paper, we study machine reading comprehension  on long texts, where a model takes as inputs a lengthy document and a question and then extracts a text span from the document as an answer. State-of-the-art models tend to use a pretrained transformer model  to encode the joint contextual information of document and question. However, these transformer-based models can only take a fixed-length  text as its input. To deal with even longer text inputs, previous approaches usually chunk them into  segments and predict answers based on each segment independently without considering the information from other segments. As a result, they may form segments that fail to cover the correct answer span or retain insufficient contexts around it, which significantly degrades the performance. Moreover, they are less capable of answering questions that need cross-segment information.  We propose to let a model learn to chunk in a more flexible way via reinforcement learning: a model can decide the next segment that it wants to process in either direction. We also employ recurrent mechanisms to enable information to flow across segments. Experiments on three MRC datasets -- CoQA, QuAC, and TriviaQA -- demonstrate the effectiveness of our proposed recurrent chunking mechanisms: we can obtain segments that are more likely to contain complete answers and at the same time provide sufficient contexts around the ground truth answers for better predictions. 
 In sequence-to-sequence learning, the decoder relies on the attention mechanism to efficiently extract information from the encoder. While it is common practice to draw information from only the last encoder layer, recent work has proposed to use representations from different encoder layers for diversified levels of information. Nonetheless, the decoder still obtains only a single view of the source sequences, which might lead to insufficient training of the encoder layer stack due to the hierarchy bypassing problem. In this work, we propose layer-wise cross-view decoding, where for each decoder layer, together with the representations from the last encoder layer, which serve as a global view, those from other encoder layers are supplemented for a stereoscopic view of the source sequences. Systematic experiments show that we successfully address the hierarchy bypassing problem and substantially improve the performance of sequence-to-sequence learning with deep representations on diverse tasks.   
  Probabilistic word embeddings have shown effectiveness in capturing notions of generality and entailment, but there is very little work on doing the analogous type of investigation for sentences. In this paper we define probabilistic models that produce distributions for sentences. Our best-performing model treats each word as a linear transformation operator applied to a multivariate Gaussian distribution. We train our models on paraphrases and demonstrate that they naturally capture sentence specificity. While our proposed model achieves the best performance overall, we also show that specificity is represented by simpler architectures via the norm of the sentence vectors. Qualitative analysis shows that our probabilistic model captures sentential entailment and provides ways to analyze the specificity and preciseness of individual words.           
 Long short-term memory  networks and their variants are capable of encapsulating long-range dependencies, which is evident from their performance on a variety of linguistic tasks. On the other hand, simple recurrent networks , which appear more biologically grounded in terms of synaptic connections, have generally been less successful at capturing long-range dependencies as well as the loci of grammatical errors in an unsupervised setting. In this paper, we seek to develop models that bridge the gap between biological plausibility and linguistic competence. We propose a new architecture, the Decay RNN, which incorporates the decaying nature of neuronal activations and models the excitatory and inhibitory connections in a population of neurons. Besides its biological inspiration, our model also shows competitive performance relative to LSTMs on subject-verb agreement, sentence grammaticality, and language modeling tasks. These results provide some pointers towards probing the nature of the inductive biases required for RNN architectures to model linguistic phenomena successfully. %Long short-term memory  and its variants, a group of recurrent networks, are capable of encapsulating long term dependencies, which is evident by their performance on the linguistic tasks. On the other hand, a simple recurrent network , which has more biological grounding in terms of synaptic connections, has consistently failed on capturing long term dependencies as well as the locus of grammatical errors in an unsupervised setting. In this paper, we use insights from psycholinguistics to develop a model that bridges the gap between neurological persuasiveness and commendable performance on linguistic tasks. We propose a new architecture-  which incorporates the decaying nature of voltage in a neuron membrane at the same time modeling the excitatory and inhibitory connections in the population of neurons. Besides its biological plausibility, our model also has a competitive performance to LSTM  on subject-verb agreement, sentence grammaticality, and language modeling tasks. The results on our model open the room to probe the nature of inductive biases responsible for the laudable or substandard performance of certain architectures. 
 %Email is one of the most popular collaborative communication media.  Spammers take advantage of email popularity to send indiscriminately unsolicited emails. Although researchers and organizations continuously develop anti-spam filters based on binary classification, spammers bypass them through new strategies, like word obfuscation or image-based spam. For the first time in literature, we propose to classify spam email in categories to improve the handle of already detected spam emails, instead of just using a binary model. First, we applied a hierarchical clustering algorithm to create SPEMC-$11$K , the first multi-class dataset, which contains three types of spam emails: Health and Technology, Personal Scams, and Sexual Content. Then, we used SPEMC-$11$K to evaluate the combination of TF-IDF and BOW encodings with Na鑼倂e Bayes, Logistic Regression and SVM classifiers. Finally, we recommend for the task of multi-class spam classification the use of  TF-IDF combined with SVM for the best micro F1 score performance, $95.39\%$, and  TD-IDF along with NB for the fastest spam classification, analyzing an email in $2.13$ms.   
 The timings of spoken response offsets in human dialogue have been shown to vary based on contextual elements of the dialogue. We propose neural models that simulate the distributions of these response offsets, taking into account the response turn as well as the preceding turn. The models are designed to be integrated into the pipeline of an incremental spoken dialogue system . We evaluate our models using offline experiments as well as human listening tests. We show that human listeners consider certain response timings to be more natural based on the dialogue context. The introduction of these models into SDS pipelines could increase the perceived naturalness of interactions.\footnote{\ Our code is available at \url{https://github.com/mattroddy/RTNets}.} 
   This paper deals with cross-lingual transfer learning for dialogue act  recognition.   Besides generic contextual information gathered from pre-trained BERT embeddings, our objective is to   transfer models trained on a standard English DA corpus to two other languages,   German and French, and to potentially very different types of dialogue with different dialogue acts   than the standard well-known DA corpora. The proposed approach thus studies the applicability   of automatic DA recognition to specific tasks that may not benefit from a large enough number   of manual annotations. A key component of our architecture is the automatic translation module,   which limitations are addressed by stacking both foreign and translated words sequences into the same model.   We further compare both CNN and multi-head self-attention to compute the speaker turn embeddings   and show that in low-resource situations, the best results are obtained by combining all sources of   transferred information. 
 Recent work has described neural-network-based agents that are trained with reinforcement learning  to execute language-like commands in simulated worlds, as a step towards an intelligent agent or robot that can be instructed by human users. However, the optimisation of multi-goal motor policies via deep RL from scratch requires many episodes of experience. Consequently, instruction-following with deep RL typically involves language generated from templates , which does not reflect the varied or ambiguous expressions of real users. Here, we propose a conceptually simple method for training instruction-following agents with deep RL that are robust to natural human instructions. By applying our method with a state-of-the-art pre-trained text-based language model , on tasks requiring agents to identify and position everyday objects relative to other objects in a naturalistic 3D simulated room, we demonstrate substantially-above-chance zero-shot transfer from synthetic template commands to natural instructions given by humans. Our approach is a general recipe for training any deep RL-based system to interface with human users, and bridges the gap between two research directions of notable recent success: agent-centric motor behavior and text-based representation learning.  
 Recent studies have revealed a number of pathologies of neural machine translation  systems. Hypotheses explaining these mostly suggest there is something fundamentally wrong with NMT as a model or its training algorithm, maximum likelihood estimation . Most of this evidence was gathered using maximum   decoding, a decision rule aimed at identifying the highest-scoring translation, \ie the mode. We argue that the evidence corroborates the inadequacy of MAP decoding more than casts doubt on the model and its training algorithm. In this work, we show that translation distributions do reproduce various statistics of the data well, but that beam search strays from such statistics. We show that some of the known pathologies and biases of NMT are due to MAP decoding and not to NMT's statistical assumptions nor MLE. In particular, we show that the most likely translations under the model accumulate so little probability mass that the mode can be considered essentially arbitrary. We therefore advocate for the use of decision rules that take into account the translation distribution holistically. We show that an approximation to minimum Bayes risk decoding gives competitive results confirming that NMT models do capture important aspects of translation well in expectation. 
 %The Motivation of this paper is dialogue state representation? But after reading this paper, I am quite confused. It seems that teachers teach nothing about the dialogue state representation. They, nevertheless, impart their learnt dialogue policy by learning a better dialogue state representation in their domain.  \\ How to build a high-quality multi-domain dialogue system is a challenging work due to its  complicated and entangled dialogue state space among each domain, which seriously limits the quality of dialogue policy, and further affects the generated response. In this paper, we propose a novel method to acquire a satisfying policy and subtly circumvent the knotty dialogue state representation problem in the multi-domain setting. Inspired by real school teaching scenarios, our method is composed of multiple domain-specific teachers and a universal student. Each individual teacher only focuses on one specific domain and learns its corresponding domain knowledge and dialogue policy based on a precisely extracted single domain dialogue state representation. Then, these domain-specific teachers impart their domain knowledge and policies to a universal student model and collectively make this student model a multi-domain dialogue expert. Experiment results show that our method reaches competitive results with SOTAs in both multi-domain and single domain setting.   % How to build a high-quality multi-domain dialogue system is a challenging work due to its knotty state representation problem.  % Neither the state tracking approach nor the hidden vector approach can handle the complicated and entangled state space of multi-domain dialogue systems,  % Dialogue state representation is a bottleneck for multi-domain dialo which seriously affects the multi-domain dialogue system policy.  % In this paper, we propose a Multiple Teachers Single Student~ model to acquire a superior dialogue policy.  % Instead of directly tackling the complicated dialogue state representation problem in multi-domain setting, we acquire a superior multi-domain dialogue policy by using multiple teachers to learn a precise dialogue policy in each domain. These domain teachers impart their dialogue policy of their corresponding dialogue domain to a single student model and collectively make this student model a multi-domain dialogue expert.    % To our best knowledge, this is the first work to utilize MTSS model to cope with the challenging multi-domain dialogue system problem. Experiment results shows that our method outperform STOAs in both multi-domain and single domain setting.  % Dialogue systems dealing with multi-domain tasks are highly required. How to record the dialogue states remains a crucial problem in a task-oriented dialogue system. A general method is to use human-defined features as dialogue states and apply a state tracker to extract these features from users' utterances. However, in a multi-domain setting, the accuracy of a state tracker is low due to the vast amount of the features. The external state tracker limits the performance of the dialogue system. In this paper, we propose a multi-domain dialogue generation model that needs no external state trackers and still benefits from human-labelled semantic data. We use a teacher-student framework. Firstly, several teacher models are trained in their respective domains, learning dialogue policies from labelled states. Then the learned knowledge and experience are merged and transferred to a universal student model. The student model takes only raw utterance as its input. Experiments show that the dialogue system trained under our framework outperforms the one uses a belief tracker.    
  % Quality Estimation  is an important component in making Machine Translation  useful in real-world applications. Existing approaches require large amounts of expert annotated data, computation and time for training. As an alternative, we devise an unsupervised approach to QE where no training or access to additional resources besides the MT system itself is required. By exploiting methods for uncertainty quantification, we achieve substantial gains in correlation with human judgments of quality, \revised{rivalling state-of-the-art supervised QE models.} % significantly outperforming state-of-the-art in supervised QE. % system. % To evaluate our approach we collect the first dataset that enables further work on unsupervised QE.  Quality Estimation  is an important component in making Machine Translation  useful in real-world applications, as it is aimed to inform the user on the quality of the MT output at test time. Existing approaches require large amounts of expert annotated data, computation and time for training. As an alternative, we devise an unsupervised approach to QE where no training or access to additional resources besides the MT system itself is required. Different from most of the current work that treats the MT system as a black box, we explore useful information that can be extracted from the MT system as a by-product of translation. By employing methods for uncertainty quantification, we achieve very good correlation with human judgments of quality, rivalling state-of-the-art supervised QE models. To evaluate our approach we collect the first dataset that enables work on both black-box and glass-box approaches to QE. 
  Neural sequence labelling approaches have achieved state of the art results in morphological tagging. We evaluate the efficacy of four standard sequence labelling models on Sanskrit, a morphologically rich, fusional Indian language. As its label space can theoretically contain more than 40,000 labels, systems that explicitly model the internal structure of a label are more suited for the task, because of their ability to generalise to labels not seen during training. We find that although some neural models perform better than others, one of the common causes for error for all of these models is mispredictions due to syncretism.\footnote{Code and data available at \url{https://github.com/ashim95/sanskrit-morphological-taggers}} 
     Named Entity Recognition  in domains like e-commerce is an understudied problem due to the lack of annotated datasets. Recognizing novel entity types in this domain, such as products, components, and attributes, is challenging because of their linguistic complexity and the low coverage of existing knowledge resources. To address this problem, we present a bootstrapped positive-unlabeled learning algorithm that integrates domain-specific linguistic features to quickly and efficiently expand the seed dictionary. The model achieves an average F1 score of $72.02\%$ on a novel dataset of product descriptions, an improvement of $3.63\%$ over a baseline BiLSTM classifier, and in particular exhibits better recall . % 
 Neural machine translation  is nowadays commonly applied at the subword level, using byte-pair encoding. A promising alternative approach focuses on character-level translation, which simplifies processing pipelines in NMT considerably. This approach, however, must consider relatively longer sequences, rendering the training process prohibitively expensive. In this paper, we discuss a novel, Transformer-based approach, that we compare, both in speed and in quality to the Transformer at subword and character levels, as well as previously developed character-level models. We evaluate our models on 4 language pairs from WMT閳15: DE-EN, CS-EN, FI-EN and RU-EN. The proposed novel architecture can be trained on a single GPU and is $\sim$34\% faster than the character-level Transformer; still, the obtained results are at least on par with it. In addition, our proposed model outperforms the subword-level model in FI-EN and shows close results in CS-EN. To stimulate further research in this area and close the gap with subword-level NMT, we make all our code and models publicly available. 
 This study aims to provide a comparative analysis of performance of certain models popular in machine learning and the BERT model on the Stanford Question Answering Dataset . The analysis shows that the BERT model, which was once state-of-the-art on SQuAD, gives higher accuracy in comparison to other models. However, BERT requires a greater execution time even when only 100 samples are used. This shows that with increasing accuracy more amount of time is invested in training the data. Whereas in case of preliminary machine learning models, execution time for full data is lower but accuracy is compromised. 
 %%Batch IS NOT Heavy: Learning Word Representations From All Samples Pair-based metric learning has been widely adopted to learn sentence embedding in many NLP tasks such as semantic text similarity due to its efficiency in computation. Most existing works employed a sequence encoder model and utilized limited sentence pairs with a pair-based loss to learn discriminating sentence representation. However, it is known that the sentence representation can be biased when the sampled sentence pairs deviate from the true distribution of all sentence pairs. In this paper, our theoretical analysis shows that existing works severely suffered from a good pair sampling and instance weighting strategy. Instead of one time pair selection and learning on equal weighted pairs, we propose a unified locality weighting and learning framework to learn task-specific sentence embedding. Our model, SentPWNet, exploits the neighboring spatial distribution of each sentence as locality weight to indicate the informative level of sentence pair. Such weight is updated along with pair-loss optimization in each round, ensuring the model keep learning the most informative sentence pairs. Extensive experiments on four public available datasets and a self-collected place search benchmark with 1.4 million places clearly demonstrate that our model consistently outperforms existing sentence embedding methods with comparable efficiency.  
 Spoken Language Understanding  converts hypotheses from automatic speech recognizer  into structured semantic representations. ASR recognition errors can severely degenerate the performance of the subsequent SLU module. To address this issue, word confusion networks  have been used as the input for SLU, which contain richer information than 1-best or n-best hypotheses list. To further eliminate ambiguity, the last system act of dialogue context is also utilized as additional input. In this paper, a novel BERT based SLU model  is proposed to encode WCNs and the dialogue context jointly. It can integrate both structural information and ASR posterior probabilities of WCNs in the BERT architecture. Experiments on DSTC2, a benchmark of SLU, show that the proposed method is effective and can outperform previous state-of-the-art models significantly.  % Spoken Language Understanding  converts hypotheses from automatic speech recognizer  into structured semantic representations. Hypotheses errors can significantly degrade the subsequent SLU performance. To address the problem, word confusion networks , which contain richer information than 1-best or n-best hypotheses list, have been used as the input for SLU. The basic component of WCN is , containing multiple word candidates and their posterior probabilities. Previous work computes a feature vector for each bin separately without considering its context. In this paper, a novel WCN based Transformer model is proposed to include context information. The Transformer encodes each word candidate in all bins using a self-attention mechanism. To consider the posterior probability of each word candidate given by ASR, score embedding and re-weighted attention mechanism are proposed. Experiments on DSTC2, a benchmark SLU dataset, show that the proposed model not only outperforms previous state-of-the-art models, but also can be trained effectively and efficiently.  % kai.yu 
 Voluminous works have been implemented to exploit content-enhanced network embedding models, with little focus on the labelled information of nodes. Although TriDNR  leverages node labels by treating them as node attributes, it fails to enrich unlabelled node vectors with the labelled information, which leads to the weaker classification result on the test set in comparison to existing unsupervised textual network embedding models. In this study, we design an integrated node encoder  for textual networks which is jointly trained on the structure-based and label-based objectives. As a result, the node encoder preserves the integrated knowledge of not only the network text and structure, but also the labelled information. Furthermore, INE allows the creation of label-enhanced vectors for unlabelled nodes by entering their node contents. Our node embedding achieves state-of-the-art performances in the classification task on two public citation networks, namely Cora and DBLP, pushing benchmarks up by 10.0\% and 12.1\%, respectively, with the 70\% training ratio. Additionally, a feasible solution that generalizes our model from textual networks to a broader range of networks is proposed. 
 Model-Agnostic Meta-Learning , a model-agnostic meta-learning method, is successfully employed in NLP applications including few-shot text classification and multi-domain low-resource language generation. Many impacting factors, including data quantity, similarity among tasks, and the balance between general language model and task-specific adaptation, can affect the performance of MAML in NLP, but few works have thoroughly studied them. In this paper, we conduct an empirical study to investigate these impacting factors and conclude when MAML works the best based on the experimental results. 
 A chatbot that converses like a human should be goal-oriented , which is beyond language generation. However, existing dialogue systems often heavily rely on cumbersome hand-crafted rules or costly labelled datasets to reach the goals. In this paper, we propose Goal-oriented Chatbots~, a framework for end-to-end training chatbots to maximize the long-term return from offline multi-turn dialogue datasets. Our framework utilizes hierarchical reinforcement learning~, where the high-level policy guides the conversation towards the final goal by determining some sub-goals, and the low-level policy fulfills the sub-goals by generating the corresponding utterance for response. In our experiments on a real-world dialogue dataset for anti-fraud in financial, our approach outperforms previous methods on both the quality of response generation as well as the success rate of accomplishing the goal.  
 Text summarization is an NLP task which aims to convert a textual document into a shorter one while keeping as much meaning as possible. This pedagogical article reviews a number of recent Deep Learning architectures that have helped to advance research in this field. We will discuss in particular applications of pointer networks, hierarchical Transformers and Reinforcement Learning. We assume basic knowledge of Seq2Seq architecture and Transformer networks within NLP. \\  
  % This document contains the instructions for preparing a manuscript for the proceedings of AACL-IJCNLP 2020. The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like. These instructions should be used for both papers submitted for review and for final versions of accepted papers. Authors are asked to conform to all the directions reported in this document. % In this paper, we describe an approach to automatically grade essays using gaze behaviour TODO: Write it better. 
 Pretrained language models such as BERT, GPT have shown great effectiveness in language understanding. The auxiliary predictive tasks in existing pretraining approaches are mostly defined on tokens, thus may not be able to capture sentence-level semantics very well. To address this issue,  we propose CERT: Contrastive self-supervised Encoder Representations from Transformers, which pretrains language representation models using contrastive self-supervised learning at the sentence level. CERT creates augmentations of original sentences using back-translation. Then it finetunes a pretrained language encoder  by predicting whether two augmented sentences originate from the same sentence. CERT is simple to use and can be flexibly plugged into any pretraining-finetuning NLP pipeline. We evaluate CERT on 11 natural language understanding tasks in the GLUE benchmark where CERT outperforms BERT on 7 tasks, achieves the same performance as BERT on 2 tasks, and performs worse than BERT on 2 tasks. On the averaged score of the 11 tasks, CERT outperforms BERT.  The data and code are available at \url{https://github.com/UCSD-AI4H/CERT} %. CERT uses contrastive self-supervised learning  to continue to pretrain a pretrained text representation model such as BERT, GPT, XLNet using the input texts in the target task. Then the pretrained model is fine-tuned on the target task using the input texts and their labels in the target task.  
 The BERT model has arisen as a popular state-of-the-art model in recent years. It is able to cope with NLP tasks such as supervised text classification without human supervision. Its flexibility to cope with any corpus delivering great results has make this approach very popular in academia and industry. Although, other approaches have been used before successfully. We first present BERT and a review on classical NLP approaches. Then, we empirically test with a suite of different scenarios the behaviour of BERT against traditional TF-IDF vocabulary fed to machine learning algorithms. The purpose of this work is adding empirical evidence to support the use of BERT as a default on NLP tasks. Experiments show the superiority of BERT and its independence of features of the NLP problem such as the language of the text adding empirical evidence to use BERT as a default technique in NLP problems.  
  Email remains one of the most frequently used means of online communication. People spend significant amount of time every day on emails to exchange information, manage tasks and schedule events. Previous work has studied different ways for improving email productivity by prioritizing emails, suggesting automatic replies or identifying intents to recommend appropriate actions. The problem has been mostly posed as a supervised learning problem where models of different complexities were proposed to classify an email message into a predefined taxonomy of intents or classes. The need for labeled data has always been one of the largest bottlenecks in training supervised models. This is especially the case for many real-world tasks, such as email intent classification, where large scale annotated examples are either hard to acquire or unavailable due to privacy or data access constraints. Email users often take actions in response to intents expressed in an email . Such actions can be inferred from user interaction logs. In this paper, we propose to leverage user actions as a source of weak supervision, in addition to a limited set of annotated examples, to detect intents in emails. We develop an end-to-end robust deep neural network model for email intent identification that leverages both clean annotated data and noisy weak supervision along with a self-paced learning mechanism. Extensive experiments on three different intent detection tasks show that our approach can effectively leverage the weakly supervised data to improve intent detection in emails.  %The need for labeled data is one of the largest bottlenecks in training supervised learning models. This is especially the case for many real-world tasks where large scale annotated examples are either too expensive to acquire or unavailable due to privacy or data access constraints. Many of these tasks involve users and as such allow access to a rich set of user {  %People nowadays spend a significantly amount of time in emails for online communication and collaboration. Identify email intent and further help users manage emails are important to enhance work productivity and task management efficiency. Existing approaches on email intent detection try to leverage deep learning to learn effective features from email contents, which often require large amount of annotated data. However, in practice, annotated data is usually limited in the scale, and rich information user  % interactions other than email contents are ignored. In addition, in email conversations, user interactions may not directly aligns \ms{Did you mean to comment out the last two sentences too?} %with the intent labels, however they could serve as sources for weak supervision. Therefore, in this paper, we study a novel problem of learning weak supervision from user interactions for email intent detection. We propose  a principled way to extract weak supervision from user interactions and a new framework named {\m} to model multi-source supervision for email intent detection. Experimental results on real-world datasets demonstrate the effectiveness of the proposed framework. 
      We can consider Counterfactuals as belonging in the domain of Discourse structure and semantics, A core area in Natural Language Understanding and in this paper, we introduce an approach to resolving counterfactual detection as well as the indexing of the antecedents and consequents of Counterfactual statements. While Transfer learning is already being applied to several NLP tasks, It has the characteristics to excel in a novel number of tasks. We show that detecting Counterfactuals is a straightforward Binary Classification Task that can be implemented with minimal adaptation on already existing model Architectures, thanks to a well annotated training data set,and we introduce a new end to end pipeline to process antecedents and consequents as an entity recognition task, thus adapting them into Token Classification.         
 Recently, neural network based dialogue systems have become ubiquitous in our increasingly digitalized society. However, due to their inherent opaqueness, some recently raised concerns about using neural models are starting to be taken seriously. In fact, intentional or unintentional behaviors could lead to a dialogue system to generate inappropriate responses. Thus, in this paper, we investigate whether we can learn to craft input sentences that result in a black-box neural dialogue model being manipulated into having its outputs contain target words or match target sentences. We propose a reinforcement learning based model that can generate such desired inputs automatically. Extensive experiments on a popular well-trained state-of-the-art neural dialogue model show that our method can successfully seek out desired inputs that lead to the target outputs in a considerable portion of cases. Consequently, our work reveals the potential of neural dialogue models to be manipulated, which inspires and opens the door towards developing strategies to defend them. 
 In simultaneous machine translation, the objective is to determine when to produce a partial translation given a continuous stream of source words, with a  trade-off between latency  and quality. We propose a neural machine translation  model that makes dynamic decisions % as to  when to continue feeding on input or  generate output words. The model is composed of two main components: one to dynamically decide on ending a source chunk, and another  that translates the consumed chunk. We train the components jointly and in a manner consistent with the inference conditions. To generate chunked  training data, we propose a method that utilizes word alignment while also preserving enough context. We compare models with bidirectional and unidirectional encoders of different depths, both on real speech and text input.  % We demonstrate  Our results on the IWSLT\footnote{The International Conference on Spoken Language Translation, \UrlFont http://iwslt.org.} 2020 English-to-German task  % using text and speech input.  % For text, we  outperform a wait-$k$ baseline by 2.6 to 3.7\% BLEU absolute. 
 Transfer learning, particularly approaches that combine multi-task learning with pre-trained contextualized embeddings and fine-tuning, have advanced the field of Natural Language Processing tremendously in recent years.  In this paper we present  are its flexible configuration options, and the support of a variety of natural language processing tasks in a uniform toolkit, from text classification and sequence labeling to dependency parsing, masked language modeling, and text generation.\footnote{The code is available at: \url{https://github.com/machamp-nlp/machamp} , and an instructional video at \url{https://www.youtube.com/watch?v=DauTEdMhUDI}.} 
 Voice Assistants aim to fulfill user requests by choosing the best intent from multiple options generated by its Automated Speech Recognition and Natural Language Understanding sub-systems. However, voice assistants do not always produce the expected results. This can happen because voice assistants choose from ambiguous intents --- user-specific or domain-specific contextual information reduces the ambiguity of the user request. Additionally the user information-state can be leveraged to understand how relevant/executable a specific intent is for a user request. In this work, we propose a novel Energy-based model for the intent ranking task, where we learn an affinity metric and model the trade-off between extracted meaning from speech utterances and relevance/executability aspects of the intent. Furthermore we present a Multisource Denoising Autoencoder based pretraining that is capable of learning fused representations of data from multiple sources. We empirically show our approach outperforms existing state of the art methods by reducing the error-rate by 3.8\%, which in turn reduces ambiguity and eliminates undesired dead-ends leading to better user experience. Finally, we evaluate the robustness of our algorithm on the intent ranking task and show our algorithm improves the robustness by 33.3\%.  
 % \todo{The whole paper gives a distinct feel of non-american english. I think we should make it sound more american to increase our chances for acceptance.} Task-oriented dialog  systems converse with users to accomplish a specific task. This task requires the system to query a knowledge  % \todo{Weak start, repetion} base  and use the retrieved results to fulfil user needs. Predicting the KB queries is crucial and can lead to severe under-performance if made incorrectly. KB queries are usually annotated in real world datasets and are learnt using supervised approaches to achieve acceptable task completion. This need for query annotations prevents TOD systems from easily adapting to new domains.  % For training, existing dialog datasets explicitly annotate a conversation with relevant KB queries. However, real-world dialogs may not always maintain this information, preventing TOD systems from easily adapting to new domains.  % \todo{Why is this a problem?}  In this paper, we propose a novel problem of learning end-to-end TOD systems using dialogs that do not contain KB query annotations. Our approach first learns to predict the KB queries using reinforcement learning  and then learns the end-to-end system using the predicted queries. However, predicting the correct query in TOD systems is uniquely plagued by correlated attributes, in which, due to data bias, certain attributes always occur together in the KB. This prevents the RL system to generalise and accuracy suffers as a result. % We show that a natural extension of existing RL \todo{This sentence is weak and can be made crisp and clear} approaches may not learn good KB queries, when attributes in the KB are correlated. \todo{What correlation? Not clear on first read.} We propose Correlated Attributes Resilient RL ,  % \todo{Shouldn't it be CARRL?}  a modification to the RL gradient estimation, which mitigates the problem of correlated attributes and predicts KB queries better than existing % \todo{Should we use weakly supervised?}  weakly supervised approaches.  Finally, we compare the performance of our end-to-end system trained using predicted queries to a system trained using annotated gold queries. % \todo{Not very excited on first read of abstract. Problem isn't well defined in my head and no attempts to sell solution. Just have mentioned CARRL is 'much better'.}  
  In this paper, we propose a novel bipartite flat-graph network  for nested named entity recognition , which contains two subgraph modules: a flat NER module for outermost entities and a graph module for all the entities located in inner layers. Bidirectional LSTM  and graph convolutional network  are adopted to jointly learn flat entities and their inner dependencies. Different from previous models, which only consider the unidirectional delivery of information from innermost layers to outer ones , our model effectively captures the bidirectional interaction between them.  We first use the entities recognized by the flat NER module to construct an entity graph, which is fed to the next graph module.  The richer representation learned from graph module carries the dependencies of inner entities and can be exploited to improve outermost entity predictions. Experimental results on three standard nested NER datasets demonstrate that our BiFlaG outperforms previous state-of-the-art models.  
   In this paper we propose a new evaluation challenge and direction in the area of High-level Video Understanding. The challenge we are proposing is designed to test automatic video analysis and understanding, and how accurately systems can comprehend a movie in terms of actors, entities, events and their relationship to each other. A pilot High-Level Video Understanding  dataset of open source movies were collected for human assessors to build a knowledge graph representing each of them. A set of queries will be derived from the knowledge graph to test systems on retrieving relationships among actors, as well as reasoning and retrieving non-visual concepts. The objective is to benchmark if a computer system can "understand" non-explicit but obvious relationships the same way humans do when they watch the same movies. This is long-standing problem that is being addressed in the text domain and this project moves similar research to the video domain. Work of this nature is foundational to future video analytics and video understanding technologies. This work can be of interest to streaming services and broadcasters hoping to provide more intuitive ways for their customers to interact with and consume video content. 
 Walk-based models have shown their advantages in knowledge graph  reasoning by achieving decent performance while providing interpretable decisions. However, the sparse reward signals offered by the KG during traversal are often insufficient to guide a sophisticated walk-based reinforcement learning  model. An alternate approach is to use traditional symbolic methods , which achieve good performance but can be hard to generalize due to the limitation of symbolic representation. In this paper, we propose RuleGuider, which leverages high-quality rules generated by symbolic-based methods to provide reward supervision for walk-based agents. Experiments on benchmark datasets show that RuleGuider improves the performance of walk-based models without losing interpretability.  %We further separate our walk-based agent into a relation agent and an entity agent to further improve training efficiency and better leverage symbolic rules. %Experiments on public datasets demonstrate that our method can further boost state-of-the-art walk-based models. \footnote{} 
  In this paper, we consider the recent trend of evaluating progress on reinforcement learning technology by using text-based environments and games as evaluation environments. This reliance on text brings advances in natural language processing into the ambit of these agents, with a recurring thread being the use of external knowledge to mimic and better human-level performance. We present one such instantiation of agents that use commonsense knowledge from ConceptNet to show promising performance on two text-based environments.    % Over the years, simulation environments and games have become a crucial way of showcasing and driving advances in reinforcement learning technology. A recent such focus environment has been TextWorld, where an agent must interact with an external environment to achieve goals while maximizing reward - all of this using only the modality of text. This seeks to bring advances in natural language processing  and question answering solutions to agent-based reinforcement learning techniques. A common thread inherent in such solutions is that mere text-based techniques cannot achieve or beat human-level performance, and that NLP systems must instead learn how to utilize additional knowledge from external sources such as knowledge bases  and knowledge graphs  to improve their performance on such tasks. In this paper, we present the  % % first true  % use of knowledge-based embeddings from open knowledge sources like ConceptNet in order to improve the performance of a reinforcement learning agent.  % \mrinmaya{Not sure if we should say first true anything. Maybe we can just say that we present xxx model and we show that ... -- KRT: Addressed}  % In this paper, we present the first true use of knowledge-based embeddings from open knowledge sources in order to improve the performance of a reinforcement learning agent. Specifically, we consider the case of a simple reinforcement learning agent   % Question-Answering  and associated tasks have become an extremely important topic of research in the NLP and AI communities in the recent past. The kinds of questions that are handled have gone from simple factoid-based queries to more complex questions that cannot be answered purely by text-based retrieval methods. Such complex questions~ often require some kind of reasoning, and the retrieval of relevant external knowledge to support that reasoning process. The common thread inherent in the solutions to such tasks is that mere text-based techniques cannot achieve or beat human-level performance, and that NLP systems must instead learn how to utilize additional knowledge from external sources such as knowledge bases  and knowledge graphs  to improve their performance on such tasks.  % In this paper, we propose a new problem setting for the use of external knowledge in an NLP task: we seek to create and deploy agents that can learn to reason about the world around them using text and textual knowledge. Specifically, we propose to employ autonomous learning-based agents that can learn to execute sequences of actions that achieve specified goals, making use of Reinforcement Learning  techniques. RL has yielded spectacular success many times over in domains such as board games, video games, and autonomous robots. Moreover, it is commonly possible to achieve great results without building in any initial hand-crafted human knowledge for the agent to get going. The main issue with RL techniques, however, lies in their sample complexity: RL is widely known to have very high sample complexity, so that many millions of episodes may be required to learn strong behavior policies.  
   We investigate multi-task learning approaches that use a shared feature representation for all tasks.   To better understand the transfer of task information, we study an architecture with a shared module for all tasks and a separate output module for each task.   We study the theory of this setting on linear and ReLU-activated models.   Our key observation is that whether or not tasks' data are well-aligned can significantly affect the performance of multi-task learning.   We show that misalignment between task data can cause negative transfer  and  provide sufficient conditions for positive transfer.   Inspired by the theoretical insights, we show that aligning tasks' embedding layers leads to performance gains for multi-task training and transfer learning on the GLUE benchmark and sentiment analysis tasks; for example, we obtain a 2.35\% GLUE score average improvement on 5 GLUE tasks over \bertlarge using our alignment method.   We also design an SVD-based task reweighting scheme and show that it improves the robustness of multi-task training on a multi-label image dataset. % 
  Neural architecture search  has advanced significantly in recent years but most NAS systems restrict search to learning architectures of a recurrent or convolutional cell. In this paper, we extend the search space of NAS. In particular, we present a general approach to learn both intra-cell and inter-cell architectures . For a better search result, we design a joint learning method to perform intra-cell and inter-cell NAS simultaneously. We implement our model in a differentiable architecture search system. For recurrent neural language modeling, it outperforms a strong baseline significantly on the PTB and WikiText data, with a new state-of-the-art on PTB. Moreover, the learned architectures show good transferability to other systems. E.g., they improve state-of-the-art systems on the CoNLL and WNUT named entity recognition  tasks and CoNLL chunking task, indicating a promising line of research on large-scale pre-learned architectures.  
 	% 閸ョ偟鐡熸稉銈勯嚋闂傤噣顣介敍 	%  婢舵俺顕㈢懛閻ㄥ埐ip reading閺勵垰鎯侀崣顖濐攽閿涙艾鍨庣猾鑽ゆ畱閸氬嫮顫掔紒鍕値閵嗕浇袙閻胶娈戦崥鍕潚缂佸嫬鎮 	%  閹绘劕鍤稉缁夊秴鎮撳銉ュ蓟閸氭垼袙閻胶娈戞径姘愁嚔鐟穕ip reading 	%  鏉堟儳鍩宻ota 	%  % 閺堫剚鏋冮崗铏暈鐎电钖勯敍姘樋鐠囶叀鈻堥懕鏂挎値閻ㄥ埐ip reading % 閸戝搫褰傞悙鐧哥窗濮ｅ繒顫掔拠顓♀枅閻ㄥ嫰鐓剁槐鐘辩闂傚娴夋禍鎺曠箾閹恒儲妲搁張澶夌鐎规俺顫夊瀣畱閿涙稑顩ч弸婊勀侀崹瀣笁閹烩茬啊娑撳秴鎮撻惃鍕嚔鐟烽幍鐎电懓绨查惃鍕箹缁夊秷顫夊瀣剁礉闁絽鐣犵亸鍗炲讲娴犮儱浠涙径姘愁嚔鐟烽惃鍒瞚p reading娴 %  % 閸╄桨绨銈忕礉閹存垳婊戦幓鎰毉娴滃摖BL濡楀棙鐏﹂妴鍌氱殺鐠囶叀鈻堢憴鍕伐閻ㄥ嫬顒熸稊鐘绘６妫版﹫绱濇潪顒瀵叉稉铏圭舶鐎规矮绗傛稉瀣瀮閻ㄥ嫭鍎忛崘鍏哥瑓鐎电懓缍嬮崜宥呭礋閸忓啰娈戦幒銊︽焽闂傤噣顣介妴 %  Lip reading has received increasing attention in recent years. This paper focuses on the synergy of multilingual lip reading. There are about as many as 7000 languages in the world, which implies that it is impractical to train separate lip reading models with large-scale data for each language. Although each language has its own linguistic and pronunciation rules, the lip movements of all languages share similar patterns due to the common structures of human organs. Based on this idea,  we try to explore the synergized learning of multilingual lip reading in this paper, and further propose a synchronous bidirectional learning  framework for effective synergy of multilingual lip reading.  We firstly introduce phonemes as our modeling units for the multilingual setting here. Phonemes are more closely related with the lip movements than the alphabet letters. At the same time, similar phonemes always lead to similar visual patterns no matter which type the target language is. Then, a novel SBL block is proposed to learn the rules for each language in a fill-in-the-blank way. Specifically, the model has to learn to infer the target unit given its bidirectional context, which could represent the composition rules of phonemes for each language. To make the learning process more targeted at each particular language, an extra task of predicting the language identity is introduced in the learning process. Finally, a thorough comparison on LRW  and LRW-1000  is performed, which shows the promising benefits from the synergized learning of different languages and also reports a new state-of-the-art result on both datasets. % 
 This paper investigates how to leverage a DurIAN-based average model to enable a new speaker to have both accurate pronunciation and fluent cross-lingual speaking with very limited monolingual data. A weakness of the recently proposed end-to-end text-to-speech  systems is that robust alignment is hard to achieve, which hinders it to scale well with very limited data. To cope with this issue, we introduce AdaDurIAN by training an improved DurIAN-based average model and leverage it to few-shot learning with the shared speaker-independent content encoder across different speakers. Several few-shot learning tasks in our experiments show AdaDurIAN can outperform the baseline end-to-end system by a large margin. Subjective evaluations also show that AdaDurIAN yields higher mean opinion score  of naturalness and more preferences of speaker similarity. In addition, we also apply AdaDurIAN to emotion transfer tasks and demonstrate its promising performance.  
 In this paper, we present the first comprehensive categorization of essential commonsense knowledge for answering the Winograd Schema Challenge . For each of the questions, we invite annotators to first provide reasons for making correct decisions and then categorize them into six major knowledge categories. By doing so, we better understand the limitation of existing methods  and shed some light on the commonsense knowledge that we need to acquire in the future for better commonsense reasoning. Moreover, to investigate whether current WSC models can understand the commonsense or they simply solve the WSC questions based on the statistical bias of the dataset, we leverage the collected reasons to develop a new task called WinoWhy, which requires models to distinguish plausible reasons from very similar but wrong reasons for all WSC questions. Experimental results prove that even though pre-trained language representation models have achieved promising progress on the original WSC dataset, they are still struggling at WinoWhy. Further experiments show that even though supervised models can achieve better performance, the performance of these models can be sensitive to the dataset distribution. WinoWhy and all codes are available at: \url{https://github.com/HKUST-KnowComp/WinoWhy}. % On top of that, we develop a new task called WinoWhy, which evaluates models' ability of understanding the commonsense knowledge by asking them to select the most  % In the end, by leveraging the existing commonsense knowledge resource, we propose the first explainable commonsense reasoning model, which outperforms all the previous models significantly on both the original Winograd schema challenge task and the new WinoWhy task.  
 An estimated half of the world's languages do not have a written form, making it impossible for these languages to benefit from any existing text-based technologies. In this paper, a speech-to-image generation  framework is proposed which translates speech descriptions to photo-realistic images without using any text information, thus allowing unwritten languages to potentially benefit from this technology. The proposed S2IG framework, named S2IGAN, consists of a speech embedding network  and a relation-supervised densely-stacked generative model . SEN learns the speech embedding with the supervision of the corresponding visual information. Conditioned on the speech embedding produced by SEN, the proposed RDG synthesizes images that are semantically consistent with the corresponding speech descriptions. Extensive experiments on datasets CUB and Oxford-102 demonstrate the effectiveness of the proposed S2IGAN on synthesizing high-quality and semantically-consistent images from the speech signal, yielding a good performance and a solid baseline for the S2IG task.  
 Recently, link prediction algorithms based on neural embeddings have gained tremendous popularity in the Semantic Web community, and     are extensively used for knowledge graph completion. While algorithmic advances have strongly focused on efficient ways of learning embeddings,     fewer attention has been drawn to the different ways their performance and robustness can be evaluated. In this work we propose an open-source     evaluation pipeline, which benchmarks the accuracy of neural embeddings in situations where knowledge graphs may experience semantic and structural changes. We     define relation-centric connectivity measures that allow us to connect the link prediction capacity to the structure of the knowledge graph.     Such an evaluation pipeline is especially important to simulate the accuracy of embeddings for knowledge graphs that are expected to be frequently updated.      %       % We focus on the link prediction problem for knowledge graphs, which is treated herein as a binary classification task on shallow knowledge graph     % embeddings. By comparing, combining and extending different methodologies for link prediction on graph-based data coming from different domains,     % we formalize a unified methodology for the quality evaluation benchmark of shallow neural embeddings for knowledge graphs. This benchmark is     % then used to empirically investigate the potential of training neural generalized embeddings once for the entire graph and test them on all     % relations, as opposed to the state-of-the-art way of training specialized embeddings one relation at a time. This new way of training the neural     % embeddings and evaluating their quality is important for scalable link prediction with limited data. We perform extensive statistical repeated     % sub-sample validation to empirically support our claims, and derive relation-centric connectivity measures for knowledge graphs to explain our     % findings. Our evaluation pipeline is made open source, and with this we aim to draw more attention of the community towards an important issue     % of transparency and reproducibility of neural embeddings evaluations.  
 Dual learning has been successfully applied in many machine learning applications including machine translation, image-to-image transformation, etc. The high-level idea of dual learning is very intuitive: if we map an $x$ from one domain to another and then map it back, we should recover the original $x$. Although its effectiveness has been empirically verified, theoretical understanding of dual learning is still very limited. In this paper, we aim at understanding why and when dual learning works. Based on our theoretical analysis, we further extend dual learning by introducing more related mappings and propose \cycle, in which we leverage feedback signals from additional domains to improve the qualities of the mappings. We prove that \cycle\ can boost the performance of standard dual learning under mild conditions. Experiments on WMT 14 English$\leftrightarrow$German and MultiUN English$\leftrightarrow$French translations verify our theoretical findings on dual learning, and the results on the translations among English, French, and Spanish of MultiUN demonstrate the effectiveness of \cycle. 
 News creation and consumption has been changing since the advent of social media. An estimated $2.95$ billion people in 2019 used social media worldwide. The widespread of the Coronavirus COVID-19 resulted with a tsunami of social media. Most platforms were used to transmit relevant news, guidelines and precautions to people. According WHO, uncontrolled conspiracy theories and propaganda are spreading faster than the COVID-19 pandemic itself, creating an {. Extensive analysis has been performed on approximately $1$ million COVID-19 related tweets collected over a period of two months. Furthermore, the profiles of $288,000$ users were analyzed including unique users' profiles, meta-data and tweets' context. The study noted various interesting conclusions including the critical impact of the  exploitation of the COVID-19 crisis to redirect readers to irrelevant topics and  widespread of unauthentic medical precautions and information. Further data analysis revealed the importance of using social networks in a global pandemic crisis by relying on credible users with variety of occupations, content developers and influencers in specific fields. In this context, several insights and findings have been provided while elaborating computing and non-computing implications and research directions for potential solutions and social networks management strategies during crisis periods.  
 Pretrained contextualized language models such as BERT have achieved impressive results on various natural language processing benchmarks. Benefiting from multiple pretraining tasks and large scale training corpora, pretrained models can capture complex syntactic word relations.  In this paper, we  %study how to  use the deep contextualized language model BERT for the task of ad hoc table retrieval. We investigate how to encode table content considering the table structure and input length limit of BERT. We also propose an approach that incorporates features from prior literature on table retrieval and jointly trains them with BERT. In experiments on public datasets, we show that our best approach can outperform the previous state-of-the-art method and BERT baselines with a large margin under different evaluation metrics.  %We also demonstrate that our methods  generalize by achieving similar improvements on the open domain WebQueryTable dataset. 
 Accurate mortality prediction allows Intensive Care Units  to adequately benchmark clinical practice and identify patients with unexpected outcomes. Traditionally, simple statistical models have been used to assess patient death risk, many times with sub-optimal performance. On the other hand deep learning holds promise to positively impact clinical practice by leveraging medical data to assist diagnosis and prediction, including mortality prediction. However, as the question of whether powerful Deep Learning models attend correlations backed by sound medical knowledge when generating predictions remains open, additional interpretability tools are needed to foster trust and encourage the use of AI by clinicians. In this work we show a Deep Learning model trained on MIMIC-III to predict mortality using raw nursing notes, together with visual explanations for word importance. Our model reaches a ROC of 0.8629 , outperforming the traditional SAPS-II score and providing enhanced interpretability when compared with similar Deep Learning approaches.  
 In this article, we describe the system that we used for the memotion analysis challenge, which is Task 8 of SemEval-2020. This challenge had three subtasks where affect based sentiment classification of the memes was required along with intensities. The system we proposed combines the three tasks into a single one by representing it as  multi-label  hierarchical  classification problem.Here,Multi-Task learning or Joint learning Procedure is used to train our model.We have used dual channels to extract text and image based features from  separate Deep Neural Network Backbone and aggregate them to create task specific features. These task specific aggregated feature vectors ware then passed on to smaller networks with dense layers, each one assigned for predicting one type of fine grain sentiment label. Our Proposed method show the superiority of this system in few tasks to other best models from the challenge. 
   Text detection in scenes based on deep neural networks have shown promising results. Instead of using word bounding box regression, recent state-of-the-art methods have started focusing on character bounding box and pixel-level prediction. This necessitates the need to link adjacent characters, which we propose in this paper using a novel Graph Neural Network  architecture that allows us to learn both node and edge features as opposed to only the node features under the typical GNN. The main advantage of using GNN for link prediction lies in its ability to connect characters which are spatially separated and have an arbitrary orientation. We show our concept on the well known SynthText dataset, achieving top results as compared to state-of-the-art methods. 
 %The fundamental issue underlying natural language understanding is that of semantics -- there is a need to move toward understanding the text at an appropriate level of abstraction, beyond the word level, in order to support access, knowledge extraction and communication.  Machine Learning and Inference methods have become ubiquitous in our attempt to induce more abstract representations of natural language text, visual scenes, and other messy, naturally occurring data, and support decisions that depend on it. However, learning models for these tasks is difficult partly because generating the necessary supervision signals for it is costly and does not scale.  This paper describes several learning paradigms that are designed to alleviate the supervision bottleneck. It will illustrate their benefit in the context of multiple problems, all pertaining to inducing various levels of semantic representations from text. % In particular, we discuss   { signals that exist in the data, independently of the task at hand, to learn models that identify and classify semantic predicates, and  the use of weak supervision to combine simple models to support global decisions where joint supervision is not available.  While these ideas are applicable in a range of Machine Learning driven fields, we will demonstrate it in the context of several natural language applications, from  text classification, to Wikification, to semantic parsing.  
  Selecting input features of top relevance has become a popular method for building self-explaining models.  In this work, we extend this selective rationalization approach to text matching, where the goal is to jointly select and align text pieces, such as tokens or sentences, as a justification for the downstream prediction. Our approach employs optimal transport  to find a minimal cost alignment between the inputs. However, directly applying OT often produces dense and therefore uninterpretable alignments. To overcome this limitation, we introduce novel constrained variants of the OT problem that result in highly sparse alignments with controllable sparsity. Our model is end-to-end differentiable using the Sinkhorn algorithm for OT and can be trained without any alignment annotations. % We evaluate our model on the StackExchange, MultiNews, e-SNLI, and MultiRC datasets. Our model achieves very sparse rationale selections with high fidelity while preserving prediction accuracy compared to strong attention baseline models.\textsuperscript{\textdagger} Denotes equal contribution.} Our code is publicly available at \url{https://github.com/asappresearch/rationale-alignment}.} 
 Opinion prediction on Twitter is challenging due to the transient nature of tweet content and neighbourhood context. In this paper, we model users' tweet posting behaviour as a temporal point process to jointly predict the posting time and the stance label of the next tweet given a user's historical tweet sequence and tweets posted by their neighbours. We design a topic-driven attention mechanism to capture the dynamic topic shifts in the neighbourhood context. Experimental results show that the proposed model predicts both the posting time and the stance labels of future tweets more accurately compared to a number of competitive baselines. 
 Detecting important events in high volume news streams is an important task for a variety of purposes. The volume and rate of online news increases the need for automated event detection methods that can operate in real time. In this paper we develop a network-based approach that makes the working assumption that important news events always involve named entities  that are linked in news articles. Our approach uses natural language processing techniques to detect these entities in a stream of news articles and then creates a time-stamped series of networks in which the detected entities are linked by co-occurrence in articles and sentences. In this prototype, weighted node degree is tracked over time and change-point detection used to locate important events. Potential events are characterized and distinguished using community detection on KeyGraphs that relate named entities and informative noun-phrases from related articles. This methodology already produces promising results and will be extended in future to include a wider variety of complex network analysis techniques. 
 Recurrent neural networks  are widely used as a memory model for sequence-related problems. Many variants of RNN have been proposed to solve the gradient problems of training RNNs and process long sequences. Although some classical models have been proposed, capturing long-term dependence while responding to short-term changes remains a challenge. To this problem, we propose a new model named Dual Recurrent Neural Networks . The DuRNN consists of two parts to learn the short-term dependence and progressively learn the long-term dependence. The first part is a recurrent neural network with constrained full recurrent connections to deal with short-term dependence in sequence and generate short-term memory. Another part is a recurrent neural network with independent recurrent connections which helps to learn long-term dependence and generate long-term memory. A selection mechanism is added between two parts to help the needed long-term information transfer to the independent neurons. Multiple modules can be stacked to form a multi-layer model for better performance. Our contributions are: 1) a new recurrent model developed based on the divide-and-conquer strategy to learn long and short-term dependence separately, and 2) a selection mechanism to enhance the separating and learning of different temporal scales of dependence. Both theoretical analysis and extensive experiments are conducted to validate the performance of our model, and we also conduct simple visualization experiments and ablation analyses for the model interpretability. Experimental results indicate that the proposed DuRNN model can handle not only very long sequences , but also short sequences very well. Compared with many state-of-the-art RNN models, our model has demonstrated efficient and better performance. 
 Self-supervised learning has attracted plenty of recent research interest. However, most works for self-supervision in speech are typically unimodal and there has been limited work that studies the interaction between audio and visual modalities for cross-modal self-supervision. This work  investigates visual self-supervision via face reconstruction to guide the learning of audio representations;  proposes an audio-only self-supervision approach for speech representation learning;  shows that a multi-task combination of the proposed visual and audio self-supervision is beneficial for learning richer features that are more robust in noisy conditions;  shows that self-supervised pretraining can outperform fully supervised training and is especially useful to prevent overfitting on smaller sized datasets. We evaluate our learned audio representations for discrete emotion recognition, continuous affect recognition and automatic speech recognition. We outperform existing self-supervised methods for all tested downstream tasks. Our results demonstrate the potential of visual self-supervision for audio feature learning and suggest that joint visual and audio self-supervision leads to more informative audio representations for speech and emotion recognition. 
 Incorporating environmental, social, and governance  considerations into systematic investments has drawn numerous attention recently.  In this paper, we focus on the ESG events in financial news flow and exploring the predictive power of ESG related financial news on stock volatility. In particular, we develop a pipeline of ESG news extraction, news representations, and Bayesian inference of deep learning models. Experimental evaluation on real data and different markets demonstrates the superior predicting performance as well as the relation of high volatility prediction to stocks with potential high risk and low return. It also shows the prospect of the proposed pipeline as a flexible predicting framework for various textual data and target variables. 
 Convolutional neural networks  have shown promising results for end-to-end speech recognition, albeit still behind RNN/transformer based models in performance. In this paper, we study how to bridge this gap and go beyond with a novel CNN-RNN-transducer architecture, which we call  that achieves good trade-off between computation and accuracy.   We demonstrate that on the widely used Librispeech benchmark,  achieves a word error rate  of 2.1\%/4.6\% without external language model , 1.9\%/4.1\% with LM and 2.9\%/7.0\% with only 10M parameters on the clean/noisy LibriSpeech test sets. This compares to the best previously published model of 2.0\%/4.6\% with LM and 3.9\%/11.3\% with 20M parameters. The superiority of the proposed  model is  also verified on a much larger internal dataset. %\jiahuiyu{Do we want to mention youtube results in abstract?}  
 Identifying multiple speakers without knowing where a speaker's voice is in a recording is a challenging task.  In this paper, a hierarchical attention network is proposed to solve a weakly labelled speaker identification problem.  The use of a hierarchical structure, consisting of a frame-level encoder and a segment-level encoder, aims to learn speaker related information locally and globally. Speech streams are segmented into fragments. The frame-level encoder with attention learns features and highlights the target related frames locally, and output a fragment based embedding. The segment-level encoder works with a second attention layer to emphasize the fragments probably related to target speakers. The global information is finally collected from segment-level module to predict speakers via a classifier. To evaluate the effectiveness of the proposed approach, artificial datasets based on Switchboard Cellular part1  and Voxceleb1 are constructed in two conditions, where speakers' voices are overlapped and not overlapped. Comparing to two baselines the obtained results show that the proposed approach can achieve better performances. Moreover, further experiments are conducted to evaluate the impact of utterance segmentation. The results show that a reasonable segmentation can slightly improve identification performances.  	 - speaker identification is more and used in real world situations where several speakers are present  - several speakers are present  in odmain triaing data is requied - however labelling of that kind of data is prohibitive.  - therefore we want to look int weak supervision  - This work proposes a network archttecture that encompasses lcoal and global selection fo data, therebey allowing to focus on speicfic speakers present in short segments  Locallly embedded information is then summarised in a global conext.  - The prposed method is evaluated on data where several speakers are present and speakers also overlap.  -  artificial datasets based on Switchboard  Cellular part1  and Voxceleb1 are constructed in two conditions.  - Compared to XX the propsed method shows significnat performance gain is YY % relative.  Experiments are conducted to evaluate the impact of utterance segmentation.   
 Many semi- and weakly-supervised approaches have been investigated for overcoming the labeling cost of building high-quality speech recognition systems. On the challenging task of transcribing social media videos in low-resource conditions, we conduct a large scale systematic comparison between two self-labeling methods on one hand, and weakly-supervised pre-training using contextual metadata on the other. We investigate distillation methods at the frame level and the sequence level for hybrid, encoder-only Connectionist Temporal Classification  based, and encoder-decoder speech recognition systems on Dutch and Romanian languages using 27,000 and 58,000 hours of unlabeled audio respectively. Although all approaches improved upon their respective baseline word error rates  by more than 8\%, sequence-level distillation for encoder-decoder models provided the largest relative WER reduction of 20\% compared to the strongest data-augmented supervised baseline. 
  Self-supervised speech models are powerful speech representation extractors for downstream applications. Recently, larger models have been utilized in acoustic model training to achieve better performance. We propose Audio ALBERT, a lite version of the self-supervised speech representation model. We apply the light-weight representation extractor to two downstream tasks, speaker classification and phoneme classification. We show that Audio ALBERT achieves performance comparable with massive pre-trained networks in the downstream tasks while having 91\% fewer parameters. Moreover, we design probing models to measure how much the latent representations can encode the speaker閳ユ獨 and phoneme閳ユ獨 information. We find that the representations encoded in internal layers of Audio ALBERT contain more information for both phoneme and speaker than the last layer, which is generally used for downstream tasks. Our findings provide a new avenue for using self-supervised networks to achieve better performance and efficiency.  
 In this paper, we explore vector quantization for acoustic unit discovery. Leveraging unlabelled data, we aim to learn discrete representations of speech that separate phonetic content from speaker-specific details.  We propose two neural models to tackle this challenge -- both use vector quantization to map continuous features to a finite set of codes. The first model is a type of vector-quantized variational autoencoder .  The VQ-VAE encodes speech into a sequence of discrete units before reconstructing the audio waveform. Our second model combines vector quantization with contrastive predictive coding .  The idea is to learn a representation of speech by predicting future acoustic units. We evaluate the models on English and Indonesian data for the ZeroSpeech 2020 challenge.  In ABX phone discrimination tests, both models outperform all submissions to the 2019 and 2020 challenges, with a relative improvement of more than 30\%.  The models also perform competitively on a downstream voice conversion task.  Of the two, VQ-CPC performs slightly better in general and is simpler and faster to train.  Finally, probing experiments show that vector quantization is an effective bottleneck, forcing the models to discard speaker information. 
   To encourage intra-class compactness and inter-class separability among trainable feature vectors, large-margin softmax methods are developed and widely applied in the face recognition community. The introduction of the large-margin concept into the softmax is reported to have good properties such as enhanced discriminative power, less overfitting and well-defined geometric intuitions. Nowadays, language modeling is commonly approached with neural networks using softmax and cross entropy. In this work, we are curious to see if introducing large-margins to neural language models would improve the perplexity and consequently word error rate in automatic speech recognition. Specifically, we first implement and test various types of conventional margins following the previous works in face recognition. To address the distribution of natural language data, we then compare different strategies for word vector norm-scaling. After that, we apply the best norm-scaling setup in combination with various margins and conduct neural language models rescoring experiments in automatic speech recognition. We find that although perplexity is slightly deteriorated, neural language models with large-margin softmax can yield word error rate similar to that of the standard softmax baseline. Finally, expected margins are analyzed through visualization of word vectors, showing that the syntactic and semantic relationships are also preserved. 
  Neural sequence-to-sequence text-to-speech synthesis  can produce high-quality speech directly from text or simple linguistic features such as phonemes. Unlike traditional pipeline TTS, the neural sequence-to-sequence TTS does not require manually annotated and complicated linguistic features such as part-of-speech tags and syntactic structures for system training. However, it must be carefully designed and well optimized so that it can implicitly extract useful linguistic features from the input features. %The inputs are much simpler than traditional pipeline TTS methods that  %%conventional statistical parametric speech synthesis  %typically rely on complex manually-annotated linguistic features  %%full-context labels  %such as part-of-speech tags, syntactic structures and ToBI labels. Therefore an encoder part of the neural sequence-to-sequence TTS approach needs to be carefully designed and optimized so that it has capabilities to implicitly extract linguistic features required for predicting target acoustic features.   In this paper we investigate under what conditions the neural sequence-to-sequence TTS can work well in Japanese and English along with comparisons with deep neural network  based pipeline TTS systems. Unlike past comparative studies, the pipeline systems also use neural autoregressive  probabilistic modeling and a neural vocoder in the same way as the sequence-to-sequence systems do for a fair and deep analysis in this paper.  %which allows a fair comparison with the neural sequence-to-sequence systems.  %This allows us to find out fundamental differences between the two approaches. %, not about the probabilistic modeling assumption or vocoder.  We investigated systems from three aspects: a) model architecture, b) model parameter size, and c) language. For the model architecture aspect, we adopt modified Tacotron systems that we previously proposed and their variants using an encoder from Tacotron or Tacotron2. For the model parameter size aspect, we investigate two model parameter sizes. For the language aspect, we conduct listening tests in both Japanese and English to see if our findings can be generalized across languages.   Our experiments on Japanese demonstrated that the Tacotron TTS systems with increased parameter size and input of phonemes and accentual type labels outperformed the DNN-based pipeline systems using the complicated linguistic features and that its encoder could learn to compensate for a lack of rich linguistic features. Our experiments on English demonstrated that, when using a suitable encoder, the Tacotron TTS system with characters as input can disambiguate pronunciations and produce natural speech as good as those of the systems using phonemes. However, we also found that the encoder could not learn English stressed syllables from characters perfectly and hence resulted in flatter fundamental frequency. %a rich encoder used in Tacotron can disambiguate pronunciation given characters as good as phonemes input cases.  In summary, these experimental results suggest that a) a neural sequence-to-sequence TTS system should have a sufficient number of model parameters to produce high quality speech, b) it should also use a powerful encoder when it takes characters as inputs, and c) the encoder still has a room for improvement and needs to have an improved architecture to learn supra-segmental features more appropriately.   %the model parameter capacity of the neural sequence-to-sequence TTS needs to be sufficiently large for producing high quality speech and also a strong and rich encoder is recommended when it uses characters as inputs. %the model parameter capacity of the neural sequence-to-sequence TTS needs to be sufficiently large for producing high quality speech and also a strong and rich encoder is recommended when it uses characters as inputs.  
   We demonstrate that a production-quality keyword-spotting model can be trained   on-device using federated learning and achieve comparable false accept and   false reject rates to a centrally-trained model. To overcome the algorithmic   constraints associated with fitting on-device data , we conduct thorough empirical   studies of optimization algorithms and hyperparameter configurations using   large-scale federated simulations. To overcome resource constraints, we   replace memory-intensive MTR data augmentation with SpecAugment, which reduces   the false reject rate by 56\%. Finally, to label examples , we explore teacher-student training. 
 In automatic speech recognition , model pruning is a widely adopted technique that reduces model size and latency to deploy neural network models on edge devices with resource constraints. However, multiple models with different sparsity levels usually need to be separately trained and deployed to heterogeneous target hardware with different resource specifications and for applications that have various latency requirements. In this paper, we present Dynamic Sparsity Neural Networks  that, once trained, can instantly switch to any predefined sparsity configuration at run-time. We demonstrate the effectiveness and flexibility of  using experiments on internal production datasets with Google Voice Search data, and show that the performance of a  model is on par with that of individually trained single sparsity networks. Our trained  model, therefore, can greatly ease the training process and simplify deployment in diverse scenarios with resource constraints. 
 Lexical substitution in context is an extremely powerful technology that can be used as a backbone of various NLP applications, such as word sense induction, lexical relation extraction, data augmentation, etc. In this paper we present a large-scale comparative study of popular neural language and masked language models , such as context2vec, ELMo, BERT, XLNet, applied to the task of lexical substitution. We show that already competitive results achieved by SOTA LMs/MLMs can be further improved if information about the target word is injected properly, and compare several target injection methods. In addition, we provide analysis of the types of semantic relations between the target and substitutes generated by different models providing insights into what kind of words are really generated or given by annotators as substitutes.   
 % [閸撳秵褰乚 unsupervised bilingual embedding 閵囶垬浠奸妶鎾变痪閹扮喆浠掗妵 Unsupervised bilingual word embedding  methods learn a linear transformation matrix that maps two monolingual embedding spaces that are separately trained with monolingual corpora. % isomorphism 閵堟帊鍒掔规哎浠愰妵锔轰簻閵堝浜撮妴浣哥箑閵囨哎浠愰妶鍌涘灇閵堝﹦鐝涢妵銈冧缓閵囶垶妾洪妶澶堜痪閵囧嫨 This method assumes that the two embedding spaces are structurally similar, which does not necessarily hold true in general. % [鐟欙絾鐒欏▔鏄 閵囨挶鍊㈤妵顔啃掑Ч鎭掍紑 Unsupervised MT 閵囶喖鍤崝娑栧伴崗鍐︿紕閵堢偨鍏楅妷鎴欏仯閵囶偄鍙嗛妶宀冪偗閵堥妵鎾变缓閵堟帗褰佸鍫涗粴閵堝 In this paper, we propose using a pseudo-parallel corpus generated by an unsupervised machine translation model to facilitate structural similarity of the two embedding spaces and improve the quality of BWEs in the mapping method. % [閵夆偓鍎婇妷姗 閵囨挶鍊㈤妵灞讳痪閵囨嚎浜滈妵鍕╀罕閵囥劊浜滈妵鍡愪缓閵嗕礁宕㈤妵顐犲剳閵夌鍋妵灞筋暭閵囧牄鍊犻妵鐘杭閵囇佷痪閵囧繈浣靛仢閵夌鍎滈妶骞垮伴妷鎴欏劦閵夘兙鍎烽妵顐犱痪閵堝浜遍妶澶 We show that our approach substantially outperforms baselines and other alternative approaches given the same amount of data, and, through detailed analysis, we argue that data augmentation with the pseudo data from unsupervised machine translation is especially effective for BWEs because  the pseudo data makes the source and target corpora  parallel;  the pseudo data reflects some nature of the original language that helps learning similar embedding spaces between the source and target languages. %閵唒seudo corpora 閵堟帊濞囬妵鍡愪紕閵囶垬浜伴妶鍌樹粣閵堝秲浜滈妶   
 A hallmark of human language is the ability to effectively and efficiently convey contextually relevant information. One theory for how humans reason about language is presented in the Rational Speech Acts  framework, which captures pragmatic phenomena via a process of recursive social reasoning . However, RSA represents ideal reasoning in an unconstrained setting. We explore the idea that speakers might learn to  the cost of RSA computation over time by directly optimizing for successful communication with an internal listener model. In simulations with grounded neural speakers and listeners across two communication game datasets representing synthetic and human-generated data, we find that our amortized model is able to quickly generate language that is effective and concise across a range of contexts, without the need for explicit pragmatic reasoning.  Keywords:  reference, pragmatics, rational speech acts, emergent communication 
 Sentiment analysis in conversations has gained increasing attention in recent years for the growing amount of applications it can serve, e.g., sentiment analysis, recommender systems, and human-robot interaction. The main difference between conversational sentiment analysis and single sentence sentiment analysis is the existence of context information which may influence the sentiment of an utterance in a dialogue. How to effectively encode contextual information in dialogues, however, remains a challenge. Existing approaches employ complicated deep learning structures to distinguish different parties in a conversation and then model the context information. In this paper, we propose a fast, compact and parameter-efficient party-ignorant framework named bidirectional emotional recurrent unit for conversational sentiment analysis. In our system, a generalized neural tensor block followed by a two-channel classifier is designed to perform context compositionality and sentiment classification, respectively. Extensive experiments on three standard datasets demonstrate that our model outperforms the state of the art in most cases. 
 We investigated word recognition in a Visually Grounded Speech model. The model has been trained on pairs of images and spoken captions to create visually grounded embeddings which can be used for speech to image retrieval and vice versa. We investigate whether such a model can be used to recognise words by embedding isolated words and using them to retrieve images of their visual referents. We investigate the time-course of word recognition using a gating paradigm and perform a statistical analysis to see whether well known word competition effects in human speech processing influence word recognition. Our experiments show that the model is able to recognise words, and the gating paradigm reveals that words can be recognised from partial input as well and that recognition is negatively influenced by word competition from the word initial cohort.  
 In this survey, we provide a comprehensive description of recent neural entity linking  systems developed since 2015 as a result of the ``deep learning revolution'' in NLP. Our goal is to systemize design features of neural entity linking systems and compare their performances to the best classic methods on the common benchmarks. We distill generic architectural components of a neural EL system, like candidate generation and entity ranking summarizing the prominent methods for each of them, such as approaches to mention encoding based on the self-attention architecture. The vast variety of modifications of this general neural entity linking architecture are grouped by several common themes: joint entity recognition and linking, models for global linking, domain-independent techniques including zero-shot and distant supervision methods, and cross-lingual approaches. Since many neural models take advantage of pre-trained entity embeddings to improve their generalization capabilities, we provide an overview of popular entity embedding techniques. Finally, we briefly discuss applications of entity linking, focusing on the recently emerged use-case of enhancing deep pre-trained masked language models such as BERT. %Previous surveys on entity linking do not provide a discussion for many of these topics including entity embeddings, applications of EL to improve deep pre-trained language models, cross-lingual linking, and zero-shot models.   
 Propaganda spreads the ideology and beliefs of like-minded people, brainwashing their audiences, and sometimes leading to violence. SemEval $2020$ Task-11 aims to design automated systems for news propaganda detection. Task-11 consists of two sub-tasks, namely, Span Identification - given any news article, the system tags those specific fragments which contain at least one propaganda technique and Technique Classification - correctly classify a given propagandist statement amongst $14$ propaganda techniques. For sub-task $1$, we use contextual embeddings extracted from pre-trained transformer models to represent the text data at various granularities and propose a multi-granularity knowledge sharing approach. For sub-task $2$, we use an ensemble of BERT and logistic regression classifiers with linguistic features. Our results reveal that the linguistic features are the reliable indicators for covering minority classes in a highly imbalanced dataset.   
     Deep neural networks excel at learning from labeled data and achieve state-of-the-art results on a wide array of Natural Language Processing tasks. In contrast, learning from unlabeled data, especially under domain shift, remains a challenge.      Motivated by the latest advances, in this survey we review neural unsupervised domain adaptation techniques which do not require labeled target domain data. This is a more challenging yet a more widely applicable setup. We outline methods, from early traditional non-neural methods to pre-trained model transfer. We also revisit the notion of domain, and we uncover a bias in the type of Natural Language Processing tasks which received most attention. Lastly, we outline future directions, particularly the broader need for out-of-distribution generalization of future NLP.\footnote{Accompanying repository: \url{https://github.com/bplank/awesome-neural-adaptation-in-NLP}} 
 % Opinions are  expressed on blogs and social-media platforms.  Stance provides a natural way to articulate social interaction  thereby lending itself to model users' opinions. However,  most existing study on Stance takes a simplistic view assuming a `sentence'  holding a perspective that is independent of the context and the author. Stance should be approached in a broader context of social action wherein authors use stance to position themselves with respect to objects of interests, thereby, aligning with other stance takers.  % In this research we study attitudinal stance as a means to model conversations on Twitter. Using `The Stance Triangle' approach, we build a computational model that evaluates authors' position towards an object, and simultaneously aligns them with other authors. To evaluate the model, we collect Tweets on controversial topics and build a dataset that has opinion labels for each user. Unlike prior work, our model positions authors as central and their alignment as a crucial to learning stance. Thus, our work proposes a new direction to the stance learning problem which is grounded in theory and is more amenable to conversations on social-media. % 
  Visual world studies show that upon hearing a word in a target-absent visual context containing related and unrelated items, toddlers and adults briefly direct their gaze towards phonologically related items, before shifting towards semantically and visually related ones. We present a neural network model that processes dynamic unfolding phonological representations and maps them to static internal semantic and visual representations. The model, trained on representations derived from real corpora, simulates this early phonological over semantic/visual preference. Our results support the hypothesis that incremental unfolding of a spoken word is in itself sufficient to account for the transient preference for phonological competitors over both unrelated and semantically and visually related ones. Phonological representations mapped dynamically in a  fashion to semantic-visual representations capture the early phonological preference effects reported in a visual world task. The semantic-visual preference observed later in such a trial does not require  feedback from a semantic or visual system.  Keywords:  language; neuro-computational models; development; visual world task; phonology; semantics; cohort effects; machine learning; lexical competition; spoken word recognition; attention. 
 In this paper, we investigate a commonsense inference task that unifies natural language understanding and commonsense reasoning. We describe our attempt at SemEval-2020 Task 4 competition: Commonsense Validation and Explanation  challenge. We discuss several state-of-the-art deep learning architectures for this challenge. Our system uses prepared labeled textual datasets that were manually curated for three different natural language inference subtasks. The goal of the first subtask is to test whether a model can distinguish between natural language statements that make sense and those that do not make sense. We compare the performance of several language models and fine-tuned classifiers. Then, we propose a method inspired by question/answering tasks to treat a classification problem as a multiple choice question task to boost the performance of our experimental results , which is significantly better than the baseline. For the second subtask, which is to select the reason why a statement does not make sense, we stand within the first six teams  among 27 participants with very competitive results. Our result for last subtask of generating reason against the nonsense statement shows many potentials for future researches as we applied the most powerful generative model of language  with 6.1732 BLEU score among first four teams\footnote{\url{https://github.com/Sirwe-Saeedi/Commonsense-NLP}}.       
  Various natural language processing tasks are structured prediction problems where outputs are constructed with multiple interdependent decisions. Past work has shown that domain knowledge, framed as constraints over the output space, can help improve predictive accuracy. However, designing good constraints often relies on domain expertise. In this paper, we study the problem of learning such constraints. We frame the problem as that of training a two-layer rectifier network to identify valid structures or substructures, and show a construction for converting a trained network into a system of linear constraints over the inference variables. Our experiments on several NLP tasks show that the learned constraints can improve the prediction accuracy, especially when the number of training examples is small. 
     This report is a survey of the relationships between     various state-of-the-art neural network architectures and formal languages as, for example, structured by the Chomsky Language Hierarchy.  Of particular interest are the abilities of a neural architecture to represent, recognize and generate words from a specific language by learning from samples of the language. 
 Deep neural language models such as BERT have enabled substantial recent advances in many natural language processing tasks. Due to the effort and computational cost involved in their pre-training, language-specific models are typically introduced only for a small number of high-resource languages such as English. While multilingual models covering large numbers of languages are available, recent work suggests monolingual training can produce better models, and our understanding of the tradeoffs between mono- and multilingual training is incomplete. In this paper, we introduce a simple, fully automated pipeline for creating language-specific BERT models from Wikipedia data and introduce 42 new such models, most for languages up to now lacking dedicated deep neural language models. We assess the merits of these models using the state-of-the-art UDify parser on Universal Dependencies data, contrasting performance with results using the multilingual BERT model. We find that UDify using WikiBERT models outperforms the parser using mBERT on average, with the language-specific models showing substantially improved performance for some languages, yet limited improvement or a decrease in performance for others. We also present preliminary results as first steps toward an understanding of the conditions under which language-specific models are most beneficial. All of the methods and models introduced in this work are available under open licenses from \url{https://github.com/turkunlp/wikibert}. 
 Event Extraction plays an important role in information-extraction to understand the world. Event extraction could be split into two subtasks: one is event trigger extraction, the other is event arguments extraction. However, the F-Score of event arguments extraction is much lower than that of event trigger extraction, i.e. in the most recent work, event trigger extraction achieves 80.7\%, while event arguments extraction achieves only 58\%. In pipelined structures, the difficulty of event arguments extraction lies in its lack of classification feature, and the much higher computation consumption. In this work, we proposed a novel Event Extraction approach based on multi-layer Dilate Gated Convolutional Neural Network  which has fewer parameters. In addition, enhanced local information is incorporated into word features, to assign event arguments roles for triggers predicted by the first subtask. The numerical experiments demonstrated significant performance improvement beyond state-of-art event extraction approaches on real-world datasets. Further analysis of extraction procedure is presented, as well as experiments are conducted to analyze impact factors related to the performance improvement. 
 A neural machine translation  system is expensive to train, especially with high-resource settings. As the NMT architectures become deeper and wider, this issue gets worse and worse. In this paper, we aim to improve the efficiency of training an NMT by introducing a novel norm-based curriculum learning method. We use the norm  of a word embedding as a measure of 1) the difficulty of the sentence, 2) the competence of the model, and 3) the weight of the sentence. The norm-based sentence difficulty takes the advantages of both linguistically motivated and model-based sentence difficulties. It is easy to determine and contains learning-dependent features. The norm-based model competence makes NMT learn the curriculum in a fully automated way, while the norm-based sentence weight further enhances the learning of the vector representation of the NMT.  Experimental results for the WMT'14 English--German and WMT'17 Chinese--English translation tasks demonstrate that the proposed method outperforms strong baselines in terms of BLEU score  and training speedup . 
  %Spoken dialogue systems reside between the user and a machine to facilitate natural interaction for the user be it for acheiving tasks or chit chat.   Automatic speech recognition and spoken dialogue systems have made great advances through the use of deep machine learning methods.  This is partly due to greater computing power but also through the large amount of data available in common languages, such as English. Conversely, research in minority languages, including sign languages, is hampered by the severe lack of data. This has led to work on transfer learning methods, whereby a model developed for one language is reused as the starting point for a model on a second language, which is less resourced. In this paper, we examine two transfer learning techniques of fine-tuning and layer substitution for language modelling of British Sign Language. Our results show improvement in perplexity when using transfer learning with standard stacked LSTM models, trained initially using a large corpus for standard English from the Penn Treebank corpus.  %that leverage similarities to another language source in order to bootstrap learning.    %Despite the fact that the spoken dialogue systems work quite well with the spoken or written languages, these systems still lack reliable visual perception. Furthermore, deaf users have to rely only on this communication medium. In this paper we focus on sign language modelling as a part of this overall improved version of the spoken dialogue system. In particular, we propose to use transfer learning techniques, such as weight finetunning and layer substitution for transferring knowledge from the Penn Treebank dataset, which is predominantly in English to the British Sign Language corpus modelling, using glosses as a proxy for the visual sign language. Our results show double improvement in perplexity when using the transfer learning with standard stacked LSTM models. 
     Approaches to Grounded Language Learning typically focus on a single task-based final performance measure that may not depend on desirable properties of the learned hidden representations, such as their ability to predict salient attributes or to generalise to unseen situations.      To remedy this, we present \grolla{}, an evaluation framework for Grounded Language Learning with Attributes with three sub-tasks: 1) Goal-oriented evaluation; 2) Object attribute prediction evaluation; and 3) Zero-shot evaluation.     We also propose a new dataset  as an instance of this framework for evaluating the quality of learned neural representations, in particular concerning attribute grounding.      To this end, we extend the original \guesswhat{} dataset by including a semantic layer on top of the perceptual one.     Specifically, we enrich the VisualGenome scene graphs associated with the \guesswhat{} images with abstract and situated attributes.     By using diagnostic classifiers, we show that current models learn representations that are not expressive enough to encode object attributes . In addition, they do not learn strategies nor representations that are robust enough to perform well when novel scenes or objects are involved in gameplay . 
 Improving neural machine translation  models using the back-translations of the monolingual target data  is currently the state-of-the-art approach for training improved translation systems. The quality of the backward system -- which is trained on the available parallel data and used for the back-translation -- has been shown in many studies to affect the performance of the final NMT model. In low resource conditions, the available parallel data is usually not enough to train a backward model that can produce the qualitative synthetic data needed to train a standard translation model. This work proposes a self-training strategy where the output of the backward model is used to improve the model itself through the forward translation technique. The technique was shown to improve baseline low resource IWSLT閳14 English-German and IWSLT閳15 English-Vietnamese backward translation models by 11.06 and 1.5 BLEUs respectively. The synthetic data generated by the improved English-German backward model was used to train a forward model which out-performed another forward model trained using standard back-translation by 2.7 BLEU.   
  How can deep neural networks encode information that corresponds to words in human speech into raw acoustic data? This paper proposes two neural network architectures for modeling unsupervised lexical learning from raw acoustic inputs, ciwGAN  and fiwGAN , that combine a Deep Convolutional GAN architecture for audio data  with an information theoretic extension of GAN -- InfoGAN , and propose a new latent space structure that can model featural learning simultaneously with a higher level classification and allows for a very low-dimension vector representation of lexical items. In addition to the Generator and the Discriminator networks, the architectures introduce a network that learns to retrieve latent codes from generated audio outputs. Lexical learning is thus modeled as emergent from an architecture that forces a deep neural network to output data such that unique information is retrievable from its acoustic outputs. The networks trained on lexical items from TIMIT learn to encode unique information corresponding to lexical items in the form of categorical variables in their latent space. By manipulating these variables, the network outputs specific lexical items. The network occasionally outputs innovative lexical items that violate training data, but are linguistically interpretable and highly informative for cognitive modeling and neural network interpretability. Innovative outputs suggest that phonetic and phonological representations learned by the network can be productively recombined and directly paralleled to productivity in human speech: a fiwGAN network trained on  and  outputs innovative , even though it never saw  or even a [st] sequence in the training data. We also argue that setting latent featural codes to values well beyond training range results in almost categorical generation of prototypical lexical items and reveals underlying values of each latent code. Probing deep neural networks trained on well understood dependencies in speech bears implications for latent space interpretability,  understanding how deep neural networks learn meaningful representations, as well as a potential for unsupervised text-to-speech generation in the GAN framework.  
  The spread of COVID-19 has become a significant and troubling aspect of society in 2020. With millions of cases reported across countries, new outbreaks have occurred and followed patterns of previously affected areas. Many disease detection models do not incorporate the wealth of social media data that can be utilized for modeling and predicting its spread. It is useful to ask, can we utilize this knowledge in one country to model the outbreak in another? To answer this, we propose the task of cross-lingual transfer learning for epidemiological alignment. Utilizing both macro and micro text features, we train on Italy's early COVID-19 outbreak through Twitter and transfer to several other countries. Our experiments show strong results with up to 0.85 Spearman correlation in cross-country predictions.    
 We present DeCLUTR: Deep Contrastive Learning for Unsupervised Textual Representations, a self-supervised method for learning universal sentence embeddings that transfer to a wide variety of natural language processing  tasks. Our objective leverages recent advances in deep metric learning  and has the advantage of being conceptually simple and easy to implement, requiring no specialized architectures or labelled training data. We demonstrate that our objective can be used to pretrain transformers to state-of-the-art performance on SentEval, a popular benchmark for evaluating universal sentence embeddings, outperforming existing supervised, semi-supervised and unsupervised methods. We perform extensive ablations to determine which factors contribute to the quality of the learned embeddings. Our code will be publicly available and can be easily adapted to new datasets or used to embed unseen text. 
  %%% Leave the Abstract empty if your article does not require one, please see the Summary Table for full details.  Training deep neural networks on well-understood dependencies in speech data can provide new insights into how they learn internal representations. This paper argues that acquisition of speech can be modeled as a dependency between random space and generated speech data in the Generative Adversarial Network architecture and proposes a methodology to uncover the network's internal representations that correspond to phonetic and phonological properties.  The Generative Adversarial architecture is uniquely appropriate for modeling phonetic and phonological learning because the network is trained on unannotated raw acoustic data and learning is unsupervised without any language-specific assumptions or pre-assumed levels of abstraction. A Generative Adversarial Network was trained on an allophonic distribution in English, in which voiceless stops surface as aspirated word-initially before stressed vowels, except if preceded by a sibilant [s]. The network successfully learns the allophonic alternation: the network's generated speech signal contains the conditional distribution of aspiration duration. The paper proposes a technique for establishing the network's internal representations that identifies latent variables that  correspond to, for example, presence of [s] and its spectral properties. By manipulating these variables, we actively control the presence of [s] and its frication amplitude in the generated outputs. This suggests that the network learns to use latent variables as an approximation of phonetic and phonological representations. Crucially, we observe that the dependencies learned in training extend beyond the training interval, which allows for additional exploration of learning representations. The paper also discusses how the network's architecture and innovative outputs resemble and differ from linguistic behavior in language acquisition, speech disorders, and speech errors,  and how well-understood dependencies in speech data can help us interpret how neural networks learn their representations.   \tiny   %All article types: you may provide up to 8 keywords; at least 5 are mandatory. 
 Medical concept normalization helps in discovering standard concepts in free-form text i.e., maps health-related mentions to standard concepts in a vocabulary.  It is much beyond simple string matching and requires a deep semantic understanding of concept mentions. Recent research approach concept normalization as either text classification or text matching. The main drawback in existing a) text classification approaches is ignoring valuable target concepts information in learning input concept mention representation b) text matching approach is the need to separately generate target concept embeddings which is time and resource consuming. Our proposed model overcomes these drawbacks by jointly learning the representations of input concept mention and target concepts. First, it learns input concept mention representation using RoBERTa. Second, it finds cosine similarity between embeddings of input concept mention and all the target concepts. Here, embeddings of target concepts are randomly initialized and then updated during training. Finally, the target concept with maximum cosine similarity is assigned to the input concept mention. Our model surpass all the existing methods across three standard datasets by improving accuracy up to 2.31\%. 
 We describe our submission to the 2020 Duolingo Shared Task on Simultaneous Translation And Paraphrase for Language Education ~. We view MT models at various training stages  as human learners at different levels. Hence, we employ an ensemble of multi-checkpoints from the same model to generate translation sequences with various levels of fluency. From each checkpoint, for our best model, we sample n-Best sequences  with a beam width $=100$. We achieve $37.57~macro\ F_1$ with a $6$ checkpoint model ensemble on the official English to Portuguese  shared task test data, outperforming a baseline Amazon translation system of $21.30~ macro\ F_1$ and ultimately demonstrating the utility of our intuitive method.    %We focus on evaluating a range of models and parameters for the English-Portuguese sub-task including the   $n$-Best prediction, multi-model for the translation, paraphrasing and model fine-tuning. 
 Detecting semantic similarities between sentences is still a challenge today due to the ambiguity of natural languages. In this work, we propose a simple approach to identifying semantically similar questions by combining the strengths of word embeddings and Convolutional Neural Networks . In addition, we demonstrate how the cosine similarity metric can be used to effectively compare feature vectors. Our network is trained on the Quora dataset, which contains over 400k question pairs. We experiment with different embedding approaches such as Word2Vec, Fasttext, and Doc2Vec and investigate the effects these approaches have on model performance. Our model achieves competitive results on the Quora dataset and complements the well-established evidence that CNNs can be utilized for paraphrase detection tasks. 
 Neural Machine Translation  for low-resource languages suffers from low performance because of the lack of large amounts of parallel data and language diversity. To contribute to ameliorating this problem, we built a baseline model for English--Hausa machine translation, which is considered a task for low--resource language. The Hausa language is the second largest Afro--Asiatic language in the world after Arabic and it is the third largest language for trading across a larger swath of West Africa countries, after English and French. In this paper, we curated different datasets containing Hausa--English parallel corpus for our translation. We trained baseline models and evaluated the performance of our models using the Recurrent and Transformer encoder--decoder architecture with two tokenization approaches: standard word--level tokenization and Byte Pair Encoding  subword tokenization. 
 Non-autoregressive neural machine translation  predicts the entire target sequence simultaneously and significantly accelerates inference process. However, NAT discards the dependency information in a sentence, and thus inevitably suffers from the multi-modality problem: the target tokens may be provided by different possible translations, often causing token repetitions or missing. To alleviate this problem, we propose a novel semi-autoregressive model \SemiNAT in this work, which generates a translation as a sequence of segments. The segments are generated simultaneously while each segment is predicted token-by-token. By dynamically determining segment length and deleting repetitive segments, \SemiNAT is capable of recovering from repetitive and missing token errors. Experimental results on three widely-used benchmark datasets show that our proposed model achieves more than 4$\times$ speedup while maintaining comparable performance compared with the corresponding autoregressive model. 
 In this paper, we explore the slot tagging with only a few labeled support sentences . Few-shot slot tagging faces a  unique challenge compared to the other few-shot classification problems as it calls for modeling the dependencies between labels. But it is hard to apply previously learned label dependencies to an unseen domain,  due to the discrepancy of label sets. To tackle this, we introduce a collapsed dependency transfer mechanism into the conditional random field  to transfer abstract label dependency patterns as transition scores. In the few-shot setting,  the emission score of CRF can be calculated as a word's similarity to the representation of each label.  To calculate such similarity,  we propose a Label-enhanced Task-Adaptive Projection Network  based on  the state-of-the-art few-shot classification model -- TapNet,  by leveraging label name semantics in representing labels.  Experimental results show that our model significantly outperforms the strongest few-shot learning baseline by  14.64 F1 scores in the one-shot setting.\footnote{Code is available at: \url{https://github.com/AtmaHou/FewShotTagging}} 
    Multi-hop reading comprehension across multiple documents attracts much attention recently. In this paper, we propose a novel approach to tackle this multi-hop reading comprehension problem. Inspired by human reasoning processing, we construct a path-based reasoning graph from supporting documents. This graph can combine both the idea of the graph-based and path-based approaches, so it is better for multi-hop reasoning. Meanwhile, we propose Gated-RGCN to accumulate evidence on the path-based reasoning graph, which contains a new question-aware gating mechanism to regulate the usefulness of information propagating across documents and add question information during reasoning. We evaluate our approach on WikiHop dataset, and our approach achieves state-of-the-art accuracy against previously published approaches. Especially, our ensemble model surpasses human performance by 4.2\%.  
  This research presents a fine-grained human evaluation to compare the Transformer and recurrent approaches to neural machine translation , on the translation direction English-to-Chinese. To this end, we develop an error taxonomy compliant with the Multidimensional Quality Metrics  framework that is customised to the relevant phenomena of this translation direction. We then conduct an error annotation using this customised error taxonomy on the output of state-of-the-art recurrent- and Transformer-based MT systems on a subset of WMT2019's news test set. The resulting annotation shows that, compared to the best recurrent system, the best Transformer system results in a 31\% reduction of the total number of errors and it produced significantly less errors in 10 out of 22 error categories.  We also note that two of the systems evaluated do not produce any error for a category that was relevant for this translation direction prior to the advent of NMT systems: Chinese classifiers.  %while it underperforms the recurrent-based system on one . %We develop a Chinese error taxonomy compliant with the Multidimensional Quality Metrics  framework. The tagset is customised to reflect Chinese linguistic phenomena and NMT features. Two annotators are engaged to do the manual annotation task. We utilise the method of  to statistically evaluate the differences in overall performance and for each issue type between the two NMT systems. The analysis showed that the NMT with Transformer reduces the amount of error by 32\% in total, in comparison to the NMT with RNN. Also, Transformer produced significantly less errors in 10 out of 22 categories.   
 The predominant approach to open-domain dialog generation relies on end-to-end training of neural models on chat datasets. However, this approach provides little insight as to what these models learn  about engaging in dialog. In this study, we analyze the internal representations learned by neural open-domain dialog systems and evaluate the quality of these representations for learning basic conversational skills. Our results suggest that standard open-domain dialog systems struggle with answering questions, inferring contradiction, and determining the topic of conversation, among other tasks. We also find that the dyadic, turn-taking nature of dialog is not fully leveraged by these models. By exploring these limitations, we highlight the need for additional research into architectures and training methods that can better capture high-level information about dialog.\footnote{Our code is available at \url{https://github.com/AbdulSaleh/dialog-probing}} 
 We consider the problem of Named Entity Recognition  on biomedical scientific literature, and more specifically the genomic variants recognition in this work. Significant success has been achieved for NER on canonical tasks in recent years where large data sets are generally available. However, it remains a challenging problem on many domain-specific areas, especially the domains where only small gold annotations can be obtained.  In addition, genomic variant entities exhibit diverse linguistic heterogeneity, differing much from those that have been characterized in existing canonical NER tasks. The state-of-the-art machine learning approaches heavily rely on arduous feature engineering to characterize those unique patterns.  In this work, we present the first successful end-to-end deep learning approach to bridge the gap between generic NER algorithms and low-resource applications through genomic variants recognition.  Our proposed model can result in promising performance without any hand-crafted features or post-processing rules. Our extensive experiments and results may shed light on other similar low-resource NER applications.  % which are usually arduous and cannot be generalized to any other tasks 
     Pivot-based neural representation models have lead to significant progress in domain adaptation for NLP. However, previous works that follow this approach utilize only labeled data from the source domain and unlabeled data from the source and target domains, but neglect to incorporate massive unlabeled corpora that are not necessarily drawn from these domains. To alleviate this, we propose PERL: A representation learning model that extends contextualized word embedding  models such as BERT  with pivot-based fine-tuning. PERL  outperforms strong baselines across 22 sentiment classification domain adaptation setups, improves  in-domain model performance, yields effective reduced-size models and increases model stability.\footnote{Our code is at \url{https://github.com/eyalbd2/PERL}.}     \footnote{This paper was accepted to TACL in June 2020} 
  This paper describes our system submitted to task 4 of SemEval  2020: Commonsense Validation and Explanation  which consists of three   sub-tasks. The challenge is to directly   validate whether the system can recognize natural language statements that make sense from those that do not, and also require to generate reasonable explanation. Based on BERT architecture with multi-task setting, we propose an  effective and   interpretable ``Explain, Reason and Predict"  system to solve the   three sub-tasks about commonsense:  Validation, and    Explanation,  Reasoning, following the order of the competition. Inspired by cognitive studies of common sense, our system first   generate a reason or understanding of the sentences and then choose which one   statement makes sense, which is achieved by multi-task learning. The rational experiment validates our assumption and boost the performance. During the   post-evaluation, our system has reached 92.9\% accuracy in subtask A ,  89.7\% accuracy in subtask B , and BLEU score of 12.9 in subtask C \footnote{All results before 29 April, 2020}. 
 All over the world and especially in Africa, researchers are putting efforts into building Neural Machine Translation  systems to help tackle the language barriers in Africa, a continent of over 2000 different languages. However, the low-resourceness, diacritical, and tonal complexities of African languages are major issues being faced. The FFR project is a major step towards creating a robust translation model from Fon, a very low-resource and tonal language, to French, for research and public use. In this paper, we introduce FFR Dataset, a corpus of Fon-to-French translations, describe the diacritical encoding process, and introduce our FFR v1.1 model, trained on the dataset. The dataset and model are made publicly available at \url{https://github.com/bonaventuredossou/ffr-v1}, to promote collaboration and reproducibility.%and are still being improved daily. 
 This short example shows a contrived example on how to format the authors' information for {. 
 Deep learning architectures based on self-attention have recently achieved and surpassed state of the art results in the task of unsupervised aspect extraction and topic modeling. While models such as neural attention-based aspect extraction  have been successfully applied to user-generated texts, they are less coherent when applied to traditional data sources such as news articles and newsgroup documents. In this work, we introduce a simple approach based on sentence filtering in order to improve topical aspects learned from newsgroups-based content without modifying the basic mechanism of ABAE. We train a probabilistic classifier to distinguish between out-of-domain texts  and in-domain texts . Then, during data preparation we filter out sentences that have a low probability of being in-domain and train the neural model on the remaining sentences. The positive effect of sentence filtering on topic coherence is demonstrated in comparison to aspect extraction models trained on unfiltered texts. 
 Word Embeddings are used widely in multiple Natural Language Processing  applications. They are coordinates associated with each word in a dictionary, inferred from statistical properties of these words in a large corpus. In this paper we introduce the notion of ``concept'' as a list of words that have shared semantic content. We use this notion to analyse the learnability of certain concepts, defined as the capability of a classifier to recognise unseen members of a concept after training on a random subset of it. We first use this method to measure the learnability of concepts on pretrained word embeddings. We then develop a statistical analysis of concept learnability, based on hypothesis testing and ROC curves, in order to compare the relative merits of various embedding algorithms using a fixed corpora and hyper parameters. We find that all embedding methods capture the semantic content of those word lists, but fastText performs better than the others. \\ \newline \Keywords{Word Embedding, Linear Classifier, Concepts
  Current event detection models under supervised learning settings fail to transfer to new event types. Few-shot learning has not been explored in event detection even though it allows a model to perform well with high generalization on new event types. In this work, we formulate event detection as a few-shot learning problem to enable to extend event detection to new event types. We propose two novel loss factors that matching examples in the support set to provide more training signals to the model. Moreover, these training signals can be applied in many metric-based few-shot learning models. Our extensive experiments on the ACE-2005 dataset  show that the proposed method can improve the performance of few-shot learning. 
 In this work, we investigate the human perception of coherence in open-domain dialogues. In particular, we address the problem of annotating and modeling the coherence of next-turn candidates while considering the entire history of the dialogue.   First, we create the Switchboard Coherence  corpus, a dataset of human-human spoken dialogues annotated with turn coherence ratings, where next-turn candidate utterances ratings are provided considering the full dialogue context. Our statistical analysis of the corpus indicates how turn coherence perception is affected by patterns of distribution of entities previously introduced and the Dialogue Acts used. Second, we experiment with different architectures to model entities, Dialogue Acts and their combination and evaluate their performance in predicting human coherence ratings on SWBD-Coh.  We find that models combining both DA and entity information yield the best performances both for response selection and turn coherence rating. % OLD % In this work we investigate human perception of coherence in open-domain spoken dialogue. While coherence across turns is still a challenge for dialogue models, the structure of open-domain conversation is far from being understood.  % In particular, in our approach we focus on exploring the patterns of distribution of entities and dialogue acts across different turns of a dialogue and how they can be jointly modelled to predict human coherence scores. % First, we create a corpus of human-human spoken dialogues annotated with coherence ratings across different turns. Our statistical analysis of the corpus indicates how turn coherence perception is affected by patterns of distribution of entities previously introduced and the dialogue acts used. % Second, we experiment with different architectures to model entities, dialogue acts and their combination and evaluate their performance in predicting human coherence ratings. 
 		Marrying topic models and language models exposes language understanding to a broader source of document-level context beyond sentences via topics.   		While introducing topical semantics in language models, existing approaches incorporate latent document topic proportions and ignore topical discourse in sentences of the document.  		This work extends the line of research by additionally introducing an explainable topic representation in language understanding, obtained from a set of key terms correspondingly for each latent topic of the proportion.    		Moreover, we retain sentence-topic associations along with document-topic association by modeling topical discourse for every sentence in the document.   		We present a novel neural composite language model that exploits both the latent and explainable topics along with topical discourse at sentence-level in a joint learning framework of topic and language models.  		Experiments over a range of tasks such as language modeling, word sense disambiguation, document classification, retrieval and text generation demonstrate ability of the proposed model in improving language understanding.  	
 Lifelong learning has recently attracted attention in building machine learning systems that continually accumulate and transfer knowledge to help future learning. Unsupervised topic modeling has been popularly used to discover topics from document collections. However, the application of topic modeling is challenging due to data sparsity, e.g., in a small collection of  documents and thus, generate incoherent topics and sub-optimal document representations. To address the problem, we propose a lifelong learning framework for neural topic modeling that can continuously process streams of document collections, accumulate topics and guide future topic modeling tasks by knowledge transfer from several sources to better deal with the sparse data. In the lifelong process, we particularly investigate jointly:  sharing generative homologies  over lifetime to transfer prior knowledge, and  minimizing catastrophic forgetting to retain the past learning via novel selective data augmentation, co-training and topic regularization approaches. Given a stream of document collections, we apply the proposed Lifelong Neural Topic Modeling  framework in modeling three sparse document collections as future tasks and demonstrate improved performance quantified by perplexity, topic coherence and information retrieval task. Code: \url{https://github.com/pgcool/Lifelong-Neural-Topic-Modeling} 
 Humans read and write hundreds of billions of messages every day. Further, due to the availability of large datasets, large computing systems, and better neural network models, natural language processing  technology has made significant strides in understanding, proofreading, and organizing these messages. Thus, there is a significant opportunity to deploy NLP in myriad applications to help web users, social networks, and businesses. In particular, we consider smartphones and other mobile devices as crucial platforms for deploying NLP models at scale. However, today's highly-accurate NLP neural network models such as BERT and RoBERTa are extremely computationally expensive, with BERT-base taking 1.7 seconds to classify a text snippet on a Pixel 3 smartphone. In this work, we observe that methods such as grouped convolutions have yielded significant speedups for computer vision networks, but many of these techniques have not been adopted by NLP neural network designers. We demonstrate how to replace several operations in self-attention layers with grouped convolutions, and we use this technique in a novel network architecture called SqueezeBERT, which runs 4.3x faster than BERT-base on the Pixel 3 while achieving competitive accuracy on the GLUE test set. The SqueezeBERT code will be released.     
   We show for the first time that learning powerful representations from speech audio alone followed by fine-tuning on transcribed speech can outperform the best semi-supervised methods while being conceptually simpler.   wav2vec 2.0 masks the speech input in the latent space and solves a contrastive task defined over a quantization of the latent representations which are jointly learned.   Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER on the clean/other test sets.   When lowering the amount of labeled data to one hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour subset while using 100 times less labeled data.   Using just ten minutes of labeled data and pre-training on 53k hours of unlabeled data still achieves 4.8/8.2 WER.   This demonstrates the feasibility of speech recognition with limited amounts of labeled data.\footnote{Code and models are available at \url{https://github.com/pytorch/fairseq}} 
 		Despite being an open-source operating system pioneered in the early 閳90s, UNIX based platforms have not been able to garner an overwhelming reception from amateur end users. One of the rationales for under popularity of UNIX based systems is the steep learning curve corresponding to them due to extensive use of command line interface instead of usual interactive graphical user interface. In past years, the majority of insights used to explore the concern are eminently centered around the notion of utilizing chronic log history of the user to make the prediction of successive command. The approaches directed at anatomization of this notion are predominantly in accordance with Probabilistic inference models. The techniques employed in past, however, have not been competent enough to address the predicament as legitimately as anticipated. Instead of deploying usual mechanism of recommendation systems, we have employed a simple yet novel approach of Seq2seq model by leveraging continuous representations of self-curated exhaustive Knowledge Base  to enhance the embedding employed in the model. This work describes an assistive, adaptive and dynamic way of enhancing UNIX command line prediction systems. Experimental methods state that our model has achieved accuracy surpassing mixture of other techniques and adaptive command line interface mechanism as acclaimed in the past. 		 	
 In this paper, we propose a new adversarial augmentation method for Neural Machine Translation . The main idea is to minimize the vicinal risk over virtual sentences sampled from two vicinity distributions, of which the crucial one is a novel vicinity distribution for adversarial sentences that describes a smooth interpolated embedding space centered around observed training sentence pairs. We then discuss our approach, { achieves significant improvements over the Transformer , and substantially outperforms other data augmentation techniques  without using extra corpora. 
   This study focused on efficient text generation using generative adversarial networks . Assuming that the goal is to generate a paragraph of a user-defined topic and sentimental tendency, conventionally the whole network has to be re-trained to obtain new results each time when a user changes the topic. This would be time-consuming and impractical. Therefore, we propose a User-Defined GAN  with two-level discriminators to solve this problem. The first discriminator aims to guide the generator to learn paragraph-level information and sentence syntactic structure, which is constructed by multiple-LSTMs. The second one copes with higher level information, such as the user-defined sentiment and topic for text generation. The cosine similarity based on TF-IDF and length penalty are adopted to determine the relevance of the topic. Then, the second discriminator is re-trained with generator if the topic or sentiment for text generation is modified. The system evaluations are conducted to compare the performance of the proposed method with other GAN-based ones. The objective results showed that the proposed method is capable of generating texts with less time than others and the generated text are related to the user-defined topic and sentiment. We will further investigate the possibility of incorporating more detailed paragraph information such as semantics into text generation to enhance the result. 
 This work presents a Convolutional Neural Network  for the prediction of next-day stock fluctuations using company-specific news headlines. Experiments to evaluate model performance using various configurations of word-embeddings and convolutional filter widths are reported. The total number of convolutional filters used is far fewer than is common, reducing the dimensionality of the task without loss of accuracy. Furthermore, multiple hidden layers with decreasing dimensionality are employed.  A classification accuracy of 61.7\% is achieved using pre-learned embeddings, that are fine-tuned during training to represent the specific context of this task. Multiple filter widths are also implemented to detect different length phrases that are key for classification. Trading simulations are conducted using the presented classification results. Initial investments are more than tripled over a 838 day testing period using the optimal classification configuration and a simple trading strategy. Two novel methods are presented to reduce the risk of the trading simulations. Adjustment of the sigmoid class threshold and re-labelling headlines using multiple classes form the basis of these methods. A combination of these approaches is found to more than double the Average Trade Profit  achieved during baseline simulations.  
 The Software Naturalness hypothesis argues that programming languages can be understood through the same techniques used in natural language processing. We explore this hypothesis through the use of a pre-trained transformer-based language model to perform code analysis tasks. Present approaches to code analysis depend heavily on features derived from the Abstract Syntax Tree  while our transformer-based language models work on raw source code. This work is the first to investigate whether such language models can discover AST features automatically. To achieve this, we introduce a sequence labeling task that directly probes the language model's understanding of AST. Our results show that transformer based language models achieve high accuracy in the AST tagging task. Furthermore, we evaluate our model on a software vulnerability identification task. Importantly, we show that our  approach obtains vulnerability identification results comparable to graph based approaches that rely heavily on compilers for feature extraction.  
 This paper presents \xlsr{} which learns cross-lingual speech representations by pretraining a single model from the raw waveform of speech in multiple languages. We build on wav2vec 2.0 which is trained by solving a contrastive task over masked latent speech representations and jointly learns a quantization of the latents shared across languages. The resulting model is fine-tuned on labeled data and experiments show that cross-lingual pretraining significantly outperforms monolingual pretraining. On the CommonVoice benchmark, XLSR shows a relative phoneme error rate reduction of 72\% compared to the best known results. On BABEL, our approach improves word error rate by 16\% relative compared to a comparable system. Our approach enables a single multilingual speech recognition model which is competitive to strong individual models. Analysis shows that the latent discrete speech representations are shared across languages with increased sharing for related languages. We hope to catalyze research in low-resource speech understanding by releasing XLSR-53, a large model pretrained in 53 languages.\footnote{} 
 \label{sec:abs} % In this work we propose three explainable deep learning architectures to automatically detect patients with Alzheimer閳ユ獨 disease based on their language abilities. The architectures use:  only the part-of-speech features;  only language embedding features and  both of these feature classes via a unified architecture.  We use self-attention mechanisms and interpretable 1-dimensional Convolutional Neural Network  to generate two types of explanations of the model's action: intra-class explanation and inter-class explanation. The inter-class explanation captures the relative importance of each of the different features in that class, while the inter-class explanation captures the relative importance between the classes. Note that although we have considered two classes of features in this paper, the architecture is easily expandable to more classes because of its modularity. Extensive experimentations and comparison with several recent models show that our method outperforms these methods with an accuracy of $92.2$\% and F1 score of $0.952$ on the DementiaBank dataset while being able to generate explanations. We show by examples, how to generate these explanations using attention values. 
  Grapheme-to-phoneme  models are a key component in Automatic Speech Recognition  systems, such as the ASR system in Alexa, as they are used to generate pronunciations for out-of-vocabulary words that do not exist in the pronunciation lexicons .   Most G2P systems are monolingual and based on traditional joint-sequence based n-gram models . As an alternative, we present a single end-to-end trained neural G2P model that shares same encoder and decoder across multiple languages. This allows the model to utilize a combination of universal symbol inventories of Latin-like alphabets and cross-linguistically shared feature representations. Such model is especially useful in the scenarios of low resource languages and code switching/foreign words, where the pronunciations in one language need to be adapted to other locales or accents. We further experiment with word language distribution vector as an additional training target in order to improve system performance by helping the model decouple pronunciations across a variety of languages in the parameter space. We show 7.2\% average improvement in phoneme error rate over low resource languages and no degradation over high resource ones compared to monolingual baselines. 
 AAAI creates proceedings, working notes, and technical reports directly from electronic source furnished by the authors. To ensure that all papers in the publication have a uniform appearance, authors must adhere to the following instructions.  
 Repeated reading  helps learners, who have little to no experience with reading fluently to gain confidence, speed and process words automatically. The benefits of repeated readings include helping all learners with fact recall, aiding identification of learners' main ideas and vocabulary, increasing comprehension, leading to faster reading as well as increasing word recognition accuracy, and assisting struggling learners as they transition from word-by-word reading to more meaningful phrasing. Thus, RR ultimately helps in improvements of learners' oral fluency and narrative production. However, there is no open audio datasets available on oral responses of learners based on their RR practices. Therefore, in this paper, we present our dataset, discuss its properties, and propose a method to assess oral fluency and narrative production for learners of English using acoustic, prosodic, lexical and syntactical characteristics. The results show that a CALL system can be developed for assessing the improvements in learners' oral fluency and narrative production. 
 The Transformer translation model  based on a multi-head attention mechanism can be computed effectively in parallel and has significantly pushed forward the performance of Neural Machine Translation . Though intuitively the attentional network can connect distant words via shorter network paths than RNNs, empirical analysis demonstrates that it still has difficulty in fully capturing long-distance dependencies . Considering that modeling phrases instead of words has significantly improved the Statistical Machine Translation  approach through the use of larger translation blocks  and its reordering ability, modeling NMT at phrase level is an intuitive proposal to help the model capture long-distance relationships. In this paper, we first propose an attentive phrase representation generation mechanism which is able to generate phrase representations from corresponding token representations. In addition, we incorporate the generated phrase representations into the Transformer translation model to enhance its ability to capture long-distance relationships. In our experiments, we obtain significant improvements on the WMT 14 English-German and English-French tasks on top of the strong Transformer baseline, which shows the effectiveness of our approach. Our approach helps Transformer Base models perform at the level of Transformer Big models, and even significantly better for long sentences, but with substantially fewer parameters and training steps. The fact that phrase representations help even in the big setting further supports our conjecture that they make a valuable contribution to long-distance relations. 
 Dialog systems research has primarily been focused around two main types of applications -- task-oriented dialog systems that learn to use clarification to aid in understanding a goal, and open-ended dialog systems that are expected to carry out unconstrained ``chit chat'' conversations.  However, dialog interactions can also be used to obtain various types of knowledge that can be used to improve an underlying language understanding system, or other machine learning systems that the dialog acts over.  In this position paper, we present the problem of designing dialog systems that enable lifelong learning as an important challenge problem, in particular for applications involving physically situated robots.   We include examples of prior work in this direction, and discuss challenges that remain to be addressed.    
 Cross-lingual text summarization aims at generating a document summary in one language given input in another language. It is a practically important but under-explored task, primarily due to the dearth of available data. Existing methods resort to machine translation to synthesize training data, but such pipeline approaches suffer from error propagation. In this work, we propose an end-to-end cross-lingual text summarization model. The model uses reinforcement learning to directly optimize a bilingual semantic similarity metric between the summaries generated in a target language and gold summaries in a source language. We also introduce techniques to pre-train the model leveraging monolingual summarization and machine translation objectives. Experimental results in both English--Chinese and English--German cross-lingual summarization settings demonstrate the effectiveness of our methods. In addition, we find that reinforcement learning models with bilingual semantic similarity as rewards generate more fluent sentences than strong baselines.\footnote{\url{https://github.com/zdou0830/crosslingual_summarization_semantic}.} 
  Convolutional neural network  and recurrent neural network  are two popular architectures used in text classification. Traditional methods to combine the strengths of the two networks rely on streamlining them or concatenating features extracted from them. In this paper, we propose a novel method to keep the strengths of the two networks to a great extent. In the proposed model, a convolutional neural network is applied to learn a 2D weight matrix where each row reflects the importance of each word from different aspects. Meanwhile, we use a bi-directional RNN to process each word and employ a neural tensor layer that fuses forward and backward hidden states to get word representations. In the end, the weight matrix and word representations are combined to obtain the representation in a 2D matrix form for the text. We carry out experiments on a number of datasets for text classification. The experimental results confirm the effectiveness of the proposed method.  
   This paper describes our study on using mutilingual BERT embeddings   and some new neural models for improving sequence tagging tasks for   the Vietnamese language. We propose new model architectures and   evaluate them extensively on two named entity recognition datasets   of VLSP 2016 and VLSP 2018, and on two part-of-speech tagging   datasets of VLSP 2010 and VLSP 2013. Our proposed models outperform   existing methods and achieve new state-of-the-art results.  In   particular, we have pushed the accuracy of part-of-speech   tagging to 95.40\% on the VLSP 2010 corpus, to 96.77\% on the VLSP   2013 corpus; and the $F_1$ score of named entity recognition to   94.07\% on the VLSP 2016 corpus, to 90.31\% on the VLSP 2018   corpus. Our code and pre-trained models viBERT and vELECTRA are   released as open source to facilitate adoption and further research. 
 % % \rrtodo{STAREJ ABSTRAKT: % Several studies have probed word representations % emerging % in neural networks trained for end-to-end NLP tasks % and examined what linguistic information may be encoded in the representations. % % % We critically revisit some of the experiments and identify risks of the commonly used methodology that may lead to overrating the generalization ability of the networks due to the word-level overlap of the train and test sets. % % % We propose a methodology that avoids this risk by carefully masking % the test tokens. % % % We showcase our methodology on predicting morphological features from the hidden representation of models trained for several different tasks and identify cases when word memorization was erroneously identified as generalization. % } %  % Multiple studies have probed representations emerging in neural networks trained for end-to-end NLP tasks and examined what word-level linguistic information may be encoded in the representations. In classical probing, a classifier is trained on the representations to extract the target linguistic information. However, there is a threat of the classifier simply memorizing the linguistic labels for individual words, instead of extracting the linguistic abstractions from the representations, thus reporting false positive results. While considerable efforts have been made to minimize the memorization problem, the task of actually measuring the amount of memorization happening in the classifier has been understudied so far. In our work, we propose a simple general method for measuring the memorization effect, based on a symmetric selection of comparable sets of test words seen versus unseen in training. Our method can be used to explicitly quantify the amount of memorization happening in a probing setup, so that an adequate setup can be chosen and the results of the probing can be interpreted with a reliability estimate. We exemplify this by showcasing our method on a case study of probing for part of speech in a trained neural machine translation encoder.   % TODO TODO TODO % % % We critically revisit the methodology commonly used in these experiments and identify a risk of overrating the generalization ability of the networks due to the word-level overlap of the train and test sets. % % % We propose a methodology that assesses this risk by comparing evaluations on carefully selected comparable sets of tokens seen versus unseen in the training data. % % % We include a case study on predicting part-of-speech tags from Transformer encoder output states, % %of a model trained for Czech-English machine translation, % showing how our methodology identifies cases where word memorization can be mistaken for generalization. %   
 How do learners acquire languages from the limited data available to them?  This process must involve some inductive biases---factors that affect how a learner generalizes---but it is unclear which inductive biases can explain observed patterns in language acquisition. To facilitate computational modeling aimed at addressing this question, we introduce a framework for giving particular linguistic inductive biases to a neural network model; such a model can then be used to empirically explore the effects of those inductive biases. This framework disentangles universal inductive biases, which are encoded in the initial values of a neural network's parameters, from non-universal factors, which the neural network must learn from data in a given language. The initial state that encodes the inductive biases is found with meta-learning, a technique through which a model discovers how to acquire new languages more easily via exposure to many possible languages. By controlling the properties of the languages that are used during meta-learning, we can control the inductive biases that meta-learning imparts. We demonstrate this framework with a case study based on syllable structure. First, we  specify the inductive biases that we intend to give our model, and then we translate those inductive biases into a space of languages from which a model can meta-learn. Finally, using existing analysis techniques, we verify that our approach has imparted the linguistic inductive biases that it was intended to impart.   Keywords:  meta-learning, inductive bias, language universals,  syllable structure typology, neural networks 
 % We propose a novel generative model that learns to identify a sparse prototype support set to generate sentences. We assume that a small set of sentences serve as prototypes  to be edited to generate a large number of diverse examples. Different from previous prototype-driven models which usually require to store and index a large retrieval database, our model is trained to identify only a small number of sentences as prototypes automatically. This is achieved by imposing a Dirichlet prior on the prototype selection distribution to encourage sparsity. In experiments, our model outperforms previous neural edit models on language modeling while bringing 100x memory saving and 50x speed-up at test time. More interestingly, we show that the learned prototypes are able to capture semantics or syntax at different granularity as we vary the sparsity of prototype selections, and certain sentence attributes can be controlled by specifying the prototype for generation.\footnote{Code will be released after the review period.}  Prototype-driven text generation uses non-parametric models that first choose from a library of sentence ``prototypes'' and then modify the prototype to generate the output text. While effective, these methods are inefficient at test time as a result of needing to store and index the entire training corpus. Further, existing methods often require heuristics to identify which prototypes to reference at training time. In this paper, we propose a novel generative model that automatically learns a  prototype support set that, nonetheless, achieves strong language modeling performance. This is achieved by  imposing a sparsity-inducing prior on the prototype selection distribution, and  utilizing amortized variational inference to learn a prototype retrieval function. In experiments, our model outperforms previous prototype-driven language models while achieving up to a 1000x memory reduction, as well as a 1000x speed-up at test time. More interestingly, we show that the learned prototypes are able to capture semantics and syntax at different granularity as we vary the sparsity of prototype selection, and that certain sentence attributes can be controlled by specifying the prototype for generation.\footnote{Code is available at \url{https://github.com/jxhe/sparse-text-prototype}.} 
 In this paper, we describe our mUlti-task learNIng for cOmmonsense reasoNing  system submitted for Task C of the SemEval2020 Task 4, which  % - Commonsense Validation and Explanation , which  %to solve the problem of  % The task is to generate a reason explaining why a given false statement  %does not make sense. is non-sensical.  %The human evaluation for the generated explanation by our model is carried out by the Sem-Eval organizers.  % The SemEval organizers carried out a human evaluation for the generated explanations. % by our system.  %UNION.  However, we found in the early experiments that simple adaptations such as fine-tuning GPT2 often yield dull and non-informative generations .  In order to generate more meaningful explanations, we propose UNION, a unified end-to-end framework, to utilize several existing commonsense datasets so that it allows a model to learn more dynamics under the scope of commonsense reasoning.  In order to perform model selection efficiently, accurately and promptly,  we also propose a couple of auxiliary automatic evaluation metrics  %to evaluate  so that we can extensively compare the models from different perspectives. Our submitted system not only results in a good performance in the proposed metrics but also outperforms its competitors with the highest achieved score of 2.10 for human evaluation while remaining a BLEU score of 15.7.  Our code is made publicly available at GitHub \footnote{\url{https://github.com/anandhperumal/ANA-at-SemEval-2020-Task-4-UNION}}. %which also  % Results show  %consolidate the % good performances achieved by our system. %in evaluation.  
 % The fabulous results of convolution neural networks in image-related tasks, attracted attention of text mining, sentiment analysis and other text analysis researchers. It is however difficult to find enough data for feeding such networks, optimize their parameters, and make the right design choices when constructing network architectures. In this paper we present the creation steps of two big datasets of song emotions. We also explore usage of convolution and max-pooling neural layers on song lyrics, product and movie review text datasets. Three variants of a simple and flexible neural network architecture are also compared. Our intention was to spot any important patterns that can serve as guidelines for parameter optimization of similar models. We also wanted to identify architecture design choices which lead to high performing sentiment analysis models. To this end, we conducted a series of experiments with neural architectures of various configurations. Our results indicate that parallel convolutions of filter lengths up to three are usually enough for capturing relevant text features. Also, max-pooling region size should be adapted to the length of text documents for producing the best feature maps. Top results we got are obtained with feature maps of lengths 6 to 18. An improvement on future neural network models for sentiment analysis, could be generating sentiment polarity prediction of documents using aggregation of predictions on smaller excerpt of the entire text.  % 
 		To build a high-quality open-domain chatbot, we introduce the effective training process of PLATO-2 via curriculum learning. There are two stages involved in the learning process. In the first stage, a coarse-grained generation model is trained to learn response generation under the simplified framework of one-to-one mapping. In the second stage, a fine-grained generation model and an evaluation model are further trained to learn diverse response generation and response coherence estimation, respectively. PLATO-2 was trained on both Chinese and English data, whose effectiveness and superiority are verified through comprehensive evaluations, achieving new state-of-the-art results. 	
 % This is a significant barrier for approximation between the distributions of human dialogs and policy generator which imitates human behaviors.    Despite its notable success in adversarial learning approaches to multi-domain task-oriented dialog system, training the dialog policy via adversarial inverse reinforcement learning often fails to balance the performance of the policy generator and reward estimator. During optimization, the reward estimator often overwhelms the policy generator and produces excessively uninformative gradients. We proposes the Variational Reward estimator Bottleneck , which is an effective regularization method that aims to constrain unproductive information flows between inputs and the reward estimator. The VRB focuses on capturing discriminative features, by exploiting information bottleneck on mutual information. Empirical results on a multi-domain task-oriented dialog dataset demonstrate that the VRB significantly outperforms previous methods. %     approximation between distributions of human dialog sessions and the policy generator which imitates human behaviors. % VRB uses constraint on mutual information to capture discriminative features. % which make this task more complicated.  
   We demonstrate a reinforcement learning agent which uses a compositional   recurrent neural network that takes as input an LTL formula and determines   satisfying actions. The input LTL formulas have never been seen before, yet   the network performs zero-shot generalization to satisfy them. This is a novel   form of multi-task learning for RL agents where agents learn from one diverse   set of tasks and generalize to a new set of diverse tasks. The formulation of   the network enables this capacity to generalize. We demonstrate this ability   in two domains. In a symbolic domain, the agent finds a sequence of letters   that is accepted. In a Minecraft-like environment, the agent finds a sequence   of actions that conform to the formula. While prior work could learn to   execute one formula reliably given examples of that formula, we demonstrate   how to encode all formulas reliably. This could form the basis of new   multi-task agents that discover sub-tasks and execute them without any   additional training, as well as the agents which follow more complex   linguistic commands. The structures required for this generalization are   specific to LTL formulas, which opens up an interesting theoretical question:   what structures are required in neural networks for zero-shot generalization   to different logics? 
 The high energy costs of neural network training and inference led to the use of acceleration hardware such as GPUs and TPUs. While this enabled us to train large-scale neural networks in datacenters and deploy them on edge devices, the focus so far is on average-case performance. In this work, we introduce a novel threat vector against neural networks whose energy consumption or decision latency are critical. We show how adversaries can exploit carefully crafted sponge examples, which are inputs designed to maximise energy consumption and latency.  We mount two variants of this attack on established vision and language models, increasing energy consumption by a factor of 10 to 200. Our attacks can also be used to delay decisions where a network has critical real-time performance, such as in perception for autonomous vehicles.  We demonstrate the portability of our malicious inputs across CPUs and a variety of hardware accelerator chips including GPUs, and an ASIC simulator. We conclude by proposing a defense strategy which mitigates our attack by shifting the analysis of energy consumption in hardware from an average-case to a worst-case perspective.   % Neural networks are deployed in more and more systems, % however, % we believe one major attack surface is missing % in the current taxonomy of failing % neural network models % In this paper, we % first define the energy gap by % showing models with different inputs % of the same shape % have a large gap in terms of energy consumed. % We then present the % Effective Energy Extortion  attack, % focusing on % maximising the energy use of neural network models % using maliciously created samples. % We show how to build extortion samples that create 10x-200x more energy % consumption on a wide range of vision and language models % on different tasks. % Further, we explain the portability of these crafted malicious samples, % the performance of running them on GPUs, CPUs and even an ASIC simulator and % a simple strategy to defend the EEE attack for the current systems. % We argue that instead of focusing on improving average energy consumption of a sample, worst case should be considered. 
 Intelligent systems need to be able to recover from mistakes, resolve uncertainty, and adapt to novel concepts not seen during training.  Dialog interaction can enable this by the use of clarifications for correction and resolving uncertainty, and active learning queries to learn new concepts encountered during operation. Prior work on dialog systems has either focused on exclusively learning how to perform clarification/ information seeking, or to perform active learning.  In this work, we train a hierarchical dialog policy to jointly perform both clarification and active learning in the context of an interactive language-based image retrieval task motivated by an online shopping application, and demonstrate that jointly learning dialog policies for clarification and active learning is more effective than the use of static dialog policies for one or both of these functions. 
 We study and quantify the generalization patterns of multitask learning  models for sequence labeling tasks. MTL models are trained to optimize a set of related tasks jointly. Although multitask learning has achieved improved performance in some problems, there are also tasks that lose performance when trained together. These mixed results motivate us to study the factors that impact the performance of MTL models. We note that theoretical bounds and convergence rates for MTL models exist, but they rely on strong assumptions such as task relatedness and the use of balanced datasets. To remedy these limitations, we propose the creation of a task simulator and the use of Symbolic Regression to learn expressions relating model performance to possible factors of influence. For MTL, we study the model performance against the number of tasks , the number of samples per task  and the task relatedness measured by the adjusted mutual information . In our experiments, we could empirically find formulas relating model performance with factors of $$, $$,  which are equivalent to sound mathematical proofs in , and we went beyond by discovering that performance relates to a factor of $$.  
   We present Villa, the first known effort on large-scale adversarial training for vision-and-language  representation learning. Villa consists of two training stages:  task-agnostic adversarial pre-training; followed by  task-specific adversarial finetuning. Instead of adding adversarial perturbations on image pixels and textual tokens, we propose to perform adversarial training in the embedding space of each modality. To enable large-scale training, we adopt the ``free'' adversarial training strategy, and combine it with KL-divergence-based regularization to promote higher invariance in the embedding space. We apply Villa to current best-performing V+L models, and achieve new state of the art on a wide range of tasks, including Visual Question Answering, Visual Commonsense Reasoning, Image-Text Retrieval, Referring Expression Comprehension, Visual Entailment, and NLVR$^2$.\footnote{Code is available at \url{https://github.com/zhegan27/VILLA}.} 
 Can advanced mathematical computations be learned from examples? Using transformers over large generated datasets, we train models to learn properties of differential systems, such as local stability, behavior at infinity and controllability. We achieve near perfect estimates of qualitative characteristics of the systems, and good approximations of numerical quantities, demonstrating that neural networks can learn advanced theorems and complex computations without built-in mathematical knowledge. 
  The non-local block is a popular module for strengthening the context modeling ability of a regular convolutional neural network. This paper first studies the non-local block in depth, where we find that its attention computation can be split into two terms, a whitened pairwise term accounting for the relationship between two pixels and a unary term representing the saliency of every pixel. We also observe that the two terms trained alone tend to model different visual clues, e.g. the whitened pairwise term learns within-region relationships while the unary term learns salient boundaries. However, the two terms are tightly coupled in the non-local block, which hinders the learning of each. Based on these findings, we present the disentangled non-local block, where the two terms are decoupled to facilitate learning for both terms. We demonstrate the effectiveness of the decoupled design on various tasks, such as semantic segmentation on Cityscapes, ADE20K and PASCAL Context, object detection on COCO, and action recognition on Kinetics. Code is available at \\\url{https://github.com/yinmh17/DNL-Semantic-Segmentation}, \\ \url{https://github.com/Howal/DNL-Object-Detection}.  
 Person-job fit is to match candidates and job posts on online recruitment platforms using machine learning algorithms.  The effectiveness of matching algorithms heavily depends on the learned representations for the candidates and job posts.  In this paper, we propose to learn comprehensive and effective representations of the candidates and job posts via feature fusion. First, in addition to applying deep learning models for processing the free text in resumes and job posts, which is adopted by existing methods, we extract semantic entities from the whole resume  and then learn features for them. By fusing the features from the free text and the entities, we get a comprehensive representation for the information explicitly stated in the resume and job post. Second, however, some information of a candidate or a job may not be explicitly captured in the resume or job post. Nonetheless, the historical applications including accepted and rejected cases can reveal some implicit intentions of the candidates or recruiters. Therefore, we propose to learn the representations of implicit intentions by processing the historical applications using LSTM. Last, by fusing the representations for the explicit and implicit intentions, we get a more comprehensive and effective representation for person-job fit. Experiments over 10 months real data show that our solution outperforms existing methods with a large margin. Ablation studies confirm the contribution of each component of the fused representation. The extracted semantic entities help interpret the matching results during the case study. 
 Asking clarifying questions in response to ambiguous or faceted queries has been recognized as a useful technique for various information retrieval systems, especially conversational search systems with limited bandwidth interfaces. Analyzing and generating clarifying questions have been studied recently but the accurate utilization of user responses to clarifying questions has been relatively less explored. In this paper, we enrich the representations learned by Transformer networks using a novel attention mechanism from external information sources that weights each term in the conversation. We evaluate this Guided Transformer model in a conversational search scenario that includes clarifying questions. In our experiments, we use two separate external sources, including the top retrieved documents and a set of different possible clarifying questions for the query. We implement the proposed representation learning model for two downstream tasks in conversational search; document retrieval and next clarifying question selection. Our experiments use a public dataset for search clarification and demonstrate significant improvements compared to competitive baselines.  % Hamed: I just edited the abstract. It's not perfect and doesn't contain some information about multi-tasking, etc. But it should be sufficient for abstract submission.  % Conversational search in information retrieval is an emerging task which recently attracted much attention. Here, we want to focus on conversational search systems in a setting that system can get back to user with a clarifying question, for faceted or ambiguous queries. The task that we want to study is learning a neural representation for an interactive conversation history between a user and a system. We hypothesis that, the conversation context, itself is not enough for learning a good history representation. Accordingly, we introduce two external resources for boosting the representation learning. To be able to utilize information of the external resource into modeling, we extended the architecture of transformer, such that, in addition to self-attention mechanism, it could apply some external attention to the input as well. We train our model in multi-task learning regime, and evaluate on two down-stream task: 1-re-ranking, and 2- selecting next clarifying question. Experiments on both tasks show significant improvement over both supervised, and non-supervised baselines.  
   Humans have a remarkable capacity to reason about abstract relational structures, an ability that may support some of the most impressive, human-unique cognitive feats. Because equality  is a simple and ubiquitous relational operator, equality reasoning has been a key case study for the broader question of abstract relational reasoning. This paper revisits the question of whether equality can be learned by neural networks that do not encode explicit symbolic structure. Earlier work arrived at a negative answer to this question, but that result holds only for a particular class of hand-crafted feature representations. In our experiments, we assess out-of-sample generalization of equality using both arbitrary representations and representations that have been pretrained on separate tasks to imbue them with abstract structure. In this setting, even simple neural networks are able to learn basic equality with relatively little training data. In a second case study, we show that sequential equality problems  can be solved with only positive training instances. Finally, we consider a more complex, hierarchical equality problem, but this requires vastly more data. However, using a pretrained equality network as a modular component of this larger task leads to good performance with no task-specific training. Overall, these findings indicate that neural models are able to solve equality-based reasoning tasks, suggesting that essential aspects of symbolic reasoning can emerge from data-driven, non-symbolic learning processes. 
 Deep neural networks  have been recently found popular for image captioning problems in remote sensing . Existing DNN based approaches rely on the availability of a training set made up of a high number of RS images with their captions. However, captions of training images may contain redundant information , resulting in information deficiency while learning a mapping from the image domain to the language domain. To overcome this limitation, in this paper, we present a novel Summarization Driven Remote Sensing Image Captioning  approach. The proposed approach consists of three main steps. The first step obtains the standard image captions by jointly exploiting convolutional neural networks  with long short-term memory  networks. The second step, unlike the existing RS image captioning methods, summarizes the ground-truth captions of each training image into a single caption by exploiting sequence to sequence neural networks and eliminates the redundancy present in the training set. The third step automatically defines the adaptive weights associated to each RS image to combine the standard captions with the summarized captions based on the semantic content of the image. This is achieved by a novel adaptive weighting strategy defined in the context of LSTM networks. Experimental results obtained on the RSCID, UCM-Captions and Sydney-Captions datasets show the effectiveness of the proposed approach compared to the state-of-the-art RS image captioning approaches. The code of the proposed approach is publicly available at \url{https://gitlab.tubit.tu-berlin.de/rsim/SD-RSIC}. 
 Current methods for learning visually grounded language from videos often rely on time-consuming and expensive data collection, such as human annotated textual summaries or machine generated automatic speech recognition transcripts. In this work, we introduce Audio-Video Language Network , a self-supervised network that learns a shared audio-visual embedding space directly from raw video inputs. We circumvent the need for annotation and instead learn audio-visual language representations directly from randomly segmented video clips and their raw audio waveforms. We train AVLnet on publicly available instructional videos and evaluate our model on video clip and language retrieval tasks on three video datasets. Our proposed model outperforms several state-of-the-art text-video baselines by up to 11.8\% in a video clip retrieval task, despite operating on the raw audio instead of manually annotated text captions.  Further, we show AVLnet is capable of integrating textual information, increasing its modularity and improving performance by up to 20.3\% on the video clip retrieval task.  Finally, we perform analysis of AVLnet's learned representations, showing our model has learned to relate visual objects with salient words and natural sounds. 
 Fitting a model into GPU memory during training is an increasing concern as models continue to grow.  To address this issue, we present Shapeshifter Networks , a flexible neural network framework that decouples layers from model weights, enabling us to implement any neural network with an arbitrary number of parameters.  In SSNs each layer obtains weights from a parameter store that decides where and how to allocate parameters to layers.  This can result in sharing parameters across layers even when they have different sizes or perform different operations. SSNs do not require any modifications to a model's loss function or architecture, making them easy to use.  Our approach can create parameter efficient networks by using a relatively small number of weights, or can improve a model's performance by adding additional model capacity during training without affecting the computational resources required at test time.  We evaluate SSNs using seven network architectures across diverse tasks that include image classification, bidirectional image-sentence retrieval, and phrase grounding, creating high performing models even when using as little as 1\% of the parameters.   %Our approach is based on the observation that many neural networks are severely overparameterized, resulting in significant waste in computational resources as well as being susceptible to overfitting. SSNs address this by learning where and how to share parameters between layers in a neural network while avoiding degenerate solutions that result in underfitting. Specifically, we automatically construct parameter groups that identify where parameter sharing is most beneficial.  Then, we map each group's weights to construct layers with learned combinations of candidates from a shared parameter pool.  SSNs can share parameters across layers even when they have different sizes, perform different operations, and/or operate on features from different modalities.  We evaluate our approach on a diverse set of tasks, including image classification, bidirectional image-sentence retrieval, and phrase grounding, creating high performing models even when using as little as 1\% of the parameters.  We also apply SSNs to knowledge distillation, where we obtain state-of-the-art results when combined with traditional distillation methods.  %We present Shapeshifter Networks, a flexible neural network framework that improves performance and reduces memory requirements on a diverse set of scenarios over standard neural networks.  Our approach is based on the observation that many neural networks are severely overparameterized, resulting in significant waste in computational resources as well as being susceptible to overfitting.  Our Shapeshifter Networks address this by learning where and how to share parameters between layers in a neural network while avoiding degenerate solutions that result in underfitting. Specifically, we automatically construct parameter groups that identify where parameter sharing is most beneficial.  Then, we map each group's weights to construct layers with learned combinations of candidates from a shared parameter pool.  Our Shapeshifter Networks can share parameters across layers even when they have different sizes, perform different operations, and/or operate on features from different modalities.  We show that our approach improves performance and efficiency on a diverse set of tasks, including image classification, bidirectional image-sentence retrieval, phrase grounding, and knowledge distillation, especially when few parameters are available.  
  Compositional generalization is a basic and essential intellective capability of human beings, which allows us to recombine known parts readily. However, existing neural network based models have been proven to be extremely deficient in such a capability. Inspired by work in cognition which argues compositionality can be captured by variable slots with symbolic functions, we present a refreshing view that connects a memory-augmented neural model with analytical expressions, to achieve compositional generalization. Our model consists of two cooperative neural modules, Composer and Solver, fitting well with the cognitive argument while being able to be trained in an end-to-end manner via a hierarchical reinforcement learning algorithm. Experiments on the well-known benchmark SCAN demonstrate that our model seizes a great ability of compositional generalization, solving all challenges addressed by previous works with $100$\% accuracies.   
 The acquisition of symbolic and linguistic representations of sensorimotor behavior is a cognitive process performed by an agent when it is executing and/or observing own and others' actions. According to Piaget's theory of cognitive development, these representations develop during the sensorimotor stage and the pre-operational stage.  We propose a model that relates the conceptualization of the higher-level information from visual stimuli to the development of ventral/dorsal visual streams. This model employs neural network architecture incorporating a predictive sensory module based on an RNNPB  and a horizontal product model. We exemplify this model through a robot passively observing an object to learn its features and movements. During the learning process of observing sensorimotor primitives, i.e. observing a set of trajectories of arm movements  and its oriented object features, the pre-symbolic representation is self-organized in the parametric units.  These representational units act as bifurcation parameters, guiding the robot to recognize and predict various learned sensorimotor primitives. The pre-symbolic representation also accounts for the learning of sensorimotor primitives in a latent learning context. %[original submission version]The acquisition of symbolic and linguistic representation of sensorimotor behaviour is a cognitive process obtained by an agent when it is executing and/or observing own and others' actions. According to Piaget's theory of cognitive development, these representations develop during the sensorimotor stage and the pre-operational stage. We model this process through a robot action and gesture imitation learning experiment. This pre-symbolic language acquisition capability is based on a neural network architecture incorporating a predictive sensory module based on an RNNPB  and horizontal product model. During the imitation learning process of sensormotor primitives, i.e. a set of arm movement trajectories and features of their orientated object, the pre-symbolic representation is self-organized in the parametric units. These representational units act as bifurcation parameters, guiding the robot to recognize and follow various learnt sensorimotor primitives. The pre-symbolic representation also accounts for the learning of sensorimotor primitives in a latent learning context.   \tiny    Pre-symbolic Communication, Sensorimotor Integration, Recurrent Neural Networks, Parametric Biases, Horizontal Product   %All article types: you may provide up to 8 keywords; at least 5 are mandatory. 
  Despite several signs of progress have been made recently, limited research has been conducted for an inductive setting where embeddings are required for newly unseen nodes -- a setting encountered commonly in practical applications of deep learning for graph networks. This significantly affects the performances of downstream tasks such as node classification, link prediction or community extraction. To this end, we propose SANNE -- a novel unsupervised embedding model -- whose central idea is to employ a transformer self-attention network to iteratively aggregate vector representations of nodes in random walks. Our SANNE aims to produce plausible embeddings not only for present nodes, but also for newly unseen nodes. Experimental results show that the proposed SANNE obtains state-of-the-art results for the node classification task on well-known benchmark datasets.    
  Recently, there has been significant progress made in Automatic Speech Recognition  of code-switched speech, leading to gains in accuracy on code-switched datasets in many language pairs. Code-switched speech co-occurs with monolingual speech in one or both languages being mixed. In this work, we show that fine-tuning ASR models on code-switched speech harms performance on monolingual speech. We point out the need to optimize models for code-switching while also ensuring that monolingual performance is not sacrificed. Monolingual models may be trained on thousands of hours of speech which may not be available for re-training a new model. We propose using the Learning Without Forgetting  framework for code-switched ASR when we only have access to a monolingual model and do not have the data it was trained on. We show that it is possible to train models using this framework that perform well on both code-switched and monolingual test sets. In cases where we have access to monolingual training data as well, we propose regularization strategies for fine-tuning models for code-switching without sacrificing monolingual accuracy. We report improvements in Word Error Rate  in monolingual and code-switched test sets compared to baselines that use pooled data and simple fine-tuning.  
   Speaker diarization is an essential step for processing multi-speaker audio.   Although an end-to-end neural diarization  method achieved state-of-the-art performance, it is limited to a fixed number of speakers.   In this paper, we solve this fixed number of speaker issue by a novel speaker-wise conditional inference method based on the probabilistic chain rule. In the proposed method, each speaker's speech activity is regarded as a single random variable, and is estimated sequentially conditioned on previously estimated other speakers' speech activities.   Similar to other sequence-to-sequence models, the proposed method produces a variable number of speakers with a stop sequence condition.   We evaluated the proposed method on multi-speaker audio recordings of a variable number of speakers.   Experimental results show that the proposed method can correctly produce diarization results with a variable number of speakers and outperforms the state-of-the-art end-to-end speaker diarization methods in terms of diarization error rate. 
 Probabilistic Latent Variable Models  provide an alternative to self-supervised learning approaches for linguistic representation learning from speech. LVMs admit an intuitive probabilistic interpretation where the latent structure shapes the information extracted from the signal. Even though LVMs have recently seen a renewed interest due to the introduction of Variational Autoencoders , their use for speech representation learning remains largely unexplored. In this work, we propose  Convolutional Deep Markov Model , a Gaussian state-space model with non-linear emission and transition functions modelled by deep neural networks. This unsupervised model is trained using black box variational inference. A deep convolutional neural network is used as an inference network for structured variational approximation. When trained on a large scale speech dataset , ConvDMM produces features that significantly outperform multiple self-supervised feature extracting methods on linear phone classification and recognition on the Wall Street Journal dataset. Furthermore, we found that ConvDMM complements self-supervised methods like Wav2Vec and PASE, improving on the results achieved with any of the methods alone. Lastly, we find that ConvDMM features enable learning better phone recognizers than any other features in an extreme low-resource regime with few labelled training examples. 
 More than half of the 7,000 languages in the world are in imminent danger of going extinct. Traditional methods of documenting language proceed by collecting audio data followed by manual annotation by trained linguists at different levels of granularity. This time consuming and painstaking process could benefit from machine learning. Many endangered languages do not have any orthographic form but usually have speakers that are bi-lingual and trained in a high resource language. It is relatively easy to obtain textual translations corresponding to speech. In this work, we provide a multimodal machine learning framework for speech representation learning by exploiting the correlations between the two modalities namely speech and its corresponding text translation. Here, we construct a convolutional neural network audio encoder capable of extracting linguistic representations from speech. The audio encoder is trained to perform a speech-translation retrieval task in a contrastive learning framework. By evaluating the learned representations on a phone recognition task, we demonstrate that linguistic representations emerge in the audio encoder's internal representations as a by-product of learning to perform the retrieval task. 
  Advanced neural network models have penetrated Automatic Speech Recognition  in recent years, however, in language modeling many systems still rely on traditional Back-off N-gram Language Models  partly or entirely. The reason for this are the high cost and complexity of training and using neural language models, mostly possible by adding a second decoding pass . In our recent work we have significantly improved the online performance of a conversational speech transcription system by transferring knowledge from a Recurrent Neural Network Language Model  to the single pass BNLM with text generation based data augmentation. In the present paper we analyze the amount of transferable knowledge and demonstrate that the neural augmented LM  can help to capture almost 50\% of the knowledge of the RNNLM yet by dropping the second decoding pass and making the system real-time capable. We also systematically compare word and subword LMs and show that subword-based neural text augmentation can be especially beneficial in under-resourced conditions. In addition, we show that using the RNN-BNLM in the first pass followed by a neural second pass, offline ASR results can be even significantly improved.   
  Recognizing code-switched speech is challenging for Automatic Speech Recognition  for a variety of reasons, including the lack of code-switched training data. Recently, we showed that monolingual ASR systems fine-tuned on code-switched data deteriorate in performance on monolingual speech recognition, which is not desirable as ASR systems deployed in multilingual scenarios should recognize both monolingual and code-switched speech with high accuracy. Our experiments indicated that this loss in performance could be mitigated by using certain strategies for fine-tuning and regularization, leading to improvements in both monolingual and code-switched ASR. In this work, we present further improvements over our previous work by using domain adversarial learning to train task agnostic models. We evaluate the classification accuracy of an adversarial discriminator and show that it can learn shared layer parameters that are task agnostic. We train end-to-end ASR systems starting with a pooled model that uses monolingual and code-switched data along with the adversarial discriminator. Our proposed technique leads to reductions in Word Error Rates  in monolingual and code-switched test sets across three language pairs.  
 Transfer learning from high-resource languages is known to be an efficient way to improve end-to-end automatic speech recognition  for low-resource languages. Pre-trained or jointly trained encoder-decoder models, however, do not share the language modeling  for the same language, which is likely to be inefficient for distant target languages. We introduce speech-to-text translation  as an auxiliary task to incorporate additional knowledge of the target language and enable transferring from that target language. Specifically, we first translate high-resource ASR transcripts into a target low-resource language, with which a ST model is trained. Both ST and target ASR share the same attention-based encoder-decoder architecture and vocabulary. The former task then provides a fully pre-trained model for the latter, bringing up to 24.6\% word error rate  reduction to the baseline . We show that training ST with human translations is not necessary. ST trained with machine translation  pseudo-labels brings consistent gains. It can even outperform those using human labels when transferred to target ASR by leveraging only 500K MT examples. Even with pseudo-labels from low-resource MT , ST-enhanced transfer brings up to 8.9\% WER reduction to direct transfer. 
 This short example shows a contrived example on how to format the authors' information for {. 
 Pre-trained language models have achieved huge improvement on many NLP tasks. However, these methods are usually designed for written text, so they do not consider the properties of spoken language.  Therefore, this paper aims at generalizing the idea of language model pre-training to lattices generated by recognition systems. We propose a framework that trains neural lattice language models to provide contextualized representations for spoken language understanding tasks. The proposed two-stage pre-training approach reduces the demands of speech data and has better efficiency. Experiments on intent detection and dialogue act recognition datasets demonstrate that our proposed method consistently outperforms strong baselines when evaluated on spoken inputs.\footnote{The scource code is available at: \url{https://github.com/MiuLab/Lattice-ELMo}.} 
 In this paper, we propose a new task of machine translation , which is based on no parallel sentences but can refer to a ground-truth bilingual dictionary. Motivated by the ability of a monolingual speaker learning to translate via looking up the bilingual dictionary, we propose the task to see how much potential an MT system can attain using the bilingual dictionary and large scale monolingual corpora, while is independent on parallel sentences. We propose anchored training  to tackle the task. AT uses the bilingual dictionary to establish anchoring points for closing the gap between source language and target language. Experiments on various language pairs show that our approaches are significantly better than various baselines, including dictionary-based word-by-word translation, dictionary-supervised cross-lingual word embedding transformation, and unsupervised MT. On distant language pairs that are hard for unsupervised MT to perform well, AT performs remarkably better, achieving performances comparable to supervised SMT trained on more than 4M parallel sentences{\footnote {Code is available at \url{https://github.com/mttravel/Dictionary-based-MT} } }.   
 The scientific community continues to publish an overwhelming amount of new research related to COVID-19 on a daily basis, leading to much literature without little to no attention. To aid the community in understanding the rapidly flowing array of COVID-19 literature, we propose a novel BERT architecture that provides a brief yet original summarization of lengthy papers. The model continually learns on new data in online fashion while minimizing catastrophic forgetting, thus fitting to the need of the community. Benchmark and manual examination of its performance show that the model provide a sound summary of new scientific literature\footnote{Our code is available at \url{https://git.io/JJJfO}}. 
     In this essay, we explore a point of intersection between deep learning and neuroscience, through the lens of large language models, transfer learning and network compression.      Just like perceptual and cognitive neurophysiology has inspired effective deep neural network architectures which in turn make a useful model for understanding the brain, here we explore how biological neural development might inspire efficient and robust optimization procedures which in turn serve as a useful model for the maturation and aging of the brain.  
 With the rapid growth of the scientific literature, manually selecting appropriate citations for a paper is becoming increasingly challenging and time-consuming. While several approaches for automated citation recommendation have been proposed in the recent years, effective document representations for citation recommendation are still elusive to a large extent. For this reason, in this paper we propose a novel approach to citation recommendation which leverages a deep sequential representation of the documents  cascaded with Siamese and triplet networks in a submodular scoring function. To the best of our knowledge, this is the first approach to combine deep representations and submodular selection for a task of citation recommendation. Experiments have been carried out using a popular benchmark dataset -- the ACL Anthology Network corpus -- and evaluated against baselines and a state-of-the-art approach using metrics such as the MRR and F1@k score. The results show that the proposed approach has been able to outperform all the compared approaches in every measured metric. 
 Neural relation extraction discovers semantic relations between entities from unstructured text using deep learning methods. In this study, we present a comprehensive review of methods on neural network based relation extraction. We discuss advantageous and incompetent sides of existing studies and investigate additional research directions and improvement ideas in this field.   
 This paper proposes a method to disentangle and quantify interactions among words that are encoded inside a DNN for natural language processing. We construct a tree to encode salient interactions extracted by the DNN. Six metrics are proposed to analyze properties of interactions between constituents in a sentence. The interaction is defined based on Shapley values of words, which are considered as an unbiased estimation of word contributions to the network prediction. Our method is used to quantify word interactions encoded inside the BERT, ELMo, LSTM, CNN, and Transformer networks. Experimental results have provided a new perspective to understand these DNNs, and have demonstrated the effectiveness of our method. 
     We present the Latvian Twitter Eater Corpus - a set of tweets in the narrow domain related to food, drinks, eating and drinking. The corpus has been collected over time-span of over 8 years and includes over 2 million tweets entailed with additional useful data. We also separate two sub-corpora of question and answer tweets and sentiment annotated tweets. We analyse contents of the corpus and demonstrate use-cases for the sub-corpora by training domain-specific question-answering and sentiment-analysis models using data from the corpus. 
 Simultaneous neural machine translation  has attracted much attention recently. In contrast to standard NMT, where the NMT system can utilize the full input sentence, simultaneous NMT is formulated as a prefix-to-prefix problem, where the system can only utilize the prefix of the input sentence and more uncertainty is introduced to decoding. \Waitk~ is a simple yet effective strategy for simultaneous NMT, where the decoder generates the output sequence $k$ words behind the input words. We observed that training simultaneous NMT systems with future information  generally outperforms the standard ones . Based on this observation, we propose a framework that automatically learns how much future information to use in training for simultaneous NMT. We first build a series of tasks where each one is associated with a different $k$, and then learn a model on these tasks guided by a controller. The controller is jointly trained with the translation model through bi-level optimization. We conduct experiments on four datasets to demonstrate the effectiveness of our method. 
   We consider the problem of disambiguating the lemma and part of speech of ambiguous   words in morphologically rich languages.   %    We propose a method for disambiguating ambiguous words in context, using a large   un-annotated corpus of text, and \comment{??? finite-state
 Automatic generation of high-quality commit messages for code commits can substantially facilitate software developers' works and coordination. However, the semantic gap between source code and natural language poses a major challenge for the task. Several studies have been proposed to alleviate the challenge but none explicitly involves code contextual information during commit message generation. Specifically,  existing research adopts static embedding for code tokens, which maps a token to the same vector regardless of its context. In this paper, we propose a novel Contextualized code representation learning strategy for commit message Generation . \tool first learns contextualized code representations which exploit the contextual information behind code commit sequences. The learned representations of code commits built upon Transformer are then fine-tuned for downstream commit message generation. Experiments on the benchmark dataset demonstrate the superior effectiveness of our model over the baseline models with at least 28.18\% improvement in terms of BLEU-4 score. Furthermore, we also highlight the future opportunities in training contextualized code representations on larger code corpus as a solution to low-resource tasks and adapting the contextualized code representation framework to other code-to-text generation tasks.  
  Communication has become increasingly dynamic with the popularization of social networks and applications that allow people to express themselves and communicate instantly. In this scenario, distributed representation models have their quality impacted by new words that appear frequently or that are derived from spelling errors. These words that are unknown by the models, known as out-of-vocabulary  words, need to be properly handled to not degrade the quality of the natural language processing  applications, which depend on the appropriate vector representation of the texts. To better understand this problem and finding the best techniques to handle OOV words, in this study, we present a comprehensive performance evaluation of deep learning models for representing OOV words. We performed an intrinsic evaluation using a benchmark dataset and an extrinsic evaluation using different NLP tasks: text categorization, named entity recognition, and part-of-speech tagging.   Although the results indicated that the best technique for handling OOV words is different for each task, Comick, a deep learning method that infers the embedding based on the context and the morphological structure of the OOV word, obtained promising results.  
 Advanced machine learning and natural language techniques enable attackers to launch sophisticated and targeted social engineering based attacks. To counter the active attacker issue, researchers have since resorted to proactive methods of detection. Email masquerading using targeted emails to fool the victim is an advanced attack method. However automatic text generation requires controlling the context and coherency of the generated content, which has been identified as an increasingly difficult problem. %\textcolor{magenta}{ The method used leverages %}  a hierarchical deep neural model which uses a learned representation of the sentences in the input document to generate structured written emails. We demonstrate the generation of short and targeted text messages using the deep  model. The global coherency of the synthesized text is evaluated using a qualitative study as well as multiple quantitative measures.  
 Geoparsing is an important task in geographic information retrieval. A geoparsing system, known as a geoparser, takes some texts as the input and outputs the recognized place mentions and their location coordinates. In June 2019, a geoparsing competition, Toponym Resolution in Scientific Papers, was held as one of the SemEval 2019 tasks. The winning teams developed neural network based geoparsers that achieved outstanding performances . This exciting result brings the question ``are we there yet?'', namely have we achieved high enough performances  to possibly consider the problem of geoparsing as solved? One limitation of this competition is that the developed geoparsers were tested on only one dataset which has 45 research articles collected from the particular domain of Bio-medicine. It is known that the same geoparser can have very different performances  on different  datasets. Thus, this work performs a systematic evaluation of these state-of-the-art geoparsers using our recently developed benchmarking platform EUPEG that has eight annotated datasets, nine baseline geoparsers, and eight performance metrics. The evaluation result suggests that these new geoparsers indeed improve the performances of geoparsing on multiple datasets although some challenges remain. 
 In this paper we study the problem of predicting clinical diagnoses from textual Electronic Health Records  data. We show the importance of this problem in medical community and present comprehensive historical review of the problem and proposed methods. As the main scientific contributions we present a modification of Bidirectional Encoder Representations from Transformers  model for sequence classification that implements a novel way of Fully-Connected  layer composition and a BERT model pretrained only on domain data. To empirically validate our model, we use a large-scale Russian EHR dataset consisting of about 4 million unique patient visits. This is the largest such study for the Russian language and one of the largest globally. We performed a number of comparative experiments with other text representation models on the task of multiclass classification for 265 disease subset of ICD-10. The experiments demonstrate improved performance of our models compared to other baselines, including a fine-tuned Russian BERT  variant. We also show comparable performance of our model with a panel of experienced medical experts. This allows us to hope that implementation of this system will reduce misdiagnosis.   
 % Systematically discovering semantic relationships in text is an important and extensively studied area in NLP, with various tasks such as entailment, semantic similarity, etc. Decomposability of sentence level scores via chunk alignments has been proposed as a way to make such models reliable . We study the problem of aligning components of sentences leading to an interpretable model for measuring semantic textual similarity. In this paper, we present a novel logic-constrained gated pointer network model to align constituents of two sentences, aiding in interpretation of semantic relationships. \fxnote{Few lines needed about the approach.} We achieve state of the art results with an F1 score of 0.97 showing significant improvements over existing solutions.  Systematically discovering semantic relationships in text is an important and extensively studied area in Natural Language Processing, with various tasks such as entailment, semantic similarity, etc. Decomposability of sentence-level scores via subsequence alignments has been proposed as a way to make models more interpretable. We study the problem of aligning components of sentences leading to an interpretable model for semantic textual similarity. In this paper, we introduce a novel pointer network based model with a sentinel gating function to align constituent chunks, which are represented using BERT. We improve this base model with a loss function to equally penalize misalignments in both sentences, ensuring the alignments are bidirectional. Finally, to guide the network with structured external knowledge, we introduce first-order logic constraints based on ConceptNet and syntactic knowledge. The model achieves an F1 score of 97.73 and 96.32 on the benchmark SemEval datasets for the chunk alignment task, showing large improvements over the existing solutions. Source code is available at \url{https://github.com/manishb89/interpretable_sentence_similarity} 
 % Though Neural Machine Translation  has been successfully adopted in many areas,  Though remarkable successes have been achieved by Neural Machine Translation  in recent years,  it still suffers from the inadequate-translation problem.  Previous studies  show that explicitly modeling the translated  and un-translated  contents of the source sentence is beneficial for translation performance. However, it is not clear whether the commonly used heuristic objective is good enough to guide the  and . In this paper, we present a novel dual learning framework that leverages both source-to-target and target-to-source NMT models to provide a more direct and accurate supervision signal for the  and  modules. Experimental results demonstrate that our proposed method significantly improves the adequacy of NMT predictions and surpasses previous methods in two well-studied translation tasks. 
     \let\thefootnote\relax\footnotetext{*  Equal Contribution.}     \footnotetext{\Letter {} Corresponding author.}          Document-level Sentiment Analysis  is more challenging due to vague semantic links and complicate sentiment information.      Recent works have been devoted to leveraging text summarization and have achieved promising results.      However, these summarization-based methods did not take full advantage of the summary including ignoring the inherent interactions between the summary and document.     As a result, they limited the representation to express major points in the document, which is highly indicative of the key sentiment.       In this paper, we study how to effectively generate a discriminative representation with explicit subject patterns and sentiment contexts for DSA.      A Hierarchical Interaction Networks  is proposed to explore bidirectional interactions between the summary and document at multiple granularities and learn subject-oriented document representations for sentiment classification.      Furthermore, we design a Sentiment-based Rethinking mechanism  by refining the HIN with sentiment label information      to learn a more sentiment-aware document representation.      We extensively evaluate our proposed models on three public datasets. The experimental results consistently demonstrate the effectiveness of our proposed models and show that HIN-SR outperforms various state-of-the-art methods.        
 Multi-modal neural machine translation  aims to translate source sentences into a target language paired with images. However, dominant multi-modal NMT models do not fully exploit fine-grained semantic correspondences between semantic units of different modalities, which have potential to refine multi-modal representation learning. To deal with this issue, in this paper, we propose a novel graph-based multi-modal fusion encoder for NMT. Specifically, we first represent the input sentence and image using a unified multi-modal graph, which captures various semantic relationships between multi-modal semantic units . We then stack multiple graph-based multi-modal fusion layers that iteratively perform semantic interactions to learn node representations. Finally, these representations provide an attention-based context vector for the decoder. We evaluate our proposed encoder on the Multi30K datasets. Experimental results and in-depth analysis show the superiority of our multi-modal NMT model. 
 This short example shows a contrived example on how to format the authors' information for {. 
 The emergence of unsupervised word embeddings, pre-trained on very large monolingual text corpora, is at the core of the ongoing neural revolution in Natural Language Processing . Initially introduced for English, such pre-trained word embeddings quickly emerged for a number of other languages. Subsequently, there have been a number of attempts to align the embedding spaces across languages, which could enable a number of cross-language NLP applications. Performing the alignment using unsupervised cross-lingual learning  is especially attractive as it requires little data and often rivals supervised and semi-supervised approaches. Here, we analyze popular methods for UCL and we find that often their objectives are, intrinsically, versions of the Wasserstein-Procrustes problem. Hence, we devise an approach to solve Wasserstein-Procrustes in a direct way, which can be used to refine and to improve popular UCL methods such as iterative closest point , multilingual unsupervised and supervised embeddings  and supervised Procrustes methods. Our evaluation experiments on standard datasets show sizable improvements over these approaches. We believe that our rethinking of the Wasserstein-Procrustes problem could enable further research, thus helping to develop better algorithms for aligning word embeddings across languages. Our code and instructions to reproduce the experiments are available at \url{https://github.com/guillemram97/wp-hungarian}. 
  Few-shot natural language processing  refers to  NLP tasks that are accompanied with merely a handful of labeled examples.   This is a real-world challenge that an AI system must learn to handle.  Usually we rely on collecting more auxiliary information or developing a more efficient learning algorithm. However, the general gradient-based optimization in high capacity models, if training from scratch,  requires many parameter-updating  steps over a large number of labeled examples to perform well .    % The general belief is that gradient-based optimization in high capacity classifiers, if training from scratch,  requires many iterative steps over many examples to perform well . However, due to the availability of large-scaled pretrained model such as BERT, RoBERTa, those classifiers could have relatively good initialization; in this case, fine-tuning on support set is feasible.  If the target task itself cannot provide more information, how about collecting more tasks equipped with rich annotations to help the model learning?  The goal of meta-learning is to train a model on a variety of tasks with rich annotations, such that it can solve a new  task using only a few  labeled samples. The key idea  is to train the model's initial parameters such that the model has maximal performance on a new task after the parameters have been updated through zero or a couple of gradient steps. % The process of training a model閳ユ獨 parameters such that a few gradient steps, or even a single gradient step, can produce good results on a new task can be viewed from a feature learning standpoint as building an internal representation that is broadly suitable for many tasks. If the internal representation is suitable to many tasks, simply fine-tuning the parameters slightly  can produce good results % .  There are already some surveys for meta-learning, such as . Nevertheless,  this paper focuses on NLP domain, especially few-shot applications. We try to provide  clearer definitions, progress summary and some common datasets  of applying meta-learning to few-shot NLP. 
 A suitable state representation	is a fundamental part of the learning process in Reinforcement Learning. In various tasks, the state can either be  described by natural language or be natural language itself. This survey outlines the strategies used in the literature to build natural language state representations. We appeal for more linguistically interpretable and grounded representations, careful justification of design decisions and evaluation of the effectiveness of different approaches.	 
 Neural machine translation  generates the next target token given as input the previous ground truth target tokens during training while the previous generated target tokens during inference, which causes discrepancy between training and inference as well as error propagation, and affects the translation accuracy. In this paper, we introduce an error correction mechanism into NMT, which corrects the error information in the previous generated tokens to better predict the next token. Specifically, we introduce two-stream self-attention from XLNet into NMT decoder, where the query stream is used to predict the next token, and meanwhile the content stream is used to correct the error information from the previous predicted tokens. We leverage scheduled sampling to simulate the prediction errors during training. Experiments on three IWSLT translation datasets and two WMT translation datasets demonstrate that our method achieves improvements over Transformer baseline and scheduled sampling. Further experimental analyses also verify the effectiveness of our proposed error correction mechanism to improve the translation quality.  
 Question paraphrase identification is a key task in Community Question Answering  to determine if an incoming question has been previously asked. Many current models use word embeddings to identify duplicate questions, but the use of topic models in feature-engineered systems suggests that they can be helpful for this task, too. We therefore propose two ways of merging topics with word embeddings  in a new neural architecture for question paraphrase identification. Our results show that our system outperforms neural baselines on multiple CQA  datasets, while an ablation study highlights the importance of topics and especially  topic-embedding fusion in our architecture. 
 	Recurrent Neural Network Language Models  have started to be used in various fields of speech recognition due to their outstanding performance.	 	However, the high computational complexity of RNNLMs has been a hurdle in applying the RNNLM to a real-time Large Vocabulary Continuous Speech Recognition . 	In order to accelerate the speed of RNNLM-based network searches during decoding, we apply the General Purpose Graphic Processing Units . 	This paper proposes a novel method of applying GPGPUs to RNNLM-based graph traversals. 	We have achieved our goal by reducing redundant computations on CPUs and amount of transfer between GPGPUs and CPUs. 	The proposed approach was evaluated on both WSJ corpus and in-house data. 	Experiments shows that the proposed approach achieves the real-time speed in various circumstances while maintaining the Word Error Rate  to be relatively 10\% lower than that of n-gram models. 	   
 %\boldmath This paper presents and benchmarks a number of end-to-end Deep Learning based models for metaphor detection in Greek. We combine Convolutional Neural Networks and Recurrent Neural Networks with representation learning to bear on the metaphor detection problem for the Greek language. The models presented achieve exceptional accuracy scores, significantly improving the previous state of the art results, which had already achieved accuracy 0.82. Furthermore, no special preprocessing, feature engineering or linguistic knowledge is used in this work. The methods presented achieve accuracy of 0.92 and F-score 0.92 with Convolutional Neural Networks  and bidirectional Long Short Term Memory networks . Comparable results of  0.91 accuracy and  0.91 F-score are also achieved with bidirectional Gated Recurrent Units  and Convolutional Recurrent Neural Nets .  The models are trained and evaluated only on the basis of the training tuples, the sentences and their labels. The outcome is a state of the art collection of metaphor detection models, trained on limited labelled resources, which can be extended to other languages and similar tasks. 
   Problems involving code-mixed language are often plagued by a lack of resources and an absence of materials to perform sophisticated transfer learning with. In this paper we describe our submission to the Sentimix Hindi-English task involving sentiment classification of code-mixed texts, and with an F1 score of 67.1\%, we demonstrate that simple convolution and attention may well produce reasonable results. 
 	Sentiment Analysis is a well-studied field of Natural Language Processing. However, the rapid growth of social media and noisy content within them poses significant challenges in addressing this problem with well-established methods and tools. One of these challenges is code-mixing, which means using different languages to convey thoughts in social media texts. Our group, with the name of IUST, participated at the SemEval-2020 shared task 9 on Sentiment Analysis for Code-Mixed Social Media Text, and we have attempted to develop a system to predict the sentiment of a given code-mixed tweet. We used different preprocessing techniques and proposed to use different methods that vary from NBSVM to more complicated deep neural network models. Our best performing method obtains an F1 score of 0.751 for the Spanish-English sub-task and 0.706 over the Hindi-English sub-task. 
  %%% Leave the Abstract empty if your article does not require one, please see the Summary Table for full details. % Subject categories of scholarly papers generally refer to the knowledge domain to which the papers belong, examples being computer science or physics. Subject category information can be used for building faceted search for digital library search engines. This can significantly assist users in narrowing down their search space of relevant documents. Unfortunately, many academic papers do not have such information as part of their metadata. Existing methods for solving this task usually focus on unsupervised learning that often relies on citation networks. However, a complete list of papers citing the current paper may not be readily available. In particular, new papers that have few or no citations cannot be classified using such methods. Here, we propose a deep attentive neural network  that classifies scholarly papers using only their abstracts. The network is trained using 9 million abstracts from Web of Science . We also use the WoS schema that covers 104 subject categories.  %The abstracts are represented by a fix-length vector, which is generated by concatenating retrained top frequency word vectors.  The proposed network consists of two bi-directional recurrent neural networks followed by an attention layer. We compare our model against baselines by varying the architecture and text representation. Our best model achieves micro-${F_1}$ measure of $0.76$ with $F_1$ of individual subject categories ranging from $0.50$--$0.95$. The results showed the importance of retraining word embedding models to maximize the vocabulary overlap and the effectiveness of the attention mechanism. The combination of word vectors with TFIDF outperforms character and sentence level embedding models. We discuss imbalanced samples and overlapping categories and suggest possible strategies for mitigation. We also determine the subject category distribution in CiteSeerX by classifying a random sample of one million academic papers.     \tiny   %All article types: you may provide up to 8 keywords; at least 5 are mandatory. 
   This paper describes BUT-FIT's submission at SemEval-2020 Task 5: Modelling Causal Reasoning in Language: Detecting Counterfactuals. The challenge focused on detecting whether a given statement contains a counterfactual  and extracting both antecedent and consequent parts of the counterfactual from the text . We experimented with various state-of-the-art language representation models .  We found RoBERTa LRM to perform the best in both subtasks. We achieved the first place in both exact match and F1 for Subtask 2 and ranked second for Subtask 1. 
 We analyze the information provided by the word embeddings about the grammatical gender in Swedish. We wish that this paper may serve as one of the bridges to connect the methods of computational linguistics and general linguistics. Taking nominal classification in Swedish as a case study, we first show how the information about grammatical gender in language can be captured by word embedding models and artificial neural networks. Then, we match our results with previous linguistic hypotheses on assignment and usage of grammatical gender in Swedish and analyze the errors made by the computational model from a linguistic perspective. 
 Neural text decoding algorithms strongly influence the quality of texts generated using language models, but popular algorithms like top-$k$, top-$p$ , and temperature-based sampling may yield texts that have objectionable repetition or incoherence.  Although these methods generate high-quality text after ad hoc parameter tuning that depends on the language model and the length of generated text, not much is known about the control they provide over the statistics of the output.  This is important, however, since recent reports show that humans prefer when perplexity is neither too much nor too little and since we experimentally show that cross-entropy  has a near-linear relation with repetition. First we provide a theoretical analysis of perplexity in top-$k$, top-$p$, and temperature sampling, under Zipfian statistics. Then, we use this analysis to design a feedback-based adaptive top-$k$ text decoding algorithm called  that generates text  with a predetermined target value of perplexity without any tuning. Experiments show that for low values of $k$ and $p$, perplexity drops significantly with generated text length and leads to excessive repetitions . Contrarily, for large values of $k$ and $p$, perplexity increases with generated text length and leads to incoherence . Mirostat avoids both traps. Specifically, we show that setting target perplexity value beyond a threshold yields negligible sentence-level repetitions. Experiments with human raters for fluency, coherence, and quality further verify our findings. 
 In cross-lingual text classification, one seeks to exploit labeled data from one language to train a text classification model that can then be applied to a completely different language. Recent multilingual representation models have made it much easier to achieve this. Still, there may still be subtle differences between languages that are neglected when doing so. To address this, we present a semi-supervised adversarial training process that minimizes the maximal loss for label-preserving input perturbations. The resulting model then serves as a teacher to induce labels for unlabeled target language samples that can be used during further adversarial training, allowing us to gradually adapt our model to the target language. Compared with a number of strong baselines, we observe significant gains in effectiveness on document and intent classification for a diverse set of languages. 
 In this paper we demonstrate that context free grammar  based methods for grammar induction benefit from modeling lexical dependencies. This contrasts to the most popular current methods for grammar induction, which focus on discovering either constituents or dependencies. Previous approaches to marry these two disparate syntactic formalisms  have been plagued by sparsity, making them unsuitable for unsupervised grammar induction.  However, in this work, we present novel neural models of lexicalized PCFGs which allow us to overcome sparsity problems and effectively induce both constituents and dependencies within a single model. Experiments demonstrate that this unified framework results in stronger results on both representations than achieved when modeling either formalism alone.\footnote{Code is available at \url{https://github.com/neulab/neural-lpcfg}.}  %\gn{Abstract is pretty dry. First maybe introduce unsupervised parsing, then explain that there are alternative formalisms: dependency and constituency, handeled by DMV and CFG respectively. Then explain that lexicalized PCFG was used in supervised parsing, but has  not been applied to unsupervised parsing, which we posit is due to sparsity. then introduce our method.} %Y% Unsupervised grammar induction aims at inducing probabilistic grammar rules from natural language corpora. Within the scope of grammar induction there are two main directions of research: unsupervised constituency parsing and unsupervised dependency parsing, on which directions dependency models with valence  and probabilistic context-free grammars  are two most successful models respectively. Lexicalized PCFGs provide a method to unify these two kinds of models, but were mostly used in supervised parsing, and its performance is largely restricted by the data-sparsity problem. In this paper, we propose neural lexicalized probabilistic context-free grammars  for jointly performing both unsupervised dependency and constituency parsing. Our Neural L-PCFGs are parameterized by several simple neural networks which score production rules by conditioning on the lexical head of the parent constituent. Key to the success of our approach is that the neural parameterization enables efficient parameter sharing, thereby alleviating the data-sparsity issues common to lexicalized PCFGs. %includes a set of Chomsky Normal Form  productions rules and their scores parameterized by neural networks. The scores of productions rules are conditioned on the head word of the parent constituent, which makes our model sensitive to lexical information; meanwhile, neural parameterization enables parameter sharing mechanism, thus alleviating the sparse-data problem.  %Y% Unlike prior work that pits constituencies and dependencies against each other, our novel formulation produces a single model which simultaneously achieves strong performance across both syntactic formulations. Experiments show that our model could achieve better results comparing to models designed specific for these two tasks. %The compound latent variable makes the L-PCFG more general. In experiments on unsupervised consitituency parsing and dependency parsing tasks, our model compete favorably against specialized models for those two tasks.  
   % Guidance on paper content for EMNLP demo % https://2020.emnlp.org/call-for-papers/demos  % What problem does the proposed system address? % Why is the system important and what is its impact? % What is the novel in the approach/technology on which this system is based? % Who is the target audience? % How does the system work? % How does it compare with existing systems? % How is the system licensed? % 6 pages  Existing tools for Question Answering  have challenges that limit their use in practice. They can be complex to set up or integrate with existing infrastructure, do not offer configurable interactive interfaces, and do not cover the full set of subtasks that frequently comprise the QA pipeline . To help address these issues, we introduce NeuralQA - a usable library for QA on large datasets. NeuralQA integrates well with existing infrastructure  and offers helpful defaults for QA subtasks. It introduces and implements contextual query expansion  using a masked language model  as well as relevant snippets ) - a method for condensing large documents into smaller passages that can be speedily processed by a document reader model. Finally, it offers a flexible user interface to support workflows for research explorations  and large scale search deployment.   Code and documentation for NeuralQA is available as open source on  {Github}.  % It is configurable via a yaml file which enables out of the box usage with minimal code.  % The library can be installed via the pip python package manager and is open sourced under the MIT license;   % Dense passage retrieval methods hold promise for improved precision/recall within QA system implementations but can introduce significant complexity which make them impractical.   % In this work, we report on findings from our experiments building NeuralQA - an end to end open source question answer  designed to address some of these challenges. We show how the candidate passage retrieval stage of the QA task can be improved with contextual query expansion on sparse representations of queries, whilst achieving  accuracy comparable to dense deep representations and at a fraction of the complexity. NeuralQA offers a flexible user interface,  and  support for multiple retriever indexes, interpretability modules for sensemaking, query expansion methods and document readers.It is released under the MIT license.  % We also introduce the legalCase dataset and benchmark results that demonstrate the value of our query enrichment approach for large domain-specific corpora.s   % [Andrew] - @Victor, not sure we'll be able to claim that we achieve "comparable accuracy to dense representations" unless we replicate their experimental setup on ALL of Wikipedia  
 % 150 -> 250 words Supervised approaches for Neural Abstractive Summarization require large annotated corpora that are costly to build.  We present a French meeting summarization task where reports are predicted based on the automatic transcription of the meeting audio recordings. In order to build a corpus for this task, it is necessary to obtain the  transcription of each meeting, and then to segment and align it with the corresponding manual report to produce training examples suitable for training. On the other hand, we have access to a very large amount of unaligned data, in particular reports without corresponding transcription. Reports are professionally written and well formatted making pre-processing straightforward. In this context, we study how to take advantage of this massive amount of unaligned data using two approaches  self-supervised pre-training using a target-side denoising encoder-decoder model;  back-summarization i.e. reversing the summarization process by learning to predict the transcription given the report, in order to align single reports with generated transcription, and use this synthetic dataset for further training. We report large improvements compared to the previous baseline  for both approaches on two evaluation sets. Moreover, combining the two gives even better results, outperforming the baseline  by a large margin of $+6$ ROUGE-1 and ROUGE-L and $+5$ ROUGE-2 on two evaluation sets.    
 Named Entity Recognition   is a fundamental NLP task, commonly formulated as classification over a sequence of tokens. Morphologically-Rich Languages  pose a challenge to this basic formulation, as %space-delimited tokens do not coincide with the basic units that compose.  the boundaries of Named Entities do not coincide with { boundaries.  To address NER in MRLs we then  need to answer two fundamental modeling questions: %In this work we ask whether in Neural models morphemes should be used instead as the basic units to be classified. If so, how should these units be obtained? %To address this  %sub-word units  should be labelled instead, and  %Here we ask   What should be the basic { architecture that uses NER to prune inaccurate or inconsistent morphological hypotheses.  %how this should be done Neural models; in terms of how does using morphemes affect performance and how should these morphemes be obtained in non-gold settings.  We empirically investigate these questions on  a novel { architecture that we propose, in which NER precedes and  prunes the morphological decomposition  space, greatly outperforms the standard { Hebrew NER and Hebrew MD in realistic   scenarios. %delivering  state-of-the-art results for Hebrew NER.\footnote{Our analysis shows that morpheme-based models generalize better to unseen  words, even those composed of seen morphemes.} %especially ones that are morphologically composed, which are extremely prevalent in MRLs.  %We further show that using a standard  pipeline approach drastically hurts NER performance and we offer a novel, { the NER and MD tasks. %This method also achieves new state-of-the-art results in Hebrew morphological disambiguation.   % Named Entity Recognition   is a fundamental NLP task, commonly formulated as classification over a sequence of tokens. Morphologically-Rich Languages  challenge this basic formulation, as space-delimited tokens do not coincide with the basic units that compose Named Entities.  \db{neural from the start} % This introduces the following questions for NER modeling in MRLs:  What are the basic units that need to compose the sequence to be classified?  how should these units be obtained? and,  How can we generalize these units in the face of productive morphology and sparse lexica? \db{only first 2, in one sentence} % To empirically address these questions, we create a new benchmark annotated with { We compare token-based and morpheme-based Neural models and empirically show that explicitly modeling  morphology, in terms of the units to be labelled and pre-trained, is indeed crucial for accurate Neural NER.  % With further analysis we show that morpheme-based models generalize better to unknown words, especially ones that are morphologically composed, which are extremely prevalent in MRLs. % We set new state-of-the-art results for Hebrew NER, and  show that morphologically-aware Neural NER can be used to achieve new state-of-the-art results in Hebrew morphological tasks, such as morphological disambiguation.  
 % Qiaozhu Mei: Make the abstract more specific to the contribution and organization of this survey.   %Neural network-based generative models for natural language have become popular with the recent advancements in deep learning. Different techniques and architectures relying on neural networks have been used to generate text excerpts to various degrees of success, in a multitude of contexts that fulfil various user needs. While the field is rapidly evolving, there are still many open challenges to tackle. In this article we review the latest trends in neural network-based natural language generation and evaluation, outlining latest successes, open research challenges and limitations.      Recent advances in neural network-based generative modeling have reignited the hopes in having computer systems capable of seamlessly conversing with humans and able to understand natural language.    Neural architectures have been employed to generate text excerpts to various degrees of success, in a multitude of contexts and tasks that fulfil various user needs. Notably, high capacity deep learning models trained on large scale datasets demonstrate unparalleled abilities to learn patterns in the data even in the lack of explicit supervision signals, opening up a plethora of new possibilities regarding producing realistic and coherent texts. While the field of natural language generation is evolving rapidly, there are still many open challenges to address. In this survey we formally define and categorize the problem of natural language generation. We review particular application tasks that are instantiations of these general formulations, in which generating natural language is of practical importance. Next we include a comprehensive outline of methods and neural architectures employed for generating diverse texts. Nevertheless, there is no standard way to assess the quality of text produced by these generative models, which constitutes a serious  bottleneck towards the progress of the field. To this end, we also review current approaches to evaluating natural language generation systems. We hope this survey will provide an informative overview of formulations, methods, and assessments of neural natural language generation.       %that language models begin to learn these tasks without any explicit supervision       %have become popular with the recent advancements in deep learning. Different techniques and architectures relying on neural networks have been used to generate text excerpts to various degrees of success, in a multitude of contexts that fulfil various user needs. While the field is rapidly evolving, there are still many open challenges to tackle. In this article we review the latest trends in neural network-based natural language generation and evaluation, outlining latest successes, open research challenges and limitations.       %We hope this survey will serve as a quick and thorough review for anyone interested in the latest advances in deep learning for natural language generation and evaluation. 
 Recent studies have demonstrated the overwhelming advantage of cross-lingual pre-trained models , such as multilingual BERT and XLM, on cross-lingual NLP tasks.  However, existing approaches essentially capture the co-occurrence among tokens through involving the masked language model  objective with token-level cross entropy. In this work, we extend these approaches to learn sentence-level representations, and show the effectiveness on cross-lingual understanding and generation. We propose Hierarchical Contrastive Learning  to  learn universal representations for parallel sentences distributed in one or multiple languages and  distinguish the semantically-related words from a shared cross-lingual vocabulary for each sentence. We conduct evaluations on three benchmarks: language understanding tasks  in the GLUE benchmark, cross-lingual natural language inference  and machine translation. Experimental results show that the Hictl obtains an absolute gain of 1.0\%/2.2\% accuracy on GLUE/XNLI as well as achieves substantial improvements of +1.7$\sim$+3.6 BLEU on  both the high-resource and low-resource English$\rightarrow$X translation tasks over strong baselines. We will release the source codes as soon as possible.%We conduct two pre-training strategies:  Pre-training from scratch on five languages , which obtains an absolute gain of 2.6\%/1.5\% accuracy on GLUE/XNLI as well as achieves substantial improvements of +1.9$\sim$+2.4 BLEU on four WMT English-to-X translation tasks.  Pre-training on the basis of mBERT/XLM-R and obtain absolute gains of 2.4\%/0.7\% accuracy. 
 Multi-task learning  significantly pre-dates the deep learning era, and it has seen a resurgence in the past few years as researchers have been applying MTL to deep learning solutions for natural language tasks. While steady MTL research has always been present, there is a growing interest driven by the impressive successes published in the related fields of transfer learning and pre-training, such as BERT, and the release of new challenge problems, such as GLUE and the NLP Decathlon . These efforts place more focus on how weights are shared across networks, evaluate the re-usability of network components and identify use cases where MTL can significantly outperform single-task solutions. This paper strives to provide a comprehensive survey of the numerous recent MTL contributions to the field of natural language processing and provide a forum to focus efforts on the hardest unsolved problems in the next decade. While novel models that improve performance on NLP benchmarks are continually produced, lasting MTL challenges remain unsolved which could hold the key to better language understanding, knowledge discovery and natural language interfaces. 
 %	Machine translation has many applications such as news translation, email translation, official letter translation etc.  In this paper, we used state of the art Sequence-to-Sequence Neural Network  for  and  translation.  We developed Neural Machine translation model for the Universiti Brunei Darussalam for  and vise versa. We created a data set of emails used at the University for communication over the period of three years.  We also added corresponding translation of the email content from Google Translate. We compared our model with Google Translation. Our objective was to study the performance of   machine translation model with attention decoder for   translation and  translation. 		 	%	We performed 80,000 iterations that reduced the cross-entropy loss from 4.498 to 0.023. We performed 40,000 iterations that reduced the loss from 4.14 to 0.106. The result model training is computationally faster in  rather than  .   %	We found BLEU score for randomly chosen 100 paragraphs from the data set after the model is trained when the NLL Loss is negligible. The low BLEU of  of our model and Google Translation indicates that the Malay Language has complex language features corresponding to English. The low BLEU of Google Translation in comparison to our model indicates that the application based regional models are better.  		 %	We observed that the model was unable to learn the context for source and target language within the input text even in the presence of attention mechanism. Thus, we need more efforts and different approach when dataset has multiple contexts. We also observed that the model was unable to learn the bilingual text in source and target languages within the input. Thus, we need new neural network for multilingual input text. A regional vocabulary based application oriented NMT model proposed in this paper gained BLEU points in comparison to Google Translate for regional vocabulary. However, we could not address all the problems observed in the Google Translate. We could improve over the regional vocabulary so to improve the BLEU score keeping the size of dataset small including multiple contexts in an email. The results indicates that application based regional models are better. Machine translation has many applications such as news translation, email translation, official letter translation etc. Commercial translators, e.g. Google Translation lags in regional vocabulary and are unable to learn the bilingual text in the source and target languages within the input. In this paper, a regional vocabulary-based application-oriented Neural Machine Translation  model is proposed over the data set of emails used at the University for communication over a period of three years. A state-of-the-art Sequence-to-Sequence Neural Network for   and  translations is compared with Google Translate using Gated Recurrent Unit Recurrent Neural Network machine translation model with attention decoder. The low BLEU score of Google Translation in comparison to our model indicates that the application based regional models are better. The low BLEU score of  of our model and Google Translation indicates that the Malay Language has complex language features corresponding to English.    
 Decomposing models into multiple components is critically important in many applications such as             language modeling    as it enables adapting individual components separately             and biasing of some components to the user's personal preferences. Conventionally, contextual and personalized adaptation for language models, are achieved through class-based factorization, 	which requires class-annotated data, or through biasing to individual phrases which is limited in scale.  In this paper, we propose a system that combines  components, by learning when to activate the generation process from each individual component,  	and how to combine probability distributions from each component, directly from unlabeled text data. 
 Conducting text retrieval in a dense representation space has many intriguing advantages. Yet the end-to-end learned dense retrieval  often underperforms word-based sparse retrieval. In this paper, we first theoretically show the learning bottleneck of dense retrieval is due to the domination of uninformative negatives sampled locally in batch, which yield diminishing gradient norms, large stochastic gradient variances, and slow learning convergence. We then propose Approximate nearest neighbor Negative Contrastive Learning , a learning mechanism that selects hard training negatives globally from the entire corpus, using an asynchronously updated ANN index. Our experiments demonstrate the effectiveness of ANCE on web search, question answering, and in a commercial search environment, showing ANCE dot-product retrieval nearly matches the accuracy of BERT-based cascade IR pipeline, while being 100x more efficient.  % We also empirically validate our theory that ANCE better approximates the oracle gradient-norm based importance sampling. % , thus improves the convergence. % of stochastic training. 
 E-commerce customers in developing nations like India tend to follow no fixed format while entering shipping addresses. Parsing such addresses is challenging because of a lack of inherent structure or hierarchy. It is imperative to understand the language of addresses, so that shipments can be routed without delays. In this paper, we propose a novel approach towards understanding customer addresses by deriving motivation from recent advances in Natural Language Processing . We also formulate different pre-processing steps for addresses using a combination of edit distance and phonetic algorithms. Then we approach the task of creating vector representations for addresses using Word2Vec with TF-IDF, Bi-LSTM and BERT based approaches. We compare these approaches with respect to sub-region classification task for North and South Indian cities. Through experiments, we demonstrate the effectiveness of generalized RoBERTa model, pre-trained over a large address corpus for language modelling task. Our proposed RoBERTa model achieves a classification accuracy of around 90\% with minimal text preprocessing for sub-region classification task outperforming all other approaches. Once pre-trained, the RoBERTa model can be fine-tuned for various downstream tasks in supply chain like pincode \footnote{Equivalent to zipcode} suggestion and geo-coding. The model generalizes well for such tasks even with limited labelled data. To the best of our knowledge, this is the first of its kind research proposing a novel approach of understanding customer addresses in e-commerce domain by pre-training language models and fine-tuning them for different purposes. 
 Visual Dialogue task requires an agent to be engaged in a conversation with human about an image. The ability of generating detailed and non-repetitive responses is crucial for the agent to achieve human-like conversation. In this paper, we propose a novel generative decoding architecture to generate high-quality responses, which moves away from decoding the whole encoded semantics towards the design that advocates both transparency and flexibility. In this architecture, word generation is decomposed into a series of attention-based information selection steps, performed by the novel recurrent Deliberation, Abandon and Memory  module. Each DAM module performs an adaptive combination of the response-level semantics captured from the encoder and the word-level semantics specifically selected for generating each word. Therefore, the responses contain more detailed and non-repetitive descriptions while maintaining the semantic accuracy. Furthermore, DAM is flexible to cooperate with existing visual dialogue encoders and adaptive to the encoder structures by constraining the information selection mode in DAM. We apply DAM to three typical encoders and verify the performance on the VisDial v1.0 dataset. Experimental results show that the proposed models achieve new state-of-the-art performance with high-quality responses. The code is available at https://github.com/JXZe/DAM.    
  The paper proposes a novel technique for representing templates and instances of concept classes. A template representation refers to the generic representation that captures the characteristics of an entire class. The proposed technique uses end-to-end deep learning to learn structured and composable representations from input images and discrete labels. The obtained representations are based on distance estimates between the distributions given by the class label and those given by contextual information, which are modeled as environments. We prove that the representations have a clear structure allowing to decompose the representation into factors that represent classes and environments. We evaluate our novel technique on classification and retrieval tasks involving different modalities .   
 Deep attention models have advanced the modelling of sequential data across many domains. For language modelling in particular, the Transformer-XL --- a Transformer augmented with a long-range memory of past activations --- has been shown to be state-of-the-art across a variety of well-studied benchmarks. The Transformer-XL incorporates a long-range memory at every layer of the network, which renders its state to be thousands of times larger than RNN predecessors. However it is unclear whether this is necessary. We perform a set of interventions to show that comparable performance can be obtained with 6X fewer long range memories and better performance can be obtained by limiting the range of attention in lower layers of the network. 
 Given an input video, its associated audio, and a brief caption, the audio-visual scene aware dialog  task requires an agent to indulge in a question-answer dialog with a human about the audio-visual content. This task thus poses a challenging multi-modal representation learning and reasoning scenario, advancements into which could influence several human-machine interaction applications. To solve this task, we introduce a  framework, consisting of a sequence of Transformer modules, each taking a modality as input and producing representations conditioned on the input question. Our proposed Transformer variant uses a shuffling scheme on their multi-head outputs, demonstrating better regularization. To encode fine-grained visual information, we present a novel dynamic scene graph representation learning pipeline that consists of an  layer producing spatio-semantic graph representations for every frame, and an  module capturing temporal cues. Our entire pipeline is trained end-to-end. We present experiments on the benchmark AVSD dataset, both on answer generation and selection tasks. Our results demonstrate state-of-the-art performances on all evaluation metrics. 
 %In image captioning, sequential models are preferred where fluency is an important factor in evaluation, \exempli $n$-gram metrics;  In image captioning where fluency is an important factor in evaluation, \exempli $n$-gram metrics, sequential models are commonly used;  however, sequential models generally result in overgeneralized expressions that lack the details that may be present in an input image. Inspired by the idea of the compositional neural module networks in the visual question answering task, we introduce a hierarchical framework for image captioning that explores both compositionality and sequentiality of natural language. Our algorithm learns to compose a detail-rich sentence by selectively attending to different modules corresponding to unique aspects of each object detected in an input image  to include specific descriptions such as counts and color. In a set of experiments on the MSCOCO dataset, the proposed model outperforms a state-of-the art model across multiple evaluation metrics, more importantly, presenting visually interpretable results. Furthermore, the breakdown of subcategories $f$-scores of the SPICE metric and human evaluation on Amazon Mechanical Turk  show that our compositional module networks effectively generate  accurate and detailed captions.   
 Generating longer textual sequences when conditioned on the visual information is an interesting problem to explore. The challenge here proliferate over the standard vision conditioned sentence-level generation  as it requires to produce a brief and coherent story describing the visual content. In this paper, we mask this Vision-to-Sequence as Graph-to-Sequence learning problem and approach it with the Transformer architecture.  To be specific, we introduce Sparse Graph-to-Sequence Transformer  for encoding the graph and decoding a sequence. The encoder aims to directly encode graph-level semantics, while the decoder is used to generate longer sequences. Experiments conducted with the benchmark image paragraph dataset show that our proposed achieve 13.3\% improvement on the CIDEr evaluation measure when comparing to the previous state-of-the-art approach. 
 % Attempts to render deep learning models interpretable, data-efficient, and robust have seen some success through hybridisation with rule-based systems, for example, in. % These neuro-symbolic models can induce interpretable rules and learn representations from data via back-propagation, while providing logical explanations for their predictions. % However, they are restricted by their computational complexity, as they need to consider all possible proof paths for explaining a goal, thus rendering them unfit for large-scale applications. % We present \glspl{CTP}, an extension to \glspl{NTP} that learns an optimal rule selection strategy via gradient-based optimisation. % We show that \glspl{CTP} are scalable and yield state-of-the-art results on the \glsentryshort{CLUTRR} dataset, which tests  of neural models by learning to reason over smaller graphs and evaluating on larger ones. % Finally, \glspl{CTP} show better link prediction results on standard benchmarks in comparison with other neural-symbolic models, while being explainable. % All source code and datasets are available online.} % 
%   <- trailing '%' for backward compatibility of .sty file Continual learning systems will interact with humans, with each other, and with the physical world through time -- and continue to learn and adapt as they do. An important open problem for continual learning is a large-scale benchmark which enable realistic evaluation of algorithms. In this paper, we study a natural setting for continual learning on a massive scale. We introduce the problem of personalized online language learning , which involves fitting personalized language models to a population of users that evolves over time. To facilitate research on POLL, we collect massive datasets of Twitter posts. These datasets, Firehose10M and Firehose100M, comprise 100 million tweets, posted by one million users over six years. Enabled by the Firehose datasets, we present a rigorous evaluation of continual learning algorithms on an unprecedented scale. Based on this analysis, we develop a simple algorithm for continual gradient descent  that outperforms prior continual learning methods on the Firehose datasets as well as earlier benchmarks. Collectively, the POLL problem setting, the Firehose datasets, and the ConGraD algorithm enable a complete benchmark for reproducible research on web-scale continual learning. 
 Social network structure is one of the key determinants of human language evolution. Previous work has shown that the network of social interactions shapes decentralized learning in human groups, leading to the emergence of different kinds of communicative conventions. We examined the effects of social network organization on the properties of communication systems emerging in decentralized, multi-agent reinforcement learning communities. We found that the global connectivity of a social network drives the convergence of populations on shared and symmetric communication systems, preventing the agents from forming many local ``dialects". Moreover, the agent's degree is inversely related to the consistency of its use of communicative conventions. These results show the importance of the basic properties of social network structure on reinforcement communication learning and suggest a new interpretation of findings on human convergence on word conventions.% among interacting humans.  %We found that the proportion of global connections in a social network determines the convergence of populations on shared and symmetric communication systems  
 Aiming to minimize service delay, we propose a new random caching scheme in device-to-device -assisted heterogeneous network. To support diversified viewing qualities of multimedia video services, each video file is encoded into a base layer  and multiple enhancement layers  by scalable video coding . A super layer, including the BL and several ELs, is transmitted to every user. We define and quantify the service delay of multi-quality videos by deriving successful transmission probabilities when a user is served by a D2D helper, a small-cell base station  and a macro-cell base station . We formulate a delay minimization problem subject to the limited cache sizes of D2D helpers and SBSs. The structure of the optimal solutions to the problem is revealed, and then an improved standard gradient projection method is designed to effectively obtain the solutions. Both theoretical analysis and Monte-Carlo simulations validate the successful transmission probabilities. Compared with three benchmark caching policies, the proposed SVC-based random caching scheme is superior in terms of reducing the service delay. 
 \label{sec:abs}  With social media becoming  ubiquitous, information consumption from this media has also increased.  However, one of the serious problems that has emerged with this increase, is the propagation of rumors.  Therefore, rumor identification is a very critical task with significant implications to economy, democracy as well as public health and safety.  We tackle the problem of automated  detection of rumors in social media  in this paper by designing a modular  explainable architecture that uses both latent  and handcrafted features and can be expanded to as many new classes of features as desired.  This approach will allow the end user to not only determine whether the piece of information on the social media is real of a rumor, but also give explanations on why the algorithm arrived at its conclusion. Using attention mechanisms, we are able to interpret the relative importance of each of these features as well as the relative importance of the feature classes themselves.  The advantage of this approach is that the architecture is expandable  to more handcrafted features as they  become available and also to conduct extensive testing to determine the relative influences of theses features in the final decision. Extensive experimentation on popular  datasets and  benchmarking against eleven  contemporary algorithms, show that  our approach performs significantly better in  terms of F-score and accuracy  while also being interpretable. 
 Understanding how people who commit suicide perceive their cognitive states and emotions represents a crucially open scientific challenge. We build upon cognitive network science, psycholinguistics and semantic frame theory to introduce a network representation of suicidal ideation as expressed in multiple suicide notes. By reconstructing the knowledge structure of such notes, we reveal interconnections between the semantic ideas and emotional states of people who committed suicide through structural balance theory, semantic prominence and emotional profiling. Our results indicate that connections between positively- and negatively-valenced terms give rise to a degree of structural balance that is significantly higher than in a null model where the affective structure is randomized and in a linguistic baseline model capturing mind-wandering in absence of suicidal ideation. We show that suicide notes are affectively compartmentalized such that positive concepts tend to cluster together and dominate the overall network structure. Notably, this positive clustering diverges from perceptions of self, which are found to be dominated by negative, sad conceptual associates in analyses about subject-verb-object structure and emotional profiling. A key positive concept is ``love'', which integrates information relating the self to others in ways that are semantically prominent across suicide notes. The emotions populating the semantic frame of ``love'' combine joy and trust with anticipation and sadness, which can be linked to psychological theories of meaning-making as well as narrative psychology. Our results open new ways for understanding the structure of genuine suicide notes and may be used to inform future research on suicide prevention. 
 In natural language processing , enormous pre-trained models like BERT have become the standard starting point for training on a range of downstream tasks, and similar trends are emerging in other areas of deep learning. In parallel, work on the  has shown that models for NLP and computer vision contain smaller  subnetworks capable of training in isolation to full accuracy and transferring to other tasks. In this work, we combine these observations to assess whether such trainable, transferrable subnetworks exist in pre-trained BERT models. For a range of downstream tasks, we indeed find matching subnetworks at 40\% to 90\% sparsity. We find these subnetworks at  initialization, a deviation from prior NLP research where they emerge only after some amount of training. Subnetworks found on the masked language modeling task  transfer ; those found on other tasks transfer in a limited fashion if at all. As large-scale pre-training becomes an increasingly central paradigm in deep learning, our results demonstrate that the main lottery ticket observations remain relevant in this context. Codes available at \url{https://github.com/VITA-Group/BERT-Tickets}. 
 We present several neural networks to address the task of named entity recognition for morphologically complex languages . % Kazakh is a morphologically complex language in which each root/stem can produce hundreds or thousands of variant word forms. % This nature of the language could lead to a serious data sparsity problem, which may prevent the deep learning models from being well trained for under-resourced MCLs. % In order to model the MCLs' words effectively, we introduce root and entity tag embedding plus tensor layer to the neural networks. % The effects of those are significant for improving NER model performance of MCLs.  % The proposed models outperform state-of-the-art including character-based approaches, and can be potentially applied to other morphologically complex languages.  
 Automatic video captioning aims to train models to generate text descriptions for all segments in a video, however, the most effective approaches require large amounts of manual annotation which is slow and expensive. Active learning is a promising way to efficiently build a training set for video captioning tasks while reducing the need to manually label uninformative examples. In this work we both explore various active learning approaches for automatic video captioning and show that a cluster-regularized ensemble strategy provides the best active learning approach to efficiently gather training sets for video captioning. We evaluate our approaches on the MSR-VTT and LSMDC datasets using both transformer and LSTM based captioning models and show that our novel strategy can achieve high performance while using up to 60\% fewer training data than the strong state of the art baselines.  
 Grounded language acquisition --- learning how language-based interactions refer to the world around them --- is a major area of research in robotics, NLP, and HCI. In practice the data used for learning consists almost entirely of textual descriptions, which tend to be cleaner, clearer, and more grammatical than actual human interactions. In this work, we present the Grounded Language Dataset , a multimodal dataset of common household objects described by people using either spoken or written language. We analyze the differences and present an experiment showing how the different modalities affect language learning from human input. This will enable researchers studying the intersection of robotics, NLP, and HCI to better investigate how the multiple modalities of image, text, and speech interact, as well as how differences in the vernacular of these modalities impact results.  
 % 150/200 words max Contrastive Predictive Coding , based on predicting future segments of speech based on past segments is emerging as a powerful algorithm for representation learning of speech signal. However, it still under-performs other methods on unsupervised evaluation benchmarks. Here, we introduce WavAugment, a time-domain data augmentation library and find that applying augmentation in the past is generally more efficient and yields better performances than other methods. We find that a combination of pitch modification, additive noise and reverberation substantially increase the performance of CPC , beating the reference Libri-light results with 600 times less data. Using an out-of-domain dataset, time-domain data augmentation can push CPC to be on par with the state of the art on the Zero Speech Benchmark 2017. We also show that time-domain data augmentation consistently improves downstream limited-supervision phoneme classification tasks by a factor of 12-15\% relative.   %\matthijs{mention that the best data augmentation can reduce the required training data by a factor 600 } % %\morgane{if we look at the ablation study in the appendix, it seems that the architecture, on LS-100, is responsible for about 1/3 of the improvement. But we must also consider other factors not mentionned in this paper: noise and speaker distribution.} 
 Spoken language understanding is typically based on pipeline architectures including speech recognition and natural language understanding steps. These components are optimized independently to allow usage of available data, but the overall system suffers from error propagation. In this paper, we propose a novel training method that enables pretrained contextual embeddings to process acoustic features. In particular, we extend it with an encoder of pretrained speech recognition systems in order to construct end-to-end spoken language understanding systems. Our proposed method is based on the teacher-student framework across speech and text modalities that aligns the acoustic and the semantic latent spaces. Experimental results in three benchmarks show that our system reaches the performance comparable to the pipeline architecture without using any training data and outperforms it after fine-tuning with ten examples per class on two out of three benchmarks. 
 The intuitive interaction between the audio and visual modalities is valuable for cross-modal self-supervised learning. This concept has been demonstrated for generic audiovisual tasks like video action recognition and acoustic scene classification. However, self-supervision remains under-explored for audiovisual speech. We propose a method to learn self-supervised speech representations from the raw audio waveform. We train a raw audio encoder by combining audio-only self-supervision  with visual self-supervision . The visual pretext task drives the audio representations to capture information related to lip movements. This enriches the audio encoder with visual information and the encoder can be used for evaluation without the visual modality. Our method attains competitive performance with respect to existing self-supervised audio features on established isolated word classification benchmarks, and significantly outperforms other methods at learning from fewer labels. Notably, our method also outperforms fully supervised training, thus providing a strong initialization for speech related tasks. Our results demonstrate the potential of multimodal self-supervision in audiovisual speech for learning good audio representations. 
 In this paper\footnote{$^*$ Equal contribution. $\dagger$ Corresponding author.}, we develop DeepSinger, a multi-lingual multi-singer singing voice synthesis  system, which is built from scratch using singing training data mined from music websites. The pipeline of DeepSinger consists of several steps, including data crawling, singing and accompaniment separation, lyrics-to-singing alignment, data filtration, and singing modeling. Specifically, we design a lyrics-to-singing alignment model to automatically extract the duration of each phoneme in lyrics starting from coarse-grained sentence level to fine-grained phoneme level, and further design a multi-lingual multi-singer singing model based on a feed-forward Transformer to directly generate linear-spectrograms from lyrics, and synthesize voices using Griffin-Lim. DeepSinger has several advantages over previous SVS systems: 1) to the best of our knowledge, it is the first SVS system that directly mines training data from music websites, 2) the lyrics-to-singing alignment model further avoids any human efforts for alignment labeling and greatly reduces labeling cost, 3) the singing model based on a feed-forward Transformer is simple and efficient, by removing the complicated acoustic feature modeling in parametric synthesis and leveraging a reference encoder to capture the timbre of a singer from noisy singing data, and 4) it can synthesize singing voices in multiple languages and multiple singers. We evaluate DeepSinger on our mined singing dataset that consists of about 92 hours data from 89 singers on three languages . The results demonstrate that with the singing data purely mined from the Web, DeepSinger can synthesize high-quality singing voices in terms of both pitch accuracy and voice naturalness\footnote{Our audio samples are shown in \url{https://speechresearch.github.io/deepsinger/}.}.  
  Speech recognition is a well developed research field so that the current state of the art systems are being used in many applications in the software industry, yet as by today, there still does not exist such robust system for the recognition of words and sentences from singing voice. This paper proposes a complete pipeline for this task which may commonly be referred as automatic lyrics transcription . We have trained convolutional time-delay neural networks with self-attention on monophonic karaoke recordings using a sequence classification objective for building the acoustic model. The dataset used in this study, DAMP - Sing! 300x30x2 is filtered to have songs with only English lyrics. Different language models are tested including MaxEnt and Recurrent Neural Networks based methods which are trained on the lyrics of pop songs in English. An in-depth analysis of the self-attention mechanism is held while tuning its context width and the number of attention heads. Using the best settings, our system achieves notable improvement to the state-of-the-art in ALT and provides a new baseline for the task.   
 In this paper, we present an efficient neural network for end-to-end general purpose audio source separation. Specifically, the backbone structure of this convolutional network is the SUccessive DOwnsampling and Resampling of Multi-Resolution Features  as well as their aggregation which is performed through simple one-dimensional convolutions. In this way, we are able to obtain high quality audio source separation with limited number of floating point operations, memory requirements, number of parameters and latency. Our experiments on both speech and environmental sound separation datasets show that \sudo performs comparably and even surpasses various state-of-the-art approaches with significantly higher computational resource requirements.   
 Recently Deep Transformer models have proven to be particularly powerful in language modeling tasks for ASR. Their high complexity, however, makes them very difficult to apply in the first  pass of an online system. Recent studies showed that a considerable part of the knowledge of neural network Language Models  can be transferred to traditional n-grams by using neural text generation based data augmentation. In our paper, we pre-train a GPT-2 Transformer LM on a general text corpus and fine-tune it on our Hungarian conversational call center ASR task. We show that although data augmentation with Transformer-generated text works well for isolating languages, it causes a vocabulary explosion in a morphologically rich language. Therefore, we propose a new method called subword-based neural text augmentation, where we retokenize the generated text into statistically derived subwords. We compare Morfessor and BPE statistical subword tokenizers and show that both methods can significantly improve the WER while greatly reducing vocabulary size and memory requirements. Finally, we also demonstrate that subword-based neural text augmentation outperforms the word-based approach not only in terms of overall WER but also in recognition of OOV words.  
 Deep neural networks  based automatic speech recognition  systems are often designed using expert knowledge and empirical evaluation. In this paper, a range of neural architecture search  techniques are used to automatically learn two types of hyper-parameters of state-of-the-art factored time delay neural networks : i) the left and right splicing context offsets; and ii) the dimensionality of the bottleneck linear projection at each hidden layer. These include the DARTS method integrating architecture selection with lattice-free MMI  TDNN training; Gumbel-Softmax and pipelined DARTS reducing the confusion over candidate architectures and improving the generalization of architecture selection; and Penalized DARTS incorporating resource constraints to adjust the trade-off between performance and system complexity. Parameter sharing among candidate architectures allows efficient search over up to $7^{28}$ different TDNN systems. Experiments conducted on the 300-hour Switchboard corpus suggest the auto-configured systems consistently outperform the baseline LF-MMI TDNN systems using manual network design or random architecture search after LHUC speaker adaptation and RNNLM rescoring. Absolute word error rate  reductions up to 1.0\% and relative model size reduction of 28\% were obtained. Consistent performance improvements were also obtained on a UASpeech disordered speech recognition task using the proposed NAS approaches. % Deep neural networks  based automatic speech recognition  systems are often designed using expert knowledge and empirical evaluation. In this paper, a range of neural architecture search  techniques are used to automatically learn three hyper-parameters that heavily affect the performance and model complexity of state-of-the-art factored time delay neural network  acoustic models: i) the left and right splicing context offsets; ii) the dimensionality of the bottleneck linear projection and iii) skip connections at each hidden layer. These include the standard DARTS method fully integrating the estimation of architecture weights and TDNN parameters in lattice-free MMI  training; Gumbel-Softmax DARTS that reduces the confusion between candidate architectures; Pipelined DARTS that circumvents the overfitting of architecture weights using held-out data; and Penalized DARTS that further incorporates resource constraints to adjust the trade-off between performance and system complexity. Parameter sharing among candidate architectures was also used to facilitate efficient search over up to $7^{28}$ different TDNN systems. Experiments conducted on a 300-hour Switchboard task suggest the NAS auto-configured TDNN-F systems consistently outperform the baseline LF-MMI trained TDNN-F systems using manual expert configurations. Absolute word error rate reductions up to 1.0\% and relative model size reduction of 28\% were obtained. Consistent performance improvements were also obtained in the disorder UASPEECH task. 
 This paper investigates different trade-offs between the number of model parameters and enhanced speech qualities by employing several deep tensor-to-vector regression models for speech enhancement. We find that a hybrid architecture, namely CNN-TT, is capable of maintaining a good quality performance with a reduced model parameter size. CNN-TT is composed of several convolutional layers at the bottom for feature extraction to improve speech quality and a tensor-train  output layer on the top to reduce model parameters. We first derive a new upper bound on the generalization power of the convolutional neural network  based vector-to-vector regression models. Then, we provide experimental evidence on the Edinburgh noisy speech corpus to demonstrate that, in single-channel speech enhancement, CNN outperforms DNN at the expense of a small increment of model sizes. Besides, CNN-TT slightly outperforms the CNN counterpart by utilizing only 32\% of the CNN model parameters. Besides, further performance improvement can be attained if the number of CNN-TT parameters is increased to 44\% of the CNN model size. Finally, our experiments of multi-channel speech enhancement on a simulated noisy WSJ0 corpus demonstrate that our proposed hybrid CNN-TT architecture achieves better results than both DNN and CNN models in terms of better-enhanced speech qualities and smaller parameter sizes. %Finally, experimental results on the multi-channel speech enhancement on the in-house noisy corrupted Wall Street Journal  corpus confirm our claims.  %This work applies various deep hybrid tensor-to-vector regression models for speech enhancement. In particular, we are mainly concerned with two goals:  Providing new insights into the tensor models based on approximation power of deep neural network  based tensor-to-vector functions from both theoretical and practical points of view, and  Finding different deep hybrid tensor architectures in terms of multiple metrics, i.e., the number of model parameters and speech enhancement performance. In particular, we focus on convolutional neural networks  and tensor-train neural networks  in dealing with tensorized speech data since the two architectures belong to the tensor-to-vector framework. Moreover, different hybrid architectures based on convolutional and tensor-train layers are evaluated. Our experiments of speech enhancement include both single-channel and multi-channel speech enhancement, and the empirical results suggest the following three findings:  CNNs attain better results than TT-NNs;  better speech enhancement results can be obtained by deploying neural models having convolutional and TT layers. % this work also investigates the use of Tucker decomposition to further reduce the number of CNN parameters, and strike a balance between speech enhancement performance and model complexity. 
 The real-world capabilities of objective speech quality measures are limited since current measures  are developed from simulated data that does not adequately model real environments; or they  predict objective scores that are not always strongly correlated with subjective ratings. Additionally, a large dataset of real-world signals with listener quality ratings does not currently exist, which would help facilitate real-world assessment. In this paper, we collect and predict the perceptual quality of real-world speech signals that are evaluated by human listeners. We first collect a large quality rating dataset by conducting crowdsourced listening studies on two real-world corpora. We further develop a novel approach that predicts human quality ratings using a pyramid bidirectional long short term memory  network with an attention mechanism. The results show that the proposed model achieves statistically lower estimation errors than prior assessment approaches, where the predicted scores strongly correlate with human judgments.  
 Text classification is the most fundamental and essential task in natural language processing.  The last decade has seen a surge of research in this area due to the unprecedented success of deep learning.  Numerous methods, datasets, and evaluation metrics have been proposed in the literature, raising the need for a comprehensive and updated survey.  This paper fills the gap by reviewing the state of the art approaches from 1961 to 2020, focusing on models from shallow to deep learning.  We create a taxonomy for text classification according to the text involved and the models used for feature extraction and classification. We then discuss each of these categories in detail, dealing with both the technical developments and benchmark datasets that support tests of predictions.  A comprehensive comparison between different techniques, as well as identifying the pros and cons of various evaluation metrics are also provided in this survey.  Finally, we conclude by summarizing key implications, future research directions, and the challenges facing the research area. 
 Relation Extraction is a way of obtaining the semantic relationship between entities in text. The state-of-the-art methods use linguistic tools to build a graph for the text in which the entities appear and then a Graph Convolutional Network  is employed to encode the pre-built graphs. Although their performance is promising, the reliance on linguistic tools results in a non end-to-end process. In this work, we propose a novel model, the Self-determined Graph Convolutional Network , which determines a weighted graph using a self-attention mechanism, rather using any linguistic tool. Then, the self-determined graph is encoded using a GCN. We test our model on the TACRED dataset and achieve the state-of-the-art result. Our experiments show that SGCN outperforms the traditional GCN, which uses dependency parsing tools to build the graph. 
 %   Most humour processing systems to date make at best discrete, coarse-grained distinctions between the comical and the conventional, yet such notions are better conceptualized as a broad spectrum.  In this paper, we present a probabilistic approach, a variant of Gaussian process preference learning , that learns to rank and rate the humorousness of short texts by exploiting human preference judgments and automatically sourced linguistic annotations.  We apply our system, which had previously shown good performance on English-language one-liners annotated with pairwise humorousness annotations, to the Spanish-language data set of the \HAHA evaluation campaign.  We report system performance for the campaign's two subtasks, humour detection and funniness score prediction, and discuss some issues arising from the conversion between the numeric scores used in the \HAHA data and the pairwise judgment annotations required for our method. 
     In this paper, we describe a methodology to predict sentiment in code-mixed tweets . Our team called verissimo.manoel in CodaLab\footnote{https://competitions.codalab.org/competitions/20654} developed an approach based on an ensemble of four models . The final classification algorithm was an ensemble of some predictions of all softmax values from these four models. This architecture was used and evaluated in the context of the SemEval 2020 challenge , and our system got 72.7\% on the F1 score. 
 %  %  %  %  \\  Generating a set of keyphrases that summarizes the core ideas discussed in a document has a significant impact on many applications, including document understanding, retrieval, advertising, and more. In recent years, deep neural sequence-to-sequence framework has demonstrated promising results in keyphrase generation. However, processing long documents using such deep neural networks requires high computational resources. To reduce the computational cost, the documents are typically truncated before given as inputs. As a result, the models may miss essential points conveyed in a document. Moreover, most of the existing methods are either extractive  or generative , and hence they do not benefit from the advantages of both modeling techniques. To address these challenges, we propose , a neural keyphrase generation model that is composed of two major components,  a selector that selects the salient sentences in a document, and  an extractor-generator that jointly extracts and generates keyphrases from the selected sentences. SEG-Net uses a self-attentive architecture, known as,  as the building block with a couple of uniqueness. First, SEG-Net incorporates a novel  coverage attention to summarize most of the points discussed in the target document. Second, it uses an  copy attention mechanism to encourage focusing on different segments of the document during keyphrase extraction and generation. Besides, SEG-Net jointly learns keyphrase generation and their part-of-speech tag prediction, where the later provides syntactic supervision to the former. The experimental results on seven keyphrase generation benchmarks from scientific and web documents demonstrate that SEG-Net outperforms the state-of-the-art neural generative methods by a large margin in both domains.  %Combining these two prevailing approaches in jointly learning to extract and generate can enable us to predict a comprehensive set of keyphrases.  % Relying on only one type of these prevailing approaches risks to miss important keyphrases.  % SEG-Net uses a self-attentive architecture, known as,  to learn document representations for its ability to capture long-range dependencies.  % SEG-Net has a couple of uniqueness compared to the vanilla Transformer.  % during keyphrase generation to emphasize less on the document segments, from where the keyphrases are extracted. % such that the extracted and generated keyphrases remain mutually exclusive.  
  We test the hypothesis that the extent to which one obtains information on a given topic through Wikipedia depends on the language in which it is consulted.  % Controlling the size factor, we investigate this hypothesis for a number of 25 subject areas.  % %That is, we test whether even in cases where two Wikipedias cover the same topic with approximately the same number of articles, they inform about this topic rather differently. % Since Wikipedia is a central part of the web-based information landscape, this indicates a language-related,  linguistic bias.  % The article therefore deals with the question of whether Wikipedia exhibits this kind of linguistic relativity or not. % From the perspective of educational science, the article develops a computational model of the information landscape from which multiple texts are drawn as typical input of web-based reading. % For this purpose, it develops a hybrid model of intra- and intertextual similarity of different parts of the information landscape and tests this model on the example of 35 languages and corresponding Wikipedias. % In this way the article builds a bridge between reading research, educational science, Wikipedia research and computational linguistics.  %%% Leave the Abstract empty if your article does not require one, please see the Summary Table for full details. % % %Deadline: 15.\,05.~2020\par %For full guidelines regarding your manuscript please refer to {Author Guidelines}.  %As a primary goal, the abstract should render the general significance and conceptual advance of the work clearly accessible to a broad readership. References should not be cited in the abstract. Leave the Abstract empty if your article does not require one, please see {Summary Table} for details according to article type.    \tiny     %All article types: you may provide up to 8 keywords; at least 5 are mandatory. 
  Threshold concepts are key terms in domain-based knowledge acquisition. % They are regarded as building blocks of the conceptual development of domain knowledge within particular learners.  % From a linguistic perspective, however, threshold concepts are instances of specialized vocabularies, exhibiting particular linguistic features. % Threshold concepts are typically used in specialized texts such as textbooks -- that is, within a  learning environment.  % However, they also occur in  learning environments like newspapers. % In this article, a first approach is taken to combine both lines into an overarching research program -- that is, to provide a computational linguistic assessment of different resources, including in particular online resources, by means of threshold concepts. % To this end, the distributive profiles of 63 threshold concepts from business education  has been investigated in three kinds of  resources, namely textbooks, newspapers, and Wikipedia. % Wikipedia is  the largest and most widely used online resources. % We looked at the threshold concepts' frequency distribution, their compound distribution, and their network structure within the three kind of resources.  % The two main findings can be summarized as follows:  % Firstly, the three kinds of resources can indeed be distinguished in terms of their threshold concepts' profiles. % Secondly, Wikipedia definitely appears to be a formal learning resource. 
 The Managed Care system within Medicaid  uses Request For Proposals  to award contracts for various healthcare and related services. RFP responses are very detailed documents  submitted by competing organisations to win contracts. Subject matter expertise and domain knowledge play an important role in preparing RFP responses along with analysis of historical submissions. Automated analysis of these responses through Natural Language Processing   systems can reduce time and effort needed to explore historical responses, and assisting in writing better responses.  Our work draws parallels between scoring RFPs and essay scoring models, while highlighting new challenges and the need for interpretability. Typical scoring models focus on word level impacts to grade essays and other short write-ups. We propose a novel Bi-LSTM based regression model, and provide deeper insight into phrases which latently impact scoring of responses. We contend the merits of our proposed methodology using extensive quantitative experiments. We also qualitatively asses the impact of important phrases using human evaluators. Finally, we introduce a novel problem statement that can be used to further improve the state of the art in NLP based automatic scoring systems.   
 Pre-trained language models like BERT and its variants have recently achieved impressive performance in various natural language understanding tasks. However, BERT heavily relies on the global self-attention block and thus suffers large memory footprint and computation cost. Although all its attention heads query on the whole input sequence for generating the attention map  from a global perspective, we observe some heads only need to learn local dependencies, which means the existence of computation redundancy. We therefore propose a novel span-based dynamic convolution to replace these self-attention heads to directly model local dependencies. The novel convolution heads, together with the rest self-attention heads, form a new mixed attention block that is more efficient at both global and local context learning. We equip BERT with this mixed attention design and build a ConvBERT model. Experiments have shown that ConvBERT significantly outperforms BERT and its variants in various downstream tasks, with lower training costs and fewer model parameters. Remarkably, ConvBERTbase model achieves 86.4 GLUE score, 0.7 higher than ELECTRAbase, using less than $1/4$ training cost. \footnote{Code and pre-trained model will be released at \url{https://github.com/yitu-opensource/ConvBert}.} 
   Humans are remarkably flexible when understanding new sentences that include   combinations of concepts they have never encountered before. Recent work has   shown that while deep networks can mimic some human language abilities when   presented with novel sentences, systematic variation uncovers the limitations   in the language-understanding abilities of neural networks. We demonstrate that these   limitations can be overcome by addressing the generalization challenges in a   recently-released dataset, gSCAN, which explicitly measures how well a robotic   agent is able to interpret novel ideas grounded in vision, e.g., novel   pairings of adjectives and nouns. The key principle we employ is   compositionality: that the compositional structure of networks should reflect   the compositional structure of the problem domain they address, while allowing   all other parameters and properties to be learned end-to-end with weak   supervision. We build a general-purpose mechanism that enables robots to   generalize their language understanding to compositional domains. Crucially,   our base network has the same state-of-the-art performance as prior work, 97\%   execution accuracy, while at the same time generalizing its knowledge when   prior work does not; for example, achieving 95\% accuracy on novel   adjective-noun compositions where previous work has 55\% average   accuracy. Robust language understanding without dramatic failures and without   corner causes is critical to building safe and fair robots; we demonstrate the   significant role that compositionality can play in achieving that goal. 
   We describe our system for SemEval-2020 Task 11 on Detection of Propaganda Techniques in News Articles. We developed ensemble models using RoBERTa-based neural architectures, additional CRF layers, transfer learning between the two subtasks, and advanced post-processing to handle the multi-label nature of the task, the consistency between nested spans, repetitions, and labels from similar spans in training. We achieved sizable improvements over baseline fine-tuned RoBERTa models, and the official evaluation ranked our system $\mathbf{3^{rd}}$  out of 36 teams on the span identification subtask with an F1 score of 0.491, and $\mathbf{2^{nd}}$  out of 31 teams on the technique classification subtask with an F1 score of 0.62. 
 We release a multilingual neural machine translation model, which can be used to translate text in the biomedical domain. The model can translate from 5 languages  into English. It is trained with large amounts of generic and biomedical data, using domain tags. Our benchmarks show that it performs near state-of-the-art both on news  and biomedical test sets, and that it outperforms the existing publicly released models. We believe that this release will help the large-scale multilingual analysis of the digital content of the COVID-19 crisis and of its effects on society, economy, and healthcare policies. We also release a test set of biomedical text for Korean-English. It consists of 758 sentences from official guidelines and recent papers, all about COVID-19.  
 Query Auto Completion , as the starting point of information retrieval tasks, is critical to user experience. Generally it has two steps: generating completed query candidates according to query prefixes, and ranking them based on extracted features. Three major challenges are observed for a query auto completion system:  QAC has a strict online latency requirement. For each keystroke, results must be returned within tens of milliseconds, which poses a significant challenge in designing sophisticated language models for it.  For unseen queries, generated candidates are of poor quality as contextual information is not fully utilized.  Traditional QAC systems heavily rely on handcrafted features such as the query candidate frequency in search logs, lacking sufficient semantic understanding of the candidate.  In this paper, we propose an efficient neural QAC system with effective context modeling to overcome these challenges. On the candidate generation side, this system uses as much information as possible in unseen prefixes to generate relevant candidates, increasing the recall by a large margin. On the candidate ranking side, an unnormalized language model is proposed, which effectively captures deep semantics of queries. This approach presents better ranking performance over state-of-the-art neural ranking methods and reduces $\sim$95\% latency compared to neural language modeling methods. The empirical results on public datasets show that our model achieves a good balance between accuracy and efficiency. This system is served in LinkedIn job search with significant product impact observed. 
 Semi-supervised learning  is an active area of research which aims to utilize unlabelled data in order to improve the accuracy of speech recognition systems. The current study proposes a methodology for integration of two key ideas: 1) SSL using connectionist temporal classification  objective and teacher-student based learning 2) Designing effective data-selection mechanisms for leveraging unlabelled data to boost performance of student models. Our aim is to establish the importance of good criteria in selecting samples from a large pool of unlabelled data based on attributes like confidence measure, speaker and content variability. The question we try to answer is: Is it possible to design a data selection mechanism which reduces dependence on a large set of randomly selected unlabelled samples without compromising on Word Error Rate ? We perform empirical investigations of different data selection methods to answer this question and quantify the effect of different sampling strategies. On a semi-supervised ASR setting with 40000 hours of carefully selected unlabelled data, our CTC-SSL approach gives 17\% relative WER improvement over a baseline CTC system trained with labelled data. It also achieves on-par performance with CTC-SSL system trained on order of magnitude larger unlabeled data based on random sampling.  
 We propose a novel generative model to explore both local and global context for joint learning topics and topic-specific word embeddings. In particular, we assume that global latent topics are shared across documents, a word is generated by a hidden semantic vector encoding its contextual semantic meaning, and its context words are generated conditional on both the hidden semantic vector and global latent topics. Topics are trained jointly with the word embeddings. The trained model maps words to topic-dependent embeddings, which naturally addresses the issue of word polysemy. Experimental results show that the proposed model outperforms the word-level embedding methods in both word similarity evaluation and word sense disambiguation. Furthermore, the model also extracts more coherent topics compared with existing neural topic models or other models for joint learning of topics and word embeddings. Finally, the model can be easily integrated with existing deep contextualized word embedding learning methods to further improve the performance of downstream tasks such as sentiment classification. 
 		In this paper, we study how to leverage pre-trained language models in Text-to-SQL. We argue that previous approaches under utilize the base language models by concatenating all columns together with the NL question and feeding them into the base language model in the encoding stage. We propose a neat approach called Hybrid Ranking Network~ which breaks down the problem into column-wise ranking and decoding and finally assembles the column-wise outputs into a SQL query by straightforward rules. In this approach, the encoder is given a NL question and one individual column, which perfectly aligns with the original tasks BERT/RoBERTa is trained on, and hence we avoid any ad-hoc pooling or additional encoding layers which are necessary in prior approaches. Experiments on the WikiSQL dataset show that the proposed approach is very effective, achieving the top place on the leaderboard. 	
   We present \sockeyeTwo, a modernized and streamlined version of the \sockeye neural machine translation  toolkit.   New features include a simplified code base through the use of \mxnet's \gluon API, a focus on state of the art model architectures, distributed mixed precision training, and efficient CPU decoding with 8-bit quantization.   These improvements result in faster training and inference, higher automatic metric scores, and a shorter path from research to production. 
 In recent years, the fields of natural language processing  and information retrieval  have made tremendous progress thanks to deep learning models like Recurrent Neural Networks , Gated Recurrent Units  and Long Short-Term Memory  networks, and Transformer~ based models like Bidirectional Encoder Representations from Transformers ~. %, Generative Pre-training Transformer ~, Multi-task Deep Neural Network ~, Extra-Long Network ~, Text-to-text transfer transformer ~, etc.  But these models are humongous in size. %: BERT~ , GPT-2~ , T5~ . On the other hand, real world applications demand small model size, low response times and low computational power wattage. In this survey, we discuss six different types of methods  for compression of such models to enable their deployment in real industry NLP  projects. Given the critical need of building applications with efficient and small models, and the large amount of recently published work in this area, we believe that this survey organizes the plethora of work done by the `deep learning for NLP' community in the past few years and presents it as a coherent story.  
 Self-supervised learning, a.k.a., pretraining, is important in natural language processing. Most of the pretraining methods first randomly mask some positions in a sentence and then train a model to recover the tokens at the masked positions. In such a way, the model can be trained without human labeling, and the massive data can be used with billion parameters. Therefore, the optimization efficiency becomes critical.  In this paper, we tackle the problem from the view of gradient variance reduction. In particular, we first propose a principled gradient variance decomposition theorem, which shows that the variance of the stochastic gradient of the language pretraining can be naturally decomposed into two terms: the variance that arises from the sample of data in a batch, and the variance that arises from the sampling of the mask. The second term is the key difference between self-supervised learning and supervised learning, which makes the pretraining slower. In order to reduce the variance of the second part, we leverage the importance sampling strategy, which aims at sampling the masks according to a proposal distribution instead of the uniform distribution. It can be shown that if the proposal distribution is proportional to the gradient norm, the variance of the sampling is reduced. To improve efficiency, we introduced a MAsk Proposal Network , which approximates the optimal mask proposal distribution and is trained end-to-end along with the model. According to the experimental result, our model converges much faster and achieves higher performance than the baseline BERT model.  
   The automatic quality assessment of self-media online articles is an urgent and new issue, which is of great value to the online recommendation and search. Different from traditional and well-formed articles, self-media online articles are mainly created by users, which have the appearance characteristics of different text levels and multi-modal hybrid editing, along with the potential characteristics of diverse content, different styles, large semantic spans and good interactive experience requirements. To solve these challenges, we establish a joint model CoQAN in combination with the layout organization, writing characteristics and text semantics, designing different representation learning subnetworks, especially for the feature learning process and interactive reading habits on mobile terminals. It is more consistent with the cognitive style of expressing an expert's evaluation of articles. We have also constructed a large scale real-world assessment dataset. Extensive experimental results show that the proposed framework significantly outperforms state-of-the-art methods, and effectively learns and integrates different factors of the online article quality assessment. 
