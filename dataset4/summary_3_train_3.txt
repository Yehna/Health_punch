 We investigate different strategies for automatic offensive language classification on German Twitter data. For this, we employ a sequentially combined BiLSTM-CNN neural network. Based on this model, three  transfer learning tasks to improve the classification performance with background knowledge are tested. We compare 1. Supervised category transfer: social media data annotated with near-offensive language categories, 2. Weakly-supervised category transfer: tweets annotated with emojis they contain, 3. Unsupervised category transfer: tweets annotated with topic clusters obtained by Latent Dirichlet Allocation . Further, we investigate the effect of three different  strategies to mitigate negative effects of `catastrophic forgetting' during transfer learning. Our results indicate that transfer learning in general improves offensive language detection. Best results are achieved from pre-training our model on the unsupervised topic clustering of tweets in combination with thematic user cluster information.  
  Customer support is a central objective at Square as it helps us build and maintain great relationships with our sellers. In order to provide the best experience, we strive to deliver the most accurate and quasi-instantaneous responses to questions regarding our products.  In this work, we introduce the Attention Fusion Network model which combines signals extracted from seller interactions on the Square product ecosystem, along with submitted email questions, to predict the most relevant solution to a seller's inquiry. We show that the innovative combination of two very different data sources that are rarely used together, using state-of-the-art deep learning systems outperforms, candidate models that are trained only on a single source.   % Square's product ecosystem, as well as the content of their emails to predict the most relevant solutions to their inquiries. We show that it outperforms models that only take into account handcrafted signals or text.  
 End-to-end approaches have recently become popular as a means of simplifying the training and deployment of speech recognition systems. However, they often require large amounts of data to perform well on large vocabulary tasks.  %To make speech recognition accessible to a wider audience,  With the aim of making end-to-end approaches usable by a broader range of researchers, we explore the potential to use end-to-end methods in small vocabulary contexts where smaller datasets may be used.  A significant drawback of small-vocabulary systems is the difficulty of expanding the vocabulary beyond the original training samples -- therefore we also study strategies to extend the vocabulary with only few examples per new class .  Our results show that an attention-based encoder-decoder can be competitive against a strong baseline on a small vocabulary keyword classification task, reaching 97.5\% of accuracy on Tensorflow's Speech Commands dataset. It also shows promising results on the few-shot learning problem where a simple strategy achieved 68.8\% of accuracy on new keywords with only 10 examples for each new class. This score goes up to 88.4\% with a larger set of 100 examples. 
  We train a recurrent neural network language model using a distributed, on-device learning framework called federated learning for the purpose of next-word prediction in a virtual keyboard for smartphones. Server-based training using stochastic gradient descent is compared with training on client devices using the FederatedAveraging algorithm. The federated algorithm, which enables training on a higher-quality dataset for this use case, is shown to achieve better prediction recall. This work demonstrates the feasibility and benefit of training language models on client devices without exporting sensitive user data to servers. The federated learning environment gives users greater control over the use of their data and simplifies the task of incorporating privacy by default with distributed training and aggregation across a population of client devices.  
     This paper presents a neural architecture for Vietnamese sequence labeling tasks including part-of-speech  tagging and named entity recognition . We applied the model described in  that is a combination of bidirectional Long-Short Term Memory and Conditional Random Fields, which rely on two sources of information about words: character-based word representations learned from the supervised corpus and pre-trained word embeddings learned from other unannotated corpora. Experiments on benchmark datasets show that this work achieves state-of-the-art performances on both tasks - 93.52\% accuracy for POS tagging and 94.88\% F1 for NER. Our sourcecode is available at  {here}. 
 Word embeddings are a key component of high-performing natural language processing  systems, but it remains a challenge to learn  on the fly, i.e., for words that did not occur in the training data. The general problem setting is that word embeddings are induced on an unlabeled training corpus and then a model is trained that embeds novel words into this induced embedding space. Currently, two approaches for learning embeddings of novel words exist:  learning an embedding from the novel word's   and  learning an embedding from the  in which it occurs. In this paper, we propose an architecture that leverages both sources of information -- surface-form and context -- and show that it results in large increases in embedding quality. Our architecture  obtains state-of-the-art results on the Definitional Nonce  and  Contextual Rare Words datasets. As input, we only require an embedding set and an unlabeled corpus for training our architecture to produce embeddings appropriate for the induced embedding space. Thus, our model can easily be integrated into any existing NLP system and enhance its capability to handle novel words. 
 Imagine a robot is shown new concepts visually together with spoken tags, e.g.\ ``milk'', ``eggs'', ``butter''. After seeing one paired audio-visual example per class, it is shown a new set of unseen instances of these objects, and asked to pick the ``milk''. Without receiving any hard labels, could it learn to match the new continuous speech input to the correct visual instance? Although unimodal one-shot learning has been studied, where one labelled example in a single modality is given per class, this example motivates multimodal one-shot learning. Our main contribution is to formally define this task, and to propose several baseline and advanced models. We use a dataset of paired spoken and visual digits to specifically investigate recent advances in Siamese convolutional neural networks. Our best Siamese model achieves twice the accuracy of a nearest neighbour model using pixel-distance over images and dynamic time warping over speech in 11-way cross-modal matching. 
 To disclose overlapped multiple relations from a sentence still keeps challenging. Most current works in terms of neural models inconveniently assuming that each sentence is explicitly mapped to a relation label, cannot handle multiple relations properly as the overlapped features of the relations are either ignored or very difficult to identify. To tackle with the new issue, we propose a novel approach for multi-labeled relation extraction with capsule network which acts considerably better than current convolutional or recurrent net in identifying the highly overlapped relations within an individual sentence. To better cluster the features and precisely extract the relations, we further devise attention-based routing algorithm and sliding-margin loss function, and embed them into our capsule network. The experimental results show that the proposed approach can indeed extract the highly overlapped features and achieve significant performance improvement for relation extraction comparing to the state-of-the-art works. 
 Social networks can serve as a valuable communication channel for asking for help, offering assistance, and coordinating rescue activities in disaster because it allows users to continuously update critical information in the fast-changing disaster environment. This paper presents a novel sequence to sequence based framework for forecasting people's needs during disasters using social media and weather data. It consists of two Long Short-Term Memory  models, one of which encodes input sequences of weather information and the other plays as a conditional decoder that decodes the encoded vector and forecasts the survivors' needs. Case studies using data collected during Hurricane Sandy in 2012, Hurricane Harvey and Hurricane Irma in 2017 demonstrate that the proposed approach outperformed the statistical language model n-gram, LSTM generative model, and convolutional neural network  based model. This research indicates its great promise for enhancing disaster management such as evacuation planning and commodity delivery.  
     Most existing works on dialog systems only consider conversation content while neglecting the personality of the user the bot is interacting with, which begets several unsolved issues.     In this paper, we present a personalized end-to-end model in an attempt to leverage personalization in goal-oriented dialogs.     We first introduce a Profile Model which encodes user profiles into distributed embeddings and refers to conversation history from other similar users.     Then a Preference Model captures user preferences over knowledge base entities to handle the ambiguity in user requests.     The two models are combined into the Personalized MemN2N.     Experiments show that the proposed model achieves qualitative performance improvements over state-of-the-art methods.     As for human evaluation, it also outperforms other approaches in terms of task completion rate and user satisfaction. 
 Fake news, rumor, incorrect information, and misinformation detection are nowadays crucial issues as these might have serious consequences for our social fabrics. The rate of such information is increasing rapidly due to the availability of enormous web information sources including social media feeds, news blogs, online newspapers etc.    In this paper, we develop various deep learning models for detecting fake news and classifying them into the pre-defined fine-grained categories.   At first, we develop models based on Convolutional Neural Network  and Bi-directional Long Short Term Memory  networks. The representations obtained from these two models are fed into a Multi-layer Perceptron Model  for the final classification. Our experiments on a benchmark dataset show promising results with an overall accuracy of 44.87\%, which outperforms the current state of the art.   
  We explore why deep convolutional neural networks  with small two-dimensional kernels, primarily used for modeling spatial relations in images, are also effective in speech recognition. We analyze the representations learned by deep CNNs and compare them with deep neural network  representations and i-vectors, in the context of acoustic model adaptation. To explore whether interpretable information can be decoded from the learned representations we evaluate their ability to discriminate between speakers, acoustic conditions, noise type, and gender using the Aurora-4 dataset. We extract both whole model embeddings  and layer-specific embeddings which enable understanding of the flow of information across the network. We also use learned representations as the additional input for a time-delay neural network   for the Aurora-4 and MGB-3 English datasets. We find that deep CNN embeddings outperform DNN embeddings for acoustic model adaptation and auxiliary features based on deep CNN embeddings result in similar word error rates to i-vectors.  
 % Autoregressive decoding is the only part of sequence-to-sequence models that prevents them from massive parallelization at inference time. % Non-autoregressive models enable the decoder to generate all output symbols independently in parallel. % We present a novel non-autoregressive architecture based on connectionist temporal classification and evaluate it on the task of neural machine translation. % Unlike other non-autoregressive methods which operate in several steps, our model can be trained end-to-end. % We conduct experiments on the WMT English-Romanian and English-German datasets. % Our models achieve a significant speedup over the autoregressive models, keeping the  translation quality comparable to other non-autoregressive models. % 
 Do unsupervised methods for learning rich, contextualized token representations obviate the need for explicit modeling of linguistic structure in neural network models for semantic role labeling ? We address this question by incorporating the massively successful ELMo embeddings  into LISA , a strong, linguistically-informed neural network architecture for SRL. In experiments on the CoNLL-2005 shared task we find that though ELMo out-performs typical word embeddings, beginning to close the gap in F1 between LISA with predicted and gold syntactic parses, syntactically-informed models still out-perform syntax-free models when both use ELMo, especially on out-of-domain data. Our results suggest that linguistic structures are indeed still relevant in this golden age of deep learning for NLP. %Our results suggest that with the right modeling, incorporating linguistic structures can indeed further improve strong neural network models for NLP. 
 		Dialogue Act  classification is a challenging problem in dialogue interpretation, which aims to attach semantic labels to utterances and characterize the speaker's intention. 		Currently, many existing approaches formulate the DA classification problem ranging from multi-classification to structured prediction, which suffer from two limitations: a) these methods are either handcrafted feature-based or have limited memories. b) adversarial examples can't be correctly classified by traditional training methods. To address these issues, in this paper we first cast the problem into a question and answering problem and proposed an improved dynamic memory networks with hierarchical pyramidal utterance encoder. Moreover, we apply adversarial training to train our proposed model. We evaluate our model on two public datasets, i.e., Switchboard dialogue act corpus and the MapTask corpus. Extensive experiments show that our proposed model is not only robust, but also achieves better performance when compared with some state-of-the-art baselines.  	
 \iffalse This paper focuses on the problem of processing natural language with Recurrent Neural Networks. Traditional RNNs usually process each token indiscriminately, in this way, however, they may miss rich semantic structure information inside a sentence. In fact, text-related problems could benefit from leveraging semantic structures such as word dependence. Since structures like word dependence patterns are not learnable parameters, it is challenging to capture and leverage structure information directly. In this paper, we propose an improved variant of RNN, Multi-channel RNN , to dynamically capture and leverage local structures and word dependence patterns inside natural languages. Concretely, MC-RNN contains multiple channels, which can enumerate different local dependence patterns respectively. An attention mechanism is designed to selectively combine these patterns at each step, according to the semantic information. By dynamically and adaptively selecting the most appropriate connection structures among different channels in MC-RNN, the idea of capturing structure information can be formulated as a parameterized learnable problem. We then solve the above problem and show that diverse local structures and dependence patterns in the sentences can be well captured. To verify the effectiveness of MC-RNN, we conduct extensive experiments on typical natural language processing tasks, including neural machine translation, abstractive summarization, and language modeling. Experimental results on these tasks all show significant improvements of MC-RNN over current top systems. \fi Recurrent Neural Networks  have been widely used in processing natural language tasks and achieve huge success. Traditional RNNs usually treat each token in a sentence uniformly and equally. However, this may miss the rich semantic structure information of a sentence, which is useful for understanding natural languages. Since semantic structures such as word dependence patterns are not parameterized, it is a challenge to capture and leverage structure information. In this paper, we propose an improved variant of RNN, Multi-Channel RNN , to dynamically capture and leverage local semantic structure information. Concretely, MC-RNN contains multiple channels, each of which represents  a local dependence pattern at a time. An attention mechanism is introduced to combine these patterns at each step, according to the semantic information. Then we parameterize structure information by adaptively selecting the most appropriate connection structures among channels. In this way, diverse local structures and dependence patterns in sentences can be well captured by MC-RNN. To verify the effectiveness of MC-RNN, we conduct extensive experiments on typical natural language processing tasks, including neural machine translation, abstractive summarization, and language modeling. Experimental results on these tasks all show significant improvements of MC-RNN over current top systems. 
 Corporate distress models typically only employ the numerical financial variables in the firms' annual reports. We develop a model that employs the unstructured textual data in the reports as well, namely the auditors' reports and managements' statements. Our model consists of a convolutional recurrent neural network which, when concatenated with the numerical financial variables, learns a descriptive representation of the text that is suited for corporate distress prediction. We find that the unstructured data provides a statistically significant enhancement of the distress prediction performance, in particular for large firms where accurate predictions are of the utmost importance. Furthermore, we find that auditors' reports are more informative than managements' statements and that a joint model including both managements' statements and auditors' reports displays no enhancement relative to a model including only auditors' reports. Our model demonstrates a direct improvement over existing state-of-the-art models. 
 User interaction with voice-powered agents generates large amounts of unlabeled utterances. In this paper, we explore techniques to efficiently transfer the knowledge from these unlabeled utterances to improve model performance on Spoken Language Understanding  tasks. We use Embeddings from Language Model  to take advantage of unlabeled data by learning contextualized word representations. Additionally, we propose  ELMo-Light , a faster and simpler unsupervised pre-training method for SLU. Our findings suggest unsupervised pre-training on a large corpora of unlabeled utterances leads to significantly better SLU performance compared to training from scratch and it can even outperform conventional supervised transfer. Additionally, we show that the gains from unsupervised transfer techniques can be further improved by supervised transfer. The improvements are more pronounced in low resource settings and when using only 1000 labeled in-domain samples, our techniques match the performance of training from scratch on 10-15x more labeled in-domain data. 
  This paper presents a novel approach for multi-task learning of language understanding  and dialogue state tracking  in task-oriented dialogue systems. Multi-task training enables the sharing of the neural network layers responsible for encoding the user utterance for both LU and DST and improves performance while reducing the number of network parameters. In our proposed framework, DST operates on a set of candidate values for each slot that has been mentioned so far. These candidate sets are generated using LU slot annotations for the current user utterance, dialogue acts corresponding to the preceding system utterance and the dialogue state estimated for the previous turn, enabling DST to handle slots with a large or unbounded set of possible values and deal with slot values not seen during training. Furthermore, to bridge the gap between training and inference, we investigate the use of scheduled sampling on LU output for the current user utterance as well as the DST output for the preceding turn. 
 Extracting valuable facts or informative summaries from multi-dimensional tables, i.e. insight mining, is an important task in data analysis and business intelligence. However, ranking the importance of insights remains a challenging and unexplored task.  The main challenge is that explicitly scoring an insight or giving it a rank requires a thorough understanding of the tables and costs a lot of manual efforts, which leads to the lack of available training data for the insight ranking problem. In this paper, we propose an insight ranking model that consists of two parts: A neural ranking model explores the data characteristics, such as the header semantics and the data statistical features,  and a memory network model introduces table structure and context information into the ranking process. We also build a dataset with text assistance. Experimental results show that our approach largely improves the ranking precision as reported in multi evaluation metrics.  
  Distant supervised relation extraction has been successfully applied to 	large corpus with thousands of relations.	However, the inevitable wrong labeling problem by distant supervision  will hurt the performance of relation extraction.  In this paper, we propose a method with neural noise converter to alleviate the impact of noisy data, and a conditional optimal selector to make proper prediction. Our noise converter learns the structured transition matrix on logit level and captures the property of distant supervised relation extraction dataset. The conditional optimal selector on the other hand helps to make proper prediction decision of an entity pair even if  the  group of sentences is overwhelmed by no-relation sentences.  We conduct experiments on a widely used dataset and the results show significant improvement over competitive baseline methods.  
   Biased language commonly occurs around topics which are of controversial nature, thus, stirring disagreement between the different involved parties of a discussion. This is due to the fact that for language and its use, specifically, the understanding and use of phrases, the stances are cohesive within the particular groups. However, such cohesiveness does not hold across groups.  In collaborative environments or environments where impartial language is desired , statements and the language therein should represent equally the involved parties and be neutrally phrased. Biased language is introduced through the presence of inflammatory words or phrases, or statements that may be incorrect or one-sided, thus violating such consensus.  In this work, we focus on the specific case of phrasing bias, which may be introduced through specific inflammatory words or phrases in a statement. For this purpose, we propose an approach that relies on a recurrent neural networks in order to capture the inter-dependencies between words in a phrase that introduced bias.   We perform a thorough experimental evaluation, where we show the advantages of a neural based approach over competitors that rely on word lexicons and other hand-crafted features in detecting biased language. We are able to distinguish biased statements with a precision of $P=0.917$, thus significantly outperforming baseline models with an improvement of over 30\%.  Finally, we release the largest corpus of statements annotated for biased language. 
   Dependency grammar induction is the task of learning dependency   syntax without annotated training data.     Traditional graph-based models with global inference achieve state-of-the-art results on   this task but they require $O$ run time.    Transition-based models enable faster inference with $O$ time complexity, but their performance still lags behind.    In this work, we propose a neural transition-based parser for dependency grammar induction,   whose inference procedure utilizes rich neural features with $O$ time complexity.    We train the parser with an integration of variational inference, posterior regularization and variance reduction techniques.    The resulting framework outperforms previous unsupervised transition-based dependency parsers and achieves performance comparable to graph-based models, both on the English Penn Treebank   and on the Universal Dependency Treebank.    In an empirical comparison, we show that our approach substantially increases parsing speed over graph-based models. 
 Learning to construct text representations in end-to-end systems can be difficult, as natural languages are highly compositional and task-specific annotated datasets are often limited in size. Methods for directly supervising language composition can allow us to guide the models based on existing knowledge, regularizing them towards more robust and interpretable representations. In this paper, we investigate how objectives at different granularities can be used to learn better language representations and we propose an architecture for jointly learning to label sentences and tokens. The predictions at each level are combined together using an attention mechanism, with token-level labels also acting as explicit supervision for composing sentence-level representations. Our experiments show that by learning to perform these tasks jointly on multiple levels, the model achieves substantial improvements for both sentence classification and sequence labeling.   % Neural text classification models need to learn composition functions in order to construct representations for sentences and paragraphs. % Learning these regularities from data can be difficult, as language is highly compositional and annotated datasets are often limited in size. % We propose an architecture for text classification based on self-attention, which can be directly trained to focus on relevant areas of the text. % The supervised attention component is optimized as a sequence labeling system, resulting in a model for text classification that also labels individual tokens.   %We propose an architecture for jointly learning to label sentences and tokens for applications where we have some degree of supervision for both levels of analysis.  %The predictions on each level are combined together using an attention mechanism, with token-level labels also acting as explicit supervision for composing sentence-level representations. %We evaluate the architecture on three tasks:  uncertainty detection, grammatical error detection, and sentiment detection. %Our experiments show that by learning to perform these tasks jointly on multiple levels, the model achieves substantial improvements on both sentence classification and sequence labeling. 
     Much effort has been devoted to evaluate whether multi-task learning can be leveraged to learn rich representations that can be used in various Natural Language Processing  down-stream applications. However, there is still a lack of understanding of the settings in which multi-task learning has a significant effect. In this work, we introduce a hierarchical model trained in a multi-task learning setup on a set of carefully selected semantic tasks. The model is trained in a hierarchical fashion to introduce an inductive bias by supervising a set of low level tasks at the bottom layers of the model and more complex tasks at the top layers of the model. This model achieves state-of-the-art results on a number of tasks, namely Named Entity Recognition, Entity Mention Detection and Relation Extraction without hand-engineered features or external NLP tools like syntactic parsers. The hierarchical training supervision induces a set of shared semantic representations at lower layers of the model. We show that as we move from the bottom to the top layers of the model, the hidden states of the layers tend to represent more complex semantic information. 
 Structured queries expressed in languages  offer a convenient and explicit way for users to express their information needs for a number of tasks. In this work, we present an approach to answer these directly over text data without storing results in a database. We specifically look at the case of knowledge bases where queries are over entities and the relations between them. Our approach combines distributed query answering  with models built for  extractive question answering. Importantly, by applying distributed querying answering we are able to simplify the model learning problem. We train models for a large portion  of the relations within Wikidata and achieve an average 0.70 F1 measure across all models. We also present a systematic method to construct the necessary training data for this task from knowledge graphs and describe a prototype implementation. 
 Recent speech synthesis systems based on sampling from autoregressive neural networks models can generate speech almost undistinguishable from human recordings. However, these models require large amounts of data.    %they are efficient at dealing with less homogenous data. % This might make possible to compensate  % evaluates this hypothesis by training several Tacotron2-like models with different blends of data.  %The mel-spectrograms generated by these models were converted to audio with a WaveRNN-like neural-vocoder trained on 74 speakers from 17 different languages.  This paper shows that the lack of data from one speaker can be compensated with data from other speakers. The naturalness of Tacotron2-like models trained on a blend of 5k utterances from 7 speakers is better than that of speaker dependent models trained on 15k utterances, but in terms of stability multi-speaker models are always more stable. %, and very close to that of SD models trained on 25k utterances.  We also demonstrate that models mixing only 1250 utterances from a target speaker with 5k utterances from another 6 speakers can produce significantly better quality than state-of-the-art DNN-guided unit selection systems trained on more than 10 times the data from the target speaker. 
 Neural conversation models are attractive because one can train a model directly on dialog examples with minimal labeling. With a small amount of data, however, they often fail to generalize over test data since they tend to capture spurious features instead of semantically meaningful domain knowledge. To address this issue, we propose a novel approach that allows any human teachers to transfer their domain knowledge to the conversation model in the form of natural language rules.  We tested our method with three different dialog datasets. The improved performance across all domains demonstrates the efficacy of our proposed method. 
 The increasing concern with misinformation has stimulated research efforts on automatic fact checking. The recently-released FEVER dataset introduced a benchmark fact-verification task in which a system is asked to verify a claim using evidential sentences from Wikipedia documents. In this paper, we present a connected system consisting of three homogeneous neural semantic matching models that conduct document retrieval, sentence selection, and claim verification jointly for fact extraction and verification. For evidence retrieval , unlike traditional vector space IR models in which queries and sources are matched in some pre-designed term vector space, we develop neural models to perform deep semantic matching from raw textual input, assuming no intermediate term representation and no access to structured external knowledge bases. We also show that Pageview frequency can also help improve the performance of evidence retrieval results, that later can be matched by using our neural semantic matching network. For claim verification, unlike previous approaches that simply feed upstream retrieved evidence and the claim to a natural language inference  model, we further enhance the NLI model by providing it with internal semantic relatedness scores  and ontological WordNet features. Experiments on the FEVER dataset indicate that  our neural semantic matching method outperforms popular TF-IDF and encoder models, by significant margins on all evidence retrieval metrics,  the additional relatedness score and WordNet features improve the NLI model via better semantic awareness, and  by formalizing all three subtasks as a similar semantic matching problem and improving on all three stages, the complete model is able to achieve the state-of-the-art results on the FEVER test set .\footnote{Code: {}}  
 Some news headlines mislead readers with overrated or false information, and identifying them in advance will better assist readers in choosing proper news stories to consume. This research introduces million-scale pairs of news headline and body text dataset with incongruity label, which can uniquely be utilized for detecting news stories with misleading headlines. On this dataset, we develop two neural networks with hierarchical architectures that model a complex textual representation of news articles and measure the incongruity between the headline and the body text. We also present a data augmentation method that dramatically reduces the text input size a model handles by independently investigating each paragraph of news stories, which further boosts the performance. Our experiments and qualitative evaluations demonstrate that the proposed methods outperform existing approaches and efficiently detect news stories with misleading headlines in the real world. 
 Affect conveys important implicit information in human communication. Having the capability to correctly express affect during human-machine conversations is one of the major milestones in artificial intelligence. In recent years, extensive research on open-domain neural conversational models has been conducted. However, embedding affect into such models is still under explored. In this paper, we propose an end-to-end affect-rich open-domain neural conversational model that produces responses not only appropriate in syntax and semantics, but also with rich affect. Our model extends the Seq2Seq model and adopts VAD  affective notations to embed each word with affects. In addition, our model considers the effect of negators and intensifiers via a novel affective attention mechanism, which biases attention towards affect-rich words in input sentences. Lastly, we train our model with an affect-incorporated objective function to encourage the generation of affect-rich words in the output responses. Evaluations based on both perplexity and human evaluations show that our model outperforms the state-of-the-art baseline model of comparable size in producing natural and affect-rich responses. 
 Citation function and provenance are two cornerstone tasks in citation analysis. Given a citation, the former task determines its rhetorical role, while the latter locates the text in the cited paper that contains the relevant cited information. We hypothesize that these two tasks are synergistically related, and build a model that validates this claim. For both tasks, we show that a single-layer convolutional neural network  outperforms existing state-of-the-art baselines. More importantly, we show that the two tasks are indeed synergistic: by jointly training both of the tasks in a multi-task learning setup, we demonstrate additional performance gains. Altogether, our models improve the current state-of-the-arts up to 2\%, with statistical significance for both citation function and provenance prediction tasks. 
 Training task-completion dialogue agents with reinforcement learning usually requires a large number of real user experiences. The Dyna-Q algorithm extends Q-learning by integrating a world model, and thus can effectively boost training efficiency using simulated experiences generated by the world model. The effectiveness of Dyna-Q, however, depends on the quality of the world model - or implicitly, the pre-specified ratio of real vs. simulated experiences used for Q-learning. To this end, we extend the recently proposed Deep Dyna-Q  framework by integrating a  that automatically determines whether to use a real or simulated experience for Q-learning. Furthermore, we explore the use of active learning for improving sample efficiency, by encouraging the world model to generate simulated experiences in the state-action space where the agent has not  explored. Our results show that by combining switcher and active learning, the new framework named as Switch-based Active Deep Dyna-Q , leads to significant improvement over DDQ and Q-learning baselines in both simulation and human evaluations.\footnote{Source code is at https://github.com/CrickWu/Switch-DDQ.} 
 Although generation-based dialogue systems have been widely researched, the response generations by most existing systems have very low diversities. The most likely reason for this problem is Maximum Likelihood Estimation  with Softmax Cross-Entropy  loss. MLE trains models to generate the most frequent responses from enormous generation candidates, although in actual dialogues there are various responses based on the context. In this paper, we propose a new objective function called Inverse Token Frequency  loss, which individually scales smaller loss for frequent token classes and larger loss for rare token classes. This function encourages the model to generate rare tokens rather than frequent tokens. It does not complicate the model and its training is stable because we only replace the objective function. On the OpenSubtitles dialogue dataset, our loss model establishes a state-of-the-art DIST-1 of 7.56, which is the unigram diversity score, while maintaining a good BLEU-1 score. On a Japanese Twitter replies dataset, our loss model achieves a DIST-1 score comparable to the ground truth. 
 %Due to recent advances in high throughput DNA sequencing techniques, there has been a huge wave in genomic data creating the need for better storage, processing and transmission therefore efficient compression mechanisms.  Sequential data is being generated at an unprecedented pace in various forms, including text and genomic data. This creates the need for efficient compression mechanisms to enable better storage, transmission and processing of such data. To solve this problem, many of the existing compressors attempt to learn models for the data and perform prediction-based compression. Since neural networks are known as universal function approximators with the capability to learn arbitrarily complex mappings, and in practice show excellent performance in prediction tasks, we explore and devise methods to compress sequential data using neural network predictors. We combine recurrent neural network predictors with an arithmetic coder and losslessly compress a variety of synthetic, text and genomic datasets. The proposed compressor outperforms Gzip on the real datasets and achieves near-optimal compression for the synthetic datasets. The results also help understand why and where neural networks are good alternatives for traditional finite context models.\\ The code and data are available at \url{https://github.com/mohit1997/DeepZip}. 
 Although Neural Machine Translation  models have advanced state-of-the-art performance in machine translation, they face problems like the inadequate translation.  We attribute this to that the standard Maximum Likelihood Estimation  cannot judge the real translation quality due to its several limitations.  In this work, we propose an adequacy-oriented learning mechanism for NMT by casting translation as a stochastic policy in Reinforcement Learning , where the reward is estimated by explicitly measuring translation adequacy. Benefiting from the sequence-level training of RL strategy and a more accurate reward designed specifically for translation, our model outperforms multiple strong baselines, including  standard and coverage-augmented attention models with MLE-based training, and  advanced reinforcement and adversarial training strategies with rewards based on both word-level BLEU and character-level chrF3. Quantitative and qualitative analyses on different language pairs and NMT architectures demonstrate the effectiveness and universality of the proposed approach.  
 Recently, a large number of neural mechanisms and models have been proposed for sequence learning, of which self-attention, as exemplified by the Transformer model, and graph neural networks  have attracted much attention. In this paper, we propose an approach that combines and draws on the complementary strengths of these two methods. Specifically, we propose contextualized non-local neural networks , which can both dynamically construct a task-specific structure of a sentence and leverage rich local dependencies within a particular neighbourhood.  Experimental results on ten NLP tasks in text classification, semantic matching, and sequence labelling show that our proposed model outperforms competitive baselines and discovers task-specific dependency structures, thus providing better interpretability to users. 
 Entity Linking aims to link entity mentions in texts to knowledge bases, and neural models have achieved recent success in this task. However, most existing methods rely on local contexts to resolve entities independently, which may usually fail due to the data sparsity of local information. To address this issue, we propose a novel neural model for collective entity linking, named as NCEL. NCEL applies Graph Convolutional Network to integrate both local contextual features and global coherence information for entity linking. To improve the computation efficiency, we approximately perform graph convolution on a subgraph of adjacent entity mentions instead of those in the entire text. We further introduce an attention scheme to improve the robustness of NCEL to data noise and train the model on Wikipedia hyperlinks to avoid overfitting and domain bias. In experiments, we evaluate NCEL on five publicly available datasets to verify the linking performance as well as generalization ability. We also conduct an extensive analysis of time complexity, the impact of key modules, and qualitative results, which demonstrate the effectiveness and efficiency of our proposed method. %Recently, neural network models have achieved a great success in the task of entity linking. However, to resolve entities independently, these methods may fail in the case that only sparse discriminative information is available from the local contexts. In this paper, we propose a novel neural model for collective entity link, namely NCEL, that integrates both local contextual features and global coherence information with the help of Graph Convolutional Network. For efficiency, we approximately make graph convolution on a subgraph of adjacent mentions instead of that for the entire document. We introduce attention mechanism so that NCEL is robust to noise, and then trained on collected Wikipedia hyperlinks to avoid overfitting and domain bias. In experiments, we evaluate NCEL on 5 public available datasets to verify the linking performance as well as generalization ability. Besides, we also give a deep analysis on time complexity, the impacts of main modules and qualitative results that demonstrates the effectiveness and efficiency of our proposed method. 
 Machine Reading Comprehension  with multiple- choice questions requires the machine to read given passage and select the correct answer among several candidates. In this paper, we propose a novel approach called Convolutional Spatial Attention  model which can better handle the MRC with multiple-choice questions. The proposed model could fully extract the mutual information among the passage, question, and the candidates, to form the enriched representations. Furthermore, to merge various attention results, we propose to use convolutional operation to dynamically summarize the attention values within the different size of regions. Experimental results show that the proposed model could give substantial improvements over various state-of- the-art systems on both RACE and SemEval-2018 Task11 datasets. 
 We propose a segmental neural language model that combines the generalization power of neural networks with the ability to discover word-like units that are latent in unsegmented character sequences. In contrast to previous segmentation models that treat word segmentation as an isolated task, our model unifies word discovery, learning how words fit together to form sentences, and, by conditioning the model on visual context, how words' meanings ground in representations of non-linguistic modalities. Experiments show that the unconditional model learns predictive distributions better than character LSTM models, discovers words competitively with nonparametric Bayesian word segmentation models, and that modeling language conditional on visual context improves performance on both. 
 Although there are more than 6,500 languages in the world, the pronunciations of many phonemes sound similar across the languages. When people learn a foreign language, their pronunciation often reflects their native language's characteristics. This motivates us to investigate how the speech synthesis network learns the pronunciation from datasets from different languages. In this study, we are interested in analyzing and taking advantage of multilingual speech synthesis network. First, we train the speech synthesis network bilingually in English and Korean and analyze how the network learns the relations of phoneme pronunciation between the languages. Our experimental result shows that the learned phoneme embedding vectors are located closer if their pronunciations are similar across the languages. Consequently, the trained networks can synthesize the English speakers' Korean speech and vice versa. Using this result, we propose a training framework to utilize information from a different language. To be specific, we pre-train a speech synthesis network using datasets from both high-resource language and low-resource language, then we fine-tune the network using the low-resource language dataset. Finally, we conducted more simulations on 10 different languages to show it is generally extendable to other languages. 
 In recent years, the sequence-to-sequence learning neural networks with attention mechanism have achieved great progress. However, there are still challenges, especially for Neural Machine Translation , such as lower translation quality on long sentences. In this paper, we present a hierarchical deep neural network architecture to improve the quality of long sentences translation. The proposed network embeds sequence-to-sequence neural networks into a two-level category hierarchy by following the coarse-to-fine paradigm. Long sentences are input by splitting them into shorter sequences, which can be well processed by the coarse category network as the long distance dependencies for short sentences is able to be handled by network based on sequence-to-sequence neural network. Then they are concatenated and corrected by the fine category network. The experiments shows that our method can achieve superior results with higher BLEU scores, lower perplexity and better performance in imitating expression style and words usage than the traditional networks. 
 Recurrent neural networks  such as long short-term memory and gated recurrent units are pivotal building blocks across a broad spectrum of sequence modeling problems. This paper proposes a recurrently controlled recurrent network  for expressive and powerful sequence encoding. More concretely, the key idea behind our approach is to learn the recurrent gating functions using recurrent networks. Our architecture is split into two components - a controller cell and a listener cell whereby the recurrent controller actively influences the compositionality of the listener cell. We conduct extensive experiments on a myriad of tasks in the NLP domain such as sentiment analysis , question classification , entailment classification , answer selection  and reading comprehension . Across all 26 datasets, our results demonstrate that RCRN not only consistently outperforms BiLSTMs but also stacked BiLSTMs, suggesting that our controller architecture might be a suitable replacement for the widely adopted stacked architecture.   
 The use of future contextual information is typically shown to be helpful for acoustic modeling. %However, for the recurrent neural network , it's not so easy to model the future temporal context effectively, meanwhile keep lower model latency.  Recently, we proposed a RNN model called minimal gated recurrent unit with input projection , in which a context module namely , is specifically designed \iffalse on the projection layer\fi to model the future context. This model, mGRUIP with context module , has been shown to be able of utilizing the future context effectively, meanwhile with quite low model latency and computation cost.   In this paper, we continue to improve mGRUIP-Ctx with two revisions: applying BN methods and enlarging model context. Experimental results on two Mandarin ASR tasks  show that, the revised mGRUIP-Ctx outperform LSTM with a large margin . It even performs slightly better than a superior BLSTM on the 8400h task, with 33M less parameters and just 290ms model latency. %After revising, mGRUIP-Ctx outperform LSTM with a large margin. It even performs slightly better than a superior BLSTM on one task, with much less parameters and much lower latency.  
 We present two architectures for multi-task learning with neural sequence models. Our approach allows the relationships between different tasks to be learned dynamically, rather than using an ad-hoc pre-defined structure as in previous work. We adopt the idea from message-passing graph neural networks, and propose a general graph multi-task learning framework in which different tasks can communicate with each other in an effective and interpretable way. We conduct extensive experiments in text classification and sequence labelling to evaluate our approach on multi-task learning and transfer learning. The empirical results show that our models not only outperform competitive baselines, but also learn interpretable and transferable patterns across tasks. 
 Named entity recognition  is one of the tasks in natural language processing that can greatly benefit from the use of external knowledge sources. We propose a named entity recognition framework composed of knowledge-based feature extractors and a deep learning model including contextual word embeddings, long short-term memory  layers and conditional random fields  inference layer. We use an entity linking module to integrate our system with Wikipedia. The combination of effective neural architecture and external resources allows us to obtain state-of-the-art results on recognition of Polish proper names. We evaluate our model on data from PolEval 2018\footnote{\url{http://poleval.pl}} NER challenge on which it outperforms other methods, reducing the error rate by 22.4\% compared to the winning solution. Our work shows that combining neural NER model and entity linking model with a knowledge base is more effective in recognizing named entities than using NER model alone. 
   The meaning of a sentence is a function of the relations that hold between its words. We instantiate this relational view of semantics in a series of neural models based on variants of relation networks  which represent a set of objects  in terms of representations of pairs of objects. We propose two extensions to the basic RN model for natural language. First, building on the intuition that not all word pairs are equally informative about the meaning of a sentence, we use constraints based on both supervised and unsupervised dependency syntax to control which relations influence the representation. Second, since higher-order relations are poorly captured by a sum of pairwise relations, we use a recurrent extension of RNs to propagate information so as to form representations of higher order relations. Experiments on sentence classification, sentence pair classification, and machine translation reveal that, while basic RNs are only modestly effective for sentence representation, recurrent RNs with latent syntax are a reliably powerful representational device. 
  % Journals and news are often important sources of information for professionals who work in finance or finance related field. In recent years, as theories of natural language processing rapidly advance, researchers are capable of discovering new information from news and journals through computing techniques such as machine learning and artificial intelligence. In this research, our goal is to discover a new way of extract information from news articles of Chinese media and construct a model for examining the corporate transparency for the listed company in Chinese stock market.  % We first used Latent Dirichlet Allocation and THU Open Chinese Lexicon from Tsinghua University to classify topics in articles which are potentially related to corporate transparency. Then, with the keywords related to each topics, we designed and trained a supervised neural network with validation data from surveys of fund manager and accountant閳ユ獨 opinion on corporate transparency.  % After finished training the neural network and articles, we classified all of the 3065 companies and ranked them based on the level of transparency we determined through the neural network.   % 
 Speech classifiers of paralinguistic traits traditionally learn from diverse hand-crafted low-level features, by selecting the relevant information for the task at hand. We explore an alternative to this selection, by learning jointly the classifier, and the feature extraction. Recent work on speech recognition has shown improved performance over speech features by learning from the waveform. We  extend this approach to paralinguistic classification and propose a neural network that can learn a filterbank, a normalization factor and a compression power from the raw speech, jointly with the rest of the architecture. We apply this model to dysarthria detection from sentence-level audio recordings. Starting from a strong attention-based baseline on which mel-filterbanks outperform standard low-level descriptors, we show that learning the filters or the normalization and compression improves over fixed features by $10\%$ absolute accuracy. We also observe a gain over OpenSmile features by learning jointly the feature extraction, the normalization, and the compression factor with the architecture. This constitutes a first attempt at learning jointly all these operations from raw audio for a speech classification task. 
 The cryptocurrency is attracting more and more attention because of the blockchain technology. Ethereum is gaining a significant popularity in blockchain community, mainly due to the fact that it is designed in a way that enables developers to write smart contracts and decentralized applications . There are many kinds of cryptocurrency information on social network. The risks and fraud problems behind it have pushed many countries including the United States, South Korea, and China to make warnings and set up corresponding regulations. However, the security of Ethereum smart contracts has not gained much attention. Through the Deep Learning approach, we propose a method of sentiment analysis for Ethereum's community comments.  In this research, we first collected the users閳 cryptocurrency comments from the social network and then fed to our LSTM + CNN model for training. Then we made prediction through sentiment analysis. With our research result, we have demonstrated that both the precision and the recall of sentiment analysis can achieve 0.80+. More importantly, we deploy our sentiment analysis\footnote{https://www.ratingtoken.net/sentiment/} on RatingToken and Coin Master . We can effectively provide the detail information to resolve the risks of being fake and fraud problems.    ethereum; social opinion, long short-term memory, convolutional neural network   
 A fundamental trade-off between effectiveness and efficiency needs to be balanced when designing an online question answering system. Effectiveness comes from sophisticated functions such as extractive machine reading comprehension , while efficiency is obtained from improvements in preliminary retrieval components such as candidate document selection and paragraph ranking. Given the complexity of the real-world multi-document MRC scenario, it is difficult to jointly optimize both in an end-to-end system. To address this problem, we develop a novel deep cascade learning model, which progressively evolves from the document-level and paragraph-level ranking of candidate texts to more precise answer extraction with machine reading comprehension. Specifically, irrelevant documents and paragraphs are first filtered out with simple functions for efficiency consideration. Then we jointly train three modules on the remaining texts for better tracking the answer: the document extraction,  the paragraph extraction and the answer extraction. Experiment results show that the proposed method outperforms the previous state-of-the-art methods on two large-scale multi-document benchmark datasets, i.e., TriviaQA and DuReader. In addition, our online system can stably serve typical scenarios with millions of daily requests in less than 50ms. 
 %Text mining of scientific libraries and social media has already proven itself as a reliable tool for drug repurposing and hypothesis generation.  The task of mapping a disease mention to a concept in a controlled vocabulary, typically to the standard thesaurus in the Unified Medical Language System , is known as medical concept normalization. This task is challenging due to the differences in medical terminology between health care professionals and social media texts coming from the lay public. To bridge this gap, we use sequence learning with recurrent neural networks and semantic representation of one- or multi-word expressions: we develop end-to-end neural architectures directly tailored to the task, including bidirectional LSTM and GRU with an attention mechanism and additional semantic similarity features based on UMLS. Our evaluation over a standard benchmark shows that our model improve results over an effective baseline for classification based on CNNs. %A qualitative examination of mentions discovered in a dataset of user reviews collected from popular online health information platforms as well as quantitative evaluation both show improvements in semantic representation of health-related expressions in social media. 
 This paper describes a novel hierarchical attention network for reading comprehension style question answering, which aims to answer questions for a given narrative paragraph. In the proposed method, attention and fusion are conducted horizontally and vertically across layers at different levels of granularity between question and paragraph. Specifically, it first encode the question and paragraph with fine-grained language embeddings, to better capture the respective representations at semantic level. Then it proposes a multi-granularity fusion approach to fully fuse information from both global and attended representations. Finally, it introduces a hierarchical attention network to focuses on the answer span progressively with multi-level soft-alignment. Extensive experiments on the large-scale SQuAD and TriviaQA datasets validate the effectiveness of the proposed method. At the time of writing the paper , our model achieves the first position on the SQuAD leaderboard for both single and ensemble models. We also achieves state-of-the-art results on TriviaQA, AddSent and AddOneSent datasets. 
 Neural network-based dialog models often lack robustness to anomalous, out-of-domain  user input which leads to unexpected dialog behavior and thus considerably limits such models' usage in mission-critical production environments. The problem is especially relevant in the setting of dialog system bootstrapping with limited training data and no access to OOD examples. In this paper, we explore the problem of robustness of such systems to anomalous input and the associated to it trade-off in accuracies on seen and unseen data. We present a new dataset for studying the robustness of dialog systems to OOD input, which is bAbI Dialog Task 6 augmented with OOD content in a controlled way. We then present turn dropout, a simple  yet efficient negative sampling-based technique for improving robustness of neural dialog models. We demonstrate its effectiveness applied to Hybrid Code Network-family models  which reach state-of-the-art results on our OOD-augmented dataset as well as the original one. Specifically, an HCN trained with turn dropout achieves state-of-the-art performance of more than 75\% per-utterance accuracy on the augmented dataset's OOD turns and 74\% F1-score as an OOD detector. Furthermore, we introduce a Variational HCN enhanced with turn dropout which achieves more than 56.5\% accuracy on the original bAbI Task 6 dataset, thus outperforming the initially reported HCN's result. 
 In semantic parsing for question-answering, it is often too expensive to collect gold parses or even gold answers as supervision signals. We propose to convert model outputs into a set of human-understandable statements which allow non-expert users to act as proofreaders, providing error markings as learning signals to the parser. Because model outputs were suggested by a historic system, we operate in a counterfactual, or off-policy, learning setup. We introduce new estimators which can effectively leverage the given feedback and which avoid known degeneracies in counterfactual learning, while still being applicable to stochastic gradient optimization for neural semantic parsing. Furthermore, we discuss how our feedback collection method can be seamlessly integrated into deployed virtual personal assistants that embed a semantic parser. Our work is the first to show that semantic parsers can be improved significantly by counterfactual learning from logged human feedback data.\footnote{Parts of the work in this paper have been previously published in the Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics  .}  
 The recent advances of deep learning in both computer vision  and natural language processing  provide us a new way of understanding semantics, by which we can deal with more challenging tasks such as automatic description generation from natural images. In this challenge, the encoder-decoder framework has achieved promising performance when a convolutional neural network  is used as image encoder and a recurrent neural network  as decoder. In this paper, we introduce a sequential guiding network that guides the decoder during word generation. The new model is an extension of the encoder-decoder framework with attention that has an additional guiding long short-term memory  and can be trained in an end-to-end manner by using image/descriptions pairs.  We validate our approach by conducting extensive experiments on a benchmark dataset, i.e., MS COCO Captions. The proposed model achieves significant improvement comparing to the other state-of-the-art deep learning models.  
 Most neural Information Retrieval  models derive query-to-document ranking scores based on term-level matching. Inspired by TileBars, a classical term distribution visualization method, in this paper, we propose a novel Neu-IR model that handles query-to-document matching at the subtopic and higher levels. Our system first splits the documents into topical segments, ``visualizes" the matchings between the query and the segments, and then feeds an interaction matrix into a Neu-IR model, DeepTileBars, to obtain the final ranking scores. DeepTileBars models the relevance signals occurring at different granularities in a document's topic hierarchy. It better captures the discourse structure of a document and thus the matching patterns. Although its design and implementation are light-weight, DeepTileBars outperforms other state-of-the-art Neu-IR models on benchmark datasets including the Text REtrieval Conference  2010-2012 Web Tracks and LETOR 4.0.   
 Recently, considerable research effort has been devoted to developing deep architectures for topic models to learn topic structures. Although several deep models have been proposed  to learn better topic proportions of documents, how to leverage the benefits of deep structures for learning word distributions of topics has not yet been rigorously studied. Here we propose a new multi-layer generative process on word distributions of topics, where each layer consists of a set of topics and each topic is drawn from a mixture of the topics of the layer above. As the topics in all layers can be directly interpreted by words, the proposed model is able to discover interpretable topic hierarchies. As a self-contained module, our model can be flexibly adapted to different kinds of topic models to improve their modelling accuracy and interpretability. Extensive experiments on text corpora demonstrate the advantages of the proposed model.  
 We propose in this paper a combined model of Long Short Term Memory and Convolutional Neural Networks   that exploits word embeddings and positional embeddings for cross-sentence $n$-ary relation extraction. The proposed model brings together the properties of both lstms and cnns, to simultaneously exploit long-range sequential information and capture most informative features, essential for cross-sentence $n$-ary relation extraction. The  lstm\_cnn model is evaluated on standard dataset on cross-sentence $n$-ary relation extraction, where it significantly outperforms baselines such as cnns, lstms and also a combined cnn\_lstm model. The paper also shows that the lstm\_cnn model outperforms the current state-of-the-art methods on cross-sentence $n$-ary relation extraction.    % and yield comparable performances on a standard intra-sentence relation extraction benchmark.   % \DB{I am not sure whether we need to highlight the last point about intra-sentence relation extraction in the abstract. The readers will wonder why we say this because our task was cross-sentence. Besides it has a bit of an anticlimax because we are not outperforming SOTA for intra-sentence, which we never plan/claim to do so anyway in this paper. We can still say this in the paper of course.}  
 Recently several deep learning based  models have been proposed for end-to-end learning of dialogs. While these models can be trained from data without the need for any additional annotations, it is hard to interpret them. On the other hand, there exist traditional state based dialog systems, where the states of the dialog are discrete and hence easy to interpret. However these states need to be handcrafted and annotated in the data. To achieve the best of both worlds, we propose Latent State Tracking Network  using which we learn an interpretable model in unsupervised manner. The model defines a discrete latent variable at each turn of the conversation which can take a finite set of values.  Since these discrete variables are not present in the training data, we use EM algorithm to train our model in unsupervised manner. In the experiments, we show that LSTN can help achieve interpretability in dialog models without much decrease in performance compared to end-to-end approaches. 
 Conditional random fields  have been shown to be one of the most successful approaches to sequence labeling. Various linear-chain neural CRFs  are developed to implement the non-linear node potentials in CRFs, but still keeping the linear-chain hidden structure. In this paper, we propose NCRF transducers, which consists of two RNNs, one extracting features from observations and the other capturing  long-range dependencies between labels. Different sequence labeling methods are evaluated over POS tagging, chunking and NER . Experiment results show that NCRF transducers achieve consistent improvements over linear-chain NCRFs and RNN transducers across all the four tasks, and can improve state-of-the-art results.  
  Summarization of long sequences into a concise statement is a core problem  in natural language processing, requiring non-trivial understanding of the  input.  Based on the promising results of graph neural networks on highly structured  data, we develop a framework to extend existing sequence encoders with a  graph component that can reason about long-distance relationships in  weakly structured data such as text.  In an extensive evaluation, we show that the resulting hybrid sequence-graph  models outperform both pure sequence models as well as pure graph models on a  range of summarization tasks. 
  	There is an increasing need for more automated system-log analysis tools for large scale online system in a timely manner.  	However, conventional way to monitor and classify the log output based on keyword list does not scale well for complex system in which codes contributed by a large group of developers, with diverse ways of encoding the error messages, often with misleading pre-set labels.  	In this paper, we propose that the design of a large scale online log analysis should follow the ``Least Prior Knowledge Principle'', in which unsupervised or semi-supervised solution with the minimal prior knowledge of the log should be encoded directly.  	Thereby, we report our experience in designing a two-stage machine learning based method, in which the system logs are regarded as the output of a { Log Analysis, Language Model, Machine Learning  
 Deep autoregressive sequence-to-sequence models have demonstrated impressive performance across a wide variety of tasks in recent years. While common architecture classes such as recurrent, convolutional, and self-attention networks make different trade-offs between the amount of computation needed per layer and the length of the critical path at training time, generation still remains an inherently sequential process. To overcome this limitation, we propose a novel blockwise parallel decoding scheme in which we make predictions for multiple time steps in parallel then back off to the longest prefix validated by a scoring model. This allows for substantial theoretical improvements in generation speed when applied to architectures that can process output sequences in parallel. We verify our approach empirically through a series of experiments using state-of-the-art self-attention models for machine translation and image super-resolution, achieving iteration reductions of up to 2x over a baseline greedy decoder with no loss in quality, or up to 7x in exchange for a slight decrease in performance. In terms of wall-clock time, our fastest models exhibit real-time speedups of up to 4x over standard greedy decoding. 
 Query expansion is a method for alleviating the vocabulary mismatch problem present in information retrieval tasks. Previous works have shown that terms selected for query expansion by traditional methods such as pseudo-relevance feedback are not always helpful to the retrieval process. In this paper, we show that this is also true for more recently proposed embedding-based query expansion methods. We then introduce an artificial neural network classifier to predict the usefulness of query expansion terms. This classifier uses term word embeddings as inputs. We perform experiments on four TREC newswire and web collections show that using terms selected by the classifier for expansion significantly improves retrieval performance when compared to competitive baselines. The results are also shown to be more robust than the baselines.  
  In this work, three lattice-free  discriminative training criteria for purely sequence-trained neural network acoustic models are compared on LVCSR tasks, namely maximum mutual information , boosted maximum mutual information  and state-level minimum Bayes risk . We demonstrate that, analogous to LF-MMI, a neural network acoustic model can also be trained from scratch using LF-bMMI or LF-sMBR criteria respectively without the need of cross-entropy pre-training. Furthermore, experimental results on Switchboard-300hrs and Switchboard+Fisher-2100hrs datasets show that models trained with LF-bMMI consistently outperform those trained with plain LF-MMI and achieve a relative word error rate  reduction of $\sim$5\% over competitive temporal convolution projected LSTM  LF-MMI baselines.                
  Knowledge graph embedding has been an active research topic for knowledge base completion, with progressive improvement from the initial {. {. The recent graph convolutional network  provides another way of learning graph node embedding by successfully utilizing graph connectivity structure. In this work, we propose a novel end-to-end Structure-Aware Convolutional Network  that takes the benefit of { together. {. {. The decoder { to be translational between entities and relations while keeps the same link prediction performance as { on standard FB15k-237 and WN18RR datasets, and it gives about 10\% relative improvement over the state-of-the-art ConvE in terms of HITS@1, HITS@3 and HITS@10.  
 Translating natural language to SQL queries for table-based question answering is a challenging problem and has received significant attention from the research community.  In this work, we extend a pointer-generator and investigate the order-matters problem in semantic parsing for SQL. Even though our model is a straightforward extension of a general-purpose pointer-generator, it outperforms early works for WikiSQL and remains competitive to concurrently introduced, more complex models. Moreover, we provide a deeper investigation of the potential order-matters problem that could arise due to having multiple correct decoding paths, and investigate the use of REINFORCE as well as a dynamic oracle in this context. \footnote{This is an updated version of our previous anonymous version  from May 2018.} 
 Language models, being at the heart of many NLP problems, are always of great interest to researchers. Neural language models come with the advantage of distributed representations and long range contexts. With its particular dynamics that allow the cycling of information within the network, `Recurrent neural network'  becomes an ideal paradigm for neural language modeling. Long Short-Term Memory  architecture solves the inadequacies of the standard RNN in modeling long-range contexts.  In spite of a plethora of RNN variants, possibility to add multiple memory cells in LSTM nodes was seldom explored. Here we propose a multi-cell node architecture for LSTMs and study its applicability for neural language modeling. The proposed multi-cell LSTM language models outperform the state-of-the-art results on well-known Penn Treebank  setup. 
 Anonymity forms an integral and important part of our digital life. It enables us to express our true selves without the fear of judgment. In this paper, we investigate the different aspects of anonymity in the social Q\&A site Quora. The choice of Quora is motivated by the fact that this is one of the rare social Q\&A sites that allow users to explicitly post anonymous questions and such activity in this forum has become normative rather than a taboo. Through an analysis of 5.1 million questions, we observe that at a global scale almost no difference manifests between the linguistic structure of the anonymous and the non-anonymous questions. We find that topical mixing at the global scale to be the primary reason for the absence. However, the differences start to feature once we ``deep dive'' and  cluster the questions and compare the clusters that have high volumes of anonymous questions with those that have low volumes of anonymous questions. In particular, we observe that the choice to post the question as anonymous is dependent on the user's perception of anonymity and they often choose to speak about depression, anxiety, social ties and personal issues under the guise of anonymity. We further perform personality trait analysis and observe that the anonymous group of users has positive correlation with extraversion, agreeableness, and negative correlation with openness.  Subsequently, to gain further insights, we build an anonymity grid to identify the differences in the perception on anonymity of the user posting the question and the community of users answering it. We also look into the first response time of the questions and observe that it is lowest for topics which talk about personal and sensitive issues, which hints toward a higher degree of community support and user engagement.  
 %		Code summarization provides a high level natural language description of the function performed by code, as it can benefit the software maintenance, code categorization and retrieval. To the best of our knowledge, most state-of-the-art approaches follow an encoder-decoder framework which encodes the code into a hidden space and then decode it into natural language space, suffering from two major drawbacks: a) their encoders only consider the sequential content of code, ignoring the tree structure which is also critical for the task of code summarization; b) their decoders are typically trained to predict the next word by maximizing the likelihood of next ground-truth word with previous ground-truth word given. However, it is expected to generate the entire sequence from scratch at test time. This discrepancy can cause an exposure bias issue, making the learnt decoder suboptimal. In this paper, we incorporate an abstract syntax tree structure as well as sequential content of code snippets into a deep reinforcement learning framework . The actor network provides the confidence of predicting the next word according to current state. On the other hand, the critic network evaluates the reward value of all possible extensions of the current state and can provide global and lookahead guidance for explorations. We employ an advantage reward composed of BLEU metric to train both networks. Comprehensive experiments on a real-world dataset show the effectiveness of our proposed model when compared with the state-of-the-art ones. Code summarization provides a high level natural language description of the function performed by code, as it can benefit the software maintenance, code categorization and retrieval. To the best of our knowledge, most state-of-the-art approaches follow an encoder-decoder framework which encodes the code into a hidden space and then decode it into natural language space, suffering from two major drawbacks: a) Their encoders only consider the sequential content of code, ignoring the tree structure which is also critical for the task of code summarization; b) Their decoders are typically trained to predict the next word by maximizing the likelihood of next ground-truth word with previous ground-truth word given. However, it is expected to generate the entire sequence from scratch at test time. This discrepancy can cause an exposure bias issue, making the learnt decoder suboptimal. In this paper, we incorporate an abstract syntax tree structure as well as sequential content of code snippets into a deep reinforcement learning framework . The actor network provides the confidence of predicting the next word according to current state. On the other hand, the critic network evaluates the reward value of all possible extensions of the current state and can provide global guidance for explorations. We employ an advantage reward composed of BLEU metric to train both networks. Comprehensive experiments on a real-world dataset show the effectiveness of our proposed model when compared with some state-of-the-art methods. 		%Code summarization provides a high level description of the function performed by code, as it can benefit the software maintenance, code categorization and retrieval.  		%%In order to provide high-quality summarization, many existing  		%Most state-of-the-art approaches follow an encoder-decoder framework, which encodes the code sequence into a hidden state, and generates word by maximizing the likelihood of next ground-truth word with previous ground-truth word given. These approaches are limited in two-fold: a) on encoding, they only consider the sequential content of code, ignoring the tree structure which is also critical for the task of code summarization; b) on decoding, they are teacher-forcing based and suffer from the exposure bias so that the learnt decoder is suboptimal. In this paper, we incorporate an abstract syntax tree structure as well as sequential content of code snippets into an actor-critic network learning framework. The actor network provides the confidence of predicting the next word according to current state. On the other hand, the critic network evaluates the reward value of all possible extentions of the current state and can provide global and lookahead guidance for explorations. We employ an advantage reward composed of BLEU metric to train both networks. Comprehensive experiments on a real-world dataset show the effectiveness of our proposed model when compared with the state-of-the-art ones. 		 	
     User emotion analysis toward videos is to automatically recognize the general emotional status of viewers from the multimedia content embedded in the online video stream.     Existing works fall in two categories:     1) visual-based methods, which focus on visual content and extract a specific set of features of videos.     However, it is generally hard to learn a mapping function from low-level video pixels to high-level emotion space due to great intra-class variance.     2) textual-based methods, which focus on the investigation of user-generated comments associated with videos. The learned word representations by traditional linguistic approaches typically lack emotion information and the global comments usually reflect viewers' high-level understandings rather than instantaneous emotions.     To address these limitations, in this paper, we propose to jointly utilize video content and user-generated texts simultaneously for emotion analysis.     In particular, we introduce exploiting a new type of user-generated texts, i.e., ``danmu'', which are real-time comments floating on the video and contain rich information to convey viewers' emotional opinions.     To enhance the emotion discriminativeness of words in textual feature extraction, we propose Emotional Word Embedding  to learn text representations by jointly considering their semantics and emotions.     Afterwards, we propose a novel visual-textual emotion analysis model with Deep Coupled Video and Danmu Neural networks , in which visual and textual features are synchronously extracted and fused to form a comprehensive representation by deep-canonically-correlated-autoencoder-based multi-view learning.     Through extensive experiments on a self-crawled real-world video-danmu dataset, we prove that DCVDN significantly outperforms the state-of-the-art baselines. 
  We explore the application of end-to-end stateless temporal modeling to small-footprint keyword spotting as opposed to recurrent networks that model long-term temporal dependencies using internal states. We propose a model inspired by the recent success of dilated convolutions in sequence modeling applications, allowing to train deeper architectures in resource-constrained configurations. Gated activations and residual connections are also added, following a similar configuration to WaveNet. In addition, we apply a custom target labeling  that back-propagates loss from specific frames of interest, therefore yielding higher accuracy and only requiring to detect the end of the keyword. Our experimental results show that our model outperforms a max-pooling loss trained recurrent neural network using LSTM cells, with a significant decrease in false rejection rate. The underlying dataset -- ``Hey Snips'' utterances recorded by over 2.2K different speakers --   has been made publicly available to establish an open reference for wake-word detection.   
 Behavioral skills or policies for autonomous agents are conventionally learned from reward functions, via reinforcement learning, or from demonstrations, via imitation learning. However, both modes of task specification have their disadvantages: reward functions require manual engineering, while demonstrations require a human expert to be able to actually perform the task in order to generate the demonstration. Instruction following from natural language instructions provides an appealing alternative: in the same way that we can specify goals to other humans simply by speaking or writing, we would like to be able to specify tasks for our machines. However, a single instruction may be insufficient to fully communicate our intent or, even if it is, may be insufficient for an autonomous agent to actually understand how to perform the desired task. In this work, we propose an interactive formulation of the task specification problem, where iterative language corrections are provided to an autonomous agent, guiding it in acquiring the desired skill. Our proposed language-guided policy learning algorithm can integrate an instruction and a sequence of corrections to acquire new skills very quickly. In our experiments, we show that this method can enable a policy to follow instructions and corrections for simulated navigation and manipulation tasks, substantially outperforming direct, non-interactive instruction following. 
  Humans are the final decision makers in  % critical tasks that involve ethical and legal concerns, ranging from recidivism prediction, to medical diagnosis, to fighting against fake news. Although machine learning models can  sometimes  achieve impressive performance in these tasks, these tasks are not amenable to full automation. % % % % % % To realize the potential of machine learning for improving human decisions,  % it is important to understand how % assistance from machine learning models affects human performance and human agency. %  In this paper, we use deception detection as a testbed and investigate how we can harness explanations and predictions of machine learning models to improve human performance while retaining human agency. % We propose a \spectrum between full human agency and full automation,  and  % develop varying levels of machine assistance along the \spectrum that gradually  % increase the influence of machine predictions. % % % We find that without showing predicted labels, explanations alone slightly improve human performance in the end task. In comparison, human performance is greatly improved by showing predicted labels  and can be further improved by explicitly suggesting strong machine performance. Interestingly, when predicted labels are shown, explanations of machine predictions  % induce a similar level of accuracy as an explicit statement of strong machine performance. % % Our results demonstrate a tradeoff between human performance and human agency and show that explanations of machine predictions can moderate this tradeoff. %   
   Many dialogue management frameworks allow the system designer to directly define belief rules to implement an efficient dialog policy. Because these rules are directly defined, the components are said to be hand-crafted. As dialogues become more complex, the number of states, transitions, and policy decisions becomes very large. To facilitate the dialog policy design process, we propose an approach to automatically learn belief rules using a supervised machine learning approach. We validate our ideas in Student-Advisor conversation domain, where we extract latent beliefs like student is curious, confused and neutral, etc. Further, we also perform epistemic reasoning that helps to tailor the dialog according to student's emotional state and hence improve the overall effectiveness of the dialog system. Our latent belief identification approach shows an accuracy of 87\% and this results in efficient and meaningful dialog management.   
 Unsupervised neural machine translation  has recently achieved remarkable results  with only large monolingual corpora in each language.  However, the uncertainty of associating target with source sentences makes UNMT theoretically an ill-posed problem.  This work investigates the possibility of utilizing images for disambiguation to improve the performance of UNMT.  Our assumption is intuitively based on the invariant property of image, i.e., the description of the same visual content by different languages should be approximately similar.  We propose an unsupervised multi-modal machine translation  framework based on the language translation cycle consistency loss conditional on the image, targeting to learn the bidirectional multi-modal translation simultaneously.  Through an alternate training between multi-modal and uni-modal, our inference model can translate with or without the image.  On the widely used Multi30K dataset, the experimental results of our approach are significantly better than those of the text-only UNMT on the 2016 test dataset.  
 In several natural language tasks, labeled sequences are available in separate domains , but the goal is to label sequences with mixed domain .  Or, we may have available models for labeling whole passages , which we would like to exploit toward better position-specific label inference .  A key characteristic shared across such tasks is that different positions in a primary instance can benefit from different `experts' trained from auxiliary data, but labeled primary instances are scarce, and labeling the best expert for each position entails unacceptable cognitive burden.  We propose ,  a unified position-sensitive multi-task recurrent neural network  architecture for such applications.  Auxiliary and primary tasks need not share training instances.  Auxiliary RNNs are trained over auxiliary instances.  A primary instance is also submitted to each auxiliary RNN, but their state sequences are gated and merged into a novel composite state sequence tailored to the primary inference task.  Our approach is in sharp contrast to recent multi-task networks like the cross-stitch and sluice network, which do not control state transfer at such fine granularity.  We demonstrate the superiority of   
 Recent years have witnessed the rising popularity of Natural Language Processing  and related fields such as Artificial Intelligence  and Machine Learning . Many online courses and resources are available even for those without a strong background in the field. Often the student is curious about a specific topic but does not quite know where to begin studying. To answer the question of \lq\lq what should one learn first,\rq\rq we apply an embedding-based method to learn prerequisite relations for course concepts in the domain of NLP. We introduce LectureBank, a dataset containing 1,352 English lecture files collected from university courses which are each classified according to an existing taxonomy as well as 208 manually-labeled prerequisite relation topics, which is publicly available \footnote{\url{https://github.com/Yale-LILY/LectureBank}}. The dataset will be useful for educational purposes such as lecture preparation and organization as well as applications such as reading list generation. Additionally, we experiment with neural graph-based networks and non-neural classifiers to learn these prerequisite relations from our dataset.  
 Biomedical association studies are increasingly done using clinical concepts, and in particular diagnostic codes from clinical data repositories as phenotypes. Clinical concepts can be represented in a meaningful, vector space using word embedding models. These embeddings allow for comparison between clinical concepts or for straightforward input to machine learning models. Using traditional approaches, good representations require high dimensionality, making downstream tasks such as visualization more difficult. We applied Poincar\'e embeddings in a 2-dimensional hyperbolic space to a large-scale administrative claims database and show performance comparable to 100-dimensional embeddings in a euclidean space. We then examine disease relationships under different disease contexts to better understand potential phenotypes. 
 Previous researches on acoustic word embeddings used in query-by-example spoken term detection have shown remarkable performance improvements when using a triplet network. However, the triplet network is trained using only a limited information about acoustic similarity between words. In this paper, we propose a novel architecture, phonetically associated triplet network , which aims at increasing discriminative power of acoustic word embeddings by utilizing phonetic information as well as word identity. The proposed model is learned to minimize a combined loss function that was made by introducing a cross entropy loss to the lower layer of LSTM-based triplet network. We observed that the proposed method performs significantly better than the baseline triplet network on a word discrimination task with the WSJ dataset resulting in over $20\%$ relative improvement in recall rate at $1.0$ false alarm per hour. Finally, we examined the generalization ability by conducting the out-of-domain test on the RM dataset.    
 Recent studies have shown that frame-level deep speaker features can be derived from a deep neural network with the training target set to discriminate speakers by a short speech segment. By pooling the frame-level features, utterance-level representations, called d-vectors, can be derived and used in the automatic speaker verification  task. This simple average pooling, however, is inherently sensitive to the phonetic content of the utterance. An interesting idea borrowed from machine translation is the attention-based mechanism, where the contribution of an input word to the translation at a particular time is weighted by an attention score. This score reflects the relevance of the input word and the present translation. We can use the same idea to align utterances with different phonetic contents.  This paper proposes a phonetic-attention scoring approach for d-vector systems. By this approach, an attention score is computed for each frame pair. This score reflects the similarity of the two frames in phonetic content, and is used to weigh the contribution of this frame pair in the utterance-based scoring. This new scoring approach emphasizes the frame pairs with similar phonetic contents, which essentially provides a soft alignment for utterances with any phonetic contents. Experimental results show that compared with the naive average pooling, this phonetic-attention scoring approach can deliver consistent performance improvement in ASV tasks of both text-dependent and text-independent.  
 Audio Sentiment Analysis is a popular research area which extends the conventional text-based sentiment analysis to depend on the effectiveness of acoustic features extracted from speech. However, current progress on audio sentiment analysis mainly focuses on extracting homogeneous acoustic features or doesn't fuse heterogeneous features effectively. In this paper, we propose an utterance-based deep neural network model, which has a parallel combination of Convolutional Neural Network  and Long Short-Term Memory  based network, to obtain representative features termed Audio Sentiment Vector , that can maximally reflect sentiment information in an audio. Specifically, our model is trained by utterance-level labels and ASV can be extracted and fused creatively from two branches. In the CNN model branch, spectrum graphs produced by signals are fed as inputs while in the LSTM model branch, inputs include spectral features and cepstrum coefficient extracted from dependent utterances in an audio. Besides, Bidirectional Long Short-Term Memory  with attention mechanism is used for feature fusion. Extensive experiments have been conducted to show our model can recognize audio sentiment precisely and quickly, and demonstrate our ASV are better than traditional acoustic features or vectors extracted from other deep learning models. Furthermore, experimental results indicate that the proposed model outperforms the state-of-the-art approach by 9.33\% on Multimodal Opinion-level Sentiment Intensity dataset  dataset. 
 Deep learning is currently playing a crucial role toward higher levels of artificial intelligence. This paradigm allows neural networks to learn complex and abstract representations, that are progressively obtained by combining simpler ones. Nevertheless, the internal "black-box" representations automatically discovered by current neural architectures often suffer from a lack of interpretability, making of primary interest the study of explainable machine learning techniques.  This paper summarizes our recent efforts to develop a more interpretable neural model for directly processing speech from the raw waveform. In particular, we propose SincNet, a novel Convolutional Neural Network  that encourages the first layer to discover more meaningful filters by exploiting parametrized sinc functions. In contrast to standard CNNs, which learn all the elements of each filter, only low and high cutoff frequencies of band-pass filters are directly learned from data. This inductive bias offers a very compact way to derive a customized filter-bank front-end, that only depends on some parameters with a clear physical meaning.  Our experiments, conducted on both speaker and speech recognition, show that the proposed architecture converges faster, performs better, and is more interpretable than standard CNNs.  
 Discourse structures are beneficial for various NLP tasks such as dialogue understanding, question answering, sentiment analysis, and so on. This paper presents a deep sequential model for parsing discourse dependency structures of multi-party dialogues. The proposed model aims to construct a discourse dependency tree by predicting dependency relations and constructing the discourse structure jointly and alternately. It makes a sequential scan of the \footnote{A discourse can be segmented into clause-level units called  which are the most fundamental discourse units in discourse parsing. Following previous work such as , we also assume that EDU segmentations are preprocessed.} in a dialogue. For each EDU, the model decides to which previous EDU the current one should link and what the corresponding relation type is. The predicted link and relation type are then used to build the discourse structure incrementally with a structured encoder. During link prediction and relation classification, the model utilizes not only local information that represents the concerned EDUs, but also global information that encodes the EDU sequence and the discourse structure that is already built at the current step. Experiments show that the proposed model outperforms all the state-of-the-art baselines.  
   The latency in the current neural based dialogue state tracking models prohibits them from being used efficiently for deployment in production systems, albeit their highly accurate performance.  This paper proposes a new scalable and accurate neural dialogue state tracking model, based on the recently proposed Global-Local Self-Attention encoder  model by~ which uses global modules to share parameters between estimators for different types  of dialogue states, and uses local modules to learn slot-specific features. By using only one recurrent networks with global conditioning, compared to  recurrent networks with global and local conditioning used in the GLAD model, our proposed model reduces the latency in training and inference times by $35\%$ on average, while preserving performance of belief state tracking, by $97.38\%$ on turn request and $88.51\%$ on joint goal and accuracy. Evaluation on Multi-domain dataset  also demonstrates that our model outperforms GLAD on turn inform and joint goal accuracy.   
 Zipf's law predicts a power-law relationship between word rank and frequency in language communication systems and has been widely reported in a variety of natural language processing applications. However, the emergence of natural language is often modeled as a function of bias between speaker and listener interests, which lacks a direct way of relating information-theoretic bias to Zipfian rank. A function of bias also serves as an unintuitive interpretation of the communicative effort exchanged between a speaker and a listener. We counter these shortcomings by proposing a novel integral transform and kernel for mapping communicative bias functions to corresponding word frequency-rank representations at any arbitrary phase transition point, resulting in a direct way to link communicative effort  to specific vocabulary used . We demonstrate the practical utility of our integral transform by showing how a change from bias to rank results in greater accuracy and performance at an image classification task for assigning word labels to images randomly subsampled from CIFAR10. We model this task as a reinforcement learning game between a speaker and listener and compare the relative impact of bias and Zipfian word rank on communicative performance  between the two agents.   % which provides no direct way of relating information-theoretic bias to Zipfian rank.  % Information-theoretic simulations have shown that language communication systems emerge at an abrupt phase transition in the fidelity of mappings between symbols and objects. The emergence of natural language is often modeled as a function of bias between speaker and listener interests, which provides no direct way of relating information-theoretic bias to Zipfian rank.   % Here we bridge information-theoretic methods with natural language processing techniques by proposing a novel integral transform and kernel for mapping communicative bias functions to corresponding word frequency-rank representations at any arbitrary phase transition point. We also conduct a reinforcement learning simulation supporting the preference of modeling communicative systems as a function of rank over a function of bias.  
  Text-based adventure games provide a platform on which to explore reinforcement learning in the context of a combinatorial action space, such as natural language. We present a deep reinforcement learning architecture that represents the game state as a knowledge graph which is learned during exploration. This graph is used to prune the action space, enabling more efficient exploration. The question of which action to take can be reduced to a question-answering task, a form of transfer learning that pre-trains certain parts of our architecture. %The question of which action to take can be reduced to a question-answering task that makes use of graph embeddings.  In experiments using the TextWorld framework, we show that our proposed technique can learn a control policy faster than baseline alternatives. We have also open-sourced our code at https://github.com/rajammanabrolu/KG-DQN.  
   In the past few years, neural abstractive text summarization with sequence-to-sequence  models have gained a lot of popularity. Many interesting techniques have been proposed to improve seq2seq models, making them capable of handling different challenges, such as saliency, fluency and human readability, and generate high-quality summaries. Generally speaking, most of these techniques differ in one of these three categories: network structure, parameter inference, and decoding/generation. There are also other concerns, such as efficiency and parallelism for training a model. In this paper, we provide a comprehensive literature survey on different seq2seq models for abstractive text summarization from the viewpoint of network structures, training strategies, and summary generation algorithms. Several models were first proposed for language modeling and generation tasks, such as machine translation, and later applied to abstractive text summarization. Hence, we also provide a brief review of these models. As part of this survey, we also develop an open source library, namely, Neural Abstractive Text Summarizer  toolkit, for the abstractive text summarization. An extensive set of experiments have been conducted on the widely used CNN/Daily Mail dataset to examine the effectiveness of several different neural network components. Finally, we benchmark two models implemented in NATS on the two recently released datasets, namely, Newsroom and Bytecup. 
 		End-to-end automatic speech recognition  commonly transcribes audio signals into sequences of characters while its performance is evaluated by measuring the word-error rate . This suggests that predicting sequences of words directly may be helpful instead. However, training with word-level supervision can be more difficult due to the sparsity of examples per label class. In this paper we analyze an end-to-end ASR model that combines a word-and-character representation in a multi-task learning  framework. We show that it improves on the WER and study how the word-level model can benefit from character-level supervision by analyzing the learned inductive preference bias of each model component empirically. We find that by adding character-level supervision, the MTL model interpolates between recognizing more frequent words  and shorter words . 	
 Answer selection and knowledge base question answering  are two important tasks of question answering  systems. Existing methods solve these two tasks separately, which requires large number of repetitive work and neglects the rich correlation information between tasks.  In this paper, we tackle answer selection and KBQA tasks simultaneously via multi-task learning , motivated by the following motivations. First, both answer selection and KBQA can be regarded as a ranking problem, with one at text-level while the other at knowledge-level. Second, these two tasks can benefit each other: answer selection can incorporate the external knowledge from knowledge base , while KBQA can be improved by learning contextual information from answer selection.  To fulfill the goal of jointly learning these two tasks, we propose a novel multi-task learning scheme that utilizes multi-view attention learned from various perspectives to enable these tasks to interact with each other as well as learn more comprehensive sentence representations.  The experiments conducted on several real-world datasets demonstrate the effectiveness of the proposed method, and the performance of answer selection and KBQA is improved. Also, the multi-view attention scheme is proved to be effective in assembling attentive information from different representational perspectives.  
 The task of answering natural language questions over knowledge bases has received wide attention in recent years. Various deep learning architectures have been proposed for this task. However, architectural design choices are typically not systematically compared nor evaluated under the same conditions. In this paper, we contribute to a better understanding of the impact of architectural design choices by evaluating four different architectures under the same conditions. We address the task of answering simple questions, consisting in predicting the subject and predicate of a triple given a question. In order to provide a fair comparison of different architectures, we evaluate them under the same strategy for inferring the subject, and compare different architectures for inferring the predicate. The architecture for inferring the subject is based on a standard LSTM model trained to recognize the span of the subject in the question and on a linking component that links the subject span to an entity in the knowledge base. The architectures for predicate inference are based on i) a standard softmax classifier ranging over all predicates as output, ii) a model that predicts a low-dimensional encoding of the property given entity representation and question, iii) a model that learns to score a pair of subject and predicate given the question as well as iv) a model based on the well-known FastText model. The comparison of architectures shows that FastText provides better results than other architectures.  
 The performance of adversarial dialogue generation models relies on the quality of the reward signal produced by the discriminator. The reward signal from a poor discriminator can be very sparse and unstable, which may lead the generator to fall into a local optimum or to produce nonsense replies. To alleviate the first problem, we first extend a recently proposed adversarial dialogue generation method to an adversarial imitation learning solution. Then, in the framework of adversarial inverse reinforcement learning, we propose a new reward model for dialogue generation that can provide a more accurate and precise reward signal for generator training. We evaluate the performance of the resulting model with automatic metrics and human evaluations in two annotation settings. Our experimental results demonstrate that our model can generate more high-quality responses and achieve higher overall performance than the state-of-the-art.  
 Conversational question answering  is a novel QA task that requires understanding of dialogue context. Different from traditional single-turn machine reading comprehension  tasks, CQA includes passage comprehension, coreference resolution, and contextual understanding. In this paper, we propose an innovated contextualized attention-based deep neural network, SDNet, to fuse context into traditional MRC models. Our model  leverages both inter-attention and self-attention to comprehend conversation context and extract relevant information from passage. Furthermore, we demonstrated a novel method to integrate the latest BERT contextual model. Empirical results show the effectiveness of our model, which sets the new state of the art result in CoQA leaderboard, outperforming the previous best model by 1.6\% $F_1$. Our ensemble model further improves the result by 2.7\% $F_1$. 
   Unsupervised word embeddings have become a popular approach of word representation in NLP tasks. However there are limitations to the semantics represented by unsupervised embeddings, and inadequate fine-tuning of embeddings can lead to suboptimal performance.  We propose a novel learning technique called Delta Embedding Learning, which can be applied to general NLP tasks to improve performance by optimized tuning of the word embeddings. A structured regularization is applied to the embeddings to ensure they are tuned in an incremental way. As a result, the tuned word embeddings become better word representations by absorbing semantic information from supervision without ``forgetting.'' We apply the method to various NLP tasks and see a consistent improvement in performance. Evaluation also confirms the tuned word embeddings have better semantic properties.   
   Machine translation  is an area of study in Natural Language processing which deals with the automatic translation of human language, from one language to another by the computer. Having a rich research history spanning nearly three decades, Machine translation is one of the most sought after area of research in the linguistics and computational community. In this paper, we investigate the models based on deep learning that have achieved substantial progress in recent years and becoming the prominent method in MT. We shall discuss the two main deep-learning based Machine Translation methods, one at component or domain level which leverages deep learning models to enhance the efficacy of Statistical Machine Translation  and end-to-end deep learning models in MT which uses neural networks to find correspondence between the source and target languages using the encoder-decoder architecture. We conclude this paper by providing a time line of the major research problems solved by the researchers and also provide a comprehensive overview of present areas of research in Neural Machine Translation. 
 In this paper, we introduce the Variational Autoencoder  to an end-to-end speech synthesis model, to learn the latent representation of speaking styles in an unsupervised manner. The style representation learned through VAE shows good properties such as disentangling, scaling, and combination, which makes it easy for style control. Style transfer can be achieved in this framework by first inferring style representation through the recognition network of VAE, then feeding it into TTS network to guide the style in synthesizing speech. To avoid Kullback-Leibler  divergence collapse in training, several techniques are adopted. %Evaluation result shows the good performance of the proposed method in style control and transfer. %Especially, the proposed model outperforms Global Style Token  model in preference tests on style transfer. Finally, the proposed model shows good performance of style control and outperforms Global Style Token  model in ABX preference tests on style transfer. 
 Distantly-supervised Relation Extraction  methods train an extractor by automatically aligning relation instances in a Knowledge Base  with unstructured text. In addition to relation instances, KBs often contain other relevant side information, such as aliases of relations . RE models usually ignore such readily available side information.  %Distantly-Supervised Relation Extraction  has been used to scale the task of extracting relational facts from plain text.  %Recently proposed neural models have automated feature extraction and have demonstrated promising performance on this task.  %Most of them employ CNN/RNN for automatically extracting features from text.  %Recent models, however, do not make full use of side information relevant for RE, which is readily available from various Knowledge Bases . %In this paper, we propose \method{}, a neural relation extraction method which utilizes additional supervision like entity type and relation alias information from KB for imposing soft constraints while predicting relations.  In this paper, we propose \method{}, a distantly-supervised neural relation extraction method which utilizes additional side information from KBs for improved relation extraction. It uses entity type and relation alias information for imposing soft constraints while predicting relations.  \method{} employs Graph Convolution Networks  to encode syntactic information from text and improves performance even when limited side information is available. % competitively even with scarce side information.  Through extensive experiments on benchmark datasets, we demonstrate \method{}'s effectiveness. We have made \method{}'s source code available to encourage reproducible research. 
  We formulate coherence modeling as a regression task and propose two novel methods to combine techniques from our setup with pairwise approaches. The first of our methods is a model that we call ``first-next,'' which operates similarly to selection sorting but conditions decision-making on information about already-sorted sentences. The second consists of a technique for adding context to regression-based models by concatenating sentence-level representations with an encoding of its corresponding out-of-order paragraph. This latter model achieves Kendall-tau distance and positional accuracy scores that match or exceed the current state-of-the-art on these metrics. Our results suggest that many of the gains that come from more complex, machine-translation inspired approaches can be achieved with simpler, more efficient models.  
 %Topic models are one of the most popular methods for learning representation of text. Most common approaches to topic modelling are probabilistic .   %In this paper,  We present Variational Aspect-based Latent Topic Allocation , a family of autoencoding topic models that learn aspect-based representations of reviews. VALTA defines a user-item encoder that maps bag-of-words vectors for combined reviews associated with each paired user and item onto structured embeddings, which in turn define per-aspect topic weights. We model individual reviews in a structured manner by inferring an aspect assignment for each sentence in a given review, where the per-aspect topic weights obtained by the user-item encoder serve to define a mixture over topics, conditioned on the aspect. The result is an autoencoding neural topic model for reviews, which can be trained in a fully unsupervised manner to learn topics that are structured into aspects. Experimental evaluation on large number of datasets demonstrates that aspects are interpretable, yield higher coherence scores than non-structured autoencoding topic model variants, and can be utilized to perform aspect-based comparison and genre discovery. 
 In recent years, Recurrent Neural Networks  based models have been applied to the Slot Filling problem of Spoken Language Understanding and achieved the state-of-the-art performances. In this paper, we investigate the effect of incorporating pre-trained language models into RNN based Slot Filling models. Our evaluation on the Airline Travel Information System  data corpus shows that we can significantly reduce the size of labeled training data and achieve the same level of Slot Filling performance by incorporating extra word embedding and language model embedding layers pre-trained on unlabeled corpora. 
 Extracting appropriate features to represent a corpus is an important task for textual mining. Previous attention based work usually enhance feature at the lexical level, which lacks the exploration of feature augmentation at the sentence level. In this paper, we exploit a Dynamic Feature Generation Network  to solve this problem. Specifically, DFGN generates features based on a variety of attention mechanisms and attaches features to sentence representation. Then a thresholder is designed to filter the mined features automatically. DFGN extracts the most significant characteristics from datasets to keep its practicability and robustness. Experimental results on multiple well-known answer selection datasets show that our proposed approach significantly outperforms state-of-the-art baselines. We give a detailed analysis of the experiments to illustrate why DFGN provides excellent retrieval and interpretative ability. %Extracting features that represent a particular corpus is important to the success of the answer selection task.In sentence dimension, features are firstly extracted by a variety of different attention mechanisms, then dynamically filtered by thresholds automatically learned. Different kinds of characteristics are distilled according to specific tasks, enhancing the practicability and robustness of the model. DFGN relies solely on the text itself, requires no external feature engineering. Our approach outperforms previous work on multiple well-known answer selection datasets. Through detailed analysis of the experiments, we prove that DFGN provides excellent retrieval and interpretative ability. 
     The embeddings of entities in a large knowledge base  are highly beneficial for solving various natural language tasks that involve real world knowledge.     In this paper, we present Wikipedia2Vec, a Python-based open-source tool for learning the embeddings of words and entities from Wikipedia.     The proposed tool enables users to learn the embeddings efficiently by issuing a single command with a Wikipedia dump file as an argument.     We also introduce a web-based demonstration of our tool that allows users to visualize and explore the learned embeddings.     In our experiments, our tool achieved a state-of-the-art result on the KORE entity relatedness dataset, and competitive results on various standard benchmark datasets.     Furthermore, our tool has been used as a key component in various recent studies.     We publicize the source code, demonstration, and the pretrained embeddings for 12 languages at \url{https://wikipedia2vec.github.io}. 
 Semantic Pattern Similarity is an interesting, though not often encountered NLP task where two sentences are compared not by their specific meaning, but by their more abstract semantic pattern . We utilize Siamese Networks to model this task, and show its usefulness in determining SQL patterns for unseen questions in a database-backed question answering scenario. Our approach achieves high accuracy and contains a built-in proxy for confidence, which can be used to keep precision arbitrarily high. 
  Current state-of-the-art speech recognition systems build on recurrent neural networks for acoustic and/or language modeling, and rely on feature extraction pipelines to extract mel-filterbanks or cepstral coefficients. In this paper we present an alternative approach based solely on convolutional neural networks, leveraging recent advances in acoustic models from the raw waveform and language modeling. This fully convolutional approach is trained end-to-end to predict characters from the raw waveform, removing the feature extraction step altogether. An external convolutional language model is used to decode words. On Wall Street Journal, our model matches the current state-of-the-art. On Librispeech, we report state-of-the-art performance among end-to-end models, including Deep Speech 2, that was trained with 12 times more acoustic data and significantly more linguistic data.  
 Mobile keyboard suggestion is typically regarded as a word-level language modeling problem. Centralized machine learning techniques require the collection of massive user data for training purposes, which may raise privacy concerns in relation to users' sensitive data.  Federated learning  provides a promising approach to learning private language modeling for intelligent personalized keyboard suggestions by training models on distributed clients rather than training them on a central server. To obtain a global model for prediction, existing FL algorithms simply average the client models and ignore the importance of each client during model aggregation. Furthermore, there is no optimization for learning a well-generalized global model on the central server.  To solve these problems, we propose a novel model aggregation with an attention mechanism considering the contribution of client models to the global model, together with an optimization technique during server aggregation.  Our proposed attentive aggregation method minimizes the weighted distance between the server model and client models by iteratively updating parameters while attending to the distance between the server model and client models. Experiments on two popular language modeling datasets and a social media dataset show that our proposed method outperforms its counterparts in terms of perplexity and communication cost in most settings of comparison.  
 Voice-enabled commercial products are ubiquitous, typically enabled by lightweight on-device keyword spotting  and full automatic speech recognition  in the cloud. ASR systems require significant computational resources in training and for inference, not to mention copious amounts of annotated speech data. KWS systems, on the other hand, are less resource-intensive but have limited capabilities. On the Comcast Xfinity X1 entertainment platform, we explore a middle ground between ASR and KWS: % for recognizing a few hundred voice commands. We introduce a novel, resource-efficient neural network for voice query recognition that is much more accurate than state-of-the-art CNNs for KWS, yet can be easily trained and deployed with limited resources. On an evaluation dataset representing the top 200 voice queries, we achieve a low false alarm rate of 1\%  and a query error rate of 6\%. Our model performs inference 8.24$\times$ faster than the current ASR system.  %Automatic speech recognition  systems are, of course, %a key component of such products, but they require significant computational resources at both  %training and inference time, not to mention copious amounts of annotated speech data. Keyword spotting % systems, on the other hand, use a fraction of the resources that ASR systems need; however, we demonstrate %that KWS is insufficient for full voice command recognition. On the Comcast Xfinity X1 entertainment  %platform, this motivates our exploration in the middle ground between ASR and  %KWS systems: a system for recognizing a few hundred voice commands. %We introduce a novel, resource-efficient neural network for voice query recognition on the X1.  %For the top-200 voice queries, which cover more than 35\% of our traffic, we achieve a  %low false alarm rate and query error rate of 1\% and 6\%,  %respectively. We perform inference 8.24 times faster than our third-party ASR system does. 
 Past years have witnessed rapid developments in Neural Machine Translation . Most recently, with advanced modeling and training techniques, the RNN-based NMT  has shown its potential strength, even compared with the well-known Transformer  model. Although the RNMT model can possess very deep architectures through stacking layers, the transition depth between consecutive hidden states along the sequential axis is still shallow. In this paper, we further enhance the RNN-based NMT through increasing the transition depth between consecutive hidden states and build a novel Deep Transition RNN-based Architecture for Neural Machine Translation, named DTMT. This model enhances the hidden-to-hidden transition with multiple non-linear transformations, as well as maintains a linear transformation path throughout this deep transition by the well-designed linear transformation mechanism to alleviate the gradient vanishing problem. Experiments show that with the specially designed deep transition modules, our DTMT can achieve remarkable improvements on translation quality. Experimental results on Chinese$\Rightarrow$English translation task show that DTMT can outperform the Transformer model by +2.09 BLEU points and achieve the best results ever reported in the same dataset. On WMT14 English$\Rightarrow$German and English$\Rightarrow$French translation tasks, DTMT\footnote{We release the source code at: https://github.com/fandongmeng/DTMT\_InDec} shows superior quality to the state-of-the-art NMT systems, including the Transformer and the RNMT+. 
   % Many neural network architectures have been proposed over the years. For the majority of them, two building blocks have dominated: Convolutions Neural Networks and Recurrent Neural Networks. Recently, the attention mechanism has been used to construct a new type of architecture that is doesn't contain CNN or RNN components. In this work, we compare the effectiveness of this new type of architecture with the old methods on the Sentiment Analysis task. We demonstrate that attention is a better building block for sentiment analysis models. The explored attention models in this paper perform better than RNNs and CNNs on 5 Sentiment Analysis datasets, all while using less memory and having less parameters.     %   Recently, new architectures have been created that utilize the attention mechanism as the basic building block.       Sentiment Analysis has seen much progress in the past two decades. For the past few years, neural network approaches, primarily RNNs and CNNs, have been the most successful for this task. Recently, a new category of neural networks, self-attention networks , have been created which utilizes the attention mechanism as the basic building block. Self-attention networks have been shown to be effective for sequence modeling tasks, while having no recurrence or convolutions. In this work we explore the effectiveness of the SANs for sentiment analysis. We demonstrate that SANs are superior in performance to their RNN and CNN counterparts by comparing their classification accuracy on six datasets as well as their model characteristics such as training speed and memory consumption. Finally, we explore the effects of various SAN modifications such as multi-head attention as well as two methods of incorporating sequence position information into SANs.       %   Finally, because the self-attention mechanism doesn't inherently model the relative or absolute position information of the input sequence, we compare the effectiveness of different techniques of incorporating such information into the models.       % We show that self-attention networks are better at capturing the meaning of longer sentences    
         Tokenization or segmentation is a wide concept that covers simple processes such as separating punctuation from words, or more sophisticated processes such as applying morphological knowledge.          Neural Machine Translation  requires a limited-size vocabulary for computational cost and enough examples to estimate word embeddings.         Separating punctuation and splitting tokens into words or subwords has proven to be helpful to reduce vocabulary and increase the number of examples of each word, improving the translation quality.          Tokenization is more challenging when dealing with languages with no separator between words. In order to assess the impact of the tokenization in the quality of the final translation on NMT, we experimented on five tokenizers over ten language pairs. We reached the conclusion that the tokenization significantly affects the final translation quality and that the best tokenizer differs for different language pairs.      
  The field of  has seen impressive progress in recent years, with neural network models replacing many of the traditional systems. A plethora of new models have been proposed, many of which are thought to be opaque compared to their feature-rich counterparts.   This has led researchers to analyze, interpret, and evaluate neural networks in novel and more fine-grained ways.   In this survey paper, we review analysis methods in neural language processing, categorize them according to prominent research trends, highlight existing limitations, and point to potential directions for future work.    
  A widespread approach to processing spoken language is to first automatically transcribe it into text. An alternative is to use an end-to-end approach: recent works have proposed to learn semantic embeddings of spoken language from images with spoken captions, without an intermediate transcription step. We propose to use multitask learning to exploit existing transcribed speech within the end-to-end setting. We describe a three-task architecture which combines the objectives of matching spoken captions with corresponding images, speech with text, and text with images. We show that the addition of the { task in isolation. We conjecture that this is due to a strong inductive bias transcribed speech provides to the model, and offer supporting evidence for this.  
 	 	%Despite the remarkable evolution of the deep neural networks, their interpretability remains a challenge. Recently, there have been several efforts to diagnose what these models learn at the representation level. Here we dive deeper to achieve a better understanding at the neuron level. %of what the individual neurons learn about different aspects of the language.  	%To this end we propose two dissection techniques based on supervised and unsupervised methods. In the former we use sequence labeling tasks such morphological or semantic tagging to analyze if individual neurons learn such linguistic phenomenon, and how distributed this information is. Secondly we develop an unsupervised method to discover important neurons in the neural network model and show experimentally that the model quality depends on the discovered neurons. We carry out our analysis and report our findings on the tasks of language modeling and neural machine translation. Our results show that ... 	 	%Despite the remarkable evolution of the deep neural networks, their interpretability remains a challenge. There have been several efforts to diagnose what these models learn at the representation level. In this work, we dive deeper into a fine-grained analysis of a network at the level of individual neurons. We propose a supervised and an unsupervised  	%method to dissect a neural model. The former aims at searching neurons responsible with respect to specific property like a part-of-speech tag , a semantic category  or any phenomenon/sub-task that is deemed important to the overall task that the network is learning. The unsupervised method discovers important neurons in a neural network model using correlations between neurons from different models trained on the same task. 	%with respect to the task it is trained on. %We probe into the model by visualizing selected neurons and find examples of human interpretable individual neurons responsible for particular properties. \alert{I think this last sentence is an unnecessary detail at this point} 	% 	%We %support  	%evaluate the effectiveness of our techniques by ablating the identified neurons and reevaluating network's performance. Our results show that decimating important neurons cause a significant deterioration in network's performance compared to ablating the same number of least important/random neurons.  	 	%top vs. least selected neurons in the network. 	 	%Despite the remarkable evolution of the deep neural networks, their interpretability remains a challenge. In this paper, we present an unsupervised and a supervised methods to dissect neural models in order to achieve a better understanding of what the individual neurons learn and know about the language. Our unsupervised method identifies most important neurons in a model and facilitates analysis at neuron level. On the other hand, with supervision we capture neurons with respect to any specific task in-hand, such as, semantic tagging. Both of our methods work independent of the architecture used to build the neural models. We conduct a thorough analysis on the correctness of our methods on a neural machine translation architecture and on neural language model architecture. 	 Despite the remarkable evolution %and the success  of deep neural networks in %the field of  natural language processing ,  their interpretability remains a challenge. %There have been several efforts to diagnose  Previous work largely focused on what these models learn at the representation level. %In this work,  We break this analysis down further  and study individual dimensions  in the vector representation learned by end-to-end neural models in NLP tasks. We propose two methods: , based on a supervised method to extract the most relevant neurons with respect to an extrinsic task, and , an unsupervised method to extract salient neurons w.r.t. the model itself.  We evaluate the effectiveness of our techniques by ablating the identified neurons and reevaluating the network's performance for two tasks: neural machine translation  and neural language modeling . We further present a comprehensive analysis of neurons with the aim to address the following questions: i) how localized or distributed are different linguistic properties in the models? ii) are certain neurons exclusive to some properties and not others? iii) is the information more or less distributed in NMT vs.\ NLM? and iv) how important are the neurons identified through the linguistic correlation method to the overall task? Our code is publicly available\footnote{\url{https://github.com/fdalvi/NeuroX}} as part of the NeuroX toolkit . %This paper is a non-archived version of the paper published at AAAI .  	 
  We present a toolkit %that facilitates  to facilitate the interpretation and understanding of neural network models.   %by conducting a fine-grained neuron-level analysis.  The toolkit provides several %mechanisms  methods to identify salient neurons with respect to the model itself or an external task. A user can visualize selected neurons, ablate them to %see  measure their effect on the model accuracy, and manipulate them to control the behavior of the model at the test time. %The analysis provided by the toolkit  Such an analysis has a potential to serve as a springboard  %provoke research  in various research directions, such as understanding %the learning of  the model, better architectural choices, model distillation and controlling data biases. The toolkit is available for download.\footnote{\url{https://github.com/fdalvi/NeuroX}} %The neuron The toolkit is flexible to use with any neural model. However, we choose neural machine translation as a use case for demonstration purposes. 
 Named entity recognition  is the task to identify  mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc.  NER always serves as the foundation for many natural language applications such as question answering, text summarization, and machine translation. Early NER systems got a huge success in achieving good performance with the cost of human engineering in designing domain-specific features and rules.  In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area. 
 Being able to recognize words as slots and detect the intent of an utterance has been a keen issue in natural language understanding. The existing works either treat slot filling and intent detection separately in a pipeline manner, or adopt joint models which sequentially label slots while summarizing the utterance-level intent without explicitly preserving the hierarchical relationship among words, slots, and intents. To exploit the semantic hierarchy for effective modeling, we propose a capsule-based neural network model which accomplishes slot filling and intent detection via a dynamic routing-by-agreement schema. A re-routing schema is proposed to further synergize the slot filling performance using the inferred intent representation. Experiments on two real-world datasets show the effectiveness of our model when compared with other alternative model architectures, as well as existing natural language understanding services}. 
 In previous works, neural sequence models have been shown to improve significantly if external prior knowledge can be provided, for instance by allowing the model to access the embeddings of explicit features during both training and inference.  In this work, we propose a different point of view on how to incorporate prior knowledge in a principled way, using a  framework. In this approach, the standard local cross-entropy training of the  sequential model is combined with a  training mode that encourages the equality of the expectations of certain predefined features between the model distribution and the empirical distribution. In particular, we show how to derive unbiased estimates of some stochastic gradients that are central to the training, and compare our framework with a formally related one: policy gradient training in reinforcement learning, pointing out some important differences in terms of the kinds of prior assumptions in both approaches.  Our initial results are promising, showing the effectiveness of our proposed framework.  
  Neural machine translation  models generally adopt an encoder-decoder architecture for modeling the entire translation process.  The encoder summarizes the representation of input sentence from scratch, which is potentially a problem if the sentence is ambiguous. When translating a text, humans often create an initial understanding of the source sentence and then incrementally refine it along the translation on the target side. Starting from this intuition, we propose a novel encoder-refiner-decoder framework, which dynamically refines the source representations based on the generated target-side information at each decoding step. Since the refining operations are time-consuming, we propose a strategy, leveraging the power of reinforcement learning models, to decide when to refine at specific decoding steps. Experimental results on both Chinese--English and English--German translation tasks show that the proposed approach significantly and consistently improves translation performance over the standard encoder-decoder framework. Furthermore, when refining strategy is applied, results still show reasonable improvement over the baseline without much decrease in decoding speed. 
 In this paper, we investigate the feasibility of applying few-shot learning algorithms to a speech task. We formulate a user-defined scenario of spoken term classification as a few-shot learning problem. In most few-shot learning studies, it is assumed that all the $N$ classes are new in a $N$-way problem. We suggest that this assumption can be relaxed and define a $N$+$M$-way problem where $N$ and $M$ are the number of new classes and fixed classes respectively. We propose a modification to the Model-Agnostic Meta-Learning  algorithm to solve the problem. Experiments on the Google Speech Commands dataset show that our approach\footnote{Code is available at: \url{https://github.com/Codelegant92/STC-MAML-PyTorch}} outperforms the conventional supervised learning approach and the original MAML. 
  Recently hyperbolic geometry has proven to be effective in building embeddings that encode  	hierarchical and entailment information. This makes it particularly suited to modelling the complex  	asymmetrical relationships between Chinese characters and words. In this paper we first train a  	large scale hyperboloid skip-gram model on a Chinese corpus, then apply the character  	embeddings to a downstream hyperbolic Transformer model derived from the principles of  	gyrovector space for Poincare disk model. In our experiments the character-based Transformer  	outperformed its word-based Euclidean equivalent. To the best of our knowledge, this is the first  	time in Chinese NLP that a character-based model outperformed its word-based counterpart,  	allowing the circumvention of the challenging and domain-dependent task of Chinese Word  	Segmentation . 
 Aspect level sentiment classification is a fine-grained sentiment analysis task. To detect the sentiment towards a particular aspect in a sentence, previous studies have developed various attention-based methods for generating aspect-specific sentence representations. However, the attention may inherently introduce noise and downgrade the performance. In this paper, we propose constrained attention networks , a simple yet effective solution, to regularize the attention for multi-aspect sentiment analysis, which alleviates the drawback of the attention mechanism. Specifically, we introduce orthogonal regularization on multiple aspects and sparse regularization on each single aspect.  Experimental results on two public datasets demonstrate the effectiveness of our approach. We further extend our approach to multi-task settings and outperform the state-of-the-art methods. 
 Knowledge representation learning  aims to represent entities and relations in knowledge graph in low-dimensional semantic space, which have been widely used in massive knowledge-driven tasks. In this article, we introduce the reader to the motivations for KRL, and overview existing approaches for KRL. Afterwards, we extensively conduct and quantitative comparison and analysis of several typical KRL methods on three evaluation tasks of knowledge acquisition including knowledge graph completion, triple classification, and relation extraction. We also review the real-world applications of KRL, such as language modeling, question answering, information retrieval, and recommender systems. Finally, we discuss the remaining challenges and outlook the future directions for KRL. The codes and datasets  used in the experiments can be found in \url{https://github.com/thunlp/OpenKE}. 
   We propose a neural network model for joint extraction of named entities and relations between them, without any hand-crafted features. The key contribution of our model is to extend a  BiLSTM-CRF-based entity recognition model with a deep biaffine attention layer to model second-order interactions between latent features for relation classification, specifically attending to the role of an entity in a directional relationship.    On the benchmark ``relation and entity recognition"  dataset CoNLL04, experimental results show that our model outperforms previous models, producing new state-of-the-art performances.    
 We propose the {first} multi-task learning model for joint Vietnamese word segmentation, part-of-speech  tagging and dependency parsing. In particular, our model extends the BIST graph-based dependency parser  with BiLSTM-CRF-based neural layers  for word segmentation and POS tagging. On Vietnamese benchmark  datasets, experimental  results  show that our joint  model obtains state-of-the-art or competitive performances. 
 In order to bring artificial agents into our lives, we will need to go beyond supervised learning on closed datasets to having the ability to continuously expand knowledge. Inspired by a student learning in a classroom, we present an agent that can continuously learn by posing natural language questions to humans. Our agent is composed of three interacting modules, one that performs captioning, another that generates questions and a decision maker that learns when to ask questions by implicitly reasoning about the uncertainty of the agent and expertise of the teacher. As compared to current active learning methods which query images for full captions, our agent is able to ask pointed questions to improve the generated captions. The agent trains on the improved captions, expanding its knowledge. We show that our approach achieves better performance using less human supervision than the baselines on the challenging MSCOCO~ dataset. 
 Advances in Deep Reinforcement Learning have led to agents that perform well across a variety of sensory-motor domains. In this work, we study the setting in which an agent must learn to generate programs for diverse scenes conditioned on a given symbolic instruction. Final goals are specified to our agent via images of the scenes. A symbolic instruction consistent with the goal images is used as the conditioning input for our policies.  Since a single instruction corresponds to a diverse set of different but still consistent end-goal images, the agent needs to learn to generate a distribution over programs given an instruction.  We demonstrate that with simple changes to the reinforced adversarial learning  objective, we can learn instruction conditioned policies to achieve the corresponding diverse set of goals. Most importantly, our agent's stochastic policy is shown to more accurately capture the diversity in the goal distribution than a fixed pixel-based reward function baseline.  We demonstrate the efficacy of our approach on two domains:  drawing MNIST digits with a paint software conditioned on instructions and  constructing scenes in a 3D editor that satisfies a certain instruction.   
 Neural networks have recently become good at engaging in dialog. However, current approaches are based solely on verbal text, lacking the richness of a real face-to-face conversation. We propose a neural conversation model that aims to read and generate facial gestures alongside with text. This allows our model to adapt its response based on the ``mood'' of the conversation. In particular, we introduce an RNN encoder-decoder that exploits the movement of facial muscles, as well as the verbal conversation. The decoder consists of two layers, where the lower layer aims at generating the verbal response and coarse facial expressions, while the second layer fills in the subtle gestures, making the generated output more smooth and natural. We train our neural network by having it ``watch'' 250 movies. We showcase our joint face-text model in generating more natural conversations through automatic metrics and a human study. We demonstrate an example application with a face-to-face chatting avatar. {\url{http://www.cs.toronto.edu/face2face}}}} 
 Exploration of new superconductors still relies on the experience and intuition of experts, and is largely a process of experimental trial and error. In one study, only 3\% of the candidate materials showed superconductivity~. Here, we report the first deep learning model for finding new superconductors. We introduced the method named ``reading periodic table'' that represented the periodic table in a way that allows deep learning to learn to read the periodic table and to learn the law of elements for the purpose of discovering novel superconductors which are outside the training data. It is recognized that it is difficult for deep learning to predict something outside the training data. Although we used only the chemical composition of materials as information, we obtained an $R^{2}$ value of 0.92 for predicting $T_\text{c}$ for materials in a database of superconductors. We also introduced the method named ``garbage-in'' to create synthetic data of non-superconductors that do not exist. Non-superconductors are not reported, but the data must be required for deep learning to distinguish between superconductors and non-superconductors. We obtained three remarkable results. The deep learning can predict superconductivity for a material with a precision of 62\%, which shows the usefulness of the model; it found the recently discovered superconductor  and another one Nb_{0.2}V2Zr_{0.3}}, neither of which is in the superconductor database; and it found Fe-based high-temperature superconductors  from the training data before 2008. These results open the way for the discovery of new high-temperature superconductor families. The candidate materials list, data, and method are openly available from the {link}. 
 Transcribed datasets typically contain speaker identity for each instance in the data. We investigate two ways to incorporate this information during training:  and . In multi-task learning, the goal is speaker prediction; we expect a performance improvement with this joint training if the two tasks of speech recognition and speaker recognition share a common set of underlying features. In contrast, adversarial learning is a means to learn representations invariant to the speaker. We then expect better performance if this learnt invariance helps generalizing to new speakers. While the two approaches seem natural in the context of speech recognition, they are incompatible because they correspond to opposite gradients back-propagated to the model. In order to better understand the effect of these approaches in terms of error rates, we compare both strategies in controlled settings. Moreover, we explore the use of additional un-transcribed data in a semi-supervised, adversarial learning manner to improve error rates. Our results show that deep models trained on big datasets already develop invariant representations to speakers without any auxiliary loss. When considering adversarial learning and multi-task learning, the impact on the acoustic model seems minor. However, models trained in a semi-supervised manner can improve error-rates.  
 We describe a new approach that improves the training of generative adversarial nets  for synthesizing diverse images from a text input. Our approach is based on the conditional version of GANs and expands on previous work leveraging an auxiliary task in the discriminator. Our generated images are not limited to certain classes and do not suffer from mode collapse while semantically matching the text input. A key to our training methods is how to form positive and negative training examples with respect to the class label of a given image. Instead of selecting random training examples, we perform negative sampling based on the semantic distance from a positive example in the class. We evaluate our approach using the Oxford-102 flower dataset, adopting the inception score and multi-scale structural similarity index  metrics to assess discriminability and diversity of the generated images. The empirical results indicate greater diversity in the generated images, especially when we gradually select more negative training examples closer to a positive example in the semantic space.  
     State-of-the-art named entity recognition  systems have been improving continuously using neural architectures over the past several years.  However, many tasks, including NER, require large sets of annotated data to achieve such performance. In particular, we focus on NER from clinical notes, which is one of the most fundamental and critical problems for medical text analysis.  Our work centers on effectively adapting these neural architectures towards low-resource settings using parameter transfer methods. We complement a standard hierarchical NER model with a general transfer learning framework consisting of parameter sharing between the source and target tasks, and showcase scores significantly above the baseline architecture. These sharing schemes require an exponential search over tied parameter sets to generate the optimal configuration. To mitigate the problem of exhaustively searching for model optimization, we propose the Dynamic Transfer Networks , a gated architecture which learns the appropriate parameter sharing scheme between source and target datasets. DTN achieves the improvements of the optimized transfer learning framework with just a single training setting, effectively removing the need for exponential search.     %We show that in low resource environments, our transfer learning framework, once optimized for parameter sharing, produces scores significantly above the baseline architecture and further that our dynamic architecture achieves similar results with a single training setting. 
   Bayesian methods have been successfully applied to sparsify weights of neural networks and to remove structure units from the networks, e. g. neurons.    We apply and further develop this approach for gated recurrent architectures. Specifically, in addition to sparsification of individual weights and neurons, we propose to sparsify preactivations of gates and information flow in LSTM. It makes some gates and information flow components constant, speeds up forward pass and improves compression. Moreover, the resulting structure of gate sparsity is interpretable and depends on the task. 
 Network models have been increasingly used in the past years to support summarization and analysis of narratives, such as famous TV series, books and news. Inspired by social network analysis, most of these models focus on the characters at play. The network model well captures all characters interactions, giving a broad picture of the narration's content. A few works went beyond by introducing additional semantic elements, always captured in a single layer network. In contrast, we introduce in this work a multilayer network model to capture more elements of the narration of a movie from its script: people, locations, and other semantic elements. This model enables new measures and insights on movies. We demonstrate this model on two very popular movies.  
\raggedright Cause-and-effect reasoning, the attribution of effects to causes, is one of the most powerful and unique skills humans possess. % knowledge gap Multiple surveys are mapping out causal attributions as networks, but it is unclear how well these efforts can be combined.  Further, the total size of the collective causal attribution network held by humans is currently unknown, making it challenging to assess the progress of these surveys. % what we do Here we study three causal attribution networks to determine how well they can be combined into a single network. % Combining these networks requires dealing with ambiguous nodes, as nodes represent written descriptions of causes and effects and different descriptions may exist for the same concept. We introduce NetFUSES, a method for combining networks with ambiguous nodes. % Crucially, treating the different causal attributions networks as independent samples allows us to use their overlap to estimate the total size of the collective causal attribution network.  We find that existing surveys capture 5.77\% $\pm$ 0.781\% of the  $\approx$293\,000 causes and effects estimated to exist, and $0.198\% \pm 0.174\%$ of the  $\approx$10\,200\,000  attributed cause-effect relationships. 
 Progress in image captioning is gradually getting complex as researchers try to generalized the model and define the representation between visual features and natural language processing. This work tried to define such kind of relationship in the form of representation called Tensor Product Representation  which generalized the scheme of language modeling and structuring the linguistic attributes  which will provide a much better structure and grammatically correct sentence. TPR enables better and unique representation and structuring of the feature space and will enable better sentence composition from these representations. A large part of the different ways of defining and improving these TPR are discussed and their performance with respect to the traditional procedures and feature representations are evaluated for image captioning application. The new models achieved considerable improvement than the corresponding previous architectures.  
 There has been growing interest in using neural networks and deep learning techniques to create dialogue systems. Conversational recommendation is an interesting setting for the scientific exploration of dialogue with natural language as the associated discourse involves goal-driven dialogue that often transforms naturally into more free-form chat. This paper provides two contributions. First, until now there has been no publicly available large-scale dataset consisting of real-world dialogues centered around recommendations. % VM: are we absolutely sure there is not even a small-scale dataset? if there is a small one, we should write no publicly available LARGE-SCALE data set: Let's hedge, somewhere there might be one To address this issue and to facilitate our exploration here, we have collected {\sc ReDial}, a dataset consisting of over 10,000 conversations centered around the theme of providing movie recommendations. We make this data available to the community for further research. Second, we use this dataset to explore multiple facets of  conversational recommendations. In particular we explore new neural architectures, mechanisms, and methods suitable for composing conversational recommendation systems. Our dataset allows us to systematically probe model sub-components addressing different parts of the overall problem domain ranging from: sentiment analysis and cold-start recommendation generation to detailed aspects of how natural language is used in this setting in the real world. We combine such sub-components into a full-blown dialogue system and examine its behavior.   % %  
  The wide spread use of online recruitment services has led to information explosion in the job market. As a result, the recruiters  have to seek the intelligent ways for Person-Job Fit, which is the bridge for adapting the right job seekers to the right positions. Existing studies on Person-Job Fit have a focus on  measuring the matching degree between the talent qualification and the job requirements mainly based on the manual inspection of human resource experts despite of the subjective, incomplete, and inefficient nature of the human judgement. To this end, in this paper, we propose a novel end-to-end Ability-aware Person-Job Fit Neural Network  model, which has a goal of reducing the dependence on manual labour and can provide better interpretation about the fitting results. The key idea is to exploit the rich information available at abundant historical job application data. Specifically, we propose a word-level semantic representation for both job requirements and job seekers' experiences based on Recurrent Neural Network . Along this line, four hierarchical ability-aware attention strategies are designed to measure the different importance of job requirements for semantic representation, as well as measuring the different contribution of each job experience to a specific ability requirement. Finally, extensive experiments on a large-scale real-world data set clearly validate the effectiveness and interpretability of the APJFNN framework compared with several baselines.  %Since the fierce competition on recruitment has raised information explosion in job market, the Person-Job fit, as the bridge to connect employers and job seekers, has attracted wide attention. Usually, existing studies on Person-Job fit target at measuring the matching degree between the talent qualification and the job requirements, based on the labeling of human resources experts and complex feature engineering. However, they may suffer subjective and inefficient judgements, which lead to inadequate candidates and then disturb the recruitment process. To that end, in this paper, we propose a novel end-to-end Ability-aware Person-Job Fit Neural Network  model, which could reduce the dependence on artificial labeling and better explain the fitting results. To be specific, given the abundant historical job applications data, we first propose a word-level joint representation for both job requirements and job seeker experiences, based on Recurrent Neural Network . Along this line, two hierarchical ability-aware attention strategies are designed to measure the different importance of job requirements for semantic representation, as well as qualifying the different contribution of each experience to a specific ability requirement. Extensive experiments on a real-world data set clearly validate the effectiveness and interpretability of our APJFNN framework compared with several baselines, which prove the potential of our approach on the talent recruitment process.  
     Learning in environments with large state and action spaces, and sparse rewards, can hinder a Reinforcement Learning  agent's learning through trial-and-error. For instance, following natural language instructions on the Web  leads to RL settings where input vocabulary and number of actionable elements on a page can grow very large.     Even though recent approaches improve the success rate on relatively simple environments with the help of human demonstrations to guide the exploration, they still fail in environments where the set of possible instructions can reach millions.     We approach the aforementioned problems from a different perspective and propose guided RL approaches that can generate unbounded amount of experience for an agent to learn from.     Instead of learning from a complicated instruction with a large vocabulary, we decompose it into multiple sub-instructions and schedule a curriculum in which an agent is tasked with a gradually increasing subset of these relatively easier sub-instructions.     In addition, when the expert demonstrations are not available, we propose a novel meta-learning framework that generates new instruction following tasks and trains the agent more effectively.     We train DQN, deep reinforcement learning agent, with Q-value function approximated with a novel QWeb neural network architecture on these smaller, synthetic instructions.     We evaluate the ability of our agent to generalize to new instructions on World of Bits benchmark, on forms with up to 100 elements, supporting 14 million possible instructions. The QWeb agent outperforms the baseline without using any human demonstration achieving $100\%$ success rate on several difficult environments.           
 In this project, we worked on speech recognition, specifically predicting individual words based on both the video frames and audio~. Empowered by convolutional neural networks~, the recent speech recognition and lip reading models are comparable to human level performance~.  We re-implemented and made derivations of the state-of-the-art model presented in . Then, we conducted rich experiments including the effectiveness of attention mechanism~, more accurate residual network~ as the backbone with pre-trained weights and the sensitivity of our model with respect to audio input with/without noise.   
 As fas as we are aware, using sequence to sequence algorithms for query expansion has not been explored yet in Information Retrieval literature nor in Question-Answering's. We tried to fill this gap in the literature with a custom Query Expansion system trained and tested on open datasets. One specificity of our engine compared to classic ones is that it does not need the documents to expand the introduced query. We test our expansions on three different tasks : Information Retrieval, Answer preselection and Text classification. Our method yielded a slight improvement in performance in the three tasks .  
 In this paper, a new deep reinforcement learning based augmented general sequence tagging system is proposed. The new system contains two parts: a deep neural network  based sequence tagging model and a deep reinforcement learning  based augmented tagger. The augmented tagger helps improve system performance by modeling the data with minority tags. The new system is evaluated on SLU and NLU sequence tagging tasks using ATIS and CoNLL-2003 benchmark datasets, to demonstrate the new system's outstanding performance on general tagging tasks. Evaluated by F1 scores, it shows that the new system outperforms the current state-of-the-art model on ATIS dataset by 1.9 $\%$ and that on CoNLL-2003 dataset by 1.4 $\%$. 
 In this paper we present Meeting Bot, a reinforcement learning based conversational system that interacts with multiple users to schedule meetings. The system is able to interpret user utterences and map them to preferred time slots, which are then fed to a reinforcement learning  system with the goal of converging on an agreeable time slot. The RL system is able to adapt to user preferences and environmental changes in meeting arrival rate while still scheduling effectively. Learning is performed via policy gradient with exploration, by utilizing an MLP as an approximator of the policy function. Results demonstrate that the system outperforms standard scheduling algorithms in terms of overall scheduling efficiency. Additionally, the system is able to adapt its strategy to situations when users consistently reject or accept meetings in certain slots , or when the meeting is called by members who are at a more senior designation. 
 A capsule is a group of neurons, whose activity vector represents the instantiation parameters of a specific type of entity. In this paper, we explore the capsule networks used for relation extraction in a multi-instance multi-label learning framework and propose a novel neural approach based on   capsule networks with attention mechanisms. We evaluate our method with different benchmarks, and it is demonstrated that our method improves the precision of the predicted relations. Particularly, we show that capsule networks improve multiple entity pairs relation extraction\footnote{In this paper, multiple entity pairs relation extraction refers to multiple entity pairs  in a single sentence and  each pair of entities  contains only one relation label.}.   
 Deep text matching approaches have been widely studied for many applications including question answering and information retrieval systems. To deal with a domain that has insufficient labeled data, these approaches can be used in a Transfer Learning  setting to leverage labeled data from a resource-rich source domain. To achieve better performance, source domain data selection is essential in this process to prevent the ``negative transfer" problem. However, the emerging deep transfer models do not fit well with most existing data selection methods, because the data selection policy and the transfer learning model are not jointly trained, leading to sub-optimal training efficiency.  In this paper, we propose a novel reinforced data selector to select high-quality source domain data to help the TL model. Specifically, the data selector ``acts" on the source domain data to find a subset for optimization of the TL model, and the performance of the TL model can provide ``rewards" in turn to update the selector. We build the reinforced data selector based on the actor-critic framework and integrate it to a DNN based transfer learning model, resulting in a Reinforced Transfer Learning  method. We perform a thorough experimental evaluation on two major tasks for text matching, namely, paraphrase identification and natural language inference. Experimental results show the proposed RTL can significantly improve the performance of the TL model. We further investigate different settings of states, rewards, and policy optimization methods to examine the robustness of our method. Last, we conduct a case study on the selected data and find our method is able to select source domain data whose Wasserstein distance is close to the target domain data. This is reasonable and intuitive as such source domain data can provide more transferability power to the model.   %  %     %  %     
 Neural TTS has shown it can generate high quality synthesized speech. In this paper, we investigate the multi-speaker latent space to improve neural TTS for adapting the system to new speakers with only several minutes of speech or enhancing a premium voice by utilizing the data from other speakers for richer contextual coverage and better generalization. A multi-speaker neural TTS model is built with the embedded speaker information in both spectral and speaker latent space. The experimental results show that, with less than 5 minutes of training data from a new speaker, the new model can achieve an MOS score of 4.16 in naturalness and 4.64 in speaker similarity close to human recordings . For a well-trained premium voice, we can achieve an MOS score of 4.5 for out-of-domain texts, which is comparable to an MOS of 4.58 for professional recordings, and significantly outperforms single speaker result of 4.28.  
 Stock market volatility forecasting is a task relevant to assessing market risk. We investigate the interaction between news and prices for the one-day-ahead volatility prediction using state-of-the-art deep learning approaches. The proposed models are trained either end-to-end or using sentence encoders transfered from other tasks. We evaluate a broad range of stock market sectors, namely Consumer Staples, Energy, Utilities, Heathcare, and Financials. Our experimental results show that adding news improves the volatility forecasting as compared to the mainstream models that rely only on price data. In particular, our model outperforms the widely-recognized GARCH model for all sectors in terms of coefficient of determination $R^2$, $MSE$ and $MAE$, achieving the best performance when training from both news and price data. 
 Twitter has been a prominent social media platform for mining population-level health data and accurate clustering of health-related tweets into topics is important for extracting relevant health insights. In this work, we propose deep convolutional autoencoders for learning compact representations of health-related tweets, further to be employed in clustering. We compare our method to several conventional tweet representation methods including bag-of-words, term frequency-inverse document frequency, Latent Dirichlet Allocation and Non-negative Matrix Factorization with 3 different clustering algorithms. Our results show that the clustering performance using proposed representation learning scheme significantly outperforms that of conventional methods for all experiments of different number of clusters. In addition, we propose a constraint on the learned representations during the neural network training in order to further enhance the clustering performance. All in all, this study introduces utilization of deep neural network-based architectures, i.e., deep convolutional autoencoders, for learning informative representations of health-related tweets. 
 End-to-end neural models have made significant progress in question answering, however recent studies show that these models implicitly assume that the answer and evidence appear close together in a single document. In this work, we propose the~\modelname~, a new question answering model that combines information from evidence across multiple documents. The~\modelnameshort~consists of a coarse-grain module that interprets documents with respect to the query then finds a relevant answer, and a fine-grain module which scores each candidate answer by comparing its occurrences across all of the documents with the query. We design these modules using hierarchies of coattention and self-attention, which learn to emphasize different parts of the input. On the Qangaroo WikiHop multi-evidence question answering task, the~\modelnameshort~obtains a new~\sota~result of~\testacc~on the blind test set, outperforming the previous best by~\sotadiff~accuracy despite not using pretrained contextual encoders. 
 E-commerce has started a new trend in natural language processing through sentiment analysis of user-generated reviews. Different consumers have different concerns about various aspects of a specific product or service. Aspect category detection , as a subtask of aspect-based sentiment analysis, tackles the problem of categorizing a given review sentence into a set of pre-defined aspect categories. By nature, in this task, a given review sentence can belong to one or more categories. In recent years, the attention mechanism has brought revolutionary advances in multiple branches of natural language processing including sentiment analysis by attending to informative words or phrases in the text. However,  in multi-label classification tasks, such as ACD, given different labels, we need to attend on different parts of a given sentence, which is not addressed by the vanilla attention methods.  In this paper, we propose a deep neural network method based on attention mechanism to identify different aspect categories of a given review sentence by attending to various parts of the review sentence based on different topics, which are more fine-grained than aspects categories.  Experimental results on two datasets in the restaurant domain released by SemEval workshop demonstrates that our approach outperforms existing methods on both datasets. Visualization of the topic attention weights shows the effectiveness of our model in identifying words related to different topics. 
 When designing a neural caption generator, a convolutional neural network can be used to extract image features. Is it possible to also use a neural language model to extract sentence prefix features? We answer this question by trying different ways to transfer the recurrent neural network and embedding layer from a neural language model to an image caption generator. We find that image caption generators with transferred parameters perform better than those trained from scratch, even when simply pre-training them on the text of the same captions dataset it will later be trained on. We also find that the best language models  do not result in the best caption generators after transfer learning. 
 In this dissertation we report results of our research on dense distributed representations of text data. We propose two novel neural models for learning such representations. The first model learns representations at the document level, while the second model learns word-level representations.  For document-level representations we propose Binary Paragraph Vector: a neural network models for learning binary representations of text documents, which can be used for fast document retrieval. We provide a thorough evaluation of these models and demonstrate that they outperform the seminal method in the field in the information retrieval task. We also report strong results in transfer learning settings, where our models are trained on a generic text corpus and then used to infer codes for documents from a domain-specific dataset. Finally, we propose a model that jointly learns short binary codes and high-dimensional real-valued representations. This model can be used for rapid retrieval of documents highly relevant to the query. In contrast to previously proposed approaches, Binary Paragraph Vector models learn embeddings directly from raw text data. Thus far, the most common way of building binary document representations was to use a data-oblivious locality sensitive hashing method on top of some intermediate text representation.  For word-level representations we propose Disambiguated Skip-gram: a neural network model for learning multi-sense word embeddings. Representations learned by this model can be used in downstream tasks, like part-of-speech tagging or identification of semantic relations. In the word sense induction task Disambiguated Skip-gram outperforms state-of-the-art models on three out of four benchmarks datasets. Our model has an elegant probabilistic interpretation. Furthermore, unlike previous models of this kind, it is differentiable with respect to all its parameters and can be trained with backpropagation. Disambiguated Skip-gram is parametric, i.e. the number of word senses must be specified a priori. That said, we describe and evaluate a pruning strategy that discards word senses with low marginal probabilities. We also introduce a regularization term that influence the expected number of senses. In addition to quantitative results, we present qualitative evaluation of Disambiguated Skip-gram, including two-dimensional visualisations of selected word-sense embeddings.  The dissertation opens with a review of background works and closes with a summary of our contributions and a discussion of possible directions for future research. In the appendix we describe datasets and software libraries that were used to conduct the experiments, as well as works that were carried out for this dissertation but did not yield as strong results as the one described in the core chapters. 
   In this paper, we propose an interactive matching network  for the multi-turn response selection task. First, IMN constructs word representations from three aspects to address the challenge of out-of-vocabulary  words. Second, an attentive hierarchical recurrent encoder , which is capable of encoding sentences hierarchically and generating more descriptive representations by aggregating with an attention mechanism, is designed. Finally, the bidirectional interactions between whole multi-turn contexts and response candidates are calculated to derive the matching information between them. Experiments on four public datasets show that IMN outperforms the baseline models on all metrics, achieving a new state-of-the-art performance and demonstrating compatibility across domains for multi-turn response selection. 
   Natural Language Inference  is a fundamental and challenging task in Natural Language Processing . Most existing methods only apply one-pass inference process on a mixed matching feature, which is a concatenation of different matching features between a premise and a hypothesis.  In this paper, we propose a new model called Multi-turn Inference Matching Network  to perform multi-turn inference on different matching features.  In each turn, the model focuses on one particular matching feature instead of the mixed matching feature. To enhance the interaction between different matching features, a memory component is employed to store the history inference information. The inference of each turn is performed on the current matching feature and the memory. We conduct experiments on three different NLI datasets. The experimental results show that our model outperforms or achieves the state-of-the-art performance on all the three datasets.     
  This paper proposes a Distilled-Exposition Enhanced Matching Network  for story-cloze test, which is still a challenging task in story comprehension. We divide a complete story into three narrative segments: an exposition, a climax, and an ending. The model consists of three modules: input module, matching module, and distillation module. The input module provides semantic representations for the three segments and then feeds them into the other two modules. The matching module collects interaction features between the ending and the climax. The distillation module distills the crucial semantic information in the exposition and infuses it into the matching module in two different ways. We evaluate our single and ensemble model on ROCStories Corpus , achieving an accuracy of 80.1\% and 81.2\% on the test set respectively. The experimental results demonstrate that our DEMN model achieves a state-of-the-art performance.  %Our evaluation shows that DR-BiLSTM obtains the best single %model and ensemble model results achieving %the new state-of-the-art scores on the %Stanford NLI dataset.   % In this paper, we divide the story into a partial context, a climax and a ending and show that matching the ending with the climax can yields an pretty good performance by the accuracy of 77.4\% . We further show how to integrate the partial context to gain further promotion. In the aggregation process, we found that aggregate the matching sequence by multi-turns works better than single-turn.   %  achieves close to state-of-the-art performance on this task without any feature engineering. We also find that considering just the last sentence of the prompt instead of the whole prompt yields higher accuracy with our approach. 
 %The abstract should briefly summarize the contents of the paper in %15--250 words. \deleted{ Commonsense Reading Comprehension  is a significantly challenging task in  reading comprehension, with the goal of making a right choice from two answer candidates for the questions referring to a narrative passage that may require commonsense knowledge.  }  Commonsense Reading Comprehension  is a significantly challenging task, aiming at choosing the right answer for the question referring to a narrative passage, which may require commonsense knowledge inference. \deleted{the given narrative passage.}  %缁楊兛绔撮崣銉ㄧ樈閹簼绠炵悰銊ㄦ彧閹靛秷鍏橀崥灞炬閹绘劕鍩 choice, passage, commonsense knowledge  Most of the existing approaches only fuse the interaction information of choice, passage, and question in a simple combination manner from a  perspective, which lacks the comparison information on a deeper level.  Instead, we propose a Multi-Perspective Fusion Network , extending the single fusion method with multiple perspectives by introducing the  and  fusion\deleted{along with the }. More comprehensive and accurate information can be captured through the three types of fusion. We design several groups of experiments on MCScript dataset  to evaluate the effectiveness of the three types of fusion respectively. From the experimental results, we can conclude that the difference fusion is comparable with union fusion, and the similarity fusion needs to be activated by the union fusion. The experimental result also shows that our MPFN model achieves the state-of-the-art with an accuracy of 83.52\% on the official test set.    
 We develop a system for the FEVER fact extraction and verification challenge that uses a high precision entailment classifier based on transformer networks pretrained with language modeling, to classify a broad set of potential evidence.  The precision of the entailment classifier allows us to enhance recall by considering every statement from several articles to decide upon each claim.  We include not only the articles best matching the claim text by TFIDF score, but read additional articles whose titles match named entities and capitalized expressions occurring in the claim text.  The entailment module evaluates potential evidence one statement at a time, together with the title of the page the evidence came from . In preliminary evaluation, the system achieves .5736 FEVER score, .6108 label accuracy, and .6485 evidence F1 on the FEVER shared task test set. 
 Popular e-commerce websites such as Amazon offer community question answering systems for users to pose product-related questions and experienced customers may provide answers voluntarily. In this paper, we show that the large volume of existing community question answering data can be beneficial when building a system for answering questions related to product facts and specifications. Our experimental results demonstrate that the performance of a model for answering questions related to products listed in the Home Depot website can be improved by a large margin via a simple transfer learning technique from an existing large-scale Amazon community question answering dataset. Transfer learning can result in an increase of about 10\% in accuracy in the experimental setting where we restrict the size of the data of the target task used for training. As an application of this work, we integrate the best performing model trained in this work into a mobile-based shopping assistant and show its usefulness. 
 The noetic end-to-end response selection challenge as one track in Dialog System Technology Challenges 7  aims to push the state of the art of utterance classification for real world goal-oriented dialog systems, for which participants need to select the correct next utterances from a set of candidates for the multi-turn context. This paper describes our systems that are ranked the top on both datasets under this challenge, one focused and small  and the other more diverse and large . Previous state-of-the-art models use hierarchy-based  neural networks to explicitly model the interactions among different turns' utterances for context modeling. In this paper, we investigate a sequential matching model based only on chain sequence for multi-turn response selection. Our results demonstrate that the potentials of sequential matching approaches have not yet been fully exploited in the past for multi-turn response selection.  In addition to ranking the top in the challenge, the proposed model outperforms all previous models, including state-of-the-art hierarchy-based models, and achieves new state-of-the-art performances on two large-scale public multi-turn response selection benchmark datasets.  
 Activation functions play a crucial role in neural networks because they are the non-linearities which have been attributed to the success story of deep learning. One of the currently most popular activation functions is ReLU, but several competitors have recently been proposed or `discovered', including LReLU functions and  function. We also show that it can successfully replace the  and \mytanh{} gates in LSTM cells, leading to a 2 percentage point  improvement over the standard choices on a challenging NLP task.  
 We present \parabank, a large-scale English paraphrase dataset that surpasses prior work in both quantity and quality. Following the approach of \paranmt , we train a Czech-English neural machine translation  system to generate novel paraphrases of English reference sentences. By adding lexical constraints to the NMT decoding procedure, however, we are able to produce multiple high-quality sentential paraphrases per source sentence, yielding an English paraphrase resource with more than 4 billion generated tokens and exhibiting greater lexical diversity. Using human judgments, we also demonstrate that \parabank's paraphrases improve over \paranmt on both semantic similarity and fluency. Finally, we use \parabank to train a monolingual NMT model with the same support for lexically-constrained decoding for sentence rewriting tasks. 
 Question answering  is an important natural language processing  task and has received much attention in academic research and industry communities. Existing QA studies assume that questions are raised by humans and answers are generated by machines. Nevertheless, in many real applications, machines are also required to determine human needs or perceive human states. In such scenarios, machines may proactively raise questions and humans supply answers. Subsequently, machines should attempt to understand the true meaning of these answers. This new QA approach is called reverse-QA  throughout this paper. In this work, the human answer understanding problem is investigated and solved by classifying the answers into predefined answer-label categories . To explore the relationships between questions and answers, we use the interactive attention network  model and propose an improved structure called semi-interactive attention network . Two Chinese data sets for rQA are compiled. We evaluate several conventional text classification models for comparison, and experimental results indicate the promising performance of our proposed models.   
 People learn in fast and flexible ways that have not been emulated by machines. Once a person learns a new verb ``dax,'' he or she can effortlessly understand how to ``dax twice," ``walk and dax,'' or ``dax vigorously.'' There have been striking recent improvements in machine learning for natural language processing, yet the best algorithms require vast amounts of experience and struggle to generalize new concepts in compositional ways. To better understand these distinctively human abilities, we study the compositional skills of people through language-like instruction learning tasks. Our results show that people can learn and use novel functional concepts from very few examples , successfully applying familiar functions to novel inputs. People can also compose concepts in complex ways that go beyond the provided demonstrations. Two additional experiments examined the assumptions and inductive biases that people make when solving these tasks, revealing three biases: mutual exclusivity, one-to-one mappings, and iconic concatenation. We discuss the implications for cognitive modeling and the potential for building machines with more human-like language learning capabilities.  Keywords:  concept learning; compositionality; word learning; neural networks 
 End-to-end task-oriented dialogue is challenging since knowledge bases are usually large, dynamic and hard to incorporate into a learning framework. We propose the global-to-local memory pointer  networks to address this issue. In our model, a global memory encoder and a local memory decoder are proposed to share external knowledge. The encoder encodes dialogue history, modifies global contextual representation, and generates a global memory pointer. The decoder first generates a sketch response with unfilled slots. Next, it passes the global memory pointer to filter the external knowledge for relevant information, then instantiates the slots via the local memory pointers. We empirically show that our model can improve copy accuracy and mitigate the common out-of-vocabulary problem. As a result, GLMP is able to improve over the previous state-of-the-art models in both simulated bAbI Dialogue dataset and human-human Stanford Multi-domain Dialogue dataset on automatic and human evaluation. %without slot values TODO Such as @location -- knowing that sth isnt in it doesnt tell you at all what it is  % The former generates a global memory pointer that attends to multiple essential words at the sentence level, and based on the global memory weights, the latter learns a sequence of local memory pointers to copy one single word at each time step. We empirically show that our model can improve pointer effectiveness and mitigate the common out-of-vocabulary problem. As a result, GLMP is able to achieve state-of-the-art performance in both simulated and human-human dialogue datasets on automatic and human evaluation.  % Our model first generates delexicalized utterances with slot sentinels and then copies plain text from external memory to replace them. To strengthen the copy ability, global and local memory pointers are introduced. The former attends to multiple positions in the encoder for utterance-level copying, and the latter weighted by the global memory pointer focuses on copying one single word at each decoding time step.  % In addition, we empirically show that contextualized word representation can improve pointer effectiveness, which mitigates the common out-of-vocabulary problem.  % As a result, GLMP is able to achieve state-of-the-art performance on both the simulated and the human-human dialogue datasets for automatic and human evaluation.  % The former focuses on generating sentences without real entity values, which can be considered as a dialogue action generator; the latter learns to fill-in-the-blank by end-to-end memory networks. Unlike the existing approaches, where the attention is solely computed step-by-step during the decoding stage, we introduce the global memory pointers in the encoder to strengthen the copy ability. In addition, contextualized embeddings are utilized to further improve the memory representation and mitigate the common out-of-vocabulary problem in task-oriented conversation. As a result, we visualize and interpret our memory attention, and show that GLMP is able to achieve state-of-the-art performance on both the simulated and the human-human datasets. 
 The majority of conversations a dialogue agent sees over its lifetime occur after it has already been trained and deployed, leaving a vast store of potential training signal untapped. In this work, we propose the self-feeding chatbot, a dialogue agent with the ability to extract new training examples from the conversations it participates in. As our agent engages in conversation, it also estimates user satisfaction in its responses. When the conversation appears to be going well, the user's responses become new training examples to imitate. When the agent believes it has made a mistake, it asks for feedback; learning to predict the feedback that will be given improves the chatbot's dialogue abilities further. On the \personachat chit-chat dataset with over 131k training examples, we find that  learning from dialogue with a self-feeding chatbot significantly improves performance, regardless of the amount of % traditional supervision. 
 %  Sequence-to-sequence models are commonly trained via maximum likelihood estimation . However, standard MLE training considers a word-level objective, predicting the next word given the previous ground-truth partial sentence. This procedure focuses on modeling local syntactic patterns, and may fail to capture long-range semantic structure.  We present a novel solution to alleviate these issues.  Our approach imposes global sequence-level guidance via new supervision based on optimal transport, enabling the overall characterization and preservation of semantic features. We further show that this method can be understood as a Wasserstein gradient flow trying to match our model to the ground truth sequence distribution.  Extensive experiments are conducted to validate the utility of the proposed approach, showing consistent improvements over a wide variety of NLP tasks, including machine translation, abstractive text summarization, and image captioning. % 
  Document classification is a challenging task with important applications. The deep learning approaches to the problem have gained much attention recently. Despite the progress, the proposed models do not incorporate the knowledge of the document structure in the architecture efficiently and not take into account the contexting importance of words and sentences. In this paper, we propose a new approach based on a combination of convolutional neural networks, gated recurrent units, and attention mechanisms for document classification tasks. The main contribution of this work is the use of convolution layers to extract more meaningful, generalizable and abstract features by the hierarchical representation. The proposed method in this paper improves the results of the current attention-based approaches.    
 With  the  development  of  high  computational  devices, deep  neural  networks ,  in  recent  years,  have  gained  significant  popularity  in  many  Artificial  Intelligence    applications.   However, previous efforts have shown that DNNs were vulnerable to  strategically modified samples, named adversarial examples. These samples are  generated with some imperceptible perturbations, but can fool the DNNs to give false predictions.  % Inspired by the popularity of generating adversarial examples for image DNNs, research efforts on attacking DNNs for textual applications emerges in recent years. However,   existing perturbation methods for images cannot be directly applied to texts as  text data is discrete .  % In this article, we review research works that address this difference and generate textual adversarial examples on DNNs. We collect, select, summarize, discuss and analyze these works in a comprehensive way and cover all the related information to make the article self-contained. Finally, drawing on the reviewed literature, we provide further discussions and suggestions on this topic.  
 Chemical information extraction is to convert chemical knowledge in text into true chemical database, which is a text processing task heavily relying on chemical compound name identification and standardization. Once a systematic name for a chemical compound is given, it will naturally and much simply convert the name into the eventually required molecular formula. However, for many chemical substances, they have been shown in many other names besides their systematic names which poses a great challenge for this task. In this paper, we propose a framework to do the auto standardization from the non-systematic names to the corresponding systematic names by using the spelling error correction, byte pair encoding tokenization and neural sequence to sequence model. Our framework is trained end to end and is fully data-driven. Our standardization accuracy on the test dataset achieves 54.04\% which has a great improvement compared to previous state-of-the-art result. 
 %\boldmath Current state-of-the-art feature-engineered and end-to-end Automated Essay Score  methods are proven to be unable to detect adversarial samples, e.g. the essays composed of permuted sentences and the prompt-irrelevant essays.  Focusing on the problem, we develop a Two-Stage Learning Framework  which integrates the advantages of both feature-engineered and end-to-end AES methods.  % the first stage, we develop three end-to-end models to calculate the semantic scores, coherence scores, and prompt-relevant scores, in which coherence scores and prompt-relevant scores are utilized to detect the adversarial samples.   %In the second stage, we concatenate the three scores with some handcrafted features, and feed them to a boosting tree model for further training.  In experiments, we compare TSLF against a number of strong baselines, and the results demonstrate the effectiveness and robustness of our models.  TSLF surpasses all the baselines on five-eighths of prompts and achieves new state-of-the-art average performance when without negative samples.  After adding some adversarial eassys to the original datasets, TSLF outperforms the features-engineered and end-to-end baselines to a great extent, and shows great robustness. 
 The Chinese pronunciation system offers two characteristics that distinguish it from other languages: deep phonemic orthography and intonation variations. We are the first to argue that these two important properties can play a major role in Chinese sentiment analysis. Particularly, we propose two effective features to encode phonetic information. Next, we develop a Disambiguate Intonation for Sentiment Analysis  network using a reinforcement network. It functions as disambiguating intonations for each Chinese character . Thus, a precise phonetic representation of Chinese is learned. Furthermore, we also fuse phonetic features with textual and visual features in order to mimic the way humans read and understand Chinese text. Experimental results on five different Chinese sentiment analysis datasets show that the inclusion of phonetic features significantly and consistently improves the performance of textual and visual representations and outshines the state-of-the-art Chinese character level representations.  
   We introduce a new approach to generative data-driven dialogue systems  called TransferTransfo which is a combination of a Transfer learning based training scheme and a high-capacity Transfo-rmer model. Fine-tuning is performed by using a multi-task objective which combines several unsupervised prediction tasks. The resulting fine-tuned model shows strong improvements over the current state-of-the-art end-to-end conversational models like memory augmented seq2seq and information-retrieval models. On the privately held {\sc persona-chat} dataset of the Conversational Intelligence Challenge 2, this approach obtains a new state-of-the-art, respectively pushing the perplexity, Hits@1 and F1 metrics to $16.28$ , $80.7$  and $19.5$ . 
 \small\baselineskip=9pt  % 姘嶈兂鐏旈瀽鎰冲妧 entity闇 鑷у嫵妫 鐢忕摽鍕层偧 鏂兼棈绋栭爟姗傚 task闆 NLP 鏀靛嫵鏆瀽鎰冲妧 闈镐緜瀚婚爩 娆锋埄娈ч爟姗傚珶.  Classifying semantic relations between entity pairs in sentences is an important task in Natural Language Processing . % rc姣 闉欏嫶鏆 姣靛韩娼 闉濆嫶鍠岄灊渚呮緫 姘氣晣鐭旈湆銈屾絻 dependency parser, pos tagger 鏀撮附螠鐡 ner tool鐡 鑷ф瑬娼 NLP tools闉欒導顢℃數闊 闉忔贩鏌庢瓎闆 lexical feature闉 闉氭﹥銆堥灊渚呮緤闆. Most previous models for relation classification rely on the high-level lexical and syntatic features obtained by NLP tools such as WordNet, dependency parser, part-of-speech  tagger, and named entity recognizers . % 鐡村矄瀚熻嚙, attention based SOTA闆 鑷ч灈 鐡村姙鐖奸灊渚呮緫 feature闉氭顫呴渻 姘囶煄銈撮浕 entity 闉涙劤娉婇瀽 闆介爟 闉濇洡鐐掓 闉濇粖瀵戞惪 闋囨粚姣勯爟姗冾潊 闉庡﹫纰 闉涘牕瀚. In addition, state-of-the-art neural models based on attention mechanisms do not fully utilize information of entity that may be the most crucial features for relation classification. % 闉 闆茶導顑撻瀽鎰冲妧 闉栧崐螠闆 entity-aware attention mechanism鐡 latent entity typing 鏃崐鐭旂摽 闋冾煃绮 闈稿牕顢￠灃 End-to-END attention based recurrent neural architecture姣 闉濇粚鏅ラ爟婊婂珶. To address these issues, we propose a novel end-to-end recurrent neural model which incorporates an entity-aware attention mechanism with a latent entity typing  method. % 闉栧崐螠闉 姘囶煄宓忛灇 entity闉 鏀磋兂娼 latent type闉 闋堫煃鑷ｉ灊渚呮簜鎼 闋囨粚姣勯爟 鑲 闉庡嫴濯归湜, entity-aware attention闉 闉佹粔鐨濋爣鏃娿偧 闊辨穩鏆 闉 闋冩尗鍔冮灇 闇呮粖瀚. Our model not only utilizes entities and their latent types as features effectively but also is more interpretable by visualizing attention mechanisms applied to our model and results of LET.  % 鑷ч灈 闉欑娊鐛忛爟 relation classification task 娆 闋冩﹤鍊堕灇 SemEval-2010 dataset闉 闆介爟 闉併倣妫欓灇 闉栧崐螠 姘囶煄宓忛灇 SOTA姘ゆ帾瀚 闆 鑶﹀瀚熼浕 鐡村喒娼 姘ゆ尗妫虫闆. Experimental results on the SemEval-2010 Task 8, one of the most popular relation classification task, demonstrate that our model outperforms existing state-of-the-art models without any high-level features. 
   A character-level convolutional neural network  motivated by applications in ``automated machine learning''  is proposed to semantically classify columns in tabular data. Simulated data containing a set of base classes is first used to learn an initial set of weights. Hand-labeled data from the CKAN repository is then used in a transfer-learning paradigm to adapt the initial weights to a more sophisticated representation of the problem . In doing so, realistic data imperfections are learned and the set of classes handled can be expanded from the base set with reduced labeled data and computing power requirements. Results show the effectiveness and flexibility of this approach in three diverse domains: semantic classification of tabular data, age prediction from social media posts, and email spam classification. In addition to providing further evidence of the effectiveness of transfer learning in natural language processing , our experiments suggest that analyzing the semantic structure of language at the character level without additional metadata---i.e., network structure, headers, etc.---can produce competitive accuracy for type classification, spam classification, and social media age prediction. We present our open-source toolkit SIMON, an acronym for Semantic Inference for the Modeling of ONtologies, which implements this approach in a user-friendly and scalable/parallelizable fashion.   
  In the process of online storytelling, individual users create and consume highly diverse content that contains a great deal of implicit beliefs and not plainly expressed narrative. It is hard to manually detect these implicit beliefs, intentions and moral foundations of the writers.    We study and investigate two different tasks, each of which reflect the difficulty of detecting an implicit user's knowledge, intent or belief that may be based on writer's moral foundation: 1) political perspective detection in news articles  2) identification of informational vs. conversational questions in community question answering  archives and. In both tasks we first describe new interesting annotated datasets and make the datasets publicly available. Second, we compare various classification algorithms, and show the differences in their performance on both tasks. Third, in political perspective detection task we utilize a narrative representation language of local press to identify perspective differences between presumably neutral American and British press.    %We sought to exploit the inherent and natural order of words within the text, consisting of multiple sentences in order to train recursive neural networks  with long short-term memory , since LSTM can capture the long-term linguistic regularities of text. We face a challenge due to the limited amount of labeled data available for training the classifier. We are able to overcome this challenge and enhance identification performance by using two forms of unlabeled data  1) pre-trained word embeddings, and 2) applying big data to by label propagation.    
 		Multi-choice reading comprehension is a challenging task to select an answer from a set of candidates when given passage and question.  This work proposes dual co-matching network which models the relationship among passage, question and answer bidirectionally. The experimental results on RACE, ROCStories and COIN Shared Task 1 show that our model obtains state-of-the-art results and even the single model outperforms the human performance on RACE dataset. 	
 We propose a task to generate a complex sentence from a simple sentence in order to amplify various kinds of responses in the database. We first divide a complex sentence into a main clause and a subordinate clause to learn a generator model of modifiers, and then use the model to generate a modifier clause to create a complex sentence from a simple sentence. We present an automatic evaluation metric to estimate the quality of the models and show that a pipeline model outperforms an end-to-end model. 
 Self-attention is a useful mechanism to build generative models for language and images.  It determines the importance of context elements by comparing each element to the current time step. In this paper, we show that a very lightweight convolution can perform competitively to the best reported self-attention results. Next, we introduce dynamic convolutions which are simpler and more efficient than self-attention. We predict separate convolution kernels based solely on the current time-step in order to determine the importance of context elements.  The number of operations required by this approach scales linearly in the input length, whereas self-attention is quadratic. Experiments on large-scale machine translation, language modeling and abstractive summarization show that dynamic convolutions improve over strong self-attention models.  On the WMT'14 English-German test set dynamic convolutions achieve a new state of the art of 29.7 BLEU.\footnote{Code and pre-trained models available at \url{http://github.com/pytorch/fairseq}}  
 Modelling compositionality has been a longstanding area of research in the field of vector space semantics. The categorical approach to compositionality maps grammar onto vector spaces in a principled way, but comes under fire for requiring the formation of very high-dimensional matrices and tensors, and therefore being computationally infeasible. In this paper I show how a linear simplification of recursive neural tensor network models can be mapped directly onto the categorical approach, giving a way of computing the required matrices and tensors. This mapping suggests a number of lines of research for both categorical compositional vector space models of meaning and for recursive neural network models of compositionality. 
 Recent years has witnessed dramatic progress of neural machine translation , however, the method of manually guiding the translation procedure remains to be better explored. Previous works proposed to handle such problem through lexcially-constrained beam search in the decoding phase. Unfortunately, these lexically-constrained beam search methods suffer two fatal disadvantages: high computational complexity and hard beam search which generates unexpected translations. In this paper, we propose to learn the ability of lexically-constrained translation with external memory, which can overcome the above mentioned disadvantages. For the training process, automatically extracted phrase pairs are extracted from alignment and sentence parsing, then further be encoded into an external memory. This memory is then used to provide lexically-constrained information for training through a memory-attention machanism. Various experiments are conducted on WMT Chinese to English and English to German tasks.  All the results can demonstrate the effectiveness of our method.  
 % Problem Multi-layer models with multiple attention heads per layer provide superior translation quality compared to simpler and shallower models, but determining what source context is most relevant to each target word is more challenging as a result. Therefore, deriving high-accuracy word alignments from the activations of a state-of-the-art neural machine translation model is an open challenge. % Contribution 1 We propose a simple model extension to the Transformer architecture that makes use of its hidden representations and is restricted to attend solely on encoder information to predict the next word. It can be trained on bilingual data without word-alignment information. % Contributions 2  We further introduce a novel alignment inference procedure which applies stochastic gradient descent to directly optimize the attention activations towards a given target word. % Result The resulting alignments dramatically outperform the na\"ive approach to interpreting Transformer attention activations, and are comparable to Giza++ on two publicly available data sets.  
 Conversational agents have begun to rise both in the academic  and commercial  world. This paper investigates the task of building a non-goal driven conversational agent, using neural network generative models and analyzes how the conversation context is handled. It compares a simpler Encoder-Decoder with a Hierarchical Recurrent Encoder-Decoder architecture, which includes an additional module to model the context of the conversation using previous utterances information. We found that the hierarchical model was able to extract relevant context information and include them in the generation of the output. However, it performed worse  than the simple Encoder-Decoder model regarding both grammatically correct output and meaningful response. Despite these results, experiments demonstrate how conversations about similar topics appear close to each other in the context space due to the increased frequency of specific topic-related words, thus leaving promising directions for future research and how the context of a conversation can be exploited.
  Triangular, overlapping Mel-scaled filters  are the current standard input for acoustic models that exploit their input's time-frequency geometry, because they provide a psycho-acoustically motivated time-frequency geometry for a speech signal. F-bank coefficients are provably robust to small deformations in the scale. In this paper, we explore two ways in which filter banks can be adjusted for the purposes of speech recognition. First, triangular filters can be replaced with Gabor filters, a compactly supported filter that better localizes events in time, or Gammatone filters, a psychoacoustically-motivated filter. Second, by rearranging the order of operations in computing filter bank features, features can be integrated over smaller time scales while simultaneously providing better frequency resolution. We make all feature implementations available online through open-source repositories. Initial experimentation with a modern end-to-end CNN phone recognizer yielded no significant improvements to phone error rate due to either modification. The result, and its ramifications with respect to learned filter banks, is discussed.  
 The abstract is to be in fully-justified italicized text, at the top of the left-hand column as it is here, below the author information. Use the word 閳ユ穾bstract閳 as the title, in 12-point Times, boldface type, centered relative to the column, initially capitalized. The abstract is to be in 10-point, single-spaced type, and up to 150 words in length. Leave two blank lines after the abstract, and then begin the main text.   
  In this paper, we propose a feature reinforcement method under the sequence-to-sequence neural text-to-speech  synthesis framework. The proposed method utilizes the multiple input encoder to take three levels of text information, i.e., phoneme sequence, pre-trained word embedding, and grammatical structure of sentence from parser as the input feature for the neural TTS system. The added word and sentence level information can be viewed as the feature based pre-training strategy, which clearly enhance the model generalization ability. The proposed method not only improves the system robustness significantly but also improves the synthesized speech to near recording quality in our experiments for out-of-domain text. 
 Continuous Speech Keyword Spotting  is the problem of spotting keywords in recorded conversations, when a small number of instances of keywords are available in training data. Unlike the more common Keyword Spotting, where an algorithm needs to detect lone keywords or short phrases like Alexa閳, 閳ユ泛textit{Cortana}閳, 閳ユ泛textit{Hi Alexa!}閳,  閳ユ泛textit{Whatsup Octavia?}閳 etc. in speech, CSKS needs to filter out embedded words from a continuous flow of speech, ie. spot 閳ユ泛textit{Anna}閳 and 閳ユ泛textit{github}閳 in 閳ユ泛textit{I know a developer named Anna who can look into this github issue}.閳 Apart from the issue of limited training data availability, CSKS is an extremely imbalanced classification problem. We address the limitations of simple keyword spotting baselines for both aforementioned challenges by using a novel combination of loss functions  and transfer learning. Our method improves F1 score by over 10\%.  
 During the last few years, spoken language technologies have known a big improvement thanks to Deep Learning. However Deep Learning-based algorithms require amounts of data that are often difficult and costly to gather. Particularly, modeling the variability in speech of different speakers, different styles or different emotions with few data remains challenging. In this paper, we investigate how to leverage fine-tuning on a pre-trained Deep Learning-based TTS model to synthesize speech with a small dataset of another speaker. Then we investigate the possibility to adapt this model to have emotional TTS by fine-tuning the neutral TTS model with a small emotional dataset.  % NT : not done yet % We also built a module that modify the features depending on an input code representing the emotion.  
 We propose a novel neural sequence prediction method based on error-correcting output codes that avoids exact softmax normalization and allows for a tradeoff between speed and performance. Instead of minimizing measures between the predicted probability distribution and true distribution, we use error-correcting codes to represent both predictions and outputs.  % , a technique that is used to mitigate exposure bias, which can be integrated into training latent variable-based neural sequence predictors such as ECOC. % \newline This involves mixing the latent codes of past predictions and past targets in one of two ways:  according to a predefined sampling schedule or  a differentiable sampling procedure whereby the mixing probability is learned throughout training by replacing the greedy argmax operation with a smooth approximation. ECOC-NSP leads to consistent improvements on language modelling datasets and the proposed Latent Variable mixture sampling methods are found to perform well for text generation tasks such as image captioning. 
 Twitter is recently being used during crises to communicate with officials and provide rescue and relief operation in real time. The geographical location information of the event, as well as users, are vitally important in such scenarios. The identification of geographic location is one of the challenging tasks as the location information fields, such as user location and place name of tweets are not reliable. The extraction of location information from tweet text is difficult as it contains a lot of non-standard English, grammatical errors, spelling mistakes, non-standard abbreviations, and so on. This research aims to extract location words used in the tweet using a Convolutional Neural Network  based model. We achieved the exact matching score of 0.929, Hamming loss of 0.002, and $F_1$-score of 0.96 for the tweets related to the earthquake. Our model was able to extract even three- to four-word long location references which is also evident from the exact matching score of over 92\%. The findings of this paper can help in early event localization, emergency situations, real-time road traffic management, localized advertisement, and in various location-based services.  
 During active learning, an effective stopping method allows users to limit the number of annotations, which is cost effective.  In this paper, a new stopping method called Predicted Change of F Measure will be introduced that attempts to provide the users an estimate of how much performance of the model is changing at each iteration.  This stopping method can be applied with any base learner. This method is useful for reducing the data annotation bottleneck encountered when building text classification systems. 
 Most of the research in convolutional neural networks has focused on increasing network depth to improve accuracy, resulting in a massive number of parameters which restricts the trained network to platforms with memory and processing constraints. We propose to modify the structure of the Very Deep Convolutional Neural Networks  model to fit mobile platforms constraints and keep performance. In this paper, we evaluate the impact of Temporal Depthwise Separable Convolutions and Global Average Pooling in the network parameters, storage size, and latency.  The squeezed model  is between 10x and 20x smaller, depending on the network depth, maintaining a maximum size of 6MB. Regarding accuracy,  the network experiences a loss between 0.4\% and 1.3\% and obtains lower latencies compared to the baseline model.     % %Text classification, Very Deep Convolutional %Neural Networks, Temporal Depthwise Separable %Convolutions, Global Average Pooling. %  
 Moderation of user-generated content in an online community is a challenge that has great socio-economical ramifications. However, the costs incurred by delegating this work to human agents are high. For this reason, an automatic system able to detect abuse in user-generated content is of great interest. There are a number of ways to tackle this problem, but the most commonly seen in practice are word filtering or regular expression matching. The main limitations are their vulnerability to intentional obfuscation on the part of the users, and their context-insensitive nature. Moreover, they are language-dependent and may require appropriate corpora for training.  In this paper, we propose a system for automatic abuse detection that completely disregards message content. We first extract a conversational network from raw chat logs and characterize it through topological measures. We then use these as features to train a classifier on our abuse detection task. We thoroughly assess our system on a dataset of user comments originating from a French Massively Multiplayer Online Game. We identify the most appropriate network extraction parameters and discuss the discriminative power of our features, relatively to their topological and temporal nature. Our method reaches an $F$-measure of $83.89$ when using the full feature set, improving on existing approaches. With a selection of the most discriminative features, we dramatically cut computing time while retaining most of the performance . 
 We define general linguistic intelligence as the ability to reuse previously acquired knowledge about a language's lexicon, syntax, semantics, and pragmatic conventions to adapt  to new tasks quickly. Using this definition, we analyze state-of-the-art natural  language understanding models and conduct an extensive empirical investigation to  evaluate them against these criteria through a series of experiments that assess the task-independence of the knowledge being acquired by the learning process. In addition to task performance, we propose a new evaluation metric based on an online encoding of the test data that quantifies how quickly an existing  agent  learns a new task. Our results show that while the  field has made impressive progress in terms of model architectures that generalize to many tasks, these models still require  a lot of in-domain training examples  , and are prone to catastrophic forgetting. Moreover, we find that far from solving  general tasks ,  our models are overfitting to the quirks  of particular datasets . We discuss missing components and conjecture on how to make progress toward general linguistic intelligence.  
 For real-world speech recognition applications, noise robustness is still a challenge. In this work, we adopt the teacher-student  learning technique using a parallel clean and noisy corpus for improving automatic speech recognition  performance under multimedia noise. On top of that, we apply a logits selection method which only preserves the $k$ highest values to prevent wrong emphasis of knowledge from the teacher and to reduce bandwidth needed for transferring data. We incorporate up to 8000 hours of untranscribed data for training and present our results on sequence trained models apart from cross entropy trained ones. The best sequence trained student model yields relative word error rate  reductions of approximately 10.1\%, 28.7\% and 19.6\% on our clean, simulated noisy and real test sets respectively comparing to a sequence trained teacher. 
 Entity linking is the task of aligning mentions to corresponding entities in a given knowledge base. Previous studies have highlighted the necessity for entity linking systems to capture the global coherence. However, there are two common weaknesses in previous global models. First, most of them calculate the pairwise scores between all candidate entities and select the most relevant group of entities as the final result. In this process, the consistency among wrong entities as well as that among right ones are involved, which may introduce noise data and increase the model complexity. Second, the cues of previously disambiguated entities, which could contribute to the disambiguation of the subsequent mentions, are usually ignored by previous models. To address these problems, we convert the global linking into a sequence decision problem and propose a reinforcement learning model which makes decisions from a global perspective. Our model makes full use of the previous referred entities and explores the long-term influence of current selection on subsequent decisions. We conduct experiments on different types of datasets, the results show that our model outperforms state-of-the-art systems and has better generalization performance. 
 Recently, progress has been made towards improving relational reasoning in machine  learning field. Among existing models, graph neural networks  is one of the most effective approaches for multi-hop relational reasoning. In fact, multi-hop relational reasoning is indispensable in many natural language processing tasks such as relation extraction. In this paper, we propose to generate the parameters of graph neural networks  according to natural language sentences, which enables GNNs to process relational reasoning on unstructured text inputs. We verify GP-GNNs in relation extraction from text. Experimental results on a human-annotated dataset and two distantly supervised datasets show that our model achieves significant improvements compared to baselines. We also perform a qualitative analysis to demonstrate that our model could discover more accurate relations by multi-hop relational reasoning. 
   Taxonomies are semantic hierarchies of concepts.   One limitation of current taxonomy learning systems is that they define   concepts as single words.   This position paper argues that contextualized word representations, which   recently achieved state-of-the-art results on many competitive NLP tasks,   are a promising method to address this limitation.   We outline a novel approach for taxonomy learning that%   ~~defines concepts as synsets,%   ~~learns density-based approximations of contextualized word   representations, and%   ~~can measure similarity and hypernymy among them. 
  Recurrent neural networks have proved to be an effective method for statistical language modeling. However, in practice their memory and run-time complexity are usually too large to be implemented in real-time offline mobile applications. In this paper we consider several compression techniques for recurrent neural networks including Long-Short Term Memory models. We make particular attention to the high-dimensional output problem caused by the very large vocabulary size.  We focus on effective compression methods in the context of their exploitation on devices: pruning, quantization, and matrix decomposition approaches . For each model we investigate the trade-off between its size, suitability for fast inference and perplexity. We propose a general pipeline for applying the most suitable methods to compress recurrent neural networks for language modeling.  It has been shown in  the experimental study with the Penn Treebank  dataset that the most efficient results in terms of speed and compression-perplexity balance are obtained by matrix decomposition techniques.     
  One of the major challenges that NLP faces is metaphor detection, especially by automatic means, a task that becomes even more difficult for languages lacking in linguistic resources and tools. Our purpose is the automatic differentiation between literal and metaphorical meaning in authentic non-annotated phrases from the Corpus of Greek Texts by means of computational methods of machine learning. For this purpose the theoretical background of distributional semantics is discussed and employed. Distributional Semantics Theory develops concepts and methods for the quantification and classification of semantic similarities displayed by linguistic elements in large amounts of linguistic data according to their distributional properties. In accordance with this model, the approach followed in the thesis takes into account the linguistic context for the computation of the distributional representation of phrases in geometrical space, as well as for their comparison with the distributional representations of other phrases, whose function in speech is already "known" with the objective to reach conclusions about their literal or metaphorical function in the specific linguistic context. This procedure aims at dealing with the lack of linguistic resources for the Greek language, as the almost impossible up to now semantic comparison between "phrases", takes the form of an arithmetical comparison of their distributional representations in geometrical space.  
 When searching for information, a human reader first glances over a document, spots relevant sections and then focuses on a few sentences for resolving her intention. However, the high variance of document structure complicates to identify the salient topic of a given section at a glance. To tackle this challenge, we present SECTOR, a model to support machine reading systems by segmenting documents into coherent sections and assigning topic labels to each section. Our deep neural network architecture learns a latent topic embedding over the course of a document. This can be leveraged to classify local topics from plain text and segment a document at topic shifts. In addition, we contribute WikiSection, a publicly available dataset with 242k labeled sections in English and German from two distinct domains: diseases and cities. From our extensive evaluation of 20 architectures, we report a highest score of 71.6\% F1 for the segmentation and classification of 30 topics from the English city domain, scored by our SECTOR LSTM model with bloom filter embeddings and bidirectional segmentation. This is a significant improvement of 29.5 points F1 compared to state-of-the-art CNN classifiers with baseline segmentation. 
 In this paper, we propose an approach for transferring the knowledge of a neural model for sequence labeling, learned from the source domain, to a new model trained on a target domain, where new label categories appear.  Our transfer learning  techniques enable to adapt the source model using the target data and new categories, without accessing to the source data.  Our solution consists in adding new neurons in the output layer of the target model and transferring parameters from the source model, which are then fine-tuned with the target data.  Additionally, we propose a neural adapter to learn the difference between the source and the target label distribution, which provides additional important information to the target model. Our experiments on Named Entity Recognition show that  the learned knowledge in the source model can be effectively transferred when the target data contains new categories and  our neural adapter further improves such transfer. 
 %Contextualized representations have proven useful for neural models in various natural language tasks.   Self-attention model  have shown its flexibility in parallel computation and the effectiveness on modeling both long- and short-term dependencies. However, it calculates the dependencies between representations without considering the contextual information, which have proven useful for modeling dependencies among neural representations in various natural language tasks.  In this work, we focus on improving self-attention networks through capturing the richness of context. To maintain the simplicity and flexibility of the self-attention networks, we propose to contextualize the transformations of the query and key layers, which are used to calculates the relevance between elements.  Specifically, we leverage the internal representations that embed both global and deep contexts, thus avoid relying on external resources.  Experimental results on WMT14 English$\Rightarrow$German and WMT17 Chinese$\Rightarrow$English translation tasks demonstrate the effectiveness and universality of the proposed methods. Furthermore, we conducted extensive analyses to quantity how the context vectors participate in the self-attention model.% and what kinds of information are captured in the enhanced representations.  \iffalse Contextualized representations are important for neural natural language modeling. Although self-attention mechanism has shown its effectiveness on modeling the  discrete sequences, it directly builds relevance between elements without considering the contextual information. In this paper, several simple but effective strategies are proposed to strengthen self-attention networks through capturing the richness of  %syntactic and semantic context.  % to we propose several simple but effective strategies The contextual information is cast as context bias to be added to queries and keys in self-attention model. Thus, the calculation of similarity between each query and key is able to consider the context and distinguish the dependencies in different context.   Experimental results on WMT14 English$\rightarrow$German and WMT17 Chinese$\rightarrow$English translation tasks demonstrate the effectiveness and universality of the proposed methods. Furthermore, we conducted extensive analyses to quantity how the context vectors participate in the self-attention model and what kinds of information are captured in the enhanced representations. \fi  
  %%%% Version 1  %%%%% % Deep neural networks have been widely used in various applications and achieved exciting performance among tasks. Fusing information across layers has already proven to be useful in computer vision community and recent studies have begun to explore aggregating layers in the field of neural machine translation . However, most of the previous methods combine layers in a static fashion in that their aggregation strategy is independent of specific hidden states. We argue that treating each combinations of layers individually is a necessary and important step. Inspired by routing-by-agreement in {capsule} networks, in this work we propose several ways to aggregate layers dynamically, meaning we could learn specific weights of combination for given hidden states.  {To the best of our knowledge, the proposed method is the first to explore capsule networks in NMT.} We implement our method upon the state-of-the-art NMT system, namely the Transformer. Experimental results on widely-used WMT14 English$\Rightarrow$ German and WMT17 Chinese$\Rightarrow$ English translation data demonstrate the effectiveness and universality of the proposed method.   %%%% Version 2  %%%%% With the promising progress of deep neural networks, layer aggregation has been used to fuse information across layers in various fields, such as computer vision and machine translation. However, most of the previous methods combine layers in a static fashion in that their aggregation strategy is independent of specific hidden states.  {Inspired by recent progress on capsule networks, in this paper we propose to use {} and conduct experiments on the widely-used WMT14 English$\Rightarrow$German and WMT17 Chinese$\Rightarrow$English translation datasets. Experimental results across language pairs show that the proposed approach consistently outperforms the strong baseline model and  a representative static aggregation model.   %瀵ら缚顔 閸忓牆鐣鹃幀褑宸 閸氬海绮扮圭偤鐛欑紒鎾诡啈 鏉╂瑤绔撮崣銉ュ閹绘劒绨 wangxing %Also, our method is the first to explore capsule networks in NMT to our knowledge.  
 Sentiment analysis has been emerging recently as one of the major natural language processing  tasks in many applications. Especially, as social media channels  have become significant sources for brands to observe user opinions about their products, this task is thus increasingly crucial. However, when applied with real data obtained from social media, we notice that there is a high volume of short and informal messages posted by users on those channels. This kind of data makes the existing works suffer from many difficulties to handle, especially ones using deep learning approaches. In this paper, we propose an approach to handle this problem. This work is extended from our previous work, in which we proposed to combine the typical deep learning technique of Convolutional Neural Networks with domain knowledge. The combination is used for acquiring additional training data augmentation and a more reasonable loss function. In this work, we further improve our architecture by various substantial enhancements, including negation-based data augmentation, transfer learning for word embeddings, the combination of word-level embeddings and character-level embeddings, and using multitask learning technique for attaching domain knowledge rules in the learning process. Those enhancements, specifically aiming to handle short and informal messages, help us to enjoy significant improvement in performance once experimenting on real datasets. 
 With the increasing importance of online communities, discussion forums, and customer reviews, Internet ``trolls" have proliferated thereby making it difficult for information seekers to find relevant and correct information. In this paper, we consider the problem of detecting and identifying Internet trolls, almost all of which are human agents. Identifying a human agent among a human population presents significant challenges compared to detecting automated spam or computerized robots.  To learn a troll's behavior, we use contextual anomaly detection to profile each chat user. Using clustering and distance-based methods, we use contextual data such as the group's current goal, the current time, and the username to classify each point as an anomaly. A user whose features significantly differ from the norm will be classified as a troll. We collected 38 million data points from the viral Internet fad, Twitch Plays Pokemon. Using clustering and distance-based methods, we develop heuristics for identifying trolls. Using MapReduce techniques for preprocessing and user profiling, we are able to classify trolls based on 10 features extracted from a user's lifetime history. 
 Self-attention network, an attention-based feedforward neural network, has recently shown the potential to replace recurrent neural networks  in a variety of NLP tasks. However, it is not clear if the self-attention network could be a good alternative of RNNs in automatic speech recognition , which processes the longer speech sequences and may have online recognition requirements. In this paper, we present a RNN-free end-to-end model: self-attention aligner , which applies the self-attention networks to a simplified recurrent neural aligner  framework. We also propose a chunk-hopping mechanism, which enables the SAA model to encode on segmented frame chunks one after another to support online recognition. Experiments on two Mandarin ASR datasets show the replacement of RNNs by the self-attention networks yields a 8.4\%-10.2\% relative character error rate  reduction. In addition, the chunk-hopping mechanism allows the SAA to have only a 2.5\% relative CER degradation with a 320ms latency. After jointly training with a self-attention network language model, our SAA model obtains further error rate reduction on multiple datasets. Especially, it achieves 24.12\% CER on the Mandarin ASR benchmark , exceeding the best end-to-end model by over 2\% absolute CER. 
 This article describes how to use the ``CLV3'' class file, developed by {'' class file  and will be modified whenever there is an update in the layout specifications. 
 End-to-end acoustic-to-word speech recognition models have recently gained popularity because they are easy to train, scale well to large amounts of training data, and do not require a lexicon. In addition, word models may also be easier to integrate with downstream tasks such as spoken language understanding, because inference  is much simplified compared to phoneme, character or any other sort of sub-word units. In this paper, we describe methods to construct contextual acoustic word embeddings directly from a supervised sequence-to-sequence acoustic-to-word speech recognition model using the learned attention distribution. On a suite of 16 standard sentence evaluation tasks, our embeddings show competitive performance against a word2vec model trained on the speech transcriptions. In addition, we evaluate these embeddings on a spoken language understanding task, and observe that our embeddings match the performance of text-based embeddings in a pipeline of first performing speech recognition and then constructing word embeddings from transcriptions. 
 This paper focuses on a comparative evaluation of the most common and modern methods for text classification, including the recent deep learning strategies and ensemble methods. The study is motivated by a challenging real data problem, characterized by high-dimensional and extremely sparse data, deriving from incoming calls to the customer care of an Italian phone company. We will show that deep learning outperforms many classical  strategies but the combination of shallow and deep learning methods in a unique ensemble classifier may improve the robustness and the accuracy of ``single'' classification methods. 
   It is intuitive that semantic representations can be useful for machine translation, mainly because they can help in enforcing meaning preservation and handling data sparsity  of machine translation models.   On the other hand, little work has been done on leveraging semantics for neural machine translation .   In this work, we study the usefulness of AMR  on NMT.   Experiments on a standard English-to-German dataset show that incorporating AMR as additional knowledge can significantly improve a strong attention-based sequence-to-sequence neural translation model.  
  Deep neural networks  have achieved remarkable success in various tasks . However, researches have shown that DNN models are vulnerable to adversarial examples, which cause incorrect predictions by adding imperceptible perturbations into normal inputs. Studies on adversarial examples in image domain have been well investigated, but in texts the research is not enough, let alone a comprehensive survey in this field. In this paper, we aim at presenting a comprehensive understanding of adversarial attacks and corresponding mitigation strategies in texts. Specifically, we first give a taxonomy of adversarial attacks and defenses in texts from the perspective of different natural language processing  tasks, and then introduce how to build a robust DNN model via testing and verification. Finally, we discuss the existing challenges of adversarial attacks and defenses in texts and present the future research directions in this emerging field. 
 Relation extraction is an important task in structuring content of text data, and becomes especially challenging when learning with weak supervision---where only a limited number of labeled sentences are given and a large number of unlabeled sentences are available. Most existing work exploits unlabeled data based on the ideas of self-training  and multi-view learning . However, these methods either suffer from the issue of semantic drift, or do not fully capture the problem characteristics of relation extraction. In this paper, we leverage a key insight that retrieving sentences expressing a relation is a dual task of predicting relation label for a given sentence---two tasks are complementary to each other and can be optimized jointly for mutual enhancement. To model this intuition, we propose DualRE, a principled framework that introduces a retrieval module which is jointly trained with the original relation prediction module. In this way, high-quality samples selected by retrieval module from unlabeled data can be used to improve prediction module, and vice versa. Experimental results\footnote{.} on two public datasets as well as case studies demonstrate the effectiveness of the  DualRE approach.  
 % concise styple like x-vector paper This paper aims to improve the widely used deep speaker embedding x-vector model. We propose the following improvements:  a hybrid neural network structure using both time delay neural network  and long short-term memory neural networks  to generate complementary speaker information at different levels;  a multi-level pooling strategy to collect speaker information from both TDNN and LSTM layers;  a regularization scheme on the speaker embedding extraction layer to make the extracted embeddings suitable for the following fusion step. The synergy of these improvements are shown on the NIST SRE 2016 eval test  and SRE 2018 dev test , as well as more than 10\% DCF scores reduction on these two test sets over the x-vector baseline.  
 	Short text classification is one of important tasks in Natural Language Processing . 	Unlike paragraphs or documents, short texts are more ambiguous since they have not enough contextual information, which poses a great challenge for classification. 	In this paper, we retrieve knowledge from external knowledge source 	to enhance the semantic representation of short texts.  	We take conceptual information as a kind of knowledge and incorporate it into deep neural networks. 	For the purpose of measuring the importance of knowledge, we introduce attention mechanisms and propose deep Short Text Classification with Knowledge powered Attention . 	We utilize Concept towards Short Text  attention and Concept towards Concept Set  attention to acquire the weight of concepts from two aspects.  	And we classify a short text with the help of conceptual information. 	Unlike traditional approaches, our model acts like a human being who has intrinsic ability to make decisions based on observation  and pays more attention to important knowledge. 	We also conduct extensive experiments on four public datasets for different tasks. The experimental results and case studies show that our model outperforms the state-of-the-art methods, justifying the effectiveness of knowledge powered attention. 
 As humans, we often rely on language to learn language. For example, when corrected in a conversation, we may learn from that correction, over time improving our language fluency. Inspired by this observation, we propose a learning algorithm for training semantic parsers from supervision  expressed in natural language. Our algorithm learns a semantic parser from users' corrections such as ``no, what I really meant was before his job, not after'', by also simultaneously learning to parse this natural language feedback in order to leverage it as a form of supervision. Unlike supervision with gold-standard logical forms, our method does not require the user to be familiar with the underlying logical formalism, and unlike supervision from denotation, it does not require the user to know the correct answer to their query. This makes our learning algorithm naturally scalable in settings where existing conversational logs are available and can be leveraged as training data. We construct a novel dataset of natural language feedback in a conversational setting, and show that our method is effective at learning a semantic parser from such natural language supervision. 
 Deep learning has emerged as a compelling solution to many NLP tasks with remarkable performances. However, due to their opacity, such models are hard to interpret and trust. Recent work on explaining deep models has introduced approaches to provide insights toward the model's behaviour and predictions, which are helpful for assessing the reliability of the model's predictions. However, such methods do not improve the model's reliability. In this paper, we aim to teach the model to make the right prediction for the right reason by providing explanation training and ensuring the alignment of the model's explanation with the ground truth explanation. Our experimental results on multiple tasks and datasets demonstrate the effectiveness of the proposed method, which produces more reliable predictions while delivering better results compared to traditionally trained models. 
 Automatically evaluating the quality of dialogue responses for unstructured domains is a challenging problem. ADEM~ formulated the automatic evaluation of dialogue systems as a learning problem and showed that such a model was able to predict responses which correlate significantly with human judgements, both at utterance and system level. Their system was shown to have beaten word-overlap metrics such as BLEU with large margins. We start with the question of whether an adversary can game the ADEM model. We design a battery of targeted attacks at the neural network based ADEM evaluation system and show that automatic evaluation of dialogue systems still has a long way to go. ADEM can get confused with a variation as simple as reversing the word order in the text! We report experiments on several such adversarial scenarios that draw out counterintuitive scores on the dialogue responses. We take a systematic look at the scoring function proposed by ADEM and connect it to linear system theory to predict the shortcomings evident in the system. We also devise an attack that can fool such a system to rate a response generation system as favorable. Finally, we allude to future research directions of using the adversarial attacks to design a truly automated dialogue evaluation system. 
  We present our system for the CLIN29 shared task on cross-genre gender detection for Dutch. We experimented with a multitude of neural models , more ``traditional'' models , different feature sets as well as data pre-processing. The final results suggested that using tokenized, non-lowercased data works best for most of the neural models, while a combination of word clusters, character trigrams and word lists showed to be most beneficial for the majority of the more ``traditional''  models, beating features used in previous tasks such as $n$-grams, character $n$-grams, part-of-speech tags and combinations thereof. In contradiction with the results described in previous comparable shared tasks, our neural models performed better than our best traditional approaches with our best feature set-up. Our final model consisted of a weighted ensemble model combining the top 25 models. Our final model won both the in-domain gender prediction task and the cross-genre challenge, achieving an average accuracy of 64.93\% on the in-domain gender prediction task, and 56.26\% on cross-genre gender prediction.  
 Defining action spaces for conversational agents and optimizing their decision-making process with reinforcement learning is an enduring challenge. Common practice has been to use handcrafted dialog acts, or the output vocabulary, e.g. in neural encoder decoders, as the action spaces. Both have their own limitations. This paper proposes a novel latent action framework that treats the action spaces of an end-to-end dialog agent as latent variables and develops unsupervised methods in order to induce its own action space from the data. Comprehensive experiments are conducted examining both continuous and discrete action types and two different optimization methods based on stochastic variational inference. Results show that the proposed latent actions achieve superior empirical performance improvement over previous word-level policy gradient methods on both DealOrNoDeal and MultiWoz dialogs. Our detailed analysis also provides insights about various latent variable approaches for policy learning and can serve as a foundation for developing better latent actions in future research.} 
 			In sequence to sequence generation tasks , inference is generally performed in a left-to-right manner to produce the result token by token. 			The neural approaches, such as LSTM and self-attention networks, are now able to make full use of all the predicted history hypotheses from left side during inference, but cannot meanwhile access any future  information and usually generate unbalanced outputs in which left parts are much more accurate than right ones. 			In this work, we propose a synchronous bidirectional inference model to generate outputs using both left-to-right and right-to-left decoding simultaneously and interactively. 			First, we introduce a novel beam search algorithm that facilitates synchronous bidirectional decoding. Then, we present the core approach which enables left-to-right and right-to-left decoding to interact with each other, so as to utilize both the history and future predictions simultaneously during inference. 			We apply the proposed model to both LSTM and self-attention networks. In addition, we propose two strategies for parameter optimization. The extensive experiments on machine translation and abstractive summarization demonstrate that our synchronous bidirectional inference model can achieve remarkable improvements over the strong baselines. 		
 %Models for the open domain usually fail in specific domains, due to the data sparsity of specific domains. Transfer learning is one promising way to leverage open domain's knowledge and solve the data sparsity issue. %Transfer learning solve the sparsity of supervised data for a specific domain. For a sequence of words , the transfer learning need to model the sequential information. Regardless of the transfer learning mechanism, recurrent neural network  is a widely used neural network, which uses a chain of repeating cells to model the sequence. However, previous transfer learning studies of neural networks focus on the information transfer across layers. Besides being unfeasible for seq2seq and sequence labeling tasks, such layer-wise transfer learning mechanism also loss the cell-level information from the source domain.  %from the sequential information among modules in one RNN layer. {Specify this!!!}   %Previous transfer learning mechanisms treat the sequential features as unordered, which cannot benefit from the sequence. %under the DL framework focus on learning a unified representation for both the open domain and the specific domain. In learning the unified representation, the supervised labels for the exact problem is irrelevant to the training, which makes the learned representation unaware of the labeled data. This irrelevance is even more serious for sequence labeling tasks, such as POS tagging, chunking. This is because the sequence labeling tasks need to represent the sequential information of the input. Such sequential information is useless in the traditional unified representation learning and thus is lost.  %In this paper, we proposed the aligned recurrent transfer, ART, to achieve cell-wise information transfer. The transfer is in a recurrent fashion that different cells in the target domain share parameters. Instead of only transferring the corresponding position's information from the source domain, the proposed transfer mechanism first finds alignments among all source domain's positions. This enables ART a more flexible way to capture the word collocation across domains. We implement ART over LSTM. We conduct extensive experiments on sequence labeling tasks  and sentence classification . ART performs best over all tasks.  {ligned \underline{r}ecurrent \underline{t}ransfer, ART, to achieve cell-level information transfer. ART is under the pre-training framework. Each cell attentively accepts transferred information from a set of positions in the source domain. Therefore, ART learns the cross-domain word collocations in a more flexible way. We conducted extensive experiments on both sequence labeling tasks  and sentence classification . ART outperforms the state-of-the-arts over all experiments.}  % transfer information among modules in the same RNN layer. An RNN layer models the sequence data through sequential memory. Similarly, we build the transfer mechanism for sequential memory transfer between each two adjacent units from different domains. We propose the transferable RNN, a novel mechanism for sequential memory transfer in RNN. It uses two extra connections to attentively transfer the sequence memory from the source domain to the target domain. We implement the transfer mechanism over LSTM and GRU. Both implementations beat the non-recurrent transfer over different NLP tasks. 
 Targeted sentiment classification aims at determining the sentimental tendency towards specific targets. Most of the previous approaches model context and target words with RNN and attention. However, RNNs are difficult to parallelize and truncated backpropagation through time brings difficulty in remembering long-term patterns. To address this issue, this paper proposes an Attentional Encoder Network  which eschews recurrence and employs attention based encoders for the modeling between context and target. We raise the label unreliability issue and introduce label smoothing regularization. We also apply pre-trained BERT to this task and obtain new state-of-the-art results. Experiments and analysis demonstrate the effectiveness and lightweight of our model. \footnote{Source code is available at \url{https://github.com/songyouwei/ABSA-PyTorch/tree/aen}.} 
 The image, question , and the corresponding answer are three vital components of visual dialog. Classical visual dialog systems integrate the image, question, and history to search for or generate the best matched answer, and so, this approach significantly ignores the role of the answer. In this paper, we devise a novel image-question-answer synergistic network to value the role of the answer for precise visual dialog. We extend the traditional one-stage solution to a two-stage solution. In the first stage, candidate answers are coarsely scored according to their relevance to the image and question pair. Afterward, in the second stage, answers with high probability of being correct are re-ranked by synergizing with image and question. On the Visual Dialog v1.0 dataset, the proposed synergistic network boosts the discriminative visual dialog model to achieve a new state-of-the-art of 57.88\% normalized discounted cumulative gain. A generative visual dialog model equipped with the proposed technique also shows promising improvements. 
 Capturing the meaning of sentences has long been a challenging task. Current models tend to apply linear combinations of word features to conduct semantic composition for bigger-granularity units e.g. phrases, sentences, and documents. However, the semantic linearity does not always hold in human language. For instance, the meaning of the phrase ``ivory tower'' cannot be deduced by linearly combining the meanings of ``ivory'' and ``tower''.  To address this issue,  we propose a new framework that models different levels of semantic units  on a single Semantic Hilbert Space, which naturally admits a non-linear semantic composition by means of a complex-valued vector word representation.  An end-to-end neural network is proposed to implement the framework in the text classification task, and evaluation results on six benchmarking text classification datasets demonstrate the effectiveness, robustness and self-explanation power of the proposed model. Furthermore, intuitive case studies are conducted to help end users to understand how the framework works.  % In our proposed QP-driven framework\footnote{https://github.com/anonymous/anonymous.git}, each word is modeled as a superposition state, and a sentence is formulated as a complex mixture of word states. A set of quantum-like measurements are applied to the sentence mixture state to extract the high-level features of the sentence, which are then used for processing any downstream NLP tasks. Evaluation results on six benchmarking text classification datasets demonstrate the effectiveness, robustness and interpretability of the proposed model.  
 Fine-Grained Named Entity Recognition  is critical for many NLP applications. While classical named entity recognition  has attracted a substantial amount of research, FG-NER is still an open research domain. The current state-of-the-art  model for FG-NER relies heavily on manual efforts for building a dictionary and designing hand-crafted features. The end-to-end framework which achieved the SOTA result for NER did not get the competitive result compared to SOTA model for FG-NER. In this paper, we investigate how effective multi-task learning approaches are in an end-to-end framework for FG-NER at different aspects. Our experiments show that using multi-task learning approaches with contextualized word representations can help an end-to-end neural network model achieve SOTA results without using any additional manual effort for creating data and designing features.  
 This paper describes our system submitted to SemEval 2019 Task 7: RumourEval 2019: Determining Rumour Veracity and Support for Rumours, Subtask A . The challenge focused on classifying whether posts from Twitter and Reddit  or  a hidden rumour, truthfulness of which is the topic of an underlying discussion thread. We formulate the problem as a stance classification, determining the rumour stance of a post with respect to the previous thread post and the source thread post. The recent BERT architecture was employed to build an end-to-end system which has reached the F1 score of 61.67\,\% on the provided test data. It finished at the 2\textsuperscript{nd} place in the competition, without any hand-crafted features, only 0.2\,\% behind the winner. 
 In this paper, we investigate the challenges of using reinforcement learning agents for question-answering over knowledge graphs for real-world applications. We examine the performance metrics used by state-of-the-art systems and determine that they are inadequate for such settings. More specifically, they do not evaluate the systems correctly for situations when there is no answer available and thus agents optimized for these metrics are poor at modeling confidence.  We introduce a simple new performance metric for evaluating question-answering agents that is more representative of practical usage conditions, and optimize for this metric by extending the binary reward structure used in prior work to a ternary reward structure which also rewards an agent for not answering a question rather than giving an incorrect answer. We show that this can drastically improve the precision of answered questions while only not answering a limited number of previously correctly answered questions. Employing a supervised learning strategy using depth-first-search paths to bootstrap the reinforcement learning algorithm further improves  performance. 
 \textcolor{black}{Over the last few years, machine learning over graph structures has manifested a significant enhancement in text mining applications such as event detection, opinion mining, and news recommendation. One of the primary challenges in this regard is structuring a graph that encodes and encompasses the features of textual data for the effective machine learning algorithm. Besides, exploration and exploiting of semantic relations is regarded as a principal step in text mining applications. However, most of the traditional text mining methods perform somewhat poor in terms of employing such relations. In this paper, we propose a sentence-level graph-based text representation which includes stop words to consider semantic and term relations. Then, we employ a representation learning approach on the combined graphs of sentences to extract the latent and continuous features of the documents. Eventually, the learned features of the documents are fed into a deep neural network for the sentiment classification task. The experimental results demonstrate that the proposed method substantially outperforms the related sentiment analysis approaches based on several benchmark datasets. Furthermore, our method can be generalized on different datasets without any dependency on pre-trained word embeddings. } 
 We suggest a new idea of Editorial Network -- a mixed extractive-abstractive summarization approach, which is applied as a post-processing step over a given sequence of extracted sentences. Our network tries to imitate the decision process of a human editor during summarization. Within such a process, each extracted sentence may be either kept untouched, rephrased or completely rejected. We further suggest an effective way for training the ``editor" based on a novel soft-labeling approach. Using the CNN/DailyMail dataset we demonstrate the effectiveness of our approach compared to state-of-the-art extractive-only or abstractive-only baseline methods. 
 %The ability of asking good questions helps human to grasp new knowledge and know better about the world. %Such ability now plays a vital role in machine intelligent systems by  Automatic question generation is an important technique that can improve the training of question answering, help chatbots to start or continue a conversation with humans, and provide assessment materials for educational purposes. % It aims to generate natural language questions, based on a given passage with the desired answer.  %It is a task of great value to question answering systems, chatbots, and educational applications. %Traditional methods include heuristic rules-based systems and sequence-to-sequence models with copy mechanism. % However, we argue that  Existing neural question generation models are not sufficient mainly due to their inability to properly model the process of how each word in the question is selected, i.e., whether repeating the given passage or being generated from a vocabulary. %In this paper, In this paper, we propose our Clue Guided Copy Network for Question Generation , which  is a sequence-to-sequence generative model with copying mechanism, yet employing a variety of novel components and techniques to boost the performance of question generation. In CGC-QG, we design a multi-task labeling strategy to identify whether a question word should be copied from the input passage or be generated instead, guiding the model to learn the accurate boundaries between copying and generation. Furthermore, our input passage encoder takes as input, among a diverse range of other features, the prediction made by a clue word predictor, which helps identify whether each word in the input passage is a potential clue to be copied into the target question.    % \red{Labeling training dataset based on it } The clue word predictor is designed based on a novel application of Graph Convolutional Networks onto a syntactic dependency tree representation of each passage, thus being able to predict clue words only based on their context in the passage and their relative positions to the answer in the tree. We jointly train the clue prediction as well as question generation with multi-task learning and a number of practical strategies to reduce the complexity. %We further propose a clue words guided question generation model, where a ``clue word'' means a word that is helpful to reduce the uncertainty of the model about how to ask a question or what to copy. %Our model explicitly predicts the potential clue words in an input sentence through a clue prediction module, and learns to copy potential clue words and generate questions through a sequence-to-sequence model with copy mechanism.  %For the clue prediction module, we %The combine the syntactic dependency tree of sentences with Graph Convolutional Network to estimate the clue words distribution. Extensive evaluations show that our model significantly improves the performance of question generation and out-performs all previous state-of-the-art neural question generation models by a substantial margin. 
 Multilingual machine translation, which translates multiple languages with a single model, has attracted much attention due to its efficiency of offline training and online serving. However, traditional multilingual translation usually yields inferior accuracy compared with the counterpart using individual models for each language pair, due to language diversity and model capacity limitations. In this paper, we propose a distillation-based approach to boost the accuracy of multilingual machine translation. Specifically, individual models are first trained and regarded as teachers, and then the multilingual model is trained to fit the training data and match the outputs of individual models simultaneously through knowledge distillation. Experiments on IWSLT, WMT and Ted talk translation datasets demonstrate the effectiveness of our method. Particularly, we show that one model is enough to handle multiple languages , with comparable or even better accuracy than individual models. 
 % Learning for matching between query and document is at the core of information retrieval: % Deep learning has been successfully applied to many typical natural language processing  tasks, such as sentence matching, question answering and so on.  % Existing neural networks are powerful in represent the  % We point out that existing approaches mainly focus on the semantic matching of short text pairs, and do not perform well on the task of relevance matching, especially between short-long text pairs.  A large number of deep learning models have been proposed for the text matching problem, which is at the core of various typical natural language processing  tasks. However, existing deep models are mainly designed for the semantic matching between a pair of short texts, such as paraphrase identification and question answering, and do not perform well on the task of relevance matching between short-long text pairs. This is partially due to the fact that the essential characteristics of short-long text matching have not been well considered in these deep models.  More specifically, these methods fail to handle extreme length discrepancy between text pieces and neither can they fully characterize the underlying structural information in long text documents.  In this paper, we are especially interested in relevance matching between a piece of short text and a long document, which is critical to problems like query-document matching in information retrieval and web searching.  To extract the structural information of documents, an undirected graph is constructed, with each vertex representing a keyword and the weight of an edge indicating the degree of interaction between keywords.  Based on the keyword graph, we further propose a Multiresolution Graph Attention Network to learn multi-layered representations of vertices through a Graph Convolutional Network , and then match the short text snippet with the graphical representation of the document with the attention mechanisms applied over each layer of the GCN. % Moreover, we develop deeper insights into the GCN model in ~ and address its limits to weighted graphs. Experimental results on two datasets demonstrate that our graph approach outperforms other state-of-the-art deep matching models. % \footnote{This is an abstract footnote} 
 Although recent neural conversation models have shown great potential, they often generate bland and generic responses. While various approaches have been explored to diversify the output of the conversation model, the improvement often comes at the cost of decreased relevance .  In this paper, we propose a SpaceFusion model to jointly optimize diversity and relevance that essentially fuses the latent space of a sequence-to-sequence model and that of an autoencoder model by leveraging novel regularization terms. As a result, our approach induces a latent space in which the distance and direction from the predicted response vector roughly match the relevance and diversity, respectively. This property also lends itself well to an intuitive visualization of the latent space. Both automatic and human evaluation results demonstrate that the proposed approach brings significant improvement compared to strong baselines in both diversity and relevance. \footnote{An implementation of our model is available at \url{https://github.com/golsun/SpaceFusion}}           
   This paper presents a new model for visual dialog, Recurrent Dual Attention Network , using multi-step reasoning to answer a series of questions about an image. In each question-answering turn of a dialog, ReDAN infers the answer progressively through multiple reasoning steps. In each step of the reasoning process, the semantic representation of the question is updated based on the image and the previous dialog history, and the recurrently-refined representation is used for further reasoning in the subsequent step.    On the VisDial v1.0 dataset, the proposed ReDAN model     achieves a new state-of-the-art of 64.47\% NDCG score.    Visualization on the reasoning process further demonstrates that ReDAN can locate context-relevant visual and textual clues via iterative refinement, which can lead to the correct answer step-by-step. 
      Recent efforts on training visual navigation agents conditioned on language using deep reinforcement learning have been successful in learning policies for different multimodal tasks, such as semantic goal navigation and embodied question answering. In this paper, we propose a multitask model capable of jointly learning these multimodal tasks, and transferring knowledge of words and their grounding in visual objects across the tasks. The proposed model uses a novel Dual-Attention unit to disentangle the knowledge of words in the textual representations and visual concepts in the visual representations, and align them with each other. This disentangled task-invariant alignment of representations facilitates grounding and knowledge transfer across both tasks. We show that the proposed model outperforms a range of baselines on both tasks in simulated 3D environments. We also show that this disentanglement of representations makes our model modular, interpretable, and allows for transfer to instructions containing new words by leveraging object detectors.\footnote[2]{See \url{https://devendrachaplot.github.io/projects/EMML} for demo videos.} 
 Multi-task learning shares information between related tasks, sometimes reducing the number of parameters required. State-of-the-art results across multiple natural language understanding tasks in the GLUE benchmark have previously used transfer from a single large task: unsupervised pre-training with BERT, where a separate BERT model was fine-tuned for each task. We explore multi-task approaches that share a  BERT model with a small number of additional task-specific parameters. Using new adaptation modules, PALs or `projected attention layers', we match the performance of separately fine-tuned models on the GLUE benchmark with $\approx$7 times fewer parameters, and obtain state-of-the-art results on the Recognizing Textual Entailment dataset. 
 There is an implicit assumption that by unfolding recurrent neural networks  in finite time, the misspecification of choosing a zero value for the initial hidden state is mitigated by later time steps. This assumption has been shown to work in practice and alternative initialization may be suggested but often overlooked. In this paper, we propose a method of parameterizing the initial hidden state of an RNN. The resulting architecture, referred to as a Contextual RNN, can be trained end-to-end. The performance on an associative retrieval task is found to improve by conditioning the RNN initial hidden state on contextual information from the input sequence. Furthermore, we propose a novel method of conditionally generating sequences using the hidden state parameterization of Contextual RNN. 
 Humans use language to collectively execute abstract strategies besides using it as a referential tool for identifying physical entities. Recently, multiple attempts at replicating the process of emergence of language in artificial agents have been made. While existing approaches study emergent languages as referential tools, in this paper, we study their role in discovering and implementing strategies. We formulate the problem using a voting game where two candidate agents contest in an election with the goal of convincing population members , that are connected to each other via an underlying network, to vote for them. To achieve this goal, agents are only allowed to exchange messages in the form of sequences of discrete symbols to spread their propaganda. We use neural networks with Gumbel-Softmax relaxation for sampling categorical random variables to parameterize the policies followed by all agents. Using our proposed framework, we provide concrete answers to the following questions:  Do the agents learn to communicate in a meaningful way and does the emergent communication play a role in deciding the winner?  Does the system evolve as expected under various reward structures?  How is the emergent language affected by the community structure in the network? To the best of our knowledge, we are the first to explore emergence of communication for discovering and implementing strategies in a setting where agents communicate over a network.\footnote{A shorter version of this paper has been accepted as an extended abstract at AAMAS 2020.} 
   Many machine learning algorithms represent input data with vector embeddings   or discrete codes.  When inputs exhibit compositional structure , it is natural to ask whether   this compositional structure is reflected in the the inputs' learned   representations. While the assessment of compositionality in languages has   received significant attention in linguistics and adjacent fields, the machine   learning literature lacks general-purpose tools for producing graded   measurements of compositional structure in more general    representation spaces. We describe a procedure for evaluating compositionality   by measuring how well the true representation-producing model can be   approximated by a model that explicitly composes a collection of inferred   representational primitives. We use the procedure to provide formal and   empirical characterizations of compositional structure in a variety of   settings, exploring the relationship between compositionality and learning   dynamics, human judgments, representational similarity, and generalization. 
 \nolinenumbers      Through specific experiences, humans learn relationships underlying the structure of events in the world. Schema theory suggests that we organize this information in mental frameworks called ``schemata," which represent our knowledge of the structure of the world. Generalizing knowledge of structural relationships to new situations requires role-filler binding, the ability to associate specific ``fillers" with abstract ``roles." For instance, when we hear the sentence ``Alice ordered a tea from Bob," the role-filler bindings ``Alice:customer," ``tea:drink," and ``Bob:barista" allow us to understand and make inferences about the sentence. We can perform these bindings for arbitrary fillers -- we understand this sentence even if we have never heard the names ``Alice," ``tea," or ``Bob" before.     In this work, we define a model as capable of performing role-filler binding if it can recall arbitrary fillers corresponding to a specified role, even when these pairings violate correlations seen during training. Previous work found that models can learn this ability when explicitly told what the roles and fillers are, or when given fillers seen during training. We show that networks with external memory can learn these relationships with fillers not seen during training and without explicitly labeled role-filler bindings, and show that analyses inspired by neural decoding can provide a means of understanding what the networks have learned. 
 We consider the problem of making efficient use of heterogeneous training data in neural machine translation . Specifically, given a training dataset with a sentence-level feature such as noise, we seek an optimal curriculum, or order for presenting examples to the system during training. Our curriculum framework allows examples to appear an arbitrary number of times, and thus generalizes data weighting, filtering, and fine-tuning schemes.  Rather than relying on prior knowledge to design a curriculum, we use reinforcement learning to learn one automatically, jointly with the NMT system, in the course of a single training run. We show that this approach can beat uniform and filtering baselines on Paracrawl and WMT English-to-French datasets by up to +3.4 BLEU, and match the performance of a hand-designed, state-of-the-art curriculum.    
 Neural Networks trained with gradient descent are known to be susceptible to catastrophic forgetting caused by parameter shift during the training process. In the context of Neural Machine Translation  this results in poor performance on heterogeneous datasets and on sub-tasks like rare phrase translation. On the other hand, non-parametric approaches are immune to forgetting, perfectly complementing the generalization ability of NMT. However, attempts to combine non-parametric or retrieval based approaches with NMT have only been successful on narrow domains, possibly due to over-reliance on sentence level retrieval. We propose a novel n-gram level retrieval approach that relies on local phrase level similarities, allowing us to retrieve neighbors that are useful for translation even when overall sentence similarity is low. We complement this with an expressive neural network, allowing our model to extract information from the noisy retrieved context. We evaluate our semi-parametric NMT approach on a heterogeneous dataset composed of WMT, IWSLT, JRC-Acquis and OpenSubtitles, and demonstrate gains on all 4 evaluation sets. The semi-parametric nature of our approach opens the door for non-parametric domain adaptation, demonstrating strong inference-time adaptation performance on new domains without the need for any parameter updates. 
   Multilingual neural machine translation  enables training a single model that supports translation from multiple source languages into multiple target languages. In this paper, we push the limits of multilingual NMT in terms of the number of languages being used. We perform extensive experiments in training massively multilingual NMT models, translating up to 102 languages to and from English within a single model. We explore different setups for training such models and analyze the trade-offs between translation quality and various modeling decisions. We report results on the publicly available TED talks multilingual corpus where we show that massively multilingual many-to-many models are effective in low resource settings, outperforming the previous state-of-the-art while supporting up to 59 languages. Our experiments on a large-scale dataset with 102 languages to and from English and up to one million examples per direction also show promising results, surpassing strong bilingual baselines and encouraging future work on massively multilingual NMT. 
   This short paper presents the design decisions taken and challenges encountered in completing OffensEval 2019    , which poses the problem of identifying and categorizing offensive language in tweets. Our proposed solutions explore Deep Learning techniques, Linear Support Vector classification and Random Forests to identify offensive tweets, to classify offenses as targeted or untargeted and eventually to identify the target subject type. 
 Machine learning has shown promise for automatic detection of Alzheimer's disease  through speech; however, efforts are hampered by a scarcity of data, especially in languages other than English.  We propose a method to learn a correspondence between independently engineered lexicosyntactic features in two languages, using a large parallel corpus of out-of-domain movie dialogue data.  We apply it to dementia detection in Mandarin Chinese, and demonstrate that our method outperforms both unilingual and machine translation-based baselines. This appears to be the first study that transfers feature domains in detecting cognitive decline.  
 Although deep learning models have brought tremendous advancements to the field of open-domain dialogue response generation, recent research results have revealed that the trained models have undesirable generation behaviors, such as malicious responses and generic  responses. In this work, we propose a framework named ``Negative Training" to minimize such behaviors. Given a trained model, the framework will first find generated samples that exhibit the undesirable behavior, and then use them to feed negative training signals for fine-tuning the model. Our experiments show that negative training can significantly reduce the hit rate of malicious responses, or discourage frequent responses and improve response diversity. 
    When answering natural language questions over knowledge bases ,    different question components and KB aspects play different roles.    However, most existing embedding-based methods for knowledge base question answering  ignore the subtle inter-relationships 	between the question and the KB .     In this work, we propose to directly model the two-way flow of interactions between the     questions and the KB via a novel Bidirectional Attentive Memory Network, called BAMnet.     Requiring no external resources and only very few hand-crafted features, on the WebQuestions     benchmark, our method significantly outperforms existing information-retrieval      based methods, and remains competitive with  semantic parsing based methods. Also, since we use attention mechanisms, our method offers better interpretability compared to other baselines.    
 Question answering  has become a popular way for humans to access billion-scale knowledge bases. Unlike web search, QA over a knowledge base gives out accurate and concise results, provided that natural language questions can be understood and mapped precisely to structured queries over the knowledge base.  The challenge, however, is that a human can ask one question in many different ways. Previous approaches have natural limits due to their representations: rule based approaches only understand a small set of ``canned'' questions, while keyword based or synonym based approaches cannot fully understand the questions.  In this paper, we design a new kind of question representation: templates, over a billion scale knowledge base and a million scale QA corpora.  For example, for questions about a city's population, we learn templates such as What's the population of \$city?, How many people are there in \$city?. We learned 27 million templates for 2782 intents. Based on these templates, our QA system KBQA effectively supports binary factoid questions, as well as complex questions which are composed of a series of binary factoid questions. Furthermore, we expand predicates in RDF knowledge base, which boosts the coverage of knowledge base by 57 times. Our QA system beats all other state-of-art works on both effectiveness and efficiency over QALD benchmarks. 
 % End-to-end approaches to knowledge base question answering  have the advantage that they % can be trained directly on QA pairs, but user generated answers are of varied quality. Noisy % answers may adversely affect training. End-to-end training has been a popular approach for knowledge base question answering . However, real world applications often contain answers of varied quality for users' questions. It is not appropriate to treat all available answers of a user question equally.  This paper proposes a novel approach based on multiple instance learning to address the problem of noisy answers by exploring consensus among answers to the same question in training end-to-end KBQA models. In particular, the QA pairs are organized into bags with dynamic instance selection and different options of instance weighting. Curriculum learning is utilized to select instance bags during training. On the public CQA dataset, the new method significantly improves both entity accuracy and the Rouge-L score over a state-of-the-art end-to-end KBQA baseline. % We also significantly outperform baselines % in accuracy and naturalness when the data is composed of both single- and multiple-answer % questions.  
 The goal of this paper is to simulate the benefits of jointly applying active learning  and semi-supervised training  in a new speech recognition application. Our data selection approach relies on confidence filtering, and its impact on both the acoustic and language models  is studied. While AL is known to be beneficial to AM training, we show that it also carries out substantial improvements to the LM when combined with SST. Sophisticated confidence models, on the other hand, did not prove to yield any data selection gain. Our results indicate that, while SST is crucial at the beginning of the labeling process, its gains degrade rapidly as AL is set in place. The final simulation reports that AL allows a transcription cost reduction of about 70\% over random selection. Alternatively, for a fixed transcription budget, the proposed approach improves the word error rate by about 12.5\% relative.   
 Multimodal language models attempt to incorporate non-linguistic features for the language modeling task. In this work, we extend a standard recurrent neural network  language model with features derived from videos. We train our models on data that is two orders-of-magnitude bigger than datasets used in prior work. We perform a thorough exploration of model architectures for combining visual and text features. Our experiments on two corpora  show that the best performing architecture consists of middle fusion of visual and text features, yielding over $25\%$ relative improvement in perplexity. We report analysis that provides insights into why our multimodal language model improves upon a standard RNN language model. 
 Multiple-choice reading comprehension  is the task of selecting the correct answer from multiple options given a question and an article. Existing MCRC models typically either read each option independently or compute a fixed-length representation for each option before comparing them. However, humans typically compare the options at multiple-granularity level before reading the article in detail to make reasoning more efficient. Mimicking humans, we propose an option comparison network  for MCRC which compares options at word-level to better identify their correlations to help reasoning. Specially, each option is encoded into a vector sequence using a skimmer to retain fine-grained information as much as possible. An attention mechanism is leveraged to compare these sequences vector-by-vector to identify more subtle correlations between options, which is potentially valuable for reasoning. Experimental results on the human English exam MCRC dataset RACE show that our model outperforms existing methods significantly. Moreover, it is also the first model that surpasses Amazon Mechanical Turker performance on the whole dataset. 
         When translating from a language that does not morphologically mark information such as gender and number into a language that does, translation systems must ``guess'' this missing information, often leading to incorrect translations in the given context. We propose a black-box approach for injecting the missing information to a pre-trained neural machine translation system, allowing to control the morphological variations in the generated translations without changing the underlying model or training data. We evaluate our method on an English to Hebrew translation task, and show that it is effective in injecting the gender and number information and that supplying the correct information improves the translation accuracy in up to 2.3 BLEU on a female-speaker test set for a state-of-the-art online black-box system. Finally, we perform a fine-grained syntactic analysis of the generated translations that shows the effectiveness of our method.      
 		The ambiguous annotation criteria lead to divergence of Chinese Word Segmentation  datasets in various granularities.  		Multi-criteria Chinese word segmentation aims to capture various annotation criteria among datasets and leverage their common underlying knowledge.  		In this paper, we propose a domain adaptive segmenter to exploit diverse criteria of various datasets. Our model is based on Bidirectional Encoder Representations from Transformers , which is responsible for introducing open-domain knowledge.  		Private and shared projection layers are proposed to capture domain-specific knowledge and common knowledge, respectively.  		We also optimize computational efficiency via distillation, quantization, and compiler optimization. Experiments show that our segmenter outperforms the previous state of the art  models on 10 CWS datasets with superior efficiency. 
 %The recent success of neural machine translation has sparked the interest in larger-context machine translation, of which representative examples have been document-level translation and multi-modal translation. Despite a growing number of newly proposed network architectures, the progress on both of these problems has been limited. In this paper, we propose a novel learning algorithm that explicitly encourages a larger-context neural translation model to take into account extra information supplied via additional context using multilevel pair-wise ranking loss. We evaluate the proposed learning algorithm with a transformer-based larger-context translation system on document-level translation and show that the proposed algorithm does indeed results in a larger-context model that does not ignore the additional context.  Interest in larger-context neural machine translation, including document-level and multi-modal translation, has been growing. Multiple works have proposed new network architectures or evaluation schemes, but potentially helpful context is still sometimes ignored by larger-context translation models. In this paper, we propose a novel learning algorithm that explicitly encourages a neural translation model to take into account additional context using a multilevel pair-wise ranking loss. We evaluate the proposed learning algorithm with a transformer-based larger-context translation system on document-level translation. By comparing performance using actual and random contexts, we show that a model trained with the proposed algorithm is more sensitive to the additional context.  %By comparing performance using actual and random contexts, we show that the proposed algorithm results in a model that is sensitive to the additional context.  
 Historical text normalization often relies on small training datasets. Recent work has shown that multi-task learning can lead to significant improvements by exploiting synergies with related datasets, but there has been no systematic study of different multi-task learning architectures. This paper evaluates 63~multi-task learning configurations for sequence-to-sequence-based historical text normalization across ten datasets from eight languages, using autoencoding, grapheme-to-phoneme mapping, and lemmatization as auxiliary tasks. We observe consistent, significant improvements across languages when training data for the target task is limited, but minimal or no improvements when training data is abundant. We also show that zero-shot learning outperforms the simple, but relatively strong, identity baseline.  
   We introduce a new syntax-aware model for dependency-based semantic role labeling that outperforms syntax-agnostic models for English and Spanish. We use a BiLSTM to tag the text with supertags extracted from dependency parses, and we feed these supertags, along with words and parts of speech, into a deep highway BiLSTM for semantic role labeling. Our model combines the strengths of earlier models that performed SRL on the basis of a full dependency parse with more recent  models that use no syntactic information at all. Our local and non-ensemble model achieves state-of-the-art performance on the CoNLL 09 English and Spanish datasets. SRL models benefit from syntactic information, and we show that supertagging is a simple, powerful, and robust way to incorporate syntax into a neural SRL system. 
 SemEval-2019 Task 6  requires us to identify and categorise offensive language in social media. In this paper we will describe the process we took to tackle this challenge. Our process is heavily inspired by  where he proposed CNN-LSTM and LSTM-CNN models to conduct twitter sentiment analysis. We decided to follow his approach as well as further his work by testing out different variations of RNN models with CNN. Specifically, we have divided the challenge into two parts: data processing and sampling and choosing the optimal deep learning architecture. In preprocessing, we experimented with two techniques, SMOTE and Class Weights to counter the imbalance between classes. Once we are happy with the quality of our input data, we proceed to choosing the optimal deep learning architecture for this task. Given the quality and quantity of data we have been given, we found that the addition of CNN layer provides very little to no additional improvement to our model's performance and sometimes even worsen our F1-score. In the end, the deep learning architecture that gives us the highest macro F1-score is a simple BiLSTM-CNN. 
 Financial market forecasting is one of the most attractive practical applications of sentiment analysis. In this paper, we investigate the potential of using sentiment   and also sentiment   extracted from financial news or tweets to help predict stock price movements. Our extensive experiments using the  test have revealed that  in general sentiment attitudes do not seem to Granger-cause stock price changes; and  while on some specific occasions sentiment emotions do seem to Granger-cause stock price changes, the exhibited pattern is not universal and must be looked at on a case by case basis. Furthermore, it has been observed that at least for certain stocks, integrating sentiment emotions as additional features into the machine learning based market trend prediction model could improve its accuracy. 
 Generating responses that are consistent with the dialogue context is one of the central challenges in building engaging conversational agents.  We demonstrate that neural conversation models can be geared towards generating consistent responses by maintaining certain features related to topics and personas throughout the conversation. Past work has required external supervision that exploits features such as user identities that are often unavailable. In our approach, topic and persona feature extractors are trained using a self-supervised discriminative training scheme that utilizes the natural structure of dialogue data.  We further adopt a feature disentangling loss which, paired with controllable response generation techniques, allows us to promote or demote certain learned topics and persona features.  Evaluation results demonstrate the model's ability to capture meaningful topics and persona features.  The incorporation of the learned features brings significant improvement in terms of the quality of generated responses on two datasets. 
 % Patent landscaping is a method that is employed for searching related patents during the process of a research and development~ project. To avoid the risk of patent infringement and to follow the current trends of technology development, patent landscaping is a crucial task that needs to be conducted during the early stages of an R\&D project. Generally, the process of patent landscaping requires several advanced resources and can be tedious. Furthermore, the patent landscaping process has to be repeated throughout the duration of an R\&D project. Owing to such reasons, the demand for automated patent landscaping is gradually increasing. However, the shortage of well-defined benchmarking datasets and comparable models makes it difficult to find related research studies.     Patent landscaping is a method used for searching related patents during a research and development  project. To avoid the risk of patent infringement and to follow current trends in technology, patent landscaping is a crucial task required during the early stages of an R\&D project. As the process of patent landscaping requires advanced resources and can be tedious, the demand for automated patent landscaping has been gradually increasing. However, a shortage of well-defined benchmark datasets and comparable models makes it difficult to find related research studies.  In this paper, we propose an automated patent landscaping model based on deep learning. To analyze the text of patents, the proposed model uses a modified transformer structure. To analyze the metadata of patents, we propose a graph embedding method that uses a diffusion graph called Diff2Vec. Furthermore, we introduce four benchmark datasets for comparing related research studies in patent landscaping. The datasets are produced by querying Google BigQuery, based on a search formula from a Korean patent attorney. The obtained results indicate that the proposed model and datasets can attain state-of-the-art performance, as compared with current patent landscaping models. % , and mean classification accuracy of 98\% can be achieved. 
 Generating an image from a given text description has two goals: visual realism and semantic consistency. Although significant progress has been made in generating high-quality and visually realistic images using generative adversarial networks, guaranteeing semantic consistency between the text description and visual content remains very challenging. In this paper, we address this problem by proposing a novel global-local attentive and semantic-preserving text-to-image-to-text framework called MirrorGAN. MirrorGAN exploits the idea of learning text-to-image generation by redescription and consists of three modules: a semantic text embedding module , a global-local collaborative attentive module for cascaded image generation , and a semantic text regeneration and alignment module . STEM generates word- and sentence-level embeddings. GLAM has a cascaded architecture for generating target images from coarse to fine scales, leveraging both local word attention and global sentence attention to progressively enhance the diversity and semantic consistency of the generated images. STREAM seeks to regenerate the text description from the generated image, which semantically aligns with the given text description. Thorough experiments on two public benchmark datasets demonstrate the superiority of MirrorGAN over other representative state-of-the-art methods.  
   With the tremendous growth in the number of scientific papers being published, searching for references while writing a scientific paper is a time-consuming process. A technique that could add a reference citation at the appropriate place in a sentence will be beneficial. In this perspective, context-aware citation recommendation has been researched upon for around two decades. Many researchers have utilized the text data called the context sentence, which surrounds the citation tag, and the metadata of the target paper to find the appropriate cited research. However, the lack of well-organized benchmarking datasets and no model that can attain high performance has made the research difficult.   In this paper, we propose a deep learning based model and well-organized dataset for context-aware paper citation recommendation. Our model comprises a document encoder and a context encoder, which uses Graph Convolutional Networks  layer and Bidirectional Encoder Representations from Transformers , which is a pre-trained model of textual data. By modifying the related PeerRead dataset, we propose a new dataset called FullTextPeerRead containing context sentences to cited references and paper metadata. To the best of our knowledge, This dataset is the first well-organized dataset for context-aware paper recommendation. The results indicate that the proposed model with the proposed datasets can attain state-of-the-art performance and achieve a more than 28\% improvement in mean average precision  and recall@k.  
 Lemmatization of standard languages is concerned with  abstracting over morphological differences and  resolving token-lemma ambiguities of inflected words in order to map them to a dictionary headword. In the present paper we aim to improve lemmatization performance on a set of non-standard historical languages in which the difficulty is increased by an additional aspect : spelling variation due to lacking orthographic standards. We approach lemmatization as a string-transduction task with an encoder-decoder architecture which we enrich with sentence context information using a hierarchical sentence encoder. We show significant improvements over the state-of-the-art when training the sentence encoder jointly for lemmatization and language modeling. Crucially, our architecture does not require POS or morphological annotations, which are not always available for historical corpora. Additionally, we also test the proposed model on a set of typologically diverse standard languages showing results on par or better than a model without enhanced sentence representations and previous state-of-the-art systems. Finally, to encourage future work on processing of non-standard varieties, we release the dataset of non-standard languages underlying the present study, based on openly accessible sources.%\todo{give a name to the data set}    %For such languages, NLP pipelines depend can hugely benefit from resolving token-lemma ambiguities and performing shallow morphological analysis of inflected forms. In the present paper we aim to improve lemmatization performance on a set of non-standard historical languages in which the difficulty is increased by an additional aspect: spelling variation due to non-existing writing standards. %   In order to obtain ..., we focus on Encoder-Decoder architectures, which have been recently shown to generally boost lemmatization performance  and are arguably more robust in the presence of spelling variation.      %   reassess the effectiveness of Encoder-Decoder architectures for lemmatization of modern languages with reference to their morphological typology.    
   Extractive summarization and imbalanced multi-label classification often require vast amounts of training data to avoid overfitting. In situations where training data is expensive to generate, leveraging information between tasks is an attractive approach to increasing the amount of available information. This paper employs multi-task training of an extractive summarizer and an RNN-based classifier to improve summarization and classification accuracy by 50\% and 75\%, respectively, relative to RNN baselines. We hypothesize that concatenating sentence encodings based on document and class context increases generalizability for highly variable corpuses.\footnote{Code and data is available on the author's {GitHub}.} 
 Multilingual Neural Machine Translation  models are capable of translating between multiple source and target languages. Despite various approaches to train such models, they have difficulty with zero-shot translation: translating between language pairs that were not together seen during training. In this paper we first diagnose why state-of-the-art multilingual NMT models that rely purely on parameter sharing, fail to generalize to unseen language pairs. We then propose auxiliary losses on the NMT encoder that impose representational invariance across languages. Our simple approach vastly improves zero-shot translation quality without regressing on supervised directions. For the first time, on WMT14 English-French-German, we achieve zero-shot performance that is on par with pivoting. We also demonstrate the easy scalability of our approach to multiple languages on the IWSLT 2017 shared task. 
  On the one hand, nowadays, fake news articles are easily propagated through various online media platforms and have become a grand threat to the trustworthiness of information. On the other hand, our understanding of the language of fake news is still minimal. Incorporating hierarchical discourse-level structure of fake and real news articles is one crucial step toward a better understanding of how these articles are structured. Nevertheless, this has rarely been investigated in the fake news detection domain and faces tremendous challenges. First, existing methods for capturing discourse-level structure rely on annotated corpora which are not available for fake news datasets. Second, how to extract out useful information from such discovered structures is another challenge. To address these challenges, we propose  Hierarchical Discourse-level Structure for Fake news detection. HDSF learns and constructs a discourse-level structure for fake/real news articles in an automated and data-driven manner. Moreover, we identify insightful structure-related properties, which can explain the discovered structures and boost our understating of fake news. Conducted experiments show the effectiveness of the proposed approach. Further structural analysis suggests that real and fake news present substantial differences in the hierarchical discourse-level structures.  
 We present a new approach for pretraining a bi-directional transformer model that provides significant performance gains across a variety of language understanding problems.  Our model solves a cloze-style word reconstruction task, where each word is ablated and must be predicted given the rest of the text.  Experiments demonstrate large performance gains on GLUE and new state of the art results on NER as well as constituency parsing benchmarks, consistent with the concurrently introduced BERT model. We also present a detailed analysis of a number of factors that contribute to effective pretraining, including data domain and size, model capacity, and variations on the cloze objective. 
  We propose a novel transition-based algorithm that straightforwardly parses sentences from left to right by building $n$ attachments, with $n$ being the length of the input sentence. Similarly to the recent stack-pointer parser by , we use the pointer network framework that, given a word, can directly point to a position from the sentence. However, our left-to-right approach is simpler than the original top-down stack-pointer parser  and reduces transition sequence length in half, from $2n-1$ actions to $n$. This results in a quadratic non-projective parser that runs twice as fast as the original while achieving the best accuracy to date on the English PTB dataset  among fully-supervised single-model dependency parsers, and improves over the former top-down transition system in the majority of languages tested.  
   This report contains the details regarding our submission to the OffensEval 2019  . The competition was based on the Offensive Language Identification Dataset . We first discuss the details of the classifier implemented and the type of input data used and pre-processing performed. We then move onto critically evaluating our performance. We have achieved a macro-average F1-score of 0.76, 0.68, 0.54, respectively for Task a, Task b, and Task c, which we believe reflects on the level of sophistication of the models implemented. Finally, we will be discussing the difficulties encountered and possible improvements for the future.  
 Despite the progress made in sentence-level NMT, current systems still fall short at achieving fluent, good quality translation for a full document. Recent works in context-aware NMT consider only a few previous sentences as context and may not scale to entire documents. To this end, we propose a novel and scalable top-down approach to hierarchical attention for context-aware NMT which uses sparse attention to selectively focus on relevant sentences in the document context and then attends to key words in those sentences. We also propose single-level attention approaches based on sentence or word-level information in the context. The document-level context representation, produced from these attention modules, is integrated into the encoder or decoder of the Transformer model depending on whether we use monolingual or bilingual context. Our experiments and evaluation on English-German datasets in different document MT settings show that our selective attention approach not only significantly outperforms context-agnostic baselines but also surpasses context-aware baselines in most cases.  %\andre{Should we mention selective attention  in the abstract? If we do some analysis that show interpretablity, we can claim here benefits in terms of interpretability as well. We need to make this abstract sound more exciting :)} 
   In this paper we propose four deep recurrent architectures to tackle the task of offensive tweet detection as well as further classification into targeting and subject of said targeting. Our architectures are based on LSTMs and GRUs, we present a simple bidirectional LSTM as a baseline system and then further increase the complexity of the models by adding convolutional layers and implementing a split-process-merge architecture with LSTM and GRU as processors. Multiple pre-processing techniques were also investigated. The validation F1-score results from each model are presented for the three subtasks as well as the final F1-score performance on the private competition test set. It was found that model complexity did not necessarily yield better results. Our best-performing model was also the simplest, a bidirectional LSTM; closely followed by a two-branch bidirectional LSTM and GRU architecture. 
 The response selection has been an emerging research topic due to the growing interest in dialogue modeling, where the goal of the task is to select an appropriate response for continuing dialogues. To further push the end-to-end dialogue model toward real-world scenarios, the seventh Dialog System Technology Challenge  proposed a challenge track based on real chatlog datasets. The competition focuses on dialogue modeling with several advanced characteristics:  natural language diversity,  capability of precisely selecting a proper response from a large set of candidates or the scenario without any correct answer, and  knowledge grounding. This paper introduces  , a novel framework for response selection, which can well estimate the relevance between the dialogue contexts and the candidates. The proposed RAP-Net is shown to be effective and can be generalize across different datasets and settings in the DSTC7 experiments.  
     With the increasing research interest in dialogue response generation, there is an emerging branch formulating this task as selecting next sentences, where given the partial dialogue contexts, the goal is to determine the most probable next sentence.   %In the seventh Dialog System Technology Challenge  , a task is set to selecting next sentence given partial conversation.      Following the recent success of the Transformer model , this paper proposes  a new variant of attention mechanism based on multi-head attention, called , and  a recurrent model based on transformer and the proposed highway attention, so-called .     % which is able to effectively model both utterance-level and dialogue-level information.     % In the proposed highway recurrent transformer, highway attention is applied recurrently to explicitly model the relationships between utterances in a conversation.     % To measure the model capability of selecting proper responses, we conduct the experiments on DSTC7 and analyze the effectiveness of each module.     Experiments on the response selection task in the seventh Dialog System Technology Challenge  show the capability of the proposed model of modeling both utterance-level and dialogue-level information; the effectiveness of each module is further analyzed as well. %    Finally, we show the effectiveness of such highway recurrent transformer by experiments. 
   The unsupervised text clustering is one of the major tasks in natural language processing  and remains a difficult and complex problem. Conventional \mbox{methods} generally treat this task using separated steps, including text representation learning and clustering the representations. As an improvement, neural methods have also been introduced for continuous representation learning to address the sparsity problem. However, the multi-step process still deviates from the unified optimization target. Especially the second step of cluster is generally performed with conventional methods such as k-Means.   We propose a pure neural framework for text clustering in an end-to-end manner. It jointly learns the text representation and the clustering model. Our model works well when the context can be obtained, which is nearly always the case in the field of NLP.  We have our method \mbox{evaluated} on two widely used benchmarks: IMDB movie reviews for sentiment classification and $20$-Newsgroup for topic categorization. Despite its simplicity, experiments show the model outperforms previous clustering methods by a large margin. Furthermore, the model is also verified on English wiki dataset as a large corpus. 
 End-to-end dialogue generation has achieved promising results without using handcrafted features and attributes specific for each task and corpus. However, one of the fatal drawbacks in such approaches is that they are unable to generate informative utterances, so it limits their usage from some real-world conversational applications. This paper attempts at generating diverse and informative responses with a variational generation model, which contains a joint attention mechanism conditioning on the information from both dialogue contexts and extra knowledge. 
  Current state-of-the-art NMT systems use large neural networks that are not only slow to train, but also often require many heuristics and optimization tricks, such as specialized learning rate schedules and large batch sizes. This is undesirable as it requires extensive hyperparameter tuning. In this paper, we propose a { of a sample and the current competence of the model. Filtering training samples in this manner prevents the model from getting stuck in bad local optima, making it converge faster and reach a better solution than the common approach of uniformly sampling training examples. Furthermore, the proposed method can be easily applied to existing NMT models by simply modifying their input data pipelines. We show that our framework can help improve the training time and the performance of both recurrent neural network models and Transformers, achieving up to a 70\% decrease in training time, while at the same time obtaining accuracy improvements of up to 2.2 BLEU.  
    So far, research to generate captions from images has been carried out from the viewpoint that a caption holds sufficient information for an image.    If it is possible to generate an image that is close to the input image from a generated caption, i.e., if it is possible to generate a natural language caption containing sufficient information to reproduce the image, then the caption is considered to be faithful to the image. To make such regeneration possible, learning using the cycle-consistency loss is effective. In this study, we propose a method of generating captions by learning end-to-end mutual transformations between images and texts. To evaluate our method, we perform comparative experiments with and without the cycle consistency. The results are evaluated by an automatic evaluation and crowdsourcing, demonstrating that our proposed method is effective.  
 Knowledge Bases  require constant updating to reflect changes to the world they represent. For general purpose KBs, this is often done through Relation Extraction , the task of predicting KB relations expressed in text mentioning entities known to the KB.  One way to improve RE is to use KB Embeddings  for link prediction. However, despite clear connections between RE and KBE, little has been done toward properly unifying these models systematically. We help close the gap with a framework that unifies the learning of RE and KBE models leading to significant improvements over the state-of-the-art in RE. The code is available at \url{https://github.com/billy-inn/HRERE}. 
 Grammatical error correction  is one of the areas in natural language processing in which purely neural models have not yet superseded more traditional symbolic models. Hybrid systems combining phrase-based statistical machine translation  and neural sequence models are currently among the most effective approaches to GEC. However, both SMT and neural sequence-to-sequence models require large amounts of annotated data. Language model based GEC  is a promising alternative which does not rely on annotated training data. We show how to improve LM-GEC by applying modelling techniques based on finite state transducers. We report further gains by rescoring with neural language models. We show that our methods developed for LM-GEC can also be used with SMT systems if annotated training data is available. Our best system outperforms the best published result on the CoNLL-2014 test set, and achieves far better relative improvements over the SMT baselines than previous hybrid systems. % 200 words max 
 We demonstrate that a character-level recurrent neural network is able to learn out-of-vocabulary  words under federated learning settings, for the purpose of expanding the vocabulary of a virtual keyboard for smartphones without exporting sensitive text to servers. High-frequency words can be sampled from the trained generative model by drawing from the joint posterior directly. We study the feasibility of the approach in two settings:  using simulated federated learning on a publicly available non-IID per-user dataset from a popular social networking website,  using federated learning on data hosted on user mobile devices. The model achieves good recall and precision compared to ground-truth OOV words in setting . With  we demonstrate the practicality of this approach by showing that we can learn meaningful OOV words with good character-level prediction accuracy and cross entropy loss.  
 %This paper studies textual style transfer, the task of rephrasing a text with a predefined style while retaining its original meaning.  We propose a reinforcement learning framework to tackle the challenge of unavailable parallel data. Our model has a generator-evaluator structure, where the generator transfers sentences into a target style and a set of evaluators to  provide feedback on different textual aspects  of generated sentences, such as content preservation, transfer strength and fluency. Each evaluator is adversarially trained to make accurate evaluations, and the interaction between the generator and the evaluators enables the generator to improve the quality of the transferred sentences. We find that our approach outperforms state-of-the-art style transfer systems on two tasks: sentiment transfer and informal-to-formal style transfer. %Specifically, the generator is an GRU based encoder-decoder design with attention mechanism; the style evaluator is a GAN based classifier with a bidirectional RNN; the semantic evaluator is based on word mover's distance; and the language model evaluator is a two-layer RNN. %when evaluated automatically and by humans. The transferred sentences are of good quality according to human annotations.   % Text style transfer rephrases a text from the source style  to the target style  while keeping its original meaning. Solving this problem is challenging when there is no parallel training corpus for the two styles. We address this challenge by using an ensemble architecture with a one-generator multi-evaluator structure. Here the role of the generator is to transfer a sentence from the source style to the target style, while that of the evaluators is to score the generated sentence for style, meaning preservation, and fluency. Our algorithm optimizes the combined evaluation score through a reinforcement learning framework to continuously improve the quality of the transferred sentences.  % Experimental results on two different style transfer tasks--sentiment transfer, and formality transfer--show that our model outperforms state-of-the-art approaches on these tasks.  Text style transfer rephrases a text from a source style  to a target style  while keeping its original meaning. Despite the success existing works have achieved using a parallel corpus for the two styles, transferring text style has proven significantly more challenging when there is no parallel training corpus. In this paper, we address this challenge by using a reinforcement-learning-based generator-evaluator architecture. Our generator employs an attention-based encoder-decoder to transfer a sentence from the source style to the target style. Our evaluator is an adversarially trained style discriminator with semantic and syntactic constraints that score the generated sentence for style, meaning preservation, and fluency. Experimental results on two different style transfer tasks  show that our model outperforms state-of-the-art approaches. Furthermore, we perform a manual evaluation that demonstrates the effectiveness of the proposed method using subjective metrics of generated text quality.  
 RNN models have achieved the state-of-the-art performance in a wide range of text mining tasks. However, these models are often regarded as black-boxes and are criticized due to the lack of interpretability. In this paper, we enhance the interpretability of RNNs by providing interpretable rationales for RNN predictions. Nevertheless, interpreting RNNs is a challenging problem. Firstly, unlike existing methods that rely on local approximation, we aim to provide rationales that are more faithful to the decision making process of RNN models. Secondly, a flexible interpretation method should be able to assign contribution scores to text segments of varying lengths, instead of only to individual words. To tackle these challenges, we propose a novel attribution method, called REAT, to provide interpretations to RNN predictions. REAT decomposes the final prediction of a RNN into additive contribution of each word in the input text. This additive decomposition enables REAT to further obtain phrase-level attribution scores. In addition, REAT is generally applicable to various RNN architectures, including GRU, LSTM and their bidirectional versions. Experimental results demonstrate the faithfulness and interpretability of the proposed attribution method. Comprehensive analysis shows that our attribution method could unveil the useful linguistic knowledge captured by RNNs. Some analysis further demonstrates our method could be utilized as a debugging tool to examine the vulnerability and failure reasons of RNNs, which may lead to several promising future directions to promote generalization ability of RNNs. 
 Current approaches to learning semantic representations of sentences often use prior word-level knowledge. The current study aims to leverage visual information in order to capture sentence level semantics without the need for word embeddings. We use a multimodal sentence encoder trained on a corpus of images with matching text captions to produce visually grounded sentence embeddings. Deep Neural Networks are trained to map the two modalities to a common embedding space such that for an image the corresponding caption can be retrieved and vice versa. We show that our model achieves results comparable to the current state-of-the-art on two popular image-caption retrieval benchmark data sets: MSCOCO and Flickr8k. We evaluate the semantic content of the resulting sentence embeddings using the data from the Semantic Textual Similarity benchmark task and show that the multimodal embeddings correlate well with human semantic similarity judgements. The system achieves state-of-the-art results on several of these benchmarks, which shows that a system trained solely on multimodal data, without assuming any word representations, is able to capture sentence level semantics. Importantly, this result shows that we do not need prior knowledge of lexical level semantics in order to model sentence level semantics. These findings demonstrate the importance of visual information in semantics. 
 % AMR-to-text generation is the task of generating sentences from AMR graphs.  % In order to use sequence-to-sequence architectures, AMR graphs can be converted into sequences. % A more direct approach requires the use of graph-to-sequence architectures, which obviate the need for this conversion and has been shown to improve performance. Unlike sequential encoding, graph encoding allows capturing reentrant structures in the AMR graphs explicitly.  % We investigate the extent to which reentrancies have an impact on AMR-to-text generation by comparing graph encoders with tree encoders, where reentrancies are not preserved. We show that improvements in dealing with reentrancies and long-range dependencies contribute to higher overall scores for graph encoders. AMR-to-text generation is a problem recently introduced to the NLP community, in which the goal is to generate sentences from Abstract Meaning Representation  graphs.  Sequence-to-sequence models can be used to this end by converting the AMR graphs to strings. Approaching the problem while working directly with graphs requires the use of graph-to-sequence models that encode the AMR graph into a vector representation. Such encoding has been shown to be beneficial in the past, and unlike sequential encoding, it allows us to explicitly capture reentrant structures in the AMR graphs. We investigate the extent to which reentrancies  have an impact on AMR-to-text generation by comparing graph encoders to tree encoders, where reentrancies are not preserved. We show that improvements in the treatment of reentrancies and long-range dependencies contribute to higher overall scores for graph encoders. Our best model achieves 24.40 BLEU on LDC2015E86, outperforming the state of the art by 1.1 points and 24.54 BLEU on LDC2017T10, outperforming the state of the art by 1.24 points.  
 % NE PAS EDITER  Current state of the art systems in NLP heavily rely on manually annotated datasets, which are expensive to construct. Very little work adequately exploits unannotated data -- such as discourse markers between sentences -- mainly because of data sparseness and ineffective extraction methods. In the present work, we propose a method to automatically discover sentence pairs with relevant discourse markers, and apply it to massive amounts of data. Our resulting dataset contains 174 discourse markers with at least 10{ or amazingly. We use the resulting data as supervision for learning transferable sentence embeddings.  In addition, we show that even though sentence representation learning through prediction of discourse markers yields state of the art results across different transfer tasks, it is not clear that our models made use of the semantic relation between sentences, thus leaving room for further improvements. Our datasets are publicly available \footnote{\url{https://github.com/synapse-developpement/Discovery}} % /NE PAS EDITER     
 Evaluating translation models is a trade-off between effort and detail. On the one end of the spectrum there are automatic count-based methods such as BLEU, on the other end linguistic evaluations by humans, which arguably are more informative but also require a disproportionately high effort. To narrow the spectrum, we propose a general approach on how to automatically expose systematic differences between human and machine translations to human experts. Inspired by adversarial settings,  we train a neural text classifier to distinguish human from machine translations. A classifier that performs and generalizes well after training should recognize systematic differences between the two classes, which we uncover with neural explainability methods. Our proof-of-concept implementation, DiaMaT, is open source. Applied to a dataset translated by a state-of-the-art neural Transformer model, DiaMaT achieves a classification accuracy of 75\% and exposes meaningful differences between humans and the Transformer, amidst the current discussion about human parity.  
 In the natural language processing literature, neural networks are becoming increasingly deeper and complex. The recent poster child of this trend is the deep language representation model, which includes BERT, ELMo, and GPT. These developments have led to the conviction that previous-generation, shallower neural networks for language understanding are obsolete. In this paper, however, we demonstrate that rudimentary, lightweight neural networks can still be made competitive without architecture changes, external training data, or additional input features. We propose to distill knowledge from BERT, a state-of-the-art language representation model, into a single-layer BiLSTM, as well as its siamese counterpart for sentence-pair tasks. Across multiple datasets in paraphrasing, natural language inference, and sentiment classification, we achieve comparable results with ELMo, while using roughly 100 times fewer parameters and 15 times less inference time.  
 % End-to-end learning has become an active research topic over the past few years in speech emotion recognition, due to its capability of automatic representation extraction from raw signals. However, Despite the increasing research interest in end-to-end learning systems for speech emotion recognition, conventional systems either suffer from the overfitting due in part to the limited training data, or do not explicitly consider the different contributions of automatically learnt representations for a specific task. In this contribution, we propose a novel end-to-end framework which is enhanced by learning other auxiliary tasks and an attention mechanism. That is,  we jointly train an end-to-end network with several different but related emotion prediction tasks, \ie arousal, valence, and dominance predictions, to extract more robust representations shared among various tasks than traditional systems with the hope that it is able to relieve the overfitting problem. Meanwhile, an attention layer is implemented on top of the layers for each task, with the aim to capture the contribution distribution of different segment parts for each individual task. To evaluate the effectiveness of the proposed system, we conducted a set of experiments on the widely used database IEMOCAP. The empirical results show that the proposed systems significantly outperform corresponding baseline systems.   
   The development of a fictional plot is centered around characters   who closely interact with each other forming dynamic social   networks. In literature analysis, such networks have mostly been   analyzed without particular relation types or focusing on roles   which the characters take with respect to each other. We argue that   an important aspect for the analysis of stories and their   development is the emotion between characters.  In this paper, we   combine these aspects into a unified framework to classify emotional   relationships of fictional characters. We formalize it as a new task   and describe the annotation of a corpus, based on fan-fiction short   stories. The extraction pipeline which we propose consists of   character identification    and the relation classification. For the latter, we provide results   using several approaches previously proposed for relation   identification with neural methods. The best result of 0.45 \F is   achieved with a GRU with character position indicators on the task   of predicting undirected emotion relations in the associated social   network graph. 
 %\boldmath Pitch detection is a fundamental problem in speech processing as F0 is used in a large number of applications. Recent articles have proposed deep learning for robust pitch tracking. In this paper, we consider voicing detection as a classification problem and F0 contour estimation as a regression problem. For both tasks, acoustic features from multiple domains and traditional machine learning methods are used. The discrimination power of existing and proposed features is assessed through mutual information. Multiple supervised and unsupervised approaches are compared. A significant relative reduction of voicing errors over the best baseline is obtained: 20\% with the best clustering method  and 45\% with a Multi-Layer Perceptron. For F0 contour estimation, the benefits of regression techniques are limited though. We investigate whether those objective gains translate in a parametric synthesis task. Clear perceptual preferences are observed for the proposed approach over two widely-used baselines .  
 We propose a distance  supervised  relation extraction approach  for long-tailed, imbalanced data which is prevalent in real-world settings. Here, the challenge is to learn accurate "few-shot" models for classes existing at the tail of the class distribution, for which little data is available. Inspired by the rich semantic correlations between classes at the long tail and those at the head, we take advantage of the knowledge  from data-rich classes at the head of the distribution to boost the performance of the data-poor classes at the tail.   First, we propose to leverage implicit  relational knowledge among class labels  from knowledge graph embeddings and  learn explicit   relational knowledge using graph  convolution  networks. Second, we integrate that relational knowledge into relation extraction model by coarse-to-fine knowledge-aware attention mechanism.  We demonstrate our results for a large-scale benchmark dataset which show that our approach significantly outperforms other baselines, especially for long-tail relations. 
 Attribute acquisition for classes is a key  step in ontology construction, which is often achieved  by community members manually. This paper investigates  an attention-based automatic paradigm called TransATT  for attribute acquisition, by learning the representation  of hierarchical classes and attributes in Chinese ontology.  The attributes of an entity can be acquired by merely  inspecting its classes, because the entity can be regard  as the instance of its classes and inherit their attributes.  For explicitly describing of the class of an entity unambiguously,  we propose class-path to represent the hierarchical  classes in ontology, instead of the terminal class word of the hypernym-hyponym relation   based hierarchy. The high performance of TransATT on attribute  acquisition indicates the promising ability of the learned  representation of class-paths and attributes. Moreover,  we construct a dataset named BigCilin11k. To the  best of our knowledge, this is the first Chinese dataset  with abundant hierarchical classes and entities with attributes. 
 Currently, many intelligence systems contain the texts from multi-sources, e.g., bulletin board system  posts, tweets and news. These texts can be ``comparative'' since they may be semantically correlated and thus provide us with different perspectives toward the same topics or events. To better organize the multi-sourced texts and obtain more comprehensive knowledge, we propose to study the novel problem of Mutual Clustering on Comparative Texts , which aims to cluster the comparative texts simultaneously and collaboratively. The MCCT problem is difficult to address because 1) comparative texts usually present different data formats and structures and thus they are hard to organize, and 2) there lacks an effective method to connect the semantically correlated comparative texts to facilitate clustering them in an unified way. To this aim, in this paper we propose a Heterogeneous Information Network-based Text clustering framework HINT. HINT first models multi-sourced texts  as heterogeneous information networks by introducing the shared ``anchor texts'' to connect the comparative texts. Next, two similarity matrices based on HINT as well as a transition matrix for cross-text-source knowledge transfer are constructed. Comparative texts clustering are then conducted by utilizing the constructed matrices. Finally, a mutual clustering algorithm is also proposed to further unify the separate clustering results of the comparative texts by introducing a clustering consistency constraint. We conduct extensive experimental on three tweets-news datasets, and the results demonstrate the effectiveness and robustness of the proposed method in addressing the MCCT problem. 
 Our goal in this work is to train an image captioning model that generates more dense and informative captions. We introduce ``relational captioning,'' a novel {image captioning} task which aims to generate multiple captions with respect to relational information between objects in an image. Relational captioning is a framework that is advantageous in both diversity and amount of information, leading to image understanding based on relationships. {Part-of-speech}  tags can be assigned to every English word. We leverage the POS as a prior to guide the correct sequence of words in a caption. To this end, we propose a multi-task triple-stream network  which consists of three recurrent units for the respective POS and jointly performs POS prediction and captioning.  We demonstrate more diverse and richer representations generated by the proposed model against several baselines and competing methods. The code is available at {https://github.com/Dong-JinKim/DenseRelationalCaptioning}. 
   We present Lemotif, an integrated natural language processing and image generation system that uses machine learning to  parse a text-based input journal entry describing the user's day for salient themes and emotions and  visualize the detected themes and emotions in creative and appealing image motifs. Synthesizing approaches from artificial intelligence and psychology, Lemotif acts as an affective visual journal, encouraging users to regularly write and reflect on their daily experiences through visual reinforcement. By making patterns in emotions and their sources more apparent, Lemotif aims to help users better understand their emotional lives, identify opportunities for action, and track the effectiveness of behavioral changes over time. We verify via human studies that prospective users prefer motifs generated by Lemotif over corresponding baselines, find the motifs representative of their journal entries, and think they would be more likely to journal regularly using a Lemotif-based app.    
 Collaborative filtering  is a core technique for recommender systems. Traditional CF approaches exploit user-item relations  only and hence they suffer from the data sparsity issue. Items are usually associated with unstructured text such as article abstracts and product reviews. We develop a Personalized Neural Embedding  framework to exploit both interactions and words seamlessly. We learn such embeddings of users, items, and words jointly, and predict user preferences on items based on these learned representations. PNE estimates the probability that a user will like an item by two terms---behavior factors and semantic factors. On two real-world datasets, PNE shows better performance than four state-of-the-art baselines in terms of three metrics. We also show that PNE learns meaningful word embeddings by visualization. 
 Automatic fact-checking systems detect misinformation, such as fake news, by  selecting  sentences for fact-checking,  gathering related information to the sentences, and  inferring the factuality of the sentences. Most prior research on  uses hand-crafted features to select check-worthy sentences, and does not explicitly account for the recent finding that the top weighted terms in both check-worthy and non-check-worthy sentences are actually overlapping . Motivated by this, we present a neural check-worthiness sentence ranking model that represents each word in a sentence by both its embedding  and its syntactic dependencies . Our model is an end-to-end trainable neural network for check-worthiness ranking, which is trained on large amounts of unlabelled data through weak supervision. Thorough experimental evaluation against state of the art baselines, with and without weak supervision, shows our model to be superior at all times . Empirical analysis of the use of weak supervision, word embedding pretraining on domain-specific data, and the use of syntactic dependencies of our model reveals that check-worthy sentences contain notably more identical syntactic dependencies than non-check-worthy sentences.  
 Reasoning is essential for the development of large knowledge graphs, especially for completion, which aims to infer new triples based on existing ones. Both rules and embeddings can be used for knowledge graph reasoning and they have their own advantages and difficulties. Rule-based reasoning is accurate and explainable but rule learning with searching over the graph always suffers from efficiency due to huge search space. Embedding-based reasoning is more scalable and efficient as the reasoning is conducted via computation between embeddings, but it has difficulty learning good representations for sparse entities because a good embedding relies heavily on data richness. Based on this observation, in this paper we explore how embedding and rule learning can be combined together and complement each other's difficulties with their advantages. We propose a novel framework IterE iteratively learning embeddings and rules, in which rules are learned from embeddings with proper pruning strategy and embeddings are learned from existing triples and new triples inferred by rules. Evaluations on embedding qualities of IterE show that rules help improve the quality of sparse entity embeddings and their link prediction results. We also evaluate the efficiency of rule learning and quality of rules from IterE compared with AMIE+, showing that IterE is capable of generating high quality rules more efficiently. Experiments show that iteratively learning embeddings and rules benefit each other during learning and prediction. 
 Yask is an online social collaborative network for practicing languages in a framework that includes requests, answers, and votes. Since measuring linguistic competence using current approaches is difficult, expensive and in many cases imprecise, we present a new alternative approach based on social networks. Our method, called Proficiency Rank, extends the well-known Page Rank algorithm to measure the reputation of users in a collaborative social graph. First, we extended Page Rank so that it not only considers positive links  but also negative links. Second, in addition to using explicit links, we also incorporate other 4 types of signals implicit in the social graph. These extensions allow Proficiency Rank to produce proficiency rankings for almost all users in the data set used, where only a minority contributes by answering, while the majority contributes only by voting. This overcomes the intrinsic limitation of Page Rank of only being able to rank the nodes that have incoming links. Our experimental validation showed that the reputation/importance of the users in Yask is significantly correlated with their language proficiency.In contrast, their written production was poorly correlated with the vocabulary profiles of the Common European Framework of Reference. In addition, we found that negative signals  are considerably more informative than positive ones. We concluded that the use of this technology is a promising tool for measuring second language proficiency, even for relatively small groups of people.    %  
 		Modern large-scale automation systems integrate thousands to hundreds of thousands of physical sensors and actuators. 		% 		Demands for more flexible reconfiguration of production systems and optimization across different information models, standards and legacy systems challenge current system interoperability concepts. 		% 		Automatic semantic translation across information models and standards is an increasingly important problem that needs to be addressed to fulfill these demands in a cost-efficient manner under constraints of human capacity and resources in relation to timing requirements and system complexity. 		% 		Here we define a translator-based operational interoperability model for interacting cyber-physical systems in mathematical terms, which includes system identification and ontology-based translation as special cases. 		% 		We present alternative mathematical definitions of the translator learning task and mappings to similar machine learning tasks and solutions based on 		% 		recent developments in machine learning. % 		% 		Possibilities to learn translators between artefacts without a common physical context, for example in simulations of digital twins and across layers of  		% 		the automation pyramid are briefly discussed. 		% 		% 	
  Active learning holds promise of significantly reducing data annotation costs while maintaining reasonable model performance. However, it requires sending data to annotators for labeling. This presents a possible privacy leak when the training set includes sensitive user data. In this paper, we describe an approach for carrying out privacy preserving active learning with quantifiable guarantees. We evaluate our approach by showing the tradeoff between privacy, utility and annotation budget on a binary classification task in a active learning setting.  
  Multilingual  embeddings represent several languages in a unique vector space. Using a common embedding space enables for a shared semantic between words from different languages. In this paper, we propose to embed images and texts into a unique distributional vector space, enabling to search images by using text queries expressing information needs related to the  content of images, as well as using image similarity. Our framework forces the representation of an image to be similar to the representation of the text that describes it. Moreover, by using multilingual embeddings we ensure that words from two different languages have close descriptors and thus are attached to similar images. We provide experimental evidence of the efficiency of our approach by experimenting it on two datasets: \gls{coco}~ and Multi30K~. 
 Combinatorial generalization - the ability to understand and produce novel combinations of already familiar elements - is considered to be a core capacity of the human mind and a major challenge to neural network models. A significant body of research suggests that conventional neural networks can閳ユ獩 solve this problem unless they are endowed with mechanisms specifically engineered for the purpose of representing symbols. In this paper we introduce a novel way of representing symbolic structures in connectionist terms - the vectors approach to representing symbols , which allows training standard neural architectures to encode symbolic knowledge explicitly at their output layers. In two simulations , we show that neural networks not only can learn to produce VARS representations, but in doing so they achieve combinatorial generalization in their symbolic and non-symbolic output. This adds to other recent work that has shown improved combinatorial generalization under specific training conditions, and raises the question of whether specific mechanisms or training routines are needed to support symbolic processing. 
   Recent studies have shown that text-to-speech synthesis quality can be improved by using glottal vocoding.  This refers to vocoders that parameterize speech into two parts, the glottal excitation and vocal tract, that occur in the human speech production apparatus. Current glottal vocoders generate the glottal excitation waveform by using deep neural networks . However, the squared error-based training of the present glottal excitation models is limited to generating conditional average waveforms, which fails to capture the stochastic variation of the waveforms. As a result, shaped noise is added as post-processing.   In this study, we propose a new method for predicting glottal waveforms by generative adversarial networks .  GANs are generative models that aim to embed the data distribution in a latent space, enabling generation of new instances very similar to the original by randomly sampling the latent distribution. The glottal pulses generated by GANs show a stochastic component similar to natural glottal pulses. In our experiments, we compare synthetic speech generated using glottal waveforms produced by both DNNs and GANs.   The results show that the newly proposed GANs achieve synthesis quality comparable to that of widely-used DNNs, without using an additive noise component.   
 The SpeakerBeam-FE  method is proposed for speaker extraction. It attempts to overcome the problem of unknown number of speakers in an audio recording during source separation. The mask approximation loss of SBF is sub-optimal, which doesn't calculate direct signal reconstruction error and consider the speech context. To address these problems, this paper proposes a magnitude and temporal spectrum approximation loss to estimate a phase sensitive mask for the target speaker with the speaker characteristics. Moreover, this paper explores a concatenation framework instead of the context adaptive deep neural network in the SBF method to encode a speaker embedding into the mask estimation network. Experimental results under open evaluation condition show that the proposed method achieves 70.4\% and 17.7\% relative improvement over the SBF baseline on signal-to-distortion ratio  and perceptual evaluation of speech quality , respectively. A further analysis demonstrates 69.1\% and 72.3\% relative SDR improvements obtained by the proposed method for different and same gender mixtures. 
 %The abstract is limited to 200 words. Recently, we proposed short-time Fourier transform -based loss functions for training a neural speech waveform model. In this paper, we generalize the above framework and propose a training scheme for such models based on spectral amplitude and phase losses obtained by either STFT or continuous wavelet transform , or both of them. Since CWT is capable of having time and frequency resolutions different from those of STFT and is cable of considering those closer to human auditory scales, the proposed loss functions could provide complementary information on speech signals. Experimental results showed that it is possible to train a high-quality model by using the proposed CWT spectral loss and is as good as one using STFT-based loss. 
 We present an approach to minimally supervised relation extraction that combines the benefits of learned representations and structured learning, and accurately predicts sentence-level relation mentions given only proposition-level supervision from a KB.  By explicitly reasoning about missing data during learning, our approach enables large-scale training of 1D convolutional neural networks while mitigating the issue of label noise inherent in distant supervision.  Our approach achieves state-of-the-art results on minimally supervised sentential relation extraction, outperforming a number of baselines, including a competitive approach that uses the attention layer of a purely neural model.\footnote{ Our code and data are publicly available on Github: \url{https://github.com/bflashcp3f/PCNN-NMAR}}    %Along the way, we replicate a number of experiments from prior work and clear up several points of potential confusion surrounding different versions of the popular New York Times / Freebase corpus used in prior work.     %We empirically show that our hybrid structured/neural approach is able to more effectively leverage larger text corpora and knowledge bases for minimally supervised mention-level relation extraction,    %We will make our code and data publicly available upon publication. 
   In the last decade, deep artificial neural networks have achieved   astounding performance in many natural language processing   tasks. Given the high productivity of language, these models must   possess effective generalization abilities. It is widely assumed   that humans handle linguistic productivity by means of algebraic   compositional rules: Are deep networks similarly compositional?   After reviewing the main innovations characterizing current deep   language processing networks, I discuss a set of studies suggesting   that deep networks are capable of subtle grammar-dependent   generalizations, but also that they do not rely on systematic   compositional rules. I argue that the intriguing behaviour of these   devices  should be of interest   to linguists and cognitive scientists, as it offers a new   perspective on possible computational strategies to deal with   linguistic productivity beyond rule-based compositionality, and it   might lead to new insights into the   less systematic generalization patterns that also appear in natural language.\\   \\   {}Keywords: artificial neural networks, deep   learning, linguistic productivity, compositionality 
 Recurrent neural networks  can model natural language by sequentially ''reading'' input tokens and outputting a distributed representation of each token. Due to the sequential nature of RNNs, inference time is linearly dependent on the input length, and all inputs are read regardless of their importance. Efforts to speed up this inference, known as ''neural speed reading'', either ignore or skim over part of the input. We present Structural-Jump-LSTM: the first neural speed reading model to both skip and jump text during inference. The model consists of a standard LSTM and two agents: one capable of skipping single words when reading, and one capable of exploiting punctuation structure , sentence end symbols , or end of text markers) to jump ahead after reading a word. A comprehensive experimental evaluation of our model against all five state-of-the-art neural reading models shows that  Structural-Jump-LSTM achieves the best overall floating point operations  reduction , while keeping the same accuracy or even improving it compared to a vanilla LSTM that reads the whole text. 
 In this work, we study abstractive text summarization by exploring different models such as LSTM-encoder-decoder with attention, pointer-generator networks, coverage mechanisms, and transformers. Upon extensive and careful hyperparameter tuning we compare the proposed architectures against each other for the abstractive text summarization task. Finally, as an extension of our work, we apply our text summarization model as a feature extractor for a fake news detection task where the news articles prior to classification will be summarized and the results are compared against the classification using only the original news text.   \\ {keywords:} LSTM, encoder-deconder, abstractive text summarization, pointer-generator, coverage mechanism, transformers, fake news detection 
Descriptive comments play a crucial role in the software engineering process. They decrease development time, enable better bug detection, and facilitate the reuse of previously written code. However, comments are commonly the last of a software developer's priorities and are thus either insufficient or missing entirely. Automatic source code summarization may therefore have the ability to significantly improve the software development process. We introduce a novel encoder-decoder model that summarizes source code, effectively writing a comment to describe the code's functionality. We make two primary innovations beyond current source code summarization models. First, our encoder is fully language-agnostic and requires no complex input preprocessing. Second, our decoder has an open vocabulary, enabling it to predict any word, even ones not seen in training. We demonstrate results comparable to state-of-the-art methods on a single-language data set and provide the first results on a data set consisting of multiple programming languages.
     %     We present JHU's system submission to the ASVspoof 2019 Challenge: Anti-Spoofing with Squeeze-Excitation and Residual neTworks .       Anti-spoofing has gathered more and more attention since the inauguration of the ASVspoof Challenges, and ASVspoof 2019 dedicates to address attacks from all three major types: text-to-speech, voice conversion, and replay.      Built upon previous research work on Deep Neural Network , ASSERT is a pipeline for DNN-based approach to anti-spoofing.     ASSERT has four components: feature engineering, DNN models, network optimization and system combination, where the DNN models are variants of squeeze-excitation and residual networks.     We conducted an ablation study of the effectiveness of each component on the ASVspoof 2019 corpus, and experimental results showed that ASSERT obtained more than $93\%$ and $17\%$ relative improvements over the baseline systems in the two sub-challenges in ASVspooof 2019, ranking ASSERT one of the top performing systems.      Code and pretrained models will be made publicly available.      
 Distributed word vector spaces are considered hard to interpret which hinders the understanding of natural language processing  models. In this work, we introduce a new method to interpret arbitrary samples from a word vector space. To this end, we train a neural model to conceptualize word vectors, which means that it activates higher order concepts it recognizes in a given vector.  Contrary to prior approaches, our model operates in the original vector space and is capable of learning non-linear relations between word vectors and concepts. Furthermore, we show that it produces considerably less entropic concept activation profiles than the popular cosine similarity. 
   Nowadays, more and more customers browse and purchase products in favor of using mobile E-Commerce Apps such as Taobao and Amazon. Since merchants are usually inclined to describe redundant and over-informative product titles to attract attentions from customers, it is important to concisely display short product titles on limited screen of mobile phones. To address this discrepancy, previous studies mainly consider textual information of long product titles and lacks of human-like view during training and evaluation process. In this paper, we propose a Multi-Modal Generative Adversarial Network  for short product title generation in E-Commerce, which innovatively incorporates image information and attribute tags from product, as well as textual information from original long titles. MM-GAN poses short title generation as a reinforcement learning process, where the generated titles are evaluated by the discriminator in a human-like view. Extensive experiments on a large-scale E-Commerce dataset demonstrate that our algorithm  outperforms other state-of-the-art methods. Moreover, we deploy our model into a real-world online E-Commerce environment and effectively boost the performance of click through rate and click conversion rate by 1.66\% and 1.87\%, respectively.   %improves the click through rate by 1.66\% and click conversion rate by 1.87\%, respectively.   % by a large margin 
 %Spoken language understanding  plays a crucial role in spoken dialog systems.  Typically, spoken language understanding  models are trained on annotated data which are costly to gather. Aiming to reduce data needs for bootstrapping a SLU system for a new language, we present  a simple but effective weight transfer approach using data from another language. The approach is evaluated with our promising multi-task SLU framework developed towards different languages. We evaluate our approach on the ATIS and a real-world SLU dataset, showing that i) our monolingual models outperform the state-of-the-art, ii) we can reduce data amounts needed for bootstrapping a SLU system for a new language greatly, and iii) while multi-task training improves over separate training, different weight transfer settings may work best for different SLU modules.  %Since our framework allows easy separation of modules even after multi-task training, it can be easily used to transfer with different settings and multi-task training, and afterwards modules with best performance can be extracted easily. 
 When building machine learning models that operate on source code, several decisions have to be made to model source-code vocabulary. These decisions can have a large impact: some can lead to not being able to train models at all, others significantly affect performance, particularly for Neural Language Models. Yet, these decisions are not often fully described. This paper lists important modeling choices for source code vocabulary, and explores their impact on the resulting vocabulary on a large-scale corpus of \numproj projects. We show that a subset of decisions have decisive characteristics, allowing to train accurate Neural Language Models quickly on a large corpus of \numprojtrain projects.  
 % In this work, we propose an unsupervised approach that can leverage the context similarity between co-references in a sentence for representation learning.  We use a simple yet efficient method to mine large-scale training samples from unlabeled corpus, to learn contextual representation that can then be utilized for pronoun disambiguation for common-sense reasoning. Experiments on two common-sense reasoning datasets show that without relying on any human-labeled data or external knowledge, our approach significantly outperforms state-of-the-art methods on pronoun disambiguation tasks, with a much smaller amount of unlabeled data.  %Key to our method is the contextual representation learned on a large amount of unlabeled corpora. %learned by comparing the similarity of a large amount of sequence pairs, which are constructed from unlabeled corpora.  %We use the contextual representation to score multiple choice questions in commonsense reasoning challenges.  %Without using any human-labeled data, hand-crafted features, or external knowledge bases, our method significantly outperforms previous state-of-the-art methods on both Pronoun Disambiguation and Winograd Schema challenges~. Compared with the previous deep learning method, our method is able to achieve the state-of-the-art performance at a faster speed and with a smaller amount of unlabeled data. %\xiaodl{Should we say less data? The advantage of unsupervised learning is to use more unlabeled data.} %} %Commonsense reasoning is an important task for natural language processing. Due to the large scale of commonsense knowledge in real life, it閳ユ獨 hard for human to list all of them. Instead, we will only make use of the sequence pair comparison from raw text to build context representation for solving commonsense reasoning. And we propose two directions, similarity and classification based methods, to train the LSTM-based context representations. Moreover, we test our models on the benchmark commonsense reasoning datasets: Pronoun Disambiguation Problems  and Winograd Schema Challenge~, and achieve the best performance on the two datasets.  
   We introduce deep inside-outside recursive autoencoders , a fully-unsupervised method for discovering syntax that simultaneously learns representations for constituents within the induced tree. Our approach predicts each word in an input sentence conditioned on the rest of the sentence and uses inside-outside dynamic programming to consider all possible binary trees over the sentence. At test time the CKY algorithm extracts the highest scoring parse. DIORA achieves a new state-of-the-art F1 in unsupervised binary constituency parsing  in two benchmark datasets, WSJ and MultiNLI. 
 Most current approaches to metaphor identification use restricted linguistic contexts, e.g.\ by considering only a verb's arguments or the sentence containing a phrase. Inspired by pragmatic accounts of metaphor, we argue that broader discourse features are crucial for better metaphor identification. We train simple gradient boosting classifiers on representations of an utterance and its surrounding discourse learned with a variety of document embedding methods, obtaining near state-of-the-art results on the 2018 VU Amsterdam metaphor identification task without the complex metaphor-specific features or deep neural architectures employed by other systems. A qualitative analysis further confirms the need for broader context in metaphor processing. 
 Generative adversarial networks  have shown considerable success, especially in the realistic generation of images. In this work, we apply similar techniques for the generation of text. We propose a novel approach to handle the discrete nature of text, during training, using word embeddings. Our method is agnostic to vocabulary size and achieves  competitive results relative to methods with various discrete gradient estimators. 
 English verbs have multiple forms. For instance, \word{talk} may also appear as \word{talks}, \word{talked} or \word{talking}, depending on the context. The NLP task of lemmatization seeks to map these diverse forms back to a canonical one, known as the lemma. We present a simple joint neural model for lemmatization and morphological tagging that achieves state-of-the-art results on 20 languages from the Universal Dependencies corpora. Our paper describes the model in addition to training and decoding procedures. Error analysis indicates that joint morphological tagging and lemmatization is especially helpful in low-resource lemmatization and languages that display a larger degree of morphological complexity. Code and pre-trained models are available at \url{https://sigmorphon.github.io/sharedtasks/2019/task2/}. 
 The overreliance on large parallel corpora significantly limits the applicability of machine translation systems to the majority of language pairs. Back-translation has been dominantly used in previous approaches for unsupervised neural machine translation, where pseudo sentence pairs are generated to train the models with a reconstruction loss. However, the pseudo sentences are usually of low quality as translation errors accumulate during training. To avoid this fundamental issue, we propose an alternative but more effective approach, extract-edit, to extract and then edit real sentences from the target monolingual corpora. Furthermore, we introduce a comparative translation loss to evaluate the translated target sentences and thus train the unsupervised translation systems. Experiments show that the proposed approach consistently outperforms the previous state-of-the-art unsupervised machine translation systems across two benchmarks  and two low-resource language pairs  by more than $2$  BLEU points. 
 Existing computational models to understand hate speech typically frame the problem as a simple classification task, bypassing the understanding of hate symbols  and their secret connotations. In this paper, we propose a novel task of deciphering hate symbols. To do this, we leverage the Urban Dictionary and collected a new, symbol-rich Twitter corpus of hate speech. We investigate neural network latent context models for deciphering hate symbols. More specifically, we study Sequence-to-Sequence models and show how they are able to crack the ciphers based on context. Furthermore, we propose a novel Variational Decipher and show how it can generalize better to unseen hate symbols in a more challenging testing setting.   
  Various NLP problems -- such as the prediction of sentence similarity, entailment, and discourse relations -- are all instances of the same general task: the modeling of semantic relations between a pair of textual elements. A popular model for such problems is to embed sentences into fixed size vectors, and use composition functions  of those vectors as features for the prediction.  At the same time, composition of embeddings has been a main focus within the field of Statistical Relational Learning  whose goal is to predict relations between entities . In this article, we show that previous work on relation prediction between texts implicitly uses compositions from baseline SRL models. We show that such compositions are not expressive enough for several tasks .  We build on recent SRL models to address textual relational problems, showing that they are more expressive, and can alleviate issues from simpler compositions. The resulting models significantly improve the state of the art in both transferable sentence representation learning and relation prediction. 
   We propose a fully convolutional sequence-to-sequence encoder architecture with a simple and efficient decoder. Our model improves WER on LibriSpeech while being an order of magnitude more efficient than a strong RNN baseline. Key to our approach is a time-depth separable convolution block which dramatically reduces the number of parameters in the model while keeping the receptive field large. We also give a stable and efficient beam search inference procedure which allows us to effectively integrate a language model. Coupled with a convolutional language model, our time-depth separable convolution architecture improves by more than 22\% relative WER over the best previously reported sequence-to-sequence results on the noisy LibriSpeech test set. 
 How are the meanings of linguistic expressions related to their use in concrete cognitive tasks? Visual identification tasks show human speakers can exhibit considerable variation in their understanding, representation and verification of certain quantifiers.  %Findings from this paradigm indicate that speakers' understanding of the quantifier ``most'' is highly context-dependent. This paper initiates an investigation into neural models of these psycho-semantic tasks.  We trained two types of network -- a convolutional neural network  model and a recurrent model of visual attention  -- on the ``most'' verification task from , manipulating the visual scene and novel notions of task duration.  Our results qualitatively mirror certain features of human performance  while differing in interesting ways .  We conclude by discussing the prospects for using neural models as cognitive models of this and other psychosemantic tasks. % how neural networks learn to verify context-dependent鑱絨uantifiers, with a long-term view towards developing neural-network based models of human quantifier verification. We trained neural networks to complete a variation on the visual identification task. This involved classifying a dot matrix stimulus in order to verify a corresponding "most" statement whilst we manipulated 3 variables, dot set ratio, dot arrangement and operationalised task duration. The experimental manipulations reflected contextual鑱絭ariables which have been shown to influence 閳ユ笗ost閳ユ獨" verification in human speakers. The鑱絥etworks' verification accuracy was measured. Two types of neural network models were鑱絬sed; . These were selected as each can operationalise some aspects of human vision and task duration.鑱絎e found that the dot set ratio and dot arrangement were significant predictors of the likelihood of a correct classification in both the CNN and RAM trials. Task duration was only a significant predictor of the likelihood of a correct classification in the CNN trials. We concluded that whilst our networks exhibit verification context-dependencies that are broadly similar to human speakers, these do not necessarily correspond to similar quantifier verification strategies. Methods to probe this discrepancy further are offered. 
 Success of deep learning techniques have renewed the interest in development of dialogue systems. However, current systems struggle to have consistent long term conversations with the users and fail to build rapport. Topic spotting, the task of automatically inferring the topic of a conversation, has been shown to be helpful in making a dialog system more engaging and efficient. We propose a hierarchical model with self attention for topic spotting. Experiments on the Switchboard corpus show the superior performance of our model over previously proposed techniques for topic spotting and deep models for text classification. Additionally, in contrast to offline processing of dialog, we also analyze the performance of our model in a more realistic setting i.e. in an online setting where the topic is identified in real time as the dialog progresses. Results show that our model is able to generalize even with limited information in the online setting. 
 In this paper, we present neural model architecture submitted to the SemEval-2019 Task 9 competition: "Suggestion Mining from Online Reviews and Forums". We participated in both subtasks for domain specific and also cross-domain suggestion mining. We proposed a recurrent neural network architecture that employs Bi-LSTM layers and also self-attention mechanism. Our architecture tries to encode words via word representations using ELMo and ensembles multiple models to achieve better results.  % We highlight importance of pre-processing of user-generated samples and its contribution to overall results.  We performed experiments with different setups of our proposed model involving weighting of prediction classes for loss function. Our best model achieved in official test evaluation score of 0.6816 for subtask A and 0.6850 for subtask B. In official results, we achieved 12th and 10th place in subtasks A and B, respectively. 
 Self-attention networks  have drawn increasing interest due to their high parallelization in computation and flexibility in modeling dependencies. SANs can be further enhanced with multi-head attention by allowing the model to attend to information from different representation subspaces. In this work, we propose novel convolutional self-attention networks, which offer SANs the abilities to 1) strengthen dependencies among neighboring elements, and 2) model the interaction between features extracted by multiple attention heads. Experimental results of machine translation on different language pairs and model settings show that our approach outperforms both the strong Transformer baseline and other existing models on enhancing the locality of SANs. Comparing with prior studies, the proposed model is parameter free in terms of introducing no more parameters.  
   Existing Machine Learning techniques yield close to human performance on text-based classification tasks. However, the presence of multi-modal noise in chat data such as emoticons, slang, spelling mistakes, code-mixed data, etc. makes existing deep-learning solutions perform poorly. The inability of deep-learning systems to robustly capture these covariates puts a cap on their performance. We propose NELEC : Neural and Lexical Combiner, a system which elegantly combines textual and deep-learning based methods for sentiment classification. We evaluate our system as part of the third task of 'Contextual Emotion Detection in Text' as part of SemEval-2019~. Our system performs significantly better than the baseline, as well as our deep-learning model benchmarks. It achieved a micro-averaged $F_{1}$ score of 0.7765, ranking $3^{rd}$ on the test-set leader-board. Our code is available at  
 % 200 words at most This paper proposes a novel unsupervised autoregressive neural model for learning generic speech representations. In contrast to other speech representation learning methods that aim to remove noise or speaker variabilities, ours is designed to preserve information for a wide range of downstream tasks. In addition, the proposed model does not require any phonetic or word boundary labels, allowing the model to benefit from large quantities of unlabeled data. Speech representations learned by our model significantly improve performance on both phone classification and speaker verification over the surface features and other supervised and unsupervised approaches. Further analysis shows that different levels of speech information are captured by our model at different layers. In particular, the lower layers tend to be more discriminative for speakers, while the upper layers provide more phonetic content. 
 Named entity recognition  systems that perform well require task-related and manually annotated datasets. However, they are expensive to develop, and are thus limited in size. As there already exists a large number of NER datasets that share a certain degree of relationship but differ in content, it is important to explore the question of whether such datasets can be combined as a simple method for improving NER performance. To investigate this, we developed a novel locally detecting multi-task model using FFNNs. The model relies on encoding variable-length sequences of words into theoretically lossless and unique fixed-size representations.  We applied this method to several well-known NER tasks and compared the results of our model to baseline models as well as other published results. As a result, we observed competitive performance in nearly all of the tasks. 
 Fine-tuning neural networks is widely used to transfer valuable knowledge from high-resource to low-resource domains.  In a standard fine-tuning scheme, source and target problems are trained using the same architecture.  %Hence, the trained units of the source network are used to initialise the target network.  Although capable of adapting to new domains, pre-trained units struggle with learning uncommon target-specific patterns.  In this paper, we propose to augment the target-network with normalised, weighted and randomly initialised units that beget a better adaptation while maintaining the valuable source knowledge.  Our experiments on POS tagging of social media texts  demonstrate that our method achieves state-of-the-art performances on 3 commonly used datasets.% in the Tweet domain.  %than the standard fine-tuning scheme. 
 Learning a shared dialog structure from a set of task-oriented dialogs is an important challenge in computational linguistics. The learned dialog structure can shed light on how to analyze human dialogs, and more importantly contribute to the design and evaluation of dialog systems. We propose to extract dialog structures using a modified VRNN model with discrete latent vectors. Different from existing HMM-based models, our model is based on variational-autoencoder . Such model is able to capture more dynamics in dialogs beyond the surface forms of the language. We find that qualitatively, our method extracts meaningful dialog structure, and quantitatively, outperforms previous models on the ability to predict unseen data. We further evaluate the model's effectiveness in a downstream task, the dialog system building task. Experiments show that, by integrating the learned dialog structure into the reward function design, the model converges faster and to a better outcome in a reinforcement learning setting.\footnote{The code is released at \url{https://github.com/wyshi/Unsupervised-Structure-Learning}} %And the dialog structure is modeled by the transition probabilities between different latent states. Besides interpretability, the learned dialog structure can also help to improve dialog system training process. First, the learned transition probability table can be used to build a more natural data-driven user simulator to assist dialog system building in reinforcement learning settings. Moreover, we find that by integrating the learned transition in reward functions, the model converges faster to a better outcome in reinforcement learning settings.  %and its variants are unsupervised VAE-based  model with discrete latent vectors to discover the latent dialog structure.  %to combine variational RNN  with Gumbel-Softmax and model the dialog structure using the discrete latent vector in VAE.  %Each conversational exchange is represented by a latent vector and later interpreted as a human-readable dialog act.  %user communication behaviours. % essential for provides insights on so that researchers can interpret user behaviors and build more natural dialog systems using the learned dialog structure.    %We propose to apply the learned dialog structure in the dialog system training. %We further propose to apply the learned dialog structure in the dialog system training process and evaluate its effectiveness in such a downstream task. %Furthermore, we also applied the learned dialog structure in a downstream dialog system building task. %We incorporate the learned structure into a downstream reinforcement learning task and shows   
   % What are the neural language models  and what makes them strong?   %The success of neural language models  is mainly attributed to its exceptional generalization capability achieved by simultaneously learning both probability distribution and dense representations of words.   The neural language models  achieve strong generalization capability by learning the dense representation of words and using them to estimate probability distribution function.   %However, learning representation of rare words, which have insufficient amount of training samples, is challenging problem which leads to unreliable probability estimates.   However, learning the representation of rare words is a challenging problem causing the NLM to produce unreliable probability estimates.   To address this problem, we propose a method to enrich representations of rare words in pre-trained NLM and consequently improve its probability estimation performance.   The proposed method augments the word embedding matrices of pre-trained NLM while keeping other parameters unchanged.   Specifically, our method updates the embedding vectors of rare words using embedding vectors of other semantically and syntactically similar words.   %Importantly, the proposed method doesn't require additional training data and expensive post-training procedures.   To evaluate the proposed method, we enrich the rare street names in the pre-trained NLM and use it to rescore $100$-best hypotheses output from the Singapore English speech recognition system.    %We evaluate the effectiveness of the proposed method on $n$-best hypotheses rescoring task for Singapore English speech recognition containing rare street names as a case study.   The enriched NLM reduces the word error rate by $6\%$ relative and improves the recognition accuracy of the rare words by $16\%$ absolute as compared to the baseline NLM.   %and achieve $6\%$ and $16\%$ relative word error rate improvements over the strong baseline NLM and Kneser-Ney smoothed 4-gram models, respectively.   \ifx %The neural language models  became indispensable component of speech recognition pipeline where it's used to rescore the $n$-best output hypotheses. The success of neural language models  is mainly attributed to its exceptional generalization capability achieved by simultaneously learning both probability distribution and dense representations of words. %Its success is mainly attributed to its exceptional generalization capability achieved by simultaneously learning both probability function and distributed representation of words. % What makes NLM's strength questionable and what is its consequences?  %However, learning representations of rare words with insufficient training samples remains challenging, leading to the sub-optimal performance of NLMs. However, learning representations of rare words remains challenging, leading to the sub-optimal performance of NLMs. The problem escalates when a rare word is a named entity such as names of persons or locations, which are important keywords for many downstream tasks. % How existing works address the problem? Currently, a common practice is to exclude the rare words from the vocabulary by treating them as out-of-vocabulary or to ignore the rare word problem and train the NLM with full vocabulary as usual. %In NLM, the common practice is to treat the rare words as out-of-vocabulary with unique representation or to break them down into finer level linguistic units. Instead, we propose to enrich the representations of rare words in pre-trained NLM by borrowing linguistic knowledge from related words. The proposed approach doesn't require additional training data and expensive post-training procedures. %We applied the proposed approach to enrich representations of Singapore street names in pretrained NLM and evaluated it on n-best rescoring task for the speech recognition system where consistent perplexity and word error rate improvements are achieved. The enriched NLM was evaluated on the $n$-best rescoring task for Singapore English speech recognition containing street names as a case study. \fi 
 This paper addresses the problem of key phrase extraction from sentences. %extracting question-answer pairs from sentences. % This paper addresses the task of extracting key phrases as well as their categories from domain-specific texts. Existing state-of-the-art supervised methods require large amounts of annotated data to achieve good performance and generalization.  Collecting labeled data is, however, often expensive. In this paper, we redefine the problem as question-answer extraction, and present SAMIE: Self-Asking Model for Information Extraction, a semi-supervised model which dually learns to ask and to answer questions by itself. Briefly, given a sentence $s$ and an answer $a$, the model needs to choose the most appropriate question $\hat q$; meanwhile, for the given sentence $s$ and same question $\hat q$ selected in the previous step, the model will predict an answer $\hat a$.  % The model can learn effectively with limited supervision, which allows it to perform few-shot learning. The model can support few-shot learning with very limited supervision. It can also be used to perform clustering analysis when no supervision is provided. Experimental results show that the proposed method outperforms typical supervised methods especially when given little labeled data. 
 The EMNLP 2018 workshop BlackboxNLP was dedicated to resources and techniques specifically developed for analyzing and understanding the inner-workings and representations acquired by neural models of language. Approaches included: systematic manipulation of input to neural networks and investigating the impact on their performance, testing whether interpretable knowledge can be decoded from intermediate representations acquired by neural networks, proposing modifications to neural network architectures to make their knowledge state or generated output more explainable, and examining the performance of networks on simplified or formal languages. Here we review a number of representative studies in each category. 
 Abuse on the Internet represents a significant societal problem of our time. Previous research on automated abusive language detection in Twitter has shown that community-based profiling of users is a promising technique for this task. However, existing approaches only capture shallow properties of online communities by modeling follower--following relationships. In contrast, working with graph convolutional networks , we present the first approach that captures not only the structure of online communities but also the linguistic behavior of the users within them. We show that such a heterogeneous graph-structured modeling of communities significantly advances the current state of the art in abusive language detection. 
  Producing a large annotated speech corpus for training ASR systems remains difficult for more than 95\% of languages all over the world which are low-resourced, but collecting a relatively big unlabeled data set for such languages is more achievable. This is why some initial effort have been reported on completely unsupervised speech recognition learned from unlabeled data only, although with relatively high error rates. In this paper, we develop a Generative Adversarial Network  to achieve this purpose, in which a Generator and a Discriminator learn from each other iteratively to improve the performance. We further use a set of Hidden Markov Models  iteratively refined from the machine generated labels to work in harmony with the GAN. The initial experiments on TIMIT data set achieve an phone error rate of 33.1\%, which is 8.5\% lower than the previous state-of-the-art.  
 Recurrent Neural Networks  have dominated language modeling because of their    superior performance over traditional \ngram based models. In   many applications, a large Recurrent Neural Network language model    or an ensemble of several \rnnlms is used. These models have large memory   footprints and require heavy computation. In this paper, we examine the effect   of applying knowledge distillation in reducing the model size for \rnnlms. In addition,   we propose a trust regularization method to improve the knowledge   distillation training for \rnnlms. Using knowledge distillation with trust   regularization, we reduce the parameter size to a third of that of the previously published best model while maintaining the state-of-the-art perplexity result on Penn Treebank data. In a speech recognition N-best rescoring task, we reduce the \rnnlm model size to $18.5\%$ of    the baseline system, with no degradation in word error rate  performance on Wall    Street Journal data set. 
 With the popularity of social networks, and e-commerce websites, sentiment analysis has become a more active area of research in the past few years.  On a high level, sentiment analysis tries to understand the public opinion about a specific product or topic, or trends from reviews or tweets.  Sentiment analysis plays an important role in better understanding customer/user opinion, and also extracting social/political trends. There has been a lot of previous works for sentiment analysis, some based on hand-engineering relevant textual features, and others based on different neural network architectures. In this work, we present a model based on an ensemble of  long-short-term-memory , and convolutional neural network , one to capture the temporal information of the data, and the other one to extract the local structure thereof.  Through experimental results, we show that using this ensemble model we can outperform both individual models. We are also able to achieve a very high accuracy rate compared to the previous works. 
 In this paper, we address three challenges in utterance-level emotion recognition in dialogue systems:  the same word can deliver different emotions in different contexts;  some emotions are rarely seen in general dialogues;  long-range contextual information is hard to be effectively captured.  We therefore propose a hierarchical Gated Recurrent Unit  framework with a lower-level GRU to model the word-level inputs and an upper-level GRU to capture the contexts of utterance-level embeddings.   Moreover, we promote the framework to two variants, HiGRU with individual features fusion  and HiGRU with self-attention and features fusion , so that the word/utterance-level individual inputs and the long-range contextual information can be sufficiently utilized.  Experiments on three dialogue emotion datasets, IEMOCAP, Friends, and EmotionPush demonstrate that our proposed HiGRU models attain at least 8.7\%, 7.5\%, 6.0\% improvement over the state-of-the-art methods on each dataset, respectively.  Particularly, by utilizing only the textual feature in IEMOCAP, our HiGRU models gain at least 3.8\% improvement over the state-of-the-art conversational memory network  with the trimodal features of text, video, and audio. 
 Multi-hop reasoning question answering requires deep comprehension of relationships between various documents and queries. We propose a Bi-directional Attention Entity Graph Convolutional Network ,  leveraging relationships between nodes in an entity graph and attention information between a query and the entity graph, to solve this task. Graph convolutional networks are used to obtain a relation-aware representation of nodes for entity graphs built from documents with multi-level features.  Bidirectional attention is then applied on graphs and queries to generate a query-aware nodes representation, which will be used for the final prediction. Experimental evaluation shows BAG achieves state-of-the-art accuracy performance on the QAngaroo WIKIHOP dataset. 
  Producing a large amount of annotated speech data for training ASR systems remains difficult for more than 95\% of languages all over the world which are low-resourced. However, we note human babies start to learn the language by the sounds  of a small number of exemplar words, and ``generalize" such knowledge to other words without hearing a large amount of data. We initiate some preliminary work in this direction. Audio Word2Vec is used to learn the phonetic structures from spoken words , while another autoencoder is used to learn the phonetic structures from text words. The relationships among the above two can be learned jointly, or separately after the above two are well trained. This relationship can be used in speech recognition with very low resource. In the initial experiments on the TIMIT dataset, only 2.1 hours of speech data  gave a word error rate of 44.6\%, and this number can be reduced to 34.2\% if 4.1 hr of speech data  were given. These results are not satisfactory, but a good starting point. 
 The paper presents a system developed for the SemEval-2019 competition Task 5 hatEval   and Task 6 OffensEval  , where we achieved $2^{nd}$ position in Subtask C. The system combines in an ensemble several models  with various embeddings  together with additional linguistic features . The system works with a multi-tier blacklist and a large corpus of crawled data, annotated for general offensiveness. In the paper we do an extensive analysis of our results and show how the combination of features and embedding affect the performance of the models.  
  We develop and investigate several cross-lingual alignment approaches for neural sentence embedding models, such as the supervised inference classifier, InferSent, and sequential encoder-decoder models. We evaluate three alignment frameworks applied to these models:  joint modeling, representation transfer learning, and sentence mapping, using parallel text to guide the alignment. Our results support representation transfer as a scalable approach for modular cross-lingual alignment of neural sentence embeddings, where we observe better performance compared to joint models in intrinsic and extrinsic evaluations, particularly with smaller sets of parallel data.   
 This paper deals with multi-lingual dialogue act  recognition.  The proposed approaches are based on deep neural networks and use word2vec embeddings for word representation. Two multi-lingual models are proposed for this task.  The first approach uses one general model trained on the embeddings from all available languages. The second method trains the model on a single pivot language and a linear transformation method is used to project other languages onto the pivot language. The popular convolutional neural network and LSTM architectures with different set-ups are used as classifiers. To the best of our knowledge this is the first attempt at multi-lingual DA recognition using neural networks.  The multi-lingual models are validated experimentally on two languages from the Verbmobil corpus.  
 When deploying a Chinese neural Text-to-Speech  system, one of the challenges is to synthesize Chinese utterances with English phrases or words embedded. This paper looks into the problem in the encoder-decoder framework when only monolingual data from a target speaker is available. Specifically, we view the problem from two aspects: speaker consistency within an utterance and naturalness. We start the investigation with an average voice model which is built from multi-speaker monolingual data, i.e., Mandarin and English data. On the basis of that, we look into speaker embedding for speaker consistency within an utterance and phoneme embedding for naturalness and intelligibility, and study the choice of data for model training. We report the findings and discuss the challenges to build a mixed-lingual TTS system with only monolingual data.  
 End-to-end text-to-speech  has shown great success on large quantities of paired text plus speech data. However, laborious data collection remains difficult for at least 95\% of the languages over the world, which hinders the development of TTS in different languages. In this paper, we aim to build TTS systems for such low-resource  languages where only very limited paired data are available. We show such TTS can be effectively constructed by transferring knowledge from a high-resource  language.   Since the model trained on source language cannot be directly applied to target language due to input space mismatch, we propose a method to learn a mapping between source and target linguistic symbols. Benefiting from this learned mapping, pronunciation information can be preserved throughout the transferring procedure. Preliminary experiments show that we only need around 15 minutes of paired data to obtain a relatively good TTS system. Furthermore, analytic studies demonstrated that the automatically discovered mapping correlate well with the phonetic expertise. 
   Titles of short sections within long documents support readers by guiding their focus towards relevant passages and by providing anchor-points that help to understand the progression of the document. The positive effects of section titles are even more pronounced when measured on readers with less developed reading abilities, for example in communities with limited labeled text resources.    We, therefore, aim to develop techniques to generate section titles in low-resource environments. In particular, we present an extractive pipeline for section title generation by first selecting the most salient sentence and then applying deletion-based compression.   Our compression approach is based on a Semi-Markov Conditional Random Field that leverages unsupervised word-representations such as ELMo or BERT, eliminating the need for a complex encoder-decoder architecture.    The results show that this approach leads to competitive performance with sequence-to-sequence models with high resources, while strongly outperforming it with low resources. In a human-subject study across subjects with varying reading abilities, we find that our section titles improve the speed of completing comprehension tasks while retaining similar accuracy.  
 Text  generation  with  generative  adversarial networks    can  be  divided  into  the text-based  and  code-based  categories  according to the type of signals used for discrimination. In this work, we introduce a novel text-based approach called Soft-GAN to effectively exploit GAN setup for text generation. We demonstrate how autoencoders  can be used for  providing a continuous representation of sentences, which we will refer to as soft-text. This soft representation will be used in GAN discrimination to synthesize similar soft-texts. We also propose hybrid latent code and text-based GAN  }) approaches with one or more discriminators, in which a combination of the latent code and the soft-text is used for GAN discriminations. We perform a number of subjective and objective experiments on two well-known datasets  to validate our techniques. We discuss the results using several evaluation metrics and show that the proposed techniques outperform the traditional GAN-based text-generation methods. 
 It is known that a deep neural network model pre-trained with large-scale data  greatly improves the accuracy of various tasks, especially when there are resource constraints. However, the information needed to solve a given task can vary, and simply using the output of the final layer is not necessarily sufficient. Moreover, to our knowledge, exploiting large language representation models to detect grammatical errors has not yet been studied. %We hypothesize that using the information of the layers suitable for a given task improves the accuracy of a model that uses a generic pre-trained language representation. In this work, we investigate the effect of utilizing information not only from the final layer but also from intermediate layers of a pre-trained language representation model to detect grammatical errors.  We propose a multi-head multi-layer attention model that determines the appropriate layers in Bidirectional Encoder Representation from Transformers . The proposed method achieved the best scores on three datasets for grammatical error detection tasks, outperforming the current state-of-the-art method by 6.0 points on FCE, 8.2 points on CoNLL14, and 12.2 points on JFLEG in terms of $\rm F_{0.5}$. %Our detailed analysis shows that proposed model successfully utilizes information from various layers. We also demonstrate that by using multi-head multi-layer attention, our model can exploit a broader range of information for each token in a sentence than a model that uses only the final layer's information.  
 While it is well-documented that climate change accepters and deniers have become increasingly polarized in the United States over time , there has been no large-scale examination of whether these individuals are prone to changing their opinions as a result of natural external occurrences. On the sub-population of Twitter users, we examine whether climate change sentiment changes in response to five separate natural disasters occurring in the U.S. in 2018.  We begin by showing that relevant tweets can be classified with over 75\% accuracy as either accepting or denying climate change when using our methodology to compensate for limited labeled data; results are robust across several machine learning models and yield geographic-level results in line with prior research .  We then apply RNNs to conduct a cohort-level analysis showing that the 2018 hurricanes yielded a statistically significant increase in average tweet sentiment affirming climate change. However, this effect does not hold for the 2018 blizzard and wildfires studied, implying that Twitter users' opinions on climate change are fairly ingrained on this subset of natural disasters. 
 For our submission to the ZeroSpeech 2019 challenge, we apply discrete latent-variable neural networks to unlabelled speech and use the discovered units for speech synthesis. Unsupervised discrete subword modelling could be useful for studies of phonetic category learning in infants or in low-resource speech technology requiring symbolic input. We use an autoencoder~ architecture with intermediate discretisation. We decouple acoustic unit discovery from speaker modelling by conditioning the AE's decoder on the training speaker identity. At test time, unit discovery is performed on speech from an unseen speaker, followed by unit decoding conditioned on a known target speaker to obtain reconstructed filterbanks. This output is fed to a neural vocoder to synthesise speech in the target speaker's voice. For discretisation, categorical variational autoencoders , vector-quantised VAEs  and straight-through estimation are compared at different compression levels on two languages. Our final model uses convolutional encoding, VQ-VAE discretisation, deconvolutional decoding and an FFTNet vocoder. We show that decoupled speaker conditioning intrinsically improves discrete acoustic representations, yielding competitive synthesis quality compared to the challenge baseline. $^*$These authors contributed equally. The other authors contributed to this work during a two-week coding sprint at Stellenbosch University.} 
   In this paper we revisit the problem of automatically identifying hate speech in posts from social media. We approach the task using a system based on minimalistic compositional Recurrent Neural Networks . We tested our approach on the SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter  shared task dataset. The dataset made available by the HatEval organizers contained English and Spanish posts retrieved from Twitter annotated with respect to the presence of hateful content and its target. In this paper we present the results obtained by our system in comparison to the other entries in the shared task. Our system achieved competitive performance ranking 7\textsuperscript{th} in sub-task A out of 62 systems in the English track. 
 The use of subword-level information  has become ubiquitous in modern word representation learning. Its importance is attested especially for morphologically rich languages which generate a large number of rare words. Despite a steadily increasing interest in such subword-informed word representations, their systematic comparative analysis across typologically diverse languages and different tasks is still missing. In this work, we deliver such a study focusing on the variation of two crucial components required for subword-level integration into word representation models: 1) segmentation of words into subword units, and 2) subword composition functions to obtain final word representations. We propose a general framework for learning subword-informed word representations that allows for easy experimentation with different segmentation and composition components, also including more advanced techniques based on position embeddings and self-attention. Using the unified framework, we run experiments over a large number of subword-informed word representation configurations  on 3 tasks  for 5 languages representing 3 language types. Our main results clearly indicate that there is no ``one-size-fits-all'' configuration, as performance is both language- and task-dependent. We also show that configurations based on unsupervised segmentation  are sometimes comparable to or even outperform the ones based on supervised word segmentation. 
 In recent years, the generation of conversation content based on deep neural networks has attracted many researchers. However, traditional neural language models tend to generate general replies, lacking logical and emotional factors. This paper proposes a conversation content generation model that combines reinforcement learning with emotional editing constraints to generate more meaningful and customizable emotional replies. The model divides the replies into three clauses based on pre-generated keywords and uses the emotional editor to further optimize the final reply. The model combines multi-task learning with multiple indicator rewards to comprehensively optimize the quality of replies. Experiments shows that our model can not only improve the fluency of the replies, but also significantly enhance the logical relevance and emotional relevance of the replies. 
     Advances in variational inference enable parameterisation of probabilistic models by deep neural networks. This combines the statistical transparency of the probabilistic modelling framework with the representational power of deep learning.      Yet, due to a problem known as , it is difficult to estimate such models in the context of language modelling effectively. %     We concentrate on one such model, the variational auto-encoder, which we argue is an important building block in hierarchical probabilistic models of language.      This paper contributes a sober view of the problem, a survey of techniques to address it, novel techniques, and extensions to the model.      To establish a ranking of techniques, we perform a systematic comparison using Bayesian optimisation and find that many techniques perform reasonably similar, given enough resources. Still, a favourite can be named based on convenience. We also make several empirical observations and recommendations of best practices that should help researchers interested in this exciting field. 
 We propose a novel method for generating titles for unstructured text documents. We reframe the problem as a sequential question-answering task. A deep neural network is trained on document-title pairs with decomposable titles, meaning that the vocabulary of the title is a subset of the vocabulary of the document. To train the model we use a corpus of millions of publicly available document-title pairs: news articles and headlines. We present the results of a randomized double-blind trial in which subjects were unaware of which titles were human or machine-generated. When trained on approximately 1.5 million news articles, the model generates headlines that humans judge to be as good or better than the original human-written headlines in the majority of cases. 
 This paper studies the performance of a neural self-attentive parser on transcribed speech. Speech presents parsing challenges that do not appear in written text, such as the lack of punctuation and the presence of speech disfluencies .  Disfluencies are especially problematic for conventional syntactic parsers, which typically fail to find any EDITED disfluency nodes at all.  This motivated the development of special disfluency detection systems, and special mechanisms added to parsers specifically to handle disfluencies. However, we show here that neural parsers can find EDITED disfluency nodes, and the best neural parsers find them with an accuracy surpassing that of specialized disfluency detection systems, thus making these specialized mechanisms unnecessary. This paper also investigates a modified loss function that puts more weight on EDITED nodes. It also describes tree-transformations that simplify the disfluency detection task by providing alternative encodings of disfluencies and syntactic information\footnote{\url{https://github.com/pariajm/joint-disfluency-detector-and-parser}}.  %This paper studies the performance of a neural self-attentive parser on transcribed speech. Speech presents parsing challenges that do not appear in written text, such as the lack of punctuation and the presence of speech disfluencies .  Disfluencies are especially problematic for conventional syntactic parsers, which typically fail to find any ``EDITED'' disfluency nodes at all.  This motivated the development of special disfluency detection  systems, and special mechanisms added to parsers specifically to handle disfluencies. However, we show here that neural parsers can find ``EDITED'' disfluency nodes, and the best neural parsers find them with an accuracy surpassing that of specialized disfluency detection systems, thus making these specialized mechanisms  unnecessary. While the parser's ``out-of-the-box'' disfluency detection performance is already state-of-the-art, we describe two innovations that improve it still further: a training loss that puts more weight on EDITED nodes, and word embeddings that combine a character LSTM and ELMO. We also describe tree-transformations that simplify the disfluency detection task by providing alternative encodings of disfluencies and syntactic information.         %Parsing transcribed speech presents several challenges absent in written text: lack of punctuations, recognition errors and presence of disfluencies . Disfluencies are particularly problematic for parsing systems as they are different in character than other constituents. As a result, most systems incorporate a separate disfluency detection stage prior to parsing. In this paper, we show that a self-attentive constituency parser not only effectively parses transcribed speech but also detects edited nodes containing disfluencies. Our empirical results also demonstrate that the performance of self-attentive parser is competitive with work that directly optimize for disfluency detection, resulting in new state-of-the-art in disfluency detection, as well as parsing speech transcripts.  
 Recurrent Neural Networks , Long Short-Term Memory Networks , and Memory Networks which contain memory are popularly used to learn patterns in sequential data.  Sequential data has long sequences that hold relationships. RNN can handle long sequences but suffers from the vanishing and exploding gradient problems. While LSTM and other memory networks address this problem, they are not capable of handling long sequences . Language modelling requiring learning from longer sequences are affected by the need for more information in memory. This paper introduces Long Term Memory network , which can tackle the exploding and vanishing gradient problems and handles long sequences without forgetting. LTM is designed to scale data in the memory and gives a higher weight to the input in the sequence. LTM avoid overfitting by scaling the cell state after achieving the optimal results. The LTM is tested on Penn treebank dataset, and Text8 dataset and LTM achieves test perplexities of 83 and 82 respectively. 650 LTM cells achieved a test perplexity of 67 for Penn treebank, and 600 cells achieved a test perplexity of 77 for Text8. LTM achieves state of the art results by only using ten hidden LTM cells for both datasets. 
 Programmers typically organize executable source code using high-level coding patterns or idiomatic structures such as nested loops, exception handlers and recursive blocks, rather than as individual code tokens. In contrast, state of the art  semantic parsers still map natural language instructions to source code by building the code syntax tree one node at a time. In this paper, we introduce an iterative method to extract code idioms from large source code corpora by repeatedly collapsing most-frequent depth-2 subtrees of their syntax trees, and train semantic parsers to apply these idioms during decoding. Applying idiom-based decoding on a recent context-dependent semantic parsing task improves the SOTA by 2.2\% BLEU score while reducing training time by more than 50\%. This improved speed enables us to scale up the model by training on an extended training set that is 5$\times$ larger, to further move up the SOTA by an additional 2.3\% BLEU and 0.9\% exact match. Finally, idioms also significantly improve accuracy of semantic parsing to SQL on the ATIS-SQL dataset, when training data is limited.  %We apply this idiom-based code generation to two recent tasks.    
 The author-specific word usage is a vital feature to let readers perceive the writing style of the author. In this work, a personalized sentence generation method based on generative adversarial networks  is proposed to cope with this issue. The frequently used function word and content word are incorporated not only as the input features but also as the sentence structure constraint for the GAN training. For the sentence generation with the related topics decided by the user, the Named Entity Recognition  information of the input words is also used in the network training. We compared the proposed method with the GAN-based sentence generation methods, and the experimental results showed that the generated sentences using our method are more similar to the original sentences of the same author based on the objective evaluation such as BLEU and SimHash score.   
  Distributed representations of words which map each word to a continuous vector have proven useful in capturing important linguistic information not only in a single language but also across different languages. Current unsupervised adversarial approaches show that it is possible to build a mapping matrix that align two sets of monolingual word embeddings together without high quality parallel data such as a dictionary or a sentence-aligned corpus. However, without post refinement, the performance of these methods' preliminary mapping is not good, leading to poor performance for typologically distant languages.  In this paper, we propose a weakly-supervised adversarial training method to overcome this limitation, based on the intuition that mapping across languages is better done at the concept level than at the word level. We propose a concept-based adversarial training method which for most languages improves the performance of previous unsupervised adversarial methods, especially for typologically distant language pairs.  
 Previous studies have shown that neural machine translation  models can benefit from explicitly modeling translated  and untranslated  source contents as recurrent states~.  However, this less interpretable recurrent process hinders its power to model the dynamic updating of \past\ and \future\ contents during decoding. In this paper, we propose to model the dynamic principles by explicitly separating source words into groups of translated and untranslated contents through parts-to-wholes assignment. The assignment is learned through a novel variant of routing-by-agreement mechanism~, namely { the routing process to assign each source word to its associated group   represented by a capsule, enabling translation to be made from holistic context. Experiments show that our approach achieves substantial improvements over both Rnmt and Transformer by producing more adequate translations. Extensive analysis demonstrates that our method is highly interpretable, which is able to recognize the translated and untranslated contents as expected.\footnote{Codes are released at \url{https://github.com/zhengzx-nlp/dynamic-nmt}.} % is not powerful enough to model and exploit these dynamically changing states for NMT. %However, it is still challenging to separate source words into either \past\ and \future\ group explicitly concerning each decoding step. %We hold that this explicit separation could be more interpretable and beneficial for NMT models to recognize the time-dependent source context, and propose to formulate it as a parts-to-wholes assignment, where the source words  should be assigned to either \past\ or \future\ .  %\SJ{You don't take this credit?}\zzx{Done.}  %with the dynamic routing mechanism,  % famous for its appealing strength of solving the problem of parts-to-wholes assignment   %depending on what to be translated at the current decoding step. \SJ{where is the point of guided?}   %, while it can produce better and more adequate translations. % and alleviate the problem \SJ{do we have to mention that?} of inadequate translation \zzx{inadequate may be better. because there is seldom over-translation problem in Transformer-related models in our exp}.     %  Ieln this paper, we follow this research path and propose to use capsule network and routing-by-agreement mechanism as an advanced alternative for distinguishing Past and Future, where the past and future contents are modeled by a group of capsules, respectively.  % \zptu{Why use capsule networks? How can their strength help modeling past and future?} %  The capsules aggregate relevant parts of source information by iterative routing, depending on what to translate at present.  %  Experiments on different translation tasks of three language pairs show that our proposed approach achieve substantial improvements over both RNMT and Transformer. Extensive analysis further verifies that our method does retrieves and separates translated and untranslated contents, and alleviate the widely noticed problem of inadequate translation.   
 Despite considerable advances in neural language modeling, it remains an open question what the best  is for text generation from a language model . The counter-intuitive empirical observation is that even though the use of likelihood as training objective leads to high quality models for a broad range of language understanding tasks,  maximization-based decoding methods such as beam search lead to  --- output text that is bland, incoherent, or gets stuck in repetitive loops.   To address this we propose Nucleus Sampling, a simple but effective method to draw  considerably higher quality text out of neural language models than previous decoding strategies.  Our approach avoids text generation by truncating the unreliable tail of the probability distribution, sampling from the dynamic nucleus of tokens containing the vast majority of the probability mass.  To properly examine current maximization-based and stochastic decoding methods, we compare generations from each of these methods to the distribution of human text along several axes such as likelihood, diversity, and repetition. Our results show that  maximization is an inappropriate decoding objective for open-ended text generation,  the probability distributions of the best current language models have an unreliable tail which needs to be truncated during generation and  Nucleus Sampling is currently the  best available  decoding strategy for generating long-form text that is both high-quality --- as measured by human evaluation --- and as diverse as human-written text. 
 Blame games tend to follow major disruptions, be they financial crises, natural disasters or terrorist attacks. To study how the blame game evolves and shapes the dominant crisis narratives is of great significance, as sense-making processes can affect regulatory outcomes, social hierarchies, and cultural norms. However, it takes tremendous time and efforts for social scientists to manually examine each relevant news article and extract the blame ties . In this study, we define a new task, Blame Tie Extraction, and construct a new dataset related to the United States financial crisis  from { and USA Today. We build a Bi-directional Long Short-Term Memory  network for contexts where the entities appear in and it learns to automatically extract such blame ties at the document level. Leveraging the large unsupervised model such as GloVe and ELMo, our best model achieves an F1 score of 70\% on the test set for blame tie extraction, making it a useful tool for social scientists to extract blame ties more efficiently. 
 Machine translation systems are conventionally trained on textual resources that do not model phenomena that occur in spoken language. While the evaluation of neural machine translation systems on textual inputs is actively researched in the literature, little has been discovered about the complexities of translating spoken language data with neural models. We introduce and motivate interesting problems one faces when considering the translation of automatic speech recognition  outputs on neural machine translation  systems. We test the robustness of sentence encoding approaches for NMT encoder-decoder modeling, focusing on word-based over byte-pair encoding. % Treating the outputs of multiple ASR systems as a source of noise that impacts translation quality, We compare the translation of utterances containing ASR errors in  state-of-the-art NMT encoder-decoder systems against a strong phrase-based machine translation baseline in order to better understand which phenomena present in ASR outputs are better represented under the NMT framework than approaches that represent translation as a linear model.  Index Terms: speech translation, machine translation, evaluation, neural machine translation  
 When analyzing the spread of viruses, epidemiologists often need to identify the location of  infected hosts. This information can be found in public databases, such as GenBank~, however, information provided in these databases are usually limited to the country or state level. More fine-grained localization information requires phylogeographers to manually read relevant scientific articles. In this work we propose an approach to automate the process of place name identification from medical  articles.  The focus of this paper is to propose a deep learning based model for toponym detection and experiment with the use of external linguistic features and domain specific information.  The model was evaluated using a collection of $105$ epidemiology articles from PubMed Central~ provided by the recent SemEval task $12$~. Our best detection model achieves an F1 score of $80.13\%$, a significant improvement compared to the state of the art of $69.84\%$. These results underline the importance of  domain specific embedding as well as specific linguistic features in toponym detection in medical journals.    
  We propose neural models to generate high-quality text from structured representations based on Minimal Recursion Semantics . MRS is a rich semantic representation that encodes more precise semantic detail than other representations such as Abstract Meaning Representation . We show that a sequence-to-sequence model that maps a linearization of Dependency MRS, a graph-based representation of MRS, to English text can achieve a BLEU score of 66.11 when trained on gold data. The performance can be improved further using a high-precision, broad coverage grammar-based parser to generate a large silver training corpus, achieving a final BLEU score of 77.17 on the full test set, and 83.37 on the subset of test data most closely matching the silver data domain.  Our results suggest that MRS-based representations are a good choice for applications that need both structured semantics and the ability to produce natural language text as output.  
 The recent success of transformer networks for neural machine translation and other NLP tasks has led to a surge in research work trying to apply it for speech recognition. Recent efforts studied key research questions around ways of combining positional embedding with speech features, and stability of optimization for large scale learning of transformer networks. In this paper, we propose replacing the sinusoidal positional embedding for transformers with convolutionally learned input representations. These contextual representations provide subsequent transformer blocks with relative positional information needed for discovering long-range relationships between local concepts. The proposed system has favorable optimization characteristics where our reported results are produced with fixed learning rate of 1.0 and no warmup steps. The proposed model achieves a competitive 4.7\% and 12.9\% WER on the Librispeech ``test clean'' and ``test other'' subsets when no extra LM text is provided.\footnote{Code available at: github.com/pytorch/fairseq/
 This short paper introduces an abstraction called Think Again Networks  which can be applied to any state-dependent function . 
  Large crowdsourced datasets are widely used for training and evaluating neural models on natural language inference . Despite these efforts, neural models have a hard time capturing logical inferences, including those licensed by phrase replacements, so-called monotonicity reasoning. Since no large dataset has been developed for monotonicity reasoning, it is still unclear whether the main obstacle is the size of datasets or the model architectures themselves. To investigate this issue, we introduce a new dataset, called HELP, for handling entailments with lexical and logical phenomena. We add it to training data for the state-of-the-art neural models and evaluate them on test sets for monotonicity phenomena. The results showed that our data augmentation improved the overall accuracy. \modified{We also find that the improvement is better on monotonicity inferences with lexical replacements than on downward inferences with disjunction and modification. This suggests that some types of inferences can be improved by our data augmentation while others are immune to it.}  
   In\footnote{This paper was initially submitted to EMNLP 2017. The authors sincerely thank the helpful comments from the Program Committee.} this paper, we consider the problem of open information extraction  for extracting entity and relation level intermediate structures from sentences in open-domain. We focus on four types of valuable intermediate structures , and propose a unified knowledge expression form, SAOKE, to express them. We publicly release a data set which contains more than forty thousand sentences and the corresponding facts in the SAOKE format labeled by crowd-sourcing. To our knowledge, this is the largest publicly available human labeled data set for open information extraction tasks. Using this labeled SAOKE data set, we train an end-to-end neural model using the sequence-to-sequence paradigm, called Logician, to transform sentences into facts. For each sentence, different to existing algorithms which generally focus on extracting each single fact without concerning other possible facts,  Logician performs a global optimization over all possible involved facts, in which facts not only compete with each other to attract the attention of words, but also cooperate to share words. An experimental study on various types of open domain relation extraction tasks reveals the consistent superiority of Logician to other states-of-the-art algorithms. The experiments verify the reasonableness of SAOKE format, the valuableness of SAOKE data set, the effectiveness of the proposed Logician model, and the feasibility of the methodology to apply end-to-end learning paradigm on supervised data sets for the challenging tasks of open information extraction.      SAOKE:  \url{https://ai.baidu.com/broad/subordinate?dataset=saoke}  
  Recently, end-to-end sequence-to-sequence models for speech recognition have gained significant interest in the research community.  While previous architecture choices revolve around time-delay neural networks  and long short-term memory  recurrent neural networks, we propose to use self-attention via the Transformer architecture as an alternative.  Our analysis shows that deep Transformer networks with high learning capacity are able to exceed performance from previous end-to-end approaches and even match the conventional hybrid systems. Moreover, we trained very deep models with up to 48 Transformer layers for both encoder and decoders combined with stochastic residual connections, which greatly improve generalizability and training efficiency.  The resulting models outperform all previous end-to-end ASR approaches on the Switchboard benchmark.  An ensemble of these models achieve $9.9\%$ and $17.7\%$ WER on Switchboard and CallHome test sets respectively.  This finding brings our end-to-end models to competitive levels with previous hybrid systems.  Further, with model ensembling the Transformers can outperform certain hybrid systems, which are more complicated in terms of both structure and training procedure. 
 Training large deep neural networks on massive datasets is  computationally very challenging. There has been recent surge in interest in using  stochastic optimization methods to tackle this issue. The most prominent algorithm in this line of research is $\lars$, which by  employing  learning rates trains $\resnet$ on ImageNet in a few minutes. However, $\lars$ performs poorly for attention models like $ consistent across tasks. In this paper, we first study a principled layerwise adaptation strategy to accelerate training of deep neural networks using large mini-batches. Using this strategy, we develop a new layerwise adaptive large batch optimization technique called $\lamb$; we then provide convergence analysis of $\lamb$ as well as $\lars$, showing convergence to a stationary point in general nonconvex settings. Our empirical results demonstrate the superior performance of $\lamb$ across various tasks such as $}. 
 Generalization and reliability of multilingual translation often highly depend on the amount of available parallel data for each language pair of interest. In this paper, we focus on zero-shot generalization---a challenging setup that tests models on translation directions they have not been optimized for at training time. To solve the problem, we  reformulate multilingual translation as probabilistic inference,  define the notion of zero-shot consistency and show why standard training often results in models unsuitable for zero-shot tasks, and  introduce a consistent agreement-based training method that encourages the model to produce equivalent translations of parallel sentences in auxiliary languages. We test our multilingual NMT models on multiple public zero-shot translation benchmarks  and show that agreement-based learning often results in 2-3 BLEU zero-shot improvement over strong baselines without any loss in performance on supervised translation directions. 
 Speech-related Brain Computer Interfaces  aim primarily at finding an alternative vocal communication pathway for people with speaking disabilities. As a step towards full decoding of imagined speech from active thoughts, we present a BCI system for subject-independent classification of phonological categories exploiting a novel deep learning based hierarchical feature extraction scheme. To better capture the complex representation of high-dimensional electroencephalography  data, we compute the joint variability of EEG electrodes into a channel cross-covariance matrix. We then extract the spatio-temporal information encoded within the matrix using a mixed deep neural network strategy. Our model framework is composed of a convolutional neural network , a long-short term network , and a deep autoencoder. We train the individual networks hierarchically, feeding their combined outputs in a final gradient boosting classification step. Our best models achieve an average accuracy of 77.9\% across five different binary classification tasks, providing a significant 22.5\% improvement over previous methods. As we also show visually, our work demonstrates that the speech imagery EEG possesses significant discriminative information about the intended articulatory movements responsible for natural speech synthesis. 
 In this paper, we propose and investigate a variety of distributed deep learning strategies for automatic speech recognition  and evaluate them with a state-of-the-art Long short-term memory  acoustic model on the 2000-hour Switchboard , which is one of the most widely used datasets for ASR performance benchmark. We first investigate what are the proper hyper-parameters  to enable the training with sufficiently large batch size without impairing the model accuracy. We then implement various distributed strategies, including Synchronous  , Asynchronous Decentralized Parallel SGD  and the hybrid of the two \hybrid, to study their runtime/accuracy trade-off. We show that we can train the LSTM model using \adpsgd in 14 hours with 16 NVIDIA P100 GPUs to reach a 7.6\% WER on the Hub5-2000 Switchboard  test set and a 13.1\% WER on the CallHome  test set. Furthermore, we can train the model using \hybrid  in 11.5 hours with 32 NVIDIA V100 GPUs without loss in accuracy.     %SWB2000 is one of the largest public speech recognition dataset with over 30 million training samples. It takes about one week to  train SWB2000 %with an state-of-art 6-layer bidirectional LSTM model on a modern GPU . Thus distributed deep learning is necessary. %Compared with the widely studied ImageNet-ResNet computer vision task, SWB2000/LSTM is much more challenging to parallelize for two reasons:  %It traditionally converges properly with batch size 256 , whereas ImageNet-ResNet converges with a batch size of 8192 or larger.  %Even with the same batch size, SWB2000-LSTM requires 5X more communication bandwidth, compared to ImageNet-ResNet.%% distributed computing as the %LSTM model is about 1.6X the size of ResNet model, while the per-sample training time is about 1/3 of that of ImageNet, which makes its %computation/communication ratio 1/5 of that of ImageNet-ResNet. Worse still, %  In this paper, we first investigate and present the proper hyper-parameters to enable training SWB2000-LSTM with sufficiently large batch size % without impairing model accuracy. We then study and implement different distributed deep learning algorithms, Synchronous-SGD, %Asynchronous Decentralized Parallel SGD  and the hybrid of these two algorithms \hybrid to study the runtime/accuracy tradeoff for %SWB2000-LSTM in a distributed computing setting. \adpsgd trains SWB2000-LSTM to reach WER 7.6 on SWB test set and WER 13.1 on CH test set in 14 %hours with 16 NVIDIA P100 GPUs. \hybrid trains SWB2000-LSTM to reach WER 7.6 on SWB and WER 13.1 on CH in 11.5 hours with 32 NVIDIA V100 GPUs. To %the best of our knowledge, our system delivers the fastest training time to reach this level of model accuracy for SWB2000 task.   
 Speech-related Brain Computer Interface  technologies provide effective vocal communication strategies for controlling devices through speech commands interpreted from brain signals.  In order to infer imagined speech from active thoughts, we propose a novel hierarchical deep learning BCI system for subject-independent classification of 11 speech tokens including phonemes and words. Our novel approach exploits predicted articulatory information of six phonological categories  as an intermediate step for classifying the phonemes and words, thereby finding discriminative signal responsible for natural speech synthesis.  The proposed network is composed of hierarchical combination of spatial and temporal CNN  cascaded with a deep autoencoder. Our best models on the KARA database achieve an average accuracy of 83.42\% across the six different binary phonological classification tasks, and 53.36\% for the individual token identification task, significantly outperforming our baselines. Ultimately, our work suggests the possible existence of a brain imagery footprint for the underlying articulatory movement related to different sounds that can be used to aid imagined speech decoding.    
   %Globally normalized neural sequence models are considered superior to their locally normalized equivalents because they may ameliorate the effects of label bias. However, when the neural decoder is conditioned on the output of a high-capacity encoder that represents the whole input sequence, both model classes are theoretically equivalent in terms of the distributions they are capable of representing and the advantage of global normalization is unclear. In this paper, we propose an end-to-end sub-differentiable optimization method for search-aware training of , using a continuous relaxation of beam search introduced by . Since our training approach is sensitive to warm-starting with pre-trained models, we also propose a novel initialization strategy based on self-normalization for pretraining globally normalized models.    %We empirically study the interaction between global normalization, high capacity encoders and search-aware optimization.   %We perform analysis of our approach on two tasks: CCG supertagging and Machine Translation, and demonstrate the importance of global normalization under different conditions while using search-aware training.   Globally normalized neural sequence models are considered superior to their locally normalized equivalents because they may ameliorate the effects of label bias. However, when considering high-capacity neural parametrizations that condition on the whole input sequence, both model classes are theoretically equivalent in terms of the distributions they are capable of representing. Thus, the practical advantage of global normalization in the context of modern neural methods remains unclear. In this paper, we attempt to shed light on this problem through an empirical study. We extend an approach for search-aware training via a continuous relaxation of beam search  in order to enable training of  recurrent sequence models through simple backpropagation. We then use this technique to conduct an empirical study of the interaction between global normalization, high-capacity encoders, and search-aware optimization. We observe that in the context of  inexact search, globally normalized neural models are still more effective than their locally normalized counterparts. Further, since our training approach is sensitive to warm-starting with pre-trained models, we also propose a novel initialization strategy based on self-normalization for pre-training globally normalized models. We perform analysis of our approach on two tasks: CCG supertagging and Machine Translation, and demonstrate the importance of global normalization under different conditions while using search-aware training.   %   %that also eliminates  commonly associated with the cross-entropy based  optimization of locally normalized models.  %   efficient beam search aware optimization of neural sequence models. 
 ProductNet is a collection of high-quality product datasets for better product understanding. Motivated by ImageNet, ProductNet aims at supporting product representation learning by curating product datasets of high quality with properly chosen taxonomy. In this paper, the two goals of building high-quality product datasets and learning product representation support each other in an iterative fashion: the product embedding is obtained via a multi-modal deep neural network  designed to leverage product image and catalog information; and in return, the embedding is utilized via active learning  to vastly accelerate the annotation process. For the labeled data, the proposed master model yields high categorization accuracy , which can be used as search indices, partition keys, and input features for machine learning models. The product embedding, as well as the fined-tuned master model for a specific business task, can also be used for various transfer learning tasks. 
 	 Intelligent personal assistant systems that are able to have multi-turn conversations with human users are becoming increasingly popular. Most previous research has been focused on using either retrieval-based or generation-based methods to develop such systems. Retrieval-based methods have the advantage of returning fluent and informative responses with great diversity. However, the performance of the methods is limited by the size of the response repository.  	On the other hand, generation-based methods can produce highly coherent responses on any topics. But the generated responses are often generic and not informative due to the lack of grounding knowledge. In this paper, we propose a hybrid neural conversation model that combines the merits of both response retrieval and generation methods. Experimental results on Twitter and Foursquare data show that the proposed model outperforms both retrieval-based methods and generation-based methods  under both automatic evaluation metrics and human evaluation. We hope that the findings in this study provide new insights on how to integrate text retrieval and text generation models for building conversation systems. 
 Standard methods in deep learning for natural language processing fail to capture the compositional structure of human language that allows for systematic generalization outside of the training distribution. However, human learners readily generalize in this way, e.g. by applying known grammatical rules to novel words. Inspired by work in neuroscience suggesting separate brain systems for syntactic and semantic processing, we implement a modification to standard approaches in neural machine translation, imposing an analogous separation. The novel model, which we call Syntactic Attention, substantially outperforms standard methods in deep learning on the SCAN dataset, a compositional generalization task, without any hand-engineered features or additional supervision. Our work suggests that separating syntactic from semantic learning may be a useful heuristic for capturing compositional structure.  
  % Instead of recognition decisions, T/S learning transfers the knowledge of posterior probabilities in the source domain as evaluated by the teacher model to the student model in the target domain.  % It is a form of transfer learning where the student model is trained to always approximate the posterior probabilities generated by a well-trained teacher model given all pairs of training samples.makes wrong decisions % sometimes given training samples. When decision error occur, the knowledge from the teacher model is not accurate enough and will  % after having acquired adequate knowledge from the teacher % The former one is selected as the training target when a correct decision is made by the teacher and the latter one is used otherwise. %The judgment of a teacher's decision is made by comparing the posterior probabilities with the ground truth label.  The teacher-student  learning has been shown to be effective for a variety of problems such as domain adaptation and model compression.  One shortcoming of the T/S learning is that a teacher model, not always perfect, sporadically produces wrong guidance in form of posterior probabilities that misleads the student model towards a suboptimal performance. To overcome this problem, we propose a conditional T/S learning scheme, in which a ``smart'' student model selectively chooses to learn from either the teacher model or the ground truth labels  whether the teacher can correctly predict the ground truth. Unlike a naive linear combination of the two knowledge sources, the conditional learning is exclusively engaged with the teacher model when the teacher model's prediction is correct, and otherwise backs off to the ground truth. Thus, the student model is able to learn effectively from the teacher and even potentially surpass the teacher. We examine the proposed learning scheme on two tasks: domain adaptation on CHiME-3 dataset and speaker adaptation on Microsoft short message dictation dataset. The proposed method achieves 9.8\% and 12.8\% relative word error rate reductions, respectively, over T/S learning for environment adaptation and speaker-independent model for speaker adaptation.   
  % Instead of recognition decisions, T/S learning transfers the knowledge of posteriori probabilities in the source domain as evaluated by the teacher model to the student model in the target domain.  Adversarial domain-invariant training  proves to be effective in suppressing the effects of domain variability in acoustic modeling and has led to improved performance in automatic speech recognition .   In ADIT, an auxiliary domain classifier takes in  deep features from   a deep neural network  acoustic model and is trained to  improve their domain-invariance by optimizing an adversarial loss function.  % mini-maximize the domain classification loss. % domain classifier network are jointly optimized to minimize the senone %  classification loss, and simultaneously mini-maximize % the domain classification loss computed from a sequence of %  intermediate deep features in the DNN.  In this work, we propose an attentive ADIT  in which we advance the domain classifier with an attention mechanism to  the input deep features according to their importance in domain classification.  %propose an attentive ADIT  in which the weight of each deep %feature in a sequence is  by an attention mechnism based on its importance in domain classification. With this attentive re-weighting,  ADDIT can focus on the domain normalization of phonetic components that are more susceptible to domain variability and generates deep features with improved domain-invariance and senone-discriminativity over ADIT. Most importantly, the attention block serves only as an  component to the DNN acoustic model and is not involved in ASR, so AADIT can be used to improve the acoustic modeling with any DNN architectures. More generally, the same methodology can improve any adversarial learning system with an auxiliary discriminator. % We explore both % dot-product and additive attentions and investigate the effects of position % encoding and multi-head attention.  Evaluated on CHiME-3 dataset, the AADIT achieves 13.6\% and 9.3\% relative WER improvements, respectively, over a multi-conditional model and a strong ADIT baseline.  % on speaker-invariant and environment-invariant training tasks.  
 We propose the Neuro-Symbolic Concept Learner , a model that learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them; instead, our model learns by simply looking at images and reading paired questions and answers. Our model builds an object-based scene representation and translates sentences into executable, symbolic programs. To bridge the learning of two modules, we use a neuro-symbolic reasoning module that executes these programs on the latent scene representation. Analogical to human concept learning, the perception module learns visual concepts based on the language description of the object being referred to. Meanwhile, the learned visual concepts facilitate learning new words and parsing new sentences. We use curriculum learning to guide the searching over the large compositional space of images and language. Extensive experiments demonstrate the accuracy and efficiency of our model on learning visual concepts, word representations, and semantic parsing of sentences. Further, our method allows easy generalization to new object attributes, compositions, language concepts, scenes and questions, and even new program domains. It also empowers applications including visual question answering and bidirectional image-text retrieval. \footnotetext{Project page: \url{http://nscl.csail.mit.edu}} 
 % ZSL g鑼卬鑼卹al  Zero-Shot Learning  aims at classifying unlabeled objects by leveraging auxiliary knowledge, such as semantic representations.  % Limitation des approches precedentes  A limitation of previous approaches is that only intrinsic properties of objects, e.g.\ their visual appearance, are taken into account while their context, e.g.\ the surrounding objects in the image, is ignored.  % pr鑼卻entation de l'approche  Following the intuitive principle that objects tend to be found in certain contexts but not others, we propose a new and challenging approach, context-aware ZSL, that leverages semantic representations in a new way to model the conditional likelihood of an object to appear in a given context. %, which is difficult to estimate due to the presence of unlabeled objects. % challenging % Due to the presence of unlabeled objects, which prevent the likelihood of an object to appear in a given context to be computed, we propose to use semantic representations in a new way to model this likelihood. % Contrib suppl鑼卪entaire % As a complementary contribution, we show that our model can cope with imbalanced class distribution in datasets, by using a careful sampling strategy. % Exp鑼 et resultats Finally, through extensive experiments conducted on Visual Genome, we show that contextual information can substantially improve the standard ZSL approach and is robust to unbalanced classes. %. 
   When the available data of a target speaker is insufficient to train a high quality speaker-dependent neural text-to-speech  system, we can combine data from multiple speakers and train a multi-speaker TTS model instead. Many studies have shown that neural multi-speaker TTS model trained with a small amount data from multiple speakers combined can generate synthetic speech with better quality and stability than a speaker-dependent one. However when the amount of data from each speaker is highly unbalanced, the best approach to make use of the excessive data remains unknown. Our experiments showed that simply combining all available data from every speaker to train a multi-speaker model produces better than or at least similar performance to its speaker-dependent counterpart. Moreover by using an ensemble multi-speaker model, in which each subsystem is trained on a subset of available data, we can further improve the quality of the synthetic speech especially for underrepresented speakers whose training data is limited.  
 In this paper we report state-of-the-art results on LibriSpeech among end-to-end speech recognition models without any external training data. Our model, Jasper, uses only 1D convolutions, batch normalization, ReLU, dropout, and residual connections. To improve training, we further introduce a new layer-wise optimizer called NovoGrad. Through experiments, we demonstrate that the proposed deep architecture performs as well or better than more complex choices. Our deepest Jasper variant uses 54 convolutional layers. With this architecture, we achieve 2.95\% WER using a beam-search decoder with an external neural language model and 3.86\% WER with a greedy decoder on LibriSpeech test-clean. We also report competitive results on Wall Street Journal and the Hub5'00 conversational evaluation datasets. 
 In general, the performance of automatic speech recognition  systems is significantly degraded due to the mismatch between training and test environments. Recently, a deep-learning-based image-to-image translation technique to translate an image from a source domain to a desired domain was presented, and cycle-consistent adversarial network  was applied to learn a mapping for speech-to-speech conversion from a speaker to a target speaker. However, this method might not be adequate to remove corrupting noise components for robust ASR because it was designed to convert speech itself. In this paper, we propose a domain adaptation method based on generative adversarial nets  with disentangled representation learning to achieve robustness in ASR systems. In particular, two separated encoders, context and domain encoders, are introduced to learn distinct latent variables. The latent variables allow us to convert the domain of speech according to its context and domain representation. We improved word accuracies by 6.55\texttildelow15.70\% for the CHiME4 challenge corpus by applying a noisy-to-clean environment adaptation for robust ASR. In addition, similar to the method based on the CycleGAN, this method can be used for gender adaptation in gender-mismatched recognition.  
 Self Normalizing Neural Networks proposed on Feed Forward Neural Networks outperform regular FNN architectures in various machine learning tasks. Particularly in the domain of Computer Vision, the activation function Scaled Exponential Linear Units  proposed for SNNs, perform better than other non linear activations such as ReLU. The goal of SNN is to produce a normalized output for a normalized input. Established neural network architectures like feed forward networks and Convolutional Neural Networks lack the intrinsic nature of normalizing outputs. Hence, requiring additional layers such as  Batch Normalization. Despite the success of SNNs, their characteristic features on other network architectures like CNN haven't been explored, especially in the domain of Natural Language Processing. In this paper we aim to show the effectiveness of proposed, Self Normalizing Convolutional Neural Networks on text classification. We analyze their performance with the standard CNN architecture used on several text classification datasets. Our experiments demonstrate that SCNN achieves comparable results to standard CNN model with significantly fewer parameters. Furthermore it also outperforms CNN with equal number of parameters. %as compared to standard CNN and outperforms CNN with equal number of parameters. %to the CNN architectures for text classification. We show that SCNN performs better than CNN architectures for text classification for same number of parameters.   
 Chinese word segmentation  is very important for Chinese text processing. Existing methods for CWS usually rely on a large number of labeled sentences to train word segmentation models, which are expensive and time-consuming to annotate. Luckily, the unlabeled data is usually easy to collect and many high-quality Chinese lexicons are off-the-shelf, both of which can provide useful information for CWS. In this paper, we propose a neural approach for Chinese word segmentation which can exploit both lexicon and unlabeled data. Our approach is based on a variant of posterior regularization algorithm, and the unlabeled data and lexicon are incorporated into model training as indirect supervision by regularizing the prediction space of CWS models. Extensive experiments on multiple benchmark datasets in both in-domain and cross-domain scenarios validate the effectiveness of our approach. 
 Chinese named entity recognition  is an important task in Chinese natural language processing field. However, CNER is very challenging since Chinese entity names are highly context-dependent. In addition, Chinese texts lack delimiters to separate words, making it difficult to identify the boundary of entities. Besides, the training data for CNER in many domains is usually insufficient, and annotating enough training data for CNER is very expensive and time-consuming.    In this paper, we propose a neural approach for CNER. First, we introduce a CNN-LSTM-CRF neural architecture to capture both local and long-distance contexts for CNER. Second, we propose a unified framework to jointly train CNER and word segmentation models in order to enhance the ability of CNER model in identifying entity boundaries. Third, we introduce an automatic method to generate pseudo labeled samples from existing labeled data which can enrich the training data. Experiments on two benchmark datasets show that our approach can effectively improve the performance of Chinese named entity recognition, especially when training data is insufficient. 
 Diacritization of Arabic text is both an interesting and a challenging problem at the same time with various applications ranging from speech synthesis to helping students learning the Arabic language. Like many other tasks or problems in Arabic language processing, the weak efforts invested into this problem and the lack of available  resources hinder the progress towards solving this problem. This work provides a critical review for the currently existing systems, measures and resources for Arabic text diacritization. Moreover, it introduces a much-needed free-for-all cleaned dataset that can be easily used to benchmark any work on Arabic diacritization. Extracted from the Tashkeela Corpus, the dataset consists of 55K lines containing about 2.3M words. After constructing the dataset, existing tools and systems are tested on it. The results of the experiments show that the neural Shakkala system significantly outperforms traditional rule-based approaches and other closed-source tools with a Diacritic Error Rate  of 2.88\% compared with 13.78\%, which the best DER for the non-neural approach . 
 Modern deep learning approaches have achieved groundbreaking performance in modeling and classifying sequential data.  Specifically, attention networks constitute the state-of-the-art paradigm for capturing long temporal dynamics.  This paper examines the efficacy of this paradigm in the challenging task of emotion recognition in dyadic conversations.  In contrast to existing approaches, our work introduces a novel attention mechanism capable of inferring the immensity of the effect of each past utterance on the current speaker emotional state. The proposed attention mechanism performs this inference procedure without the need of a decoder network; this is achieved by means of innovative self-attention arguments.  Our self-attention networks capture the correlation patterns among consecutive encoder network states, thus allowing to robustly and effectively model temporal dynamics over arbitrary long temporal horizons. Thus, we enable capturing strong affective patterns over the course of long discussions. We exhibit the effectiveness of our approach considering the challenging IEMOCAP benchmark.  As we show, our devised methodology outperforms state-of-the-art alternatives and commonly used approaches, giving rise to promising new research directions in the context of Online Social Network  analysis tasks.  
 The Pointer-Generator architecture has shown to be a big improvement for abstractive summarization seq2seq models. However, the summaries produced by this model are largely extractive as over 30\% of the generated sentences are copied from the source text. This work proposes a multihead attention mechanism, pointer dropout and two new loss functions to promote more abstractive summaries while maintaining similar ROUGE scores. Both the multihead attention ,and dropout do not improve N-gram novelty, however, the dropout acts as a regularizer which improves the ROUGE score. The new loss function achieves significantly higher novel N-grams and sentences, at the cost of a slightly lower ROUGE score. 
 Text generation is of particular interest in many NLP applications such as  machine translation, language modeling, and text summarization. Generative adversarial networks  achieved a remarkable success in high quality image generation in computer vision, and recently, GANs have gained lots of interest from the NLP community as well. However, achieving similar success in NLP would be more challenging due to the discrete nature of text. In this work, we introduce a method using knowledge distillation to effectively exploit GAN setup for text generation. We demonstrate how autoencoders  can be used for providing a continuous representation of sentences, which is a smooth representation that assign non-zero probabilities to more than one word. We distill this representation to train the generator to synthesize similar smooth representations. We perform a number of experiments to validate our idea using different datasets and show that our proposed approach yields better performance in terms of the BLEU score and Jensen-Shannon distance  measure compared to traditional GAN-based text generation approaches without pre-training.    
 Lifelong machine learning is a novel machine learning paradigm which can continually accumulate knowledge during learning. The knowledge extracting and reusing abilities enable the lifelong machine learning to solve the related problems. The traditional approaches like Na\"ive Bayes and some neural network based approaches only aim to achieve the best performance upon a single task. Unlike them, the lifelong machine learning in this paper focus on how to accumulate knowledge during learning and leverage them for the further tasks. Meanwhile, the demand for labeled data for training also be significantly decreased with the knowledge reusing. This paper suggests that the aim of the lifelong learning is to use less labeled data and computational cost to achieve the performance as well as or even better than the supervised learning. 
   In this paper, we extend the persona-based sequence-to-sequence  neural network conversation model to a multi-turn dialogue scenario by modifying the state-of-the-art hredGAN architecture to simultaneously capture utterance attributes such as speaker identity, dialogue topic, speaker sentiments and so on. The proposed system, phredGAN has a persona-based HRED generator  and a conditional discriminator. We also explore two approaches to accomplish the conditional discriminator:  $phredGAN_a$, a system that passes the attribute representation as an additional input into a traditional adversarial discriminator, and  $phredGAN_d$, a dual discriminator system which in addition to the adversarial discriminator, collaboratively predicts the attribute that generated the input utterance. To demonstrate the superior performance of phredGAN over the persona Seq2Seq model, we experiment with two conversational datasets, the Ubuntu Dialogue Corpus  and TV series transcripts from the Big Bang Theory and Friends. Performance comparison is made with respect to a variety of quantitative measures as well as crowd-sourced human evaluation. We also explore the trade-offs from using either variant of $phredGAN$ on datasets with many but weak attribute modalities  and ones with few but strong attribute modalities . 
 In this paper, we extend the persona-based sequence-to-sequence  neural network conversation model to multi-turn dialogue by modifying the state-of-the-art hredGAN architecture. To achieve this,  we introduce an additional input modality into the encoder and decoder of hredGAN to capture other  attributes such as speaker identity, location, sub-topics, and other external attributes that  might be available from the corpus of human-to-human interactions. The resulting persona hredGAN   shows better performance than both the existing persona-based Seq2Seq and hredGAN models when  those external attributes are available in a multi-turn dialogue corpus.  This superiority is demonstrated on TV drama series with character consistency  and customer service interaction datasets such as Ubuntu dialogue corpus in terms  of perplexity, BLEU, ROUGE, and Distinct n-gram scores. 
 Security Analysts that work in a `Security Operations Center'  play a major role in ensuring the security of the organization. The amount of background knowledge they have about the evolving and new attacks makes a significant difference in their ability to detect attacks. Open source threat intelligence sources, like text descriptions about cyber-attacks, can be stored in a structured fashion in a cybersecurity knowledge graph. A cybersecurity knowledge graph can be paramount in aiding a security analyst to detect cyber threats because it stores a vast range of cyber threat information in the form of semantic triples which can be queried. A semantic triple contains two cybersecurity entities with a relationship between them. In this work, we propose a system to create semantic triples over cybersecurity text, using deep learning approaches to extract possible relationships. We use the set of semantic triples generated through our system to assert in a cybersecurity knowledge graph. Security Analysts can retrieve this data from the knowledge graph, and use this information to form a decision about a cyber-attack.     cybersecurity, deep learning, knowledge graphs    %Security Analysts that work in a Security Operations Center play a major role in ensuring the security of the organization. The amount of background knowledge they have about the evolving and new attacks makes a significant difference in their ability to detect attacks. Public sources of information such as security blogs and after action reports contain a significant amount of information that can be useful to these analysts in detecting and preventing attacks. However, these reports needs to be processed manually causing significant delays. There has been recent work in automating the extraction of information from such reports to populate Cybersecurity Knowledge Graphs . This work involves extracting the named entities in a report, and the possible relationships between them.  In this work, we propose a system to create semantic triples over cybersecurity reports, using deep learning approaches to extract possible relationships.  We integrate our models within a cybersecurity pipeline that generates a cybersecurity KG based on the triples predicted. We have modularized our system to the lowest possible level, keeping the system flexible for improvements in future. 
 Syntax has been demonstrated highly effective in neural machine translation . Previous NMT models integrate syntax by representing 1-best tree outputs from a well-trained parsing system, e.g., the representative Tree-RNN and Tree-Linearization methods, which may suffer from error propagation. In this work, we propose a novel method to integrate source-side syntax implicitly for NMT. The basic idea is to use the intermediate hidden representations of a well-trained end-to-end dependency parser, which are referred to as syntax-aware word representations . Then, we simply concatenate such SAWRs with ordinary word embeddings to enhance basic NMT models. The method can be straightforwardly integrated into the widely-used sequence-to-sequence  NMT models. We start with a representative RNN-based Seq2Seq baseline system, and test the effectiveness of our proposed method on two benchmark datasets of the Chinese-English and English-Vietnamese translation tasks, respectively. Experimental results show that the proposed approach is able to bring significant BLEU score improvements on the two datasets compared with the baseline, 1.74 points for Chinese-English translation and 0.80 point for English-Vietnamese translation, respectively. In addition, the approach also outperforms the explicit Tree-RNN and Tree-Linearization methods. 
  \qquad In this work we explore how fine-grained differences between the { of the objects. We first build a large scale, carefully controlled dataset of human utterances that each refers to a 2D rendering of a 3D CAD model so as to distinguish it from a set of  shape-wise similar alternatives. Using this dataset, we develop neural language understanding  and production  models that vary in their grounding , the degree of pragmatic reasoning captured , and the neural architecture . We find models that perform well with both synthetic and human partners, and with held out utterances and objects. We also find that these models are amenable to { of objects , and that transfer to novel classes is most successful when known part-words are available. This work illustrates a practical approach to language grounding, and provides a case study in the relationship between object shape and linguistic structure when it comes to {\bf object differentiation}. 
 This short example shows a contrived example on how to format the authors' information for {. 
  The proliferation of fake news and its propagation on social media have become a major concern due to its ability to create devastating impacts. Different machine learning approaches have been attempted to detect it. However, most of those focused on a special type of news  and did not apply many advanced techniques. In this research, we conduct a benchmark study to assess the performance of different applicable approaches on three different datasets where the largest and most diversified one was developed by us.  We also implemented some advanced deep learning models that have shown promising results.     
 Existing approaches to neural machine translation  generate the target language sequence token by token from left to right. However, this kind of unidirectional decoding framework cannot make full use of the target-side future contexts which can be produced in a right-to-left decoding direction, and thus suffers from the issue of unbalanced outputs. In this paper, we introduce a synchronous bidirectional neural machine translation  that predicts its outputs using left-to-right and right-to-left decoding simultaneously and interactively, in order to leverage both of the history and future information at the same time. Specifically, we first propose a new algorithm that enables synchronous bidirectional decoding in a single model. Then, we present an interactive decoding model in which left-to-right  generation does not only depend on its previously generated outputs, but also relies on future contexts predicted by right-to-left  decoding. We extensively evaluate the proposed SB-NMT model on large-scale NIST Chinese-English, WMT14 English-German, and WMT18 Russian-English translation tasks. Experimental results demonstrate that our model achieves significant improvements over the strong Transformer model by 3.92, 1.49 and 1.04 BLEU points respectively, and obtains the state-of-the-art performance on Chinese-English and English-German translation tasks.{\footnote[1]{The source code is available at \url{https://github.com/wszlong/sb-nmt}.}} 
 We present a survey on multilingual neural machine translation , which has gained a lot of traction in the recent years. MNMT has been useful in improving translation quality as a result of knowledge transfer. MNMT is more promising and interesting than its statistical machine translation counterpart because end-to-end modeling and distributed representations open new avenues. Many approaches have been proposed in order to exploit multilingual parallel corpora for improving translation quality. However, the lack of a comprehensive survey makes it difficult to determine which approaches are promising and hence deserve further exploration. In this paper, we present an in-depth survey of existing literature on MNMT. We categorize various approaches based on the resource scenarios as well as underlying modeling principles. We hope this paper will serve as a starting point for researchers and engineers interested in MNMT. 
 % max 200 words Current neural network-based conversational models lack diversity and generate boring responses to open-ended utterances. Priors  such as persona, emotion, or topic provide additional information to dialog models to aid response generation, but annotating a dataset with priors  is expensive and such annotations are rarely available. While previous methods for improving the quality of open-domain response generation focused on either the underlying model or the training objective, we present a method of filtering dialog datasets by removing generic utterances from training data using a simple entropy-based approach that does not require human supervision. We conduct extensive experiments with different variations of our method, and compare dialog models across 17 evaluation metrics to show that training on datasets filtered this way results in better conversational quality as chatbots learn to output more diverse responses. 
   Transfer learning or multilingual model is essential for low-resource neural machine translation , but the applicability is limited to cognate languages by sharing their vocabularies. This paper shows effective techniques to transfer a pre-trained NMT model to a new, unrelated language without shared vocabularies. We relieve the vocabulary mismatch by using cross-lingual word embedding, train a more language-agnostic encoder by injecting artificial noises, and generate synthetic data easily from the pre-training data without back-translation. Our methods do not require restructuring the vocabulary or retraining the model. We improve plain NMT transfer by up to +5.1\% Bleu in five low-resource translation tasks, outperforming multilingual joint training by a large margin. We also provide extensive ablation studies on pre-trained embedding, synthetic data, vocabulary size, and parameter freezing for a better understanding of NMT transfer.\\ 
  Many tasks, including language generation, benefit from learning the structure of the output space, particularly when the space of output labels is large and the data is sparse.  %  State-of-the-art neural language models indirectly capture the output space structure in their classifier weights since they lack parameter sharing across output labels. Learning shared output label mappings helps, but existing methods have limited expressivity and are prone to overfitting. % In this paper, we investigate the usefulness of more powerful shared mappings for output labels, and propose a deep residual output mapping with dropout between layers to better capture the structure of the output space and avoid overfitting.  % Evaluations on three language generation tasks show that our output label mapping can match or improve state-of-the-art recurrent and self-attention architectures, and  suggest that the classifier does not necessarily need to be high-rank to better model natural language if it is better at capturing the structure of the output space.  
 Segmenting a chunk of text into words is usually the first step of processing Chinese text, but its necessity has rarely been explored.    In this paper, we ask the fundamental question of whether Chinese word segmentation  is necessary for deep learning-based Chinese Natural Language Processing. We benchmark neural word-based models which rely on word segmentation  against neural char-based models which do not involve word segmentation in four end-to-end NLP benchmark tasks: language modeling, machine translation, sentence matching/paraphrase and text classification. Through direct  comparisons between these two types of models, we find that char-based models consistently outperform word-based models.   Based on these observations, we conduct comprehensive  experiments to study why word-based models underperform char-based models in these deep learning-based NLP tasks. We show that it is because word-based models  are more vulnerable to data sparsity and the presence of out-of-vocabulary  words, and thus more prone to overfitting.   We hope this paper could encourage researchers in the community to rethink the necessity of word segmentation in deep learning-based Chinese Natural Language Processing. \footnote{Yuxian Meng and Xiaoya Li contribute equally to this paper.} \footnote{Paper to appear at ACL2019.}  
 		 		Natural language generation  is an essential component of task-oriented dialogue systems. 		Despite the recent success of neural approaches for NLG, they are typically developed for particular domains with rich annotated training examples. 		In this paper, we study NLG in a low-resource setting to generate sentences in new scenarios with handful training examples. 		We formulate the problem from a meta-learning perspective, and propose a generalized optimization-based approach~ based on the well-recognized model-agnostic meta-learning~ algorithm. 		\meta\ defines a set of meta tasks, and directly incorporates the objective of adapting to new low-resource NLG tasks into the meta-learning optimization process. 		Extensive experiments are conducted on a large multi-domain dataset  with diverse linguistic variations.  		We show that \meta\ significantly outperforms other training procedures in various low-resource configurations.  		We analyze the results, and demonstrate that \meta\ adapts extremely fast and well to low-resource situations. 		 	
 In this article, we tackle the issue of the limited quantity of manually sense annotated corpora for the task of word sense disambiguation,  by exploiting  the semantic relationships between senses such as synonymy, hypernymy and hyponymy, in order to compress the sense vocabulary of Princeton WordNet, and thus reduce the number of different sense tags that must be observed to disambiguate all words of the lexical database.  We propose two different methods that  greatly reduce  the size of neural WSD models,  with the benefit of improving their coverage without additional training data, and without impacting their precision.  In addition to our methods, we present  a WSD system which relies on pre-trained BERT word vectors  in order to achieve results  that significantly outperforms the state of the art on all WSD evaluation tasks.  
 The recent work of Super Characters method using two-dimensional word embedding achieved state-of-the-art results in text classification tasks, showcasing the promise of this new approach. This paper borrows the idea of Super Characters method and two-dimensional embedding, and proposes a method of generating conversational response for open domain dialogues. The experimental results on a public dataset shows that the proposed SuperChat method generates high quality responses. An interactive demo is ready to show at the workshop.  
   Recognizing a piece of writing as a poem or prose is usually easy for the majority of people; however,   only specialists can determine which meter a poem belongs to. In this paper, we build Recurrent   Neural Network  models that can classify poems according to their meters from plain text. The   input text is encoded at the character level and directly fed to the models without feature   handcrafting. This is a step forward for machine understanding and synthesis of languages in   general, and Arabic language in particular.    Among the 16 poem meters of Arabic and the 4 meters of English the networks were able to correctly   classify poem with an overall accuracy of 96.38\% and 82.31\% respectively. The poem datasets used to   conduct this research were massive, over 1.5 million of verses, and were crawled from different   nontechnical sources, almost Arabic and English literature sites, and in different heterogeneous   and unstructured formats. These datasets are now made publicly available in clean, structured, and   documented format for other future research.    To the best of the authors' knowledge, this research is the first to address classifying poem   meters in a machine learning approach, in general, and in RNN featureless based approach, in   particular. In addition, the dataset is the first publicly available dataset ready for the purpose   of future computational research. 
 The ability of neural networks to capture relational knowledge is a matter of long-standing controversy. Recently, some researchers in the PDP side of the debate have argued that  classic PDP models can handle relational structure  and  the success of deep learning approaches to text processing suggests that structured representations are unnecessary to capture the gist of human language . In the present study we tested the Story Gestalt model , a classic PDP model of text comprehension, and a Sequence-to-Sequence with Attention model , a contemporary deep learning architecture for text processing. Both models were trained to answer questions about stories based on the thematic roles that several concepts played on the stories. In three critical test we varied the statistical structure of new stories while keeping their relational structure constant with respect to the training data. Each model was susceptible to each statistical structure manipulation to a different degree, with their performance failing below chance at least under one manipulation. We argue that the failures of both models are due to the fact that they cannot perform dynamic binding of independent roles and fillers. Ultimately, these results cast doubts on the suitability of traditional neural networks models for explaining phenomena based on relational reasoning, including language processing. 
 We introduce a curriculum learning approach to adapt generic neural machine translation models to a specific domain. Samples are grouped by their similarities to the domain of interest and each group is fed to the training algorithm with a particular schedule. This approach is simple to implement on top of any neural framework or architecture, and consistently outperforms both unadapted and adapted baselines in experiments with two distinct domains and two language pairs.% Experiments on two domains and two language pairs show that curriculum learning improves by up to 3.22 BLEU points over adaptation by continued training. % {\Marine: We introduce a curriculum learning approach to adapt generic neural machine translation models to a specific domain. Our approach defines a schedule to sample new training examples for continued training, based on their distance to the domain of interest. % This approach is simple to implement on top of any neural framework or architecture, and consistently outperforms both unadapted and adapted baselines. Experiments on two domains and two language pairs show that curriculum learning approach improves BLEU by 5\%-10.4\% over the standard continued training.} % {\Kevin: We introduce a curriculum learning approach to adapt generic neural machine translation models to new domains. The idea is to group samples by their similarities to the in-domain data and feed each group to the training algorithm with a particular schedule.  % Our experiments on four different tasks demonstrate that the curriculum learning approach improves BLEU by 5\%-10.4\% over the standard continued training adaptation method. % This approach is simple to implement on top of any neural framework or architecture, and yields consistent gains in various domain adaptation settings.}  
 Natural language understanding  and natural language generation  are both critical research topics in the NLP and dialogue fields. Natural language understanding is to extract the core semantic meaning from the given utterances, while natural language generation is opposite, of which the goal is to construct corresponding sentences based on the given semantics.  However, such dual relationship has not been investigated in literature. This paper proposes a novel learning framework for natural language understanding and generation on top of dual supervised learning, providing a way to exploit the duality. The preliminary experiments show that the proposed approach boosts the performance for both tasks, demonstrating the effectiveness of the dual relationship.\footnote{\url{https://github.com/MiuLab/DuaLUG}} 
 Research on parsing language to SQL has largely ignored the structure of the database  schema, either because the DB was very simple, or because it was observed at both training and test time. In , a recently-released text-to-SQL dataset, new and complex DBs are given at test time, and so the structure of the DB schema can inform the predicted SQL query. In this paper, we present an encoder-decoder semantic parser, where the structure of the DB schema is encoded with a graph neural network, and this representation is later used at both encoding and decoding time.  Evaluation shows that encoding the schema structure improves our parser accuracy  from 33.8\% to 39.4\%, dramatically above the current state of the art, which is at 19.7\%. 
  Contextualized representation models such as ELMo  and BERT  have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks. Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline. We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena.  We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline.  
   Analysis methods which enable us to better understand the   representations and functioning of neural models of language are   increasingly needed as deep learning becomes the dominant approach   in NLP. Here we present two methods based on Representational   Similarity Analysis  and Tree Kernels  which allow us to   directly quantify how strongly the information encoded in neural   activation patterns corresponds to information represented by   symbolic structures such as syntax trees. We first validate our   methods on the case of a simple synthetic language for arithmetic   expressions with clearly defined syntax and semantics, and show that   they exhibit the expected pattern of results. We then apply our methods to   correlate neural representations of English sentences with their   constituency parse trees. 
 A common intermediate language representation in neural machine translation can be used to extend bilingual to multilingual systems by incremental training. In this paper, we propose a new architecture based on introducing an interlingual loss as an additional training objective.  %The encoder-decoders are implemented with the latest Transformer model while variational autoencoders are implemented with the Transformer with discrete latent variables.  By adding and forcing this interlingual loss, we are able to train multiple encoders and decoders for each language, sharing a common intermediate representation.   Translation results on the low-resourced tasks   show the following BLEU improvements up to 2.8. However, results on a larger dataset  show BLEU loses if the same amount. %Additionally, since the final objective of our architecture is having compatible encoder/decoders based on a common representation, we visualize and evaluate the learned intermediate representations. While our system is only providing improvements for the low-resourced tasks in terms of translation quality, our system is capable of quickly deploying new language pairs without retraining the rest of the system, which may be a game changer in some situations .    Precisely, what is most relevant from our architecture is that it is capable of:  reducing the number of production systems, with respect to the number of languages, from quadratic to linear  incrementally adding a new language in the system without retraining languages previously there and  allowing for translations from the new language to all the others present in the system.    %{ the other side if one considers situations where deploying 2 new language pairs in less time is more important than 1,5 BLEU score, these results are useful to know. ADD well-known limitations: BPE on new corpora, }     
 Large-scale clinical data is invaluable to driving many computational scientific advances today. However, understandable concerns regarding patient privacy hinder the open dissemination of such data and give rise to suboptimal siloed research.  De-identification methods attempt to address these concerns but were shown to be susceptible to adversarial attacks. In this work, we focus on the vast amounts of unstructured natural language data stored in clinical notes and propose to automatically generate synthetic clinical notes that are more amenable to sharing using generative models trained on real de-identified records.  To evaluate the merit of such notes, we measure both their privacy preservation properties as well as utility in training clinical NLP models. Experiments using neural language models yield notes whose utility is close to that of the real ones in some clinical NLP tasks, yet leave ample room for future improvements. 
 The prosodic aspects of speech signals produced by current text-to-speech systems are typically averaged over training material, and as such lack the variety and liveliness found in natural speech. To avoid monotony and averaged prosody contours, it is desirable to have a way of modeling the variation in the prosodic  aspects of speech, so audio signals can be synthesized in multiple ways for a given text. % We present a new, hierarchically structured conditional variational auto-encoder to generate prosodic features  suitable for use with a vocoder or a generative model like WaveNet. % The encoder compresses linguistic and acoustic input features into a variational bottleneck layer. % The decoder has the same linguistic features as then input encoder, but, instead of having access to acoustic features directly, gets an embedding sampled from the variational layer, designed to capture the prosodic aspects of the input text. At inference time, an embedding representing the prosody of a sentence may be sampled from the variational layer to allow for prosodic variation. % To efficiently capture the hierarchical nature of the linguistic input , both the encoder and decoder parts of the auto-encoder are hierarchical, in line with the linguistic structure, with layers being clocked dynamically at the respective rates.  We show in our experiments that our dynamic hierarchical network outperforms a non-hierarchical state-of-the-art baseline, and, additionally, that prosody transfer across sentences is possible by employing the prosody embedding of one sentence to generate the speech signal of another. 
 The paper introduces methods of adaptation of multilingual masked language models for a specific language. Pre-trained bidirectional language models show state-of-the-art performance on a wide range of tasks including reading comprehension, natural language inference, and sentiment analysis. At the moment there are two alternative approaches to train such models: monolingual and multilingual. While language specific models show superior performance, multilingual models allow to perform a transfer from one language to another and solve tasks for different languages simultaneously. This work shows that transfer learning from a multilingual model to monolingual model results in significant growth of performance on such tasks as reading comprehension, paraphrase detection, and sentiment analysis. Furthermore, multilingual initialization of monolingual model substantially reduces training time. Pre-trained models for the Russian language are open sourced.    
 Accurately predicting conversions in advertisements is generally a challenging task, because such conversions do not occur frequently. In this paper, we propose a new framework to support creating high-performing ad creatives, including the accurate prediction of ad creative text conversions before delivering to the consumer. The proposed framework includes three key ideas: multi-task learning, conditional attention, and attention highlighting. Multi-task learning is an idea for improving the prediction accuracy of conversion, which predicts clicks and conversions simultaneously, to solve the difficulty of data imbalance. Furthermore, conditional attention focuses attention of each ad creative with the consideration of its genre and target gender, thus improving conversion prediction accuracy. Attention highlighting visualizes important words and/or phrases based on conditional attention. We evaluated the proposed framework with actual delivery history data , and confirmed that these ideas improve the prediction performance of conversions, and visualize noteworthy words according to the creatives' attributes. 
   Relation extraction  is an indispensable information extraction task in several disciplines.~RE models typically assume that named entity recognition  is already performed in a previous step by another independent model.~Several recent efforts, under the theme of  RE, seek to exploit inter-task correlations by modeling both NER and RE tasks jointly.~Earlier work in this area commonly reduces the task to a table-filling problem wherein an additional expensive decoding step involving beam search is applied to obtain globally consistent cell labels. In efforts that do not employ table-filling, global optimization in the form of CRFs with Viterbi decoding for the NER component is still necessary for competitive performance.~We introduce a novel neural architecture utilizing the table structure, based on repeated applications of 2D convolutions for pooling local dependency and metric-based features, that improves on the state-of-the-art   without the need for global optimization.~We validate our model on the ADE and CoNLL04 datasets for end-to-end RE and demonstrate $\approx 1\%$ gain  over prior best results with training and testing times that are seven to ten times faster --- the latter highly advantageous for time-sensitive end user applications. 
 Preventable adverse drug reactions as a result of medical errors present a growing concern in modern medicine. As drug-drug interactions  may cause adverse reactions, being able to extracting DDIs from drug labels into machine-readable form is an important effort in effectively deploying drug safety information. The DDI track of TAC 2018 introduces two large hand-annotated test sets for the task of extracting DDIs from structured product labels with linkage to standard terminologies. Herein, we describe our approach to tackling tasks one and two of the DDI track, which corresponds to named entity recognition  and sentence-level relation extraction respectively. Namely, our approach resembles a multi-task learning framework designed to jointly model various sub-tasks including NER and interaction type and outcome prediction. On NER, our system ranked second  at 33.00\% and 38.25\% F1 on Test Sets 1 and 2 respectively. On relation extraction, our system ranked second  at 21.59\% and 23.55\% on Test Sets 1 and 2 respectively. 
  In this study we propose a framework to characterize documents based on their semantic flow. The proposed framework encompasses a network-based model that connected sentences based on their semantic similarity. Semantic fields are detected using standard community detection methods. as the story unfolds, transitions between semantic fields  are represent in Markov networks, which in turned are characterized via network motifs . Here we show that the proposed framework can be used to classify books according to their style and publication dates. Remarkably, even without a systematic optimization of parameters, philosophy and investigative books were discriminated with an accuracy rate of 92.5\%. % Because this model captures semantic features of texts, it could be used as an additional feature in traditional network-based models of texts that capture only syntactical/stylistic information, as it is the case of word adjacency  networks.  %Nos 鐓timos anos a modelagem de textos em redes complexas trouxe um novo ponto de vista para a 璋﹔ea de NLP, o que permitiu a explora鑾借尗o da l閾唍gua sobre uma nova luz.  %Nesse trabalho, mais uma vez usando o framework de redes complexas, demonstramos que essa modelagem al鑼卪 de poder ser utilizada como uma t鑼卌nica para caracteriza鑾借尗o de textos que normalmente 鑼 associada a tarefas de aprendizado de m璋﹒uina como classifica鑾借尗o de textos, desamgigua鑾借尗o, an璋﹍ise de sentimento, sumariza鑾借尗o, tamb鑼卪 鑼 poss閾唙el derivar estruturas que retratam como a informa鑾借尗o flui nos textos e a partir dessas estruturas indentificar tra鑾給s da origem do texto  ou mesmo o estilo liter璋﹔io .  %Mas como representar o fluxo de informa鑾借尗o no texto? Para representar esse fluxo, primeiro 鑼 necess璋﹔io definir qual a unidade sem鑺抧tica  considerada em um texto, que poder ser uma palavra, uma senten鑾絘, um par璋ゞrafo ou mesmo um conjunto de par璋ゞrafos. Essa escolha define a granularidade da representa鑾借尗o, se eu uso palavras, informa鑾界帿es de contexto e estruturas mais complexas acabam desaparecendo, no outro extremo, usando conjuntos de par璋ゞrafos pequenas intera鑾界帿es s鑼玱 negligenciadas, o que torna senten鑾絘s um 璐竧imo ponto de in閾哻io. % %Definida a unidade sem鑺抧tica podemos seguir para a primeira parte da representa鑾借尗o, que consiste na representa鑾借尗o em redes complexas. Para tanto adaptamos uma representa鑾借尗o utilizada em trabalhos anteriores que combina a representa鑾借尗o em redes complexas e a representa鑾借尗o vetorial denonimada word embeddings. Basicamente cada unidade sem鑺抧tica 鑼 transformada em um vetor , a unidade ent鑼玱 se torna um n璐 na rede que 鑼 conectado a um conjunto de $k$ n璐竤 mais pr璐竫imos, considerando a similaridade  do vetor de embeddings.  %Em trabalhos anteriores estruturas semelhantes a essa demonstraram ser capazes de capturar a forma鑾借尗o de comunidades no n閾唙el sem鑺抧tico, ou seja, quando um algoritmo de detec鑾借尗o de comunidades era aplicado, as comunidades encontradas poderiam representar os m鐓tiplos sentidos de uma palavra, como indicado por WSI\_DL. No nosso caso, as comunidades encontradas podem representar momentos em uma narrativa ou um t璐竝ico/aspecto abordado no texto . % %Logo 鑼 poss閾唙el verificar como o texto flui por essas comunidades, tratando o texto como uma s鑼卹ie temporal discreta, no qual um par璋ゞrafo representa um estado, estado esse que pertence 鑴 uma determianda comunidade. Assim temos uma cadeia de markov, onde os n璐竤 da rede s鑼玱 as comunidades e as arestas representam a intera鑾借尗o dessas comunidades ao longo do texto.  %Agora com as cadeias de markov definidas 鑼 poss閾唙el caracterizar essas estruturas e consequentemente caracterizar o fluxo sem鑺抧tico do texto. Para isso utilizamos a extra鑾借尗o de motifs, t鑼卌nica previamente utilizada em.....   %A partir dessa caracteriza鑾借尗o demonstramos que 鑼 poss閾唙el classificar textos por sua 鑼卲oca e tamb鑼卪 por sua categoria, utilizando somente os atributos oriundos da cadeia de markov...  
 Keyphrase extraction from documents is useful to a variety of applications such as information retrieval and document summarization. This paper presents an end-to-end method called DivGraphPointer for extracting a set of diversified keyphrases from a document.  DivGraphPointer combines the advantages of traditional graph-based ranking methods and recent neural network-based approaches. Specifically, given a document, a word graph is constructed from the document based on word proximity and is encoded with graph convolutional networks, which effectively capture document-level word salience by modeling long-range dependency between words in the document and aggregating multiple appearances of identical words into one node. Furthermore, we propose a diversified point network to generate a set of diverse keyphrases out of the word graph in the decoding process. Experimental results on five benchmark data sets show that our proposed method significantly outperforms the existing state-of-the-art approaches.  
 The success of neural networks comes hand in hand with a desire for more interpretability.  We focus on text classifiers and make them more interpretable by having them provide a justification---a ---for their predictions.  We approach this problem by jointly training two neural network models: a latent model that selects a rationale , and a classifier that learns from the words in the rationale alone.  Previous work proposed to assign binary latent masks to input positions and to promote short selections via sparsity-inducing penalties such as $L_0$ regularisation.  We propose a latent model that mixes discrete and continuous behaviour allowing at the same time for binary selections and gradient-based training without REINFORCE. In our formulation, we can tractably compute the expected value of penalties such as $L_0$, which allows us to directly optimise the model towards a pre-specified text selection rate.  We show that our approach is competitive with previous work on rationale extraction, and explore further uses in attention mechanisms. 
 To improve low-resource Neural Machine Translation~ with multilingual corpora, training on the most related high-resource language only is often more effective than using all data available~. However, it is possible that an intelligent data selection strategy can further improve low-resource NMT with data from other auxiliary languages. In this paper, we seek to construct a sampling distribution over all multilingual data, so that it minimizes the training loss of the low-resource language. %we formulate multilingual training as an importance sampling process, where we can construct a good sampling distribution over all multilingual data that minimizes the bias in the training objective of the low-resource NMT.  Based on this formulation, we propose an efficient algorithm, \dis~, which first samples a target sentence, and then conditionally samples its source sentence. Experiments show that \disab~brings significant gains of up to 2 BLEU on three of four languages we test, with minimal training overhead.     
 	Question answering  using textual sources for purposes such as reading comprehension  has attracted much attention. This study focuses on the task of explainable multi-hop QA, which requires the system to return the answer with evidence sentences by reasoning and gathering disjoint pieces of the reference texts. It proposes the Query Focused Extractor  model for evidence extraction and uses multi-task learning with the QA model. QFE is inspired by extractive summarization models; compared with the existing method, which extracts each evidence sentence independently, it sequentially extracts evidence sentences by using an RNN with an attention mechanism on the question sentence. It enables QFE to consider the dependency among the evidence sentences and cover important information in the question sentence. Experimental results show that QFE with a simple RC baseline model achieves a state-of-the-art evidence extraction score on HotpotQA. Although designed for RC, it also achieves a state-of-the-art evidence extraction score on FEVER, which is a recognizing textual entailment task on a large textual database. 	
    introduced the SCAN dataset probing the   ability of seq2seq models to capture compositional generalizations,   such as inferring the meaning of  0-shot from   the component words. Recurrent networks  were found to   completely fail the most challenging generalization cases. We test   here a convolutional network  on these tasks, reporting hugely improved performance with respect to   RNNs. Despite the big improvement, the   CNN has however not induced systematic rules, suggesting that the difference   between compositional and non-compositional behaviour is not   clear-cut. 
  Multi-feature data analysis  is challenging especially if one wants to do it efficiently and retain the flexibility by choosing features of interest for analysis. Features  can be explicitly given from datasets, but also can be derived from content .  Analysis from multiple perspectives is needed to understand the datasets  and to infer meaningful knowledge. For example, the influence of age, location, and marital status on political views may need to be inferred separately .  In this paper, we adapt multilayer network  analysis, a non-traditional approach, to model the Facebook datasets, integrate content analysis, and conduct analysis, which is driven by a list of desired application based queries.  %we demonstrate the flexibility of the proposed approach in analyzing complex social network data to infer trends and establish some feature correlations.   Our experimental analysis shows the flexibility and efficiency of the proposed approach when modeling and analyzing datasets with multiple features.   % Although graph-based approach is widely used and well-suited, traditional way of using a single graph representing multiple features poses difficulty for modeling, and computationally inefficient. 
 Gender bias has been found in existing coreference resolvers. In order to eliminate gender bias, a gender-balanced dataset Gendered Ambiguous Pronouns  has been released and the best baseline model achieves only 66.9\% F1. Bidirectional Encoder Representations from Transformers  has broken several NLP task records and can be used on GAP dataset. However, fine-tune BERT on a specific task is computationally expensive. In this paper, we propose an end-to-end resolver by combining pre-trained BERT with Relational Graph Convolutional Network . R-GCN is used for digesting structural syntactic information and learning better task-specific embeddings. Empirical results demonstrate that, under explicit syntactic supervision and without the need to fine tune BERT, R-GCN's embeddings outperform the original BERT embeddings on the coreference task. Our work significantly improves the snippet-context baseline F1 score on GAP dataset from 66.9\% to 80.3\%. We participated in the Gender Bias for Natural Language Processing 2019 shared task, and our codes are available online. \footnote{Our codes and models are available at: \url{https://github.com/ianycxu/RGCN-with-BERT}.}    
 Neural Machine Translation  has been proven to achieve impressive results. The NMT system translation results depend strongly on the size and quality of parallel corpora. Nevertheless, for many language pairs, no rich-resource parallel corpora exist. As described in this paper, we propose a corpus augmentation method by segmenting long sentences in a corpus using back-translation and generating pseudo-parallel sentence pairs. The experiment results of the Japanese-Chinese and Chinese-Japanese translation with Japanese-Chinese scientific paper excerpt corpus  show that the method improves translation performance. 
  Emerging research in Neural Question Generation  has started to integrate a larger variety of inputs, and generating questions requiring higher levels of cognition. These trends point to NQG as a bellwether for NLP, about how human intelligence embodies the skills of curiosity and integration.   We present a comprehensive survey of neural question generation, examining the corpora, methodologies, and evaluation methods. From this, we elaborate on what we see as emerging on NQG's trend: in terms of the learning paradigms, input modalities, and cognitive levels considered by NQG.  We end by pointing out the potential directions ahead.   
 Unsupervised domain adaptation  is the task of modifying a statistical model trained on labeled data from a source domain to achieve better performance on data from a target domain, with access to only unlabeled data in the target domain. % Existing state-of-the-art UDA approaches use neural networks to learn representations that can predict the values of subset of important features called ``pivot features.'' %on combined data from the source and target domains. % In this work, we show that it is possible to improve on these methods by jointly training the representation learner with the task learner, and examine the importance of existing pivot selection methods. % % Our jointly trained model is competitive with the state of the art, while oracle pivot selection shows that there is still room for improvement on this task. % Our results show competitive performance with a simpler model. 
   Reading Comprehension has received significant attention in recent years as high quality Question Answering  datasets have become available. Despite state-of-the-art methods achieving strong overall accuracy, Multi-Hop  reasoning remains particularly challenging. To address MH-QA specifically, we propose a Deep Reinforcement Learning based method capable of learning sequential reasoning across large collections of documents so as to pass a query-aware, fixed-size context subset to existing models for answer extraction. Our method is comprised of two stages: a linker, which decomposes the provided support documents into a graph of sentences, and an extractor, which learns where to look based on the current question and already-visited sentences. The result of the linker is a novel graph structure at the sentence level that preserves logical flow while still allowing rapid movement between documents. Importantly, we demonstrate that the sparsity of the resultant graph is invariant to context size. This translates to fewer decisions required from the Deep-RL trained extractor, allowing the system to scale effectively to large collections of documents.       The importance of sequential decision making in the document traversal step is demonstrated by comparison to standard IE methods, and we additionally introduce a BM25-based IR baseline that retrieves documents relevant to the query only. We examine the integration of our method with existing models on the recently proposed QAngaroo benchmark and achieve consistent increases in accuracy across the board, as well as a 2-3x reduction in training time.         % 
   Text classification approaches have usually required task-specific model architectures and huge labeled datasets. Recently, thanks to the rise of text-based transfer learning techniques, it is possible to pre-train a language model in an unsupervised manner and leverage them to perform effectively on downstream tasks. In this work we focus on Japanese and show the potential use of transfer learning techniques in text classification. Specifically, we perform binary and multi-class sentiment classification on the Rakuten product review and Yahoo movie review datasets. We show that transfer learning-based approaches perform better than task-specific models trained on 3 times as much data. Furthermore, these approaches perform just as well for language modeling pre-trained on $\frac{1}{30}$ of Wikipedia. We release our pre-trained models and code as open source. 
 % Personalized dialogue agents have received considerable attention in the research community since they can make chit-chat systems more consistent.  %In this paper, we propose Persona-Agnostic Meta-Learning , an extension from Model-Agnostic Meta-Learning , to personalize a dialog agent to improve dialog consistency. Our model learns to quickly switch to different personas in response to the user, by leveraging few dialogues collected from the same user. This is more efficient than conditioning the response on manually-defined persona descriptions. Collecting such descriptions to personalize a dialogue agent is expensive and time-consuming. Empirical results on Persona-chat dataset~ indicate that our proposed PAML outperforms non-meta learning baseline training in terms of human-evaluated fluency and consistency, and on automatic evaluation metrics.  Existing personalized dialogue models use human designed persona descriptions to improve dialogue consistency. Collecting such descriptions from existing dialogues is expensive and requires hand-crafted feature designs. In this paper, we propose to extend Model-Agnostic Meta-Learning ~ to personalized dialogue learning without using any persona descriptions. Our model learns to quickly adapt to new personas by leveraging only a few dialogue samples collected from the same user, which is fundamentally different from conditioning the response on the persona descriptions. Empirical results on Persona-chat dataset~ indicate that our solution outperforms non-meta-learning baselines using automatic evaluation metrics, and in terms of human-evaluated fluency and consistency. % by meta-learning a persona we can achieve an higher dialog consistency score.  % In this paper, we propose to extend Model-Agnostic Meta-Learning ~ for personalized dialogue learning. We frame personalized dialogue learning as a meta-learning problem, and we learn to adapt to a new persona by using few dialogue traces instead of conditioning the response using its persona description. This as the advantage of not requiring an explicit persona description when creating a personalized dialogue agent. We evaluate our proposed solution using Persona chat dataset~, by clustering dialogues by the persona description. Our results shows that by meta-learning a persona we can achieve an higher dialog consistency score.  
 It has been previously observed that training Variational Recurrent Autoencoders  for text generation suffers from serious uninformative latent variables problem. The model would collapse into a plain language model that totally ignore the latent variables and can only generate repeating and dull samples. In this paper, we explore the reason behind this issue and propose an effective regularizer based approach to address it. The proposed method directly injects extra constraints on the posteriors of latent variables into the learning process of VRAE, which can flexibly and stably control the trade-off between the KL term and the reconstruction term, making the model learn dense and meaningful latent representations. The experimental results show that the proposed method outperforms several strong baselines and can make the model learn interpretable latent variables and generate diverse meaningful sentences. Furthermore, the proposed method can perform well without using other strategies, such as KL annealing.\footnote{Our code and data are available at \url{https://github.com/dayihengliu/Mu-Forcing-VRAE}} 
 We apply an ensemble pipeline composed of a character-level convolutional neural network  and a long short-term memory  as a general tool for addressing a range of disinformation problems. We also demonstrate the ability to use this architecture to transfer knowledge from labeled data in one domain to related  tasks. Character-level neural networks and transfer learning are particularly valuable tools in the disinformation space because of the messy nature of social media, lack of labeled data, and the multi-channel tactics of influence campaigns. We demonstrate their effectiveness in several tasks relevant for detecting disinformation: spam emails, review bombing, political sentiment, and conversation clustering. 
 Most neural machine translation systems are built upon subword units extracted by methods such as Byte-Pair Encoding  or wordpiece. However, the choice of number of merge operations is generally made by following existing recipes. In this paper, we conduct a systematic exploration on different numbers of BPE merge operations to understand how it interacts with the model architecture, the strategy to build vocabularies and the language pair. Our exploration could provide guidance for selecting proper BPE configurations in the future. Most prominently: we show that for LSTM-based architectures, it is necessary to experiment with a wide range of different BPE operations as there is no typical optimal BPE configuration, whereas for Transformer architectures, smaller BPE size tends to be a typically optimal choice. We urge the community to make prudent choices with subword merge operations, as our experiments indicate that a sub-optimal BPE configuration alone could easily reduce the system performance by 3--4 BLEU points. 
 Generated output from neural NLG systems often contain errors such as hallucination, repetition or contradiction. % This work focuses on designing a symbolic intermediate representation to be used in multi-stage neural generation with the intention of reducing the frequency of failed outputs. % We show that surface realization from this intermediate representation is of high quality and when the full system is applied to the E2E dataset it outperforms the winner of the E2E challenge. % Furthermore, by breaking out the surface realization step from typically end-to-end neural systems, we also provide a framework for non-neural content selection and planning systems to potentially take advantage of semi-supervised pretraining of neural surface realization models. 
 While data augmentation is an important trick to boost the accuracy of deep learning methods in computer vision tasks, its study in natural language tasks is still very limited. In this paper, we present a novel data augmentation method for neural machine translation. Different from previous augmentation methods that randomly drop, swap or replace words with other words in a sentence, we softly augment a randomly chosen word in a sentence by its contextual mixture of multiple related words. More accurately, we replace the one-hot representation of a word by a distribution  over the vocabulary, i.e., replacing the embedding of this word by a weighted combination of multiple semantically similar words. Since the weights of those words depend on the contextual information of the word to be replaced, the newly generated sentences capture much richer information than previous augmentation methods. Experimental results on both small scale and large scale machine translation datasets demonstrate the superiority of our method over strong baselines\footnote{Our code can be found at \url{https://github.com/teslacool/SCA}}.  
  Dialogue policy plays an important role in task-oriented spoken dialogue systems. It determines how to respond to users. The recently proposed deep reinforcement learning  approaches have been used for policy optimization. However, these deep models are still challenging for two reasons: 1) Many DRL-based policies are not sample-efficient. 2) Most models don't have the capability of policy transfer between different domains. In this paper, we propose a universal framework, AgentGraph, to tackle these two problems. The proposed AgentGraph is the combination of GNN-based architecture and DRL-based algorithm. It can be regarded as one of the multi-agent reinforcement learning approaches. Each agent corresponds to a node in a graph, which is defined according to the dialogue domain ontology. When making a decision, each agent can communicate with its neighbors on the graph.  Under AgentGraph framework, we further propose Dual GNN-based dialogue policy, which implicitly decomposes the decision in each turn into a high-level global decision and a low-level local decision. Experiments show that AgentGraph models significantly outperform traditional reinforcement learning approaches on most of the 18 tasks of the PyDial benchmark. Moreover, when transferred from the source task to a target task, these models not only have acceptable initial performance but also converge much faster on the target task. 
 Using different sources of information to support automated extracting of relations between biomedical concepts contributes to the development of our understanding of biological systems. The primary comprehensive source of these relations is biomedical literature. Several relation extraction approaches have been proposed to identify relations between concepts in biomedical literature, namely, using neural networks algorithms. The use of multichannel architectures composed of multiple data representations, as in deep neural networks, is leading to state-of-the-art results. The right combination of data representations can eventually lead us to even higher evaluation scores in relation extraction tasks. Thus, biomedical ontologies play a fundamental role by providing semantic and ancestry information about an entity. The incorporation of biomedical ontologies has already been proved to enhance previous state-of-the-art results.   
 Most deep learning approaches for text-to-SQL generation are limited to the WikiSQL dataset, which only supports very simple queries.  Recently, template-based and sequence-to-sequence approaches were proposed to support complex queries, which contain join queries, nested queries, and other types. However,  demonstrated that both the approaches lack the ability to generate SQL of unseen templates. In this paper, we propose a template-based one-shot learning model for the text-to-SQL generation so that the model can generate SQL of an untrained template based on a single example.  First, we classify the SQL template using the Matching Network  that is augmented by our novel architecture Candidate Search Network. Then, we fill the variable slots in the predicted template using the Pointer Network . We show that our model outperforms state-of-the-art approaches for various text-to-SQL datasets in two aspects: 1) the SQL generation accuracy for the trained templates, and 2) the adaptability to the unseen SQL templates based on a single example without any additional training.  
 Semantic parsing is the process of translating natural language utterances into logical forms, which has many important applications such as question answering and instruction following. Sequence-to-sequence models have been very successful across many NLP tasks. However, a lack of task-specific prior knowledge can be detrimental to the performance of these models. Prior work has used frameworks for inducing grammars over the training examples, which capture conditional independence properties that the model can leverage. Inspired by the recent success stories such as BERT we set out to extend this augmentation framework into two stages. The first stage is to pre-train using a corpus of augmented examples in an unsupervised manner. The second stage is to fine-tune to a domain-specific task. In addition, since the pre-training stage is separate from the training on the main task we also expand the universe of possible augmentations without causing catastrophic inference. We also propose a novel data augmentation strategy that interchanges tokens that co-occur in similar contexts to produce new training pairs. We demonstrate that the proposed two-stage framework is beneficial for improving the parsing accuracy in a standard dataset called GeoQuery for the task of generating logical forms from a set of questions about the US geography. 
  We present an unsupervised end-to-end training scheme where we discover discrete subword units from speech without using any labels. The discrete subword units are learned under an ASR-TTS autoencoder reconstruction setting, where an ASR-Encoder is trained to discover a set of common linguistic units given a variety of speakers, and a TTS-Decoder trained to project the discovered units back to the designated speech. We propose a discrete encoding method, Multilabel-Binary Vectors , to make the ASR-TTS autoencoder differentiable. We found that the proposed encoding method offers automatic extraction of speech content from speaker style, and is sufficient to cover full linguistic content in a given language. Therefore, the TTS-Decoder can synthesize speech with the same content as the input of ASR-Encoder but with different speaker characteristics, which achieves voice conversion . We further improve the quality of VC using adversarial training, where we train a TTS-Patcher that augments the output of TTS-Decoder. Objective and subjective evaluations show that the proposed approach offers strong VC results as it eliminates speaker identity while preserving content within speech. In the ZeroSpeech 2019 Challenge, we achieved outstanding performance in terms of low bitrate.  
  It has been shown that the performance of neural machine translation  drops starkly in low-resource conditions, underperforming phrase-based statistical machine translation  and requiring large amounts of auxiliary data to achieve competitive results. In this paper, we re-assess the validity of these results, arguing that they are the result of lack of system adaptation to low-resource settings. We discuss some pitfalls to be aware of when training low-resource NMT systems, and recent techniques that have shown to be especially helpful in low-resource settings, resulting in a set of best practices for low-resource NMT. In our experiments on German--English with different amounts of IWSLT14 training data, we show that, without the use of any auxiliary monolingual or multilingual data, an optimized NMT system can outperform PBSMT with far less data than previously claimed. We also apply these techniques to a low-resource Korean--English dataset, surpassing previously reported results by 4 BLEU. 
 The variational autoencoder  can learn the manifold of natural images on certain datasets, as evidenced by meaningful interpolation or extrapolation in the continuous latent space. However, on discrete data such as text, it is unclear if unsupervised learning can discover a similar latent space that allows controllable manipulation. In this work, we find that sequence VAEs trained on text fail to properly decode when the latent codes are manipulated, because the modified codes often land in holes or vacant regions in the aggregated posterior latent space, where the decoding network fails to generalize. Both as a validation of the explanation and as a fix to the problem, we propose to constrain the posterior mean to a learned probability simplex, and perform manipulation within this simplex.  Our proposed method mitigates the latent vacancy problem and achieves the first success in unsupervised learning of controllable representations for text. Empirically, our method outperforms unsupervised baselines and strong supervised approaches on text style transfer, and is capable of performing more flexible fine-grained control over text generation than existing methods. % On automatic evaluation metrics used in text style transfer, even with the decoding network trained from scratch, our method achieves comparable results with state-of-the-art supervised approaches leveraging large-scale pre-trained models for generation. % Furthermore, it is capable of performing more flexible fine-grained control over text generation than existing methods. 
  A type description is a succinct noun compound which helps human and machines to quickly grasp the informative and distinctive information of an entity. Entities in most knowledge graphs  still lack such descriptions, thus calling for automatic methods to supplement such information. However, existing generative methods either overlook the grammatical structure or make factual mistakes in generated texts. To solve these problems, we propose a head-modifier template-based method to ensure the readability and data fidelity of generated type descriptions. We also propose a new dataset and two automatic metrics for this task. Experiments show that our method improves substantially compared with baselines and achieves state-of-the-art performance on both datasets.  
   There has been significant interest recently in learning multilingual word embeddings -- in which semantically similar words across languages have similar embeddings. State-of-the-art approaches have relied on expensive labeled data, which is unavailable for low-resource languages, or have involved post-hoc unification of monolingual embeddings. In the present paper, we investigate the efficacy of multilingual embeddings learned from weakly-supervised image-text data. In particular, we propose methods for learning multilingual embeddings using image-text data, by enforcing similarity between the representations of the image and that of the text. Our experiments reveal that even without using any expensive labeled data, a bag-of-words-based embedding model trained on image-text data achieves performance comparable to the state-of-the-art on crosslingual semantic similarity tasks. 
  Word representation is a key component in neural-network-based sequence labeling systems. However, representations of unseen or rare words trained on the end task are usually poor for appreciable performance. This is commonly referred to as the out-of-vocabulary  problem. In this work, we address the OOV problem in sequence labeling using only training data of the task. To this end, we propose a novel method to predict representations for OOV words from their surface-forms  and contexts. The method is specifically designed to avoid the error propagation problem suffered by existing approaches in the same paradigm. To evaluate its effectiveness, we performed extensive empirical studies on four part-of-speech tagging  tasks and four named entity recognition  tasks. Experimental results show that the proposed method can achieve better or competitive performance on the OOV problem compared with existing state-of-the-art methods.   
 Typical methods for unsupervised text style transfer often rely on two key ingredients: 1) seeking the explicit disentanglement of the content and the attributes, and 2) troublesome adversarial learning.  In this paper, we show that neither of these components is indispensable.  We propose a new framework that utilizes the gradients to revise the sentence in a continuous space during inference to achieve text style transfer. Our method consists of three key components: a variational auto-encoder , some attribute predictors , and a content predictor. The VAE and the two types of predictors enable us to perform gradient-based optimization in the continuous space, which is mapped from sentences in a discrete space, to find the representation of a target sentence with the desired attributes and preserved content.  Moreover, the proposed method naturally has the ability to simultaneously manipulate multiple fine-grained attributes, such as sentence length and the presence of specific words, when performing text style transfer tasks. Compared with previous adversarial learning based methods, the proposed method is more interpretable, controllable and easier to train. Extensive experimental studies on three popular text style transfer tasks show that the proposed method significantly outperforms five state-of-the-art methods. 
  %Long-Short Term Memory  models led to remarkable progress on many NLP tasks. As a consequence, there has been increasing interest in understanding what kind of information such models encode and to what extent they process language as humans do. In this line of work, we aim to uncover LSTM-based Seq2Seq models' biases with respect to ``natural" word-order constraints. We implement two Seq2Seq agents, that must instruct each other about paths in a   %primitive gridworld, and are trained with languages that respect, to   %different degrees, the core constraints of temporal iconicity, the   %trade-off between expressing constituent structure through word order or   %with explicit markers, and long-distance dependency minimization. We   %study how these constraints affect both the difficulty of single   %agents to interpret and produce different languages, and   %language stability across multiple agent generations in an iterated   %learning setup. We find that the neural network models follow some natural patterns while being insensitive to others.   %We find that simpler LSTM agents are affected, to some extent, by all constraints, whereas more powerful architectures endowed  with attention are not sensitive to some natural pressures.   % Our work thus provides insights on how to encourage more natural protocols in communication-enhanced agents.   Sequence-processing neural networks led to remarkable progress on many NLP tasks. As a consequence, there has been increasing interest in understanding to what extent they process language as humans do. We aim here to uncover which biases such models display with respect to ``natural" word-order constraints. We train models to communicate about paths in a simple gridworld, using miniature languages that reflect or violate various natural language trends, such as the tendency to avoid redundancy or to minimize long-distance dependencies. We study how the controlled characteristics of our miniature languages affect individual learning and their stability across multiple network generations. The results draw a mixed picture. On the one hand, neural networks show a strong tendency to avoid long-distance dependencies. On the other hand, there is no clear preference for the efficient, non-redundant  encoding of information that is widely attested in natural language. We thus suggest inoculating a notion of ``effort'' into neural networks, as a possible way to make their linguistic behaviour more human-like.   
 The recent introduction of entity-centric implicit network representations of unstructured text offers novel ways for exploring entity relations in document collections and streams efficiently and interactively. Here, we present TopExNet as a tool for exploring entity-centric network topics in streams of news articles. The application is available as a web service at \url{https://topexnet.ifi.uni-heidelberg.de}. 
 Recurrent networks have achieved great success on various sequential tasks with the assistance of complex recurrent units, but suffer from severe computational inefficiency due to weak parallelization. One direction to alleviate this issue is to shift heavy computations outside the recurrence.  In this paper, we propose a lightweight recurrent network, or LRN.  LRN uses input and forget gates to handle long-range dependencies as well as gradient vanishing and explosion, with all parameter-related calculations factored outside the recurrence. The recurrence in LRN only manipulates the weight assigned to each token, tightly connecting LRN with self-attention networks.  We apply LRN as a drop-in replacement of existing recurrent units in several neural sequential models. Extensive experiments on six NLP tasks show that LRN yields the best running efficiency with little or no loss in model performance.\footnote{Source code is available at \url{https://github.com/bzhangGo/lrn}.} 
   The sequence-to-sequence paradigm employed by neural text-to-SQL models typically performs token-level decoding and does not consider generating SQL hierarchically from a grammar. Grammar-based decoding has shown significant improvements for other semantic parsing tasks, but SQL and other general programming languages have complexities not present in logical formalisms that make writing hierarchical grammars difficult.  We introduce techniques to handle these complexities, showing how to construct a schema-dependent grammar with minimal over-generation. We analyze these techniques on ATIS and , two challenging text-to-SQL datasets, demonstrating that they yield 14--18\% relative reductions in error. 
  %We present extensions to a transition-based Abstract Meaning Represenation  parser. Our starting point is the Stack-LSTM transition-based AMR parser  that we modify with several improvements:  combination of several AMR to text alignments and soft alignments via attention,  pre-processed concept identification,  pre-processed named entities,  contextualized embeddings and  policy Learning. We achieve a highly competitive performance that is comparable with the best published results. We show an in-depth study ablating each of the new components of the parser.  %We present an augmented transition-based parser to transform a sentence into an Abstract Meaning Representation .   Our work involves enriching the Stack-LSTM transition-based AMR parser  by  augmenting training with Policy Learning and rewarding the Smatch score of sampled graphs. In addition, we also combined several AMR-to-text alignments with an attention mechanism and we supplemented the parser with pre-processed concept identification, named entities and contextualized embeddings. We achieve a highly competitive performance that is comparable to the best published results. We show an in-depth study ablating each of the new components of the parser.  
 Open information extraction  is the task of extracting open-domain assertions from natural language sentences. A key step in open IE is confidence modeling, ranking the extractions based on their estimated quality to adjust precision and recall of extracted assertions. We found that the extraction likelihood, a confidence measure used by current supervised open IE systems, is not well calibrated when comparing the quality of assertions extracted from  sentences. We propose an additional binary classification loss to calibrate the likelihood to make it more globally comparable, and an iterative learning process, where extractions generated by the open IE model are incrementally included as training samples to help the model learn from trial and error. Experiments on OIE2016 demonstrate the effectiveness of our method.\footnote{Code and data are available at \url{https://github.com/jzbjyb/oie_rank}} 
 We propose a novel application of self-attention networks towards grammar induction.  We present an attention-based supertagger for a refined type-logical grammar, trained on constructing types inductively. In addition to achieving a high overall type accuracy, our model is able to learn the syntax of the grammar's type system along with its denotational semantics.  This lifts the closed world assumption commonly made by lexicalized grammar supertaggers, greatly enhancing its generalization potential.  This is evidenced both by its adequate accuracy over sparse word types and its ability to correctly construct complex types never seen during training, which, to the best of our knowledge, was as of yet unaccomplished. 
 Various encoder-decoder models have been applied to response generation in open-domain dialogs, but a majority of conventional models directly learn a mapping from lexical input to lexical output without explicitly modeling intermediate representations. Utilizing language hierarchy and modeling intermediate information have been shown to benefit many language understanding and generation tasks. Motivated by Broca's aphasia, we propose to use a content word sequence as an intermediate representation for open-domain response generation. Experimental results show that the proposed method improves content relatedness of produced responses, and our models can often choose correct grammar for generated content words. Meanwhile, instead of evaluating complete sentences, we propose to compute conventional metrics on content word sequences, which is a better indicator of content relevance.  
   %Existing deep learning methods for dialogue response generation mainly use sequence-to-sequence  models. %More advanced methods also consider dialogue history in multi-turn chatting. Existing neural models for dialogue response generation assume that utterances are sequentially organized.~However, many real-world dialogues involve multiple interlocutors , where the assumption does not hold as utterances from different interlocutors can occur ``in parallel.''~This paper generalizes existing sequence-based models to a Graph-Structured neural Network  for dialogue modeling.~The core of GSN is a graph-based encoder that can model the information flow along the graph-structured dialogues . Experimental results show that GSN significantly outperforms existing sequence-based models. 
 Rumours have existed for a long time and have been known for serious consequences.  The rapid growth of social media platforms has multiplied the negative impact of rumours; it thus becomes  important to early detect them.  Many methods have been introduced to detect rumours using the content or the social context of news.  However, most existing methods ignore or do not explore effectively  the propagation pattern of  news in social media, including the sequence of interactions of  social media users with  news across time.  In this work, we propose a novel method for rumour detection based on deep learning.  Our method leverages the propagation process of the news by learning the users' representation and the temporal interrelation of users' responses.  Experiments conducted on Twitter and Weibo datasets demonstrate the state-of-the-art performance of the proposed method. 
 There have been multiple recent proposals on using deep neural networks for code search using natural language. Common across these proposals is the idea of embedding code and natural language queries into real vectors and then using vector distance to approximate semantic correlation between code and the query. Multiple approaches exist for learning these embeddings, including  techniques, which rely only on a corpus of code examples, and  techniques, which use an  corpus of paired code and natural language descriptions. The goal of this supervision is to produce embeddings that are more similar for a query and the corresponding desired code snippet.  Clearly, there are choices in whether to use supervised techniques at all, and if one does, what sort of network and training to use for supervision. This paper is the first to evaluate these choices systematically.  To this end, we assembled implementations of state-of-the-art techniques to run on a common platform, training and evaluation corpora. To explore the design space in network complexity, we also introduced a new design point that is a  supervision extension to an existing unsupervised technique.  Our evaluation shows that: 1. adding supervision to an existing unsupervised technique can improve performance, though not necessarily by much; 2. simple networks for supervision can be more effective that more sophisticated sequence-based networks for code search; 3. while it is common to use docstrings to carry out supervision, there is a sizable gap between the effectiveness of docstrings and a more query-appropriate supervision corpus. 
 Neural machine translation - using neural networks to translate human language - is an area of active research exploring new neuron types and network topologies with the goal of dramatically improving machine translation performance. Current state-of-the-art approaches, such as the multi-head attention-based transformer, require very large translation corpuses and many epochs to produce models of reasonable quality. Recent attempts to parallelize the official TensorFlow ``Transformer'' model across multiple nodes have hit roadblocks due to excessive memory use and resulting out of memory errors when performing MPI collectives.  This paper describes modifications made to the Horovod MPI-based distributed training framework to reduce memory usage for transformer models by converting assumed-sparse tensors to dense tensors, and subsequently replacing sparse gradient gather with dense gradient reduction. The result is a dramatic increase in scale-out capability, with CPU-only scaling tests achieving 91\% weak scaling efficiency up to 1200 MPI processes , and up to 65\% strong scaling efficiency up to 400 MPI processes  using the Stampede2 supercomputer. 
 We study the problem of knowledge graph  embedding. A widely-established assumption to this problem is that similar entities are likely to have similar relational roles. However, existing related methods derive KG embeddings mainly based on triple-level learning, which lack the capability of capturing long-term relational dependencies of entities. Moreover, triple-level learning is insufficient for the propagation of semantic information among entities, especially for the case of cross-KG embedding. In this paper, we propose recurrent skipping networks , which employ a skipping mechanism to bridge the gaps between entities. RSNs integrate recurrent neural networks  with residual learning to efficiently capture the long-term relational dependencies within and between KGs. We design an end-to-end framework to support RSNs on different tasks. Our experimental results showed that RSNs outperformed state-of-the-art embedding-based methods for entity alignment and achieved competitive performance for KG completion. 
 The cloud-based speech recognition/API provides developers or enterprises an easy way to create speech-enabled features in their applications. However, sending audios about personal or company internal information to the cloud, raises concerns about the privacy and security issues. The recognition results generated in cloud may also reveal some sensitive information. This paper proposes a deep polynomial network  that can be applied to the encrypted speech as an acoustic model. It allows clients to send their data in an encrypted form to the cloud to ensure that their data remains confidential, at mean while the DPN can still make frame-level predictions over the encrypted speech and return them in encrypted form. One good property of the DPN is that it can be trained on unencrypted speech features in the traditional way. To keep the cloud away from the raw audio and recognition results, a cloud-local joint decoding framework is also proposed. We demonstrate the effectiveness of model and framework on the Switchboard and Cortana voice assistant tasks with small performance degradation and latency increased comparing with the traditional cloud-based DNNs.  
   	 	 There has been an explosion of multimodal content generated on social media networks in the last few years, which has necessitated a deeper understanding of social media content and user behavior. We present a novel content-independent content-user-reaction model for social multimedia content analysis. Compared to prior works that generally tackle semantic content understanding and user behavior modeling in isolation, we propose a generalized solution to these problems within a unified framework.  We embed users, images and text drawn from open social media in a common multimodal geometric space, using a novel loss function designed to cope with distant and disparate modalities, and thereby enable seamless three-way retrieval.   Our model not only outperforms unimodal embedding based methods on cross-modal retrieval tasks but also shows improvements stemming from jointly solving the two tasks on Twitter data.  We also show that the user embeddings learned within our joint multimodal embedding model are better at predicting user interests compared to those learned with unimodal content on Instagram data.  Our framework thus goes beyond the prior practice of using explicit leader-follower link information to establish affiliations by extracting implicit content-centric affiliations from isolated users.   We provide qualitative results to show that the user clusters emerging from learned embeddings have consistent semantics and the ability of our model to discover fine-grained semantics from noisy and unstructured data.  Our work reveals that social multimodal content is inherently multimodal and possesses a consistent structure because in social networks meaning is created through interactions between users and content.          
  The relationship between two entities in a sentence is often implied by word order and common sense, rather than an explicit predicate. For example, it is evident that ``Fed chair Powell indicates rate hike'' implies  and . These tuples are just as significant as the explicit-predicate tuple , but have much lower recall under traditional Open Information Extraction  systems. Implicit tuples are our term for this type of extraction where the relation is not present in the input sentence. There is very little OpenIE training data available relative to other NLP tasks and none focused on implicit relations. We develop an open source, parse-based tool for converting large reading comprehension datasets to OpenIE datasets and release a dataset 35x larger than previously available by sentence count. A baseline neural model trained on this data outperforms previous methods on the implicit extraction task.  
   Image captioning is a challenging task and attracting more and more attention in the field of Artificial Intelligence, and which can be applied to efficient image retrieval, intelligent blind guidance and human-computer interaction, etc. In this paper, we present a survey on advances in image captioning based on Deep Learning methods, including Encoder-Decoder structure, improved methods in Encoder, improved methods in Decoder, and other improvements. Furthermore, we discussed future research directions. 
 This article proposes a biologically inspired neurocomputational architecture which learns associations between words and referents in different contexts, considering evidence collected from the literature of Psycholinguistics and Neurolinguistics. The multi-layered architecture takes as input raw images of objects  and streams of word's phonemes , builds an adequate representation, recognizes the current context, and associates label with referents incrementally, by employing a Self-Organizing Map which creates new association nodes  as required, adjusts the existing prototypes to better represent the input stimuli and removes prototypes that become obsolete/unused. The model takes into account the current context to retrieve the correct meaning of words with multiple meanings. Simulations show that the model can reach up to 78\% of word-referent association accuracy in ambiguous situations and approximates well the learning rates of humans as reported by three different authors in five Cross-Situational Word Learning experiments, also displaying similar learning patterns in the different learning conditions. 
 Automated prediction of public speaking performance enables novel systems for tutoring public speaking skills. We use the largest open repository---TED Talks---to predict the ratings provided by the online viewers. The dataset contains over 2200 talk transcripts and the associated meta information including over 5.5 million ratings from spontaneous visitors to the website. We carefully removed the bias present in the dataset  by modeling the data generating process using a causal diagram. We use a word sequence based recurrent architecture and a dependency tree based recursive architecture as the neural networks for predicting the TED talk ratings. Our neural network models can predict the ratings with an average F-score of 0.77 which largely outperforms the competitive baseline method. 
 Text matching is the core problem in many natural language processing  tasks, such as information retrieval, question answering, and conversation. Recently, deep leaning technology has been widely adopted for text matching, making neural text matching a new and active research domain. With a large number of neural matching models emerging rapidly, it becomes more and more difficult for researchers, especially those newcomers, to learn and understand these new models. Moreover, it is usually difficult to try these models due to the tedious data pre-processing, complicated parameter configuration, and massive optimization tricks, not to mention the unavailability of public codes sometimes. Finally, for researchers who want to develop new models, it is also not an easy task to implement a neural text matching model from scratch, and to compare with a bunch of existing models. In this paper, therefore, we present a novel system, namely MatchZoo, to facilitate the learning, practicing and designing of neural text matching models. The system consists of a powerful matching library and a user-friendly and interactive studio, which can help researchers: 1) to learn state-of-the-art neural text matching models systematically, 2) to train, test and apply these models with simple configurable steps; and 3) to develop their own models with rich APIs and assistance.  %The system now provides an online service and would be a software package for local installation in the short future.    % ., and paraphrase identification. Building effective text matching model has become the major challenge in these tasks.  % In recent years, researchers have proposed a number of neural text matching models, which have achieved the state-of-the-art performance in many NLP tasks.  % However, it is often not easy to fairly compare the existing models.  % The key barriers come from not only the implementation of these neural matching models, but also the complicated data processing steps as well as the unknown tricks in tuning the neural models. % In this paper, we present a general-purpose text matching system for easing the process of applying neural text matching models for matching based NLP tasks.  % Our system uses a state-of-the-art implementation of neural text matching models, and is designed to lower threshold of applying the neural matching models.  % Advantages of the system include: 1) providing a unified framework for different neural matching models. 2) easing the implementation of neural matching models in real world applications. 3) lowering the threshold of designing new matching models. % %easing the parameter tuning with the automatic machine learning components.  % The system has been deployed as a online service and can be access from the Internet.  
 Despite the remarkable progress made in synthesizing emotional speech from text, it is still challenging to provide emotion information to existing speech segments.  Previous methods mainly rely on parallel data, and few works have studied the generalization ability for one model to transfer emotion information across different languages. % To cope with such problems, we propose an emotion transfer system named ET-GAN, for learning language-independent emotion transfer from one emotion to another without parallel training samples.  % Based on cycle-consistent generative adversarial network, our method ensures the transfer of only emotion information across speeches with simple loss designs.  % Besides, we introduce an approach for migrating emotion information across different languages by using transfer learning. The experiment results show that our method can efficiently generate high-quality emotional speech for any given emotion category, without aligned speech pairs.  
  %Reviews posted by users to comment products contain rich information of both users and products to enhance the representation of users and products. %They have been used in many recommender systems to enhance the representation of users and products, and alleviate the sparsity problem of rating matrix. Existing review-based recommendation methods usually use the same model to learn the representations of all users/items from reviews posted by users towards items. However, different users have different preference and different items have different characteristics. Thus, the same word or the similar reviews may have different informativeness for  different users and items. In this paper we propose a neural recommendation approach with personalized attention to learn personalized representations of users and items from reviews. We use a review encoder to learn representations of reviews from words, and a user/item encoder to learn representations of users or items from reviews. We propose a personalized attention model, and apply it to both review and user/item encoders to select different important words and reviews for different users/items. Experiments on five datasets validate our approach can effectively improve the performance of neural recommendation.  
 We present a mechanism to compute a sketch  of how a complex modular deep network processes its inputs. The sketch summarizes essential information about the inputs and outputs of the network and can be used to quickly identify key components and summary statistics of the inputs. Furthermore, the sketch is recursive and can be unrolled to identify sub-components of these components and so forth, capturing a potentially complicated DAG structure. These sketches erase gracefully; even if we erase a fraction of the sketch at random, the remainder still retains the ``high-weight'' information present in the original sketch. The sketches can also be organized in a repository to implicitly form a ``knowledge graph''; it is possible to quickly retrieve sketches in the repository that are related to a sketch of interest; arranged in this fashion, the sketches can also be used to learn emerging concepts by looking for new clusters in sketch space. Finally, in the scenario where we want to learn a ground truth deep network, we show that augmenting input/output pairs with these sketches can theoretically make it easier to do so. 
 The social media revolution has produced a plethora of web services to which users can easily upload and share multimedia documents. Despite the popularity and convenience of such services, the sharing of such inherently personal data, including speech data, raises obvious security and privacy concerns. In particular, a user's speech data may be acquired and used with speech synthesis systems to produce high-quality speech utterances which reflect the same user's speaker identity. These utterances may then be used to attack speaker verification systems. One solution to mitigate these concerns involves the concealing of speaker identities before the sharing of speech data. For this purpose, we present a new approach to speaker anonymization. The idea is to extract linguistic and speaker identity features from an utterance and then to use these with neural acoustic and waveform models to synthesize anonymized speech. The original speaker identity, in the form of timbre, is suppressed and replaced with that of an anonymous pseudo identity. The approach exploits state-of-the-art x-vector speaker representations. These are used to derive anonymized pseudo speaker identities through the combination of multiple, random speaker x-vectors. Experimental results show that the proposed approach is effective in concealing speaker identities. It increases the equal error rate of a speaker verification system while maintaining high quality, anonymized speech.  
 In neural dialogue modeling, a neural network is trained to predict the next utterance, and at inference time, an approximate decoding algorithm is used to generate next utterances given previous ones. While this autoregressive framework allows us to model the whole conversation during training, inference is highly suboptimal, as a wrong utterance can affect future utterances. While beam search yields better results than greedy search does, we argue that it is still  in the context of the entire conversation, in that it does not consider future utterances. We propose a novel approach for conversation-level inference by explicitly modeling the dialogue partner and running beam search across multiple conversation turns. Given a set of candidates for next utterance, we unroll the conversation for a number of turns and identify the candidate utterance in the initial hypothesis set that gives rise to the most likely sequence of future utterances. We empirically validate our approach by conducting human evaluation using the Persona-Chat dataset~, and find that our multi-turn beam search generates significantly better dialogue responses. We propose three approximations to the partner model, and observe that more informed partner models give better performance. 
   It has been previously noted that neural machine translation  is very sensitive to domain shift. In this paper, we argue that this is a dual effect of the highly lexicalized nature of NMT, resulting in failure for sentences with large numbers of unknown words, and lack of supervision for domain-specific words.  To remedy this problem, we propose an unsupervised adaptation method which fine-tunes a pre-trained out-of-domain NMT model using a pseudo-in-domain corpus. Specifically, we perform lexicon induction to extract an in-domain lexicon, and construct a pseudo-parallel in-domain corpus by performing word-for-word back-translation of monolingual in-domain target sentences. In five domains over twenty pairwise adaptation settings and two model architectures, our method achieves consistent improvements without using any in-domain parallel sentences, improving up to 14 BLEU over unadapted models, and up to 2 BLEU over strong back-translation baselines. {\let\thefootnote\relax\footnote{{Code/scripts are released at \url{https://github.com/junjiehu/dali}.}}}   %\footnote{Code to replicate experiments will be released upon acceptance. }  \jh{hide the superscript of the footnote in case there is a mismatch with the one before abstract due} 
 We investigate adaptive ensemble weighting for Neural Machine Translation, addressing the case of improving performance on a new and potentially unknown domain without sacrificing performance on the original domain. We adapt sequentially across two Spanish-English and three English-German tasks, comparing unregularized fine-tuning, L2 and Elastic Weight Consolidation. We then report a novel scheme for adaptive NMT ensemble decoding by extending Bayesian Interpolation with source information, and show strong improvements across test domains without access to the domain label. 
 This paper examines various unsupervised pretraining objectives for learning dialog context representations. Two novel methods of pretraining dialog context encoders are proposed, and a total of four methods are examined. Each pretraining objective is fine-tuned and evaluated on a set of downstream dialog tasks using the MultiWoz dataset and strong performance improvement is observed. Further evaluation shows that our pretraining objectives result in not only better performance, but also better convergence, models that are less data hungry and have better domain \linebreak generalizability. 
 Identifying the unknown  user intents that have never appeared in the training set is a challenging task in the dialogue system. In this paper, we present a two-stage method for detecting unknown intents. We use bidirectional long short-term memory  network with the margin loss as the feature extractor. With margin loss, we can learn discriminative deep features by forcing the network to maximize inter-class variance and to minimize intra-class variance. Then, we feed the feature vectors to the density-based novelty detection algorithm, local outlier factor , to detect unknown intents. Experiments on two benchmark datasets show that our method can yield consistent improvements compared with the baseline methods. 
  This paper presents a new approach that extends Deep Dyna-Q  by incorporating a Budget-Conscious Scheduling  to best utilize a fixed, small amount of user interactions  for learning task-oriented dialogue agents. BCS consists of  a Poisson-based global scheduler to allocate budget over different stages of training;  a controller to decide at each training step whether the agent is trained using real or simulated experiences;  a user goal sampling module to generate the experiences that are most effective for policy learning. Experiments on a movie-ticket booking task with simulated and real users show that our approach leads to significant improvements in success rate over the state-of-the-art baselines given the fixed budget.  % This paper presents a new approach to best utilize a fixed, small number of user interactions  for training task-oriented dialogue agents, by extending Deep Dyna-Q  to incorporate Budget-Conscious Scheduling . BCS consists of  a Poisson-based global scheduler to allocate budget over the different stages of training;  a controller to decide at each training step whether the agent is trained using real or simulated experiences;  a user goal sampling module to generate the experiences that are most effective for dialogue policy learning. Experiments on a movie-ticket booking task with simulated and real users show that our approach leads to significantly higher success rates over the state-of-the-art baselines given a fixed budget.  % Training dialogue agents to accomplish a task with limited budget via reinforcement learning is challenging, because it requires a lot of interactions from real users. In this paper, we propose the Tactical Budget Scheduling  framework to learn dialogue policies effectively by making full use of the limited budget from real users. First, a Poisson-based algorithm is designed to allocate budget during training. Then, based on pre-allocated budget, we explore the use of active learning to obtain high-quality real user conversation experiences. In this way, we encourage the real users to generate dialogue experiences in the state-action space where the agent has not  explored, and train the dialogue agent to learn from human teaching via imitation learning and human feedback via reinforcement learning. Experiments on a movie-ticket booking task with simulated and real users show that our approach leads to significant improvements over the state-of-the-art baselines.  %is typically formulated as a reinforcement learning  problem. However, it requires a large number of interactions with real users, resulting in poor performance on low-resource scenarios. In this paper, we explore to train a dialogue agent with a limited budget, which is more common in practice. To this end, we propose a novel Budget-Conscious Scheduling  framework to make full use of the budget to learn a good dialogue policy. First of all, in order to satisfy the constraints of the budget, a Poisson-based budget allocation algorithm is designed to allocate budgets during training. Then based on pre-assigned budgets, we explore the use of active learning for obtaining high-quality and informative conversation experiences. In this way, we encourage the real or simulated user to generate dialogue experiences in the state-action space where the agent has not  explored, and train the dialogue agent via a hybrid imitation and reinforcement learning method with which the agent can effectively learn from interactions with users by learning from human teaching and feedback. Experiments in a movie-ticket booking domain with simulated and real users show that our approach leads to significant improvements over strong baselines.  
  Self-attention networks  %have received increasing research attention %.  By  have attracted a lot of interests  due to their high parallelization and strong performance on a variety of NLP tasks, e.g. machine translation.  Due to the lack of recurrence structure such as recurrent neural networks , SAN is ascribed to be weak at learning positional information of words for sequence modeling.  However, neither this speculation has been empirically confirmed, nor explanations for their strong performances on machine translation tasks when ``lacking positional information'' have been explored.  To this end, we propose a novel { indeed has difficulty learning the positional information even with the position embedding; and 2) SAN trained on machine translation learns better positional information than its RNN counterpart, in which position embedding plays a critical role. Although recurrence structure make the model more universally-effective on learning word order, learning objectives matter more in the downstream tasks such as machine translation. % Directional SAN, which augments SAN with recurrence modeling, performs well in both scenarios.  
 Hashtags are often employed on social media and beyond to add metadata to a textual utterance with the goal of increasing discoverability, aiding search, or providing additional semantics. However, the semantic content of hashtags is not straightforward to infer as these represent ad-hoc conventions which frequently include multiple words joined together and can include abbreviations and unorthodox spellings. We build a dataset of 12,594 hashtags split into individual segments and propose a set of approaches for hashtag segmentation by framing it as a pairwise ranking problem between candidate segmentations.\footnote{Our toolkit along with the code and data are publicly available at \url{https://github.com/mounicam/hashtag_master}} Our novel neural approaches demonstrate 24.6\% error reduction in hashtag segmentation accuracy compared to the current state-of-the-art method.  Finally, we demonstrate that a deeper understanding of hashtag semantics obtained through segmentation is useful for downstream applications such as sentiment analysis, for which we achieved a 2.6\% increase in average recall on the SemEval 2017 sentiment analysis dataset. 
 	The neural machine translation model has suffered from the lack of large-scale parallel corpora. 	In contrast, we humans can learn multi-lingual translations even without parallel texts by referring our languages to the external world. 	To mimic such human learning behavior, we employ images as pivots to enable zero-resource translation learning. 	However, a picture tells a thousand words, which makes multi-lingual sentences pivoted by the same image noisy as mutual translations and thus hinders the translation model learning. 	In this work, we propose a progressive learning approach for image-pivoted zero-resource machine translation. 	Since words are less diverse when grounded in the image, we first learn word-level translation with image pivots, and then progress to learn the sentence-level translation by utilizing the learned word translation to suppress noises in image-pivoted multi-lingual sentences. 	Experimental results on two widely used image-pivot translation datasets, IAPR-TC12 and Multi30k, show that the proposed approach significantly outperforms other state-of-the-art methods. 
  This paper proposes a novel method to inject custom terminology into neural machine translation at run time.   Previous works have mainly proposed modifications to the decoding algorithm in order to constrain the output to include run-time-provided target terms. While being effective,  these constrained decoding methods add, however, significant computational overhead to the inference step, and, as we show in this paper, can be brittle when tested in realistic conditions. In this paper we approach the problem by training a neural MT system to learn how to use custom terminology when provided with the input. Comparative experiments show that our method is not only more effective than a state-of-the-art implementation of constrained decoding, but is also as fast as constraint-free decoding.    
 Noise and domain are important aspects of data quality for neural machine translation. Existing research focus  separately on domain-data selection, clean-data selection,  or their static combination, leaving the dynamic interaction across them not explicitly examined.  This paper introduces a ``co-curricular learning'' method to compose dynamic domain-data selection with dynamic clean-data selection, for transfer learning across both capabilities. We apply an EM-style optimization procedure to further refine the ``co-curriculum''. Experiment results and analysis with two domains demonstrate the effectiveness of the method and the properties of data scheduled by the co-curriculum.     Noise and domain are important aspects of data quality for neural machine translation. Research has focused separately on domain-data selection, or clean-data selection,  or their static combination, leaving the dynamic interaction across them not explicitly examined. This paper introduces a ``co-curricular learning'' method to compose dynamic domain-data selection with dynamic clean-data selection, to transfer both capabilities into a final co-curriculum that is better than either constituent one or their static combination, particularly on noisy parallel data. We introduce an optimization procedure to bootstrap the composed curriculum, and gain additional improvements, especially with small models.    %an effect usually seen in model distillation, without a teacher in our case.     % introduces a ``co-curricular learning'' method to compose dynamic domain-data selection %with dynamic clean-data selection, %to transfer both capabilities into a final ``co-curriculum''.  %Our method takes as input a small source monolingual corpus that is in-domain, and a small, trusted but %out-of-domain parallel corpus. It then schedules training examples from a large, background dataset to train %an NMT model.  %We  apply an EM-style optimization procedure %to further refine the  co-curriculum. %Results show that NMT models trained by our method translate the in-domain data  better than models trained on either of the original data selection do, in particular for domain-data selection on noisy parallel corpora.  
   Simultaneous translation is widely useful %in many scenarios   but remains one of the most difficult tasks in NLP.   Previous work either uses fixed-latency policies, or train   a complicated two-staged model using reinforcement learning.   We propose a much simpler { to greatly simplify training.   %is as  easy as local training.   Experiments on  Chinese$\leftrightarrow$English simultaneous translation   show that our work leads to flexible policies that achieve better BLEU scores and lower latencies   compared to   both fixed and RL-learned policies. % and reinforcement learning method. 
 Zero-shot translation, translating between language pairs on which a Neural Machine Translation  system has never been trained, is an emergent property when training the system in multilingual settings.  However, na\"ive training for zero-shot NMT easily fails, and is sensitive to hyper-parameter setting. The performance typically lags far behind the more conventional pivot-based approach which translates twice using a third language as a pivot. In this work, we address the degeneracy problem due to capturing spurious correlations by quantitatively analyzing the mutual information between language IDs of the source and decoded sentences. Inspired by this analysis, we propose to use two simple but effective approaches:  decoder pre-training;  back-translation. These methods show significant improvement  over the vanilla zero-shot translation on three challenging multilingual datasets, and achieve similar or better results than the pivot-based approach. %The proposed approach also significantly improves the system on pairs that have no available pivots. 
 { \renewcommand{\thefootnote}{\fnsymbol{footnote}} \footnotetext[1]{Equal contribution} \footnotetext[2]{Corresponding author} } In aspect-level sentiment classification , it is prevalent to equip dominant neural models with attention mechanisms, for the sake of acquiring the importance of each context word on the given aspect. However, such a mechanism tends to excessively focus on a few frequent words with sentiment polarities, while ignoring infrequent ones. In this paper, we propose a progressive self-supervised attention learning approach for neural ASC models, which automatically mines useful attention supervision information from a training corpus to refine attention mechanisms. Specifically, we iteratively conduct sentiment predictions on all training instances. Particularly, at each iteration, the context word with the maximum attention weight is extracted as the one with active/misleading influence on the correct/incorrect prediction of every instance, and then the word itself is masked for subsequent iterations. Finally, we augment the conventional training objective with a regularization term, which enables ASC models to continue equally focusing on the extracted active context words while decreasing weights of those misleading ones. Experimental results on multiple datasets show that our proposed approach yields better attention mechanisms, leading to substantial improvements over the two state-of-the-art neural ASC models. %Source code and trained models are available at https://github.com/DeepLearnXMU/PSSAttention. Source code and trained models are available.\footnote[1]{https://github.com/DeepLearnXMU/PSSAttention}  
 The emotion cause extraction  task aims at discovering the potential causes behind a certain emotion expression in a document. Techniques including rule-based methods, traditional machine learning methods and deep neural networks have been proposed to solve this task. However, most of the previous work considered ECE as a set of independent clause classification problems and ignored the relations between multiple clauses in a document. In this work, we propose a joint emotion cause extraction framework, named RNN-Transformer Hierarchical Network , to encode and classify multiple clauses synchronously. RTHN is composed of a lower word-level encoder based on RNNs to encode multiple words in each clause, and an upper clause-level encoder based on Transformer to learn the correlation between multiple clauses in a document. We furthermore propose ways to encode the relative position and global predication information into Transformer that can capture the causality between clauses and make RTHN more efficient. We finally achieve the best performance among 12 compared systems and improve the F1 score of the state-of-the-art from 72.69\% to 76.77\%. 
  In Semantic Dependency Parsing , semantic relations form directed acyclic graphs, rather than trees. We propose a new iterative predicate selection  algorithm for SDP. Our IPS algorithm combines the graph-based and transition-based parsing approaches in order to handle {~semantic heads, head-selection parsing algorithms  %Semantic dependency parsers assign directed acyclic graphs to words in sentences, reflecting their semantic structure according to linguistic formalisms. Because words may have {~semantic heads, head-selection parsing algorithms from syntactic dependency parsing cannot be applied directly. We propose a novel solution to this problem with a new iterative predicate selection  algorithm. We demonstrate that we can learn better IPS state representations using multi-task learning with three formalisms; and that IPS error propagation can be reduced using policy gradient training. By combining multi-task learning and task-specific reinforcement learning, the proposed IPS model achieves a new state of the art across three linguistic formalisms. In our analysis, we observe that policy gradient training learns an easy-first strategy that is clearly different from the parsing strategies of our supervised models.  %Analysis of our experimental results demonstrates two important observations:  the proposed architecture learns to find semantic predicates iteratively,  the policy gradient training enables the model to adopt an easy-first strategy that is clearly different from supervised learning.   Semantic dependency parsing  assigns directed acyclic graphs to words in sentences, reflecting their semantic structure according to a linguistic formalism. Because words may have {  %Semantic parsing determines complex semantic relations between words. %Semantic dependency parsing graphs don't necessarily form trees. %While some neighboring relations are easy to resolve, other long-term relations are difficult to find. %Semantic dependency parsing   resolves semantic relations of argument words and their semantic predicate words in a sentence. %Unlike tree-structured syntactic dependency graphs in which each word has invariably one head word, %SDP forms a directed acyclic graph and some words in SDP have multiple predicate words %while some other words have no predicate words. %In syntactic dependency parsing, recently proposed head-selection parsers outperform existing parsers. %The head-selection parsers determine all arcs in dependency graphs simultaneously and do not exploit other dependency arcs to be created. %However, they can not be applied for SDP straightforwardly because words in SGP have multiple head words. %Therefore we expand the head-selection algorithm for an iterative algorithm that handles multiple head words and exploit other creating arcs. %In this study, we propose a novel iterative head-selection or predicate selection  algorithm. %In our proposal algorithm, parsers are able to choose which arcs are created first and which are created later in SDP. %This is a part of the non-deterministic oracle problem and %we apply not only supervised learning but also reinforcement learning for parsers to learn the orders of creating arcs. %We combine our model with multi-task learning. %In our experiments, our proposal parsing model archives competitive or state-of-the-art scores in SDP.  %that is combined with both supervised learning and reinforcement learning. %semantic dependency graphs become directed acyclic graphs. %We therefore combine argument-selection parsing approach and deep reinforcement learning. %Our model allows several actions and each action resolve some semantic arcs simultaneously.  %This enables the parsing model to resolve the easy arcs for the first and difficult arcs in the latter.  %We combine this with multi-task learning to use the results of easier tasks in more difficult tasks.  
 Providing plausible responses to why questions is a challenging but critical goal for language based human-machine interaction. %, because humans often demand explanations of the world. Explanations are challenging in that they require many different forms of abstract knowledge and reasoning. Previous work has either relied on human-curated structured knowledge bases or detailed domain representation to generate satisfactory explanations. They are also often limited to ranking pre-existing explanation choices. In our work, we contribute to the under-explored area of generating natural language explanations for general phenomena. We automatically collect large datasets of explanation-phenomenon pairs which allow us to train sequence-to-sequence models to generate natural language explanations. We compare different training strategies and evaluate their performance using both automatic scores and human ratings. We demonstrate that our strategy is sufficient to generate highly plausible explanations for general open-domain phenomena compared to other models trained on different datasets. % We provide an interactive demo of our system at \url{http://3.18.91.191}.  % explanations are important %   - people ask for them a lot 閳 %   - explanations are used to evaluate model's acquisition of abstract knowledge, because ... % ... explanations are hard 閳 --> why? %   - requires lots of different kinds of knowledge and reasoning 閳  % we don't require structured knowledge 閳 % chatbots don't respond to why questions well % 閳 generating as opposed to ranking explanations % human ratings of model-generated explanations for a variety of model types and training corpora   % Providing a plausible explanation has been used as an evaluation task to measure the amount of commonsense in an artificial system. However, directly generating plausible natural language explanations using modern machine learning approaches is under-explored due to the difficulty of acquiring training data. % We show that training on raw text and human dialogue is insufficient for generating high quality, plausible explanations. % We propose a data generation technique to mine a large dataset of phenomenon-explanation pairs from raw text corpora. % We show that training sequence-to-sequence and language models on this curated dataset of explanations result in explanations that are judged more plausible by humans than existing language generation models. % Explanation pairs collected using our extraction method can be used for a variety of applications: to train chatbots to give better answers to "why" questions, for developing better psycholinguistic theories of explanation, and for evaluating commonsense knowledge acquisition in artificial intelligence systems. 
 % Recent work has shown the importance of sentential context in neural machine translation  .  In this work, we present novel approaches to exploit sentential context for neural machine translation . Specifically,  we first show that a {, which aggregates the sentential context representations from all the internal layers of the encoder to form a more comprehensive context representation. Experimental results on the WMT14 English$\Rightarrow$German and English$\Rightarrow$French benchmarks show that our model consistently improves performance over the strong Transformer model~, demonstrating the necessity and effectiveness of exploiting sentential context for NMT. 
  The cognitive mechanisms needed to account for the English past tense have long been a subject of debate in linguistics and cognitive science.  Neural network models were proposed early on, but were shown to have clear flaws. Recently, however,  showed that modern encoder-decoder  models overcome many of these flaws. They also presented evidence that ED models demonstrate humanlike performance in a nonce-word task. Here, we look more closely at the behaviour of their model in this task. We find that  the model exhibits instability across multiple simulations in terms of its correlation with human data, and  even when results are aggregated across simulations , the fit to the human data is not strong---worse than an older rule-based model. These findings hold up through several alternative training regimes and evaluation measures. Although other neural architectures might do better, we conclude that there is still insufficient evidence to claim that neural nets are a good cognitive model for this task.   
 Neural machine translation  takes deterministic sequences for source representations. However, either word-level or subword-level segmentations have multiple choices to split a source sequence with different word segmentors or different subword vocabulary sizes. We hypothesize that the diversity in segmentations may affect the NMT performance. To integrate different segmentations with the state-of-the-art NMT model, Transformer, we propose lattice-based encoders to explore effective word or subword representation in an automatic way during training. We propose two methods: 1) lattice positional encoding and 2) lattice-aware self-attention. These two methods can be used together and show complementary to each other to further improve translation performance. Experiment results show superiorities of lattice-based encoders in word-level and subword-level representations over conventional Transformer encoder. 
 Neural natural language generation  from structured meaning representations has become increasingly popular in recent years. While we have seen progress with generating syntactically correct utterances that preserve semantics, various shortcomings of { by:  scalably  creating training datasets of parallel meaning representations and reference texts with rich style markup by using data from freely available and naturally descriptive user reviews, and  systematically exploring how the style markup enables joint  control of semantic and stylistic aspects of neural model output. We present { datasets for other domains. The experiments show that the models control important aspects, including lexical choice of adjectives, output length, and sentiment, allowing the models to successfully hit multiple style targets without sacrificing semantics. 
 We identify agreement and disagreement between utterances that express stances towards a topic of discussion.  Existing methods focus mainly on conversational settings, where dialogic features are used for agreement inference.  We extend this scope and seek to detect stance agreement in a broader setting, where independent stance-bearing utterances, which prevail in many stance corpora and real-world scenarios, are compared. To cope with such non-dialogic utterances, we find that the reasons uttered to back up a specific stance can help predict stance agreements. We propose a reason comparing network  to leverage reason information for stance comparison. Empirical results on a well-known stance corpus show that our method can discover useful reason information, enabling it to outperform several baselines in stance agreement detection. 
  % ABSTRACT by NP: % Neural language modeling has recently led to significant improvements in several downstream tasks, % NP: removed 'including  text classification, natural language inference and speech recognition'. maybe we could skip mentioning them here  % however, they typically require large amounts of training data, which are not readily available for many rare domains and languages. %NP: One could say that this is why people usually pretrain models in out-of-domain data which are more likely to be  available.  %In this study, we propose a regularized multilingual neural language model, which can effectively be trained jointly on domain-specific data of several low-resource languages. The proposed multilingual model consists of language-specific word embeddings in the encoder and decoder, and one language-specific LSTM layer, plus two LSTM layers with shared parameters across the languages. The parameter sharing facilitates transfer learning across the languages, and acts as an effective %extra NP: we haven't mentioned what other regularizers exist in our architecture yet. regularizer in very low-resource scenarios. We integrate our proposed multilingual neural language model with  state-of-the-art regularization techniques, and evaluate on the conversational data domain of four languages over varying training data sizes. Compared to monolingual models, the results show significant improvements of our  multilingual model when the amount of available training data is limited, indicating the advantages of cross-lingual parameter sharing in very low-resource language scenarios.   Neural language modeling  has led to significant improvements in several applications, including Automatic Speech Recognition.  However, they typically require large amounts of training data, which is not available for many domains and languages.  In this study, we propose a multilingual neural language model architecture, trained jointly on the domain-specific data of several low-resource languages. The proposed multilingual LM consists of language specific word embeddings in the encoder and decoder, and one language specific LSTM layer, plus two LSTM layers with shared parameters across the languages. This multilingual LM model facilitates transfer learning across the languages, acting as an extra regularizer in very low-resource scenarios. We integrate our proposed multilingual approach with a state-of-the-art highly-regularized neural LM, and evaluate on the conversational data domain for four languages over a range of training data sizes. Compared to monolingual LMs, the results show significant improvements of our proposed multilingual LM when the amount of available training data is limited, indicating the advantages of cross-lingual parameter sharing in very low-resource language modeling.  
  Neural abstractive text summarization  has received a lot of attention in the past few years from both industry and academia. In this paper, we introduce an open-source toolkit, namely LeafNATS, for training and evaluation of different sequence-to-sequence based models for the NATS task, and for deploying the pre-trained models to real-world applications. The toolkit is modularized and extensible in addition to maintaining competitive performance in the NATS task. A live news blogging system has also been implemented to demonstrate how these models can aid blog/news editors by providing them suggestions of headlines and summaries of their articles.  
 Despite their popularity in the chatbot literature, retrieval-based models have had modest impact on task-oriented dialogue systems, with the main obstacle to their application being the low-data regime of most task-oriented dialogue tasks. Inspired by the recent success of pretraining in language modelling, we propose an effective method for deploying  in task-oriented dialogue. To train response selection models for task-oriented dialogue tasks, we propose a novel method which: 1) pretrains the response selection model on large general-domain conversational corpora; and then 2) fine-tunes the pretrained model for the target dialogue domain, relying only on the small in-domain dataset to capture the nuances of the given dialogue domain. Our evaluation on six diverse application domains, ranging from e-commerce to banking, demonstrates the effectiveness of the proposed training method.  
     Neural network architectures have been augmented with differentiable stacks in order to introduce a bias toward learning hierarchy-sensitive regularities. It has, however, proven difficult to assess the degree to which such a bias is effective, as the operation of the differentiable stack is not always interpretable.  In this paper, we attempt to detect the presence of latent representations of hierarchical structure through an exploration of the unsupervised learning of constituency structure. Using a technique due to , we extract syntactic trees from the pushing behavior of stack RNNs trained on language modeling and classification objectives. We find that our models produce parses that reflect natural language syntactic constituencies, demonstrating that stack RNNs do indeed  infer linguistically relevant hierarchical structure. 
   Neural generative models have been become increasingly popular when building conversational agents. They offer flexibility, can be easily adapted to new domains, and require minimal domain engineering. A common criticism of these systems is that they seldom understand or use the available dialog history effectively. In this paper, we take an empirical approach to understanding how these models use the available dialog history by studying the sensitivity of the models to artificially introduced unnatural changes or perturbations to their context at test time. We experiment with 10 different types of perturbations on 4 multi-turn dialog datasets and find that commonly used neural dialog architectures like recurrent and transformer-based seq2seq models are rarely sensitive to most perturbations such as missing or reordering utterances, shuffling words, etc. Also, by open-sourcing our code, we believe that it will serve as a useful diagnostic tool for evaluating dialog systems in the future \footnote{Code is available at \url{https://github.com/chinnadhurai/ParlAI/}}.   %We work under the premise that good dialog systems, that leverage information about the conversation dynamics and word ordering within utterances, should be sensitive to perturbations that destroy this information, but find that this rarely happens. % Probably good to change this once we finalize results.    
  Neural word representations are at the core of many state-of-the-art natural language processing models. A widely used approach is to pre-train, store and look up word or character embedding matrices. While useful, such representations occupy huge memory making it hard to deploy on-device and often do not generalize to unknown words due to vocabulary pruning.     In this paper, we propose a skip-gram based architecture coupled with Locality-Sensitive Hashing  projections to learn efficient dynamically computable representations. Our model does not need to store lookup tables as representations are computed on-the-fly and require low memory footprint. The representations can be trained in an unsupervised fashion and can be easily transferred to other NLP tasks. For qualitative evaluation, we analyze the nearest neighbors of the word representations and discover semantically similar words even with misspellings. For quantitative evaluation, we plug our transferable projections into a simple LSTM and run it on multiple NLP tasks and show how our transferable projections achieve better performance compared to prior work. 
 This work attempts to explain the types of computation that neural networks can perform by relating them to automata. We first define what it means for a real-time network with bounded precision to accept a language. A measure of network memory follows from this definition. We then characterize the classes of languages acceptable by various recurrent networks, attention, and convolutional networks. We find that LSTMs function like counter machines and relate convolutional networks to the subregular hierarchy. Overall, this work attempts to increase our understanding and ability to interpret neural networks through the lens of theory. These theoretical insights help explain neural computation, as well as the relationship between neural networks and natural language grammar. 
 We present a detailed comparison of two types of sequence to sequence models trained to conduct a compositional task. The models are architecturally identical at inference time, but differ in the way that they are trained: our baseline model is trained with a task-success signal only, while the other model receives additional supervision on its attention mechanism , which has shown to be an effective method for encouraging more compositional solutions . We first confirm that the models with attentive guidance indeed infer more compositional solutions than the baseline, by training them on the lookup table task presented by . We then do an in-depth analysis of the structural differences between the two model types, focusing in particular on the organisation of the parameter space and the hidden layer activations and find noticeable differences in both these aspects. Guided networks focus more on the components of the input rather than the sequence as a whole and develop small functional groups of neurons with specific purposes that use their gates more selectively.  Results from parameter heat maps, component swapping and graph analysis also indicate that guided networks exhibit a more modular structure with a small number of specialized, strongly connected neurons. 
  We train a diachronic long short-term memory  part-of-speech tagger on a large corpus of American English from the 19th, 20th, and 21st centuries. We analyze the tagger's ability to implicitly learn temporal structure between years, and the extent to which this knowledge can be transferred to date new sentences. The learned year embeddings show a strong linear correlation between their first principal component and time. We show that temporal information encoded in the model can be used to predict novel sentences' years of composition relatively well. Comparisons to a feedforward baseline suggest that the temporal change learned by the LSTM is syntactic rather than purely lexical. Thus, our results suggest that our tagger is implicitly learning to model syntactic change in American English over the course of the 19th, 20th, and early 21st centuries.   
   Neural machine translation  has set new quality standards in automatic translation, yet its effect on post-editing productivity is still pending thorough investigation. We empirically test how the inclusion of NMT, in addition to domain-specific translation memories and termbases, impacts speed and quality in professional translation of financial texts. We find that even with language pairs that have received little attention in research settings and small amounts of in-domain data for system adaptation, NMT post-editing allows for substantial time savings and leads to equal or slightly better quality. 
 Common language models typically predict the next word given the context. In this work, we propose a method that improves language modeling by learning to align the given context and the following phrase. The model does not require any linguistic annotation of phrase segmentation. Instead, we define syntactic heights and phrase segmentation rules, enabling the model to automatically induce phrases, recognize their task-specific heads, and generate phrase embeddings in an unsupervised learning manner. Our method can easily be applied to language models with different network architectures since an independent module is used for phrase induction and context-phrase alignment, and no change is required in the underlying language modeling network. Experiments have shown that our model outperformed several strong baseline models on different data sets. We achieved a new state-of-the-art performance of 17.4 perplexity on the Wikitext-103 dataset. Additionally, visualizing the outputs of the phrase induction module showed that our model is able to learn approximate phrase-level structural knowledge without any annotation. 
     Transformer is the state-of-the-art model in recent machine translation evaluations. Two strands of research are promising to improve models of this kind: the first uses wide networks  and has been the de facto standard for the development of the Transformer system, and the other uses deeper language representation but faces the difficulty arising from learning deep networks. Here, we continue the line of research on the latter. We claim that a truly deep Transformer model can surpass the Transformer-Big counterpart by 1) proper use of layer normalization and 2) a novel way of passing the combination of previous layers to the next. On WMT'16 English-German, NIST OpenMT'12 Chinese-English and larger WMT'18 Chinese-English tasks, our deep system   outperforms the shallow Transformer-Big/Base baseline  by 0.4$}. 
 % Constituting highly informative network embeddings is an important tool for network analysis. It encodes network topology, along with other useful side information, into low-dimensional node-based feature representations that can be exploited by statistical modeling. This work focuses on learning context-aware network embeddings augmented with text data. We reformulate the network-embedding problem, and present two novel strategies to improve over traditional attention mechanisms:  a content-aware sparse attention module based on optimal transport, and  a high-level attention parsing module. Our approach yields naturally sparse and self-normalized relational inference. It can capture long-term interactions between sequences, thus addressing the challenges faced by existing textual network embedding schemes. Extensive experiments are conducted to demonstrate our model can consistently outperform alternative state-of-the-art methods.   
   We propose a novel model architecture and training algorithm to learn bilingual sentence embeddings from a combination of parallel and monolingual data. Our method connects autoencoding and neural machine translation to force the source and target sentence embeddings to share the same space without the help of a pivot language or an additional transformation.   %We apply distance metrics as well as an ANN-based binary classifier on the bilingual sentence embeddings and test these methods on the task of sentence alignment recovery and the WMT 2018 parallel corpus filtering tasks   We train a multilayer perceptron on top of the sentence embeddings to extract good bilingual sentence pairs from nonparallel or noisy parallel data. Our approach shows promising performance on sentence alignment recovery and the WMT 2018 parallel corpus filtering tasks with only a single model.\\ 
  Non-autoregressive translation models  have achieved impressive inference speedup. A potential issue of the existing NAT algorithms, however, is that the decoding is conducted in parallel, without directly considering previous context. In this paper, we propose an imitation learning framework for non-autoregressive machine translation, which still enjoys the fast translation speed but gives comparable translation performance compared to its auto-regressive counterpart. We conduct experiments on the IWSLT16, WMT14 and WMT16 datasets. Our proposed model achieves a significant speedup over the autoregressive models, while keeping the translation quality comparable to the autoregressive models. By sampling sentence length in parallel at inference time, we achieve the performance of 31.85 BLEU on WMT16 Ro$\rightarrow$En and 30.68 BLEU on IWSLT16 En$\rightarrow$De. 
 This paper presents a dataset and supervised learning experiments for term extraction from Slovene academic texts. Term candidates in the dataset were extracted via morphosyntactic patterns and annotated for their termness by four annotators. Experiments on the dataset show that most co-occurrence statistics, applied after morphosyntactic patterns and a frequency threshold, perform close to random and that the results can be significantly improved by combining, with supervised machine learning, all the seven statistic measures included in the dataset. On multi-word terms the model using all statistics obtains an AUC of 0.736 while the best single statistic produces only AUC 0.590. Among many additional candidate features, only adding multi-word morphosyntactic pattern information and length of the single-word term candidates achieves further improvements of the results.   
 Legal judgment prediction is the task of automatically predicting the outcome of a court case, given a text describing the case's facts. Previous work on using neural models for this task has focused on Chinese; only feature-based models  have been considered in English. We release a new English legal judgment prediction dataset, containing cases from the European Court of Human Rights. We evaluate a broad variety of neural models on the new dataset, establishing strong baselines that surpass previous feature-based models in three tasks:  binary violation classification;  multi-label classification;  case importance prediction. We also explore if models are biased towards demographic information via data anonymization. As a side-product, we propose a hierarchical version of bert, which bypasses bert's length limitation. 
 Researchers illustrate improvements in contextual encoding strategies via resultant performance on a battery of shared Natural Language Understanding  tasks. Many of these tasks are of a categorical prediction variety: given a conditioning context , provide a label based on an associated prompt . The categorical nature of these tasks has led to common use of a cross entropy log-loss objective during training. We suggest this loss is intuitively wrong when applied to  tasks, where the prompt by design is neither categorically  nor  given the context. Log-loss naturally drives models to assign scores near 0.0 or 1.0, in contrast to our proposed use of a margin-based loss. Following a discussion of our intuition, we describe a confirmation study based on an extreme, synthetically curated task derived from MultiNLI. We find that a margin-based loss leads to a more plausible model of plausibility. Finally, we illustrate improvements on the Choice Of Plausible Alternative  task through this change in loss.  
 % REDO While most social norms are informal, they are often formalized by companies in contracts to regulate trades of goods and services.  When poorly written, contracts may contain normative conflicts resulting from opposing deontic meanings or contradict specifications.  As contracts tend to be long and contain many norms, manually identifying such conflicts requires human-effort, which is time-consuming and error-prone.  Automating such task benefits contract makers increasing productivity and making conflict identification more reliable.  To address this problem, we introduce an approach to detect and classify norm conflicts in contracts by converting them into latent representations that preserve both syntactic and semantic information and training a model to classify norm conflicts in four conflict types.  Our results reach the new state of the art when compared to a previous approach.  
   %NLP community has recently observed substantial accuracy gains across many fundamental tasks, ranging from syntactic parsing to machine translation. These gains have largely been facilitated by recent advances in specialized compute hardware such as GPUs, which have made the training of large neural network models feasible. At the same time, our planet is facing a climate crisis    %Advances in methodology and hardware for training deep neural networks have recently enabled substantial accuracy improvements across fundamental NLP tasks by facilitating training of large networks on abundant data.       Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.    %We estimate the energy and resulting carbon emissions, as well as cloud compute and electricity costs for training these models.    %come at high computational cost, necessitating not only a high financial burden required to obtain the computational resources, but also   
 	Recently, there has been an increasing interest in         unsupervised parsers that optimize semantically oriented         objectives, typically using reinforcement         learning. Unfortunately, the learned trees often do not match         actual syntax trees well.  propose a structured         attention mechanism for language modeling , which         induces better syntactic structures but relies on ad hoc         heuristics. Also, their model lacks interpretability as it is         not grounded in parsing actions. In our work, we propose an         imitation learning approach to unsupervised parsing, where we         transfer the syntactic knowledge induced by the PRPN to a         Tree-LSTM model with discrete parsing actions. Its policy is         then refined by Gumbel-Softmax training towards a semantically         oriented objective. We evaluate our approach on the All         Natural Language Inference dataset and show that it achieves a         new state of the art in terms of parsing $F$-score,         outperforming our base models, including the PRPN.\footnote{Our           code can be found at           \\\url{https://github.com/libowen2121/Imitation-Learning-for-Unsup-Parsing}} 	
 Current state-of-the-art systems for the sequence labeling  tasks are typically based on the family of Recurrent Neural Networks .  However, the shallow connections between consecutive hidden states of RNNs and insufficient modeling of global information restrict the potential performance of those models. In this paper, we try to address these issues, and thus propose a Global Context enhanced Deep Transition architecture for sequence labeling named GCDT. We deepen the state transition path at each position in a sentence, and further assign every token with a global representation learned from the entire sentence. Experiments on two standard sequence labeling tasks show that, given only training data and the ubiquitous word embeddings , our GCDT achieves 91.96 $F_1$ on the CoNLL03 NER task and 95.43 $F_1$ on the CoNLL2000 Chunking task, which outperforms the best reported results under the same settings. Furthermore, by leveraging BERT as an additional resource, we establish new state-of-the-art results with 93.47 $F_1$ on NER and 97.30 $F_1$ on Chunking \footnote{Code is available at:  https://github.com/Adaxry/GCDT.}.   
  Neural Machine Translation  generates target words sequentially in the way of predicting the next word conditioned on the context words. At training time, it predicts with the ground truth words as context while at inference it has to generate the entire sequence from scratch. This discrepancy of the fed context leads to error accumulation among the way. Furthermore, word-level training requires strict matching between the generated sequence and the ground truth sequence which leads to overcorrection over different but reasonable translations. In this paper, we address these issues by sampling context words not only from the ground truth sequence but also from the predicted sequence by the model during training, where the predicted sequence is selected with a sentence-level optimum.  Experiment results on Chinese$\rightarrow$English and WMT'14 English$\rightarrow$German translation tasks demonstrate that our approach can achieve significant improvements on multiple datasets.  
 Although neural conversation models are effective in learning  to produce fluent responses, their primary challenge lies in knowing  to say to make the conversation  and non-vacuous.  We present a new end-to-end approach to contentful neural conversation that jointly models response generation and on-demand machine reading.  The key idea is to provide the conversation model with relevant long-form text on the fly as a source of external knowledge. The model performs QA-style reading comprehension on this text in response to each conversational turn, thereby allowing for more focused integration of external knowledge than has been possible in prior approaches.  To support further research on knowledge-grounded conversation, we introduce a new large-scale conversation dataset grounded in external web pages . Both human evaluation and automated metrics show that our approach results in more contentful responses compared to a variety of previous methods, improving both the informativeness and diversity of generated output.  
 Knowing how to use words appropriately has been a key to improving language proficiency. Previous studies typically discuss how students learn receptively to select the correct candidate from a set of confusing words in the fill-in-the-blank task where specific context is given. In this paper, we go one step further, assisting students to learn to use confusing words appropriately in a productive task: sentence translation. We leverage the GiveMeExample system, which suggests example sentences for each confusing word, to achieve this goal. In this study, students learn to differentiate the confusing words by reading the example sentences, and then choose the appropriate word to complete the sentence translation task. Results show students made substantial progress in terms of sentence structure. In addition, highly proficient students better managed to learn confusing words. In view of the influence of the first language on learners, we further propose an effective approach to improve the quality of the suggested sentences.              % We leverage the GiveMeExample system to achieve this goal. Specifically, the % system suggests example sentences for each confusing word. In this study, % students learn to differentiate the confusing words by reading the example % sentences. Afterwards, they choose the appropriate word to complete % the sentence translation task. The results of a deployment study conducted with 16 % English-as-a-Second-Language  learners show that with the % assistance of the provided example sentences, students made substantial % progress in terms of sentence structure. In addition, compared with their less % proficient counterparts, highly proficient students better managed to learn % confusing words. In view of the influence of the first language on learners % from this deployment, we propose an approach to improve the quality of the % suggested sentences. Evaluations conducted by Amazon mechanical turkers and a % professional native editor demonstrate the effectiveness of this approach. 
 Obstacles hindering the development of capsule networks for challenging NLP applications include poor scalability to large output spaces and less reliable routing processes. In this paper, we introduce  an agreement score to evaluate the performance of routing processes at instance level;  an adaptive optimizer to enhance the reliability of routing;  capsule compression and partial routing to improve the scalability of capsule networks. We validate our approach on two NLP tasks, namely: multi-label text classification and question answering. Experimental results show that our approach considerably improves over strong competitors on both tasks. In addition, we gain the best results in low-resource settings with few training instances.\footnote{Our code is publicly available at {http://bit.ly/311Dcod}}  
 Supervised models of NLP rely on large collections of text which closely resemble the intended testing setting.  Unfortunately matching text is often not available in sufficient quantity, and moreover, within any domain of text, data is often highly heterogenous. In this paper we propose a method to distill the important domain signal as part of a multi-domain learning system, using a latent variable model in which parts of a neural model are stochastically gated based on the inferred domain. We compare the use of discrete versus continuous latent variables, operating in a domain-supervised or a domain semi-supervised setting, where the domain is known only for a subset of training inputs. We show that our model leads to substantial performance improvements over competitive benchmark domain adaptation methods, including methods using adversarial learning. 
 Word embedding is central to neural machine translation , which has attracted intensive research interest in recent years.  In NMT, the source embedding plays the role of the entrance while the target embedding acts as the terminal.  These layers occupy most of the model parameters for representation learning. Furthermore, they indirectly interface via a soft-attention mechanism, which makes them comparatively isolated.  In this paper, we propose  bilingual word embeddings, which give a closer relationship between the source and target embeddings, and which also reduce the number of model parameters. For similar source and target words, their embeddings tend to share a part of the features and they cooperatively learn these common representation units. % This not only gives better word representations but also reduces the number of model parameters. % Experiments on Chinese-English and English-German translation tasks demonstrate that the proposed model provides a significant performance boost over the strong baselines. Experiments on 5 language pairs belonging to 6 different language families and written in 5 different alphabets demonstrate that the proposed model provides a significant performance boost over the strong baselines with dramatically fewer model parameters. 
 In this paper, we propose to boost low-resource cross-lingual document retrieval performance with deep bilingual query-document representations. We match queries and documents in both source and target languages with four components, each of which is implemented as a term interaction-based deep neural network with cross-lingual word embeddings as input. By including query likelihood scores as extra features, our model effectively learns to rerank the retrieved documents by using a small number of relevance labels for low-resource language pairs. Due to the shared cross-lingual word embedding space, the model can also be directly applied to another language pair without any training label. Experimental results on the Material dataset show that our model outperforms the competitive translation-based baselines on English-Swahili, English-Tagalog, and English-Somali cross-lingual information retrieval tasks. 
 Domain adaptation is an essential task in dialog system building because there are so many new dialog tasks created for different needs every day. Collecting and annotating training data for these new tasks is costly since it involves real user interactions. We propose a domain adaptive dialog generation method based on meta-learning . DAML is an end-to-end trainable dialog system model that learns from multiple rich-resource tasks and then adapts to new domains with minimal training samples. We train a dialog system model using multiple single-domain dialog data with rich-resource by applying the model-agnostic meta-learning algorithm to dialog domain. The model is capable of learning a competitive dialog system on a new domain with only a few training examples in an efficient manner. The two-step gradient updates in DAML enable the model to learn general features across multiple tasks. We evaluate our method on a simulated dialog dataset and achieve state-of-the-art performance, which is generalizable to new tasks. % Our model outperforms other domain adaptation dialog system training models with equivalent training resource.    
   As the core component of Natural Language Processing  system, Language Model  can provide word representation and probability indication of word sequences. Neural Network Language Models  overcome the curse of dimensionality and improve the performance of traditional LMs. A survey on NNLMs is performed in this paper. The structure of classic NNLMs is described firstly, and then some major improvements are introduced and analyzed. We summarize and compare corpora and toolkits of NNLMs. Furthermore, some research directions of NNLMs are discussed. 
 We introduce temporally and contextually-aware models for the novel task of predicting unseen but plausible concepts, as conveyed by noun-noun compounds in a time-stamped corpus. We train compositional models on observed compounds, more specifically the composed distributed representations of their constituents across a time-stamped corpus, while giving it corrupted instances  as negative evidence. The model captures generalisations over this data and learns what combinations give rise to plausible compounds and which ones do not. After training, we query the model for the plausibility of automatically generated novel combinations and verify whether the classifications are accurate. For our best model, we find that in around 85\% of the cases, the novel compounds generated are attested in previously unseen data. An additional estimated 5\% are plausible despite not being attested in the recent corpus, based on judgments from independent human raters. 
 In this paper, we systematically assess the ability of standard recurrent networks to perform dynamic counting and to encode hierarchical representations. All the neural models in our experiments are designed to be small-sized networks both to prevent them from memorizing the training sets and to visualize and interpret their behaviour at test time. Our results demonstrate that the Long Short-Term Memory  networks can learn to recognize the well-balanced parenthesis language  and the shuffles of multiple Dyck-$1$ languages, each defined over different parenthesis-pairs, by emulating simple real-time $k$-counter machines. To the best of our knowledge, this work is the first study to introduce the shuffle languages to analyze the computational power of neural networks. We also show that a single-layer LSTM with only one hidden unit is practically sufficient for recognizing the Dyck-$1$ language. However, none of our recurrent networks was able to yield a good performance on the Dyck-$2$ language learning task, which requires a model to have a stack-like mechanism for recognition. 
  In this paper, we explore various approaches for learning two types of appraisal components from happy language. We focus on `agency' of the author and the `sociality' involved in happy moments based on the HappyDB dataset. We develop models based on deep neural networks for the task, including uni- and bi-directional long short-term memory networks, with and without attention. We also experiment with a number of novel embedding methods, such as embedding from neural machine translation  and embedding from language models . We compare our results to those acquired by several traditional machine learning methods. Our best models achieve 87.97\% accuracy on agency and 93.13\% accuracy on sociality, both of which are significantly higher than our baselines.  %traditional machine learning methods like Linear Support Vector Machine , Naive Bates , Logistic Regression  and Voting Classifier. We tried different split ratios for training and validation dataset. We also tried different pre-trained embeddings such as GloVe and FastText. Different hyperparameters were tried for all the model and they were optimized for this particular task. Our LSTM model with multiple layer performs best for predicting 'social' label and BiLSTM model performs the best for predicting 'agency' label. We take the best model for each label and predict the unlabeled sentences in training dataset and add the sentences with higher prediction confidence to the training dataset and train again. This leads to 0.3\% increase in the accuracy for 'social' label with LSTM model.   
 We examine learning offensive content on Twitter with limited, imbalanced data. For the purpose, we investigate the utility of using various data enhancement methods with a host of classical ensemble classifiers. Among the 75 participating teams in SemEval-2019 sub-task B, our system ranks 6th . For sub-task C, among the 65 participating teams, our system ranks 9th .  
    Due to the ubiquitous use of embeddings as input representations for a wide range of natural language tasks, imputation of embeddings for rare and unseen words is a critical problem in language processing. Embedding imputation involves learning representations for rare or unseen words during the training of an embedding model, often in a post-hoc manner. In this paper, we propose an approach for embedding imputation which uses grounded information in the form of a knowledge graph. This is in contrast to existing approaches which typically make use of vector space properties or subword information. We propose an online method to construct a graph from grounded information and design an algorithm to map from the resulting graphical structure to the space of the pre-trained embeddings. Finally, we evaluate our approach on a range of rare and unseen word tasks across various domains and show that our model can learn better representations. For example, on the Card-660 task our method improves Pearson's and Spearman's correlation coefficients upon the state-of-the-art by 11\% and 17.8\% respectively using GloVe embeddings.     
   Sequential labeling-based NER approaches restrict each word belonging to at most one entity mention, which will face a serious problem when recognizing nested entity mentions. In this paper, we propose to resolve this problem by modeling and leveraging the head-driven phrase structures of entity mentions, i.e., although a mention can nest other mentions, they will not share the same head word. Specifically, we propose , a sequence-to-nuggets architecture for nested mention detection. ARNs first identify anchor words  of all mentions, and then recognize the mention boundaries for each anchor word by exploiting regular phrase structures. Furthermore, we also design , an objective function which can train ARNs in an end-to-end manner without using any anchor word annotation. Experiments show that ARNs achieve the state-of-the-art performance on three standard nested entity mention detection benchmarks.  
 This short example shows a contrived example on how to format the authors' information for {. 
 Generating keyphrases that summarize the main points of a document is a fundamental task in natural language processing. Although existing generative models are capable of predicting multiple keyphrases for an input document as well as determining the number of keyphrases to generate, they still suffer from the problem of generating too few keyphrases. To address this problem, we propose a reinforcement learning  approach for keyphrase generation, with an adaptive reward function that encourages a model to generate both sufficient and accurate keyphrases. Furthermore, we introduce a new evaluation method that incorporates name variations of the ground-truth keyphrases using the Wikipedia knowledge base. Thus, our evaluation method can more robustly evaluate the quality of predicted keyphrases. Extensive experiments on five real-world datasets of different scales demonstrate that our RL approach consistently and significantly improves the performance of the state-of-the-art generative models with both conventional and new evaluation methods.  
 We propose a learning approach for turn-level spoken language understanding, which facilitates a user to speak one or more utterances compositionally in a turn for completing a task . A typical pipelined approach for these understanding tasks requires non-trivial annotation effort for developing its multiple components. Also, the pipeline is difficult to port to a new domain or scale up. To address these problems, we propose an end-to-end statistical model with weak supervision. We employ randomized beam search with memory augmentation  to solve complicated problems for which long promising trajectories are usually difficult to explore. Furthermore, considering the diversity of problem complexity, we explore automated curriculum learning  for weak supervision to accelerate exploration and learning. We evaluate the proposed approach on real-world user logs of a commercial voice ordering system. Results demonstrate that when trained on a small number of end-to-end annotated sessions collected with low cost, our model performs comparably to the deployed pipelined system, saving the development labor over an order of magnitude. The RBSMA algorithm improves the test set accuracy by 7.8\% relative compared to the standard beam search. Automated CL leads to better generalization and further improves the test set accuracy by 5\% relative. 
 We show that a word-level recurrent neural network can predict emoji from text typed on a mobile keyboard. We demonstrate the usefulness of transfer learning for predicting emoji by pretraining the model using a language modeling task. We also propose mechanisms to trigger emoji and tune the diversity of candidates. The model is trained using a distributed on-device learning framework called federated learning. The federated model is shown to achieve better performance than a server-trained model. This work demonstrates the feasibility of using federated learning to train production-quality models for natural language understanding tasks while keeping users' data on their devices.  
 We present a document-grounded matching network  for response selection that can power a knowledge-aware retrieval-based chatbot system. The challenges of building such a model lie in how to ground conversation contexts with background documents and how to recognize important information in the documents for matching. To overcome the challenges, DGMN fuses information in a document and a context into representations of each other, and dynamically determines if grounding is necessary and importance of different parts of the document and the context through hierarchical interaction with a response at the matching step. Empirical studies on two public data sets indicate that DGMN can significantly improve upon state-of-the-art methods and at the same time enjoys good interpretability.   
             This paper describes our competing system to enter the MEDIQA-2019 competition. We use a multi-source transfer learning approach to transfer the knowledge from MT-DNN  and SciBERT  to natural language understanding tasks in the medical domain. For transfer learning fine-tuning, we use multi-task learning on NLI, RQE and QA tasks on general and medical domains to improve performance. The proposed methods are proved effective for natural language understanding in the medical domain, and we rank the first place on the QA task.         
 Many state-of-the-art neural models for NLP are heavily parameterized and thus memory inefficient. This paper proposes a series of lightweight and memory efficient neural architectures for a potpourri of natural language processing  tasks. To this end, our models exploit computation using Quaternion algebra and hypercomplex spaces, enabling not only expressive inter-component interactions but also significantly  reduced parameter size due to lesser degrees of freedom in the Hamilton product. We propose Quaternion variants of models, giving rise to new architectures such as the Quaternion attention Model and Quaternion Transformer. Extensive experiments on a battery of NLP tasks  demonstrates the utility of proposed Quaternion-inspired models, enabling up to $75\%$ reduction in parameter size without significant loss in performance. 
 We study learning of a matching model for response selection in retrieval-based dialogue systems. The problem is equally important with designing the architecture of a model, but is less explored in existing literature. To learn a robust matching model from noisy training data, we propose a general co-teaching framework with three specific teaching strategies that cover both teaching with loss functions and teaching with data curriculum. Under the framework, we simultaneously learn two matching models with independent training sets. In each iteration, one model transfers the knowledge learned from its training set to the other model, and at the same time receives the guide from the other model on how to overcome noise in training. Through being both a teacher and a student, the two models learn from each other and get improved together.  Evaluation results on two public data sets indicate that the proposed learning approach can generally and significantly improve the performance of existing matching models. 
 Aspect-level sentiment classification aims to distinguish the sentiment polarities over one or more aspect terms in a sentence. Existing approaches mostly model different aspects in one sentence independently, which ignore the sentiment dependencies between different aspects. However, we find such dependency information between different aspects can bring additional valuable information. In this paper, we propose a novel aspect-level sentiment classification model based on graph convolutional networks  which can effectively capture the sentiment dependencies between multi-aspects in one sentence.  Our model firstly introduces bidirectional attention mechanism with position encoding to model aspect-specific representations between each aspect and its context words, then employs GCN over the attention mechanism to capture the sentiment dependencies between different aspects in one sentence. We evaluate the proposed approach on the SemEval 2014 datasets. Experiments show that our model outperforms the state-of-the-art methods. We also conduct experiments to evaluate the effectiveness of GCN module, which indicates that the dependencies between different aspects is highly helpful in aspect-level sentiment classification. %\footnote{Source code is available at \url{https://github.com/Pinlong-Zhao/SDGCN}.} 
 Inter-sentence relation extraction deals with a number of complex semantic relationships in documents, which require local, non-local, syntactic and semantic dependencies. Existing methods do not fully exploit such dependencies.  We present a novel inter-sentence relation extraction model that builds a labelled edge graph convolutional neural network model on a document-level graph. The graph is constructed using various inter- and intra-sentence dependencies to capture local and non-local dependency information. In order to predict the relation of an entity pair, we utilise multi-instance learning with bi-affine pairwise scoring. Experimental results show that our model achieves comparable performance to the state-of-the-art neural models on two biochemistry datasets. Our analysis shows that all the types in the graph are effective for inter-sentence relation extraction. 
   Existing neural generation approaches create multi-sentence text as   a single sequence. In this paper we propose a structured   convolutional decoder that is guided by the content structure of   target summaries.  We compare our model with existing sequential   decoders on three data sets representing different domains.   Automatic and human evaluation demonstrate that our summaries have   better content coverage. 
 	Clarifying user needs is essential for existing task-oriented dialogue systems. However, in real-world applications, developers can never guarantee that all possible user demands are taken into account in the design phase. Consequently, existing systems will break down when encountering unconsidered user needs. To address this problem, we propose a novel incremental learning framework to design task-oriented dialogue systems, or for short Incremental Dialogue System~, without pre-defining the exhaustive list of user needs. Specifically, we introduce an  to evaluate the confidence of giving correct responses. If there is high confidence, IDS will provide responses to users. Otherwise, humans will be involved in the dialogue process, and IDS can learn from human intervention through an . To evaluate our method, we propose a new dataset which simulates unanticipated user needs in the deployment stage. Experiments show that IDS is robust to unconsidered user actions, and can update itself online by smartly selecting only the most effective training data, and hence attains better performance with less annotation cost.\footnote{\url{https://github.com/Leechikara/Incremental-Dialogue-System}} 
 % De-identification is the task of detecting  in medical text. % It is a critical step in sanitizing  to be shared for research. % Automatic de-identification classifiers can significantly speed up the sanitization process. % However, obtaining a large and diverse dataset to train such a classifier that works well across many types of medical text poses a challenge as privacy laws prohibit the sharing of raw medical records. % We introduce a method to create privacy-preserving shareable representations of medical text  that does not require expensive manual pseudonymization.  % These representations can be shared between organizations to create unified datasets for training de-identification models. % Our representation allows training a simple - de-identification model to an \fone score of $97.4\%$, which is comparable to a strong baseline that exposes private information in its representation. % A robust, widely available de-identification classifier based on our representation could potentially enable studies for which de-identification would otherwise be too costly. 
 People can learn a new concept and use it compositionally, understanding how to ``blicket twice'' after learning how to ``blicket.'' In contrast, powerful sequence-to-sequence  neural networks fail such tests of compositionality, especially when composing new concepts together with existing concepts. In this paper, I show how memory-augmented neural networks can be trained to generalize compositionally through meta seq2seq learning. In this approach, models train on a series of seq2seq problems to acquire the compositional skills needed to solve new seq2seq problems. Meta se2seq learning solves several of the SCAN tests for compositional learning and can learn to apply implicit rules to variables. 
 Inspired by the success of the General Language Understanding Evaluation benchmark, we introduce the Biomedical Language Understanding Evaluation  benchmark to facilitate research in the development of pre-training language representations in the biomedicine domain. The benchmark consists of five tasks with ten datasets that cover both biomedical and clinical texts with different dataset sizes and difficulties. We also evaluate several baselines based on BERT and ELMo and find that the BERT model pre-trained on PubMed abstracts and MIMIC-III clinical notes achieves the best results. We make the datasets, pre-trained models, and codes publicly available at \url{https://github.com/ncbi-nlp/BLUE_Benchmark}. 
 Alzheimer's disease  is an irreversible brain disease that can dramatically reduce quality of life, most commonly manifesting in older adults and eventually leading to the need for full-time care. Early detection is fundamental to slowing its progression; however, diagnosis can be expensive, time-consuming, and invasive.  In this work we develop a neural model based on a CNN-LSTM architecture that learns to detect AD and related dementias using targeted and implicitly-learned features from conversational transcripts.  Our approach establishes the new state of the art on the DementiaBank dataset, achieving an F1 score of 0.929 when classifying participants into AD and control groups.  
 Natural languages are complexly structured entities. They exhibit characterising regularities that can be exploited to link them one another. In this work, I compare two morphological aspects of languages: Written Patterns and Sentence Structure. I show how languages spontaneously group by similarity in both analyses and derive an average language distance. Finally, exploiting Sentence Structure I developed an Artificial Neural Network capable of distinguishing languages suggesting that not only word roots but also grammatical sentence structure is a characterising trait which alone suffice to identify them.\\ \\ Keywords: Data Science and Analytics, Artificial Neural Networks, Natural Language Processing, Natural Languages 
 News in social media such as Twitter has been generated in high volume and speed. However, very few of them can be labeled  in a short time. In order to achieve timely detection of fake news in social media,  a novel deep two-path semi-supervised learning model is proposed, where one path is for supervised learning and the other is for unsupervised learning. These two paths implemented with convolutional neural networks are  jointly optimized to enhance detection performance. In addition, we build a shared convolutional neural networks between these two paths to share the low level features. Experimental results using Twitter datasets show that the proposed model can recognize fake news  effectively with very few labeled data.     
  %TODO African languages are numerous, complex and low-resourced. The datasets required for machine translation are difficult to discover, and existing research is hard to reproduce. Minimal attention has been given to machine translation for African languages so there is scant research regarding the problems that arise when using machine translation techniques. To begin addressing these problems, we trained models to translate English to five of the official South African languages , making use of modern neural machine translation techniques. The results obtained show the promise of using neural machine translation techniques for African languages. By providing reproducible publicly-available data, code and results, this research aims to provide a starting point for other researchers in African machine translation to compare to and build upon. 
 This paper focuses on the end-to-end abstractive summarization of a single product review {, in which the summary is the root, and the child sentences explain their parent in detail. By recursively estimating a parent from its children, our model learns the latent discourse tree without an external parser and generates a concise summary. We also introduce an architecture that ranks the importance of each sentence on the tree to support summary generation focusing on the main review point. The experimental results demonstrate that our model is competitive with or outperforms other unsupervised approaches. In particular, for relatively long reviews, it achieves a competitive or better performance than supervised models. The induced tree shows that the child sentences provide additional information about their parent, and the generated summary abstracts the entire review.  
 The 2019 WMT Biomedical translation task involved translating Medline abstracts. We approached this using transfer learning to obtain a series of strong neural models on distinct domains, and combining them into multi-domain ensembles. We further experiment with an adaptive language-model ensemble weighting scheme. Our submission achieved the best submitted results on both directions of English-Spanish.   
 Machine reading comprehension with unanswerable questions is a challenging task. In this work, we propose a data augmentation technique by automatically generating relevant unanswerable questions according to an answerable question paired with its corresponding paragraph that contains the answer. We introduce a pair-to-sequence model for unanswerable question generation, which effectively captures the interactions between the question and the paragraph. We also present a way to construct training data for our question generation models by leveraging the existing reading comprehension dataset. Experimental results show that the pair-to-sequence model performs consistently better compared with the sequence-to-sequence baseline. We further use the automatically generated unanswerable questions as a means of data augmentation on the SQuAD 2.0 dataset, yielding $1.9$ absolute F1 improvement with BERT-base model and $1.7$ absolute F1 improvement with BERT-large model. 
 We present open domain response generation with meta-words. A meta-word is a structured record that describes various attributes of a response, and thus allows us to explicitly model the one-to-many relationship within open domain dialogues and perform response generation in an explainable and controllable manner.  To incorporate meta-words into generation, we enhance the sequence-to-sequence architecture with a goal tracking memory network that formalizes meta-word expression as a goal and manages the generation process to achieve the goal with a state memory panel and a state controller. Experimental results on two large-scale datasets indicate that our model can significantly outperform several state-of-the-art generation models in terms of response relevance, response diversity, accuracy of one-to-many modeling, accuracy of meta-word expression, and human evaluation.    
   This paper describes our system for The Microsoft AI Challenge India 2018: Ranking Passages for Web Question Answering. The system uses the bi-LSTM network with co-attention mechanism between query and passage representations. Additionally, we use self attention on embeddings to increase the lexical coverage by allowing the system to take union over different embeddings. We also incorporate hand-crafted features to improve the system performance. Our system achieved a Mean Reciprocal Rank  of 0.67 on eval-1 dataset.  
    Automatic post-editing  seeks to automatically refine the   output of a black-box machine translation  system through human   post-edits. APE systems are usually trained by complementing human   post-edited data with large, artificial data generated through   back-translations, a time-consuming process often no easier than   training a MT system from scratch. In this paper, we propose an   alternative where we fine-tune pre-trained BERT models on both the   encoder and decoder of an APE system, exploring several parameter   sharing strategies. By only training on a dataset of 23K sentences   for 3 hours on a single GPU we obtain results that are competitive   with systems that were trained on 5M artificial sentences. When we   add this artificial data, our method obtains state-of-the-art   results.  
 We report our ongoing work about a new deep architecture working in tandem with a statistical test procedure for jointly training texts and their label descriptions for multi-label and multi-class classification tasks. A statistical hypothesis testing method is used to extract the most informative words for each given class. These words are used as a class description for more label-aware text classification. Intuition is to help the model to concentrate on more informative words rather than more frequent ones. The model leverages the use of label descriptions in addition to the input text to enhance text classification performance. Our method is entirely data-driven, has no dependency on other sources of information than the training data, and is adaptable to different classification problems by providing appropriate training data without major hyper-parameter tuning. We trained and tested our system on several publicly available datasets, where we managed to improve the state-of-the-art on one set with a high margin, and to obtain competitive results on all other ones. 
 We present a system, \spoke, for creating and searching internal knowledge base  articles for organizations. \spoke is available as a SaaS  product deployed across hundreds of organizations with a diverse set of domains. \spoke continually improves search quality using conversational user feedback which allows it to provide better search experience than standard information retrieval systems without encoding any explicit domain knowledge. We achieve this by using a real-time online learning-to-rank  algorithm that automatically customizes relevance scoring for each organization deploying \spoke by using a query similarity kernel.   The focus of this paper is on incorporating practical considerations into our relevance scoring function and algorithm that make \spoke easy to deploy and suitable for handling events that naturally happen over the life-cycle of any KB deployment. We show that \spoke outperforms competitive baselines by up to 41\% in offline F1 comparisons. 
 This paper presents a multi-level matching and aggregation network  for few-shot relation classification. Previous studies on this topic adopt prototypical networks, which calculate the embedding vector of a query instance and the prototype vector of each support set independently. In contrast, our proposed MLMAN model encodes the query instance and each support set in an interactive way by considering their matching information at both local and instance levels. The final class prototype for each support set is obtained by attentive aggregation over the representations of its support instances, where the weights are calculated using the query instance. Experimental results demonstrate the effectiveness of our proposed methods, which achieve a new state-of-the-art performance on the FewRel dataset\footnote{The code is available at \url{https://github.com/ZhixiuYe/MLMAN}.}. 
  In this paper we propose a novel neural approach for automatic decipherment of lost languages. To compensate for the lack of strong supervision signal, our model design is informed by patterns in language change documented in historical linguistics.  The model utilizes an expressive sequence-to-sequence model to capture character-level correspondences between cognates. To effectively train the model in an unsupervised manner, we innovate the training procedure by formalizing it as a minimum-cost flow problem. When applied to the decipherment of Ugaritic, we achieve a 5.5\% absolute improvement over state-of-the-art results. We also report the first automatic results in deciphering Linear B, a syllabic language related to ancient Greek, where our model correctly translates  67.3\% of cognates.\footnote{Code and all datasets are hosted in \url{https://github.com/j-luo93/NeuroDecipher}.}    We introduce a neural decipherment approach. Our approach is language-independent and built upon fundamental principles of decipherment across multiple languages, which effectively guide the model decipherment process without supervision. We employ a neural sequence-to-sequence model to capture character-level cognate generation process, and innovate a training procedure is formulated as flow to impose lexicon-level structural sparsity. We demonstrate the efficacy of our approach on two lost languages -- Ugaritic  and Linear B, from different linguistic families, and observed substantially high accuracy in cognate identification.  % We propose a novel approach for language decipherment. Our approach uses an expressive neural sequence-to-sequence model to capture character-level correspondence between the cipher and known languages. In order to effectively train the model in unsupervised manner, we innovate the training procedure by formalizing it as a minimum-cost flow problem. We incorporate prior linguistic knowledge into the design of both model architecture and training in order to  properly guide the decipherment learning process. We conducted experiments on cognate identification tasks for Romance languages, Ugaritic, and for the first time, Linear B. In all cases our system reached high accuracy and significant relative gains over results reported in existing literature.   
 Transformers are emerging as the new workhorse of NLP, showing great success across tasks. Unlike LSTMs, transformers process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model formal languages. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of self-attention, finding that it cannot model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. These limitations seem surprising given the practical success of self-attention and the prominent role assigned to hierarchical structure in linguistics, suggesting that natural language can be approximated well with models that are too weak for the formal languages typically assumed in theoretical linguistics.  
 We present a supervised approach for style change detection, which aims at predicting whether there are changes in the style in a given text document, as well as at finding the exact positions where such changes occur. In particular, we combine a TF.IDF representation of the document with features specifically engineered for the task, and we make predictions via an ensemble of diverse classifiers including SVM, Random Forest, AdaBoost, MLP, and LightGBM. Whenever the model detects that style change is present, we apply it recursively, looking to find the specific positions of the change. Our approach powered the winning system for the PAN@CLEF 2018 task on Style Change Detection. % The effectiveness of fitting a TF-IDF vectorizer on the texts from the test data in addition to the train data is also explored.  % The abstract should briefly summarize the contents of the paper in % 15--250 words.   
  We consider open domain event extraction, the task of extracting unconstraint types of events from news clusters. A novel latent variable neural model is constructed, which is scalable to very large corpus. A dataset is collected and manually annotated, with task-specific evaluation metrics being designed. Results show that the proposed unsupervised model gives better performance compared to the state-of-the-art method for event schema induction. %There is a rapidly growing sets of news reports published by miscellaneous posts in the real world, leading to textual redundancy. %However, most open domain schema induction models rely on sparse features and restrain the event types beforehand, training with learning methods which is not scalable in large corpus. %In this paper, we propose a model to extract unconstraint types of events and induce universal schemas from news clusters by continuous contextual features, modeling latent event types and leveraging redundant ratios. %Besides, our learning framework combines both the strengths of neural networks and latent variable models and is scalable to large corpus. %For evaluation, we construct the GNBusiness dataset by merging news reports about the same events and introduce slot coherence as a new metrics to evaluate the intrinsic qualities quantitatively of learned slots and schemas. %The experiment results demonstrate that the proposed model achieves competitive results compared with state-of-the-art methods.  
 	In this paper, we present an approach to incorporate retrieved datapoints as supporting evidence for context-dependent semantic parsing, such as generating source code conditioned on the class environment.  	Our approach naturally combines a retrieval model and a meta-learner, where the former learns to find similar datapoints from the training data, and the latter considers retrieved datapoints as a pseudo task for fast adaptation.  	Specifically, our retriever is a context-aware encoder-decoder model with a latent variable which takes context environment into consideration, and  	our meta-learner learns to utilize retrieved datapoints in a model-agnostic meta-learning paradigm for fast adaptation.  	We conduct experiments on CONCODE and CSQA datasets, where the context refers to class environment in JAVA codes and conversational history, respectively. 	We use sequence-to-action model as the base semantic parser, which performs the state-of-the-art accuracy on both datasets. 	Results show that both the context-aware retriever and the meta-learning strategy improve accuracy, and our approach performs better than retrieve-and-edit baselines. 
 Generating fluent natural language responses from structured semantic representations is a critical step in task-oriented conversational systems. Avenues like the E2E NLG Challenge have encouraged the development of neural approaches, particularly sequence-to-sequence  models for this problem. The semantic representations used, however, are often underspecified, which places a higher burden on the generation model for sentence planning, and also limits the extent to which generated responses can be controlled in a live system. In this paper, we  propose using  %tree-structured semantic representations, like those used in traditional rule-based %NLG systems, with Seq2Seq models;  introduce a challenging dataset using this  tree-structured semantic representations, like those used in traditional rule-based NLG systems, for better discourse-level structuring and sentence-level planning;  introduce a challenging dataset using this representation for the weather domain;  introduce a constrained decoding approach for Seq2Seq models that leverages this representation to improve semantic correctness; and  demonstrate promising results on our dataset and the E2E dataset. 
   Recurrent neural networks  have reached striking performance in   many natural language processing tasks. This has renewed interest in   whether these generic sequence processing devices are inducing   genuine linguistic knowledge. Nearly all current analytical studies,   however, initialize the RNNs with a vocabulary of known words, and   feed them tokenized input during training. We present a   multi-lingual study of the linguistic knowledge encoded in RNNs   trained as character-level language models, on input data with word   boundaries removed. These networks face a tougher and more   cognitively realistic task, having to discover any useful   linguistic unit from scratch based on input statistics. The results   show that our ``near '' RNNs are mostly able to   solve morphological, syntactic and semantic tasks that intuitively   presuppose word-level knowledge, and indeed they learned, to some extent, to track    word boundaries. Our study opens the door to speculations   about the necessity of an explicit, rigid word lexicon in language learning and   usage. 
 Back-translation --- data augmentation by translating target monolingual data --- is a crucial component in modern neural machine translation .  In this work, we reformulate back-translation in the scope of cross-entropy optimization of an NMT model, clarifying its underlying mathematical assumptions and approximations beyond its heuristic usage.  Our formulation covers broader synthetic data generation schemes, including sampling from a target-to-source NMT model. With this formulation, we point out fundamental problems of the sampling-based approaches and propose to remedy them by  disabling label smoothing for the target-to-source model and  sampling from a restricted search space. Our statements are investigated on the WMT 2018 German $\leftrightarrow$ English news translation task. 
 Modern text-to-speech~ systems are able to generate audio that sounds almost as natural as human speech. % However, the bar of developing high-quality TTS systems remains high since a sizable set of studio-quality~$<$text, audio$>$ pairs is usually required. % Compared to commercial data used to develop state-of-the-art systems, publicly available data are usually worse in terms of both quality and size. % Audio generated by TTS systems trained on publicly available data tends to not only sound less natural, but also exhibits more background noise. % In this work, we aim to lower TTS systems' reliance on high-quality data by providing them the textual knowledge extracted by deep pre-trained language models during training. % In particular, we investigate the use of BERT to assist the training of Tacotron-2, a state of the art TTS consisting of an encoder and an attention-based decoder. % BERT representations learned from large amounts of unlabeled text data are shown to contain very rich semantic and syntactic information about the input text, and have potential to be leveraged by a TTS system to compensate the lack of high-quality data. % We incorporate BERT as a parallel branch to the Tacotron-2 encoder with its own attention head. % For an input text, it is simultaneously passed into BERT and the Tacotron-2 encoder. % The representations extracted by the two branches are concatenated and then fed to the decoder. % As a preliminary study, although we have not found incorporating BERT into Tacotron-2 generates more natural or cleaner speech at a human-perceivable level, we observe improvements in other aspects such as the model is being significantly better at knowing when to stop decoding such that there is much less babbling at the end of the synthesized audio and faster convergence during training. 
 Dependency trees convey rich structural information that is proven useful for extracting relations among entities in text. However, how to effectively make use of relevant information while ignoring irrelevant information from the dependency trees remains a challenging research question. Existing approaches employing rule based hard-pruning strategies for selecting relevant partial dependency structures may not always yield optimal results. In this work, we propose Attention Guided Graph Convolutional Networks , a novel model which directly takes full dependency trees as inputs. Our model can be understood as a soft-pruning approach that automatically learns how to selectively attend to the relevant sub-structures useful for the relation extraction task. Extensive results on various tasks including cross-sentence $n$-ary relation extraction and large-scale sentence-level relation extraction show that our model is able to better leverage the structural information of the full dependency trees, giving significantly better results than previous approaches. 
  Automating the assessment of learner summaries provides a useful tool for assessing learner reading comprehension. We present a summarization task for evaluating non-native reading comprehension and propose three novel approaches to automatically assess the learner summaries. We evaluate our models on two datasets we created and show that our models outperform traditional approaches that rely on exact word match on this task. Our best model produces quality assessments close to professional examiners.  
  This paper addresses the task of readability assessment for the texts aimed at second language  learners. One of the major challenges in this task is the lack of significantly sized level-annotated data. For the present work, we collected a dataset of CEFR-graded texts tailored for learners of English as an L2 and investigated text readability assessment for both native and L2 learners. We applied a generalization method to adapt models trained on larger native corpora to estimate text readability for learners, and explored domain adaptation and self-learning techniques to make use of the native data to improve system performance on the limited L2 data. In our experiments, the best performing model for readability on learner texts achieves an accuracy of $0.797$ and $PCC$ of $0.938$.   
 This paper details LTG-Oslo team's participation in the sentiment track of the NEGES 2019 evaluation campaign. We participated in the task with a hierarchical multi-task network, which used shared lower-layers in a deep BiLSTM to predict negation, while the higher layers were dedicated to predicting document-level sentiment. The multi-task component shows promise as a way to incorporate information on negation into deep neural sentiment classifiers, despite the fact that the absolute results on the test set were relatively low for a binary classification task.    
 We present an end-to-end approach to extract semantic concepts directly from the speech audio signal. To overcome the lack of data available for this spoken language understanding approach, we investigate the use of a transfer learning strategy based on the principles of curriculum learning. This approach allows us to exploit out-of-domain data that can help to prepare a fully neural architecture. Experiments are carried out on the French MEDIA and PORTMEDIA corpora and show that this end-to-end SLU approach reaches the best results ever published on this task. We compare our approach to a classical pipeline approach that uses ASR, POS tagging, lemmatizer, chunker... and other NLP tools that aim to enrich ASR outputs that feed an SLU text to concepts system.  Last, we explore the promising capacity of our end-to-end SLU approach to address the problem of domain portability.  
  Sentiment analysis is directly affected by compositional phenomena in language that act on the prior polarity of the words and phrases found in the text.  is the most prevalent of these phenomena and in order to correctly predict sentiment, a classifier must be able to identify negation and disentangle the effect that its scope has on the final polarity of a text. This paper proposes a multi-task approach to explicitly incorporate information about negation in sentiment analysis, which we show outperforms learning negation implicitly in an end-to-end manner. We describe our approach, a cascading and hierarchical neural architecture with selective sharing of LSTM layers, and show that explicitly training the model with negation as an auxiliary task helps improve the main task of sentiment analysis. The effect is demonstrated across several different standard English-language data sets for both tasks and we analyze several aspects of our system related to its performance, varying types and amounts  of input data and different multi-task setups.  
 %show end-to-end high order Semantic dependency parsing aims to identify semantic relationships between words in a sentence that form a graph. In this paper, we propose a second-order semantic dependency parser, which takes into consideration not only individual dependency edges but also interactions between pairs of edges. We show that second-order parsing can be approximated using mean field  variational inference or loopy belief propagation . We can unfold both algorithms as recurrent layers of a neural network and therefore can train the parser in an end-to-end manner. Our experiments show that our approach achieves state-of-the-art performance. 
 In this paper, we propose two novel methods for domain adaptation for the attention-only neural machine translation  model, i.e.,  the Transformer. Our methods focus on training a single translation model for multiple domains by either learning domain specialized hidden state representations or predictor biases for each domain. We combine our methods with a previously proposed black-box method called mixed fine tuning, which is known to be highly effective for domain adaptation. In addition, we incorporate multilingualism into the domain adaptation framework. Experiments show that multilingual multi-domain adaptation can significantly improve both resource-poor in-domain and resource-rich out-of-domain translations, and the combination of our methods with mixed fine tuning achieves the best performance. 
 We present the first sentence simplification model that learns explicit edit operations  via a neural programmer-interpreter approach. Most current neural sentence simplification systems are variants of sequence-to-sequence models adopted from machine translation. These methods learn to simplify sentences as a byproduct of the fact that they are trained on complex-simple sentence pairs. By contrast, our neural programmer-interpreter is directly trained to predict explicit edit operations on targeted parts of the input sentence, resembling the way that humans might perform simplification and revision. Our model outperforms previous state-of-the-art neural sentence simplification models  by large margins on three benchmark text simplification corpora in terms of SARI , and is judged by humans to produce overall better and simpler output sentences\footnote{Link to our code and data can be found here \url{https://github.com/yuedongP/EditNTS}.}.  
 Data-driven models have demonstrated state-of-the-art performance in inferring the temporal ordering of events in text. However, these models often overlook explicit temporal signals, such as dates and time windows. Rule-based methods can be used to identify the temporal links between these time expressions , but they fail to capture timexes' interactions with events and are hard to integrate with the distributed representations of neural net models. In this paper, we introduce a framework to infuse temporal awareness into such models by learning a pre-trained model to embed timexes. We generate synthetic data consisting of pairs of timexes, then train a character LSTM to learn embeddings and classify the timexes' temporal relation. We evaluate the utility of these embeddings in the context of a strong neural model for event temporal ordering, and show a small increase in performance on the MATRES dataset and more substantial gains on an automatically collected dataset with more frequent event-timex interactions.\footnote{Data and code are available at \url{https://github.com/tagoyal/Temporal-event-ordering}} 
 Vector representations of sentences, trained on massive text corpora, are widely used as generic sentence embeddings across a variety of NLP problems.  The learned representations are generally assumed to be  and , giving rise to a large memory footprint and slow retrieval speed, which hinders their applicability to low-resource  platforms, such as mobile devices.  In this paper, we propose four different strategies to transform  and generic sentence embeddings into a  form, while preserving their rich semantic information.  The introduced methods are evaluated across a wide range of downstream tasks, % To this end, four strategies to parametrize the continuous-to-binary transformation are explored and evaluated  where the binarized sentence embeddings are demonstrated to degrade performance by only about $2\%$ relative to their continuous counterparts, while reducing the storage requirement by over $98\%$. Moreover, with the learned binary representations, the semantic relatedness of two sentences can be evaluated by simply calculating their Hamming distance, which is more computational efficient compared with the inner product operation between continuous embeddings.  %\asli {i am not sure you need the following sentence, we already said that the methods are extensively evaluated on downstream tasks, so it is repetition. Also, which case study?} Detailed analysis and case study further validate the effectiveness of proposed methods. 
     In practical scenario, relation extraction needs to first identify entity pairs that have relation and then assign a correct relation class. However, the number of non-relation entity pairs in context  usually far exceeds the others , which negatively affects a model's performance. To mitigate this problem, we propose a multi-task architecture which jointly trains a model to perform relation identification with cross-entropy loss and relation classification with ranking loss. Meanwhile, we observe that a sentence may have multiple entities and relation mentions, and the patterns in which the entities appear in a sentence may contain useful semantic information that can be utilized to distinguish between positive and negative instances. Thus we further incorporate the embeddings of character-wise/word-wise BIO tag from the named entity recognition task into character/word embeddings to enrich the input representation. Experiment results show that our proposed approach can significantly improve the performance of a baseline model with more than 10\% absolute increase in F1-score, and outperform the state-of-the-art models on ACE 2005 Chinese and English corpus. Moreover, BIO tag embeddings are particularly effective and can be used to improve other models as well.      %Thus we argue that BIO Tag embeddings could be used as a general part of character/word representation. 
 %  Code-switching, the interleaving of two or more languages within a sentence or discourse is pervasive in multilingual societies. Accurate language models for code-switched text are critical for NLP tasks. State-of-the-art data-intensive neural language models are difficult to train well from scarce language-labeled code-switched text. A potential solution is to use deep generative models to synthesize large volumes of realistic code-switched text. Although generative adversarial networks and variational autoencoders can synthesize plausible monolingual text from continuous latent space, they cannot adequately address code-switched text, owing to their informal style and complex interplay between the constituent languages. We introduce \ourmodel, a novel variational autoencoder architecture specifically tailored to code-switching phenomena. \ourmodel{} encodes to and decodes from a two-level hierarchical representation, which models syntactic contextual signals in the lower level, and language switching signals in the upper layer. Sampling representations from the prior and decoding them produced well-formed, diverse code-switched sentences. Extensive experiments show that using %augmenting  %scarce hand-labeled  synthetic code-switched text with  natural monolingual data %more plentiful synthetic labeled code-switched text  results  in significant  drop in perplexity. 
  We introduce a demonstration of our system, which implements online learning for neural machine translation in a production environment. These techniques allow the system to continuously learn from the corrections provided by the translators. We implemented an end-to-end platform integrating our machine translation servers to one of the most common user interfaces for professional translators: {SDL Trados Studio}. Our objective was to save post-editing effort as the machine is continuously learning from human choices and adapting the models to a specific domain or user style.    
 We present an end-to-end trainable multi-task network that addresses the problem of lexicon-free text extraction from complex documents. This network simultaneously solves the problems of text localization and text recognition and text segments are identified with no post-processing, cropping, or word grouping. A convolutional backbone and Feature Pyramid Network are combined to provide a shared representation that benefits each of three model heads: text localization, classification, and text recognition. To improve recognition accuracy, we describe a dynamic pooling mechanism that retains high-resolution information across all RoIs.  For text recognition, we propose a convolutional mechanism with attention which out-performs more common recurrent architectures.   Our model is evaluated against benchmark datasets and comparable methods and achieves high performance in challenging regimes of non-traditional OCR.  
 SPARQL is a highly powerful query language for an ever-growing number of Linked Data resources and Knowledge Graphs. Using it requires a certain familiarity with the entities in the domain to be queried as well as expertise in the language's syntax and semantics, none of which average human web users can be assumed to possess. To overcome this limitation, automatically translating natural language questions to SPARQL queries has been a vibrant field of research. However, to this date, the vast success of deep learning methods has not yet been fully propagated to this research problem. This paper contributes to filling this gap by evaluating the utilization of eight different Neural Machine Translation  models for the task of translating from natural language to the structured query language SPARQL. While highlighting the importance of high-quantity and high-quality datasets, the results show a dominance of a CNN-based architecture with a BLEU score of up to 98 and accuracy of up to 94\%.    
   Benefiting from the excellent ability of neural networks on learning semantic representations, existing studies for entity linking  have resorted to neural networks to exploit both the local mention-to-entity compatibility and the global interdependence between different EL decisions for target entity disambiguation. However, most neural collective EL methods depend entirely upon neural networks to automatically model the semantic dependencies between different EL decisions, which lack of the guidance from external knowledge. In this paper, we propose a novel end-to-end neural network with recurrent random-walk layers for collective EL, which introduces external knowledge to model the semantic interdependence between different EL decisions. Specifically, we first establish a model based on local context features, and then stack random-walk layers to reinforce the evidence for related EL decisions into high-probability decisions, where the semantic interdependence between candidate entities is mainly induced from an external knowledge base. Finally, a semantic regularizer that preserves the collective EL decisions consistency is incorporated into the conventional objective function, so that the external knowledge base can be fully exploited in collective EL decisions. Experimental results and in-depth analysis on various datasets show that our model achieves better performance than other state-of-the-art models. Our code and data are released at \url{https://github.com/DeepLearnXMU/RRWEL}. 
 Deep neural networks have achieved significant improvements in information retrieval . However, most existing models are computational costly and can not efficiently scale to long documents. This paper proposes a novel End-to-End neural ranking framework called Reinforced Long Text Matching  which matches a query with long documents efficiently and effectively. The core idea behind the framework can be analogous to the human judgment process which firstly locates the relevance parts quickly from the whole document and then matches these parts with the query carefully to obtain the final label. Firstly, we select relevant sentences from the long documents by a coarse and efficient matching model. Secondly, we generate a relevance score by a more sophisticated matching model based on the sentence selected. The whole model is trained jointly with reinforcement learning in a pairwise manner by maximizing the expected score gaps between positive and negative examples. Experimental results demonstrate that RLTM has greatly improved the efficiency and effectiveness of the state-of-the-art models. 
 Non-Autoregressive Transformer  aims to accelerate the Transformer model through discarding the autoregressive mechanism and generating target words independently, which fails to exploit the target sequential information. Over-translation and under-translation errors often occur for the above reason, especially in the long sentence translation scenario. In this paper, we propose two approaches to retrieve the target sequential information for NAT to enhance its translation ability while preserving the fast-decoding property.  Firstly, we propose a sequence-level training method based on a novel reinforcement algorithm for NAT  to reduce the variance and stabilize the training procedure.  Secondly, we propose an innovative Transformer decoder named FS-decoder to fuse the target sequential information into the top layer of the decoder.  Experimental results on three translation tasks show that the Reinforce-NAT surpasses the baseline NAT system by a significant margin on BLEU without decelerating the decoding speed and the FS-decoder achieves comparable translation performance to the autoregressive Transformer with considerable speedup.      
  Existing graph-based methods for extractive document summarization represent sentences of a corpus as the nodes of a graph or a hypergraph in which edges depict relationships of lexical similarity between sentences. Such approaches fail to capture semantic similarities between sentences when they express a similar information but have few words in common and are thus lexically dissimilar. To overcome this issue, we propose to extract semantic similarities based on topical representations of sentences. Inspired by the Hierarchical Dirichlet Process, we propose a probabilistic topic model in order to infer topic distributions of sentences. As each topic defines a semantic connection among a group of sentences with a certain degree of membership for each sentence, we propose a fuzzy hypergraph model in which nodes are sentences and fuzzy hyperedges are topics. To produce an informative summary, we extract a set of sentences from the corpus by simultaneously maximizing their relevance to a user-defined query, their centrality in the fuzzy hypergraph and their coverage of topics present in the corpus. We formulate a polynomial time algorithm building on the theory of submodular functions to solve the associated optimization problem. A thorough comparative analysis with other graph-based summarization systems is included in the paper. Our obtained results show the superiority of our method in terms of content coverage of the summaries.\\ %% keywords here, in the form: keyword  Automatic Text Summarization, Fuzzy Graphs, Probabilistic Topic Models, Hierarchical Dirichlet Process, Personalized PageRank, Submodular Set Functions 
 We introduce a family of multitask variational methods for semi-supervised sequence labeling. Our model family consists of a latent-variable generative model and a discriminative labeler. The generative models use latent variables to define the conditional probability of a word given its context, drawing inspiration from word prediction objectives commonly used in learning word embeddings. The labeler helps inject discriminative information into the latent space. We explore several latent variable configurations, including ones with hierarchical structure, which enables the model to account for both label-specific and word-specific information. Our models consistently outperform standard sequential baselines on 8 sequence labeling datasets, and improve further with unlabeled data. 
 Paraphrasing exists at different granularity levels, such as lexical level, phrasal level and sentential level. This paper presents Decomposable Neural Paraphrase Generator , a Transformer-based model that can learn and generate paraphrases of a sentence at different levels of granularity in a disentangled way. Specifically, the model is composed of multiple encoders and decoders with different structures, each of which corresponds to a specific granularity. The empirical study shows that the decomposition mechanism of DNPG makes paraphrase generation more interpretable and controllable. Based on DNPG, we further develop an unsupervised domain adaptation method for paraphrase generation. Experimental results show that the proposed model achieves competitive in-domain performance compared to the state-of-the-art neural models, and significantly better performance when adapting to a new domain.  %By introducing the latent variables controlling the granularity of each word in the sentence, the model can disentangle the paraphrasing patterns at the lexical and phrasal level from those at the sentential level. The decomposition mechanism makes the generation of paraphrase more interpretable and controllable. Based on DNPG, we further develop a simple yet effective method for unsupervised domain adaptation. Experimental results show that our model achieves superior performance compared to the state-of-the-art neural models on paraphrase generation, especially when adapting to new domains. %Paraphrase generation is of great use to many NLP applications. Neural sequence-to-sequence models have demonstrated their ability to produce grammatically correct and semantically relevant paraphrases of a sentence. However, the black-box nature of the neural networks makes the paraphrasing process less controllable or interpretable, compared to the traditional symbolic approaches. In this work, we propose a Transformer-based model with multiple encoders and decoders that can process and generate paraphrases at different levels of granularity. By introducing the latent variables controlling the granularity of each token in the sentence, the model can disentangle the paraphrasing operations at the lexical and phrasal level from those at the sentential level, making the generation of paraphrases more controllable and interpretable. Experimental results show that our model outperforms the state-of-the-art neural models on paraphrase generation, especially when adapting to new domains. 
  We treat projective dependency trees as latent variables in our probabilistic model and induce them in such a way as to be beneficial for a downstream task, without relying on any direct tree supervision. Our approach relies on Gumbel perturbations and differentiable dynamic programming.  Unlike previous approaches to latent tree learning, we stochastically sample global structures and our parser is fully differentiable. We illustrate its effectiveness on sentiment analysis and natural language inference tasks. We also study its properties on a synthetic structure induction task. Ablation studies emphasize the importance of both stochasticity and constraining latent structures to be projective trees.  
   This paper describes the LIAAD system that was ranked second place in the Word-in-Context challenge  featured in SemDeep-5.   Our solution is based on a novel system for Word Sense Disambiguation  using contextual embeddings and full-inventory sense embeddings. We adapt this WSD system, in a straightforward manner, for the present task of detecting whether the same sense occurs in a pair of sentences.   Additionally, we show that our solution is able to achieve competitive performance even without using the provided training or development sets, mitigating potential concerns related to task overfitting. 
 Strong inductive biases allow children to learn in fast and adaptable ways. Children use the mutual exclusivity  bias to help disambiguate how words map to referents, assuming that if an object has one label then it does not need another. In this paper, we investigate whether or not vanilla neural architectures have an ME bias, demonstrating that they lack this learning assumption. Moreover, we show that their inductive biases are poorly matched to lifelong learning formulations of classification and translation. We demonstrate that there is a compelling case for designing task-general neural networks that learn through mutual exclusivity, which remains an open challenge. 
   % Attention mechanism was first perceived as could be used as modeling word alignments.   % This was soone shown not to be true~, and even less so with the Transformer architecture .   % In this paper, we propose a model-agnostic interpretation algorithm that allows one to produce alignments on par or better than the quality of fast\_align~ without the need to run any external alignment models as postprocessing.   Despite their original goal to jointly learn to align and translate, Neural Machine Translation  models, especially Transformer, are often perceived as not learning interpretable word alignments.   In this paper, we show that NMT models do learn interpretable word alignments, which could only be revealed with proper interpretation methods.   We propose a series of such methods that are model-agnostic, are able to be applied either offline or online, and do not require parameter update or architectural change.   We show that under the force decoding setup, the alignments induced by our interpretation method are of better quality than fast-align for some systems, and when performing free decoding, they agree well with the alignments induced by automatic alignment tools. % \pk{not in the abstract} 
  Unlike major Western languages, most African languages are very low-resourced. Furthermore, the resources that do exist are often scattered and difficult to obtain and discover. As a result, the data and code for existing research has rarely been shared. This has lead a struggle to reproduce reported results, and few publicly available benchmarks for African machine translation models exist. To start to address these problems, we trained neural machine translation models for 5 Southern African languages on publicly-available datasets. Code is provided for training the models and evaluate the models on a newly released evaluation set, with the aim of spur future research in the field for Southern African languages.  
  Acoustic model adaptation to unseen test recordings aims to reduce the mismatch between training and testing conditions.  Most adaptation schemes for neural network models require the use of an initial one-best transcription for the test data, generated by an unadapted model, in order to estimate the adaptation transform.  It has been found that adaptation methods using discriminative objective functions -- such as cross-entropy loss -- often require careful regularisation to avoid over-fitting to errors in the one-best transcriptions.  In this paper we solve this problem by performing discriminative adaptation using lattices obtained from a first pass decoding, an approach that can be readily integrated into the lattice-free maximum mutual information  framework.  We investigate this approach on three transcription tasks of varying difficulty: TED talks, multi-genre broadcast  and a low-resource language .  We find that our proposed approach enables many more parameters to be adapted without over-fitting being observed, and is successful even when the initial transcription has a WER in excess of 50\%. 
 Neural networks have become the state-of-the-art approach for machine translation  in many languages.  %  While linguistically-motivated tokenization techniques were shown to have significant effects on the performance of statistical MT, it remains unclear if those techniques are well suited for neural MT.  % Successful neural MT systems typically rely on language-agnostic tokenization techniques.  % Therefore, it would be interesting to study whether tokenization schemes, typically associated with neural MT, are suited for statistical MT as well in the context of Arabic-English MT.  In this paper, we systematically compare neural and statistical MT models for Arabic-English translation on data preprecossed by various prominent tokenization schemes. Furthermore, we consider a range of data and vocabulary sizes and compare their effect on both approaches. Our empirical results show that the best choice of tokenization scheme is largely based on the type of model and the size of data. We also show that we can gain significant improvements using a system selection that combines the output from neural and statistical MT.  
  What is the relationship between sentence representations learned by deep recurrent models against those encoded by the brain? Is there any correspondence between hidden layers of these recurrent models and brain regions when processing sentences? Can these deep models be used to synthesize brain data which can then be utilized in other extrinsic tasks? We investigate these questions using sentences with simple syntax and semantics . We consider multiple neural network architectures, including recently proposed ELMo and BERT. We use magnetoencephalography  brain recording data collected from human subjects when they were reading these simple sentences.   Overall, we find that BERT's activations correlate the best with MEG brain data. We also find that the deep network representation can be used to generate brain data from new sentences to augment existing brain data.  % To the best of our knowledge, this is the first work showing that the MEG brain recording when reading a word in a sentence can be used to distinguish earlier words in the sentence. Our exploration is also the first to use deep neural network representations to generate synthetic brain data and to show that it helps in improving subsequent stimuli decoding task accuracy. %We study the question of how the deep learning networks process simple sentences by using the human brain as a reference. More precisely, we used sentences with simple syntax and semantics , and trained multiple neural networks to predict the part of speech, next word, as each word arrives.  We presented other sentences of this same simple form word-by-word, to humans in a magnetoencephalography  scanner. We then trained a linear regression model to predict observed brain recording from the hidden layers of the trained neural network and some popular pre-trained networks like BERT and ELMo.  %Our results show  the neural network activations approximate observed brain recording when given the same input, suggesting that the deep network layer representation of input correlates with the brain activity, the network representation stores information about earlier words in the sentence,  the neural network representation can be used to generate brain data from new sentences to augment existing brain data.  % To our knowledge this is the first work showing that the MEG brain activation when reading a word in a sentence can be used to distinguish earlier words in the sentence. Our exploration is the first to use deep neural network representations to generate synthetic brain data and to show that it helps in improving the stimuli decoding accuracy.  % Q1. Can we train two different neural network architectures, and show that even though both predict the training signal well, one of them predicts neural activity better?     % Q2.  Does our model capture memory of earlier words   % Q3.  Can we use the neural network context to generate cheaper brain data to help in brain classification tasks ? [Yes]  
   Pre-trained word embeddings are the primary method for transfer learning in several Natural Language Processing  tasks. Recent works have focused on using unsupervised techniques such as language modeling to obtain these embeddings. In contrast, this work focuses on extracting representations from multiple pre-trained supervised models, which enriches word embeddings with task and domain specific knowledge. Experiments performed in cross-task, cross-domain and cross-lingual settings indicate that such supervised embeddings are helpful, especially in the low-resource setting, but the extent of gains is dependent on the nature of the task and domain. We make our code publicly available. \footnote{https://github.com/asiddhant/taskonomy-nlp} 
   The transformer is a state-of-the-art neural translation model that uses attention to iteratively refine lexical representations with information drawn from the surrounding context. Lexical features are fed into the first layer and propagated through a deep network of hidden layers. We argue that the need to represent and propagate lexical features in each layer limits the model's capacity for learning and representing other information relevant to the task. To alleviate this bottleneck, we introduce gated shortcut connections between the embedding layer and each subsequent layer within the encoder and decoder. This enables the model to access relevant lexical content dynamically, without expending limited resources on storing it within intermediate states. We show that the proposed modification yields consistent improvements over a baseline transformer on standard WMT translation tasks in 5 translation directions  and reduces the amount of lexical information passed along the hidden layers. We furthermore evaluate different ways to integrate lexical connections into the transformer architecture and present ablation experiments exploring the effect of proposed shortcuts on model behavior.\footnote{Our code is publicly available to aid the reproduction of the reported results: \url{https://github.com/demelin/transformer\_lexical\_shortcuts}} 
 Tables contain valuable knowledge in a structured form.  We employ neural language modeling approaches to embed tabular data into vector spaces.  Specifically, we consider different table elements, such caption, column headings, and cells, for training word and entity embeddings.  These embeddings are then utilized in three particular table-related tasks, row population, column population, and table retrieval, by incorporating them into existing retrieval models as additional semantic similarity signals.  Evaluation results show that table embeddings can significantly improve upon the performance of state-of-the-art baselines. 
 	Online media outlets adopt clickbait techniques to lure readers to click on articles in a bid to expand their reach and subsequently increase revenue through ad monetization. As the adverse effects of clickbait attract more and more attention, researchers have started to explore machine learning techniques to automatically detect clickbaits. Previous work on clickbait detection assumes that all the training data is available locally during training. In many real-world applications, however, training data is generally distributedly stored by different parties , and the parties cannot share their data with each other due to data privacy issues. It is challenging to build models of high-quality federally for detecting clickbaits effectively without data sharing. In this paper, we propose a federated training framework, which is called federated hierarchical hybrid networks, to build clickbait detection models, where the titles and contents are stored by different parties, whose relationships must be exploited for clickbait detection. We empirically demonstrate that our approach is effective by comparing our approach to the state-of-the-art approaches using datasets from social media. 
 The article presents a method that improves the quality of classification of objects described by a combination of known and unknown features. The method is based on modernized Informational Neurobayesian Approach with consideration of unknown features. The proposed method was developed and trained on 1500 text queries of Promobot users in Russian to classify them into 20 categories . As a result, the use of the method allowed to completely solve the problem of misclassification for queries with combining known and unknown features of the model.  The theoretical substantiation of the method is presented by the formulated and proved theorem On the Model with Limited Knowledge.  It states, that in conditions of limited data, an equal number of equally unknown features of an object cannot have different significance for the classification problem. 
 We introduce a lifelong language learning setup where a model needs to learn from a stream of text examples without any  dataset identifier. We propose an episodic memory model that performs sparse experience replay and  local adaptation to mitigate catastrophic forgetting in this setup. Experiments on text classification and question answering demonstrate the complementary benefits of sparse experience replay and local adaptation to allow the model  to continuously learn from new datasets. We also show that the space complexity of the episodic memory module can be  reduced significantly  by randomly choosing which examples to store in memory with a minimal decrease in performance. We consider an episodic memory component as a  crucial building block of  general linguistic intelligence and see our model as a first step in that direction. 
 \if 0 Knowledge graph  embeddings are useful for a wide variety of NLP tasks. However, knowledge graphs suffer from missing links between entities. Relation Prediction in KG is the main area of research due to incompleteness. Previous methods are based on relatively simple translational models for triples in KG. In contrast, recent works are based on  convolution which are efficient and learn more expressive features using deep learning. However, these methods treat triples independently and do not capture local neighborhood information connecting the triples in KG. This paper proposes a novel architecture of graph based attention model along with entity and relation features to improve KG embeddings. We generalize the neighborhood information of each entity to $n$-hops. This path generalization helps in extracting more information  for a smaller degree node or when the graph is sparse. We performed extensive experiments on five benchmark datasets and compared against state-of-the-art methods.  In addition, we conducted ablative studies on our attention model. Our results show significantly better performance on all the datasets than existing methods. \fi The recent proliferation of knowledge graphs  coupled with incomplete or partial information, in the form of missing relations  between entities, has fueled a lot of research on knowledge base completion . Several recent works suggest that convolutional neural network  based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction.  However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple.  To this effect, our paper proposes a novel attention-based feature embedding that captures both entity and relation features in any given entity's neighborhood. Additionally, we also encapsulate relation clusters and multi-hop relations  in our model. Our empirical study offers insights into the efficacy of our attention-based model and we show marked performance gains in comparison to state-of-the-art methods on all datasets.  
 Text reviews can provide rich useful semantic information for modeling users and items, which can benefit rating prediction in recommendation. Different words and reviews may have different informativeness for users or items. Besides, different users and items should be personalized. Most existing works regard all reviews equally or utilize a general attention mechanism.  In this paper, we propose a hierarchical attention model fusing latent factor model for rating prediction with reviews, which can focus on important  words and informative reviews.  Specially, we use the factor vectors of Latent Factor Model to guide the attention network and combine the factor vectors with feature representation learned from reviews to predict the final ratings.  Experiments on real-world datasets validate the effectiveness of our approach.  
 In this paper, we define and apply  , an intuitive way of analyzing neural language models. ReStA is a variant of the popular   in cognitive neuroscience. While RSA can be used to compare representations in models, model components, and human brains, ReStA compares instances of the  model, while systematically varying single model parameter.  % Using ReStA, we study four recent and successful neural language models, and evaluate how sensitive their internal representations are to the amount of prior context. Using RSA, we perform a systematic study of how similar the representational spaces in the first and second  layers of these models are to each other and to patterns of activation in the human brain.  % Our results reveal surprisingly strong differences between language models, and give insights into where the  linguistic processing, that integrates information over multiple sentences, is happening in these models. The combination of ReStA and RSA on models and brains allows us to start addressing the important question of what kind of linguistic processes we can hope to observe in fMRI brain imaging data. In particular, our results suggest that the data on story reading from Wehbe et al.\/  contains a signal of  linguistic processing, but show no evidence on the more interesting  linguistic processing. 
 Unitary Evolution Recurrent Neural Networks  have three attractive properties:  the unitary property,  the complex-valued nature, and  their efficient linear operators~. The literature so far does not address -- how critical is the unitary property of the model? Furthermore, uRNNs have not been evaluated on large tasks. To study these shortcomings, we propose the complex evolution Recurrent Neural Networks , which is similar to uRNNs but drops the unitary property selectively. On a simple multivariate linear regression task, we illustrate that dropping the constraints improves the learning trajectory. In copy memory task, ceRNNs and uRNNs perform identically, demonstrating that their superior performance over LSTMs is due to complex-valued nature and their linear operators. In a large scale real-world speech recognition, we find that pre-pending a uRNN degrades the performance of our baseline LSTM acoustic models, while pre-pending a ceRNN improves the performance over the baseline by 0.8\% absolute WER.   
 Medical ultrasound technology is widely used in routine clinical applications such as disease diagnosis and treatment as well as other applications like real-time monitoring of human tongue shapes and motions as visual feedback in second language training. Due to the low-contrast characteristic and noisy nature of ultrasound images, it might require expertise for non-expert users to recognize tongue gestures. Manual tongue segmentation is a cumbersome, subjective, and error-prone task. Furthermore, it is not a feasible solution for real-time applications.  \\ In the last few years, deep learning methods have been used for delineating and tracking tongue dorsum. Deep convolutional neural networks , which have shown to be successful in medical image analysis tasks, are typically weak for the same task on different domains. In many cases, DCNNs trained on data acquired with one ultrasound device, do not perform well on data of varying ultrasound device or acquisition protocol. Domain adaptation is an alternative solution for this difficulty by transferring the weights from the model trained on a large annotated legacy dataset to a new model for adapting on another different dataset using fine-tuning.  \\ In this study, after conducting extensive experiments, we addressed the problem of domain adaptation on small ultrasound datasets for tongue contour extraction. We trained a U-net network comprises of an encoder-decoder path from scratch, and then with several surrogate scenarios, some parts of the trained network were fine-tuned on another dataset as the domain-adapted networks. We repeat scenarios from target to source domains to find a balance point for knowledge transfer from source to target and vice versa. The performance of new fine-tuned networks was evaluated on the same task with images from different domains.    
 Grounding referring expressions in images aims to locate the object instance in an image described by a referring expression. It involves a joint understanding of natural language and image content, and is essential for a range of visual tasks related to human-computer interaction. As a language-to-vision matching task, the core of this problem is to not only extract all the necessary information  in both the image and referring expression, but also make full use of context information to align cross-modal semantic concepts in the extracted information. Unfortunately, existing work on grounding referring expressions fails to accurately extract multi-order relationships from the referring expression and associate them with the objects and their related contexts in the image. In this paper, we propose a Cross-Modal Relationship Extractor  to adaptively highlight objects and relationships  related to the given expression with a cross-modal attention mechanism, and represent the extracted information as a language-guided visual relation graph. In addition, we propose a Gated Graph Convolutional Network  to compute multimodal semantic contexts by fusing information from different modes and propagating multimodal information in the structured relation graph. Experimental results on three common benchmark datasets show that our Cross-Modal Relationship Inference Network, which consists of CMRE and GGCN, significantly surpasses all existing state-of-the-art methods.  % Grounding referring expressions in images aims to locate the object instance in an image described by a referring expression. It involves a joint understanding of natural language and image content and is essential for a range of visual tasks related to human-computer interaction. As a language-to-vision matching task, the core of this problem is to not only extract all the necessary information  in both the image and referring expressions, but also to to make full use of context information to achieve alignment of cross-modal semantic concepts in the extracted information.   % %Grounding referring expressions is a fundamental yet challenging task facilitating human-machine communication in the physical world. It aims to locate the target object in an image on the basis of comprehending the correlation between referring expressions in the form of natural language and the image content. A feasible solution for grounding referring expressions not only needs to extract all the necessary information  in both the image and referring expressions, but also compute and represent multimodal context from the extracted information.   % Unfortunately, existing work on grounding referring expressions fails to accurately extract multi-order relationships from the referring expressions and associate it with the object and its related context in the image. % the context they obtain have discrepancies with the context described by referring expressions.   % In this paper, we propose a Cross-Modal Relationship Extractor  to adaptively highlight objects and relationships  related to the given expression, with a cross-modal attention mechanism, and represent the extracted information as { language-guided visual relation graphs}. In addition, we propose a Gated Graph Convolutional Network  to compute multimodal semantic context by fusing information from different modes and propagating multimodal information in the structured {relation graphs}. Experimental results on three common benchmark datasets show that our Cross-Modal Relationship Inference Network, which consists of CMRE and GGCN, greatly surpass all existing state-of-the-art methods.    
 Events are happening in real-world and real-time, which can be planned and organized occasions involving multiple people and objects. Social media platforms publish a lot of text messages containing public events with comprehensive topics. However, mining social events is challenging due to the heterogeneous event elements in texts and explicit and implicit social network structures. In this paper, we design an event meta-schema to characterize the semantic relatedness of social events and build an event-based heterogeneous information network  integrating information from external knowledge base, and propose a novel Pairwise Popularity Graph Convolutional Network  based fine-grained social event categorization model. We propose a Knowledgeable meta-paths Instances based social Event Similarity  between events and build a weighted adjacent matrix as input to the PP-GCN model. Comprehensive experiments on real data collections are conducted to compare various social event detection and clustering tasks. Experimental results demonstrate that our proposed framework outperforms other alternative social event categorization techniques. 
 Inferring new facts from existing knowledge graphs  with explainable reasoning processes is a significant problem and has received much attention recently. However, few studies have focused on relation types unseen in the original KG, given only one or a few instances for training. To bridge this gap, we propose \model~for one-shot KG reasoning. The one-shot relational learning problem is tackled through two modules: the summary module summarizes the underlying relationship of the given instances, based on which the reasoning module infers the correct answers. Motivated by the dual process theory in cognitive science, in the reasoning module, a cognitive graph is built by iteratively coordinating retrieval  and reasoning . The structural information offered by the cognitive graph enables our model to aggregate pieces of evidence from multiple reasoning paths and explain the reasoning process graphically. Experiments show that \model}. 
   Today, the dominant paradigm for training neural networks involves   minimizing task loss on a large dataset. % Using world knowledge to inform a model, and yet retain the ability to perform end-to-end training remains an open question. % In this paper, we present a novel framework for introducing declarative knowledge to neural network architectures in order to guide training and prediction. Our framework systematically compiles logical statements into computation graphs that augment a neural network without extra learnable parameters or manual redesign. We evaluate our modeling strategy on three tasks: machine comprehension, natural language inference, and text chunking. % [VS: removed the next sentence. We shouldn't apologize in the abstract] % Instead of racing for state-of-the-art performance, we validate % and analyze the use of our framework. Our experiments show that knowledge-augmented networks can strongly improve over baselines, especially in low-data regimes.  %  End-to-end trained neural networks are widely used across %  NLP tasks. While successful in terms of accuracy, they are typically %  treated as black box classifiers.  In this paper, we address the %  question of systematically introducing declarative knowledge into %  the internal states of a neural network. To this end, we present %  \theModel: a modeling framework to integrate logical constraints %  into neural networks while retaining end-to-end learnability.  We %  show the utility of constraining neural models on text chunking %  and natural language inference tasks with significant improvements, %  especially in low training data regimes.  
 Solving complex, temporally-extended tasks is a long-standing problem in reinforcement learning . We hypothesize that one critical element of solving such problems is the notion of . With the ability to learn concepts and sub-skills that can be composed to solve longer tasks, i.e. hierarchical RL, we can acquire temporally-extended behaviors. However, acquiring effective yet general abstractions for hierarchical RL is remarkably challenging. In this paper, we propose to use language as the abstraction, as it provides unique compositional structure, enabling fast learning and combinatorial generalization, while retaining tremendous flexibility, making it suitable for a variety of problems. Our approach learns an instruction-following low-level policy and a high-level policy that can reuse abstractions across tasks, in essence, permitting agents to reason using structured language. To study compositional task learning, we introduce an open-source object interaction environment built using the MuJoCo physics engine and the CLEVR engine. We find that, using our approach, agents can learn to solve to diverse, temporally-extended tasks such as object sorting and multi-object rearrangement, including from raw pixel observations. Our analysis reveals that the compositional nature of language is critical for learning diverse sub-skills and systematically generalizing to new sub-skills in comparison to non-compositional abstractions that use the same supervision.\footnote{Code and videos of the environment, and experiments are at {https://sites.google.com/view/hal-demo}}    
 Recent progress in AutoML has lead to state-of-the-art methods  that can be readily used by non-experts to approach  supervised learning problem. Whereas these methods are quite effective, they are still limited in the sense that they work for tabular  data only.  %are already available, nonetheless none of them concentrate on the challenges of Natural Language Processing.  This paper describes one step forward in trying to automate the design of supervised learning methods in the context of text mining. %We approach the problem of automatically obtaining a representation for text mining tasks starting from raw text.  We introduce a meta learning methodology for automatically obtaining a representation for text mining tasks starting from raw text.  We report experiments considering 60 different textual representations and more than 80 text mining datasets associated to a wide variety of tasks. Experimental results show the proposed methodology is a promising solution to obtain highly effective off the shell text classification pipelines.   
\label{abs} Machine learning plays an increasing role in intelligent tutoring systems as both the amount of data available and specialization among students grow. Nowadays, these systems are frequently deployed on mobile applications. Users on such mobile education platforms are dynamic, frequently being added, accessing the application with varying levels of focus, and changing while using the service. The education material itself, on the other hand, is often static and is an exhaustible resource whose use in tasks such as problem recommendation must be optimized. The ability to update user models with respect to educational material in real-time is thus essential; however, existing approaches require time-consuming re-training of user features whenever new data is added. In this paper, we introduce a neural pedagogical agent for real-time user modeling in the task of predicting user response correctness, a central task for mobile education applications. Our model, inspired by work in natural language processing on sequence modeling and machine translation, updates user features in real-time via bidirectional recurrent neural networks with an attention mechanism over embedded question-response pairs. We experiment on the mobile education application SantaTOEIC, which has 559k users, 66M response data points as well as a set of 10k study problems each expert-annotated with topic tags and gathered since 2016. Our model outperforms existing approaches over several metrics in predicting user response correctness, notably out-performing other methods on new users without large question-response histories. Additionally, our attention mechanism and annotated tag set allow us to create an interpretable education platform, with a smart review system that addresses the aforementioned issue of varied user attention and problem exhaustion. %  We develop a smart, efficient review system for downstream problem suggestion by testing the interpretability of our model with respect to these tags and empirically demonstrate the ability to achieve efficient real-time user modeling while also having better effectiveness in accuracy compared to existing models. The improved performance and interpretability of our model are essential for dependent tasks in educational applications such as problem suggestion and score prediction.   % The model can also be applied within other frameworks which require a user-modeling component. % enables real-time updates of the user features by capturing item responses via recurrent neural networks.   % This high cost is a bottleneck for the introduction of such methods into practical applications.   
  Automatic data extraction from charts is challenging for two reasons: there exist many relations among objects in a chart, which is not a common consideration in general computer vision problems; and different types of charts may not be processed by the same model. To address these problems, we propose a framework of a single deep neural network, which consists of object detection, text recognition and object matching modules. The framework handles both bar and pie charts, and it may also be extended to other types of charts by slight revisions and by augmenting the training data. Our model performs successfully on 79.4\% of test simulated bar charts and 88.0\% of test simulated pie charts, while for charts outside of the training domain it degrades for 57.5\% and 62.3\%, respectively.  
  Generating textual descriptions for images has been an attractive problem for the computer vision and natural language processing researchers in recent years. Dozens of models based on deep learning have been proposed to solve this problem. The existing approaches are based on neural encoder-decoder structures equipped with the attention mechanism. These methods strive to train decoders to minimize the log likelihood of the next word in a sentence given the previous ones, which results in the sparsity of the output space. In this work, we propose a new approach to train decoders to regress the word embedding of the next word with respect to the previous ones instead of minimizing the log likelihood. The proposed method is able to learn and extract long-term information and can generate longer fine-grained captions without introducing any external memory cell. Furthermore, decoders trained by the proposed technique can take the importance of the generated words into the consideration while generating captions. In addition, a novel semantic attention mechanism is proposed that guides attention points through the image, taking the meaning of the previously generated word into account. We evaluate the proposed approach with the MS-COCO dataset. The proposed model outperformed the state of the art models especially in generating longer captions. It achieved a CIDEr score equal to 125.0 and a BLEU-4 score equal to 50.5, while the best scores of the state of the art models are 117.1 and 48.0, respectively.     % \PACS{PACS code1 \and PACS code2 \and more} %  
 In this work, we present graph star net , a novel and unified graph neural net architecture which utilizes message-passing relay and attention mechanism for multiple prediction tasks - node classification, graph classification and link prediction. GraphStar addresses many earlier challenges facing graph neural nets and achieves non-local representation without increasing the model depth or bearing heavy computational costs. We also propose a new method to tackle topic-specific sentiment analysis based on node classification and text classification as graph classification. Our work shows that 閳ユ笩tar nodes閳 can learn effective graph-data representation and improve on current methods for the three tasks. Specifically, for graph classification and link prediction, GraphStar outperforms the current state-of-the-art models by 2-5\% on several key benchmarks. 
     Speech processing systems rely on robust feature extraction to handle phonetic and semantic variations found in natural language. While techniques exist for desensitizing features to common noise patterns produced by Speech-to-Text  and Text-to-Speech  systems, the question remains how to best leverage state-of-the-art language models  on inputs with ASR errors. In this paper, we present Telephonetic, a data augmentation framework that helps robustify language model features to ASR corrupted inputs. To capture phonetic alterations, we employ a character-level language model trained using probabilistic masking. Phonetic augmentations are generated in two stages: a TTS encoder  and a STT decoder . Similarly, semantic perturbations are produced by sampling from nearby words in an embedding space, which is computed using the BERT language model. Words are selected for augmentation according to a hierarchical grammar sampling strategy. Telephonetic is evaluated on the Penn Treebank  corpus, and demonstrates its effectiveness as a bootstrapping technique for transferring neural language models to the speech domain. Notably, our language model achieves a test perplexity of 37.49 on PTB, which to our knowledge is state-of-the-art among models trained only on PTB. \\  
   Recently, speaker embeddings extracted from a speaker discriminative deep neural network  yield better performance than the conventional methods such as i-vector.   In most cases, the DNN speaker classifier is trained using cross entropy loss with softmax.   However, this kind of loss function does not explicitly encourage inter-class separability and intra-class compactness. As a result, the embeddings are not optimal for speaker recognition tasks.   In this paper, to address this issue, three different margin based losses which not only separate classes but also demand a fixed margin between classes are introduced to deep speaker embedding learning. It could be demonstrated that the margin is the key to obtain more discriminative speaker embeddings. Experiments are conducted on two public text independent tasks: VoxCeleb1 and Speaker in The Wild .   The proposed approach can achieve the state-of-the-art performance, with 25\% $\sim$ 30\% equal error rate  reduction on both tasks when compared to strong baselines using cross entropy loss with softmax, obtaining 2.238\% EER on VoxCeleb1 test set and 2.761\% EER on SITW core-core test set, respectively.  
 %When reading a sentences, humans naturally recognize entities formed of multiple words, such as ``the United Kingdom", and interpret them as single objects in the physical world. The dominant network architectures in NLP, however, keep each token separate during encoding. Named entity recognition  is one of the best studied tasks in natural language processing. However, most approaches are not capable of handling nested structures which are common in many applications. In this paper we introduce  a novel neural network architecture  %composed entirely of feedforward layers  that first merges tokens and/or entities into entities forming nested structures, and then labels each of them independently.  Unlike previous work, our merge and label approach predicts real-valued instead of discrete segmentation structures, which allow it to combine word and nested entity embeddings while maintaining differentiability. %which smoothly groups entities into single vectors across multiple levels.  %\todo{Say here what the advantages are}  We evaluate our approach using the ACE 2005 Corpus, where it achieves state-of-the-art F1 of 74.6, further improved with contextual embeddings  to 82.4, an overall improvement of close to 8 F1 points over previous approaches trained on the same data. Additionally we compare it against BiLSTM-CRFs, the dominant approach for flat NER structures, demonstrating that its ability to predict nested structures does not impact performance in simpler cases.\footnote{Code available at \url{https://github.com/fishjh2/merge_label}}  %achieving an F1 of 87.59 with non-contextual embeddings and 89.20 with BERT embeddings.   
 Automatic question generation according to an answer within the given passage is useful for many applications, such as question answering system, dialogue system, etc. Current neural-based methods mostly take two steps which extract several important sentences based on the candidate answer through manual rules or supervised neural networks and then use an encoder-decoder framework to generate questions about these sentences. These approaches neglect the semantic relations between the answer and the context of the whole passage which is sometimes necessary for answering the question. To address this problem, we propose the Weak Supervision Enhanced Generative Network  which automatically discovers relevant features of the passage given the answer span in a weak supervised manner to improve the quality of generated questions. More specifically, we devise a discriminator, Relation Guider, to capture the relations between the whole passage and the associated answer and then the Multi-Interaction mechanism is deployed to transfer the knowledge dynamically for our question generation system. Experiments show the effectiveness of our method in both automatic evaluations and human evaluations. 
 % Audiovisual synchronisation is the task of determining the time offset between speech audio  and a video recording of the articulators.  %  In child speech therapy, audio and ultrasound videos of the tongue are captured using instruments which rely on hardware to synchronise the two modalities at recording time. Hardware synchronisation can fail in practice, and no mechanism   exists to synchronise the signals post hoc.  % To address this problem,  we employ a two-stream neural network  which exploits the correlation between the two modalities  to find the offset.  % We train our model on recordings from 69 speakers,  and show that it correctly synchronises 82.9\% of test utterances from  unseen therapy sessions and unseen speakers, thus considerably reducing the number of utterances to be manually synchronised.  An analysis of model performance on the test utterances shows that  directed phone articulations are more difficult to automatically synchronise % compared to utterances containing natural variation in speech such as words, sentences, or conversations. %.  
 Claims are a fundamental unit of scientific discourse. The exponential growth in the number of scientific publications makes automatic claim extraction an important problem for researchers who are overwhelmed by this information overload. Such an automated claim extraction system is useful for both manual and programmatic exploration of scientific knowledge. In this paper, we introduce a new dataset of 1,500 scientific abstracts from the biomedical domain with expert annotations for each sentence indicating whether the sentence presents a scientific claim. We introduce a new model for claim extraction and compare it to several baseline models including rule-based and deep learning techniques. Moreover, we show that using a transfer learning approach with a fine-tuning step allows us to improve performance from a large discourse-annotated dataset. Our final model increases F1-score by over 14 percent points compared to a baseline model without transfer learning. We release a publicly accessible tool for discourse and claims prediction along with an annotation tool. We discuss further applications beyond biomedical literature. 
  Machine reading comprehension , which requires a machine to answer questions based on a given context, has attracted increasing attention with the incorporation of various deep-learning techniques over the past few years. Although research on MRC based on deep learning is flourishing, there remains a lack of a comprehensive survey summarizing existing approaches and recent trends, which motivated the work presented in this article. Specifically, we give a thorough review of this research field, covering different aspects including  typical MRC tasks: their definitions, differences, and representative datasets;  the general architecture of neural MRC: the main modules and prevalent approaches to each; and  new trends: some emerging areas in neural MRC as well as the corresponding challenges. Finally, considering what has been achieved so far, the survey also envisages what the future may hold by discussing the open issues left to be addressed. 
 Developing Video-Grounded Dialogue Systems , where a dialogue is conducted based on visual and audio aspects of a given video, is significantly more challenging than traditional image or text-grounded dialogue systems because   feature space of videos span across multiple picture frames, making it difficult to obtain semantic information; and  a dialogue agent must perceive and process information from different modalities  to obtain a comprehensive understanding.  Most existing work is based on RNNs and sequence-to-sequence architectures, which are not very effective for capturing complex long-term dependencies .  To overcome this, we propose Multimodal Transformer Networks  to encode videos and incorporate information from different modalities. We also propose query-aware attention through an auto-encoder to extract query-aware features from non-text modalities. We develop a training procedure to simulate token-level decoding to improve the quality of generated responses during inference. We get state of the art performance on Dialogue System Technology Challenge 7 . Our model also generalizes to another multimodal visual-grounded dialogue task, and obtains promising performance.  We implemented our models using PyTorch and the code is released at \url{https://github.com/henryhungle/MTN}.  
 Grammatical error correction can be viewed as a low-resource sequence-to-sequence task, because publicly available parallel corpora are limited.  To tackle this challenge, we first generate erroneous versions of large unannotated corpora using a realistic noising function. The resulting parallel corpora are subsequently used to pre-train Transformer models. Then, by sequentially applying transfer learning, we adapt these models to the domain and style of the test set.  Combined with a context-aware neural spellchecker, our system achieves competitive results in both restricted and low resource tracks in ACL 2019 BEA Shared Task.  We release all of our code and materials for reproducibility. \footnote{\url{https://github.com/kakaobrain/helo\_word}} 
 As summarization moves towards more abstractive generation, there is an increasing need for models that capture inherent narrative flow and challenging datasets suitable for measuring discourse-awareness of summarization models. In this paper, we introduce a dataset for discourse-aware summarization of scientific papers and a novel discriminator framework for generation of scientific abstracts with coherent narrative flow. We also propose a set of generation tasks with benchmarks for our new scientific paper dataset to encourage future research in this area. To capture the global context required for generation of coherent text with specific discourse structure and domain knowledge awareness, we use a two-stage transformer architecture that first generates abstracts, then re-ranks generations by predicting likelihood of sentence adjacency. We investigate the ability of the model to generalize beyond the formal and well-defined writing style of scientific documents to an existing dataset of web how-to guides. Our empirical results show that our transformer-based model outperforms existing summarization models on our new dataset and achieves state-of-the-art results on another discourse-aware summarization dataset.  
 As a commercial provider of machine translation, we are constantly training engines for a variety of uses, languages, and content types. In each case, there can be many variables, such as the amount of training data available, and the quality requirements of the end user. These variables can have an impact on the robustness of Neural MT engines. On the whole, Neural MT cures many ills of other MT paradigms, but at the same time it has introduced a new set of challenges to address. In this paper, we describe some of the specific issues with practical NMT and the approaches we take to improve model robustness in real world scenarios. 
  We use parsing as sequence labeling as a common framework to learn across constituency and dependency syntactic abstractions. To do so, we cast the problem as multitask learning . First, we show that adding a parsing paradigm as an auxiliary loss consistently improves the performance on the other paradigm. Secondly, we explore an mtl sequence labeling model that parses both representations, at almost no cost in terms of performance and speed. The results across the board show that on average mtl models with auxiliary losses for constituency parsing outperform single-task ones by 1.14 F1 points, and for dependency parsing by 0.62  uas points.\footnote{This is a revision of \url{https://arxiv.org/abs/1907.01339v2}. The previous version contained a bug where the EVALB scripts were not considering the COLLINS.prm and spmrl.prm parameter files.}    
  Neural language models  have been shown to outperform conventional n-gram language models by a substantial margin in Automatic Speech Recognition  and other tasks. There are, however, a number of challenges that need to be addressed for an NLM to be used in a practical large-scale ASR system.  In this paper, we present solutions to some of the challenges, including training NLM from heterogenous corpora, limiting latency impact and handling personalized bias in the second-pass rescorer. Overall, we show that we can achieve a 6.2\% relative WER reduction using neural LM in a second-pass n-best rescoring framework with a minimal increase in latency. 
 This paper describes a conditional neural network architecture for Mandarin Chinese polyphone disambiguation. The system is composed of a bidirectional recurrent neural network component acting as a sentence encoder to accumulate the context correlations, followed by a prediction network that maps the polyphonic character embeddings along with the conditions to corresponding pronunciations. We obtain the word-level condition from a pre-trained word-to-vector lookup table. One goal of polyphone disambiguation is to address the homograph problem existing in the front-end processing of Mandarin Chinese text-to-speech system. Our system achieves an accuracy of 94.69\% on a publicly available polyphonic character dataset. To further validate our choices on the conditional feature, we investigate polyphone disambiguation systems with multi-level conditions respectively. The experimental results show that both the sentence-level and the word-level conditional embedding features are able to attain good performance for Mandarin Chinese polyphone disambiguation.  
 Reinforcement learning  is frequently used to increase performance in text generation tasks, including machine translation ,  notably through the use of Minimum Risk Training  and Generative Adversarial Networks .  However, little is known about what and how these methods learn in the context of MT.  We prove that one of the most common RL methods for MT does not optimize the  expected reward, as well as show that other methods take an infeasibly long time to converge. In fact, our results suggest that RL practices in MT are likely to improve performance only where the pre-trained parameters are already close to yielding the correct translation. Our findings further suggest that observed gains may be due to effects unrelated to the training signal, but rather from changes in the shape of the distribution curve. 	  %Our results thus show that current RL practices for MT effectively           %consider only a very small part of the output space, contrary to one of the main motivations for using them. 	
 % Neural machine translation  has achieved significant progress in the recent years.  % Deep neural networks have brought significant advances to neural machine translation  with their strong modeling capacity.  While very deep neural networks have shown effectiveness for computer vision and text classification applications, how to increase the network depth of neural machine translation  models for better translation quality remains a challenging problem. Directly stacking more blocks to the NMT model results in no improvement and even reduces performance. In this work, we propose an effective two-stage approach with three specially designed components to construct deeper NMT models, which results in significant improvements over the strong Transformer baselines on WMT$14$ English$\to$German and English$\to$French translation tasks\footnote{{Our code is available at \url{https://github.com/apeterswu/Depth_Growing_NMT}}}. % Our approach is verified on two large-scale translation tasks, WMT$14$ English$\to$German and WMT$14$ English$\to$French translations. We achieved significant improvement on both tasks, especially in English$\to$German translation with more than $1.0$ BLEU score gain over the strong Transformer baseline. 
 % algorithm, and study its performance based on various qualitative and quantitative metrics. 
 This paper investigates the application of machine learning  techniques to enable intelligent systems to learn multi-party turn-taking models from dialogue logs. The specific ML task consists of determining who speaks next, after each utterance of a dialogue, given who has spoken and what was said in the previous utterances. With this goal, this paper presents comparisons of the accuracy of different ML techniques such as Maximum Likelihood Estimation , Support Vector Machines , and Convolutional Neural Networks  architectures, with and without utterance data. We present three corpora: the first with dialogues from an American TV situated comedy , the second with logs from a financial advice multi-bot system and the third with a corpus created from the Multi-Domain Wizard-of-Oz dataset . The results show:  the size of the corpus has a very positive impact on the accuracy for the content-based deep learning approaches and those models perform best in the larger datasets; and  if the dialogue dataset is small and topic-oriented , it is sufficient to use an agent-only MLE or SVM models, although slightly higher accuracies can be achieved with the use of the content of the utterances with a CNN model. 
 Multi-label charge prediction is a task to predict the corresponding accusations for legal cases, and recently becomes a hot topic. However, current studies use rough methods to deal with the label number. These methods manually set parameters to select label numbers, which has an effect in final prediction quality. We propose an external knowledge enhanced multi-label charge prediction approach that has two phases. One is charge label prediction phase with external knowledge from law provisions, the other one is number learning phase with a number learning network  designed. Our approach enhanced by external knowledge can automatically adjust the threshold to get label number of law cases. It combines the output probabilities of samples and their corresponding label numbers to get final prediction results. In experiments, our approach is connected to some state-of-the art deep learning models. By testing on the biggest published Chinese law dataset, we find that our approach has improvements on these models. We future conduct experiments on multi-label samples from the dataset. In items of macro-F1, the improvement of baselines with our approach is 3\%-5\%; In items of micro-F1, the significant improvement of our approach is 5\%-15\%. The experiment results show the effectiveness our approach for multi-label charge prediction.    
   We propose an interactive-predictive neural machine translation framework    for easier model personalization using reinforcement and imitation learning.    During the interactive translation process, the user is asked for feedback    on uncertain locations identified by the system.    Responses are weak feedback in the form of ``keep'' and ``delete'' edits,    and expert demonstrations in the form of ``substitute'' edits.    Conditioning on the collected feedback, the system creates alternative    translations via constrained beam search. In simulation experiments on    two language pairs our systems get close to the performance of supervised    training with much less human effort.    
 We address the task of assessing discourse coherence, an aspect of text quality that is essential for many NLP tasks, such as summarization and language assessment. We propose a hierarchical neural network trained in a multi-task fashion that learns to predict a document-level coherence score  along with word-level grammatical roles , taking advantage of inductive transfer between the two tasks.   We assess the extent to which our framework generalizes to different domains and prediction tasks, and demonstrate its effectiveness not only on standard binary evaluation coherence tasks, but also on real-world tasks involving the prediction of varying degrees of coherence, achieving a new state of the art.  
   Indicators of Compromise  are artifacts observed on a network or in an operating system that can be utilized to indicate a computer intrusion and detect cyber-attacks in an early stage. Thus, they exert an important role in the field of cybersecurity. However, state-of-the-art IOCs detection systems rely heavily on hand-crafted features with expert knowledge of cybersecurity, and require large-scale manually annotated corpora to train an IOC classifier. In this paper, we propose using an end-to-end neural-based sequence labelling model to identify IOCs automatically from  cybersecurity articles without expert knowledge of cybersecurity.  %   Our work is the first to apply an end-to-end sequence labelling to the task in IOCs identification.    By using a multi-head self-attention module and contextual features, we find that the proposed model is capable of gathering contextual information from texts of cybersecurity articles and performs better in the task of IOC identification.   Experiments show that the proposed model outperforms other sequence labelling models, achieving the average F1-score of 89.0\% on English cybersecurity article test set, and approximately the average F1-score of 81.8\% on Chinese test set. 
 \normalsize This paper proposes a novel multilingual multistage fine-tuning approach for low-resource neural machine translation , taking a challenging Japanese--Russian pair for benchmarking. Although there are many solutions for low-resource scenarios, such as multilingual NMT and back-translation, we have empirically confirmed their limited success when restricted to in-domain data. We therefore propose to exploit out-of-domain data through transfer learning, by using it to first train a multilingual NMT model followed by multistage fine-tuning on in-domain parallel and back-translated pseudo-parallel data. Our approach, which combines domain adaptation, multilingualism, and back-translation, helps improve the translation quality by more than 3.7 BLEU points, over a strong baseline, for this extremely low-resource scenario. 
 Cross-lingual embeddings aim to represent words in multiple languages in a shared vector space by capturing semantic similarities across languages. They are a crucial component for scaling tasks to multiple languages by transferring knowledge from languages with rich resources to low-resource languages. A common approach to learning cross-lingual embeddings is to train monolingual embeddings separately for each language and learn a linear projection from the monolingual spaces into a shared space, where the mapping relies on a small seed dictionary. While there are high-quality generic seed dictionaries and pre-trained cross-lingual embeddings available for many language pairs, there is little research on how they perform on specialised tasks. In this paper, we investigate the best practices for constructing the seed dictionary for a specific domain. We evaluate the embeddings on the sequence labelling task of Curriculum Vitae parsing and show that the size of a bilingual dictionary, the frequency of the dictionary words in the domain corpora and the source of data  influence the performance. We also show that the less training data is available in the low-resource language, the more the construction of the bilingual dictionary matters, and demonstrate that some of the choices are crucial in the zero-shot transfer learning case.  
 Event factuality prediction  is the task of assessing the degree to which an event mentioned in a sentence has happened. For this task, both syntactic and semantic information are crucial to identify the important context words. The previous work for EFP has only combined these information in a simple way that cannot fully exploit their coordination. In this work, we introduce a novel graph-based neural network for EFP that can integrate the semantic and syntactic information more effectively. Our experiments demonstrate the advantage of the proposed model for EFP. %, leading to the state-of-the-art results on different public datasets. 
 Lack of labeled training data is a major bottleneck for neural network based aspect and opinion term extraction on product reviews.  To alleviate this problem, we first propose an algorithm to automatically mine extraction rules from existing training examples based on dependency parsing results. The mined rules are then applied to label a large amount of auxiliary data. Finally, we study training procedures to train a neural model which can learn from both the data automatically labeled by the rules and a small amount of data accurately annotated by human. Experimental results show that although the mined rules themselves do not perform well due to their limited flexibility, the combination of human annotated data and rule labeled auxiliary data can improve the neural model and allow it to achieve performance better than or comparable with the current state-of-the-art. 
 Earlier approaches indirectly studied the information captured by the hidden states of recurrent and non-recurrent neural machine translation models by feeding them into different classifiers.  %  In this paper, we look at the encoder hidden states of both transformer and recurrent machine translation models from the nearest neighbors perspective. We investigate to what extent the nearest neighbors share information with the underlying word embeddings as well as related WordNet entries. Additionally, we study the underlying syntactic structure of the nearest neighbors to shed light on the role of syntactic similarities in bringing the neighbors together. We compare transformer and recurrent models in a more intrinsic way in terms of capturing lexical semantics and syntactic structures, in contrast to extrinsic approaches used by previous works.  %  In agreement with the extrinsic evaluations in the earlier works, our experimental results show that transformers are superior in capturing lexical semantics, but not necessarily better in capturing the underlying syntax. Additionally, we show that the backward recurrent layer in a recurrent model learns more about the semantics of words, whereas the forward recurrent layer encodes more context. 
 Transfer learning aims to reduce the amount of data required to excel at a new task by re-using the knowledge acquired from learning other related tasks. This paper proposes a novel transfer learning scenario, which distills robust phonetic features from grounding models that are trained to tell whether a pair of image and speech are semantically correlated, without using any textual transcripts.  As semantics of speech are largely determined by its lexical content, grounding models learn to preserve phonetic information while disregarding uncorrelated factors, such as speaker and channel. To study the properties of features distilled from different layers, we use them as input separately to train multiple speech recognition models. Empirical results demonstrate that layers closer to input retain more phonetic information,  while following layers exhibit greater invariance to domain shift. Moreover, while most previous studies include training data for speech recognition for feature extractor training, our grounding models are not trained on any of those data, indicating more universal applicability to new domains.  
 We present a multispeaker, multilingual text-to-speech  synthesis model based on Tacotron that is able to produce high quality speech in multiple languages. Moreover, the model is  able to transfer voices across languages, e.g.\ synthesize fluent Spanish speech using an English speaker's voice, without training on any bilingual or parallel examples. Such transfer % works across distantly related languages, e.g.\ English and Mandarin.   Critical to achieving this result are: [1.] Further scaling up the model by training on multiple speakers of each language, and incorporating an autoencoding input to help stabilize attention during training, results in a model which can be used to consistently synthesize intelligible speech for training speakers in all languages seen during training, and in native or foreign accents.  
 % Filters of convolutional networks used in computer vision are often visualized as image patches that maximize the response of the filter. % We use the same approach to interpret weight matrices in simple architectures for natural language processing tasks. % We interpret a convolutional network for sentiment classification as word-based rules. Using the rule, we recover the performance of the original model. % %Further, we analyze simple model for natural language inference and part-of-speech tagging and analyze what words are the networks respond to. % 
   It can be challenging to train multi-task neural networks that outperform or even match their single-task counterparts.    To help address this, we propose    using knowledge distillation where single-task models teach a multi-task model.   We enhance this training with teacher annealing, a novel method that gradually transitions the model from distillation to supervised learning, helping the multi-task model surpass its single-task teachers.   We evaluate our approach by multi-task fine-tuning BERT on the GLUE benchmark.    Our method consistently improves over standard single-task and multi-task training.  
  We introduce our efforts towards building a universal neural machine translation  system capable of translating between any language pair. We set a milestone towards this goal by building a single massively multilingual NMT model handling 103 languages trained on over 25 billion examples. Our system demonstrates effective transfer learning ability, significantly improving translation quality of low-resource languages, while keeping high-resource language translation quality on-par with competitive bilingual baselines. We provide in-depth analysis of various aspects of model building that are crucial to achieving quality and practicality in universal NMT. While we prototype a high-quality universal translation system, our extensive empirical analysis exposes issues that need to be further addressed, and we suggest directions for future research. 
 Not all types of supervision signals are created equal: Different types of feedback have different costs and effects on learning. We show how self-regulation strategies that decide when to ask for which kind of feedback from a teacher  can be cast as a learning-to-learn problem leading to improved cost-aware sequence-to-sequence learning. In experiments on interactive neural machine translation, we find that the self-regulator discovers an $\epsilon$-greedy strategy for the optimal cost-quality trade-off by mixing different feedback types including corrections, error markups, and self-supervision. Furthermore, we demonstrate its robustness under domain shift and identify it as a promising alternative to active learning. 
 Relation extraction  aims at extracting the relation between two entities from the text corpora. It is a crucial task for Knowledge Graph  construction. Most existing methods predict the relation between an entity pair by learning the relation from the training sentences, which contain the targeted entity pair. In contrast to existing distant supervision approaches that suffer from insufficient training corpora to extract relations, our proposal of mining implicit mutual relation from the massive unlabeled corpora transfers the semantic information of entity pairs into the RE model, which is more expressive and semantically plausible. After constructing an entity proximity graph based on the implicit mutual relations, we preserve the semantic relations of entity pairs via embedding each vertex of the graph into a low-dimensional space. As a result, we can easily and flexibly integrate the implicit mutual relations and other entity information, such as entity types, into the existing RE methods.    % Our experimental results on a New York Times and another Google Distant Supervision datasets suggest that our proposed neural RE framework provides a promising improvement for the RE task, and significantly outperforms the state-of-the-art methods. Moreover, the component for mining implicit mutual relations is so flexible that can help to improve the performance of both CNN-based and RNN-based RE models significant. 
 Chinese input recommendation plays an important role in alleviating human cost in typing Chinese words, especially in the scenario of mobile applications. The fundamental problem is to predict the conditional probability of the next word given the sequence of previous words. Therefore, statistical language models, i.e.~n-grams based models, have been extensively used on this task in real application. However, the characteristics of extremely different typing behaviors usually lead to serious sparsity problem, even n-gram with smoothing will fail. A reasonable approach to tackle this problem is to use the recently proposed neural models, such as probabilistic neural language model, recurrent neural network and word2vec. They can leverage more semantically similar words for estimating the probability. However, there is no conclusion on which approach of the two will work better in real application. In this paper, we conduct an extensive empirical study to show the differences between statistical and neural language models. The experimental results show that the two different approach have individual advantages, and a hybrid approach will bring a significant improvement. 
 % End-to-end  have attracted a lot of attention for their superiority  over pipeline modularized . % Previous studies on end-to-end  use a single-module model to generate responses for complex dialogue contexts. However, no model consistently outperforms the others in all cases.  We propose a neural  framework, in which a few expert bots are combined to generate the response for a given dialogue context.  consists of a chair bot and several expert bots. Each expert bot is specialized for a particular situation, e.g., one domain, one type of action of a system, etc.  The chair bot coordinates multiple expert bots and adaptively selects an expert bot to generate the appropriate response. We further propose a  model to implement , where the expert bots predict multiple tokens at each timestamp and the chair bot determines the final generated token by fully taking into consideration the outputs of all expert bots. Both the chair bot and the expert bots are jointly trained in an end-to-end fashion.  To verify the effectiveness of , we carry out extensive experiments on a benchmark dataset. Compared with the baseline using a single-module model, our  improves the performance by 8.1\% of inform rate and 0.8\% of success rate. 
 Personalized news recommendation is very important for online news platforms to help users find interested news and improve user experience. News and user representation learning is critical for news recommendation. Existing news recommendation methods usually learn these representations based on single news information, e.g., title, which may be insufficient. In this paper we propose a neural news recommendation approach which can learn informative representations of users and news by exploiting different kinds of news information. The core of our approach is a news encoder and a user encoder. In the news encoder we propose an attentive multi-view learning model to learn unified news representations from titles, bodies and topic categories by regarding them as different views of news. In addition, we apply both word-level and view-level attention mechanism to news encoder to select important words and views for learning informative news representations. In the user encoder we learn the representations of users based on their browsed news and apply attention mechanism to select informative news for user representation learning. Extensive experiments on a real-world dataset show our approach can effectively improve the performance of news recommendation.  
 The dominant approaches for named entity recognition  mostly adopt complex recurrent neural networks ,  long-short-term-memory . However, RNNs are limited by their recurrent nature in terms of computational efficiency. In contrast, convolutional neural networks  can fully exploit the GPU parallelism with their feed-forward architectures. However, little attention has been paid to performing NER with CNNs, mainly owing to their difficulties in capturing the long-term context information in a sequence. In this paper, we propose a simple but effective CNN-based network for NER,  gated relation network , which is more capable than common CNNs in capturing long-term context. Specifically, in \GRN{} we firstly employ CNNs to explore the local context features of each word. Then we model the relations between words and use them as gates to fuse local context features into global ones for predicting labels. Without using recurrent layers that process a sentence in a sequential manner, our \GRN{} allows computations to be performed in parallel across the entire sentence. Experiments on two benchmark NER datasets  show that, our proposed \GRN{} can achieve state-of-the-art performance with or without external knowledge. It also enjoys lower time costs to train and test. We have made the code publicly available at https://github.com/HuiChen24/NER-GRN. 
 Deep learning based question answering  on English documents has achieved success because there is a large amount of English training examples. However, for most languages, training examples for high-quality QA models are not available.  In this paper, we explore the problem of cross-lingual transfer learning for QA, where a source language  task with plentiful annotations is utilized to improve the performance of a QA model on a target language  task with limited available annotations.  We examine two different approaches.  A machine translation  based approach translates the source language into the target language, or vice versa. Although the MT-based approach brings improvement, it assumes the availability of a sentence-level translation system. A GAN-based approach incorporates a language discriminator to learn language-universal feature representations, and consequentially transfer knowledge from the source language. The GAN-based approach rivals the performance of the MT-based approach with fewer linguistic resources.  Applying both approaches simultaneously  yield the best results. We use two English benchmark datasets, SQuAD and NewsQA, as source language data, and show significant improvements over a number of established baselines on a Chinese QA task.  We achieve the new state-of-the-art on the Chinese QA dataset.  
   This paper describes the Microsoft Translator submissions to the WMT19 news translation shared task for English-German. Our main focus is document-level neural machine translation with deep transformer models.    We start with strong sentence-level baselines, trained on large-scale data created via data-filtering and noisy back-translation and find that back-translation seems to mainly help with translationese input. We explore fine-tuning techniques, deeper models and different ensembling strategies to counter these effects.   Using document boundaries present in the authentic and synthetic parallel data, we create sequences of up to 1000 subword segments and train transformer translation models. We experiment with data augmentation techniques for the smaller authentic data with document-boundaries and for larger authentic data without boundaries.      We further explore multi-task training for the incorporation of document-level source language monolingual data via the BERT-objective on the encoder and two-pass decoding for combinations of sentence-level and document-level systems.   Based on preliminary human evaluation results, evaluators strongly prefer the document-level systems over our comparable sentence-level system. The document-level systems also seem to score higher than the human references in source-based direct assessment.  
 Language identification  has relevance in many speech processing applications. For the automatic recognition of code-switching speech, the conventional approaches often employ an LID system for detecting the languages present within an utterance. In the existing works, the LID on code-switching speech involves modelling of the underlying languages separately. In this work, we propose a joint modelling based LID system for code-switching speech. To achieve the same, an attention-based end-to-end  network has been explored. For the development and evaluation of the proposed approach, a recently created Hindi-English code-switching corpus has been used. For the contrast purpose, an LID system employing the connectionist temporal classification-based  E2E network is also developed. On comparing both the LID systems, the attention based approach is noted to result in better LID accuracy. The effective location of code-switching boundaries within the utterance by the proposed approach has been demonstrated by plotting the attention weights of E2E network.\\ 
  Keyword extraction is used for summarizing the content of a document and supports efficient document retrieval, and is as such an indispensable part of modern text-based systems. We explore how load centrality, a graph-theoretic measure applied to graphs derived from a given text can be used to efficiently identify and rank keywords. Introducing meta vertices  and systematic redundancy filters, the proposed method performs on par with state-of-the-art for the keyword extraction task on 14 diverse datasets. The proposed method is unsupervised, interpretable and can also be used for document visualization.  
 Modeling relations between languages can offer understanding of language characteristics and uncover similarities and differences between languages. Automated methods applied to large textual corpora can be seen as opportunities for novel statistical studies of language development over time, as well as for improving cross-lingual natural language processing techniques. In this work, we first propose how to represent textual data as a directed, weighted network by the text2net algorithm. We next explore how various fast, network-topological metrics, such as network community structure, can be used for cross-lingual comparisons. In our experiments, we employ eight different network topology metrics, and empirically showcase on a parallel corpus, how the methods can be used for modeling the relations between nine selected languages. We demonstrate that the proposed method scales to large corpora consisting of hundreds of thousands of aligned sentences on an of-the-shelf laptop. We observe that on the one hand properties such as communities, capture some of the known differences between the languages, while others can be seen as novel opportunities for linguistic studies.     
   Relation detection is a core step in many natural language process applications including knowledge base question answering. Previous efforts show that single-fact questions could be answered with high accuracy. However, one critical problem is that current approaches only get high accuracy for questions whose relations have been seen in the training data. But for unseen relations, the performance will drop rapidly. The main reason for this problem is that the representations for unseen relations are missing. In this paper, we propose a simple mapping method, named representation adapter, to learn the representation mapping for both seen and unseen relations based on previously learned relation embedding. We employ the adversarial objective and the reconstruction objective to improve the mapping performance. We re-organize the popular SimpleQuestion dataset to reveal and evaluate the problem of detecting unseen relations. Experiments show that our method can greatly improve the performance of unseen relations while the performance for those seen part is kept comparable to the state-of-the-art.\footnote{Our code and data are available at  \url{https://github.com/wudapeng268/KBQA-Adapter}.}    
   We are surprised to find that BERT's peak performance of 77\% on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work. 
 People express their opinions and emotions freely in social media posts and online reviews that contain valuable feedback for multiple stakeholders such as businesses and political campaigns. Manually extracting opinions and emotions from large volumes of such posts is an impossible task. Therefore, automated processing of these posts to extract opinions and emotions is an important research problem. However, human emotion detection is a challenging task due to the complexity and nuanced nature. To overcome these barriers, researchers have extensively used techniques such as deep learning, distant supervision, and transfer learning. In this paper, we propose a novel Pyramid Attention Network  based model for emotion detection in microblogs. The main advantage of our approach is that PAN has the capability to evaluate sentences in different perspectives to capture multiple emotions existing in a single text. The proposed model was evaluated on a recently released dataset and the results achieved the state-of-the-art accuracy of 58.9\%. 
   Detecting emotions from text is an extension of simple sentiment polarity detection. Instead of considering only positive or negative sentiments, emotions are conveyed using more tangible manner; thus, they can be expressed as many shades of gray. This paper manifests the results of our experimentation for fine-grained emotion analysis on Bangla text. We gathered and annotated a text corpus consisting of user comments from several Facebook groups regarding socio-economic and political issues, and we made efforts to extract the basic emotions  conveyed through these comments. Finally, we compared the results of the five most popular classical machine learning techniques namely Na\"{\% and an F1 score  of 0.3324. 
     There is a growing interest in investigating what neural NLP models learn about language.     A prominent open question is the question of whether or not it is necessary to model hierarchical structure.      We present a linguistic investigation of a neural parser adding insights to this question.     We look at transitivity and agreement information of auxiliary verb constructions  in comparison to finite main verbs . This comparison is motivated by theoretical work in dependency grammar and in particular the work of  where AVCs and FMVs are both instances of a nucleus, the basic unit of syntax. An AVC is a dissociated nucleus, it consists of at least two words, and an FMV is its non-dissociated counterpart, consisting of exactly one word. We suggest that the representation of AVCs and FMVs should capture similar information.     We use diagnostic classifiers to probe agreement and transitivity information in vectors learned by a transition-based neural parser in four typologically different languages. We find that the parser learns different information about AVCs and FMVs if only sequential models  are used in the architecture but similar information when a recursive layer is used. We find explanations for why this is the case by looking closely at how information is learned in the network and looking at what happens with different dependency representations of AVCs. We conclude that there may be benefits to using a recursive layer in dependency parsing and that we have not yet found the best way to integrate it in our parsers. 
 %Text mining of scientific libraries and social media has already proven itself as a reliable tool for drug repurposing and hypothesis generation.  In this work, we consider the  problem, i.e., the problem of mapping a health-related entity mention in a free-form text to a concept in a controlled vocabulary, usually to the standard thesaurus in the Unified Medical Language System . % is known as medical concept normalization.  This is a challenging task since medical terminology is very different when coming from health care professionals or from the general public in the form of social media texts. We approach it as a sequence learning problem with powerful neural networks such as recurrent neural networks and contextualized word representation models trained to obtain semantic representations of social media expressions. Our experimental evaluation over three different benchmarks shows that neural architectures leverage the semantic meaning of the entity mention and significantly outperform an existing state of the art models. %We develop end-to-end neural architectures tailored specifically to medical concept normalization, including bidirectional LSTM and GRU with an attention mechanism and additional semantic similarity features based on UMLS. Our evaluation over three standard benchmarks shows  %that our model improves over a state of the art baseline for classification based on CNNs. %A qualitative examination of mentions discovered in a dataset of user reviews collected from popular online health information platforms as well as quantitative evaluation both show improvements in semantic representation of health-related expressions in social media. 
   In this paper, we try to understand neural machine translation  via simplifying NMT architectures and training encoder-free NMT models. In an encoder-free model, the sums of word embeddings and positional embeddings represent the source. The decoder is a standard Transformer or recurrent neural network that directly attends to embeddings via attention mechanisms. Experimental results show  that the attention mechanism in encoder-free models acts as a strong feature extractor,  that the word embeddings in encoder-free models are competitive to those in conventional models,  that non-contextualized source representations lead to a big performance drop, and  that encoder-free models have different effects on alignment quality for German$\rightarrow$English and Chinese$\rightarrow$English.   
   Recent work has demonstrated that vector offsets obtained by   subtracting pretrained word embedding vectors can be used to predict lexical relations with surprising   accuracy. Inspired by this finding, in this paper, we extend the idea   to the document level, in generating document-level embeddings,   calculating the distance between them, and   using a linear classifier to classify the relation between the   documents. In the context of duplicate detection and dialogue act   tagging tasks, we show that document-level difference vectors have utility in assessing   document-level similarity, but perform less well in multi-relational   classification. 
 Named entity recognition  and entity linking  are two fundamentally related tasks, since in order to perform EL, first the mentions to entities have to be detected. However, most entity linking approaches disregard the mention detection part, assuming that the correct mentions have been previously detected. In this paper, we perform joint learning of NER and EL to leverage their relatedness and obtain a more robust and generalisable system. For that, we introduce a model inspired by the Stack-LSTM approach . We observe that, in fact, doing multi-task learning of NER and EL improves the performance in both tasks when comparing with models trained with individual objectives. Furthermore, we achieve results competitive with the state-of-the-art in both NER and EL. 
Learning dynamic word embeddings with drift regularisation
Advanced neural language models  are widely used in sequence generation tasks because they are able to produce fluent and meaningful sentences. They can also be used to generate fake reviews, which can then be used to attack online review systems and influence the buying decisions of online shoppers.  To perform such attacks, it is necessary for experts to train a tailored LM for a specific topic. In this work, we show that a low-skilled threat model can be built just by combining publicly available LMs and show that the produced fake reviews can fool both humans and machines. In particular, we use the GPT-2 NLM to generate a large number of high-quality reviews based on a review with the desired sentiment and then using a BERT based text classifier  to filter out reviews with undesired sentiments. Because none of the words in the review are modified, fluent samples like the training data can be generated from the learned distribution. A subjective evaluation with 80 participants demonstrated that this simple method can produce reviews that are as fluent as those written by people. It also showed that the participants tended to distinguish fake reviews randomly. Three countermeasures, Grover, GLTR, and OpenAI GPT-2 detector, were found to be difficult to accurately detect fake review.  
 Semantic role labeling , also known as shallow semantic parsing, is an important yet challenging  task in NLP.  Motivated by the close correlation between syntactic and semantic structures, traditional discrete-feature-based SRL approaches make heavy use of syntactic features.  In contrast,  deep-neural-network-based approaches usually encode the input sentence as a word sequence without considering the syntactic structures.  In this work, we investigate several previous approaches for encoding syntactic trees, and make a thorough study on whether extra syntax-aware representations are beneficial for neural SRL models. Experiments on the benchmark CoNLL-2005 dataset show that syntax-aware SRL approaches can effectively improve performance over a strong baseline with external word representations from ELMo. With the extra syntax-aware representations, our approaches achieve new state-of-the-art 85.6 F1  and 86.6 F1  on the test data, outperforming the corresponding strong baselines with ELMo by 0.8 and 1.0, respectively. Detailed error analysis are conducted to gain more insights on the investigated approaches.   
  We consider the problem of learning to map from natural language instructions to state transitions  in a data-efficient manner.  Our method takes inspiration from the idea that it should be easier to ground language to concepts that have already been formed through pre-linguistic observation.  We augment a baseline instruction-following learner with an initial environment-learning phase that uses observations of language-free state transitions to induce a suitable latent representation of actions before processing the instruction-following training data.  We show that mapping to pre-learned representations substantially improves performance over systems whose representations are learned from limited instructional data alone.  
 Natural Language Inference , also known as Recognizing Textual Entailment , is one of the most important problems in natural language processing. It requires to infer the logical relationship between two given sentences. While current approaches mostly focus on the interaction architectures of the sentences, in this paper, we propose to transfer knowledge from some important discourse markers to augment the quality of the NLI model. We observe that people usually use some discourse markers such as ``so" or ``but" to represent the logical relationship between two sentences. These words potentially have deep connections with the meanings of the sentences, thus can be utilized to help improve the representations of them. Moreover, we use reinforcement learning to optimize a new objective function with a reward defined by the property of the NLI datasets to make full use of the labels information. Experiments show that our method achieves the state-of-the-art performance on several large-scale datasets. 
 People ask questions that are far richer, more informative, and more creative than current AI systems. We propose a neuro-symbolic framework for modeling human question asking, which represents questions as formal programs and generates programs with an encoder-decoder based deep neural network. From extensive experiments using an information-search game, we show that our method can ask optimal questions in synthetic settings, and predict which questions humans are likely to ask in unconstrained settings. We also propose a novel grammar-based question generation framework trained with reinforcement learning, which is able to generate creative questions without supervised human data. 
 Neural dialog models have exhibited strong performance, however their end-to-end nature lacks a representation of the explicit structure of dialog. This results in a loss of generalizability, controllability and a data-hungry nature. Conversely, more traditional dialog systems do have strong models of explicit structure. This paper introduces several approaches for explicitly incorporating structure into neural models of dialog. Structured Fusion Networks first learn neural dialog modules corresponding to the structured components of traditional dialog systems and then incorporate these modules in a higher-level generative model. Structured Fusion Networks obtain strong results on the MultiWOZ dataset, both with and without reinforcement learning. Structured Fusion Networks are shown to have several valuable properties, including better domain generalizability, improved performance in reduced data scenarios and robustness to divergence during reinforcement learning. 
 Variants dropout methods have been designed for the fully-connected layer, convolutional layer and recurrent layer in neural networks, and shown to be effective to avoid overfitting. As an appealing alternative to recurrent and convolutional layers, the fully-connected self-attention layer surprisingly lacks a specific dropout method. This paper explores the possibility of regularizing the attention weights in Transformers to prevent different contextualized feature vectors from co-adaption. Experiments on a wide range of tasks show that DropAttention can improve performance and reduce overfitting.     
 Neural network has become the dominant method for Chinese word segmentation. Most existing models cast the task as sequence labeling, using BiLSTM-CRF for representing the input and making output predictions. Recently, attention-based sequence models have emerged as a highly competitive alternative to LSTMs, which allow better running speed by parallelization of computation. We investigate self attention for Chinese word segmentation, making comparisons between BiLSTM-CRF models. In addition, the influence of contextualized character embeddings is investigated using BERT, and a method is proposed for integrating word information into SAN segmentation. Results show that SAN gives highly competitive results compared with BiLSTMs, with BERT and word information further improving segmentation for in-domain and cross-domain segmentation. Our final models give the best results for 6 heterogenous domain benchmarks. 
  Highlights        In light of the increasing availability of digitally recorded safety reports in the construction industry, it is important to develop methods to exploit these data to improve our understanding of safety incidents and ability to learn from them. In this study, we compare several approaches to automatically learn injury precursors from raw construction accident reports.  More precisely, we experiment with two state-of-the-art deep learning architectures for Natural Language Processing , Convolutional Neural Networks  and Hierarchical Attention Networks , and with the established Term Frequency - Inverse Document Frequency representation  + Support Vector Machine  approach. For each model, we provide a method to identify  the textual patterns that are, on average, the most predictive of each safety outcome. We show that among those pieces of text, valid injury precursors can be found. The proposed methods can also be used by the user to visualize and understand the models' predictions. 
 In this paper, we present an end-to-end empathetic conversation agent, CAiRE. Our system adapts the learning approach from TransferTransfo~ which fine-tunes a large-scale pre-trained language model with multiple objectives: response language modeling, response prediction, and dialogue emotion detection. We evaluate our model on the recently proposed empathetic-dialogues dataset~. Our experiment results show that CAiRE achieves state-of-the-art performance on dialogue emotion detection and empathetic response generation. 
 The dialogue management is a task of conversational artificial intelligence. The goal of the dialogue manager is to select the appropriate response to the conversational partner conditioned by the input message and recent dialogue state. Hybrid Code Networks is one of the models of dialogue managers, which uses an average of word embeddings and bag-of-words as input features. We perform experiments on Dialogue bAbI Task 6 and Alquist Conversational Dataset. The experiments show that the convolutional neural network used as an input layer of the Hybrid Code Network improves the model's turn accuracy.  
  This paper presents a simple and computationally efficient approach for entity linking , compared with recurrent neural networks  or convolutional neural networks , by making use of feedforward neural networks  and the recent dual fixed-size ordinally forgetting encoding  method to fully encode the sentence fragment and its left/right contexts into a fixed-size representation. Furthermore, in this work, we propose to incorporate PageRank based distillation in our candidate generation module. Our neural linking models consist of three parts: a PageRank based candidate generation module, a dual-FOFE-net neural ranking model and a simple NIL entity clustering system. Experimental results have shown that our proposed neural linking models achieved higher EL accuracy than state-of-the-art models on the TAC2016 task dataset over the baseline system, without requiring any in-house data or complicated handcrafted features. Moreover, it achieves a competitive accuracy on the TAC2017 task dataset.   
  Building dialogue systems that naturally converse with humans is being an attractive and an active research domain. Multiple systems are being designed everyday and several datasets are being available. For this reason, it is being hard to keep an up-to-date state-of-the-art. In this work, we present the latest and most relevant retrieval-based dialogue systems and the available datasets used to build and evaluate them. We discuss their limitations and provide insights and guidelines for future work. %Today, retrieval-based dialogue systems are an active research area. In this survey paper, we present an overview of the latest works in this area, present the datasets and the metrics used in building and evaluating the existing systems. Currently, many works are interested in building and constructing dialogue systems and large datasets. In this work, we briefly overview the most recent systems and the available datasets and provide a catalogue for people   
 %  can be formulated as a sequential decision-making problem, which can be solved by  algorithms.  The predominant RL paradigm for summarisation learns a  policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards. % Learning  RL policies is a more efficient alternative\MM[,]{} but so far depends on handcrafted rewards, which are difficult to design and yield poor performance. % We propose \rise{}, a novel RL paradigm that learns a reward function with  algorithms  at training time and uses this reward function to train an  \mbox{input-specific} RL policy at test time. % We prove that \rise{} guarantees to  generate \mbox{near-optimal} summaries  with appropriate L2R and RL algorithms. % Empirically, we evaluate our approach on  extractive multi-document summarisation. % summarisation}. We show that \rise{} reduces the training  time by two orders of magnitude compared to  the state-of-the-art models while performing on par with them.    %}  
 Understanding and conversing about dynamic scenes is one of the key capabilities of AI agents that navigate the environment and convey useful information to humans. Video question answering is a specific scenario of such AI-human interaction where an agent generates a natural language response to a question regarding the video of a dynamic scene. Incorporating features from multiple modalities, which often provide supplementary information, is one of the challenging aspects of video question answering. Furthermore, a question often concerns only a small segment of the video, hence encoding the entire video sequence using a recurrent neural network is not computationally efficient. Our proposed question-guided video representation module efficiently generates the token-level video summary guided by each word in the question. The learned representations are then fused with the question to generate the answer. Through empirical evaluation on the Audio Visual Scene-aware Dialog  dataset~, our proposed models in single-turn and multi-turn question answering achieve state-of-the-art performance on several automatic natural language generation evaluation metrics. 
 Dialogue systems are increasingly using knowledge bases  storing real-world facts to help generate quality responses. However, as the KBs are inherently incomplete and remain fixed during conversation, it limits dialogue systems' ability to answer questions and to handle questions involving entities or relations that are not in the KB. In this paper, we make an attempt to propose an engine for Continuous and Interactive Learning of Knowledge  for dialogue systems to give them the ability to continuously and interactively learn and infer new knowledge during conversations. With more knowledge accumulated over time, they will be able to learn better and answer more questions. Our empirical evaluation shows that CILK is promising.  
 Recently, there has been interest in multiplicative recurrent neural networks for language modeling.  Indeed, simple Recurrent Neural Networks  encounter difficulties recovering from past mistakes when generating sequences due to high correlation between hidden states.  These challenges can be mitigated by integrating second-order terms in the hidden-state update.  One such model, multiplicative Long Short-Term Memory  is particularly interesting in its original formulation because of the sharing of its second-order term, referred to as the intermediate state. We explore these architectural improvements by introducing new models and testing them on character-level language modeling tasks. This allows us to establish the relevance of shared parametrization in recurrent language modeling. 
  Recent work has shown that memory modules are crucial for the generalization ability of neural networks on learning simple algorithms. However, we still have little understanding of the working mechanism of memory modules. To alleviate this problem, we apply a two-step analysis pipeline consisting of first inferring hypothesis about what strategy the model has learned according to visualization and then verify it by a novel proposed qualitative analysis method based on dimension reduction. Using this method, we have analyzed two popular memory-augmented neural networks, neural Turing machine and stack-augmented neural network on two simple algorithm tasks including reversing a random sequence and evaluation of arithmetic expressions. Results have shown that on the former task both models can learn to generalize and on the latter task only the stack-augmented model can do so. We show that different strategies are learned by the models, in which  specific categories of input are monitored and different policies are made based on that to change the memory.   % To the best of our knowledge, this is the first time that hypothesis-verification pipelines about what strategy is induced are carried out for memory augmented neural networks. 
 There has been an increased interest in multimodal language processing including multimodal dialog, question answering, sentiment analysis, and speech recognition. However, naturally occurring multimodal data is often imperfect as a result of imperfect modalities, missing entries or noise corruption. To address these concerns, we present a regularization method based on tensor rank minimization. Our method is based on the observation that high-dimensional multimodal time series data often exhibit correlations across time and modalities which leads to low-rank tensor representations. However, the presence of noise or incomplete values breaks these correlations and results in tensor representations of higher rank. We design a model to learn such tensor representations and effectively regularize their rank. Experiments on multimodal language data show that our model achieves good results across various levels of imperfection. 
 Service robots are envisioned to undertake a wide range of tasks at the request of users.  Semantic parsing is one way to convert natural language commands given to these robots into executable representations. Methods for creating semantic parsers, however, rely either on large amounts of data or on engineered lexical features and parsing rules, which has limited their application in robotics. To address this challenge, we propose an approach that leverages neural semantic parsing methods in combination with contextual word embeddings to enable the training of a semantic parser with little data and without domain specific parser engineering.  Key to our approach is the use of an anonymized target representation which is more easily learned by the parser. In most cases, this simplified representation can trivially be transformed into an executable format, and in others the parse can be completed through further interaction with the user. We evaluate this approach in the context of the RoboCup@Home  task, where we have collected a corpus of paraphrased versions of commands from the standardized command generator. Our results show that neural semantic parsers can predict the logical form of unseen commands with 89\% accuracy. We release our data and the details of our models to encourage further development from the RoboCup and service robotics communities.   
  Search is a prominent channel for discovering products on an e-commerce platform. Ranking products retrieved from search becomes crucial to address customer's need and optimize for business metrics. While learning to Rank  models have been extensively studied and have demonstrated efficacy in the context of web search; it is a relatively new research area to be explored in the e-commerce.  In this paper, we present a framework for building LETOR model for an e-commerce platform. We analyze user queries and propose a mechanism to segment queries between broad and narrow based on user's intent. We discuss different types of features - query, product and query-product and discuss challenges in using them. We show that sparsity in product features can be tackled through a denoising auto-encoder while skip-gram based word embeddings help solve the query-product sparsity issues. We also present various target metrics that can be employed for evaluating search results and compare their robustness.   Further, we build and compare performances of both pointwise and pairwise LETOR models on fashion category data set. We also build and compare distinct models for broad and narrow queries, analyze feature importance across these and show that these specialized models perform better than a combined model in the fashion world.    %We analyze user queries  and show  for unnamed products typically present in fashion category and show that.We build and compare performances of both pointwise and pairwise LETOR models on fashion category data set,  We also explore several target metrics relevant for e-commerce. Further, we segment queries between broad and narrow based on user's intent and highlight differences by building distinct LETOR models for them.   %We discuss various challenges involved in building search ranking for e-commerce ranging from feature representation, relevance scores and applying pointwise and pairwise models.    %Our work attempts to apply LETOR in e-commerce and discuss the various challenges involved ranging from feature representation, relevance scores and applying pointwise and pairwise models; and highlight significant differences between broad and narrow queries. We propose different types of features  and demonstrate the relative importance of each in broad and narrow queries.   %As a leading fashion e-tailer, it is imperative to rank search results to cater to both the customers' needs and optimize for business metrics. Although Learning to Rank  has demonstrated the efficacy in the context of web search; it is a relatively new research area to be explored in the e-commerce. The primary difference between the web search and e-commerce search lies in the interplay of relevance and popularity features. While web search queries would often be concrete and have relevance play the most important role in ranking, e-commerce queries like "tshirts" can yield a recall set of thousands of products which make it indispensable to incorporate popularity features. Typical human relevance judgments would not suffice as in web search. We have segmented all our queries into broad and narrow basis the coherency of results.  Our work attempts to apply LETOR in e-commerce and discuss the various challenges involved ranging from feature representation, relevance scores and applying pointwise and pairwise models; and highlight significant differences between broad and narrow queries. We propose different types of features  and demonstrate the relative importance of each in broad and narrow queries. The sparsity in product features have been tackled through a denoising autoencoder while skip-gram based word embeddings help solve the query-product sparsity issues. We study the robustness of different business metrics   as relevance scores. All our experiments are performed on the fashion industry dataset and showcase significant NDCG improvements over a traditional popularity based search ranking    % In this paper, we are presenting the application of LTR in Fashion E-commerce Domain and highlight the major aspects which differentiate fashion from a usual ecommerce platform. Firstly, nature of the queries being broad and less informative, most of the traffic constitutes of high recall queries like t-shirts, shirts and tops. Second, the physical attributes of products in fashion are relatively less informative which makes it difficult for user to specify attributes in the query. For that purpose, we have classified the queries into two categories 閳 broad and narrow based on their recall set size and analysed the major difference from modelling perspective. We identified the popularity features are very useful in broad queries and but not so relevant in case of narrow queries. Deploying different models for broad and narrow queries resulted in improved metrics. We experimented with various targets such as click rate, add-to-cart ratios, order rates and reported the findings. We have experimented with both point wise models 閳ユ悜andom forest, gradient boosting trees and pairwise models 閳 ranknet and lambdamart  
 A character network is a graph extracted from a narrative, in which vertices represent characters and edges correspond to interactions between them. A number of narrative-related problems can be addressed automatically through the analysis of character networks, such as summarization, classification, or role detection. Character networks are particularly relevant when considering works of fictions , as their exploitation allows developing information retrieval and recommendation systems. However, works of fiction possess specific properties making these tasks harder.  This survey aims at presenting and organizing the scientific literature related to the extraction of character networks from works of fiction, as well as their analysis. We first describe the extraction process in a generic way, and explain how its constituting steps are implemented in practice, depending on the medium of the narrative, the goal of the network analysis, and other factors. We then review the descriptive tools used to characterize character networks, with a focus on the way they are interpreted in this context. We illustrate the relevance of character networks by also providing a review of applications derived from their analysis. Finally, we identify the limitations of the existing approaches, and the most promising perspectives. 
 Knowledge bases store information about the semantic types of entities, which can be utilized in a range of information access tasks.  This information, however, is often incomplete, due to new entities emerging on a daily basis.  We address the task of automatically assigning types to entities in a knowledge base from a type taxonomy.   Specifically, we present two neural network architectures, which take short entity descriptions and, optionally, information about related entities as input.   Using the DBpedia knowledge base for experimental evaluation, we demonstrate that these simple architectures yield significant improvements over the current state of the art.    
 % %Video Question Answering  is a critical and challenging task in multimedia comprehension. While deep learning based models are extremely capable of representing and understanding videos, these models heavily rely on massive data, which is expensive to label.  % %In this paper,  We introduce a novel task, Video Question Generation . A Video QG model automatically generates questions given a video clip and its corresponding dialogues. Video QG requires a range of skills -- sentence comprehension, temporal relation, the interplay between vision and language, and the ability to ask meaningful questions. To address this, we propose a novel semantic rich cross-modal self-attention  network to aggregate the multi-modal and diverse features. To be more precise, we enhance the video frames semantic by integrating the object-level information, and we jointly consider the cross-modal attention for the video question generation task. Excitingly, our proposed model remarkably improves the baseline from 7.58 to 14.48 in the BLEU-4 score on the TVQA dataset. Most of all, we arguably pave a novel path toward understanding the challenging video input and we provide detailed analysis in terms of diversity, which ushers the avenues for future investigations. 
  % bridge the gap between  % aiming to find a balance between the  % to bridge the gap between the neural and symbolic AI methodologies methodologies % seeking to bridge the gap between neural and symbolic AI approaches   methodologies % methodologies of AI  approaches  We introduce the Neural State Machine, seeking to bridge the gap between the neural and symbolic views of AI and integrate their complementary strengths for the task of visual reasoning. Given an image, we first predict a probabilistic graph that represents its underlying semantics and serves as a structured world model. Then, we perform sequential reasoning over the graph, iteratively traversing its nodes to answer a given question or draw a new inference. In contrast to most neural architectures that are designed to closely interact with the raw sensory data, our model operates instead in an abstract latent space, by transforming both the visual and linguistic modalities into semantic concept-based representations, thereby achieving enhanced transparency and modularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets that involve compositionality, multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. We provide further experiments that illustrate the model's strong generalization capacity across multiple dimensions, including novel compositions of concepts, changes in the answer distribution, and unseen linguistic structures, demonstrating the qualities and efficacy of our approach.  % 	Since its inception, AI has witnessed a long-lasting debate between the symbolic and connectionist approaches. While the former advocates structure, transparency, and compositionality, the latter offers robustness, scalability and versatility. % seeking to bridge the gap between symbolic and neural perspectives/paradigms % We introduce the Neural State Machine, seeking to  % find a balance between the nerual and symbolic paradigms of AI and join together % bring together the neural and symbolic views to AI and integrate their complementary strengths. % seeking to bring the two competing  % seeking to  % find the balance between the long- neural and symbolic approaches   % find a balance between the neural and symbolic  % bridge the graph between symbolic and neural   % balance the advantages of neural and symbolic approaches to AI and integrate  We explore this model in the context of visual reasoning:      %%%%%% compositional world model %%%%% with raw sensory  % Since its inception, AI has witnessed a long-lasting debate between the symbolic and connectionist approaches. While the former advocates structure, transparency, and compositionality, the latter offers robustness, scalability and versatility. We introduce the Neural State Machine, seeking to balance these views and integrate their complementary strengths, and exploring it in the context of visual reasoning. Given an image, we first construct a probabilistic graph that represents its underlying semantic knowledge, serving as a mental world model. Then, we perform iterative reasoning over the graph, traversing across its nodes, in order to answer a given question or draw a new inference. In contrast to the common tendency of neural networks to closely interact with the raw sensory data, our model operates instead in an abstract space, by elevating both the visual and linguistic modalities into semantic concept-based representations, thereby achieving modularity and interpretability. We evaluate our model using two recent VQA datasets that involve compositionality, multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. We further provide experiments that illustrate the model's strong generalization capacity across several dimensions, including novel compositions of concepts, changes in the answer distribution, and unseen question types, demonstrating the qualities and efficacy of our approach.  % high-level semantic concepts?? % predict/construct % traversing across ??? % We test our model over % in a differentiable manner  % long-lasting / decades-long % predict / construct % represent / distill / capture % including generalizing to   % dominant, differentiable % test/evaluate % involve/demand % generalization capacity/skills % efficacy/efficency % Unlike the common tendency  % are linked to concepts % converting % dominant % integreate, leverage, unify, synergize, utilize, unite, join % opposite % predicts / constructs / creates  % versatility, interpretability flexibility % as opposed to, in contrast, unlike % paradigms % demonstrating the value  %%%%%%%  % The model operates in two phases, learning and inference: first,  % disentangle structure from content / syntax from semantics  % world model in the form of a graph that captures its  % modularity, generalization and interpretability % tendency of deep learning % closely or directly % integrate / leverage / synergize / combine % shifting our attention across nodes, % distill / extract / capture % the same set of concepts, a joint set % modularity generalization and interpretability.  %%%%%%%  % Motivated to find middle ground / in this paper benefit from  % leverage their qualities % completemtary advatges, qualities benefit leverage   %%%%%%%  % Motivated % Seeking to balance between these views and integrate their complementary strengths, we introduce the  % opposite views/approaches of ...  % aiming to answer  % inferences about it  % Rather then interacting with raw sensory data as is common for deep learning, our model operates instead in an abstract space, elevating both visual and linguistic modalities into a concept-based semantic representations,  % More importantly, we perform experiments to  % We perform detailed experiments  % We demonstrate the efficacy of our model over two  More importantly,  % Rather then interacting with raw sensory data as is common for deep learning,  % The has been an everlasting debate between the the symbolic and connectionist views of AI. The has been    % Since its inception, AI has witnessed an everlasting debate between the the symbolic and connectionist approaches. While the former advocates for structure, transparency, and compositionality, the latter offers robustness, scalability and versatility. We introduce the Neural State Machine, seeking to balance these views and integrate their complementary strengths, and explore it in the context of visual reasoning. Given an image, we first predict a probabilistic graph that represents its semantic knowledge and serves as a world model, and then perform iterative reasoning over the graph in order to answer a given question or draw a new inference. In contrast to the common tendency of neural networks to closely interact with raw sensory data, our model operates instead in an abstract space, by elevating both visual and linguistic modalities into semantic concept-based representations, thereby achieving modularity and interpretability. We test our model over recent VQA datasets that involve multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. In further experiments, we show the model's strong generalization capacity across several dimensions, including unseen words, alterations of the answer distribution, and novel question types, demonstrating the qualities and efficiency of our approach. % demand for skills % value and efficacy  % show how the neurla state machine / model can generalize across several dimensions, answering / learning to answer / deal with new combinations of words, differences/alterations in the answer distribution, and questions of new types/ new types of questions, demonstrating the value and efficiency of our approach.  % demand for diverse % test for for % value  % We demonstrate the model's strength, robustness and interpretability on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-art 98.9\% accuracy, halving the error rate of the previous best model. More importantly, we show that the model is computationally-efficient and data-efficient, in particular requiring 5x less data than existing models to achieve strong results.   % by traversing the  % We demonstrate the strengths of our model by 閳 over recents real-world visual question answering datasets, that in particular test for compositionality / questions multi-step inference and divese/various reasoning skills. , further experiments show how the neurla state machine / model can generalize across several dimensions, answering / learning to answer / deal with new combinations of words, differences/alterations in the answer distribution, and questions of new types/ new types of questions, demonstrating the value and efficiency of our approach.   % Since its inception, Artificial Intelligence has witnessed an everlasting debate between the the symbolic and connectionist approaches. While the former advocates for structure, transparency, and compositionality, the latter offers robustness, scalability and versatility. Motivated to balance these opposing views and integrate their complementary strengths, we introduce the Neural State Machine, a differentiable model that simulates the operation of an automaton, and explore it in the context of visual reasoning.  % Unlike the common tendency of neural networks to closely interact with the raw sensory data, our model operates instead in an abstract space, elevating both visual and linguistic modalities to be represented through a set of semantic concepts, thereby achieving better modularity, generalization and interpretability. We demonstrate the strengths of our model by 閳 over recents real-world visual question answering datasets, that in particular test for compositionality / questions multi-step inference and divese/various reasoning skills. , further experiments show how the neurla state machine / model can generalize across several dimensions, answering / learning to answer / deal with new combinations of words, differences/alterations in the answer distribution, and questions of new types/ new types of questions, demonstrating the value and efficiency of our approach.   % Since its inception, Artificial Intelligence has witnessed an everlasting debate between the the symbolic and connectionist approaches. While the former advocates for structure, transparency, and compositionality, the latter offers robustness, scalability and versatility. Motivated to balance these opposing views and integrate their complementary strengths, we introduce the Neural State Machine, a differentiable model that simulates the operation of an automaton, and explore it in the context of visual reasoning. Given an image, we first predict a probablistic graph that represents its underlying semantic knowledge and serves as a world model. Then, we perform iterative reasoning over the graph by a soft traversal across its nodes, seeking to answer a given question or draw a new inference. In contrast to the common tendency of neural networks to closely interact with the raw sensory data, our model operates instead in an abstract  space, elevating both visual and linguistic modalities to be represented through semantic concepts, thereby achieving better modularity, generalization and interpretability.  % elevating both the image and the question into embedded representations that are based on semantic concepts, thereby achieving    % , our model operates instead in an abstract semantic space, by elevating both visual and linguistic modalities to be represented over same set of concepts, thereby speaking the same language, minimizing/avoid chance potential for of learning statiscal / spurios associations . We demonstrate the strengths of our model by 閳 over recents real-world visual question answering datasets, that in particular test for compositionality / questions multi-step inference and divese/various reasoning skills. , further experiments show how the neurla state machine / model can generalize across several dimensions, answering / learning to answer / deal with new combinations of words, differences/alterations in the answer distribution, and questions of new types/ new types of questions, demonstrating the value and efficiency of our approach.  % Add: both. Disengetable structure from content, and achieves both compositionality, And abstraction, Demand, Common dominant, differentiable, complementary strengths.  % elevates both the image and question into semantic representations,   % common practice of neural networks % Diverging from the dominant tendency % Diverging from the dominant tendency  % In contrast to the common para  % common practice  % There has been a long debate between the alternative/opposing views/paradigms of connectionist and symbolic ai. The former advocated for 閳 and achieves scalability, robustness and flexibility, where the latter 閳 and offers modularity, 閳, transparency, and interpretability. Motivated to find middle ground / in this paper, we introduce the neural state machine, seeking to balance between these two views.. A neural symbolic that learns a .. and simulate e Motivated to find閳 and explore it in the context of visual reasoning. Given an image, our model / we first infer a structured probablistic graph represnts/ distils / capture the semantic knowledge of the image. Then we iteratively reason over the graph by traversing fromne node to another, / shifting our attention from閳 in order to answer a given question or make  new inference/s. , our model operates instead in an abstract semantic space, by  elevating both visual and linguistic modalities to be represented over same set of concepts, thereby speaking the same language, minimizing/avoid chance potential for of learning statiscal / spurios associations . We demonstrate the strengths of our model by 閳 over recents real-world visual question answering datasets, that in particular test for compositionality / questions multi-step inference and divese/various reasoning skills. , further experiments show how the neurla state machine / model can generalize across several dimensions, answering / learning to answer / deal with new combinations of words, differences/alterations in the answer distribution, and questions of new types/ new types of questions, demonstrating the value and efficiency of our approach.  % Add: both. Disengetable structure from content, and achieves both compositionality, And abstraction, Demand, Common dominant, differentiable, complementary strengths.  % probablistic graph that dthe semantic knowledge   % world model   % probablistic world model   % structured probablistic graph represnts/ distils / capture the semantic knowledge  % In this paper, we introduce the Neural State Machine, seeking to balance these opposing views and integrate their complementary strengths.  Our model operates in two stages: learning and inference.   % In this paper, we introduce the Neural State Machine, seeking to balance these opposing views and integrate their complementary strengths. We between between  % We explore the model in the context % The model operates in two phases: learning and inference. First, it predicts a graph-based world model   % Since its inception, AI has witnessed a decades-long debate between the symbolic and connectionist approaches. While the former advocates for structure, transparency, and compositionality, the latter offers robustness, scalability and versatility. We introduce the Neural State Machine, seeking to balance these views and integrate their complementary strengths, while exploring it in the context of visual reasoning. Given an image, we first predict a probabilistic graph that represents its underlying semantic knowledge and serves as a world model. Then, we perform iterative reasoning over the graph, traversing across its nodes, in order to answer a given question or draw a new inference. In contrast to the common tendency of neural networks to closely interact with the raw sensory data, our model operates instead in an abstract space, by elevating both the visual and linguistic modalities into semantic concept-based representations, thereby achieving modularity and interpretability. We test our model over two recent VQA datasets that involve multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. In further experiments, we show the model's strong generalization capacity across several dimensions, including unseen words, alterations of the answer distribution, and novel question types, demonstrating the qualities and efficacy of our approach.  % We build the model to be differentaible on the one hand  % seeking to balance between these views, we propose the nsm, and explore it in the context of visual reasoing  % complementary benefits. Demonstrating the value and efficiency/efficacy of our approach. More importantly, generalization across several different dimensions: to new combination of words, difference in the answer distribution, and new typ[es of questions. Compositional questions that demand multi-step inference and variety of reasoning skills. % Seek to find a middle ground between these two extremes. We introduce/propose the neural state machine    % advocates for  % the latter enjoys  % offers  % declerateive % between the connectionist and the symbolic views/approaches.  % Since the inception of artificial intelligence, there has been a decades-long debate between the connectionist and symbolic approaches.  % opposing views of connectionism and symbolism. % While the former advocates for   % symbolic approaches.  % opposite approaches of   % There has always been a debate      % There has been a decade-long debate   % since the inception of artificial intelligence % The field of artificial in   % We introduce GQA, a new dataset for real-world visual reasoning and compositional question answering, seeking to address key shortcomings of previous VQA datasets. We have developed a strong and robust question engine that leverages scene graph structures to create 22M diverse reasoning questions, all come with functional programs that represent their semantics. We use the programs to gain tight control over the answer distribution and present a new tunable smoothing technique to mitigate language biases. Accompanying the dataset is a suite of new metrics that evaluate essential qualities such as consistency, grounding and plausibility. An extensive analysis is performed for baselines as well as state-of-the-art models, providing fine-grained results for different question types and topologies. Whereas a blind LSTM obtains mere 42.1\%, and strong VQA models achieve 54.1\%, human performance tops at 89.3\%, offering ample opportunity for new research to explore. We strongly hope GQA will provide an enabling resource for the next generation of models with enhanced robustness, improved consistency, and deeper semantic understanding for images and language.  %We present the MAC network, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning. MAC moves away from monolithic black-box neural architectures towards a design that encourages both transparency and versatility. The model approaches problems by decomposing them into a series of attention-based reasoning steps, each performed by a novel recurrent Memory, Attention, and Composition  cell that maintains a separation between control and memory. By stringing the cells together and imposing structural constraints that regulate their interaction, MAC effectively learns to perform iterative reasoning processes that are directly inferred from the data in an end-to-end approach. We demonstrate the model's strength, robustness and interpretability on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-art 98.9\% accuracy, halving the error rate of the previous best model. More importantly, we show that the model is computationally-efficient and data-efficient, in particular requiring 5x less data than existing models to achieve strong results.   % We introduce GQA, a new dataset for real-world visual reasoning and compositional question answering, seeking to address key shortcomings of previous VQA datasets. We have developed a strong and robust question engine that leverages scene graph structures to create 22M diverse reasoning questions, all come with functional programs that represent their semantics. We use the programs to gain tight control over the answer distribution and present a new tunable smoothing technique to mitigate language biases. Accompanying the dataset is a suite of new metrics that evaluate essential qualities such as consistency, grounding and plausibility. An extensive analysis is performed for baselines as well as state-of-the-art models, providing fine-grained results for different question types and topologies. Whereas a blind LSTM obtains mere 42.1\%, and strong VQA models achieve 54.1\%, human performance tops at 89.3\%, offering ample opportunity for new research to explore. We strongly hope GQA will provide an enabling resource for the next generation of models with enhanced robustness, improved consistency, and deeper semantic understanding for images and language.  % thorough and coherent understanding of images and We believe GQA will provide an important enabling resource for a next generation of models with enhanced robustness, improved consistency and deeper semantic understanding for images and language. language. GQA We complement explored representations We perform  important % fine-grained diagnosis for different question types % an extensive probabilistic grammar based on  % Despite significant attention to this task in recent years, there is a widespread feeling that current benchmarks fail to provide accurate indication of visual understanding capacity.  % have suffered from to measure the models'  %  Scene understanding remains a key challenge in computer vision. Visual question answering  is not only an effective way to measure it but an intriguing multimodal inference problem in its own right. Despite significant attention to this task in recent years, there is a widespread feeling that current benchmarks fail to provide accurate indication of visual understanding capacity. Not only are they severely biased, they also lack semantic compositionality, and do not provide any tools or measures to gain significant insight into models' performance and behavior.  %  We design a new dataset, GQA, to address these shortcomings, featuring compositional questions over real-world images. We leverage scene graph representations and questions underlying semantics to mitigate language priors and conditional biases, allow for fine-grained diagnosis for different question types, and introduce new evaluation metrics to measure the consistency and coherence of systems. A highly developed and refined natural language generation system produces a balanced dataset of 1.5M diverse and well-formed questions over the 108k images.    %  We present results of baselines, state-of-the-art models, and humans on the dataset: Whereas a blind LSTM gets mere 42.0\%, and strong VQA models achieve 53.8\%, human performance tops at 89.3\%. We believe GQA will provide an important enabling resource for a next generation of VQA systems with thorough and coherent understanding of images and language.  
 Online social media platforms have made the world more connected than ever before, thereby making it easier for everyone to spread their content across a wide variety of audiences. Twitter is one such popular platform where people publish tweets to spread their messages to everyone. Twitter allows users to Retweet other users' tweets in order to broadcast it to their network. The more retweets a particular tweet gets, the faster it spreads. This creates incentives for people to obtain artificial growth in the reach of their tweets by using certain blackmarket services to gain inorganic appraisals for their content.  In this paper, we attempt to detect such tweets that have been posted on these blackmarket services in order to gain artificially boosted retweets. We use a multitask learning framework to leverage soft parameter sharing between a classification and a regression based task on separate inputs. This allows us to effectively detect tweets that have been posted to these blackmarket services, achieving an F1-score of 0.89 when classifying tweets as blackmarket or genuine.  
 		Brain-Computer Interfaces  help patients with faltering communication abilities due to neurodegenerative diseases produce text or speech output by direct neural processing. However, practical implementation of such a system has proven difficult due to limitations in speed, accuracy, and generalizability of the existing interfaces. To this end, we aim to create a BCI system that decodes text directly from neural signals. We implement a framework that initially isolates frequency bands in the input signal encapsulating differential information regarding production of various phonemic classes. These bands then form a feature set that feeds into an LSTM which discerns at each time point probability distributions across all phonemes uttered by a subject. Finally, these probabilities are fed into a particle filtering algorithm which incorporates prior knowledge of the English language to output text corresponding to the decoded word. Performance of this model on data obtained from six patients shows encouragingly high levels of accuracy at speeds and bit rates significantly higher than existing BCI communication systems. Further, in producing an output, our network abstains from constraining the reconstructed word to be from a given bag-of-words, unlike previous studies. The success of our proposed approach, offers promise for the employment of a BCI interface by patients in unfettered, naturalistic environments. 	
 An integrated approach is proposed across visual and textual data to both determine and justify a medical diagnosis by a neural network. As deep learning techniques improve, interest grows to apply them in medical applications. To enable a transition to workflows in a medical context that are aided by machine learning, the need exists for such algorithms to help justify the obtained outcome so human clinicians can judge their validity. In this work, deep learning methods are used to map a frontal X-Ray image to a continuous textual representation. This textual representation is decoded into a diagnosis and the associated textual justification that will help a clinician evaluate the outcome. Additionally, more explanatory data is provided for the diagnosis by generating a realistic X-Ray that belongs to the nearest alternative diagnosis. With a clinical expert opinion study on a subset of the X-Ray data set from the Indiana University hospital network, we demonstrate that our justification mechanism significantly outperforms existing methods that use saliency maps. While performing multi-task training with multiple loss functions, our method achieves excellent diagnosis accuracy and captioning quality when compared to current state-of-the-art single-task methods.  
 {Deep learning had been used in program analysis for the prediction of hidden software defects using software defect datasets, security vulnerabilities using generative adversarial networks as well as identifying syntax errors by learning a trained neural machine translation on program codes. However, all these approaches either require defect datasets or bug-free source codes that are executable for training the deep learning model. Our neural network model is neither trained with any defect datasets nor bug-free programming source codes, instead it is trained using structural semantic details of Abstract Syntax Tree  where each node represents a construct appearing in the source code. This model is implemented to fix one of the most common semantic errors, such as undeclared variable errors as well as infer their type information before program compilation. By this approach, the model has achieved in correctly locating and identifying 81$\%$ of the programs on prutor dataset of 1059 programs with only undeclared variable errors and also inferring their types correctly in 80$\%$ of the programs.} 
 We present MedCATTrainer\footnote{https://www.youtube.com/watch?v=lM914DQjvSo} an interface for building, improving and customising a given Named Entity Recognition and Linking  model for biomedical domain text. NER+L is often used as a first step in deriving value from clinical text. Collecting labelled data for training models is difficult due to the need for specialist domain knowledge. MedCATTrainer offers an interactive web-interface to inspect and improve recognised entities from an underlying NER+L model via active learning. Secondary use of data for clinical research often has task and context specific criteria. MedCATTrainer provides a further interface to define and collect supervised learning training data for researcher specific use cases. Initial results suggest our approach allows for efficient and accurate collection of research use case specific training data. 
  We present SentiMATE, a novel end-to-end Deep Learning model for Chess, employing Natural Language Processing that aims to learn an effective evaluation function assessing move quality. This function is pre-trained on the sentiment of commentary associated with the training moves, and is used to guide and optimize the agent's game-playing decision making. The contributions of this research are three-fold: we build and put forward both a classifier which extracts commentary describing the quality of Chess moves in vast commentary datasets, and a Sentiment Analysis model trained on Chess commentary to accurately predict the quality of said moves, to then use those predictions to evaluate the optimal next move of a Chess agent. Both classifiers achieve over 90\% classification accuracy. Lastly, we present a Chess engine, SentiMATE, which evaluates Chess moves based on a pre-trained sentiment evaluation function. Our results exhibit strong evidence to support our initial hypothesis -  ``Can Natural Language Processing be used to train a novel and sample efficient evaluation function in Chess Engines?'' - as we integrate our evaluation function into modern Chess engines and play against agents with traditional Chess move evaluation functions, beating both random agents and a DeepChess implementation at a level-one search depth - representing the number of moves a traditional Chess agent  looks ahead in order to evaluate a given chess state.  
 This paper learns multi-modal embeddings from text, audio, and video views/modes of data in order to improve upon downstream sentiment classification. The experimental framework also allows investigation of the relative contributions of the individual views in the final multi-modal embedding. Individual features derived from the three views are combined into a multi-modal embedding using Deep Canonical Correlation Analysis  in two ways i) One-Step DCCA and ii) Two-Step DCCA. This paper learns text embeddings using BERT, the current state-of-the-art in text encoders. We posit that this highly optimized algorithm dominates over the contribution of other views, though each view does contribute to the final result. Classification tasks are carried out on two benchmark data sets and on a new Debate Emotion data set, and together these demonstrate that the one-Step DCCA outperforms the current state-of-the-art in learning multi-modal embeddings.  % This paper presents two techniques to obtain multi-modal embeddings from text, audio and video views/modes for sentiment analysis. Multi-modal embeddings are obtained using Deep Canonical Correlation Analysis  in a One-Step and Two-Step configuration. The learned multi-modal embeddings are then used in downstream sentiment classification tasks on standard benchmark data sets as well as on a new Debate Emotion data set. Empirical results show that the proposed One-Step and Two-Step DCCA approaches learn the most effective multi-modal embeddings from input data. 
   String similarity models are vital for record linkage, entity resolution, and   search. In this work, we present \alg--a  model for   computing the similarity of two strings. Our approach encodes the   characters of each string, aligns the encodings using Sinkhorn   Iteration    and scores the alignment with a convolutional neural network. We   evaluate \alg's ability to detect whether two strings    refer to the same entity--a task we term . We   construct five new alias detection datasets .    We show that \alg  outperforms both state-of-the-art and   classic, parameter-free similarity models on four of the five   datasets.    We also demonstrate \alg's ability to improve downstream   tasks by applying it to an instance of cross-document coreference   and show that it leads to a 2.8 point improvement in $B^3$ F1 over   the previous state-of-the-art approach. 
Automation of tasks can have critical consequences when humans lose agency over decision processes. Deep learning models are particularly susceptible since current black-box approaches lack explainable reasoning. We argue that both the visual interface and model structure of deep learning systems need to take into account interaction design. We propose a framework of collaborative semantic inference  for the co-design of interactions and models to enable visual collaboration between humans and algorithms. The approach exposes the intermediate reasoning process of models which allows semantic interactions with the visual metaphors of a problem, which means that a user can both understand and control parts of the model reasoning process. We demonstrate the feasibility of CSI with a co-designed case study of a document summarization system. %The study demonstrates how humans can retain agency without losing the benefits of using deep learning systems.  
  We present a neural text-to-speech system for fine-grained prosody transfer from one speaker to another. Conventional approaches for end-to-end prosody transfer typically use either fixed-dimensional or variable-length prosody embedding via a secondary attention to encode the reference signal. However, when trained on a single-speaker dataset, the conventional prosody transfer systems are not robust enough to speaker variability, especially in the case of a reference signal coming from an unseen speaker. Therefore, we propose decoupling of the reference signal alignment from the overall system. For this purpose, we pre-compute phoneme-level time stamps and use them to aggregate prosodic features per phoneme, injecting them into a sequence-to-sequence text-to-speech system. We incorporate a variational auto-encoder to further enhance the latent representation of prosody embeddings. We show that our proposed approach is significantly more stable and achieves reliable prosody transplantation from an unseen speaker. We also propose a solution to the use case in which the transcription of the reference signal is absent. We evaluate all our proposed methods using both objective and subjective listening tests.  
 In this project, we aim to build a Text-to-Speech system able to produce speech with a controllable emotional expressiveness. We propose a methodology for solving this problem in three main steps. The first is the collection of emotional speech data. We discuss the various formats of existing datasets and their usability in speech generation. The second step is the development of a system to automatically annotate data with emotion/expressiveness features. We compare several techniques using transfer learning to extract such a representation through other tasks and propose a method to visualize and interpret the correlation between vocal and emotional features. The third step is the development of a deep learning-based system taking text and emotion/expressiveness as input and producing speech as output. We study the impact of fine tuning from a neutral TTS towards an emotional TTS in terms of intelligibility and perception of the emotion.    %%%%%%% % Then summarize contributions  
 We present a novel deep learning model for the detection and reconstruction of dysarthric speech. We train the model with a multi-task learning technique to jointly solve dysarthria detection and speech reconstruction tasks. The model key feature is a low-dimensional latent space that is meant to encode the properties of dysarthric speech. It is commonly believed that neural networks are 閳ユ競lack boxes閳 that solve problems but do not provide interpretable outputs. On the contrary, we show that this latent space successfully encodes interpretable characteristics of dysarthria, is effective at detecting dysarthria, and that manipulation of the latent space allows the model to reconstruct healthy speech from dysarthric speech. This work can help patients and speech pathologists to improve their understanding of the condition, lead to more accurate diagnoses and aid in reconstructing healthy speech for afflicted patients. 
 In automatic speech recognition , wideband  and narrowband  speech signals with different sampling rates typically use separate acoustic models. Therefore mixed-bandwidth  acoustic modeling has important practical values for ASR system deployment.  In this paper, we extensively investigate large-scale MB deep neural network acoustic modeling for ASR using 1,150 hours of WB data and 2,300 hours of NB data. We study various MB strategies including downsampling, upsampling and bandwidth extension for MB acoustic modeling and evaluate their performance on 8 diverse WB and NB test sets from various application domains. To deal with the large amounts of training data, distributed training is carried out on multiple GPUs using synchronous data parallelism. 
 	Integrating an external language model into a sequence-to-sequence speech recognition system is non-trivial. Previous works utilize linear interpolation or a fusion network to integrate external language models. However, these approaches introduce external components, and increase decoding computation. In this paper, we instead propose a knowledge distillation based training approach to integrating external language models into a sequence-to-sequence model. A recurrent neural network language model, which is trained on large scale external text, generates soft labels to guide the sequence-to-sequence model training. Thus, the language model plays the role of the teacher. This approach does not add any external component to the sequence-to-sequence model during testing. And this approach is flexible to be combined with shallow fusion technique together for decoding. The experiments are conducted on public Chinese datasets AISHELL-1 and CLMAD. Our approach achieves a character error rate of $9.3\%$, which is relatively reduced by $18.42\%$ compared with the vanilla sequence-to-sequence model. 
 We introduce Multi-Frame Cross-Entropy training  for convolutional neural network acoustic models. Recognizing that similar to RNNs, CNNs are in nature sequence models that take variable length inputs, we propose to take as input to the CNN a part of an utterance long enough that multiple labels are predicted at once, therefore getting cross-entropy loss signal from multiple adjacent frames. This increases the amount of label information drastically for small marginal computational cost. We show large WER improvements on hub5 and rt02 after training on the 2000-hour Switchboard benchmark. 
  Conversational machine comprehension  has proven significantly more challenging compared to traditional MC since it requires better utilization of conversation history. However, most existing approaches do not effectively capture conversation history and thus have trouble handling questions involving coreference or ellipsis. Moreover, when reasoning over passage text, most of them simply treat it as a word sequence without exploring rich semantic relationships among words. In this paper, we first propose a simple yet effective graph structure learning technique to dynamically construct a question and conversation history aware context graph at each conversation turn. Then we propose a novel Recurrent Graph Neural Network, and based on that, we introduce a flow mechanism to model the temporal dependencies in a sequence of context graphs. The proposed GraphFlow model can effectively capture conversational flow in a dialog, and shows competitive performance compared to existing state-of-the-art methods on CoQA, QuAC and DoQA benchmarks. In addition, visualization experiments show that our proposed model can offer good interpretability for the reasoning process.    % Conversational machine comprehension  has proven significantly more challenging compared to traditional MC since it requires better utilization of conversation history. However, most existing approaches do not effectively capture conversation history and thus have trouble handling questions involving coreference or ellipsis. % In this paper, we propose a novel graph neural network  based model, namely GraphFlow, which can effectively capture conversational flow in a dialog. % Specifically, we first propose a new approach to dynamically construct a question-aware context graph from passage text at each turn. We then present a novel flow mechanism to model the temporal dependencies in the sequence of context graphs. % The proposed GraphFlow model shows competitive performance compared to existing state-of-the-art methods. % % For instance, GraphFlow outperforms two recently proposed models on the CoQA benchmark dataset: FlowQA by 2.3\% and SDNet by 0.7\% on F1 score, respectively. % In addition, visualization experiments show that our proposed model can better mimic the human reasoning process for conversational MC compared to existing models.  
 This paper describes the system submitted to "Sentiment Analysis at SEPLN -2019" shared task. The task includes sentiment analysis of Spanish tweets, where the tweets are in different dialects spoken in Spain, Peru, Costa Rica, Uruguay and Mexico. The tweets are short  and the language is informal, i.e., it contains misspellings, emojis, onomatopeias etc. Sentiment analysis includes classification of the tweets into 4 classes, viz., Positive, Negative, Neutral and None. For preparing the proposed system, we use Deep Learning networks like LSTMs.   % \PACS{PACS code1 \and PACS code2 \and more} %  
   In the current work, we present a description of the system submitted to WMT 2018 News Translation Shared task. The system was created to translate news text from Finnish to English. The system used a Character Based Neural Machine Translation model to accomplish the given task. The current paper documents the preprocessing steps, the description of the submitted system and the results produced using the same. Our system garnered a BLEU score of 12.9. 
 Although the problem of similar language translation has been an area of research interest for many years, yet it is still far from being solved. In this paper, we study the performance of two popular approaches: statistical and neural. We conclude that both methods yield similar results; however, the performance varies depending on the language pair. While the statistical approach outperforms the neural one by a difference of 6 BLEU points for the Spanish-Portuguese language pair, the proposed neural model surpasses the statistical one by a difference of 2 BLEU points for Czech-Polish. In the former case, the language similarity  is much higher than in the latter case. Additionally, we report negative results for the system combination with back-translation.  Our TALP-UPC system submission won 1st place for Czech$\rightarrow$Polish and 2nd place for Spanish$\rightarrow$Portuguese in the official evaluation of the 1st WMT Similar Language Translation task. 
 	 Open relation extraction  remains a challenge to obtain a semantic representation by discovering arbitrary relation tuples from the unstructured text. Conventional methods heavily depend on feature engineering or syntactic parsing, they are inefficient or error-cascading. Recently, leveraging supervised deep learning structures to address the ORE task is an extraordinarily promising way. However, there are two main challenges:  The lack of enough labeled corpus to support supervised training;  The exploration of specific neural architecture that adapts to the characteristics of open relation extracting. In this paper, to overcome these difficulties, we build a large-scale, high-quality training corpus in a fully automated way, and design a tagging scheme to assist in transforming the ORE task into a sequence tagging processing. Furthermore, we propose a hybrid neural network model  for open relation tagging. The model employs the Ordered Neurons LSTM to encode potential syntactic information for capturing the associations among the arguments and relations. It also emerges a novel Dual Aware Mechanism, including Local-aware Attention and Global-aware Convolution. The dual aware nesses complement each other so that the model can take the sentence-level semantics as a global perspective, and at the same time implement salient local features to achieve sparse annotation. Experimental results on various testing sets show that our model can achieve state-of-the-art performances compared to the conventional methods or other neural models. 	 
 Concerns about interpretability, computational resources, and principled inductive priors have motivated efforts to engineer sparse  neural  models for NLP tasks. If sparsity is important for NLP, might well-trained neural models naturally become roughly sparse? Using the Taxi-Euclidean norm to measure sparsity, we find that frequent input words are associated with concentrated or sparse activations, while frequent target words are associated with dispersed activations but concentrated gradients. We find that  gradients associated with function words are more concentrated than the gradients of content words, even controlling for word frequency. 
 In the last few years, neural networks have been intensively used to develop meaningful distributed representations of words and contexts around them. When these representations, also known as ``embeddings'', are learned from unsupervised large corpora, they can be transferred to different tasks with positive effects in terms of performances, especially when only a few supervisions are available. In this work, we further extend this concept, and we present an unsupervised neural architecture that jointly learns word and context embeddings, processing words as sequences of characters. This allows our model to spot the regularities that are due to the word morphology, and to avoid the need of a fixed-sized input vocabulary of words. We show that we can learn compact encoders that, despite the relatively small number of parameters, reach high-level performances in downstream tasks, comparing them with related state-of-the-art approaches or with fully supervised methods.   
     In this paper we present DELTA, a deep learning based language technology platform. DELTA is an end-to-end platform designed to solve industry level natural language and speech processing problems. It integrates most popular neural network models for training as well as comprehensive deployment tools for production. DELTA aims to provide easy and fast experiences for using, deploying, and developing natural language processing and speech models for both academia and industry use cases. We demonstrate the reliable performance with DELTA on several natural language processing and speech tasks, including text classification, named entity recognition, natural language inference, speech recognition, speaker verification, etc. DELTA has been used for developing several state-of-the-art algorithms for publications and delivering real production to serve millions of users. 
 Dialog state tracking is used to estimate the current belief state of a dialog given all the preceding conversation. Machine reading comprehension, on the other hand, focuses on building systems that read passages of text and answer questions that require some understanding of passages. We formulate dialog state tracking as a reading comprehension task to answer the question what is the state of the current dialog? after reading conversational context. In contrast to traditional state tracking methods where the dialog state is often predicted as a distribution over a closed set of all the possible slot values within an ontology, our method uses a simple attention-based neural network to point to the slot values within the conversation. Experiments on MultiWOZ-2.0 cross-domain dialog dataset show that our simple system can obtain similar accuracies compared to the previous more complex methods. By exploiting recent advances in contextual word embeddings, adding a model that explicitly tracks whether a slot value should be carried over to the next turn, and combining our method with a traditional joint state tracking method that relies on closed set vocabulary, we can obtain a joint-goal accuracy of 47.33\% on the standard test split, exceeding current state-of-the-art by 11.75\%**\@. 
 This paper presents an investigation of using a co-attention based neural network for source-dependent essay scoring. We use a co-attention mechanism to help the model learn the importance of each part of the essay more accurately. Also, this paper shows that the co-attention based neural network model provides reliable score prediction of source-dependent responses. We evaluate our model on two source-dependent response corpora. Results show that our model outperforms the baseline on both corpora. We also show that the attention of the model is similar to the expert opinions with examples.  
 Semantic role labeling  is a task to recognize all the predicate-argument pairs of a sentence, which has been in a performance improvement bottleneck after a series of latest works were presented. This paper proposes a novel syntax-agnostic SRL model enhanced by the proposed associated memory network , which makes use of inter-sentence attention of label-known associated sentences as a kind of memory to further enhance dependency-based SRL. In detail, we use sentences and their labels from train dataset as an associated memory cue to help label the target sentence. Furthermore, we compare several associated sentences selecting strategies and label merging methods in AMN to find and utilize the label of associated sentences while attending them. By leveraging the attentive memory from known training data, Our full model reaches state-of-the-art on CoNLL-2009 benchmark datasets for syntax-agnostic setting, showing a new effective research line of SRL enhancement other than exploiting external resources such as well pre-trained language models. 
 Historical linguists have identified regularities in the process of historic sound change. The comparative method utilizes those regularities to reconstruct proto-words based on observed forms in daughter languages. Can this process be efficiently automated?  We address the task of proto-word reconstruction, in which the model is exposed to cognates in contemporary daughter languages, and has to predict the proto word in the ancestor language. We provide a novel dataset for this task, encompassing over 8,000 comparative entries, and show that neural sequence models outperform conventional methods applied to this task so far. Error analysis reveals a variability in the ability of neural model to capture different phonological changes, correlating with the complexity of the changes. Analysis of learned embeddings reveals the models learn phonologically meaningful generalizations, corresponding to well-attested phonological shifts documented by historical linguistics.   
 Natural Language Understanding  models are typically trained in a supervised learning framework. In the case of intent classification, the predicted labels are predefined and based on the designed annotation schema while the labeling process is based on a laborious task where annotators manually inspect each utterance and assign the corresponding label. We propose an Active Annotation   approach where we combine an unsupervised learning method in the embedding space, a human-in-the-loop verification process, and linguistic insights to create lexicons that can be open categories and adapted over time. In particular, annotators define the y-label space on-the-fly during the annotation using an iterative process and without the need for prior knowledge about the input data. We evaluate the proposed annotation paradigm in a real use-case NLU scenario. Results show that our Active Annotation paradigm achieves accurate and higher quality training data, with an annotation speed of an order of magnitude higher with respect to the traditional human-only driven baseline annotation methodology.   
 We define a representation framework for extracting spatial information from radiology reports . We annotated a total of 2000 chest X-ray reports with 4 spatial roles corresponding to the common radiology entities. Our focus is on extracting detailed information of a radiologist's interpretation containing a radiographic finding, its anatomical location, corresponding probable diagnoses, as well as associated hedging terms. For this, we propose a deep learning-based natural language processing  method involving both word and character-level encodings. Specifically, we utilize a bidirectional long short-term memory  conditional random field  model for extracting the spatial roles. The model achieved average F1 measures of $ 90.28 $ and $ 94.61 $ for extracting the Trajector and Landmark roles respectively whereas the performance was moderate for Diagnosis and Hedge roles with average F1 of $ 71.47 $ and $ 73.27 $ respectively. The corpus will soon be made available upon request. 
 This paper focuses on how to take advantage of external relational knowledge to improve machine reading comprehension  with multi-task learning. Most of the traditional methods in MRC assume that the knowledge used to get the correct answer generally exists in the given documents. However, in real-world task, part of knowledge may not be mentioned and machines should be equipped with the ability to leverage external knowledge.  In this paper, we integrate relational knowledge into MRC model for commonsense reasoning. Specifically, based on a pre-trained language model , we design two auxiliary relation-aware tasks  % about relation existence and relation type  to predict if there exists any commonsense relation and what is the relation type between two words, % to enable the model to be aware of the commonsense relationship.  % between words,  in order to better model the interactions between document and candidate answer option. We conduct experiments on two multi-choice benchmark datasets: the SemEval-2018 Task 11 and the Cloze Story Test. The experimental results demonstrate the effectiveness of the proposed method,  which achieves superior performance compared with the comparable baselines on both datasets.  
 Recently, the pre-trained language model, BERT , has attracted a lot of attention in natural language understanding , and achieved state-of-the-art accuracy in various NLU tasks, such as sentiment classification, natural language inference, semantic textual similarity and question answering. Inspired by the linearization exploration work of Elman~, we extend BERT to a new model, StructBERT, by incorporating language structures into pre-training. Specifically, we pre-train StructBERT with two auxiliary tasks to make the most of the sequential order of words and sentences, which leverage language structures at the word and sentence levels, respectively. As a result, the new model is adapted to different levels of language understanding required by downstream tasks.  The StructBERT with structural pre-training gives surprisingly good empirical results on a variety of downstream tasks, including pushing the state-of-the-art on the GLUE benchmark to 89.0 , the F1 score on SQuAD v1.1 question answering to 93.0, the accuracy on SNLI to 91.7. 
  Lexically constrained decoding for machine translation has shown to be beneficial in previous studies. Unfortunately, constraints provided by users may contain mistakes in real-world situations. It is still an open question that how to manipulate these noisy constraints in such practical scenarios. We present a novel framework that treats constraints as external memories. In this soft manner, a mistaken constraint can be corrected. Experiments demonstrate that our approach can achieve substantial BLEU gains in handling noisy constraints. These results motivate us to apply the proposed approach on a new scenario where constraints are generated without the help of users. Experiments show that our approach can indeed improve the translation quality with the automatically generated constraints.   
 This short example shows a contrived example on how to format the authors' information for {. 
  Natural question generation  aims to generate questions from a passage and an answer. Previous works on QG either  ignore the rich structure information hidden in text,  solely rely on cross-entropy loss that leads to issues like exposure bias and inconsistency between train/test measurement, or  fail to fully exploit the answer information.  To address these limitations, in this paper, we propose a reinforcement learning  based graph-to-sequence  model for QG. Our model consists of a Graph2Seq generator with a novel Bidirectional Gated Graph Neural Network based encoder to embed the passage, and a hybrid evaluator with a mixed objective combining both cross-entropy and RL losses to ensure the generation of syntactically and semantically valid text. We also introduce an effective Deep Alignment Network for incorporating the answer information into the passage at both the word and contextual levels. Our model is end-to-end trainable and achieves new state-of-the-art scores, outperforming existing methods by a significant margin on the standard SQuAD benchmark.       
 %We introduce an autonomous agent that uses discrete communication to interactively guide other agents in sequential decision making problems.  %The developed communication protocol is trainable, emergent and requires no additional supervision.  %The emergent language speeds up learning of new agents, and generalizes across incrementally more difficult tasks.  %Although it is not grounded, it is highly interpretable.  %We demonstrate how the emitted messages correlate with particular actions and observations, and how new agents become less dependent on this guidance as training progresses. %By exploiting the correlations identified in our analysis, we manage to successfully address the agents in their own language.  % %A longstanding goal of AI is to develop artificial agents that can cooperate with humans to achieve goals using natural language communication.  To cooperate with humans effectively, virtual agents need to be able to understand and execute language instructions. A typical setup to achieve this is with a scripted teacher which guides a virtual agent using language instructions. However, such setup has clear limitations in scalability and, more importantly, it is not interactive.  Here, we introduce an autonomous agent that uses discrete communication to interactively guide other agents to navigate and act on a simulated environment.  The developed communication protocol is trainable, emergent and requires no additional supervision.  The emergent language speeds up learning of new agents, it generalizes across incrementally more difficult tasks and, contrary to most other emergent languages, it is highly interpretable. We demonstrate how the emitted messages correlate with particular actions and observations, and how new agents become less dependent on this guidance as training progresses. By exploiting the correlations identified in our analysis, we manage to successfully address the agents in their own language.   
 	Most existing approaches to disfluency detection heavily rely on human-annotated data, which is expensive to obtain in practice.  	To tackle the training data bottleneck, we investigate methods for combining multiple self-supervised tasks-i.e., supervised tasks where data can be collected without manual labeling. 	First, we construct large-scale pseudo training data by randomly adding or deleting words from unlabeled news data, and propose two self-supervised pre-training tasks: 	 tagging task to detect the added noisy words. 	 sentence classification to distinguish original sentences from grammatically-incorrect sentences. 	We then combine these two tasks to jointly train a network. 	The pre-trained network is then fine-tuned using human-annotated disfluency detection training data.  	Experimental results on the commonly used English Switchboard test set show that our approach can achieve competitive performance compared to the previous systems  by using less than 1\%  of the training data.  	Our method trained on the full dataset significantly outperforms previous methods, reducing the error by 21\% on English Switchboard. 
 Previous work on neural noisy channel modeling relied on latent variable models that incrementally process the source and target sentence. This makes decoding decisions based on partial source prefixes even though the full source is available. We pursue an alternative approach based on standard sequence to sequence models which utilize the entire source. These models perform remarkably well as channel models, even though they have neither been trained on, nor designed to factor over incomplete target sentences. Experiments with neural language models trained on billions of words show that noisy channel models can outperform a direct model by up to 3.2 BLEU on WMT'17 German-English translation. We evaluate on four language-pairs and our channel models consistently outperform strong alternatives such right-to-left reranking models and ensembles of direct models.\footnote{We release code and pre-trained models at {https://github.com/pytorch/fairseq}} 
   We present a new local entity disambiguation system. The key to our system is a novel approach for learning entity representations. In our approach we learn an entity aware extension of Embedding for Language Model  which we call Entity-ELMo . Given a paragraph containing one or more named entity mentions, each mention is first defined as a function of the entire paragraph , then they predict the referent entities. Utilizing E-ELMo for local entity disambiguation, we outperform all of the state-of-the-art local and global models on the popular benchmarks by improving about 0.5\% on micro average accuracy for AIDA test-b with Yago candidate set. The evaluation setup of the training data and candidate set are the same as our baselines for fair comparison. 
 Learning with minimal data is one of the key challenges in the development of practical, production-ready goal-oriented dialogue systems. In a real-world enterprise setting where dialogue systems are developed rapidly and are expected to work robustly for an ever-growing variety of domains, products, and scenarios, efficient learning from a limited number of examples becomes indispensable.    In this paper, we introduce a technique to achieve state-of-the-art dialogue generation performance in a few-shot setup, without using any annotated data. We do this by leveraging background knowledge from a larger, more highly represented dialogue source~---namely, the MetaLWOz dataset. We evaluate our model on the Stanford Multi-Domain Dialogue Dataset, consisting of human-human goal-oriented dialogues in in-car navigation, appointment scheduling, and weather information domains.    We show that our few-shot approach achieves state-of-the art results on that dataset by consistently outperforming the previous best model in terms of BLEU and Entity F1 scores, while being more data-efficient by not requiring any data annotation.  
 %     In this paper, we focus on graph-to-sequence learning, which can be framed as transducing graph structures to sequences for text generation. To capture graph structure information,  we investigate a graph encoder solely based on graph convolutional networks .  However, current GCNs with shallow architectures are unable to extract non-local information. In order to address this limitation, we introduce the  dense  connection  strategy and propose a novel Densely Connected Graph Convolutional Networks . Such deep architecture is able to integrate local and non-local features to learn a better structural representation. Our model outperforms the state-of-the-art neural models significantly on AMR-to-text generation and syntax-based neural machine translation.       %     % Moreover, instead of using average summation in  GCN, we aggregate node information with filter weights to dynamically select features. % 
 The Hierarchical Attention Network  has made great strides, but it suffers a major limitation: at level 1, each sentence is encoded in complete isolation. In this work, we propose and compare several modifications of HAN in which the sentence encoder is able to make context-aware attentional decisions . Furthermore, we propose a bidirectional document encoder that processes the document forwards and backwards, using the preceding and following sentences as context. Experiments on three large-scale sentiment and topic classification datasets show that the bidirectional version of CAHAN outperforms HAN everywhere, with only a modest increase in computation time. While results are promising, we expect the superiority of CAHAN to be even more evident on tasks requiring a deeper understanding of the input documents, such as abstractive summarization. Code is publicly available\footnote{{https://github.com/JbRemy/Cahan}}. 
 %   %   %  % \johannes{Latex todo notes is the best way of communicating :D} %  We perform extensive experiments  on 86 combinations of languages and tasks. %with DepRel labelling and semantic tagging as main tasks and part-of-speech tagging as an %low-level  %auxiliary task, %  %as well as 41 languages, yielding a total of 86 unique language--task combinations. Our results are that, on average, transductive auxiliary task self-training improves absolute accuracy by up to $9.56\%$ over the pure multi-task model for dependency relation tagging and by up to $13.03\%$ for semantic tagging. %We argue that our method is a straight-forward way to improve the performance of neural multi-task models. %  
 External knowledge is often useful for natural language understanding tasks. We introduce a contextual text representation model called Conceptual-Contextual  embeddings, which incorporates structured knowledge into text representations. Unlike entity embedding methods, our approach encodes a knowledge graph into a context model. CC embeddings can be easily reused for a wide range of tasks in a similar fashion to pre-trained language models. Our model effectively encodes the huge UMLS database by leveraging semantic generalizability. Experiments on electronic health records  and medical text processing benchmarks showed our model gives a major boost to the performance of supervised medical NLP tasks. 
   Neural machine translation  typically adopts the encoder-decoder framework. A good understanding of the characteristics and functionalities of the encoder and decoder can help to explain the pros and cons of the framework, and design better models for NMT. In this work, we conduct an empirical study on the encoder and the decoder in NMT, taking Transformer as an example. We find that 1) the decoder handles an easier task than the encoder in NMT, 2) the decoder is more sensitive to the input noise than the encoder, and 3) the preceding words/tokens in the decoder provide strong conditional information, which accounts for the two observations above. We hope those observations can shed light on the characteristics of the encoder and decoder and inspire future research on NMT. 
 Graph neural networks have recently emerged as a very effective framework for processing graph-structured data. These models have achieved state-of-the-art performance in many tasks. Most graph neural networks can be described in terms of message passing, vertex update, and readout functions. In this paper, we represent documents as word co-occurrence networks and propose an application of the message passing framework to NLP, the Message Passing Attention network for Document understanding . We also propose several hierarchical variants of MPAD. Experiments conducted on 10 standard text classification datasets show that our architectures are competitive with the state-of-the-art. Ablation studies reveal further insights about the impact of the different components on performance. Code is publicly available at: \url{https://github.com/giannisnik/mpad}. 
 Text adventure games, in which players must make sense of the world through text descriptions and declare actions through text descriptions,  provide a stepping stone toward grounding action in language. %The use of text-adventure games as a platform for testing deep reinforcement learning algorithms with natural language is becoming steadily more wide-spread. %However, despite this and the ubiquity of deep reinforcement learning algorithms in general, the problem of transfer remains unsolved. Prior work has demonstrated that using a knowledge graph as a state representation and question-answering to pre-train a deep Q-network facilitates faster control policy learning. %% NOT STRICTLY ACCURATE TO LEAVE THIS OUT, BUT IT'S MINOR AND WE ARE PRECISE IN THE PAPER %transfer and suggests that knowledge transfer will be an essential aspect of practical solutions. In this paper, we explore the use of knowledge graphs as a representation for domain knowledge transfer for training text-adventure playing reinforcement learning agents. %We build on these ideas, exploring the modifications required to help learn more generalized policies, focusing specifically on both knowledge graph and deep Q-network parameter transfer. Our methods are tested across multiple computer generated and human authored games, varying in domain and complexity, and demonstrate that our transfer learning methods let us learn a higher-quality control policy faster. 
   Syntax-incorporated machine translation models have been proven successful in improving the model's reasoning and meaning preservation ability. In this paper, we propose a simple yet effective graph-structured encoder, the Recurrent Graph Syntax Encoder, dubbed RGSE, which enhances the ability to capture useful syntactic information. The RGSE is done over a standard encoder , regarding recurrent network units as graph nodes and injects syntactic dependencies as edges, such that RGSE models syntactic dependencies and sequential information  simultaneously. Our approach achieves considerable improvements over several syntax-aware NMT models in English$\Rightarrow$German and English$\Rightarrow$Czech translation tasks. And RGSE-equipped big model obtains competitive result compared with the state-of-the-art model in WMT14 En-De task. Extensive analysis further verifies that RGSE could benefit long sentence modeling, and produces better translations. 
   We propose two neural network architectures for nested named entity recognition~, a setting in which named entities may overlap and also be labeled with more than one label. We encode the nested labels using a linearized scheme. In our first proposed approach, the nested labels are modeled as multilabels corresponding to the Cartesian product of the nested labels in a standard LSTM-CRF architecture. In the second one, the nested NER is viewed as a sequence-to-sequence problem, in which the input sequence consists of the tokens and output sequence of the labels, using hard attention on the word whose label is being predicted. The proposed methods outperform the nested NER state of the art on four corpora: ACE-2004, ACE-2005, GENIA and Czech CNEC.  We also enrich our architectures with the recently published contextual embeddings: ELMo, BERT and Flair, reaching further improvements for the four nested entity corpora. In addition, we report flat NER state-of-the-art results for CoNLL-2002 Dutch and Spanish and for CoNLL-2003 English. 
 Electronic health record is an important source for clinical researches and applications, and errors inevitably occur in the data, which lead to severe damages to both patients and hospital services.  One of such errors is the mismatch between diagnose and prescription, which we address as ``medication anomaly'' in the paper, and clinicians used to manually identify and correct them.  With the development of machine learning techniques, researchers are able to train specific model for the task, but the process still requires expert knowledge to construct proper features, and few semantic relations are considered.  In this paper, we propose a simple, yet effective detection method that tackles the problem by detecting the semantic inconsistency between diagnoses and prescriptions.  Unlike traditional outlier or anomaly detection, the scheme uses continuous bag of words to construct the semantic connection between specific central words and their surrounding context.  The detection of medication anomaly is transformed into identifying the least possible central word based on given context. To help distinguish the anomaly from normal context, we also incorporate a ranking accumulation strategy.  The experiments were conducted on two real hospital electronic medical records, and the $top N$ accuracy of the proposed method increased by 3.91 to 10.91\% and 0.68 to 2.13\% on the datasets, respectively, which is highly competitive to other traditional machine learning-based approaches. 
 Although neural machine translation models reached high translation quality, the autoregressive nature makes inference difficult to parallelize and leads to high translation latency. Inspired by recent refinement-based approaches, we propose LaNMT, a latent-variable non-autoregressive model with continuous latent variables and deterministic inference procedure.  In contrast to existing approaches, we use a deterministic  inference algorithm to find the target sequence that maximizes the lowerbound to the log-probability. During inference, the length of translation automatically adapts itself. Our experiments show that the lowerbound can be greatly increased by running the inference algorithm, resulting in significantly improved translation quality. Our proposed model closes the performance gap between non-autoregressive and autoregressive approaches on ASPEC Ja-En dataset with 8.6x faster decoding. On WMT'14 En-De dataset, our model narrows the gap with autoregressive baseline to 2.0 BLEU points with 12.5x speedup. By decoding multiple initial latent variables in parallel and rescore using a teacher model, the proposed model further brings the gap down to 1.0 BLEU point on WMT'14 En-De task with 6.8x speedup.  
   Transition-based and graph-based dependency parsers have previously been shown    to have    complemen\-tary strengths and weaknesses:    transition-based parsers exploit rich structural features but   suffer from error propagation, while graph-based parsers    benefit from global   optimization but have restricted feature scope.    In this paper, we   show that, even though some details of the picture have changed after the   switch to neural networks and continuous representations, the basic   trade-off between rich features and global optimization remains essentially the same.    Moreover, we show that deep contextualized word embeddings,   which allow parsers to pack   information about global sentence structure into local feature   representations, benefit transition-based parsers more than graph-based   parsers, making the two approaches virtually equivalent in terms of both   accuracy and error profile. We argue that the reason is that these    representations help prevent search errors and thereby allow   transition-based parsers to better exploit their inherent strength of making   accurate local decisions. We support this explanation by an error   analysis of parsing experiments on 13 languages. 
   Majority of the text modelling techniques yield only point-estimates of   document embeddings and lack in capturing the uncertainty of the estimates.   These uncertainties give a notion of how well the embeddings represent   a document. We present Bayesian subspace multinomial model ,   a generative log-linear model that learns to represent documents in the   form of Gaussian distributions, thereby encoding the uncertainty in its   covariance. Additionally, in the proposed Bayesian SMM, we address a commonly   encountered problem of intractability that appears during variational   inference in mixed-logit models. We also present a generative Gaussian   linear classifier for topic identification that exploits the uncertainty   in document embeddings. Our intrinsic evaluation using perplexity measure   shows that the proposed Bayesian SMM fits the data better as compared to the    state-of-the-art neural variational document model on    speech and  text corpora. Our topic    identification experiments show that the proposed systems are robust to    over-fitting on unseen test data. The topic ID results show that the proposed    model is outperforms state-of-the-art unsupervised topic models and    achieve comparable results to the state-of-the-art fully    supervised discriminative models. 
 Monolingual data has been demonstrated to be helpful in improving the translation quality of neural machine translation . The current methods stay at the usage of word-level knowledge, such as generating synthetic parallel data or extracting information from word embedding. In contrast, the power of sentence-level contextual knowledge which is more complex and diverse, playing an important role in natural language generation, has not been fully exploited. In this paper, we propose a novel structure which could leverage monolingual data to acquire sentence-level contextual representations.  Then, we design a framework for integrating both source and target sentence-level representations into NMT model to improve the translation quality. Experimental results on Chinese-English, German-English machine translation tasks show that our proposed model achieves improvement over strong Transformer baselines, while experiments on English-Turkish further demonstrate the effectiveness of our approach in the low-resource scenario. \footnote{In Progress} 
 Dialogue state tracking  is an essential component in task-oriented dialogue systems, which estimates user goals at every dialogue turn. However, most previous approaches usually suffer from the following problems. Many discriminative models, especially end-to-end  models, are difficult to extract unknown values that are not in the candidate ontology; previous generative models, which can extract unknown values from utterances, degrade the performance due to ignoring the semantic information of pre-defined ontology. Besides, previous generative models usually need a hand-crafted list to normalize the generated values. How to integrate the semantic information of pre-defined ontology and dialogue text  to generate unknown values and improve performance becomes a severe challenge. In this paper, we propose a Copy-Enhanced Heterogeneous Information Learning model with multiple encoder-decoder for DST , which can effectively generate all possible values including unknown values by copying values from heterogeneous texts. Meanwhile, CEDST can effectively decompose the large state space into several small state spaces through multi-encoder, and employ multi-decoder to make full use of the reduced spaces to generate values. Multi-encoder-decoder architecture can significantly improve performance. Experiments show that CEDST can achieve state-of-the-art results on two datasets and our constructed datasets with many unknown values.   
 Recurrent Neural Network  and its variations such as Long Short-Term Memory  and Gated Recurrent Unit , have become standard building blocks for learning online data of sequential nature in many research areas, including natural language processing and speech data analysis. In this paper, we present a new methodology to significantly reduce the number of parameters in RNNs while maintaining performance that is comparable or even better than classical RNNs. The new proposal, referred to as Restricted Recurrent Neural Network , restricts the weight matrices corresponding to the input data and hidden states at each time step to share a large proportion of parameters. The new architecture can be regarded as a compression of its classical counterpart, but it does not require pre-training or sophisticated parameter fine-tuning, both of which are major issues in most existing compression techniques. Experiments on natural language modeling show that compared with its classical counterpart, the restricted recurrent architecture generally produces comparable results at about 50\% compression rate. In particular, the Restricted LSTM can outperform classical RNN with even less number of parameters.  
 Cross-lingual word embeddings are vector representations of words in different languages where words with similar meaning are represented by similar vectors, regardless of the language. Recent developments which construct these embeddings by aligning monolingual spaces have shown that accurate alignments can be obtained with little or no supervision, which usually comes in the form of bilingual dictionaries. However, the focus has been on a particular controlled scenario for evaluation, and there is no strong evidence on how current state-of-the-art systems would fare with noisy text or for language pairs with major linguistic differences. In this paper we present an extensive evaluation over multiple cross-lingual embedding models, analyzing their strengths and limitations with respect to different variables such as target language, training corpora and amount of supervision. Our conclusions put in doubt the view that high-quality cross-lingual embeddings can always be learned without much supervision.\\ \newline \Keywords{Multilinguality, Evaluation Methodologies, Semantics, Semi-supervised, weakly-supervised and unsupervised learning
 Multi-Task Learning  aims at boosting the overall performance of each individual task by leveraging useful information contained in multiple related tasks. It has shown great success in natural language processing . Currently, a number of MTL architectures and learning mechanisms have been proposed for various NLP tasks, including exploring linguistic hierarchies, orthogonality constraints, adversarial learning, gate mechanism, and label embedding.   However, there is no systematic exploration and comparison of different MTL architectures and learning mechanisms for their strong performance in-depth. In this paper, we conduct a thorough examination of five typical MTL methods with deep learning architectures for a broad range of representative NLP tasks.  Our primary goal is to understand the merits and demerits of existing MTL methods in NLP tasks, thus devising new hybrid architectures intended to combine their strengths. Following the empirical evaluation, we offer our insights and conclusions regarding the MTL methods we have considered.  
 Mining causality from text is a complex and crucial natural language understanding task. Most of the early attempts at its solution can group into two categories: 1) utilizing co-occurrence frequency and world knowledge for causality detection; 2) extracting cause-effect pairs by using connectives and syntax patterns directly. However, because causality has various linguistic expressions, the noisy data and ignoring implicit expressions problems induced by these methods cannot be avoided. In this paper, we present a neural causality detection model, namely Multi-level Causality Detection Network , to address this problem. Specifically, we adopt multi-head self-attention to acquire semantic feature at word level and integrate a novel Relation Network to infer causality at segment level. To the best of our knowledge, in touch with the causality tasks, this is the first time that the Relation Network is applied. The experimental results on the AltLex dataset, demonstrate that: a) MCDN is highly effective for the ambiguous and implicit causality inference; b) comparing with the regular text classification task, causality detection requires stronger inference capability; c) the proposed approach achieved state-of-the-art performance. 
 Despite a multitude of empirical studies, little consensus exists on whether neural networks are able to generalise , a controversy that, in part, stems from a lack of agreement about what it means for a neural model to be compositional. As a response to this controversy, we present a set of tests that provide a bridge between, on the one hand, the vast amount of linguistic and philosophical theory about compositionality of language and, on the other, the successful neural models of language. We collect different interpretations of compositionality and translate them into five theoretically grounded tests for models that are formulated on a task-independent level. In particular, we provide tests to investigate  if models systematically recombine known parts and rules %   if models can extend their predictions beyond the length they have seen in the training data %    if models' composition operations are local or global %    if models' predictions are robust to synonym substitutions and %  and   if models favour rules or exceptions during training. %. To demonstrate the usefulness of this evaluation paradigm, we instantiate these five tests on a highly compositional data set which we dub \pcfg and apply the resulting tests to three popular sequence-to-sequence models: a recurrent, a convolution-based and a transformer model. We provide an in-depth analysis of the results, which uncover the strengths and weaknesses of these three architectures and point to potential areas of improvement. 
 	For neural sequence model training, maximum likelihood  has been commonly adopted to optimize model parameters with respect to the corresponding objective. However, in the case of sequence prediction tasks like neural machine translation , training with the ML-based cross entropy loss would often lead to models that overgeneralize and plunge into local optima. In this paper, we propose an extended loss function called  , which aims to give a better tradeoff between generalization ability and error avoidance during NMT training. Our empirical study indicates that switching to DSD loss after the convergence of ML training helps the model skip the local optimum and  stimulates a stable performance improvement. The evaluations on WMT 2014 English-German and English-French translation tasks demonstrate that the proposed loss indeed helps bring about better translation performance than several baselines. 
 Electronic Health Records  in hospital information systems contain patients閳 diagnosis and treatments, so EHRs are essential to clinical data mining. Of all the tasks in the mining process, Chinese Word Segmentation  is a fundamental and important one, and most state-of-the-art methods greatly rely on large-scale of manually-annotated data. Since annotation is time-consuming and expensive, efforts have been devoted to techniques, such as active learning, to locate the most informative samples for modeling. In this paper, we follow the trend and present an active learning method for CWS in EHRs. Specifically, a new sampling strategy combining Normalized Entropy with Loss Prediction  is proposed to select the most representative data. Meanwhile, to minimize the computational cost of learning, we propose a joint model including a word segmenter and a loss prediction model. Furthermore, to capture interactions between adjacent characters, bigram features are also applied in the joint model. To illustrate the effectiveness of NE-LP, we conducted experiments on EHRs collected from the Shuguang Hospital Affiliated to Shanghai University of Traditional Chinese Medicine. The results demonstrate that NE-LP consistently outperforms conventional uncertainty-based sampling strategies for active learning in CWS.  
 CRF has been used as a powerful model for statistical sequence labeling. For neural sequence labeling, however, BiLSTM-CRF does not always lead to better results compared with BiLSTM-softmax local classification. This can be because the simple Markov label transition model of CRF does not give much information gain over strong neural encoding. For better representing label sequences, we investigate a hierarchically-refined label attention network, which explicitly leverages label embeddings and captures potential long-term label dependency by giving each word incrementally refined label distributions with hierarchical attention. Results on POS tagging, NER and CCG supertagging show that the proposed model not only improves the overall tagging accuracy with similar number of parameters, but also significantly speeds up the training and testing compared to BiLSTM-CRF. 
 A conversational agent  is a piece of software that is able to communicate with humans using natural language. Modeling conversation is an important task in natural language processing and artificial intelligence . Indeed, ever since the birth of AI, creating a good chatbot remains one of the field閳ユ獨 hardest challenges. While chatbots can be used for various tasks, in general they have to understand users閳 utterances and provide responses that are relevant to the problem at hand.  In the past, methods for constructing chatbot architectures have relied on hand-written rules and templates or simple statistical methods. With the rise of deep learning these models were quickly replaced by end-to-end trainable neural networks around 2015. More specifically, the recurrent encoder-decoder model  dominates the task of conversational modeling. This architecture was adapted from the neural machine translation domain, where it performs extremely well. Since then a multitude of variations  and features were presented that augment the quality of the conversation that chatbots are capable of.  In my work, I conduct an in-depth survey of recent literature, examining over 70 publications related to chatbots published in the last 3 years. Then I proceed to make the argument that the very nature of the general conversation domain demands approaches that are different from current state-of-the-art architectures. Based on several examples from the literature I show why current chatbot models fail to take into account enough priors when generating responses and how this affects the quality of the conversation. In the case of chatbots these priors can be outside sources of information that the conversation is conditioned on like the persona  or mood of the conversers. In addition to presenting the reasons behind this problem, I propose several ideas on how it could be remedied.  The next section of my paper focuses on adapting the very recent Tranformer  model to the chatbot domain, which is currently the state-of-the-art in neural machine translation. I first present my experiments with the vanilla model, using conversations extracted from the Cornell Movie-Dialog Corpus . Secondly, I augment the model with some of my ideas regarding the issues of encoder-decoder architectures. More specifically, I feed additional features into the model like mood or persona together with the raw conversation data. Finally, I conduct a detailed analysis of how the vanilla model performs on conversational data by comparing it to previous chatbot models and how the additional features, affect the quality of the generated responses. 
 Motivated by the recent progresses on machine learning-based models that learn artistic styles, in this paper we focus on the problem of poem generation. This is a challenging task in which the machine has to capture the linguistic features that strongly characterize a certain poet, as well as the semantics of the poet's production, that are influenced by his personal experiences and by his literary background. Since poetry is constructed using syllables, that regulate the form and structure of poems, we propose a syllable-based neural language model, and we describe a poem generation mechanism that is designed around the poet style, automatically selecting the most representative generations. The poetic work of a target author is usually not enough to successfully train modern deep neural networks, so we propose a multi-stage procedure that exploits non-poetic works of the same author, and also other publicly available huge corpora to learn syntax and grammar of the target language. We focus on the Italian poet Dante Alighieri, widely famous for his Divine Comedy. A quantitative and qualitative experimental analysis of the generated tercets is reported, where we included expert judges with strong background in humanistic studies. The generated tercets are frequently considered to be real by a generic population of judges, with relative difference of 56.25\% with respect to the ones really authored by Dante, and expert judges perceived Dante's style and rhymes in the generated text.   % We present both quantitative and qualitative results to evaluate the model and the generated tercets. In the latter case we ask people to judge real and fake tercets. We consider two samples of evaluators: expert of the author and non-expert . Results shows that tercets from our model are considered as real by non-expert annotators half of the times the real ones.   
 Text summarization aims at compressing long documents into a shorter form that conveys the most important parts of the original document. Despite increased interest in the community and notable research effort, progress on benchmark datasets has stagnated. We critically evaluate key ingredients of the current  research  setup:  datasets,  evaluation  metrics,  and  models, and    highlight three primary shortcomings: 1)~automatically collected datasets leave the task underconstrained and may contain noise detrimental to training and evaluation,  2)~current evaluation protocol is weakly correlated with human judgment and does not account for important characteristics such as factual correctness, 3)~models overfit to layout biases of current datasets and offer limited diversity in their outputs. 
 Recent developments in natural language representations have been accompanied by large and expensive models that leverage vast amounts of general-domain text through self-supervised pre-training. Due to the cost of applying such models to down-stream tasks, several model compression techniques on pre-trained language representations have been proposed~. However, surprisingly,  the simple baseline of just pre-training and fine-tuning compact models has been overlooked. In this paper, we first show that pre-training remains important in the context of smaller architectures, and fine-tuning pre-trained compact models can be competitive to more elaborate methods proposed in concurrent work. Starting with pre-trained compact models, we then explore transferring task knowledge from large fine-tuned models through standard knowledge distillation. The resulting simple, yet effective and general algorithm, , brings further improvements. Through extensive experiments, we more generally explore the interaction between pre-training and distillation under two variables that have been under-studied: model size and properties of unlabeled task data. One surprising observation is that they have a compound effect even when sequentially applied on the  data. To accelerate future research, we will make our 24 pre-trained miniature BERT models publicly available.   %Second, we discover that pre-trained compact models can be further improved by distilling from large fine-tuned models. This results in a simple and yet effective algorithm, . Finally, we conduct extensive analysis on the non-trivial interactions between pre-training and distillation, and demonstrates the importance of fully pre-training compact models.   % Recent developments in NLP have been accompanied by large, expensive models that leverage vast amounts of general-domain data through self-supervised learning. However, applying language model pre-training to more compact models has been overlooked. We show that it remains important in the context of smaller architectures, as approximations explored in prior work suffer quality loss. Pre-trained compact models can be further refined through standard knowledge distillation. The resulting algorithm, , is competitive to more elaborate strategies proposed in concurrent work, with the additional benefit of being architecture-agnostic. Through extensive experiments, we more generally explore the interaction between pre-training and distillation under two variables that have been under-studied: model size and properties of unlabeled task data. One surprising observation is that they have a compound effect even when sequentially applied on the  data. To accelerate future research, we will make our 24 pre-trained miniature BERT models publicly available. 
      Traditionally, most data-to-text applications have been designed using a modular pipeline architecture, in which non-linguistic input data is converted into natural language through several intermediate transformations. By contrast, recent neural models for data-to-text generation have been proposed as end-to-end approaches, where the non-linguistic input is rendered in natural language with much less explicit intermediate representations in between. This study introduces a systematic comparison between neural pipeline and end-to-end data-to-text approaches for the generation of text from RDF triples. Both architectures were implemented making use of the encoder-decoder Gated-Recurrent Units  and Transformer, two state-of-the art deep learning methods. Automatic and human evaluations together with a qualitative analysis suggest that having explicit intermediate steps in the generation process results in better texts than the ones generated by end-to-end approaches. Moreover, the pipeline models generalize better to unseen inputs. Data and code are  publicly available.\footnote{\url{https://github.com/ThiagoCF05/DeepNLG/}}    
    is a fundamental task in natural language processing and has been widely studied. Recently, RNN-based sequence labeling models have increasingly gained attentions. Despite superior performance achieved by learning the long short-term  dependencies,   %long term token dependencies,   the way of sequentially processing inputs might limit the ability to capture the non-continuous relations over tokens within a sentence.   %  latent relations among tokens, since neglecting the discrete context dependencies of input sequence.   % , which mainly focuses on the successive context modeling , but neglecting modeling relative positions    % however neglecting modeling the relative positions , thus neglects modeling the discrete context dependencies of input sequence.   To tackle the problem, we focus on how to effectively model  and  dependencies of each token for enhancing the sequence labeling performance.   %which is rarely addressed in previous works.   %   Specifically, we propose an innovative and well-designed attention-based model    within a neural network architecture, to explore the positional information of an input sequence for capturing the latent relations among tokens.   % To tackle the problem, we propose a novel neural architecture by incorporating self-attention mechanism and to enhance sequence labeling tasks.   %   In this study, we focus on better extracting the context features of each token by modeling the discrete context dependencies, which is rarely addressed in previous works. Specifically, a new well-designed attention model  is further proposed within the framework to help capture the latent relations among tokens by exploring the positional information of an input sequence.   Extensive experiments on three classical tasks in  domain,   ,   and , demonstrate our proposed model outperforms the state-of-the-arts without any external knowledge, in   terms of various metrics.   % the significant improvements of  over  methods without any external knowledge.  
 % Performing reasoning across multiple sentences to answer questions is a natural human behavior but has attracted little attention in the literature. In this study, we propose a novel graph neural network called propagate-selector , which propagates information over sentences to understand information that cannot be inferred when considering sentences in isolation. First, we design a graph structure in which each node represents an individual sentence, and some pairs of nodes are selectively connected based on the text structure. Then, we develop an iterative attentive aggregation and a skip-combine method in which a node interacts with its neighborhood nodes to accumulate the necessary information. To evaluate the performance of the proposed approaches, we conduct experiments with the standard HotpotQA dataset. The empirical results demonstrate the superiority of our proposed approach, which obtains the best performances, compared to the widely used answer-selection models that do not consider the intersentential relationship. \\ \newline \Keywords{question answering, supporting sentence, graph neural network
 To extract the structured representations of open-domain events, Bayesian graphical models have made some progress.  However, these approaches typically assume that all words in a document are generated from a single event. While this may be true for short text such as tweets, such an assumption does not generally hold for long text such as news articles. Moreover, Bayesian graphical models often rely on Gibbs sampling for parameter inference which may take long time to converge. To address these limitations, we propose an event extraction model based on Generative Adversarial Nets, called Adversarial-neural Event Model . AEM models an event with a Dirichlet prior and uses a generator network to capture the patterns underlying latent events. A discriminator is used to distinguish documents reconstructed from the latent events and the original documents. A byproduct of the discriminator is that the features generated by the learned discriminator network allow the visualization of the extracted events. Our model has been evaluated on two Twitter datasets and a news article dataset. Experimental results show that our model outperforms the baseline approaches on all the datasets, with more significant improvements observed on the news article dataset where an increase of 15\% is observed in F-measure.  
 Multilingual neural machine translation , which translates multiple languages using a single model, is of great practical importance due to its advantages in simplifying the training process, reducing online maintenance costs, and enhancing low-resource and zero-shot translation.  Given there are thousands of languages in the world and some of them are very different, it is extremely burdensome to handle them all in a single model or use a separate model for each language pair. Therefore, given a fixed resource budget, e.g., the number of models, how to determine which languages should be supported by one model is critical to multilingual NMT, which, unfortunately, has been ignored by previous work. In this work, we develop a framework that clusters languages into different groups and trains one multilingual model for each cluster. We study two methods for language clustering:  using prior knowledge, where we cluster languages according to language family, and  using language embedding, in which we represent each language by an embedding vector and cluster them in the embedding space. In particular, we obtain the embedding vectors of all the languages by training a universal neural machine translation model. Our experiments on 23 languages show that the first clustering method is simple and easy to understand but leading to suboptimal translation accuracy, while the second method sufficiently captures the relationship among languages well and improves the translation accuracy for almost all the languages over baseline methods.  %Most existing work on multilingual NMT focuses on how to design/train a better model for a given set of languages. 
 The encoder-decoder based neural machine translation usually generates a target sequence token by token from left to right. Due to error propagation, the tokens in the right side of the generated sequence are usually of poorer quality than those in the left side. In this paper, we propose an efficient method to generate a sequence in both left-to-right and right-to-left manners using a single encoder and decoder, combining the advantages of both generation directions. Experiments on three translation tasks show that our method achieves significant improvements over conventional unidirectional approach. Compared with ensemble methods that train and combine two models with different generation directions, our method saves 50\% model parameters and about 40\% training time, and also improve inference speed.   %Neural machine translation typically leverages the encoder-decoder framework, where the decoder usually generates a target sequence token by token from left to right. Due to error propagation, the tokens in the right side of the generated sequence are usually of poorer quality than those in the left side. In this paper, we propose a novel and efficient framework to generate a sequence with both left-to-right and right-to-left manners in a single encoder and decoder, combining the advantages of both generation directions. Experiments on three translation tasks demonstrate that our proposed method can achieve significant improvements over conventional unidirectional approach. Compared with the conventional methods that train two models with different generation directions for ensembling, our method can save 50\% model parameters, nearly 40\% training time and also improve the inference speed.  
 Machine Translation models are trained to translate a variety of documents from one language into another. However, models specifically trained for a particular characteristics of the documents tend to perform better. Fine-tuning is a technique for adapting an NMT model to some domain. In this work, we want to use this technique to adapt the model to a given test set. In particular, we are using transductive data selection algorithms which take advantage the information of the test set to retrieve sentences from a larger parallel set.   In cases where the model is available at translation time , it can be adapted with a small subset of data, thereby achieving better performance than a generic model or a domain-adapted model. 
  %Neural machine translation  has been prominent in many machine translation tasks. However, in some domain-specific tasks, only the corpora from similar domains can improve translation performance. If out-of-domain corpora are directly added into the in-domain corpus, the translation performance may even degrade. Therefore, domain adaptation techniques are essential to solve the NMT domain problem.  Domain adaptation has been well-studied in supervised  neural machine translation .   However, it has not been well-studied for unsupervised neural machine translation , although UNMT has recently achieved remarkable results in several domain-specific language pairs.  %In  a  real-world  scenario,  it is  difficult  to  get  enough  in-domain parallel or even monolingual corpora in some other specific domain.    Besides the domain inconsistence between parallel training data and test data for SNMT, there sometimes exists domain inconsistence between two monolingual training data for UNMT.   In this work, we empirically categorize different domain adaptation scenarios for  UNMT.   Based on these scenarios, we revisit the effect of the existing representative domain adaptation methods including batch weighting and fine tuning methods in UNMT. Finally, we propose modified methods to improve the performances of domain-specific UNMT systems. 
   Name tagging in low-resource languages or domains suffers from inadequate training data. Existing work heavily relies on additional information, while leaving those noisy annotations unexplored that extensively exist on the web. In this paper, we propose a novel neural model for name tagging solely based on weakly labeled  data, so that it can be applied in any low-resource settings. To take the best advantage of all WL sentences, we split them into high-quality and noisy portions for two modules, respectively:  a classification module focusing on the large portion of noisy data can efficiently and robustly pretrain the tag classifier by capturing textual context semantics; and  a costly sequence labeling module focusing on high-quality data utilizes Partial-CRFs with non-entity sampling to achieve global optimum. Two modules are combined via shared parameters. Extensive experiments involving five low-resource languages and fine-grained food domain demonstrate our superior performance  as well as efficiency\footnote{Our project can be found in \url{https://github.com/zig-kwin-hu/Low-Resource-Name-Tagging}.}. 
   Author profiling is the characterization of an author through some key attributes such as gender, age, and language. In this paper, a RNN model with Attention  is proposed to predict the gender of a twitter user using their tweets. Both word level and tweet level attentions are utilized to learn 'where to look'. This model\footnote{https://github.com/Darg-Iztech/gender-prediction-from-tweets} is improved by concatenating LSA-reduced n-gram features with the learned neural representation of a user. Both models are tested on three languages: English, Spanish, Arabic. The improved version of the proposed model  achieves state-of-the-art performance on English and has  competitive results on Spanish and Arabic.  
 		Neural Machine Translation  has achieved notable success in recent years. Such a framework usually generates translations in isolation. In contrast, human translators often refer to reference data, either rephrasing the intricate sentence fragments with common terms in source language, or just accessing to the golden translation directly. In this paper, we propose a Reference Network to incorporate referring process into translation decoding of NMT. To construct a , an intuitive way is to store the detailed translation history with extra memory, which is computationally expensive. Instead, we employ Local Coordinates Coding  to obtain global context vectors containing monolingual and bilingual contextual information for NMT decoding. Experimental results on Chinese-English and English-German tasks demonstrate that our proposed model is effective in improving the translation quality with lightweight computation cost. 	
 This paper proposes a novel procedure for training an encoder-decoder based deep neural network which compresses $N\times M$ models into a single model enabling us to dynamically choose the number of encoder and decoder layers for decoding. Usually, the output of the last layer of the $N$-layer encoder is fed to the $M$-layer decoder, and the output of the last decoder layer is used to compute softmax loss. Instead, our method computes a single loss consisting of $N\times M$ losses: the softmax loss for the output of each of the $M$ decoder layers derived using the output of each of the $N$ encoder layers. A single model trained by our method can be used for decoding with an arbitrary fewer number of encoder and decoder layers. In practical scenarios, this ~enables faster decoding with insignificant losses in translation quality and ~alleviates the need to train $N\times M$ models, thereby saving space. We take a case study of neural machine translation and show the advantage and give a cost-benefit analysis of our approach. 
 Learning general representations of text is a fundamental problem for many natural language understanding  tasks. Previously, researchers have proposed to use language model pre-training and multi-task learning to learn robust representations. However, these methods can achieve sub-optimal performance in low-resource scenarios. Inspired by the recent success of optimization-based meta-learning algorithms, in this paper, we explore the model-agnostic meta-learning algorithm  and its variants for low-resource NLU tasks. We validate our methods on the GLUE benchmark and show that our proposed models can outperform several strong baselines. We further empirically demonstrate that the learned representations can be adapted to new tasks efficiently and effectively. 
 There have been a recent line of works to automatically predict the emotions of posts in social media. Existing approaches consider the posts individually and predict their emotions independently. Different from previous researches, we explore the dependence among relevant posts via the authors' backgrounds, since the authors with similar backgrounds, e.g., , , tend to express similar emotions. However, such personal attributes are not easy to obtain in most social media websites, and it is hard to capture attributes-aware words to connect similar people. Accordingly, we propose a Neural Personal Discrimination  approach to address  above challenges by determining  personal attributes from posts, and connecting  relevant posts with similar attributes to jointly learn their emotions. In particular, we employ adversarial discriminators to determine the personal attributes, with attention mechanisms to aggregate attributes-aware words. In this way, social correlationship among different posts can be better addressed. Experimental results show the usefulness of personal attributes, and the effectiveness of our proposed NPD approach in capturing such personal attributes with significant gains over the state-of-the-art models. 
     Dialog policy decides what and how a task-oriented dialog system will respond, and plays a vital role in delivering effective conversations.     Many studies apply Reinforcement Learning to learn a dialog policy with the reward function which requires elaborate design and pre-specified user goals.     With the growing needs to handle complex goals across multiple domains, such manually designed reward functions are not affordable to deal with the complexity of real-world tasks. To this end, we propose Guided Dialog Policy Learning, a novel algorithm based on Adversarial Inverse Reinforcement Learning for joint reward estimation and policy optimization in multi-domain task-oriented dialog. The proposed approach estimates the reward signal and infers the user goal in the dialog sessions. The reward estimator evaluates the state-action pairs so that it can guide the dialog policy at each dialog turn. Extensive experiments on a multi-domain dialog dataset show that the dialog policy guided by the learned reward function achieves remarkably higher task success than state-of-the-art baselines. 
     Recent advances in neural sequence-to-sequence models have led to promising results for several language generation-based tasks, including dialogue response generation, summarization, and machine translation. However, these models are known to have several problems, especially in the context of chit-chat based dialogue systems: they tend to generate short and dull responses that are often too generic. Furthermore, these models do not ground conversational responses on knowledge and facts, resulting in turns that are not accurate, informative and engaging for the users. In this paper, we propose and experiment with a series of response generation models that aim to serve in the general scenario where in addition to the dialogue context, relevant unstructured external knowledge in the form of text is also assumed to be available for models to harness. Our proposed approach extends pointer-generator networks  by allowing the decoder to hierarchically attend and copy from external knowledge in addition to the dialogue context. We empirically show the effectiveness of the proposed model compared to several baselines including  through both automatic evaluation metrics and human evaluation on ConvAi2 dataset.     
 Generating paraphrases from given sentences involves decoding words step by step from a large vocabulary. To learn a decoder, supervised learning which maximizes the likelihood of tokens always suffers from the exposure bias. Although both reinforcement learning  and imitation learning  have been widely used to alleviate the bias, the lack of direct comparison leads to only a partial image on their benefits. In this work, we present an empirical study on how RL and IL can help boost the performance of generating paraphrases, with the pointer-generator as a base model \footnote{The data and code for this work can be obtained from: \url{https://github.com/ddddwy/Reinforce-Paraphrase-Generation}}. Experiments on the benchmark datasets show that  imitation learning is constantly better than reinforcement learning; and  the pointer-generator models with imitation learning outperform the state-of-the-art methods with a large margin. 
 Humans observe and interact with the world to acquire knowledge. However, most existing machine reading comprehension  tasks miss the interactive, information-seeking component of comprehension. Such tasks present models with static documents that contain all necessary information, usually concentrated in a single short substring. Thus, models can achieve strong performance through simple word- and phrase-based pattern matching. We address this problem by formulating a novel text-based question answering task: Question Answering with Interactive Text .\footnote{The dataset and implementation of our baseline agents are publicly available at \url{https://github.com/xingdi-eric-yuan/qait_public}.} In \qait, an agent must interact with a partially observable text-based environment to gather information required to answer questions. \qait poses questions about the existence, location, and attributes of objects found in the environment. The data is built using a text-based game generator that defines the underlying dynamics of interaction with the environment. We propose and evaluate a set of baseline models for the \qait task that includes deep reinforcement learning agents. Experiments show that the task presents a major challenge for machine reading systems, while humans solve it with relative ease. %We also introduce to the MRC domain the practice of generating unlimited training data on the fly %We hope our work can encourage the community to think beyond word matching, to teach machines to gather information and comprehend in a more human-inspired way. 
 Most data selection research in  machine translation focuses on improving a single domain. We perform data selection for multiple domains at once. This is achieved by carefully introducing instance-level domain-relevance features and automatically constructing a training curriculum to gradually concentrate on multi-domain relevant and noise-reduced data batches. Both the choice of features and  %the denoising capability  the use of curriculum are crucial for balancing and improving all domains, including out-of-domain. In large-scale experiments, the multi-domain curriculum simultaneously reaches or outperforms the individual performance and brings solid gains over no-curriculum training. 
 Knowledge graphs typically undergo open-ended growth of new relations. This cannot be well handled by relation extraction that focuses on pre-defined relations with sufficient training data. To address new relations with few-shot instances, we propose a novel bootstrapping approach, Neural Snowball, to learn new relations by transferring semantic knowledge about existing relations. More specifically, we use Relational Siamese Networks  to learn the metric of relational similarities between instances based on existing relations and their labeled data. Afterwards, given a new relation and its few-shot instances, we use RSN to accumulate reliable instances from unlabeled corpora; these instances are used to train a relation classifier, which can further identify new facts of the new relation. The process is conducted iteratively like a snowball. Experiments show that our model can gather high-quality instances for better few-shot relation learning and achieves significant improvement compared to baselines. Codes and datasets are released on \url{https://github.com/thunlp/Neural-Snowball}. 
 Shallow syntax provides an approximation of phrase-syntactic structure of sentences; it can be produced with high accuracy, and is computationally cheap to obtain. We investigate the role of shallow syntax-aware representations for NLP tasks using two techniques. First, we enhance the ELMo architecture  to allow pretraining on predicted shallow syntactic parses, instead of just raw text, so that contextual embeddings make use of shallow syntactic context. Our second method involves shallow syntactic features obtained automatically on downstream task data. Neither approach leads to a significant gain on any of the four downstream tasks we considered relative to ELMo-only baselines. Further analysis using black-box probes from  confirms that our shallow-syntax-aware contextual embeddings do not transfer to linguistic tasks any more easily than ELMo's embeddings. We take these findings as evidence that ELMo-style pretraining discovers representations which make additional awareness of shallow syntax redundant. 
 % Recent neural seq2seq models have been applied to text-to-SQL learning successfully. However, few work has paid attention to how these models generalize to realistic unseen data .  % %We find the mapping from question words to SQL table schema is crucial to the query generation as well as model's generalizability to the text-to-SQL learning.  % In this work, we propose an auxiliary task  % %adding to the traditional seq2seq SQL generation. The auxiliary task  % that explicitly maps question words to table schema. The auxiliary mapping task serves as a supportive model as well as a regularization term to the generation task to increase the model's generalization. In addition, our seq2seq model for generation task is augmented with an attentive pooling inside the question, and bi-directional attention flow to enhance the interaction between the question and table schema.  % %In addition, the auxiliary mapping task serves as a supportive model as well as a regularization term to the generation task to increase its generalization to the text-to-SQL learning.  % We test our models on a large text-to-SQL dataset WikiSQL. % %Quantitative and qualitative results show their effectiveness.  % Compared to a strong baseline coarse-to-fine model, our models improve over the baseline by more than 3\% absolute in accuracy on the whole dataset. More interestingly, on a zero-shot subset test of WikiSQL, our models achieve 5\% absolute accuracy gain over the baseline, clearly demonstrating its superior generalizability.      Recent years have seen great success in the use of neural seq2seq models on the text-to-SQL task. However,  little work has paid attention to how these models generalize to realistic unseen data, which naturally raises a question: does this impressive performance signify a perfect generalization model, or are there still some limitations?  In this paper, we first diagnose the bottleneck of text-to-SQL task by providing a new testbed, in which we observe that existing models present poor generalization ability on rarely-seen data. The above analysis encourages us to design a simple but effective auxiliary task, which serves as a supportive model as well as a regularization term to the generation task to increase the model閳ユ獨 generalization. Experimentally, We evaluate our models on a large text-to-SQL dataset WikiSQL. %Quantitative and qualitative results show their effectiveness.  Compared to a strong baseline coarse-to-fine model, our models improve over the baseline by more than 3\% absolute in accuracy on the whole dataset. More interestingly, on a zero-shot subset test of WikiSQL, our models achieve 5\% absolute accuracy gain over the baseline, clearly demonstrating its superior generalizability.          
 % Recent literature shows that large-scale language modeling provides excellent     reusable sentence representations with both recurrent and self-attentive     architectures. % However, there has been less clarity on the commonalities and differences in     the representational properties induced by the two architectures.  It also     has been shown that visual information serves as one of the means for     grounding sentence representations. % In this paper, we present a meta-study assessing the representational quality     of models where the training signal is obtained from different modalities,     in particular, language modeling, image features prediction, and both     textual and multimodal machine translation. % We evaluate textual and visual features of sentence representations obtained     using predominant approaches on image retrieval and semantic textual     similarity. % Our experiments reveal that on moderate-sized datasets,  in a target language or  provides much     stronger training signal for sentence representation than language     modeling. % Importantly, we observe that while the Transformer models achieve superior     machine translation quality, representations from the recurrent neural     network based models perform significantly better over tasks focused on     semantic relevance. % 
  The general trend in NLP is towards increasing model capacity and performance via deeper neural networks. However, simply stacking more layers of the popular Transformer architecture for machine translation results in poor convergence and high computational overhead. Our empirical analysis suggests that convergence is poor due to gradient vanishing caused by the interaction between residual connections and layer normalization. We propose depth-scaled initialization , which decreases parameter variance at the initialization stage, and reduces output variance of residual connections so as to ease gradient back-propagation through normalization layers. To address computational cost, we propose a merged attention sublayer  which combines a simplified average-based self-attention sublayer and the encoder-decoder attention sublayer on the decoder side. Results on WMT and IWSLT translation tasks with five translation directions show that deep Transformers with DS-Init and MAtt can substantially outperform their base counterpart in terms of BLEU , while matching the decoding speed of the baseline model thanks to the efficiency improvements of MAtt.\footnote{Source code for reproduction is available at \url{https://github.com/bzhangGo/zero}}  
 	Incorporating Item Response Theory  into NLP tasks can provide valuable information about model performance and behavior. 	Traditionally, IRT models are learned using human response pattern  data, presenting a significant bottleneck for large data sets like those required for training deep neural networks . 	In this work we propose learning IRT models using RPs generated from artificial crowds of DNN models. 	We demonstrate the effectiveness of learning IRT models using DNN-generated data through quantitative and qualitative analyses for two NLP tasks. 	Parameters learned from human and machine RPs for natural language inference and sentiment analysis exhibit medium to large positive correlations. 	We demonstrate a use-case for latent difficulty item parameters, namely training set filtering, and show that using difficulty to sample training data outperforms baseline methods. 	Finally, we highlight cases where human expectation about item difficulty does not match difficulty as estimated from the machine RPs. 
  	Multi-choice reading comprehension is a challenging task to select an answer from a set of candidate options when given passage and question. Previous approaches usually only calculate question-aware passage representation and ignore passage-aware question representation when modeling the relationship between passage and question, which cannot effectively capture the relationship between passage and question. In this work, we propose dual co-matching network  which models the relationship among passage, question and answer options bidirectionally. Besides, inspired by how humans solve multi-choice questions, we integrate two reading strategies into our model:  passage sentence selection that finds the most salient supporting sentences to answer the question,   answer option interaction that encodes the comparison information between answer options. DCMN equipped with the two strategies  obtains state-of-the-art results on five multi-choice reading comprehension datasets from different domains: RACE, SemEval-2018 Task 11, ROCStories, COIN, MCTest.  
 Recently we proposed the Span Attribute Tagging  Model~ to infer clinical entities  and their properties . It tackles the challenge of large label space and limited training data using a hierarchical two-stage approach that identifies the span of interest in a tagging step and assigns labels to the span in a classification step.  We extend the SAT model to jointly infer not only entities and their properties but also relations between them. Most relation extraction models restrict inferring relations between tokens within a few neighboring sentences, mainly to avoid high computational complexity. In contrast, our proposed Relation-SAT  model is computationally efficient and can infer relations over the entire conversation, spanning an average duration of 10 minutes.   We evaluate our model on a corpus of clinical conversations. When the entities are given, the R-SAT outperforms baselines in identifying relations between symptoms and their properties by about 32\%  and by about 50\%  on medications and their properties. On the more difficult task of jointly inferring entities and relations, the R-SAT model achieves a performance of 0.34 and 0.45 for symptoms and medications respectively, which is significantly better than 0.18 and 0.35 for the baseline model. The contributions of different components of the model are quantified using ablation analysis.  
  Emotion recognition in conversation  has received much attention, lately, from researchers due to its potential widespread applications in diverse areas, such as health-care, education, and human resources. In this paper, we present Dialogue Graph Convolutional Network , a graph neural network based approach to ERC. We leverage self and inter-speaker dependency of the interlocutors to model conversational context for emotion recognition. Through the graph network, DialogueGCN addresses context propagation issues present in the current RNN-based methods. We empirically show that this method alleviates such issues, while outperforming the current state of the art on a number of benchmark emotion classification datasets. 
 Aspect category detection is an essential task for sentiment analysis and opinion mining. However, the cost of categorical data labeling, e.g., label the review aspect information for a large number of product domains, can be inevitable but unaffordable. In this study, we propose a novel problem, cross-domain aspect category transfer and detection, which faces three challenges: various feature spaces, different data distributions, and diverse output spaces. To address these problems, we propose an innovative solution, Traceable Heterogeneous Graph Representation Learning . Unlike prior text-based aspect detection works, THGRL explores latent domain aspect category connections via massive user behavior information on a heterogeneous graph. Moreover, an innovative latent variable ``Walker Tracer'' is introduced to characterize the global semantic/aspect dependencies and capture the informative vertexes on the random walk paths. By using THGRL, we project different domains' feature spaces into a common one, while allowing data distributions and output spaces stay differently. Experiment results show that the proposed method outperforms a series of state-of-the-art baseline models. 
   Neural machine translation  has achieved new state-of-the-art performance in translating ambiguous words. However, it is still unclear which component dominates the process of disambiguation. In this paper, we explore the ability of NMT encoders and decoders to disambiguate word senses by evaluating hidden states and investigating the distributions of self-attention. We train a classifier to predict whether a translation is correct given the representation of an ambiguous noun. We find that encoder hidden states outperform word embeddings significantly which indicates that encoders adequately encode relevant information for disambiguation into hidden states. Decoders could provide further relevant information for disambiguation.  Moreover, the attention weights and attention entropy show that self-attention can detect ambiguous nouns and distribute more attention to the context. Note that this is a revised version of . The content related to decoder hidden states has been updated.  
 This paper explores the task of answer-aware questions generation. Based on the attention-based pointer generator model, we propose to incorporate an auxiliary task of language modeling to help question generation in a hierarchical multi-task learning structure. Our joint-learning model enables the encoder to learn a better representation of the input sequence, which will guide the decoder to generate more coherent and fluent questions. On both SQuAD and MARCO datasets, our multi-task learning model boosts the performance, achieving state-of-the-art results. Moreover, human evaluation further proves the high quality of our generated questions.  
   Image paragraph generation is the task of producing a coherent story  that describes the visual content of an image. The problem nevertheless is not trivial especially when there are multiple descriptive and diverse gists to be considered for paragraph generation, which often happens in real images. A valid question is how to encapsulate such gists/topics that are worthy of mention from an image, and then describe the image from one topic to another but holistically with a coherent structure. In this paper, we present a new design --- Convolutional Auto-Encoding  that purely employs convolutional and deconvolutional auto-encoding framework for topic modeling on the region-level features of an image. Furthermore, we propose an architecture, namely CAE plus Long Short-Term Memory , that novelly integrates the learnt topics in support of paragraph generation. Technically, CAE-LSTM capitalizes on a two-level LSTM-based paragraph generation framework with attention mechanism. The paragraph-level LSTM captures the inter-sentence dependency in a paragraph, while sentence-level LSTM is to generate one sentence which is conditioned on each learnt topic. Extensive experiments are conducted on Stanford image paragraph dataset, and superior results are reported when comparing to state-of-the-art approaches. More remarkably, CAE-LSTM increases CIDEr performance from 20.93\% to 25.15\%. 
 Language systems have been of great interest to the research community and have recently reached the mass market through various assistant platforms on the web. Reinforcement Learning methods that optimize dialogue policies have seen successes in past years and have recently been extended into methods that  the dialogue, e.g. take the personal context of users into account. These works, however, are limited to personalization to a single user with whom they require multiple interactions and do not generalize the usage of context across users. This work introduces a problem where a generalized usage of context is relevant and proposes two Reinforcement Learning -based approaches to this problem. The first approach uses a single learner and extends the traditional POMDP formulation of dialogue state with features that describe the user context. The second approach segments users by context and then employs a learner per context. We compare these approaches in a benchmark of existing non-RL and RL-based methods in three established and one novel application domain of financial product recommendation. We compare the influence of context and training experiences on performance and find that learning approaches generally outperform a handcrafted gold standard. 
 Most speech recognition tasks pertain to mapping words across two modalities: acoustic and orthographic. In this work, we suggest learning encoders that map variable-length --- acoustic or phonetic --- sequences that represent words into fixed-dimensional vectors in a shared latent space; such that the distance between two word vectors represents how closely the two words sound. Instead of directly learning the distances between word vectors, we employ weak supervision and model a binary classification task to predict whether two inputs, one of each modality, represent the same word given a distance threshold. We explore various deep-learning models, bimodal contrastive losses, and techniques for mining hard negative examples such as the semi-supervised technique of self-labeling. Our best model achieves an $F_1$ score of 0.95 for the binary classification task. 
   Dozens of countries have committed to restoring the ecological functionality of 350 million hectares of land by 2030. In order to achieve such wide-scale implementation of restoration, the values and priorities of multi-sectoral stakeholders must be aligned and integrated with national level commitments and other development agenda. Although misalignment across scales of policy and between stakeholders are well known barriers to implementing restoration, fast-paced policy making in multi-stakeholder environments complicates the monitoring and analysis of governance and policy. In this work, we assess the potential of machine learning to identify restoration policy agenda across diverse policy documents. An unsupervised neural information retrieval architecture is introduced that leverages transfer learning and word embeddings to create high-dimensional representations of paragraphs. Policy agenda labels are recast as information retrieval queries in order to classify policies with a cosine similarity threshold between paragraphs and query embeddings. This approach achieves a 0.83 F1-score measured across 14 policy agenda in 31 policy documents in Malawi, Kenya, and Rwanda, indicating that automated text mining can provide reliable, generalizable, and efficient analyses of restoration policy. 
% Social media data has evolved over recent years into a valuable platform that allows users to share various forms of information with others. % In concert with real-time streaming capabilities, social media naturally provides situation awareness and expediency in both detecting events and diffusing crises situations. Various domain users are increasingly leveraging real-time social media data to gain rapid situational awareness. However, due to the high noise in the deluge of data, effectively determining semantically relevant information can be difficult, further complicated by the changing definition of relevancy by each end user for different events. The majority of existing methods for short text relevance classification fail to incorporate users' knowledge into the classification process. Existing methods that incorporate interactive user feedback focus on historical datasets. Therefore, classifiers cannot be interactively retrained for specific events or user-dependent needs in real-time. This limits real-time situational awareness, as streaming data that is incorrectly classified cannot be corrected immediately, permitting the possibility for important incoming data to be incorrectly classified as well. We present a novel interactive learning framework to improve the classification process in which the user iteratively corrects the relevancy of tweets in real-time to train the classification model on-the-fly for immediate predictive improvements. % Specifically, we utilize Google's \textit{word2vec
  The learning rate warmup heuristic achieves remarkable success in stabilizing training, accelerating convergence and improving generalization for adaptive stochastic optimization algorithms like RMSprop and Adam. Pursuing the theory behind warmup, we identify a problem of the adaptive learning rate -- its variance is problematically large in the early stage, and presume warmup works as a variance reduction technique. We provide both empirical and theoretical evidence to verify our hypothesis. We further propose Rectified Adam , a novel variant of Adam, by introducing a term to rectify the variance of the adaptive learning rate. Experimental results on image classification, language modeling, and neural machine translation verify our intuition and demonstrate the efficacy and robustness of RAdam.\footnote{All implementations are available at: \url{https://github.com/LiyuanLucasLiu/RAdam}.}   % Here, we study its mechanism in details.  % This paper presents the theoretical justification of the heuristic, showing that its effectiveness is due to the fact that it reduces the problematically large variance of the adaptive learning rate in the early stage.  %Further analysis derives a reliable and concise variance approximation, and we propose Rectified Adam, % \XD{What RAdam refers to? rectified Adam?} %a new variant of the Adam algorithm which rectifies the variance of the adaptive learning rate. %We conduct experiments on various datasets and observe that RAdam leads to consistent improvements over the vanilla Adam, which demonstrates that the variance issue generally exists and affects training stability and model performance}. % \XD{Font of x-y axis is too small and hard to see. Pls make it bigger.} % and fixing such issues leads to better robustness and efficiency.  
 Vision-and-Language Navigation  tasks such as Room-to-Room  require machine agents to interpret natural language instructions and learn to act in visually realistic environments to achieve navigation goals. The overall task requires competence in several perception problems: successful agents combine spatio-temporal, vision and language understanding to produce appropriate action sequences. Our approach adapts pre-trained vision and language representations to relevant in-domain tasks making them more effective for VLN. Specifically, the representations are adapted to solve both a cross-modal sequence alignment and sequence coherence task. In the sequence alignment task, the model determines whether an instruction corresponds to a sequence of visual frames. In the sequence coherence task, the model determines whether the perceptual sequences are predictive sequentially in the instruction-conditioned latent space. By transferring the domain-adapted representations, we improve competitive agents in R2R as measured by the success rate weighted by path length  metric. 
  The emergence of online services in our daily lives has been accompanied by a range of malicious attempts to trick individuals into performing undesired actions, often to the benefit of the adversary. The most popular medium of these attempts is phishing attacks, particularly through emails and websites. In order to defend against such attacks, there is an urgent need for automated mechanisms to identify this malevolent content before it reaches users. Machine learning techniques have gradually become the standard for such classification problems. However, identifying common measurable features of phishing content  is notoriously difficult. To address this problem, we engage in a novel study into a phishing content classifier based on a recurrent neural network , which identifies such features without human input. At this stage, we scope our research to emails, but our approach can be extended to apply to websites. Our results show that the proposed system outperforms state-of-the-art tools. Furthermore, our classifier is efficient and takes into account only the text and, in particular, the textual structure of the email. Since these features are rarely considered in email classification, we argue that our classifier can complement existing classifiers with high information gain.   
 Neural text generation is a key tool in natural language applications,  but it is well known there are major problems at its core. In  particular, standard likelihood training and decoding leads to  dull and repetitive outputs .  While some post-hoc fixes have been proposed, in particular top-$k$ and nucleus sampling, they do not address the fact that the token-level  probabilities predicted by the model are poor. In this paper we show that the likelihood objective itself is at fault, resulting in a  model that assigns too much probability to sequences containing repeats and  frequent words,  unlike those from the human training distribution. We propose a new objective, unlikelihood training, which forces unlikely generations to be assigned lower probability by the model. We show that both token and sequence level unlikelihood training give less repetitive, less dull text while maintaining perplexity, giving superior generations using standard greedy or beam search. According to human evaluations,  our approach with standard beam search also outperforms the currently popular decoding methods of nucleus sampling or beam blocking, thus providing a strong alternative to existing techniques.  
 Sex trafficking is a global epidemic. Escort websites are a primary vehicle for selling the services of such trafficking victims and thus a major driver of trafficker revenue. Many law enforcement agencies do not have the resources to manually identify leads from the millions of escort ads posted across dozens of public websites. We propose an ordinal regression neural network to identify escort ads that are likely linked to sex trafficking. Our model uses a modified cost function to mitigate inconsistencies in predictions often associated with nonparametric ordinal regression and leverages recent advancements in deep learning to improve prediction accuracy. The proposed method significantly improves on the previous state-of-the-art on Trafficking-10K, an expert-annotated dataset of escort ads. Additionally, because traffickers use acronyms, deliberate typographical errors, and emojis to replace explicit keywords, we demonstrate how to expand the lexicon of trafficking flags through word embeddings and t-SNE. 
  A large percentage of medical information is in unstructured text format in electronic medical record systems. Manual extraction of information from clinical notes is extremely time consuming. Natural language processing has been widely used in recent years for automatic information extraction from medical texts. However, algorithms trained on data from a single healthcare provider are not generalizable and error-prone due to the heterogeneity and uniqueness of medical documents. We develop a two-stage federated natural language processing method that enables utilization of clinical notes from different hospitals or clinics without moving the data, and demonstrate its performance using obesity and comorbities phenotyping as medical task. This approach not only improves the quality of a specific clinical task but also facilitates knowledge progression in the whole healthcare system, which is an essential part of learning health system. To the best of our knowledge, this is the first application of federated machine learning in clinical NLP. 
 Relation extraction aims to extract relational facts from sentences. Previous models mainly rely on manually labeled datasets, seed instances or human-crafted patterns, and distant supervision. However, the human annotation is expensive, while human-crafted patterns suffer from semantic drift and distant supervision samples are usually noisy. Domain adaptation methods enable leveraging labeled data from a different but related domain. However, different domains usually have various textual relation descriptions and different label space .  To solve these problems,  we propose a novel model of  relation-gated adversarial learning   for relation extraction, which extends the adversarial based domain adaptation.  Experimental results have shown that the proposed approach outperforms previous domain adaptation methods regarding partial domain adaptation and can improve the accuracy of distance supervised relation extraction through fine-tuning. 
 Text classification tends to be difficult when data are deficient or when it is required to adapt to unseen classes. In such challenging scenarios, recent studies have often used meta-learning to simulate the few-shot task, thus negating implicit common linguistic features across tasks. This paper addresses such problems using meta-learning and unsupervised language models. Our approach is based on the insight that having a good generalization from a few examples relies on both a generic model initialization and an effective strategy for adapting this model to newly arising tasks.  We show that our approach is not only simple but also produces a state-of-the-art performance on a well-studied sentiment classification dataset. It can thus be further suggested that pretraining could be a promising solution for few-shot learning of many other NLP tasks.  The code and the dataset to replicate the experiments are made available at \url{https://github.com/zxlzr/FewShotNLP}. 
We implement a method for re-ranking top-10 results of a state-of-the-art question answering  system. 	The goal of our re-ranking approach is to improve the answer selection given the user question and the top-10 candidates. 	We focus on improving deployed QA systems that do not allow re-training or when re-training comes at a high cost. 	Our re-ranking approach learns a similarity function using n-gram based features using the query, the answer and the initial system confidence as input. 	% 	Our contributions are: 	 we generate a QA training corpus starting from 877 answers from the customer care domain of T-Mobile Austria,  	 we implement a state-of-the-art QA pipeline using neural sentence embeddings that encode queries in the same space than the answer index, and 	 we evaluate the QA pipeline and our re-ranking approach using a separately provided test set. 	The test set can be considered to be available after deployment of the system, e.g., based on feedback of users. 	% 	Our results show that the system performance, in terms of top-n accuracy and the mean reciprocal rank, benefits from re-ranking using gradient boosted regression trees. On average, the mean reciprocal rank improves by $9.15\%$.
 Training chatbots using the reinforcement learning paradigm is challenging due to high-dimensional states, infinite action spaces and the difficulty in specifying the reward function. We address such problems using clustered actions instead of infinite actions, and a simple but promising reward function based on human-likeness scores derived from human-human dialogue data. We train Deep Reinforcement Learning  agents using chitchat data in raw text---without any manual annotations. Experimental results using different splits of training data report the following. First, that our agents learn reasonable policies in the environments they get familiarised with, but their performance drops substantially when they are exposed to a test set of unseen dialogues. Second, that the choice of sentence embedding size between 100 and 300 dimensions is not significantly different on test data. Third, that our proposed human-likeness rewards are reasonable for training chatbots as long as they use lengthy dialogue histories of $\geq$10 sentences. 
 \textcolor{black}{Trainable chatbots that exhibit fluent and human-like conversations remain a big challenge in artificial intelligence. Deep Reinforcement Learning  is promising for addressing this challenge, but its successful application remains an open question.} This article describes a novel ensemble-based approach applied to value-based DRL chatbots, which use finite action sets as a form of meaning representation. In our approach, while dialogue actions are derived from sentence clustering, the training datasets in our ensemble are derived from dialogue clustering. The latter aim to induce specialised agents that learn to interact in a particular style. In order to facilitate neural chatbot training using our proposed approach, we assume dialogue data in raw text only -- without any manually-labelled data. \textcolor{black}{Experimental results using chitchat data reveal that  near human-like dialogue policies can be induced,  generalisation to unseen data is a difficult problem, and  training an ensemble of chatbot agents is essential for improved performance over using a single agent. In addition to evaluations using held-out data, our results are further supported by a human evaluation that rated dialogues in terms of fluency, engagingness and consistency -- which revealed that our proposed dialogue rewards strongly correlate with human judgements.\footnote{https://doi.org/10.1016/j.neucom.2019.08.007}} 
 Recurrent Neural Network  has been widely used to tackle a wide variety of language generation problems and are capable of attaining state-of-the-art  performance. However despite its impressive results, the large number of parameters in the RNN model makes deployment in mobile and embedded devices infeasible. Driven by this problem, many works have proposed a number of pruning methods to reduce the sizes of the RNN model. In this work, we propose an end-to-end pruning method for image captioning models equipped with visual attention. Our proposed method is able to achieve sparsity levels up to $97.5\%$ without significant performance loss relative to the baseline . Our method is also simple to use and tune, facilitating faster development times for neural network practitioners. We perform extensive experiments on the popular MS-COCO dataset in order to empirically validate the efficacy of our proposed method. 
 Textual network embeddings aim to learn a low-dimensional representation for every node in the network so that both the structural and textual information from the networks can be well preserved in the representations. Traditionally, the structural and textual embeddings were learned by models that rarely take the mutual influences between them into account. In this paper, a deep neural architecture is proposed to effectively fuse the two kinds of informations into one representation. The novelties of the proposed architecture are manifested in the aspects of a newly defined objective function, the complementary information fusion method for structural and textual features, and the mutual gate mechanism for textual feature extraction. Experimental results show that the proposed model outperforms the comparing methods on all three datasets. 
 Recent successes in language modeling, notably with deep learning methods, coincide with a shift from probabilistic to weighted representations. We raise here the question of the importance of this evolution, in the light of the practical limitations of a classical and simple probabilistic modeling approach for the classification of protein sequences and in relation to the need for principled methods to learn non-probabilistic models. 
   Speaker embeddings become growing popular in the text-independent speaker verification task.    %An embedding is a high-representation vector of an utterance, generally, a deep neural network  is trained for classifying different speakers in a closed training-set by using softmax, and then the output of one hidden layer is taken as an embedding.    %As a backend system, the standard Linear Discriminant Analysis  followed by the Probabilistic Linear Discriminant Analysis  is a common method for making confidence scores of trials.  In this paper, we propose two improvements during the training stage. The improvements are both based on triplet cause the training stage and the evaluation stage of the baseline x-vector system focus on different aims.   Firstly, we introduce triplet loss for optimizing the Euclidean distances between embeddings while minimizing the multi-class cross entropy loss. Secondly, we design an embedding similarity measurement network for controlling the similarity between the two selected embeddings. We further jointly train the two new methods with the original network and achieve state-of-the-art.    %Confidence scores of trials are made by the standard Linear Discriminant Analysis  followed by the Probabilistic Linear Discriminant Analysis .   The multi-task training synergies are shown with a 9\% reduction equal error rate  and detected cost function  on the 2016 NIST Speaker Recognition Evaluation  Test Set.    
 This paper presents our latest investigation on end-to-end automatic speech recognition  for overlapped speech. We propose to train an end-to-end system conditioned on speaker embeddings and further improved by transfer learning from clean speech. This proposed framework does not require any parallel non-overlapped speech materials and is independent of the number of speakers. Our experimental results on overlapped speech datasets show that joint conditioning on speaker embeddings and transfer learning significantly improves the ASR performance. 
 Text classification has been one of the major problems in natural language processing. With the advent of deep learning, convolutional neural network  has been a popular solution to this task. However, CNNs which were first proposed for images, face many crucial challenges in the context of text processing, namely in their elementary blocks: convolution filters and max pooling. These challenges have largely been overlooked by the most existing CNN models proposed for text classification. In this paper, we present an experimental study on the fundamental blocks of CNNs in text categorization. Based on this critique, we propose Sequential Convolutional Attentive Recurrent Network . The proposed SCARN model utilizes both the advantages of recurrent and convolutional structures efficiently in comparison to previously proposed recurrent convolutional models. We test our model on different text classification datasets across tasks like sentiment analysis and question classification. Extensive experiments establish that SCARN outperforms other recurrent convolutional architectures with significantly less parameters. Furthermore, SCARN achieves better performance compared to equally large various deep CNN and LSTM architectures.% with approximately matching number of parameters. 
 Recurrent neural networks can learn to predict upcoming words remarkably well on average; in syntactically complex contexts, however, they often assign unexpectedly high probabilities to ungrammatical words. We investigate to what extent these shortcomings can be mitigated by increasing the size of the network and the corpus on which it is trained. We find that gains from increasing network size are minimal beyond a certain point. Likewise, expanding the training corpus yields diminishing returns; we estimate that the training corpus would need to be unrealistically large for the models to match human performance. A comparison to GPT and BERT, Transformer-based models trained on billions of words, reveals that these models perform even more poorly than our LSTMs in some constructions. Our results make the case for more data efficient architectures. 
     Deep neural networks  can fit  the training data very well. If a DNN model is trained using data with noisy labels and tested on data with clean labels, the model may perform poorly. This paper studies the problem of learning with noisy labels for sentence-level sentiment classification. We propose a novel DNN model called NetAb  to handle noisy labels during training. NetAb consists of two convolutional neural networks, one with a noise transition layer for dealing with the input noisy labels and the other for predicting `clean' labels. We train the two networks using their respective loss functions in a mutual reinforcement manner. Experimental results demonstrate the effectiveness of the proposed model. %   Deep learning  models can fit  training data very well. If training data are corrupted with noisy  labels and a DL model is trained using such noisy training data, the model can memorize these noisy labels after training. When the trained model is tested on clean data, it performs badly, see Figure \ref{fig1}. This paper studies the problem of learning with noisy labels for sentence-level sentiment classification. We propose a deep neural Networks with an Absorber layer to absorb noisy labels. 
 Deep reinforcement learning  has been a commonly-used strategy for the abstractive summarization task to address both the exposure bias and non-differentiable task issues. However, the conventional reward Rouge-L simply looks for exact n-grams matches between candidates and annotated references, which inevitably makes the generated sentences repetitive and incoherent. In this paper, instead of Rouge-L, we explore the practicability of utilizing the distributional semantics to measure the matching degrees. With distributional semantics, sentence-level evaluation can be obtained, and semantically-correct phrases can also be generated without being limited to the surface form of the reference sentences. Human judgments on Gigaword and CNN/Daily Mail datasets show that our proposed distributional semantics reward  has distinct superiority in capturing the lexical and compositional diversity of natural language.  %Deep reinforcement learning  has been a commonly-used strategy for the abstractive summarization task to address both the exposure bias and non-differentiable task issues. However, the conventional reward ROUGE-L simply looks for exact n-grams matches between candidates and annotated references, which inevitably makes the generated sentences repetitive and incoherent. In this paper, instead of ROUGE-L, we explore the practicability of utilizing the distributional semantics to measure the matching degrees. Not only it can provide sentence level evaluation, but also semantically-correct phrases can be generated without being limited to the surface form of the reference sentences. Human judgments on Gigaword corpus show that our proposed distributional semantics reward  has distinct superiority in capturing the lexical and compositional diversity of natural language, while reducing the sample complexity of RL algorithm. 
  Prior work on pretrained sentence embeddings and benchmarks focuses on the capabilities of representations for stand-alone sentences.  We propose \disceval, a test suite of tasks to evaluate whether sentence representations include information about the role of a sentence in its discourse context. We also propose a variety of training objectives that make use of natural annotations from Wikipedia to build sentence encoders capable of modeling discourse information.  We benchmark sentence encoders trained with our proposed objectives, as well as other popular pretrained sentence encoders, on \disceval and other sentence evaluation tasks. Empirically, we show that these training objectives help to encode different aspects of information from the surrounding document structure. Moreover,  and {}.}  
 	Contextual word embeddings  have demonstrated state-of-the-art performance on various NLP tasks. Recent work with the multilingual version of BERT has shown that the model performs very well in zero-shot and zero-resource cross-lingual settings, where only labeled English data is used to finetune the model. We improve upon multilingual BERT's zero-resource cross-lingual performance via adversarial learning. We report the magnitude of the improvement on the multilingual MLDoc text classification and CoNLL 2002/2003 named entity recognition tasks. Furthermore, we show that language-adversarial training encourages BERT to align the embeddings of English documents and their translations, which may be the cause of the observed performance gains. 
 Cross-lingual summarization  is the task to produce a summary in one particular language for a source document in a different language. Existing methods simply divide this task into two steps: summarization and translation, leading to the problem of error propagation. To handle that, we present an end-to-end CLS framework, which we refer to as Neural Cross-Lingual Summarization , for the first time. Moreover, we propose to further improve NCLS by incorporating two related tasks, monolingual summarization and machine translation, into the training process of CLS under multi-task learning. Due to the lack of supervised CLS data, we propose a round-trip translation strategy to acquire two high-quality large-scale CLS datasets based on existing monolingual summarization datasets. Experimental results have shown that our NCLS achieves remarkable improvement over traditional pipeline methods on both English-to-Chinese and Chinese-to-English CLS human-corrected test sets. In addition, NCLS with multi-task learning can further significantly improve the quality of generated summaries. We make our dataset and code publicly available here: \url{http://www.nlpr.ia.ac.cn/cip/dataset.htm}. 
  Many pledges are made in the course of an election campaign, forming important corpora for political analysis of campaign strategy and governmental accountability.  At present, there are no publicly available annotated datasets of pledges, and most political analyses rely on manual analysis. In this paper we collate a novel dataset of manifestos from eleven Australian federal election cycles, with over 12,000 sentences annotated with specificity  on a fine-grained scale. We propose deep ordinal regression approaches for specificity prediction, under both supervised and semi-supervised settings, and provide empirical results demonstrating the effectiveness of the proposed techniques over several baseline approaches. We analyze the utility of pledge specificity modeling across a spectrum of policy issues in performing ideology prediction, and further provide qualitative analysis in terms of capturing party-specific issue salience across election cycles. 
   Multi-head attention advances neural machine translation by working out multiple versions of attention in different subspaces, but the neglect of semantic overlapping between subspaces increases the difficulty of translation and consequently hinders the further improvement of translation performance. In this paper, we employ capsule networks to comb the information from the multiple heads of the attention so that similar information can be clustered and unique information can be reserved. To this end, we adopt two routing mechanisms of Dynamic Routing and EM Routing, to fulfill the clustering and separating. We conducted experiments on Chinese-to-English and English-to-German translation tasks and got consistent improvements over the strong Transformer baseline.                  
 The pre-trained language models have achieved great successes in various natural language understanding  tasks due to its capacity to capture the deep contextualized information in text by pre-training on large-scale corpora. In this technical report, we present our practice of pre-training language models named NEZHA  on Chinese corpora and finetuning for the Chinese NLU tasks. The current version of NEZHA is based on BERT~ with a collection of proven improvements, which include  as an effective positional encoding scheme,  strategy,  and the  in training the models. The experimental results show that NEZHA achieves the state-of-the-art performances when finetuned on several representative Chinese tasks, including named entity recognition , sentence matching , Chinese sentiment classification  and natural language inference .  %We release the source code and the pre-trained models at {this https URL}. 
  Standard accuracy metrics indicate that modern reading comprehension systems have achieved strong performance in many question answering datasets.  However, the extent these systems truly understand language remains unknown, and existing systems are not good at distinguishing distractor sentences, which look related but do not actually answer the question. To address this problem, we propose QAInfomax as a regularizer in reading comprehension systems by maximizing mutual information among passages, a question, and its answer.  QAInfomax helps regularize the model to not simply learn the superficial correlation for answering questions. The experiments show that our proposed QAInfomax achieves the state-of-the-art performance on the benchmark Adversarial-SQuAD dataset\footnote{The source code is publicly available at \url{https://github.com/MiuLab/QAInfomax}.}.   
     Document-level relation extraction is a complex human process that requires logical inference to extract relationships between named entities in text.      Existing approaches use graph-based neural models with words as nodes and edges as relations between them, to encode relations across sentences. These models are node-based, i.e., they form pair representations based solely on the two target node representations. However, entity relations can be better expressed through unique edge representations formed as paths between  nodes. We thus propose an edge-oriented graph neural model for document-level relation extraction. The model utilises different types of nodes and edges to create a document-level graph. An inference mechanism on the graph edges enables to learn intra- and inter-sentence relations using multi-instance learning internally. Experiments on two document-level biomedical datasets for chemical-disease and gene-disease associations show the usefulness of the proposed edge-oriented approach.\footnote{Source code available at \url{https://github.com/fenchri/edge-oriented-graph}} 
   Aspect based sentiment analysis  aims to identify the sentiment polarity towards the given aspect in a sentence, while previous models typically exploit an aspect-independent  encoder for sentence representation generation. In this paper, we propose a novel Aspect-Guided Deep Transition model, named AGDT, which utilizes the given aspect to guide the sentence encoding from scratch with the specially-designed deep transition architecture. Furthermore, an aspect-oriented objective is designed to enforce AGDT to reconstruct the given aspect with the generated sentence representation. In doing so, our AGDT can accurately generate aspect-specific sentence representation, and thus conduct more accurate sentiment predictions. Experimental results on multiple SemEval datasets demonstrate the effectiveness of our proposed approach, which significantly outperforms the best reported results with the same setting\footnote{The code is publicly available at: \url{https://github.com/XL2248/AGDT}}. %and achieves competitive performances on multiple SemEval datasets. 
  % Although neural machine translation  has advanced the state-of-the-art on various language pairs, the interpretability of NMT remains unsatisfactory.  % In this work, we propose to address this gap by focusing on understanding the input-output behavior of NMT models. Specifically, we measure the word importance by attributing the NMT output to every input word with a gradient-based method. % We validate the approach on a couple of perturbation operations, languages pairs, and model architectures, demonstrating its superiority on identifying input words with higher influence on translation performance.  % Encouragingly, the calculated importance can serve as indicators of input words that are under-translated by NMT models. % Furthermore, our analysis reveals that words of certain syntactic categories have higher importance while the categories vary across languages, which can inspire better design principles of NMT architectures for multi-lingual translation.  Although neural machine translation  has advanced the state-of-the-art on various language pairs, the interpretability of NMT remains unsatisfactory. In this work, we propose to address this gap by focusing on understanding the input-output behavior of NMT models. Specifically, we measure the word importance by attributing the NMT output to every input word through a gradient-based method. We validate the approach on a couple of perturbation operations, language pairs, and model architectures, demonstrating its superiority on identifying input words with higher influence on translation performance. Encouragingly, the calculated importance can serve as indicators of input words that are under-translated by NMT models. Furthermore, our analysis reveals that words of certain syntactic categories have higher importance while the categories vary across language pairs, which can inspire better design principles of NMT architectures for multi-lingual translation.  %%%%%%%%%%%% %Specifically, we attribute the NMT output to input sentences with a gradient-based method, which is used to measure the importance of each input word on translation performance. % that some words  indeed affect the translation performance more notably than others.  % Using the notion of word importance, we find that the calculated importance   words with lower importance are generally ignored by NMT models, suggesting . %For example, nouns are more important for Chinese-English translation, while prepositions are more important for English-French and -Japanese translation. % \zptu{what is the benefit of the finding?}    % . \zptu{why should from input side?} % % pointing to the set of what we call important words in the input sentence. % Specifically, we  measure the word importance by attributing the generation of translation to every input word with a gradient-based method. Experiments across language pairs and NMT models demonstrate that the identified set of important words indeed affect the translation performance more notably than the rest words.  % Linguistic analyses reveal that different types of words play different roles across language pairs . % Motivated by the findings of our analysis, we propose an importance indicator for each input word, which leads to significant improvement in translation quality.  %Moreover, we probe into the word importance thoroughly from the linguistic perspective and obtained some interesting findings, which might guide the improvement and debugging of NMT models.  % We expect this study can shed light on the understanding of NMT models at the lexical level. % \fi  
 %         % Our results provide strong insight into how applicable the representations learned from multilingual machine translation are, across languages and tasks.    %   The recently proposed Massively Multilingual Neural Machine Translation system has been shown to be capable of translating 102 languages to and from English within a single model . In this paper, we investigate and evaluate the cross-lingual effectiveness of representations from the encoder of such a translation model on 5 downstream classification and sequence labeling tasks on a diverse set of over 50 languages. We compare against a strong multilingual baseline, BERT  trained on 104 languages in different cross-lingual transfer learning scenarios and show gains in zero-shot transfer in 4 out of these 5 tasks.        The recently proposed massively multilingual neural machine translation  system has been shown to be capable of translating over 100 languages to and from English within a single model . Its improved translation performance on low resource languages hints at potential cross-lingual transfer capability for downstream tasks. In this paper, we evaluate the cross-lingual effectiveness of representations from the encoder of a massively multilingual NMT model on 5 downstream classification and sequence labeling tasks covering a diverse set of over 50 languages. We compare against a strong baseline, multilingual BERT  , in different cross-lingual transfer learning scenarios and show gains in zero-shot transfer in 4 out of these 5 tasks.        % Alternate version by Naveen and Melvin.      % It demonstrates large improvements on low resource NMT which suggests that it is effectively able to learn transferable representations.      % Multilingual NMT has been shown to be effective at learning cross-lingual representations as evidenced by improved performance on low resource languages. More recently, work on Massively Multilingual Neural Machine Translation systems have shown that this transfer can be achieved on over 100 languages within a single model . In this paper, we investigate and evaluate the cross-lingual effectiveness of representations from the encoder of such a translation model on 5 downstream classification and sequence labeling tasks on a diverse set of over 50 languages. We compare against a strong multilingual baseline, BERT  trained on 104 languages in different cross-lingual transfer learning scenarios and show gains in zero-shot transfer in 4 out of these 5 tasks.          % Multilingual BERT , trained on 104 languages, has shown to be capable of cross-lingual transfer learning on many NLP tasks. Recently, a single massively multilingual neural machine translation  model has been shown to be capable of translating between 102 languages~. While mBERT leverages unsupervised monolingual data using a masking objective, the translation models leverage parallel data that is potentially more useful for cross-lingual transfer learning. In this paper, we compare representations from a massively multilingual translation encoder  to mBERT on five downstream classification and sequence labeling tasks on a diverse set of over 50 languages in different cross-lingual transfer learning scenarios. We find that MMTE outperforms mBERT on most setups suggesting that parallel data leveraged in a suitable objective is effective for cross-lingual transfer.          % Many NLP tasks have data only in English and rely on translation systems for internationalization. Recently an array of approaches have been developed to enable this transfer in an intermediate latent space by learning cross-lingual representations. Multilingual BERT , trained on 104 languages, has obtained impressive cross-lingual transfer performance on many NLP tasks. In this paper we evaluate the intermediate representations extracted from a massively multilingual translation encoder  on five downstream classification and sequence labeling tasks on a diverse set of over 50 languages in different cross-lingual transfer learning scenarios. We find that MMTE which uses the good old translation objective and data outperforms alternative specialized approaches to learn cross-lingual representations.            
 We introduce a novel discriminative word alignment model, which we integrate into a Transformer-based machine translation model.  In experiments based on a small number of labeled examples  we evaluate its performance intrinsically on both English-Chinese and English-Arabic alignment, where we achieve major improvements over unsupervised baselines . We evaluate the model extrinsically on data projection for Chinese NER, showing that our alignments lead to higher performance when used to project NER tags from English to Chinese. Finally, we perform an ablation analysis and an annotation experiment that jointly support the utility and feasibility of future manual alignment elicitation.  
   In recent years, several studies on neural machine translation  have attempted to use document-level context by using a multi-encoder and two attention mechanisms to read the current and previous sentences to incorporate the context of the previous sentences.   These studies concluded that the target-side context is less useful than the source-side context.   However, we considered that the reason why the target-side context is less useful lies in the architecture used to model these contexts.    Therefore, in this study, we investigate how the target-side context can improve context-aware neural machine translation.   We propose a weight sharing method wherein NMT saves decoder states and calculates an attention vector using the saved states when translating a current sentence.   Our experiments show that the target-side context is also useful if we plug it into NMT as the decoder state when translating a previous sentence.  
 Context modeling is essential to generate coherent and consistent translation for Document-level Neural Machine Translations. The widely used method for document-level translation usually compresses the context information into a representation via hierarchical attention networks. However, this method neither considers the relationship between context words nor distinguishes the roles of context words. To address this problem, we propose a query-guided capsule networks to cluster context information into different perspectives from which the target translation may concern. Experiment results show that our method can significantly outperform strong baselines on multiple data sets of different domains.   
 Enriching existing medical terminology knowledge bases  is an important and never-ending work for clinical research because new terminology alias may be continually added and standard terminologies may be newly renamed. In this paper, we propose a novel automatic terminology enriching approach to supplement a set of terminologies to KBs. Specifically, terminology and entity characters are first fed into pre-trained language model to obtain semantic embedding. The pre-trained model is used again to initialize the terminology and entity representations, then they are further embedded through graph convolutional network to gain structure embedding. Afterwards, both semantic and structure embeddings are combined to measure the relevancy between the terminology and the entity. Finally, the optimal alignment is achieved based on the order of relevancy between the terminology and all the entities in the KB. Experimental results on clinical indicator terminology KB, collected from 38 top-class hospitals of Shanghai Hospital Development Center, show that our proposed approach outperforms baseline methods and can effectively enrich the KB.  % Enriching existing medical terminology knowledge bases  is an important and never-ending work for clinical research, since new terminology alias may be supplemented and standard terminologies may be renamed. However, existing well-known KBs, such as SNOMED-CT, manually complete the task, which consume large amount of time and labor. In this paper, we propose a novel automatic terminology enriching approach to align a set of terminologies to KBs. Specifically, the terminology and entity characters are first fed into pre-trained language model to obtain semantic embedding. Then the terminology and entity representations are initialized by the pre-trained model, and are further embedded through graph convolutional network to gain structure embedding. Finally, the semantic and structure embeddings are integrated to measure the relevancy between the terminology and the entity. The optimal alignment is acquired by ranking the relevancy between the terminology and all the entities in the KB. Experimental results on real-world dataset show that the proposed approach outperforms other baseline methods. %The closet task is entity alignment, which aligns between different KBs, but the enriching task aims to align a set of terminologies to terminology KBs.% 
 Recognizing affective events that trigger positive or negative sentiment has a wide range of natural language processing applications but remains a challenging problem mainly because the polarity of an event is not necessarily predictable from its constituent words. In this paper, we propose to propagate affective polarity using discourse relations. Our method is simple and only requires a very small seed lexicon and a large raw corpus. % Experiments show that our method learns affective events effectively without manually labeled data. Our experiments using Japanese data show that our method learns affective events effectively without manually labeled data. It also improves supervised learning results when labeled data are small. 
  In medical documents, it is possible that an entity of interest not only contains a discontiguous sequence of words but also overlaps with another entity.  Entities of such structures are intrinsically hard to recognize due to the large space of possible entity combinations.  In this work, we propose a neural two-stage approach to recognizing discontiguous and overlapping entities by decomposing this problem into two subtasks:  1) it first detects all the overlapping spans that either form entities on their own or present as segments of discontiguous entities, based on the representation of segmental hypergraph,  2) next it learns to combine these segments into discontiguous entities with a classifier, which filters out other incorrect combinations of segments.   Two neural components are designed for these subtasks respectively and they are learned jointly using a shared encoder for text.  %Empirical results show that our model achieves a significant improvement compared with previous methods,  Our model achieves the state-of-the-art performance in a standard dataset,  even in the absence of external features that previous methods used.  
 Conventional Neural Machine Translation  models benefit from the training with an additional agent, e.g., dual learning, and bidirectional decoding with one agent decoding from left to right and the other decoding in the opposite direction. In this paper, we extend the training framework to the multi-agent scenario by introducing diverse agents in an interactive updating process. At training time, each agent learns advanced knowledge from others, and they work together to improve translation quality. Experimental results on NIST Chinese-English, IWSLT 2014 German-English, WMT 2014 English-German and large-scale Chinese-English translation tasks indicate that our approach achieves absolute improvements over the strong baseline systems and shows competitive performance on all tasks. 
  The French TARPON project aims to build a national injury surveillance system based on emergency room  visit reports. To this end, it is necessary to develop a coding system capable of classifying the causes of these visits based on clinical notes in French written by emergency room clinicians. While supervised learning techniques have shown good results in this area, they require manual annotation of large number of texts in order to build a sufficiently large labeled training dataset. Over the past two years, new levels of performance have been achieved in neural language models  with Transformer architecture based models by incorporating an unsupervised generative pre-training step. Our hypothesis is that methods involving a generative self-supervised pre-training step can significantly reduce the number of annotated samples required for the supervised fine-tuning phase.  We aimed to measure the gain in terms of manual annotation load obtained by adopting this pre-training step.  To test our hypothesis, we exploited the fact that we could derive the traumatic/non-traumatic nature of the cause of the ER visit from available diagnostic codes. We then designed a case study to predict from free-text clinical notes whether a given ER visit was the consequence of a traumatic or a non-traumatic event. We compared two scenarios: Scenario A consisted in training the GPT-2 NLM on a trauma/non-trauma labeled dataset  in a single fully-supervised phase. In Scenario B, we split the training dataset in two parts, a large unlabeled one of $151\,930$ for the self-supervised pre-training phase and a much smaller labeled dataset  for the supervised fine-tuning. In both scenarios, the GPT-2 model is trained from scratch.   In Scenario A, AUC and F1 score reach the values of $0.979$ and $0.908$ respectively after the processing of the $161\,930$ labeled notes. The use of generative pre-training  achieved an AUC of $0.949$ and an F1 score of $0.852$ after the processing of only 600 labeled clinical notes. To achieve the same performance, $6\,000$ labeled clinical notes had to be processed in Scenario A.  To conclude, it is possible to easily adapt a multi-purpose NLM model such as the GPT-2 to create a powerful tool for classification of free-text notes with only a very small number of labeled samples.  
  based document summarisation systems yield state-of-the-art performance in terms  of ROUGE scores, because %most RL systems  they directly use ROUGE as the  during training. % However, summaries with high ROUGE scores often receive low human judgement. % To find a better reward function that can guide RL to generate human-appealing  %high-human-judgement  summaries, % with high human judgement scores, we learn a reward function from human ratings on 2,500 summaries.  % %We perform the reward learning on a recent dataset that includes %human ratings on 2500 summaries for 500 news articles from %CNN/DailyMail. % Our reward function %does not require reference summaries and  only takes the document and system summary as input. Hence, once trained, it can be used to train RL-based summarisation systems without using any reference summaries. % We show that our learned rewards have significantly higher correlation with human ratings than previous approaches. %strong baselines. Human evaluation experiments show that, compared to the state-of-the-art supervised-learning systems and ROUGE-as-rewards RL summarisation systems, the RL systems using our learned rewards during training generate summaries with higher human ratings. % The learned reward function and our source code %and the supplementary materials  are available at  \url{https://github.com/yg211/summary-reward-no-reference}.   
         This study proposes a Neural Attentive Bag-of-Entities model, which is a neural network model that performs text classification using entities in a knowledge base.         Entities provide unambiguous and relevant semantic signals that are beneficial for capturing semantics in texts.         We combine simple high-recall entity detection based on a dictionary, to detect entities in a document, with a novel neural attention mechanism that enables the model to focus on a small number of unambiguous and relevant entities.         We tested the effectiveness of our model using two standard text classification datasets  and a popular factoid question answering dataset based on a trivia quiz game.         As a result, our model achieved state-of-the-art results on all datasets.         The source code of the proposed model is available online at \url{https://github.com/wikipedia2vec/wikipedia2vec}.     
  Modern sentence-level NMT systems often produce plausible translations of isolated sentences.  However, when put in context, these translations may end up being inconsistent with each other.  We propose a monolingual DocRepair model to correct inconsistencies between sentence-level translations. DocRepair performs automatic post-editing on a sequence of sentence-level translations, refining translations of sentences in context of each other. For training, the DocRepair model requires only monolingual document-level data in the target language. It is trained as a monolingual sequence-to-sequence model that maps inconsistent groups of sentences into consistent ones. The consistent groups come from the original training data; the inconsistent groups are obtained by sampling round-trip translations for each isolated sentence. We show that this approach successfully imitates inconsistencies we aim to fix: using contrastive evaluation, we show large improvements in the translation of several contextual phenomena in an English$\to$Russian translation task, as well as improvements in the BLEU score. We also conduct a human evaluation and show a strong preference of the annotators to corrected translations over the baseline ones. Moreover, we analyze which discourse phenomena are hard to capture using monolingual data only.\footnote{The code and data sets  are available at \url{https://github.com/lena-voita/good-translation-wrong-in-context}.}  
 Whereas traditional cryptography encrypts a secret message into an unintelligible form, steganography conceals that communication is taking place by encoding a secret message into a cover signal. Language is a particularly pragmatic cover signal due to its benign occurrence and independence from any one medium. Traditionally, linguistic steganography systems encode secret messages in existing text via synonym substitution or word order rearrangements. Advances in neural language models enable previously impractical generation-based techniques. We propose a steganography technique based on arithmetic coding with large-scale neural language models. We find that our approach can generate realistic looking cover sentences as evaluated by humans, while at the same time preserving security by matching the cover message distribution with the language model distribution. %We find that the approach achieves close to theoretical bounds in terms of compression, and can fool human evaluators.   %Unlike traditional cryptography which encrypts a secret message into an unintelligible form, steganography conceals the fact that communication is taking place at all by encoding a secret message into a natural-seeming carrier signal. In this work we propose generative word-choice steganography in which a secret message is encoded in the choices a generative model for text makes during generation. To ensure that a third-party is unable to tell the difference between the encoded message and human written text, we leverage recent advancements in scaling large pretrained language models to formulate and approach this problem. We develop a theoretical framework which connects intuitions about entropy and information with the realities of steganography and use it to derive performance bounds. We propose specific tractable algorithms within this framework, and in experiments show the trade-off between words/bit and security and quantify the gap between our implementation and theoretical bounds. 
  Link prediction is an important way to complete knowledge graphs , while embedding-based methods, effective for link prediction in KGs, perform poorly on relations that only have a few associative triples. In this work, we propose a Meta Relational Learning  framework to do the common but challenging few-shot link prediction in KGs, namely predicting new triples about a relation by only observing a few associative triples. We solve few-shot link prediction by focusing on transferring relation-specific meta information to make model learn the most important knowledge and learn faster, corresponding to relation meta and gradient meta respectively in MetaR.  Empirically, our model achieves state-of-the-art results on few-shot link prediction KG benchmarks.    
   %Simultaneous translation is widely useful but remains challenging.  Previous work falls into two main categories:  fixed-latency policies , which, due to the difference between source and target word order, have to aggressively hallucinate future content; and  adaptive policies learned by reinforcement learning, which do not anticipate, but suffer from unstable training due to randomness in exploration.  To combine the merits of both approaches, we propose a simple supervised-learning framework to learn an adaptive policy from oracle READ/WRITE sequences generated from parallel text.  At each step, such an oracle sequence chooses to WRITE the next target word if the available source sentence context provides enough information to do so, otherwise READ the next source word.  German$\leftrightarrow$English experiments show that our method can learn flexible policies with better BLEU scores and similar latencies compared to previous work, without retraining the underlying NMT model.   Simultaneous translation is widely useful but remains challenging.  Previous work falls into two main categories:  fixed-latency policies such as~   and  adaptive policies such as~.   The former are simple and effective, but %inevitably   have to aggressively predict future content   due to diverging source-target word order;    the latter do not anticipate, but suffer from unstable and inefficient training.  To combine the merits of both approaches, we propose a simple supervised-learning framework to learn an adaptive policy from oracle READ/WRITE sequences generated from parallel text.  At each step, such an oracle sequence chooses to WRITE the next target word if the available source sentence context provides enough information to do so, otherwise READ the next source word.  Experiments on German$\leftrightarrow$English show that our method, without retraining the underlying NMT model, can learn flexible policies with better BLEU scores and similar latencies compared to previous work.  
 In this paper, we present a generic and robust multimodal synthesis system that produces highly natural speech and facial expression simultaneously. The key component of this system is the Duration Informed Attention Network , an autoregressive model in which the alignments between the input text and the output acoustic features are inferred from a duration model. This is different from the end-to-end attention mechanism used, and accounts for various unavoidable artifacts, in existing end-to-end speech synthesis systems such as Tacotron. Furthermore, DurIAN can be used to generate high quality facial expression which can be synchronized with generated speech with/without parallel speech and face data. To improve the efficiency of speech generation, we also propose a multi-band parallel generation strategy on top of the WaveRNN model. The proposed Multi-band WaveRNN effectively reduces the total computational complexity from 9.8 to 3.6 GFLOPS, and is able to generate audio that is 6 times faster than real time on a single CPU core. We show that DurIAN could generate highly natural speech that is on par with current state of the art end-to-end systems, while at the same time avoid word skipping/repeating errors in those systems. Finally, a simple yet effective approach for fine-grained control of expressiveness of speech and facial expression is introduced.  
  Scientific article summarization is challenging: large, annotated corpora are not available, and the summary should ideally include the article's impacts on research community. This paper provides novel solutions to these two challenges. We 1) develop and release the first large-scale manually-annotated corpus for scientific papers  by enabling faster annotation, and 2) propose summarization methods that integrate the authors' original highlights  and the article's actual impacts on the community , to create comprehensive, hybrid summaries. We conduct experiments to demonstrate the efficacy of our corpus in training data-driven models for scientific paper summarization and the advantage of our hybrid summaries over abstracts and traditional citation-based summaries. Our large annotated corpus and hybrid methods provide a new framework for scientific paper summarization research.\footnote{Our dataset is available at \url{https://michiyasunaga.github.io/projects/scisumm_net/}}  
   Recently, neural networks based on multi-task learning have achieved promising performance on fake news detection, which focus on learning shared features among tasks as complementary features to serve different tasks. However, in most of the existing approaches, the shared features are completely assigned to different tasks without selection, which may lead to some useless and even adverse features integrated into specific tasks. In this paper, we design a sifted multi-task learning method with a selected sharing layer for fake news detection. The selected sharing layer adopts gate mechanism and attention mechanism to filter and select shared feature flows between tasks. Experiments on two public and widely used competition datasets, i.e. RumourEval and PHEME, demonstrate that our proposed method achieves the state-of-the-art performance and boosts the F1-score by more than 0.87\%, 1.31\%, respectively. 
 The state of the art in machine translation  is governed by neural approaches, which typically provide superior translation accuracy over statistical approaches. However, on the closely related task of word alignment, traditional statistical word alignment models often remain the go-to solution.  In this paper, we present an approach to train a Transformer model to produce both accurate translations and alignments. We extract discrete alignments from the attention probabilities learnt during regular neural machine translation model training and leverage them in a multi-task framework to optimize towards translation and alignment objectives. We demonstrate that our approach produces competitive results compared to GIZA++ trained IBM alignment models without sacrificing translation accuracy and outperforms previous attempts on Transformer model based word alignment. Finally, by incorporating IBM model alignments into our multi-task training, we report significantly better alignment accuracies compared to GIZA++ on three publicly available data sets. Our implementation has been open-sourced\footnote{Code can be found at \url{https://github.com/pytorch/fairseq/pull/1095}}. 
 %\lipsum[1] %\lipsum[15]   Commonsense reasoning aims to empower machines with the human ability to make presumptions about ordinary situations in our daily life.   In this paper, we propose a textual inference framework for answering commonsense questions, which effectively utilizes external, structured commonsense knowledge graphs to perform explainable inferences.  The framework first grounds a question-answer pair from the semantic space to the knowledge-based symbolic space as a schema graph, a related sub-graph of external knowledge graphs. It represents schema graphs with a novel knowledge-aware graph network module named \KagNet, and finally scores answers with graph representations. Our model is based on graph convolutional networks and LSTMs, with a hierarchical path-based attention mechanism. The intermediate attention scores make it transparent and interpretable, which thus produce trustworthy inferences. Using ConceptNet as the only external resource for Bert-based models, we achieved state-of-the-art performance on the CommonsenseQA, a large-scale dataset for commonsense reasoning. We open-source our code\footnote{\url{https://github.com/INK-USC/KagNet}} to the community for future research in knowledge-aware commonsense reasoning. 
  Current state-of-the-art neural machine translation  uses a deep multi-head self-attention network with no explicit phrase information. However, prior work on statistical machine translation has shown that extending the basic translation unit from words to phrases has produced substantial improvements, suggesting the possibility of improving NMT performance from explicit modeling of phrases. In this work, we present { indeed captures useful phrase information at various levels of granularities.    
   When an entity name contains other names within it, the identification of all combinations of names can become difficult and expensive.      We propose a new method to recognize not only outermost named entities but also inner nested ones.   We design an objective function for training a neural model that treats the tag sequence for nested entities as the second best path within the span of their parent entity.   In addition, we provide the decoding method for inference that extracts entities iteratively from outermost ones to inner ones in an outside-to-inside way.   Our method has no additional hyperparameters to the conditional random field based model widely used for flat named entity recognition tasks.   Experiments demonstrate that our method performs better than or at least as well as existing methods capable of handling nested entities, achieving the F1-scores of $85.82\%$, $84.34\%$, and $77.36\%$ on ACE-2004, ACE-2005, and GENIA datasets, respectively. 
   Due to the highly parallelizable architecture, Transformer is faster to train than RNN-based models and popularly used in machine translation tasks. However, at inference time, each output word requires all the hidden states of the previously generated words, which limits the parallelization capability, and makes it much slower than RNN-based ones. In this paper, we systematically analyze the time cost of different components of both the Transformer and RNN-based model. Based on it, we propose a hybrid network of self-attention and RNN structures, in which, the highly parallelizable self-attention is utilized as the encoder, and the simpler RNN structure is used as the decoder. Our hybrid network can decode 4-times faster than the Transformer. In addition, with the help of knowledge distillation, our hybrid network achieves comparable translation quality to the original Transformer. 
 Tracking entities in procedural language requires understanding the transformations arising from actions on entities as well as those entities' interactions. While self-attention-based pre-trained language encoders like GPT and BERT  have been successfully applied across a range of natural language understanding tasks, their ability to handle the nuances of procedural texts is still untested.  In this paper, we explore the use of pre-trained transformer networks for entity tracking tasks in procedural text. First, we test standard lightweight approaches for prediction with pre-trained transformers, and find that these approaches underperform even simple baselines. We show that much stronger results can be attained by restructuring the input to guide the transformer model to focus on a particular entity. Second, we assess the degree to which transformer networks capture the process dynamics, investigating such factors as merged entities and oblique entity references. On two different tasks, ingredient detection in recipes and QA over scientific processes, we achieve state-of-the-art results, but our models still largely attend to shallow context clues and do not form complex representations of intermediate entity or process state.\footnote{Code to reproduce experiments in this paper is available at \url{https://github.com/aditya2211/transformer-entity-tracking}} % citations is good 
   The recognition of emotions by humans is a complex process which   considers multiple interacting signals such as facial expressions   and both prosody and semantic content of utterances. Commonly,   research on automatic recognition of emotions is, with few   exceptions, limited to one modality. We describe an in-car   experiment for emotion recognition from speech interactions for   three modalities: the audio signal of a spoken interaction, the   visual signal of the driver's face, and the manually transcribed   content of utterances of the driver. We use off-the-shelf tools for   emotion detection in audio and face and compare that to a neural   transfer learning approach for emotion recognition from text which   utilizes existing resources from other domains. We see that transfer   learning enables models based on out-of-domain corpora to perform   well. This method contributes up to 10 percentage points in \F, with   up to 76 micro-average \F across the emotions joy, annoyance and   insecurity. Our findings also indicate that off-the-shelf-tools   analyzing face and audio are not ready yet for emotion detection in   in-car speech interactions without further adjustments. 
 This thesis is concerned with type-logical grammars and their practical applicability as tools of reasoning about sentence syntax and semantics. The focal point is narrowed to Dutch, a language exhibiting a large degree of word order variability. In order to overcome difficulties arising as a result of that variability, the thesis explores and expands upon a type grammar based on Multiplicative Intuitionistic Linear Logic, agnostic to word order but enriched with decorations that aim to reduce its proof-theoretic complexity. An algorithm for the conversion of dependency-annotated sentences into type sequences is then implemented, populating the type logic with concrete, data-driven lexical types. Two experiments are ran on the resulting grammar instantiation. The first pertains to the learnability of the type-assignment process by a neural architecture.  A novel application of a self-attentive sequence transduction model is proposed; contrary to established practices, it constructs types inductively by internalizing the type-formation syntax, thus exhibiting generalizability beyond a pre-specified type vocabulary. The second revolves around a deductive parsing system that can resolve structural ambiguities by consulting both word and type information; preliminary results suggest both excellent computational efficiency and performance. 
 We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We show that this extractive step significantly improves summarization results. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism  while still achieving higher rouge scores. Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper based on an earlier draft of this paper. 
 Most research on lifelong learning applies to images or games, but not language. We present LAMOL, a simple yet effective method for lifelong language learning  based on language modeling. LAMOL replays pseudo-samples of previous tasks while requiring no extra memory or model capacity. Specifically, LAMOL is a language model that simultaneously learns to solve the tasks and generate training samples. When the model is trained for a new task, it generates pseudo-samples of previous tasks for training alongside data for the new task. The results show that LAMOL prevents catastrophic forgetting without any sign of intransigence and can perform five very different language tasks sequentially with only one model.  Overall, LAMOL outperforms previous methods by a considerable margin and is only 2--3\% worse than multitasking, which is usually considered the LLL upper bound. The source code is available at \url{https://github.com/jojotenya/LAMOL}. 
 Almost all existing machine translation models are built on top of character-based vocabularies: characters, subwords or words. Rare characters from noisy text or character-rich languages such as Japanese and Chinese however can unnecessarily take up vocabulary slots and limit its compactness. Representing text at the level of bytes and using the 256 byte set as vocabulary is a potential solution to this issue. High computational cost has however prevented it from being widely deployed or used in practice. In this paper, we investigate byte-level subwords, specifically byte-level BPE , which is compacter than character vocabulary and has no out-of-vocabulary tokens, but is more efficient than using pure bytes only is. We claim that contextualizing BBPE embeddings is necessary, which can be implemented by a convolutional or recurrent layer. Our experiments show that BBPE has comparable performance to BPE while its size is only $1/8$ of that for BPE. In the multilingual setting, BBPE maximizes vocabulary sharing across many languages and achieves better translation quality. Moreover, we show that BBPE enables transferring models between languages with non-overlapping character sets. 
 Due to their inherent capability in semantic alignment of aspects and their context words, attention mechanism and Convolutional Neural Networks  are widely applied for aspect-based sentiment classification. However, these models lack a mechanism to account for relevant syntactical constraints and long-range word dependencies, and hence may mistakenly recognize syntactically irrelevant contextual words as clues for judging aspect sentiment. To tackle this problem, we propose to build a Graph Convolutional Network  over the dependency tree of a sentence to exploit syntactical information and word dependencies. Based on it, a novel aspect-specific sentiment classification framework is raised. Experiments on three benchmarking collections illustrate that our proposed model has comparable effectiveness to a range of state-of-the-art models\footnote{Code and preprocessed datasets are available at {https://github.com/GeneZC/ASGCN}.}, and further demonstrate that both syntactical information and long-range word dependencies are properly captured by the graph convolution structure. 
    Variational language models seek to estimate the posterior of latent variables with an approximated variational posterior. The model often assumes the variational posterior to be factorized even when the true posterior is not. The learned variational posterior under this assumption does not capture the dependency relationships over latent variables. We argue that this would cause a typical training problem called posterior collapse observed in all other variational language models. We propose Gaussian Copula Variational Autoencoder  to avert this problem. Copula is widely used to model correlation and dependencies of high-dimensional random variables, and therefore it is helpful to maintain the dependency relationships that are lost in VAE. The empirical results show that by modeling the correlation of latent variables explicitly using a neural parametric copula, we can avert this training difficulty while getting competitive results among all other VAE approaches. \footnote{Code will be released at \url{https://github.com/kingofspace0wzz/copula-vae-lm}} 
 Sensational headlines are headlines that capture people's attention and generate reader interest. Conventional abstractive headline generation methods, unlike human writers, do not optimize for maximal reader attention. In this paper, we propose a model that generates sensational headlines without labeled data. We first train a sensationalism scorer by classifying online headlines with many comments  against a baseline of headlines generated from a summarization model. The score from the sensationalism scorer is used as the reward for a reinforcement learner. However, maximizing the noisy sensationalism reward will generate unnatural phrases instead of sensational headlines. To effectively leverage this noisy reward, we propose a novel loss function, Auto-tuned Reinforcement Learning , to dynamically balance reinforcement learning  with maximum likelihood estimation . Human evaluation shows that  60.8\% of samples generated by our model are sensational, which is significantly better than the Pointer-Gen baseline~ and other RL models.  % to classify online headlines with a lot of comments  against a baseline of headlines generated from a summarization model.  %Our new loss function has no hyper-parameters to tune, making it easy to train.   
 Building named entity recognition  models for languages that do not have much training data is a challenging task. While recent work has shown promising results on cross-lingual transfer from high-resource languages to low-resource languages, it is unclear what knowledge is transferred. In this paper, we first propose a simple and efficient neural architecture for cross-lingual NER. Experiments show that our model achieves competitive performance with the state-of-the-art. We further analyze how transfer learning works for cross-lingual NER on two transferable factors: sequential order and multilingual embeddings, and investigate how model performance varies across entity lengths. Finally, we conduct a case-study on a non-Latin language, Bengali, which suggests that leveraging knowledge from Wikipedia will be a promising direction to further improve the model performances. Our results can shed light on future research for improving cross-lingual NER.  
 In this paper, we propose a method for incorporating world knowledge  into a neural question generation model. This world knowledge helps to encode additional information related to the entities present in the passage required to generate human-like questions. We evaluate our models on both SQuAD and MS MARCO to demonstrate the usefulness of the world knowledge features. The proposed world knowledge enriched question generation model is able to outperform the vanilla neural question generation model by $1.37$ and $1.59$ absolute BLEU\_4 score on SQuAD and MS MARCO test dataset respectively.  
 Neural Conversational QA tasks like ShARC require systems to answer questions based on the contents of a given passage. On studying recent state-of-the-art models on the ShARC QA task, we found indications that the models learn spurious clues/patterns in the dataset. Furthermore, we show that a heuristic-based program designed to exploit these patterns can have performance comparable to that of the neural models. In this paper we share our findings about four types of patterns found in the ShARC corpus and describe how neural models exploit them. Motivated by the aforementioned findings, we create and share a modified dataset that has fewer spurious patterns, consequently allowing models to learn better. 
 Natural language processing  tasks tend to suffer from a paucity of suitably annotated training data, hence the recent success of transfer learning across a wide variety of them. The typical recipe involves:  training a deep, possibly bidirectional, neural network with an objective related to language modeling, for which training data is plentiful; and  using the trained network to derive contextual representations that are far richer than standard linear word embeddings such as word2vec, and thus result in important gains. In this work, we wonder whether the opposite perspective is also true: can contextual representations trained for different NLP tasks improve language modeling itself? Since language models  are predominantly locally optimized, other NLP tasks may help them make better predictions based on the entire semantic fabric of a document. We test the performance of several types of pre-trained embeddings in neural LMs, and we investigate whether it is possible to make the LM more aware of global semantic information through embeddings pre-trained with a domain classification model. Initial experiments suggest that as long as the proper objective criterion is used during training, pre-trained embeddings are likely to be beneficial for neural language modeling.  
    Semantic parsing aims to map natural language utterances onto   machine interpretable meaning representations, aka programs whose   execution against a real-world environment produces a denotation.   Weakly-supervised semantic parsers are trained on   utterance-denotation pairs treating programs as latent. The task is   challenging due to the large search space and spuriousness of   programs which may execute to the correct answer but do not   generalize to unseen examples.  Our goal is to instill an inductive   bias in the parser to help it distinguish between spurious and   correct programs.  We capitalize on the intuition that correct   programs would likely respect certain structural constraints were   they to be aligned to the question  and propose to model   alignments as structured latent variables.  In order to make the   latent-alignment framework tractable, we decompose the parsing task   into  predicting a partial ``abstract program'' and  refining   it while modeling structured alignments with differential dynamic   programming. We obtain state-of-the-art performance on the \wtq and   \wsq datasets. When compared to a standard attention baseline, we   observe that the proposed structured-alignment mechanism is highly   beneficial. 
 Opinion spam has become a widespread problem in social media, where hired spammers write deceptive reviews to promote or demote products to mislead the consumers for profit or fame. Existing works mainly focus on manually designing discrete textual or behavior features, which cannot capture complex semantics of reviews. Although recent works apply deep learning methods to learn review-level semantic features, their models ignore the impact of the user-level and product-level information on learning review semantics and the inherent user-review-product relationship information.   In this paper, we propose a Hierarchical Fusion Attention Network  to automatically learn the semantics of reviews from user and product level. Specifically, we design a multi-attention unit to extract user-related review information. Then, we use orthogonal decomposition and fusion attention to learn a user, review, and product representation from the review information. Finally, we take the review as a relation between user and product entity and apply TransH to jointly encode this relationship into review representation. Experimental results obtained more than 10\% absolute precision improvement over the state-of-the-art performances on four real-world datasets, which show the effectiveness and versatility of the model.  
  Neural language models have achieved state-of-the-art performances on many NLP tasks, and recently have been shown to learn a number of hierarchically-sensitive syntactic dependencies between individual words. However, equally important for language processing is the ability to combine words into phrasal constituents, and use constituent-level features to drive downstream expectations. Here we investigate neural models' ability to represent constituent-level features, using coordinated noun phrases as a case study. We assess whether different neural language models trained on English and French represent phrase-level number and gender features, and use those features to drive downstream expectations. Our results suggest that models use a linear combination of NP constituent number to drive CoordNP/verb number agreement. This behavior is highly regular and even sensitive to local syntactic context, however it differs crucially from observed human behavior. Models have less success with gender agreement. Models trained on large corpora perform best, and there is no obvious advantage for models trained using explicit syntactic supervision.   
 % Word embedding models such as the skip-gram learn vector representations of words' semantic relationships, and document embedding models perform a similar representation learning task for documents.  % using a log-bilinear classifier to parameterize the distributions over words. % On the other hand, topic models provide latent representations of topical themes and topic distributions for documents. However, these models do not provide interpretable joint vector-space representations of topics, documents, and words all together in a common semantic space. In this work, we propose a new algorithm, called  , that deconstructs topic models into interpretable vector-space embeddings of topics, documents, and words, % all together in a shared latent space, % by learning neural embeddings to mimic the topic models. We showcase our algorithm on LDA, author-topic models and the recently proposed mixed membership skip gram topic model %by conducting several experiments on different corpora to validate our approach % and achieve better performance with the word, topic, and document representations compared with several state-of-the-art models. Furthermore, we demonstrate that NEA improves topic coherence scores over the original topic models when the number of topics is large.   Word embedding models such as the skip-gram learn vector representations of words' semantic relationships, and document embedding models learn similar representations for documents. On the other hand, topic models provide latent representations of the documents' topical themes. To get the benefits of these representations simultaneously, we propose a unifying algorithm, called  , which deconstructs topic models into interpretable vector-space embeddings of words, topics, documents, authors, and so on, by learning neural embeddings to mimic the topic models. We showcase NEA's effectiveness and generality on LDA, author-topic models and the recently proposed mixed membership skip gram topic model and achieve better performance with the embeddings compared to several state-of-the-art models. Furthermore, we demonstrate that using NEA to smooth out the topics improves coherence scores over the original topic models when the number of topics is large.   
 Neural Machine Translation  can be used to generate fluent output. As such, language models have been investigated for incorporation with NMT. In prior investigations, two models have been used: a translation model and a language model. The translation model's predictions are weighted by the language model with a hand-crafted ratio in advance. However, these approaches fail to adopt the language model weighting with regard to the translation history.  In another line of approach, language model prediction is incorporated into the translation model by jointly considering source and target information. However, this line of approach is limited because it largely ignores the adequacy of the translation output.  Accordingly, this work employs two mechanisms, the translation model and the language model, with an attentive architecture to the language model as an auxiliary element of the translation model. Compared with previous work in English--Japanese machine translation using a language model, the experimental results obtained with the proposed Dynamic Fusion mechanism improve BLEU and Rank-based Intuitive Bilingual Evaluation Scores  scores.  Additionally, in the analyses of the attention and predictivity of the language model, the Dynamic Fusion mechanism allows predictive language modeling that conforms to the appropriate grammatical structure.    
 Language models are at the heart of numerous works, notably in the text mining and information retrieval communities. These statistical models aim at extracting word distributions, from simple unigram models to recurrent approaches with latent variables that capture subtle dependencies in texts. However, those models are learned from word sequences only, and authors' identities, as well as publication dates, are seldom considered. We propose a neural model, based on recurrent language modeling, which aims at capturing language diffusion tendencies in author communities through time. By conditioning language models with author and temporal vector states, we are able to leverage the latent dependencies between the text contexts. This allows us to beat several temporal and non-temporal language baselines on two real-world corpora, and to learn meaningful author representations that vary through time. 
  Speakers of different languages must attend to and encode strikingly different aspects of the world in order to use their language correctly ~. One such difference is related to the way gender is expressed in a language. Saying ``I am happy'' in English, does not encode any additional knowledge of the speaker that uttered the sentence. However, many other languages do have grammatical gender systems and so such knowledge would be encoded. In order to correctly translate such a sentence into, say, French, the inherent gender information needs to be retained/recovered. The same sentence would become either ``Je suis heureux'', for a male speaker or ``Je suis heureuse'' for a female one. Apart from morphological agreement, demographic factors  also influence our use of language in terms of word choices or even on the level of syntactic constructions~. We integrate gender information into NMT systems. Our contribution is two-fold:  the compilation of large datasets with speaker information for 20 language pairs, and  a simple set of experiments that incorporate gender information into NMT for multiple language pairs. Our experiments show that adding a gender feature to an NMT system significantly improves the translation quality for some language pairs.  
 Linguistic Code-switching  is still an understudied phenomenon in natural language processing. The NLP community has mostly focused on monolingual and multi-lingual scenarios, but little attention has been given to CS in particular. This is partly because of the lack of resources and annotated data, despite its increasing occurrence in social media platforms. In this paper, we aim at adapting monolingual models to code-switched text in various tasks.  Specifically, we transfer English knowledge from a pre-trained ELMo model to different code-switched language pairs  using the task of language identification.  Our method, CS-ELMo, is an extension of ELMo with a simple yet effective position-aware attention mechanism inside its character convolutions.  We show the effectiveness of this transfer learning step by outperforming multilingual BERT and homologous CS-unaware ELMo models and establishing a new state of the art in CS tasks, such as NER and POS tagging.  Our technique can be expanded to more English-paired code-switched languages, providing more resources to the CS community. 
 		Neural semantic parsing has achieved impressive results in recent years, yet {its} success  		relies on the availability of  		large amounts of supervised data. 		Our goal is to learn a neural semantic parser when only prior knowledge about a limited number of simple rules is available,  		without access to either annotated programs or execution results. 		Our approach is initialized by rules, and improved in a back-translation paradigm using generated question-program pairs from the semantic parser and the question generator.  		A phrase table with frequent mapping patterns is automatically derived, also updated as training progresses, to measure the quality of generated instances.  We train the model with model-agnostic meta-learning to guarantee the accuracy and stability on examples covered by rules, and meanwhile acquire the versatility to generalize well on examples uncovered by rules. 		Results on three benchmark datasets with different domains and programs show that our approach incrementally improves the accuracy. 		On WikiSQL, our best model is comparable to the SOTA system learned from denotations.  	
 With the rise of social media like Twitter and of software distribution platforms like app stores, users got various ways to express their opinion about software products.  Popular software vendors get user feedback thousandfold per day. Research has shown that such feedback contains valuable information for software development teams such as problem reports or feature and support inquires.  Since the manual analysis of user feedback is cumbersome and hard to manage many researchers and tool vendors suggested to use automated analyses based on traditional supervised machine learning approaches. In this work, we compare the results of traditional machine learning and deep learning in classifying user feedback in English and Italian into problem reports, inquiries, and irrelevant. Our results show that using traditional machine learning, we can still achieve comparable results to deep learning, although we collected thousands of labels. 
 Speech emotion recognition is a challenging problem because human convey emotions in subtle and complex ways. For emotion recognition on human speech, one can either extract emotion related features from audio signals or employ speech recognition techniques to generate text from speech and then apply natural language processing to analyze the sentiment. Further, emotion recognition will be beneficial from using audio-textual multimodal information, it is not trivial to build a system to learn from multimodality. One can build models for two input sources separately and combine them in a decision level, but this method ignores the interaction between speech and text in the temporal domain. In this paper, we propose to use an attention mechanism to learn the alignment between speech frames and text words, aiming to produce more accurate multimodal feature representations. The aligned multimodal features are fed into a sequential model for emotion recognition.  We evaluate the approach on the IEMOCAP dataset and the experimental results show the proposed approach achieves the state-of-the-art performance on the dataset. \footnote{Our code is available at https://github.com/didi/delta}  % We evaluate the approach on the IEMOCAP dataset and the experimental results show the advantage of the proposed approach.  Index Terms: Emotion Recognition, Multimodal, Attention, Alignment 
 We propose a system that finds the strongest supporting evidence for a given answer to a question, using passage-based question-answering  as a testbed. We train evidence agents to select the passage sentences that most convince a pretrained QA model of a given answer, if the QA model received those sentences instead of the full passage. Rather than finding evidence that convinces one model alone, we find that agents select evidence that generalizes; agent-chosen evidence increases the plausibility of the supported answer, as judged by other QA models and humans. Given its general nature, this approach improves QA in a robust manner: using agent-selected evidence  humans can correctly answer questions with only $\sim$20\% of the full passage and  QA models can generalize to longer passages and harder questions. 
  As modern deep networks become more complex, and get closer to human-like capabilities in certain domains, the question arises of how the representations and decision rules they learn compare to the ones in humans. In this work, we study representations of sentences in one such artificial system for natural language processing. We first present a diagnostic test dataset to examine the degree of abstract composable structure represented. Analyzing performance on these diagnostic tests indicates a lack of systematicity in the representations and decision rules, and reveals a set of heuristic strategies. We then investigate the effect of the training distribution on learning these heuristic strategies, and study changes in these representations with various augmentations to the training set. Our results reveal parallels to the analogous representations in people. We find that these systems can learn abstract rules and generalize them to new contexts under certain circumstances -- similar to human zero-shot reasoning. However, we also note some shortcomings in this generalization behavior -- similar to human judgment errors like belief bias. Studying these parallels suggests new ways to understand psychological phenomena in humans as well as informs best strategies for building artificial intelligence with human-like language understanding.  
 Neural dialogue models have been widely adopted in various chatbot applications because of their good performance in simulating and generalizing human conversations. However, there exists a dark side of these models -- due to the vulnerability of neural networks, a neural dialogue model can be manipulated by users to say what they want, which brings in concerns about the security of practical chatbot services. In this work, we investigate whether we can craft inputs that lead a well-trained black-box neural dialogue model to generate targeted outputs. We formulate this as a reinforcement learning  problem and train a Reverse Dialogue Generator which efficiently finds such inputs for targeted outputs. Experiments conducted on a representative neural dialogue model show that our proposed model is able to discover %find out  such desired inputs in a considerable portion of cases. Overall, our work reveals this weakness of neural dialogue models and may prompt further researches of developing corresponding solutions to avoid it. %  
 Named Entity Recognition  plays an important role in a wide range of natural language processing tasks, such as relation extraction, question answering, etc. However, previous studies on NER are limited to particular genres, using small manually-annotated or large but low-quality datasets. Meanwhile, previous datasets for open-domain NER, built using distant supervision, suffer from low precision, recall and ratio of annotated tokens . %coverage\footnote{Coverage refers to the ratio of annotated words in all words.\ww{Not sure what you meant by annotated words and all words.}}\ww{Isn't recall and coverage the same?}.  In this work, to address the low precision and recall problems, we first utilize DBpedia as the source of distant supervision to annotate abstracts from Wikipedia and design a neural correction model trained with a human-annotated NER dataset, DocRED, to correct the false entity labels. In this way, we build a large and high-quality dataset called AnchorNER and then train various models with it. To address the low RAT problem of previous datasets, we introduce a multi-task learning method to exploit the context information. We evaluate our methods on five NER datasets and our experimental results show that models trained with AnchorNER and our multi-task learning method obtain state-of-the-art performances in the open-domain setting. %we have obtained state-of-the-art open-domain performances --- on top of the strong baselines BERT-base and BERT-large, we achieve relative improvements of 4.66\% and 3.07\% respectively. 
     Neural Machine Translation  is resource intensive. We design a quantization procedure to compress NMT models better for devices with limited hardware capability. Because most neural network parameters are near zero, we employ logarithmic quantization in lieu of fixed-point quantization.  However, we find bias terms are less amenable to log quantization but note they comprise a tiny fraction of the model, so we leave them uncompressed.        We also propose to use an error-feedback mechanism during retraining, to preserve the compressed model as a stale gradient. We empirically show that NMT models based on Transformer or RNN architecture can be compressed up to 4-bit precision without any noticeable quality degradation. Models can be compressed up to binary precision, albeit with lower quality. The RNN architecture seems to be more robust to quantization, compared to the Transformer. 
 Ironies can not only express stronger emotions but also show a sense of humor. With the development of social media, ironies are widely used in public. Although many prior research studies have been conducted in irony detection, few studies focus on irony generation. The main challenges for irony generation are the lack of large-scale irony dataset and difficulties in modeling the ironic pattern. In this work, we first systematically define irony generation based on style transfer task. To address the lack of data, we make use of twitter and build a large-scale dataset. We also design a combination of rewards for reinforcement learning to control the generation of ironic sentences. Experimental results demonstrate the effectiveness of our model in terms of irony accuracy, sentiment preservation, and content preservation\footnote{Our data and code are released at https://github.com/zmd971202/IronyGeneration.}. 
    %Word embeddings are learned from local context windows, whereas topic models take a more global view.  Though word embeddings and topics are complementary representations,  % in the sense that how they learn from word occurrences in a text corpora,  several past works have only used pre-trained word embeddings in  topic modeling to address data sparsity problem in short text or small collection of documents. However, no prior work has employed  topics in transfer learning paradigm.  %Essentially, word embeddings are fine-granularity  representations in contrast to coarse-granularity  in latent topics,   In this paper, we propose an approach to  % perform knowledge transfer from a { from one or many related or distant domains, i.e., multi-source.   %To achieve it, %in the sparse settings of the target domain,  %we guide the generative process of learning the hidden topics in the target domain by latent topic vectors  from a source domain such that the hidden topics in the target domain get more meaningful and representative in explaining the target corpus. We quantify the quality of hidden topics via generalization  on unseen documents, interpretability ,  text retrieval and classification.   
 While most neural machine translation  systems are still trained using maximum likelihood estimation, recent work has demonstrated that optimizing systems to directly improve evaluation metrics such as BLEU can substantially improve final translation accuracy. However, training with BLEU has some limitations: it doesn't assign partial credit, it has a limited range of output values, and it can penalize semantically correct hypotheses if they differ lexically from the reference. In this paper, we introduce an alternative reward function for optimizing NMT systems that is based on recent work in semantic similarity. We evaluate on four disparate languages translated to English, and find that training with our proposed metric results in  better translations as evaluated by BLEU, semantic similarity, and human evaluation, and also that the optimization procedure converges faster. Analysis suggests that this is because the proposed metric is more conducive to optimization, assigning partial credit and providing more diversity in scores than BLEU.% \footnote{Code and data to replicate results are available at \url{https://www.cs.cmu.edu/~jwieting}.} 
 In longitudinal electronic health records , the event records of a patient are distributed over a long period of time and the temporal relations between the events reflect sufficient domain knowledge to benefit prediction tasks such as the rate of inpatient mortality. Medical concept embedding as a feature extraction method that transforms a set of medical concepts with a specific time stamp into a vector, which will be fed into a supervised learning algorithm. The quality of the embedding significantly determines the learning performance over the medical data. In this paper, we propose a medical concept embedding method based on applying a self-attention mechanism to represent each medical concept. We propose a novel attention mechanism which captures the contextual information and temporal relationships between medical concepts. A light-weight neural net, ``Temporal Self-Attention Network '', is then proposed to learn medical concept embedding based solely on the proposed attention mechanism. To test the effectiveness of our proposed methods, we have conducted clustering and prediction tasks on two public EHRs datasets comparing TeSAN against five state-of-the-art embedding methods. The experimental results demonstrate that the proposed TeSAN model is superior to all the compared methods. To the best of our knowledge, this work is the first to exploit temporal self-attentive relations between medical events.  
 In recent years, Neural Machine Translation  has been shown to be more effective than phrase-based statistical methods, thus quickly becoming the state of the art in machine translation .  However, NMT systems are limited in translating low-resourced languages, due to the significant amount of parallel data that is required to learn  useful mappings between languages.  In this work, we show how the so-called multilingual NMT can help to tackle the challenges associated with low-resourced language translation. The underlying principle  of multilingual NMT is to force the creation of hidden representations of words in a shared semantic space across multiple languages, thus enabling a positive parameter transfer across languages.  Along this direction, we present multilingual translation experiments with three languages  covering six translation directions, utilizing both recurrent neural networks and transformer  neural networks. We then  focus on the zero-shot translation problem, that is how to leverage multi-lingual data in order to learn translation directions  that are not covered by the available training material.  To this aim, we introduce our recently proposed iterative self-training  method, which incrementally improves a multilingual NMT  on a zero-shot direction by just relying on monolingual data. Our results on TED talks data show that multilingual NMT outperforms conventional bilingual NMT, that  the transformer NMT outperforms recurrent NMT, and that zero-shot NMT    outperforms conventional pivoting methods and even matches the performance of a fully-trained bilingual system.  
 %   We present a model that grounds color comparative adjectives in 2 different color spaces. We find that modifiers represented as vectors from reference colors to target colors show different behaviors in RGB and HSV color space. Based on this finding we design models that primarily improve modeling of color related modifiers, such as ``pinkish". In experiments, we pre-train basic models in different color spaces and train hard and soft ensemble models. Experimental results show significant and consistent improvements compared to the state-of-the-art baseline model.  % 
 % We focus on the task of the targeted sentiment analysis -- jointly predicting targets as well as their associated sentiment information.  % Existing works mostly regard this joint task as a sequence labeling problem and build models based on CRF to capture explicit linear chain structure.  % However, there does not exist any works to capture global implicit dependencies, such as self-attention, between targets and the whole sentence in a joint manner.  % We propose a neural architecture which is capable of modeling the explicit structure improving on an existing work -- sentiment scope.  % Furthermore, it is also able to model the implicit structure based on self-attention for each predicted target to capture the global dependencies for the targeted sentiment. % The experimental result shows that such an approach is able to achieve better performance than strong baselines. % We also conducted rich experiments to investigate model effectiveness and robustness\footnote{Our code is available at **URL**}. Targeted sentiment analysis is the task of jointly predicting target entities and their associated sentiment information. Existing research efforts mostly regard this joint task as a sequence labeling problem, building models that can capture explicit structures in the output space. However, the importance of capturing implicit global structural information that resides in the input space is largely unexplored. In this work, we argue that both types of information  are crucial for building a successful targeted sentiment analysis model. Our experimental results show that properly capturing both information is able to lead to better performance than competitive existing approaches. We also conduct extensive experiments to investigate our model's effectiveness and robustness\footnote{We release our code at \url{http://www.statnlp.org/research/st}.}. 
   Neural machine translation  systems require large amounts of high   quality in-domain parallel corpora for training.   State-of-the-art NMT systems still face challenges related to out of   vocabulary words and dealing with low-resource language pairs.   In this paper, we propose and compare several models for fusion of bilingual   lexicons with an end-to-end trained sequence-to-sequence model for machine   translation.   The result is a fusion model with two information sources for the   decoder: a neural conditional language model and a bilingual lexicon.   This fusion model learns how to combine both sources of information in order   to produce higher quality translation output.   Our experiments show that our proposed models work well in relatively   low-resource scenarios, and also effectively reduce the parameter size and   training cost for NMT without sacrificing performance. 
 Attention mechanisms are ubiquitous components  in neural architectures applied to natural language processing.  In addition to yielding gains in predictive accuracy,  attention weights are often claimed to confer ,  purportedly useful both for providing insights to practitioners  and for explaining  to stakeholders. We call the latter use of attention mechanisms into question by demonstrating a simple method for training models to  produce deceptive attention masks. Our method diminishes the total weight assigned to designated impermissible tokens, even when the models  can be shown to  nevertheless rely on these features to drive predictions.  Across multiple models and tasks,  our approach manipulates attention weights  while paying surprisingly little cost in accuracy.  Through a human study, we show  that our manipulated attention-based explanations deceive people into thinking  that predictions from a model biased against gender minorities %\gnc{biased against gender minorities} %{ %that uses gender as an indicative feature when making predictions %} %gender biased model  do not rely on the gender. % When our manipulated attention-based explanations % are presented to human subjects, % they are deceived into thinking  %doesn't take gender into account. Consequently, our results  %Although our results do not rule out potential insights due to organically-trained attention, cast doubt on attention's reliability as a tool for auditing algorithms in the context of fairness and accountability\footnote{The code and the datasets used in paper are available at \url{https://github.com/danishpruthi/deceptive-attention}}. 
   %Sequence-based models are popularly applied to modeling text and enjoy success in many NLP tasks. However,    The complicated syntax structure of natural language is hard to be explicitly modeled by sequence-based models.    %Many of the words connected with others are not consecutive, thus requiring longer dependency.    Graph is a natural structure to describe the complicated relation between tokens. The recent advance in Graph Neural Networks  provides a powerful tool to model graph structure data, but simple graph models such as Graph Convolutional Networks  suffer from over-smoothing problem, that is, when stacking multiple layers, all nodes will converge to the same value. In this paper, we propose a novel Recursive Graphical Neural Networks model  to represent text organized in the form of graph. In our proposed model, LSTM is used to dynamically decide which part of the aggregated neighbor information should be transmitted to upper layers thus alleviating the over-smoothing problem. Furthermore, to encourage the exchange between the local and global information, a global graph-level node is designed. We conduct experiments on both single and multiple label text classification tasks. Experiment results show that our ReGNN model surpasses the strong baselines significantly in most of the datasets and greatly alleviates the over-smoothing problem.    
  Fine-tuning pre-trained Neural Machine Translation  models is the dominant approach for adapting to new languages and domains. However, fine-tuning requires adapting and maintaining a separate model for each target task. We propose a simple yet efficient approach for adaptation in NMT. Our proposed approach consists of injecting tiny task specific adapter layers into a pre-trained model. These lightweight adapters, with just a small fraction of the original model size, adapt the model to multiple individual tasks simultaneously.  We evaluate our approach on two tasks:  Domain Adaptation and  Massively Multilingual NMT. Experiments on domain adaptation demonstrate that our proposed approach is on par with full fine-tuning on various domains, dataset sizes and model capacities. On a massively multilingual dataset of 103 languages, our adaptation approach bridges the gap between individual bilingual models and one massively multilingual model for most language pairs, paving the way towards universal machine translation.  
 Native speakers can judge whether a sentence is an acceptable instance of their language. Acceptability provides a means of evaluating whether computational language models are processing language in a human-like manner. We test the ability of computational language models, simple language features, and word embeddings to predict native English speakers' judgments of acceptability on English-language essays written by non-native speakers. We find that much of the sentence acceptability variance can be captured by a combination of features including misspellings, word order, and word similarity . While predictive neural models fit acceptability judgments well , we find that a 4-gram model with statistical smoothing is just as good . Thanks to incorporating a count of misspellings, our 4-gram model surpasses both the previous unsupervised state-of-the art , %reducing the gap to expert performance   and the average non-expert native speaker . Our results demonstrate that acceptability is well captured by n-gram statistics and simple language features. 
   We present  mechanism is introduced to further reduce WERs.   \espresso achieves state-of-the-art ASR performance on the WSJ, LibriSpeech, and Switchboard data sets among other end-to-end systems without data augmentation, and is 4--11$\times$ faster for decoding than similar systems . 
 Under special circumstances, summaries should conform to a particular style with patterns, such as court judgments and abstracts in academic papers. To this end, the prototype document-summary pairs can be utilized to generate better summaries. There are two main challenges in this task:  the model needs to incorporate learned patterns from the prototype, but  should avoid copying contents other than the patternized words---such as irrelevant facts---into the generated summaries. To tackle these challenges, we design a model named Prototype Editing based Summary Generator . PESG first learns summary patterns and prototype facts by analyzing the correlation between a prototype document and its summary. Prototype facts are then utilized to help extract facts from the input document. Next, an editing generator generates new summary based on the summary pattern or extracted facts.  Finally, to address the second challenge, a fact checker is used to estimate mutual information between the input document and generated summary, providing an additional signal for the generator. Extensive experiments conducted on a large-scale real-world text summarization dataset\footnote{\url{https://github.com/gsh199449/proto-summ}} show that PESG achieves the state-of-the-art performance in terms of both automatic metrics and human evaluations.  
  We review the limitations of BLEU and ROUGE -- the most popular metrics used to assess reference summaries against hypothesis summaries, and come up with criteria for what a good metric should behave like and propose concrete ways to use recent Transformers-based Language Models to assess reference summaries against hypothesis summaries.      
 This paper explores the task of leveraging typology in the context of cross-lingual dependency parsing. While this linguistic information has shown great promise in pre-neural parsing, results for neural architectures have been mixed. The aim of our investigation is to better understand this state-of-the-art. Our main findings are as follows: 1) The benefit of typological information is derived from coarsely grouping languages into syntactically-homogeneous clusters rather than from learning to leverage variations along individual typological dimensions in a compositional manner; 2) Typology consistent with the actual corpus statistics yields better transfer performance; 3) Typological similarity is only a rough proxy of cross-lingual transferability with respect to parsing.\footnote{Code: \url{github.com/ajfisch/TypologyParser}} 
 Entity alignment is a viable means for integrating heterogeneous knowledge among different knowledge graphs . Recent developments in the field often take an embedding-based approach to model the structural information of KGs so that entity alignment can be easily performed in the embedding space. However, most existing works do not explicitly utilize useful relation representations to assist in entity alignment, which, as we will show in the paper, is a simple yet effective way for improving entity alignment. This paper presents a novel joint learning framework for entity alignment. At the core of our approach is a Graph Convolutional Network  based framework for learning both entity and relation representations. Rather than relying on pre-aligned relation seeds to learn relation representations, we first approximate them using entity embeddings learned by the GCN. We then incorporate the relation approximation into entities to iteratively learn better representations for both. Experiments performed on three real-world cross-lingual datasets show that our approach substantially outperforms state-of-the-art entity alignment methods. 	 
 The exploding cost and time needed for data labeling and model training are bottlenecks for training DNN models on large datasets. Identifying smaller representative data samples with strategies like active learning can help mitigate such bottlenecks. Previous works on active learning in NLP identify the problem of sampling bias in the samples acquired by uncertainty-based querying and develop costly approaches to address it. Using a large empirical study, we demonstrate that active set selection using the posterior entropy of deep models like FastText.zip  is robust to sampling biases and to various algorithmic choices  unlike that suggested by traditional literature. We also show that FTZ based query strategy produces sample sets similar to those from more sophisticated approaches . Finally, we show the effectiveness of the selected samples by creating tiny high-quality datasets, and utilizing them for fast and cheap training of large models. Based on the above, we propose a simple baseline for deep active text classification that outperforms the state-of-the-art. We expect the presented work to be useful and informative for dataset compression and for problems involving active, semi-supervised or online learning scenarios. Code and models are available at: {https://github.com/drimpossible/Sampling-Bias-Active-Learning}   %Ameya: REMOVE THIS? and replace with above? %\footnote{We will release our code on Github} 
 This study mainly investigates two decoding problems in neural keyphrase generation: sequence length bias and beam diversity. We introduce an extension of beam search inference based on word-level and n-gram level attention score to adjust and constrain Seq2Seq prediction at test time. Results show that our proposed solution can overcome the algorithm bias to shorter and nearly identical sequences, resulting in a significant improvement of the decoding performance on generating keyphrases that are present and absent in source text. 
   We present effective pre-training strategies for neural machine translation  using parallel corpora involving a pivot language, i.e., source-pivot and pivot-target, leading to a significant improvement in source$\rightarrow$target translation.   We propose three methods to increase the relation among source, pivot, and target languages in the pre-training: 1) step-wise training of a single model for different language pairs, 2) additional adapter component to smoothly connect pre-trained encoder and decoder, and 3) cross-lingual encoder training via autoencoding of the pivot language.   Our methods greatly outperform multilingual models up to +2.6\% Bleu in WMT 2019 French$\rightarrow$German and German$\rightarrow$Czech tasks.   We show that our improvements are valid also in zero-shot/zero-resource scenarios.\\ 
  Because it is not feasible to collect training data for every language, there is a growing interest in cross-lingual transfer learning. In this paper, we systematically explore zero-shot cross-lingual transfer learning on reading comprehension tasks with a language representation model pre-trained on multi-lingual corpus.   The experimental results show that with pre-trained language representation zero-shot learning is feasible, and translating the source data into the target language is not necessary and even degrades the performance.  We further explore what does the model learn in zero-shot setting\footnote[0]{All the modifications of existing corpora used in this paper would be released in https://github.com/ntu-spml-lab/artificial-reading-comprehension-datasets}.   
 Answer selection is an important research problem, with applications in many areas. Previous deep learning based approaches for the task mainly adopt the Compare-Aggregate architecture that performs word-level comparison followed by aggregation. In this work, we take a departure from the popular Compare-Aggregate architecture, and instead, propose a new gated self-attention memory network for the task. Combined with a simple transfer learning technique from a large-scale online corpus, our model outperforms previous methods by a large margin, achieving new state-of-the-art results on two standard answer selection datasets: TrecQA and WikiQA. 
  Machine Translation  is a zone of concentrate in Natural Language processing which manages the programmed interpretation of human language, starting with one language then onto the next by the PC. Having a rich research history spreading over about three decades, Machine interpretation is a standout amongst the most looked for after region of research in the computational linguistics network. As a piece of this current ace's proposal, the fundamental center is examine the Deep-learning based strategies that have gained critical ground as of late and turning into the de facto strategy in MT. We would like to point out the recent advances that have been put forward in the field of Neural Translation models, different domains under which NMT has replaced conventional SMT models and would also like to mention future avenues in the field. Consequently, we propose an end-to-end self-attention transformer network for Neural Machine Translation, trained on Hindi-English parallel corpus and compare the model's efficiency with other state of art models like encoder-decoder and attention based encoder-decoder neural models on the basis of BLEU. We conclude this paper with a comparitive analysis of the three proposed models.    
 Semantic role labeling  is the task of identifying predicates and labeling argument spans with semantic roles. Even though most semantic-role formalisms are built upon constituent syntax, and only syntactic constituents can be labeled as arguments , all the recent work on syntax-aware SRL relies on dependency representations of syntax. In contrast, we show how graph convolutional networks  can be used to encode constituent structures and inform an SRL system. Nodes in our SpanGCN correspond to constituents. The computation is done in 3 stages. First, initial node representations are produced by `composing' word representations of the first and last words in the constituent. Second, graph convolutions relying on the constituent tree are performed, yielding syntactically-informed constituent representations. Finally, the constituent representations are `decomposed' back into word representations, which are used as input to the SRL classifier.   We evaluate SpanGCN against alternatives, including a model using GCNs over dependency trees, and show its effectiveness on standard English SRL benchmarks CoNLL-2005, CoNLL-2012, and FrameNet. 
 We follow the step-by-step approach to neural data-to-text generation we proposed in , in which the generation process is divided into a text-planning stage followed by a plan-realization stage. We suggest four extensions to that framework:  we introduce a trainable neural planning component that can generate effective plans several orders of magnitude faster than the original planner;  we incorporate typing hints that improve the model's ability to deal with unseen relations and entities;  we introduce a verification-by-reranking stage that substantially improves the faithfulness of the resulting texts;  we incorporate a simple but effective referring expression generation module. These extensions result in a generation process that is faster, more fluent, and more accurate. 
  Latent tree learning  methods learn to parse sentences using only indirect supervision from a downstream task. Recent advances in latent tree learning have made it possible to recover moderately high-quality tree structures by training with language modeling or auto-encoding objectives.  %However, none of the attempts to date using only semantics-oriented labeled-data tasks have yielded linguistically non-trivial trees.  In this work, we explore the hypothesis that decoding in machine translation, as a conditional language modeling task, will produce better tree structures since it offers a similar training signal as language modeling, but with more semantic signal. We adapt two existing latent-tree language models---PRPN and ON-LSTM---for use in translation. We find that they indeed recover trees that are better in F1 score than those seen in language modeling on WSJ test set, while maintaining strong translation quality. We observe that translation is a better objective than language modeling for inducing trees, marking the first success at latent tree learning using a machine translation objective. Additionally, our findings suggest that, although translation provides better signal for inducing trees than language modeling, translation models can perform well without exploiting the latent tree structure.     
     We propose a novel deep structured learning framework for event temporal relation extraction. The model consists of 1) a recurrent neural network  to learn scoring functions for pair-wise relations, and 2) a structured support vector machine  to make joint predictions. The neural network automatically learns representations that account for long-term contexts to provide robust features for the structured model, while the SSVM incorporates domain knowledge such as transitive closure of temporal relations as constraints to make better globally consistent decisions. By jointly training the two components, our model combines the benefits of both data-driven learning and knowledge exploitation.      Experimental results on three high-quality event temporal relation datasets  demonstrate that incorporated with pre-trained contextualized embeddings, the proposed model achieves significantly better performances than the state-of-the-art methods on all three datasets. We also provide thorough ablation studies to investigate our model. 
 It has been widely accepted that Long Short-Term Memory  network, coupled with attention mechanism and memory module, is useful for aspect-level sentiment classification. However, existing approaches largely rely on the modelling of semantic relatedness of an aspect with its context words, while to some extent ignore their syntactic dependencies within sentences. Consequently, this may lead to an undesirable result that the aspect attends on contextual words that are descriptive of other aspects. In this paper, we propose a proximity-weighted convolution network to offer an aspect-specific syntax-aware representation of contexts. In particular, two ways of determining proximity weight are explored, namely position proximity and dependency proximity. The representation is primarily abstracted by a bidirectional LSTM architecture and further enhanced by a proximity-weighted convolution. Experiments conducted on the SemEval 2014 benchmark demonstrate the effectiveness of our proposed approach compared with a range of state-of-the-art models\footnote{Code is available at {https://github.com/GeneZC/PWCN}.}. 
 In this paper, we explore a new approach for automated chess commentary generation, which aims to generate chess commentary texts in different categories . We introduce a neural chess engine into text generation models to help with encoding boards, predicting moves, and analyzing situations. By jointly training the neural chess engine and the generation models for different categories, the models become more effective. We conduct experiments on 5 categories in a benchmark Chess Commentary dataset and achieve inspiring results in both automatic and human evaluations.  
   This document contains the instructions for preparing a camera-ready   manuscript for the proceedings of . The document itself   conforms to its own specifications, and is therefore an example of   what your manuscript should look like. These instructions should be   used for both papers submitted for review and for final versions of   accepted papers.  Authors are asked to conform to all the directions   reported in this document. 
     Neural language models  perform well on tasks that require sensitivity to syntactic structure. Drawing on the syntactic priming paradigm from psycholinguistics, we propose a novel technique to analyze the representations that enable such success. By establishing a gradient similarity metric between structures, this technique allows us to reconstruct the organization of the LMs' syntactic representational space. We use this technique to demonstrate that LSTM LMs' representations of different types of sentences with relative clauses are organized hierarchically in a linguistically interpretable manner, suggesting that the LMs track abstract properties of the sentence.   
 Recent works show that ordering of the training data affects the model performance for Neural Machine Translation. Several approaches involving dynamic data ordering and data sharding based on curriculum learning have been analyzed for the their performance gains and faster convergence. In this work we propose to empirically study several ordering approaches for the training data based on different metrics and evaluate their impact on the model performance. Results from our study show that pre-fixing the ordering of the training data based on perplexity scores from a pre-trained model performs the best and outperforms the default approach of randomly shuffling the training data every epoch.  
   With the advent of social media, our online feeds increasingly consist of short, informal, and unstructured text. This textual data can be analyzed for the purpose of improving user recommendations and detecting trends. Instagram is one of the largest social media platforms, containing  both text and images. However, most of the prior research on text processing in social media is focused on analyzing Twitter data, and little attention has been paid to text mining of Instagram data. Moreover, many text mining methods rely on annotated training data, which in practice is both difficult and expensive to obtain. In this paper, we present methods for unsupervised mining of fashion attributes from Instagram text, which can enable a new kind of user recommendation in the fashion domain. In this context, we analyze a corpora of Instagram posts from the fashion domain, introduce a system for extracting fashion attributes from Instagram, and train a deep clothing classifier with weak supervision to classify Instagram posts based on the associated text.  With our experiments, we confirm that word embeddings are a useful asset for information extraction. Experimental results show that information extraction using word embeddings outperforms a baseline that uses Levenshtein distance. The results also show the benefit of combining weak supervision signals using generative models instead of majority voting. Using weak supervision and generative modeling, an $F_1$ score of $0.61$ is achieved on the task of classifying the image contents of Instagram posts based solely on the associated text, which is on level with human performance. Finally, our empirical study provides one of the few available studies on Instagram text and shows that the text is noisy, that the text distribution exhibits the long-tail phenomenon, and that comment sections on Instagram are multi-lingual. 
   Employing pre-trained language models  to extract contextualized word representations has achieved state-of-the-art performance on various NLP tasks.   However, applying this technique to noisy transcripts generated by automatic speech recognizer  is concerned.   Therefore, this paper focuses on making contextualized representations more ASR-robust.   We propose a novel confusion-aware fine-tuning method to mitigate the impact of ASR errors on pre-trained LMs. Specifically, we fine-tune LMs to produce similar representations for acoustically confusable words that are obtained from word confusion networks  produced by ASR. Experiments on multiple benchmark datasets show that the proposed method significantly improves the performance of spoken language understanding when performing on ASR transcripts\footnote{Code available at: \url{https://github.com/MiuLab/SpokenVec}}. 
  %%% Version 1 % Despite being the dominant approach in the field of machine translation, neural machine translation takes days up to weeks to train translation model and a large number of parallel sentences, which hinders their performance over the majority of low resource languages and spend a large amount of computation time and energy. % In this work, we propose a method of transfer learning how to re-use old trained models for different language pairs without any need for framework modification, leading to better performance and also shorter convergence times. % These translation models are significantly better even when the re-used model uses language pair not related to the child language pair. Especially for low-resource languages. % Contra-intuitively, re-used model's language pair does not have to be related to the child language pair.  %% Version 2 % Neural machine translation is demanding in terms of training time, hardware resources and quantity of parallel sentences.  % We propose a method of transfer learning to re-use old trained models for different language pairs without any need for framework modification. We achieve better translation quality in shorter convergence times. % Our translation models are significantly better even when the re-used model's language pair is not linguistically related to the child language pair, especially for low-resource languages. % Counter-intuitively, re-used model's language pair does not have to be related to the child language pair.  %% Version 3 % Neural machine translation is demanding in terms of training time, hardware resources, size, and quantity of parallel sentences. We propose a simple transfer learning method to recycle already trained models for different language pairs with no need for modifications in model architecture, hyper-parameters, or vocabulary. We achieve better translation quality and shorter convergence times than when training from random initialization.  % To show the applicability of our method, we recycle a Transformer model trained by different researchers for translating English-to-Czech and used it to seed models for seven language pairs. Our translation models are significantly better even when the re-used model's language pair is not linguistically related to the child language pair, especially for low-resource languages. % Our approach needs only one pretrained model for all transferring to all various language pairs. % Additionally, we improve this approach with a simple vocabulary transformation. We analyze the behaviour of transfer learning to understand the gains from unrelated languages.    Recent progress in neural machine translation is directed towards larger neural networks trained on an increasing amount of hardware resources. As a result, NMT models are costly to train, both financially, due to the electricity and hardware cost, and environmentally, due to the carbon footprint. It is especially true in transfer learning for its additional cost of training the ``parent'' model before transferring knowledge and training the desired ``child'' model. In this paper, we propose a simple method of re-using an already trained model for different language pairs where there is no need for modifications in model architecture. Our approach does not need a separate parent model for each investigated language pair, as it is typical in NMT transfer learning. To show the applicability of our method, we recycle a Transformer model trained by different researchers and use it to seed models for different language pairs.  We achieve better translation quality and shorter convergence times than when training from random initialization.  % Counter-intuitively, re-used model's language pair does not have to be related to the child language pair.    
   Rhetorical structure trees    have been shown to be useful for several document-level tasks including summarization and document classification.   Previous approaches to RST parsing have used discriminative   models; however, these are less sample efficient than generative   models, and RST parsing datasets are typically small.   In this paper, we present the first generative model for RST   parsing. Our model is a document-level RNN grammar  with a bottom-up traversal order. We show that, for our parser's traversal order, previous   beam search    algorithms for RNNGs have a left-branching    bias which is ill-suited for RST parsing.   We develop a    novel beam search algorithm that keeps track of both structure- and word-generating actions   without exhibiting this branching   bias and results in absolute improvements of 6.8 and 2.9 on unlabelled and labelled  F1 over previous algorithms.   Overall, our generative model outperforms a discriminative model with the same features   by 2.6 F1 points and achieves  performance comparable to the state-of-the-art,   outperforming all published parsers  from a recent replication study that do not use additional training data. 
 How to incorporate external knowledge into a neural dialogue model is critically important for dialogue systems to behave like real humans. To handle this problem, memory networks are usually a great choice and a promising way. However, existing memory networks do not perform well when leveraging heterogeneous information from different sources. In this paper, we propose a novel and versatile external memory networks called Heterogeneous Memory Networks , to simultaneously utilize user utterances, dialogue history and background knowledge tuples. In our method, historical sequential dialogues are encoded and stored into the context-aware memory enhanced by gating mechanism while grounding knowledge tuples are encoded and stored into the context-free memory. During decoding, the decoder augmented with HMNs recurrently selects each word in one response utterance from these two memories and a general vocabulary. Experimental results on multiple real-world datasets show that HMNs significantly outperform the state-of-the-art data-driven task-oriented dialogue models in most domains. 
 Aspect-based sentiment analysis  is to predict the sentiment polarity towards a particular aspect in a sentence. Recently, this task has been widely addressed by the neural attention mechanism, which computes attention weights to softly select words for generating aspect-specific sentence representations. The attention is expected to concentrate on opinion words for accurate sentiment prediction. However, attention is prone to be distracted by noisy or misleading words, or opinion words from other aspects. In this paper, we propose an alternative hard-selection approach, which determines the start and end positions of the opinion snippet, and selects the words between these two positions for sentiment prediction. Specifically, we learn deep associations between the sentence and aspect, and the long-term dependencies within the sentence by leveraging the pre-trained BERT model. We further detect the opinion snippet by self-critical reinforcement learning. Especially, experimental results demonstrate the effectiveness of our method and prove that our hard-selection approach outperforms soft-selection approaches when handling multi-aspect sentences.  
 Named entity recognition  identifies typed entity mentions in raw text. While the task is well-established, there is no universally used tagset: often, datasets are annotated for use in downstream applications and accordingly only cover a small set of entity types relevant to a particular task. For instance, in the biomedical domain, one corpus might annotate genes, another chemicals, and another diseases---despite the texts in each corpus containing references to all three types of entities. In this paper, we propose a deep structured model to integrate these ``partially annotated'' datasets to {} 
 Text classification is one of the most critical areas in machine learning and artificial intelligence research. It has been actively adopted in many business applications such as conversational intelligence systems, news articles categorizations, sentiment analysis , emotion detection systems , and many other recommendation systems in our daily life. One of the problems in supervised text classification models is that the models' performance depends heavily on the quality of data labeling that is typically done by humans. In this study, we propose a new network community detection-based approach to automatically label and classify text data into multiclass value spaces. Specifically, we build networks with sentences as the network nodes and pairwise cosine similarities between the Term Frequency-Inversed Document Frequency  vector representations of the sentences as the network link weights. We use the Louvain method  to detect the communities in the sentence networks. We train and test the Support Vector Machine and the Random Forest models on both the human-labeled data and network community detection labeled data. Results showed that models with the data labeled by the network community detection outperformed the models with the human-labeled data by 2.68-3.75\% of classification accuracy. Our method may help developments of more accurate conversational intelligence and other text classification systems. % We would like to encourage you to list your keywords within % the abstract section using the  command.   
 Dialogue state tracking is an important component in task-oriented dialogue systems to identify users' goals and requests as a dialogue proceeds. However, as most previous models are dependent on dialogue slots, the model complexity soars when the number of slots increases. In this paper, we put forward a slot-independent neural model  to track dialogue states while keeping the model complexity invariant to the number of dialogue slots. The model utilizes attention mechanisms between user utterance and system actions. SIM achieves state-of-the-art results on WoZ and DSTC2 tasks, with only 20\% of the model size of previous models.  
 Aspect and opinion term extraction is a critical step in Aspect-Based Sentiment Analysis . Our study focuses on evaluating transfer learning using pre-trained BERT  to classify tokens from hotel reviews in bahasa Indonesia. The primary challenge is the language informality of the review texts. By utilizing transfer learning from a multilingual model, we achieved up to 2\% difference on token level F1-score compared to the state-of-the-art Bi-LSTM model with fewer training epochs . The fine-tuned model clearly outperforms the Bi-LSTM model on the entity level. Furthermore, we propose a method to include CRF with auxiliary labels as an output layer for the BERT-based models. The CRF addition further improves the F1-score for both token and entity level. 
   Automatic news comment generation is a new testbed for techniques of natural language generation. In this paper, we propose a ``read-attend-comment'' procedure for news comment generation and formalize the procedure with a reading network and a generation network. The reading network comprehends a news article and distills some important points from it, then the generation network creates a comment by attending to the extracted discrete points and the news title. We optimize the model in an end-to-end manner by maximizing a variational lower bound of the true objective using the back-propagation algorithm. Experimental results on two datasets indicate that our model can significantly outperform existing methods in terms of both automatic evaluation and human judgment. 
  %In Machine Translation  field, models require of large amounts of parallel data to be trained. This is especially critical for Neural Machine Translation  as they achieve the best performance when larger sets of parallel sentences are provided for training.   Neural Machine Translation  models tend to achieve best performance when larger sets of parallel sentences are provided for training. For this reason, augmenting the training set with artificially-generated sentence pairs can boost performance.  Nonetheless, the performance can also be improved with a small number of sentences if they are in the same domain as the test set. Accordingly, we want to explore the use of artificially-generated sentences along with data-selection algorithms to improve German-to-English NMT models trained solely with authentic data.  In this work, we show how artificially-generated sentences can be more beneficial than authentic pairs, and demonstrate their advantages when used in combination with data-selection algorithms.  %use of smaller but in-domain sentence pair are pre  %sets of data can also perform bettbe used for % %it is also preferable to use in-domain sentences even if it is a smaller set. For this reason we explore the performance of data-selection algorithms for retrieving   %the best small subset that causes the performance  %selection of artificially-generated sentences to be used for improving NMT models.   %\textcolor{red}{We discover that in some cases it is preferable to select sentences from a synthetic set of sentences as they can be more accurate translation.} %\textcolor{red}{We discover that artificially-generated sentence can have benefits when used with transductive data selection algorithms such as they ........ }   
 Linking facts across documents is a challenging task, as the language used to express the same information in a sentence can vary significantly, which complicates the task of multi-document summarization. Consequently, existing approaches heavily rely on hand-crafted features, which are domain-dependent and hard to craft, or additional annotated data, which is costly to gather. To overcome these limitations, we present a novel method, which makes use of two types of sentence embeddings: universal embeddings, which are trained on a large unrelated corpus, and domain-specific embeddings, which are learned during training.  To this end, we develop SemSentSum, a fully data-driven model able to leverage both types of sentence embeddings by building a sentence semantic relation graph. SemSentSum achieves competitive results on two types of summary, consisting of 665 bytes and 100 words. Unlike other state-of-the-art models, neither hand-crafted features nor additional annotated data are necessary, and the method is easily adaptable for other tasks.  To our knowledge, we are the first to use multiple sentence embeddings for the task of multi-document summarization. 
 Semantic parsing is the problem of deriving machine interpretable meaning representations from natural language utterances. Neural models with encoder-decoder architectures have recently achieved substantial improvements over traditional methods. Although neural semantic parsers appear to have relatively high recall using large beam sizes, there is room for improvement with respect to one-best precision. In this work, we propose a generator-reranker architecture for semantic parsing. The generator produces a list of potential candidates and the reranker, which consists of a pre-processing step for the candidates followed by a novel critic network, reranks these candidates based on the similarity between each candidate and the input sentence. We show the advantages of this approach along with how it improves the parsing performance through extensive analysis. We experiment our model on three semantic parsing datasets . The overall architecture achieves the state-of-the-art results in all three datasets.  
  OpenNRE is an open-source and extensible toolkit that provides a unified framework to implement neural models for relation extraction . Specifically, by implementing typical RE methods, OpenNRE not only allows developers to train custom models to extract structured relational facts from the plain text but also supports quick model validation for researchers. Besides, OpenNRE provides various functional RE modules based on both TensorFlow and PyTorch to maintain sufficient modularity and extensibility, making it becomes easy to incorporate new models into the framework. Besides the toolkit, we also release an online system to meet real-time extraction without any training and deploying. Meanwhile, the online system can extract facts in various scenarios as well as aligning the extracted facts to Wikidata, which may benefit various downstream knowledge-driven applications . More details of the toolkit and online system can be obtained from \url{http://github.com/thunlp/OpenNRE}.      
 The identification of syllables within phonetic sequences is known as syllabification. This task is thought to play an important role in natural language understanding, speech production, and the development of speech recognition systems. The concept of the syllable is cross-linguistic, though formal definitions are rarely agreed upon, even within a language. In response, data-driven syllabification methods have been developed to learn from syllabified examples. These methods often employ classical machine learning sequence labeling models. In recent years, recurrence-based neural networks have been shown to perform increasingly well for sequence labeling tasks such as named entity recognition , part of speech  tagging, and chunking. We present a novel approach to the syllabification problem which leverages modern neural network techniques. Our network is constructed with long short-term memory  cells, a convolutional component, and a conditional random field  output layer. Existing syllabification approaches are rarely evaluated across multiple language families. To demonstrate cross-linguistic generalizability, we show that the network is competitive with state of the art systems in syllabifying English, Dutch, Italian, French, Manipuri, and Basque datasets. 
 In recent years, neural machine translation  has become the dominant approach in automated translation. However, like many other deep learning approaches, NMT suffers from overfitting when the amount of training data is limited. This is a serious issue for low-resource language pairs and many specialized translation domains that are inherently limited in the amount of available supervised data. For this reason, in this paper we propose regressing word  and sentence  embeddings at training time as a way to regularize NMT models and improve their generalization. During training, our models are trained to jointly predict categorical  and continuous  outputs. An extensive set of experiments over four language pairs of variable training set size has showed that ReWE and ReSE can outperform strong state-of-the-art baseline models, with an improvement that is larger for smaller training sets . Visualizations of the decoder's output space show that the proposed regularizers improve the clustering of unique words, facilitating correct predictions. In a final experiment on unsupervised NMT, we show that ReWE and ReSE are also able to improve the quality of machine translation when no parallel data are available. 
 Social media hold valuable, vast and unstructured information on public opinion that can be utilized to improve products and services. The automatic analysis of such data, however, requires a deep understanding of natural language. Current sentiment analysis approaches are mainly based on word co-occurrence frequencies, which are inadequate in most practical cases. In this work, we propose a novel hybrid framework for concept-level sentiment analysis in Persian language, that integrates linguistic rules and deep learning to optimize polarity detection. When a pattern is triggered, the framework allows sentiments to flow from words to concepts based on symbolic dependency relations. When no pattern is triggered, the framework switches to its subsymbolic counterpart and leverages deep neural networks  to perform the classification. The proposed framework outperforms state-of-the-art approaches  and DNN classifiers  with a margin of 10--15\% and 3--4\% respectively, using benchmark Persian product and hotel reviews corpora. } 
 In this paper, we take stock of the current state of summarization datasets and explore how different factors of datasets influence the generalization behaviour of neural extractive summarization models. Specifically, we first propose several properties of datasets, which matter for the generalization of summarization models. Then we build the connection between priors residing in datasets and model designs, analyzing how different properties of datasets influence the choices of model structure design and training methods. Finally, by taking a typical dataset as an example, we rethink the process of the model design based on the experience of the above analysis. We demonstrate that when we have a deep understanding of the characteristics of datasets, a simple approach can bring significant improvements to the existing state-of-the-art model. 
 %	ICML guidelines:  %	Abstracts must be a single paragraph, ideally between 4--6 sentences long. %	Gross violations will trigger corrections at the camera-ready phase.  Recent work has shown that topological enhancements to recurrent neural networks  can increase their expressiveness and representational capacity. Two popular enhancements are stacked RNNs, which increases the capacity for learning non-linear functions, and bidirectional processing, which exploits acausal information in a sequence. In this work, we explore the delayed-RNN, which is a single-layer RNN that has a delay between the input and output. We prove that a weight-constrained version of the delayed-RNN is equivalent to a stacked-RNN. We also show that the delay gives rise to partial acausality, much like bidirectional networks. Synthetic experiments confirm that the delayed-RNN can mimic bidirectional networks, solving some acausal tasks similarly, and outperforming them in others. Moreover, we show similar performance to bidirectional networks in a real-world natural language processing task. These results suggest that delayed-RNNs can approximate topologies including stacked RNNs, bidirectional RNNs, and stacked bidirectional RNNs -- but with equivalent or faster runtimes for the delayed-RNNs. 
   While neural models show remarkable accuracy on individual predictions, their   internal beliefs can be inconsistent  examples.  In this paper,   we formalize such inconsistency as a generalization of prediction error. We   propose a learning framework for constraining models using logic rules to   regularize them away from inconsistency. Our framework can leverage both   labeled and unlabeled examples and is directly compatible with off-the-shelf   learning schemes without model redesign.  We instantiate our framework on   natural language inference, where experiments show that enforcing invariants   stated in logic can help make the predictions of neural models both accurate   and consistent.  
 Deep learning systems thrive on abundance of labeled training data but such data is not always available, calling for alternative methods of supervision. One such method is expectation regularization  , where models are trained based on expected label proportions. We propose a novel application of the XR framework for transfer learning between related tasks, where knowing the labels of task A provides an estimation of the label proportion of task B. We then use a model trained for A to label a large corpus, and use this corpus with an XR loss to train a model for task B. To make the XR framework applicable to large-scale deep-learning setups, we propose a stochastic batched approximation procedure. We demonstrate the approach on the task of Aspect-based Sentiment classification, where we effectively use a sentence-level sentiment predictor to train accurate aspect-based predictor. The method improves upon fully supervised neural system trained on aspect-level data, and is also cumulative with LM-based pretraining, as we demonstrate by improving a BERT-based Aspect-based Sentiment model. 
 When trained effectively, the Variational Autoencoder  is both a powerful language model and an effective representation learning framework. In practice, however, VAEs are trained with the evidence lower bound  as a surrogate objective to the intractable marginal data likelihood. This approach to training yields unstable results, frequently leading to a disastrous local optimum known as posterior collapse. In this paper, we investigate a simple fix for posterior collapse which yields surprisingly effective results. The combination of two known heuristics, previously considered only in isolation, substantially improves held-out likelihood, reconstruction, and latent representation learning when compared with previous state-of-the-art methods. More interestingly, while our experiments demonstrate superiority on these principle evaluations, our method obtains a worse ELBO. We use these results to argue that the typical surrogate objective for VAEs may not be sufficient or necessarily appropriate for balancing the goals of representation learning and data distribution modeling.$^{*}$Equal contribution.}\footnote{Code is available at \url{https://github.com/bohanli/vae-pretraining-encoder}.}  %Variational Autoencoders  have received increasing attention in recent text modeling research as a powerful framework for representation learning and data distribution modeling. In practice, VAEs are trained with evidence lower bound  as a surrogate objective to the intractable log marginal likelihood. However, a well-known phenomenon in VAEs is the posterior collapse problem, which means the latent variables of VAEs fail to capture any information and the decoder learns to ignore them.  % In this paper, we propose a simple fix to posterior collapse which greatly improves marginal likelihood, reconstruction, and latent representation learning compared with existing solutions. Surprisingly, our method results in a worse ELBO value, suggesting that the surrogate objective ELBO of VAEs may not be sufficient or necessarily appropriate for balancing the goals of representation learning and data distribution modeling.  % % The Variational Autoencoder  is a powerful framework that combines unsupervised representation learning and generative modeling. In practice, however,  % \gn{The following sentence is pretty long and complicated, can you simplify?} % \yy{I rewrote the first three sentences as follows.} % \yyc{Applying Variational Autoencoders  to text modeling is challenging due to the posterior collapse problem, where the latent code fails to capture any information. Existing solutions to the posterior collapse issue struggle to tradeoff representation learning and generative modeling -- while maintaining competitive perplexity numbers, we show that their learned latent representation is far from satisfactory with bad reconstruction. % We argue that the evidence lower bound  objective of VAEs may not feature a local optimum that strikes a good balance between representation learning and generative modeling,} % {Variational Autoencoders  have received increasing attention in recent text modeling research.   A well-known phenomenon in VAEs is the posterior collapse problem, which means the latent variables of VAEs  are too week for any effort on the decoders. We argue that the evidence lower bound  of VAEs may not be sufficient or necessarily appropriate for balancing the representation learning part and generative part of the model,}  % We {further} propose a simple fix to bias VAE training  % through pretraining the encoder with a standard autoencoder objective, followed by training with the free bits technique, which is a constraint on the minimum KL divergence between the prior and the approximate posterior per group of latent variables. %\gn{the ``free bits technique'' requires more explanation}.  % Despite its simplicity, on three text benchmarks this new training method \gnc{reaches a divergent solution from previous methods and produces}{greatly improves the} state-of-the-art \gnc{}{with respect to} held-out likelihood  % \gnc{and an average of 6 absolute points boost on the reconstruction likelihood. We further demonstrate our improvement of representation learning ability}{and learns more informative latent codes as demonstrated}  % and learns more informative  latent codes as demonstrated through latent space manipulation, text reconstruction, and classification. 
 Recently, the development and implementation of phishing attacks require little technical skills and costs. This uprising has led to an ever-growing number of phishing attacks on the World Wide Web. Consequently, proactive techniques to fight phishing attacks have become extremely necessary. In this paper, we propose HTMLPhish, a deep learning based data-driven end-to-end automatic phishing web page classification approach. Specifically, HTMLPhish receives the content of the HTML document of a web page and employs Convolutional Neural Networks  to learn the semantic dependencies in the textual contents of the HTML. The CNNs learn appropriate feature representations from the HTML document embeddings without extensive manual feature engineering. Furthermore, our proposed approach of the concatenation of the word and character embeddings allows our model to manage new features and ensure easy extrapolation to test data. We conduct comprehensive experiments on a dataset of more than 50,000 HTML documents that provides a distribution of phishing to benign web pages obtainable in the real-world that yields over 93\% Accuracy and True Positive Rate. Also, HTMLPhish is a completely language-independent and client-side strategy which can, therefore, conduct web page phishing detection regardless of the textual language. 
 Decoding language representations directly from the brain can enable new Brain-Computer Interfaces  for high bandwidth human-human and human-machine communication. Clinically, such technologies can restore communication in people with neurological conditions affecting their ability to speak. In this study, we propose a novel deep network architecture Brain2Char, for directly decoding text  from direct brain recordings . Brain2Char framework combines state-of-the-art deep learning modules --- 3D Inception layers for multiband spatiotemporal feature extraction from neural data and bidirectional recurrent layers, dilated convolution layers followed by language model weighted beam search to decode character sequences, optimizing a connectionist temporal classification  loss. Additionally, given the highly non-linear transformations that underlie the conversion of cortical function to character sequences, we perform regularizations on the network's latent representations motivated by insights into cortical encoding of speech production and artifactual aspects specific to ECoG data acquisition. To do this, we impose auxiliary losses on latent representations for articulatory movements, speech acoustics and session specific non-linearities. In 3 participants tested here, Brain2Char achieves 10.6\%, 8.5\% and 7.0\% Word Error Rates  respectively on vocabulary sizes ranging from 1200 to 1900 words. Brain2Char also performs well when 2 participants silently mimed sentences. These results set a new state-of-the-art on decoding text from brain and demonstrate the potential of Brain2Char as a high-performance communication BCI.  
 %In the real world, constructing a labeled dataset for image caption generation can be cumbersome and time-consuming. On the other hand, unpaired image and caption samples can be relatively easier to collect.  {Constructing an organized dataset comprised of a large number of images and several captions for each image is a laborious task, which requires vast human effort. On the other hand, collecting a large number of images and sentences separately may be immensely easier.} In this paper, we develop a novel data-efficient  framework for training an image captioning model. We leverage massive  image and caption data by learning to associate them.  To this end, our proposed semi-supervised learning method assigns pseudo-labels to unpaired samples via Generative Adversarial Networks to learn the joint distribution of image and caption. % To learn the alignment between image and caption distributions,  % { % We leverage a large-scale unpaired dataset to train an image captioning neural network % in a novel  framework. % that is designed specifically for caption and image modalities. % } % In order to train a model with the unpaired dataset,  % we utilize a semi-supervised learning method to assign pseudo-labels for unpaired samples by learning to align respective distributions of image and captions with Generative Adversarial Networks .  To evaluate, we construct {scarcely-paired COCO} dataset, a modified version of MS COCO caption dataset. The empirical results show the effectiveness of our method compared to several {strong} baselines, {especially when the amount of the paired samples are scarce}. 
  Task-specific scores are often used to optimize for and evaluate the performance of conditional text generation systems. However, such scores are non-differentiable and cannot be used in the standard supervised learning paradigm. Hence, policy gradient methods are used since the gradient can be computed without requiring a differentiable objective. %  leads to improved results on semantical evaluation measures in policy-gradient models for image captioning tasks. Our InferSent actor-critic model improves over a BLEU trained actor-critic model on MSCOCO when evaluated on a Word Mover's Distance similarity measure by 6.97 points, also improving on a Sliding Window Cosine Similarity measure by 10.48 points. Similar performance improvements are also obtained on the smaller Flickr-30k dataset, demonstrating the general applicability of the proposed transfer learning method.  
  Entity recommendation, providing search users with an improved experience via assisting them in finding related entities for a given query, has become an indispensable feature of today's search engines. Existing studies typically only consider the queries with explicit entities. They usually fail to handle complex queries that without entities, such as "what food is good for cold weather", because their models could not infer the underlying meaning of the input text. In this work, we believe that contexts convey valuable evidence that could facilitate the semantic modeling of queries, and take them into consideration for entity recommendation. In order to better model the semantics of queries and entities, we learn the representation of queries and entities jointly with attentive deep neural networks. We evaluate our approach using large-scale, real-world search logs from a widely used commercial Chinese search engine. Our system has been deployed in ShenMa Search Engine \footnote{m.sm.cn} and you can fetch it in UC Browser of Alibaba. Results from online A/B test suggest that the impression efficiency of click-through rate increased by 5.1\% and page view increased by 5.5\%.  
   Prior work has proposed effective methods to learn event representations that can capture syntactic and semantic information over text corpus, demonstrating their effectiveness for downstream tasks such as script event prediction. On the other hand, events extracted from raw texts lacks of commonsense knowledge, such as the intents and emotions of the event participants, which are useful for distinguishing event pairs when there are only subtle differences in their surface realizations. To address this issue, this paper proposes to leverage external commonsense knowledge about the intent and sentiment of the event. Experiments on three event-related tasks, i.e., event similarity, script event prediction and stock market prediction, show that our model obtains much better event embeddings for the tasks, achieving 78\% improvements on hard similarity task, yielding more precise inferences on subsequent events under given contexts, and better accuracies in predicting the volatilities of the stock market\footnote{The code and data are available on https://github.com/MagiaSN/CommonsenseERL\_EMNLP\_2019.}.   %Embedding structured event into continues vector spaces offers a new way for defining dense features for natural language processing  applications. Prior work has proposed effective methods to learn event representations that can capture syntactic and semantic information over text corpus, demonstrating their effectiveness for downstream tasks such as script event prediction. On the other hand, events extracted from raw texts lacks of commonsense knowledge, such as the intents and emotions of the event participants, which are useful for distinguishing event pairs when there are only subtle differences in their surface realizations. To address this issue, this paper proposes to leverage external commonsense knowledge about the intent and sentiment of the event. Specifically, we propose a joint model to combine intent and sentiment information into the objective function of an event embedding learning model. Experiments on event similarity, script event prediction and stock market prediction show that our model is more capable of obtaining better event embeddings, making more accurate inference on choosing the most reasonable subsequent event and predicting the stock market. 
 We describe a system called Overton, whose main design goal is to support engineers in building, monitoring, and improving production machine learning systems. Key challenges engineers face are monitoring fine-grained quality, diagnosing errors in sophisticated applications, and handling contradictory or incomplete supervision data. Overton automates the life cycle of model construction, deployment, and monitoring by providing a set of novel high-level, declarative abstractions. Overton's vision is to shift developers to these higher-level tasks instead of lower-level machine learning tasks. In fact, using Overton, engineers can build deep-learning-based applications without writing any code in frameworks like TensorFlow. For over a year, Overton has been used in production to support multiple applications in both near-real-time applications and back-of-house processing. In that time, Overton-based applications have answered billions of queries in multiple languages and processed trillions of records reducing errors $1.7-2.9\times$ versus production systems. 
  To train neural machine translation models simultaneously on multiple tasks , it is common to sample each task uniformly or in proportion to dataset sizes. As these methods offer little control over performance trade-offs, we explore different task scheduling approaches. We first consider existing  non-adaptive techniques, then move on to adaptive schedules that over-sample tasks with poorer results compared to their respective baseline. As explicit schedules can be inefficient, especially if one task is highly over-sampled, we also consider implicit schedules, learning to scale learning rates or gradients of individual tasks instead. These techniques allow training multilingual models that perform better for low-resource language pairs , while minimizing negative effects on high-resource tasks. 
  Pronounced as "musician", the musicnn library contains a set of pre-trained musically motivated convolutional neural networks~ for music audio tagging:   	\url{https://github.com/jordipons/musicnn}   This repository also includes some pre-trained vgg-like baselines~. These models can be used as out-of-the box music audio taggers, as music feature extractors, or as pre-trained models for transfer learning.  These models are trained with two different datasets: the MagnaTagATune dataset \footnote{The MagnaTagATune 50-tags vocabulary: guitar, classical, slow, techno, strings, drums, electronic, rock, fast, piano, ambient, beat, violin, vocal, synth, female, indian, opera, male, singing, vocals, no vocals, harpsichord, loud, quiet, flute, woman, male vocal, no vocal, pop, soft, sitar, solo, man, classic, choir, voice, new age, dance, male voice, female vocal, beats, harp, cello, no voice, weird, country, metal, female voice, choral.} and the Million Song Dataset \footnote{The Million Song Dataset 50-tags vocabulary: rock, pop, alternative, indie, electronic, female vocalists, dance, 00s, alternative rock, jazz, beautiful, metal, chillout, male vocalists, classic rock, soul, indie rock, mellow, electronica, 80s, folk, 90s, chill, instrumental, punk, oldies, blues, hard rock, ambient, acoustic, experimental, female vocalist, guitar, hip-hop, 70s, party, country, easy listening, sexy, catchy, funk, electro, heavy metal, progressive rock, 60s, rnb, indie pop, sad, house, happy.}.  %The MTT dataset considers this , and the MSD dataset considers this 50-tags vocabulary.  Which pre-trained models are available? Although the main focus of the library is to release pre-trained musically motivated convolutional neural networks, we also provide several vgg-like models\footnote{\label{mark2}An in-depth depiction of vgg architecture and its feature-maps is accessible online via a Jupyter Notebook: \url{https://github.com/jordipons/musicnn/blob/master/vgg_example.ipynb}} . A high-level depiction of the musicnn architecture\footnote{\label{mark1}An in-depth depiction of the musicnn architecture  and its feature-maps is accessible online via a Jupyter Notebook: \url{https://github.com/jordipons/musicnn/blob/master/musicnn_example.ipynb}} is depicted in the following figure:  [H] 	 	 architecture: a musically motivated convolutional neural network~.} 	\label{fig:example}   The following models are available: \verb|MTT_musicnn|, \verb|MSD_musicnn|, \verb|MSD_musicnn_big|, \verb|MTT_vgg|, and \verb|MSD_vgg|. The \verb|MTT| models are trained with the MagnaTagATune dataset, and the \verb|MSD| models are trained with the Million Song Dataset. Given that the Million Song Dataset contains more training data, we also provide a larger musicnn model: \verb|MSD_musicnn_big|. Architectural details are accessible online\footref{mark1}\footref{mark2}.  What's the musicnn library for? Out-of-the-box music audio tagging.  From within python, one can estimate the top-10 tags by simply running:   from musicnn.tagger import top_tags top_tags  \phantom{}  From the command-line, one can also print the top-N tags on the screen  or save them to a file :   python -m musicnn.tagger music.au --model 'MTT_musicnn' --topN 10 --print python -m musicnn.tagger audio.wav -m 'MTT_vgg' --topN 5 --save out.tags  What's the musicnn library for? Music feature extraction.  Out of the extractor, see the example below, one gets the output of the model  and all the intermediate representations of it . The features are packed in a dictionary and, for the musicnn models, you can extract \verb|timbral|, \verb|temporal|, \verb|cnn1|, \verb|cnn2|, \verb|cnn3|, \verb|mean_pool|, \verb|max_pool|, and \verb|penultimate| features\footref{mark1}. For the vgg models, you can extract \verb|pool1|, \verb|pool2|, \verb|pool3|, \verb|pool4|, and \verb|pool5| features\footref{mark2}. %For example, see the activations of the \verb|taggram| and \verb|max_pool| layers that we extract with the following code snippet:   from musicnn.extractor import extractor output = extractor taggram, tags, features = output  % %[H] %	}% %	\qquad %	}% %	% %	\label{fig:example}% %  What's the musicnn library for? Transfer learning. Our pre-trained deep learning models can be fine-tuned, together with an output neural-network that acts as a classifier, to perform any other music~task. To assess the utility of our embeddings, we build SVM classifiers on top of several pre-trained models that act as music feature extractors. The tools used to run this simple transfer learning experiment are accessible online:   		\url{https://github.com/jordipons/sklearn-audio-transfer-learning}   We report accuracy results on the test set of the GTZAN  dataset, and our processing pipeline consists of ``feature extraction'' + 128 PCA + SVM. The feature extraction can be based on VGGish audioset features , OpenL3 audioset features , \verb|MTT_musicnn| features , \verb|MTT_vgg| features , or \verb|MSD_musicnn| features . Note that our MSD pre-trained models outperform the MTT ones. Besides, the \verb|MSD_musicnn| achieves similar results than the VGGish audioset features .  %The VGGish  pre-trained model achieved 77.58\% accuracy in our test set. Employing this same setup with openl3 features, we achieve: 74.65\% accuracy. Interestingly, these basic models can achieve better results than a standard MFCCs + SVM classifier , and are quite competent when compared to the best result we are aware of: 82.1\% accuracy.   % SAY SOMETHING ABOUT EMBEDDINGS! The MSD works better??!  How did you train musicnn models? The code we employed to train the models above is also accessible:   	\url{https://github.com/jordipons/musicnn-training}   These models achieve state-of-the-art performance on the MagnaTagATune dataset: \verb|MTT_musicnn| \mbox{} and \verb|MTT_vgg| \mbox{}. But also for the Million Song Dataset:  \verb|MSD_musicnn| \mbox{},  \verb|MSD_musicnn_big| \mbox{} and \verb|MSD_vgg| \mbox{}.   %Musicnn MTT: ROC-AUC: 90.69 | PR-AUC: 38.44 | VAL-COST: 0.1304 %Musicnn MSD:  %Musicnn MSD big:  %Vgg MTT:  %Vgg MSD:  But the \verb|musicnn-training| framework also allows to implement other models. For example, a similar architecture than musicnn but with an attention-based output layer  can achieve 90.77 ROC-AUC / 38.61 PR-AUC on the MagnaTagATune dataset --- and 88.81 ROC-AUC / 31.51~PR-AUC on the Million Song Dataset. You can find further details about this new architecture online.  	     % % %[h] % %\label{sample-table} % %{ll} %\toprule %PART & DESCRIPTION \\ %\midrule %Dendrite         &Input terminal \\ %Axon             &Output terminal \\ %Soma             &Cell body  \\ % % %\label{tab:example} % % % % % %All bibliographical references should be listed at the end, %inside a section named ``REFERENCES,'' numbered and in alphabetical order. %All references listed should be cited in the text. %When referring to a document, type the number in square brackets %, or for a range . % %Indicate footnotes with a number in the text.\footnote{This is a footnote.}  
     Standard autoregressive seq2seq models are easily trained by max-likelihood, but tend to show poor results under small-data conditions. We introduce a class of seq2seq models, GAMs , which combine an autoregressive component with a log-linear component, allowing the use of global a priori features to compensate for lack of data. We train these models in two steps. In the first step, we obtain an  GAM that maximizes the likelihood of the data, but is improper for fast inference or evaluation. In the second step, we use this GAM to train  a second autoregressive model that approximates the  distribution associated with the GAM, and can be used for fast inference and evaluation. Our experiments focus on language modelling under synthetic conditions and show a strong perplexity reduction of using the second autoregressive model over the standard one. 
 A series of deep learning approaches extract a large number of credibility features to detect fake news on the Internet. However, these extracted features still suffer from many irrelevant and noisy features that restrict severely the performance of the approaches. In this paper, we propose a novel model based on Adversarial Networks and inspirited by the Shared-Private model , which aims at reducing common, irrelevant features from the extracted features for information credibility evaluation. Specifically, ANSP involves two tasks: one is to prevent the binary classification of true and false information for capturing common features relying on adversarial networks guided by reinforcement learning. Another extracts credibility features  from multiple types of credibility information and compares with the common features through two strategies, i.e., orthogonality constraints and KL-divergence for making the private features more differential. Experiments first on two six-label LIAR and Weibo datasets demonstrate that ANSP achieves the state-of-the-art performance, boosting the accuracy by 2.1\%, 3.1\%, respectively and then on four-label Twitter16 validate the robustness of the model with 1.8\% performance improvements. 
  Recently, generating adversarial examples has become an important means of measuring robustness of a deep learning model. Adversarial examples help us identify the susceptibilities of the model and further counter those vulnerabilities by applying adversarial training techniques. In natural language domain, small perturbations in the form of misspellings or paraphrases can drastically change the semantics of the text. We propose a reinforcement learning based approach towards generating adversarial examples in black-box settings. We demonstrate that our method is able to fool well-trained models for  IMDB sentiment classification task and  AG's news corpus news categorization task with significantly high success rates. We find that the adversarial examples generated are semantics-preserving perturbations to the original text.   
             In this work we present Ludwig, a flexible, extensible and easy to use toolbox which allows users to train deep learning models and use them for obtaining predictions without writing code.             Ludwig implements a novel approach to deep learning model building based on two main abstractions: data types and declarative configuration files.     		The data type abstraction allows for easier code and sub-model reuse, and the standardized interfaces imposed by this abstraction allow for encapsulation and make the code easy to extend.     		Declarative model definition configuration files enable inexperienced users to obtain effective models and increase the productivity of expert users.     		Alongside these two innovations, Ludwig introduces a general modularized deep learning architecture called Encoder-Combiner-Decoder that can be instantiated to perform a vast amount of machine learning tasks.     		These innovations make it possible for engineers, scientists from other fields and, in general, a much broader audience to adopt deep learning models for their tasks, concretely helping in its democratization.         
  %The task of adopting a model trained on the source to a distribution different target domain with good performance has received considerable attention in sentiment analysis.   %Domain-invariant representation learning  is one of the most popular frameworks for cross-domain sentiment analysis. However, in this work, we find out that DIRL may harm domain adaptation when the label distribution $\rm{P}$ changes across domains. To address this problem, we propose a modification to DIRL, obtaining a novel weighted domain-invariant representation learning  framework. We show that it is easy to transfer existing SOTA DIRL models to WDIRL. Empirical studies on extensive cross-domain sentiment analysis tasks verified our analysis and showed the effectiveness of our proposed solution.   Cross-domain sentiment analysis is currently a hot topic in the research and engineering areas. One of the most popular frameworks in this field is the domain-invariant representation learning  paradigm, which aims to learn a distribution-invariant feature representation across domains. However, in this work, we find out that applying DIRL may harm domain adaptation when the label distribution $\rm{P}$ changes across domains. To address this problem, we propose a modification to DIRL, obtaining a novel weighted domain-invariant representation learning  framework. We show that it is easy to transfer existing SOTA DIRL models to WDIRL. Empirical studies on extensive cross-domain sentiment analysis tasks verified our statements and showed the effectiveness of our proposed solution.    
 Automatic question generation is  an important problem in natural language processing.  In this paper we propose  a novel adaptive copying recurrent neural network model to tackle the problem of  question generation from sentences and paragraphs.  The proposed model adds a copying mechanism component onto a bidirectional LSTM architecture  to generate more suitable questions adaptively from the input data.  Our experimental results show the proposed model can outperform the state-of-the-art question generation methods in terms of BLEU and ROUGE evaluation scores.     
   Memory-augmented neural networks  have been shown to outperform other recurrent neural network architectures on a series of artificial sequence learning tasks, yet they have had limited application to real-world tasks. We evaluate direct application of Neural Turing Machines  and Differentiable Neural Computers  to machine translation. We further propose and evaluate two models which extend the attentional encoder-decoder with capabilities inspired by memory augmented neural networks. We evaluate our proposed models on IWSLT Vietnamese$\rightarrow$English and ACL Romanian$\rightarrow$English datasets. Our proposed models and the memory augmented neural networks perform similarly to the attentional encoder-decoder on the Vietnamese$\rightarrow$English translation task while have a 0.3-1.9 lower BLEU score for the Romanian$\rightarrow$English task. Interestingly, our analysis shows that despite being equipped with additional flexibility and being randomly initialized memory augmented neural networks learn an algorithm for machine translation almost identical to the attentional encoder-decoder. 
 Comprehensive IT support teams in large scale organizations require more man power for handling engagement and requests of employees from different channels on a 24$\times$7 basis. Automated email technical queries help desk is proposed to have instant real-time quick solutions and email categorisation. Email topic modelling with various machine learning, deep-learning approaches are compared with different features for a scalable, generalised solution along with sure-shot static rules.  Email's title, body, attachment, OCR text, and some feature engineered custom features are given as input elements. XGBoost cascaded hierarchical models, Bi-LSTM model with word embeddings perform well showing 77.3 overall accuracy For the real world corporate email data set. By introducing the thresholding techniques, the overall automation system architecture provides 85.6 percentage of accuracy for real world corporate emails. Combination of quick fixes, static rules, ML categorization as a low cost inference solution reduces 81 percentage of the human effort in the process of automation and real time implementation. 
 Compared to natural images, understanding scientific figures is particularly hard for machines. However, there is a valuable source of information in scientific literature that until now has remained untapped: the correspondence between a figure and its caption. In this paper we investigate what can be learnt by looking at a large number of figures and reading their captions, and introduce a figure-caption correspondence learning task that makes use of our observations. Training visual and language networks without supervision other than pairs of unconstrained figures and captions is shown to successfully solve this task. We also show that transferring lexical and semantic knowledge from a knowledge graph significantly enriches the resulting features. Finally, we demonstrate the positive impact of such features in other tasks involving scientific text and figures, like multi-modal classification and machine comprehension for question answering, outperforming supervised baselines and ad-hoc approaches.  
     % The ability to train bigger networks  with improved infrastructure has enhanced the performance in several machine learning tasks like object recognition, object detection, machine translation, face recognition, question-answering etc.     There has been a rapid progress in the task of Visual Question Answering with improved model architectures. Unfortunately, these models are usually computationally intensive due to their sheer size which poses a serious challenge for deployment. We aim to tackle this issue for the specific task of Visual Question Answering . A Convolutional Neural Network  is an integral part of the visual processing pipeline of a VQA model . In this project, we propose an efficient and modular neural architecture for the VQA task with focus on the CNN module. Our experiments demonstrate that a sparsely activated CNN based VQA model achieves comparable performance to a standard CNN based VQA model architecture. 
 NeMo  is a Python framework-agnostic toolkit for creating AI applications through re-usability, abstraction, and composition. NeMo is built around neural modules, conceptual blocks of neural networks that take typed inputs and produce typed outputs. Such modules typically represent data layers, encoders, decoders, language models, loss functions, or methods of combining activations. NeMo makes it easy to combine and re-use these building blocks while providing a level of semantic correctness checking via its neural type system. The toolkit comes with extendable collections of pre-built modules for automatic speech recognition  and natural language processing. Furthermore, NeMo provides built-in support for distributed training and mixed precision on latest NVIDIA GPUs. NeMo is open-source.\footnote{Available at: \url{https://github.com/NVIDIA/NeMo}} 
 	Long Short-Term Memory Recurrent Neural Networks  are one of the most powerful dynamic classifiers publicly known.  	The network itself and the related learning algorithms are reasonably well documented to get an idea how it works.  	This paper will shed more light into understanding how LSTM-RNNs evolved and why they work impressively well, focusing on the early, ground-breaking publications. 	We significantly improved documentation and fixed a number of errors and inconsistencies that accumulated in previous publications. 	To support understanding we as well revised and unified the notation used. 
 This paper introduces Strict Partial Order Networks , a novel neural network architecture designed to enforce asymmetry and transitive properties as soft constraints. We apply it to induce hypernymy relations by training with  pairs. We also present an augmented variant of SPON that can generalize type information learned for in-vocabulary terms to previously unseen ones. An extensive evaluation over eleven benchmarks across different tasks shows that SPON consistently either outperforms or attains the state of the art on all but one of these benchmarks. 
 Joint image-text embedding is the bedrock for most Vision-and-Language  tasks, where multimodality inputs are simultaneously processed for joint visual and textual understanding. In this paper, we introduce UNITER, a UNiversal Image-TExt Representation, learned through large-scale pre-training over four image-text datasets , which can power heterogeneous downstream V+L tasks with joint multimodal embeddings. We design four pre-training tasks: Masked Language Modeling , Masked Region Modeling , Image-Text Matching , and Word-Region Alignment . Different from previous work that applies joint random masking to both modalities, we use conditional masking on pre-training tasks . In addition to ITM for global image-text alignment, we also propose WRA via the use of Optimal Transport  to  encourage fine-grained alignment between words and image regions during pre-training.   Comprehensive analysis shows that both conditional masking and OT-based WRA contribute to better pre-training. We also conduct a thorough ablation study to find an optimal combination of pre-training tasks. Extensive experiments show that UNITER achieves new state of the art across six V+L tasks , including Visual Question Answering, Image-Text Retrieval, Referring Expression Comprehension, Visual Commonsense Reasoning, Visual Entailment, and NLVR$^2$.\footnote{Code is available at \url{https://github.com/ChenRocks/UNITER}.} 
 The performance of many network learning applications crucially hinges on the success of network embedding algorithms, which aim to encode rich network information into low-dimensional vertex-based vector representations. This paper considers a novel variational formulation of network embeddings, with special focus on textual networks. Different from most existing methods that optimize a discriminative objective, we introduce Variational Homophilic Embedding , a fully generative model that learns network embeddings by modeling the semantic  information with a variational autoencoder, while accounting for the structural  information through a novel { vertex embeddings encourage similar embedding vectors for related  vertices.  The proposed VHE promises better generalization for downstream tasks, robustness to incomplete observations, and the ability to generalize to unseen vertices. Extensive experiments on real-world networks, for multiple tasks, demonstrate that the proposed method consistently achieves superior performance relative to competing state-of-the-art approaches. 
 Self-training is one of the earliest and simplest semi-supervised methods. The key idea is to augment the original labeled dataset with unlabeled data paired with the model's prediction . While self-training has been extensively studied on classification problems, in complex sequence generation tasks  it is still unclear how self-training works due to the compositionality of the target space.  In this work, we first empirically show that self-training is able to decently improve the supervised baseline on neural sequence generation tasks. Through careful examination of the performance gains,  we find that the perturbation on the hidden states  is critical for self-training to benefit from the pseudo-parallel data, which acts as a regularizer and forces the model to yield close predictions for %semantically  similar unlabeled inputs. Such effect helps the model correct some incorrect predictions on unlabeled data. To further encourage this mechanism, we propose to inject noise to the input space, resulting in a ``noisy'' version of self-training. Empirical study on standard machine translation and text summarization benchmarks shows that noisy self-training is able to effectively utilize unlabeled data and improve the performance of the supervised baseline by a large margin.\footnote{Code is available at {https://github.com/jxhe/self-training-text-generation}.} % Moreover, when applying self-training to text the model needs to % decode at generation time, which forces the model to learn its own decoding process.  % Finally and more importantly, % we find that a ``noisy'' version of self-training, whereby noise is added to both inputs hidden states, % is critical to self-training success, as this acts like a regularizer which forces the model to yield similar predictions % for semantically similar inputs. We demonstrate this new version of self-training on two text generation tasks, machine % translation and summarization, reporting gains of up to XX BLEU and YY Rouge compared to the supervised baselines. %In this work, we comprehensively investigate self-training in the context of neural sequence generation,  %and find that the implicit perturbation of hidden states is a key factor for its success.  %To understand this phenomenon, we show that such injected noise during training has an effect of label  %propagation among the unlabeled data. Based on this observation, we propose to further perturb the input which  %results in a ``noisy'' version of self-training. Empirically, we demonstrate that noisy self-training  %is able to effectively utilize unlabeled data across machine translation and text summarization tasks under  %different resource settings. 
 This study compares the effectiveness and robustness of multi-class categorization of Amazon product data using transfer learning on pre-trained contextualized language models. Specifically, we fine-tuned BERT and XLNet, two bidirectional models that have achieved state-of-the-art performance on many natural language tasks and benchmarks, including text classification. While existing classification studies and benchmarks focus on binary targets, with the exception of ordinal ranking tasks, here we examine the robustness of such models as the number of classes grows from 1 to 20. Our experiments demonstrate an approximately linear decrease in performance metrics  with the number of class labels. BERT consistently outperforms XLNet using identical hyperparameters on the entire range of class label quantities for categorizing products based on their textual descriptions. BERT is also more affordable than XLNet in terms of the computational cost  required for training. In all cases studied, the performance degradation rates were estimated to be 1\% per additional class label. 
 We propose self-teaching networks to improve the generalization capacity of deep neural networks. The idea is to generate soft supervision labels using the output layer for training the lower layers of the network. During the network training, we seek an auxiliary loss that drives the lower layer to mimic the behavior of the output layer. The connection between the two network layers through the auxiliary loss can help the gradient flow, which works similar to the residual networks. Furthermore, the auxiliary loss also works as a regularizer, which improves the generalization capacity of the network. We evaluated the self-teaching network with deep recurrent neural networks on speech recognition tasks, where we trained the acoustic model using 30 thousand hours of data. We tested the acoustic model using data collected from 4 scenarios. We show that the self-teaching network can achieve consistent improvements and outperform existing methods such as label smoothing and confidence penalization.  
 % % Kanda's modification In this paper, we propose a novel end-to-end neural-network-based speaker diarization method. Unlike most existing methods, our proposed method does not have separate modules for extraction and clustering of speaker representations. Instead, our model has a single neural network that directly outputs speaker diarization results. To realize such a model, we formulate the speaker diarization problem as a multi-label classification problem, and introduces a permutation-free objective function to directly minimize diarization errors without being suffered from the speaker-label permutation problem. Besides its end-to-end simplicity, the proposed method also benefits from being able to explicitly handle overlapping speech during training and inference. Because of the benefit, our model can be easily trained/adapted with real-recorded multi-speaker conversations just by feeding the corresponding multi-speaker segment labels. We evaluated the proposed method on simulated speech mixtures. The proposed method achieved diarization error rate of 12.28\%, while a conventional clustering-based system produced diarization error rate of 28.77\%. Furthermore, the domain adaptation with real-recorded speech provided 25.6\% relative improvement on the CALLHOME dataset. Our source code is available online at \url{https://github.com/hitachi-speech/EEND}.  %  % 0404 version In this paper, we propose a novel end-to-end neural speaker diarization method that directly optimizes a diarization-error-oriented objective. Unlike most existing methods, our proposed method does not have separate modules for extraction and clustering of speaker representations. These modules are integrated into one neural network that can be jointly optimized to minimize diarization errors. To realize such an optimization, we formulate the speaker diarization problem as a multi-label classification problem, and introduces permutation-free schemes to solve the speaker-label permutation problem. Besides its end-to-end simplicity, the proposed method also benefits from being able to explicitly handle overlapping speech during training and inference. The model can be trained/adapted with real-recorded multi-speaker conversations and the corresponding multi-speaker segment ground truth labeling. We evaluated the proposed method on simulated speech mixtures. The proposed method achieved diarization error rate of 12.28\%, while a conventional clustering-based system produced diarization error rate of 28.77\%.  
 Speaker diarization has been mainly developed based on the clustering of speaker embeddings. %The dominant approach to speaker diarization has been clustering of speaker embeddings.  However, the clustering-based approach has two major problems; i.e.,  it is not optimized to minimize diarization errors directly, and  it cannot handle speaker overlaps correctly. To solve these problems, the End-to-End Neural Diarization , in which a bidirectional long short-term memory  network directly outputs speaker diarization results given a multi-talker recording, was recently proposed. In this study, we enhance EEND by introducing self-attention blocks instead of BLSTM blocks. In contrast to BLSTM, which is conditioned only on its previous and next hidden states, self-attention is directly conditioned on all the other frames, making it much suitable for dealing with the speaker diarization problem. We evaluated our proposed method on simulated mixtures, real telephone calls, and real dialogue recordings. The experimental results revealed that the self-attention was the key to achieving good performance and that our proposed method performed significantly better than the conventional BLSTM-based method. Our method was even better than that of the state-of-the-art x-vector clustering-based method. %, while it correctly handled speaker overlaps. %Finally, by visualizing the latent representation, we show that the similarity between distant frames is actually captured by the self-attention blocks. Finally, by visualizing the latent representation, we show that the self-attention can capture global speaker characteristics in addition to local speech activity dynamics. Our source code is available online at \url{https://github.com/hitachi-speech/EEND}.  
   In recent years, the softmax model and its fast approximations have become the de-facto loss functions for deep neural networks when dealing with multi-class prediction. This loss has been extended to language modeling and recommendation, two fields that fall into the framework of learning from Positive and Unlabeled data.      In this paper, we stress the different drawbacks of the current family of softmax losses and sampling schemes when applied in a Positive and Unlabeled learning setup. We propose both a Relaxed Softmax loss  and a new negative sampling scheme based on Boltzmann formulation. We show that the new training objective is better suited for the tasks of density estimation, item similarity and next-event prediction by driving uplifts in performance on textual and recommendation datasets against classical softmax. 
 % 100~150 word闉愵剣鏆爟 Voice activity detection , which classifies frames as speech or non-speech, is an important module in many speech applications including speaker verification. In this paper, we propose a novel method, called self-adaptive soft VAD, to incorporate a deep neural network -based VAD into a deep speaker embedding system.  The proposed method is a combination of the following two approaches. The first approach is soft VAD, which performs a soft selection of frame-level features extracted from a speaker feature extractor. %from a feature extractor for speaker verification.  %For a given utterance, DNN-based VAD produces frame-wise speech posteriors. The frame-level features are weighted by their corresponding speech posteriors estimated from the DNN-based VAD, and then aggregated to generate a speaker embedding. The second approach is self-adaptive VAD, which fine-tunes the pre-trained VAD on the speaker verification data to reduce the domain mismatch. Here, we introduce two unsupervised domain adaptation  schemes, namely speech posterior-based DA  and joint learning-based DA .  %Our experiments on the VoxCeleb and Korean speech databases Experiments on a Korean speech database demonstrate that the verification performance is improved significantly in real-world environments by using self-adaptive soft VAD. %which is the combination of self-adaptive VAD and soft VAD. %Instead of discarding audio using speech/non-speech decisions based on a threshold as done with VAD, soft-decision VAD weights the inputs  or the outputs from the speaker embedding network with their speech posteriors obtained from the VAD. %According to both VAD error analysis and speaker verification results utilizing state-of-the-art i-vector system, the proposed method outperforms energy VAD variants by a wide margin.  % 闉 闆茶導顑撻瀽鎰冲妧闆  
  Semantic parses are directed acyclic graphs , so semantic parsing should be modeled as graph prediction. But predicting graphs presents difficult technical challenges, so it is simpler and more common to predict the  graphs found in semantic parsing datasets using well-understood sequence models. The cost of this simplicity is that the predicted strings may not be well-formed graphs. We present recurrent neural network DAG grammars, a graph-aware sequence model that ensures only well-formed graphs while sidestepping many difficulties in graph prediction. We test our model on the Parallel Meaning Bank---a multilingual semantic graphbank. Our approach yields competitive results in English and establishes the first results for German, Italian and Dutch. 
 With the aim of promoting and understanding the multilingual version of image search, we leverage visual object detection and propose a model with diverse multi-head attention to learn grounded multilingual multimodal representations. Specifically, our model attends to different types of textual semantics in two languages and visual objects for fine-grained alignments between sentences and images. We introduce a new objective function which explicitly encourages attention diversity to learn an improved visual-semantic embedding space. We evaluate our model in the German-Image and English-Image matching tasks on the Multi30K dataset, and in the Semantic Textual Similarity task with the English descriptions of visual content. Results show that our model yields a significant performance gain over other methods in all of the three tasks. 
 Word embeddings are an essential component in a wide range of natural language processing applications. However, distributional semantic models are known to struggle when only a small number of context sentences are available. Several methods have been proposed to obtain higher-quality vectors for these words, leveraging both this context information and sometimes the word forms themselves through a hybrid approach. We show that the current tasks do not suffice to evaluate models that use word-form information, as such models can easily leverage word forms in the training data that are related to word forms in the test data. We introduce 3 new tasks, allowing for a more balanced comparison between models. Furthermore, we show that hyperparameters that have largely been ignored in previous work can consistently improve the performance of both baseline and advanced models, achieving a new state of the art on 4 out of 6 tasks. 
   Document-level context has received lots of attention for compensating neural machine translation  of isolated sentences.   However, recent advances in document-level NMT focus on sophisticated integration of the context, explaining its improvement with only a few selected examples or targeted test sets.   We extensively quantify the causes of improvements by a document-level model in general test sets, clarifying the limit of the usefulness of document-level context in NMT.   We show that most of the improvements are not interpretable as utilizing the context.   We also show that a minimal encoding is sufficient for the context modeling and very long context is not helpful for NMT.\\ 
 Neural machine translation has become the state-of-the-art for language pairs with large parallel corpora. However, the quality of machine translation for low-resource languages leaves much to be desired. There are several approaches to mitigate this problem, such as transfer learning, semi-supervised and unsupervised learning techniques. In this paper, we review the existing methods, where the main idea is to exploit the power of monolingual data, which, compared to parallel, is usually easier to obtain and significantly greater in amount. 
  %Machine reading comprehension  for question answering , which aims to answer a question given the relevant context passages, has been increasingly attracting attentions from both academia and industry in recent years.  Machine Reading Comprehension  for question answering , which aims to answer a question given the relevant context passages, is an important way to test the ability of intelligence systems to understand human language. Multiple-Choice QA  is one of the most difficult tasks in MRC because it often requires more advanced reading comprehension skills such as logical reasoning, summarization, and arithmetic operations, compared to the extractive counterpart where answers are usually spans of text within given passages. Moreover, most existing MCQA datasets are small in size, making the learning task even harder. We introduce {MMM}, a Multi-stage Multi-task learning framework for Multi-choice reading comprehension. Our method involves two sequential stages: coarse-tuning stage using out-of-domain datasets and multi-task learning stage using a larger in-domain dataset to help model generalize better with limited data. Furthermore, we propose a novel multi-step attention network  as the top-level classifier for this task. We demonstrate MMM significantly advances the state-of-the-art on four representative MCQA datasets.\footnote{Code is released: https://github.com/jind11/MMM-MCQA} %, which all surpass previous SOTA by at least 16\%. 
 The slot filling task aims at extracting answers for queries about entities from text, such as  ``Who founded Apple''. In this paper, we focus on the relation classification component of a slot filling system. We propose type-aware convolutional neural networks to benefit from the mutual dependencies between entity and relation classification. In particular, we explore different ways of integrating the named entity types of the relation arguments into a neural network for relation classification, including a joint training and a structured prediction approach. To the best of our knowledge, this is the first study on type-aware neural networks for slot filling. The type-aware models lead to the best results of our slot filling pipeline. Joint training performs comparable to structured prediction. To understand the impact of the different components of the slot filling pipeline, we perform a recall analysis, a manual error analysis and several ablation studies.  Such analyses are of particular importance to other slot filling researchers since the official slot filling evaluations only assess pipeline outputs. The analyses show that especially coreference resolution and our convolutional neural networks have a large positive impact on the final performance of the slot filling pipeline. The presented models, the source code of our system as well as  our coreference resource is publicy available. 
   Bootstrapping labels from radiology reports has become the scalable alternative to provide inexpensive ground truth for medical imaging. Because of the domain specific nature, state-of-the-art report labeling tools are predominantly rule-based. These tools, however, typically yield a binary 0 or 1 prediction that indicates the presence or absence of abnormalities. These hard targets are then used as ground truth to train image models in the downstream, forcing models to express high degree of certainty even on cases where specificity is low. This could negatively impact the statistical efficiency of image models. We address such an issue by training a Bidirectional Long-Short Term Memory Network to augment heuristic-based discrete labels of X-ray reports from all body regions and achieve performance comparable or better than domain-specific NLP, but with additional uncertainty estimates which enable finer downstream image model training. 
 Self-attention has been a huge success for many downstream tasks in NLP, which led to exploration of applying self-attention to speech problems as well. The efficacy of self-attention in speech applications, however, seems not fully blown yet since it is challenging to handle highly correlated speech frames in the context of self-attention. In this paper we propose a new neural network model architecture, namely multi-stream self-attention, to address the issue thus make the self-attention mechanism more effective for speech recognition. The proposed model architecture consists of parallel streams of self-attention encoders, and each stream has layers of 1D convolutions with dilated kernels whose dilation rates are unique given stream, followed by a self-attention layer. The self-attention mechanism in each stream pays attention to only one resolution of input speech frames and the attentive computation can be more efficient. In a later stage, outputs from all the streams are concatenated then linearly projected to the final embedding. By stacking the proposed multi-stream self-attention encoder blocks and rescoring the resultant lattices with neural network language models, we achieve the word error rate of 2.2\% on the test-clean dataset of the LibriSpeech corpus, the best number reported thus far on the dataset. 
  %--------spandana version---------------- User generated text on social media often suffers from a lot of undesired characteristics including hatespeech, abusive language,  insults etc. that are targeted to attack or abuse a specific group  of people. Often such text is written differently compared to traditional  text such as news involving either explicit mention of abusive words, obfuscated words and typological errors or implicit abuse i.e., indicating or targeting negative stereotypes. Thus, processing this text poses several robustness challenges when  we apply natural language processing techniques developed for traditional text. For example, using word or token based models to process such text can treat two spelling variants of a word as two different words. Following recent work,  we analyze how character, subword and byte pair encoding  models can be  aid some of the challenges posed by user generated text.  In our work, we analyze the effectiveness  of each of the above techniques, compare and contrast various   word decomposition techniques when used in combination with others. We experiment with finetuning large pretrained language models, and demonstrate their robustness  to domain shift by studying Wikipedia attack, toxicity  and Twitter hatespeech datasets.  %-----sravan version abstract ----------- %The text we see in social media suffers from lots of undesired   %characterstics like hatespeech, abusive language, insults etc.  %The nature of this text is also very different compared to the  %traditional text we see in news with lots of obfuscated words,  %intended typos. This poses several robustness challenges to  %many natural language processing  techniques developed for  %traditional text. Many techniques proposed in the recent times  %such as character encoding models, subword models, byte pair encoding to extract subwords can aid in dealing with few of these nuances.  %In our work, we analyze the effectiveness  %of each of the above techniques, compare and contrast various   %word decomposition techniques when used in combination with others. We experiment with recent advances of finetuning  %pretrained language models, and demonstrate their robustness  %to domain shift. We also show our approaches achieve  %state of the art performance on Wikipedia attack, toxicity datasets,  %and Twitter hatespeech dataset. 
 Pretrained deep contextual representations have advanced the state-of-the-art on various commonsense NLP tasks, but we lack a concrete understanding of the capability of these models. Thus, we investigate and challenge several aspects of BERT's commonsense representation abilities. First, we probe BERT's ability to classify various object attributes, demonstrating that BERT shows a strong ability in encoding various commonsense features in its embedding space, but is still deficient in many areas. Next, we show that, by augmenting BERT's pretraining data with additional data related to the deficient attributes, we are able to improve performance on a downstream commonsense reasoning task while using a minimal amount of data. Finally, we develop a method of fine-tuning knowledge graphs embeddings alongside BERT and show the continued importance of explicit knowledge graphs. 
 What information from an act of sentence understanding is robustly represented in the human brain? We investigate this question by comparing sentence encoding models on a brain decoding task, where the sentence that an experimental participant has seen must be predicted from the fMRI signal evoked by the sentence. We take a pre-trained BERT architecture as a baseline sentence encoding model and fine-tune it on a variety of natural language understanding  tasks, asking which lead to improvements in brain-decoding performance.  We find that none of the sentence encoding tasks tested yield significant increases in brain decoding performance. Through further task ablations and representational analyses, we find that tasks which produce syntax-light representations yield significant improvements in brain decoding performance. Our results constrain the space of NLU models that could best account for human neural representations of language, but also suggest limits on the possibility of decoding fine-grained syntactic information from fMRI human neuroimaging. 
 The performances of automatic speech recognition  systems are usually evaluated by the metric word error rate  when the manually transcribed data are provided, which are, however, expensively available in the real scenario.  In addition, the empirical distribution of WER for most ASR systems usually tends to put a significant mass near zero, making it difficult to simulate with a single continuous distribution.  In order to address the two issues of ASR quality estimation , we propose a novel neural zero-inflated model to predict the WER of the ASR result without transcripts.  We design a neural zero-inflated beta regression on top of a bidirectional transformer language model conditional on speech features .  We adopt the pre-training strategy of token level masked language modeling for speech-BERT as well, and further fine-tune with our zero-inflated layer for the mixture of discrete and continuous outputs.  The experimental results show that our approach achieves better performance on WER prediction compared with strong baselines. 
 %OL edited version Goal-oriented dialogue systems are now being widely adopted in industry where it is of key importance to maintain a rapid prototyping cycle for new products and domains. Data-driven dialogue system development has to be adapted to meet this requirement~--- therefore, reducing the amount of data and annotations necessary for training such systems is a central research problem.  In this paper, we present the Dialogue Knowledge Transfer Network , a state-of-the-art approach to goal-oriented dialogue generation which only uses a few example dialogues , none of which has to be annotated. We achieve this by performing a 2-stage training. Firstly, we perform unsupervised dialogue representation pre-training on a large source of goal-oriented dialogues in multiple domains, the MetaLWOz corpus. Secondly, at the transfer stage, we train DiKTNet using this representation together with 2 other textual knowledge sources with different levels of generality: ELMo encoder and the main dataset's source domains.  Our main dataset is the Stanford Multi-Domain dialogue corpus. We evaluate our model on it in terms of BLEU and Entity F1 scores, and show that our approach significantly and consistently improves upon a series of baseline models as well as over the previous state-of-the-art dialogue generation model, ZSDG. The improvement upon the latter~--- up to 10\% in Entity F1 and the average of 3\% in BLEU score~--- is achieved using only the equivalent of 10\% of  ZSDG's in-domain training data. % Although the prior work has been presented as a zero-shot model, we show that our approach 
 Due to the lack of publicly available resources, conversation summarization has received far less attention than text summarization. As the purpose of conversations is to exchange information between at least two interlocutors, key information about a certain topic is often scattered and spanned across multiple utterances and turns from different speakers. This phenomenon is more pronounced during spoken conversations, where speech characteristics such as backchanneling and false-starts might interrupt the topical flow. Moreover, topic diffusion and  topic drift are also more common in human-to-human conversations. Such linguistic characteristics of dialogue topics make sentence-level extractive summarization approaches used in spoken documents ill-suited for summarizing conversations.  Pointer-generator networks have effectively demonstrated its strength at integrating extractive and abstractive capabilities through neural modeling in text summarization. To the best of our knowledge, to date no one has adopted it for summarizing conversations. In this work, we propose a topic-aware architecture to exploit the inherent hierarchical structure in conversations to further adapt the pointer-generator model. Our approach significantly outperforms competitive baselines, achieves more efficient learning outcomes, and attains more robust performance. 
Complex networks based word embeddings.
 AAAI creates proceedings, working notes, and technical reports directly from electronic source furnished by the authors. To ensure that all papers in the publication have a uniform appearance, authors must adhere to the following instructions.  
 In this paper we focus on the problem of dialog act  labelling. This problem has recently attracted a lot of attention as it is an important sub-part of an automatic question answering system, which is currently in great demand. Traditional methods tend to see this problem as a sequence labelling task and deals with it by applying classifiers with rich features. Most of the current neural network models still omit the sequential information in the conversation.  Henceforth, we apply a novel multi-level gated recurrent neural network  with non-textual information to predict the DA tag. Our model not only utilizes textual information, but also makes use of non-textual and contextual information. %Experiment shows that our model performs better at short sentences.  In comparison, our model has shown significant improvement over previous works on Switchboard Dialog Act  task by over 6\%. 
 	 %Fake news or misinformation is one of the most challenging issues of society according to The World Economic Forum \footnote{http://reports.weforum.org/outlook-14/top-ten-trends-category-page/10-the-rapid-spread-of-misinformation-online/}. 	%Fake news is one of the most pressing issues of modern society. 	In fighting against fake news, many fact-checking systems comprised of human-based fact-checking sites  and automatic detection systems have been developed in recent years. However, online users still keep sharing fake news even when it has been debunked. It means that early fake news detection may be insufficient and we need another complementary approach to mitigate the spread of misinformation. In this paper, we introduce a novel application of text generation for combating fake news. In particular, we  leverage online users named , who cite fact-checking sites as credible evidences to fact-check information in public discourse;  analyze linguistic characteristics of fact-checking tweets; and  propose and build a deep learning framework to generate responses with fact-checking intention to increase the fact-checkers' engagement in fact-checking activities. Our analysis reveals that the fact-checkers tend to refute misinformation and use formal language . Our framework successfully generates relevant responses, and outperforms competing models by achieving up to 30\% improvements. Our qualitative study also confirms that the superiority of our generated responses compared with responses generated from the existing models.  %Our analysis reveal that fact-checkers tend to refute information posted in online users  %Fake news is everywhere. Thus, there are many detection approaches proposed. However, fake news still widely spread. In addition to detection, we need other methodologies. Educating people is an interesting approach . Another direction is to intervene spread of fake news.  %Following work studied fake news intervention behavior . We now build a model to generate fact-checking tweets as another proactive way to intervene the spread of fake news. This model is also helpful in detecting fake news as well.    %There are many approaches such as deploying bots or hiring crowd workers. However, these approaches may violate terms of services of online platform. Therefore, we propose to legitimately curate a group of guardians who usually embedding fact-checking URLs in their tweets. To utlize  %Since online users   to online users as a way to inform them  %.  disseminating URLs of verified information sources on social media   %by curating a group of online users who express enthusiasm in protecting credibility of online social network by posting fact-checking URLs from credible information sources. These users are called guardians and act as middle men in spreading correct information as a way to mitigate 
 Fake news is a type of pervasive propaganda that spreads misinformation online, taking advantage of social media閳ユ獨 extensive reach to manipulate public perception. Over the past three years, fake news has become a focal discussion point in the media due to its impact on the 2016 U.S. Presidential election. Fake news can have severe real-world implications: in 2016, a man walked into a pizzeria carrying a rifle because he read that 閳ユ窏illary Clinton was harboring children as sex slaves閳. This project presents a high accuracy  machine learning classifier that determines the validity of news based on the word distributions and specific linguistic and stylistic differences in the first few sentences of an article. This can help readers identify the validity of an article by looking for specific features in the opening lines aiding them in making informed decisions. Using a dataset of 2,107 articles from 30 different websites, this project establishes an understanding of the variations between fake and credible news by examining the model, dataset, and features. This classifier appears to use the differences in word distribution, levels of tone authenticity, and frequency of adverbs, adjectives, and nouns. The differentiation in the features of these articles can be used to improve future classifiers. This classifier can also be further applied directly to browsers as a Google Chrome extension or as a filter for social media outlets or news websites to reduce the spread of misinformation. 
 One of the goals of natural language understanding is to develop models that map sentences into meaning representations.  However, training such models requires expensive annotation of complex structures, which hinders their adoption. %Training models that produce meaning representations is mostly done through supervised learning, which requires expensive annotation, thus hindering their adoption.  Learning to actively-learn  is a recent paradigm for reducing the amount of labeled data by learning a policy that selects which samples should be labeled. In this work, we examine LTAL for learning semantic representations, such as QA-SRL. We show that even an  policy that is allowed to pick examples that maximize performance on the test set ,  does not substantially improve performance compared to a  policy. %, which constitutes an upper bound on the potential of LTAL as it is allowed to pick the examples that maximize its performance on a set sampled from the , does not substantially improve performance compared to a random policy. We investigate factors that could explain this finding and show that a distinguishing characteristic of successful  applications of LTAL is the interaction between optimization and the oracle policy selection process. In successful applications of LTAL, the examples selected by the oracle policy do not substantially depend on the optimization procedure, while in our setup  the stochastic nature of optimization  strongly affects the examples selected by the oracle. We conclude that the current applicability of LTAL for  improving data efficiency in learning semantic meaning representations is limited. %We thoroughly investigate factors that could explain the sub-optimal performance of the oracle policy, and find that, in all tested scenarios, achieving substantial gains over a random policy is difficult. We conclude that the applicability of LTAL for learning semantic representations is limited, as the samples selection process is mostly affected by the stochasticity of the optimization of such models, rather  than the contribution of the samples to the entire learning process.    %\gs{but if it's a problem specific to the oracle selection, what does it entail about actual LTAL selection process?} \gs{Abstract seems a little too long IMO, see comments for a shorter version.} 
 While translating between East Asian languages, many works have discovered clear advantages of using  characters as the translation unit. Unfortunately, traditional recurrent neural machine translation systems hinder the practical usage of those character-based systems due to their architectural limitations. They are unfavorable in handling extremely long sequences as well as highly restricted in parallelizing the computations. In this paper, we  demonstrate that the new transformer architecture can perform character-based translation better than the recurrent one. We conduct experiments on a low-resource language pair: Japanese-Vietnamese. Our models considerably outperform the state-of-the-art systems which employ word-based recurrent architectures.  
