article,summary
"The world seeing paradigm shift way conduct daily activities amidst ongoing coronavirus pandemic - online learning, way socialize, interact, conduct businesses shopping. Such global catastrophes direct effect social life; however, cultures react respond way given crisis. Even normal circumstances, research suggests people across different cultures reason differently . For instance, Nisbett book ""The geography thought: How Asians Westerners think differently... why"" stated East Asians think basis experience dialectically holistically, Westerners think logically, abstractly, analytically . This cultural behavior attitude mostly governed many factors, including socio-economic situation country, faith belief system, lifestyle. In fact, COVID-19 crisis showed greater cultural differences countries seem alike respect language, shared history culture. For example, even though Denmark Sweden two neighboring countries speak almost language share lot culture history, stand extreme ends spectrum comes way reacted coronavirus . Denmark Norway imposed robust lockdown measures closing borders, schools, restaurants, restricting gathering social contact, side, Sweden taken relaxed approach corona outbreak keeping schools, restaurants, borders open. Social media platforms play essential role extreme crisis individuals use communication channels share ideas, opinions, reactions others cope react crises. Therefore, study, focus exploring collective reactions events expressed social media. Particular emphasis given analyzing people's reactions global health-related events especially COVID-19 pandemic expressed Twitter's social media platform widespread popularity ease access using API. To end, tweets collected thousands Twitter users communicated within four weeks corona crisis analyzed understand different cultures reacting responding coronavirus. Additionally, extended version publicly available tweets dataset also used. A new model sentiment emotion analysis proposed. The model takes advantage natural language processing deep neural networks comprises two main stages. The first stage involves sentiment polarity classifier classifies tweets positive negative. The output first stage used input emotion classifier aims assign tweet either one positive emotions classes one negative emotions classes . Figure shows abstract model proposed system sentiment emotion analysis tweets' text. \subsection{Study Objective \& Research Questions} Our primary objective study understand different cultures behave react given global crisis. The state questions addressed cultural differences techno-social system reveals potentialities societal attitudinal, behavioral, emotional predictions. In present investigation, examine behavioral emotional factors describe societies react different circumstances, general objective analyze potential utilizing NLP-based sentiment emotional analysis techniques finding answers following research questions . \subsection{Contribution} The major contributions article following: {} The rest article organized follows. Section presents research design study dimensions. Related work presented section . Data collection procedure data preparation steps described section , whereas, sentiment emotion analysis model presented section . Section entails results followed discussion analysis section . Lastly, section concludes paper potential future research directions."," How different cultures react and respond given a crisis is predominant in a society's norms and political will to combat the situation. Often the decisions made are necessitated by events, social pressure, or the need of the hour, which may not represent the will of the nation. While some are pleased with it, others might show resentment. Coronavirus  brought a mix of similar emotions from the nations towards the decisions taken by their respective governments. Social media was bombarded with posts containing both positive and negative sentiments on the COVID-19, pandemic, lockdown, hashtags past couple of months. Despite geographically close, many neighboring countries reacted differently to one another. For instance, Denmark and Sweden, which share many similarities, stood poles apart on the decision taken by their respective governments. Yet, their nation's support was mostly unanimous, unlike the South Asian neighboring countries where people showed a lot of anxiety and resentment. This study tends to detect and analyze sentiment polarity and emotions demonstrated during the initial phase of the pandemic and the lockdown period employing natural language processing  and deep learning techniques on Twitter posts. Deep long short-term memory  models used for estimating the sentiment polarity and emotions from extracted tweets have been trained to achieve state-of-the-art accuracy on the sentiment140 dataset. The use of emoticons showed a unique and novel way of validating the supervised deep learning models on tweets extracted from Twitter."
"Knowledge transfer rapidly growing advancing research area AI. As humans, live world In practice, observed models become bigger performance grows. % Out commercial needs, committed improve privacy , security user experience . There many reasons reducing size models important, real-time inference efficiency deployment mobile devices. Transferring knowledge large, powerful models compact models proven practical solution. Clearly, knowledge transfer agents tasks important component towards AGI. %%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%% What knowledge transfer? In general, regarded learning process learners acquire new modify existing knowledge interacting teachers. If represent knowledge probabilistic distribution, e.g., \nonumber \end{align} Thus, learning means get closer , distributions learner teacher. It's natural relate knowledge transfer KL-divergence measures much information lost approximating distribution another. Existing approaches categorized minimizing KL-divergence order. Learners infinite capacity would end behaving exact way teachers. In case, order matter. Unfortunately, true. In practice, learners typically restricted simple function family, e.g., Gaussian, parameterized neural networks finite layers hidden units. Meanwhile, teachers perfect. noisy especially high-dimensional action space. The question order performs better? Previous works attempt analyze difference restricting Gaussian distributions. However, learning process, i.e., learner interact teacher acquires knowledge, totally unclear. In paper, reinterpret KL-divergence minimization knowledge transfer provide in-depth analysis way learner acquires knowledge teacher, without applying constraints distributions. At high level, noticed encourages learners exposed distributions reinforced on-policy learning. Thus, propose minimize solving sequential decision making problems. To verify hypothesis, revisit Knowledge Distillation attempts distill knowledge teacher learner minimizing Neural Machine Translation task. The goal task generate sequence tokens target language given sentence source language. The generation procedure is: position , given previous actions , try produce token expected give maximum reward . Basically, NMT solve sequential decision making problem high-dimensional, discrete action space. Exposure bias known important issue due lacking exploration. We simply replace call approach Knowledge Acquisition . We describe learning process dialog, shown Fig.. Empirical results show +0.7-1.1 BLEU gains WMT'17 De-En IWSLT'15 Th-En tasks. % related work"," Knowledge Transfer has been applied in solving a wide variety of problems. For example, knowledge can be transferred between tasks  or between agents . Without loss of generality, we relate knowledge transfer to KL-divergence minimization, i.e., matching the  distributions of learners and teachers. The equivalence gives us a new perspective in understanding variants of the KL-divergence by looking at how learners structure their interaction with teachers in order to acquire knowledge.  In this paper, we provide an in-depth analysis of KL-divergence minimization in \texttt{Forward} and \texttt{Backward} orders, which shows that learners are reinforced via on-policy learning in \texttt{Backward}. In contrast, learners are supervised in \texttt{Forward}. Moreover, our analysis is gradient-based, so it can be generalized to arbitrary tasks and help to decide which order to minimize given the property of the task. By replacing \texttt{Forward} with \texttt{Backward} in Knowledge Distillation, we observed +0.7-1.1 BLEU gains on the WMT'17 De-En and IWSLT'15 Th-En machine translation tasks."
"Digital humanities transdisciplinary subject information technologies humanities, literary classics. For instance, Google makes contribution digital humanities promoting ``Google Books Library Project'' includes millions paper books scanned electronic text . Digital text easier researchers explore printed books, since development information technology provided numerous effective tools . In past decade, overwhelming data science techniques advanced research digital humanities; thus, components extracted analyzed literature. A review previous research reveals areas digital humanities remain unexplored. First, mainstream studies limited humanities works background Western world . It interesting constructive investigate humanities works oriental backgrounds. Second, comparative studies literature different styles story conducted . Particularly, previous researches focused longitudinal studies, wherein researchers usually adopt story series, Harry Potter Books 1閳7, object study . A potential research interest story discovers varied features sentiments arise different literature, may driven literary genres authors閳 opinion, among others. Third, network study essential social network story network possesses topological structure, help gain insight story閳ユ獨 characters based grand narration . To fill gap, paper introduces social network sentimental analysis work two different texts one famous Chinese story, The Three Kingdoms. In particular, leverage state-of-the-art natural language processing -based model extract social networks narratives two books. A series descriptive statistical analysis extracted networks conducted, discover homogeneity heterogeneity terms topological features networks. Additionally, adopt sentimental analysis compare evaluations main characters. The results reveal social network complicated narrative novel historical text . Consequently, concluded literariness stories tight relationship complexity social networks entail. The main contribution paper follows: The remainder paper organized follows. In Section , backgrounds text mining social network analysis researches presented. Section elaborates network extraction approach. We perform series empirical studies Section demonstrate thesis work. Finally, paper concluded Section summary potential future studies."," Digital humanities is an important subject because it enables developments in history, literature, and films. In this paper, we perform an empirical study of a Chinese historical text, Records of the Three Kingdoms , and a historical novel of the same story, Romance of the Three Kingdoms . We employ natural language processing techniques to extract characters and their relationships. Then, we characterize the social networks and sentiments of the main characters in the historical text and the historical novel. We find that the social network in Romance is more complex and dynamic than that of Records, and the influence of the main characters differs. These findings shed light on the different styles of storytelling in the two literary genres and how the historical novel complicates the social networks of characters to enrich the literariness of the story."
"\subsection{Background} With rapid development online social network Twitter Facebook, people frequently using OSN express opinions emotions. It provides researchers novel effective way detect mood, communication, activity, social behavior pattern individuals . In past decade, researchers various fields conducted quantitative analyses different illnesses mental disorders based OSN platform . Sina Weibo popular OSN Chinese community . A statistic shows number Weibo's monthly active users reached 480 million second quarter 2019\footnote{https://www.statista.com/statistics/941456/china-number-of-sina-weibo-users/}. Major depressive disorder, referred depression, common mental disease. According survey World Health Organization \footnote{https://www.who.int/en/news-room/fact-sheets/detail/depression}, 300 million people worldwide suffer depression. Depression cause great psychological pain, even suicidal tendencies. Moreover, evidence health action plan WHO\footnote{https://www.who.int/mental\_health/action\_plan\_2013/en/} shows people suffering depression much likely end life prematurely general population. Despite current availability psychotherapy, medical therapy, modalities treatment depression, 76\%-85\% patients low- middle-income countries remain untreated. The emergence phenomenon lack medical resources also inability make accurate assessment early stage depression, leads large number people depression difficult get diagnosis treatment timely . Pictures, text, videos, information posted OSN reflect feelings worthlessness, guilt, helplessness, self-hatred, help researchers specifically analyze characterize depressed individuals . However, insurmountable problems online depression detection using traditional analyzing methods. They often focus analyzing characteristics users depression rather constructing predictive models. Therefore, difficult give timely prediction results new depressed users. Moreover, incapable deal large number instant interactive user data. With rapid development artificial intelligence technologies, machine learning approaches made great contributions detection depression . An automated depression detection model based machine learning usually needs analyze various information tweets, pictures, videos, social activity data users. Then, gives classification results predicted objects, presented binary result normal depressive. If individual predicted potential depressive tendency, resources assistance provided, including later medical psychological diagnoses. Such heuristic learning approaches quite effective helping early detection depression since capable handling large number instant interactive user data. \subsection{Challenges} However, current approaches online depression detection still face many unresolved challenges. Firstly, many current studies user-oriented modeling . Those works usually aim analyze model language style user. Through sentiment analysis feature engineering tweet text, classification model developed detect whether specific tweet depressive tendency. These works analyzed fine-grained features achieved pretty good results. However, results cannot directly applied user-level depression detection, may lead incorrect prediction. Second, several existing studies , size dataset used modeling insufficient, hundred thousand data samples used. Because difficulty accurately obtaining labeling depressed samples, researchers usually choose construct small datasets directly cited datasets works. As consequence, trained model fails reach good generalization performance, thus hard accurately predict depressed users OSN. Moreover, enough studies user depression detection proposed Weibo compare Twitter Facebook. To best knowledge, published large Weibo user depression detection dataset available currently. Finally, many existing proposed models still reach high level classification performance, i.e. F1-Score 90\% above. Thus, models need improved achieve better performance. \subsection{Contributions} Given problems challenges, hereby summarize contributions work below: The subsequent sections paper organized follows. In Section \uppercase\expandafter{\romannumeral2}, related work achievements field depression detection OSNs introduced analyzed. The proposed framework elaborated Section \uppercase\expandafter{\romannumeral3}. Furthermore, Section \uppercase\expandafter{\romannumeral4} gives significance evaluation statistical features performance comparison experiments several classification models . At last paper, Section \uppercase\expandafter{\romannumeral5} summarizes work discusses directions future work."," In recent years, due to the mental burden of depression, the number of people who endanger their lives has been increasing rapidly. The online social network  provides researchers with another perspective for detecting individuals suffering from depression. However, existing studies of depression detection based on machine learning still leave relatively low classification performance, suggesting that there is significant improvement potential for improvement in their feature engineering. In this paper, we manually build a large dataset on Sina Weibo , namely Weibo User Depression Detection Dataset . It includes more than 20,000 normal users and more than 10,000 depressed users, both of which are manually labeled and rechecked by professionals. By analyzing the user's text, social behavior, and posted pictures, ten statistical features are concluded and proposed. In the meantime, text-based word features are extracted using the popular pretrained model XLNet. Moreover, a novel deep neural network classification model, i.e. FusionNet , is proposed and simultaneously trained with the above-extracted features, which are seen as multiple classification tasks. The experimental results show that FusionNet achieves the highest F1-Score of 0.9772 on the test dataset. Compared to existing studies, our proposed method has better classification performance and robustness for unbalanced training samples. Our work also provides a new way to detect depression on other OSN platforms."
"As unsupervised approach, topic modelling enjoyed great success automatic text analysis. In general, topic model aims discover set latent topics collection documents, describes interpretable semantic concept. Topic models like Latent Dirichlet Allocation ~ hierarchical/Bayesian extensions, e.g., in~\citet{blei2010nested,paisley2015nested,gan2015learning,zhou2016augmentable} achieved impressive performance document analysis. Recently, developments Variational AutoEncoders Autoencoding Variational Inference ~ facilitated proposal Neural Topic Models in~\citet{miao2016neural,srivastava2017autoencoding,krishnan2018challenges,burkhardt2019decoupling}. Inspired VAE, many NTMs use encoder takes Bag-of-Words representation document input approximates posterior distribution latent topics. The posterior samples input decoder reconstruct BoW representation. Compared conventional topic models, NTMs usually enjoy better flexibility scalability, important applications large-scale data. Despite promising performance recent popularity, several shortcomings existing NTMs, could hinder usefulness extensions. i) The training inference processes NTMs typically complex due prior posterior constructions latent topics. To encourage topic sparsity smoothness, Dirichlet~ gamma~ distributions usually used prior posterior topics, reparameterisation inapplicable them, thus, complex sampling schemes approximations used, could limit model flexibility. ii) A desideratum topic model generate better topical representations documents coherent diverse topics; many existing NTMs, hard achieve good document representation coherent/diverse topics time. This objective NTMs achieve lower reconstruction error, usually means topics less coherent diverse, observed analysed in~. iii) It well-known topic models degrade performance severely short documents tweets, news headlines product reviews, individual document contains insufficient word co-occurrence information. This issue exacerbated NTMs use encoder decoder networks, vulnerable data sparsity. To address shortcomings NTMs, paper propose neural topic model, built upon novel Optimal Transport framework derived new view topic modelling. For document, consider content encoded two representations: observed representation, , distribution words vocabulary latent representation, , distribution topics. obtained normalising document's word count vector needs learned model. For document collection, vocabulary size large one individual document usually consists tiny subset words. Therefore, sparse low-level representation semantic information document. As number topics much smaller vocabulary size, relatively dense high-level representation content. Therefore, learning topic model viewed process learning distribution close distribution possible. Accordingly, crucial investigate measure distance two distributions different supports. As optimal transport powerful tool measuring distance travelled transporting mass one distribution match another given specific cost function, recent development computational OT shown promising feasibility efficiently compute OT large-scale problems, natural us develop new NTM based minimisation OT. Specifically, model leverages encoder outputs topic distribution document taking word count vector input like standard NTMs, minimise OT distance , two discrete distributions support words topics, respectively. Notably, cost function OT distance specifies weights topics words, define distance embedding space, embed topics words represent semantics. By leveraging pretrained word embeddings, cost function function topic embeddings, learned jointly encoder. With advanced properties OT modelling geometric structures spaces probability distributions, model able achieve better balance obtaining good document representation generating coherent/diverse topics. In addition, model eases burden designing complex sampling schemes posterior NTMs. More interestingly, model natural way incorporating pretrained word embeddings, demonstrated able alleviate issue insufficient word co-occurrence information short texts~. With extensive experiments, model shown enjoy state-of-the-art performance terms topic quality document representations regular short texts."," Recently, Neural Topic Models  inspired by variational autoencoders have obtained increasingly research interest due to their promising results on text analysis. However, it is usually hard for existing NTMs to achieve good document representation and coherent/diverse topics at the same time. Moreover, they often degrade their performance severely on short documents. The requirement of reparameterisation could also comprise their training quality and model flexibility. To address these shortcomings, we present a new neural topic model via the theory of optimal transport . Specifically, we propose to learn the topic distribution of a document by directly minimising its OT distance to the document's word distributions. Importantly, the cost matrix of the OT distance models the weights between topics and words, which is constructed by the distances between topics and words in an embedding space. Our proposed model can be trained efficiently with a differentiable loss. Extensive experiments show that our framework significantly outperforms the state-of-the-art NTMs on discovering more coherent and diverse topics and deriving better document representations for both regular and short texts."
"Even advent COVID-19 pandemic, people across world turning internet find answers medical concerns . Around 7\% Google閳ユ獨 daily searches health related, equivalent around 70,000 queries every minute . With emergence medical question-answering websites ADAM , WebMD , AskDocs HealthTap , people opportunity ask detailed questions find answers, experts, satisfied needs. COVID-19 done nothing accelerate trend. Almost every government agency healthcare organization tried meet informational need users building online FAQs try address many COVID-related topics possible %With ubiquity Internet emergence medical question-answering websites ADAM , WebMD , HealthTap , people increasingly searching online answers medical questions. Pew Internet Project surveys consistently find 75-83\% internet users look online health information . The examples already illustrate two important problems medical Q\&A collection: large number possible questions formulated different ways, easy user browse large collection pre-existing questions find one resembles need. A scalable solution overcome issues build system automatically match user formulated questions semantically similar answered questions, provide suggestions users. If similar answered questions exist, mark priority experts respond. This approach directly satisfies user needs allowing use words formulate question. It also provides avenue collecting unanswered questions users want answered, extremely important rapidly changing situation currrent COVID-19 pandemic. %However, number people asking medical questions online far exceeds number qualified experts -- i.e doctors -- answering them. A scalable solution overcome imbalance build system automatically match unanswered questions semantically similar answered questions, provide suggestions users. When similar answered questions exist, mark priority doctors respond. This approach uses doctor time efficiently, reducing number unanswered questions lowering cost providing online care. %Many individuals seeking medical advice online otherwise reluctant seek medical help due cost, convenience, embarrassment. For patients, accurate online system critical may medical advice receive. Of course, medical problems require in-person care, online system must indicate that. Other patients use internet addition in-person care either determine appointment needed follow visits lingering questions. For second group, answers see online match given doctors, less likely follow advice doctors , serious consequences. The problem matching general unanswered questions semantically similar answered questions well-studied context online user forums , community QA question answer archives . Typical approaches either assume large amount training data which, either statistics computed models learned. However, approaches fall short applied problem medical question similarity. First, medical questions imbibe large amount medical information single word completely change meaning question. As example, I閳ユ獡 pregnant I believe I閳ユ獫e infected coronavirus. What I know going hospital? Should I visit doctor I expecting think I might COVID-19? similar questions low overlap, Is safe take Vitamin D3 supplements build immunity Coronavirus? Is safe take Hydroxychloroquine build immunity Coronavirus? critically different couple words apart. Second, publicly available medical question-question similarity data scale differences effectively encoded order learn reliable similarity function. In fact, hypothesize constructing large datasets cover large functional space nuanced variations medical domain quite hard, scalable proposition. %Coming accurate algorithm finding similar medical questions, however, difficult. Simple heuristics word-overlap ineffective Can menstrual blood clot travel heart lungs like blood clots can? Can clots period cause stroke embolism? similar questions low overlap, Is candida retested treatment Is Chlamydia retested treatment? critically different one word apart. Machine learning good candidate complex tasks, requires labeled training data. As widely available data particular task exists, generate release dataset medical question pairs ones shown Table. % \TODO{Can least add COVID-19 related example?} \end{center} \end{table} % \footnote{We acknowledge fails edge cases. For instance, answers two questions ""Yes, correct"", mean questions similar.} In paper, tackle general problem medical question-question similarity, assuming small amount labeled data similarity pairs. We also apply general solution specific COVID-19 scenario many different questions different sources integrated user-friendly experience. Our proposed solution stems two key insights: First, whether two questions semantically similar akin asking whether answer one also answers other. This means answers answered questions contain wealth medical knowledge distilled model. The second insight infuse medical knowledge answers pretraining task within language model, capture relatedness words/concepts language. Recent success pretrained bi-directional transformer networks natural language processing non-medical fields supports insight . % In examples above, answer question Can clots period cause stroke embolism? talk about, instance, `menstrual blood' `bleeding' establishes relationships `period' `menstrual blood'. Similar connection established heart, lungs embolism. In contrast, answers around candida treatment likely discuss yeast around Chlamydia bacteria. %The second insight infuse medical knowledge answers pre-training task within language model, capture relatedness words/concepts language. Recent success pre-trained bi-directional transformer networks natural language processing non-medical fields supports insight . % \TODO{Can find COVID-19 related example?} %Given recent success pre-trained bi-directional transformer networks natural language processing outside medical field , research efforts medical NLP tried apply general language models medical tasks . However, models trained medical information, make errors reflect this. Our approach stems augmenting general language model BERT, medical knowledge process double fine-tuning first distills medical knowledge using large corpus relevant in-domain task medical question-answer pairs. Subsequently, fine-tunes available small corpus question-question similarity dataset. Our models pretrained medical question-answer pairs outperform models pretrained out-of-domain question similarity high statistical significance. In particular, pretraining tasks yield accuracy 78.7\% task, model achieves accuracy 82.6\% number training examples, accuracy 80.0\% much smaller training set, accuracy 84.5\% full corpus medical question-answer data used. % Furthermore, results show promise generalizing domains well. We present early results extensibilty approach another expert domain: question-question similarity context community driven question answer website Ubuntu operating system. %The task question-answer matching specifically chosen closely related question similarity; one component whether two questions semantically similar whether answer one also answers other. We show performance gains achieved particular task realized in-domain tasks, medical question-categorization medical answer completion. %However, labeled training data still one largest barriers supervised learning, particularly medical field expensive get doctor time hand-labeling data. } The main contributions paper are: The rest paper structured follows: \S describes methodology used creating dataset made publicly available. \S provides overview approach. \S describes used model build service matches user's COVID-19-related questions FAQs published online. \S describes experimental details key results, % \S gives peek application methodology domains. \S discusses related work end discussion future work."," People increasingly search online for answers to their medical questions but the rate at which medical questions are asked online significantly exceeds the capacity of qualified people to answer them. This leaves many questions unanswered or inadequately answered. Many of these questions are not unique, and reliable identification of similar questions would enable more efficient and effective question answering schema. COVID-19 has only exacerbated this problem. Almost every government agency and healthcare organization has tried to meet the informational need of users by building online FAQs, but there is no way for people to ask their question and know if it is answered on one of these pages. While many research efforts have focused on the problem of general question similarity, these approaches do not generalize well to domains that require expert knowledge to determine semantic similarity, such as the medical domain. In this paper, we show how a double fine-tuning approach of pretraining a neural network on medical question-answer pairs followed by fine-tuning on medical question-question pairs is a particularly useful intermediate task for the ultimate goal of determining medical question similarity. While other pretraining tasks yield an accuracy below 78.7\% on this task, our model achieves an accuracy of 82.6\% with the same number of training examples, an accuracy of 80.0\% with a much smaller training set, and an accuracy of 84.5\% when the full corpus of medical question-answer data is used. We also describe a currently live system that uses the trained model to match user questions to COVID-related FAQs. %We also present early experimental evidence suggesting the applicability of our proposed approach on another completely different domain: question-question similarity in the context of community driven question and answer website for the Ubuntu operating system."
"% Alternative first paragraph: %The goal acoustic scene classification identify class given audio recording, e.g., park, office, library. The ASC task challenging sounds within certain scenes similar characteristics, sound events overlap one another. The growing interest solving ASC problem, confirmed high participation researchers academia industry recent IEEE Detection Classification Acoustic Scenes Events challenge , justified impact robust ASC system several real-world applications. For instance, hearing aid devices modify behaviour accordingly different acoustic envijironments. % If paragraph becomes first paragraph, could reduced, simply say deep learning greatly improved performance ASC. Although many different solutions proposed years, interested reader referred official DCASE website, key elements successful ASC system CNN, data-augmentation, attention, mix-up. % Then need make clear device mismatch problem received less attention, proposal put forth, example . You clarify key problem right away say want address Knowledge distillation. The third paragraph look good needs polished perhaps trimmed bit. Instead, contribution must make stronger. What new work people pay attention it. %The goal acoustic scene classification identify class given audio recording, e.g., park, airport, metro station . The ASC task challenging sounds within certain scenes similar characteristics, sound events overlap one another. The growing interest solving ASC problem, indicated high participation researchers academia industry recent IEEE Detection Classification Acoustic Scenes Events challenges , justified impact robust ASC system real-world applications. For instance, hearing aid devices could modify behaviour accordingly different acoustic environments. In recent years, witnessed great progress acoustic scene classification task, demonstrated high participation IEEE Detection Classification Acoustic Scenes Events challenges . Top ASC systems use deep neural networks , main ingredient success application deep convolutional neural networks . Further boost ASC performance obtained introduction advanced deep learning techniques, attention mechanism , mix-up , Generative Adversial Network Variational Auto Encoder based data augmentation , deep feature learning . Nevertheless, ASC systems yet work well processing audios mismatched domain, e.g., audios recorded different devices . Device mismatch inevitable problem real production, therefore important aspect handle deploying ASC system. Indeed, new sub-task, namely Task1b, added DCASE 2018 foster research direction. The goal design system attain good performance 10-second audios segments collected target devices, either represented development phase, represented ASC system deployment scarce amount training material compared available source device. However, Task1b attracted minor interest among DCASE 2018 2019 participants, even fewer teams directly concerned device mismatch issue. %There exist approaches proposed tackle domain invariant problem ASC. For example, multi-instance learning , low-level mid-level feature learning , transfer knowledge across domains thereby tackle robustness issue broader sense. In literature, exist approaches tackle domain invariant problem ASC. For example, multi-instance learning , low-level mid-level feature learning , however address robustness issue broader sense. Less approaches instead proposed directly combat ASC device mismatch issue, actually focus present work. In particular, spectrum correction channel conversion build front-end module convert speech features source domain target domain feeding back-end classifier. Besides front-end features, mid-level feature based transfer systems, uses bottleneck features hidden layer representations adopted transfer knowledge source target domain. Adversarial training methods leverage extra domain discriminator solve device mismatch problem although key focus lack labeled target data. %Although mentioned techniques beneficial ASC robustness issue, yet clear gap source target device classification results. %In work, device mismatch problem investigated within Teacher-student learning, also named knowledge distillation , recently shown effective ASC domain adaptation speech tasks, e.g., . The key idea minimizes distance measurement teacher student model output distributions, i.e., information transferred soft-label level. %, namely class posterior probabilities, embedded structure relationships among output classes, usually used transfer knowledge teacher model student model. %In recent years, researchers propose relational learning . It directly models relationships sample pairs teacher student model. In , relational knowledge distillation demonstrated improve knowledge distillation process. RKD takes account relations outputs rather individual outputs themselves. %Independently whether relationships among outputs taken account, TS methods require effective soft labels accurately generated; otherwise, information encoded labels meaningless. %Among TS learning methods, There necessary condition get good effects, soft label must accurate enough, otherwise information encoded soft labels dose make senses. %As consequence, Unfortunately, conventional TS learning applied success if: source target data similar domain , source target data come pair although belong different domains . Neural label embedding , recently proposed , ingenues solution distill knowledge across domains neither aforementioned two requirements could met. %NLE embedding label level encode structural relationships among pair output classes deep neural models. Structural relationships turn represent measurements similarity dissimilarity among pairs objects distances points low-dimensional space. Label embedding viewed centroid soft labels class. NLE viewed centroid soft labels class. As extension soft labels, encodes knowledge distilled source domain teacher model, transferred target domain. %%More information build NLE given Section . In , NLE applied accent children's adaptation automatic speech recognition. %In work, extend NLE design started deploy NLE teacher-student adaptation approach combat ASC robustness problem presence source target device mismatch. In study, extend NLE adaptation scheme taking account relationships among different acoustic scenes adaptation. We achieve goal proposing relational teacher student learning approach based NLE ASC device mismatching problem. First, NLE learned relatively large-size source data set, i.e., collected source devices. %The source device data encodes structural relationships among different acoustic scenes. Next, ASC system adapted target device leveraging upon target domain data only, i.e., teacher-student learning unpaired data, set NLE, one per acoustic scene class. The proposed solution assessed DCASE 2018 Task1b data. Experimental results confirm intuitions demonstrate adaptation technique generates significant classification improvement target domain data. Indeed, NLE-based TS adaptation outperforms multi-device training strategies, conventional TS adaptation schemes. Furthermore, additional boost obtained TS adaptation carried leveraging structural information. %In work, solve device mismatching problem ASC systemss, focus structural relationship among scene classes. We propose novel NLE relational teacher student learning approach solve domain mismatch problem ASC. At first, label embedding learned relatively large-size source domain data, encode structural relationship information classes. Then system target domain data trained label embedding criterion including relationship loss. Our proposed approached evaluated DCASE2018 task1b development data. The experimental results verify methods obtain significant improvement target domain data. And visualization verify arguments structural relationships. %The rest work organized follows: Section describes NLE, including generation use. The relational TS learning framework described Section. Next, Section shows experimental results analysis. Finally, Section concludes work."," %The device domain mismatch issue is an important problem of acoustic scene classification  for real-world applications. To leverage this problem, we focus on the knowledge transfer of the inner structural relationships between each classes. A label embedding with relational teacher student learning approach is proposed. Embedded labels are learned from the source domain data, which encodes the structural relationships. Then a relational teacher student learning framework is used to transfer knowledge. Our proposed approach is evaluated on DCASE2018 task1b data set. And the experimental and visualized results successfully verify our augment and proposed method, which significantly improve the classification accuracy on target device data, with the knowledge transferred from the source device data.  %  Alternative 1: %In this work, we use a model adaptation approach based on  neural label embedding  and  knowledge distillation to combat the accuracy drop in acoustic scene classification with deep neural networks caused by a mismatch between  development  and production  audio recording devices. The proposed adaptation approach works with unpaired source-target data and leverages upon NLE designed to take into account the relationships among acoustic scene classes. The NLE thereby not only condenses a representation of the DNN output distribution given all audio recordings aligned with the same output class but also captures the inherent relationships among acoustic scene classes. Device adaptation is carried out using relational teacher-student learning  solely based on target data, target labels, source DNN, and NLE. The latter serve as soft targets for DNN adaptation.  The proposed approach is assessed against the DCASE 2018 task1b dataset. Experimental evidence confirm the effectiveness our our approach, which compares favourably to conventional device adaptation, and traditional teacher-student based adaptation. Moreover, we observe that NLE based on structural information lead to superior ASC  results than NLE obtained with symmetric Kullback-Leibler divergence ,which do not take into account the relationships among acoustic scene classes.  % Alternative 2 In this paper, we propose a domain adaptation framework to address the device mismatch issue in acoustic scene classification leveraging upon neural label embedding  and relational teacher student learning .  Taking into account the structural relationships between acoustic scene classes, our proposed framework captures such relationships which are intrinsically device-independent. In the training stage, transferable knowledge is condensed in NLE from the source domain. Next in the adaptation stage, a novel RTSL strategy is adopted to learn adapted target models without using paired source-target data often required in conventional teacher student learning. The proposed framework is evaluated on the DCASE 2018 Task1b data set. Experimental results based on AlexNet-L deep classification models confirm the effectiveness of our proposed approach for mismatch situations. %when training with Device A data and testing with data recorded with Devices B and C.  NLE-alone adaptation compares favourably with the conventional device adaptation and teacher student based adaptation techniques. NLE with RTSL further improves the classification accuracy."
"%Motivate bit ASR side %Introduce bit punctuation problem. The output text generated automatic speech recognition systems typically devoid punctuation sentence formatting. Lack sentence segmentation punctuation makes difficult comprehend ASR output. For example, consider two sentences: ``Let's eat Grandma'' vs. ``Let's eat, Grandma!''. Punctuation restoration helps understand context text also greatly improves readability. Punctuated text often helps boosting performance several downstream natural language understanding tasks.% There plethora work done punctuation prediction past decades. While early methods punctuation prediction used finite state hidden markov models , techniques investigated probabilistic models like language modeling , conditional random fields maximum entropy models . As neural networks gained popularity, several approaches proposed based sequence labeling neural machine translation . These models widely used convolutional neural networks LSTM based architectures . More recently, attention transformer based architectures successfully applied wide variety tasks, shown perform well punctuation prediction. Although well explored problem literature, improvements directly translate domains. In particular, punctuation prediction conversational speech well explored . Also, number approaches proposed exploiting use acoustic features addition lexical features punctuation task, rather limited clearly address gap performance ASR outputs. In paper, focus multimodal semi-supervised deep learning approach punctuation prediction conversational speech leveraging pretrained lexical acoustic encoders. %two set approaches emerged. One approach tags every word punctuation following punctuation mark treating sequence labeling problem . The second approach uses machine translation based sequence sequence models generate punctuated text unpunctuated text . \subsection{Relation prior multimodal work} While several methodologies used either text acoustic information predicting punctuation, many studies show combining features yields best performance . Acoustic features widely used literature include prosodic information pause duration, phone duration, pitch related values like fundamental frequency, energy. shows using acoustic information lead increased recognition full stops. In , hierarchical encoder used encode per frame acoustic features word level features results show incorporating acoustic features significantly outperform purely lexical systems. However, trained large independent text corpus, lexical system outperformed multimodal system trained parallel audio/text corpora. To mitigate this, work introduced speech2vec embeddings vary respect acoustic context reference speech. In general, identify two potential shortcomings aforementioned multimodal systems. First, training still suboptimal due lack large-scale parallel audio/text corpora. Secondly, models trained reference text transcripts perform well ASR outputs, although incorporating acoustic features reduced gap extent. \subsection{Novelty work} %And tell approach different acoustic based approaches. %We therefore focus investigating benefits exploiting semi-supervised learning approach. In work, introduce novel framework multimodal fusion lexical acoustic embeddings punctuation prediction conversational speech. Specifically, investigate benefits using lexical acoustic encoders pretrained large amounts unpaired text audio data using unsupervised learning. The key idea learn contextual representations unsupervised training substantial amounts unlabeled data available improve performance downstream task like punctuation, amount data limited, leveraging learned representations. For multimodal fusion, explore attention mechanism automatically learn alignment word level lexical features frame level acoustic features absence explicit forced alignments. We also show adaptation proposed multimodal architecture streaming usecase limiting future context. We study effect pretrained encoders respect varying data sizes performance trained small amounts data. Finally, exploit N-best lists ASR perform data augmentation reduce gap performance tested ASR outputs. % We investigate following research questions paper: % %The rest paper organized follows: Section introduces semi-supervised learning approach pre-trained lexical acoustic encoder punctuation prediction. Section describes procedure fusion acoustic features lexical encoder. We discuss experimental setup Section results presented Section . Finally, Section , summarize conclusions.","  In this work, we explore a multimodal semi-supervised learning approach for punctuation prediction by learning representations from large amounts of unlabelled audio and text data. Conventional approaches in speech processing typically use forced alignment to encoder per frame acoustic features to word level features and perform multimodal fusion of the resulting acoustic and lexical representations. As an alternative, we explore attention based multimodal fusion and compare its performance with forced alignment based fusion. Experiments conducted on the Fisher corpus show that our proposed approach achieves $\sim$6-9\% and $\sim$3-4\% absolute improvement  over the baseline BLSTM model on reference transcripts and ASR outputs respectively. We further improve the model robustness to ASR errors by performing data augmentation with N-best lists which achieves up to an additional $\sim$2-6\% improvement on ASR outputs. We also demonstrate the effectiveness of semi-supervised learning approach by performing ablation study on various sizes of the corpus. When trained on 1 hour of speech and text data, the proposed model achieved $\sim$9-18\% absolute improvement over baseline model.   %We also incorporate a pretrained lexical BERT encoder to further enhance the hidden representation of acoustic embedding when performed fusion with lexical embedding."
"Contemporary end-to-end speech synthesis systems achieve great results produce natural-sounding human-like speech even real time . They make possible efficient training put high demands quality, amount, preprocessing training data. Based advances, researchers aim at, example, expressiveness , controllability , few-shot voice cloning . When extending models support multiple languages, one may encounter obstacles different input representations pronunciations, imbalanced amounts training data per language. In work, examine cross-lingual knowledge-sharing aspects multilingual text-to-speech . We experiment languages simultaneously previous TTS work %\TN{nen閾 moc siln鑼 tvrzen閾?}\OD{to 閳ユ笒nown us閳 trochu omezuje :-)... ale m鏆栧暘em napsat 閳 works閳 jestli chce鎷 known us. We summarize contributions follows: We propose scalable grapheme-based model utilizes idea contextual parameter generator network compare baseline models using different levels parameter sharing. We introduce new small dataset based Common Voice includes data five languages 84 speakers. We evaluate effectiveness compared models ten languages three different scripts show code-switching abilities five languages. For purposes evaluation, created new test set 400 bilingual code-switching sentences. % \OD{TODO v閾哻 se chlubit} \TN{Je鎷鑷 v閾哻?} % \TNdel{\OD{todo nov濯 鑶穒鎷鑷巒濯 dataset}} % \TNdel{\OD{nov濯 code-switch test set}} Our source code, hyper-parameters, training evaluation data, samples, pre-trained models, interactive demos freely available GitHub.\footnote{\url{https://github.com/Tomiinek/Multilingual\_Text\_to\_Speech} }","   We introduce an approach to multilingual speech synthesis which uses the meta-learning concept of contextual parameter generation and produces natural-sounding multilingual speech using more languages and less training data than previous approaches. Our model is based on Tacotron~2 with a fully convolutional input text encoder whose weights are predicted by a separate parameter generator network. To boost voice cloning, the model uses an adversarial speaker classifier with a gradient reversal layer that removes speaker-specific information from the encoder.      We arranged two experiments to compare our model with baselines using various levels of cross-lingual parameter sharing, in order to evaluate:  stability and performance when training on low amounts of data,  pronunciation accuracy and voice quality of code-switching synthesis. For training, we used the CSS10 dataset and our new small dataset based on Common Voice recordings in five languages. Our model is shown to effectively share information across languages and according to a subjective evaluation test, it produces more natural and accurate code-switching speech than the baselines.      %The only drawback of this article is its unappealing abstract. It is probably because there includes no explicit description of the research objectives or the challenges that were dealt with in this study.  The reviewer thus thinks that improving the abstract will make this paper perfect.            %\OD{TODO p閼诡摣formulovat tak, 閸熺尃 se soust閼诡摣d闁惧攲e na n鐠嬧晜瀚 model, p閼诡摨dat info o datasetu}   %This work explores cross-lingual knowledge sharing in the context of speech synthesis. We compare three models based on Tacotron that utilize various levels of parameter sharing. Two of them follow recent multilingual text-to-speech systems. The first makes use of a fully-shared encoder and an adversarial classifier that ought to remove speaker-dependent information from the encoder. The other uses language-specific encoders. We introduce a new approach that combines the best of both previous methods. It enables effective parameter sharing using a meta-learning technique, preserves encoder闁炽儲鐛 flexibility, and actively removes speaker-specific information in the encoder.      %We compare the three models on two tasks. The first aims at joint multilingual training on ten languages. The second concerns code-switching or voice cloning. We show that our model effectively shares information across languages, and according to a subjective evaluation test, it produces more natural and accurate code-switching speech."
"Peking Opera, also known Beijing Opera Jingju, Chinese traditional performing art combines music, vocal performance, mime, dance acrobatics. Singing Peking Opera various styles, widely different depending different role type music styles. Strong personal styles also make actual singing different given music notes. Like dialect Mandarin, even unique way pronunciation. Moreover, melody singing often consist arias variation complex transitory vibratos, makes singing expressive difficult learn. Another difference normal singing note length great variance, sometime long note appear . All factors makes challenging modelling generating Peking Opera singing comparing normal singing. Although works focusing synthesis Peking Opera, broadly, opera, synthesis singing voice researched since 1962 Kelly Lochbaum used acoustic tube model synthesis singing voice success. Recently, several works use deep neural networks synthesis singing voice which, known parametric systems, process fundamental frequency harmonics features separately. As typical case among systems, Neural Parametric Singing Synthesizer using phoneme timing model, pitch model timbre model consist set neural networks generate acoustic parameters singing. In NPSS, Fitting Heuristic method introduced eliminate mismatch music note duration predicted phoneme duration. However, Fitting Heuristic method totally rule based requires locate principal vowel adjusting phoneme duration. This maybe acceptable English Japanese singing cases, cause huge duration error synthesizing Peking Opera. Different normal speech singing, Peking Opera, one syllable last long time contains long sequence phonemes, e.g. ``l-j-E-a-a-N"". More importantly, one can't simply tell phoneme amongst phonemes principle phone. There could multiple equally important phonemes Peking Opera singing. To better synthesize expressive Peking Opera, paper proposes Peking Opera singing synthesis system based Duration Informed Attention Network . The main contribution study lies two following points: 1) To tackle rhythm mismatch music note duration predicted phoneme duration, contextual based mixture density networks followed Lagrange Multiplier optimization proposed implemented duration modelling. This method completely data-driven, importantly, skips step locating principle phoneme conventional Fitting Heuristic method. 2) To deal melody mismatch original music score actual singing, also better model expressive variations vibratos Peking Opera, pseudo music score generated real singing fed input DurIAN model training. Experimental Results show proposed duration modeling prediction method outperforms Fitting Heuristic method large margin. And generated pitch contours also demonstrate system's ability synthesize singing variations vibratos Peking Opera. The following sections paper organized follows. Firstly, proposed model architecture introduced. Next, proposed Lagrange Multiplier-based duration prediction pseudo score generation introduced Section 2. In section 3 experiments conducted based unique Peking Opera database. Finally, quick discussion conclusion given Section 4.","  Peking Opera has been the most dominant form of Chinese performing art since around 200 years ago. A Peking Opera singer usually exhibits a very strong personal style via introducing improvisation and expressiveness on stage which leads the actual rhythm and pitch contour to deviate significantly from the original music score. This inconsistency poses a great challenge in Peking Opera singing voice synthesis from a music score. In this work, we propose to deal with this issue and synthesize expressive Peking Opera singing from the music score based on the Duration Informed Attention Network  framework. To tackle the rhythm mismatch, Lagrange multiplier is used to find the optimal output phoneme duration sequence with the constraint of the given note duration from music score. As for the pitch contour mismatch, instead of directly inferring from music score, we adopt a pseudo music score generated from the real singing and feed it as input during training. The experiments demonstrate that with the proposed system we can synthesize Peking Opera singing voice with high-quality timbre, pitch and expressiveness."
"Many machine learning datasets label imbalance dataset bias problem. In many cases, either data harder collect certain classes data collection phase biased bias introduced collected dataset. Typical training algorithms, optimized order minimize error, tend exacerbating bias, e.g., providing higher recall precision majority class minority classes. Therefore, label imbalance problem raises concern fairness machine learning systems general. Spoken language understanding problems often suffer label imbalance, ways may hide important errors designers SLU systems. Consider SLU dataset Air Traffic Information Systems speech-to-intent detection problem dataset. About 75\% dataset carries intent searching flight, conversely, minority intent classes represented single training example; severe label imbalance problem. Suppose train model without concerns fairness imbalance. The model likely learn output `flight' intent time, give us accuracy 75\% low could acceptable depending application. Considering roughly 30 classes whole dataset, one class recall 1.0 precision 0.75 remaining 29 classes recall precision 0.0. In scenario, F-measure, harmonic average precision recall, 0.86 common class 0.0 rest, give average 0.03 acceptable many cases. % Previous work Fair ML, There recent interest introducing fairness training machine learning literature . Most studies applied benchmark datasets related socioeconomic problems, e.g., disparate impact equal opportunity . In studies, fairness defined task protecting use explicit implicit information protected attribute decisions machine learning algorithm, instance, framing problem constrained optimization problem introducing several penalties. In work, introduce fairness speech-related problem, namely SLU. We also propose positive generalized definition fairness, terms missed detection false alarm error rates suffered classes, regardless whether class definitions matters socioeconomic importance merely engineering convenience. % Previous methods F-measure optimization There several studies F-measure maximization . These models usually focus binary classification using non-neural-network models: situation problem F-measure optimization reduces problem learning threshold scores computed model make decision. We aware one study performs F-measure optimization convolutional neural networks, again, using system generates several binary classification outputs parallel; scenario, F-measure optimization reduces task tuning thresholds individual binary classifiers order maximize weighted log likelihood. However, true multi-class classification, using softmax output neural network, requires modified definition F-measure. There threshold tuned; instead, F-measure optimization requires optimizing model generate `better' scores terms F-measure. Model versus threshold optimization fundamental difference study previous ones. In work, goal design loss function maximize F-measure instead accuracy DNNs. Our methods tested two standard socioeconomic classification problems literature fairness , two SLU tasks . On SLU tasks, perform end-to-end SLU, i.e., directly map speech input labels instead performing automatic speech recognition followed natural language processing . We pose SLU problems multi-class classification tasks use softmax output DNN, making possible apply optimization criterion socioeconomic SLU learning problems. We approximate F-measure differentiable function softmax activations use standard backpropagation algorithm train DNN."," Spoken language understanding  datasets, like many other machine learning datasets, usually suffer from the label imbalance problem. Label imbalance usually causes the learned model to replicate similar biases at the output which raises the issue of unfairness to the minority classes in the dataset. In this work, we approach the fairness problem by maximizing the F-measure instead of accuracy in neural network model training. We propose a differentiable approximation to the F-measure and train the network with this objective using standard backpropagation. We perform experiments on two standard fairness datasets, Adult, and Communities and Crime, and also on speech-to-intent detection on the ATIS dataset and speech-to-image concept classification on the Speech-COCO dataset. In  all four of these tasks, F-measure maximization results in improved micro-F1 scores, with absolute improvements of up to 8\% absolute, as compared to models trained with the cross-entropy loss function.  In the two multi-class SLU tasks, the proposed approach significantly improves class coverage, i.e., the number of classes with positive recall."
"Recent neural text-to-speech systems based sequence-to-sequence approach, Tacotron~2 , brought considerable quality improvements, require relatively large amounts training data computational resources train operate. %Recent advances text-to-speech synthesis allowed integration high-quality speech synthesis systems products Alexa Google Assistant. However, adapting synthesis models custom domains requires access relatively large amounts training data computational resources. %Moreover, real-time synthesis may problematic due size systems sequential inference. Several works attempt reduce computational burden various ways , still tradeoff fast training times, fast inference, output quality. In paper, address training efficiency TTS systems well inference speed hardware requirements sustaining good quality synthesized audio. We propose fully convolutional, non-sequential approach speech synthesis %based combination ideas . %Similarly , system consisting teacher student network, similarly FastSpeech . The teacher network autoregressive %\OD{je tu pot鑹ba 鑹￠搯kat 閳ユ竵uteregresivn閾嗛垾, kdy鍟 se tak nikdy nepou鍟搯v璋?} \todo{myslim, ze jo -- jde zpusob, jaky modeluje audio. Kdyby nemodeloval audio autoregresivne, tak nemel moc motivace naucit se spravny alignment} \OD{Fair enough.} convolutional network % based used extract correct alignments phonemes corresponding audio frames. The student network non-autoregressive, fully convolutional network %with residual connections % based encodes input phonemes, predicts duration one, decodes mel-scale spectrogram based phoneme encodings durations. %used synthesize spectrograms input phonemes. The student network first encodes input phonemes. Then duration prediction module predicts duration phoneme. Finally, phoneme encoding vectors expanded based durations fed decoder module synthesizes final spectrogram. We combine student network pretrained MelGAN vocoder achieve fast high-quality spectrogram inversion. Our model trained LJ~Speech data 40 hours single 8GB GPU generates high-quality audio samples faster real-time GPU CPU. %\OD{d璋 se tohle rozd鑷巐it na v閾哻 bod鏆 ne鍟 2?} \todo{ano :)}\OD{d閾唊 :-)} Our contributions follows: We simplify teacher-student architecture FastSpeech provide fast stable training procedure. We use simpler, smaller faster-to-train convolutional teacher model single attention layer instead Transformer used FastSpeech. % . We show self-attention layers student network needed %necessary order achieve high-quality speech synthesis. We describe simple data augmentation technique used early training make teacher network robust sequential error propagation. We show model significantly outperforms strong baselines keeping speedy training inference. %Finally, provide results experiments various techniques batch normalization , dropout , positional encoding style loss functions."," %Recent breakthrough in in the quality of text-to-speech systems can be largely accounted to neural sequence-to-sequence models \cite{Tacotron2, WaveNet}. Extensive research has been conducted to improve the effectiveness of training \cite{DeepVoice3, EfficientTTS}, inference speed \cite{WaveRNN, ParallelWaveNet} and voice quality \cite{FastSpeech, TransformerTTS} of the speech synthesis systems.  While recent neural sequence-to-sequence models have greatly improved the quality of speech synthesis, % in the past years, %However, to our knowledge  there has not been a system capable of %fast and efficient training, speedy inference and fast training, fast inference and high-quality audio synthesis at the same time.  %However, none of the aforementioned systems excels in all of the traits.  %In this work,  We propose a student-teacher network %based on \cite{FastSpeech, DeepVoice3, EfficientTTS}  capable of high-quality faster-than-real-time spectrogram synthesis, with low requirements on computational resources and fast training time. We show that self-attention layers are not necessary for generation of high quality audio.  %In fact,  We utilize simple convolutional blocks with residual connections in both student and teacher networks and use only a single attention layer in the teacher model. Coupled with a MelGAN vocoder, our model's voice quality was rated significantly higher than Tacotron~2. Our model can be efficiently trained on a single GPU and can run in real time even on a  %4-core  CPU. We provide both our source code and audio samples in our GitHub repository.\footnote{\url{https://github.com/janvainer/speedyspeech}\label{fn:github}}"
"Automatic speaker verification several applications voice biometrics commercial applications, speaker detection surveillance, speaker diarization, etc. A speaker enrolled sample utterance, task ASV detect whether target speaker present given test utterance not. Several challenges organized years benchmarking advancing speaker verification technology NIST speaker recognition Evaluation challenge 2019 , VoxCeleb speaker recognition challenge VOiCES challenge . The major challenges speaker verification include language mismatch testing, short duration audio presence noise/reverberation speech data. %The field attracting lot participants, thereby rapidly updating state-of-the-art. The state-of-the-art systems speaker verification use model extract embeddings fixed dimension utterances variable duration. The earlier approaches based unsupervised Gaussian mixture model i-vector extractor recently replaced neural embedding extractors trained large amounts supervised speaker classification tasks. These fixed dimensional embeddings pre-processed length normalization technique followed probabilistic linear discriminant analysis based backend modeling approach . In previous work, explored discriminative neural PLDA approach backend modeling discriminative similarity function used. The learnable parameters NPLDA model optimized using approximation minimum detection cost function . This model also showed good improvements SRE evaluations VOiCES distance challenge . In paper, extend work propose joint modeling framework optimizes front-end x-vector embedding model backend NPLDA model single end-to-end neural framework. The proposed model initialized pre-trained x-vector time delay neural network . The NPLDA E2E fully trained pairs speech utterances starting directly mel-frequency cepstral coefficient features. The advantage method embedding extractor well final score computation optimized pairs utterances speaker verification metric. With experiments NIST SRE 2018 2019 datasets, show proposed NLPDA E2E model improves significantly baseline system using x-vectors generative PLDA modeling. % backend models trained embeddings output score. These scores scaled log-likelihood ratios using calibration methods. Speaker verification systems apply application specific threshold log-likelihood ratios output decision. Widely used examples embeddings i-vector, x-vector d-vector. I-vectors unsupervised embeddings representing alignment statistics utterance using Gaussian mixture universal background model , X-vectors d-vectors embeddings obtained Neural Network models trained objective speaker classification thousand speakers. The Probabilistic Linear Discriminant Analysis widely used backend model compute log-likelihood. Other backend models include DPLDA, pairwise Gaussian backend, SVMs, Neural PLDA. In majority systems, model extract embeddings trained separately backend model. % An area growing interest training End-to-End speaker verification systems, optimizes entire model verification objective function. In paper, extend prior work Neural PLDA model enable joint learning X-vector extractor NPLDA backend, fully end-to-end manner. We address GPU memory issues, analyse two straightforward methods sampling training trials batch. We provide comparisons different loss functions training."," While deep learning models have made significant advances in supervised classification problems, the application of these models for out-of-set verification tasks like speaker recognition has been limited to deriving feature embeddings. The state-of-the-art x-vector PLDA based speaker verification systems use a generative model based on probabilistic linear discriminant analysis  for computing the verification score. Recently, we had proposed a neural network approach  for backend modeling in speaker verification called the neural PLDA  where the likelihood ratio score of the generative PLDA model is posed as a discriminative similarity function and the learnable parameters of the score function are optimized using a verification cost. In this paper, we extend this work to achieve joint optimization of the embedding neural network  with the NPLDA network in an end-to-end  fashion. This proposed end-to-end model is optimized directly from the acoustic features with a verification cost function and during testing, the model directly outputs the likelihood ratio score. With various experiments using the NIST speaker recognition evaluation  2018 and 2019 datasets, we show that the proposed E2E model improves significantly over the  x-vector PLDA baseline speaker verification system."
"Speech enabled applications increasingly gaining popularity across world. This initiated need build accurate automatic speech recognition system across different languages. Also, End-to-End ASR systems emerging popular alternative conventional hybrid ASR systems. They replace acoustic model , language model pronunciation model single neural network . Recurrent neural network transducer one E2E system allow streaming input suitable real-time ASR applications. Therefore lot interest building accurate RNN-T models different languages spoken across world. %The speech recognition accuracy largely depends upon amount training data available. There often disparity availability transcribed data different languages. In cases, lot data available American English languages. The quality ASR model depends number factors including, training data quantity diversity, acoustic model structure, optimization algorithm. Furthermore, training data diversity spans number factors adults, kids, speaking rate, accents, near-field, far-field acoustic conditions. A low-resource locale limited ASR training data, may meet acoustic diversity needed train robust model generalize acoustic factors. To overcome low-resource constraint, transfer learning widely used hybrid ASR system transfer knowledge well trained source locale low-resource target locale bring significant acoustic robustness target locale. In recent work, applied TL large scale en-US conventional hybrid model corresponding models en-IN it-IT locales, achieved 8\% word error rate relative reduction . Motivated success TL methods hybrid ASR system, explore TL methods improve low-resource RNN-T models. Besides improving target model acoustic robustness, TL also crucial training large complex deep learning architectures. RNN-T models difficult train also require significantly large amount data jointly train acoustic well language model attributes. In study noted weaker convergence significant parameter tuning requirements desirable E2E training outcome low-resource locale. Therefore expect TL techniques even relevant E2E systems stabilize training improve ASR accuracy. In hybrid ASR system, transfer learning typically done initializing target AM source AM. In RNN-T framework, several transfer learning strategies exist depending upon choice initialization model encoder prediction networks. In paper, compare different transfer learning strategies RNN-T framework. We propose two-stage TL, first training target initialization model bootstrapped pretrained source model. Subsequently, model used initialize target RNN-T model. The two-stage TL approach shows ~ WERR reduction faster convergence training loss compared randomly initialized RNN-T model. We also study effect TL different amount training data show importance transfer learning case low-resource languages.","  Transfer learning  is widely used in conventional hybrid automatic speech recognition  system, to transfer the knowledge from source to target language. TL can be applied to end-to-end  ASR system such as recurrent neural network transducer  models, by initializing the encoder and/or prediction network of the target language with the pre-trained models from source language. In the hybrid ASR system, transfer learning is typically done by initializing the target language acoustic model  with source language AM. Several transfer learning strategies exist in the case of the RNN-T framework, depending upon the choice of the initialization model for encoder and prediction networks. This paper presents a comparative study of four different TL methods for RNN-T framework. We show ~$10\%-17\%$ relative word error rate reduction with different TL methods over randomly initialized RNN-T model. We also study the impact of TL with varying amount of training data ranging from $50$ hours to $1000$ hours and show the efficacy of TL for languages with a very small amount of training data.\\"
"With advent deep learning, end-to-end text-to-speech shown many advantages conventional TTS techniques . Tacotron-based approaches encoder-decoder architecture attention mechanism shown remarkable performance. The key idea integrate conventional TTS pipeline unified network learn mapping directly text-waveform pair . The recent progress neural vocoder also contributes improvement speech quality. Speech prosody includes affective prosody linguistic prosody. Affective prosody represents emotion speaker, linguistic prosody relates language content. They crucial speech communication. A TTS system expected synthesize right prosodic pattern right time. However, current end-to-end systems explicitly modeled speech prosody. Therefore, can't control well melodic rhythmic aspects generated speech. This usually leads monotonous speech, even models trained expressive speech datasets. In paper, would like study way enable Tacotron-based TTS expressive prosody generation. Multi-task learning learning paradigm leverages information multiple related tasks help improve overall performance . MTL inspired human learning activities people often apply knowledge learned many tasks learning new task, called inductive transfer. For example, learn read write together, experience reading strengthen writing vice versa. MTL widely used speech enhancement , speech recognition . It also used speech synthesis , statistical parametric speech synthesis GANs DNN-based speech synthesis stacked bottleneck features. In paper, apply multi-task learning Tacotron-based TTS prosody modeling. The study expressive speech synthesis focused prosody modeling , speech prosody generally refers intonation, stress, speaking rate, phrase breaks. Prosodic phrasing plays important role affective linguistic expressions. Inadequate phrase breaks may lead misperception speech communication. There recent studies prosody modeling end-to-end TTS system , example, improve prosodic phrasing using contextual information , syntactic features . They incorporated stage text preprocessing, therefore, optimized part synthesis processing. We propose novel two-task learning scheme Tacotron-based TTS model improve prosodic phrasing: 1) main task learns prediction speech spectrum parameters character-level embedding representation, 2) secondary task learns prediction word-level prosody embedding. During training, secondary task serves additional supervision Tacotron learn exquisite prosody structure associated input text. At run-time, prosody embedding serves local condition controls prosodic phrasing voice generation. The main contributions paper include: 1) novel Tacotron-based TTS architecture explicitly models prosodic phrasing; 2) multi-task learning scheme, optimizes model high quality speech spectrum, adequate prosodic phrasing time. The proposed system achieves remarkable voice quality Chinese Mandarin Mongolian. To best knowledge, first multi-task Tacotron implementation includes explicit prosodic model. This paper organized follows. Section recaps Tacotron TTS framework. We propose multi-task Tacotron Section report experiments Section. Section concludes discussion."," Tacotron-based end-to-end speech synthesis has shown remarkable voice quality. However, the rendering of prosody in the synthesized speech remains to be improved, especially for long sentences, where prosodic phrasing errors can occur frequently. In this paper, we extend the Tacotron-based speech synthesis framework to explicitly model the prosodic phrase breaks. We propose a multi-task learning scheme for Tacotron training, that optimizes the system to predict both Mel spectrum and phrase breaks.  To our best knowledge, this is the first implementation of multi-task learning for Tacotron based TTS with a prosodic phrasing model. Experiments show that our proposed training scheme consistently improves the voice quality for both Chinese and Mongolian systems."
"% 1. 娴犲绮涚拠顓㈢叾閸氬牊鍨氬Ο鈥崇烽崚鍡曡礋娑撱倓閲滈柈銊ュ瀻閿涘苯绱╅崙鐑樻拱閺傚洣瀵岀憰浣稿彠濞夈劎顑囨稉娑擃亝膩閸 Speech synthesis, also known text-to-speech , attracted lot attention obtained satisfactory results recent years due advances deep learning. Several TTS systems based deep networks proposed, Char2Wav , Tacotron2 , DeepVoice3 , Transformer TTS , FastSpeech ParaNet . These systems usually first predict acoustic feature sequence input text sequence, generate waveform acoustic feature sequence using vocoder Griffin-Lim , WaveNet , WaveRNN , WaveGlow GAN-TTS . % 2. 娴犲绮涢惄顔煎閻 閸忓厖绨琺el鐠嬮亶顣╁ù瀣秹缂佹粎娈戠拋鎹愵吀閸╃儤婀伴弬鐟扮础 LSTM, Conv, transformer % According characteristics network strucutre, current mainstream TTS systems divided % three types: RNN-based, CNN-based Transformer-based. % The RNN-based TTS systems, Char2Wav , % Tacotron 2 Tacotron , % use recurrent neural network design main network structure, % attention mechanism applied model alignment % acoustic feature sequence text sequence, % nature RNN limits parallelism. % The CNN-based TTS systems, DeepVoice 3 % ParaNet , adopt convolution neural network model timing dependencies, % enable parallel processing training. % Especially ParaNet , iteratively refined attention mechanism proposed enable system % perform inference process parallel. % The Transformer-based TTS systems, Transformer TTS , FastSpeech AlignTTS , % apply architecture Transformer realize process speech synthesis. % FastSpeech uses self-attention structure Transformer design feed-forward network % predicting mel-spectrum parallel, needs guidance teacher autoregressive TTS model % due difficulty learning alignment text mel-spetrum. % AlignTTS proposes alignment loss make feed-forward TTS system capable model aligment % without guidance TTS systems. % 2. 瀵洖鍤ぐ鎾冲鐠囶參鐓堕崥鍫熷灇鐎佃鏋冮張顒勬毐鎼达妇娈戦梽鎰煑 Although current speech synthesis systems obtained high-quality speech, difficult achieve satisfactory results long text speech synthesis scenarios. In sequence-to-sequence TTS model, since monotonicity locality properties TTS alignment fully utilized, alignment procedure lacks robustness inference, leads skipping repeating words, incomplete synthesis, inability synthesize long utterances . To address issue, many monotonic attention mechanisms presented , alignment paths satisfying monotonic condition taken consideration decoder timestep. In , location-based GMM attention introduced also studied TTS systems generalize long utterances. Especially, AlignTTS proposes alignment loss model alignment text mel-spectrum, uses length regulator adjust alignment, solves instability problem alignment efficient. However, since self-attention Transformer used model dependencies input sequence elements AlignTTS, positional encodings required introduce positional information, limits maximum length input text. In paper, novel self-attention mechanism proposed remove need positional encodings lift restriction input text length. % In Tacotron , content-based attention mechanism introduced % used align text melspectrum, % exploit monotonicity TTS alignment. % Tacotron 2 uses hybrid attention meachnism % encourage attention alignment move forward consistently input sequence. % makes synthesis process instability. % long text sequence conducive % calcualtion attention mechanism TTS system, % affects prediction acoustic feature stop token inference. % FastSpeech AlignTTS use length regulator instead attention mechanism, % locational encoding Transformer also limits max length input text. % In order lift restriction, design novel self-attention mechanism % model timing dependencies TTS system. % 3. 娑擃厽鏋冪拠顓㈢叾閸氬牊鍨氭稉顓炲彠娴滃酣鐓瑰瀣紦濡紕娈戦崚鍡樼 On hand, prosody speech directly affects overall listening perception voice, especially long utterances. In order improve naturalness synthetic speech, necessary TTS systems model prosody information. In , prosody embedding introduced emotional expressive speech synthesis, enables fine-grained control speaking style. In , interpretable latent variable model prosody based Tacotron 2 presented model phoneme-level word-level prosody information speech. proposes quantized latent feature prosody speech, trains autoregressive prior model generate natural samples without reference speech. These prosody control methods enable us learn prosody speech fine-grained synthesized speech, still cannot effectively predict correct prosody according input text. One reason prosody information speech generally depends meaning text, phoneme information text used input current mainstream TTS systems, limits capabilities modeling prosody speech. In , textual knowledge BERT introduced TTS systems improve prosody speech, ignore variability prosody. For example, text may produce speech different prosody due pronunciation uncertainty. % 4. 閹崵绮ㄩ弬鍥ㄦ拱閻ㄥ嫬鍨遍弬鎵仯 In works, propose novel self-attention mechanism, named local attention, model timing dependencies, abandons positional encoding uses relative position matrix model influence positional relationship input sequence. At time, introduce prosody learning mechanism feed-forward TTS systems, prosody embedding phoneme learned mel-spectrum training. In addition, prosody predictor designed predict prosody embedding according text phoneme, pre-trained language model applied introduce meaning text. And main contributions works follows:","     Recent neural speech synthesis systems have gradually    focused on the control of prosody to improve the quality    of synthesized speech, but they rarely consider the    variability of prosody and the correlation between prosody    and semantics together. In this paper, a prosody learning    mechanism is proposed to model the prosody of speech based    on TTS system, where the prosody information of speech is    extracted from the mel-spectrum by a prosody learner and    combined with the phoneme sequence to reconstruct the    mel-spectrum. Meanwhile, the sematic features of text from    the pre-trained language model is introduced to improve the    prosody prediction results. In addition, a novel self-attention    structure, named as local attention, is proposed to lift    this restriction of input text length, where the relative    position information of the sequence is modeled by the    relative position matrices so that the position encodings    is no longer needed. Experiments on English and Mandarin show    that speech with more satisfactory prosody has obtained    in our model. Especially in Mandarin synthesis,    our proposed model outperforms baseline model with a MOS gap    of 0.08, and the overall naturalness of the synthesized    speech has been significantly improved."
"Conventional SLU pipeline mainly consists two components : Automatic Speech Recognition module generates transcriptions N-hypotheses, Natural Language Understanding module classifies transcriptions intents, speech recognition error propagation amplified sub-sequence NLU process. Although rapid development end-to-end speech recognition systems, performance SLU significant improved , still satisfy application requirements, due complexity scenarios. %The improved performance SLU mainly benefits increasing maturity ASR. The application deep neural networks acoustic models language models together rapid development end-to-end technique make ASR systems extend research domains . Usually errors speech recognition harm SLU module, errors impact eventual performance . The SLU component keeps attention keywords discarding irrelevant words . Thus joint optimization approach strengthen focus model improving transcription accuracy relates target events . Recently, many efforts dedicated end-to-end SLU domain intent predicted directly input audio . Previous researches shown large amount data determining factor excellent performance model . However, due lack audio ambiguity intents, difficult obtain sufficient in-domain labeled data. Transfer learning methodology become common strategy address insufficient data problem . %which vital technique generalizes models trained one setting task settings tasks. Different transfer learning strategies applied SLU model result competitive complementary results . In paper, strategy also applied amplify feature extraction capability encoder component, pre-train encoder large amount speech recognition labeled data, transfer encoder SLU model. Recently, proposed compared various encoder-decoder approaches optimize module SLU end-to-end manners proved intermediate text representation crucial SLU jointly training full model advantageous. Attention-based models widely used speech recognition provide impressive performance . Inspired this, propose Transformer based multi-task strategy adopt textual information SLU model. Since text information acts decoder component speech recognition task, treated adaptive regularizer adjust encoder parameters contributing improve intent prediction performance. It noticed lack textual corpus also major challenge training language models. To address problem, various methods carried expand corpus past decade . In addition, textual level transfer learning strategy merging pre-trained representation decoder also explored. The pre-trained representation obtained BERT model, designed pre-train deep bidirectional representations unlabeled text jointly conditioning left right context layers . Encoder decoder mutual independent connected attention block, get collaborated optimization training. To maximize performance, encoder decoder optimized transfer leaning strategies. In paper, first propose self-attention based end-to-end SLU structure, applied cross-lingual transfer learning method solve insufficient acoustic data problem. Then propose Transformer based multi-task strategy conducts intent classification speech recognition parallel. Finally, textual-level transfer learning structure designed aggregate pre-trained BERT model decoder component improves feature extraction capability decoder, indirectly.","   End-to-end Spoken Language Understanding  models are made increasingly large and complex to achieve the state-of-the-art accuracy. However, the increased complexity of a model can also introduce high risk of over-fitting, which is a major challenge in SLU tasks due to the limitation of available data. In this paper, we propose an attention-based SLU model together with three encoder enhancement strategies to overcome data sparsity challenge. The first strategy focuses on the transfer-learning approach to improve feature extraction capability of the encoder. It is implemented by pre-training the encoder component with a quantity of Automatic Speech Recognition annotated data relying on the standard Transformer architecture and then fine-tuning the SLU model with a small amount of target labelled data. The second strategy adopts multi-task learning strategy, the SLU model integrates the speech recognition model by sharing the same underlying encoder, such that improving robustness and generalization ability. The third strategy, learning from Component Fusion  idea, involves a Bidirectional Encoder Representation from Transformer  model and aims to boost the capability of the decoder with an auxiliary network. It hence reduces the risk of over-fitting and augments the ability of the underlying encoder, indirectly. Experiments on the FluentAI dataset show that cross-language transfer learning and multi-task strategies have been improved by up to $4.52\%$ and $3.89\%$ respectively, compared to the baseline."
"Most speech synthesis models take two-stage procedures generate waveform audio text. First stage generates spectrogram conditioned linguistic features text phoneme. In second stage, generally refer vocoder stage, audio samples generated model capable estimating audio samples acoustic features. Traditional approaches estimated audio samples either directly spectral density model hand-crafted acoustic model, approaches tended produce low-quality audio. After emergence WaveNet, models generate audio samples previously generated samples shown exceptional works field.. Nevertheless, dilated causal convolution networks used model require sequential generation process inference, infers real-time speech synthesis hard achieve parallel inference can't utilized. For reason, generating high-quality waveform audio real-time become challenging task. To overcome structural limitation auto-regressive model, recent works focused non-autoregressive models knowledge distillation, generative adversarial network, flow-based generative model. We focus flow-based generative model since model highly flexible approximate posterior distribution variational inference. The transformation single data-point Gaussian noise one-to-one, makes parallel generation possible. However, acknowledge audio samples discrete data. In words, naive modeling continuous probability density discrete data produce arbitrary high likelihood discrete location. This lead degraded generation performance flow-based neural vocoder. Therefore, dequantization required transformation. In paper, present various audio dequantization schemes implemented flow-based neural vocoder. In image generation, adding continuous noise data-points dequantize data commonly used. However, best knowledge, effectiveness data dequantization audio domain still unknown area, investigation needed. Unlike pixels image, audio samples bounded signed integer. To overcome domain issue, either normalize range noise values range audio samples different normalization method. In addition, adapt flow block flow-based neural vocoder generate flexible noises known variational dequantization.","     In recent works, a flow-based neural vocoder has shown significant improvement in real-time speech generation task. The sequence of invertible flow operations allows the model to convert samples from simple distribution to audio samples. However, training a continuous density model on discrete audio data can degrade model performance due to the topological difference between latent and actual distribution. To resolve this problem, we propose audio dequantization methods in flow-based neural vocoder for high fidelity audio generation. Data dequantization is a well-known method in image generation but has not yet been studied in the audio domain. For this reason, we implement various audio dequantization methods in flow-based neural vocoder and investigate the effect on the generated audio. We conduct various objective performance assessments and subjective evaluation to show that audio dequantization can improve audio generation quality. From our experiments, using audio dequantization produces waveform audio with better harmonic structure and fewer digital artifacts."
"Associative memory defined psychology ability remember many sets, called memories, unrelated items. Prompted large enough subset items taken one memory, animal computer associative memory retrieve rest items belonging memory. The diverse human cognitive abilities involve making appropriate responses stimulus patterns often understood operation associative memory, ``memories'' often distillations consolidations multiple experiences rather merely corresponding single event. The intuitive idea associative memory described using ``feature space''. In mathematical model abstracted neurobiology, presence particular feature denoted activity model neuron due directly driven feature signal. If possible features, distinct connections neural circuit involving neurons. Typical cortical synapses highly reliable, store bits information\footnote{For instance, recent study reports information content individual synapses ranging bits, based electron microscopy imaging, see also . These numbers refer structural accuracy synapses. There also electrical chemical noise synaptic currents induced biophysical details vesicle release neurotransmitter binding. The unreliability fusion pre-synaptic vesicles pre-synaptic neuron membrane dominant source trial-to-trial synaptic current variation . This noise decreases electrical information capacity individual synapses maximal value synaptic structure would otherwise provide.}. The description particular memory requires roughly bits information. Such system therefore store unrelated memories. Simple artificial neural network models associative memory exhibit limitation even precise synapses, limits memory storage less memories . Situations arise number small desired number memories far exceeds , see examples biological AI systems Section . In situations associative memory model would insufficient, since would able memorize required number patterns. At time, models associative memory large storage capacity considered paper, easily solve problems. The starting point paper machine learning approach associative memory based energy function attractor dynamics space variables, called Dense Associative Memory . This idea shown dramatically increase memory storage capacity corresponding neural network proposed useful increasing robustness neural networks adversarial attacks . Recently, extension idea continuous variables, called modern Hopfield network, demonstrated remarkably successful results immune repertoire classification , provided valuable insights properties attention heads Transformer architectures . Dense Associative Memories modern Hopfield networks, however, cannot describe biological neural networks terms true microscopic degrees freedom, since contain many-body interaction terms equations describing dynamics corresponding energy functions. To illustrate point consider two networks: conventional Hopfield network Dense Associative Memory cubic interaction term energy function . In conventional network dynamics encoded matrix , represents strengths synaptic connections feature neurons . Thus, network manifestly describable terms two-body synapses, approximately true many biological synapses. In contrast, Dense Associative Memory network cubic energy function naively requires synaptic connections tensors three indices, harder, although impossible, implement biologically. Many-body synapses become even problematic situations interaction term described complicated function simple power . Many-body synapses typically appear situations one starts microscopic theory described two-body synapses integrates degrees freedom . The argument described based counting information stored synapses conjunction fact modern Hopfield nets Dense Associative Memories huge storage capacity hints solution. The reason networks storage capacity much greater describe dynamics neurons, rather involve additional neurons synapses. Thus, remains theoretical question: hidden circuitry look like? Is possible introduce set hidden neurons appropriately chosen interaction terms activation functions resulting theory large memory storage capacity , and, time, manifestly describable terms two-body synapses? The main contributions current paper following. First, extend model continuous state variables continuous time, state network described system non-linear differential equations. Second, couple additional set ``complex neurons'' ``memory neurons'' hidden neurons feature neurons. When synaptic couplings neuron activation functions appropriately chosen, dynamical system variables energy function describing dynamics. The minima dynamics locations - dimensional feature subspace minima corresponding Dense Associative Memory system. Importantly, resulting dynamical system mathematical structure conventional recurrent neural network, neurons interact pairs two-body matrix synaptic connections. We study three limiting cases new theory, call models A, B, C. In one limit reduces Dense Associative Memory model depending choice activation function. In another limit model reduces network . Finally, present third limit call Spherical Memory model. To best knowledge model studied literature. However, high degree symmetry reason might useful future explorations various models large associative memory recurrent neural networks machine learning. For purposes paper defined ``biological plausiblity'' absence many-body synapses. It important note aspects model described equations biologically implausible. For instance, assumes strengths two physically different synapses equal. This assumption necessary existence energy function, makes easy prove convergence fixed point. It relaxed equations , makes even biological, but, time, difficult analyse.","  Dense Associative Memories or modern Hopfield networks permit storage and reliable  retrieval of an exponentially large  number of memories. At the same time, their naive implementation is non-biological, since it seemingly requires the existence of many-body synaptic junctions between the neurons.   We show that these models are effective descriptions of a more microscopic  theory that has additional  neurons and only requires two-body interactions between them. For this reason our proposed microscopic theory is a valid model of large associative memory with a degree of biological plausibility. The dynamics of our network and its reduced dimensional equivalent both minimize energy  functions. When certain dynamical variables  are integrated out from our microscopic theory, one can recover many of the models that were previously discussed in the literature, e.g. the model presented in ``Hopfield Networks is All You Need'' paper. We also provide an alternative derivation of the energy function and the update rule proposed in the aforementioned paper and clarify the relationships between various models of this class."
"Unsupervised machine learning led marriage symbolic learning vectorized representation learning . In computer music community, MusicVAE enables interpolation learned latent space render smooth music transition. The EC-VAE manages disentangle certain interpretable factors music also provides manipulable generation pathway based factors. Pati et al. utilizes recurrent networks learned music representations longer-term coherence. % With advances machine learning, idea combining symbolic music generation representation learning become popular % . As one successful models, variational autoencoders learn compact latent representation music, lots applications music generation. For example, MusicVAE introduces latent space interpolation make smooth music transitions; ECVAE disentangles latent space interpretable factors manipulates generate new pieces; Lerch et al. use representation music segment token generate longer-term music using recurrent networks. Unfortunately, success limited monophonic music. The generalization learning frameworks polyphonic music trivial, due much higher dimensionality complicated musical syntax. % richer underlying factorization. The commonly-adopted MIDI-like event sequence modeling piano-roll formats fed either recurrent convolutional networks fell short learning good representation, usually leads unsatisfied generation results . In paper, hope pioneer development challenging task. To begin with, conjecture proper set inductive bias desired framework: -a sparse encoding music model input; -a neural architecture incorporates hierarchical structure polyphonic music . % However, aforementioned progress achieved VAEs monophonic music. As demonstrate, success cannot easily generalized polyphonic music using commonly-used MIDI-like event sequence piano-roll formats standard recurrent convolutional neural encoders/decoders. The main reason that, compared monophony, polyphonic data higher dimensional complex structured distribution. To tackle challenge, need proper inductive bias, specifically: % % 閺傛澘鍟撻惃鍕唽閽鏂ょ窗瀵啰鏁 % Guided design principles, propose PianoTree VAE, VAE structure learns latent representation polyphonic music hierarchical manner. For data representation, adopt tree-structured hierarchical music syntax. In top-down order: \score{} contains series \simunote{} events, \simunote{} consists multiple \note{} events, \note{} several attributes. In paper, focus simple yet common form polyphonic music---piano score pitch duration attributes. Note tree structure generalized multiple instruments expressive performance adding extra attributes voice, expressive timing, dynamics, etc. % We expect syntax provides sufficient inductive bias learn semantically-meaningful latent representation, [while still compatible current VAE architectures.] Guided aforementioned design principles, propose PianoTree VAE, hierarchical representation learning model VAE framework. We adopt tree structured musical syntax reflects hierarchy musical concepts, shown \figref{fig:example}. In top-down order: define \score{} series \simunote{} events , \simunote{} multiple \note{} events sharing onset , \note{} several attributes pitch duration. In paper, focus simple yet common form polyphonic music---piano score, note pitch duration attributes. For future work, syntax generalized multiple instruments expressive performance adding extra attributes voice, expressive timing, dynamics, etc. % The whole neural architecture PianoTree VAE seen tree. Each node represents embedding either \score{}, \simunote{}, \note{}, higher level representation larger receptive fields. The edges bidirectional recurrent module applied either encode children parent decode parent generate children. % As model structure, encoder decoder PianoTree VAE hierarchical recurrent networks, hierarchy one-to-one correspondence proposed tree structured polyphonic syntax. At level, recurrent network either encodes children parent decodes parent generate children. % We believe architecture provides reasonable inductive bias encoding/decoding procedures analogous musicians memorize/interpret score. For example, usually ``roll chord'', similarly, model uses recurrent networks expand \simunote{} \note{}'s. Through extensive evaluations, show PianoTree VAE yields semantically meaningful latent representations downstream generation quality gains, top current state-of-the-art solutions. % 娴犮儰绗呯粭顑跨閸欍儲妲搁弬鏉垮晸閻ㄥ嫸绱濈粭顑跨癌閸欍儲妲搁崢鐔告降閻ㄥ嫨鍌涘灉鐟欏绶卞▽鈥虫殣閻㈩煉绱濋崚鐘辩啊閵 %The mechanism recurrent modules analogous procedure ``roll chord'' pitch ascending order. % Reviewer閿涙瓬etter specify representation compared. % Finally, compare PianoTree VAE baseline VAEs using data representation either piano-roll MIDI-like event sequence corresponding model structure show learned latent representation yields accurate reconstruction, smoother musical latent space interpolation, better downstream music generation combined standard sequence generative models."," The dominant approach for music representation learning involves the deep unsupervised model family variational autoencoder . However, most, if not all, viable attempts on this problem have largely been limited to monophonic music. Normally composed of richer modality and more complex musical structures, the polyphonic counterpart has yet to be addressed in the context of music representation learning. In this work, we propose the PianoTree VAE, a novel tree-structure extension upon VAE aiming to fit the polyphonic music learning.  % It consists of multiple layers of encoding and decoding networks, which learn the representation of a tree-structure polyphonic segment in a hierarchical manner.  The experiments prove the validity of the PianoTree VAE via -semantically meaningful latent code for polyphonic segments; -more satisfiable reconstruction aside of decent geometry learned in the latent space; -this model闁炽儲鐛 benefits to the variety of the downstream music generation.\!\!\footnote{Code and demos can be accessed via \url{https://github.com/ZZWaang/PianoTree-VAE}}   % Music representation learning by variational autoencoders  has proven to be a promising direction towards better music generation. However, most successful studies  focus on monophonic music and it is still difficult to generalize the learning methods to polyphonic pieces. This is mainly because polyphonic data has higher dimensionality and contains more complex structures, which is difficult to be captured by the existing VAE architectures for sequential data.  In this paper, we contribute PianoTree VAE, a VAE that considers polyphonic music a tree-structure data and learns the representation in a hierarchical manner. The model effectively learns a semantically meaningful latent code of a polyphonic music segment. Experiments show that the latent code yields better reconstruction and latent space interpolation. The learned latent embedding also leads to better downstream music generation when combined with standard sequence generative models."
"Over past years, developments sequence-to-sequence neural text-to-speech research led synthetic speech sounds almost indistinguishable human speech . However, large amounts high-quality recordings typically required professional voice talent train models quality, make prohibitively expensive produce. To counter issue, investigations S2S models facilitate multi-speaker data become popular topic research. %\EJ{I like starting sentence citation citation number brackets} \MK{Agreed} A study by, example, showed multi-speaker models perform well even better single-speaker models large amounts target speaker data available, single-speaker models perform better substantial amounts data used. Their research also showed amount data necessary additional speaker little 1250 2500 sentences without significantly reducing naturalness. With regards parametric synthesis, investigated effect several multi-speaker modeling strategies class imbalanced data. Their research found limited amounts speech, multi-speaker modeling oversampling could improve speech naturalness compared single speaker models, undersampling found generally harmful effect. They also showed ensemble methods improve naturalness, strategy comes considerable computational cost usually feasible S2S modeling. Although research shows multi-speaker modeling effective strategy reduce data requirements, suitable solution many languages large quantities high-quality multi-speaker data available. Multilingual multi-speaker synthesis aims address issue training multilingual model data multiple languages. Among first propose neural approach multilingual modeling was. Instead modeling languages separately, modeled language variation cluster adaptive training, mean tower well language basis towers trained. They found multilingual modeling harm naturalness high-resource languages, low-resource languages benefited multilingual modeling. Another study scaled number unseen low-resource languages twelve, similarly found multilingual models tend outperform single speaker models. More recently, multilingual modeling also adopted S2S architectures, however mostly purposes code-mixing cross-lingual synthesis. Language information typically represented either language embedding separate encoder language, applied approaches code-mixing accent conversion. With regards multilingual modeling, showed multilingual models attain naturalness speaker similarity comparable single speaker model high-resource target languages, research obtained promising results crosslingual transfer learning approach. While research S2S multilingual modeling clearly vibrant, appears exist little systematic research S2S multilingual models could used increase speech naturalness low-resource languages. To fill void, paper investigated extent results found S2S monolingual multi-speaker modeling transferable multilingual multi-speaker modeling, possible attain higher naturalness low-resource languages multilingual models single speaker models. Because multilingual modeling benefit inclusion large amounts non-target language data, also experimented several data addition strategies evaluated extent strategies effective improve naturalness low-resource languages. As research primarily addressing viability different approaches regards low-resource languages, focus much maximizing naturalness rather gaining better understanding different strategies work would potentially scale using larger amounts data. The rest paper organized follows. In Section, describe architecture used conduct experiments. In Section, describe experimental design give details training evaluation. In Section, provide experimental results. Finally, Section, discuss conclusions directions future research."," Recent advances in neural TTS have led to models that can produce high-quality synthetic speech. However, these models typically require large amounts of training data, which can make it costly to produce a new voice with the desired quality. Although multi-speaker modeling can reduce the data requirements necessary for a new voice, this approach is usually not viable for many low-resource languages for which abundant multi-speaker data is not available. In this paper, we therefore investigated to what extent multilingual multi-speaker modeling can be an alternative to monolingual multi-speaker modeling, and explored how data from foreign languages may best be combined with low-resource language data. We found that multilingual modeling can increase the naturalness of low-resource language speech, showed that multilingual models can produce speech with a naturalness comparable to monolingual multi-speaker models, and saw that the target language naturalness was affected by the strategy used to add foreign language data."
"% \dcrm{In standard Question Answering system, user enters natural language question,e.g., Who founded Tesla?}. Knowledge Graph based Question Answering systems use background Knowledge Graph answer queries posed user. Let us take following question example : Who founded Tesla?. The standard sequence steps traditional Entity Linking system follows: The system tries identify Tesla span interest. This task called Mention Detection Span Detection. Then attempt made link appropriate entity Knowledge Base. In work focus Knowledge Bases form graphs, hence entity linker case tries link Tesla appropriate node graph. For human, evident question looking person's name created organisation named Tesla, since text contains relation . Hence, important entity linker understands nuance ignores entity nodes Knowledge Graph also contain Tesla labels, e.g., considering example Wikidata knowledge graph. The task ignoring wrong candidate nodes, identifying right candidate node instead, called Entity Disambiguation . The cumulative process involving Mention Detection Entity Disambiguation called Entity Linking . Typically, MD ED stages implemented different machine learning models require separate training. Especially MD part, sentences marked entity spans requirement. In practice, data easily available. Moreover, errors introduced MD phase cascade ED phase. Hence, movement towards end-to-end Entity Linkers began . Such systems require labelled entity spans training. In spite benefits end-to-end models challenges remain: Due lack span detector initial phase, word sentence needs considered entity candidate disambiguation leads generation much larger number entity candidates. To re-rank candidates large amount time consumed, processing features candidates, also compiling features. %Some systems fetch neighbouring entities relations fly candidate entity, step take minute certain entities large KGs. In work, remain cognizant challenges design system completely avoids querying Knowledge Graph runtime. PNEL instead relies pre-computed pre-indexed TransE embeddings pre-indexed entity label description text set features given candidate entity. We demonstrate produces competitive performance maintaining lower response times compared VCG . While wide variety KG embeddings choose from, confine experiments pre-computed TransE Wikidata supplied PyTorch-BigGraph. Our choice based popularity ease availability embeddings. Traditionally, Knowledge Graphs choice Question Answering research DBpedia, Freebase YAGO. However, recent times Wikidata received significant attention owing fact covers large number entities . DBpedia, YAGO Wikidata source information Wikipedia, however DBpedia YAGO filter large percentage original entities, Wikidata not. While Wikidata larger number entities also adds noise challenge EL system. Wikidata also allows direct edits leading up-to-date information, DBpedia depends edits performed Wikipedia. Freebase discontinued portion merged Wikidata. Moreover DBpedia extracts data directly Wikidata, apart Wikipedia \footnote{https://databus.dbpedia.org/dbpedia/wikidata} . %Wikidata allows wiki based edits hence up-to-date. %Both DBpedia Freebase decided merge Wikidata form. Hence, decide base work Wikidata knowledge graph datasets evaluate based Wikidata.\\ In work contributions follows: The paper organised following sections: Related Work, outlining major contributions entity linking used question answering; PNEL, discuss pointer networks architecture PNEL Dataset used paper Evaluation, various evaluation criteria, results ablation test Error Analysis Discussion future direction."," Question Answering systems are generally modelled as a pipeline consisting of a sequence of steps. In such a pipeline, Entity Linking  is often the first step. Several EL models first perform span detection and then entity disambiguation. In such models errors from the span detection phase cascade to later steps and result in a drop of overall accuracy. Moreover, lack of gold entity spans in training data is a limiting factor for span detector training. Hence the movement towards end-to-end EL models began where no separate span detection step is involved. In this work we present a novel approach to end-to-end EL by applying the popular Pointer Network model, which achieves competitive performance. We demonstrate this in our evaluation over three datasets on the Wikidata Knowledge Graph.    \keywords{Entity Linking  \and Question Answering \and Knowledge Graphs \and Wikidata}"
"Slot filling one major challenging tasks spoken language understanding aims automatically extract semantic concepts assigning set task-related slots word sentence. first reported work applied recurrent neural network slot filling task encouraged follow-up deep learning work task. The next works focused deep learning: tried replace vanilla RNNs advanced RNN cells based long short-term memory bi-directional LSTM , focused recursive neural networks, utilizes attention-based RNN. In study, firstly generalize variational inference -based dropout regularization LSTM-RNNs advanced RNN architectures gated recurrent unit bi-directional LSTM/GRU. Then, RNN models VI-based dropout regularization employed slot filling task ATIS database. Compared , work presents slight modification LSTM-RNNs lead better baseline result, RNN architectures without VI-based dropout regularization tested experiments. As opposed , methods much easier implement attention-based RNN, similar results obtained practice. Since shown RNNs overfit quickly , various regularization methods, early stopping small under-specified models , used RNN training stage. Although dropout normally taken simple effective regularization overcome problem overfitting deep neural networks , concluded naive dropout regularization recurrent weights RNNs cannot reliably solve RNN overfitting problem noise added recurrent connections leads model instabilities . However, recent work shown dropout regularization variational approximation technique Bayesian learning. In addition, variational inference provides new variant dropout regularization, dropout masks separately shared along time embedding, decoding, recurrent weights, successfully applied recurrent layers RNNs. The remainder paper organized follows: Section presents VI-based dropout regularization RNNs. Section develops GRU bi-directional LSTM/GRU-based RNNs VI-based dropout regularization. Section shows experimental results ATIS database paper concluded Section ."," This paper proposes to generalize the variational recurrent neural network  with variational inference -based dropout regularization employed for the long short-term memory  cells to more advanced RNN architectures like gated recurrent unit  and bi-directional LSTM/GRU. The new variational RNNs are employed for slot filling, which is an intriguing but challenging task in spoken language understanding. The experiments on the ATIS dataset suggest that the variational RNNs with the VI-based dropout regularization can significantly improve the naive dropout regularization RNNs-based baseline systems in terms of F-measure. Particularly, the variational RNN with bi-directional LSTM/GRU obtains the best F-measure score."
"The percolation social media throughout world facilitated unprecedented ease access flow information. The rise internet availability also enabled every user consume, also contribute information flow. However, benefits ecosystems come cost mistrust veracity information. In recent years, social media scene witnessed proliferation false information campaigns, ordinary users intentionally otherwise consuming false news also spreading among communities. This phenomenon commonly referred fake news, broadly defined broadcasting information intentionally verifiably false . The rise fake news societal impact studied context numerous recent events, Brexit referendum 2016 US presidential elections . Fake news thus proven major threat democracy, journalism, freedom expression . The exposure users fake news shown numerous deleterious effects, instances include inducing attitudes inefficacy, alienation, trusting false propaganda, cynicism toward certain political candidates communities, times give rise violent events. For example, coordinated fake news propaganda campaigns Facebook considered key inciting Myanmar genocide 2016-2017 . Also, recent proliferation false information 5G communication networks cause novel Coronavirus outbreak resulted attacks employees infrastructure cellular careers UK . Fake news also affect financial markets, observed case fake news claiming Barack Obama injured explosion resulting loss \$130 billion stock value . Hence, growing need effective tools techniques detect control spread false information campaigns social media. Fake news classification process determining whether news contains false news misinformation not. Traditionally, classification performed subject-matter experts journalists via comparing claims article established facts cross-checking trusted alternative sources. However, high volume velocity information flow platforms render manual approaches infeasible. Therefore, recent efforts stakeholders research community focused automated techniques classification detection fake news. A promising solution domain leverage recent advances machine learning Natural Language Processing automated processing classification high-dimensional complex text news articles posts . %We purpose model news article classified dividing overall tasks three parts: Style-Based Classification, Knowledge-Based Classification, Propagation Credibility-Based Classification. This paper focus Style-based classification. % %Machine learning proven useful detecting fake news. The n-gram, part speech tagging probabilistic context free grammar widely used linguistic analysis neural networks. Mihalcea Strapparava used n-gram approach lie detection training Naive Bayes Support Vector Machine classifiers. They used crowd sourcing creating datasets three different topics, opinion abortions, opinion death penalty feelings best friend. They applied minimal pre-processing datasets tokenization stemming without performing feature selection stop words removal. They received average accuracy 70.8\% NB 70.1\% SVM, %Ott et al. trained SVM classifiers using relative POS tag frequencies texts features. They found probable relationship deceptive spam imaginative writing based POS distributional similarities. %Feng et al. investigated syntactic stylometry deception detection. They found features driven Context Free Grammar parse trees improved deception detection Ott et al. While literature applications machine learning fake news classification grown rapidly, body work classification short-text claims remains relatively thin. This issue paramount importance, many posts social media Twitter contain short claim extracted longer text news articles. The short form claims poses challenge classification task, provides limited information thus constrains applicability machine learning models trained full-length articles texts. Over past years, number datasets models proposed classification short-text claims, notable instances studies based LIAR dataset short statements . However, performance machine learning models trained dataset remain impractical levels, best accuracy values reported \~41.5\% . % reported study The problem non neural network approach news articles longer length using non neural network approach semantic syntactic features sentences cannot extracted exploited properly full extent non neural network approaches. The solution neural network methods. %Rashkin et al. trained LSTM model takes sequence words input predicts Politifact rating, found accurate NBC Maximum Entropy models. They also concatenated LSTM output Linguistic Inquiry Word Count features undergoing activation layers. The NBC Maximum Entropy models improved LIWC LSTM perform well. The reason might LSTM learn formations LIWC themselves. Wang used deep learning based CNN model LIAR dataset found better results non-neural network methods. %Qian et al. proposed two models, first one Two-Level Convolutional Neural Network variant CNN second one User Response Generator . The TCNN captured semantic information articles' text representing sentence word level. And URG learns generative responses news article text historical user responses assist classification. In paper, introduce Sentimental LIAR, extends LIAR dataset including new features based sentiment emotion analysis claims. Our extended dataset also proposes modified encoding textual attributes mitigate unintended bias modeling. Furthermore, propose novel deep learning architecture based BERT-Base language model classification claims genuine fake. Our results demonstrate proposed architecture trained Sentimental LIAR achieve accuracy 70\%, improvement ~30\% previously reported results LIAR benchmark. The Sentimental LIAR dataset proof-of-concept code made available GitHub. %In paper, present series experiments performed using BERT-Base extended LIAR datasets compare results. The base BERT-Base model modified adding linear neural net top modification done adding CNN model top. The modified models tested different version LIAR datasets. We modified LIAR dataset extending sentiment score sentiment statement. The extension done adding five emotions statement The remainder paper organized follows: Section presents technical background overview relevant datasets literature false claim classification. Section describes extended features Sentimental LIAR, details proposed deep learning architectures false claim detection. The experimental evaluation proposed techniques reported Section . Finally, concludes paper discussion results remarks future directions work."," The rampant integration of social media in our every day lives and culture has given rise to fast and easier access to the flow of information than ever in human history. However, the inherently unsupervised nature of social media platforms has also made it easier to spread false information and fake news. Furthermore, the high volume and velocity of information flow in such platforms make manual supervision and control of information propagation infeasible. This paper aims to address this issue by proposing a novel deep learning approach for automated detection of false short-text claims on social media. We first introduce Sentimental LIAR, which extends the LIAR dataset of short claims by adding features based on sentiment and emotion analysis of claims. Furthermore, we propose a novel deep learning architecture based on the BERT-Base language model for classification of claims as genuine or fake. Our results demonstrate that the proposed architecture trained on Sentimental LIAR can achieve an accuracy of 70\%, which is an improvement of ~30\% over previously reported results for the LIAR benchmark. %improve the previously reported accuracy of the task by     Focusing on the prevalent short-text format of claims on social media such as Twitter, our work   to an unprecedented challenge in  . Fake news is not only threatening to undermine democracy but equally has been proven to cause violence, disruption, and chaos in the world. Hence, in this research paper, we are going to use the machine learning approach to classify the fake news from the true ones. The rise of Natural Language Processing makes it possible to analyze the news articles. We are proposing a model composed of three perspectives. The first perspective is the Style Based Classification where we classify the article based on its intention is misleading or not, by analyzing the text pattern from the attribute-based and structure-based language features. The second perspective is Knowledge-based classification which is going to classify the news articles based on its authenticity by knowledge extraction and fact-checking. The third perspective is the Propagation and Credibility based classification by analyzing the propagation model of fake news and the credibility of the engaging users. This research paper currently focused on first perspective i.e. Style based classification by deception detection using deep neural networks where we performed experiments using LIAR Dataset by changing it into binary labels and BERT-Base."
"The ever-growing amount user-generated data social media platforms Facebook, Twitter, blogs electronic medium introduces new challenges terms automatic content moderation, especially regarding hate speech offensive language detection. Not hate speech likely happen Internet, anonymity easily obtained speakers psychologically distant audience, online nature also gives far-reaching determinative impact. User content mostly consists microposts, context post missing inferred current events. Manual verification posting human moderator infeasible due high amount postings created every day. Consequently, automated detection attacking postings feasible way counter kind hostility. However, task challenging natural language fraught ambiguities, language social media extremely noisy. The classification system would prepared task, needed generalized various test corpora well. In paper I described system consisting sequential pipeline text feature extraction classification main components. Firstly, bag-of-words model used encoding sentences corresponding integer sequence. Thereafter, vectors generated sequences fed series BiLSTM layers training. Then softmax layer used ternary classification corresponding offensive language categories. The rest paper organized follows. Section describes data, which, task performed. The methodology followed described Section . This followed results concluding remarks Section respectively. % % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % %. % % % final paper: en-us version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. % }"," SemEval-2020 Task 12 was OffenseEval: Multilingual Offensive Language Identification in Social Media \cite{zampieri-etal-2020-semeval}. The task was subdivided into multiple languages and datasets were provided for each one. The task was further divided into three sub-tasks: offensive language identification, automatic categorization of offense types, and offense target identification. I have participated in the task-C, that is, offense target identification. For preparing the proposed system, I have made use of Deep Learning networks like LSTMs and frameworks like Keras which combine the bag of words model with automatically generated sequence based features and manually extracted features from the given dataset. My system on training on 25\% of the whole dataset achieves macro averaged f1 score of  47.763\%."
"The discourse structure document describes discourse relationships elements graph tree. Discourse parsing largely dominated greedy parsers~\cite[\eg.][]{braud2016multi,ji2014representation,yu2018transition,SogaardBC17}. Global parsing rarer dependency node's label internal split point make prediction computationally prohibitive. % resulting large grammar constant. % This expense comes dependency relation % labels assigned node % split point separates children, results % large constant global inference terms time % complexity, making inference process extremely slow. In work, propose CKY-based global parser tractable inference using new independence assumption loosens coupling identification best split point label prediction. % For particular node, first decide split % point without considering labels; based % split point, make decisions labels % current node. % However, apply recursion, total score % node sum scores split point label % assignments instead recursing split % score. % By making independence decisions split point label % assignment, remove large constant terms time % complexity; recursing sum scores, % dependency relations maintained. Doing gives us advantage search best tree larger space. % One side effect % need complex models represent EDUs. Greedy discourse parsers use complex models ensure step correct search space limited. For example, \citet{ji2014representation} manually crafted features feature transformations encode elementary discourse units ; \citet{yu2018transition} \citet{braud2016multi} used multi-task learning better EDU representation. Instead, work, use simple recurrent span representation build parser outperforms previous global parsers.% comparable state-of-art % greedy parsers. Our contributions are: %%% Local Variables: %%% mode: latex %%% TeX-master: ""main"" %%% End: % % File emnlp2019.tex % %% Based style files ACL 2019, %% Based style files EMNLP 2018, %% Based style files ACL 2018, %% Based style files ACL-2015, improvements %% taken NAACL-2016 style %% Based style files ACL-2014, were, turn, %% based ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009, %% EACL-2009, IJCNLP-2008... %% Based style files EACL 2006 %%e.agirre@ehu.es Sergi.Balari@uab.es %% ACL 08 Joakim Nivre Noah Smith \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{emnlp-ijcnlp-2019} \usepackage{times} \usepackage{latexsym} \usepackage{mlsymbols} \usepackage{mystyle} \usepackage{symbol} \usepackage{comment} \usepackage{url} \aclfinalcopy % Uncomment line final submission % \setlength\titlebox{5cm} % You expand titlebox need extra space % show authors. Please make titlebox % smaller 5cm ; check % camera-ready version ask change back. \newcommand\BibTeX{B{\sc ib}\TeX} \newcommand\confname{EMNLP-IJCNLP 2019} \newcommand\conforg{SIGDAT} \title{A Simple Global Neural Discourse Parser} \author{ Yichu Zhou \\ University Utah \\ flyaway@cs.utah.edu \\\And% Omri Koshorek \\ Tel-Aviv University \\ omri.koshorek@cs.tau.ac.il \\\AND%\\ Vivek Srikumar \\ University Utah \\ svivek@cs.utah.edu \\\And% Jonathan Berant \\ Tel-Aviv University\\ joberant@cs.tau.ac.il } \date{}","     Discourse parsing is largely dominated by     greedy parsers with manually-designed     features, while global parsing is rare due to its     computational expense.  In this paper, we propose a     simple chart-based neural discourse parser that does not     require any manually-crafted features and is based on     learned span representations only. To overcome the     computational challenge, we propose an independence     assumption between the label assigned to a node in the     tree and the splitting point that separates its children,     which results in tractable decoding. We empirically     demonstrate that our model achieves the best performance     among global parsers, and comparable performance to     state-of-art greedy parsers, using only learned     span representations."
"Large-scale language model pretraining become increasingly prevalent achieving high performance variety natural language processing tasks. When applying models specific task, usually fine-tuned using supervised learning, often maximize log probability set human demonstrations. % Fundamentally, objectives weight every word equally lack humanimbued notion important get right less important . While strategy led markedly improved performance, still misalignment fine-tuning objective---maximizing likelihood human-written text---and care about---generating high-quality outputs determined humans. This misalignment several causes: maximum likelihood objective distinction important errors unimportant errors ; models incentivized place probability mass human demonstrations, including low-quality; distributional shift sampling degrade performance . Quality often improved significantly non-uniform sampling strategies beam search , lead repetition undesirable artifacts . Optimizing quality may principled approach overcoming problems. \footnotetext{Throughout paper, error bars represent 1 standard error.} Our goal paper advance methods training language models objectives closely capture behavior care about. To make short-term progress towards goal, focus abstractive English text summarization, long history NLP community , subjective task believe difficult quantify summary quality without human judgments. Indeed, existing automatic metrics evaluating summary quality, ROUGE , received criticism poor correlation human judgments . We follow works , fine-tune language models human feedback using reward learning . We first collect dataset human preferences pairs summaries, train reward model via supervised learning predict human-preferred summary. Finally, train policy via reinforcement learning maximize score given RM; policy generates token text `time step', updated using PPO algorithm based RM `reward' given entire generated summary. We gather human data using samples resulting policy, repeat process. We follow works use large pretrained GPT-3 models many 6.7 billion parameters. \iffalse \footnotetext{Throughout paper, error bars represent 1 standard error.} \fi Our main contributions four-fold. We show training human feedback significantly outperforms strong baselines English summarization. When applying methods version Reddit TL;DR dataset , train policies via human feedback produce better summaries much larger policies trained via supervised learning. Summaries human feedback models preferred labelers original human demonstrations dataset . We show human feedback models generalize much better new domains supervised models. Our Reddit-trained human feedback models also generate high-quality summaries news articles CNN/DailyMail dataset without news-specific fine-tuning, almost matching quality dataset閳ユ獨 reference summaries. We perform several checks ensure human preferences reflect real quality difference: consistently monitor agreement rates amongst labelers researchers, find researcher-labeler agreement rates nearly high researcher-researcher agreement rates , verify models merely optimizing simple metrics like length amount copying . We conduct extensive empirical analyses policy reward model. We examine impact model data size , study performance continue optimize given reward model , analyze reward model performance using synthetic human-written perturbations summaries . We confirm reward model outperforms metrics ROUGE predicting human preferences, optimizing reward model directly results better summaries optimizing ROUGE according humans . We publicly release human feedback dataset research. The dataset contains 64,832 summary comparisons TL;DR dataset, well evaluation data TL;DR CNN/DM . \iffalse \paragraph{Main result.} When applying methods version Reddit TL;DR dataset , train policies via human feedback produce better summaries much larger policies trained via supervised learning. Summaries human feedback models preferred labelers original human demonstrations dataset . These Reddit-trained human feedback models also generate high-quality summaries news articles CNN/DailyMail dataset without fine-tuning, almost matching quality dataset閳ユ獨 reference summaries. We perform several checks ensure strong human preferences reflect real quality difference: consistently monitor agreement rates amongst labelers researchers, find researcher-labeler agreement rates nearly high researcher-researcher agreement rates , verify models merely optimizing simple metrics like length amount copying . % we've performed qualitative evaluations policy outputs agree worker judgments ; we've spot-checked surprising conclusions, extractive baselines outperforming human-written summaries CNN/DM, found worker judgments seemed reasonable . \paragraph{Additional analysis.} We also examine impact model data size , study performance continue optimize given reward model , analyze reward model performance using synthetic human-written perturbations summaries , confirm reward model outperforms metrics ROUGE predicting human preferences . \fi The methods present paper motivated part longer-term concerns misalignment AI systems humans want do. When misaligned summarization models make facts, mistakes fairly low-risk easy spot. However, AI systems become powerful given increasingly important tasks, mistakes make likely become subtle safety-critical, making important area research.","   As language models become more powerful, training and evaluation are increasingly bottlenecked by the data and metrics used for a particular task. %, rather than by model understanding.   For example, summarization models are often trained to predict human reference summaries and evaluated using ROUGE, but both of these metrics are rough proxies for what we really care about---summary quality. In this work, we show that it is possible to significantly improve summary quality by training a model to optimize for human preferences.  We collect a large, high-quality dataset of human comparisons between summaries, train a model to predict the human-preferred summary, and use that model as a reward function to fine-tune a summarization policy using reinforcement learning. We apply our method to a version of the TL;DR dataset of Reddit posts \cite{volske2017tl} and find that our models significantly outperform both human reference summaries and much larger models fine-tuned with supervised learning alone. Our models also transfer to CNN/DM news articles \cite{hermann2015teaching}, producing summaries nearly as good as the human reference without any news-specific fine-tuning.\footnote{Samples from all of our models can be viewed \href{https://openaipublic.blob.core.windows.net/summarize-from-feedback/website/index.html}{on our website}.}    We conduct extensive analyses to understand our human feedback dataset and fine-tuned models.\footnote{We provide inference code for our 1.3B models and baselines, as well as a model card and our human feedback dataset with over 64k summary comparisons,  \href{https://github.com/openai/summarize-from-feedback}{here}.}   We establish that our reward model generalizes to new datasets, and that optimizing our reward model results in better summaries than optimizing ROUGE according to humans.   We hope the evidence from our paper motivates machine learning researchers to pay closer attention to how their training loss affects the model behavior they actually want."
"Language models exhibit one- few-shot learning growing interest machine learning applications adapt knowledge new information . One-shot language learning physical world also interest developmental psychologists; fast-mapping, ability bind new word unfamiliar object single exposure, much studied facet child language learning . Our goal enable embodied learning system perform fast-mapping, take step towards goal developing embodied agent situated 3D game environment learn names entirely unfamiliar objects single exposure, immediately apply knowledge carry instructions based objects. The agent observes world via active perception raw pixels, learns respond linguistic stimuli executing sequences motor actions. It trained combination conventional RL predictive learning. We find agent architecture consisting standard neural network components sufficient follow language instructions whose meaning preserved across episodes. However, learning fast-map novel names novel objects single episode relies semi-supervised prediction mechanisms novel form external memory, inspired dual-coding theory knowledge representation . With components, agent exhibit slow word learning fast-mapping. Moreover, agent exhibits emergent propensity integrate fast-mapped slowly acquired word meanings single episode, successfully executing instructions ``put dax box"" depend slow-learned fast-mapped word meanings. %An embodied learning system executed fast-mapping flexibility best large-scale text-based language models could lead similarly improved human-agent interaction users game-based agents, virtual-reality avatars robotic assistants. Via controlled generalization experiments, find agent reasonably robust degree variation number objects involved given fast-mapping task test time. The agent also exhibits above-chance success presented name particular object ShapeNet taxonomy instructed interact different exemplar object class, propensity enhanced specific meta-training. We find number unique objects observed agent training temporal aspect perceptual experience objects contribute critically ability generalize, particularly ability execute fast-mapping entirely novel objects. Finally, show dual-coding memory schema provide effective basis derive signal intrinsic motivation conventional memory. %Equipped intrinsic curiosity, agent resolve long episodes requiring fast-binding intermediate environment rewards stimulate requisite information discovery."," Recent work has shown that large text-based neural language models acquire a surprising propensity for one-shot learning. Here, we show that an agent situated in a simulated 3D world, and endowed with a novel dual-coding external memory, can exhibit similar one-shot word learning when trained with conventional RL algorithms. After a single introduction to a novel object via visual perception and language , the agent can manipulate the object as instructed , combining short-term, within-episode knowledge of the nonsense word with long-term lexical and motor knowledge. We find that, under certain training conditions and with a particular memory writing mechanism, the agent's one-shot word-object binding generalizes to novel exemplars within the same ShapeNet category, and is effective in settings with unfamiliar numbers of objects. We further show how dual-coding memory can be exploited as a signal for intrinsic motivation, stimulating the agent to seek names for objects that may be useful later. Together, the results demonstrate that deep neural networks can exploit meta-learning, episodic memory and an explicitly multi-modal environment to account for fast-mapping, a fundamental pillar of human cognitive development and a potentially transformative capacity for artificial agents."
"Emphasis selection emerging research problem natural language processing domain, involves automatic identification words phrases short text would serve good candidates visual emphasis. This research relevant visual media flyers, posters, ads, motivational messages certain words phrases visually emphasized use different color, font, typographic features. This type emphasis help expressing intent, providing clarity, drawing attention towards specific information text. Automatic emphasis selection therefore useful graphic design presentation applications assist users appropriate choice text layout. Prior works speech processing modeled word-level emphasis using acoustic prosodic features. Understanding emphasis speech critical many downstream applications text-to-speech synthesis , speech-to-speech translation , computer assisted pronunciation training . In computational linguistics, emphasis selection closely related problem keyphrase extraction . Keyphrases typically refer nouns noun-phrases capture salient topics long documents scientific articles , news articles , web pages , etc. In contrast, emphasis selection deals short texts , also emphasis could applied words belonging various parts speech. The goal SemEval 2020 - Task 10 design methods automatic emphasis selection short texts. To end, organizers provided dataset consisting 3,000 sentences annotated token-level emphasis multiple annotators. The authors employed standard I-O tagging schema, widely used annotation token-level tags. We approached emphasis selection sequence labeling task solved using Bidirectional Long Short-term Memory model, individual tokens represented using various contextual embedding models. We also employ label distribution learning approach, elegantly accounts disagreements annotators."," This paper presents our submission to the SemEval 2020 - Task 10 on emphasis selection in written text. We approach this emphasis selection problem as a sequence labeling task where we represent the underlying text with various contextual embedding models. We also employ label distribution learning to account for annotator disagreements. We experiment with the choice of model architectures, trainability of layers, and different contextual embeddings. Our best performing architecture is an ensemble of different models, which achieved an overall matching score of 0.783, placing us 15th out of 31 participating teams. Lastly, we analyze the results in terms of parts of speech tags, sentence lengths, and word ordering. \blfootnote{*Authors contributed equally.}"
"Licence details: http://creativecommons.org/licenses/by/4.0/. } The Internet represents biggest source knowledge humankind currently possesses. People corners world express opinions, thoughts, share insights regarding certain ideas. During past decade, new never seen way sharing beliefs arose, memes. For example, humorously combining text images, authors emphasize series aspects amuse, various degrees ways, receptors. Motivation. Internet memes come various templates formats. Some purely humorous, others, behind amusing appearance, intend convey subtle nuances including sarcasm, disbelief regarding idea, motivational purpose. %Others express sarcasm disbelief regarding idea, motivational purpose. All present online environment offer %a great opportunity studying online user's behaviors beliefs. Thus, offers insight opinion communities regarding particular aspects. Moreover, used obtaining valuable information lead improvements web content mining process. Challenges. The mining task becomes increasingly difficult, since image text clarity usually seem vary substantially, depending user region posted from. %as, usually, image text clarity seem vary substantially, depending user region posted from. %Unclear posts sometimes lead considerable difficulties identifying overall message author. These situations may cause unfavorable results performing analysis process and, particular cases, transmit different idea intended. If ambiguity reaches high values, lead impossibility separating two main ways memes convey information: text image. Also, since text embedded image, low-quality picture introduce noise inside content compromise entire meme. On way around, extremely unclear text create discrepancy visual aspect post, thus weaken overall message. \comment{ Figure shows example ambiguous well-created memes. } The memotion analysis shared task organized SemEval-2020 intends challenge participants approach previously mentioned issues create systems able analyze Internet memes. The competition consists three subtasks. Subtask A intends properly classify memes either positive, neutral, negative. Furthermore, Subtask B builds upon first subtask participants challenged binary classify posts considering four categories: humor, sarcasm, offense, motivation. Finally, Subtask B extended Subtask C, four categories expanded classes different granularity, gradually increasing lowest highest possibility regarding category. Proposed Approach. We intend solve previously mentioned subtasks introducing neural network based multi-task learning . The system contain modules dedicated image analysis modules specialized text processing. The architecture outputs single answer required subtasks. % The architecture outputs time answer required tasks. \comment{ } The next parts work structured follows. In section 2, perform analysis existing solutions found related works. In section 3, outline approaches applied memotion analysis. Section 4 details performed experiments, experimental setup, error analysis. Finally, draw conclusions section 5.","  Users from the online environment can create different ways of expressing their thoughts, opinions, or conception of amusement. Internet memes were created specifically for these situations. Their main purpose is to transmit ideas by using combinations of images and texts such that they will create a certain state for the receptor, depending on the message the meme has to send. These posts can be related to various situations or events, thus adding a funny side to any circumstance our world is situated in. In this paper, we describe the system developed by our team for SemEval-2020 Task 8: Memotion Analysis. More specifically, we introduce a novel system to analyze these posts, a multimodal multi-task learning architecture that combines ALBERT for text encoding with VGG-16 for image representation. In this manner, we show that the information behind them can be properly revealed. Our approach achieves good performance on each of the three subtasks of the current competition, ranking  \ for Subtask A , \ for Subtask B , and \ for Subtask C  while exceeding the official baseline results by high margins."
"A series countries world multilingual, implies multiple languages spoken population. People tend mix phrase sentence level order express ideas ease, thus creating phenomenon called code-mixing code-switching. As expected, embedding language another one makes appearance virtual space, well. For example, Twitter users combine Hindi Spanish phrases English words, thus creating bilingual phrase lead understanding problems non-natives. However, virtual space adds layers difficulty identifying sentiment author. Usually, social media users tend adopt phonetic typing, implies words take original form, adapted faster express main idea. As particular case, Hindi-English users, new problem arises: Hindi English use different alphabets, determines user romanize Hindi words languages use alphabet throughout text. At time, social media users tend express sentiments repeating certain vocals words. Furthermore, use emojis, add extra layer complexity analyzing text. This entire process creates new opportunities research, given importance sentiment analysis area. The SemEval-2020 Task 9: Sentiment Analysis Code-Mixed Social Media Text challenges research community solve previously mentioned problem introducing two subtasks, focusing three world's spoken languages: Hindi Spanish, alongside English. We proposed series neural models intend solve issue, contributing usernames eduardgzaharia clementincercel, respectively. Firstly, experimented Recurrent Neural Network solutions alongside word embeddings. After that, performed leap towards Transformer-based models usually perform better offer insight combined language models. Furthermore, adding auxiliary task training multi-task learning architecture lead even better results, models become able learn new features input texts. The paper structured follows. In section 2, perform analysis existing solutions several code-mixed tasks sentiment analysis. In section 3, detail proposed approaches code-mixed sentiment analysis. Section 4 details performed experiments, including data preprocessing, experimental setup, discussion results. Finally, draw conclusions section 5."," Sentiment analysis is a process widely used in opinion mining campaigns conducted today. This phenomenon presents applications in a variety of fields, especially in collecting information related to the attitude or satisfaction of users concerning a particular subject. However, the task of managing such a process becomes noticeably more difficult when it is applied in cultures that tend to combine two languages in order to express ideas and thoughts. By interleaving words from two languages, the user can express with ease, but at the cost of making the text far less intelligible for those who are not familiar with this technique, but also for standard opinion mining algorithms. In this paper, we describe the systems developed by our team for SemEval-2020 Task 9 that aims to cover two well-known code-mixed languages: Hindi-English and Spanish-English.  We intend to solve this issue by introducing a solution that takes advantage of several neural network approaches, as well as pre-trained word embeddings. Our approach  achieves promising performance on the Hindi-English task, with an average F1-score of 0.6850, registered on the competition leaderboard, ranking our team \ out of 62 participants. For the Spanish-English task, we obtained an  average F1-score of 0.7064 ranking our team \ out of 29 participants by using another multilingual Transformer-based model, XLM-RoBERTa."
"The recent outbreak SARS-CoV-2 led global pandemic total number infections exceeding 6 million 370000 mortality already. The disease code named COVID-19 far reaching repercussions world over. This article aims uncover life science universe Corona virus related ailments employing state-of-the-art natural language processing technologies applied biomedical domain. We took corpus 40000 titles abstracts released part CORD-19 Open Research Challenge applied entity recognition relationship discovery models construct knowledge graph related COVID-19. In process, uncovered 40000 entities 80000 relationships. This article presents salient findings organized follows. Section briefly describes masked entities model masked relationship model. Section presents network analysis knowledge network discovered mining CORD-19 dataset. The coverage CORD-19 dataset may exhaustive up-to-date. We took snapshot around April 15, 2020. Nevertheless, primary aim work demonstrate application artificial intelligence condensing unstructured information biomedical domain sufficiently low entropy state important leads established."," We extract entities and relationships related to COVID-19 from a corpus of articles related to Corona virus by employing a novel entities and relationship model. The entity recognition  and relationship discovery models are trained with a multi-task learning objective  on a large annotated corpus. We employ a concept masking paradigm to prevent the evolution of neural networks functioning as an associative memory and induce right inductive bias guiding the network to make inference using only the context. We uncover several import subnetworks, highlight important terms and concepts and elucidate several treatment modalities employed in related ailments in the past."
"The COVID-19 pandemic urged various science disciplines best contribute understanding relieving impact. Thus, scholars practitioners working information sciences dedicating significant effort help. Collecting analyzing data published social media platforms become focus respect. We joined community aims organizing data collected social media , informative uninformative. The WNUT-2020 Task 2 considers tweets recovered, suspected, confirmed death cases well location travel history cases informative. All tweets considered uninformative. The organizers share annotation manual baseline system made available, presumably prevent use manually annotated data encourage broad participation respectively.\footnote{\url{http://noisy-text.github.io/2020/covid19tweet-task.html}, accessed September 4, 2020.} The effort managed terms shared task, organizers share dataset consists annotated tweets conduct evaluation submissions. The task requires participating teams develop short-text classification systems facilitate training development data generalize test set release. Although gold labels training development data available participants, neither gold labels test data annotation guidelines part data shared participants. Moreover, test instances unknown participating teams. They hidden larger dataset. Each team allowed submit two outputs systems developed classifying tweets Codalab page task.\footnote{\url{https://competitions.codalab.org/competitions/25845}, accessed September 4, 2020.} The highest score terms F1 positive class team used rank leaderboard. Integrating automatically created machine learning based models manually formulated rules tackle text classification task promises best worlds. We pursued goal integrating output two deep learning models rule-based system team name COVCOR20. Although integration slightly improves total performance training development sets cross-validation setting, overall performance test data turned slightly worse best ML system. Our best submission ranked 22nd among 55 teams. The integration systems would ranked 27th score used final score team. The deep learning models rule-based system introduced Sections respectively. Next, Section describes integrate output systems. Then Section provide results discussion. Finally, conclude report share future plans continuing line research Section."," In the scope of WNUT-2020 Task 2, we developed various text classification systems, using deep learning models and one using linguistically informed rules. While both of the deep learning systems outperformed the system using the linguistically informed rules, we found that through the integration of  the three systems a better performance could be achieved than the standalone performance of each approach in a cross-validation setting. However, on the test data the performance of the integration was slightly lower than our best performing deep learning model. These results hardly indicate any progress in line of integrating machine learning and expert rules driven systems. We expect that the release of the annotation manuals and gold labels of the test data after this workshop will shed light on these perplexing results."
"The phenomenon combining two languages message known code-switching code-mixing . Code-switching indicator bilingual competence , also motivated social cultural factors social status, race, age, etc. . % Instead consider indicator lack competence , cultural social factors motivate study . Although phenomenon studied extensively linguistics , still challenging machines process mixed natural languages. Code-switching notoriously present social media posts chats Twitter, Facebook WhatsApp; consequently making difficult process sentiment expressed contents. %Multilingual people, non-native English speakers, tend code-mix using English-based phonetic typing insertion anglicisms main language. %In addition mixing languages sentence level, fairly common find code-mixing behavior word level. %This linguistic phenomenon cannot tackled conventional NLP systems, based monolingual resources handle combination multiple languages. %Statistics show half messages Twitter language English. This evidence suggests languages, including multilingualism code-mixing, need considered NLP community. % \hl{Statistics show used code switching social media} In work, present Convolutional Neural Network system predict sentiment given code-mixed tweet. The sentiment labels either positive, negative, neutral, languages involved English Spanish. Our best model utilizes Spanish word embeddings tweets require manual feature engineering. % Before classification, English texts normalized anonymize entities, label stylistic patterns, transform words tackle typical issues texts Twitter. % We highlight contributions work follows: % %This paper structured six different sections. Section 2 contains dataset description. As section 3, contains literature review presents existing related work code-mixing. Section 4 depicts methodology. Section 5 devoted presentation discussion experimental results. Finally, recommendations future research opportunities along conclusion reported section 6. % ======================== Article section"," %   Code-switching is a phenomenon in which two or more languages are used in the same message. Nowadays, it is quite common to find messages with languages mixed in social media. This phenomenon presents a challenge for sentiment analysis. % forcing the models to use a mix of language resources. In this paper, we use a standard convolutional neural network model to predict the sentiment of tweets in a blend of Spanish and English languages. Our simple approach achieved a F1-score of $0.71$ on test set on the competition. We analyze our best model capabilities and perform error analysis to expose important difficulties for classifying sentiment in a code-switching setting."
". % % % final paper: en-us version % % space normally used marker This work licensed Creative Commons Attribution 4.0 International License. License details: \url{http://creativecommons.org/licenses/by/4.0/}. } Emphasis selection written text visual media proposed . The purpose shared task design automatic methods emphasis selection, i.e. choosing candidates emphasis short written text, enable automated design assistance authoring. For example, mentions technique applied graphic design applications Adobe Spark perform automatic text layout using templates include images text different fonts colors. The major challenge given thousands annotated short text data without context text visual background images, asked learn author- domain-specific emphatic short text. Besides, short text data annotated crowd-sourcing workers. And find different annotators different standards, increases difficulty task. To identify important words, model task sequential labeling problem. Our base models leverage different unsupervised language model ERNIE 2.0 , XLM-ROBERTA , ROBERTA ALBERT . These large unsupervised models pre-trained large amount unannotated data carry valuable lexical, syntactic, semantic information training corpora. Our approach follows: firstly, word-level output representations sentence computed pre-trained models fed designed downstream neural network word selections; secondly, finetune downstream networks together pre-trained models annotated training data; thirdly, investigate several different objective functions learn model; finally, apply feature engineering several data augmentation strategies improvement. The rest paper organized follows. In Section , briefly overview related works system. Section shows details approach. Our experiments shown Section , Section concludes.","   This paper describes the system designed by ERNIE Team which achieved the first place in SemEval-2020 Task 10: Emphasis Selection For Written Text in Visual Media. Given a sentence, we are asked to find out the most important words as the suggestion for automated design. We leverage the unsupervised pre-training model and finetune these models on our task. After our investigation, we found that the following models achieved an excellent performance in this task: ERNIE 2.0, XLM-ROBERTA, ROBERTA and ALBERT. We combine a pointwise regression loss and a pairwise ranking loss which is more close to the final $Match_{m}$ metric to finetune our models. And we also find that additional feature engineering and data augmentation can help improve the performance. Our best model achieves the highest score of 0.823 and ranks first for all kinds of metrics."
"The 2020 edition Workshop Noisy User-generated Text hosted shared task `Identification Informative COVID-19 English Tweets'. The task involves automatically identifying whether English Tweet related novel coronavirus `informative' not. For tweet considered informative context, provide information recovered, suspected, confirmed, death cases well location travel history cases. The goal developing automated system help track development COVID-19 outbreak provide users information related virus, e.g. new suspicious/confirmed cases near/in users' regions. Aligned goals shared task, paper details use state-of-the-art natural language processing techniques task. %to identify informative tweets related COVID-19. We experiment variety methods, ranging feature-based classifiers leveraging recent advances pre-trained neural architectures . To improve performance, incorporate unlabelled tweets released COVID-19 via masked language modelling pseudo-labelling techniques. Our best performing model ensemble uses Logistic Regression combine output probabilities several base classifiers . We analyze impact pre-processing semi-supervision ablation studies. Through qualitative adversarial analysis, show predictions BERT model sensitive towards specific tokens `confirmed case' even locations numerals, also guides data pre-processing steps."," We describe our system for WNUT-$2020$ shared task on the identification of informative COVID-19 English tweets. Our system is an ensemble of various machine learning methods, leveraging both traditional feature-based classifiers as well as recent advances in pre-trained language models that help in capturing the syntactic, semantic, and contextual features from the tweets. We further employ pseudo-labelling to incorporate the unlabelled Twitter data released on the pandemic. Our best performing model achieves an F1-score of $0.9179$ on the provided validation set and $0.8805$ on the blind test-set."
"Text classification important problem natural language processing . The task assign document one predefined categories. It wide range applications sentiment analysis~, topic categorization~, email filtering~. Early machine learning approaches text classification based extraction bag-of-words features followed supervised classifier na\""ive Bayes~ linear SVM~. Later, better word representations introduced, latent semantic analysis~, skipgram~, fastText~, improved classification accuracy. Recently, recurrent convolutional neural network~ models introduced utilize word order grammatical structure. Many complex variations models proposed improve text classification accuracy, e.g. training one-hot CNN one-hot bidirectional LSTM network dynamic max-pooling . Current state-of-the-art approaches text classification involve using pretrained LSTMs complex computationally intensive models . DL15 argued randomly initialized LSTMs difficult optimize lead worse performance linear models. Therefore, improve performance, proposed pretraining LSTM either language model sequence auto-encoder. However, pretraining using complicated models time consuming, major disadvantage may always feasible. In paper, consider BiLSTM classifier model similar one proposed DL15 text classification. For simple BiLSTM model pretrained embeddings, propose training strategy achieve accuracy competitive previous purely supervised models, without extra pretraining step. We also perform ablation studies understand aspects proposed training strategy result improvement. Pretraining approaches often use extra unlabeled data addition labeled data. We explore applicability semi-supervised learning training framework, prior pretraining step. In regard, propose mixed objective function SSL utilize labeled unlabeled data obtain improvement classification. To summarize, contributions follows:"," \begin{quote}     In this paper, we study bidirectional LSTM network for the task of text classification using both supervised and semi-supervised approaches. Several prior works have suggested that either complex pretraining schemes using unsupervised methods such as language modeling or complicated models are necessary to achieve a high classification accuracy. However, we develop a training strategy that allows even a simple BiLSTM model, when trained with cross-entropy loss, to achieve competitive results compared with more complex approaches. Furthermore, in addition to cross-entropy loss, by using a combination of entropy minimization, adversarial, and virtual adversarial losses for both labeled and unlabeled data, we report state-of-the-art results for text classification task on several benchmark datasets. In particular, on the ACL-IMDB sentiment analysis and AG-News topic classification datasets, our method outperforms current approaches by a substantial margin. We also show the generality of the mixed objective function by improving the performance on relation extraction task.\footnote{\mycodeurl} \end{quote}"
"Coreference resolution aims identifying expressions refer entity text. It helps derive correct interpretation text binding antecedents pronouns together recognizing syntactic relationship among them. The coreference resolution considered critical preprocessing step various high-level natural language processing tasks including document summarization, question answering, information extraction . Existing coreference resolution approaches divided two major categories: mention-pair models entity-mention models . One main shortcomings mention-pair model making coreference decision without entity-level information. Moreover, lack information preceding clusters may result contradictory links. The entity-mention model tries make use non-local information encouraging sharing features across mentions point real-world entity. However, coreferent mentions usually spread far apart text, makes extremely difficult define effective global features. Previous studies either count long-term memory variants implicitly capture global features seek incorporate features clusters already formed determine whether mention coreferent preceding cluster . The former might miss important features specific pairwise predictions without help explicit entity-level features, latter may suffer error propagation false clusters used create entity-level features making future predictions. Taking text ``On November 3, 1992, Clinton elected 42nd president United States, following year Hillary Clinton became first lady. In 2013, Presidential Medal Freedom."" example, assume three mentions ``Clinton"", ``Hillary Clinton"", ``he"" well identified. The traditional mention-pair model likely group three mentions cluster shown Figure since ``Clinton"" ``Hillary Clinton"" share surname, ``he'' agrees ``Clinton"" gender number. To make use information clusters already formed, recent studies try better represent current mention incorporating features derived preceding cluster probably join . However, methods allow information shared forward fashion, i.e., antecedent expressions postcedent ones, prone reaching results shown Figure . The reason ``Hillary Clinton'' merged ``Clinton'' form cluster, pronoun ``he'' either joins formed cluster begins new one itself. Even though errors might recovered using proper decoding algorithm test time, maximum spanning tree algorithm, similar errors cannot completely eliminated. If information shared iteratively forward backward ways, disagreement gender ``Hillary Clinton'' ``he'' detected representation ``Clinton'' updated two possible co-references, helps find correct result Figure . Recently, graph neural network gained increasing popularity due ability modeling dependencies nodes graph . For coreference resolution, mentions linked via edges modeling likely two linked mentions refer entity. The features nodes shared direction message passing neighborhood aggregation iterative way. We found entity-centric features well captured GNN, achieving close state-of-the-art performance. To avoid contradictory links mention clustering results, propose use variant maximum spanning tree algorithm, second-order decoding algorithm instead traditional greedy search algorithm beam search algorithm . We factorize score tree sum arc-pair scores. A pair arcs link three different mentions, connected mentions viewed small cluster. Our global inference algorithm second-order features helps define powerful entity-level features clusters mentions aggregating scores small clusters. Traditional coreference resolution methods usually include three successive steps: mention detection, candidate pair generation, mention clustering . However, recent studies show joint solutions usually lead improved performance pipelined systems avoiding error propagation. We follow line research formulate coreference resolution joint manner. Our contributions summarized follows: graph neural networks introduced perform coreference resolution, aims better leverage entity-centric information encouraging sharing features across mentions refer entity; global inference algorithm second-order features presented optimally cluster mentions consistent groups; show GNN-based method combing second-order decoding algorithm achieved close state-of-the-art performance CoNLL-2012 coreference resolution benchmark."," One of the major challenges in coreference resolution is how to make use of entity-level features defined over clusters of mentions rather than mention pairs. However, coreferent mentions usually spread far apart in an entire text, which makes it extremely difficult to incorporate entity-level features. We propose a graph neural network-based coreference resolution method that can capture the entity-centric information by encouraging the sharing of features across all mentions that probably refer to the same real-world entity. Mentions are linked to each other via the edges modeling how likely two linked mentions point to the same entity.  Modeling by such graphs, the features between mentions can be shared by message passing operations in an entity-centric manner. A global inference algorithm up to second-order features is also presented to optimally cluster mentions into consistent groups. Experimental results show our graph neural network-based method combing with the second-order decoding algorithm  achieved close to state-of-the-art performance on the English CoNLL-2012 Shared Task dataset."
"Encoding linguistic units words, phrases sentences low-dimensional vectors core preliminary task deep learning natural language. The current language representation learning usually done different individual levels, typically, word sentence. The former includes pioneering works word2vec, GloVe fastText , latter includes recent so-called contextualized representations ELMo, GPT, BERT, XLNet ELECTRA . Nevertheless, works done uniformly learning representing linguistic units different hierarchies vector space. Actually, nearly existing work still focus individual granular language unit representation learning . However, universal representation among different levels linguistic units may offer great convenience needed handle free text language hierarchy unified way. As well known that, embedding representation certain linguistic unit enables linguistics-meaningful arithmetic calculation among different vectors, also known word analogy. For example, vector - vector + vector results vector . Thus universal representation may generalize good analogy features meaningful arithmetic operation onto free text language levels involved together. For example, Eat onion : Vegetable :: Eat pear : Fruit. In paper, explore regularities representations including words, phrases sentences vector space. To end, introduce universal analogy tasks derived Google's word analogy dataset. In addition, train Transformer-based model compare currently popular representation methods. Experimental results demonstrate well-trained Transformer-based models able map sequences variable lengths shared vector space similar sequences close other. Meanwhile, addition subtraction embeddings reflect semantic syntactic connections sequences. In addition, explore applicability characteristic retrieval-based chatbots evaluation insurance FAQ task, universal representation models significantly outperform TF-IDF BM25."," Despite the well-developed cut-edge representation learning for language, most language representation models usually focus on specific level of linguistic unit, which cause great inconvenience when being confronted with handling multiple layers of linguistic objects in a unified way. Thus this work introduces and explores the universal representation learning, i.e.,  embeddings of different levels of linguistic unit in a uniform vector space through a task-independent evaluation. We present our approach of constructing analogy datasets in terms of words, phrases and sentences and experiment with multiple representation models to examine geometric properties of the learned vector space. Then we empirically verify that well pre-trained Transformer models incorporated with appropriate training settings may effectively yield universal representation. Especially, our implementation of fine-tuning ALBERT on NLI and PPDB datasets achieves the highest accuracy on analogy tasks in different language levels. Further experiments on the insurance FAQ task show effectiveness of universal representation models in real-world applications."
"The ability learn tasks continuously lifetime limited supervision hallmark human intelligence. This enabled efficient transfer knowledge past experience. On contrary, current deep learning methods subjected learning new tasks sequential manner, suffer catastrophic forgetting , previous information lost due shift data distribution. Non-stationarity inevitable real world data continuously evolving. Thus, need design robust machine learning mechanisms deal catastrophic interference. Lifelong learning, also known continual learning , aims developing models continuously learn stream tasks sequence without forgetting existing knowledge rather building information acquired previously learned tasks order learn new tasks . One conceptualization accelerate learning positive transfer tasks minimizing interference respect network updates . Many approaches continual learning employ manually-designed techniques regularization gradient alignment mitigate catastrophic forgetting, shown effective computer vision reinforcement learning tasks. A recent trend continual learning, well machine learning general, directly learn generalizable solutions via meta-learning . Meta-learning aims learn new tasks quickly using limited number examples training many related tasks. In continual learning, meta-learning applied objective learning new tasks continually relatively small number examples per task traditional continual learning setup interleaving several past examples memory component, i.e. experience replay . While high rate experience replay usually mitigates catastrophic forgetting, comes closer multi-task learning lifelong learning setup computationally expensive learning data stream real-life applications. In natural language processing , continual learning still remains relatively unexplored . Despite success large pre-trained language models BERT , still require considerable amounts in-domain examples training new tasks prone catastrophic forgetting . Existing continual learning approaches language processing tasks include purely replay-based methods , meta-learning based method well generative replay-based method . However, approaches suffer several important limitations: require task identifiers, high rate replay multiple epochs training, deviates realistic lifelong learning scenario; tend expensive inference step . In paper, propose novel approach lifelong learning language processing tasks using meta-learning experience replay sparse time size. We consider realistic setting one pass training set possible task identifiers available. We extend two algorithms, namely online meta-learning neuromodulatory meta-learning algorithm domain NLP augment episodic memory module experience replay. While original objective continually learn new sequence tasks testing time, enhance conventional continual learning setup evaluation previously seen tasks, thus directly addressing problem catastrophic forgetting. Furthermore, realizing experience replay query set, directly optimize prevent forgetting. We show combining strong language model BERT along meta-learning sparse replay produces state-of-the-art performance lifelong text classification relation extraction benchmarks compared current methods realistic setting. To best knowledge, first meta-learning approach lifelong learning language tasks incorporates sparse replay. Through experiments, demonstrate approach considerably efficient previous work terms computational complexity well memory usage. To facilitate research field, make code publicly available."," Lifelong learning requires models that can continuously learn from sequential streams of data without suffering catastrophic forgetting due to shifts in data distributions. Deep learning models have thrived in the non-sequential learning paradigm; however, when used to learn a sequence of tasks, they fail to retain past knowledge and learn incrementally. We propose a novel approach to lifelong learning of language tasks based on meta-learning with sparse experience replay that directly optimizes to prevent forgetting. We show that under the realistic setting of performing a single pass on a stream of tasks and without any task identifiers, our method obtains state-of-the-art results on lifelong text classification and relation extraction. We analyze the effectiveness of our approach and further demonstrate its low computational and space complexity."
"Humans possess ability encode express wide range intricate verbal non-verbal cues based goal context. This evolved complementary ability detect nuanced cues everyday communication. This ability result top-down processing based context learning humans able encode decode person person information flow efficiently. Context typically set communicated multi-modal cues. Inspired this, several studies shown multi-modal input systems improve accuracy tasks involving human communication, speech recognition , emotion recognition speaker recognition . Recently, use generalized feature representations become prevalent computer vision natural language research. Computer vision tasks like object detection semantic segmentation show improved accuracy features images extracted using models trained large amounts data like ImageNet . In natural learning literature, generalized embeddings like GloVe word2vec demonstrated state art performance several tasks like word similarity, word analogy named entity recognition. For speech applications like automatic speech recognition , speaker recognition paralinguistics still traditional use hand-crafted features like MFCCs, LFBEs features toolkits like openSMILE . However, also demonstrated features learned directly audio improve performance amount training data large enough . The research various domains demonstrated transfer learning models trained large datasets improve accuracy subsequent tasks. This especially important size labeled datasets large. There variety multi-modal tasks like emotion recognition still large amounts publicly available datasets. Motivated this, propose model learn embeddings combine features audio, video, text modalities improve performance downstream tasks. The main contribution paper understand leverage large datasets build representations outperform models built specific tasks datasets limited. For work, use emotion recognition downstream task evaluate embeddings. In practical applications, possible modalities available machine learning system inference. For example, applications use video web-based applications, disturbance communication network lead missing audio visual input. This leads second objective study; perform ablation studies understand impact missing modality, understand compensate it. This paper organized follows; Section , discuss prior work multi-modal tasks embedding generation techniques. Our proposed technique embedding extraction presented Section . In discuss training setup data. Finally, present results Section conclude Section .","     General embeddings like word2vec, GloVe and ELMo have shown a lot of success in natural language tasks. The embeddings are typically extracted from models that are built on general tasks such as skip-gram models and natural language generation. In this paper, we extend the work from natural language understanding to multi-modal architectures that use audio, visual and textual information for machine learning tasks. The embeddings in our network are extracted using the encoder of a  transformer model trained using multi-task training. We use person identification and automatic speech recognition as the tasks in our embedding generation framework. We tune and evaluate the embeddings on the downstream task of emotion recognition and demonstrate that on the CMU-MOSEI dataset, the embeddings can be used to improve over previous state of the art results."
"%\hl{Where motivation? Why need graph solve dialogueRE?} %1: briefly mention document-level RE tell task paper focuses on. Relation extraction task aims recognize relations two entities present document. It plays pivotal role understanding unstructured text constructing knowledge bases. Although task document-level relation extraction studied extensively past, task relation extraction dialogues yet receive extensive study. %As intelligent dialogue systems attract attention, become interesting topic research relation extraction dialogue background. %\hl{In particular, dialogue relation extraction great research potential helping develop intelligent conversational agents.} %2: Compare dialogue RE previous document-level RE, present example show task looks like. Conversational text exhibits intra- inter-utterance relations, makes different text % focus previous document-level relation extraction. Most previous works focus professional formal % written literature like biomedical documents Wikipedia articles. These kinds datasets well-formatted logically coherent clear referential semantics. Hence NLP tasks analyzing continuous sentences enough grasp pivotal information. % \hl{Okay. contains terminologies; what?} However, dialogue relation extraction, conversational text sampled daily chat, casual nature. Hence logic simpler entangled referential ambiguity always occurs external reader. Compared formal literature, lower information density difficult model understand. Moreover, compared document-level RE dataset DocRED, dialogue text much cross-sentence relations. % ~\hl{I aware term personal pronoun. What it?} \cref{fig1} presents example dialogue relation extraction, taken DialogRE dataset. In order infer relation Speaker1 Emma, may need find triggers recognize characteristics Emma. Triggers evidences support inference. As see, following utterances talking Emma, key word baby daughter mentioned Speaker1 trigger, provides evidence Emma Speaker1's daughter. %As see, large gap argument pair Emma Baby Got Back. To infer relation them, first locate triggers. In case, personal pronoun `her' previous utterance trigger. After analyzing utterances two arguments, know person Speaker1 Speaker2 talking Emma. So know `her' refers Emma. Next, get fact Emma laughing hears `Baby Got Back', giving us evidence infer relation alternate names. %3: Previous approaches document-level RE Prior works show triggers arguments facilitate document-level relation inference. Thus, DocRED dataset provides several supporting evidences argument pair. Some efforts utilize dependency paths arguments find possible triggers. For example, LSR model constructs meta dependency paths argument pair aggregates word representations located paths model, order enhance model's reasoning ability. \citet{sahu2019inter} uses syntactic parsing coreference resolution find intra- inter-related words argument. \citet{christopoulou2019connecting} proposes edge-oriented graph synthesize argument-related information. These models graph-based proven powerful encoding long-distance information. However, dialogue relation extraction, interlocutors exist every utterance dialogue, often considered argument. Although previous approaches utilized entity features arguments, employ meta dependency paths find related words, results missing necessary information related speakers, since speaker references little dependency features utterance. We think structure graph allows model intra- inter-speaker relations paths involve conversational discourse word-level semantics. This phenomenon enables model outshine state-of-the-art frameworks int task dialogue level relation extraction. %Moreover, although \citet{nan2020reasoning} construct nodes containing arguments, way choose average mention representations argument sentence een encoded context encoder. This lose global information argument conversation. %4: Introduce contribution In work, propose simple yet effective attention-based heterogeneous graph neural network tackle dialogue relation extraction task using multi-type features create graph employing graph attention mechanism propagate contextual information. Different previous works, proposed model customized relation extraction task dialogue background, specially modeled speaker information designed mechanism propagate massages among different sentences better inter-sentence representation learning. %In case, question solved.... %\hl{List novelties} %5: Structure paper The remainder paper organized follows: \cref{method} elaborates proposed framework; \cref{experiment} introduces used dataset baseline models; \cref{result} lays experiment results analysis; ~\cref{related-work} briefly discusses relevant works heterogeneous graph neural networks; \cref{conclusion} concludes paper. %","  Dialogue relation extraction  aims to detect the relation between two entities mentioned in a multi-party dialogue. It plays an important role in constructing knowledge graphs from conversational data increasingly abundant on the internet and facilitating intelligent dialogue system development. % Previous document-level relation extraction tasks mainly focus on professional text like biomedical documents and Wikipedia articles. However, dialogue relation extraction is different, as conversational text is mainly based on spoken language. So it contains a lower information density and more inter-sentence interactions. Additionally, interlocutors are also considered as argument entities although their names may not exist in the utterances. The prior methods of DRE do not meaningfully leverage speaker information---they just prepend the utterances with the respective speaker names. Thus, they fail to model the crucial inter-speaker relations that may give additional context to relevant argument entities through pronouns and triggers. We, however, present a graph attention network-based method for DRE where a graph, that contains meaningfully connected speaker, entity, entity-type, and utterance nodes, is constructed. This graph is fed to a graph attention network for context propagation among relevant nodes, which effectively captures the dialogue context. % Further, the utterance representations are derived by passing their syntactic parse trees, that explicitly capture key syntactic relations between different entities within an utterance, through a graph convolutional network . We empirically show that this graph-based approach quite effectively captures the relations between different entity pairs in a dialogue as it outperforms the state-of-the-art approaches by a significant margin on the benchmark dataset DialogRE. Our code is released at: \url{https://github.com/declare-lab/dialog-HGAT} %\hl{write: graph attention network helps to grasp/model dialogue context}   % a syntactically-aware heterogeneous graph attention network to tackle this problem, where we utilize syntactic dependency graph to extract features of utterances, specially construct speaker nodes and entity semantic nodes, and aggregate utterance information and entity type information to argument entities. Our framework outperforms the state-of-the-art approaches by a significant margin on the benchmark dataset DialogRE."
"Humans exhibit resilience orthographic variation written text . As result, spelling mistakes typos often left unnoticed. This flexibility ours, however, shown detrimental neural machine translation systems, typically trained curated corpora tend break faced noisy data . Achieving NMT robustness human blunder, however, important translating texts less formal origins, chat conversations, social media posts web pages comment sections. In work, propose, augment NMT system's training data data source sentences corrupted adversarial examples different types. There various studies impact different types sources noise NMT . In work, focus noise caused orthographic variation words, unintentional misspellings deliberate spelling alternations well noise due misplaced omitted punctuation. Thus, closest study work black-box adversarial training NMT systems , models trained adversarial examples generated without accessing model's parameters. Unlike previous work, focuses adversarial examples model unintentional changes spelling, also model deliberate orthographic alternation, omission substitution diacritical signs. As show experiments, orthographic variation substantial negative impact MT outputs types noise thus important accounted for. Further, overcome lack curated evaluation datasets required previous work , propose automatic evaluation method measures noise invariance MT outputs without relying reference translation. By measuring noise invariance MT outputs method also allows us assess whether MT system translation consistency improves facing small variations source text. \end{table}"," Neural machine translation systems typically are trained on curated corpora and break when faced with non-standard orthography or punctuation. Resilience to spelling mistakes and typos, however, is crucial as machine translation systems are used to translate texts of informal origins, such as chat conversations, social media posts and web pages. We propose a simple generative noise model to generate adversarial examples of ten different types. We use these to augment machine translation systems' training data and show that, when tested on noisy data, systems trained using adversarial examples perform almost as well as when translating clean data, while baseline systems' performance drops by 2-3 BLEU points. To measure the robustness and noise invariance of machine translation systems' outputs, we use the average translation edit rate between the translation of the original sentence and its noised variants. Using this measure, we show that systems trained on adversarial examples on average yield 50\% consistency improvements when compared to baselines trained on clean data."
"%============================================================================ Natural language understanding often requires ability comprehend reason expressions involving numbers. This produced recent rise interest build applications automatically solve math word problems~. These math problems consist textual description comprising numbers question guide reasoning process get numerical solution . This complex task The research community focused solving mainly two types mathematical word problems: arithmetic word problems algebraic word problems . Arithmetic word problems solved using basic mathematical operations involve single unknown variable. Algebraic word problems, hand, involve complex operators square root, exponential logarithm multiple unknown variables. In work, focus solving arithmetic word problems one illustrated \figref{fig:example}. This figure illustrates . The main idea paper explore use tree-based Recursive Neural Networks encode score expression tree . This contrasts predominantly sequential neural representations encode problem statement left right vice versa. By using Tree-RNN architectures, naturally embed equation inside tree structure link structure directly reflects various mathematical operations operands selected sequential textual input. We hypothesize structured approach efficiently capture semantic representations candidate equations solve complex arithmetic problems involving multiple and/or non-commutative operators. To test results, use recently introduced SingleEQ dataset . It contains collection 508 arithmetic word problems varying degrees complexity. This allows us track performance evaluated systems subsets require different reasoning capabilities. More concretely, subdivide initial dataset different subsets varying reasoning complexity non-commutative operations), investigate whether performance proposed architecture remains consistent across problems increasing complexity. \Figref{fig:conceptualview} provides high-level conceptual view interconnection main components proposed system. The processing flow consists two main steps. In first step, use candidate generator generate list potential candidate equations solving particular arithmetic word problem. To achieve this, employ Integer Linear Programming constraint optimization component proposed \mbox{} . In second step, candidate equations ranked candidate ranker, equation highest score chosen solution processed arithmetic word problem . In paper, focus second step exploring impact structural Tree-RNN-based sequential Long Short Term Memory-based candidate equation encoding methods. More specifically, define two Tree-RNN models inspired work \TreeLSTM{} models: . In rest manuscript refer general tree-structured architecture models \TreeLSTM{}. The main difference two that, \TLSTM{} child node representations summed up, \NTLSTM{} concatenated. Unlike representation used , input given word embeddings, Tree-LSTM models also take input operation embeddings represent arithmetic operators . This allows architecture distinguish different operators contained particular expression tree. We show \NTLSTM{} suitable deal equations involve non-commutative operators architecture able capture order operands. We also compare \TreeLSTM{} models sequential LSTM model call \BLSTM{}. All models take input contextualized representation numbers text produced bidirectional \LSTM{} layer . After conducting thorough multi-fold experimentation phase involving multiple random weight re-initializations order ensure validity results, show main added value \TreeLSTM{}-based models compared state-of-the-art methods lays increased performance complex arithmetic word problems. More concretely, contribution three-fold: %----------------------------------------------------------------------------","   Solving arithmetic word problems is a cornerstone task in assessing language understanding and reasoning capabilities in NLP systems. Recent works    use automatic extraction and ranking of candidate solution equations providing the answer to arithmetic word problems. In this work, we explore novel approaches to score such candidate solution equations using tree-structured   recursive neural network  configurations.    The advantage of this Tree-RNN approach over using more established sequential representations, is that it can naturally capture the structure of the equations. Our proposed method consists of transforming the mathematical expression of the equation into an expression tree. Further, we encode this tree into a Tree-RNN by using different \TreeLSTM{} architectures.      Experimental results show that our proposed method     \begin{enumerate*}[]     \item  improves overall performance with more than 3\% accuracy points compared to previous state-of-the-art, and with over 15\% points on a subset of problems that require more complex reasoning, and \item outperforms sequential LSTMs by 4\% accuracy points on such more complex problems.  \end{enumerate*}"
"Semantic role labeling , namely semantic parsing, shallow semantic parsing task aims recognize predicate-argument structure predicate sentence, whom, when, etc. Specifically, SRL seeks identify arguments label semantic roles given predicate. SRL important method obtaining semantic information beneficial wide range natural language processing tasks, including machine translation, question answering, discourse relation sense classification relation extraction. SRL split four subtasks: predicate detection, predicate disambiguation, argument identification, argument classification. For argument annotation, two formulizations . One based constituents , based dependencies. The other, proposed CoNLL-2008 shared task, also called semantic dependency parsing annotates heads arguments rather phrasal arguments. Figure shows example annotations. In prior SRL work, considerable attention paid feature engineering, struggles capture sufficient discriminative information compared neural network models, capable extracting features automatically. In particular, syntactic information, including syntactic tree features, known extremely beneficial SRL since large scale empirical verification of~\citet{punyakanok-etal-2008-importance}. Despite success, work suffered erroneous syntactic input, leading unsatisfactory performance. To alleviate issues, \citet{marcheggiani-etal-2017-simple,he-etal-2017-deep} proposed simple effective neural model SRL without syntactic input. Their work suggested neural SRL rely syntactic features, contradicting belief syntax necessary prerequisite SRL, believed early as~\citet{gildea-palmer-2002-necessity}. This dramatic contradiction motivated us make thorough exploration syntactic contribution SRL. Both span dependency effective formal representations semantics, though unknown form, span dependency, would better convenience effectiveness semantic machine learning later applications long time. This topic roughly discussed , concluded dependency SRL system clearly outperformed span-based system gold syntactic structure transformation; however, due different requirements downstream task applications, span dependency remain focuses research. Additionally, two forms SRL may benefit joint rather separated development. We, therefore, revisit syntax roles solid empirical basis explore syntax roles two styles syntax information equal quality, respectively. Recent works syntax contributions limited individual models ways syntax utilized. The conclusions drawn syntax roles therefore limitations. In order reduce limitations, explored three typical strong baseline models two categories syntactic utilization methods. In addition, pre-trained language models, ELMo BERT , build contextualized representations, continue provide gains NLP benchmarks, \citet{hewitt-manning-2019-structural} showed structure syntax information emerges deep models' word representation spaces. Whether neural SRL models benefit explicit syntax information addition implicit syntax information, however, another issue consider. %This paper focus semantic dependency parsing formulate SRL one two sequence tagging tasks predicate-specific encoding. With help proposed -order argument pruning algorithm syntactic tree, model obtains state-of-the-art scores CoNLL benchmarks English Chinese. Besides, SRL literature dedicated impressive performance gains English, multiple languages receive relatively little attention. Although human languages basic commonalities syntactic structure even different levels grammar, differences also obvious. The study syntactic roles needs examined context multiple languages verifying effectiveness applicability. In order quantitatively evaluate contribution syntax SRL, adopt ratios labeled F score semantic dependencies labeled attachment score syntactic dependencies, F score syntactic constituents. This ration first introduced CoNLL-2008 Shared Task evaluation metric. Considering various syntactic parsers contribute different syntactic inputs varying levels quality, ratio provides fairer comparison syntactically-driven SRL systems, empirical study surveys."," Semantic role labeling  is dedicated to recognizing the semantic predicate-argument structure of a sentence.  Previous studies in terms of traditional models have shown syntactic information can make remarkable contributions to SRL performance; however, the necessity of syntactic information was challenged by a few recent neural SRL studies that demonstrate impressive performance without syntactic backbones and suggest that syntax information becomes much less important for neural semantic role labeling, especially when paired with recent deep neural network and large-scale pre-trained language models. Despite this notion, the neural SRL field still lacks a systematic and full investigation on the relevance of syntactic information in SRL, for both dependency and both monolingual and multilingual settings.  This paper intends to quantify the importance of syntactic information for neural SRL in the deep learning framework. We introduce three typical SRL frameworks , sequence-based, tree-based, and graph-based, which are accompanied by two categories of exploiting syntactic information: syntax pruning-based and syntax feature-based. Experiments are conducted on the CoNLL-2005, 2009, and 2012 benchmarks for all languages available, and results show that neural SRL models can still benefit from syntactic information under certain conditions. Furthermore, we show the quantitative significance of syntax to neural SRL models together with a thorough empirical survey using existing models."
"Building dialogue system converse people naturally meaningfully one challenging problems towards high-level artificial intelligence, drawing increasing interests academia industry area. Most existing dialogue systems either generation-based retrieval-based. Given dialogue context, generation-based approaches synthesize response word word conditional language model, retrieval-based methods select proper response candidate pool. In paper, focus retrieval-based approaches superior providing informative responses widely applied several famous commercial products XiaoIce Microsoft AliMe Assist Alibaba. We consider response selection task multi-turn dialogues, retrieval model ought select proper response measuring matching degree multi-turn dialogue context number response candidates. Earlier studies concatenate context single utterance calculate matching score utterance-level representations. Later, response selection models perform context-response matching within representation-matching-aggregation paradigm, turn utterance represented individually sequential information aggregated among sequence utterance-response matching features. To improve performance response selection, recent approaches consider multiple granularities representations matching propose complicated interaction mechanisms context response. Recently, wide range studies shown pre-trained language models , BERT, XLNET RoBERTa, large corpus learn universal language representations, helpful various downstream natural language processing tasks get rid training new model scratch. To adapt pre-trained models multi-turn response selection, \citet{whang2020domain} \citet{gu2020speaker} make first attempt utilize BERT learn matching model, context candidate response first concatenated fed PLMs calculating final matching score. These pre-trained language models well capture interaction information among inter-utterance intra-utterance multiple transformer layers. Although PLM-based response selection models demonstrate superior performance due strong representation ability, still challenging effectively learn task-related knowledge training process, especially size training corpora limited. Naturally, studies typically learn response selection model context-response matching task %learn matching model single response prediction task, overlook many potential training signals contained dialogue data. %come rich characteristics dialogue text. Such training signals might beneficial context understanding produce better features response prediction. Besides, response retrieved existing dialogue systems supervised conventional way still faces critical challenges, including incoherence inconsistency. On account issues, paper, instead configuring complex context-response matching models, propose learning context-response matching model auxiliary self-supervised tasks designed dialogue data based pre-trained language models . Specifically, introduce four self-supervised tasks including next session prediction, utterance restoration, incoherence detection consistency discrimination, jointly train PLM-based response selection model auxiliary tasks multi-task manner. On one hand, auxiliary tasks help improve capability response selection model understand dialogue context measure semantic relevance, consistency coherent context response candidates. On hand, guide matching model effectively learn task-related knowledge fixed amount train corpora produce better features response prediction. We conduct experiments two benchmark data sets multi-turn response selection: Ubuntu Dialog Corpus E-commerce Dialogue Corpus. Evaluation results show proposed approach significantly better state-of-the-art models datasets. Compared previous state-of-the-art methods, model achieves 2.9\% absolute improvement terms Ubuntu dataset 4.8\% absolute improvement E-commerce dataset. Furthermore, applied proposed self-supervised learning schema non-PLM-based response selection models, e.g., dual LSTM ESIM. Experimental results indicate learning schema also bring consistent significant improvement performance existing matching models. Surprisingly, self-supervised learning, simple ESIM even performs better BERT ubuntu dataset, demonstrating approach beneficial various matching architectures. % We publish source code later. In summary, contributions three-fold:"," Building an intelligent dialogue system with the ability to select a proper response according to a multi-turn context is a great challenging task. Existing studies focus on building a context-response matching model with various neural architectures or PLMs and typically learning with a single response prediction task. These approaches overlook many potential training signals contained in dialogue data, which might be beneficial for context understanding and produce better features for response prediction.  Besides, the response retrieved from existing dialogue systems supervised by the conventional way still faces some critical challenges, including incoherence and inconsistency. To address these issues, in this paper, we propose learning a context-response matching model with auxiliary self-supervised tasks designed for the dialogue data based on pre-trained language models. Specifically, we introduce four self-supervised tasks including next session prediction, utterance restoration, incoherence detection and consistency discrimination, and jointly train the PLM-based response selection model with these auxiliary tasks in a multi-task manner.   By this means, the auxiliary tasks can guide the learning of the matching model to achieve a better local optimum and select a more proper response. Experiment results on two benchmarks indicate that the proposed auxiliary self-supervised tasks bring significant improvement for multi-turn response selection in retrieval-based dialogues, and our model achieves new state-of-the-art results on both datasets."
"Named Entity Recognition process identification named entities natural language text. The present paper concentrates three low resource languages : Bhojpuri, Maithili Magahi , belong Indo-Aryan language family. This work may seen first attempt develop NER tool Bhojpuri, Maithili Magahi. There previous work NER languages far know. The main aim present paper start insights NER systems developed Indian Languages resources based try develop NER System BMM. The NER module important component Natural Language Processing Information Extraction systems. It essential task computational purposes like Machine Translation , developing search engines, automatic indexing, document classification text summarization, questiona answering etc., possible build end-to-end Deep Learning systems languages due lack data. It also helpful many cross-linguistic applications relevant Indian Languages, particularly LRLs. The present study mainly focuses Named Entities BMM machine translation goal. \subsection{Named Entity Recognition} The concept Named Entity introduced Sixth Message Understanding Conference . It often seen part Information Extraction system, refers automatic extraction structured information entities, relationships entities attributes describing entities unstructured sources. The role NER system locate classify words text predefined categories names persons, organizations, locations, expressions times, quantities etc. The NEs could identified two conventional ways, recent success machine learning Deep Learning based techniques: It challenging task implement NER Indian languages due absence capitalization writing systems. On hand, systems phonetically organized designed, makes easily possible use phonetic features NER Indian languages. Preparing gazetteer閳ユ獨 list nouns impossible vast number unknown named entities world terms corpus versus language. Here, one important point noted much work reported NER Low Resource languages due insufficient lexical resources also due morphological richness. There efforts major Indian languages, i.e., Hindi, Tamil, Telugu, Urdu, Punjabi, efforts Low Resource Indian languages BMM. \subsection{Bhojpuri, Maithili, Magahi : An Introduction} Bhojpuri often considered major `sub-language' Hindi. It language spoken various states India countries well, viz. Nepal, Mauritius, Fiji, Surinam etc. The writing system Bhojpuri earlier Kaithi script Devanagari script used write Bhojpuri. According 2011 census~, 5,05,79,447 Bhojpuri speakers. Maithili belongs Indo-Aryan language family, Bhojpuri Magahi considered `sub-languages' Hindi mainly spoken Eastern Uttar Pradesh, Bihar Jharkhand states India. Maithili included 22 `scheduled' languages Republic India . Maithili added Constitution India 2003 92nd Constitutional Amendment Act. Maithili, sister language Hindi, spoken India, particularly Bihar, Jharkhand, Uttar Pradesh etc. well Nepal. It language Bihari sub-family included eighth schedule Indian constitution. There 1,35,83,464 Maithili speakers . It also one 122 recognised languages Nepal. In 2007, Maithili included interim Constitution Nepal March 2018, received second official language status Jharkhand state India. It earlier considered sub-language dialect. Magahi Magadhi, also considered major sub-language Hindi, chiefly spoken districts Bihar, Jharkhand, also Maldah district West Bengal. Magahi also written Kaithi script earlier days, present usually written Devanagari script. There 1,27,06,825 Magahi speakers . Earlier work machine translation reported proper handling named tokens improve translation quality performance. These named tokens would translated source target translation without NER module, NER module instead simply transliterated. The current BMM machine translation systems plan use NER module, based transfer-based approach machine translation. Even though MT systems based transfer approach, NER module based machine learning Deep Learning, rule-based approach. Due this, annotated corpus developed NER system three languages reported lower higher baseline results. The former based CRF latter combination Long Short Term Memory , Convolutional Neural Networ Conditional Randon Fields , called LSTM-CNNs-CRF. \subsection{Contributions} As prior work NER problem Bhojpuri, Maithili Magahi, contributions paper follows:"," 			In Natural Language Processing  pipelines, Named Entity Recognition  is one of the preliminary problems, which marks proper nouns and other named entities such as Location, Person, Organization, Disease etc. Such entities, without a NER module, adversely affect the performance of a machine translation system. NER helps in overcoming this problem by recognising and handling such entities separately, although it can be useful in Information Extraction systems also. Bhojpuri, Maithili and Magahi are low resource languages, usually known as Purvanchal languages. This paper focuses on the development of a NER benchmark dataset for the Machine Translation systems developed to translate from these languages to Hindi by annotating parts of their available corpora. Bhojpuri, Maithili and Magahi corpora of sizes 228373, 157468 and 56190 tokens, respectively, were annotated using 22 entity labels. The annotation considers coarse-grained annotation labels followed by the tagset used in one of the Hindi NER datasets. We also report a Deep Learning based baseline that uses an LSTM-CNNs-CRF model. The lower baseline F$_1$-scores from the NER tool obtained by using Conditional Random Fields models are 96.73 for Bhojpuri, 93.33 for Maithili and 95.04 for Magahi. The Deep Learning-based technique  achieved 96.25 for Bhojpuri, 93.33 for Maithili and 95.44 for Magahi."
"As fundamental task speech language processing, Automatic Speech Recognition aims generate transcripts human speech. Recently, successful application deep neural networks pushed accuracy end-to-end ASR models new level, brings significant challenges building large-scale, robust ASR systems, especially industrial applications. Major bottlenecks twofold: i) abundant labeled training data learning large, accurate ASR models; ii) efficient distributed, computing framework model training serving scale. In demo, present EasyASR, distributed machine learning platform address challenges. EasyASR built upon Machine Learning Platform AI Alibaba Cloud~\footnote{https://www.alibabacloud.com/product/machine-learning/}, provides ultra-scale, deep learning framework distributed GPU clusters. Our platform supports complete process training, evaluating serving ASR models. Additionally, integrated functionalities i) extract high-quality audio aligned transcripts massive video data ii) expand existing ASR training sets various augmentation policies. We designed easy-to-use PAI components enable users build run ASR models within lines command, hides complicated techniques starters. We also provide add-on configurations PAI commands allow advanced users customize network architectures models. On EasyASR, achieve state-of-the-art performance Mandarin speech recognition multiple public datasets. %In following, describe EasyASR detail. %"," We present EasyASR, a distributed machine learning platform for training and serving large-scale Automatic Speech Recognition  models, as well as collecting and processing audio data at scale. Our platform is built upon the Machine Learning Platform for AI of Alibaba Cloud. Its main functionality is to support efficient learning and inference for end-to-end ASR models on distributed GPU clusters. It allows users to learn ASR models with either pre-defined or user-customized network architectures via simple user interface. On EasyASR, we have produced state-of-the-art results over several public datasets for Mandarin speech recognition."
"Pretraining ever-larger language models massive plain text corpora led significant improvements wide range NLP tasks \cite[inter alia]{radford2018improving,devlin2018bert,liu2019roberta,raffel2019exploring}. A standard approach replace pretrained model's output layer task-specific head finetune entire model set labeled training data. However, language modeling powerful pretraining objective, many tasks reformulated cloze questions , allowing pretrained LMs solve without labeled examples . Very recently, \citet{brown2020language} introduced \gpt{}, pretrained LM enormous 175 billion parameters, showed amazing few-shot abilities: By reformulating tasks language modeling problems, \gpt{} achieves near state-of-the-art results tasks SuperGLUE benchmark given 32 labeled examples. This achieved priming: \gpt{} given demonstrations inputs corresponding outputs context predictions, gradient updates performed. While straightforward use, method two major drawbacks: An alternative priming pattern-exploiting training , combines idea reformulating tasks cloze questions regular gradient-based finetuning. While \pet{} additionally requires unlabeled data, unlabeled data much easier obtain labeled examples many real-world applications. Crucially, \pet{} works answers predicted LM correspond single token vocabulary; severe limitation many tasks cannot easily worded way. In work, modify \pet{} also work tasks require predicting one token. We show combination ALBERT , \pet{} iterative variant outperform \gpt{} SuperGLUE 32 training examples, requiring 0.1\% parameters . Finally, show similar performance also achieved without unlabeled data provide detailed analysis factors contributing \pet{}'s strong performance: ability combine multiple task formulations, resilience wordings hard understand, usage labeled data, characteristics underlying LM."," When scaled to hundreds of billions of parameters, pretrained language models such as \gpt{} \citep{brown2020language} achieve remarkable few-shot performance on challenging natural language understanding benchmarks. In this work, we show that performance similar to \gpt{} can be obtained with language models whose parameter count is several orders of magnitude smaller. This is achieved by converting textual inputs into cloze questions that contain some form of task description, combined with gradient-based optimization; additionally exploiting unlabeled data gives further improvements. Based on our findings, we identify several key factors required for successful natural language understanding with small language models.\footnote{Our implementation is publicly available at \url{https://github.com/timoschick/pet}.}"
"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Most neural machine translation systems autoregressive, hence decoding latency grows linearly respect length target sentence. For faster generation, several work proposed non-autoregressive models sub-linear decoding latency given sufficient parallel computation~. As challenging precisely model dependencies among tokens without autoregression, many existing non-autoregressive models first generate initial translation iteratively refined yield better output~. While various training objectives used admit refinement , generation process models similar refinement process happens discrete space sentences. Meanwhile, another line work proposed use continuous latent variables non-autoregressive translation, distribution target sentences factorized time given latent variables~. Unlike models discussed above, finding likely target sentence models requires searching continuous latent variables. To end, \citet{shu20latent} proposed EM-like inference procedure optimizes hybrid space consisting continuous discrete variables. By introducing deterministic delta posterior, maximizes proxy lowerbound alternating matching delta posterior original approximate posterior , finding target sentence maximizes proxy lowerbound . In work, propose iterative inference procedure latent variable non-autoregressive models purely operates continuous space.} Given latent variable model, train inference network estimate gradient marginal log probability target sentence, using latent variable input. At inference time, find target sentence approximately maximizes log probability initializing latent variable e.g. mean prior, following gradients estimated inference network. We compare proposed approach EM-like inference~ three machine translation datasets: {\wmtende}, {\wmtroen} {\iwsltdeen}. The advantages approach twofold: %We observe two advantages approach: refinement step twice fast, avoids discrete search large vocabulary, effective, giving higher marginal probabilities BLEU scores number refinement steps. Our procedure results significantly faster inference, instance giving speedup autoregressive baseline {\wmtende} expense BLEU score. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"," We propose an efficient inference procedure for non-autoregressive machine translation that iteratively refines translation purely in the continuous space. Given a continuous latent variable model for machine translation, we train an inference network to approximate the gradient of the marginal log probability of the target sentence, using only the latent variable as input. This allows us to use gradient-based optimization to find the target sentence at inference time that approximately maximizes its marginal probability. As each refinement step only involves computation in the latent space of low dimensionality , we avoid computational overhead incurred by existing non-autoregressive inference procedures that often refine in token space. We compare our approach to a recently proposed EM-like inference procedure that optimizes in a hybrid space, consisting of both discrete and continuous variables. We evaluate our approach on {\wmtende}, {\wmtroen} and {\iwsltdeen}, and observe two advantages over the EM-like inference:  it is computationally efficient, i.e. each refinement step is twice as fast, and  it is more effective, resulting in higher marginal probabilities and BLEU scores with the same number of refinement steps. On {\wmtende}, for instance, our approach is able to decode $6.2$ times faster than the autoregressive model with minimal degradation to translation quality ."
"Deep learning methods revolutionized NLP field past ten years. Although LSTM networks around two decades, NLP community learned train use effectively past ten years. \citet{DBLP:journals/corr/ChoMGBSB14} introduced new sequence-to-sequence method, boosting field neural machine translation significantly . The year \citet{bahdanau2014neural} presented attention mechanism aimed focusing specific words within prefix, order make accurate prediction next word mapping one sequence another. During period new text representation methods adapted, complementing following representation methods: bag-of-words , tf-idf, one-hot vectors dense representations, prominent word2vec Glove embeddings, served go-to methods many works . \citet{devlin2018bert} introduced pre-trained transformer based attention mechanism without recurrent connections. BERT provided another advancement field pre-trained text representations, showing enhanced performance various NLP tasks . Many research directions shaped pre-trained word embeddings representations several software toolkits available training deep neural networks. While Keras toolkit widely used text classification padding, DyNet PyTorch toolkits excelled tasks dynamic computation graph recurrent networks exploited achieve better predictive performance sentences varying length . An important advancement dense representation area occurred introduction TensorFlow Hub 2018. According Google."," One of the challenges in  the NLP field is training  large  classification  models, a task that is both difficult and tedious. It is even harder when GPU hardware is unavailable. The increased availability of pre-trained and off-the-shelf word embeddings, models, and modules aim at easing the process of training large models and achieving a competitive performance.   We explore the use of off-the-shelf BERT models and share the results of our experiments and compare their results to those of LSTM networks and more simple baselines. We show that the complexity and computational cost of BERT is not a guarantee for enhanced predictive performance in the classification tasks at hand."
"Autoregressive models ubiquitous natural language processing. Due sequential nature text generation, often tool choice tackling sequence-to-sequence problems translation , summarization , dialogue . Furthermore, form backbone several successful generative pre-training architectures . Two recent trends made autoregressive models cumbersome deploy real-world, natural language generation applications. First, state-of-the-art models grown larger larger, amounting hundreds millions even billions parameters . The increase size depth dramatically slows inference speed. Second, architecture choice autoregressive models seems shifted recurrent neural network Transformer . Though Transformer's self-attention mechanism improves performance, also increases computational complexity step-by-step generation algorithms used test time. Thus, trends contributed significantly increasing inference time costs, especially CPUs low-resource devices, hindering use production systems. % The increasing memory inference time costs enormous models make cumbersome deploy real-world settings. Inference CPU already quite slow, much less smartphone device. Thus, exists need scale large autoregressive models practical purposes. Knowledge distillation one popular method model compression. It transfers information learned large, pretrained teacher smaller, untrained student. In comparison methods weight pruning quantization, KD allows compressed model's architecture significantly differ original teacher. This feature enables models trained KD achieve high performance meeting particular inference requirements . Sequence-level knowledge distillation , proposed \citet{kim2016sequence}, dominant technique autoregressive KD current NLG literature, especially machine translation . This method trains student model using modified dataset generated teacher model standard negative log-likelihood objective. While SeqKD simple efficient, argue take advantage teacher's full potential. %This method two-step procedure 1) generates full sequences using teacher model produce modified dataset 2) trains student model modified dataset standard negative log-likelihood training. While seqKD conceptually simple efficient implement, argue reducing teacher's impact static dataset take advantage full potential. % Autoregressive models often trained way different used inference time. During training, true sequence available, model learns predict one-step-ahead given ground-truth context. However, inference time, model must generate entire sequence scratch repeatedly using outputs context subsequent steps. This training-inference inconsistency leads exposure bias problem, may manifested decrease sequence quality number generation steps increases. The seqKD algorithm simply NLL training modified dataset, also experiences issue. Training student model static dataset leads exposure bias problem. During training, student model learns predict next token given previous tokens provided data. However, inference time, student generates entire sequence scratch repeatedly using outputs context subsequent steps. This training-inference inconsistency causes decrease generation quality. Alternatively, propose student leverage teacher dynamic fashion learning process. % Our main contributions following: We recast distillation autoregressive models imitation learning problem, drawing parallels SeqKD behavioral cloning. From perspective, design new compression algorithm aimed addressing exposure bias autoregressive models called imitation-based knowledge distillation . We conduct several experiments translation summarization, demonstrating ImitKD especially suitable compressing deep Transformers achieve high performance shallow RNNs generate much faster inference time. %The key insight ImitKD treat teacher model oracle corrects student閳ユ獨 generations every step. Thus, student explicitly learns generate training. Our method consistently outperforms popular distillation algorithms, SeqKD. It yields student models beat models trained without teacher 1.4 4.8 points Bleu Rouge metrics. We devise new compression algorithm autoregressive models called imitation-based knowledge distillation . It inspired imitation learning perspective autoregressive distillation problem. Our algorithm trains student model within IL framework treating teacher oracle, allows student explore generation training. The teacher corrects student's generation every time step, thereby guiding student learning generate. % Experimental results translation summarization show ImitKD especially suitable compressing deep Transformer models achieve high performance shallow RNNs generate 14 times faster inference time. Our method consistently outperforms distillation algorithms , yields student models beat models trained without teacher 1.4 4.8 points generation metrics BLEU ROUGE. %"," The performance of autoregressive models on natural language generation tasks has dramatically improved due to the adoption of deep, self-attentive architectures.  However, these gains have come at the cost of hindering inference speed, making state-of-the-art models cumbersome to deploy in real-world, time-sensitive settings.  We develop a compression technique for autoregressive models that is driven by an imitation learning perspective on knowledge distillation.  The algorithm is designed to address the exposure bias problem.     On prototypical language generation tasks such as translation and summarization, our method consistently outperforms other distillation algorithms, such as sequence-level knowledge distillation.  Student models trained with our method attain 1.4 to 4.8 BLEU/ROUGE points higher than those trained from scratch, while increasing inference speed by up to 14 times in comparison to the teacher model.\footnote{Our code can be found at \url{https://github.com/asappresearch/imitkd}.}"
"Extracting event temporal relations raw text data attracted surging attention NLP research community recent years fundamental task commonsense reasoning natural language understanding. It facilitates various downstream applications, forecasting social events tracking patients' medical history. Figure shows example task event extractor first needs identify events input relation classifier predicts pairwise relations among them, resulting temporal ordering illustrated figure. For example, \event{say} \temprel{before} \event{stop}; \event{buildup} \temprel{includes} \event{say}; temporal ordering \event{buildup} \event{stop} cannot decided context, relation \temprel{vague}.","  Extracting event temporal relations is a critical task for information extraction and plays an important role in natural language understanding. Prior systems leverage deep learning and pre-trained language models to improve the performance of the task. However, these systems often suffer from two shortcomings: 1) when performing maximum a posteriori  inference based on neural models, previous systems only used structured knowledge that is assumed to be absolutely correct, i.e., hard constraints; 2) biased predictions on dominant temporal relations when training with a limited amount of data. To address these issues, we propose a framework that enhances deep neural network with distributional constraints constructed by probabilistic domain knowledge. We solve the constrained inference problem via Lagrangian Relaxation and apply it to end-to-end event temporal relation extraction tasks. Experimental results show our framework is able to improve the baseline neural network models with strong statistical significance on two widely used datasets in news and clinical domains."
"Encoder-decoder architecture, uses encoder create representation source sequence decoder predict target sequence, established state art approaches neural machine translation . Recurrent neural network based model , convolutional neural network model self-attention network based model representative encoder-decoder models, NMT models variants combination three. NMT models based encoder-decoder architecture similar aspects, stack layers structure. Stack layers increases complexity model approximate nonlinear function. Viewing layers one function, every single layer captures different information input. Looking every single NMT model RNN-based model SAN-based model, models always try make representation one word containing information whole sentence every layer. However, empirically, one layer alone cannot result satisfactory result. It common regard sentence NMT model directed complete simple graph, views words nodes relationships words edges. However, perspective focuses relationship words, ignoring information, relationship phrases relationship different fragments sentences. As result, structure simple graph cannot fully reflect information. To overcome shortcomings simple graph, view sentence multigraph SAN-based model. In multigraph , multiple edges exist two nodes. Edge connects nodes also subgraphs reflects relationship different fragments sentences relationship word-pair. Encoding also regarded process generating multigraph approximate infinitely. Compared simple graph, multigraph explain th essence encoding comprehensively, explain relationship words general way. One layer NMT model capture incremental information automatically compared previous layer. Fusion previous incremental information makes representation rich thus benefits translation. From perspective multigraph, incremental information described set higher-order subgraphs generated layer. Even though current NMT models capture information subgraphs different orders, fusing representation fixed weight makes model difficulty pay attention really salient part. To solve problem, propose graph-based SAN empowered Graph-Transformer enhancing ability capturing subgraph information current NMT models. First all, generally define full representation fusing result concerned subgraph representations. Then let representation one layer split two parts, previous representation incremental representation. The previous representation reflects full representation previous layer, incremental representation reflects new information generated layer. Based this, encoding process modified adapt representation division. We split original self-attention three independent parts generate incremental representation. Our method accommodates subgraphs different orders different parts incremental representation, reduces information redundancy. To fuse full representation, We consider three fusing strategies terms different weighting schemes let model focus important parts representation. In experiments WMT14 English-to-German IWSLT14 German-to-English , results experiments prove model improve performance translation parameters increasing. Our model achieves performance outperforming Transformer improvement 1.1 BLEU points En-De 1.0 BLEU points De-En."," Neural machine translation  usually works in a seq2seq learning way by viewing either source or target sentence as a linear sequence of words, which can be regarded as a special case of graph, taking words in the sequence as nodes and relationships between words as edges. In the light of the current NMT models more or less capture graph information among the sequence in a latent way, we present a graph-to-sequence model facilitating explicit graph information capturing. In detail, we propose a graph-based SAN-based NMT model called Graph-Transformer by capturing information of subgraphs of different orders in every layers. Subgraphs are put into different groups according to their orders, and every group of subgraphs respectively reflect different levels of dependency between words. For fusing subgraph representations, we empirically explore three methods which weight different groups of subgraphs of different orders. Results of experiments on WMT14 English-German and IWSLT14 German-English show that our method can effectively boost the Transformer with an improvement of 1.1 BLEU points on WMT14 English-German dataset and 1.0 BLEU points on IWSLT14 German-English dataset."
"Open-domain human-machine dialogue systems, especially generation-based genre, attracted extensive attention recently. Typically, following neural encoder-decoder paradigm, contemporary dialogue generation models~, often not, trained Maximum Likelihood Estimation principle mimic human context-response pairs training corpus. While notable gains achieved learning framework, prior art~ suggests naive MLE objective used training neural dialogue generation models effective enough tends result issues like dull response generation. By optimizing likelihood training dialogues, neural models inclined assign high probabilities ``safe'' responses, due fact vacuous responses like ``I know'' relatively high frequencies conversational datasets~. One promising training framework neural dialogue generation adversarial learning~, discriminator provides rewards generator contrastively distinguishing dialogues human-generated machine-generated. However, learning ability GANs text drastically limited due training instability model collapse~. First, discriminator usually unlikely fooled easily, generator hardly learn ineffective rewards. Second, generator sometimes encouraged mimic high-frequency generic responses training corpus, \checkhere{because cases, discriminator fails distinguish good response bad one: easily recognize contentful less-grammatical responses machine-generated, yet treat human-generated dull responses oracle.} In paper, introduce contrastive learning~ dialogue generation, model explicitly perceives difference well-chosen positive negative utterances. From perspective contrastive learning, discriminator adversarial learning considers human-generated responses positive utterances synthetic ones negative samples. Instead, work deems highly-matched context-response pairs positive samples mismatched training pairs negative samples. In particular, utilize pretrained baseline model reference. During contrastive learning, context response , target dialogue model trained give higher conditional probabilities positive samples, lower conditional probabilities negative samples, compared reference model. This training paradigm encourages model pull positive data points together push apart negative samples, exemplified Figure. As result, proposed training scheme explicitly takes semantic associations differences among training examples account dialogue modeling. Besides, contrastively characterizing distinctions relative strong reference, method implicitly enhances {distinctiveness} generated responses well, ensures overall performance target model inferior reference. Contrastively learning one pair positive negative samples quite straightforward, however, multi-mapping relations prevail human-human conversations, exist multiple appropriate responses given context, response sometimes fits well several contexts, known one-to-many many-to-one relations. Such complex multi-mapping relations overlooked previous learning framework, hampers effective dialogue response learning. Furthermore, potential highly-matched utterance pair treated negative sample outlier used positive sample, model may confused. Therefore, order consider multi-mapping phenomenon human conversations remedy potential problematic false learning samples, enhance training stability, augment contrastive learning group-wise dual sampling, groups positive negative instances sampled regarding context response, respectively. To depict subtle differences instances group, adapt instance importance matching scores, optimize \iffalse expected \fi weighted loss. We show illustration case understand learning framework Figure. Given training context-response pair . By mean, target model actually induced pull positive sample pairs together push mismatched pairs apart, thus learns distinctions positives negatives. The proposed group-wise contrastive learning framework suited training various neural dialogue generation models. We conduct extensive studies three large-scale conversation datasets using four popular dialogue models assess proposed approach. The experimental results confirm effectiveness learning framework favorable performance baseline training approaches.% % File emnlp2020.tex % %% Based style files ACL 2020, %% Based style files ACL 2018, NAACL 2018/19, %% Based style files ACL-2015, improvements %% taken NAACL-2016 style %% Based style files ACL-2014, were, turn, %% based ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009, %% EACL-2009, IJCNLP-2008... %% Based style files EACL 2006 %%e.agirre@ehu.es Sergi.Balari@uab.es %% ACL 08 Joakim Nivre Noah Smith \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{emnlp2020-templates/emnlp2020} \usepackage{times} \usepackage{latexsym} \renewcommand{\UrlFont}{\ttfamily\small} % This strictly necessary, may commented out, % improve layout manuscript, % typically save space. \usepackage{microtype} % --------- packages added authors ---------> % \usepackage{booktabs} % For formal tables \usepackage{amsmath} \usepackage{amsfonts} \usepackage{bm} \usepackage{array} \usepackage{enumitem} % \usepackage{needspace} % \usepackage{adjustbox} \usepackage{tikz} \usepackage{pgfplots} \usepackage{multirow} % \usepackage{autobreak} \usepackage{makecell} \usepackage{xcolor} \usepackage{amssymb} % \usepackage{import} % \usepackage{subcaption} \usepackage{nicefrac} % compact symbols 1/2, etc. \usepackage{microtype} % microtypography % \usepackage{tabularx} % \usepackage{dcolumn} \usepackage{url} % <--------- packages added authors --------- % % --------- commands added author ----------> % % \newcommand\setrow[1]{\gdef\rowmac{#1}#1\ignorespaces} \newcommand\clearrow{\global\let\rowmac\relax} \clearrow \newcommand{\wideslash}{\text{ / }} \newcommand{\xxx}{\textcolor{red}{Placeholder}} % \newcommand{\alert}[1]{{\textcolor{red}{#1}}} \newcommand{\alert}[1]{{#1}} % \newcommand{\notice}[1]{\textcolor{red}{#1}} \newcommand{\notice}[1]{{#1}} % \newcommand{\checkhere}[1]{\textcolor{blue}{#1}} \newcommand{\checkhere}[1]{{#1}} \newcommand*{\rom}[1]{\romannumeral#1\relax} \newcommand{\centercell}[1]{\multicolumn{1}{c}{#1}} % \DeclareUnicodeCharacter{001D}{\textcolor{red}{CHECK THIS UNICODE CHAR!!!}} % <--------- commands added author ---------- % \aclfinalcopy % Uncomment line final submission \def\aclpaperid{690} % Enter acl Paper ID %\setlength\titlebox{5cm} % You expand titlebox need extra space % show authors. Please make titlebox % smaller 5cm ; check % camera-ready version ask change back. \newcommand\BibTeX{Bib\TeX} \title{Group-wise Contrastive Learning Neural Dialogue Generation} % \author{First Author \\ % Affiliation / Address line 1 \\ % Affiliation / Address line 2 \\ % Affiliation / Address line 3 \\ % \\\And % Second Author \\ % Affiliation / Address line 1 \\ % Affiliation / Address line 2 \\ % Affiliation / Address line 3 \\ % \\} \author{ Hengyi Cai\thanks{\ \ Work done JD.com.}, Hongshen Chen\\ {\bf Yonghao Song, Zhuoye Ding, Yongjun Bao, Weipeng Yan, Xiaofang Zhao} \\ {Institute Computing Technology, Chinese Academy Sciences, Beijing, China} \\ {University Chinese Academy Sciences, Beijing, China} \\ {JD.com, China} \\ {caihengyi@ict.ac.cn, ac@chenhongshen.com} \\ {\{songyonghao, zhaoxf\}@ict.ac.cn, \{dingzhuoye, baoyongjun, Paul.yan\}@jd.com} } \date{} % \hypersetup{draft} %%%%% NEW MATH DEFINITIONS %%%%% \usepackage{amsmath,amsfonts,bm} % Mark sections captions referring divisions figures \newcommand{\figleft}{} \newcommand{\figcenter}{} \newcommand{\figright}{} \newcommand{\figtop}{} \newcommand{\figbottom}{} \newcommand{\captiona}{} \newcommand{\captionb}{} \newcommand{\captionc}{} \newcommand{\captiond}{} % Highlight newly defined term \newcommand{\newterm}[1]{{\bf #1}} % Figure reference, lower-case. \def\figref#1{figure} % Figure reference, capital. For start sentence \def\Figref#1{Figure} \def\twofigref#1#2{figures } \def\quadfigref#1#2#3#4{figures , , } % Section reference, lower-case. \def\secref#1{section} % Section reference, capital. \def\Secref#1{Section} % Reference two sections. \def\twosecrefs#1#2{sections } % Reference three sections. \def\secrefs#1#2#3{sections , } % Reference equation, lower-case. \def\eqref#1{equation} % Reference equation, upper case \def\Eqref#1{Equation} % A raw reference equation---avoid using possible \def\plaineqref#1{} % Reference chapter, lower-case. \def\chapref#1{chapter} % Reference equation, upper case. \def\Chapref#1{Chapter} % Reference range chapters \def\rangechapref#1#2{chapters--} % Reference algorithm, lower-case. \def\algref#1{algorithm} % Reference algorithm, upper case. \def\Algref#1{Algorithm} \def\twoalgref#1#2{algorithms } \def\Twoalgref#1#2{Algorithms } % Reference part, lower case \def\partref#1{part} % Reference part, upper case \def\Partref#1{Part} \def\twopartref#1#2{parts } \def\ceil#1{\lceil #1 \rceil} \def\floor#1{\lfloor #1 \rfloor} \def\1{\bm{1}} \newcommand{\train}{\mathcal{D}} \newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}} \newcommand{\test}{\mathcal{D_{\mathrm{test}}}} \def\eps{{\epsilon}} % Random variables \def\reta{{\textnormal{}}} \def\ra{{\textnormal{a}}} \def\rb{{\textnormal{b}}} \def\rc{{\textnormal{c}}} \def\rd{{\textnormal{d}}} \def\re{{\textnormal{e}}} \def\rf{{\textnormal{f}}} \def\rg{{\textnormal{g}}} \def\rh{{\textnormal{h}}} \def\ri{{\textnormal{i}}} \def\rj{{\textnormal{j}}} \def\rk{{\textnormal{k}}} \def\rl{{\textnormal{l}}} % rm already command, name random variables \def\rn{{\textnormal{n}}} \def\ro{{\textnormal{o}}} \def\rp{{\textnormal{p}}} \def\rq{{\textnormal{q}}} \def\rr{{\textnormal{r}}} \def\rs{{\textnormal{s}}} \def\rt{{\textnormal{t}}} \def\ru{{\textnormal{u}}} \def\rv{{\textnormal{v}}} \def\rw{{\textnormal{w}}} \def\rx{{\textnormal{x}}} \def\ry{{\textnormal{y}}} \def\rz{{\textnormal{z}}} % Random vectors \def\rvepsilon{{\mathbf{\epsilon}}} \def\rvtheta{{\mathbf{\theta}}} \def\rva{{\mathbf{a}}} \def\rvb{{\mathbf{b}}} \def\rvc{{\mathbf{c}}} \def\rvd{{\mathbf{d}}} \def\rve{{\mathbf{e}}} \def\rvf{{\mathbf{f}}} \def\rvg{{\mathbf{g}}} \def\rvh{{\mathbf{h}}} \def\rvu{{\mathbf{i}}} \def\rvj{{\mathbf{j}}} \def\rvk{{\mathbf{k}}} \def\rvl{{\mathbf{l}}} \def\rvm{{\mathbf{m}}} \def\rvn{{\mathbf{n}}} \def\rvo{{\mathbf{o}}} \def\rvp{{\mathbf{p}}} \def\rvq{{\mathbf{q}}} \def\rvr{{\mathbf{r}}} \def\rvs{{\mathbf{s}}} \def\rvt{{\mathbf{t}}} \def\rvu{{\mathbf{u}}} \def\rvv{{\mathbf{v}}} \def\rvw{{\mathbf{w}}} \def\rvx{{\mathbf{x}}} \def\rvy{{\mathbf{y}}} \def\rvz{{\mathbf{z}}} % Elements random vectors \def\erva{{\textnormal{a}}} \def\ervb{{\textnormal{b}}} \def\ervc{{\textnormal{c}}} \def\ervd{{\textnormal{d}}} \def\erve{{\textnormal{e}}} \def\ervf{{\textnormal{f}}} \def\ervg{{\textnormal{g}}} \def\ervh{{\textnormal{h}}} \def\ervi{{\textnormal{i}}} \def\ervj{{\textnormal{j}}} \def\ervk{{\textnormal{k}}} \def\ervl{{\textnormal{l}}} \def\ervm{{\textnormal{m}}} \def\ervn{{\textnormal{n}}} \def\ervo{{\textnormal{o}}} \def\ervp{{\textnormal{p}}} \def\ervq{{\textnormal{q}}} \def\ervr{{\textnormal{r}}} \def\ervs{{\textnormal{s}}} \def\ervt{{\textnormal{t}}} \def\ervu{{\textnormal{u}}} \def\ervv{{\textnormal{v}}} \def\ervw{{\textnormal{w}}} \def\ervx{{\textnormal{x}}} \def\ervy{{\textnormal{y}}} \def\ervz{{\textnormal{z}}} % Random matrices \def\rmA{{\mathbf{A}}} \def\rmB{{\mathbf{B}}} \def\rmC{{\mathbf{C}}} \def\rmD{{\mathbf{D}}} \def\rmE{{\mathbf{E}}} \def\rmF{{\mathbf{F}}} \def\rmG{{\mathbf{G}}} \def\rmH{{\mathbf{H}}} \def\rmI{{\mathbf{I}}} \def\rmJ{{\mathbf{J}}} \def\rmK{{\mathbf{K}}} \def\rmL{{\mathbf{L}}} \def\rmM{{\mathbf{M}}} \def\rmN{{\mathbf{N}}} \def\rmO{{\mathbf{O}}} \def\rmP{{\mathbf{P}}} \def\rmQ{{\mathbf{Q}}} \def\rmR{{\mathbf{R}}} \def\rmS{{\mathbf{S}}} \def\rmT{{\mathbf{T}}} \def\rmU{{\mathbf{U}}} \def\rmV{{\mathbf{V}}} \def\rmW{{\mathbf{W}}} \def\rmX{{\mathbf{X}}} \def\rmY{{\mathbf{Y}}} \def\rmZ{{\mathbf{Z}}} % Elements random matrices \def\ermA{{\textnormal{A}}} \def\ermB{{\textnormal{B}}} \def\ermC{{\textnormal{C}}} \def\ermD{{\textnormal{D}}} \def\ermE{{\textnormal{E}}} \def\ermF{{\textnormal{F}}} \def\ermG{{\textnormal{G}}} \def\ermH{{\textnormal{H}}} \def\ermI{{\textnormal{I}}} \def\ermJ{{\textnormal{J}}} \def\ermK{{\textnormal{K}}} \def\ermL{{\textnormal{L}}} \def\ermM{{\textnormal{M}}} \def\ermN{{\textnormal{N}}} \def\ermO{{\textnormal{O}}} \def\ermP{{\textnormal{P}}} \def\ermQ{{\textnormal{Q}}} \def\ermR{{\textnormal{R}}} \def\ermS{{\textnormal{S}}} \def\ermT{{\textnormal{T}}} \def\ermU{{\textnormal{U}}} \def\ermV{{\textnormal{V}}} \def\ermW{{\textnormal{W}}} \def\ermX{{\textnormal{X}}} \def\ermY{{\textnormal{Y}}} \def\ermZ{{\textnormal{Z}}} % Vectors \def\vzero{{\bm{0}}} \def\vone{{\bm{1}}} \def\vmu{{\bm{\mu}}} \def\vtheta{{\bm{\theta}}} \def\va{{\bm{a}}} \def\vb{{\bm{b}}} \def\vc{{\bm{c}}} \def\vd{{\bm{d}}} \def\ve{{\bm{e}}} \def\vf{{\bm{f}}} \def\vg{{\bm{g}}} \def\vh{{\bm{h}}} \def\vi{{\bm{i}}} \def\vj{{\bm{j}}} \def\vk{{\bm{k}}} \def\vl{{\bm{l}}} \def\vm{{\bm{m}}} \def\vn{{\bm{n}}} \def\vo{{\bm{o}}} \def\vp{{\bm{p}}} \def\vq{{\bm{q}}} \def\vr{{\bm{r}}} \def\vs{{\bm{s}}} \def\vt{{\bm{t}}} \def\vu{{\bm{u}}} \def\vv{{\bm{v}}} \def\vw{{\bm{w}}} \def\vx{{\bm{x}}} \def\vy{{\bm{y}}} \def\vz{{\bm{z}}} % Elements vectors \def\evalpha{{\alpha}} \def\evbeta{{\beta}} \def\evepsilon{{\epsilon}} \def\evlambda{{\lambda}} \def\evomega{{\omega}} \def\evmu{{\mu}} \def\evpsi{{\psi}} \def\evsigma{{\sigma}} \def\evtheta{{\theta}} \def\eva{{a}} \def\evb{{b}} \def\evc{{c}} \def\evd{{d}} \def\eve{{e}} \def\evf{{f}} \def\evg{{g}} \def\evh{{h}} \def\evi{{i}} \def\evj{{j}} \def\evk{{k}} \def\evl{{l}} \def\evm{{m}} \def\evn{{n}} \def\evo{{o}} \def\evp{{p}} \def\evq{{q}} \def\evr{{r}} \def\evs{{s}} \def\evt{{t}} \def\evu{{u}} \def\evv{{v}} \def\evw{{w}} \def\evx{{x}} \def\evy{{y}} \def\evz{{z}} % Matrix \def\mA{{\bm{A}}} \def\mB{{\bm{B}}} \def\mC{{\bm{C}}} \def\mD{{\bm{D}}} \def\mE{{\bm{E}}} \def\mF{{\bm{F}}} \def\mG{{\bm{G}}} \def\mH{{\bm{H}}} \def\mI{{\bm{I}}} \def\mJ{{\bm{J}}} \def\mK{{\bm{K}}} \def\mL{{\bm{L}}} \def\mM{{\bm{M}}} \def\mN{{\bm{N}}} \def\mO{{\bm{O}}} \def\mP{{\bm{P}}} \def\mQ{{\bm{Q}}} \def\mR{{\bm{R}}} \def\mS{{\bm{S}}} \def\mT{{\bm{T}}} \def\mU{{\bm{U}}} \def\mV{{\bm{V}}} \def\mW{{\bm{W}}} \def\mX{{\bm{X}}} \def\mY{{\bm{Y}}} \def\mZ{{\bm{Z}}} \def\mBeta{{\bm{\beta}}} \def\mPhi{{\bm{\Phi}}} \def\mLambda{{\bm{\Lambda}}} \def\mSigma{{\bm{\Sigma}}} % Tensor \DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl} \SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n} \newcommand{\tens}[1]{\bm{\mathsfit{#1}}} \def\tA{{\tens{A}}} \def\tB{{\tens{B}}} \def\tC{{\tens{C}}} \def\tD{{\tens{D}}} \def\tE{{\tens{E}}} \def\tF{{\tens{F}}} \def\tG{{\tens{G}}} \def\tH{{\tens{H}}} \def\tI{{\tens{I}}} \def\tJ{{\tens{J}}} \def\tK{{\tens{K}}} \def\tL{{\tens{L}}} \def\tM{{\tens{M}}} \def\tN{{\tens{N}}} \def\tO{{\tens{O}}} \def\tP{{\tens{P}}} \def\tQ{{\tens{Q}}} \def\tR{{\tens{R}}} \def\tS{{\tens{S}}} \def\tT{{\tens{T}}} \def\tU{{\tens{U}}} \def\tV{{\tens{V}}} \def\tW{{\tens{W}}} \def\tX{{\tens{X}}} \def\tY{{\tens{Y}}} \def\tZ{{\tens{Z}}} % Graph \def\gA{{\mathcal{A}}} \def\gB{{\mathcal{B}}} \def\gC{{\mathcal{C}}} \def\gD{{\mathcal{D}}} \def\gE{{\mathcal{E}}} \def\gF{{\mathcal{F}}} \def\gG{{\mathcal{G}}} \def\gH{{\mathcal{H}}} \def\gI{{\mathcal{I}}} \def\gJ{{\mathcal{J}}} \def\gK{{\mathcal{K}}} \def\gL{{\mathcal{L}}} \def\gM{{\mathcal{M}}} \def\gN{{\mathcal{N}}} \def\gO{{\mathcal{O}}} \def\gP{{\mathcal{P}}} \def\gQ{{\mathcal{Q}}} \def\gR{{\mathcal{R}}} \def\gS{{\mathcal{S}}} \def\gT{{\mathcal{T}}} \def\gU{{\mathcal{U}}} \def\gV{{\mathcal{V}}} \def\gW{{\mathcal{W}}} \def\gX{{\mathcal{X}}} \def\gY{{\mathcal{Y}}} \def\gZ{{\mathcal{Z}}} % Sets \def\sA{{\mathbb{A}}} \def\sB{{\mathbb{B}}} \def\sC{{\mathbb{C}}} \def\sD{{\mathbb{D}}} % Don't use set called E, would symbol % expectation. \def\sF{{\mathbb{F}}} \def\sG{{\mathbb{G}}} \def\sH{{\mathbb{H}}} \def\sI{{\mathbb{I}}} \def\sJ{{\mathbb{J}}} \def\sK{{\mathbb{K}}} \def\sL{{\mathbb{L}}} \def\sM{{\mathbb{M}}} \def\sN{{\mathbb{N}}} \def\sO{{\mathbb{O}}} \def\sP{{\mathbb{P}}} \def\sQ{{\mathbb{Q}}} \def\sR{{\mathbb{R}}} \def\sS{{\mathbb{S}}} \def\sT{{\mathbb{T}}} \def\sU{{\mathbb{U}}} \def\sV{{\mathbb{V}}} \def\sW{{\mathbb{W}}} \def\sX{{\mathbb{X}}} \def\sY{{\mathbb{Y}}} \def\sZ{{\mathbb{Z}}} % Entries matrix \def\emLambda{{\Lambda}} \def\emA{{A}} \def\emB{{B}} \def\emC{{C}} \def\emD{{D}} \def\emE{{E}} \def\emF{{F}} \def\emG{{G}} \def\emH{{H}} \def\emI{{I}} \def\emJ{{J}} \def\emK{{K}} \def\emL{{L}} \def\emM{{M}} \def\emN{{N}} \def\emO{{O}} \def\emP{{P}} \def\emQ{{Q}} \def\emR{{R}} \def\emS{{S}} \def\emT{{T}} \def\emU{{U}} \def\emV{{V}} \def\emW{{W}} \def\emX{{X}} \def\emY{{Y}} \def\emZ{{Z}} \def\emSigma{{\Sigma}} % entries tensor % Same font tensor, without \bm wrapper \newcommand{\etens}[1]{\mathsfit{#1}} \def\etLambda{{\etens{\Lambda}}} \def\etA{{\etens{A}}} \def\etB{{\etens{B}}} \def\etC{{\etens{C}}} \def\etD{{\etens{D}}} \def\etE{{\etens{E}}} \def\etF{{\etens{F}}} \def\etG{{\etens{G}}} \def\etH{{\etens{H}}} \def\etI{{\etens{I}}} \def\etJ{{\etens{J}}} \def\etK{{\etens{K}}} \def\etL{{\etens{L}}} \def\etM{{\etens{M}}} \def\etN{{\etens{N}}} \def\etO{{\etens{O}}} \def\etP{{\etens{P}}} \def\etQ{{\etens{Q}}} \def\etR{{\etens{R}}} \def\etS{{\etens{S}}} \def\etT{{\etens{T}}} \def\etU{{\etens{U}}} \def\etV{{\etens{V}}} \def\etW{{\etens{W}}} \def\etX{{\etens{X}}} \def\etY{{\etens{Y}}} \def\etZ{{\etens{Z}}} % The true underlying data generating distribution \newcommand{\pdata}{p_{\rm{data}}} % The empirical distribution defined training set \newcommand{\ptrain}{\hat{p}_{\rm{data}}} \newcommand{\Ptrain}{\hat{P}_{\rm{data}}} % The model distribution \newcommand{\pmodel}{p_{\rm{model}}} \newcommand{\Pmodel}{P_{\rm{model}}} \newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}} % Stochastic autoencoder distributions \newcommand{\pencode}{p_{\rm{encoder}}} \newcommand{\pdecode}{p_{\rm{decoder}}} \newcommand{\precons}{p_{\rm{reconstruct}}} \newcommand{\laplace}{\mathrm{Laplace}} % Laplace distribution \newcommand{\E}{\mathbb{E}} \newcommand{\Ls}{\mathcal{L}} \newcommand{\R}{\mathbb{R}} \newcommand{\emp}{\tilde{p}} \newcommand{\lr}{\alpha} \newcommand{\reg}{\lambda} \newcommand{\rect}{\mathrm{rectifier}} \newcommand{\softmax}{\mathrm{softmax}} \newcommand{\sigmoid}{\sigma} \newcommand{\softplus}{\zeta} \newcommand{\KL}{D_{\mathrm{KL}}} \newcommand{\Var}{\mathrm{Var}} \newcommand{\standarderror}{\mathrm{SE}} \newcommand{\Cov}{\mathrm{Cov}} % Wolfram Mathworld says function spaces vectors % But seem use vectors throughout site, % wikipedia. \newcommand{\normlzero}{L^0} \newcommand{\normlone}{L^1} \newcommand{\normltwo}{L^2} \newcommand{\normlp}{L^p} \newcommand{\normmax}{L^\infty} \newcommand{\parents}{Pa} % See usage notation.tex. Chosen match Daphne's book. \DeclareMathOperator*{\argmax}{arg\,max} \DeclareMathOperator*{\argmin}{arg\,min} \DeclareMathOperator{\sign}{sign} \DeclareMathOperator{\Tr}{Tr} \let\ab\allowbreak"," \checkhere{ Neural dialogue response generation has gained much popularity in recent years.  Maximum Likelihood Estimation  objective is widely adopted in existing dialogue model learning. However, models trained with MLE objective function are plagued by the low-diversity issue when it comes to the open-domain conversational setting. Inspired by the observation that humans not only learn from the positive signals but also benefit from correcting behaviors of undesirable actions, in this work, we introduce contrastive learning into dialogue generation, where the model explicitly perceives the difference between the well-chosen positive and negative utterances. Specifically, we employ a pretrained baseline model as a reference. During contrastive learning, the target dialogue model is trained to give higher conditional probabilities for the positive samples, and lower conditional probabilities for those negative samples, compared to the reference model. To manage the multi-mapping relations prevalent in human conversation, we augment contrastive dialogue learning with group-wise dual sampling. Extensive experimental results show that the proposed group-wise contrastive learning framework is suited for training a wide range of neural dialogue generation models with very favorable performance over the baseline training approaches. }"
"Spoken dialogue systems connect users computer applications human-machine conversations. The users achieve goals, finding restaurant, interacting task-oriented SDS multiple dialogue rounds turns. Dialogue state tracking important task SDS key function maintain state system track progress dialogue. In context work, state user's intention interest accumulated conversation history, user's intention interest turn referred turn-level state. %The state immediate state usually expressed terms set slot-value pairs. % For example, state contains two slot-value pairs, . In example, slots, , values. This state expresses system's belief user wants find cheap Italian restaurant. %At turn, system generates action, expressed user sentences natural language, user responds sentences, referred utterance. The system updates state. The problem dialogue state tracking learn predictor set training dialogues, specified sequences quadruples; learned predictor needs able predict state current turn dialogue history. %Various models developed DST. Traditional works usually deal task incorporating Spoken Language Understanding module. These works make limited progress rely hand-crafted features. The neural networks thus used DST achieve much success. Many neural-network models successfully applied DST. These models usually solve DST problem two approaches, Implicit Tracking Explicit Tracking. As shown Figure , Implicit Tracking models employs recurrent networks accumulate features extracted historical system action user utterance pairs. A classifier built upon accumulated features state prediction. Although Implicit Tracking captures temporal feature dependencies recurrent-network cells, state dependencies explicitly modeled. Only considering temporal feature dependencies insufficient accurate state prediction. This fact confirmed via ablation study experiment. Unlike Implicit Tracking, Explicit Tracking approaches, NBT GLAD, model state dependencies explicitly. From model structure Figure, Explicit Tracking approaches first build classifier predict turn-level state turn utilize state aggregator state aggregation. %One branch models handle DST problem building immediate-state predictor map historical immediate states accumulative state. To distinguish branch models another one ignore immediate state directly model state accumulation Recurrent Neural Networks , name former indirect models latter direct models. Unlike indirect models, Direct models, including, explicitly model dependencies immediate state accumulative state. Indirect models like NBT GALD, build immediate-state predictors using features extracted current turn's system action user uttrance , update state deterministic rule heuristics. They use Convolutional Neural Networks attention-based RNNs feature extraction achieve remarkable improvements upon previous models. Despite success, two limitations existing indirect models. Despite achieving remarkable improvements upon previous models, current Explicit Tracking models improved two aspects. One temporal feature dependencies considered model design. The Explicit Tracking models extract features current system action user utterance pair. In practice, slot-value pairs different turns highly dependent. For example, user specifies appears future turn-level states. \end{center} :Feature Extractor, CNNs, RNNs. {\bf RC}:Recurrent Cell, LSTM, GRU. {\bf CL}:Classifier. {\bf SA}:State Aggregator. The dotted arrowed lines emphasize modeling temporal feature dependencies. The dashed arrowed lines emphasize modeling temporal state dependencies.} \end{figure*} The uncertainties state aggregation expressively modeled. The state-aggregation approaches current Explicit Tracking models sub-optimal. The deterministic rule GLAD propagate errors future turns lead incorrect state aggregation. The heuristic aggregation NBT needs estimate best configuration coefficient . An approach reduce error propagation require less parameter estimation necessary state aggregation. % The uncertainties state aggregation expressively modeled. The deterministic state aggregation rule used GLAD sub-optimal errors caused hard decision propagate future turns lead incorrect aggregation future states. The NBT aware uncertainty deal using simple rule-based aggregation. And best configuration coefficient need estimated. %In Figure, see TEN TEN-X model correctly estimate state first turn second turn. At third turn, suppose predicted turn-label probabilities values , TEN-X model using deterministic state updating rule , output wrong state value . On contrary, TEN model uncertainty modeling still obtain true state value higher confidence . This example indicates significance uncertainty modeling state estimation. Although turn labels states related deterministic mapping , models estimating state deterministic rules fact sub-optimal. This estimation current state averaged uncertainties estimation previous states turn labels. Such averaging effect ignored deterministic rules used state updating. Models attempt update states heuristics leave state updating learning task also sub-optimal. Actually, due fact deterministic mapping already exists, heuristics learned function may under-perform deterministic mapping. A proper solution maintain deterministic mapping handle uncertainties simultaneously. % This training dialogue, system estimates current state, arguably accounted uncertainties estimating previous state estimating current turn label. That is, system predictive distribution current state result averaged uncertainties. Updating state using deterministic rules essentially ignores averaging effect. % dependency need taken account turn label state prediction. 2) inadequate consideration uncertainty state estimates. The prediction current state consider uncertainty estimating previous state uncertainty estimating current turn label. 3) less expressive modelling known dialogue dynamics. The known dynamics turn labels states model explicitly. A detailed discussion limitation existing models depicted ""Related Works"" Section. % %{\bf Less expressive modelling known dialogue dynamics.} Some works, including, build DST models recurrent networks. They ignore provided turn labels directly use states training target. In models, temporal feature dependency considered predicting states. They however, explicitly model known dynamics turn labels states. Demanding additional capacity, models may under-perform models use turn labels training target. The immediate state important source estimating accumulative state accumulative state changes immediate state changed. In study, propose novel Temporally Expressive Networks jointly model temporal feature dependencies temporal state dependencies ). Specifically, improve turn-level state prediction, exploits hierarchical recurrent networks capture temporal feature dependencies across dialogue turns. Furthermore, reduce state aggregation errors, introduce factor graphs formulate state dependencies, employ belief propagation handle uncertainties state aggregation. Evaluating DSTC2, WOZ MultiWoZ datasets, TEN shown improve accuracy turn-level state prediction state aggregation. The TEN model establishes new state-of-the-art model DSTC2 dataset state-of-the-art comparable model WOZ dataset. %The system take action respond users basis estimated state. % The State Updating task fully studied among three subtasks. Some works avoid Turn-level Prediction directly update dialogue state using Recurrent Neural Networks. It's natural use RNN state updating, supervision turn labels considered. Some works train models turn labels, update dialogue states rule, performs compatible better models updating states RNN. The limitations updating rules used recent works are: The updating rule GLAD makes hard decision state ignores rich probabilistic distribution information, thus turn-level error may propagate cumulatively. The updating rule NBT rely carefully tuned hyperparameters simple rule difficulty handling complex nature state updating. The MDT proposes RNN-based updating rule training using outputs turn-level prediction model. However, updating rule trained independently turn-level prediction model. % In work, propose novel state updating model factor graphs, call Factor Graph Tracker . The FGT implemented sum-product algorithm effectively reduce cumulative error propagation. It natural use sum-product algorithm summary previous states turn-level goal updating current state. The FGT easily built upon turn-level prediction model unified model; turn-level prediction state updating thus jointly learned. The state tracking may benefit joint learning strategy. % Another limitation existing models dependency turn-level goals ignored turn-level prediction stage. We argue dependency turn-level goals considered. For example, area slot usually requested food slot requested; slot-value pair already imformed, lower probability expressed user current turn. Instead directly building classifiers predict turn-level goals, work, use GRU turn-label-tracker handle dependency turn-level goals build classifiers upon outputs turn-label-tracker. % The GLAD introduce attention machinisum propose Global-Locally Self-Attentive encoder feature extraction. Specifically, global self attention model bidirectional LSTM used extract global features input slot, local BiLSTMATT extracting slot-specific features. We propose slot attention encoder simplify GLSA encoder significantly decreases model parameters."," Dialogue state tracking  is an important part of a spoken dialogue system. Existing DST models either ignore temporal feature dependencies across dialogue turns or fail to explicitly model temporal state dependencies in a dialogue. In this work, we propose Temporally Expressive Networks  to jointly model the two types of temporal dependencies in DST. The TEN model utilizes the power of recurrent networks and probabilistic graphical models. Evaluating on standard datasets, TEN is demonstrated to improve the accuracy of turn-level-state prediction and the state aggregation.   %The existing models usually solve DST problem by two approaches, Implicit Tracking and Explicit Tracking. The Implicit Tracking employs recurrent networks to model the temporal feature dependencies across dialogue turns, but fails to consider the temporal state dependencies. While Explicit Tracking models state dependencies explicitly, it ignores the feature dependencies.  %Dialogue state tracking  is an important part of a spoken dialogue system. Some of the prior arts for DST build an momentary-state predictor and map the historical immediate states to the accumulative state. These models are however insufficiently modelling the temporal dependencies across dialogue turns and the uncertainties in state updating. In this work, we introduce a probabilistic graphical model to formulate the dialogue process and propose Temporally Expressive Networks  that utilizes hierarchical recurrent networks and belief propagation to deal with these issues. Evaluating on standard datasets, the proposed model is demonstrated to be significantly effective in improving accuracy for immediate-state prediction and reducing errors in state updating.  % a GRU  encoder sharing parameters across all slots to capture global information. The slot attention is adopted for each slot to capture local information. To alleviate the error propagation caused by hard decision on the turn-level goals, we propose a neural-network-based DST model with factor graphs and introduce the sum-product algorithm to handle the problem. Experimental stdies demonstrate that the proposed approach significantly improves the current art in tracking the joint goals."
"%The web became important source accessing knowledge information daily lives. It's necessary develop intelligent applications help users access understand web information easily. Spoken dialogue system application help users complete goals efficiently. % Users achieve goals, booking restaurant, communicating SDS natural language multiple dialogue turns. An SDS usually logic engine, called dialogue manager, involves two main sub-tasks determining system respond users: dialogue state tracking dialogue policy learning. The task discuss paper dialogue state tracking, allows system maintaining internal representation state dialogue dialogue progress. Dialogue state tracking involving single domain extensively studied achieved much progress. As challenging task, Multi-domain dialogue state tracking introduced attracts much attention research community. %The state multi-domain dialogues usually expressed set pair, MDST, model expected predict pair specific expressive pattern involved dialogue. A feature extractor designed specific pair. 2) unlike single-domain DST problem, slot overlapping exists multi-domain DST problems overlapping domains share similar values. A global feature extractor may fail extract correct features dialogue history. For example, restaurant hotel domain slot area. A global feature extractor may extract hotel-area restaurant-area. %shows example multi-domain dialogues involves Restaurant domain Hotel domain. At turn, system generates utterance followed user utterance. Each utterance may specify domain, slot values. The aim multi-domain dialogue state tracking extract identify pairs specified last 4 turns Restaurant Hotel domain. One challenges multi-domain dialogue state tracking values pair come copying dialogue history , summary utterance pair turn 4)."," The dependencies between system and user utterances in the same turn and across different turns are not fully considered in existing multi-domain dialogue state tracking  models. In this study, we argue that the incorporation of these dependencies is crucial for the design of MDST and propose Parallel Interactive Networks  to model these dependencies. Specifically, we integrate an interactive encoder to jointly model the in-turn dependencies and cross-turn dependencies. The slot-level context is introduced to extract more expressive features for different slots. And a distributed copy mechanism is utilized to selectively copy words from historical system utterances or historical user utterances. Empirical studies demonstrated the superiority of the proposed PIN model.  % Multi-domain dialogue state tracking  involves large-size ontology and cross-turn inference, making it a challenge in research community. Recent MDST models fail to considering the interactive dependencies and the slot overlapping in multi-domain dialogues. In this work, we propose a robust generation-based model, Parallel Interactive Networks  , to tackle with the MDST challenge. More precisely, PIN incorporates an Interactive Encoder to jointly model the cross-turn dependencies and in-turn dependencies. The slot-level context is introduced in PIN to extract more expressive features for different slots. And a distributed copy mechanism is utilized in PIN to selectively copy words from historical system utterances and history user utterances. The PIN is demonstrated to outperform existing models on bench-marking multi-domain state tracking datasets.	   %The model however ignore the dependencies between words from system-side and user-side, and the context of decoder in these models fails to incorporating local features from specific domain and slot. In this paper, we propose a parallel-interactive recurrent neural network to modeling the human-system-interaction nature of the dialogues and introduce local context modeling to enhance the state generation performance. And a special distributed-copy operation is designed in the decoder that can copy a word from either the system-side utterances or the user-side utterances, which improves the robustness of the model. The proposed model is demonstrated to outperform existing models on bench-marking multi-domain state tracking data sets.	 	 %Multi-domain dialogue state tracking involves complex dialogue context and domain transferring, making it a challenge in research community. The traditional classification-based dialogue state tracking models need predefined ontology and are unable to dealing with unknown slot-values. The recent generation-based models tackle with this issue by incorporating the copy mechanism and generating the value sequence using the sequence-to-sequence framework. However, these generation-based models are limited in their simple encoder that insufficiently considers the human-system interaction property of the dialogues, and the context of decoder in these models fails to incorporating local features from specific domain and slot. In this paper, we propose a parallel-interactive recurrent neural network to modeling the human-system-interaction nature of the dialogues and introduce local context modeling to enhance the state generation performance. And a special adversarial-copy operation is designed in the decoder that can copy a word from either the system-side utterances or the user-side utterances, which improves the robustness of the model. The proposed model is demonstrated to outperform existing models on bench-marking multi-domain state tracking data sets."
"%%General subject \ac{NLG} process generating coherent natural language text non-linguistic data. Despite community agreement text speech output systems, far less consensus input be. A large number inputs hence employed \ac{NLG} systems, including images , numeric data, \ac{SW} data. Practical applications found domains weather forecasts , feedback car drivers , diet management . %%%specific problem subject Presently, generation natural language %\ac{SW}, precisely \ac{RDF} data gained substantial attention. The RDF-to-text task hence proposed investigate quality automatically generated texts \ac{RDF} \acp{KG}. %Moreover, \ac{RDF} demonstrated promising ability support creation \ac{NLG} benchmarks. With emergence neural methods, end-to-end data-to-text models introduced learn input-output mappings directly. These approaches rely much less %\todo{less comparative, ergo less what?} explicit intermediate representations compared rule-based approaches. Although Neural \ac{NLG} models achieving good results %\todo{cite paper shown} , English language widely targeted. % \todo[inline]{why important able generate different language text model} % \todo[inline]{What motivation behind investigating generation different language families?} In work, alleviate language limitation proposing multilingual approach, named NABU. The motivation behind multilingual models lies several directions, mainly transfer learning; low-resource language pairs trained together high-resource languages, translation quality improves; zero-shot translation, multilingual models able translate language pairs similar families never seen training; Easy deploy, multilingual model achieving performance many languages comparison several separate language-specific models much desirable companies terms deployment. Our approach, NABU, based fact knowledge graphs language-agnostic hence used encoder side generate multilingual text. NABU consists encoder-decoder architecture incorporates structural information RDF triples using encoding mechanism inspired \ac{GAT}. In contrast recent related work, NABU relies use reification %\todo{sure?} strategy modeling graph structure RDF input. The decoder part %\todo{do mean decoder?} based vanilla Transformer model along unsupervised tokenization model. %which implements \ac{BPE} unigram language model handling multilinguality. %\todo{Is statement really necessary here?Would make sense add details approach.} %Note NABU follows strategy recent literature multilingual \ac{NMT} models special token used encoder determine target language translate. %evaluation We evaluate NABU standard benchmarking WebNLG datasets three settings: monolingual, bilingual multilingual. For monolingual setting, compare NABU state-of-the-art English approaches also perform experiments Russian German. The goal bilingual setting analyze performance NABU language families. To achieve goal, train evaluate bilingual models using NABU English-German English-Russian. In multilingual setting, compare NABU multilingual Transformer model English, German Russian. %%%results Our results show NABU outperforms state-of-the-art approaches English achieves 66.21 BLEU. NABU also achieves consistent results across languages multilingual settings 56.04 BLEU. In addition, NABU presents promising results bilingual models 61.99 BLEU. %\todo{numbers?} Our findings suggest NABU able generate multilingual text similar quality generated humans. %conclusion The main contributions paper summarized follows: The version NABU used paper also experimental data publicly available.~\footnote{https://github.com/dice-group/NABU}."," The RDF-to-text task has recently gained substantial attention due to continuous growth of Linked Data. In contrast to traditional pipeline models, recent studies have focused on neural models, which are now able to convert a set of RDF triples into text in an end-to-end style with promising results. However, English is the only language widely targeted. We address this research gap by presenting NABU, a multilingual graph-based neural model that verbalizes RDF data to German, Russian, and English. NABU is based on an encoder-decoder architecture, uses an encoder inspired by Graph Attention Networks and a Transformer as decoder. Our approach relies on the fact that knowledge graphs are language-agnostic and they hence can be used to generate multilingual text. We evaluate NABU in monolingual and multilingual settings on standard benchmarking WebNLG datasets. Our results show that NABU outperforms state-of-the-art approaches on English with 66.21 BLEU, and achieves consistent results across all languages on the multilingual scenario with 56.04 BLEU. %Moreover, we trained bilingual models for analyzing the capability of NABU to model jointly distinct language families such as English-Russian.  %\todo{Which conclusion did you reach from this training?} \keywords{Knowledge Graphs  \and Natural Language Generation \and Semantic Web.}"
"We digitally surrounded computational Language Models guide us writing reduce user effort, suggest different options words/sentences enhance style, fix grammatical/correctness errors accurately . Many keys press writing keyboard act part inputs compose new datasets models shape communicate others. Nevertheless, happen way write code? Succinctly, yes. According recent surveys found literature , Natural Language Processing subfield related programming language includes examples LMs used several tasks contexts. For example, authors used different techniques graph-based statistical LMs, probabilistic LMs, Deep Learning LMs suggest code programmers similarly auto-completer features IDEs. LMs used generate automated source code based sample code inputs pseudo-code evaluating generated code performs . Another exciting application NLP source code languages automatic translation different languages. The work reported explores different supervised unsupervised approaches migrate code different programming languages improve interoperability port codebases written obsolete deprecated languages . Another example found use Bayesian networks, attention mechanisms, pointer networks fill given code portion missings. There general understanding natural languages閳 different characteristics NLP broad field. Since exist many research fields related human languages, richer background existing language characteristics. For example, much knowledge aspects like minimal representation units word specific language, used words language, word neologism not. Programming languages share syntax similarities spoken languages. However, restrictions sense common words neologisms , syntax restrictions features punctuation, format, style. Every programming language indeed reserved words symbols denote different actions, resources, syntax. However, essential part source code limited programmer閳ユ獨 imagination, conventions existing, guides good practices. As claims, In paper, Karampatsis Sutton \citeyear{karampatsis2019maybe} present segmenting words subword units improve source code modeling. Similarly, researchers dug representing source code vocabulary similar emphasis modeling words using sub-word units envisioning importance using neural networks . Nevertheless, word segmentation affect accuracy appropriateness code generated auto-completed modern LM using deep learning approaches? That kind question raises main goal paper: discover kinds associations different modern neural network architectures tokenization models produce best results creating LMs generate auto-complete source code. To pursue goal, research aims conduct experiments combining different deep neural network architectures different tokenization pre-trained models existing Python dataset. Using experimentation, want investigate combinations improve code generation auto-completion tasks checking outcomes tasks using metrics like accuracy human assessment. The rest paper follows: Section 2 presents different approaches followed research, DNNs used, software methods data employed. Section 3 describes results achieved research according different metrics tests, section 4 discusses findings implications results appropriate. Finally, Section 5 presents conclusions."," In recent years, the use of deep learning in language models gained much attention. Some research projects claim that they can generate text that can be interpreted as human-writing, enabling new possibilities in many application areas. Among the different areas related to language processing, one of the most notable in applying this type of modeling is programming languages. For years, the Machine Learning community has been researching this software engineering area, pursuing goals like applying different approaches to auto-complete, generate, fix, or evaluate code programmed by humans. Considering the increasing popularity of the Deep-Learning-enabled language models approach, we detected a lack of empirical papers that compare different deep learning architectures to create and use language models based on programming code. This paper compares different neural network architectures like AWD-LSTMs, AWD-QRNNs, and Transformer while using transfer learning and different tokenizations to see how they behave in building language models using a Python dataset for code generation and filling mask tasks. Considering the results, we discuss each approach闁炽儲鐛 different strengths and weaknesses and what gaps we find to evaluate the language models or apply them in a real programming context."
"A dominant approach text generation use autoregressive models learned maximum likelihood estimation supervised data. However, approach introduces two well-known discrepancies training evaluation objectives lead undesired generations. % First, training loss negative log-likelihood, whereas evaluation based human judgment output quality. Under model misspecification, MLE tends over-generalize, assigning large probability mass high-quality low-quality sequences . Therefore, practice, must carefully select decoding algorithms produce high-quality outputs. Second, training, autoregressive model conditions gold history/prefix; however, inference time conditions model-generated history. This known exposure bias problem . In worst case, one incorrect prediction produce low-probability prefix gold data distribution, errors compound following steps . In practice, prior work observed problems repetition hallucination partly due exposure bias . We aim bridge gap training evaluation paper. To match training evaluation objectives, ideally maximize output quality given model-generated histories. This corresponds reinforcement learning objective: maximizing expected reward trajectories induced policy . However, optimizing objective notoriously difficult. Prior RL approaches mainly focus fine-tuning learned model optimize sequence-level metrics BLEU~, empirically remains unclear RL beneficial text generation . % Note many challenges RL arise exploring exponentially large space sequences, sparse rewards close reference. We thus propose learn reference sequences without interaction . Specifically, use off-policy policy gradient importance weighting , training examples higher probability model weighted higher. Further, reward functions approximate human judgment output quality estimating likely human would generated sequence. We call algorithm \algoname . Results news summarization, question generation, machine translation show \algoname leads better model performance MLE RL fine-tuning task metrics human-rated quality. Further, analysis shows \algoname learns high-precision models less sensitive decoding algorithms. In addition, alleviates exposure bias: output quality degrade much generation length increases.","     Current approaches to text generation largely rely on autoregressive models and maximum likelihood estimation.     This paradigm leads to       diverse but low-quality samples due to mismatched learning objective and evaluation metric      and  exposure bias due to mismatched history distributions .      To alleviate these problems, we frame text generation as an offline reinforcement learning  problem with expert demonstrations ,     where the goal is to maximize quality given model-generated histories.      We propose \algoname :     an easy-to-optimize algorithm that learns from the demonstrations by importance weighting.      Intuitively, \algoname upweights confident tokens and downweights unconfident ones in the reference during training,      avoiding optimization issues faced by prior RL approaches that rely on online data collection.     According to both automatic and human evaluation,     models trained by \algoname outperform those trained by MLE and policy gradient      on summarization, question generation, and machine translation.      Further, our models are less sensitive to decoding algorithms     and alleviate exposure bias."
"\let\thefootnote\relax\footnote{ Corresponding author.} Recent years witnessed significant improvements vision language communities, consequently led substantial attention vision-language multi-modality tasks visual grounding , image captioning , visual question answering . Furthermore, video becomes ubiquitous, daily source information communication, video-language tasks video captioning , video moment retrieval , video question answering emerging important topics. Among topics, video QA especially challenging, requires fine-grained understanding video language. \sh{Figure shows example multiple-choice video QA TVQA dataset. The multiple-choice video QA task requires model select correct answer given question, corresponding video frames, subtitles.}"," Video Question Answering  requires fine-grained understanding of both video and language modalities to answer the given questions. In this paper, we propose novel training schemes for multiple-choice video question answering with a self-supervised pre-training stage and a supervised contrastive learning in the main stage as an auxiliary learning. In the self-supervised pre-training stage, we transform the original problem format of predicting the correct answer into the one that predicts the relevant question to provide a model with broader contextual inputs without any further dataset or annotation. For contrastive learning in the main stage, we add a masking noise to the input corresponding to the ground-truth answer, and consider the original input of the ground-truth answer as a positive sample, while treating the rest as negative samples. By mapping the positive sample closer to the masked input, we show that the model performance is improved. We further employ locally aligned attention to focus more effectively on the video frames that are particularly relevant to the given corresponding subtitle sentences. We evaluate our proposed model on highly competitive benchmark datasets related to multiple-choice video QA: TVQA, TVQA+, and DramaQA. Experimental results show that our model achieves state-of-the-art performance on all datasets. We also validate our approaches through further analyses."
"Neural machine translation typically follows encoder-decoder framework, directly applies single neural network transform source sentence target sentence. With tens millions trainable parameters NMT model, translation tasks usually data-hungry, many low-resource even zero-resource terms training data. Following idea unsupervised self-supervised pre-training methods NLP area , works proposed improve NMT model pre-training, making full use widely available monolingual corpora . Typically, two different branches pre-training approaches proposed NMT: model-fusion parameter-initialization. The model-fusion approaches seek incorporate sentence representation provided pre-trained model, BERT, NMT model . These approaches able leverage publicly available pre-trained checkpoints website need change NMT model fuse sentence embedding calculated pre-trained model. Large-scale parameters pre-trained model significantly increase storage cost inference time, makes hard branch approaches directly used production. As opposed model-fusion approaches, parameter-initialization approaches aim directly pre-train whole part NMT model tailored objectives, initialize NMT model pre-trained parameters . These approaches production-ready since keep size structure model standard NMT systems. While achieving substantial improvements, pre-training approaches two main cons. Firstly, pointed \citet{yang2019xlnet}, artificial symbols like [mask] used approaches pre-training absent real data fine-tuning time, resulting pretrain-finetune discrepancy. Secondly, pre-training step involves sentences language, approaches unable make use cross-lingual alignment information contained source target monolingual corpus. We argue that, cross-lingual sequence generation task, NMT requires tailored pre-training objective capable making use cross-lingual alignment signals explicitly, e.g., word-pair information extracted source target monolingual corpus, improve performance. To address limitations mentioned above, propose Code-Switching Pre-training NMT. We extract word-pair alignment information source target monolingual corpus automatically, apply extracted alignment information enhance pre-training performance. The detailed training process CSP presented two steps: 1) perform lexicon induction get translation lexicons unsupervised word embedding mapping ; 2) randomly replace words input sentence translation words extracted translation lexicons train NMT model predict replaced words. CSP adopts encoder-decoder framework: encoder takes code-mixed sentence input, decoder predicts replaced fragments based context calculated encoder. By predicting sentence fragment replaced encoder side, CSP able either attend remaining words source language translation words replaced fragment target language. Therefore, CSP trains NMT model to: 1) learn build sentence representation input sentence traditional pre-training methods do; 2) learn perform cross-lingual translation extracted word-pair alignment information. In summary, mainly make following contributions: \footnotetext[1]{To used production easily, models need distilled student model structure size standard NMT systems.}","  This paper proposes a new pre-training method, called Code-Switching Pre-training  for Neural Machine Translation . Unlike traditional pre-training method which randomly masks some fragments of the input sentence,  the proposed CSP randomly replaces some words in the source sentence with their translation words in the target language. Specifically, we firstly perform lexicon induction with unsupervised word embedding mapping between the source and target languages, and then randomly replace some words in the input sentence with their translation words according to the extracted translation lexicons. CSP adopts the encoder-decoder framework: its encoder takes the code-mixed sentence as input, and its decoder predicts the replaced fragment of the input sentence. In this way, CSP is able to pre-train the NMT model by explicitly making the most of the cross-lingual alignment information extracted from the source and target monolingual corpus. Additionally,  we relieve the pretrain-finetune discrepancy caused by the artificial symbols like [mask].  To verify the effectiveness of the proposed method, we conduct extensive experiments on unsupervised and supervised NMT. Experimental results show that CSP achieves significant improvements over baselines without pre-training or with other pre-training methods."
"With increasingly larger amounts unstructured text becoming digitally available many different fields, need robust geographically-aware retrieval information large textual collections urgent ever. Textual data often deeply geographical shown geographic queries make large part search queries . Toponym resolution class entity linking focuses specifically geographical entities. Given toponym recognized text,\footnote{We consider toponym detection part toponym resolution task paper. There large body research natural language processing community deals specific problem named entity recognition, toponym detection part.} aim resolve spatial footprint . This step requires external source knowledge usually comes shape gazetteer, is, dictionary geographical entities associated alternative place names geospatial information. On hand, candidate selection task identifying potential entities referred named entity recognized text. As intermediary step named entity recognition downstream task entity disambiguation, candidate selection integral part entity linking. And yet, often overlooked component entity linking pipeline, even though shown significant impact final performance , especially noisy non-standard text. Toponyms particularly prone name variations changes, arise multiple causes, regional spelling differences, diachronic spelling variation, change geopolitical status . In toponyms, variation common token-level , also character-level , token- character-level . In addition these, noisy text often presents types character-level variations, spelling errors, typographical errors, OCR errors . The number potential variations high, yet candidate selection ensure correct location provided among pool retrieved entities. In paper, present new flexible deep learning approach geographical candidate selection toponym matching, specifically tailored dealing challenges characteristic noisy scenarios. Our method consists two main components: toponym matching, formulated binary classification toponym query-candidate pairs, candidate selection, formulated ranking task aim rank good candidates first minimizing presence noisy candidates. The main contributions paper are: Our method designed language-independent possible. It relies upon character tokenizer processing string inputs reference gazetteer. We tested downstream application datasets different languages, time periods origins, seventeenth century Latin America nineteenth century Britain United States. All codes, datasets, gazetteers evaluation settings openly available support research reproducibility foster use DeezyMatch downstream tasks.\footnote{DeezyMatch codes found here: \url{https://github.com/Living-with-machines/DeezyMatch/}. For detailed description DeezyMatch architecture functionalities, see \citet{hosseini2020deezy}. All experiments found here: \url{https://github.com/Living-with-machines/LwM_SIGSPATIAL2020_ToponymMatching}. We provide resources allow full reproducibility results.} %% SECTION"," %   Recognizing toponyms and resolving them to their real-world referents is required for providing advanced semantic access to textual data. This process is often hindered by the high degree of variation in toponyms. Candidate selection is the task of identifying the potential entities that can be referred to by a toponym previously recognized. While it has traditionally received little attention in the research community, it has been shown that candidate selection has a significant impact on downstream tasks , especially in noisy or non-standard text. In this paper, we introduce a flexible deep learning method for candidate selection through toponym matching, using state-of-the-art neural network architectures. We perform an intrinsic toponym matching evaluation based on several new realistic datasets, which cover various challenging scenarios . We report its performance on candidate selection in the context of the downstream task of toponym resolution, both on existing datasets and on a new manually-annotated resource of nineteenth-century English OCR'd text. %"
"% \{-0.3em} % General introduction Belief tracking important component task-oriented dialog systems. The system tracks user goals multiple dialog turns, i.e. infers structured belief states expressed terms slots values , query external database . Different belief tracking models proposed recent years, either trained independently within end-to-end trainable dialog systems . % problem Existing belief trackers mainly depend supervised learning human annotations belief states every user utterance. However, collecting turn-level annotations labor-intensive time-consuming, often requires domain knowledge identify slots correctly. Building E2E trainable dialog systems, called E2E dialog systems short, even magnifies demand increased amounts labeled data . % idea Notably, often easily-available unlabeled dialog data customers trained human agents accumulated real-world customer services. In paper, interested reducing reliance belief state annotations building E2E task-oriented dialog systems, leveraging unlabeled dialog data towards semi-supervised learning. Intuitively, dialog data, even unlabeled, used enhance performance belief tracking thus benefit whole dialog system, cues user inputs system responses reveal belief states, shown Figure . %The underlying idea simple: system makes responses based belief user goals, able use system response infer corresponding belief state. %The correlation belief states system responses also reported previous works , shows learning belief tracking response generation together beneficial tasks. % mutual information % proposed model Technically, propose latent variable model task-oriented dialogs, called LAtent BElief State dialog model. The model generally consists multiple turns user inputs system responses observations, belief states latent variables. Basically, \modelname{} conditional generative model belief states system responses given user inputs, i.e. . Once built, model used infer belief states generate responses. More importantly, latent variable modeling enables us develop semi-supervised learning mix labeled unlabeled data principled variational learning framework . In manner, hope LABES model exploit cues belief tracking user inputs system responses. Furthermore, develop \modelname{}-S2S, specific model instantiation \modelname{}, employing copy-augmented Seq2Seq based conditional distributions implementing . %To leverage correlation, propose LAtent BElief State dialog model , conditional generative model models belief states system responses jointly given user inputs. %In particular, represent structured belief state discrete latent variables, e.g. sequence words defined vocabulary space. %With recent advances neural variational inference , effective methods proposed address structured latent representation learning , discrete latent variable modeling sequential inference . Inspired works, propose VI-based scheme learn latent belief states sequentially multiple dialog turns, employed unsupervised scenarios. Thus model conduct semi-supervised learning labeled unlabeled dialog data. We show advantage model compared E2E task-oriented dialog models, demonstrate effectiveness semi-supervised learning scheme three benchmark task-oriented datasets: CamRest676 , In-Car MultiWOZ across various scales domains. In supervised experiments, \modelname{}-S2S obtains state-of-the-art results CamRest676 In-Car, outperforms existing models leverage large pretrained language models MultiWOZ. In utilizing unlabeled dialog data, semi-supervised \modelname{}-S2S significantly outperforms supervised-only prior semi-supervised baselines. Remarkably, reduce annotation requirements 50\% without performance loss MultiWOZ, equivalent saving around 30,000 annotations."," 		%濞存粣绠戠槐閬嶆晬鐏炲墽澹岄柟璇″枟閸ㄦ粓鎯冮崚鐞籺ro闁挎稑濂旈幈銊╁绩鐟欏嫭鍠呴悷 		Structured belief states are crucial for user goal tracking and database query in task-oriented dialog systems. However, training belief trackers often requires expensive turn-level annotations of every user utterance. 		In this paper we aim at alleviating the reliance on belief state labels in building end-to-end dialog systems, by leveraging unlabeled dialog data towards semi-supervised learning. 		We propose a probabilistic dialog model, called the LAtent BElief State  model, where belief states are represented as discrete latent variables and jointly modeled with system responses given user inputs. 		Such latent variable modeling enables us to develop semi-supervised learning under the principled variational learning framework. 		Furthermore, we introduce LABES-S2S, which is a copy-augmented Seq2Seq model instantiation of LABES\footnote{Code available at https://github.com/thu-spmi/LABES}. 		In supervised experiments, LABES-S2S obtains strong results on three benchmark datasets of different scales. In utilizing unlabeled dialog data, semi-supervised LABES-S2S significantly outperforms both supervised-only and semi-supervised baselines. 		Remarkably, we can reduce the annotation demands to 50\% without performance loss on MultiWOZ."
"Deep learning achieved significant successes, successes heavily rely massive annotated data. Few-Shot Learning one keys breaking shackle, commits learning new tasks examples . FSL made impressive progress many areas, computer vision . But progress FSL natural language processing much slower. One primary constraints lack unified benchmark few-shot NLP, thus new methods cannot easily compared iteratively improved. %Similar computer vision, Existing few-shot NLP researches mainly focus simple N-classification problems, text classification entity relation classification . However, one hand, works often report results constructed few-shot data, pretty inefficient results comparison thus hinders cumulative progress. On hand, simple N-classification problems cannot reflect complexity real-world NLP tasks. NLP tasks often face challenges structure prediction problems, sequence labeling parsing . More importantly, different NLP tasks often deeply related other, i.e. multi-task problems . One typical scenario complex NLP Dialogue Language Understanding problem, includes two sub-tasks: Intent Detection Slot Tagging . As multi-task problem, two sub-tasks proved strongly promote depend . One main obstacles constructing NLP FSL benchmark comes special evaluation paradigm FSL. Few-shot models usually first pre-trained data-rich domains tested unseen few-shot domains. %where pre-training test tasks need related . Thus, FSL evaluations always need lot different domains conquer result-randomness domain selection limited learning shots. But often hard gather enough domains NLP tasks. To solve this, existing works construct fake domains single dataset. They split labels training labels testing labels. Then, construct fake pre-training testing domains training testing labels respectively, testing labels unseen pre-training. Such simulation yield plenty related domains, lacks reality works label set large. Actually, splitting labels impractical many real-world NLP problems. For example Name Entity Recognition, label sets often small split . In paper, present FewJoint, novel FSL benchmark joint multi-task learning, promote FSL research NLP area. To reflect real word NLP complexities beyond simple N-classification, adopt sophisticated important NLP problem benchmark: Task-oriented Dialogue Language Understanding. Task-oriented Dialogue rising research area develops dialogue systems help users achieve goals, booking tickets. Language Understanding fundamental module Task-oriented Dialogue extracts semantic frames user utterances . It contains two sub-tasks: Intent Detection Slot Tagging. With Slot Tagging task, benchmark covers one common structure prediction problems: sequence labeling. Besides, thanks natural dependency Intent Detection Slot Tagging, benchmark embody multi-task challenge NLP problems. %Fig shows example few-shot joint language understanding. To conquer randomness make adequate evaluation, include 59 different dialogue domains real industrial API, considerable domain amount compared existing few-shot dialogue data. We also provide Few-shot Learning platform ease experiment set comparison. In summary, contribution three-fold: We present novel Few-shot learning benchmark 59 real-world domains, allows evaluating few-shot models without constructing fake domains. We propose reflect real-world NLP complexities covering structure prediction problems multi-task learning problems. We propose Few-shot Learning platform ease comparison implement few-shot methods. % \end{figure*} %"," Few-shot learning  is one of the key future steps in machine learning and has raised a lot of attention. However, in contrast to the rapid development in other domains, such as Computer Vision, the progress of FSL in Nature Language Processing  is much slower.  One of the key reasons for this is the lacking of public benchmarks.  NLP FSL researches always report new results on their own constructed few-shot datasets, which is pretty inefficient in results comparison and thus impedes cumulative progress. In this paper, we present FewJoint, a novel Few-Shot Learning benchmark for NLP.  Different from most NLP FSL research that only focus on simple N-classification problems, our benchmark introduces few-shot joint dialogue language understanding, which additionally covers the structure prediction and multi-task reliance problems.  This allows our benchmark to reflect the real-word NLP complexity beyond simple N-classification.  Our benchmark is used in the few-shot learning contest of SMP2020-ECDT task-1.\footnote{The Eighth China National Conference on Social Media Processing. Link: \url{https://smp2020.aconf.cn/smp.html}}  We also provide a compatible FSL platform to ease experiment set-up.\footnote{The dataset and platform is available at \url{https://github.com/AtmaHou/MetaDialog}}"
"Event coreference resolution aims identify event mentions document refer event . For example, two event mentions Figure , departing leave, refer EndPosition event Nokia's CEO. Traditional event coreference resolution methods usually rely series upstream components , entity recognition event detection. Such pipeline framework, unfortunately, often suffers error propagation problem. For instance, best event detection system KBP 2017 achieved 56 F1 , undoubtedly limit performance follow-up event coreference task . Furthermore, previous approaches use hand-crafted features , heavily depend NLP components thus hard generalize new languages/domains/datasets. In paper, propose End-to-End Event Coreference method -- neural network, predict event chains raw text end-to-end manner. For example, taking raw text Figure input, directly output two event coreference chains, \{departing, leave, goodbye\} \{rejoin\}. By jointly modeling event detection event coreference, neural network require prior components, representations/pieces evidence different tasks different decisions shared reinforced. Besides, learned end-to-end manner, inherently resolve error propagation problem. End-to-end event coreference, however, challenging due mention diversity long-distance coreference. First, event mentions highly diversified , may variety syntactic objects, including nouns, verbs, even adjectives. For example, EndPosition event triggered departing, leave, goodbye former. By contrast, mentions entity coreference mostly noun phrases . Second, coreferential event mentions commonly appear long-distance sentences, therefore event coreference intricately governed long-distance, semantic-dependent decisions . For example, Figure closest antecedent\footnote{In paper, antecedents coreferential mentions appear earlier document.} mention goodbye -- leave, far it. To resolve coreference two distant, diverse event mentions, system rely semantic meanings, i.e., describe EndPosition event different perspectives. By contrast, entity mentions' closest antecedents immediately preceding sentence , resolved easily using local syntactic clues. To resolve mention diversity problem long-distance coreference problem, paper proposes type-guided mechanism neural network. This mechanism bridges distant, diverse event mentions exploiting event type information three folds: 1) type-informed antecedent network enables capture semantic information event mentions predicting coreferential scores type scores simultaneously; 2) type-refined mention representation enhances mention representation type information, therefore even lexically dissimilar mentions bridged together, two diverse EndPosition mentions goodbye departing; 3) type-guided decoding algorithm exploit global type consistency accurate event chains. The main contributions paper are: 1. We propose end-to-end neural network event coreference resolution 閳- neural network. jointly model event detection event coreference, learn automatically extract features raw text. To best knowledge, first end-to-end neural event coreference model achieve state-of-the-art performance. 2. We design type-guided mechanism event coreference, effectively resolve mention diversity problem long-distance coreference problem event coreference resolution. 3. We conduct experiments two standard datasets: KBP 2016 KBP 2017, show achieves new state-of-the-art performance. And additional ablation experiments verify effectiveness proposed type-guided mechanism.","   Traditional event coreference systems usually rely on pipeline framework and hand-crafted features, which often face error propagation problem and have poor generalization ability.   In this paper, we propose an End-to-End Event Coreference approach -- $\text{E}^{3}\text{C}$ neural network, which can jointly model event detection and event coreference resolution tasks, and learn to extract features from raw text automatically.   Furthermore, because event mentions are highly diversified and event coreference is intricately governed by long-distance, semantic-dependent decisions, a type-guided event coreference mechanism is further proposed in our $\text{E}^{3}\text{C}$ neural network.   Experiments show that our method achieves new state-of-the-art performance on two standard datasets."
"Sequence labeling assigns token label sequence. Tasks Named Entity Recognition , Part-Of-Speech tagging chunking formulated sequence labeling tasks. BiLSTM-CRF one successful neural sequence labeling architectures. It feeds pretrained word representations single layer bi-directional LSTM encoder extract contextual features feeds features CRF decoder layer produce final predictions. The CRF layer linear-chain structure models relation neighboring labels. In traditional CRF approach, exact probabilistic inference algorithms forward-backward Viterbi algorithms applied training prediction respectively. %The Viterbi algorithm applied exactly find best label sequence inference forward-backward algorithm applied compute posterior marginal distributions exactly position training. In many sequence labeling tasks, CRF layer leads better results simpler method predicting label independently. In practice, sometimes require fast sequence labelers training prediction . The BiLSTM encoder CRF layer contain sequential computation require time input words even parallelized GPU. A common practice improve speed encoder replace BiLSTM CNN structure , distill larger encoders smaller ones settings . The CRF layer, however, difficult replace superior accuracy compared faster alternatives many tasks. %More recently, \citet{cui-zhang-2019-hierarchically} proposed BiLSTM-LAN replace CRF layer, lower time complexity, network introduces 3 additional LSTM layers require sequential computations. The CRF layer still necessary better accuracy many tasks, limits speed. % showed algorithm unfolded RNN grid-structure, expand work sequence structure unfold MFVI algorithm RNN In order achieve sublinear time complexity CRF layer, must parallelize CRF prediction tokens. In paper, apply Mean-Field Variational Inference approximately decode linear-chain CRF. MFVI iteratively passes messages among neighboring labels update distributions locally. Unlike exact probabilistic inference algorithms, MFVI parallelized different positions sequence, achieving time complexity constant full parallelization. %Similar \citet{zheng2015conditional}, show algorithm unfolded RNN, Previous work showed algorithm unfolded RNN grid CRF structure. We expand work linear-chain CRF structure unfold algorithm RNN connected encoder form end-to-end neural network amenable parallelization training prediction. We call unfolded RNN approximate inference network . In addition linear-chain CRFs, also apply AIN factorized second-order CRF models, consider relations neighboring labels. Our empirical results show AIN significantly improves speed achieves competitive accuracy traditional CRF approach 4 tasks 15 datasets."," %with pretrained word embeddings and contextual feature extractors such as RNN or CNN  The linear-chain Conditional Random Field  model is one of the most widely-used neural sequence labeling approaches. Exact probabilistic inference algorithms such as the forward-backward and Viterbi algorithms are typically applied in training and prediction stages of the CRF model. However, these algorithms require sequential computation that makes parallelization impossible. In this paper, we propose to employ a parallelizable approximate variational inference algorithm for the CRF model. Based on this algorithm, we design an approximate inference network that can be connected with the encoder of the neural CRF model to form an end-to-end network, which is amenable to parallelization for faster training and prediction. The empirical results show that our proposed approaches achieve a 12.7-fold improvement in decoding speed with long sentences and a competitive accuracy compared with the traditional CRF approach."
"Neural Machine Translation established encoder-decoder framework, encoder takes source sentence input encodes fixed-length embedding vector, decoder generates translation sentence according encoder embedding, achieved advanced translation performance recent years . So far, despite big advance model architecture, models keep taking standard assumption translate every sentence independently, ignoring implicit explicit sentence correlation document-level contextual clues translation. % 1 涓轰粈涔圖ocument鍦∟MT涓噸瑕侊紝璇存槑浣犵殑璇鹃鏈夋剰涔夈 However, document-level information shown helpful improving translation performance multiple aspects: consistency, disambiguation, coherence . If translating every sentence completely independent document-level context, difficult keep every sentence translations across entire document consistent other. Moreover, even sentence independent translation may still benefit document-level clues effectively disambiguating words referring multiple sentence contexts. At last, document-level clues kind global information across entire text may effectively help generate coherent translation results compared way adopting local information inside sentence alone. % 2 宸叉湁鏂规硶濡備綍鍒╃敤Document锛屾湁浣曚紭缂虹偣銆傝繖閲屽彲浠ョ畝瑕佷粙缁嶅凡鏈夋柟娉曪紝涓嶇敤鍏紡銆% %% 銆愬彲浠ラ厡鎯呬慨鏀瑰垹鍑忋 There recent attempts introduce document-level information existing standard NMT models. Various existing methods focus modeling context surrounding text addition source sentence. For high-level context, \citet{miculicich2018han} propose multi-head hierarchical attention machine translation model capture word-level sentence-level information. The cache-based model raised \citet{kuang2018cache} uses dynamic cache topic cache capture inter-sentence connection. \citet{tan-etal-2019-hierarchical} integrate proposed Hierarchical Modeling Global Document Context model original Transformer model improve document-level translation. % 3 閽堝宸叉湁鏂规硶鐨勭己鐐癸紝鏈枃鎻愬嚭涓绉峏XX鏂规硶锛岀壒鐐瑰拰浼樼偣鏄粈涔 % 鍙叧娉ㄥ叏灞鎴栬呭眬閮ㄧ殑淇℃伅锛屾病鏈夌患鍚堣冭檻 However, existing document-level NMT methods focus introducing information disambiguating global document surrounding sentences fail comprehend relationship among current sentence, global document information, local document information, let alone refined global document-level clues. In way, proposed model focus relevant part concerned translation exactly encodes related document-level context. The empirical results indicate proposed method significantly improves BLEU score compared strong Transformer baseline performs better related models document-level machine translation multiple tasks."," Standard neural machine translation  is on the assumption of document-level context independent. Most existing document-level NMT methods are satisfied with a smattering sense of brief document-level information, while this work focuses on exploiting detailed document-level context in terms of multiple forms of document embeddings, which is capable of sufficiently modeling deeper and richer document-level context. The proposed document-aware NMT is implemented to enhance the Transformer baseline by introducing both global and local document-level clues on the source end. Experiments show that the proposed method significantly improves the translation performance over strong baselines and other related studies."
"Historically, metrics evaluating quality machine translation relied assessing similarity MT-generated hypothesis human-generated reference translation target language. Traditional metrics focused basic, lexical-level features counting number matching n-grams MT hypothesis reference translation. Metrics {\sc Bleu} {\sc Meteor} remain popular means evaluating MT systems due light-weight fast computation. Modern neural approaches MT result much higher quality translation often deviates monotonic lexical transfer languages. %A single reference translation might always sufficient accommodate expressiveness translations. For reason, become increasingly evident longer rely metrics {\sc Bleu} provide accurate estimate quality MT . While increased research interest neural methods training MT models systems resulted recent, dramatic improvement MT quality, MT evaluation fallen behind. The MT research community still relies largely outdated metrics new, widely-adopted standard emerged. In 2019, WMT News Translation Shared Task received total 153 MT system submissions . The Metrics Shared Task year saw 24 submissions, almost half entrants Quality Estimation Shared Task, adapted metrics . The findings above-mentioned task highlight two major challenges MT evaluation seek address herein . Namely, current metrics struggle accurately correlate human judgement segment level fail adequately differentiate highest performing MT systems. %The findings Metrics Shared Task highlight segment-level evaluation strong neural MT systems major challenges, none submitted metrics achieving satisfactory levels correlation human judgements . In paper, present {\sc Comet}\footnote{Crosslingual Optimized Metric Evaluation Translation.}, PyTorch-based framework training highly multilingual adaptable MT evaluation models function metrics. Our framework takes advantage recent breakthroughs cross-lingual language modeling generate prediction estimates human judgments Direct Assessments , Human-mediated Translation Edit Rate metrics compliant Multidimensional Quality Metric framework . Inspired recent work Quality Estimation demonstrated possible achieve high levels correlation human judgements even without reference translation , propose novel approach incorporating source-language input MT evaluation models. Traditionally QE models made use source input, whereas MT evaluation metrics rely instead reference translation. As , show using multilingual embedding space allows us leverage information three inputs demonstrate value added source input MT evaluation models. To illustrate effectiveness flexibility {\sc Comet} framework, train three models estimate different types human judgements show promising progress towards better correlation segment level robustness high-quality MT. %The rest paper organized follows. Section presents overview related literature. Section describes corpora used. Section describes different model architectures training regimes. Section describes conducted experiments evaluation metrics. Section reports corresponding results achieved. Finally, Section presents relevant conclusions, pinpoints possible future directions. We release {\sc Comet} framework trained MT evaluation models described paper research community upon publication."," We present {\sc Comet}, a neural framework for training multilingual machine translation evaluation models which obtains new state-of-the-art levels of correlation with human judgements. Our framework leverages recent breakthroughs in cross-lingual pretrained language modeling resulting in highly multilingual and adaptable MT evaluation models that exploit information from both the source input and a target-language reference translation in order to more accurately predict MT quality. To showcase our framework, we train three models with different types of human judgements: Direct Assessments, Human-mediated Translation Edit Rate and Multidimensional Quality Metrics. Our models achieve new state-of-the-art performance on the WMT 2019 Metrics shared task and demonstrate robustness to high-performing systems. %Furthermore, they show promising results towards solving the current challenges of accurate segment-level evaluation and robustness to top performing systems."
"Aspect detection, vital component aspect-based sentiment analysis , aims identifying predefined aspect categories discussed segments online reviews. Table shows example review television several different aspects, Image, Sound, Ease Use. With large number reviews, automatic aspect detection allows people efficiently retrieve review segments aspects interested in. It also benefits many downstream tasks, review summarization recommendation justification . } \end{table} There several research directions aspect detection. Supervised approaches leverage annotated labels aspect categories suffer domain adaptation problems . Another research direction consists unsupervised approaches gained lot attention recent years. Early unsupervised systems dominated Latent Dirichlet Allocation based topic models . However, several recent studies revealed LDA-based approaches perform well aspect detection extracted aspects poor quality . Compared LDA-based approaches, deep learning models, aspect-based autoencoder , shown excellent performance extracting coherent aspects identifying aspect categories review segments. However, models require human effort manually map model discovered aspects aspects interest, may lead inaccuracies mapping especially model discovered aspects noisy. Another research direction based weakly supervised approaches leverage small number aspect representative words fine-grained aspect detection . Although models outperform unsupervised approaches, make use human annotated data extract high-quality aspect seed words, may limit application. In addition, able automatically discover new aspects review corpus. We focus problem unsupervised aspect detection since massive amount reviews generated every day many newer products. It difficult humans efficiently capture new aspects manually annotate segments scale. Motivated ABAE, learn interpretable aspects mapping aspect embeddings word embedding space, aspects interpreted nearest words. To learn better representations aspects review segments, formulate UAD self-supervised representation learning problem solve using contrastive learning algorithm, inspired success self-supervised contrastive learning visual representations . In addition learning algorithm, also resolve two problems deteriorate performance ABAE, including self-attention mechanism segment representations aspect mapping strategy . Finally, discover quality aspect detection improved knowledge distillation . The contributions paper summarized follows: % } % % % \end{table} \def\year{2021}\relax %File: formatting-instructions-latex-2021.tex %release 2021.1 \documentclass[letterpaper]{article} % DO NOT CHANGE THIS \usepackage{aaai21} % DO NOT CHANGE THIS \usepackage{times} % DO NOT CHANGE THIS \usepackage{helvet} % DO NOT CHANGE THIS \usepackage{courier} % DO NOT CHANGE THIS \usepackage[hyphens]{url} % DO NOT CHANGE THIS \usepackage{graphicx} % DO NOT CHANGE THIS \urlstyle{rm} % DO NOT CHANGE THIS \def\UrlFont{\rm} % DO NOT CHANGE THIS \usepackage{natbib} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \frenchspacing % DO NOT CHANGE THIS \setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS \setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS %new added start \usepackage{booktabs} \usepackage{footnote} \usepackage{amsmath,amssymb,mathrsfs} \usepackage[ruled,linesnumbered]{algorithm2e} \usepackage{epstopdf} \usepackage{multirow} \usepackage[skip=0pt]{subcaption} \usepackage{soul} \usepackage{tabularx} \renewcommand\tabularxcolumn[1]{m{#1}} \usepackage{enumitem} \renewcommand\vec[1]{\overrightarrow{#1}} \newcommand\cev[1]{\overleftarrow{#1}} \newcommand{\etal}{et~al.} \usepackage{microtype} \usepackage[switch]{lineno} %new added end %\nocopyright %PDF Info Is REQUIRED. % For /Author, add authors within parentheses, separated commas. No accents commands. % For /Title, add Title Mixed Case. No accents commands. Retain parentheses. \pdfinfo{ /Title /Author /TemplateVersion } %Leave % /Title % Put actual complete title within parentheses mixed case % Leave space \Title beginning parenthesis alone % /Author % Put actual complete list authors within parentheses mixed case. % Each author comma. If name contains accents, remove them. If LaTeX commands, % remove them. % DISALLOWED PACKAGES % \usepackage{authblk} -- This package specifically forbidden % \usepackage{balance} -- This package specifically forbidden % \usepackage{color % \usepackage{CJK} -- This package specifically forbidden % \usepackage{float} -- This package specifically forbidden % \usepackage{flushend} -- This package specifically forbidden % \usepackage{fontenc} -- This package specifically forbidden % \usepackage{fullpage} -- This package specifically forbidden % \usepackage{geometry} -- This package specifically forbidden % \usepackage{grffile} -- This package specifically forbidden % \usepackage{hyperref} -- This package specifically forbidden % \usepackage{navigator} -- This package specifically forbidden % % \indentfirst} -- This package specifically forbidden % \layout} -- This package specifically forbidden % \multicol} -- This package specifically forbidden % \nameref} -- This package specifically forbidden % \usepackage{savetrees} -- This package specifically forbidden % \usepackage{setspace} -- This package specifically forbidden % \usepackage{stfloats} -- This package specifically forbidden % \usepackage{tabu} -- This package specifically forbidden % \usepackage{titlesec} -- This package specifically forbidden % \usepackage{tocbibind} -- This package specifically forbidden % \usepackage{ulem} -- This package specifically forbidden % \usepackage{wrapfig} -- This package specifically forbidden % DISALLOWED COMMANDS % \nocopyright -- Your paper published use command % \addtolength -- This command may used % \balance -- This command may used % \baselinestretch -- Your paper published use command % \clearpage -- No page breaks kind may used final version paper % \columnsep -- This command may used % \newpage -- No page breaks kind may used final version paper % \pagebreak -- No page breaks kind may used final version paperr % \pagestyle -- This command may used % \tiny -- This acceptable font size. % {0} %May changed 1 2 section numbers desired. % The file aaai21.sty style file AAAI Press % proceedings, working notes, technical reports. % % Title % Your title must mixed case, sentence case. % That means verbs , % nouns, adverbs, adjectives capitalized, including words hyphenated terms, % articles, conjunctions, prepositions lower case unless % directly follow colon long dash \title{A Simple Effective Self-Supervised Contrastive Learning Framework\\ Aspect Detection} \author{ %Authors % All authors must font size format. Tian Shi\textsuperscript{\rm 1}, Liuqing Li\textsuperscript{\rm 2}, Ping Wang\textsuperscript{\rm 1}, Chandan K. Reddy\textsuperscript{\rm 1}\\ } \affiliations{ %Afiliations \textsuperscript{\rm 1}Department Computer Science, Virginia Tech\\ \textsuperscript{\rm 2}Verizon Media\\ tshi@vt.edu, liuqing.li@verizonmedia.com, ping@vt.edu, reddy@cs.vt.edu % See examples next } \iffalse %Example, Single Author, ->> remove \iffalse,\fi place surrounding AAAI title use \title{My Publication Title --- Single Author} \author { % Author Author Name \\ } \affiliations{ Affiliation \\ Affiliation Line 2 \\ name@example.com } \fi \iffalse %Example, Multiple Authors, ->> remove \iffalse,\fi place surrounding AAAI title use \title{My Publication Title --- Multiple Authors} \author { % Authors First Author Name,\textsuperscript{\rm 1} Second Author Name, \textsuperscript{\rm 2} Third Author Name \textsuperscript{\rm 1} \\ } \affiliations { % Affiliations \textsuperscript{\rm 1} Affiliation 1 \\ \textsuperscript{\rm 2} Affiliation 2 \\ firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com } \fi"," Unsupervised aspect detection  aims at automatically extracting interpretable aspects and identifying aspect-specific segments  from online reviews. However, recent deep learning based topic models, specifically aspect-based autoencoder, suffer from several problems such as extracting noisy aspects and poorly mapping aspects discovered by models to the aspects of interest. To tackle these challenges, in this paper, we first propose a self-supervised contrastive learning framework and an attention-based model equipped with a novel smooth self-attention  module for the UAD task in order to learn better representations for aspects and review segments. Secondly, we introduce a high-resolution selective mapping  method to efficiently assign aspects discovered by the model to the aspects of interest. We also propose using a knowledge distillation technique to further improve the aspect detection performance. Our methods outperform several recent unsupervised and weakly supervised approaches on publicly available benchmark user review datasets. Aspect interpretation results show that extracted aspects are meaningful, have a good coverage, and can be easily mapped to aspects of interest. Ablation studies and attention weight visualization also demonstrate effectiveness of SSA and the knowledge distillation method."
"There several recent studies aim predict aspect ratings using deep neural network based models multi-task learning framework . In setting, rating predictions different aspects, typically highly correlated share review encoder, treated different tasks. However, models rely hand-crafted aspect keywords aid rating/sentiment predictions . Thus, results, especially case studies reviews, biased towards pre-defined aspect keywords. In addition, models focus improving prediction accuracy, however, knowledge discovery review corpus still relies unsupervised rule-based methods , limits applications current MARP models . In past years, model uncertainty deep neural network classifiers received increasing attention , identify low-confidence regions input space give reliable predictions. Uncertainty models also applied deep neural networks text classification . However, existing uncertainty methods used improve overall prediction accuracy multi-task learning models crowd-sourcing annotation involved MARP task. In paper, attempt tackle mentioned issues. The primary contributions paper follows: The rest paper organized follows: In Section , introduce related work MARP task uncertainty estimation methods. In Section , present details proposed FEDAR model, AKR method LEAD uncertainty estimation approach. In Section , introduce different MARP datasets, baseline methods implementation details, well analyze experimental results. Our discussion concludes Section.%% %% This file `sample-sigconf.tex', %% generated docstrip utility. %% %% The original source files were: %% %% samples.dtx %% %% IMPORTANT NOTICE: %% %% For copyright see source file. %% %% Any modified versions file must renamed %% new filenames distinct sample-sigconf.tex. %% %% For distribution original source see terms %% copying modification file samples.dtx. %% %% This generated file may distributed long %% original source files, listed above, part %% distribution. %% %% The first command LaTeX source must \documentclass command. \documentclass[sigconf]{acmart} \usepackage{amsmath,amssymb,multicol,mathrsfs} \usepackage[ruled,linesnumbered]{algorithm2e} \usepackage{graphicx} \usepackage{balance} \usepackage{epstopdf} \usepackage{multirow} \usepackage{color,soul} \usepackage{tabularx} \renewcommand\tabularxcolumn[1]{m{#1}} \usepackage[normalem]{ulem} \usepackage{enumitem} \setlist{leftmargin=5.5mm} \usepackage{flushend} \usepackage{tikz} \usepackage{pgf} \usepackage[eulergreek]{sansmath} \usepackage{graphicx} \usepackage{subcaption} \renewcommand\vec[1]{\overrightarrow{#1}} \newcommand\cev[1]{\overleftarrow{#1}} \newcommand{\etal}{et~al. } \usepackage{url} \newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}} %%%% As March 2017, [siggraph] longer used. Please use sigconf SIGGRAPH conferences. %%%% As May 2020, [sigchi] [sigchi-a] longer used. Please use sigconf SIGCHI conferences. %%%% Proceedings format SIGPLAN conferences % \documentclass[sigplan, anonymous, review]{acmart} %%%% Proceedings format conferences using one-column small layout % \documentclass[acmsmall,review]{acmart} %% %% \BibTeX command typeset BibTeX logo docs \AtBeginDocument{% \providecommand\BibTeX{{% \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}} %% Rights management information. This information sent %% complete rights form. These commands SAMPLE %% values them; responsibility author replace %% commands values provided %% complete rights form. \setcopyright{acmcopyright} \copyrightyear{2018} \acmYear{2018} \acmDOI{10.1145/1122445.1122456} %% These commands PROCEEDINGS abstract paper. \acmConference[]{}{}{} \acmBooktitle{} \acmPrice{15.00} \acmISBN{978-1-4503-XXXX-X/18/06} %% %% Submission ID. %% Use submitting article sponsored event. You'll %% receive unique submission ID organizers %% event, ID used parameter command. %%\acmSubmissionID{123-A56-BU3} %% %% The majority ACM publications use numbered citations %% references. The command \citestyle{authoryear} switches %% ""author year"" style. %% %% If preparing content event %% sponsored ACM SIGGRAPH, must use ""author year"" style %% citations references. %% Uncommenting %% next command enable style. %%\citestyle{acmauthoryear} %% %% end preamble, start body document source. %% %% The code generated tool http://dl.acm.org/ccs.cfm. %% Please copy paste code instead example below. %% \ccsdesc[500]{Information systems~Sentiment analysis} \ccsdesc[500]{Information systems~Clustering classification} \ccsdesc[300]{Information systems~Information extraction} %% %% Keywords. The author pick words accurately describe %% work presented. Separate keywords commas. \keywords{Multi-task learning, model uncertainty, deep neural network, dropout, classification, online reviews} %% A ""teaser"" image appears author affiliation %% information body document, typically spans %% page. % %% %% This command processes author affiliation title %% information builds first part formatted document. %% %% The acknowledgments section defined using ""acks"" environment %% . This ensures proper %% identification section article metadata, %% consistent spelling heading. % \newpage \balance %% %% The next two lines define bibliography style used, %% bibliography file. \bibliographystyle{ACM-Reference-Format} \bibliography{ref} \end{document} \endinput %% %% End file `sample-sigconf.tex'.","  In recent years, several online platforms have seen a rapid increase in the number of review systems that request users to provide aspect-level feedback. Multi-Aspect Rating Prediction , where the goal is to predict the ratings from a review at an individual aspect level, has become a challenging and an imminent problem. To tackle this challenge, we propose a deliberate self-attention deep neural network model, named as FEDAR, for the MARP problem, which can achieve competitive performance while also being able to interpret the predictions made. As opposed to the previous studies, which make use of hand-crafted keywords to determine aspects in sentiment predictions, our model does not suffer from human bias issues since aspect keywords are automatically detected through a self-attention mechanism. FEDAR is equipped with a highway word embedding layer to transfer knowledge from pre-trained word embeddings, an RNN encoder layer with output features enriched by pooling and factorization techniques, and a deliberate self-attention layer. In addition, we also propose an Attention-driven Keywords Ranking  method, which can automatically extract aspect-level sentiment-related keywords from the review corpus based on the attention weights. Since crowdsourcing annotation can be an alternate way to recover missing ratings of reviews, we propose a LEcture-AuDience  strategy to estimate model uncertainty in the context of multi-task learning, so that valuable human resources can focus on the most uncertain predictions. Our extensive set of experiments on different DMSC datasets demonstrate the superiority of the proposed FEDAR and LEAD models. Visualization of aspect-level sentiment keywords demonstrate the interpretability of our model and effectiveness of our AKR method."
"% However, gap machine translation systems human translators needs manually closed post-editing. % The recent success deep learning algorithms heavily relies increasing availability crowdsourcing services either data annotations human evaluations, ImageNet dataset Amazon Mechanical Turk. % Through power crowd, data requesters expect obtain large amounts data relatively low cost. % However, growing demand quality data requires technical expertise. % For example, cornerstone multilingual researches natural language processing typically lies multilingual paralleled corpus. % Post-editing crowdsourcing efficient way produce high-quality translations. % However, de facto demanding human intelligence generally requires crowdsourcing participants educated certain ability language translation, consequently leads substantial increase spent expense elapsed time. The explosive advances sequence sequence model enable deep learning based neural machine translation approximate even achieve human parity specific language pairs scenarios. Instead translating scratch human translators, new translation paradigm emerged: computer assisted translation system, includes machine translation human post-editing. The post-editing process whereby humans amend machine-generated translations achieve acceptable final product. %, necessarily reference generated another human translator. Practically, estimated average translation time reduced 17.4\% . However, utilizing NMT poses two key challenges. First, neural machine translation quality still continues vary great deal across different domains genres, less proportion availability paralleled training corpora. % Many experiments show large scale in-domain data boost performance NMT . Second, zero tolerance policy common choice vast majority important applications. For example, business legal documents translated, even single incorrect word could bring serious financial property losses. Therefore, subsequent human post-editing indispensable situations like this. Unfortunately, NMT systems saves time providing preliminary translations, time spent error corrections humans remains substantial extent offsets efficiency gained NMT systems. In paper, explore automatic post-editing deep learning framework. Specifically, adopt imitation learning approach, model first screens translation candidates quality prediction decides whether post edit generation atomic operation method. % Figure demonstrates example system atomic operation post-editing, quality estimation step illustrates errors found original machine translation APE step proceeds proposed corrections. % The benefits crowdsourcing system faster error detection automatic QE system faster error correction automatic correction suggestion system. % In pilot system one shown Figure, observe improved human efficiency aid automatic systems especially systems produce top-quality error corrections, requiring actions human. Starting wide range features used CAT system, carefully analyze human post-editing results narrow framework design three key modules: quality estimation , generative post-editing atomic operation post-editing. These modules tightly integrated transformer neural networks . Our main innovation % adaptive crowdsourcing system two modular post-editing algorithms either independently conditionally used. hierarchical model two modular post-editing algorithms conditionally used based novel fine-grained quality estimation model. % In iteration f For machine translation, %the system model i) runs QE model predict detailed token level errors, summarized overall quality score decide whether machine translation quality high not, ii) conditional previous decision, employs atomic operation post-editing algorithm high quality sentence generative model rephrase translation low one. We examine approach public English--German dataset WMT 2017 APE shared task. Our system outperforms top ranked methods BLEU TER metrics. In addition, following standard human evaluation process aimed achieving impartiality respect efficiency CAT system, ask several certified translators edit machine translation outputs without APE assistance. Evaluation results show system significantly improves translators' efficiency."," % Text translation is a difficult and expensive task in crowdsourcing, since it requires the expertise of at least two languages.  With the advent of neural machine translation, there has been a marked shift towards leveraging and consuming the machine translation results.  However, the gap between machine translation systems and human translators needs to be manually closed by post-editing.  In this paper, we propose an end-to-end deep learning framework of %as a computer assisted crowdsourcing system for  the quality estimation and automatic post-editing of the machine translation output.  Our goal is to provide error correction suggestions and to further relieve the burden of human translators through an interpretable model.  To imitate the behavior of human translators, we design three efficient delegation modules -- quality estimation, generative post-editing, and atomic operation post-editing and construct a hierarchical model based on them.  %When the quality estimation model predicts the translation to be poor, the generative post-editing module is called to completely rephrase the translation.  % In contrast, the translation quality is high, the output only needs several atomic operations, such as deletion, insertion, or substitution.  We examine this approach with the English--German dataset from WMT 2017 APE shared task and our experimental results can achieve the state-of-the-art performance.  We also verify that the certified translators can significantly expedite their post-editing processing with our model in human evaluation."
"Recent advances deep learning led significant improvement Neural Machine Translation . Particularly, performance sentence-level translation low- high- resource language pairs dramatically improved . However, translating text long-range dependencies, conversations documents, original mode translating one sentence time ignores discourse phenomena , introducing undesirable behaviors inconsistent pronouns across different translated sentences. Document-level NMT, realistic translation task scenarios, systematically investigated machine translation community. Most literatures focused looking back fixed number previous source target sentences document-level context . Some latest works innovatively attempted either get entire document context dynamically select suitable context . Because scarcity document training data, benefit gained approach, reflected BLEU, usually limited. We therefore elect pay attention context previous sentences small number usually cover entire document. Almost latest studies chose standard transformer model baseline translates sentence document model trained sentence-level data. The cohesion consistency general poor. A reasonable baseline train transformer context prepended, modification could simply implemented via data preprocessing. \citet{bawden2018evaluating} conducted detailed analysis RNN-based NMT models topic whether include extended context. Consistency precision often viewed trade-off other. We conduct detailed analysis effect document context consistency transformer architecture accepting multi-sentence input. When comes leveraging contextual information, common approach model interaction sentence context specially designed attention modules . Such works tend include one encoder decoder, substantial number parameters additional computations. In work, reduce contextual regular attention modules one single encoder decoder. Our idea motivated one transformer decoder two-stream self-attention . % In particular, maintain two different sets hidden states employ two different masking matrices capture long short term dependencies. The contributions paper threefold: i) extensively research performance standard transformer setting multi-sentence input output; ii) propose simple effective modification adapting transformer document NMT aim ameliorating effect error accumulation; iii) experiments demonstrate even simple baseline achieve comparable results."," Many document-level neural machine translation  systems have explored the utility of context-aware architecture, usually requiring an increasing number of parameters and computational complexity.  However, few attention is paid to the baseline model.  In this paper, we research extensively the pros and cons of the standard transformer in document-level translation, and find that the auto-regressive property can simultaneously bring both the advantage of the consistency and the disadvantage of error accumulation.  Therefore, we propose a surprisingly simple long-short term masking self-attention on top of the standard transformer to both effectively capture the long-range dependence and reduce the propagation of errors.  We examine our approach on the two publicly available document-level datasets.  We can achieve a strong result in BLEU and capture discourse phenomena."
"Response generation dialogue systems stimulated great interests researchers recently . The core idea dialogue generation formulate task sequence translation problem translate query response. One common neural model sequence-to-sequence encoder-decoder framework. Many approaches proposed improve basic S2S model better human-computer conversation performance. Despite popularity, approaches assume training sample, namely, query-response pair, contributes equally model ignore consideration different response quality contrastively. Table depicts example responses particular query dialogue dataset. Both first second response relevant query first one obviously better considering informativeness interestingness. The third response acceptable conversation quite universal, meaning that, also used answer queries. Thus, quality good first two responses. The fourth response poor since directly copies part query. Although fourth response acceptable, still better compared fifth response, completely irrelevant query. & \multirow{2}{*}{Relevant interesting} \\ & Although rains inconvenient, sunny day better rainy day since I afraid sun. & \\ \cline{2-3} & & \multirow{2}{*}{Relevant simple}. \\ & I hate rainy days! & \\ \cline{2-3} & & \multirow{2}{*}{Acceptable universal} \\ It started rain & Are Qingdao Guangzhou now? & \\ \cline{2-3} & & \multirow{2}{*}{Quiet boring} \\ & Yes, rains again. & \\ \cline{2-3} & & \multirow{2}{*}{Irrelevant} \\ & The university near martyrs cemetery. & \\ %\piji{DO NOT show kind informaitn} \Xhline{3\arrayrulewidth} \end{tabular}} \end{table} Some initial attempts conducted consider quality training data. Following idea instance weighting, pre-train calibration network calculate response quality score training sample update model weighted combination sample loss. Similarly, estimate instance score based corpus-level n-gram co-occurrence length response. Both simple implement still limitations: The calibration network trained relevant responses irrelevant responses queries therefore cannot capture fine-grained response quality, exemplified Table; The instance weighting strategy treats tokens response equal importance query assigning quality score, may erroneously encourage generation uninformative words relevant responses . To tackle issues mentioned above, introduce Contrastive Learning paradigm model multi-level fine-grained quality responses respect query. Specifically, develop Rank-aware Calibration network aiming modeling fine-grained quality characterizing response properties affect conversation experience multi-scale response quality score. The rank-aware calibrator adopts strategies pointwise regression pairwise ranking gauging quality query-response pair. Besides, address second limitation aforementioned, design exquisite strategy consider different importance tokens instead simply scaling training sample loss response-level quality score. Concretely, propose conditionally sample response via Monte-Carlo Rollout gold standard response token deem quality scores sampled responses importance tokens sample loss estimation. It also observed meaningful words ``university'' ``martyrs cemetery'' fifth response Table likely receive low quality scores due irrelevance query. Thus, propose Knowledge Inference component explicitly encourage generation informative tokens gold standard responses. This component firstly associates query decoder hidden representation memories informative tokens incorporates summarized memories decoding step. In summary, contributions follows: \indent To enhance performance dialogue generation, propose multi-level contrastive learning paradigm model fine-grained quality responses respect query.\\ \indent We propose Rank-aware Calibration network construct multi-level contrastive objectives. We design strategy calibrate model training token-level quality information.\\ \indent We propose reconsider generation informative words erroneously punished calibrator via tailor-made Knowledge Inference component. \\ \indent We build dataset fine-grained response annotations conduct extensive evaluations. The experimental results validate effectiveness proposed framework. Code labelled dataset public facilitate research."," Most of the existing works for dialogue generation are data-driven models trained directly on corpora crawled from websites. They mainly focus on improving the model architecture to produce better responses but pay little attention to considering the quality of the training data contrastively. In this paper, we propose a multi-level contrastive learning paradigm to model the fine-grained quality of the responses with respect to the query. A Rank-aware Calibration  network is designed to construct the multi-level contrastive optimization objectives. Since these objectives are calculated based on the sentence level, which may erroneously encourage/suppress the generation of uninformative/informative words. To tackle this incidental issue, on one hand, we design an exquisite token-level strategy for estimating the instance loss more accurately. On the other hand, we build a Knowledge Inference  component to capture the keyword knowledge from the reference during training and exploit such information to encourage the generation of informative words. We evaluate the proposed model on a carefully annotated dialogue dataset and the results suggest that our model can generate more relevant and diverse responses compared to the baseline models."
"Knowledge Distillation popular model acceleration compression approach . It assumes lightweight network learn generalize way large network . To end, simple method train student network predicted probabilities teacher network targets. In KD, student network ``copycat'' teacher network knowledge learned teacher prediction. Rather, straightforward way transfer knowledge parameters two networks, parameters sources predictions. Such idea recently found effective pre-training fine-tuning paradigm . For example, parameters learned large-scale unlabeled data used good start train complex network target task. However, parameter reuse applicable model acceleration compression teacher student networks might different width depth\footnote{In multi-layer neural network, number neurons hidden layer referred network width, number stacked layers referred network depth.}. In paper, propose Weight Distillation transfer parameters teacher network student network. We design parameter generator model transformation teacher network parameters student network parameters, even different sized weight matrices. After that, fine-tuning process performed improve quality transferred parameters. See \fig{fig:compare} comparison KD WD. We test WD method well-tuned Transformer-based machine translation system. The experiments run three machine translation tasks, including WMT16 English-Roman , NIST12 Chinese-English , WMT14 English-German . With similar speedup, student network trained WD 0.511.82 BLEU higher KD. With similar BLEU performance, student network trained WD 1.111.39 faster KD. More interestingly, found WD effective improve student network model size close teacher network. On WMT14 En-De data, WD-based system establishes new state-of-the-art 1.88 faster big teacher network. %% predictions \node[teacher prob,minimum height=0.6cm,anchor=south] {}; \node[teacher prob,minimum height=1cm,anchor=south east] {}; \node[teacher prob,minimum height=0.8cm,anchor=south east] {}; \node[teacher prob,minimum height=0.4cm,anchor=south west] {}; \node[teacher prob,minimum height=0.2cm,anchor=south west] {}; % Student \node[student weight,anchor=west] {}; \node[font=\small,anchor=south,inner sep=0pt] {}; \node[student weight,anchor=south] {}; %% predictions \node[student prob,minimum height=0.4cm,anchor=south] {}; \node[student prob,minimum height=0.8cm,anchor=south east] {}; \node[student prob,minimum height=0.6cm,anchor=south east] {}; \node[student prob,minimum height=0.1cm,anchor=south west] {}; \node[student prob,minimum height=0.3cm,anchor=south west] {}; %% ground truth \node[ground truth prob,minimum height=0.1cm,anchor=south] {}; \node[ground truth prob,minimum height=1cm,anchor=south east] {}; \node[ground truth prob,minimum height=0.1cm,anchor=south east] {}; \node[ground truth prob,minimum height=0.1cm,anchor=south west] {}; \node[ground truth prob,minimum height=0.1cm,anchor=south west] {}; % Connections \draw[-latex',red] .. controls + + .. ; \draw[-latex',red] ; \draw[-latex,densely dashed] ; \draw[-latex,densely dashed] ; \draw[-latex,densely dashed] ; \draw[-latex,densely dashed] ; \draw[-latex,densely dashed] ; \draw[-latex,densely dashed] ; \end{tikzpicture} } \hfill \subfigure[Weight Distillation] { %% predictions \node[teacher prob,minimum height=0.6cm,anchor=south] {}; \node[teacher prob,minimum height=1cm,anchor=south east] {}; \node[teacher prob,minimum height=0.8cm,anchor=south east] {}; \node[teacher prob,minimum height=0.4cm,anchor=south west] {}; \node[teacher prob,minimum height=0.2cm,anchor=south west] {}; % Student \node[student weight,anchor=west] {}; \node[font=\small,anchor=south,inner sep=0pt] {}; \node[student weight,anchor=south] {}; %% predictions \node[student prob,minimum height=0.1cm,anchor=south] {}; \node[student prob,minimum height=0.8cm,anchor=south east] {}; \node[student prob,minimum height=0.1cm,anchor=south east] {}; \node[student prob,minimum height=0.3cm,anchor=south west] {}; \node[student prob,minimum height=0.1cm,anchor=south west] {}; %% ground truth \node[ground truth prob,minimum height=0.1cm,anchor=south] {}; \node[ground truth prob,minimum height=1cm,anchor=south east] {}; \node[ground truth prob,minimum height=0.1cm,anchor=south east] {}; \node[ground truth prob,minimum height=0.1cm,anchor=south west] {}; \node[ground truth prob,minimum height=0.1cm,anchor=south west] {}; % Parameter Generator \coordinate ; \node[pgnode] }]pgmid) {}; \node[pgnode] }]pgmid) {}; \node[pgnode] }]pgmid) {}; \node[pgnode] }]pgmid) {}; \draw[-latex,lyyblue] ; \draw[-latex,lyyblue] ; \draw[-latex,lyyblue] ; \draw[-latex,lyyblue] ; % Connections \draw[-latex',red] .. controls + + .. ; \draw[-latex',red] ; \draw[-latex',red] .. controls + + .. ; \draw[-latex',red] .. controls + + .. ; \draw[-latex',red] .. controls + + .. ; \draw[-latex',red] .. controls + + .. ; \draw[-latex',red] .. controls + + .. ; \draw[-latex,densely dashed] ; \draw[-latex,densely dashed] ; \draw[-latex,densely dashed] ; \draw[-latex,densely dashed] ; \draw[-latex,densely dashed] ; \draw[-latex,densely dashed] ; \end{tikzpicture} } \hspace*{\fill} \end{figure*}","   Knowledge distillation has been proven to be effective in model acceleration and compression. It allows a small network to learn to generalize in the same way as a large network. Recent successes in pre-training suggest the effectiveness of transferring model parameters. Inspired by this, we investigate methods of model acceleration and compression in another line of research. We propose Weight Distillation to transfer the knowledge in the large network parameters through a parameter generator. Our experiments on WMT16 En-Ro, NIST12 Zh-En, and WMT14 En-De machine translation tasks show that weight distillation can train a small network that is 1.88$\sim$2.94$\times$ faster than the large network but with competitive performance. With the same sized small network, weight distillation can outperform knowledge distillation by 0.51$\sim$1.82 BLEU points."
"% ============================================================================== The CLEVR dataset modern 3D incarnation historically significant shapes-based datasets like SHRDLU , used demonstrating AI efficacy language understanding . Although originally aimed visual question answering problem , versatility seen use diverse ML domains, including extensions physics simulation engines language augmented hierarchical reinforcement learning causal reasoning . Parallelly, research interest geometric learning GNN based techniques seen dramatic surge recent deep learning zeitgeist. In focused paper, present library allows easy integration application geometric representation learning CLEVR dataset tasks - enabling NLP research community apply GNN based techniques research . The library three main components: 1. Parser: allows extraction graph structured relationships among objects environment -- textual questions, semantic image scene graphs, 2. Embedder: allows generation latent embeddings using models desired backend choice , 3. Visualizer: provides tools visualizing structural graphs latent embeddings. % %Thus, release library, hope enable greater adoption geometric learning NLP community, lowering initial learning curve and/or rapid prototyping integration GNNs NLP research domains like language grounded RL, visual reasoning, language compositionality etc. . % =============================================================================="," The CLEVR dataset has been used extensively in language grounded visual reasoning in  Machine Learning  and Natural Language Processing  domains. We present a graph parser library for CLEVR, that provides functionalities for object-centric attributes and relationships extraction, and construction of structural graph representations for dual modalities. Structural order-invariant representations enable geometric learning and can aid in downstream tasks like language grounding to vision, robotics, compositionality, interpretability, and computational grammar construction. We provide three extensible main components -- parser, embedder, and visualizer that can be tailored to suit specific learning setups. We also provide out-of-the-box functionality for seamless integration with popular deep graph neural network  libraries. Additionally, we discuss downstream usage and applications of the library, and how it accelerates research for the NLP research community\footnote{Code is available at - \url{https://github.com/raeidsaqur/clevr-parser}}."
"Aggressive language detection aims automatically detect abusive, offensive language hate speech social media texts, one important applications Natural Language Processing , recently received increasing research attention. Yet still limited efforts paid ALD task. Current works mostly treat ALD regular text classification neural networks, e.g., Long-short Term Memory , Convolutional Neural Networks Transformer , sophisticated features, e.g., pre-trained embeddings . Nevertheless, social media texts often differ substantially written texts, is, social media texts much noisy contain typos , e.g., abbreviations, letter repetition, etc. Such characteristic unnormalized texts greatly hinder detection aggressive contents. Taking examples sentence Fig. , raw unnormalized expressions carry crucial signals indicating offensive languages, difficult detector give correct prediction merely seeing surface forms. However, unnormalized contents transformed normalized standard texts, inferences detector much easier. Based observation, paper, propose improve ALD task simultaneously handling text normalization . A multi-task learning framework adopted joint training two tasks. As depicted Fig. , first, shared encoder expected learn underlying common features two tasks, private encoders ALD TN learn task-relevant features, respectively, based decoders make task predictions. To enhance capabilities shared private feature representations, respectively, suggest adversarial training architecture . Technically, task discriminator used distinguishing separate learning ALD TN tasks. We conduct experiments four widely used ALD datasets, including TRAC , HSOL , KTC OLI , based annotated text normalization data, Lexnorm15 . Results show aggressive language detection benefit much joint learning text normalization. Our model outperforms baseline methods large margin, 64.0\% 53.6\% F1 score TRAC-FB TRAC-TW test sets, respectively, average 90.5\% F1 score three datasets. In-depth analysis performed understanding TN influences ALD task, well mechanism proposed adversarial multi-task learning framework."," Aggressive language detection , detecting the abusive and offensive language in texts, is one of the crucial applications in NLP community. Most existing works treat ALD as regular classification with neural models, while ignoring the inherent conflicts of social media text that they are quite unnormalized and irregular. In this work, we target improving the ALD by jointly performing text normalization , via an adversarial multi-task learning framework. The private encoders for ALD and TN focus on the task-specific features retrieving, respectively, and the shared encoder learns the underlying common features over two tasks. During adversarial training, a task discriminator distinguishes the separate learning of ALD or TN. Experimental results on four ALD datasets show that our model outperforms all baselines under differing settings by large margins, demonstrating the necessity of joint learning the TN with ALD. Further analysis is conducted for a better understanding of our method. \keywords{Natural language processing \and Multi-task learning \and  Aggressive language detection \and Text normalization \and Adversarial training.}"
"Deep neural networks proved vulnerable adversarial attacks, maliciously craft adversarial examples fool victim model . For instance, highly poisonous phrases minor modification easily deceive Google's toxic comment detection system . With broad use DNN-based natural language processing systems, spam filtering malware detection , growing concern security. As result, research textual adversarial attacking becomes increasingly important. %by perturbing original input In recent years plenty adversarial attack models proposed . Nevertheless, work satisfactorily real-world attack situations. Existing adversarial attack models roughly classified four categories according accessibility victim model: gradient-based, score-based, decision-based blind models. First, gradient-based models, also known white-box models, require full knowledge victim model perform gradient computation . % attack models work white-box setting , full knowledge victim model required gradient computation. Unfortunately, hardly know architecture victim model real-world attack situations, let alone compute gradients. Second, blind models need know anything victim model, attack performance usually good enough, precisely complete ignorance victim model. Specifically, existing blind models either implement character-level random perturbations conduct sentence-level distracting paraphrasing . However, character-level attacks easy repulse , sentence-level attacks cannot guarantee attack validity, i.e, keeping ground-truth label adversarial example original input. More importantly, attack success rates blind models unsatisfactory. % adversarial example quality, including grammaticality language naturality. % % inclined craft invalid adversarial examples, different ground-truth labels original input, Finally, score- decision-based attack models seem suitable real-world adversarial attack situations. They need know output victim models -- former requires prediction scores latter needs final prediction decision. % normally practicable real-world adversarial attacking situations % Attack models two kinds models seem suitable real-world situation adversarial attacking, usually able invoke victim model obtain output. Existing score- decision-based attack models achieved great attack performance , significant problem. To craft adversarial example, models iteratively make perturbations query victim model many times, e.g., recent score-based model needs query victim model times average generate adversarial example . % They utilize victim model output guidance iteratively conduct perturbations finding adversarial example . % PWWS濞屸剝婀乮teratively % Although achieving good attacking performance, models usually need invoke victim model many times, e.g., attack model \citet{zang2020word} needs invoke victim model times average attack one instance. It neither efficient practical invoke victim model many times real-world situations adversarial attacking. We argue low efficiency existing score- decision-based attack models results learning ability simply follow certain fixed optimization rules attack, e.g., greedy algorithm , genetic algorithm particle swarm optimization . % model -> score- decision-based models? % For instance, start attack scratch. % And lessons learned previous attacks. %For example, \citet{zang2020word} ? To solve problem, propose build attack model possessing learning ability, learn lessons attack history store parameters improve attack efficiency. % learn weak sides data victim model% data? % history launch deadly attacks efficiently. Considering labeled data available adversarial attacking, design model following reinforcement learning paradigm. There two main operations model, including identifying key words original sentences crucially influence decision victim model, selecting appropriate substitutes replace them. Our model aimed learning optimal policy series substitution operations iteratively conducted generate adversarial examples. % The prober aimed locating vulnerable sentence, i.e., word sentence easiest attack. % The attacker supposed find fatal attack, i.e., word replace vulnerable word original input. %Our attack model highly adaptable combined different word substitution methods. In experiments, evaluate attack model benchmark datasets three typical NLP tasks including sentiment analysis, text classification natural language inference. The victim models respective state-of-the-art models datasets, namely ALBERT , XLNet RoBERTa , two open APIs. Since model work score- decision-based attack settings, carry experiments two settings. Experimental results show attack model consistently outperforms baseline methods datasets terms attack success rate attack efficiency. % within whatever limit number victim model query times. We also find model bring robustness improvement victim model adversarial training. % conduct quantitative analyses exhibit learning ability model. % 閸滃矁鐦濋弴鎸庡床閺傝纭堕惃鍕波閸氬牊褝绱 % score閸滃畳ecision based閻ㄥ嫭甯归崙鐚寸吹 % 娣囶喗鏁奸悳鍥ㄦЦ閸氾箒顩︽担婊璐熸稉娑擃亪鍣哥憰浣瑰瘹閺嶅浄绱垫稉宥勭稊娑撴椽鍣哥憰浣瑰瘹閺嶅洤鎯傞敍灞惧壈娑斿绗夐弰顖滃閸掝偅妲戠涵&閹存垳婊戦惃鍕侀崹瀣躬鐠囥儲瀵氶弽鍥︾瑐濞屸剝婀侀弰搴㈡▔娴兼ê濞嶉妴"," Adversarial attacking aims to fool deep neural networks with adversarial examples. In the field of natural language processing, various textual adversarial attack models have been proposed, varying in the accessibility to the victim model. Among them, the attack models that only require the output of the victim model are more fit for real-world situations of adversarial attacking. However, to achieve high attack performance, these models usually need to query the victim model too many times, which is neither efficient nor viable in practice. To tackle this problem, we propose a reinforcement learning based attack model, which can learn from attack history and launch attacks more efficiently. In experiments, we evaluate our model by attacking several state-of-the-art models on the benchmark datasets of multiple tasks including sentiment analysis, text classification and natural language inference. Experimental results demonstrate that our model consistently achieves both better attack performance and higher efficiency than recently proposed baseline methods. We also find our attack model can bring more robustness improvement to the victim model by adversarial training. All the code and data of this paper will be made public."
"In natural languages, lexical items often used multiple word classes without overt changes word form. For instance, word buru Mundari used noun denote `mountain', verb denote `to heap up' . Known word class flexibility, phenomenon considered one challenging topics linguistic typology . We present computational methodology quantify regularity word class flexibility across languages. There extensive literature languages vary word class flexibility, either directly related notions word class conversion . However, existing studies tend rely analyses small sets lexical items may representative word class flexibility broad lexicon. Critically lacking systematic analyses word class flexibility across many languages, existing typological studies focused qualitative comparisons word class systems. We take knowledge first step towards computational quantification word class flexibility \NumLanguages languages, taken Universal Dependencies project . We focus lexical items used nouns verbs, i.e., noun-verb flexibility. This choice motivated fact distinction nouns verbs stable word class systems across languages: language makes distinction word classes all, likely distinction nouns verbs . However, understanding cross-linguistic regularity noun-verb flexibility impoverished. We operationalize word class flexibility property lemmas. We define lemma flexible occurrences tagged nouns others verbs. Flexible lemmas sorted noun dominant lemmas, occur frequently nouns, verb dominant lemmas occur frequently verbs. Our methodology builds contextualized word embedding models quantify semantic shift grammatical classes lemma, within single language. This methodology also help quantify metrics flexibility lexicon across languages. We use methodology address one fundamental questions study word class flexibility: phenomenon analyzed directional word-formation process similar derivation, form underspecification? Derived words commonly argued lower frequency use narrower range meaning compared base . If word class flexibility directional process, expect flexible lemmas subject semantic variation dominant word class less frequent class. We also test claim noun-to-verb flexibility involves semantic shift verb-to-noun flexibility. While previous work explored questions, remains challenging quantify semantic shift semantic variation, particularly across different languages. We present novel probing task reveals ability deep contextualized models capture semantic information across word classes. Our utilization deep contextual models predicts human judgment spectrum noun-verb flexible usages including homonymy , polysemy , word class flexibility. We find BERT outperforms ELMo non-contextual word embeddings, upper layers BERT capture semantic information, resonates existing probing studies ."," Word class flexibility refers to the phenomenon whereby a single word form is used across different grammatical categories. Extensive work in linguistic typology has sought to characterize word class flexibility across languages, but quantifying this phenomenon accurately and at scale has been fraught with difficulties. We propose a principled methodology to explore regularity in word class flexibility. Our method builds on recent work in contextualized word embeddings to quantify semantic shift between word classes , and we apply this method to \NumLanguages languages\footnote{Code and data to reproduce the experimental findings are available at: \url{https://github.com/SPOClab-ca/word-class-flexibility}.}. We find that contextualized embeddings not only capture human judgment of  class variation within words in English, but also uncover shared tendencies in class flexibility across languages. Specifically, we find greater semantic variation when flexible lemmas are used in their dominant word class, supporting the view that word class flexibility is a directional process. Our work highlights the utility of deep contextualized models in linguistic typology."
"Coreference resolution task identifying mentions document co-refer entity. It important task facilitating many applications question answering text summarization. \citet{lee-etal-2017-end} proposed first neural end-to-end architecture coreference resolution. Most recent state-of-the-art systems use backbone utilizing better scoring functions, pruning procedures, pre-trained token representations. Despite usage, knowledge, in-depth analysis done better understand inner workings influential system. This understanding important: example, \citet{kummerfeld-klein-2013-error}'s analysis then-best classical coreference systems inspired many important follow-up works . However, unknown observations classical feature-based often highly pipelined systems extend current end-to-end models. In paper, empirically analyze best instantiation model family, SpanBERT + c2f-coref, investigating interaction two components: mention detector mention linker. Specifically, study errors independently jointly affect final clustering. Using CoNLL-2012 PreCo datasets, highlight low-precision, high-recall nature detector. While traditionally recall emphasized detector design decision , show huge degradation noisy mentions that, perhaps surprisingly, increasing number candidates considered baseline linker deteriorates performance. While classical coreference pipelines focused detector precision, rarely emphasized modern end-to-end systems. We hence stress importance precision-recall balance detector demonstrate pruning hyperparameters, addition reducing computational complexity, help control trade-off. However, show difficulty obtaining high-precision detector demonstrating importance anaphoricity decisions inability detector make decisions. Finally, highlight high potential linker remaining errors besides anaphoricity decisions mainly involve pronoun resolution. We hope findings shed light internal mechanism mainstream coreference system lay empirical foundation future research.","  Coreference resolution is an important task for discourse-level natural language understanding. However, despite significant recent progress, the quality of current state-of-the-art systems still considerably trails behind human-level performance. Using the CoNLL-2012 and PreCo datasets, we dissect the best instantiation of the mainstream end-to-end coreference resolution model that underlies most current best-performing coreference systems, and empirically analyze the behavior of its two components: the mention detector and mention linker. While the detector traditionally focuses heavily on recall as a design decision, we demonstrate the importance of precision, calling for their balance. However, we point out the difficulty in building a precise detector due to its inability to make important anaphoricity decisions. We also highlight the enormous room for improving the linker and that the rest of its errors mainly involve pronoun resolution. We hope our findings will help future research in building coreference resolution systems."
"Neural machine translation enables end-to-end training translation models known give state-of-the-art results large variety language pairs. NMT high-resource language pairs straightforward: choose NMT architecture implementation, train model existing data. In contrast, low-resource language pairs, work well due inability neural networks generalize small amounts data. One reason strong over-fitting potential neural models . There several solutions address issue two effective ones transfer learning model regularization. Transfer learning sometimes considered data regularization comes form monolingual cross-lingual transfer learning , pseudo-parallel data generation , multi-task learning . On hand, model regularization techniques place constraints learning model parameters order aid model learn robust representations positively impact model performance. Among existing model regularization methods, dropout commonly used known effective regardless size data. We thus focus designing technique complement dropout especially extremely low-resource situation. The common way train NMT models minimize softmax cross-entropy loss, i.e., cross-entropy softmax distribution smoothed label distribution typically represented one-hot vector. In words, NMT model trained produce softmax distribution similar label. In high-resource settings, may never happen due diversity label sequences. However, low-resource settings, due lack diversity, high chance occurring over-fitting said take place. We consider simple manipulation softmax distribution may help prevent it. This paper presents investigation softmax tempering training NMT models order address over-fitting issue. Softmax tempering realized simply dividing pre-softmax logits positive real number greater 1.0. This leads smoother softmax probability distribution, used compute cross-entropy loss. Softmax tempering devised used regularly knowledge distillation , albeit different purposes. We regard softmax tempering means deliberately making softmax distribution noisy training expectation positive impact final translation quality. We primarily evaluate utility softmax tempering extremely low-resource settings involving English 11 languages Asian Languages Treebank . Our experiments reveal softmax tempering reasonably high temperature improves translation quality. Furthermore, makes greedy search performance models trained softmax tempering comparable better performance beam search using models trained without softmax tempering, enabling faster decoding. We expand scope study high-resource settings, taking WMT 2019 English-to-German translation task, well multilingual settings using ALT data. We also show softmax tempering improves performance NMT models using recurrently stacked layers heavily share parameters. Furthermore, clarify relationship softmax tempering dropout, i.e., widely used effective regularization mechanism. Finally, analyze impact softmax tempering softmax distributions gradient flows training."," Neural machine translation  models are typically trained using a softmax cross-entropy loss where the softmax distribution is compared against smoothed gold labels. In low-resource scenarios, NMT models tend to over-fit because the softmax distribution quickly approaches the gold label distribution. To address this issue, we propose to divide the logits by a temperature coefficient, prior to applying softmax, during training. In our experiments on 11 language pairs in the Asian Language Treebank dataset and the WMT 2019 English-to-German translation task, we observed significant improvements in translation quality by up to 3.9 BLEU points. Furthermore, softmax tempering makes the greedy search to be as good as beam search decoding in terms of translation quality, enabling 1.5 to 3.5 times speed-up. We also study the impact of softmax tempering on multilingual NMT and recurrently stacked NMT, both of which aim to reduce the NMT model size by parameter sharing thereby verifying the utility of temperature in developing compact NMT models. Finally, an analysis of softmax entropies and gradients reveal the impact of our method on the internal behavior of NMT models."
"Neural text generation one extensively studied tasks natural language processing , forms basis dialogue systems, machine translation, text summarization. However, often monotonous dull, texts generated existing methods fully reflect rich diversity expression human language. In particular, models tend overproduce words frequently appearing data, hardly utilizing informative words . % along fast-evolving model architectures pre-training techniques. \dkp{} % \st{However, existing methods neural text generation stop short resolving problem degeneration machine-generated texts either monotonous repeating words phrases, often failing complete proper sentence.} Even pre-training techniques large corpora fail resolve issue. %\dkpc{Current logic: three causes, choose solve last Better logic: one cause - drawback, second cause - drawback, third cause - directly addressing model, thus optimal!} Possible causes text degeneration illuminated, defect specific model architectures discrepancy training data true distribution. Recently, emphasis placed investigating flaws maximum likelihood objective. Concretely, likelihood training pays little attention top ranks terms target token probabilities, maximizing likelihood adequately reflect human language processing. Therefore, maximum likelihood-based training, models learn produce tokens frequently appearing data often. We argue, however, primary reason behind sub-optimal performance likelihood objective essentially imbalanced token distribution inherent natural language. Natural language extremely skewed distribution, top hundred frequently-used words occupy nearly half total corpus following Zipf's law. Training classifier inherently imbalanced data maximum likelihood estimation leads biased classification boundaries favor majority classes. In words, models play difficult role learning imbalanced label distribution. % \st{Our analysis comparing word frequencies corpus texts generated MLE model reveals model uses top-100 words 40\% often original data.} % Although might contributing factors, found word distribution provides clues text degeneration. %We set work line last category. However, unlike previous approaches, claim data distribution provide clues text degenerates. %Prior studies report number main causes text degeneration. First, attributed Attention mechanisms, \dkp{bulabula}. Another reason lies training machine fixed corpora distribution agree real-world language distribution. Lastly, maximum-likelihood objective, machine trained with, questioned. Following maximum-likelihood, little attention made top ranks next \dkpc{next what?} token probabilities. \dkpc{this explained crystal clear, since phenomenon directly related model}. differs human behavior. % We hypothesize text generation enriched balancing training data distribution. To end, introduce F-Softmax , Section), factorizes probability distribution target token product two conditional probabilities frequency class, token target frequency class. It ensures training balanced data, since frequency classes designed distribution close uniformity, token distributions within class confined subsets vocabularies grouped similar frequencies. To end, unique tokens assigned frequency class prior training, novel mean efficiency maximization , Section). MefMax evaluates maximizes class-labeling performance normalized entropy , probability distributions learned uniform possible. % Athe probability distributions learned model uniform possible, without introducing hyperparameter. % \st{which assigns tokens, order decreasing frequency, unique frequency class given condition classes share frequency mass. In way, prediction pipelines frequency classes tokens, respectively, performed based well-defined data near-uniform class distribution.} % We propose factorized softmax achieves introducing concept classes decomposing output probabilities using classes. It computes probability distributions tokens factorized manner; probability distribution class conditional probability distribution next token given class. The probability next token computed within subset vocabulary, rather full vocabulary. Well structured subsets vocabulary allows model benefit balanced output distributions. We assign token unique class utilizing proposed mean efficiency maximization algorithm data distribution trained distribution uniform possible. We conduct extensive performance evaluations seven relevant metrics quantify diversity quality generated texts. In terms diversity generated texts, approach significantly outperforms MLE baseline also diversity-promoting alternatives . We also achieve state-of-the-art results quality performances."," %Despite recent advances in neural text generation, encoding the rich diversity in human language remains elusive. We argue that the sub-optimal text generation is largely attributable to the imbalanced token distribution, which particularly misdirects the learning model when trained with the maximum-likelihood objective. As a simple yet effective remedy, we propose F$^2$-Softmax to enable a balanced training over the tokens with skewed frequency distribution. \dkp{By decomposing the softmax function, F$^2$-Softmax confines probability distribution to subsets of vocabularies which are more uniformly distributed. The subsets are further optimized by our novel mean efficiency maximization , without introducing any hyperparameter.} Significant performance gains across generation quality metrics suggest that our methods achieve human-like diversity in text generation.  Despite recent advances in neural text generation, encoding the rich diversity in human language remains elusive. We argue that the sub-optimal text generation is mainly attributable to the imbalanced token distribution, which particularly misdirects the learning model when trained with the maximum-likelihood objective. As a simple yet effective remedy, we propose two novel methods, F$^2$-Softmax and MefMax, for a balanced training even with the skewed frequency distribution. MefMax assigns tokens uniquely to frequency classes, trying to group tokens with similar frequencies and equalize frequency mass between the classes. F$^2$-Softmax then decomposes a probability distribution of the target token into a product of two conditional probabilities of  frequency class, and  token from the target frequency class. Models learn more uniform probability distributions because they are confined to subsets of vocabularies.  Significant performance gains on seven relevant metrics suggest the supremacy of our approach in improving not only the diversity but also the quality of generated texts.  % Despite recent advances in neural text generation, encoding the rich diversity in human language remains elusive. We argue that the sub-optimal text generation is mainly attributable to the imbalanced token distribution, which particularly misdirects the learning model when trained with the maximum-likelihood objective. As a simple yet effective remedy, we propose F$^2$-Softmax for a balanced training even with the skewed frequency distribution. F$^2$-Softmax decomposes a probability distribution of the target token into a product of two conditional probabilities of  frequency class  token from the target frequency class. Models learn more uniform probability distributions because they are confined to subsets of vocabularies. The subsets are further optimized by our novel mean efficiency maximization . It maximizes the . Significant performance gains across generation quality metrics suggest that our method achieves human-like diversity in text generation, without compromising the quality of generated texts. Significant performance gains on seven relevant metrics suggest the supremacy of our approach improves both diversity and quality in text generation."
"Natural language understanding key component conversational dialogue systems, converting user's utterances corresponding semantic representations certain narrow domain . As core task NLU, slot tagging usually formulated sequence labeling problem. Recently, motivated commercial applications like Amazon Alexa, Apple Siri, Google Assistant, Microsoft Cortana, great interest attached rapid domain transfer adaptation samples. Few-shot learning approaches become appealing scenario , general model learned existing domains transferred new domains rapidly merely examples . The similarity-based few-shot learning methods widely analyzed classification problems, classify item according similarity representation class. These methods learn domain-general encoder extract feature vectors items existing domains, utilize encoder obtain representation new class labeled samples . This scenario successfully adopted slot tagging task considering word-label similarity temporal dependency target labels. Nonetheless, still challenge devise appropriate word-label similarity metrics generalization capability. In work, vector projection network proposed few-shot slot tagging task NLU. To eliminate impact unrelated label vectors large norm, exploit projections contextual word embeddings normalized label vector word-label similarity. Moreover, half norm label vector utilized threshold, help reduce false positive errors. %It first normalizes vector representation label unit vector, exploits projections contextual word embeddings unit label vectors word-label similarities. One-shot five-shot experiments slot tagging named entity recognition tasks show method outperform various few-shot learning baselines, enhance existing advanced methods like TapNet prototypical network, achieve state-of-the-art performances. Our contributions summarized follows:","  Few-shot slot tagging becomes appealing for rapid domain transfer and adaptation, motivated by the tremendous development of conversational dialogue systems. In this paper, we propose a vector projection network for few-shot slot tagging, which exploits projections of contextual word embeddings on each target label vector as word-label similarities. Essentially, this approach is equivalent to a normalized linear model with an adaptive bias. The contrastive experiment demonstrates that our proposed vector projection based similarity metric can significantly surpass other variants. Specifically, in the five-shot setting on benchmarks SNIPS and NER, our method outperforms the strongest few-shot learning baseline by $6.30$ and $13.79$ points on F$_1$ score, respectively. Our code will be released at \url{https://github.com/sz128/few_shot_slot_tagging_and_NER}."
"% Over last decade increasing number people access news online, use social networking platforms engage, consume propagate content social circles. Social networks provide easy means distribute news commentary, resulting sharp increase number media outlets, representing wide range perspectives ideologies. However, despite diversity, content often shared among people hold similar beliefs ideologies, resulting highly segregated information communities, often referred ``echo chambers''. % To date, works studying phenomenon either focused linguistic aspects biased polarized content, social aspects connecting users content providers way documents spread. Our main observation paper modeling aspects needed order understand analyze information communities. %focused analyzing interactions news sources users social networks % Our goal paper formalize connections perspectives expressed text, users share them, social interactions information communities emerging connections. We suggest novel, minimally supervised, approach embedding information communities, allows us map news media landscape politically divisive issues, capture ideological biases perspectives expressed news content. We analyze differences communities based position continuous conservative-liberal ideological spectrum, observe differences perspectives expressed documents shared communities three issues-- immigration, gun-control abortion. % %Identifying perspective difference making explicit help strengthen trust newly-formed information landscape ensure perspectives represented. It also help lay foundation automatic detection false content rumors help identify information echo-chambers single perspective highlighted. %ribeiro2018media \subsection{Issue-Framing Political Perspective} To help clarify objectives, consider two articles highly polarized immigration issue. \\ % Example 1: Different Perspectives Immigration %Difference frame usage party. Topic: Immigration, Frame used: Economic % colback=blue!5!white,colframe=blue!75!black \end{tcbraster} The two articles capture opposite political perspectives, liberal conservative . They directly contradict other, rather focus discussion different aspects helping argue case. The first emphasizing contribution immigrants community tax revenue, second emphasizing implication wages U.S. workers. This process known framing. % Our goal capture political perspective associated articles, explain perspective identifying framing dimensions text, associated perspective support it. Previous work by~\citet{boydstun2014tracking} studied policy issue framing news media suggested 15 broad frames analyze issues framed, include Economic, Morality Security, among others. These framing dimensions help capture ideological splits. For example, framing immigration issue using morality frame using security frame, reader primed accept liberal conservative perspectives, respectively. However, shown Example 1, cases analysis coarse grained, articles frame issue using economic frame, suggesting finer grained analysis needed capture differences perspective. To help resolve issue, suggest data-driven refinement frames, described section, identifying repeating expressions used context different frames, grouping form sub-frames, separate different usages frame express different political perspectives . % Our goal capture ideological perspective associated documents, identify issues framed support perspectives, represent political meaning frames ideological spectrum. \subsection{Embedding Information Communities} %Identifying political perspectives typically framed text-categorization The analysis discussed typically framed text classification, e.g., biased language analysis, political ideology identification framing analysis. Given highly dynamic nature political events strategies used discuss them, methods would require continuous adaptation. % Instead, take different approach driven principal social homophily, referring tendency individuals form social ties others share views. This phenomenon previously used help overcome language variation issues. In settings, follow observation political perspectives attitudes expressed text reflected behavior users engaging it. We identify similar patterns exploit distant supervision construct information communities consisting documents users, holding similar views focusing similar aspects issues. Figure describes example immigration issue. We define communities information graph, modeling interaction news document nodes, users share Twitter, political influencers, politicians, followed-by sharing users. % %Given graph connecting Twitter users nodes, via activity-links news article nodes , via social-links politically affiliated users , Our algorithm groups users news-article nodes together communities, associates political meaning communities observing social links politicians, identifies repeating themes perspectives observing topic framed news articles associated community. %TODO: explain - embedding space, allowing share representation, creates common language evaluating relationship elements, connecting frames political labels, documents . A community defines probability distribution, elements, belong cluster. The assignments overlapping. The community represented using centroid, allowing us create embedding community, evaluated embedding space - observing similarity elements, labels, perspectives, explain community. % % To accomplish that, define latent space embedding users, documents, political influencers, frames ideology-labels. Intuitively, embedding space shaped textual content documents, engagement patterns users documents social ties politicians. We take community embedding approach, define communities multivariate Gaussian distribution latent space. We suggest EM-style learning approach, augmenting graph embedding objective, based first-order graph relations, global-view derived inferred community assignments. Unlike related work analyzing community behavior conflicts, analyze observed community structures, rather goal construct communities, way characterize different issues discussed align social information text. Recent work ~\citet{li2019encoding} exploits social supervision detecting political bias documents. We take broader view work, aim characterize discussion, rather individual articles. %TODO - experiments designed todo? One practical thing evaluate document classification, show adding communities help. More broadly - sanity check communities. communities properties. We conduct extensive experiments evaluate inferred community structures, three politically divisive issues, namely, immigration, abortion gun-control. We show approach used detect political ideology documents, even little social information available, well characterize cohesive information communities, focusing different aspects issues. % % TODO : discuss disconnected docs % todo: discuss ""beyond binary labels"" % todo : discuss no-supervision settings - similar topic models etc. %Eval: %Extenral Indicators sanity - % frame/subframe label correlation+visualization %indicator correlation. % classifier results - subframes good features, comparable BERT. %Internal Sanity check - % took top-K articles SF, evaluated correspond definition . % TODO: add example couple paragraphs. % Sample 10 side, topic = 60 documents. Compare two lists SF predicted text - GLDA vs. embedding %Applying SF analyzing data - %event based table"," In this paper we suggest a minimally-supervised approach for identifying nuanced frames in news article coverage of politically divisive topics. We suggest to break the broad policy frames suggested by, \citeyear{boydstun2014tracking} into fine-grained subframes which can capture differences in political ideology in a better way. We evaluate the suggested subframes and their embedding, learned using minimal supervision, over three topics, namely, immigration, gun-control and abortion. We demonstrate the ability of the subframes to capture ideological differences and analyze political discourse in news media.  % a method for characterizing the perspectives on news media on several politically divisive issues, such as immigration, gun-control and abortion."
"% Neural machine translation made great progress recent years. Recently, novel network structures neural machine translation proposed , among Transformer achieves best results. One important difference Transformer translation models multi-head attention mechanism. % The original intention introducing multi-head attention capture different aspects context information indeed improves performance NMT models. Some interesting phenomena attention heads discovered recently. find small subset heads appears important translation task vast majority heads removed without seriously affecting performance. also find several heads removed trained transformer models without statistically significant degradation test performance. It turns heads equally important. We speculate attributed imbalanced training multi-head attention, heads trained adequately contribute little model. However, turned bottleneck whole model. For analogy, soccer player gets used using right foot spares training opportunities it, stronger stronger. As result, right foot relied on, left foot receives less training gradually turns limitation. In paper, firstly empirically confirm inequality multi-head attention. Then new training method two variants % \SJ{reconsider choice words: stragety, ways, methods... You need two. } proposed avoid bottleneck improve translation performance. Further analyses also made verify assumption. %"," Recent studies show that the attention heads in Transformer are not equal. We relate this phenomenon to the imbalance training of multi-head attention and the model dependence on specific heads. To tackle this problem, we propose a simple masking method: HeadMask, in two specific ways. Experiments show that translation improvements are achieved on multiple language pairs. Subsequent empirical analyses also support our assumption and confirm the effectiveness of the method."
"Two widely-known formalisms commonly used represent syntactic structure sentences human languages: constituent dependency representations. Constituent trees, commonly used tasks span information crucial, describe syntax sentence terms constituents hierarchical order. We find two kinds constituent trees: continuous discontinuous , respectively). The latter extend former allowing %the representation crossing branches constituents gaps middle. These necessary describing wh-movement, long-distance extractions, dislocations, cross-serial dependencies linguistic phenomena common free word order languages German . On hand, dependency tree straightforwardly connects word sentence dependent another, considered head word. This structure composed binary syntactic dependencies known representing information closer semantic relations classified projective non-projective , respectively). %, Non-projective dependency trees %are complex structure allows allow crossing dependencies, model linguistic phenomena described discontinuous constituent trees. Since information described %regular constituent tree cannot fully represented %regular dependency tree vice versa , %typically parsers typically parsers exclusively trained produce either dependency constituent structures and, cases, %they restricted less complex continuous/projective representations. %, supporting one four syntactic structures described before. \carlos{There exceptions, i.e., approaches trained generate constituents dependencies. For instance, chart parser \citet{zhou-zhao-2019-head} generates continuous projective structures single model, sequence labeling parser \citet{strzyz19} combines continuous constituents non-projective dependency structures. In cases, discussed detail Section, representations shown benefit terms accuracy.} \carlos{However, knowledge, joint training approaches defined support non-projective dependency trees discontinuous constituents; accurate least computationally complex models formalisms single-representation approaches: graph-based transition-based models non-projective dependencies, transition-based parsers discontinuous phrase-structure trees.} \carlos{In order fill gap,} propose novel multitask transition-based parser efficiently generate unrestricted constituent dependency structures \carlos{} single trained model. We design encoder-decoder neural architecture jointly trained across syntactic information represented two formalisms following multitask learning strategy . Inspired , model constituent trees augmented dependency structures use two separate task-specific decoders produce regular augmented dependency trees. Each decoder relies Pointer Networks biaffine classifier incrementally generate labelled dependencies left right, proposed \citet{L2RPointer}. Finally, decoding runtime $) required memory space multi-representational approach remains single-task dependency parser \citet{L2RPointer}, since single model trained multitask learning strategy impact decoding time, allowing decoders run parallel. We test multi-representational neural model\footnote{Source code available \url{https://github.com/danifg/MultiPointer}.} continuous English Chinese Penn Treebanks discontinuous NEGRA TIGER datasets. In benchmarks, approach outperforms single-task parsers , proves learning across regular dependency trees constituent information leads gains accuracy tasks, obtaining competitive results cases surpassing current state art %by wide margin several datasets. \deproot{2}{} \depedge[edge unit distance=4ex]{2}{1}{ROOT+S\#2} \depedge{2}{3}{VP\#1} \depedge[edge unit distance=3ex]{2}{4}{VP\#1} \depedge[edge unit distance=3ex]{2}{5}{ROOT+S\#2} \end{dependency} % \deproot[edge unit distance=2ex]{4}{} \depedge[edge unit distance=5ex]{4}{1}{nsubj} \depedge[edge unit distance=4ex]{4}{2}{cop} \depedge{4}{3}{advmod} \depedge[edge unit distance=4ex]{4}{5}{punct} \end{dependency}\\ % {\tiny a) Continuous constituent tree.} {\tiny b) Projective augmented dependency tree.} {\tiny c) Projective dependency tree.}\\ %%%%%%%%%%%%%%%%%%%%%%%%% \includegraphics[width=0.3\textwidth]{treedisc.png} % \deproot[edge unit distance=4ex]{2}{} \depedge[edge unit distance=2ex]{4}{1}{NP\#2} \depedge{4}{3}{NP\#1} \depedge[edge unit distance=4.5ex]{2}{4}{S\#1} \depedge[edge unit distance=4ex]{2}{5}{VROOT\#2} \end{dependency} % \deproot[edge unit distance=2.5ex]{2}{} \depedge[edge unit distance=2ex]{4}{1}{APP} \depedge{4}{3}{DET} \depedge[edge unit distance=4.5ex]{2}{4}{SUBJ} \depedge[edge unit distance=4ex]{2}{5}{punct} \end{dependency}\\ % {\tiny d) Discontinuous constituent tree.} {\tiny e) Non-projective augmented dependency tree.} {\tiny f) Non-projective dependency tree.} \end{figure*}"," We propose a transition-based approach that, by training a single model, can efficiently parse any input sentence with both constituent and dependency trees, supporting both continuous/projective and discontinuous/non-projective syntactic structures. To that end, we develop a Pointer Network architecture with two separate task-specific decoders and a common encoder, and follow a multitask learning strategy to jointly train them. The resulting quadratic system, not only becomes the first parser that can jointly produce both unrestricted constituent  and dependency   trees from a single model, but also proves that both syntactic formalisms can benefit from each other during training, achieving state-of-the-art accuracies in several widely-used benchmarks such as the continuous English and Chinese Penn Treebanks, as well as the discontinuous German NEGRA and TIGER datasets."
"%GOAL: introducing rule based% %Traditional solutions task-oriented dialogue systems decompose task building complete task-oriented dialogue system several sequential steps, including \ac{LU}, \ac{DM} \ac{NLG}~ . In paper focus dialogue policy key component dialogue management; decides actions system take time step according context user feedback. The aim dialogue policies \ac{TDS} select appropriate actions time step according current context conversation user feedback~. In early work, dialogue policies manually designed set rules map dialogue context corresponding system action~. %That feasible domain complex. %, approach suffers limited task scalability inability easily updated user behavior changes. %When task domain complex possible conversation scenarios predefined explicitly, dialogue policy represented set rules map dialogue context corresponding system action . The ability rule-based solutions limited domain complexity task scalability. Moreover, design maintenance rules require lot effort domain knowledge. %GOAL: introducing supervised learning disadvantages% Due recent advantages deep learning availability labeled conversational datasets, supervised learning employed dialogue policy training overcome disadvantages rule-based systems. %Dialogue context-action pairs fed model infer underlying relation dialogue context corresponding dialogue actions supervised learning methods. \todo{It looks obvious task first sentence paragraph} The downside supervised learning approach dialogues observed datasets unlikely represent possible conversation scenarios; extreme cases, required conversational dataset cannot collected acquiring might cost-prohibitive. %GOAL: introducing RL disadvantages% The success \ac{RL} areas holds promises dialogue \ac{PL}~. Using \ac{RL} techniques, train dialogue policies optimize automatically, scratch utilizing interactions users~. % Handcrafting complex rules essential anymore expense pressure maintaining policy time alleviated. In \ac{RL}-based solutions, dialogue system takes actions controlled dialogue policy, user feedback , provided dialogue finished, utilized adjust initial policy~. %These methods assume system access reward signal end dialogue. In practice, reward signals always available may inconsistent~. As practical ask explicit user feedback dialogue policy training, different strategies proposed design rule-based user simulator along reward function approximate real reward function exists user's mind. Designing appropriate user simulator accurate reward function requires strong domain knowledge. This process disadvantages rule-based dialog systems~. The difference rule-based approaches system design meet problem dialogue agent side rule-based user simulators need solve environment side. %To train dialogue agent reinforcement learning, handcraft rule-based user simulator suffer problem rule-based dialogue agent task becoming complex. %The difference one approach meets problem dialogue agent side another one solve environment side . %%GOAL: Describing bottleneck% If task simple easy solve, build rule-based system rather user-simulator used \ac{RL} techniques train dialogue system, uncontrollable factors involved? And task domain complex hard solve, easier design maintain complicated rule-based user simulator build rule-based dialogue agent? % Training model-based user simulator~ real human dialogue dataset alternative solution still data-hungry. %Besides, guarantee human-designed model-based simulator cover possible dialogue scenarios. % With respect comparison reinforcement learning supervised learning, Supervised learning methods suffer issues require labeled conversational data; exceptional cases, data cannot collected privacy reasons, \ac{RL} solution. However, collecting labeled data feasible many applications~. % Therefore work seek answer following research question: Are really making progress c{TDSs focusing purely advancing \ac{RL}-based methods?} To address question, introduce three dialogue \ac{PL} methods require user simulator. The proposed methods achieve comparable even higher performance compared \ac{SOTA} \ac{RL} methods. The first method utilizes action decoder predict dialogue combinations. %The sequential decision setup make use dependency information different atomic dialogue actions response. The second method regards dialogue \ac{PL} task multi-label classification problem. Unlike previous work, assign dense layer action label action space. % This change provides dialogue agent stable higher performance. Based second method, propose adversarial learning method dialogue \ac{PL} without utilizing \ac{RL}. To backpropagate loss reward model policy model, utilize Gumbel-Softmax connect policy model reward model third method. % We compare methods \ac{RL} adversarial \ac{RL} based dialogue training solutions show achieve comparable performance without utilizing costly user simulator. To summarize, contributions are:"," %\todo[maybe a more interesting title? like ``rethinking supervised learning and reinforcement learning in dialogue policy learning""] Dialogue policy learning for \ac{TDSs} has enjoyed great progress recently mostly through employing \ac{RL} methods. However, these approaches have become very sophisticated. It is time to re-evaluate it. Are we really making progress developing dialogue agents only based on \ac{RL}? We demonstrate how ~traditional supervised learning together with ~a simulator-free adversarial learning method can be used to achieve performance comparable to \ac{SOTA} \ac{RL}-based methods.  First, we introduce a simple dialogue action decoder to predict the appropriate actions. Then, the traditional multi-label classification solution for dialogue policy learning is extended by adding dense layers to improve the dialogue agent performance. Finally, we employ the Gumbel-Softmax estimator to alternatively train the dialogue agent and the dialogue reward model without using \ac{RL}.  Based on our extensive experimentation, we can conclude the proposed methods can achieve more stable and higher performance with fewer efforts, such as the domain knowledge required to design a user simulator and the intractable parameter tuning in reinforcement learning. Our main goal is not to beat \ac{RL} with supervised learning, but to demonstrate the value of rethinking the role of \ac{RL} and supervised learning in optimizing \ac{TDSs}."
"Despite many recent advances Natural Language Generation, successful creative narrative composition remains elusive. Current neural approaches plagued difficulty mastering structure, veer topics, lack long-range cohesion. They successfully imitate fluency style human writing, closer inspection sentences fit together form whole, reader left impression generation content. % \np{I think abi see good work cite.} This lack structure also degrades relevance generations conditioned prompt source text - strong language model repeat key phrases given prompt remain topic. These issues illustrated Naive Generated Story Table , many sentences individually fine, fit together one story, relate prompt. We hypothesise problem addressed focus deeper latent narrative structures. In Aristotle's Poetics, one enduring treatises craft writing good stories, philosopher lays elements story order importance. They are: An amateur masters skills later list, mastery event choice event arrangement distinguishes good writer . Next character, relevance, finally style diction matter. %A good writer must begin events, solidified transform events surface forms - names, details, natural language. This philosophical framework fits remarkably well traditional Natural Language Generation Pipeline approach emphasizes Content Planning . The pipeline divides generation three steps: Content Planning, Microplanning Surface Realization, step input modified refined, getting closer final textual output. %Abstract concepts get grounded, synonyms chosen actual wording selected, order convey semantic information present input. Incorporating plot order generate stories viewed proxy Content Planning/MicroPlanning language model makes use convert readable grammatically correct natural language output . Inspired Aristotelian Content Planning Frameworks, develop novel system story generation. We focus developing system learn expertly select events, characters, relevant content, write good plot structures. After work plot complete, large language model best fill descriptions, details, local specifics story. For plot generation, employ event-choice event-arrangement rescoring models assist building arc cohesion plot, character rescoring model helps select characters appear where, relevance model responsible keeping plot structure story topic. As improving plot-generation via rescoring using Aristotelian framework neural generation novel concepts, previous work implement practice. % \np{may contribution list 1) propose leverage principled Aristotelian framework content planning. 2) propose implementation framework using revise-based approach several rescoring models. 3) strong experimental results. } propose leverage principled Aristotelian framework content planning, 2) propose implementation framework using revision-based approach via several rescoring models 3) show strong experimental results 4 baselines. % Our contributions are: 1) We build system rescoring models enforce Aristotelian principles content planning process, 2) We experiment various different architectures rescoring model, ways create training examples encode Aristotelian concept, 3) We evaluate best system two state-of-the-art story generation systems dataset, well two ablated versions itself, find system improved relevance overall quality. %- neither best train models learn select correct events, arrange right order. There similarly work best teach model incorporate character. \\"," Long-form narrative text generated from large language models manages a fluent impersonation of human writing, but only at the local sentence level, and lacks structure or global cohesion. We posit that many of the problems of story generation can be addressed via high-quality content planning, and present a system that focuses on how to learn good plot structures to guide story generation. We utilize a plot-generation language model along with an ensemble of rescoring models that each implement an aspect of good story-writing as detailed in Aristotle's Poetics. We find that stories written with our more principled plot-structure are both more relevant to a given prompt and higher quality than baselines that do not content plan, or that plan in an unprincipled way.\footnote{Code at \url{https://github.com/PlusLabNLP/story-gen-BART}} %may need to talk about using the plot scaffolding to write stories later more directly - just trying to keep the focus on storyline % also could add a focus on ""long form text"" to differentiate from dialogue systems etc"
"% What neural keyphrase generation general Keyphrases phrases summarize highlight important information piece text. Keyphrase generation task automatically predicting keyphrases given source text. The task easily misunderstood trivialized yet another natural language generation task like summarization translation, failing recognize one key aspect distinguishes KPG: multiplicity generation targets; input sequence, KPG system expected output multiple keyphrases, mini-sequence multiple word tokens. % Typically, one source text associated multiple keyphrases, % may either present absent source text. % This property task, along others, pushes community investigate leveraging deep neural networks handle task. % There quite work KPGen task, people mainly use two popular frameworks: one2one one2seq % However, previous literature, comparison two frameworks, effects architectural hyper-parameter choice remain unclear. % Keyphrase generation essentially natural language generation task. Despite unique nature, KPG essentially ``brute-forced'' sequence-to-sequence framework existing literature .%,sun2019divgraphpointer,ye2018kp_semi}. % Seq2Seq models encoder-decoder neural networks, encoder reads source text form hidden representation, decoder generates target sequence word word conditioned source text representation passed encoder. The community approached unique challenges much ingenuity problem formulation, model design, evaluation. For example, multiple target phrases reformulated either splitting one phrase per data point joining single sequence delimiters , allowing straightforward applications existing neural techniques Seq2Seq. In accordance tremendous success demonstrated effectiveness neural approaches, steady progress made past years --- least empirically --- across various domains, including sub-areas previously shown rather difficult . Meanwhile, myriad KPG's unique challenges comes ever-growing collection studies that, albeit novel practical, may quickly proliferate overwhelm. We therefore motivated present study --- best knowledge --- first systematic investigation challenges well effect interplay among solutions. We hope study serve practical guide help researchers gain holistic view task, profit empirical results investigations variety topics KPG including model design, evaluation, hyper-parameter selection. %data processing, % Based training paradigms, keyphrase generation models introduced prior works fall two categories, namely \onetoone \onetoseq . % Models achieved improved performance texts various types, including scientific publications , news articles , forum postings . % However, unaware existing systematic comprehensive empirical analysis neural keyphrase generation, particularly examining effects fundamental factors shared various model designs. % In empirical study, exhaustive experiments provide comprehensive analysis. % To facilitate future research community clarifying, % In work, present comprehensive empirical study neural keyphrase generation extensive experiments, aiming characterize key factors keyphrase generation models, quantitatively analyze impacts model performance, compare wide range baseline variants. % We hope study serves practical guide help researchers architecture, methods, hyper-parameter selection. % We also hope provide new insights community. % Based extensive experiments, provide comprehensive analyses number factors affect training generalization performance keyphrase generation models. % Thus contributions are: The rest paper organized follows. We first enumerate specific challenges KPG due multiplicity target, describe general setups experiments. We subsequently present experimental results discussions answer three main questions:\\ 1. How well KPG models generalize various testing distributions?\\ 2. Does order target keyphrases matter training \onetoseq ?\\ 3. Are larger training data helpful? How better make use them? %"," Recent years have seen a flourishing of neural keyphrase generation  works, including the release of several large-scale datasets and a host of new models to tackle them. Model performance on KPG tasks has increased significantly with evolving deep learning research. % \todo{Among the growing number of neural models competing on this track, we observe that most of them fall into two categories --- \onetoone and \onetoseq --- based on their training paradigms.} % However, there lacks a comprehensive comparison among different model designs, and an investigation on related factors  that may affect a keyphrase generation system's performance. However, there lacks a comprehensive comparison among different model designs, and a thorough investigation on related factors that may affect a KPG system's generalization performance. In this empirical study, we aim to fill this gap by providing extensive experimental results and analyzing the most crucial factors impacting the generalizability of KPG models. We hope this study can help clarify some of the uncertainties surrounding the KPG task and facilitate future research on this topic."
"The de-facto supervised neural network training paradigm requires large dataset annotations. It time-consuming, difficult sometimes even infeasible collect large number data-points due task nature. A typical example task medical diagnosis. In addition, annotating datasets also costly, especially domains experts difficult recruit. In traditional annotation process, human-machine communication bandwidth narrow. Each label provides bits per sample -class classification problem. However, humans solely rely low bandwidth communication learn. They instead learn natural language communication, grounds abstract concepts knowledge. Psychologists philosophers long posited natural language explanations central, organizing elements human learning reasoning. Following intuition, explore methods incorporate natural language explanations learning paradigms improve learning algorithm's data efficiency. \newcommand{\hightlightmodelname}[1]{{{{ \underline{A}ctive \underline{L}earning w\underline{i}th \underline{C}ontrastive % Natural Language \underline{E}xplanations }}}{#1}} \newcommand{\modelabbrevname}[1]{{{{ALICE}}}{#1}} \newcommand{\weixin}[1]{[{\color{red}WX: #1}]} % \newcommand{\weixin}[1]{{}} % % File emnlp2020.tex % %% Based style files ACL 2020, %% Based style files ACL 2018, NAACL 2018/19, %% Based style files ACL-2015, improvements %% taken NAACL-2016 style %% Based style files ACL-2014, were, turn, %% based ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009, %% EACL-2009, IJCNLP-2008... %% Based style files EACL 2006 %%e.agirre@ehu.es Sergi.Balari@uab.es %% ACL 08 Joakim Nivre Noah Smith \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{emnlp2020} \usepackage{times} \usepackage{latexsym} \renewcommand{\UrlFont}{\ttfamily\small} % This strictly necessary, may commented out, % improve layout manuscript, % typically save space. \usepackage{microtype} \usepackage{booktabs} \usepackage{multirow} \usepackage{graphicx} \usepackage{subcaption} \usepackage{comment} \usepackage{amsmath} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{algorithm} \usepackage{algorithmic} \renewcommand{\algorithmicrequire}{Input:} \renewcommand{\algorithmicensure}{Output:} \aclfinalcopy % Uncomment line final submission \def\aclpaperid{76} % Enter acl Paper ID %\setlength\titlebox{5cm} % You expand titlebox need extra space % show authors. Please make titlebox % smaller 5cm ; check % camera-ready version ask change back. \newcommand{\james}[1]{{\color{red} {\bf James:} #1}} \newcommand\BibTeX{Bib\TeX} \title{ ALICE: Active Learning Contrastive Natural Language Explanations } \author{Weixin Liang \\ Stanford University \\ \\\And James Zou \\ Stanford University \\ \\\And Zhou Yu \\ University California, Davis \\ \\ } \date{} \input macro % self-defined macro \footnotetext[1]{Co-supervised project.} \input introduction % \input delete_introduction \input relatedwork % \input rawrelatedwork \input problemformulation \input method \input experiment \input conclusion \input acknowledgement \bibliography{emnlp2020} \bibliographystyle{acl_natbib} \clearpage \input appendix \end{document}","  % abstract   \input abstract   % Long papers may consist of up to 8 pages of content, plus unlimited pages for references; final versions of long papers will be given one additional page of content  so that reviewers闁 comments can be taken into account."
"Causal explanation detection aims detect whether causal explanation given message . Linguistically, coherence relations messages explain meaning different textual units combine jointly build discourse meaning larger unit. The explanation important relation coherence refers textual unit message expresses explanatory coherent semantics . As shown Figure , M1 divided three discourses, D2 explanation expresses reason advantageous equipment operate temperatures. CED important tasks require understanding textual expression . For example, question answering, answers questions likely group sentences contains causal explanations . Furthermore, summarization event descriptions improved selecting causally motivated sentences . Therefore, CED problem worthy study. The existing methods mostly regard task classification problem . At present, mainly two kinds methods, feature-based methods neural-based methods, similar semantic understanding tasks discourse granularity, opinion sentiment classification discourse parsing . The feature-based methods extract feature relation discourses. However, methods deal well implicit instances lack explicit features. For CED, shown Figure , D2 lacks explicit features of, due to, features tenses, friendly feature-based methods. The methods based neural network mainly Tree-LSTM model hierarchical Bi-LSTM model . The Tree-LSTM models learn relations words capture semantics discourses accurately lack understanding semantics discourses. The hierarchical Bi-LSTM models employ sequence structure implicitly learn relations words discourses. However, previous work shows compared Tree-LSTM, Bi-LSTM lacks direct understanding dependency relations words. Therefore, method implicit learning inter-word relations prominent tasks related understanding semantic relations messages . Therefore, directly learn relations words effectively consider discourse-level correlation filter key information valuable point worth studying. Further analysis, relations words imply semantics message discourses? From view computational semantics, meaning text meaning words also relation, order, aggregation words. In simple words meaning text partially based syntactic structure . In detail, CED, core subsidiary words discourses contain basic semantics. For example, D1 shown Figure , according word order syntactic structure, capture ability temperature advantageous. We understand basic semantic D1 expresses kind ability advantageous via root words advantageous affiliated words. Additionally, correlation key information discourse level important capture causal explanatory semantics message? Through observation, different discourse different status explanatory semantics message. For example, M1, combined D1, D2 expresses explanatory semantics ability work temperatures advantageous, D3 expresses semantic transition. In detail, D1 D2 keys explanatory semantics M1, treated D1, D2, D3 differently, transitional semantic D3 affect understanding explanatory semantic M1. Therefore, make better use information keywords syntactic structure pay attention discourses key explanatory semantics problem solved. To end, propose Pyramid Salient-Aware Networks utilizes keywords syntactic structure discourse focuses key discourses critical explanatory semantics detect causal explanation messages. First, keywords syntactic structure? From perspective syntactic dependency, root word central element dominates words, dominated words, subordinate root word . From that, root subsidiary words dependency structure keywords syntax level discourse. Specifically, sample 100 positive sentences training data illuminate whether keywords obtained syntactic dependency contain causal explanatory semantics. And find causal explanatory semantics 80\% sentences captured keywords dependency structure\footnote{Five Ph.D. students majoring NLP judge whether sentences could identified containing causal explanatory semantics root word surrounding words syntactic dependency, agreement consistency 0.8}. Therefore, extract root word surrounding words syntactic dependency discourse keywords. Next, need consider make better use information keywords contained syntactic structure. To pay attention keywords, common way using attention mechanisms increase attention weight them. However, implicitly learned attention interpretable. Inspired previous researches , propose bottom graph-based word-level salient network merges syntactic dependency capture salient semantics discourses contained keywords. Finally, consider correlation discourse level pay attention discourses key explanatory semantics? Inspired previous work , propose top attention-based discourse-level salient network focus key discourses terms explanatory semantics. In summary, contributions paper follows:"," 		Causal explanation analysis  can assist us to understand the reasons behind daily events, which has been found very helpful for understanding the coherence of messages. In this paper, we focus on Causal Explanation Detection, an important subtask of causal explanation analysis, which determines whether a causal explanation exists in one message. We design a Pyramid Salient-Aware Network  to detect causal explanations on messages. PSAN can assist in causal explanation detection via capturing the salient semantics of discourses contained in their keywords with a bottom graph-based word-level salient network. Furthermore, PSAN can modify the dominance of discourses via a top attention-based discourse-level salient network to enhance explanatory semantics of messages. The experiments on the commonly used dataset of CEA shows that the PSAN outperforms the state-of-the-art method by 1.8\% F1 value on the Causal Explanation Detection task."
"Event coreference resolution task determining event mentions document refer real-world event. Event coreference resolution important part NLP systems summarization, text-level event extraction, question answering on. Besides, compared considerable research entity coreference resolution, less attention event coreference resolution. Therefore, event coreference resolution still challenging task performance improved. Event mentions refer event occur within document across multiple documents . We focus WD event coreference paper WD event coreference basic work CD event coreference. The main task WD event coreference judging whether pair events coreferential not. Figure shows two coreferential event pairs two documents. The first event pair D1 shooting event second event pair D2 fire event. In order judge coreference event pair, approaches solving event coreference resolution relied various linguistic properties especially event argument, contains {spatio-temporal} information events. For instances, Figure, words red front events. And words blue, green orange front participant, time, location events respectively. Although event arguments contain useful information event coreference resolution, two problems using event arguments information event coreference resolution. Firstly, difficult extract event arguments accurately due diversity expression event arguments. The performance event argument extraction 55.7 ACE corpus. For instance, D1, arguments shooting event two sentences expressed differently. In details, D1, participant, time, location shooting event worker/2 women, 8:30 p.m. kraft S1, women, Friday evening building S2 respectively. Secondly, every event mention contains arguments one event may make model confused coreference two events event pair. For instance, D2, Wasilla Bible Church location fire event S1 S2. Besides, D2, devoid event arguments, burned event fire event coreferential context. As aforementioned, arguments events difficult extract. It also difficult use arguments solve problems event coreference resolution even extracted. Thus, context event mentions important effective event coreference resolution. In order use context information efficiently, propose multi-loss neural network model need argument information accomplish within-document event coreference resolution task. We propose two sub-models use context information detect coreference two events event pair train jointly. One classifier predicts whether two events one pair coreferential, another scorer calculates similarity scores assist infer coreference. The final stage event coreference resolution event clustering. After event pairs predicted scored, filter event pairs according results classifier scorer. Then, use dynamic connectivity algorithm construct graph event clustering. Each node graph event mention edge two nodes represent whether two event coreferential not. Finally, events connected one graph considered one event cluster. We evaluate model ECB+ corpus use B, CEAF, MUC CoNLL measures. The experimental results show model achieve significant improvement compared state-of-the-art methods use event argument features.","Event coreference resolution is an important task in Natural Language Processing  and nearly all the existing approaches to this task  rely on event argument information. However, these methods tend to suffer from error propagation from the stage of event argument extraction. Besides, not every event mention contains all arguments of an event and argument information may confuse the model that events have arguments to detect event coreference in real text. Furthermore, the context information of an event is useful to infer coreference between events. Thus, in order to reduce the errors propagated from event argument extraction and use context information effectively, we propose a multi-loss neural network model which does not need any argument information to do the within-document event coreference resolution task and achieve a significant performance than the state-of-the-art methods."
"A task-oriented spoken dialogue system usually consists three modules: input,output control, shown Fig.. The input module consists automatic speech recognition spoken language understanding extracts semantic-level user dialogue actions user speech signal. The control module two missions. One maintain dialogue state, encoding machine's understanding conversation. Once information input module received, dialogue state updated dialogue state tracking . The choose semantic-level machine dialogue action response user, called dialogue decision policy. The output consists natural language generation text-to-speech synthesis, convert dialogue action audio. Dialogue management important part dialogue system. Nevertheless, inevitable ASR SLU errors make hard track true dialogue state make decision. In recent statistical dialogue system, distribution dialogue state, i.e. belief state, tracked. A well-founded theory belief tracking decision making offered partially observable Markov Decision Process framework. Previous DST algorithms divided three families: hand-crafted rules, generative models, discriminative models. Recently, since Dialog State Tracking Challenges provided labelled dialog state tracking data common evaluation framework test-bed, variety machine learning methods DST proposed. These methods rely strictly set labelled off-line data. Since labelled data off-line, learning process supervised learning methods independent dialogue policy module. The key issues supervised learning methods poor generalization over-tuning. Due lack labels, approaches easily used on-line update DST. This work marks first step towards employing deep reinforcement learning method dialogue state tracking module. The performance DST module optimized conversation user dialogue system. We call DRL-based DST module tracking agent. In order bound search space tracking agent, propose companion teaching framework . Furthermore, framework, train tracking agent dialogue policy agent jointly respective deep reinforcement learning algorithms order make two agents adaptive other. % And two main types DST systems current dialogue system. One semantic-based dialogue state tracking system, text-based dialogue state tracking system implicitly explicitly removes spoken language understanding module. In paper, explain proposed tracking agent framework based semantic-based dialogue state tracking system. The paper two main contributions: The rest paper organized follows. Section gives overview related work. In Section , framework on-line DST presented. The implementation detail represented Section . In Section , joint training process introduced. Section presents experiments conducted evaluate proposed framework, followed conclusion Section ."," Dialogue state tracking  is a crucial module in dialogue management. It is usually cast as a supervised training problem, which is not convenient for on-line optimization. In this paper, a novel companion teaching based deep reinforcement learning  framework for on-line DST optimization is proposed. To the best of our knowledge, this is the first effort to optimize the DST module within DRL framework for on-line task-oriented spoken dialogue systems. In addition, dialogue policy can be further jointly updated. Experiments show that on-line DST optimization can effectively improve the dialogue manager performance while keeping the flexibility of using predefined policy. Joint training of both DST and policy can further improve the performance."
"{T}{he} task-oriented spoken dialogue system aims assist human user accomplishing specific task . The dialogue management core part SDS. There two main missions dialogue management: dialogue belief state tracking dialogue decision-making . In work, focus devising policy chooses dialogue action respond user. The sequential system decision-making process abstracted partially observable Markov decision process . Under framework, reinforcement learning approaches used automated policy optimization. In past years, many deep reinforcement learning algorithms閿 use neural networks function approximators, investigated dialogue policy . Most approaches focus dialogue policy optimization single dialogue task. However, real-life scenarios, dialogue agent asked many users different dialogue tasks, e.g., Apple Siri support many dialogue tasks . In multi-task setup, traditional DRL-based approaches train individual policy dialogue task. It means dialogue policy independent model parameters, whose scale increase proportionally number tasks. One solution train generic policy dialogue tasks . However, two obstacles traditional DRL-based approaches. In paper, propose Structured Actor-Critic Reinforcement Learning Universal Dialogue Management address two problems. It use data collected different dialogue tasks train generic policy. To tackle scalability problem, utilize recently proposed structured dialogue policy , dialogue policy represented graph neural network . With scalability GNN , single set parameters used different dialogue tasks. That makes possible train generic policy among multiple dialogue tasks. To tackle efficiency problem, deploy advanced off-policy actor-critic algorithm, combines decoupled acting learning novel off-policy correction method called V-trace. Combining improved optimization algorithm structured dialogue policy, make generic policy learning process stable efficient original GNN-based dialogue policy . We evaluate performance STRAC PyDial benchmark, includes six environments three dialogue domains. Results show unified dialogue agent STRAC gets best performance 18 tasks benchmark."," Traditional dialogue policy needs to be trained independently for each dialogue task. In this work, we aim to solve a collection of independent dialogue tasks using a unified dialogue agent. The unified policy is parallelly trained using the conversation data from all of the distributed dialogue tasks. However, there are two key challenges: the design of a unified dialogue model to adapt to different dialogue tasks;  finding a robust reinforcement learning method to keep the efficiency and the stability of the training process. Here we propose a novel structured actor-critic approach to implement structured deep reinforcement learning , which not only can learn parallelly from data of different dialogue tasks\footnote{In the experimental setup of this work, each dialogue task has only one dialogue domain.} but also achieves stable and sample-efficient learning. We demonstrate the effectiveness of the proposed approach on 18 tasks of PyDial benchmark. The results show that our method is able to achieve state-of-the-art performance."
"%When building dialogue system, complex tasks require information exchange often challenging. One example handle restaurant reservation consultation multiple areas single conversation. Specifically, type task needs complete subtasks order finish conversation called composite task. Composite tasks different multi-domain dialogue tasks. The latter often mentioned papers focusing transfer learning. In case, multi-domain dialogue tasks involve one domain single dialogue, performance one domain model tested different domains order highlight transferability. On contrary, composite dialogue tasks may involve multiple domains single dialogue, agent must complete subtasks order get positive feedback. Consider process completing composite task . An agent first chooses subtask , make sequence decisions gather related information information required users provided subtasks completed, choose next subtask complete. The state-action space increase number subtasks. Thus, dialogue policy learning composite task needs exploration, needs take dialogue turn agent user complete composite task. The sparse reward problem magnified. Solving composite tasks using method one solving single domain tasks may hit obstacles. The complexity composite task makes hard agent learn acceptable strategy. While hierarchical deep reinforcement learning shows promising power, introducing framework options Markov Decision Process , original task decomposed two parts: deciding subtask solve solve one subtask, thus simplifying problem. However, previous works, multi-layer perceptrons often used DQN estimate Q-value. MLPs use concatenation flatten dialogue state inputs. In way, cannot capture structural information semantic slots state easily, results low sampling efficiency. In work, propose ComNet, makes use Graph Neural Network better leverage graph structure observations coherent HDRL method. Our main contributions three-fold: 1. We propose new framework ComNet combining HDRL GNN solve composite tasks achieving sample efficiency. 2. We test ComNet based PyDial benchmark show result over-performed vanilla HDRL systems robust noise environment. 3. We test transferability framework prove framework, efficient accurate transfer possible."," Dialogue policy training for composite tasks, such as restaurant reservation in multiple places, is a practically important and challenging problem. Recently, hierarchical deep reinforcement learning  methods have achieved good performance in composite tasks. However, in vanilla HDRL, both top-level and low-level policies are all represented by multi-layer perceptrons  which take the concatenation of all observations from the environment as the input for predicting actions. Thus, traditional HDRL approach often suffers from low sampling efficiency and poor transferability. In this paper, we address these problems by utilizing the flexibility of graph neural networks . A novel ComNet is proposed to model the structure of a hierarchical agent. The performance of ComNet is tested on composited tasks of the PyDial benchmark. Experiments show that ComNet outperforms vanilla HDRL systems with performance close to the upper bound. It not only achieves sample efficiency but also is more robust to noise while maintaining the transferability to other composite tasks."
"Relation extraction aims identify semantic relations named entities text. While previous work focuses extracting relations within sentence, a.k.a.~sentence-level RE, recent studies escalated document level, since large amount relations entities usually span across multiple sentences real world. According analysis Wikipedia corpus , least 40.7\% relations extracted document level. Compared sentence-level RE, document-level RE requires complex reasoning, logical reasoning, coreference reasoning common-sense reasoning. A document often contains many entities, entities multiple mentions phrase alias. To identify relations entities appearing different sentences, document-level RE models must capable modeling complex interactions multiple entities synthesizing context information multiple mentions. Figure shows example document-level RE. Assume one wants extract relation ``Surfers Riverwalk"" S11 ``Queensland"" S1. One find ``Surfers Riverwalk"" contains ``Pacific Fair"" , ``Pacific Fair"" located ``Queensland"" . This chain interactions helps infer inter-sentential relation ``located in"" ``Surfers Riverwalk"" ``Queensland"". %===================="," Relation extraction  aims to identify the semantic relations between named entities in text. Recent years have witnessed it raised to the document level, which requires complex reasoning with entities and mentions throughout an entire document. In this paper, we propose a novel model to document-level RE, by encoding the document information in terms of entity global and local representations as well as context relation representations. Entity global representations model the semantic information of all entities in the document, entity local representations aggregate the contextual information of multiple mentions of specific entities, and context relation representations encode the topic information of other relations. Experimental results demonstrate that our model achieves superior performance on two public datasets for document-level RE. It is particularly effective in extracting relations between entities of long distance and having multiple mentions."
"Dialogue state tracker core part task-oriented dialogue system, records dialogue state. The dialogue state consists set domain-slot-value triples, specific value represents user goal, e.g., . The dialogue system responds user based dialogue state. Thus, order make dialogue process natural fluent, essential extract dialogue state dialogue context accurately. However, paucity annotated data main challenge field. In work, solve key problem learn unlabeled data DST task. We design dual learning framework DST task, dialogue state tracker primal agent dual agent utterance generator. Within dual learning framework, two primal-dual agents help update external reward signals reconstruction errors using unlabeled data. It needs labeled dialogue data warm two primal-dual agents. However, two main challenges combining dual learning framework previous dialogue state tracking methods: How represent dialogue state dual learning framework? Dual learning method first proposed neural machine translation task. The outputs primal-dual agents NMT task sequential natural languages. However, DST task, output dialogue state tracker consists isolated domain-slot-value triples. The traditional DST task formulated classification problem given ontology, possible values corresponding slot listed. Under problem definition, previous classification methods choose right value slot. The recent innovated tracker TRADE directly generates values slot slot using copy mechanism dialogue context. However, tracker methods get slot values independently. During dual learning loop, hard get reward signal independent slot values. The reward signal dual utterance generator also hard allocate isolated value generation processes. Since relations predicted values modeled assumed independent other, would face serious reward sparse problem. In work, reformulate dialogue state tracking task sequential generation task. The whole dialogue state represented sequence structured information. For example, state represented ``\textless\textgreater \textless\textgreater \textless\textgreater \textless\textgreater \textless\textgreater \textless\textgreater \textless\textgreater''. Is reasonable generating whole dialogue context dialogue state? The intuitive dual task state tracker dialogue context generation. However, MultiWOZ 2.1 dataset, dialogue context 10 turns average average length sentence 10 tokens. It difficult generating accurately dialogue context dialogue state. Because dialogue context long, hard guarantee generated dialogue context contains semantics given state. In work, simplify dual task user utterance generation task ignores specific values given state. The input dual task composed two parts , output delexicalized user utterance. The delexicalized script copied released code \footnote{https://github.com/ConvLab/ConvLab}. The system utterance user utterance lexicalized respectively according given turn state. We get new pseudo-labeled dialogue turn. In order produce multi-turn pseudo-labeled data, sample labeled dialogue data combine pseudo-labeled dialogue turn, dialogue turn directly adds end sampled dialogue context turn state covers label sampled state. Finally, get new dialogue context pseudo label state, intuitive dual-task does. The main contributions paper summarized follows:"," In task-oriented multi-turn dialogue systems, dialogue state refers to a compact representation of the user goal in the context of dialogue history. Dialogue state tracking  is to estimate the dialogue state at each turn. Due to the dependency on complicated dialogue history contexts, DST data annotation is more expensive than single-sentence language understanding, which makes the task more challenging. In this work, we formulate DST as a sequence generation problem and propose a novel dual-learning framework to make full use of unlabeled data. In the dual-learning framework, there are two agents: the primal tracker agent  and the dual utterance generator agent . Compared with traditional supervised learning framework, dual learning can iteratively update both agents through the reconstruction error and reward signal respectively without labeled data. Reward sparsity problem is hard to solve in previous DST methods. In this work, the reformulation of DST as a sequence generation model effectively alleviates this problem. We call this primal tracker agent dual-DST. Experimental results on MultiWOZ2.1 dataset show that the proposed dual-DST works very well, especially when labelled data is limited. It achieves comparable performance to the system where labeled data is fully used."
"% P1 intro {T}{ask-oriented} dialog system aims users achieve goals finding attractions booking restaurants. Developing system typically requires following dialog components construct pipeline illustrated \fig : natural language understanding extract user's intents slot-values , dialog state tracking update belief states , querying database, dialog policy decide system's next action , natural language generation generate system responses . Although recent advances neural approaches natural language domain greatly improved performance individual dialog components, errors component accumulated pipelined system, resulting degradation overall performance. Therefore, designing effective architecture optimizing entire dialog system end-to-end fashion still challenging. % P2 % e2e Recently, several end-to-end neural dialog systems proposed . % Modularized % seq2seq Sequence-to-sequence approaches directly generate system responses given user utterance inputs, limitations querying external database unavailable , system actions interpretable . % RL e2e Moreover, previous researchers investigated dialog policy optimization reinforcement learning end-to-end neural task-oriented dialog systems . % GPT-2 Meanwhile, recent approaches transfer general linguistic knowledge large pre-trained language model, GPT-2 , goal-oriented dialog shown remarkable improvements . They employed GPT-2 backbone is, fine-tuned model auto-regressively generate dialog states, system actions, responses sequence. Although leveraging rich knowledge allows models generate natural appropriate responses, reinforcement learning transformer-based architectures reported unstable , learning dialog policy models explored yet. % P4 approaches In paper, present end-to-end trainable neural dialog system reinforcement learning multi-domain task-completion tasks, SUMBT+LaRL, consists two components: extended version SUMBT word-level dialog state tracker LaRL word-level policy model. In addition SUMBT updates belief states employing slot-utterance matching mechanism, SUMBT+ predicts domains user-intents user utterance. Then given predictions SUMBT+, LaRL models categorical latent system action spaces generates system responses. In training framework, emphasize importance separately pre-train SUMBT+ LaRL fine-tune entire model end-to-end fashion. Then, trained dialog policy optimized off-line reinforcement learning using REINFORCE algorithm succeed dialog tasks. During reinforcement training, policy gradients latent actions decouple discourse-level decision making language generation decoder, enabling stable effective reinforcement learning. We propose new success criteria system respond requestable slots calculate match performance using belief state estimated SUMBT+. We demonstrated efficacy proposed system MultiWOZ2.0, implementing ConvLab platform user simulator-based evaluations. Our extensive experimental results corpus simulator-based evaluation shows effectiveness proposed pretraining end-to-end fine-tuning framework well reinforcement learning latent action space. From results qualitative analysis simulated dialog examples, also present discrepancy problem corpus automatic evaluations, limitations off-line reinforcement learning dialog systems, needs advanced reward design success criteria. Our model achieved new state-of-the-art success rate end-to-end corpus-based evaluation MultiWOZ2.0, well outperformed challenge winner 8th dialog system technology challenge challenge simulator-based evaluation. % P5 contribution summary In summary, main contributions paper three-fold: % section intro \sect 2 briefly reviews end-to-end multi-domain task-completion dialog systems DSTC8 Challenge. \sect 3 explains detailed architecture proposed SUMBT+LaRL training procedures. Related work described \sect 4 experimental results presented \sect 5. %\newpage %\clearpage"," The recent advent of neural approaches for developing each dialog component in task-oriented dialog systems has remarkably improved, yet optimizing the overall system performance remains a challenge. In this paper, we propose an end-to-end trainable neural dialog system with reinforcement learning, named SUMBT+LaRL. The SUMBT+ estimates user-acts as well as dialog belief states, and the LaRL models latent system action spaces and generates responses given the estimated contexts. We experimentally demonstrate that the training framework in which the SUMBT+ and LaRL are separately pretrained and then the entire system is fine-tuned significantly increases dialog success rates. We propose new success criteria for reinforcement learning to the end-to-end dialog system as well as provide experimental analysis on a different result aspect depending on the success criteria and evaluation methods. Consequently, our model achieved the new state-of-the-art success rate of 85.4\% on corpus-based evaluation, and a comparable success rate of 81.40\% on simulator-based evaluation provided by the DSTC8 challenge.  %The recent advent of neural approaches for developing each dialog component in task-oriented dialog systems has remarkably improved, yet optimizing the overall system performance remains a challenge. In this paper, we propose an end-to-end trainable neural dialog system with reinforcement learning, named SUMBT+LaRL. The SUMBT+ estimates user-acts as well as dialog belief states, and the LaRL models latent system action spaces and generates responses given the estimated contexts. We experimentally demonstrate that the training framework in which the SUMBT+ and LaRL are separately pretrained and then the entire system is fine-tuned significantly increases dialog success rates. We propose new success criteria for reinforcement learning to the end-to-end dialog system as well as provide experimental analysis on a different result aspect depending on the success criteria and evaluation methods. Consequently, our model achieved the new state-of-the-art success rate of 85.4% on corpus-based evaluation, and a comparable success rate of 81.40% on simulator-based evaluation provided by the DSTC8 challenge."
"The massive rise user-generated web content, alongside freedom speech social media anonymity users brought increase online offensive content anti-social behavior. The consequences behavior genuine users social media become serious concern researchers Natural Language Processing related fields recent years. The shared task number 6 SemEval 2019, OffensEval , proposes model task offensive language identification hierarchically, means identifying offensive content, whether targeted, so, target offense. In OffensEval, offensive language defined ``any form non-acceptable language targeted offense, veiled direct'' includes ``insults, threats, posts containing profane language swear words'' . We participated first two subtasks OffensEval proposed approach deep model consisting Recurrent Neural Network word-level Convolutional Neural Network character-level processing. Character-level processing beneficial, offensive comments likely follow unorthodox writing styles, contain obfuscated words, irregular word separation leads tokenization issues . We also experimented two methods, Support Vector Machine TFIDF count features another SVM BERT -encoded sentences input, lower performances comparing deep model. After overviewing related work section , discuss methodology data details section , results section . In section , analyze results conclude paper section ."," This paper presents the models submitted by Ghmerti team for subtasks A and B of the OffensEval shared task at SemEval 2019. OffensEval addresses the problem of identifying and categorizing offensive language in social media in three subtasks; whether or not a content is offensive , whether it is targeted  towards an individual, a group, or other entities . The proposed approach includes character-level Convolutional Neural Network, word-level Recurrent Neural Network, and some preprocessing. The performance achieved by the proposed model for subtask A is 77.93\% macro-averaged F\textsubscript{1}-score."
"A wide range Natural Language Processing tasks, Machine Translation , speech recognition, information retrieval, data mining, creating text resources low-resource languages benefit upstream task language identification. The Cuneiform Language Identification task VarDial 2019 tries address problem identifying languages dialects texts written cuneiform symbols. Identifying languages dialects cuneiform texts difficult task, since languages lack resources also problem tokenization. Although work addressing problem tokenization languages dialects, universal method tool available tokenization cuneiform texts, task depends rules language, simply cuneiform writing system syllabic well logographic one. As result, endeavors paper based character-level features. This work investigates different machine learning methods proven effective text classification compares obtained F\textsubscript{1}-score, accuracy, training time. In paper, first review literature language identification work languages written using cuneiform writing system , introduce models used tackle problem identifying languages dialects , describe training data , discuss results . % You begin brief description task overview approach. % We would like ensure future readers paper find relevant task description, data results. So, ask cite shared task report paper introduction."," Identification of the languages written using cuneiform symbols is a difficult task due to the lack of resources and the problem of tokenization. The Cuneiform Language Identification task in VarDial 2019 addresses the problem of identifying seven languages and dialects written in cuneiform; Sumerian and six dialects of Akkadian language: Old Babylonian, Middle Babylonian Peripheral, Standard Babylonian, Neo-Babylonian, Late Babylonian, and Neo-Assyrian. This paper describes the approaches taken by  \tt{SharifCL} \normalfont team to this problem in VarDial 2019. The best result belongs to an ensemble of Support Vector Machines and a naive Bayes classifier, both working on character-level features, with macro-averaged F\textsubscript{1}-score of 72.10\%."
"In recent years, growing interest hierarchical multi-label classification applied wide range applications International Patent Classification , product annotation advertising recommendation . In common flat classification problem, input sample associated single label set disjoint labels. However, HMC problem, labels organized form tree Directed Acyclic Graph input sample usually associated multiple labels, made challenging. The straight-forward approach dealing HMC problem convert flat multi-label classification problem simply ignoring relevance labels . The main disadvantage loss useful hierarchical information. Alternatively, local approach designed perform multi-label classification, classifications carried level label hierarchy . The overall classification results generated based local predictions. While hierarchical information better utilized local approaches, misclassifications easily propagated next levels . Global approaches proposed learn single global model labels reduce model size consider entire label hierarchy . These global classifiers typically built flat classifiers modifications made integrate hierarchical information labels model. Recently, algorithms combine local global approaches proposed . All algorithms introduced focus design hierarchical classifier ignoring hierarchical features may extracted important HMC well. \citet{HARNN'2019} \citet{rojas2020efficient} consider hierarchical feature extraction work. However, extraction process designed fulfilled applying typical attention mechanism whole text. Since HMC problem text may associated multiple labels hierarchy level, features extracted typical attention may diluted. We believe reasonable hypothesize label-based attention, information extraction performed based different labels different hierarchical levels, would allow model interpretable overall better performance accuracy. Given motivations, propose LA-HCN --- HMTC model label-based attention facilitate label-based hierarchical feature extraction, introduce concept mechanism component intermediate representation helps bridge latent association words labels label-based attention. \paragraph{Contribution} Main contributions work:"," Hierarchical multi-label text classification  has been gaining popularity in recent years thanks to its applicability to a plethora of real-world applications. The existing HMTC algorithms largely focus on the design of classifiers, such as the local, global, or a combination of them. However, very few studies have focused on hierarchical feature extraction and explore the association between the hierarchical labels and the text. In this paper, we propose a Label-based Attention for Hierarchical Mutlti-label Text Classification Neural Network  , where the novel label-based attention module is designed to hierarchically extract important information from the text based on the labels from different hierarchy levels. Besides, hierarchical information is shared across levels while preserving the hierarchical label-based information. Separate local and global document embeddings are obtained and used to facilitate the respective local and global classifications. In our experiments, LA-HCN outperforms other state-of-the-art neural network-based HMTC algorithms on four public HMTC datasets. The ablation study also demonstrates the effectiveness of the proposed label-based attention module as well as the novel local and global embeddings and classifications. By visualizing the learned attention , we find that LA-HCN is able to extract meaningful information corresponding to the different labels which provides explainability that may be helpful for the human analyst."
"Multi-task learning problem minimizing average error across tasks, measured held-out samples, motivated observation sometimes learning single model partially shared parameters performs better single-task models. In learning-to-learn setting, worry error task . Both settings apply randomly initialized base learners, well architectures pre-trained yet another task. In learning-to-learn, new task assumed come ambiguity set defined tasks. Unsurprisingly, approaches multi-task learning minimize average loss across training samples available tasks. This always lead best solution, however, since relations loss error may differ across tasks. Several off- online methods normalizing relations proposed , even this, minimizing average loss across tasks two disadvantages: Performance outlier tasks may poor ; learning-to-learn setting, minimizing average loss optimal task selection unbiased . Minimizing worst-case loss across tasks instead average loss, theory solves two problems, approach popular algorithmic fairness domain adaptation covariate shift assumptions . In multi-task settings, possible directly modify loss minimized multi-task learning , example possible common approach multi-task learning batch sampled one tasks random . We present general approach multi-task learning worst-case-aware loss minimization, instead relying automated curriculum learning . \paragraph{Contributions} We present automated curriculum learning approach robust multi-task transfer learning. Our approach general parameterizes family worst-case-aware objectives, minimax loss-proportional minimization two extremes. In series experiments GLUE multi-task benchmark , show several objectives lead better performance benchmark itself, importantly, also lead much better generalization out-of-domain data sets. %Finally, show shared models learned using worst-case-aware curriculum learning also perform better learning-to-learn settings."," Multi-task transfer learning based on pre-trained language encoders achieves state-of-the-art performance across a range of tasks. Standard approaches implicitly assume the tasks, for which we have training data, are equally representative of the tasks we are interested in, an assumption which is often hard to justify. This paper presents a more agnostic approach to multi-task transfer learning, %, relying on $\alpha$-ball  which uses automated curriculum learning to minimize a new family of worst-case-aware losses across tasks. Not only do these losses lead to better performance on outlier tasks; they also lead to better performance in zero-shot and few-shot transfer settings."
"There wide range existing natural language processing toolkits CoreNLP , UDPipe , FLAIR , spaCy\footnote{https://spacy.io}, Stanza English, makes easier users build tools sophisticated linguistic processing. Recently, need Chinese NLP dramatic increase many downstream applications. A Chinese natural language processing platform always includes lexical analysis , named entity recognition ), syntactic parsing , semantic parsing ) modules. Unfortunately, relatively fewer high performance high-efficiency toolkits Chinese NLP tasks. To fill gap, important build Chinese NLP toolkit support Chinese basic NLP tasks, achieving enable researchers quickly process NLP tasks Chinese. Recently, introduce python NLP toolkit Stanza multi-lingual languages, including Chinese language. Though Stanza applied processing Chinese texts, suffers several limitations. First, supports part Chinese NLP tasks make semantic parsing analysis , resulting incomplete analysis Chinese NLP. Second, trained task separately, ignoring shared knowledge across related tasks, proven effective Chinese NLP tasks . In addition, modeling method occupy memory increase number tasks, makes hard deploy mobile devices real-word scenario. & & \\ \hline % CoreNLP & Java & & & & \\ % spaCy & Python & & & & \\ % CoreNLP & Java & & & & \\ LTP & C++ & & & & \\ UDPipe & C++ & & & & \\ FLAIR & Python & & & & \\ % spaCy & Python & & & & \\ Stanza & Python & & & & \\ \hline & Python & & & & \\ \hline \end{tabular} \end{adjustbox} \end{table*} In paper, introduce , PyTorch-based Chinese natural language processing toolkit NLP, built SOTA pre-trained model. As shown Figure, given Chinese corpus, produces comprehensive analysis results, including lexical analysis, syntactic parsing, semantic parsing. In addition, user-friendly fundamental tasks API visualization tool provided. %in-depth result analysis. As shown Table, compared existing widely-used NLP toolkits, following advantages: fully open-sourced support Chinese fundamental NLP tasks. We hope facilitate Chinese NLP research applications.","   We introduce \texttt{N-LTP}, an open-source Python Chinese natural language processing toolkit supporting five basic tasks: Chinese word segmentation, part-of-speech tagging, named entity recognition, dependency parsing, and semantic dependency parsing. \texttt{N-LTP} adopts the multi-task framework with the pre-trained model to capture the shared knowledge across all Chinese relevant tasks. In addition, we propose to use knowledge distillation where single-task models teach a multi-task model, helping the multi-task model surpass its single-task teachers.   Finally, we provide fundamental tasks API and a visualization tool to make users easier to use and view the processing results directly.   To the best of our knowledge, this is the first toolkit to support all Chinese NLP fundamental tasks.   Source code, documentation, and pre-trained models are available at \url{https://github.com/HIT-SCIR/ltp}."
"Building robust task-oriented dialogue systems challenging due complex system design limited availability human-annotated data. A dialogue agent expected learn dialogue reasoning, decision making, language generation, require large amount training data. However, collecting annotating data training dialogue system time-intensive transferable among domains. One possible workaround leverage pre-trained language model reduce human supervision. Recent progress pre-training language models shown promising alleviating data scarcity problem. Such models typically pre-trained large-scale plain text self-supervised objectives, e.g., language modeling language denoising. Fine tuning pre-trained language models improves wide range natural language processing applications, notably machine translation, personalized dialogue response generation. However, adapting pre-trained language models task-oriented dialogue systems trivial. Current state-of-the-art approaches task-oriented dialogue rely several tasks-specific modules, State Operation Predictor dialogue state tracking, CopyNet end-to-end dialogue task completion. Such modules usually absent pre-training stage. Therefore, tasks-specific architecture modifications required order adapt pre-trained language models different dialogue tasks. In work, aim simplify process transferring prior knowledge pre-trained language models improving task-oriented dialogue systems. We propose Minimalist Transfer Learning , simple yet effective transfer learning framework allows plug-and-play pre-trained sequence-to-sequence models jointly learn dialogue state tracking dialogue response generation. Unlike previous approaches, use copy mechanism ``carryover'' previous dialogue states generate new dialogue states, introduce Levenshtein belief spans models difference old states new states. In practice, MinTL first decodes updating previous dialogue state; then, updated state used search external knowledge base; finally, response decoder decodes response conditioning dialogue context knowledge base match result. MinTL easy set using different pre-trained seq2seq backbones. We conduct extensive experiments DST end-to-end dialogue response generation tasks two pre-trained seq2seq models, T5 BART. The experimental result large-scale task-oriented dialogue benchmark MultiWOZ suggests proposed method significantly improves SOTA performance full data simulated low resource setting. Our contributions summarized follows:"," In this paper, we propose Minimalist Transfer Learning  to simplify the system design process of task-oriented dialogue systems and alleviate the over-dependency on annotated data. MinTL is a simple yet effective transfer learning framework, which allows us to plug-and-play pre-trained seq2seq models, and jointly learn dialogue state tracking and dialogue response generation.  Unlike previous approaches, which use a copy mechanism to ``carryover'' the old dialogue states to the new one, we introduce Levenshtein belief spans , that allows efficient dialogue state tracking with a minimal generation length. We instantiate our learning framework with two pre-trained backbones: T5 and BART, and evaluate them on MultiWOZ. Extensive experiments demonstrate that: 1) our systems establish new state-of-the-art results on end-to-end response generation, 2) MinTL-based systems are more robust than baseline methods in the low resource setting, and they achieve competitive results with only 20\% training data, and 3) $Lev$ greatly improves the inference efficiency\footnote{Code available in \url{https://github.com/zlinao/MinTL}}."
"Recent advancements area generative modeling helped increase fluency generative models. However, several issues persist: coherence output semblance mere repetition/hallucination tokens training data . One reason could generation task typically construed end-to-end system. This contrast traditional approaches, incorporate sequence steps NLG system, including content determination, sentence planning, surface realization . A review literature psycholinguistics cognitive science also provides strong empirical evidence human language production process monolith . Prior approaches indeed incorporated content planning NLG system, example data-to-text generation problems well classic works include planning, based speech acts . Our work closely follows prior approaches, one crucial difference: planners based dialogue acts speech acts. Consider example Fig.. An input utterance Person B, statement , followed question , effectively responded using plans, learned generated, prior realization phase. The realization output include mention provides relief, consistent generated plan . Dialogue acts , nature, encompass wide variety realized output, hence cannot sufficiently constrain language model generation process. Research addressed issue adapting existing taxonomies towards goals . We instead use adapted extended form lexical-conceptual structures help constrain realization output effectively . Our work makes following contributions: \\ % \end{inparaenum}"," Achieving true human-like ability to conduct a conversation remains an elusive goal for open-ended dialogue systems. We posit this is because extant approaches towards natural language generation  are typically construed as end-to-end architectures that do not adequately model human generation processes.    To investigate, we decouple generation into two separate phases: planning and realization. In the planning phase, we train two planners to generate plans for response utterances. The realization phase uses response plans to produce an appropriate response. Through rigorous evaluations, both automated and human, we demonstrate that decoupling the process into planning and realization performs better than an end-to-end approach."
"A metaphor figurative form expression compares word phrase object action literally applicable helps explain idea suggest likeness analogy them. Metaphors used extensively types literature writings, especially poetry songs communicate complex feelings, emotions, visuals present text readers effectively. Metaphors ubiquitous natural language help structuring understanding world even without conscious realization presence. Given prevalence significance metaphorical language, effective detection metaphors plays essential role many natural language processing applications, example, language understanding, information extraction, sentiment analysis, etc. However, automated detection metaphorical phrases difficult problem primarily due three reasons. First, subjective component involved: metaphoricity expression may vary across humans. Second, metaphors domain context dependent. And third, lack annotated data, required train supervised machine learning algorithms facilitate automated detection accurately. Most previous approaches detection metaphorical phrases, either relied manual lexical detection requires heavily handcrafted features built linguistic resources, costly obtain greatly limits applicability used supervised machine learning based algorithms limited forms linguistic context, example using subject verb objects triplets . Although techniques automate detection metaphorical phrases, however, prediction accuracies good prediction accuracies techniques text classification tasks. Inspired recent works field NLP transfer learning, paper, present end-to-end method composed deep contextualized word embeddings, bidirectional LSTMs multi-head attention mechanism address limitations aforementioned. Our method notable sense unlike many existing approaches, requires raw text sequences input depend complex fine-tuned feature pipelines."," %% Text of abstract Metaphors are ubiquitous in natural language, and their detection plays an essential role in many natural language processing tasks, such as language understanding, sentiment analysis, etc. Most existing approaches for metaphor detection rely on complex, hand-crafted and fine-tuned feature pipelines, which greatly limit their applicability. In this work, we present an end-to-end method composed of deep contextualized word embeddings, bidirectional LSTMs and multi-head attention mechanism to address the task of automatic metaphor detection. Our method, unlike many other existing approaches, requires only the raw text sequences as input features to detect the metaphoricity of a phrase. We compare the performance of our method against the existing baselines on two benchmark datasets, TroFi, and MOH-X respectively. Experimental evaluations confirm the effectiveness of our approach."
"For text editing, sequence-to-sequence framework applied text simplification , punctuation restoration , grammatical error correction , machine translation post-editing , etc. We observe current inference methods roughly grouped two categories: End-to-end Tagging . For models categories, encoders extract encode information source text sequence. Yet, goal decoders different End2end Tagging. Upon receiving encoder's hidden states comprise source text information, decoder End2end directly decodes hidden states generates completely edited target text sequence. But, decoder Tagging produces sequence editing operations, deletion insertion, later applied source text yield edited text via realization step . The mechanisms End2end Tagging illustrated Figure .","  In neural text editing, prevalent sequence-to-sequence based approaches directly map the unedited text either to the edited text or the editing operations, in which the performance is degraded by the limited source text encoding and long, varying decoding steps. To address this problem, we propose a new inference method, Recurrence, that iteratively performs editing actions, significantly narrowing the problem space. In each iteration, encoding the partially edited text, Recurrence decodes the latent representation, generates an action of short, fixed-length, and applies the action to complete a single edit. For a comprehensive comparison, we introduce three types of text editing tasks: Arithmetic Operators Restoration , Arithmetic Equation Simplification , Arithmetic Equation Correction . Extensive experiments on these tasks with varying difficulties demonstrate that Recurrence achieves improvements over conventional inference methods."
"There broad consensus among grammar formalisms composition form meaning natural language resource-sensitive process, words making phrase contributing exactly resulting whole. The sentence ``the Mad Hatter offered'' ill-formed lack grammatical material, ``offer'' ditransitive verb; ``the Cheshire Cat grinned Alice cup tea'' hand ill-formed excess material, intransitive verb ``grin'' cannot accommodate. Given resource-sensitive nature language, comes surprise Linear Logic , particular intuitionistic version ILL, plays central role current logic-based grammar formalisms. Abstract Categorial Grammars Lambda Grammars use ILL ``as-is'' characterize abstract level grammatical structure surface form semantic interpretation obtained means compositional translations. Modern typelogical grammars tradition Lambek Calculus, e.g.~Multimodal TLG, Displacement Calculus, Hybrid TLG, refine type language account syntactic aspects word order constituency; ILL target logic semantic interpretation, reached homomorphism relating types derivations syntactic calculus semantic counterparts. A common feature aforementioned formalisms adoption parsing-as-deduction method: determining whether phrase syntactically well-formed seen outcome process logical deduction. This logical deduction automatically gives rise program meaning composition, thanks remarkable correspondence logical proof computation known Curry-Howard isomorphism, natural manifestation syntax-semantics interface. The Curry-Howard -terms associated derivations neutral respect particular semantic theory one wants adopt, accommodating truth-conditional view formal semantics vector-based distributional view, among others. Despite formal appeal, grammars based variants linear logic fallen favour within NLP community, owing scarcity large-scale datasets, also due difficulties aligning established high-performance neural toolkit. Seeking bridge gap formal theory applied practice, focus proof nets linear logic, lean graphical calculus away bureaucratic symbol-manipulation overhead characteristic conventional prooftheoretic presentations . Integrating proof nets recent advances neural processing, propose novel approach linear logic proof search eliminates issues commonly associated higher-order types hypothetical reasoning, greatly reducing computational costs structure manipulation, backtracking iterative processing burden standard parsing techniques . Our proposed methodology relies two key components. The first encoder/decoder-based supertagger converts raw text sentences linear logic judgements dynamically constructing contextual type assignments, one primitive symbol time. The second bi-modal encoder contextualizes generated judgement conjunction input sentence. The contextualized representations fed Sinkhorn layer, tasked finding valid permutation brings primitive symbol occurrences alignment. The architecture induced trained labeled data, assumes role formally grounded yet highly accurate parser, transforms raw text sentences linear logic proofs computational terms simply typed linear -calculus, decorated dependency annotations allow reconstruction underlying dependency graph ."," Linear logic and the linear $\lambda$-calculus have a long standing tradition in the study of natural language form and meaning. Among the proof calculi of linear logic, proof nets are of particular interest, offering an attractive geometric representation of derivations that is unburdened by the bureaucratic complications of conventional prooftheoretic formats. Building on recent advances in set-theoretic learning, we propose a neural variant of proof nets based on Sinkhorn networks, which allows us to translate parsing as the problem of extracting syntactic primitives and permuting them into alignment. Our methodology induces a batch-efficient, end-to-end differentiable architecture that actualizes a formally grounded yet highly efficient neuro-symbolic parser. We test our approach on {\AE}thel, a dataset of type-logical derivations for written Dutch, where it manages to correctly transcribe raw text sentences into proofs and terms of the linear $\lambda$-calculus with an accuracy of as high as $70\%$."
"Autoregressive language models functions estimate probability distribution next word sequence past words, . This requires capturing statistical dependencies words short timescales, syntactic information likely dominates , well long timescales, semantic narrative information likely dominate . Because probability distribution grows exponentially sequence length, approaches simplify problem ignoring long-range dependencies. Classical -gram models, example, assume word independent last words, typical . Hidden Markov models assume influence previous words decays exponentially distance current word . In contrast, neural network language models recurrent transformer networks include longer-range interactions, simplify problem working lower-dimensional representational spaces. Attention-based networks combine position content-based information small number attention heads flexibly capture different types dependencies within sequence . Gated recurrent neural networks compress information past words fixed-length state vector . The influence word state vector tends decay exponentially time. However, element state vector different exponential time constant, ``timescale'' , enabling gated RNNs like long short-term memory network flexibly learn many different types temporal relationships . Stacked LSTM networks reduce single layer , showing network depth insignificant influence LSTM captures temporal relationships. %Yet types networks flexibility comes cost, since models must learn shape dependencies data. %\ahcomment{rewrote substantially. think quite bit better now?} Yet networks shape temporal dependencies must learned directly data. This seems particularly problematic long-range dependencies, sparsely informative . This raises two related questions: temporal dependencies language model look like? And information incorporated neural network language model? To answer first question, look empirical theoretical work explored dependency statistics natural language. \citet{tegmark} quantified temporal dependencies English French language corpora measuring mutual information tokens function distance them. They observed mutual information decays power law, i.e.\ constant . This behavior common hierarchically structured natural languages well sequences generated probabilistic context-free grammars . %While precise shape dependency function may vary languages corpora, shall take given mathematical form follows power law. Now second question: temporal dependencies natural language follow power law, information incorporated neural network language models? To knowledge, little work explored control temporal dependencies learned attention-based models. However, many approaches proposed controlling gated RNNs, including updating different groups units different intervals , gating units across layers , explicitly controlling input forget gates determine information stored removed memory . Yet none proposals incorporate specific shape temporal dependencies based known statistics natural language. %\vvcomment{Rewrote last sentence -- claiming unclear relate theoretical stuff seems bit odd since directly control input/forget gates relate theory :D} \ahcomment{LOVE IT}%Yet unclear relate largely practical modifications theoretical properties models capture temporal dependencies. %\ahcomment{SHOULD WE SAY SOMETHING ABOUT TRANSFORMERS HERE? I'D LIKE TO, BUT I'M NOT EXACTLY SURE WHAT!} %\vvcomment{I'm tempted claim top paragraph nobody's really thought measure, let alone control, transformers encoding temporal dependencies words. So good candidate incorporating information need way measure specific, controllable mechanism group mechanismin model encode temporal dependencies words. Then say thought put RNNs...etc.} %\ahcomment{good suggestion!} In work, build framework \citet{chrono} develop theory memory mechanism LSTM language models capture temporal dependencies follow power law. This relies defining timescale individual LSTM unit based unit retains forgets information. We show theory predicts distribution unit timescales LSTM %We show theory predicts specific characteristics--the distribution timescales across LSTM units--of models trained natural English formal languages . Further, show forcing models follow theoretical distribution improves language modeling performance. These results highlight importance combining theoretical modeling understanding language models capture temporal dependencies multiple scales. %dependencies multiple timescales. %Effective language models capture statistical properties natural language, including information varies multiple timescales. For example, syntactic effects evolve timescale words, whereas semantics, emotions, narratives evolve much longer timescales tens hundreds thousands words. The importance long timescale information evident results showing neural networks outperformed classical n-gram models many language modeling benchmarks . This difference attributed networks' ability capture long timescale dependencies impossible n-gram models. Yet difficult interpret neural language models represent information different timescales, unclear timescale representations controlled yield better interpretable models. %One popular architecture neural language models recurrent neural networks, particular Long Short-Term Memory . Efforts interpret representations learned LSTMs using probing tasks shown LSTM language models capable learning short timescale information word order ~, long timescale semantic information~. Other methods attempted interpret timescale LSTM representations using predictive models brain responses natural language~. Yet question information different timescales maintained LSTM representations still satisfying answer. %One alternative interpreting representations existing models construct language models different layers groups units explicitly constrained operate different timescales. Several approaches proposed building explicitly multi-timescale models, including updating different groups units different intervals , gating units across layers , including explicit control input forget gates determine information stored removed memory . These approaches ease interpretation controlling timescales represented different units. Yet raises new concern: unlike standard LSTMs, explicitly multi-timescale models unable flexibly learn statistics natural language. This decrease performance models diminish utility. Thus, constructing explicitly multi-timescale language models important consider timescales present natural language. %\citet{tegmark} quantified distribution timescales natural language measuring mutual information tokens function distance them. They observed mutual information decays power law, common many hierarchical structures . It would desirable language model retain temporal information mimics statistics. However, clear attain power law using LSTMs, fundamentally designed decay information exponentially across time . %In work, present method control timescales information represented unit LSTM language model, resulting interpretable multi-timescale representations. Building theoretical grounding \citet{chrono}, quantify timescale represented unit using forget gate activations. We use framework analyze existing LSTM language model show different layers model retain information across time. Next, use framework construct explicitly multi-timescale language models timescale LSTM unit controlled setting forget input gate biases. To determine distribution timescales within model used prior mimics power law statistical properties natural language combination exponential timescales. Finally, show prior creates interpretable representations long short timescale information selectively routed different parts network.","  Language models must capture statistical dependencies between words at timescales ranging from very short to very long. %, but how much information is needed for each timescale? Earlier work has demonstrated that dependencies in natural language tend to decay with distance between words according to a power law. However, it is unclear how this knowledge can be used for analyzing or designing neural network language models. %However, it is unclear how power law decay of information should manifest in neural network language models. In this work, we derived a theory for how the memory gating mechanism in long short-term memory  language models can capture power law decay. We found that unit timescales within an LSTM, which are determined by the forget gate bias, should follow an Inverse Gamma distribution. Experiments then showed that LSTM language models trained on natural English text learn to approximate this theoretical distribution. Further, we found that explicitly imposing the theoretical distribution upon the model during training yielded better language model perplexity overall, with particular improvements for predicting low-frequency  words. Moreover, the explicit multi-timescale model selectively routes information about different types of words through units with different timescales, potentially improving model interpretability. These results demonstrate the importance of careful, theoretically-motivated analysis of memory and timescale in language models.   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % EMNLP version %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %Although neural language models are effective at capturing statistics of natural language, their representations are challenging to interpret. In particular, it is unclear how these models retain information over multiple timescales.  %In this work, we construct explicitly multi-timescale language models by manipulating the input and forget gate biases in a long short-term memory  network. %%In this work, we quantify and control the timescale of each unit in a LSTM language model via the the input and forget gate biases.  %The distribution of timescales is selected to approximate power law statistics of natural language through a combination of exponentially decaying memory cells. %%We then design a prior based on statistical properties of natural language and construct a multi-timescale LSTM language model.  %We then empirically analyze the timescale of information routed through each part of the model using word ablation experiments and forget gate visualizations. %%Next, we propose word ablation experiments and forget gate visualizations to interpret the timescale of information routing through the different parts of a model.  %These experiments show that the multi-timescale model successfully learns representations at the desired timescales, and that the distribution includes longer timescales than a standard LSTM.  %%Moreover, it outperforms the standard model on the language modeling task on the Penn Treebank and WikiText-2 datasets, especially on rare words. \ahcomment{change last sentence to point about interpretability} %Further, information about high-, mid-, and low-frequency words is routed preferentially through units with the appropriate timescales. %Thus we show how to construct language models with interpretable representations of different information timescales.  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %Shivangi's version %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Language models should ideally capture the statistical properties of natural language varying over multiple timescales. However, representations within language models  are challenging to interpret. Hence, it is unclear how different layers of an LSTM LM retain information over different timescales.  % % In this paper, we propose a mechanism to interpret and control the timescale of information routing through an LSTM unit. We observed that a standard LSTM LM favors representations of short timescale information . We then introduce a prior based on the statistical properties of language to control the distribution of the timescales across LSTM units to achieve an effective multi-timescale language model. In addition to this, we present a word ablation experiment and forget gate visualization to interpret the timescale of information routing through the different parts of the model. % % The proposed model learns representations of both short as well as long-timescale information. It also achieves better prediction performance than a standard LSTM LM on Penn Treebank and WikiText-2 datasets, especially on rare words."
"The advancement field Computer Vision ~ Natural Language Processing ~ last decade, introduced several interesting machine learning techniques. %problems convenient. The problems object detection~, segmentation~, image classification~ CV, machine translation~, question answering~, biomedical clinical text mining~ , speech recognition~ NLP, solved much efficiently ever before. This facilitated researchers indulge solving interdisciplinary problems demand knowledge fields. Visual Question Answering ~ emerged one problem. In VQA, task poised questions asked respect image, machine needs learn generate answers questions based learned features input image. In contrast typical CV tasks largely focus %have singular solving problems %restricted problems ~ Inception-Resnet-v2~, respectively. We fuse representations together pass specific answer prediction model leaf node. For task question classification root node, propose question segregation technique. We use Support Vector Machine ~ classifier hand-engineered word frequency-based features QS. We use machine learning technique QS, rule-based strategy suffers problem defining many rules may extend datasets~. The following examples RAdiology Data ~ show difficulty rule-based approach medical domain. Careful analysis question reveals first example expects descriptive type answer list facts indicate kidney hemorrhage , second example expects confirm presence/absence spleen . The presence anomalies question acts hindrance formation robust rules classification questions correct type. We perform experiments RAD ImageCLEF2018 VQA-Med 2018 datasets, perfectly capture problem statement intend solve. Detailed discussion dataset found Section. Experimental evaluation demonstrates promising results, showing effectiveness proposed approach. %'s efficiency. Additionally, error analysis system's outputs %error analysis shows future direction research area addressing different kinds errors. The organization paper follows. We first discuss related work VQA. Then present details methodologies implemented solve specific problem. In particular, explain proposed HQS-VQA models detail. Basically, discussed technique used question segregation module VQA components used generate query-specific answers. Details experiments along evaluation results necessary analysis reported. %We perform experiments show results qualitative quantitative analysis. Finally, conclude provide future directions work. \subsection{Motivation} The motivation behind work stemmed following facts: %of medical visual question answering listed follows: \end{adjustwidth} \end{table} \item We identify need, propose SVM-based question segregation technique segregate questions. We use information propose hierarchical deep multi-modal network generate answers. \end{itemize} \subsection{Contributions}","        {        Visual Question Answering in Medical domain  plays an important role in providing medical assistance to the end-users. These users are expected to raise either a straightforward question with a Yes/No answer or a challenging question that requires a detailed and descriptive answer. The existing techniques in VQA-Med fail to distinguish between the different question types sometimes complicates the simpler problems, or over-simplifies the complicated ones. It is certainly true that for different question types, several distinct systems can lead to confusion and discomfort for the end-users. To address this issue, we propose a hierarchical deep multi-modal network that analyzes and classifies end-user questions/queries and then incorporates a query-specific approach for answer prediction. We refer our proposed approach as Hierarchical Question Segregation based Visual Question Answering, in short HQS-VQA.      %   We first use the Support Vector Machine  with the hand-engineered features to classify the questions into yes/no and descriptive types.    % Then, based on the question types, we employ different strategies to provide the answer. The Yes/No type questions are treated as a binary classification problem. We generate the answer from a fixed vocabulary for the descriptive type question.     Our contributions are three-fold, viz. firstly, we propose a question segregation  technique for VQA-Med; secondly, we integrate the QS model to the hierarchical deep multi-modal neural network to generate proper answers to the queries related to medical images; and thirdly, we study the impact of QS in Medical-VQA by comparing the performance of the proposed model with QS and a model without QS. We evaluate the performance of our proposed model on two benchmark datasets, viz. RAD and CLEF18. Experimental results show that our proposed HQS-VQA technique outperforms the baseline models with significant margins. We also conduct a detailed quantitative and qualitative analysis of the obtained results and discover potential causes of errors and their solutions.         }"
The following instructions directed authors papers submitted EMNLP 2020 accepted publication proceedings. All authors required adhere specifications. Authors required provide Portable Document Format version papers. The proceedings designed printing A4 paper.," This document contains the instructions for preparing a manuscript for the proceedings of EMNLP 2020. The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like. These instructions should be used for both papers submitted for review and for final versions of accepted papers. Authors are asked to conform to all the directions reported in this document."
"The rapid development science technology world created vast amount data. In particular, growth social networks continuously creates huge amount comments posts valuable sources exploit analyze digital era. Text classification prerequisite works analyzing user opinion network environment, filtering removing malicious information, detecting criminal risk. With great potential, text classification attracted much attention experts natural language processing community worldwide. In English, easily search range text classification publications many fields. However, relatively researches done Vietnamese text. Most published articles focus binary classification. However, large amount information today requires analysis many aspects . The lack knowledge techniques Vietnamese language makes us decide conduct research classify multi-class text Vietnamese social media datasets. These datasets provided VLSP share-task publications text classification. In particular, various social media textual datasets UIT-VSMEC emotion recognition UIT-VSFC students' feedback classification HSD-VLSP hate speech detection . These datasets multi-label imbalance labels published recently. They suitable requirements would like study. The emergence deep neural networks word embeddings made text classification efficient. Pre-trained word embeddings accurately capture semantics assist deep learning models improve efficiency classification. In study, implement deep learning models CNN , LSTM variants solve classification problems. Besides, implement BERT model , state-of-the-art model many natural language processing tasks recent years. BERT trained transformer閳ユ獨 two-dimensional context . BERT contrast previous deep learning models looked text sequence left right combined left-to-right right-to-left training. To improve word representation, create normalized words dictionary, helps recognize words included pre-trained embedding represented due misspellings. As result, CNN model combined fastText's pre-trained embedding , remarkably performance Vietnamese social media datasets. Our study also proves efficiency BERT Vietnamese students' feedback dataset. Besides, combine single models increase efficiency classification. As result, ensemble model accomplishes higher results single model. Compared previous studies done datasets, models achieve better results."," Text classification is a popular topic of natural language processing, which has currently attracted numerous research efforts worldwide. The significant increase of data in social media requires the vast attention of researchers to analyze such data. There are various studies in this field in many languages but limited to the Vietnamese language. Therefore, this study aims to classify Vietnamese texts on social media from three different Vietnamese benchmark datasets. Advanced deep learning models are used and optimized in this study, including CNN, LSTM, and their variants. We also implement the BERT, which has never been applied to the datasets. Our experiments find a suitable model for classification tasks on each specific dataset. To take advantage of single models, we propose an ensemble model, combining the highest-performance models. Our single models reach positive results on each dataset. Moreover, our ensemble model achieves the best performance on all three datasets. We reach 86.96\% of F1-score for the HSD-VLSP dataset, 65.79\% of F1-score for the UIT-VSMEC dataset, 92.79\% and 89.70\% for sentiments and topics on the UIT-VSFC dataset, respectively. Therefore, our models achieve better performances as compared to previous studies on these datasets."
"The Transformer model achieved state-of-the-art performance various natural language preprocessing tasks, originally neural machine translation , recently massive multilingual machine translation , crosslingual pretraining , many tasks. There growing interest increasing model capacity Transformers, demonstrates improved performance various sequence modeling generation tasks . %However, still two challengee Training Transformers increased variable depth still open problem. Depending position layer norm sub-layer, backpropagating gradients multiple layers may suffer gradient vanishing . In addition, performance always improve simply stacking layers . When used multilingual multi-task pretraining, multilingual machine translation, crosslingual language modeling, etc., simplicity using one shared Transformer network languages appealing. However, share model capacity among languages facilitate positive transfer mitigating negative transfer well explored. %how determine part model share In work, present novel approach train deep Transformers, layers used effective depth static, learnt based underlying task. Concretely, model decision use layer latent variable, whose distribution jointly learnt rest Transformer parameters. %inference network acts layer weighting training, %\asa{I would say: 'At training time approximate discrete choice Gumbel-Softmax distribution. The `soft weights' sampled distribution also act gradient normalization layer, allows us train deep Transformers without using regular layer normalization layers. At inference time, learnt discrete choice used directly derive compact model pruning layers low probability, choice leaving learned layer selection probabilities soft weights.} At training time approximate discrete choice Gumbel-Softmax distribution. The `soft weights' sampled distribution also act gradient normalization layer, allows us train deep Transformers without using regular layer normalization layers. At inference time, learnt discrete choice used directly derive compact model pruning layers low probability, choice leaving learned layer selection probabilities soft weights. %At inference time, learnt discrete choice used directly derive compact model pruning layers low probability. Such dynamic ``soft weighting"" also acts gradient normalization layer, proposed approach used train deep Transformer without using regular layer normalization layers. By evaluating WMT'16 English-German machine translation masked language modeling tasks , show successfully train deeper Transformer outperform existing approaches terms quality training stability. %is learnt jointly rest Transfor weighs layer training contribution learn contribution layer %automatically learn Transformer layer use language multilingual machine translation task. Our approach allows training deep Transformer without vanishing exploding gradient. As result, enables using increased model capacity training, inference time pruning compact model using layer selection policies. %Our approach learns layer selection optimized improving translation quality language single Transformer network. At inference time, learnt sub-network %Our contributions follows: We show approach extended learn task-specific sub-networks learning different layer selection probabilities language pair multilingual machine translation. %learning multiple ``views"" layer selection shared Transformer. This result contributes growing interest learning efficient architectures multi-task transfer learning natural language understanding generation . %\asa{selfish plug cite BERT PALs here?} %Particularly, deep models trained WMT'16 English-German machine translation task, crosslingual masked language modeling task , 64-layer 96-layer encoders/decoders, respectively. The main contributions paper follows. We present probabilistic framework learn layers select Transformer architecture. Based framework, propose novel method train one shared Transformer network multilingual machine translation different layer selection probabilities language pair. The proposed method alleviates vanishing gradient issue enables stable training deep Transformers. We conduct experiments several tasks evaluate proposed approach: WMT'16 English-German machine translation, masked language modeling, multilingual many-to-one well one-to-many machine translation diverse languages. \end{comment} % First, present principled approach utilize layers Transformer architecture. Our method learns weighting selection Transformer layers. \xian{Is sentence clear?} %Our method learns latent layers used weighting selection one training without additional distillation steps \asa{This clear me?}. % Second, proposed method improves vanishing gradient issue thus enables stable training deep Transformers. We evaluate deep models latent layers WMT'16 English-German machine translation task task, 96-layer model crosslingual masked language modeling . % Third, show variant approach learn language-aware layer selections automatically determine layers share multilingual Transformer. % We evaluated effectiveness approach machine translation masked language modeling multiple languages. Our work contributes growing interest learning efficient architectures multi-task transfer learning natural language understanding generation, \end{comment} \paragraph{Why bad?} \paragraph{When happen?} \paragraph{How mitigate it?} \end{comment} %Our results contributes the, opens potentials %The rest paper organized follows. We present relevant background Sections present approach Section . We present experiments evaluation results Section analysis proposed approach Section ."," %We propose two approaches to improve Transformer for multilingual tasks such as multilingual machine translation, XLM-R, etc. We propose a new method to adaptively learn which layers to share in a multilingual Transformer. Our approach increased the depth of the decoder with stable training. Besides achieving superior quality, the learnt layer selection leads to a compact architecture with reduced inference cost.   %We present a principled approach to utilize layers in Transformers based on task distribution. Our method uses variational inference to learn optimal weighting of each layer. This approach enables training very deep Transformers without vanishing gradients. At inference time, the learnt layer selection posterior can be used for pruning to derive a compact model with reduced depth. We demonstrate the quality improvement from this method in multilingual sequence modeling, specifically multilingual machine translation and crosslingual masked language modeling , compared to strong baselines such as existing layer drop and wide models with similar number of parameters. Further analysis reveals such data-driven layer selection learns both specialization layers as well as common layers shared across languages.       The Transformer model has achieved state-of-the-art performance in many sequence modeling tasks. However, how to leverage model capacity with large or variable depths is still an open challenge. We present a probabilistic framework to automatically learn which layer to use by learning the posterior distributions of layer selection. As an extension of this framework, we propose a novel method to train one shared Transformer network for multilingual machine translation with different layer selection posteriors for each language pair. The proposed method alleviates the vanishing gradient issue and enables stable training of deep Transformers . We evaluate on WMT English-German machine translation and masked language modeling tasks, where our method outperforms existing approaches for training deeper Transformers. Experiments on multilingual machine translation demonstrate that this approach can effectively leverage increased model capacity and bring universal improvement for both many-to-one and one-to-many translation with diverse language pairs.   % In particular, we show that this approach can learn adaptive sub-networks by learning multiple ``views"" of layer selections in one shared Transformer. Our approach enables training deep Transformers  without vanishing gradients.  %training with latent layers.   %For multilingual machine translation we can learn a sub-network for each language pair by using different 'layer selection' probabilities per-language.      %\asa{bring universal improvement -> improves performance?}  %\xian{Here I want to express we can improve both average performance as well as performance for individual languages pairs; commenting discussion for now since I want to have a sharable version while we continue iterating}  % to leverage increased model capacity, which also can be pruned to its ``effective depth"" to derive a compact model.  .     %We present a principled approach to improve the training of Transformers by learning to both ``soft weight"" and ``hard select"" each layer via variational inference.     %This approach allows us to train very deep Transformers without layer normalization. At inference time, the learnt layer selection posterior can be used for pruning to derive a compact model with reduced depth. We evaluate the proposed approach on machine translation and masked languaage modeling tasks, where we can train deeper Transformer up to  100 layers with improved quality. On WMT En-De, and multilingual translation.   %We demonstrate the quality improvement from this method in several sequence modeling tasks such as machine translation , specifically multilingual machine translation and crosslingual masked language modeling , improving on strong baselines such as layer drop as well as wide models with a similar number of parameters. Analyzing the data-driven layer selection, we find bottom layers are shared across all languages, while top layers specialize to a particular language."
"In recent years, Transformers defined state-of-the-art performance variety NLP tasks, including machine translation language modeling. While large Transformer models learn uniquely rich representations, also highly overparameterized . Several studies therefore attempted prune Transformers training retaining much performance possible . Some methods fairly successful, achieving compression ratios 10 depending downstream task. Looking beyond task performance, however, remains unclear widely-used pruning methods affect model's learned representations. For example, pruned Transformer may translate text BLEU, pruning affect model ways unaccounted metric? Motivated question, apply recent analysis techniques study representations increasingly sparse Transformers trained MT. We perform magnitude pruning iterative, lottery-ticket fashion identify Transformers competitive sparsities drop task performance . We examine internal structures models sparsity increases, specifically addressing following questions: Using iterative magnitude pruning , train En-De Transformer retains 99.4\% BLEU 66.4\% sparsity. During IMP, obtain eight Transformer models varying levels sparsity, along original unpruned model. We probe models' representations learned linguistic knowledge eighteen auxiliary syntactic semantic tasks . We perform unsupervised comparison representations attention distributions dense sparse models, adopting metrics posed \citet{wu_similarity_2020}. Our key conclusions follows:"," Recent work on the lottery ticket hypothesis has produced highly sparse Transformers for NMT while maintaining BLEU. However, it is unclear how such pruning techniques affect a model's learned representations. By probing Transformers with more and more low-magnitude weights pruned away, we find that complex semantic information is first to be degraded. Analysis of internal activations reveals that higher layers diverge most over the course of pruning, gradually becoming less complex than their dense counterparts. Meanwhile, early layers of sparse models begin to perform more encoding. Attention mechanisms remain remarkably consistent as sparsity increases."
"ACM's consolidated article template, introduced 2017, provides consistent \LaTeX\ style use across ACM publications, incorporates accessibility metadata-extraction functionality necessary future Digital Library endeavors. Numerous ACM SIG-specific \LaTeX\ templates examined, unique features incorporated single new template. If new publishing ACM, document valuable guide process preparing work publication. If published ACM before, document provides insight instruction recent changes article template. The ``\verb|acmart|'' document class used prepare articles ACM publication --- conference journal, stage publication, review final ``camera-ready'' copy, author's version, {\itshape very} changes source."," With the ever-increasing growth of online recruitment data, job-resume matching has become an important task to automatically match jobs with suitable resumes. This task is typically casted as a supervised text matching problem. Supervised learning is powerful when the labeled data is sufficient. However, on online recruitment platforms, job-resume interaction data is sparse and noisy, which affects the performance of job-resume match algorithms.  \ignore{This task is typically casted as a supervised text matching problem.While supervised learning is powerful when the labeled data is sufficient and clean, the job-resume interaction in practice is usually sparse and noisy, which brings difficulties to effective text representation learning.}  To alleviate these problems, in this paper, we propose a novel multi-view co-teaching network from sparse interaction data for job-resume matching.  Our network consists of two major components, namely text-based matching model and relation-based matching model.  The two parts capture semantic compatibility in two different views, and complement each other.  In order to address the challenges from sparse and noisy data, we design two specific  strategies  to combine the two components. First, two components share the learned parameters or representations, so that the original representations of each component can be enhanced. More importantly, we adopt a co-teaching mechanism to reduce the influence of noise in training data. The core idea is to let the two components help each other by selecting more reliable training instances. The two strategies focus on representation enhancement and data enhancement, respectively.  Compared with pure text-based matching models, the proposed approach is able to learn better data representations from limited or even sparse interaction data, which is more resistible to noise in training data.  Experiment results have demonstrated that our model is able to outperform state-of-the-art methods for job-resume matching.  %In such a way, compared with pure text-based match models, the proposed approach is able to learn better representations from limited or even sparse interaction data, and is more resistible to noise in training data."
"In rule-based machine translation , linguist formalises linguistic knowledge lexicons grammar rules, used system analyse sentences source language translate them. While approach require parallel corpora training grants control translations created system, process encoding linguistic knowledge requires great amount expert time. Notable examples RBMT systems original, rule-based Systran , Lucy LT Apertium platform . Instead, corpus-based machine translation systems learn translate examples, usually form sentence-level aligned corpora. On one hand, approach generally computationally expensive offers limited control generated translations. Furthermore, feasible language pairs limited available parallel resources. On hand, parallel resources available, boasts much higher coverage targeted language pair. Examples corpus-based MT paradigms phrase-based statistical machine translation neural machine translation . In work, focused leveraging RBMT knowledge improving performance NMT systems under-resourced scenario. Namely, used information provided Lucy LT, RBMT system linguistic knowledge formalised human linguists computational grammars, monolingual bilingual lexicons. Grammars collections transformations annotated trees. Monolingual lexicons collections lexical entries, lexical entry set feature-value pairs containing morphological, syntactic semantic information. Bilingual lexicon entries include source-target lexical correspondences and, optionally, contextual conditions actions. The Lucy LT system divides translation process three sequential phases: analysis, transfer, generation. During analysis phase, source sentence morphologically analysed using lexicon identifies surface form plausible morphological readings. Next, Lucy LT chart parser together analysis grammar consisting augmented syntactic rules extracts underlying syntax tree structure annotates it. The transfer generation grammars applied succession tree, undergoes multiple annotations transformations add information equivalences target language adapt source language structures appropriate ones target language. Finally, terminal nodes generation tree assembled translated sentence. We focused analysis phase, special interest two features used: morphological category inflexion class classes lexical entries. %%% NE/TERM Additionally, focused two language phenomena easily addressable using RBMT present challenge using corpus-based MT: named entities terminological expressions. A named entity word sequence words unequivocally refer real-world object, proper nouns, toponyms, numbers dates. In context MT, NEs present different challenges. For example, English sentence starts word Smith, know priori dealing name profession, translated, proper noun may left untranslated, maybe transliterated different script. A second issue may arise using subword units: word-level models may accidentally preserve out-of-vocabulary NE, subword level model generate translation it. NEs one main out-of-vocabulary word classes, often cause translation problems seriously affect meaning sentence . Similarly, terminological expression consist single word sequence words may different meaning depending context domain appear. Hence, translation term might different depending context domain. Moreover, different contexts domains may impose additional restrictions language used, different modes use active passive voice, presence particular terminology may suggest translation acceptable even meaning source sentence preserved. Accurate terminology translation crucial produce adequate translations . In work extend analyse injection morphological information technique proposed previous word propose approach NEs terminology rely particular technology applied MT approach using kind resource detect translate NEs terminological expressions. To test proposed approach, focused English-Spanish , English-Basque, English-Irish English-Simplified Chinese language pairs under-resourced scenario, using corpora around one million parallel entries per language pair domain. Additional test sets contain several examples terms, NEs rich morphology also selected used explore performance proposed approaches. Results suggest that, obtaining results statistically significantly different baseline several scenarios, proposed approaches show appropriate behaviours keeping passive voice characteristic domains. %Results suggested adding morphological information source language effective using subword units particular setting."," Rule-based machine translation is a machine translation paradigm where linguistic knowledge is encoded by an expert in the form of rules that translate text from source to target language. While this approach grants extensive control over the output of the system, the cost of formalising the needed linguistic knowledge is much higher than training a corpus-based system, where a machine learning approach is used to automatically learn to translate from examples. In this paper, we describe different approaches to leverage the information contained in rule-based machine translation systems to improve a corpus-based one, namely, a neural machine translation model, with a focus on a low-resource scenario. Three different kinds of information were used: morphological information, named entities and terminology. In addition to evaluating the general performance of the system, we systematically analysed the performance of the proposed approaches when dealing with the targeted phenomena. Our results suggest that the proposed models have limited ability to learn from external information, and most approaches do not significantly alter the results of the automatic evaluation, but our preliminary qualitative evaluation shows that in certain cases the hypothesis generated by our system exhibit favourable behaviour such as keeping the use of passive voice. %Our results suggest that adding morphological information to the source language is as effective as using subword units in this particular setting."
"% Spoken Language Understanding technology plays crucial part goal-oriented dialogue systems. It typically involves intent detection slot filling tasks. As names imply, intent detection aims identify users閳 intents, slot filling focuses capturing semantic constituents user utterances . As shown Fig., given user query 閳ユイook restaurant next fall 5閳ユ, sampled SNIPS dataset , intent BookRestaurant assigned whole sentence, token sentence corresponds one specific slot type. Due process interdependence SLU subsequent dialogue components, dialogue manager natural language generator, performance two tasks, i.e., ID SF, determines upper limit utility dialogue system . Intuitively, intent detection slot filling associated , observed Fig.. For instance, intent utterance extit{PlayMusic, slots utterance likely artist rather cuisine, vice versa % . . As accumulation annotated queries, co-occurrence characteristic slot tags intent labels become prominent perceptible, providing hints mutual dependence ID SF. Hence, promising achieve complementary effect modeling two tasks joint fashion sharing knowledge them. % proposed using CNN based triangular CRF joint intent detection slot filling. % Some works simply rely shared parameters model co-occurrence characteristic implicit way. Some works proposed model intent-slot relation sharing parameters, outperforming previous separated models large margin. % With rise RNN-based methods attention mechanisms, practice working relationship intents slots joint models likely get sophisticated. More recently, gate mechanism attention mechanism also introduced RNN-based models , provides new perspective joint ID SF modeling. % proposed using slot-gated mechanism enhance slot filling performance intent information. To take one step further, proposed Stack-Propagation Framework incorporate token-level intent information better guide slot prediction process. This stacking neural network model could provide better interpretability slot-gated mechanism. However, methods still suffer various limitations. For one thing, local context information fully exploited models, ignoring intuition local context useful architectural inductive prior SF. For another thing, methods fail take full advantage supervised signals due implicit unidirectional modeling style intent-slot relations. Those limitations hinder improvement SLU systems, especially overall accuracy, highly depends joint performance ID SF. In work, propose novel Parallel Interactive Network address issues. For first issue, Gaussian self-attentive encoder introduced better capture local structure contextual information token, incorporates valuable inductive prior knowledge SF. For second issue, design Intent2Slot module Slot2Intent module model bidirectional information flow SF ID. Specifically, inspired Dual Process Theory neurocognitive science, divide information processing modules two stages: implicit interaction stage explicit interaction stage. These two stages correspond two different processing styles human brain operates: implicit , unconscious learning explicit , conscious learning. In implicit interaction stage, relationships intents slots implicitly captured parameters shared encoder, utilized intuitive decoders obtain token-level intent distribution slot label distribution. In explicit interaction stage, distribution information obtained former stage explicitly utilized rational decoders reduce solution space. Finally, cooperation mechanism, comprehensively considers information two stages, performed reduce prediction bias thereby improve precision accuracy model predictions. To verify effectiveness proposed method, conduct experiments two real-world datasets, i.e., ATIS SNIPS , popularly used benchmarks recent works. Empirical results show method achieves competent performance intent error rate, slot F1-score, sentence-level semantic frame accuracy compared baselines. % 閹存垿妫潻妯瑰▏閻⑩暈ert娴ｆ粈璐熸０鍕唲缂佸啯膩閸ㄥ绱濇潻娑楃濮濄儲褰侀崡鍥︾啊濡崇烽惃鍕冮悳鑸 In addition, Bidirectional Encoder Representation Transformer explored improve performance model. In summary, key contributions follows:"," % 闂侇厾顢婃担鍝ョ憥濞ｅ浂鍠楅弫濂告偋 Spoken Language Understanding  is an essential part of the spoken dialogue system, which typically consists of intent detection  and slot filling  tasks. Recently, recurrent neural networks  based methods achieved the state-of-the-art for SLU. It is noted that, in the existing RNN-based approaches, ID and SF tasks are often jointly modeled to utilize the correlation information between them. However, we noted that, so far, the efforts to obtain better performance by supporting bidirectional and explicit information exchange between ID and SF are not well studied. % However, we note that, so far, the explicit and bidirectional information flow for ID and SF tasks has not been explored to improve the performance of SLU.  % In addition, the utilization of the local context information will enhance the performance of SF.  In addition, few studies attempt to capture the local context information to enhance the performance of SF. Motivated by these findings, in this paper, Parallel Interactive Network  is proposed to model the mutual guidance between ID and SF. Specifically, given an utterance, a Gaussian self-attentive encoder is introduced to generate the context-aware feature embedding of the utterance which is able to capture local context information. Taking the feature embedding of the utterance, Slot2Intent module and Intent2Slot module are developed to capture the bidirectional information flow for ID and SF tasks. Finally, a cooperation mechanism is constructed to fuse the information obtained from Slot2Intent and Intent2Slot modules to further reduce the prediction bias. The experiments on two benchmark datasets, i.e., SNIPS and ATIS, demonstrate the effectiveness of our approach, which achieves a competitive result with state-of-the-art models. More encouragingly, by using the feature embedding of the utterance generated by the pre-trained language model BERT, our method achieves the state-of-the-art among all comparison approaches. % 闁告鍠撴晶 % Spoken Language Understanding  is an essential part of the spoken dialogue system, which typically consists of intent detection  and slot filling  tasks. Recurrent neural networks  based methods have achieved the state-of-the-art in SLU field. It is noted that, in those approaches, ID and SF are often jointly modeled due to the correlation between them.  % However, most existing joint models fall short of supporting bidirectional and explicit information exchange between ID and SF, which hinders the overall improvement of SLU systems.  % In addition, few studies have taken into account the explicit attention on local context, which is a useful structural inductive prior for SF task. Motivated by these findings, in this paper, Parallel Interactive Network  is proposed to model the mutual guidance between ID and SF. Specifically, given an utterance, we introduce a gaussian self-attentive encoder to extract context-aware features aiming at enhancing local structure information. Then these features are simultaneously fed to the Slot2Intent module and Intent2Slot module to build two-stage interactions where the semantic knowledge is both implicitly and explicitly shared between ID and SF tasks. Finally, a cooperation mechanism is proposed to fuse the information obtained from the two-stage interaction and further reduce the prediction bias. % The experiments on two benchmark datasets, i.e., SNIPS and ATIS, demonstrate the effectiveness of our approach, which achieves a competitive result with state-of-the-art models. % More encouragingly, by incorporating our approach to the pre-trained language model BERT, we outperform all comparison approaches and establish the new state-of-the-art performances in terms of slot F1-score and overall accuracy."
"Task-oriented dialogue systems designed help users achieve predefined goals, booking restaurants movie recommendations via natural language interactions. These systems deeply connected external Knowledge Bases since system responses guided output KB dialogue history. The current state-of-the-arts end-to-end pipelined systems rely Dialogue State Tracking Speech Act annotations. Aside annotation cost, knowingly high, pipelined systems must predict valid DST querying KB, execute query, generate response template, finally fulfill retrieved information. The resulting systems usually overly complicated, require multiple steps, including direct interaction KB. On end spectrum, end-to-end trainable models use KB dialogue history input, directly generate system responses. Most implementations use either Gold KB input intermediate API call retrieve part KB . These systems require least DST annotation generating API calls select gold KB. Moreover, even advanced transformer architecture, end-to-end models struggle input becomes large. For example, MWOZ, 22K entities one domains. Interested readers refer Appendix C overview different task-oriented methodologies. On hand, \citet{petroni2019language} discovered simple yet effective way query factual knowledge BERT. Later on, \citet{roberts2020much} fine-tuned pre-trained language model, T5, question-answers pairs, without letting model access external context knowledge. These results suggest actual knowledge stored model parameters. However, task-oriented dialogue systems, KB entities appear news articles Wikipedia, e.g., hotel addresses postcodes, thus aforementioned methods cannot straightforwardly applied, especially KB dynamically changes . In paper, propose method store KB directly model parameters using novel Knowledge Embedded approach. The resulting model use DST template responses, KB input inference time, used dynamically changing KBs via fine-tuning. The KE approach consists newly defined user goal query generates equivalents KE dialogues KB using minimal annotation effort. Figure shows high level overview approach. To verify effectiveness proposed methodology, extensively experiment, using automatic human metrics, five task-oriented datasets small, medium, large KBs. Our experiments show end-to-end models effectively embed knowledge bases parameters achieve competitive performance five datasets. % Additionally, show end-to-end models perform well pipelined modularized systems uses DST S-ACT."," %Task-Oriented Dialogue Systems are either modularized with separate dialog %state tracking  and management steps, or end-to-end trainable. In either case, %, and they can be very large. Task-oriented dialogue systems are either modularized with separate dialogue state tracking  and management steps or end-to-end trainable. In either case, the knowledge base  plays an essential role in fulfilling user requests. Modularized systems rely on DST to interact with the KB, which is expensive in terms of annotation and inference time. End-to-end systems use the KB directly as input, but they cannot scale when the KB is larger than a few hundred entries. In this paper, we propose a method to embed the KB, of any size, directly into the model parameters. The resulting model does not require any DST or template responses, nor the KB as input, and it can dynamically update its KB via fine-tuning. We evaluate our solution in five task-oriented dialogue datasets with small, medium, and large KB size. Our experiments show that end-to-end models can effectively embed knowledge bases in their parameters and achieve competitive performance in all evaluated datasets\footnote{Code available in \url{https://github.com/HLTCHKUST/ke-dialogue}}. % The resulting model do not access any external resource during the user interaction, and do not require any KB as input. % to learn to embed structured knowledge of any size directly with model parameters. % % We propose to fine-tune large pre-trained models for task-oriented dialog system with our approach to learning task-specific structured knowledge.   %This has the advantage of  as part of the input nor as an external source during the user interaction."
"Open domain question answering~ involves finding answers questions open corpus. The task led growing interest scalable end-to-end retrieval systems question answering. Recent neural retrieval models shown rapid improvements, surpassing traditional information retrieval~ methods BM25. When QA formulated reading comprehension task, cross-attention models like BERT achieved better-than-human performance benchmarks Stanford Question Answering Dataset . Cross-attention models especially well suited problems involving comparisons paired textual inputs, provide early fusion fine-grained information within pair. This encourages careful comparison integration details across within two texts. However, early fusion across questions answers poor fit retrieval, since prevents pre-computation answer representations. Rather, neural retrieval models independently compute embeddings questions answers typically using dual encoders fast scalable search. Using dual encoders results late fusion within shared embedding space. For machine reading, early fusion using cross-attention introduces inductive bias compare fine grained text spans within questions answers. This inductive bias missing single dot-product based scoring operation dual encoder retrieval models. Without equivalent inductive bias, late fusion expected require additional training data learn necessary representations fine grained comparisons. To support learning improved representations retrieval, explore supervised data augmentation approach leveraging complex classification model cross-attention question-answer pairs. Given gold question passage pairs, first train cross-attention classification model supervisor. Then collection questions used mine potential question passage pairs supervision cross-attention model. The retrieval model training benefits additional training pairs annotated graded predictions cross-attention model augmenting, existing gold data. Experiments reported MultiReQA-SQuAD MultiReQA-NQ, retrieval models establishing significant improvements Precision Mean Reciprocal Rank metrics."," Neural models that independently project questions and answers into a shared embedding space allow for efficient continuous space retrieval from large corpora. Independently computing embeddings for questions and answers results in late fusion of information related to matching questions to their answers. While critical for efficient retrieval, late fusion underperforms models that make use of early fusion . We present a supervised data mining method using an accurate early fusion model to improve the training of an efficient late fusion retrieval model. We first train an accurate classification model with cross-attention between questions and answers. The accurate cross-attention model is then used to annotate additional passages in order to generate weighted training examples for a neural retrieval model. The resulting retrieval model with additional data significantly outperforms retrieval models directly trained with gold annotations on Precision at $N$  and Mean Reciprocal Rank ."
"Topic models, Latent Dirichlet Allocation , aim discover underlying topics semantic structures text collections. Due interpretability effectiveness, LDA extended many Natural Language Processing tasks . Most models employ mean-field variational inference collapsed Gibbs sampling model inference result intractable posteriors. However, inference algorithms model specific require dedicated derivations. To address limitation, neural topic models black-box inference explored, flexible training schemes. Inspired variational autoencoder , \citet{miao2016nvdm} proposed Neural Variational Document Model interprets latent code VAE topics. Following way, \citet{srivastava2017prodlda} adopted logistic normal prior rather Gaussian mimic simplex properties topic distribution. Logistic normal Laplace approximation Dirichlet distribution . However, logistic normal exhibit multiple peaks vertices simplex Dirichlet distribution. Therefore, less capable capturing multi-modality crucial topic modeling . To overcome limitation, \citet{wang2019atm} proposed Adversarial-neural Topic Model , topic model based Generative Adversarial Networks sampling topics directly Dirichlet distribution impose Dirichlet prior. ATM employs generator transforming randomly sampled topic distributions word distributions, adversarially trained discriminator estimating probability word distribution came training data rather generator. Although ATM shown effective discovering coherent topics, used induce topic distribution given document due absence topic inference module. Such limitation hinders application downstream tasks, text classification. Moreover, ATM fails deal document labels help extract coherent topics. For example, document labeled `sports' likely belongs topics `basketball' `football' rather `economics' `politics'. To address limitations ATM, propose novel neural topic modeling approach, named Topic Modeling Cycle-consistent Adversarial Training . In ToMCAT, topic modeling cast transformation topic distributions word distributions. Specifically, transformation topic distributions word distributions used interpret topics, reverse transformation used infer underlying topics given document. Under formulation, ToMCAT employs generator transform topic distributions randomly sampled Dirichlet prior corresponding word distributions, encoder reversely transform documents represented word distributions topic distributions. To encourage generator/encoder produce realistic target samples, discriminators word/topic distributions introduced enable adversarial training. Additional cycle-consistency constraints utilized align learning encoder generator prevent contradicting other. Furthermore, documents labels, propose sToMCAT introduces extra classifier regularize topic modeling process. The main contributions paper are:","   Advances on deep generative models have attracted significant research interest in neural topic modeling.   The recently proposed Adversarial-neural Topic Model models topics with   an adversarially trained generator network   and employs Dirichlet prior to capture the semantic patterns in latent topics.   It is effective in discovering coherent topics but unable to infer topic distributions for given documents   or utilize available document labels.   To overcome such limitations, we propose Topic Modeling with Cycle-consistent Adversarial Training    and its supervised version sToMCAT.   ToMCAT employs a generator network to interpret topics and an encoder network to infer document topics.   Adversarial training and cycle-consistent constraints are used to   encourage the generator and the encoder to produce realistic samples that coordinate with each other.   sToMCAT extends ToMCAT by incorporating document labels   into the topic modeling process to help discover more coherent topics.   The effectiveness of the proposed models is evaluated on unsupervised/supervised topic modeling and   text classification.   The experimental results show that our models can produce both coherent and informative topics,   outperforming a number of competitive baselines."
"Probabilistic topic models tools discovering main themes large corpora. The popular Latent Dirichlet Allocation variants effective extracting coherent topics interpretable manner, usually cost designing sophisticated model-specific learning algorithm. Recently, neural topic modeling utilizes neural-network-based black-box inference main research direction field. Notably, NVDM employs variational autoencoder model topic inference document generation. Specifically, NVDM consists encoder inferring topics documents decoder generating documents topics, latent topics constrained Gaussian prior. \citet{srivastava2017prodlda} argued Dirichlet distribution appropriate prior topic modeling Gaussian NVDM proposed ProdLDA approximates Dirichlet prior logistic normal. There also attempts directly enforced Dirichlet prior document topics. W-LDA models topics Wasserstein autoencoders framework achieves distribution matching minimizing Maximum Mean Discrepancy , adversarial topic model directly generates documents Dirichlet prior process adversarially trained discriminator framework Generative Adversarial Network . Recently, due effectiveness Graph Neural Networks embedding graph structures, surge interests applying GNN natural language processing tasks . For example, GraphBTM neural topic model incorporates graph representation document capture biterm co-occurrences document. To construct graph, sliding window document employed word pairs window connected. A limitation GraphBTM word relationships considered ignoring document relationships. Since topic possessed subset documents corpus, believe topical neighborhood document, i.e., documents similar topics, would help determine topics document. To end, propose Graph Topic Model , neural topic model corpus represented document relationship graph documents words corpus nodes connected based document-word co-occurrences. In GTM, topical representation document node aggregated multi-hop neighborhood, including document word nodes, using Graph Convolutional Network . As GCN able capture high-order neighborhood relationships, GTM essentially capable modeling word-word doc-doc relationships. In specific, relationships relevant documents established shared words, desirable topic modeling documents belonging one topic typically similar word distributions. The main contributions paper are:","   Graph Neural Networks    that capture the relationships between graph nodes via message passing   have been a hot research direction   in the natural language processing community.   In this paper, we propose Graph Topic Model , a GNN based neural topic model   that represents a corpus as a document relationship graph.   Documents and words in the corpus become nodes in the graph and   are connected based on document-word co-occurrences.   By introducing the graph structure,   the relationships between documents are established through their shared words   and thus the topical representation of a document is enriched by   aggregating information from its neighboring nodes using graph convolution.   Extensive experiments on three datasets were conducted   and the results demonstrate the effectiveness of the proposed approach."
"% {\color{red}jiaqi: outlines} % \ys{Need put Covid information here. Logic need covid 19 rather information so. } In work, report system architecture results team TEST\_POSITIVE competition W-NUT 2020 sharred Task-3: extracting COVID-19 event Twitter. Since February 2020, pandemic COVID-19 spreading world, posing significant threat mankind every aspect. The information sharing pandemic critical stopping virus spreading. With recent advance social networks machine learning, able automatically detect potential events COVID cases, identify key information prepare ahead. % \kenneth{I would probably make explicit ``this paper reports system architecture results team ABC XYZ competition IMWUT 2020''.} % Users share wide range information social networks. Large platforms, Twitter Facebook, provide sufficient user-generated content natural language processing applications. For example, massive tweet data posted users nourished variety applications, e.g. sentiment analysis ~, disaster monitoring ~, event extraction ~ etc. We interested COVID-19 related event extraction tweets. With prevalence coronavirus, Twitter valuable source news information. Twitter users share COVID-19 related topics personal narratives news social media . The information could helpful doctors, epidemiologists, policymakers controlling pandemic. However, manual extracting useful information tremendous amount tweets impossible. Hence, aim develop system automatically extract structured knowledge Twitter. % \ys{According Chieh-Yang, using global model solved issue limited annotation, using various types tasks use event data training.} Extracting COVID-19 related events Twitter non-trivial due following challenges: \\ How deal limited annotations heterogeneous events subtasks?. The creation annotated data relies completely human labors, thus limited amount data obtained event categories. There variety types events subtasks. % Due sparsity positive samples, % \cc{why due sparsity positve samples} annotation cannot scale properly thus limited amount data obtained. % The training dataset relies manual annotation. Hence, obtain limited number training data. Many existing works solve low resource problem different approaches, inlcuding crowdsourcing , unsupervised training , multi-task learning . Here adopt multi-task training paradigm benefit inter-event intra-event information sharing. In way, \ours learns shared embedding network globally events data. In way, implicitly augment dataset global training fine-tuning language model. % events subtasks share similarities % make use fundamental relations across different subtasks events learning global embedding network. % Heterogeneous types events subtasks. How make type-aware predictions? Existing work encode information different subtask types model, could useful suggesting candidate slot entity type. In order make type-aware predictions, propose NER-based post-processing procedure end \ours pipeline. We use NER automatically tag candidate slots remove candidate whose entity type match corresponding subtask type. For example, shown Figure, subtask ``Who'', ``my wife's grandmother'' valid candidate slot, ``old persons home'', tagged location entity, would replaced ``Not Specified'' post-processing. % UK閳 valid slot subtask 閳ユ辅ho閳,as 閳ユ辅ho閳 would require human-related descrip-tion 閳ユ矾K閳 tagged location-related entityby NER. % % % trains % tackles event separately trains multiple models different events. % \cy{Didn't see reason become challenge.} % To tackle aforementioned challenges, propose \underline{Jo}int \underline{E}vent Mu\underline{l}ti-task Learn\underline{in}g model. % Built upon joint event multi-task learning framework, \ours benefits training data across event types. % In way, implicitly augment dataset global training fine-tuning embedding parameters. % Furthermore, design type-aware post-processing step automatically remove predictions whose entities match corresponding subtask types leveraging named entity recognition . % For example, ``UK'' valid slot subtask ``who'', ``who'' would require human-related description ``UK'' tagged location-related entity NER. % \kenneth{This example quite confusing. Need make clear.} % For example, predicted slot subtask ``who'' tagged location related entity, invalidate prediction ``Not Specified''. % In summary, \ours enabled following technical contributions:\\ % % % covid-19 wide spreading % To automatically extract structured knowledge events % related COVID-19 Twitter useful epidemiologists, journalist policymakers. % Challenges: Noisy text Twitter; Limited training data; % In work, propose joint event multi-task learning model noisy text slot filling tasks limited training data. % Our Contributions: % %","  The competition of extracting COVID-19 events from Twitter is to develop systems that can automatically extract related events from tweets. The built system should identify different pre-defined slots for each event, in order to answer important questions . To tackle these challenges, we propose the \underline{Jo}int \underline{E}vent Mu\underline{l}ti-task Learn\underline{in}g  model. Through a unified global learning framework, we make use of all the training data across different events to learn and fine-tune the language model.  Moreover, we implement a type-aware post-processing procedure using named entity recognition  to further filter the predictions. \ours outperforms the BERT baseline by $17.2\%$ in micro F1.\footnote{\url{https://github.com/Chacha-Chen/JOELIN}}    % Extracting structured knowledge from Twitter is non-trivial because:  Limited annotated data: structured knowledge needs to be annotated manually;   Various types of tasks: there are different types of slot filling tasks for different events and subtasks.   % To tackle these challenges, we propose \underline{Jo}int \underline{E}vent Mu\underline{l}ti-task Learn\underline{in}g  model. Through a unified global learning framework, we make use of all the training data across different events to learn and fine-tune the language embedding parameters.  Moreover, we implement a type-aware post-processing procedure using NER-based techniques to further filter the predictions.\footnote{\url{https://github.com/Chacha-Chen/JOELIN}} % \kenneth{ I would give one or two examples about the event types-- what is an ``event relevant to COVID-19''? It's unclear in the abstract alone.  I would probably just say the performance numbers in the abstract. What is the performance of the proposed method?} % \jq{Thanks! Kenneth}"
"In era digitization, businesses turning towards leveraging artificial intelligence techniques exploit information contained business documents. Traditional information extraction approaches utilize Natural Language Processing methods process information documents expressed form natural language text . However, documents contain rich multi-modal information includes text document layout. The document layout organises textual information different formats sections, paragraphs, tables, multi-column etc. utilising different font-types/colors/positions/sizes/styles. Further, important visual cues also indicated figures/charts/logos etc. overall document page appearance. In general, information document spans multiple pages gives rise variety complex document layouts observed scientific articles, invoices, receipts, emails, contracts, presentations, blogs, etc. Analyzing understanding documents challenging endeavor requires multi-disciplinary perspective combining NLP, computer vision , knowledge-representation learn generic document representation suitable different downstream applications . Recent approaches towards document analysis explored frameworks utilize information document text, document layout document image different capacities specific document tasks. proposed joint training document text structure task IE form-like documents, combine text image information task semantic segmentation documents. Their proposed frameworks optimize network performance respect downstream task suitable tasks. To address limitation, proposed pre-training technique based BERT transformer architecture , combine text layout information scanned documents. They showcase applicability pre-trained network different downstream tasks utilizing image information fine-tuning task. Although presents pre-trained framework learn document representation, two limitations approach - framework allows single page documents proposed pre-training tasks cannot utilize image information learning document representation. In real-world scenario, multi-page documents common different pages potentially containing different information across text, layout, image dimensions. Also, page image captures overall layout beyond appearance text tokens document. Thus, serving different documents tasks, unified pre-training framework learns generic document representation three modalities works multi-page documents necessary. In paper, propose generic document representation learning framework takes input document text, layout, image information applicable different document tasks. Specifically, encode multi-modal document information - text position embeddings similar BERT text token 2D position embeddings capture layout, text token image embeddings capture appearance, document page image position embeddings learn document representation capable handling multi-page documents. In order handle large token sequences courtesy multi-page documents, utilize Longformer model proposed backbone framework introduces attention mechanism scales linearly sequence length. Following work , utilize Masked Visual Language Modelling task document classification task enforces joint pre-training input embeddings. To ensure network learns image embeddings, introduce two additional self-supervised pre-training tasks framework - document topic modeling document shuffle prediction . Similar work , mine latent topics document text train framework predict topic distribution using document page image embeddings task DTM. On hand, DSP involves shuffling page image order keeping embeddings intact randomly sampled documents training identify document tampered with. While DSP task enforces joint pre-training image embeddings text layout embeddings, DTM task helps learn richer page image embeddings. As explored different approaches prior art , employ multi-task learning framework simultaneously train multiple objectives different pre-training tasks learn shared representations across text, layout, image modalities documents. We train network publicly available ArXiv dataset contains millions research articles spanning variety STEM domains mathematics, physics, computer science, etc. Fig. signifies applicability pre-trained embeddings different document tasks. We evaluate performance framework following tasks datasets - Form Understanding IE scanned forms Document Classification Table Token Classification Document Retrieval . We conduct exhaustive set experiments analyze performance pre-trained embeddings state-of-the-art baselines ablations framework. We're able beat SOTA baselines trained comparable dataset size network parameters tasks. In summary, main contributions work are: % We're able beat SOTA performance certain tasks achieve comparable performance cases utilizing pre-trained embeddings fine-tuning task. In summary, main contributions work"," In this paper, we propose a multi-task learning-based framework that utilizes a combination of self-supervised and supervised pre-training tasks to learn a generic document representation. We design the network architecture and the pre-training tasks to incorporate the multi-modal document information across text, layout, and image dimensions and allow the network to work with multi-page documents. We showcase the applicability of our pre-training framework on a variety of different real-world document tasks such as document classification, document information extraction, and document retrieval. We conduct exhaustive experiments to compare performance against different ablations of our framework and state-of-the-art baselines. We discuss the current limitations and next steps for our work and make the code available to promote future research in this direction.   % In this paper, we propose a multi-task learning-based framework that utilizes a combination of self-supervised and supervised pre-training tasks to learn a generic document representation. We design the network architecture and the pre-training tasks to incorporate the multi-modal document information across text, structure, and image dimensions and allow the network to work with multi-page documents. We showcase the applicability of our pre-training framework on a variety of different real-world document tasks such as document classification, document information extraction, document table structure detection, and document retrieval. We conduct exhaustive experiments to compare performance against different ablations of our framework and SOTA baselines.  % To the best of our knowledge, this is the first approach in which multiple pages \& token-level visual information is encoded along with text and layout during pre-training.  % Our model outperforms existing SOTA baselines pre-trained on comparable dataset sizes across various downstream tasks. We discuss the current limitations and next steps for our work and make the code available to promote future research in this direction."
"Discourse coherence subject much research Computational Linguistics thanks widespread applications . Most current methods described either stemming explicit representations based Centering Theory , deep learning approaches learn without use hand-crafted linguistic features. Our work explores third research avenue based Rhetorical Structure Theory . We hypothesize texts low/high coherence tend adhere different discourse structures. Thus, pose using even silver-standard RST features help separating coherent texts incoherent ones. This stems definition coherence - writer document needs follow specific rules building clear narrative argument structure role constituent document appropriate respect local global context, even existing discourse parsers able predict plausible structure consistent across coherent documents. However, parser difficulty interpreting given document, likely produce unrealistic trees improbable patterns discourse relations constituents. This idea first explored \citeauthor{feng-etal-2014-impact} \shortcite{feng-etal-2014-impact}, followed approach similar \citeauthor{Barzilay-Entity-Grid} \shortcite{Barzilay-Entity-Grid} estimating entity transition likelihoods, instead using discourse relations entities participate opposed grammatical roles. Their method achieved significant improvements performance even using silver-standard discourse trees, showing potential use parsed RST features classifying textual coherence. Our work, however, first develop test neural approach leveraging RST discourse representations coherence evaluation. Furthermore, \citet{feng-etal-2014-impact} tested proposal sentence permutation task, involves ranking sentence-permuted text original. As noted \citet{lai-grammerly}, accurate proxy realistic coherence evaluation. We evaluate method realistic Grammarly Corpus Of Discourse Coherence , model needs classify naturally produced text one three levels coherence. Our contributions involve: RST-Recursive, RST-based neural tree-recursive method coherence evaluation achieves 2\% state art performance GCDC 62\% fewer parameters. When ensembled current state art, namely Parseq , achieve notable improvement plain ParSeq model. We demonstrate usefulness silver-standard RST features coherence classification, establish results lower-bound performance improvements gained using RST features."," This paper evaluates the utility of Rhetorical Structure Theory  trees and relations in discourse coherence evaluation. We show that incorporating silver-standard RST features can increase accuracy when classifying coherence. We demonstrate this through our tree-recursive neural model, namely RST-Recursive, which takes advantage of the text's RST features produced by a state of the art RST parser. We evaluate our approach on the Grammarly Corpus for Discourse Coherence  and show that when ensembled with the current state of the art, we can achieve the new state of the art accuracy on this benchmark. Furthermore, when deployed alone, RST-Recursive achieves competitive accuracy while having 62\% fewer parameters.  %This paper explores the impact of silver-standard Rhetorical Structure Theory  trees and relations on discourse coherence evaluation. We show that incorporating discourse features benefits the previous state of the art model and also propose three models based on Recursive Neural Networks. We evaluate our models on the Grammarly Corpus for Discourse Coherence , showing promising results with one model achieving new state of the art performance on discourse classification, and another nearing previous state of the art accuracy. In addition, we provide valuable insights with respect to the application and behaviour of RST relations and trees in discourse analysis, and motivate future work in this area."
"Medical code assignment categorizes clinical documents sets codes facilitate hospital management improve health record searching~. These clinical texts comprise physiological signals, laboratory tests, physician notes, International Classification Diseases coding system widely used annotation. Most hospitals rely manual coding human coders assign standard diagnosis codes discharge summaries billing purposes. However, work error-prone~. Incorrect coding cause billing mistakes mislead general practitioners patients readmitted. Intelligent automated coding systems could act recommendation system help coders allocate correct medical codes clinical notes. Automatic medical code assignment intensively researched past decades~. Recent advances natural language processing deep learning techniques inspired many methods automatic medical code assignment~. \citet{zhang2019learning} incorporated structured knowledge medical text representations preserving translational property concept embeddings. However, several challenges remain medical text understanding. Diagnosis notes contain complex diagnosis information, includes large number professional medical vocabulary noisy information non-standard synonyms misspellings. Free text clinical notes lengthy documents, usually hundreds thousands tokens. Thus, medical text understanding requires effective feature representation learning complex cognitive process enable multiple diagnosis code assignment. Previous neural methods medical text encoding generally fall two categories. Medical text modeling commonly regarded synonym recurrent neural networks capture sequential dependency. Such works include AttentiveLSTM~, Bi-GRU~ HA-GRU~. The category uses convolutional neural networks CAML~ MultiResCNN~. These methods capture locality achieved optimal predictive performance medical code assignment. Inspired generic temporal convolutional network architecture~, consider medical text modeling causal constraints, encoding current token depends previous tokens, using dilated convolutional network. We combine label attention network fine-grained information aggregation. \paragraph{Distinction Our Model} The MultiResNet currently state-of-the-art model. It applies multi-channel CNN different filters learn features concatenates features produce final prediction. In contrast, model extends TCN sequence modeling uses single filter dilation operation control receptive field. In addition, instead weight tying used TCN, customize label attention pooling extract relevant rich features. \paragraph{Our Contributions} We contribute literature three ways. We consider medical text modeling perspective imposing sequential causal constraint medical code assignment using dilated convolutions, effectively captures long sequential dependencies learns contextual representations long clinical notes. We propose dilated convolutional attention network , coupling residual dilated convolution, label attention network effective efficient medical text modeling. Experiments real-world medical data show improvement state art. Compared multi-channel CNN RNN models, model also offers smaller computational cost."," Medical code assignment, which predicts medical codes from clinical texts, is a fundamental task of intelligent medical information systems. The emergence of deep models in natural language processing has boosted the development of automatic assignment methods.  However, recent advanced neural architectures with flat convolutions or multi-channel feature concatenation ignore the sequential causal constraint within a text sequence and may not learn meaningful clinical text representations, especially for lengthy clinical notes with long-term sequential dependency. This paper proposes a Dilated Convolutional Attention Network , integrating dilated convolutions, residual connections, and label attention, for medical code assignment. It adopts dilated convolutions to capture complex medical patterns with a receptive field which increases exponentially with dilation size. Experiments on a real-world clinical dataset empirically show that our model improves the state of the art."
"The Transformer translation model , outperformed previous RNN/CNN based sequence-to-sequence models, based multi-head attention networks. The multi-head attention mechanism, computes several scaled dot-product attention parallel, efficiently parallelized sequence level RNNs , addressing drawback CNNs model contexts inside fixed window. Even though advantages parallelization multi-head attention mechanism, recent studies suggest computation scaled dot-product attention sufficiently efficient, especially handling long sequences, due quadratic increasing size attention matrix. In paper, study accelerate inference scaled dot-product attention another perspective. Specifically, propose learn hard retrieval attention attends one position sequence rather tokens simplify computation scaled dot-product attention. Since hard attention mechanism attends one token, matrix multiplication attention probabilities value sequence standard scaled dot-product attention achieved simple efficient retrieval operation. Our contributions follows:"," The Transformer translation model that based on the multi-head attention mechanism can be parallelized easily and lead to competitive performance in machine translation. The multi-head attention network performs the scaled dot-product attention function in parallel, empowering the model by jointly attending to information from different representation subspaces at different positions. Though its advantages in parallelization, many previous works suggest the computation of the attention mechanism is not sufficiently efficient, especially when processing long sequences, and propose approaches to improve its efficiency with long sentences. In this paper, we accelerate the inference of the scaled dot-product attention in another perspective. Specifically, instead of squeezing the sequence to attend, we simplify the computation of the scaled dot-product attention by learning a hard retrieval attention which only attends to one token in the sentence rather than all tokens. Since the hard attention mechanism only attends to one position, the matrix multiplication between attention probabilities and the value sequence in the standard scaled dot-product attention can be replaced by a simple and efficient retrieval operation. As a result, our hard retrieval attention mechanism can empirically accelerate the scaled dot-product attention for both long and short sequences by $66.5\%$, while performing competitively in a wide range of machine translation tasks when using for cross attention networks."
"Neural Machine Translation opened new opportunities transfer learning high-resource low-resource language pairs . While transfer learning shown great promise, transfer languages different scripts brings additional challenges. For successful transfer embedding layer, parent child model use partially overlapping vocabulary . It common merge two vocabularies aligning identical subwords randomly assigning remaining subwords child vocabulary positions parent vocabulary . This works well transfer languages use script, child language written unseen script, vocabulary positions replaced random subwords. This significantly reduces transfer embedding layer. \citet{gheini2019universal} argue romanization improve transfer languages unseen scripts. However, romanization also introduce information loss might hurt translation quality. In work, study usefulness romanization transfer many-to-many multilingual MT models low-resource languages different scripts. Our contributions following:"," Transfer learning is a popular strategy to improve the quality of low-resource machine translation. For an optimal transfer of the embedding layer, the child and parent model should share a substantial part of the vocabulary.   This is not the case when transferring to languages with a different script. We explore the benefit of romanization in this scenario. Our results show that romanization entails information loss and is thus not always superior to simpler vocabulary transfer methods, but can improve the transfer between related languages with different scripts. We compare two romanization tools and find that they exhibit different degrees of information loss, which affects translation quality. Finally, we extend romanization to the target side, showing that this can be a successful strategy when coupled with a simple deromanization model."
"Machine learning models used practice today predominantly supervised models rely large datasets labeled training. However, cost collecting maintaining labeled training data remains bottleneck training high-capacity supervised models. Data programming aims address difficulty collecting labeled data using programmatic approach weak supervision heuristics, domain experts expected provide data programs incorporating domain knowledge. Prior work data programming focuses modeling aggregating labeling functions written manually generated automatically denoise labeling functions. % However, little known user experience % writing labeling functions improve it. Writing data programs be, however, challenging time consuming. Most domain experts lay users little programming literacy, even proficient programmers, often difficult convert domain knowledge set rules writing programs. % By extending data programming programming example, bridge gap scalable training data generation domain experts. To address challenges, introduce data programming demonstration , new framework aims make creating labeling functions easier learning users' interactive visual demonstrations. DPBD moves burden writing labeling functions intelligent synthesizer enabling users steer synthesis process multiple semantic levels, providing rationales relevant labeling choices interactively filtering proposed functions. DPBD draws two lines prior research; programming demonstration example , e.g.,, aims make programming easier synthesizing based user interactions input output examples, interactive learning user-provided features rationales . We operationalize framework \system, interactive system enables accessible data programming create labeled training datasets document classification. \system automatically generates document level labeling rules span-level annotations relations specific examples provided users. Through user study conducted 10 data scientists, evaluate \system alongside manual data programming using Snorkel. We measure predictive performances models created participants two common labeling tasks, sentiment classification spam detection. We also elicit ratings qualitative feedback participants multiple measures, including ease use, ease learning, expressivity, overall satisfaction. We find \system facilitates accessible creation labeling functions without loss quality learned labeling models. Tagging token level classification text documents another widely used task benefit DPBD. Here also briefly discuss work progress \tagruler, DPBD system learns token labeling functions user interaction create training datasets tagging models. % Tagging span-level classification text documents another widely used task benefit DPBD. Here also briefly discuss work progress \tagruler, DPBD system enables interactive generation token labeling functions order create labeled training data tagging models. % On hand, \tagruler synthesizes token classification rules based users. In summary, contribute DPBD, general data independent framework learning labeling rules interactive demonstration; \system, interactive system operationalizing framework document classification tasks; comparative user study conducted data scientists performing real world tasks evaluate \system conventional data programming. We made research artifacts, including \system code demo, publicly available~. % along materials anonymized results user study % \documentclass[sigconf]{acmart} \usepackage[moderate]{savetrees} \usepackage{booktabs} % For formal tables \usepackage{listings} \usepackage{latexsym} \usepackage[sets]{cryptocode} \usepackage{amsmath} \usepackage{amssymb} \usepackage{graphicx} \usepackage{setspace} \usepackage{fullpage} \usepackage{xspace} \usepackage{xcolor} \usepackage{caption} \usepackage{subfigure} \usepackage{courier} \usepackage{enumitem} \usepackage[font=normal,skip=2pt]{caption} \usepackage{times} \usepackage{microtype} \usepackage{balance} % better equalize last page \usepackage{xcolor} \usepackage[hang,flushmargin]{footmisc} \setlength{\textfloatsep}{8pt plus 2pt minus 2.0pt} \setlength{\intextsep}{3.0pt plus 1.0pt minus 1.0pt} % \textfloatsep: 20.0pt plus 2.0pt minus 4.0pt; % \floatsep: 12.0pt plus 2.0pt minus 2.0pt; % \intextsep: 12.0pt plus 2.0pt minus 2.0pt. \renewcommand{\UrlFont}{\ttfamily\small} \renewcommand % search images % Copyright \setcopyright{none} \acmConference[]{}{} %% %% Submission ID. %% Use submitting article sponsored event. You'll %% receive unique submission ID organizers %% event, ID used parameter command. %%\acmSubmissionID{123-A56-BU3} %% %% The majority ACM publications use numbered citations %% references. The command \citestyle{authoryear} switches %% ""author year"" style. %% %% If preparing content event %% sponsored ACM SIGGRAPH, must use ""author year"" style %% citations references. %% Uncommenting %% next command enable style. %%\citestyle{acmauthoryear} %% %% end preamble, start body document source. %Conference %\acmYear{1997} %\copyrightyear{2016} %\acmArticle{4} %\acmPrice{15.00} %% These commands optional %%\acmBooktitle{Transactions ACM Woodstock conference} %\editor{Jennifer B. Sartor} %\editor{Theo D'Hondt} %\editor{Wolfgang De Meuter} \definecolor{tomato}{rgb}{1,0.2,0} \definecolor{turqoise}{rgb}{0.03, 0.91, 0.87} \definecolor{grey}{rgb}{0.4,0.4,0.4} \newif\ifnotes \notestrue \DeclareRobustCommand{\cagatay}[1]{\ifnotes{\small[\textcolor{grey}{\c{C}a\u{g}atay:}\textcolor{tomato}{#1}]}\fi} \DeclareRobustCommand{\sara}[1]{\ifnotes{\small[\textcolor{grey}{Sara:}\textcolor{turqoise}{#1}]}\fi} \DeclareRobustCommand{\subhead}[1]{#1} \DeclareRobustCommand{\system}{\mbox{\sc Ruler}\xspace} \DeclareRobustCommand{\ruler}{\mbox{\sc Ruler}\xspace} \DeclareRobustCommand{\tagruler}{\mbox{\sc TagRuler}\xspace} \DeclareRobustCommand{\snorkel}{\mbox{\sc Snorkel}\xspace} \DeclareRobustCommand{\babblelabble}{\mbox{\sc BabbleLabble}\xspace} \DeclareRobustCommand{\thenum}{ten\xspace} \newcommand{\eat}[1]{} \newcommand{\example}[1]{{\underline{Example:} #1\qed}} \newcommand{\stitle}[1]{\smallskip {#1}} \newcommand{\sstitle}[1]{\smallskip {\underline{#1}}} \DeclareRobustCommand{\subhead}[1]{#1} \newcommand{\squishlist}{ } \renewcommand{\shortauthors}{} \settopmatter{printacmref=false,printfolios=true,printccs=false}"," % problem & importance   Data programming is a programmatic weak supervision approach to efficiently curate large-scale labeled training data. Writing data programs  requires, however, both programming literacy and domain expertise. Many subject matter experts have neither programming proficiency nor time to effectively write data programs. Furthermore, regardless of one's expertise in coding or machine learning, transferring domain expertise into labeling functions by enumerating rules and thresholds is not only time consuming but also inherently difficult.  % proposed solution  Here we propose a new framework, data programming by demonstration , to generate labeling rules using interactive demonstrations of users. DPBD aims to relieve the burden of writing labeling functions from users, enabling them to focus on higher-level semantics such as identifying relevant signals for labeling tasks.  We operationalize our framework with \system, an interactive system that synthesizes labeling rules for document classification by using span-level annotations of users on document examples.  % evidence that it works  We compare \system with conventional data programming  through a user study conducted with 10 data scientists creating labeling functions for sentiment and spam classification tasks.  We find that \system is easier to use and learn  and offers higher overall satisfaction, while providing discriminative model performances comparable to ones achieved by conventional data programming."
"Deep neural networks typically trained large amount single task data time-consuming optimization phase. This assumes distribution data points fixed. However, neural models scale complex, realistic environments prone distributional shifts adversarial data points. Online learning hand make distributional assumption naturally involves adversarial scenario. However, due larger number training parameters non-convex optimization landscape, deep neural networks hard train online settings. % data points made available time streaming fashion. \vskip -0.45in \end{wrapfigure} Meta-learning emerged promising technique fast training deep neural networks acquiring transferring knowledge across different tasks learned learning algorithm. This work proposes meta-learning approach learn sequential adaptation algorithms deep neural networks. We introduce sparse variant Meta Networks perform online continual fast adaptation deep neural networks data stream non-stationary distribution. In Sparse Meta Networks , fast-weights generated sparsely step meta-learner accumulated across multiple steps. When sparse fast-weights accumulated way, across different tasks, together act mixture multiple experts single Sparse-MetaNet model. Such sparsely generated recurrent fast-weights computationally efficient; thus applied large scale deep neural networks, also crucial maintain far past memory streaming data. To demonstrate effectiveness approach, introduce new vision based benchmark called Online Cifar. In Online Cifar setup, Sparse-MetaNet shows better flexibility less catastrophic interference, achieves best classification accuracy compared gradient based baselines. We also evaluate Sparse-MetaNet Wisconsin Card Sorting Test , simple online reinforcement learning problem adapted human cognitive test large scale language modelling benchmarks. When used along Transformer-XL adaptive language modelling, Sparse-MetaNet achieves 1.00 bpc enwik8 22.67 perplexity WikiText-103 datasets, improving upon original Transformer-XL result 1.06 bpc 24.0 perplexity, respectively. \vskip -0.45in \end{wrapfigure}","     Training a deep neural network requires a large amount of single-task data and involves a long time-consuming optimization phase. This is not scalable to complex, realistic environments with new unexpected changes.      Humans can perform fast incremental learning on the fly and memory systems in the brain play a critical role.     We introduce Sparse Meta Networks -- a meta-learning approach to learn online sequential adaptation algorithms for deep neural networks, by using deep neural networks.      We augment a deep neural network with a layer-specific fast-weight memory. The fast-weights are generated sparsely at each time step and accumulated incrementally through time providing a useful inductive bias for online continual adaptation. We demonstrate strong performance on a variety of sequential adaptation scenarios, from a simple online reinforcement learning to a large scale adaptive language modelling."
"The advent open-source software question answering websites contributed improving way developers produce code. Nowadays, code search permeates development activities. Developers spend 15\% time searching online piece code works, fix bug, use API . According \citet{sadowski-how-developers-search-for-code-case-study:2015}, Google, developers search code 12 times day, clicking 2 3 results average per search session. Most developers use general-purpose search engines look code , uses page rank indexes tactics optimized searching code. Then, general-purpose search engines adequately find code snippets unless accompanying descriptions. According \citet{masudur-developers-use-google-code-retrieval:2018}, developers spend time, visit pages, change queries often code-related searches. In particular, newcomers project greatly benefit semantic search since face variety entrance barriers . GitHub, popular source code hosting platform, attempted build semantic code search. They extracted millions lines code repositories matched code snippet docstring. The final results satisfactory tool could find relevant code snippet user provided query matched docstring description . According \citet{cambronero-deep-code-search-2019}, users' intents better matched questions collected question-answering sites related programming, e.g., Stack Overflow. Those sites allow users ask question approve best answer it. Other users vote helpful answer mark wrong helpful ones. Those collective actions curate organize information. Initial code search studies based deductive-logic rules manually extracted features . The recent success artificial neural networks shifted recent works machine learning-based approach. \citet{cambronero-deep-code-search-2019} coined name, neural code search, i.e., code search based neural networks. Recent works applied neural networks summarize retrieve code snippets. \citet{cambronero-deep-code-search-2019} proposed neural network attention mechanism \citet{Gu-deep-code-search:2018} presented recurrent neural network. Our novel approach based Convolutional Neural Networks . For best knowledge, CNNs yet used search code, achieved good results selecting answers . CNNs prioritize local interactions translation invariant, important traits task. In study, answer following research questions:"," Software developers routinely search for code using general-purpose search engines. However, these search engines cannot find code semantically unless it has an accompanying description. We propose a technique for semantic code search: A Convolutional Neural Network approach to code retrieval . Our technique aims to find the code snippet that most closely matches the developer's intent, expressed in natural language. We evaluated our approach's efficacy on a dataset composed of questions and code snippets collected from Stack Overflow. Our preliminary results showed that our technique, which prioritizes local interactions , improved the state-of-the-art  by 5\% on average, retrieving the most relevant code snippets in the top 3  positions by almost 80\% of the time. Therefore, our technique is promising and can improve the efficacy of semantic code retrieval."
"In recent years, deep learning methods become standard solving information retrieval tasks. These methods effectively map words phrases vector representations. These representations facilitate better matching phrases similar meanings. Phrases closer meaning represented closer vector space. In information retrieval, many ways develop relevance scores used, counting word overlap query document. Recently, complex machine learning models use human-verified datasets train models assign similarity scores used rankings. Applying deep learning Natural Language Processing problems given rise new approaches better represent sentence閳ユ獨 meaning using neural networks. For instance, Long Short Term Memory models attention mechanism allow word relationships constructed different sentences thus words better placed context, rather examining words closest them. A breakthrough development Natural Language Processing, BERT architecture, extracts word consequently sentence representations masking words throughout sentence predicting omitted words, using self-attention encode entire sentence once. Within BERT framework, model also trained predict next sentence choices, given input sentence. \\ Even advances, deep learning methods still struggle inherent difficulties IR tasks. These challenges result discrepancies query document vocabulary, limited size data used training, weaknesses given human-generated query. In effort mitigate effects, team閳ユ獨 approach inspired existing method, doc2query, given input document uses transformer model architecture predict plausible queries leading document. Although shown expanded documents indeed allowed improved retrieval performance downstream ranking model, approach requires documents collection interest first ``pre-indexed'' feeding input transformer model, practical. Instead, propose query2query method takes given query input generates several queries similar meaning. The hope create powerful query augmenting generated queries given query single representation, used match desired passage. To complete architecture, feed expanded queries pre-trained BERT model predict similarity scores queries documents produce final ranking. The goal approach reduce surface form 閳ユ笜oise閳 within certain query generating queries ask information, different ways. By different representations 閳ユ笩ame閳 query, hope create holistic queries result obtain end-to-end method generalize better potentially reduce problems modern IR faces."," This paper describes Brown University's submission to the TREC 2019 Deep Learning track. We followed a 2-phase method for producing a ranking of passages for a given input query: In the the first phase, the user's query is expanded by appending 3 queries generated by a transformer model which was trained to rephrase an input query into semantically similar queries. The expanded query can exhibit greater similarity in surface form and vocabulary overlap with the passages of interest and can therefore serve as enriched input to any downstream information retrieval method. In the second phase, we use a BERT-based model pre-trained for language modeling but fine-tuned for query - document relevance prediction to compute relevance scores for a set of 1000 candidate passages per query and subsequently obtain a ranking of passages by sorting them based on the predicted relevance scores.  According to the results published in the official Overview of the TREC Deep Learning Track 2019, our team ranked 3rd in the passage retrieval task , and 2nd when considering only re-ranking submissions."
"% Background Collecting sufficient amount electronic health records challenging task various factors . Due problem, researchers medical field often provided small amount data given. Owing fact deep learning techniques perform better large amounts data, number studies using machine learning techniques conducted solve specific medical problems, regarding limited number data . Dementia also one many medical symptoms facing situation. % Alzheimer's Dementia Dementia, syndrome deterioration cognitive function beyond might expected normal ageing, mostly affected Alzheimer閳ユ獨 Disease . % Although studies Dementia also faces problem lacking dataset, There previous researches various approaches recognize Alzheimer's Dementia , shown excellent performance. % However, dataset used works adequete quantity one used paper. However, datasets used works sufficient quantity one used paper. % The ADReSS challenge The ADReSS challenge INTERSPEECH 2020 hosts two tasks: Alzheimer閳ユ獨 Dementia classification Mini Mental Status Examination regression, providing refined dataset. The dataset equally balanced AD non-AD participants metadata age gender. % Each data conversation participant investigator composed acoustic textual information. % Each data conversation participant investigator participant spontaneously describes picture given investigator. % Each data conversation participant spontaneously describes picture given investigator acoustic textual modality. Each data conversation participants, audio text modalities, spontaneously describes picture given investigator. % proposing work Participants challenge suggested solve hosted tasks using given data, numbers train test data 108 48, respectively. For recognizing AD small amounts data, determined would beneficial use acoustic textual features. % why? % thought would best use many information possible recognizing AD 闉氭帾鐓遍瀬婵庢簜鎼 姘氭棄闈栨棶? Furthermore, leverage models pre-trained large scale datasets feature extractor get better representation. To end, paper focus exploiting various multi-modal features, design suitable network architecture. % 闇嬨倢妫 闆﹥妲 闆尗姣勯湆 鑷ф粚娈 鑷у嫴鐏ラ爟姗佺煀 闈广倠鐛忛爟姗佽荡 We compare 3 4 different acoustic textual features, respectively, use hand-crafted feature part-of-speech tagging additional inputs. The usage POS HC influenced previous research, approved using features gained transcript improve performance . The proposed network modified version Convolutional Recurrent Neural Network ; capable computing conversations variable lengths, implemented methods fit small amount data. Also, model able compute using acoustic feature only, without metadata, efficient considering real-world situation. Our experimental results show using features pre-trained network leads performance gain raw, regression results imply potential network classifying classes cognitive impairment based MMSE score."," % The ADReSS Challenge at INTERSPEECH 2020 regards to discern patients suspicious of Alzheimer闁炽儲鐛 Dementia by providing acoustic and textual data. Since the given training dataset only comprised of 108 conversations, leveraging pre-trained models is effective than fitting from scratch. Therefore, this paper aims to recognize Alzheimer闁炽儲鐛 Dementia by exploiting various multi-modal features from pre-trained networks. With the given dataset of conversational form, we modify a Convolutional Recurrent Neural Network based structure to compute input modalities. Our model performs classification and regression tasks simultaneously and is capable of computing conversations with variable lengths. For the classification task, the best test accuracy using only acoustic input is 72.92\%, while using both modality results in 81.25\%. For the regression task, we achieved an RMSE score of 3.7749 . Additionally, our 5-fold cross-validation result for the regression task shows the possibility of classifying 4 classes of cognitive impairment, categorized by the MMSE score, with an accuracy of 78.70\%.   %We use 5-fold cross-validation for measuring model performance. For the classification task, the best F1 score using only acoustic input is 86.28\%, while using both modality results in 94.54\%. For the regression task, the best RMSE score is 3.3493.   Collecting and accessing a large amount of medical data is very time-consuming and laborious, not only because it is difficult to find specific patients but also because it is required to resolve the confidentiality of a patient's medical records. On the other hand, there are deep learning models, trained on easily collectible, large scale datasets such as Youtube or Wikipedia, offering useful representations. It could therefore be very advantageous to utilize the features from these pre-trained networks for handling a small amount of data at hand. In this work, we exploit various multi-modal features extracted from pre-trained networks to recognize Alzheimer's Dementia using a neural network, with a small dataset provided by the ADReSS Challenge at INTERSPEECH 2020. The challenge regards to discern patients suspicious of Alzheimer闁炽儲鐛 Dementia by providing acoustic and textual data. % With the given dataset, we assess features extracted from the pre-trained networks using a neural network. With the multi-modal features, we modify a Convolutional Recurrent Neural Network based structure to perform classification and regression tasks simultaneously and is capable of computing conversations with variable lengths. % Our model performs classification and regression tasks simultaneously and is capable of computing conversations with variable lengths. % For the classification task, the best test accuracy using only acoustic input is 72.92\%, while using both modality results in 81.25\%. For the regression task, we achieved an RMSE score of 3.7749 . Additionally, our 5-fold cross-validation result for the regression task shows the possibility of classifying 4 classes of cognitive impairment, categorized by the MMSE score, with an accuracy of 78.70\%. Our test results surpass baseline's accuracy by 18.75\%, and our validation result for the regression task shows the possibility of classifying 4 classes of cognitive impairment with an accuracy of 78.70\%."
"Transformer one state-of-the-art approaches Neural Machine Translation , hence, widely accepted. For example, WMT19 machine translation tasks, reported 80\% submitted systems adopted Transformer architecture . Note high translation quality Transformer models entails large number parameters. Moreover, Transformer model inherently much slower conventional machine translation approaches mainly due auto-regressive inference scheme incrementally generating token. As result, deploying Transformer model mobile devices limited resources involves numerous practical implementation issues. To address implementation challenges little degradation translation quality, study low-bit quantization strategy Transformer accomplish high-performance on-device NMT. We note previous studies compress Transformer models utilize uniform quantization . While uniform quantization may effective memory footprint savings, would face various issues improve inference time maintain reasonable BLEU score. For example, even integer arithmetic units inference operations present limited speed resulting BLEU score quantized Transformer substantially degraded low-bit quantization INT4 . While determining number quantization bits Transformer, crucial consider component Transformer may exhibit varied sensitivity quantization error toward degradation translation quality . Accordingly, mixed precision quantization suggested effort assign different numbers quantization bits depending component quantization sensitive loss function. In addition, illustrate later, even assigning different quantization bits row embedding block reduce overall number quantization bits entire Transformer model. Our proposed quantization strategy, thus, provides finer-grained mixed precision approach compared previous methods, consider layer-wise matrix-wise mixed precision. % One important aspect block Transformer contributes inference computation translation accuracy differently. Transformer consists three major blocks: embedding, encoder, decoder. The embedding block huge number parameters due dependence vocabulary size, easily scale tens thousands. On contrary, matrices encoder decoder relatively small since independent vocabulary size. As result, embedding block causes major memory latency consumption. Since decoding steps parallelizable inference time, also contributes largely inference computation. % In consideration these, propose mixed precision quantization strategy Transformer quantization efficient inference computation reasonable accuracy loss. Accommodating distinguished implementation properties component Transformer, propose following methodologies decide precision block: 1) case embedding block, statistical importance word taken account 2) encoder decoder blocks, sensitivity quantized sub-layer considered. The main contributions paper follows:","  The deployment of widely used Transformer architecture is challenging because of heavy computation load and memory overhead during inference, especially when the target device is limited in computational resources such as mobile or edge devices. Quantization is an effective technique to address such challenges. Our analysis shows that for a given number of quantization bits, each block of Transformer contributes to translation quality and inference computations in different manners. Moreover, even inside an embedding block, each word presents vastly different contributions. Correspondingly, we propose a mixed precision quantization strategy to represent Transformer weights by an extremely low number of bits . For example, for each word in an embedding block, we assign different quantization bits based on statistical property. Our quantized Transformer model achieves 11.8$\times$ smaller model size than the baseline model, with less than -0.5 BLEU. We achieve 8.3$\times$ reduction in run-time memory footprints and 3.5$\times$ speed up  such that our proposed compression strategy enables efficient implementation for on-device NMT."
"The rapid progression generative models computer vision natural language processing led increasing likelihood realistic-looking news articles generated Artificial Intelligence . The malicious use technology could present major societal problem. \citet{zellers2019defending} report humans easily deceived AI-generated propaganda. By manipulating technology, adversaries would able disseminate large amounts online disinformation rapidly. While promising pretrained generative models best defense , often challenging aware models utilized adversaries beforehand. More importantly, ignores fact news articles often accompanied images captions . %We argue visual context provides vital clues discriminating machine-generated articles. In paper, present first line defence neural fake news images captions. To best knowledge, first address challenging realistic problem. Premised assumption adversarial text generator unknown beforehand, propose evaluate articles based semantic consistency linguistic visual components. While state-of-the-art approaches bidirectional image-sentence retrieval leveraged visual-semantic consistency great success standard datasets MSCOCO Flickr30K , show Appendix able reason effectively objects image named entities present caption article body. This due discrepancies distribution datasets, captions standard datasets usually contain general terms including woman dog opposed named entities Mrs Betram Golden Retriever, commonly contained news article captions. Moreover, images often directly related articles associated with. For example, Figure , article contains mentions British Prime Minister. Yet, contains image United Kingdom flag. To circumvent problem, present DIDAN, simple yet surprisingly effective approach exploits possible semantic inconsistencies text image/captions detect machine-generated articles. For example, notice article caption Fig. actually mention different Prime Ministers. Besides evaluating semantic relevance images captions article, DIDAN also exploits co-occurrences named entities article captions determine authenticity score. The authenticity score thought probability article human-generated. We adopt learning paradigm commonly used image-sentence retrieval models trained reason dissimilarities images non-matching captions. In instance, negative samples constitute articles non-corresponding image-caption pairs. Not reasonable approach adversarial generative model unknown, show empirically crucial detecting machine-generated articles high confidence even access machine-generated samples training. More importantly, means DIDAN easily trained abundance online news articles without additional costly annotations. To study threat, construct NeuralNews dataset contains human machine-generated articles. These articles contain title, main body well images captions. The human-generated articles sourced GoodNews dataset. Using titles main article bodies context, use GROVER generate articles. Instead using GAN-generated images easy detect even without exposure training time , consider much harder setting articles completed original images. We include real generated captions generated SOTA entity-aware image captioning model . We present results findings series empirical well user study experiments. In user study experiments, use 4 types articles including real generated news determine humans susceptible to. The insights derived findings help identify possible weaknesses adversaries exploit produce neural fake news serve valuable reference defending threat. Last least, experimental results provide competitive baseline future research area. In summary, contributions multi-fold:"," Large-scale dissemination of disinformation online intended to mislead or deceive the general population is a major societal problem. Rapid progression in image, video, and natural language generative models has only exacerbated this situation and intensified our need for an effective defense mechanism. While existing approaches have been proposed to defend against neural fake news, they are generally constrained to the very limited setting where articles only have text and metadata such as the title and authors. In this paper, we introduce the more realistic and challenging task of defending against machine-generated news that also includes images and captions. To identify the possible weaknesses that adversaries can exploit, we create a NeuralNews dataset composed of 4 different types of generated articles as well as conduct a series of human user study experiments based on this dataset. In addition to the valuable insights gleaned from our user study experiments, we provide a relatively effective approach based on detecting visual-semantic inconsistencies, which will serve as an effective first line of defense and a useful reference for future work in defending against machine-generated disinformation."
"Code completion become essential feature Integrated Development Environments . It speeds process software development suggesting next probable token based existing code. The main goal existing code completion systems suggest accurate variables, arguments, APIs developers. Recently, along development deep learning technologies easy-to-acquire open-source codebases, researchers started tackle code completion learning large-scale code corpora. In paper, define new code completion task: full-line code completion. Given partially completed code snippet, full-line code completion requires predicting next line code, different traditional code completion predicts next code element. Figure 1 shows motivating example task. To complete last line Figure 1, traditional code completion needs predict least six times separately, time developer needs choose correct token. But generate entire line simultaneously, even prediction partially correct, developer correct code line fewer operations. Currently, popular technique research area code completion language models, especially neural language models. Neural language model powerful tool predicting next token given token sequence, naturally fits scenario code completion. Recent researches shown large-scale neural language models like GPT-2 capable generating long text, brings potential code sequence generation. One key challenges full-line code generation guarantee syntactical correctness generated code. To tackle challenge, draw lessons past researches semantic parsing. We adopted widely used framework syntax-based code generation, converts generation code snippet generating abstract syntax tree sequence construction actions. We conduct experiments two public Python datasets contain Python files crawled Github repositories. One dataset Python2, one Python3. We evaluate performance state-of-the-art approach traditional code completion, along group neural language models. Our results show datasets, Transformer language models outperform RNN-based models, consistent past researches language modeling. We also find syntax-based approaches outperform token-based approaches, indicating directly applying techniques syntax-based code generation full-line code completion ineffective. The main contributions paper summarized follows: 1) We propose novel code completion task: full-line code completion build datasets task. 2) We evaluate state-of-the-art models used traditional code completion group neural language models datasets. 3) We analyze performance plain token sequence-based language models versus syntax-based language models, discussed effectiveness incorporating syntax information full-line code completion possible improvements future."," A code completion system suggests future code elements to developers given a partially-complete code snippet. Code completion is one of the most useful features in Integrated Development Environments . Currently, most code completion techniques predict a single token at a time. In this paper, we take a further step and discuss the probability of directly completing a whole line of code instead of a single token. We believe suggesting longer code sequences can further improve the efficiency of developers. Recently neural language models have been adopted as a preferred approach for code completion, and we believe these models can still be applied to full-line code completion with a few improvements. We conduct our experiments on two real-world python corpora and evaluate existing neural models based on source code tokens or syntactical actions. The results show that neural language models can achieve acceptable results on our tasks, with significant room for improvements."
"As neural networks adopted solve real-world problems, parts network may easy develop, unknown aspects hyperparameters, clear method derivation. Ongoing research focuses developing new network architectures training methods. When developing neural networks, question hand set hyperparameter values maximize results set training configuration. For network architecture design, important hyperparameters include type network, number layers, number units per layer, unit type. For training configurations, important hyperparameters include learning algorithm, learning rate, dropout ratio. All hyperparameters interact affect performance neural networks. This interaction hyperparameters referred epistasis. Thus need tuned simultaneously get optimum results.\\ The motivation behind research replace tedious manual tuning hyperparameters automatic method performed computers. Current methods optimization limited trivial methods like Grid search. Grid search simple method hyperparameter optimization. However, number hyperparameters increases, Grid search becomes time consuming computationally taxing. This number lattice points increases exponential way increase number hyperparameters . For example, ten hyperparameters tuned try five values parameter, alone requires 9 Million evaluations: . For reason, grid search feasible certain applications. To solve this, look GA higher-performing less computationally taxing solution. The use GA neural network hyperparameter optimization explored previously . \\ We present empirical study GAs neural network models machine translation natural language specifically Japanese English. We describe experiment setup Section 2, GA method Section 3, results Section 4. The preliminary findings suggest simple GA encoding potential find optimum network architectures compared random search baseline.","  With neural networks having demonstrated their versatility and benefits, the need for their optimal performance is as prevalent as ever. A defining characteristic, hyperparameters, can greatly affect its performance. Thus engineers go through a process, tuning, to identify and implement optimal hyperparameters. That being said, excess amounts of manual effort are required for tuning network architectures, training configurations, and preprocessing settings such as Byte Pair Encoding . In this study, we propose an automatic tuning method modeled after Darwin's Survival of the Fittest Theory via a Genetic Algorithm . Research results show that the proposed method, a GA, outperforms a random selection of hyperparameters."
"In past decades, knowledge graph construction applications rapidly developed achieved significant outcomes. For better relevancy web search, Google leveraging knowledge graph represents real-world entities relationships one another since 2012. %, also large amount publicly available knowledge graphs, freebase, Dbpedia, YAGO constructed used many real-world intelligent applications. To identify entities text, named entity recognition techniques extensively studied applied many areas including e-commerce search . Such NER systems usually work well defined ontology classify tokens sequence words . A comprehensive domain-specific PT ontology beneficial product search discovery e-commerce platform . At The Home Depot , PT ontology used tremendously online search improve query understanding product retrieval. For example, Figure shows snippet PT ontology consists known PT classes. The PTs ontology serve entity reference NER task well classes SKU-PT mapping catalog side facilitates retrieval relevant products. %. Kutiyanawala et al. also proposed product ontology framework created specially e-commerce search retrieval . %comprehensive domain-specific Ontology required order better understand customers閳 intent account expanding catalog. The Ontology enrichment proved effective boost search relevancy. For example, given customer query ""shower curtain hook"", system would also return ""shower curtain"" products since failed infer proper product type due lack knowledge. By introducing new product type ""shower curtain hook"", system able remove noise provide relevant results. % % \end{equation*} % \[ % z = \overbrace[1pt][5pt]{ge}^{brand}\ \overbrace{7.3\:cu\:ft}^{dim} \quad\overbrace{dryer}^{product}\quad\overbrace{gas}^{attribute} % \] %In domain e-commerce, strong well-structured knowledge graph also plays pivotal roles business business communications customer search navigation experience. %A structured standardized product ontology define product description, catalog formats business documents support electric data exchange vendors buyers. %The Home Depot world leading home improvement retailer customers business. Orange Graph repository access point THD domain-specific knowledge, includes rich product information, project information relationships. By adopting well-structured knowledge graph, high-level search quality, project-based buying features, marketing customer services offered THD e-commerce enterprise systems. % } % % % \end{table} Discovering valid PTs key task build expand PT ontology fundamental challenge regarding definition PT. % given concept instead fact. A PT defined demand side atomic keywords/phrase describes customers look supply side semantic tag/label uniquely identifies product. Within THD, also practical guidelines distinguish valid invalid PTs like %Product type essential component PT ontology. %it widely used e-commerce domain group similar products together. For instance, consider Appliances category, goal discover distinct types refrigerators case could be: ""Side By Side"", ""French Door"", etc. %Although different definitions valid PT, In paper, define valid PT leaf-level description entity. common attributes like color, brand, material, style etc PTs requires significant differences form, functionality usage location make new PT comparing existing ones . %Another determiner whether adding token product type makes new product type addition new token changes form, function usage location. In example, cordless change drill, utility sink. Obviously, neither definition definite guidelines exhaustive enough always complicated cases exceptions human judgement based knowledge merchandising, customer preference common sense required. %without involving human knowledge usually expensive term time monetary cost. %automatically determine candidate . %Although aforementioned definition would generally help distinguish valid invalid PTs, several challenges task %as depicted Table. %First foremost, crucial determine right level granularity discovered PTs. Very generic PTs generally ambiguous could attributable broad set products different use cases. For example, PT chairs ambiguous comprise outdoor chairs, office chairs, dining chairs chairs types different usage location. %Specifically, domain experts great advantage For example, generic PT range broken granular ones fuel type like gas range, electric range attribute like induction range, convention range. The word ""wood"" material wood rolling pin usage wood glue. % Moreover, often subjective determine level granularity PT discovery stopped based criteria generic PT broken granular PTs. For instance, given generic PT ranges break fuel type features . In example, consider one PT one attribute; alternatively combined construct granular PT. % Another challenge automatically identify token PT attribute not. As example, consider wood rolling pin wood glue; token wood latter change use case glue, former material. However, leveraging human knowledge large scale problems usually timely expensive. To reduce cost, paper proposes %The main contribution paper follows: proposing active learning framework minimizes human effort PT discovery 1) identifying high quality candidates using phrase mining user behavior. 2) limiting number PT candidates human validation. %%%%%%%"," Entity-based semantic search has been widely adopted in modern search engines to improve search accuracy by understanding users' intent. %behind the search terms.  %In e-commerce domain, product type  is a central concept in intent understanding as well as catalog organization. %indicating customers' intent in their search queries.  %be identified from customers' queries for understanding  In e-commerce, an accurate and complete product type  ontology is essential for recognizing product entities in queries and retrieving relevant products from catalog.  However, finding product types  to construct such an ontology is usually expensive due to the considerable amount of human efforts it may involve.  In this work, we propose an active learning framework that efficiently utilizes domain experts' knowledge for PT discovery.  We also show the quality and coverage of the resulting PTs in the experiment results."
"Distributional word representations trained large-scale corpora widely used modern natural language processing systems, aims describe meaning words sentences vectorized representations . Recent studies addressed state-of-the-art word embedding performance various NLP tasks, start focus evaluate performance different word embeddings accurately. However, \citet{Tsvetkov15} \citet{Chiu16} demonstrated even word embedding, existing evaluation methods provide constantly correlative results intrinsic evaluation extrinsic evaluation. Therefore, evaluating performance word embeddings unified metric challenging NLP tasks. \citet{Hollenstein19} proposed new evaluation framework called CogniVal, applied traditional neural networks regression considered intrinsic extrinsic measurements based collected human natural language processing-related cognitive data sources across three modalities: electroencephalography , functional magnetic resonance imaging , eye-tracking. CogniVal potentially identified pioneer multi-modal cognitive word embedding evaluation framework, conducts vectorized word embeddings evaluation predicting much reflect semantic representations cognitive data sources recorded human processing natural language. However, CogniVal framework ignored measure characteristics human physiological signals. Specifically, three modalities cognitive data used experiment featuring non-stationary non-linear motions . Inspired \citet{Zekri08,Bodyanskiy13}, assume neural networks fuzzy systems computational intelligence methods suitable tools modelling expert knowledge dealing uncertain non-linear processes non-stationary time series dynamic system, approximate reasoning characteristics fuzzy systems could present practical model handle uncertainty disturbances real data complex hybrid non-linear non-stationary problems . For reason, proposed fuzzy-based neural network framework evaluating word embeddings cognitive datasets, name CogniFNN, expects enhance quality evaluating performance word embeddings cognitive data sources , achieve higher ratio significant results random word embeddings well. \paragraph{Contributions} The main contributions study shown follows:"," Word embeddings can reflect the semantic representations, and the embedding qualities can be comprehensively evaluated with human natural reading-related cognitive data sources. In this paper, we proposed the CogniFNN framework, which is the first attempt at using fuzzy neural networks to extract non-linear and non-stationary characteristics for evaluations of English word embeddings against the corresponding cognitive datasets. In our experiment, we used 15 human cognitive datasets across three modalities: EEG, fMRI, and eye-tracking, and selected the mean square error and multiple hypotheses testing as metrics to evaluate our proposed CogniFNN framework. Compared to the recent pioneer framework, our proposed CogniFNN showed smaller prediction errors of both context-independent  and context-sensitive  word embeddings, and achieved higher significant ratios with randomly generated word embeddings. Our findings suggested that the CogniFNN framework could provide a more accurate and comprehensive evaluation of cognitive word embeddings. It will potentially be beneficial to the further word embeddings evaluation on extrinsic natural language processing tasks."
"Reinforcement Learning~ methods increasingly used solving sequential decision-making problems natural language inputs, like text-based games chat-bots personal conversation assistants. In work, focus Text-Based Games~, require solving goals like ``Obtain coin kitchen'', based natural language description agent's observation environment. To interact environment, agent issues text-based action commands~ upon receives reward signal used training RL agent. % generalization problem Traditional text-based RL methods focus problems partial observability large action spaces. However, topic generalization unseen TBGs less explored literature. We show previous RL methods TBGs often show poor generalization unseen test games. We hypothesize overfitting caused due presence irrelevant tokens observation text, might lead action memorization. % ~(eg. every time agent. To alleviate problem, propose CREST, first trains overfitted base model original observation text training games using Q-learning. Subsequently, apply observation pruning that, episode training games, remove observation tokens semantically related base policy's action tokens. Finally, re-train bootstrapped policy pruned observation text using Q-learning improves generalization removing irrelevant tokens. Figure shows illustrative example method. Experimental results TextWorld games show proposed method generalizes unseen games using almost x-x fewer training games compared SOTA methods; features significantly faster learning."," 		We show that Reinforcement Learning~ methods for solving Text-Based Games~ often fail to generalize on unseen games, especially in small data regimes. To address this issue, we propose Context Relevant Episodic State Truncation~ for irrelevant token removal in observation text for improved generalization. Our method first trains a base model using Q-learning, which typically overfits the training games. The base model's action token distribution is used to perform observation pruning that removes irrelevant tokens. A second bootstrapped model is then retrained on the pruned observation text. Our bootstrapped agent shows improved generalization in solving unseen TextWorld games, using $10$x-$20$x fewer training games compared to previous state-of-the-art~ methods despite requiring less number of training episodes."
"As key step constructing knowledge graph, relation extraction task extract relation entities expressed sentence. Previous work largely focused intra-sentence binary relation extraction, goal extract relation entity pair sentence. However, relations require two entities may span multiple sentences, defined n-ary cross-sentence relation extraction. As example shown Table, relation ``educate'' includes four entities, person's ""name``, ""academic degree``, ""academic major`` ""school``. In addition, relation spans four sentences example. Some prior works applied supervised learning approach tackle task, require large-scale labeled training data. \end{table} To obtain large-scale annotated data, work assumes consecutive sentences contain entities relation knowledge base, sentences whole describe relation. This assumption referred distant supervision n-ary cross-sentence relation extraction task. Even though methods based distant supervision quickly annotate sentences, still two main limitations: 1) suffer noisy labeling problem; 2) strong distant supervision assumption consider non-consecutive sentences, reduces generalizability trained model. As example shown Table, sentences 18th 20th positions describe fact labeled using distant supervision consecutive. The first sentence incorrectly labeled noisy labeled data, describes Alan Turing's work instead education. To address first limitation, propose train sentence distribution estimator , two-level agent reinforcement learning model. This provides well-trained model select high-quality labeled sentence groups alleviate impact noisy data. There previous works applying reinforcement learning remove binary intra-sentence noisy data achieve state-of-the-art performance. When applying RL n-ary cross-sentence relation extraction, key challenge RL model learn sentence features, also know context relation sentence. In paper, process selecting sentences influenced feature sentence itself, also indicators defined , measure semantic relationship sentences. Moreover, whether sentence selected state going affect decision next state. This state transition property provides ability choose best combination sentences sentence group. To address second limitation, relax strong distant supervision assumption lies heart prior work replacing weaker distant supervision assumption. The assumption sentence least one main entity two supplementary entities annotated relation entities. We follow Wikidata Knowledge Base scheme, main entity ``value'' fact supplementary entity ``qualifer'' fact. This assumption introduces non-consecutive sentences propose novel universal relation extractor encode consecutive non-consecutive sentence groups. This relation extractor self-attention soft attention mechanism layer, compares similarity word-level features relation query vectors. The relation extractor also encodes sentence via Piece-wise Convolution Neural Network layer. The PCNN output used learn information transforms sentences via non-linear transformation layer."," The models of n-ary cross sentence relation extraction based on distant supervision assume that consecutive sentences mentioning $n$ entities describe the relation of these $n$ entities. However, on one hand, this assumption introduces noisy labeled data and harms the models' performance. On the other hand, some non-consecutive sentences also describe one relation and these sentences cannot be labeled under this assumption. In this paper, we relax this strong assumption by a weaker distant supervision assumption to address the second issue and propose a novel sentence distribution estimator model to address the first problem. This estimator selects correctly labeled sentences to alleviate the effect of noisy data is a two-level agent reinforcement learning model. In addition, a novel universal relation extractor with a hybrid approach of attention mechanism and PCNN is proposed such that it can be deployed in any tasks, including consecutive and non-consecutive sentences. Experiments demonstrate that the proposed model can reduce the impact of noisy data and achieve better performance on general n-ary cross sentence relation extraction task compared to baseline models."
"Healthcare information systems store huge volumes electronic health records contain detailed visit information patients period time. The data structured three levels top bottom: patient journey, individual visit medical code. Fig. provides typical example structure. An anonymous patient visits his/her doctor, pathology lab admitted hospital different days. The procedures diagnoses performed visits recorded industry-standard medical codes. Each medical code, i.e. International Classification Diseases Current Procedure Terminology , lowest level, records independent observation set codes higher level depict medical conditions patient given time point. At top level, occurrences medical events different time-stamps chained together patient journey, offers informative details. Predicting sequential medical outcomes based patient's journey, hospital re-admissions diagnoses, core research task significantly benefits healthcare management hospitals governments. For example, re-admission statistics could used measure quality care; Diagnoses used understand fully patient's problems relevant medical research. However, researchers encountered many challenges attempts represent patient journeys predict medical outcomes EHR data characteristics temporality, high-dimensionality irregularity. Recurrent neural networks widely used analyze sequential data, unsurprisingly including medical events modelling clinical prediction. For example, Choi et al. proposed multi-level representation learning, integrates visits medical concepts based visit sequences co-occurrence medical concepts. They indirectly exploited RNN embed visit sequences patient representation downstream prediction tasks. Some research works directly employed RNNs model time-ordered patient visits predicting diagnoses. However, length patient visit sequence grows, RNN-based models restricted less expressive power RNNs, vanishing gradient forgetfulness. However, RNN-based models constrained forgetfulness, i.e., predictive power drops significantly sequence patient visits grows long. To memorize historical records, LSTM GRU developed utilize memory gate mechanism mitigating issues. To go further, Song et al. proposed utilise attention mechanism deep framework model sequential medical events. It worth noting sequences medical events often found lengthy, especially patient suffers chronic disease. Hence, due restricted ability RNNs long-term dependency modeling , traditional RNNs, even memory cells gates, usually underperform cases long sequence medical events. In light this, neural model overcome performance bottleneck RNN-based models particularly desirable medical predictions based longitudinal EHR data. %%%%%%%% WHAT THE RELATION BETWEEN SHEN2018DISAN AND THIS ONE?? Directional self-attention networks alleviate long sequence problems improve accuracy predictions, models trained available input information - past future.. CAN WE COME TO THE CONCLUSION: ONE OF CONTRIBUTION IS WE HAVE FULLY CONSIDERED ALL MEDICAL EVENTS COMPARING TO OTHER WORKS THAT CAN ONLY PARTIALLY CONSIDER. % Recently, attention mechanism integrated RNNs model sequential EHRs data, achieves good prediction accuracy. Although attention-based RNNs relatively improves prediction performance, limitations RNNs weaken advantage attention mechanism. In natural language processing , sole attention mechanism used construct sequence sequence model achieves state-of-the-art quality score neural machine translation task. The attention mechanism flexibility sequence length RNN, task/data-driven modeling dependencies. Unlike sequential models, computation easily significantly accelerated existing distributed/parallel computing schemes. However, best knowledge, neural net entirely based attention designed patient journey EHRs data. Most recently, attention mechanisms sprung fore effective integrations RNNs modeling sequential EHR data. So far, approaches shown satisfactory prediction accuracy, argue power attention RNN limited weaknesses RNN . In particular, Vaswani et al. used sole attention mechanism, i.e., multi-head attention self-attention, construct sequence-to-sequence model neural machine translation tasks achieved state-of-the-art quality score. And according Shen et al., self-attention mechanism allows flexibility sequence lengths RNNs task/data-driven modeling contextual dependencies. Unlike recurrent models, attention procedure easy compute computation also significantly accelerated distributed/parallel computing schemes. For example, Song et al. proposed employ 1D CNN model local context use attention mechanism capture long-term dependency sequential medical events. However, applied EHR data instead regular sequential data , current attention models cannot appropriately deal aspects EHR data, arbitrary time-stamps hierarchical data format. Hence, best knowledge, neural network-based entirely attention never designed analytics EHR data. To bridge gap literature address open issues listed above, propose novel attention mechanism called Masked Encoder temporal context fusion. It uses self-attention capture contextual information temporal dependencies patient's visits. Then, propose end-to-end neural network, called Bidirectional temporal encoder Network , predict medical outcomes leveraging learned representation patient journey, representation generated solely proposed attention mechanism, MasEnc. BiteNet constructs multi-level self-attention network represent visits patient journeys simultaneously, using attention pooling stacked MasEnc layers. It worth noting that, compared existed RNN-based methods, BiteNet yield better prediction performance long sequences medical records. Experiments conducted two supervised prediction two unsupervised clustering tasks real-world EHR datasets demonstrate proposed BiteNet model superior prior state-of-the-art baseline methods. To summarize, main contributions are: % The remainders paper organized follows. Section reviews related studies. In Section, briefly discuss preliminary, details model presented Section. In Section, demonstrate experimental results conducted real-world datasets. Lastly, conclude study Section.%and outline future work %"," Electronic health records  are longitudinal records of a patient's interactions with healthcare systems. A patient's EHR data is organized as a three-level hierarchy from top to bottom: patient journey - all the experiences of diagnoses and treatments over a period of time; individual visit - a set of medical codes in a particular visit; and medical code - a specific record in the form of medical codes. As EHRs begin to amass in millions, the potential benefits, which these data might hold for medical research and medical outcome prediction, are staggering - including, for example, predicting future admissions to hospitals, diagnosing illnesses or determining the efficacy of medical treatments. Each of these analytics tasks requires a domain knowledge extraction method to transform the hierarchical patient journey into a vector representation for further prediction procedure. The representations should embed a sequence of visits and a set of medical codes with a specific timestamp, which are crucial to any downstream prediction tasks. Hence, expressively powerful representations are appealing to boost learning performance. To this end, we propose a novel self-attention mechanism that captures the contextual dependency and temporal relationships within a patient's healthcare journey. An end-to-end bidirectional temporal encoder network  then learns representations of the patient's journeys, based solely on the proposed attention mechanism. We have evaluated the effectiveness of our methods on two supervised prediction and two unsupervised clustering tasks with a real-world EHR dataset. The empirical results demonstrate the proposed BiteNet model produces higher-quality representations than state-of-the-art baseline methods."
"The International Classification Diseases establishes standardized fine-grained classification system broad range diseases, disorders, injuries, symptoms, related health conditions . It primarily intended use healthcare workers, policymakers, insurers national health program managers. The United States incurs administrative costs billions dollars annually arising complex billing infrastructure . Specifically, ICD code assignment typically manual process, consuming average 25 43 minutes per patient depending ICD version . It also prone errors resulting inexperienced coders, variation coders, incorrect grouping codes mistakes patient discharge summaries. These errors costly one report estimating preventable errors ICD coding cost Medicare system 31.6 billion FY2018 .\\\\ Recent work tried automate task ICD code assignment using deep learning. Typically framed multilabel classification problem, researchers trained Convolutional Neural Networks , Recurrent Neural Networks , Transformer models predict ICD-9 codes patient discharge summaries. These models outperformed rule-based approaches utilizing conventional algorithms Logistic Regression, Support Vector Machines, Random Forests etc., achieving competitive micro F1-scores range 42\% - 68\%. Amongst models, based CNNs achieved best performance. Neural network models revolutionized field NLP SOTA models various NLP tasks involve deep neural network models BERT, Bidirectional RNN CNN-based methods. Recent works shown particular vulnerability deep models adversarial examples often produced adding small imperceptible perturbations input data. The state art models NLP exceptions perturbations. provides review different adversarial attacks defense strategies NLP literature. Based granularity perturbation, adversarial attack strategies NLP classified three types - character-level attacks, word-level attacks sentence-level attacks. In character-level attack strategy, model induces noise character level. Character-level noise induced due naturally occurring reasons typos misspellings due intentional modification malicious third-party. existing character-level attack strategies NLP. To accurately model naturally occurring typos, restrict typos distribution based character constraints found standard English keyboard. We follow strategy work. Furthermore, assume white-box setting adversary access gradients loss function wrt model inputs. To knowledge, first work investigate effects adversarial samples clinical NLP domain.","   Manual annotation of ICD-9 codes is a time consuming and error-prone process. Deep learning based systems tackling the problem of automated ICD-9 coding have achieved competitive performance. Given the increased proliferation of electronic medical records, such automated systems are expected to eventually replace human coders. In this work, we investigate how a simple typo-based adversarial attack strategy can impact the performance of state-of-the-art models for the task of predicting the top 50 most frequent ICD-9 codes from discharge summaries. Preliminary results indicate that a malicious adversary, using gradient information, can craft specific perturbations, that appear as regular human typos, for less than $3\%$ of words in the discharge summary to significantly affect the performance of the baseline model."
"Systematic Generalization characterized capacity understand produce potentially infinite number novel combinations known components . For example, Figure, model could exposed set facts , possible facts inferred combination known components . More recent work examined systematic generalization terms ability ``a model manipulate concepts new combinations trained concepts, limited set combinations'' . This view systematic generalization shifts emphasis reasoning learning. %If model able perfectly accomplish task leveraging existing facts infer new ones, deem model generalizing systematically. Here examine systematic generalization measuring ability model reason new inference step combinations despite trained limited subset them. %, conditioning upon small subset active relationships inference time. Recent developments natural language processing shown Transformer Language Models able capture linguistic knowledge , yield state-of-the-art performance many NLP tasks , including limited answering reading comprehension questions generating factual knowledge little task supervision. These models optimized large corpora predict next words set masked words sentence. While yielding impressive results, clear TLMs rely many superficial patterns data actually learn re-usable skills, enabling generalize new tasks leveraging compositionality skills . Training massive data give certain advantages respect understanding meanings words, conjecture data gives models less experience reasoning inference chains. In work, study less understood issues related well TLMs able perform long chains reasoning. In particular, use TLMs task theorem proving, facts proofs specified natural language. Using theorem proving, test TLMs generate interpretable proofs logically consistent language modeling main objective. % In setting, language models various attractive properties: require logical rule engineering still interpretable, need human annotations, easy extend data. % Language models many advantages theorem provers: require rule engineering, allow practitioners query open class relations, easy extend data, require human supervision train. In particular, study behavior logical reasoners text analyzing generated proofs final answer. This setup allows us evaluate reasoning generalization capabilities TLMs. Recent work suggest language models treated knowledge bases. This directly motivates us investigate language models also learn certain reasoning strategies. Studying abilities give us insights facilitate use models dynamic knowledge bases could infer new knowledge even seen pre-training. For natural language theorem proving, use question answering CLUTRR benchmark suite perform controlled studies. This dataset interest because: compositional nature tasks involved make well suited evaluating systematic generalization, question--answer pair accompanied proof used explain arrive answer. %Our goal obtain state-of-the-art results dataset, rather, We use dataset medium understand reasoning capacity TLMs. Our experiments reveal following: To best knowledge, first use language modeling objective interpretable theorem proving Transformer. We hope work shed light reasoning capacity TLMs inspire future research design models greater reasoning capacity."," We are interested in understanding how well Transformer language models  can perform reasoning tasks when trained on knowledge encoded in the form of natural language. We investigate their systematic generalization abilities on a logical reasoning task in natural language, which involves reasoning over relationships between entities grounded in first-order logical proofs. Specifically, we perform soft theorem-proving by leveraging TLMs to generate natural language proofs. We test the generated proofs for logical consistency, along with the accuracy of the final inference. We observe length-generalization issues when evaluated on longer-than-trained sequences. However, we observe TLMs improve their generalization performance after being exposed to longer, exhaustive proofs. In addition, we discover that TLMs are able to generalize better using backward-chaining proofs compared to their forward-chaining counterparts, while they find it easier to generate forward chaining proofs. We observe that models that are not trained to generate proofs are better at generalizing to problems based on longer proofs. This suggests that Transformers have efficient internal reasoning strategies that are harder to interpret. These results highlight the systematic generalization behavior of TLMs in the context of logical reasoning, and we believe this work motivates deeper inspection of their underlying reasoning strategies."
"Singing voice synthesis aims synthesize high-quality expressive singing voices based musical score information, attracts lot attention industry academia ~. Singing voice synthesis shares similar pipeline text speech synthesis, achieved rapid progress~ techniques developed text speech synthesis~. Most previous works SVS~ adopt sampling rate used text speech, frequency bands sampling data points enough convey expression emotion high-fidelity singing voices. However, simply increasing sampling rate cause several challenges singing modeling. First, audio higher sampling rate contains wider higher frequency bands\footnote{According Nyquist-Shannon sampling theorem~, sampling rate cover frequency band . Therefore, frequency band audio 48kHz sampling rate spans 024kHz 012kHz 24kHz sampling rate. The additional high frequency band 1224kHz increases difficulty modeling since high-frequency signals complicated less predictive.}, throws challenges predicting frequency spectrums acoustic model. Second, audio higher sampling rate contains longer waveform points much fine-grained fluctuations fixed period time\footnote{For example, 1 second audio waveform contains 48,000 sampling points sampling rate 48kHz.}, also increases difficulty vocoder modeling time domain. As consequence, even previous works~ adopt higher sampling rate , either leverage coarse-grained MFCC~ acoustic features slow autoregressive neural vocoder~, use non-neural vocoder Griffin-Lim~ WORLD~ generate waveform, fully exploit potential high sampling rate thus cannot yield good voice quality. In paper, develop HiFiSinger, SVS system towards high-fidelity singing voices. HiFiSinger adopts FastSpeech~ acoustic model Parallel WaveGAN~ vocoder since popular speech synthesis~ ensure fast training inference speed also high quality. %. Instead using Griffin-Lim, WORLD autoregressive neural model WaveRNN WaveNet vocoder, HiFiSinger leverages To address challenges high sampling rate singing modeling , design multi-scale adversarial training acoustic model vocoder, introduce several additional systematic designs findings crucial improve singing modeling: We conduct experiments internal singing voice synthesis datasets contain 11 hours high-fidelity singing recordings 48kHz sampling rate. Experiment results demonstrate advantages developed HiFiSinger previous singing voice synthesis system. Further ablation studies verify effectiveness design HiFiSinger generate high-fidelity voices."," High-fidelity singing voices usually require higher sampling rate  with large range of frequency to convey expression and emotion. However, higher sampling rate causes the wider frequency band and longer waveform sequences and throws challenges for singing modeling in both frequency and time domains in singing voice synthesis . Conventional SVS systems that adopt moderate sampling rate  cannot well address the above challenges. In this paper, we develop HiFiSinger, an SVS system towards high-fidelity singing voice using 48kHz sampling rate. HiFiSinger consists of a FastSpeech based neural acoustic model and a Parallel WaveGAN based neural vocoder to ensure fast training and inference and also high voice quality. To tackle the difficulty of singing modeling caused by high sampling rate , we introduce multi-scale adversarial training in both the acoustic model and vocoder to improve singing modeling. Specifically, 1) To handle the larger range of frequencies caused by higher sampling rate , we propose a novel sub-frequency GAN  on mel-spectrogram generation, which splits the full 80-dimensional mel-frequency into multiple sub-bands  and models each sub-band with a separate discriminator. 2) To model longer waveform sequences caused by higher sampling rate, we propose a multi-length GAN  for waveform generation to model different lengths of waveform sequences with separate discriminators. 3) We also introduce several additional designs and findings in HiFiSinger that are crucial for high-fidelity voices, such as adding F0  and V/UV  as acoustic features, choosing an appropriate window/hop size for mel-spectrogram, and increasing the receptive field in vocoder for long vowel modeling in singing voices. Experiment results show that HiFiSinger synthesizes high-fidelity singing voices with much higher quality: 0.32/0.44 MOS gain over 48kHz/24kHz baseline and 0.83 MOS gain over previous SVS systems. Audio samples are available at \url{https://speechresearch.github.io/hifisinger/}."
"Deep speech representation learning subject large number past works. Many techniques developed employed extracting representations speech related tasks speaker recognition speech emotion recognition using deep learning. A significant number deep learning models based Convolutional Neural Networks SR SER . The common approach training CNN models speech-related tasks use time-frequency inputs spectrograms derived raw audio signals. Given sufficient data, deep learning models enable extraction better speech representations compared methods i-Vectors . Attention mechanisms shown positive impact extracting effective deep representations input data, instance speech signals. Considerable improvements accuracy emotion recognition models speaker recognition models examples demonstrate potential benefits using attention mechanisms representation learning. Attention models uphold memory-query paradigm, memory set information items CNN embeddings region spectral representation speech-related tasks , part utterance embedded recurrent cell recurrent neural network . The query derived hidden state model either modality different one . The majority attention models used speech-related tasks, use features extracted utterances using deep neural network information items memory, last hidden layer model query . The general purpose attention model generating deep representations speech signals focus information item individually. The information items considered attention model define granularity model focus on. The spectral representation utterance enables deep learning models consider fine-grained features frequency bins short time-frames. However, typical attention models used audio signals utilize embedding obtained CNN model memory final embedding model query. Using embeddings obtained CNNs, limits granularity attention models large regions spectral representation. On hand, improving granularity CNN embeddings utterance leads large attention models harder train prone over-fitting. While number studies investigating various attention models using CNN embeddings utterances , limited number studies aim use fine-grained attention models spectral representation utterance. In paper, address challenge improving granularity attention models introducing fine-grained attention mechanism audio signals. This mechanism enables deep learning models focus individual frequency bins spectrogram without drawbacks complex models typically involve large number parameters. The aim model attend frequency bin spectrogram representation order boost contribution salient bins. This mechanism also helps reduce importance bins useful information leading accurate representations, also lead robustness respect existing noise input audio. The performance proposed attention mechanism tested using select set prominent CNN architectures two tasks SR SER. The experimental results show deploying fine-grained frequency attention mechanism improves performance benchmark networks substantially less impacted added noise. Our contributions paper follows: The rest paper organized follows. First, discuss related work area speech representation learning followed particular approaches used attention mechanisms purpose. Next, present proposed attention mechanism. In following section, discuss experiments along implementation details. Next, provide results work. And finally, summarize conclude paper."," Deep learning techniques have considerably improved speech processing in recent years. Speech representations extracted by deep learning models are being used in a wide range of tasks such as speech recognition, speaker recognition, and speech emotion recognition. Attention models play an important role in improving deep learning models. However current attention mechanisms are unable to attend to fine-grained information items. In this paper we propose the novel Fine-grained Early Frequency Attention  for speech signals. This model is capable of focusing on information items as small as frequency bins. We evaluate the proposed model on two popular tasks of speaker recognition and speech emotion recognition. Two widely used public datasets, VoxCeleb and IEMOCAP, are used for our experiments. The model is implemented on top of several prominent deep models as backbone networks to evaluate its impact on performance compared to the original networks and other related work. Our experiments show that by adding FEFA to different CNN architectures, performance is consistently improved by substantial margins, even setting a new state-of-the-art for the speaker recognition task. We also tested our model against different levels of added noise showing improvements in robustness and less sensitivity compared to the backbone networks."
"%%%%%% % TH % % First mention recent progress TTS systems due seq2seq end-to-end training. Text-to-speech systems made great strides introduction sequence-to-sequence neural models, combined end-to-end trainable architectures . Neural models typically take character input learn direct mapping spectrogram waveform output, without need feature engineering. % Then explain common paradigm sentence-based synthesis start defining vocabulatory past/future, left/right/full context. However, neural TTS systems designed work sentence level, i.e. synthetic speech signal generated user typed complete sentence. When processing given word, system thus rely full linguistic context build internal representation. % Now explain paradim problematic several context Despite ability generate high-quality speech, synthesis paradigm ideal several applications. For example, used substitute voice people severe communication disorders integrated dialog system , system's need wait end sentence introduces latency might disruptive conversational flow system interactivity. % Now introduce iTTS Incremental TTS aims address issues synthesizing speech on-the-fly, outputting audio chunks soon new word become available. This task particularly challenging since producing speech without relying full linguistic context result segmental supra-segmental errors . % Now present state art iTTS % first HMM-based synthesis Early iTTS systems developed context HMM-based speech synthesis . In paradigm, models trained set explicit linguistic features . The authors developed coping mechanisms handle missing features making predictions iTTS: unknown future context information replaced common values features inference time , whereas uncertainty features explicitly integrated training time . In , adaptive decoding policy based online estimation stability linguistic features proposed: synthesis given word delayed part-of-speech likely change additional words added. Several strategies proposed reduce latency sequence-to-sequence model input text neural machine translation incremental speech translation. However, studies attempted adapt models iTTS . The authors proposed approach consists marking three subunits within training sentences using start, middle end tags, training Tacotron 2 TTS model tags learns intrasentential boundary characteristics, synthesizing sentences inputting chunks length words appropriate middle end tag. An alternate policy reported \laurent{ consists access future context input tokens generating speech output. They also rely soft attention learn relationship predicted spectrogram currently available source text.} %triggering synthesis attention weights Tacotron decoder moved past increment model processing. These two approaches give promising results introduce fixed size latency. %%%1) splitting training corpus incremental units fixed size 2) training standard Tacotron 2 considering incremental unit training sequence, 3) triggering synthesis time new incremental unit available. The goal present paper pave way toward adaptive decoding policy neural iTTS. Similarly HMM-based iTTS system described , envisioned neural iTTS expected modulate lookahead uncertainty features due lack future context. However, gain naturalness provided end-to-end models also accompanied reduced interpretability. Because black box nature models, studying importance missing features challenging task. To address this, %we finely investigate neural TTS Tacotron2 exploits future context build internal representations. We analyse evolution encoder representations neural TTS words incrementally added . We also investigate text features influential evolution towards final encoder representation. Finally, evaluate effect lookahead perceptual level using MUSHRA listening test. %The rest paper organized follows: describe methodology experimental material section . We follow results discussion section . We finally present conclusions section . %%%%% %Most current text-to-speech systems rely full sentence input produce natural sounding speech. This type system however ideal applications user wants communicate real time, like simultaneous speech interpretation assistive technologies speech impaired. \laurent{In situations, system produce output access entire input. To deal low latency constraint, several strategies proposed encoder-decoder models input text works investigated incremental speech translation incremental text-to-speech synthesis . This latter task particularly challenging since} %with automatic interpreters assistive technologies speech impaired; latency waiting end sentence implies disruptive conversational flow. Conversely, producing speech full context known result segmental errors unnatural prosody. %\laurent{In work study behavior neural sequence-to-sequence TTS system used incremental mode, i.e. generating speech output token , system access tokens text sequence.} %To find balance latency naturalness, measure relative importance different degrees future context studying encoder representations Tacotron 2 system. We believe measuring changes representation different values lookahead parameter might possible define adaptive decoding policy iTTS. We also estimate much future context needed decode cohesive audio output. %The rest paper organized follows: present section related work pertaining iTTS. We describe methodology experimental material section . We follow results discussion section . We finally present conclusions section . %"," In incremental text to speech synthesis , the synthesizer produces an audio output before it has access to the entire input sentence. In this paper, we study the behavior of a neural sequence-to-sequence TTS system when used in an incremental mode, i.e. when generating speech output for token $n$, the system has access to $n+k$ tokens from the text sequence. We first analyze the impact of this incremental policy on the evolution of the encoder representations of token $n$ for different values of $k$ . The results show that, on average, tokens travel $88\%$ of the way to their full context representation with a one-word lookahead and $94\%$ after 2 words. We then investigate which text features are the most influential on the evolution towards the final representation using a random forest analysis. The results show that the most salient factors are related to token length. We finally evaluate the effects of lookahead $k$ at the decoder level, using a MUSHRA listening test. This test shows results that contrast with the above high figures: speech synthesis quality obtained with 2 word-lookahead is significantly lower than the one obtained with the full sentence."
"Text summarization aims produce condensed summaries covering salient non-redundant information source documents. Recent studies single-document summarization benefit advances neural sequence learning well pre-trained language models make great progress. However, multi-document summarization tasks, neural models still facing challenges often underperform classical statistical methods built upon handcrafted features. We observe two major challenges adapting advanced neural SDS methods MDS: Large search space. MDS aims producing summaries multiple source documents, exceeds capacity neural SDS models sets learning obstacles adequate representations, especially considering MDS labeled data limited. For example, 287K training samples CNN/Daily Mail SDS dataset 30 DUC 2003 MDS dataset . High redundancy. In MDS, statement even sentence spread across different documents. Although SDS models adopt attention mechanisms implicit measures reduce redundancy, fail handle much higher redundancy MDS effectively . There attempts solve aforementioned challenges MDS. Regarding large search space, prior studies perform sentence filtering using sentence ranker take top-ranked sentences. However, hard cutoff search space makes approaches insufficient exploration labeled data limited ranker since sentences discarded,\footnote{ set 7 in~\citet{lebanoff-etal-2018-adapting} 15 in~\citet{zhang-etal-2018-adapting}. One document set DUC 2004, example, averages 265.4 sentences.} albeit discarded sentences important could favored. As result, although studies perform better directly applying base SDS models MDS, outperform state-of-the-art MDS methods. Regarding high redundancy, various redundancy measures proposed, including heuristic post-processing counting new bi-grams cosine similarity, dynamic scoring compares source sentence current summary like Maximal Marginal Relevance . Nevertheless, methods still use lexical features without semantic representation learning. One extension studies uses capsule networks improve redundancy measures. However, capsule networks pre-trained SDS fixed feature inputs classical methods without end-to-end representation learning. In paper, present deep RL framework, MMR-guided Reinforcement Learning MDS, unifies advances SDS one classical MDS approach, MMR end-to-end learning. \ours addresses MDS challenges follows: \ours overcomes large search space soft attention. Compared hard cutoff, soft attention favors top-ranked candidates sentence ranker . However, discard low-ranked ones, ranker imperfect, sentences ranked low may also contribute high-quality summary. Soft attention restrains search space allowing exploration limited labeled data, leading better representation learning. Specifically, \ours infuses entire prediction MMR neural module attending important sentences downplaying rest instead completely discarding them. \ours resolves high redundancy MDS unified way: explicit redundancy measure MMR incorporated neural representation current state, two modules coordinated RL reward optimization, encourages non-redundant summaries. We conduct extensive experiments ablation studies examine effectiveness \ours. Experimental results show \ours achieves state-of-the-art performance DUC 2004 TAC 2011 datasets . A comparison various combination mechanisms demonstrates benefits soft attention large search space MDS . In addition, ablation manual studies confirm \ours superior applying either RL MMR MDS alone, MMR guidance effective redundancy avoidance . \start{Contributions} We present RL-based MDS framework combines advances classical MDS neural SDS methods via end-to-end learning. We show proposed soft attention better hard cutoff previous methods learning adequate neural representations. Also, infusing neural representation current summary explicit MMR measures significantly reduces summary redundancy. We demonstrate \ours achieves new state-of-the-art results benchmark MDS datasets."," While neural sequence learning methods have made significant progress in single-document summarization , they produce unsatisfactory results on multi-document summarization . We observe two major challenges when adapting SDS advances to MDS:  MDS involves larger search space and yet more limited training data, setting obstacles for neural methods to learn adequate representations;  MDS needs to resolve higher information redundancy among the source documents, which SDS methods are less effective to handle. To close the gap, we present \ours, Maximal Margin Relevance-guided Reinforcement Learning for MDS, which unifies advanced neural SDS methods and statistical measures used in classical MDS.  \ours casts MMR guidance on fewer promising candidates, which restrains the search space and thus leads to better representation learning. Additionally, the explicit redundancy measure in MMR helps the neural representation of the summary to better capture redundancy. Extensive experiments demonstrate that \ours achieves state-of-the-art performance on benchmark MDS datasets. In particular, we show the benefits of incorporating MMR into end-to-end learning when adapting SDS to MDS in terms of both learning effectiveness and efficiency.\footnote{Code can be found at \url{https://github.com/morningmoni/RL-MMR}.}"
"Natural language generators task-oriented dialogue take meaning representations inputs, i.e. set dialogue acts attributes values, output natural language utterances realizing MR. Current NLGs trained end-to-end corpus MR/utterance pairs MRs cover specific set dialogue acts domain attributes. Creation datasets labor intensive time consuming. However, building NLG new domain ontology, possible re-use data built existing domain ontologies. If possible, would speed development new dialogue systems significantly. \end{footnotesize} blue} NYC {\color{darkred}red}. Some attributes shared sources: unique dialogue acts attributes source underlined E1 E2. E3 illustrates MR target test set dub COM. All MRs COM combine dialogue acts attributes E2E NYC. There training data corresponding E3. %: goal task re-use %the existing training data E2E NYC %and train NLG %can generalize unseen combinations %as shown E3. The MRs illustrate attribute values, e.g. {\sc restaurant name, point-of-interest}, delexicalized improve generalization.} \end{figure*} Here experiment one version task building new domain ontology based {\bf combining} two existing ontologies, utilizing training data. Each dataset based different domain ontology restaurant domain, novel attributes dialogue acts seen dataset, e.g. one attributes representing family friendly rating information, one attributes decor service. Our aim NLG engine realize utterances extended {\bf combined} ontology seen training data, e.g. MRs specify values family friendly, rating, decor service. Figure illustrates task. Example E1 training set referred NYC, previous work controllable sentence planning NLG , E2 E2E NLG shared task . As describe detail Section, E1 E2 based two distinct ontologies. Example E3 %in Figure illustrates task addressed paper: create test set novel MRs combined ontology, train model generate high quality outputs individual sentences realize attributes ontologies. To knowledge, completely novel task. While common practice NLG construct test sets MRs realize attribute combinations seen training, initial experiments showed task surprisingly adversarial. However, methods supporting type generalization extension new cases would great benefit task-oriented dialogue systems, common start restricted set attributes enlarge domain ontology time. New attributes constantly added databases restaurants, hotels entities support better recommendations better search. Our experiments test whether existing data covers subset attributes used produce NLG enlarged ontology. We describe create test set --- call {\sc com} --- combined MRs test different methods creating NLG. A baseline sequence-to-sequence NLG model slot error rate .45 produces semantically perfect outputs 3.5\% time. To improve performance, experiment three different ways conditioning model incorporating side constraints encode source attributes MR . %, i.e.,whether E2E NYC both. However, increases proportion semantically perfect model outputs 3.5\% 5.5\% . We propose motivate novel self-training method greatly improves performance learning model mistakes. An error analysis shows models {\bf do} produce many {\bf combined} outputs, errorful semantics. We develop rule-based text-to-meaning semantic extractor automatically creates novel correct MR/text training instances errorful model outputs, use self-training experiments, thus learning mistakes . We validate text-to-meaning extractor human evaluation. We find model trained process produces SERs .03, semantically perfect outputs 81\% time . A human evaluation shows outputs also natural, coherent grammatical. Our contributions are: We start Section defining task detail, describe models metrics Section, results Section. We discuss related work throughout paper relevant conclusion Section."," Natural language generators  for task-oriented dialogue typically take a meaning representation  as input, and are trained end-to-end with a corpus of MR/utterance pairs, where the MRs cover a specific set of dialogue acts and domain attributes. Creation of such datasets is labor intensive and time consuming. Therefore, dialogue systems for new domain ontologies would benefit from using data for pre-existing ontologies.   Here we explore, for the first time, whether  it  is possible to train  an NLG for a new {\bf larger} ontology using  existing training sets for the restaurant domain, where each set is based on a {\bf different} ontology. We create a new, larger {\bf combined}  ontology,  and then  train an NLG  to produce utterances covering it. For example, if one dataset has  attributes for family friendly and   rating information, and the other has attributes for decor and service, our aim is an NLG for the combined ontology that can produce utterances that realize values for family friendly, rating, decor and   service.   Initial experiments with a baseline neural sequence-to-sequence model show that this task is surprisingly  challenging. %, and that in many cases the models do not produce combine attributes from the two original ontologies, and when they do the semantics are highly errorful. We then develop a  novel {\bf self-training} method that identifies  model outputs, automatically  constructs a corrected MR input to form a new  training pair, and then repeatedly adds these new instances back into the training data. %that combine attributes from both sources %and then automatically construct an MR that matches the string that %was actually generated .   %We repeatedly construct and add these %new instances back into training, resulting in a self-trained %model that produces semantically perfect outputs 83\% of the time. %We repeatedly construct and add these %new instances back into training, resulting  We then test the resulting model on a new test set. The result is a self-trained model whose performance is an absolute 75.4\% improvement over the baseline model.  %can produce semantically perfect outputs 83\% of the time. %improves the proportion of semantically perfect outputs for the new combined ontology  from 5.5\% to 83\%.  We also report a human qualitative evaluation of the final  model showing that it achieves high naturalness, semantic coherence and grammaticality."
"In recent years, neural LMs shown profound abilities generate texts could almost indistinguishable human writings . Neural LMs could used generate concise summaries , coherent stories , complete documents given prompts . It natural question source extent rhetorical knowledge: What makes neural LMs articulate, how? While recent works query linguistic knowledge , open question remain unanswered. We hypothesize contextualized neural LMs encode rhetorical knowledge intermediate representations, would like quantify extent encode rhetorical knowledge. To verify hypothesis, hand-craft set 24 rhetorical features including used examine rhetorical capacities students , evaluate well neural LMs encode rhetorical features representations encoding texts. Recent work started evaluate encoded features hidden representations. Among them, probing popular choice. Previous work probed morphological , agreement , syntactic features . Probing involves optimizing simple projection model representations features. The loss optimization measures difficulty decode features representations. In work, use probe containing self attention mechanism. We first project variable-length embeddings fixed-length latent representation per document. Then, apply simple diagnostic classifier detect rhetorical features latent representation. This design probe reduces total number parameters, enable us better understand model's ability encode rhetorical knowledge. We find that: These observations allow us investigate mechanisms neural LMs better understand degree encode linguistic knowledge. We demonstrate discourse-level features queried analyzed neural LMs. All code parsed tree data available github."," Recently, neural language models  have demonstrated impressive abilities in generating high-quality discourse. While many recent papers have analyzed the syntactic aspects encoded in LMs, to date, there has been no analysis of the inter-sentential, rhetorical knowledge.  In this paper, we propose a method that quantitatively evaluates the rhetorical  capacities of neural LMs. We examine the capacities of neural LMs understanding the rhetoric of discourse by evaluating their abilities to encode a set of linguistic features derived from Rhetorical Structure Theory . Our experiments show that BERT-based LMs outperform other Transformer LMs, revealing the richer discourse knowledge in their intermediate layer representations. In addition, GPT-2 and XLNet apparently encode less rhetorical knowledge, and we suggest an explanation drawing from linguistic philosophy. Our method presents an avenue towards quantifying the rhetorical capacities of neural LMs."
"Our WeChat AI team participates WMT 2020 shared news translation task ChineseEnglish. In year閳ユ獨 translation task, mainly focus exploiting several effective model architectures, better data augmentation, training model ensemble strategies. For model architectures, mainly exploit two different architectures approaches, namely Transformers RNMT. For Transformers, implement Deeper transformer Pre-Norm, Wider Transformer larger filter-size average attention based transformer. For RNMT, use deep transition based DTMT model. We finally ensemble four kinds models system. For synthetic data generation, explore various methods out-of-domain in-domain data generation. For out-of-domain data generation, explore back-translation method leverage target side monolingual data knowledge distillation method leverage source side golden parallel data. For in-domain data generation, employ iterative in-domain knowledge transfer leverage source side monolingual data golden parallel data. Furthermore, data augmentation methods, including noisy fake data sampling, used training robust NMT models. %We also apply techniques corresponding side golden parallel data. For training strategies, mainly focus parallel scheduled sampling, target denoising minimum risk training algorithm in-domain finetuning. We also exploit self-bleu based model ensemble approach enhance system. As result, constrained ChineseEnglish system achieves highest case-sensitive BLEU score among submitted systems. In remainder paper, start overview model architectures Section. Section describes details systems training strategies. Then Section shows experimental settings results. Finally, conclude work Section."," We participate in the WMT 2020 shared news translation task on Chinese$\to$English. Our system is based on the Transformer with effective variants and the DTMT architecture. In our experiments, we employ data selection, several synthetic data generation approaches ,  advanced finetuning approaches and self-bleu based model ensemble. Our constrained Chinese$\to$English system achieves 36.9 case-sensitive BLEU score, which is the highest among all submissions."
"Social media become essential element society people communicate exchange information daily basis. The strong influence social media internet users great benefit many individuals, businesses, organizations. Many companies organizations nowadays use social media reach customers, promote products, ensure customer satisfaction. Despite benefits associated widespread use social media, remain vulnerable ill-intentioned activities, openness, anonymity, informal structure platforms contributed spread harmful violent content. \par Although social media service providers policies control ill-intentioned behaviors, rules rarely followed users. Social media providers also allow users report inappropriate content, unreported content may discovered due huge volume data platforms. Some countries restricted use social media, others taken legal action regarding violent harmful content might target particular individuals communities. However, violations might end unpunished due anonymous nature platforms, allowing ill-intentioned users fearlessly share harmful content using nicknames fake identities. One most-shared harmful content social media hate content, might take different forms text, photos, and/or video. Hate speech expression encourages, promotes, justifies violence, hatred, discrimination person group individuals based characteristics color, gender, race, sexual orientation, nationality, religion, attributes. Online hate speech rapidly increasing entire world, nearly \% world閳ユ獨 population communicates social media. Studies shown nearly \% Americans experienced online hate harassment. This result \% higher results comparable questionnaire conducted . For younger people, results show \% teenagers frequently encounter hate speech social media. \par One dangerous influential forms online hate speech led spread supporters extreme ideologies target racial groups minorities. White supremacists one ideological groups believe people white race superior dominant people races; also referred white nationalism radical ideologies. White supremacists claim undermined dark skin people, Jews, multicultural Muslims, want restore white people閳ユ獨 power, violently necessary. They also claimed responsibility many violent incidents happened s, including bank robberies, bombings, murders. The white supremacist ideology adopted right-wing left-wing extremists combine white supremacy political movements. \par White supremacist hate speech become significant threat community, either influencing young people hateful ideas creating movements implement goals real world. A study also suggested links hate speech hate crimes others . Several recent brutal attacks also committed supporters radical white supremacists active members social media. The mass shootings New Zealand, Texas, Norway committed white supremacists shared opinions ideologies social media. The attacker two mosques Christchurch, New Zealand, 28 year old man identified white nationalist hero, posted manifesto discussed intent kill people way reinforce sovereignty white extremists. From psychological point view, violent attack must preceded warning behaviors, includes behavior shows violent attack associated it, certain situations predict it. Warning behaviors either real-world markers linguistic markers signs happen real life and/or online. \par Automatic detection white supremacist content social media used predict hate crimes violent events. Perpetrators caught attacks happen examining online posts give strong indications intent make attack. Predicting violent attacks based monitoring online behavior would helpful crime prevention, detecting hateful speech social media also help reduce hatred incivility among social media users, especially younger generations. \par Studies investigated detection different kinds hate speech detecting cyberbullying , offensive language , targeted hate speech general distinguishing types hate speech neutral expressions. Others dealt problem detecting specific types hate speech, anti-religion, jihadist, sexist, racist. However, less attention given detecting white supremacism particular, limited studies. \par White supremacist extremists tend use rhetoric language. They also use specific vocabulary, abbreviations, coded words express beliefs intent promote hatred encourage violence avoid detected traditional detection methods. They mostly use hate speech races religions, claim races undermining them. Figure shows example white supremacist tweet. \par \subsection{Research goal contributions} In paper, aim detect white supremacist tweets based textual features using deep learning techniques. We collected tweets white supremacist accounts hashtags extract word embeddings, labeled subsets data corpus build white supremacist dataset. We applied two approaches: first uses domain-specific word embedding learned corpus classifies tweets using Bidirectional LSTM-based deep model. This approach evaluated multiple dataset achieved different results depending datasets ranged \% \% F1-score. The second approach uses pre-trained language model fine-tune white supremacist dataset using Neural Network dense layer. The BERT language model F1-scores ranged \% \%. Thus, research contribution summarized follow: \par The rest paper proceeds Background Section , provides information methodology used, related studies Literature Review section , detailed description methods Methodology section , details used datasets Dataset section , specifications methodologies results approach Experiments Results section , observations analysis performance approach Discussion section , finally, Conclusion Future Work section .","  White supremacists embrace a radical ideology that considers white people superior to people of other races. The critical influence of these groups is no longer limited to social media; they also have a significant effect on society in many ways by promoting racial hatred and violence. White supremacist hate speech is one of the most recently observed harmful content on social media. Traditional channels of reporting hate speech have proved inadequate due to the tremendous explosion of information, and therefore, it is necessary to find an automatic way to detect such speech in a timely manner. This research investigates the viability of automatically detecting white supremacist hate speech on Twitter by using deep learning and natural language processing techniques. Through our experiments, we used two approaches, the first approach is by using domain-specific embeddings which are extracted from white supremacist corpus in order to catch the meaning of this white supremacist slang with bidirectional Long Short-Term Memory  deep learning model, this approach reached a 0.74890 F1-score. The second approach is by using the one of the most recent language model which is BERT, BERT model provides the state of the art of most NLP tasks. It reached to a 0.79605 F1-score. Both approaches are tested on a balanced dataset given that our experiments were based on textual data only. The dataset was combined from dataset created from Twitter and a Stormfront dataset compiled from that white supremacist forum."
"Graph Neural Networks recent years shown provide scalable highly performant means incorporating linguistic information structural biases NLP models. They applied various kinds representations shown effective range tasks, including relation extraction~, question answering~, syntactic semantic parsing tasks~, summarization ~, machine translation~ abusive language detection social networks~. While GNNs often yield strong performance, % models % complex, difficult understand `reasoning' behind predictions. For NLP practitioners, highly desirable know linguistic information given model encodes encoding happens~. The difficulty interpreting GNNs represents barrier analysis. % Furthermore, opaqueness decreases user trust% , impedes discovery harmful biases, complicates error analysis% ~, issue GNNs seemingly small implementation differences make break models~. In work, focus post-hoc analysis GNNs formulate desiderata interpretation method: A simple way perform interpretation use erasure search~, approach wherein attribution happens searching maximal subset features entirely removed without affecting model predictions. % The removal guarantees information discarded features ignored model. This contrasts approaches use heuristics define feature importance, example attention-based methods~ back-propagation techniques~. They guarantee model ignores low-scoring features, attracting criticism recent years . % The trust erasure search reflected literature methods % motivated approximations erasure~, new attribution techniques % evaluated using erasure search ground truth~. Applied GNNs, erasure search would involve search largest subgraph completely discarded. Besides faithfulness considerations conceptual simplicity, discrete attributions would also simplify comparison relevance paths; contrast continuous attribution edges, straightforward extract visualize important paths. Furthermore, contrast techniques based artificial gradients~, erasure search would provide implementation invariance~. This important NLP, models commonly use highly parametrized decoders top GNNs, e.g.~\citet{koncel-kedziorski-etal-2019-text}. While arguably satisfying criteria desiderata, erasure search unfortunately fails tractability. In practical scenarios, infeasible, even approximations, remove one feature time~ underestimate contribution due saturation~, remain prohibitively expensive. Our GraphMask aims meeting desiderata achieving benefits erasure search scalable manner. That is, method makes easily interpretable hard choices whether retain discard edges discarded edges relevance model predictions, remaining tractable model-agnostic~. GraphMask understood differentiable form subset erasure, where, instead finding optimal subset erase every given example, learn erasure function predicts every edge every layer whether connection retained. Given example graph , method returns layer subgraph faithfully claim edges outside influence predictions model. To enable gradient-based optimization erasure function, rely sparse stochastic gates~. In erasure search, optimization happens individually example. This result form overfitting even non-superfluous edges aggressively pruned, similar prediction could made using alternative smaller subgraph; refer problem hindsight bias. % Because model relies parametrized erasure function rather individual per-edge choice, address issue amortizing parameter learning training dataset process similar readout bottleneck introduced in~\citet{schulz2020restricting}. As demonstrate Section, strategy avoids hindsight bias. \paragraph{Contributions} Our contributions follows:"," Graph neural networks  have become a popular approach to integrating structural inductive biases into NLP models. However, there has been little work on interpreting them, and specifically on understanding which parts of the graphs  contribute to a prediction. In this work, we introduce a post-hoc method for interpreting the predictions of GNNs which identifies unnecessary edges. % Given a trained GNN model, we learn a simple classifier that, for every edge in every layer, predicts if that edge can be dropped. We demonstrate that such a classifier can be trained in a fully differentiable fashion, employing stochastic gates and encouraging sparsity through the expected  $L_0$ norm. We use our technique as an attribution method to analyze GNN models for two tasks -- question answering and semantic role labeling -- providing insights into the information flow in these models. We show that we can drop a large proportion of edges without deteriorating the performance of the model, while we can analyse the remaining edges for interpreting model predictions."
"Many natural language tasks involve entities, e.g., relation classification, entity typing, named entity recognition , question answering . Key solving entity-related tasks model learn effective representations entities. Conventional entity representations assign entity fixed embedding vector stores information regarding entity knowledge base . Although models capture rich information KB, require entity linking represent entities text, cannot represent entities exist KB. By contrast, contextualized word representations based transformer , BERT , RoBERTa , provide effective general-purpose word representations trained unsupervised pretraining tasks based language modeling. Many recent studies solved entity-related tasks using contextualized representations entities computed based CWRs . However, architecture CWRs well suited representing entities following two reasons: Because CWRs output span-level representations entities, typically need learn compute representations based downstream dataset typically small. Many entity-related tasks, e.g., relation classification QA, involve reasoning relationships entities. Although transformer capture complex relationships words relating multiple times using self-attention mechanism , difficult perform reasoning entities many entities split multiple tokens model. Furthermore, word-based pretraining task CWRs suitable learning representations entities predicting masked word given words entity, e.g., predicting ``Rings'' given ``The Lord [MASK]'', clearly easier predicting entire entity. In paper, propose new pretrained contextualized representations words entities developing LUKE . LUKE based transformer trained using large amount entity-annotated corpus obtained Wikipedia. An important difference LUKE existing CWRs treats words, also entities independent tokens, computes intermediate output representations tokens using transformer . Since entities treated tokens, LUKE directly model relationships entities. LUKE trained using new pretraining task, straightforward extension BERT's masked language model . The task involves randomly masking entities replacing entities, trains model predicting originals masked entities. We use RoBERTa base pre-trained model, conduct pretraining model simultaneously optimizing objectives MLM proposed task. When applied downstream tasks, resulting model compute representations arbitrary entities text using entities inputs. Furthermore, entity annotation available task, model compute entity representations based rich entity-centric information encoded corresponding entity embeddings. Another key contribution paper extends transformer using entity-aware self-attention mechanism. Unlike existing CWRs, model needs deal two types tokens, i.e., words entities. Therefore, assume beneficial enable mechanism easily determine types tokens. To end, enhance self-attention mechanism adopting different query mechanisms based attending token token attended to. We validate effectiveness proposed model conducting extensive experiments five standard entity-related tasks: entity typing, relation classification, NER, cloze-style QA, extractive QA. Our model outperforms baseline models, including RoBERTa, experiments, obtains state-of-the-art results five tasks: entity typing Open Entity dataset , relation classification TACRED dataset , NER CoNLL-2003 dataset , cloze-style QA ReCoRD dataset , extractive QA SQuAD 1.1 dataset . We publicize source code pretrained representations \url{https://github.com/studio-ousia/luke}. The main contributions paper summarized follows:","     Entity representations are useful in natural language tasks involving entities.     In this paper, we propose new pretrained contextualized representations of words and entities based on the bidirectional transformer \cite{NIPS2017_7181}.     The proposed model treats words and entities in a given text as independent tokens, and outputs contextualized representations of them.     Our model is trained using a new pretraining task based on the masked language model of BERT \cite{devlin2018bert}.     The task involves predicting randomly masked words and entities in a large entity-annotated corpus retrieved from Wikipedia.     We also propose an entity-aware self-attention mechanism that is an extension of the self-attention mechanism of the transformer, and considers the types of tokens  when computing attention scores.     The proposed model achieves impressive empirical performance on a wide range of entity-related tasks.     In particular, it obtains state-of-the-art results on five well-known datasets: Open Entity , TACRED , CoNLL-2003 , ReCoRD , and SQuAD 1.1 .     Our source code and pretrained representations are available at \url{https://github.com/studio-ousia/luke}."
"Modern methods natural language processing based complex neural network architectures, language units represented metric space . Such phenomenon allows us express linguistic features mathematically. The method obtaining representation interpretations described multiple overview works. Almeida Xex\'eo surveyed different types static word embeddings , Liu et al. focused contextual representations found recent neural models. Belinkov Glass surveyed strategies interpreting latent representation. Best knowledge, first focus syntactic morphological abilities word representations. We also cover latest approaches, go beyond interpretation latent vectors analyze attentions present state-of-the-art Transformer models. %analyzed matrix representation neural networks. %. %\tltodo{Maybe use ToC instroduction section remove here} %The survey organized following way: %In Section, introduce several types NLP models going analyzed. Section shortly describes metrics used evaluate syntactic information captured models. The observations results static contextual word embeddings presented Section. The observations attention matrices different Transformer architectures described Section. We summarize findings Section. %for attention matrices Transformer models. %We conclude survey mentioning supervised approaches enhance syntactic signal. %","  Neural networks trained on natural language processing tasks capture syntax even though it is not provided as a supervision signal. %The syntax is captured by the natural language processing models even when not provided as a supervision signal. This %This phenomenon  indicates that syntactic analysis is essential to the understating of language in artificial intelligence systems. % This overview paper covers approaches of evaluating the amount of syntactic information included in the representations of words for different neural network architectures. %This overview paper covers approaches to evaluating of syntactic information in the representation of words in neural networks. We compare the spectrum of model architectures and the training data. We mainly summarize research on English monolingual data on language modeling tasks and multilingual data for neural machine translation systems and multilingual language models.   %Particularly we consider corpora in one language, mainly English used for training Language Models, and multilingual data for Machine Translation Systems and Multilingual Language Models. We describe which pre-trained models and representations of language are best suited for transfer to syntactic tasks.  % We hope that our comparison will help in finding pretrained model for transfer   % The survey covers the research on producing representation of language and evaluation of captured syntactic information. I focus on the works that do not use syntactic supervision during training of the representation, and are obtained on large mono or multilingual corpora.  % The aim of this work is to examine to what extent syntactic features can be extracted from plain text and how it can be compared to expert annotations."
"Texts represent main source knowledge society. However, written various manners, thus creating barrier readers ideas intend convey. Therefore, document comprehension main challenge users overcome, understanding meaning behind troublesome words becoming familiar them. Complex Word Identification task intends identify hard-to-understand tokens, highlighting clarification assisting users grasping contents document. Motivation. Each culture includes exclusive ideas, available ones pass obstacle language. However, properly understanding language prove difficult task. By identifying complex words, users make consistent steps towards adapting culture accessing knowledge offer. As example, entries like ""mayoritariamente"" ""gobernatura"" Spanish environment create understanding problems non-native Spanish speakers, thus requiring users familiarize particular terms. Challenges. The identification task becomes increasingly difficult, proper complex word identification guaranteed. For example, use human identification techniques, language learners may consider new word complex, others might share opinion relying prior knowledge language. Therefore, universal annotation techniques required, ground truth established set words considered complex context. Proposed Approach. We consider state-of-the-art solutions, namely multilingual Transformer-based approaches, address CWI challenge. First, apply zero-shot learning approach. This performed training Recurrent Neural Networks Transformer-based models source language corpus, followed validating testing corpus target language, different source language. A second experiment consists one-shot learning approach considers training three languages , keeping one entry target language, validating testing English, German, Spanish, French, respectively. In addition, performed few-shot learning experiments validating testing language, training others, addition small number training entries target language. The model learns sample structures language and, general, performs better applied multiple entries. Furthermore, training process help model adapt situations number training inputs scarce. The dataset provided CWI Shared Task 2018 used perform experiments. This paper structured follows. The second section describes related work impact CWI task. The third section describes corpus outlines method based multilingual embeddings Transformer-based models, together corresponding experimental setup. The fourth section details results, alongside discussion error analysis. The fifth section concludes paper outlines main ideas, together potential extensions."," Complex Word Identification  is a task centered on detecting hard-to-understand words, or groups of words, in texts from different areas of expertise. The purpose of CWI is to highlight problematic structures that non-native speakers would usually find difficult to understand. Our approach uses zero-shot, one-shot, and few-shot learning techniques, alongside state-of-the-art solutions for Natural Language Processing  tasks . Our aim is to provide evidence that the proposed models can learn the characteristics of complex words in a multilingual environment by relying on the CWI shared task 2018 dataset available for four different languages . Our approach surpasses state-of-the-art cross-lingual results in terms of macro F1-score on English , German , and Spanish  languages, for the zero-shot learning scenario. At the same time, our model also outperforms the state-of-the-art monolingual result for German ."
"Aspect based sentiment analysis fine-grained sentiment analysis task. ABSA contains several subtasks, four aspect category detection detecting aspect categories mentioned sentences, aspect category sentiment analysis predicting sentiments detected aspect categories, aspect term extraction identifying aspect terms presenting sentences aspect term sentiment analysis classifying sentiments toward identified aspect terms. While aspect categories mentioned sentence predefined categories may occur sentence, aspect terms explicitly appear sentences. Fig. shows example. ACD detects two aspect categories food service ACSA predicts positive negative sentiments toward them. ATE identifies two aspect terms ``taste'' ``service'' ATSA classifies positive negative sentiments toward them. In paper, concentrate ACSA task. The ACD task auxiliary used find aspect category-related nodes sentence constituency parse trees ACSA task. Since sentence usually discusses one aspect categories expresses different sentiments toward them, various attention-based methods developed allocate appropriate sentiment words given aspect categories. Wang et al. first explore attention mechanism ACSA task proposed attention based LSTM . For given sentence aspect category mentioned sentence, AT-LSTM first models sentence via LSTM model, combines hidden states LSTM representation aspect category generate aspect category-specific word representations, finally applies attention mechanism word representations find aspect category-related sentiment words, used predict sentiment aspect category. The constrained attention networks handles multiple aspect categories sentence simultaneously introduces orthogonal sparse regularizations constrain attention weight allocation. The aspect-level sentiment capsules model performs ACD ACSA simultaneously, also uses attention mechanism find aspect category related sentiment words achieves state-of-the-art performances ACSA task. However, models directly use given aspect category find aspect category-related sentiment words, may cause mismatching sentiment words aspect categories unrelated sentiment word semantically meaningful given aspect category. For example Fig., ``Great'' ``bad'' used interchangeably. It hard attention-based methods distinguish word associated aspect category food service among ``good'' ``bad''. To solve problem, The HiErarchical ATtention network first finds aspect terms indicating given aspect cagegory, finds aspect category-related sentiment words depending position information semantics aspect terms. Although HEAT obtains good results, train HEAT, additionally need annotate aspect terms indicating given aspect category, time-consuming expensive. To mitigate mismatch problem, propose Sentence Constituent-Aware Network aspect-category sentiment analysis require additional annotation. SCAN contains two graph attention networks interactive loss function. Given sentence, first use Berkeley Neural Parser generate constituency parse tree. The two GATs generate representations nodes sentence constituency parse tree ACD task ACSA task, respectively. The GAT ACD mainly attends words indicating aspect categories, GAT ACSA mainly attends sentiment words. For given aspect category, interactive loss function helps ACD task find nodes predict aspect category can閳ユ獩 predict aspect categories. The sentiment words nodes used predict sentiment polarity aspect category ACSA task. Fig. shows constituency parse tree sentence ``Greate taste bad service.''. For aspect category food, SCAN first finds yellow nodes ``Greate taste'' ``taste'', predict sentiment food based sentiment word ``Great'' node ``Great taste''. SCAN excludes blue node ``Great taste bad service.'' food, predict food also service. The main contributions work summarized follows:"," Aspect category sentiment analysis  aims to predict the sentiment polarities of the aspect categories discussed in sentences. Since a sentence usually discusses one or more aspect categories and expresses different sentiments toward them, various attention-based methods have been developed to allocate the appropriate sentiment words for the given aspect category and obtain promising results. However, most of these methods directly use the given aspect category to find the aspect category-related sentiment words, which may cause mismatching between the sentiment words and the aspect categories when an unrelated sentiment word is semantically meaningful for the given aspect category. To mitigate this problem, we propose a Sentence Constituent-Aware Network  for aspect-category sentiment analysis. SCAN contains two graph attention modules and an interactive loss function. The graph attention modules generate representations of the nodes in sentence constituency parse trees for the aspect category detection  task and the ACSA task, respectively. ACD aims to detect aspect categories discussed in sentences and is a auxiliary task. For a given aspect category, the interactive loss function helps the ACD task to find the nodes which can predict the aspect category but can闁炽儲鐛 predict other aspect categories. The sentiment words in the nodes then are used to predict the sentiment polarity of the aspect category by the ACSA task. The experimental results on five public datasets demonstrate the effectiveness of SCAN. \footnote{Data and code can be found at https://github.com/l294265421/SCAN}  \keywords{Aspect Category Sentiment Analysis  \and Aspect Based Sentiment Analysis \and Graph Attention Network.}"
"With rapid development e-commerce, online reviews written users become increasingly important reflecting real customer experiences. To ease process review writing, task personalized review generation~ proposed automatically produce review text conditioned necessary context data, \eg users, items, ratings. As mainstream solution, RNN-based models widely applied PRG task. Standard RNN models mainly model sequential dependency among tokens, cannot effectively generate high-quality review text. Many efforts devoted improving kind architecture PRG task, including context utilization, long text generation, writing style enrichment. These studies improved performance PRG task extent. However, two major issues still remain solved. First, generated text likely uninformative, lacking factual description product information. Although several studies try incorporate structural semantic features , mainly extract features review text. Using review data alone, difficult fully capture diverse comprehensive facts unstructured text. Second, studies focus word-level generation, makes difficult directly model user preference higher level. For example, given product, user may focus price, another user may emphasize look. To address issues, propose improve PRG task external knowledge graph . By associating online items KG entities, able obtain rich attribute feature information items, potentially useful PRG task. Although idea intuitive, easy fully utilize knowledge information generating review text task. KG typically organizes facts triples, describing relation two involved entities. It may suitable simply integrate KG information enhance text representations capture user preference due varying intrinsic characteristics different data signals. In order bridge semantic gap, augment original KG user word nodes, construct heterogeneous knowledge graph adding user-item links entity-word links. User-item links formed according user-item interactions, entity-word links formed according co-occurrence review sentences. We seek learn unified semantic space able encode different kinds nodes. Figure presents illustrative example HKG. Given graph, focus two kinds useful information PRG task. First, associated facts regarding item incorporated enrich review content. Second, considering users target nodes, utilize graph infer users' preference specific relation aspect . The two kinds information reflect word- aspect-level enrichment, respectively. To utilize semantics two levels, decompose review generation process two stages, namely aspect sequence generation sentence generation. We aim inject multi-granularity KG information different generation stages improving PRG task. To end, paper, propose KG-enhanced personalized review generation model based capsule graph neural networks~. Compared existing GNN-based methods representing graphs individual scalar features, Caps-GNN extract underlying characteristics graphs capsules graph level dynamic routing mechanism capsule reflects graph properties different aspects. Based constructed HKG, utilize Caps-GNN extract graph properties different aspects graph capsules, may helpful infer aspect- word-level user preference. For aspect sequence generation, propose novel adaptive learning algorithm able capture personalized user preference aspect level, called aspect capsules, graph capsules. We associate aspect capsule unique aspect unsupervised topic models. Furthermore, generation sentences, utilize learned aspect capsules capture personalized user preference word level. Specially, design graph-based copy mechanism generate related entities words copying HKG, enrich review contents. In way, KG information effectively utilized aspect word levels model. %To knowledge, first utilize knowledge graph generate personalized review text, able capture aspect- word-level KG semantics learning user preference. To knowledge, first utilize KG capture aspect- word-level user preference generating personalized review text. For evaluation, constructed three review datasets associating items KG entities. Extensive experiments demonstrate effectiveness KG information model. %%Our code dataset released review period."," Personalized review generation  aims to automatically produce review text reflecting user preference, which is a challenging natural language generation task. Most of previous studies do not explicitly model  factual description of products, tending to generate uninformative content. Moreover, they mainly focus on word-level generation, but cannot accurately reflect more abstractive  user preference in multiple aspects.  To address the above issues, we propose a novel knowledge-enhanced PRG model  based on capsule graph neural network~. We first  construct a heterogeneous knowledge graph  for utilizing rich item attributes. We adopt  Caps-GNN to learn graph capsules for encoding underlying characteristics from the HKG. Our generation process contains two major steps, namely aspect sequence generation and sentence generation. First, based on graph capsules, we adaptively learn aspect capsules for inferring the aspect sequence.   Then, conditioned on the inferred aspect label, we design a graph-based copy mechanism to generate sentences by incorporating related entities or words from HKG. To our knowledge, we are the first to utilize knowledge graph for the PRG task. The incorporated KG information is able to enhance user preference at both aspect and word levels. Extensive experiments on three real-world datasets have demonstrated the effectiveness of our model on the PRG task."
"% significance sentence functions dialog Humans express intentions conversations sentence functions, interrogation acquiring information, declaration making statements, imperative making requests instructions. For machines interact humans, therefore essential enable make use sentence functions dialogue generation. Sentence function important linguistic feature indicating communicative purpose sentence conversation. There four major sentence functions: Declarative, Interrogative, Exclamatory Imperative . Each major sentence function decomposed fine-grained ones according different purposes indicated conversations. For example, Interrogative divided Wh-style Interrogative, Yes-no Interrogative types. These fine-grained sentence functions great influences structures utterances conversations including word orders, syntactic patterns, aspects . Figure presents sentence functions influence responses. Given query expressed Positive Declarative, responses expressed Wh-style Interrogative Negative Declarative completely different. % challenges, quantitatively list numbers Although use sentence functions improves overall quality generated responses , suffers data imbalance issue. For example, recently released response generation dataset manually annotated sentence functions STC-SeFun , 40\% utterances Positive Declarative utterances annotated Declarative Interrogative words account less 1\% entire dataset. Therefore, dialogue generation models suffer data deficiency infrequent sentence functions. % proposed method Recently, model-agnostic meta-learning ~ shown promising results several low-resource natural language generation tasks, including neural machine translation , personalized response generation domain-adaptive dialogue generation . They treat languages translation, personas dialog dialog domains separate tasks MAML respectively. In spirit previous works, first treat dialogue generation conditioned different sentence functions separate tasks, meta-train dialogue generation model using high-resource sentence functions. Moreover, observe sentence functions hierarchical structures: four major sentence functions divided twenty fine-grained types. Some fine-grained sentence functions may share similarities others disparate. For example, utterances belong Wh-style Interrogative Yes-no Interrogative may share transferable word patterns utterances Wh-style Interrogative Exclamatory interjections totally differ other. Motivated observation, explore structured meta-learning considering inherent structures among fine-grained sentence functions. Inspired recent advances learning several initializations set meta-learners , develop approach utilize underlying structure sentence functions. More specifically, proposed SML explicitly tailors transferable knowledge among different sentence functions. It utilizes learned representations fine-grained sentence functions parameter gates influence globally shared parameter initialization. Therefore, conversation models similar sentence functions share similar parameter initializations vice versa. As result, SML enhances meta-learning effectiveness promoting knowledge customization among different sentence functions simultaneously preserving knowledge generalization similar sentence functions. % experiments The experimental results STC-SeFun dataset show responses generated proposed structured meta-learning algorithm better quality several baselines human automatic evaluations. Moreover, proposed model generate responses consistent target sentence functions baseline models may ignore target sentence functions generate generic responses. We conduct detailed analysis proposed model show indeed learn word orders syntactic patterns different fine-grained sentence functions."," Sentence function is an important linguistic feature indicating the communicative purpose in uttering a sentence. Incorporating sentence functions into conversations has shown improvements in the quality of generated responses. However, the number of utterances for different types of fine-grained sentence functions is extremely imbalanced. Besides a small number of high-resource sentence functions, a large portion of sentence functions is infrequent. Consequently, dialogue generation conditioned on these infrequent sentence functions suffers from data deficiency. In this paper, we investigate a structured meta-learning  approach for dialogue generation on infrequent sentence functions. We treat dialogue generation conditioned on different sentence functions as separate tasks, and apply model-agnostic meta-learning to high-resource sentence functions data.  Furthermore, SML enhances meta-learning effectiveness by promoting knowledge customization among different sentence functions but simultaneously preserving knowledge generalization for similar sentence functions.  Experimental results demonstrate that SML not only improves the informativeness and relevance of generated responses, but also can generate responses consistent with the target sentence functions."
"As mentioned Chapter , models trained simply obtain high accuracy held-out sets often learn rely shallow input statistics, resulting brittle models. % susceptible adversarial attacks. For example, \citet{lime} present document classifier distinguishes Christianity Atheism test accuracy . However, close inspection, model spuriously separates classes based words contained headers, ``Posting'', ``Host'', ``Re''. Spurious correlations training test sets allow undesired models obtain high accuracies. Much complex hidden correlations may present arbitrarily large human-annotated dataset . Such correlations may difficult spot, even one identifies them, open question mitigate . In chapter, I investigate direction potential steer neural models away relying spurious correlations provide explanations predictions models. This direction enhancing neural models capability learn natural language explanations training time generate explanations test time. For humans, shown explanations play key role structuring conceptual representations categorisation generalisation . Humans also benefit tremendously reading explanations acting environment first time . Thus, explanations may also used set model better initial position learn correct functionality. Meanwhile, test time, generating correct argumentation addition obtaining high accuracy potential endow model higher level transparency trust. %In work, introduce new dataset models exploiting generating explanations task recognizing textual entailment. Incorporating external knowledge neural model shown result robust models . % show models achieving high accuracies SNLI, , show dramatically reduced performance simpler dataset, model \citet{kim} robust due incorporating external knowledge. Free-form natural language explanations form external knowledge following advantages formal language. First, easy humans provide free-form language, eliminating additional effort learning produce formal language, thus making simpler collect datasets. Secondly, natural language explanations might potentially mined existing large-scale free-form text. Finally, natural language readily comprehensible end-user needs assert reliability model. %Thirdly, formal languages chosen researchers may differ work work therefore models constructed one formal language might trivially transferred another. Meanwhile free-form explanations generic applicable diverse areas research, natural language processing, computer vision, policy learning. Despite potential natural language explanations improve learning transparency, scarcity datasets community, discussed Section . To address deficiency, I collected large corpus K human-annotated explanations SNLI dataset~. I chose SNLI constitutes influential corpus natural language understanding requires deep assimilation fine-grained nuances commonsense knowledge. %A plethora models developed dataset, including previous state-of-the-art universal sentence representations , demonstrates power task dataset. I call explanation-augmented dataset e-SNLI, I release publicly\footnote{The dataset found \url{https://github.com/OanaMariaCamburu/e-SNLI}.} advance research direction training generation free-form natural language explanations. %To demonstrate efficacy e-SNLI dataset, %I show much difficult neural models produce correct natural language explanations based spurious correlations produce correct labels. Further, I develop models predict label generate explanation prediction. I also investigate presence natural language explanations training time guide neural models learning better universal sentence representations better capabilities solve out-of-domain instances. Secondly, I show much difficult neural model produce correct natural language explanations based spurious correlations produce correct labels based correlations. Thirdly, I develop models predict label generate explanation prediction, I investigate correctness generated explanations. Finally, I investigate whether training neural model natural language explanations result better universal sentence representations produced model better performance out-of-domain datasets. \paragraph{Remark.} In chapter, I use concept correct explanation refer correct argumentation ground-truth label instance. This confused concept faithful explanation, refers accuracy explanation describes decision-making process model, described Section . The capability neural model generate correct explanations important aspect development models. For example, correct argumentation may sometimes needed practice, alongside correct final answer. Hence, chapter, I inspect correctness explanations generated introduced neural models. In next chapter, I take step towards verifying faithfulness explanations.% given Chapter .","  Deep neural networks are becoming more and more popular due to their revolutionary success in diverse areas, such as computer vision, natural language processing, and speech recognition. However, the decision-making processes of these models are generally not interpretable to users. In various domains, such as healthcare, finance, or law, it is critical to know the reasons behind a decision made by an artificial intelligence system. Therefore, several directions for explaining neural models have recently been explored.   In this thesis, I investigate two major directions for explaining deep neural networks. The first direction consists of feature-based post-hoc explanatory methods, that is, methods that aim to explain an already trained and fixed model , and that provide explanations in terms of input features, such as tokens for text and superpixels for images . The second direction consists of self-explanatory neural models that generate natural language explanations, that is, models that have a built-in module that generates explanations for the predictions of the model. The contributions in these directions are as follows.   % In this thesis, I investigate the topic of explaining deep neural networks. This topic is crucial nowadays as neural model are becoming more and more employed in real-world applications due to their high performance in diverse areas, such as computer vision, natural language processing, and speech recognition. However, the decision-making processes learned by these models are not generally human-interpretable. In various real-world applications, such as healthcare, finance, or criminal justice, it is critical to know the reasons behind a decision made by an artificial intelligence system. Therefore, several directions for explaining neural models have recently been explored.   % a series of methods have recently been developed to provide explanations for the predictions of neural models. This thesis brings contributions to two major directions for explaining deep neural networks: feature-based post-hoc explanatory methods and self-explanatory neural models that generate natural language explanations for their predictions. The contributions are as follows.   %However, it is still an open question how to verify whether the explanations provided by these methods are faithfully describing the decision-making processes of the models that they aim to explain. Secondly, it is also an open question whether neural networks can learn from human-provided natural language explanations for the ground-truth labels at training time, as well as support their predictions with natural language explanations at test time, just like humans do.    First, I reveal certain difficulties of explaining even trivial models using only input features. I show that, despite the apparent implicit assumption that explanatory methods should look for one specific ground-truth feature-based explanation, there is often more than one such explanation for a prediction. I also show that two prevalent classes of explanatory methods target different types of ground-truth explanations without explicitly mentioning it. Moreover, I show that, sometimes, neither of these explanations is enough to provide a complete view of a decision-making process on an instance. %These findings can have an important impact on how users choose explanatory methods to best suit their needs.    Second, I introduce a framework for automatically verifying the faithfulness with which feature-based post-hoc explanatory methods describe the decision-making processes of the models that they aim to explain. This framework relies on the use of a particular type of model that is expected to provide insight into its decision-making process. I analyse potential limitations of this approach and introduce ways to alleviate them.  % The introduced verification framework is generic and can be instantiated on different tasks and domains to provide off-the-shelf sanity tests that can be used to test feature-based post-hoc explanatory methods. I instantiate this framework on a task of sentiment analysis and provide sanity tests\footnote{The sanity tests are available at \\ \url{https://github.com/OanaMariaCamburu/CanITrustTheExplainer}.} %to test any feature-based post-hoc explanatory method. Furthermore,  on which I present the performances of three popular explanatory methods. %The results show that these methods may provide unfaithful explanations.  %I also discuss ways in which the current limitations of the framework can further be addressed to lead to more robust and flexible verifications.    %In the process of developing this framework, I uncover several ways in which a particular type of model that is expected to provide insight into its decision-making process can provide misleading such insight. I also introduce checks that can be done to account for this misleading insight in order to use this type of model in the proposed framework.  % %%%%%%%% BEFORE %%%%%%%%%%The framework is generic and can be instantiated on different tasks and domains. I instantiate it on a task of sentiment analysis and provide sanity tests that can be used off-the-shelf\footnote{The tests are available at \url{https://github.com/OanaMariaCamburu/CanITrustTheExplainer}.} to test any feature-based post-hoc explanatory method. Furthermore, I present preliminary results of three explanatory methods on these tests, which raise awareness of the unfaithful explanations that these methods may provide. %I discuss ways in which the limitations of this verification framework can further be addressed and open the path towards more robust and flexible verification frameworks that can be adapted to users' needs.  %%%% this framework relies on the use of a particular type of model that is expected to provide insight into its decision-making process. I analyse the potential limitations of this approach and introduce ways to overcome them. By constructions   %In addition, as a step towards addressing the question of verifying if explanatory methods faithfully describe the decision-making processes learned by the models they aim to explain, I investigate a particular type of self-explanatory neural model and I show three ways in which this type of model can provide misleading explanations. % on its decision-making process.    %Secondly, I present a novel verification framework that can generate a multitude of sanity tests for explanatory methods. I instantiate this framework on the task of sentiment analysis and provide three sanity tests, which can be used off-the-shelf.\footnote{The tests are available at \url{https://github.com/OanaMariaCamburu/CanITrustTheExplainer}.} I present the results of three explanatory methods on these tests. I discuss ways in which the limitations of this verification framework can further be addressed and open the path towards more robust and flexible verification frameworks that can be adapted to users' needs.  % improve their behaviour and performance %exhibit improved behaviour  % if they are additionally given natural language explanations for the ground-truth label at training time  Third, to explore the direction of self-explanatory neural models that generate natural language explanations for their predictions, I collected a large dataset of $\sim\!\!570$K human-written natural language explanations on top of the influential Stanford Natural Language Inference  dataset. I call this explanation-augmented dataset e-SNLI.\footnote{The dataset is publicly available at \url{https://github.com/OanaMariaCamburu/e-SNLI}.} %, which I release publicly\footnote{The dataset is available at \url{https://github.com/OanaMariaCamburu/e-SNLI}.} %to advance research in the direction of training with and generation of natural language explanations.  % Further, I provide empirical evidence that models generating correct explanations are more reliable than models that just predict the correct labels.  % I also train different neural models that generate natural language explanations at test time, and I measure the success of these models to generate correct explanations. I also investigate whether the presence of natural language explanations at training time can lead a model to produce better universal sentence representations and to perform better on out-of-domain datasets. I do a series of experiments that investigate both the capabilities of neural models to generate correct natural language explanations at test time, and the benefits of providing natural language explanations at training time.  Fourth, I show that current self-explanatory models that generate natural language explanations for their own predictions may generate inconsistent explanations, such as ``There is a dog in the image.'' and ``There is no dog in the [same] image.''. Inconsistent explanations reveal either that the explanations are not faithfully describing the decision-making process of the model or that the model learned a flawed decision-making process.  I introduce a simple yet effective adversarial framework for sanity checking models against the generation of inconsistent natural language explanations. Moreover, as part of the framework, I address the problem of adversarial attacks with exact target sequences, a scenario that was not previously addressed in sequence-to-sequence attacks, and which can be useful for other tasks in natural language processing. I apply the framework on a state of the art neural model on e-SNLI and show that this model can generate a significant number of inconsistencies.  This work paves the way for obtaining more robust neural models accompanied by faithful explanations for their predictions.  %My hope is that in the future feature-based post-hoc explanatory methods will be superseded  by robust and accurate neural models that faithfully explain themselves to their human users in natural language."
"Aspect-based sentiment analysis , also termed Target-based Sentiment Analysis literature, fine-grained sentiment analysis task. It usually formulated detecting aspect terms sentiments expressed sentence towards aspects. This type formulation referred aspect-sentiment pair extraction. Meanwhile, exists another type approach ABSA, referred aspect-opinion co-extraction, focuses jointly deriving aspect terms opinion terms sentences, yet without figuring sentiment dependencies. The compelling performances directions illustrate strong dependency aspect terms, opinion terms expressed sentiments. This motivates us put forward new perspective ABSA joint extraction aspect terms, opinion terms sentiment polarities,\footnote{For simplicity, four concepts hereafter referred aspect, opinion, sentiment, triplet, respectively.} short opinion triplet extraction. An illustrative example differences among aspect-sentiment pair extraction, aspect-opinion co-extraction, opinion triplet extraction given Figure. Opinion triplet extraction viewed integration aspect-sentiment pair extraction aspect-opinion co-extraction, taking consideration complementary nature. It brings two-fold advantages: opinions boost expressive power models help better determine aspect-oriented sentiments; sentiment dependencies aspects opinions bridge gap sentiment decisions made promote interpretability models. There prior research similar viewpoint. proposes extract opinion tuples, i.e., s,\footnote{To extent, opinion triplet extraction aims solving task regardless minor difference.} first jointly extracting aspect-sentiment pairs opinions two sequence taggers, sentiments attached aspects via unified tags,\footnote{An aspect tag set \{, , \} sentiment tag set \{, , \} unified aspect-sentiment tag set \{, , , , , , \}. Here, , , indicate begin, inside, outside span. And , , neutral, negative, positive.} pairing extracted aspect-sentiments opinions additional classifier. Despite remarkable performance approach achieved, two issues need addressed. The first issue arises prediction aspects sentiments set unified tags thus degrading sentiment dependency parsing process binary classification. As discussed prior studies aspect-sentiment pair extraction, although concerned framework unified tagging scheme theoretically elegant mitigates computational cost, insufficient model interaction aspects sentiments. Secondly, coupled aspect-sentiment formalization disregards importance interaction opinions. Such interaction shown important handle overlapping circumstances different triplet patterns share certain elements, triplet extraction-based tasks relation extraction. To show triplet interaction modelling crucial, divide triplets three categories, i.e., aspect overlapped, opinion overlapped, normal ones. Examples three kinds triplets shown Figure. We observe two triplets tend sentiment share aspect opinion. Hence, modelling triplet interaction shall benefit ASBA task, yet explored unified aspect-sentiment tags sentiments attached aspects without considering overlapping cases. To circumvent issues, propose multi-task learning framework opinion triplet extraction, namely OTE-MTL, jointly detect aspects, opinions, sentiment dependencies. On one hand, aspects opinions extracted two independent heads multi-head architecture propose. On hand, decouple sentiment prediction aspect extraction. Instead, employ sentiment dependency parser third head, predict word-level sentiment dependencies, utilized decode span-level\footnote{The aspects opinions usually spans several words sentence} dependencies incorporated detected aspects opinions. In so, expect alleviate issues brought unified tagging scheme. Specifically, exploit sequence tagging strategies extraction aspects opinions, whilst taking advantage biaffine scorer obtain word-level sentiment dependencies. Additionally, since task-heads jointly trained, learning objectives aspect opinion extraction could considered regularization applied sentiment dependency parser. In way, parser learned aspect- opinion-aware constraints, therefore fulfilling demand triplet interaction modelling. Intuitively, provided sentence containing two aspects one opinion , identify triplets overlapped opinion thereby. Extensive experiments carried four SemEval benckmarking data collections ABSA. Our framework compared range state-of-the-art approaches. The results demonstrate effectiveness overall framework individual components within it. A case study shows model better handles overlapping cases."," The state-of-the-art Aspect-based Sentiment Analysis  approaches are mainly based on either detecting aspect terms and their corresponding sentiment polarities, or co-extracting aspect and opinion terms. However, the extraction of aspect-sentiment pairs lacks opinion terms as a reference, while co-extraction of aspect and opinion terms would not lead to meaningful pairs without determining their sentiment dependencies. To address the issue, we present a novel view of ABSA as an opinion triplet extraction task, and propose a multi-task learning framework to jointly extract aspect terms and opinion terms, and simultaneously parses sentiment dependencies between them with a biaffine scorer. At inference phase, the extraction of triplets is facilitated by a triplet decoding method based on the above outputs. We evaluate the proposed framework on four SemEval benchmarks for ASBA. The results demonstrate that our approach significantly outperforms a range of strong baselines and state-of-the-art approaches.\footnote{Code and datasets for reproduction are available at \href{https://github.com/GeneZC/OTE-MTL}{\texttt{https://github.com/GeneZC/OTE-MTL}}.}"
"We use sequence vectors represent sentence, vector consists semantic-role tag, part-of-speech tag, syntactic semantic tags, refer sequence \textsl{meta sequence}. We present application using meta-sequence learning generate, given article, adequate QAPs form multiple-choice questions. In particular, develop scheme called MetaQA learn meta sequences declarative sentences corresponding interrogative sentences training dataset. % consisting sentences. Combining removing redundant meta sequences yields set called MSDIP , element pair MD corresponding MI, MD MI stand for, respectively, meta sequence declarative sentence interrogative sentence. A trained MetaQA model generates QAPs given declarative sentence follows: Generate meta sequence , find best-matched MD MSDIP, generates meta sequences interrogative sentences according corresponding MIs meta sequence , identifies meta-sequence answer MI, coverts back text form QAP. \begin{comment}"," %Creating multiple-choice questions to assess reading comprehension of a given article %involves generating question-answer pairs  on the main points of the document. We present a meta-sequence representation of sentences and demonstrate how to use meta-sequence learning to generate adequate question-answer pairs  over a given article. %learning scheme to generate adequate QAPs  %via meta-sequence representations of sentences.   %without handcrafted features.  A meta sequence is a sequence of vectors of semantic and syntactic tags. %In particular, %we devise a scheme called MetaQA to %learn meta sequences from training data to form  %pairs of a meta sequence for a declarative sentence   %and a corresponding  interrogative sentences . % indexed for fast retrieval,  On a given declarative sentence, a trained model  converts it to a meta sequence,  finds a matched meta sequence in its learned database,  and   uses the corresponding meta sequence for interrogative sentence to generate QAPs. %We implement MetaQA for the English language using  %semantic-role labeling,  %part-of-speech tagging, and  named-entity recognition, We show that, trained on a small dataset,  our method generates efficiently, on the official SAT practice reading tests, a large number of syntactically and semantically correct QAPs with high accuracy."
"In recent years, revolution machine learning-based program synthesis techniques automatically generating programs high-level expressions user intent, input-output examples~ natural language~. Many techniques use deep neural networks consume specifications perform model-guided search find program %---often domain-specific language--- satisfies user. However, %both natural language input examples user's specification inherently ambiguous~, recent thread work multimodal synthesis attempts combine different types cues, natural language examples, allow program synthesis effectively scale complex problems. Critically, setting introduces new challenge: efficiently synthesize programs combination hard soft constraints distinct sources? In paper, formulate multimodal synthesis optimal synthesis task propose optimal synthesis algorithm solve it. % In paper, cast multimodal synthesis type optimal synthesis problem goal The goal optimal synthesis generate program satisfies hard constraints provided user also maximizing score learned neural network model captures noisy information, like natural language. % This problem, refer optimal neural synthesis, important In practice, many programs satisfy hard constraints, maximization crucial finding program actually meets user's expectations: neural model well-calibrated, program maximizes score neural model likely user's intended program. % The key technical contribution paper new optimal neural synthesis algorithm contexts user guidance includes combination natural language examples. Our optimal neural synthesis algorithm takes input multimodal user guidance. In setting, train neural model take natural language input used guide search program consistent user-provided examples. Because search procedure enumerates programs according score, first enumerated program satisfying examples guaranteed optimal according model. A central feature approach use tree-structured neural model, namely abstract syntax network ~, constructing syntactically valid programs top-down manner. The structure ASN model restricts search programs syntactically correct, thereby avoiding need deal program syntax errors~, allows us search programs flexible way, without constraining left-to-right generation order like seq2seq models do. More importantly, use top-down search allows us effectively leverage automated program analysis techniques proving infeasibility partial ASTs. As result, synthesizer prune search space aggressively prior work significantly speed search. While network structure pruning techique adapted prior work, combine generalize optimal neural synthesis setting new way, show general approach leads substantial improvements previous synthesis approaches. We implement method synthesizer called \toolname%\footnote{MultIModal Optimal Synthesis Asn} evaluate challenging {\sc StructuredRegex} dataset~ synthesizing regular expressions linguistically diverse natural language descriptions positive/negative examples. We compare approach range approaches prior work ablations method. \toolname\ achieves substantial gain past work solving 59.8\% programs Test set \streg{} exploring average 560 states, surpasses previous state-of-the-art 11.7\% fewer states. %"," Multimodal program synthesis, which leverages different types of user input to synthesize a desired program, is an attractive way to scale program synthesis to challenging settings; however, it requires integrating noisy signals from the user  with hard constraints on the program's behavior. This paper proposes an optimal neural synthesis approach where the goal is to find a program that satisfies user-provided constraints while also maximizing the program's score with respect to a neural model. Specifically, we focus on multimodal synthesis tasks in which the user intent is expressed using combination of natural language  and input-output examples. At the core of our method is a top-down recurrent neural model that places distributions over abstract syntax trees conditioned on the NL input. This model not only allows for efficient search over the space of syntactically valid programs, but it allows us to leverage automated program analysis techniques for pruning the search space based on infeasibility of partial programs with respect to the user's constraints. The experimental results on a multimodal synthesis dataset  show that our method substantially outperforms prior state-of-the-art techniques in terms of accuracy %, finds model-optimal programs more frequently, and explores fewer states during search."
"The desire human-like interfaces technical systems, evidenced growing use intelligent assistants, belies need conversational AI systems accomplish wide range tasks, booking restaurants, trains, flights, IT help desk accessing financial accounts transaction records. The wide range tasks necessitated need flexible scalable dialogue system support variety use cases minimal development maintenance effort. Existing dialogue systems broken two major categories, open-domain dialogue systems, focus non-task related conversations, task-oriented dialogue systems, focus user task completion. A typical open-domain system uses end-to-end neural architecture often trained input output utterances human-to-human conversations . While open-domain systems optimized engaging human-like conversation, lack inherent ability interface systems behalf conversation partner. Whereas, typical task-oriented dialogue system seeks understand human intents execute them. This done adopting modularized pipeline architecture three modules sequentially connected shown Fig. . A natural language understanding module recognizes user intents extract useful entity information . The dialogue management module contains two submodules, dialogue state tracker dialogue action policy modules. The DST module tracks mapping entities slots relevant required completing user tasks . The POL module decides actions execute via API. Finally, natural language generation module generates user response based user aspects system actions . In cases, multiple modules combined together, e.g. systems composite NLU DST module , systems composite POL NLG module maps previous utterances dialogue states system response . Despite research advances modular neural approaches, hardly used practice. Industrial dialogue systems, though modularized, still use expensive expert driven rule-based heuristics implemented several lines codes hand-crafted templates, therefore difficult scale number use cases grows. More recently, renewed effort apply single end-to-end neural architecture model task-oriented dialogue use autoregressive transformer architecture . This led reformulation dialogue system design text generation sequence modeling task. While efforts obtained state-of-the-art performance publicly available task-oriented dialogue datasets, still room improvement, especially areas generality practicality. First, problem formulation fails reconcile open-domain task-oriented dialogue model architecture. Also, many cases, address complexity action policy especially towards back-end API system. Finally, fully incorporate control, verification explanation capabilities make modularized approaches attractive. To resolve shortcomings, propose DLGNet-Task, end-to-end neural network simultaneously handles open-domain task-oriented dialogue, way model outputs controllable, verifiable, explainable module level. This system compatible data driven expert driven rule-based approaches. That is, approach simultaneously modular end-to-end, drop-in replacement traditional modular task-oriented dialogue systems. To best knowledge, expressive approach date achieving objective. In summary, able model individual behavior NLU, DM NLG components single neural network model trained end-to-end. Still, model flexible enough allow individual modules separately trained validated line traditional TOD system. % Validation module level provide information additional training needed. It could also help balancing contribution module model finetuned module-level objectives. % The DLGNet-Task model based autoregressive transformer architecture similar DLGNet GPT-2/3 models. To evaluate performance DLGNet-Task, trained model system-level training objective modified MultiWoz2.1 dataset. The dataset modification done mainly support DLGNet-Task design framework . Based widely used TOD metrics, inform rate, success rate, BLEU score , experiments show DLGNet-Task produces comparable performance state-of-the-art approaches MultiWoz2.1 dataset. % addition controllable, verifiable, explainable model's intermediate outputs."," Task oriented dialogue  requires the complex interleaving of a number of individually controllable components with strong guarantees for explainability and verifiability. This has made it difficult to adopt the multi-turn multi-domain dialogue generation capabilities of streamlined end-to-end open-domain dialogue systems. In this paper, we present a new framework, DLGNet-Task, a unified task-oriented dialogue system which employs autoregressive transformer networks such as DLGNet and GPT-2/3 to complete user tasks in multi-turn multi-domain conversations. Our framework enjoys the controllable, verifiable, and explainable outputs of modular approaches, and the low development, deployment and maintenance cost of end-to-end systems. Treating open-domain system components as additional TOD system modules allows DLGNet-Task to learn the joint distribution of the inputs and outputs of all the functional blocks of existing modular approaches such as, natural language understanding , state tracking, action policy, as well as natural language generation . Rather than training the modules individually, as is common in real-world systems, we trained them jointly  with appropriate module separations. When evaluated on the MultiWOZ2.1 dataset, DLGNet-Task shows comparable performance to the existing state-of-the-art approaches. Furthermore, using DLGNet-Task in conversational AI systems reduces the level of effort required for developing, deploying, and maintaining intelligent assistants at scale.  % significant improvement over existing approaches, and achieves state-of-the-art performance at both the module and system levels."
"Knowledge graphs represent knowledge world relationships entities, i.e., triples form . Such knowledge resource provides clean structured evidence many downstream applications question answering. KGs usually constructed human experts, time-consuming leads highly incomplete graphs . Therefore automatic KG completion proposed infer missing link relationship head entity tail entity . Existing KG completion work mainly makes use two types information: 1) co-occurrence entities relations 2) deducible reasoning paths tuples. KG embeddings encode entities relations, first type information, together continuous vector space low-rank tensor approximations~. Ours approach utilizes second type information, reasoning path tuples deduced target tuple~. Here reasoning path starts head entity ends tail entity \e{t}: \e{h \overset{r_1}{\rightarrow} e_1 \overset{r_k}{\rightarrow} e_k \overset{r_N}{\rightarrow} t}, \e{r_1 \wedge ... \wedge r_N} forms relation chain infers existence . Therefore methods also referred multi-hop reasoning KGs, learns multi-hop chain rule deduce target . An example chain given Figurea infer whether athlete plays location. Multi-hop reasoning approaches usually utilize richer evidence self-justifiable terms reasoning path rules used predictions, making prediction missing relations interpretable. Despite advantages success multi-hop reasoning approach , target relationship may perfectly inferred single relation chain. There could exist multiple weak relation chains correlate target relation. Figure gives examples cases. These multiple chains could leveraged following ways: reasoning process naturally relies logic conjunction multiple chains ; commonly, instances none chains accurate, aggregating multiple pieces evidence improves confidence , also observed case-based study works. Inspired observations, propose concept multi-chain multi-hop rule set. Here, instead treating single multi-hop chain rule, learn rules consisting small set multi-hop chains. Therefore inference target relationships becomes joint scoring set chains. {We treat set chains one rule and, since different query pairs follow different rules, together set rules reason relation.} Learning generalized multi-hop rule set combinatorial search problem. We address challenge game-theoretic approach inspired by. Our approach consists two steps: selecting generalized multi-hop rule set employing Multi-Layer Perceptron candidate chains; reasoning generalized rule set, uses another MLP model conditional probability target relationship given selected relation chains. The nonlinearity MLP reasoner provides potential model logic conjunction among selected chains rule set. We demonstrate advantage method KG completion tasks FB15K-237 NELL-995. Our method outperforms existing single-chain approaches, showing defined generalized rules necessary many reasoning tasks."," Multi-hop reasoning approaches over knowledge graphs infer a missing relationship between entities with a multi-hop rule, which corresponds to a chain of relationships. We extend existing works to consider a generalized form of multi-hop rules, where each rule is a set of relation chains.  To learn such generalized rules efficiently, we propose a two-step approach that first selects a small set of relation chains as a rule and then evaluates the confidence of the target relationship by jointly scoring the selected chains. A game-theoretical framework is proposed to this end to simultaneously optimize the rule selection and prediction steps. Empirical results show that our multi-chain multi-hop  rules result in superior results compared to the standard single-chain approaches, justifying both our formulation  of  generalized rules  and the effectiveness of the proposed learning framework."
"Generating text conforms syntactic semantic constraints benefits many NLP applications. To name few, paired data limited, \citet{yang-etal-2019-low} build templates large-scale unpaired data aid training dialog generation model; \citet{Niu2017ASO} \citet{liu-etal-2019-rhetorically} apply style constraints adjust formality rhetoric utterances; \citet{iyyer2018adversarial} \citet{li-etal-2019-Insufficient} augment dataset using controlled generation improve model performance. We study problem syntactically controlled text generation, aims generate target text pre-defined syntactic guidance. Most recent studies topic use sentences exemplars specify syntactic guidance. However, guidance specified sentence vague, syntactic semantic factors tangled. Different them, use constituency parse trees explicit syntactic constraints. As providing full-fledged parse trees target text impractical, require template parse tree sketches top levels full tree . Figure shows pipeline. \citet{iyyer2018adversarial} adopt setting ours. Their proposed SCPN model uses two LSTM encoders respectively encode source text parse tree, connects one decoder additional attention pointer structures. Nonetheless, recurrent encoders suffer information loss compressing whole sequence one vector also incapable properly modeling tree structure constituency parse well. Consequently, network tends ``translate'' parse tree, instead learning real syntactic structures it. % \zc{this sentence still unclear.} We propose Transformer-based syntax-guided text generation method, named \ours. It first expands template constituency parse tree full-fledged parse tree tailored input source text, uses full tree guide text generation. To capture tree structure syntax, apply path attention mechanism text generation model. It forces one node attend nodes located path instead nodes tree. Such mechanism limits information flow among nodes constituency tree direct ancestor-descendant relationship, forcing parent nodes carry information children. In cooperation path attention, linearize constituency trees compact node-level format . Moreover, address challenge properly integrating semantic syntactic information, design multi-encoder attention mechanism . It enables Transformer decoder accept outputs multiple encoders simultaneously. We evaluated model controlled paraphrasing task. The experiment results show \ours outperforms state-of-the-art SCPN method syntactic quality semantic quality. % \zc{ use absolute improvements instead relative ones} Human evaluations prove method generates semantically syntactically superior sentences, semantic syntactic score improvements. % \zc{also give concrete numbers here, much improvements?} Further, find multi-encoder attention mechanism enhances Transformer's ability deal multiple inputs, path attention mechanism significantly contributes model's semantic performance . Our contributions include: 1) multi-encoder attention mechanism allows Transformer decoder attend multiple encoders; 2) path attention mechanism designed better incorporate tree-structured syntax guidance special tree linearization format; 3) syntax-guided text generation method \ours achieves new state-of-the-art semantic syntactic performance.","   We study the problem of using  constituency parse trees as syntactic guidance for controlled text generation. Existing approaches to this problem use recurrent structures, which not only suffer from the long-term dependency problem but also falls short in modeling the tree structure of the syntactic guidance. We propose to leverage the parallelism of Transformer to better incorporate parse trees. Our method first expands a partial template constituency parse tree to a full-fledged parse tree tailored for the input source text, and then uses the expanded tree to guide text generation. The effectiveness of our model in this process hinges upon two new attention mechanisms: 1) a path attention mechanism that forces one node to attend to only other nodes located in its path in the syntax tree to better incorporate syntax guidance; 2) a multi-encoder attention mechanism that allows the decoder to dynamically attend to information from multiple encoders. Our experiments in the controlled paraphrasing task show that our method outperforms SOTA models both semantically and syntactically, improving the best baseline's BLEU score from $11.83$ to $26.27$."
"Recently, great success automatic text summarization generation. To better compare improve performance models, evaluation systems problem interest. The selection evaluation metrics greatly affect assessed quality generated summary thus affect evaluation summarization models. The ideal metric definitely human judgement, often treated gold standard. But human evaluation time-consuming labor-intensive, automatic evaluation metric cannot save human resources also simulate ability human judgement crucial importance. Most existing automatic evaluation methods assess summary comparing reference texts written humans. Some model-free simply use hand-crafted matching functions calculate similarity candidate summary reference . These methods consider reference candidate sequence tokens n-gram blocks. For instance, de facto standard evaluation metric, ROUGE calculates n-gram overlap machine-generated summaries reference summaries. Although methods advantage interpretability efficiency, found correlate poorly human evaluation. To reduce requirement exact word matching, recent work tried match reference candidate summary embedding space words sentences . For instance, BERTScore uses contextual word embeddings generated BERT performs greedy matching obtain maximum cosine similarity two texts. %\citeauthor{clarketal2019sentence} designed metric combines sentence-level embeddings word mover閳ユ獨 distance calculate distance moving candidate sequence reference transforms distance similarity score, MoverScore combines n-gram embeddings WMD. These methods proved correlate better human judgement ROUGE many datasets, demonstrates effectiveness using contextual embeddings. } , three dimensions focus evaluating linguistic quality summaries.} \end{table*} However, aforementioned methods intrinsic drawbacks: methods always need least one human-generated reference assess candidate summary. References written humans costly obtain. In addition, consider semantic similarities references, i.e. semantic qualities summaries, ignores linguistic qualities important aspects. In paper, propose new unsupervised contrastive learning framework automatically evaluating summary qualities without comparing reference summaries training human ratings. Specifically, design evaluator consider linguistic semantic aspects summary. Then aspect create set negative samples perturbing training samples. We compare scores original training samples negative samples obtain contrastive loss function learn evaluator. The experiments Newsroom CNN/Daily Mail demonstrate new evaluation method much higher correlation human judgement. We summarize contributions follows:"," Evaluation of a document summarization system has been a critical factor to impact the success of the summarization task. Previous approaches, such as ROUGE, mainly consider the informativeness of the assessed summary and require human-generated references for each test summary. In this work, we propose to evaluate the summary qualities without reference summaries by unsupervised contrastive learning. Specifically, we design a new metric which covers both linguistic qualities and semantic informativeness based on BERT. To learn the metric, for each summary, we construct different types of negative samples with respect to different aspects of the summary qualities, and train our model with a ranking loss. Experiments on Newsroom and CNN/Daily Mail demonstrate that our new evaluation method outperforms other metrics even without reference summaries. Furthermore, we show that our method is general and transferable across datasets."
"Part-of-speech tags dependency parsing formed long-standing union NLP. But equally long-standing question efficacy. % union. %POS tags features parsers. \carlos{Prior prevalence deep learning NLP, shown useful syntactic disambiguation certain contexts} %Certainly nigh-on forgotten pre-deep learning era NLP, seemed useful syntactic disambiguation certain contexts . However, neural network implementations, especially utilise character embeddings, POS tags shown much less useful . Others found POS tags still positive impact using character representations given accuracy predicted POS tags used sufficiently high . \citet{smith2018investigation} undertook systematic study impact features Universal Dependency parsing found using universal POS tags still offer marginal improvement transition-based neural parser. The use fine-grained POS tags still seems garner noticeable improvements %even challenging multi-lingual settings . %By far away common use Latterly, POS tags commonly utilised implicitly neural network parsers multi-learning frameworks leveraged without cost error-propagation . Beyond multi-learning systems, \citet{strzyz2019viable} introduced dependency parsing sequence labelling encoding dependencies using relative positions UPOS tags, thus explicitly requiring runtime. %So even coarse POS tags, universal otherwise, prove superfluous graph- transition-based neural parsers direct features, still many uses them.% dependency parsing. We follow work \citet{smith2018investigation} evaluate interplay word embeddings, character embeddings, POS tags features two modern parsers, one graph-based parser, Biaffine, transition-based parser, UUParser . Similar \citet{zhang2020pos}, focus contribution POS tags evaluate UPOS tags. \paragraph{Contribution} We analyse effect UPOS accuracy two dependency parser systems number UD treebanks. Our results suggest order leverage UPOS tags explicit features neural parsers, prohibitively high tagging accuracy needed, gold tag annotation seems possess exceptionality. We also investigate aspects predicted UPOS tags impact parsing accuracy."," We present an analysis %contributing to the discussion  on the effect UPOS accuracy has on parsing performance. Results suggest that leveraging UPOS tags as features for neural parsers requires a prohibitively high tagging accuracy and that the use of gold tags offers a non-linear increase in performance, suggesting some sort of exceptionality. We also investigate what aspects of predicted UPOS tags impact parsing accuracy the most, highlighting some potentially meaningful linguistic facets of the problem."
"Conversational Machine Reading challenging rule text may contain literal answer, provide procedure derive interactions . In case, machine needs read rule text, interpret user scenario, clarify unknown user's background asking questions, derive final answer. Taking Figure example, answer user whether suitable loan program, machine needs interpret rule text know requirements, understand meets ``American small business'' user scenario, ask follow-up clarification questions ``for-profit business'' ``not get financing resources'', finally concludes answer ``Yes'' user's initial question. Existing approaches decompose problem two sub-tasks. Given rule text, user question, user scenario, dialog history , first sub-task make decision among ``Yes'', ``No'', ``Inquire'' ``Irrelevant''. The ``Yes/No'' directly answers user question ``Irrelevant'' means user question unanswerable rule text. If user-provided information enough determine fulfillment eligibility, ``Inquire'' decision made second sub-task activated. The second sub-task capture underspecified condition rule text generate follow-up question clarify it. \citet{zhong-zettlemoyer-2019-e3} adopt BERT reason decision, propose entailment-driven extracting editing framework extract span rule text edit follow-up question. The current \sota model EMT uses Recurrent Entity Network explicit memory track fulfillment rules dialog turn decision making question generation. In problem, document interpretation requires identification conditions determination logical structures rules appear format bullet points, in-line conditions, conjunctions, disjunctions, etc. Hence, correctly interpreting rules first step towards decision making. Another challenge dialog understanding. The model needs evaluate user's fulfillment conditions, jointly consider fulfillment states logical structure rules decision making. For example, disjunctions conjunctions conditions completely different requirements user's fulfillment states. However, existing methods considered condition-level understanding reasoning. In work, propose \modelnameshortnsp: \modelnamecap. To better understand logical structure rule text extract conditions it, first segment rule text clause-like elementary discourse units using pre-trained discourse segmentation model. Each EDU treated condition rule text, model estimates entailment confidence scores three states: Entailment, Contradiction Neutral reading user scenario description existing dialog. Then map scores entailment vector condition, reason decision based entailment vectors logical structure rules. Compared previous methods little entailment reasoning use multi-task learning , \modelnameshort first method explicitly build dependency entailment states decisions dialog turn. \modelnameshort achieves new \sota results blind, held test set ShARC. In particular, \modelnameshort outperforms previous best model EMT 3.8\% micro-averaged decision accuracy 3.5\% macro-averaged decision accuracy. Specifically, \modelnameshort performs well simple in-line conditions conjunctions rules still needing improvements understanding disjunctions. Finally, conduct comprehensive analyses unveil limitation \modelnameshort current challenges ShARC benchmark. We find one biggest bottlenecks user scenario interpretation, various types reasoning required. % Code models released facilitate research along line.","  Document interpretation and dialog understanding are the two major challenges for conversational machine reading. In this work, we propose \modelnameshortnsp, a discourse-aware entailment reasoning network to strengthen the connection and enhance the understanding for both document and dialog. Specifically, we split the document into clause-like elementary discourse units  using a pre-trained discourse segmentation model, and we train our model in a weakly-supervised manner to predict whether each EDU is entailed by the user feedback in a conversation. Based on the learned EDU and entailment representations, we either reply to the user our final decision ``yes/no/irrelevant"" of the initial question, or generate a follow-up question to inquiry more information. Our experiments on the ShARC benchmark  show that \modelnameshort achieves \sota results of 78.3\% macro-averaged accuracy on decision making and 64.0 BLEU1 on follow-up question generation. Code and models are released at \url{https://github.com/Yifan-Gao/Discern}."
". % % % final paper: en-us version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. } Neural Language Models become central component NLP systems last years, showing outstanding performance improving state-of-the-art many tasks . However, introduction systems come cost interpretability %and explainability and, consequently, cost obtaining meaningful explanations automated decisions take place. % and, specifically, understanding linguistic predictors - common features earlier systems - encoded models. Recent work begun study models order understand whether encode %are able learn linguistic phenomena even without explicitly designed %forse meglio trained? learn properties . Much work focused analysis interpretation attention mechanisms definition probing models trained predict simple linguistic properties unsupervised representations. Probing models trained different contextual representations provided evidences models able capture wide range linguistic phenomena even organize information hierarchical manner . However, way knowledge affects decisions make solving specific downstream tasks less studied. In paper, extended prior work studying linguistic properties encoded one prominent NLM, BERT , properties affect predictions solving specific downstream task. %, using suite 80 probing tasks. % qui vedere se tenere 'several' perch鑼 abbiamo 10 task di classificazione dire che 鐚 uno solo diviso 10 ""sotto-task"". We defined three research questions aimed understanding: kind linguistic properties already encoded pre-trained version BERT across 12 layers; knowledge properties modified fine-tuning process; whether implicit knowledge %of properties affects ability model solve specific downstream task, i.e. Native Language Identification . %With aim, firstly perform large suite probing tasks using %on %DOMI: SPOSTIAMO QUESTA PARTE %To answer first two questions, firstly perform large suite probing tasks using %on %the sentence representations extracted internal layers BERT. Each tasks makes explicit particular property sentence, shallow features complex aspects morpho--syntactic syntactic structure , thus making particularly suitable assess implicit linguistic knowledge encoded NLM deep level granularity. %with respect wide spectrum phenomena overing lexical, morpho-syntactic syntactic structure. To tackle first two questions, adopted approach inspired `linguistic profiling' methodology put forth , assumes wide counts linguistic features automatically extracted parsed corpora allow modeling specific language variety detecting changes respect varieties, e.g. complex vs simple language, female vs male--authored texts, texts written L2 language authors different L1 languages. Particularly relevant study, multi-level linguistic features shown highly predictive role tracking evolution learners' linguistic competence across time developmental levels, first second language acquisition scenarios . %when leveraged traditional learning models variety text classification problems, successfully tackled using formal, rather content based aspects text: assessment sentence complexity text readability , identification personal sociodemographics traits author, his/her native language, gender, age etc. prediction evolution learners' linguistic competence across time . %From perspective, approach considered particular implementation `linguistic profiling' methodology put forth , assumes wide counts linguistic features automatically extracted parsed corpora allow modeling specific language variety detecting way changes respect varieties, e.g. complex vs simple language, female vs male--authored texts, texts written L2 language authors different L1 languages. Given strong informative power features encode variety language phenomena across stages acquisition, assume also helpful dig issues interpretability NLMs. In particular, would like investigate whether features successfully exploited model evolution language competence similarly helpful profiling implicit linguistic knowledge NLM changes across layers tuning specific downstream task. We chose NLI task, i.e. task automatically classifying L1 writer based his/her language production learned language . %Secondly, investigate type degree variations linguistic information fine-tuning pre-trained model 10 distinct datasets used solve Native Language Identification , i.e. task automatically classifying L1 writer based his/her language production learned language . As shown , linguistic features play important role NLI tackled sentence--classification task rather traditional document--classification task. %NLI addressed exploiting linguistic features extracted sentence--level reaching comparable performance obtained state--of--the--art models based word embeddings . This reason considered sentence-level NLI classification task particularly suitable probing NLM linguistic knowledge. %perch鑼 鐚 un task che per essere risolto 鐚 necessario che il modello codifichi un'ampia gamma di informazioni linguistiche e anche perch鑼 鐚 un task basato sull'info estratta dalla sentence -come dimostrato da Cimino et al nonostante lo stato dell'arte 鐚 stato definito soltanto usando word embeddings %vecchia versione: fine-tuning process based Native Language Identification downstream task. %vecchia versione: -base 10 fine-tuned models obtained training BERT many Native Language Identification tasks. Finally, investigated whether linguistic information encoded BERT involved discriminating sentences correctly incorrectly classified fine-tuned models. To end, tried understand linguistic knowledge model sentence affects ability solve specific downstream task involving sentence. %vecchia versione: Adopting suite 80 probing tasks, firstly perform % We perform experiments using suite 80 probing tasks, corresponds specific/distinct sentence-level feature. We find / We show %The remainder paper organized follows. We start presenting related works closely related study Section highlight main novelties approach. We describe details data , probing tasks models used. Experiments results described Section , . To conclude, Section summarize main findings study. \paragraph{Contributions} In paper: carried in-depth linguistic profiling BERT's internal representations %deep analysis implicit linguistic knowledge stored BERT's internal representations changes across layers using wide suite sentence-level probing tasks, corresponding wide spectrum linguistic phenomena different level complexity; % verify implicit linguistic knowledge stored BERT's internal representations using suite 80 probing tasks corresponding wide range linguistic phenomena different level complexity; showed contextualized representations tend lose precision encoding wide range linguistic properties %general-purpose linguistic properties fine-tuning process; % RIVEDERE 'GENERAL-PURPOSE' COME TERMINE PER DESCRIVERE LE NOSTRE FEATURES showed linguistic knowledge stored contextualized representations BERT positively affects ability solve NLI downstream tasks: BERT stores information features% embeddings/internal representations , higher capacity predicting correct label."," In this paper we investigate the linguistic knowledge learned by a Neural Language Model  before and after a fine-tuning process and how this knowledge affects its predictions during several classification problems. We use a wide set of probing tasks, each of which corresponds to a distinct sentence-level feature extracted from different levels of linguistic annotation. We show that BERT is able to encode a wide range of linguistic characteristics, but it tends to lose this information when trained on specific downstream tasks. We also find that BERT's capacity to encode different kind of linguistic properties has a positive influence on its predictions: the more it stores readable linguistic information of a sentence, the higher will be its capacity of predicting the expected label assigned to that sentence."
"Recent emergent-communication studies, renewed astonishing success neural networks, often motivated desire develop neural network agents eventually able verbally interact humans . To facilitate interaction, neural networks' emergent language possess many natural-language-like properties. However, shown that, even emergent languages lead successful communication, often bear core properties natural language . In work, focus one basic property natural language resides tendency use messages close informational optimum. This illustrated Zipf's law Abbreviation , empirical law states natural language, frequent word is, shorter tends . Crucially, ZLA considered efficient property language . Besides obvious fact efficient code would easier process us, also argued core property natural language, likely correlated fundamental aspects human communication, regularity compositionality . Encouraging might hence lead emergent languages also likely develop desirable properties. Despite importance property, \citet{chaabouni:etal:2019} showed standard neural network agents, trained play simple signaling game , develop inefficient code, even displays anti-ZLA pattern. That is, counterintuitively, frequent inputs coded longer messages less frequent ones. This inefficiency related neural networks' ``innate preference'' long messages. In work, aim understanding constraints need introduced neural network agents order overcome innate preferences communicate efficiently, showing proper ZLA pattern. To end, %follow \citet{chaabouni:etal:2019} use reconstruction game two neural network agents: speaker listener. For input, speaker outputs sequence symbols sent listener. The latter needs predict speaker's input based given message. Also, similarly previous work, inputs drawn power-law distribution. We first describe experimental optimization framework . In particular, introduce new communication system called `LazImpa', comprising two different constraints Laziness speaker side Impatience listener side. The former constraint inspired least-effort principle attested ubiquitous pressure human communication . However, constraint applied early, system learn efficient system. We show incrementally penalizing long messages cost function enables early exploration message space prevents converging inefficient local minimum. The constraint, listener side, relies prediction mechanism, argued important language comprehension \citep[e.g.,][]{federmeier2007, altmann2009}, achieved allowing listener reconstruct intended input soon possible. We also provide two-level analytical method: first, metrics quantifying efficiency code; second, new protocol measure informativeness . Applying metrics, demonstrate that, contrary standard speaker/listener agents, new communication system `LazImpa' leads emergence efficient code. The latter follows ZLA-like distribution, close natural languages . Besides plausibility introduced constraints, new communication system is, first, task- architecture-agnostic , second allows stable optimization speaker/listener. We also show listener speaker constraints fundamental emergence ZLA-like distribution, efficient natural language ."," Previous work has shown that artificial neural agents naturally develop surprisingly non-efficient codes.  This is illustrated by the fact that in a referential game involving a speaker and a listener neural networks optimizing accurate transmission over a discrete channel, the emergent messages fail to achieve an optimal length. Furthermore, frequent messages tend to be longer than infrequent ones, a pattern contrary to the Zipf Law of Abbreviation  observed in all natural languages. Here, we show that near-optimal and ZLA-compatible messages can emerge, but only if both the speaker and the listener are modified. We hence introduce a new communication system, ``LazImpa'', where the speaker is made increasingly lazy, i.e.,~avoids long messages, and the listener impatient, i.e.,~seeks to guess the intended content as soon as possible."
"% 1 - What problem solving? Entity typing classifies textual mentions entities, according semantic class, within set labels organized inventory. %Multi-label text classification task assigning sample relevant labels label inventory . The task progressed recognizing coarse classes , extremely large inventories, hundreds thousands labels . Therefore, exploiting inter-label correlations become critical improve performance. % 2 - Why interesting/important problem? % es interesante porque son buenos para modelar redes estructuras jer璋﹔quicas. % Problema: su adopcion en nlp ha sido baja dado que hay una forma muy intuitiva de modelar texto en ellos. Distintos papers muestran como agregar un peque甯給 cambio pero una aplicacion real completa Large inventories tend exhibit hierarchical structure, either explicit tree-like arrangement labels , implicitly label distribution dataset . %A natural solution dealing large inventories organize hierarchy ranging general, coarse labels near top, specific, fine classes bottom. Prior work integrated explicit hierarchical information formulating hierarchy-aware loss representing instances labels joint Euclidean embedding space . However, resulting space hard interpret, methods fail capture implicit relations label inventory. Hyperbolic space naturally equipped embedding symbolic data hierarchical structures . Intuitively, amount space grows exponentially points move away origin. This mirrors exponential growth number nodes trees increasing distance root . %Its tree-like properties make efficient learn hierarchical representations low distortion . % Embeddings close origin disk relatively small distance points, rep-resenting root hierarchy. On hand,embeddings close boundary disk relatively large distance points well suited represent leaf nodes % 3 - How going solve it? In work, propose fully hyperbolic neural model fine-grained entity typing. Noticing perfect match hierarchical label inventories linguistic task benefits hyperbolic spaces, endow classification model suitable geometry capture fundamental property data distribution. By virtue hyperbolic representations, proposed approach automatically infers latent hierarchy arising class distribution achieves meaningful interpretable organization label space. This arrangement captures implicit hyponymic relations inventory enables model excel fine-grained classification. To best knowledge, work first apply hyperbolic geometry beginning end perform multi-label classification real NLP datasets. %NICE PHRASE FROM GULCEHRE: The focus work endow neural network representations suitable geometry capture fundamental properties data... given perfect fit label distribution linguistic task entity typing mathematical properties hyperbolic spaces. % esto deberia ser ""hay componentes ya hechos"". Y lo conecto al toque con el parrafo sig. Recent work proposed hyperbolic neural components, word embeddings , recurrent neural networks attention layers . %Advantages hyperbolic representations well-established discrete data networks graphs . In realm Natural Language Processing components exploit hyperbolic geometry developed well, word embeddings , recurrent neural networks attention layers . %or classifiers Me encanta este paper pero hace NLP :. We address issues. Our model encodes textual inputs, applies novel attention mechanism, performs multi-class multi-label classification, executing operations Poincar\'e model hyperbolic space . %By employing leveraging geometric properties hyperbolic space %The lack systems utilize hyperbolic space beginning end due three main difficulties: %First, different analytic models hyperbolic space, previous work operates one, hinders combination. %Second, clear integrate components conventional Euclidean neural models since mapping data one space onto required. Third, optimization hyperbolic models non-trivial. %We bridge gaps among previous work developing missing connections adapting different components employ Poincar\'e model hyperbolic space layers network. % We bridge gaps among previous work developing missing connections adapting different components, order accomplish full hyperbolic neural network. This is, network extracts features text, applies attention layers performs \todo{I one this}{multi-class classification}, executing operations hyperbolic geometry. % able perform multi-label multi-class classification text input %The model proposed generic manner applied classify sequential data . Since hyperbolic geometry naturally equipped model hierarchical structures, hypothesize model excel tasks profit incorporation hierarchical information. % \todo{awful}{systems} operate metric space result superior performance incorporating hierarchical information. %We evaluate model task fine-grained entity type classification , consider suitable testbed due connection textual inputs hierarchical type inventories. % Introduce main results % HNN's phrase: ""On series experiments datasets showcase effectiveness hyperbolic neural network layers compared ""classic"" Euclidean variants on"" % \todo[inline]{Forwarding bit results good idea . %\todo[inline]{Cambiar esta frase la idea de que ""imponer right metric es como imponer right bias""} %We impose inductive bias model means geometry internal representation. This allows us operate low-dimensional spaces thus substantially reducing parameter cost. Instead relying large pre-trained models, impose suitable inductive bias choosing adequate metric space embed data, introduce extra burden parameter footprint. %Phrase xiong2019inductiveBias: ""Instead using explicit graphical model, enforce relational bias model parameters, introduce extra burden label decoding."" % Misma idea pero yo meto el bias en la representacion, lo cual introduce un costo adicional permite operar con MUCHOS menos par璋﹎etros. %Our components developed modular way allows seamlessly integrated NLP architectures. %\todo{Remove!}{While exist several hyperbolic components, practitioner faced options simple question: How integrate conventional layers? In work, answer question.} By means exponential logarithmic maps able mix hyperbolic Euclidean components one model, aiming exploit strengths different levels representation. We perform thorough ablation allows us understand impact hyperbolic component final performance system , showcases ease integration Euclidean layers. %In summary, make following contributions: %%%%% % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"," Label inventories for fine-grained entity typing have grown in size and complexity. Nonetheless, they exhibit a hierarchical structure. Hyperbolic spaces offer a mathematically appealing approach for learning hierarchical representations of symbolic data. However, it is not clear how to integrate hyperbolic components into downstream tasks. This is the first work that proposes a fully hyperbolic model for multi-class multi-label classification, which performs all operations in hyperbolic space. We evaluate the proposed model on two challenging datasets and compare to different baselines that operate under Euclidean assumptions.  Our hyperbolic model infers the latent hierarchy from the class distribution, captures implicit hyponymic relations in the inventory, and shows performance on par with state-of-the-art methods on fine-grained classification with remarkable reduction of the parameter size. A thorough analysis sheds light on the impact of each component in the final prediction and showcases its ease of integration with Euclidean layers. \footnote{Code available at:\\ \url{https://github.com/nlpAThits/hyfi}}"
"Entity Recognition involves detection classification entities mentioned unstructured text pre-defined categories. It one foundational sub-task several Information Extraction Natural Language Processing pipelines. Hence, errors introduced extraction entities propagate degrade performance complete IE NLP pipeline. In domains experimental biology, growing complexity experiments resulted need automate wet laboratory procedures. Such automation useful avoiding human errors introduced wet lab protocols thereby enhance reproducibility experimental biological research. To achieve reproducibility, previous research works focussed defining machine-readable formats writing wet lab protocols . However, vast majority today閳ユ獨 protocols written natural language jargon colloquial language constructs emerge byproduct ad-hoc protocol documentation. This motivates need machine reading systems interpret meaning natural language instructions, enhance reproducibility via semantic protocols enable robotic automation mapping natural language instructions executable actions. In order enable research interpreting natural language instructions, practical applications biology life sciences, annotated database wet lab protocols introduced. The first step interpreting natural language lab protocols extract entities, followed identification relations them. To address research focussing entity recognition Wet Lab Protocols shared task introduced EMNLP WNUT-2020 Workshop. The task based annotated database wet lab protocols. We tackle task two phases. In first phase, experiment various contextualised word embeddings BiLSTM-CRF model arrive best-performing architecture. In second phase, create ensemble composed eleven BiLSTM-CRF models. The individual models trained random train-validation splits complete dataset. Here, also experiment different output merging schemes, including Majority Voting SLE. The rest paper structured follows: Section 2 states task definition. Section 3 describes specifics methodology. Section 4 explains experimental setup results, Section 5 concludes paper."," In this paper, we describe the approach that we employed to address the task of Entity Recognition over Wet Lab Protocols - a shared task in EMNLP WNUT-2020 Workshop. Our approach is composed of two phases. In the first phase, we experiment with various contextualised word embeddings  and a BiLSTM-CRF model to arrive at the best-performing architecture. In the second phase, we create an ensemble composed of eleven BiLSTM-CRF models. The individual models are trained on random train-validation splits of the complete dataset. Here, we also experiment with different output merging schemes, including Majority Voting and Structured Learning Ensembling . Our final submission achieved a micro F1-score of 0.8175 and 0.7757 for the partial and exact match of the entity spans, respectively. We were ranked first and second, in terms of partial and exact match, respectively."
"We make many decisions interact world. When rewarded , learn modify proximal cause stimulus chain decisions leading it, encourage future similar results. This process naturally paradigm Reinforcement Learning . Policy-based learning seeks find good estimates , function returns expected cumulative reward action chosen state . A desirable property methodologies learn ability generalize appropriate action taken encountering previously unseen state. Recent advances shown strong evidence generalization spatiotemporal modalities robotic manipulation , video games , autonomous navigation . However, modality language, less work applying generalization approaches decision making. Useful applications sequential decision making language models personal assistants proactively anticipate client needs; anti-phishing mediation agents waste would-be thief's time relevant non-helpful responses; investigative journalist assistants determine read, contact, questions ask create revelatory news report. Neural reinforcement learning training approaches, used play action video games , potential applicability language-based decision making due ability learn navigate adversarial exploratory scenarios. Naturally, generalization background knowledge capability afforded large contextualized language models \bert may applicable well. A useful virtual world proxy explore approaches' applicability text adventure game playing. In text adventure game, player immersed environment reading textual descriptions scene issuing natural language commands navigate inside scene. The player discovers interacts entities accomplishes goals, receiving explicit rewards so. Learning play text games useful pursuit convenient proxy real world cases cited above. Unlike these, plentiful data numerous games exist, endless supply games constructed, text games built-in reward functions, making suitable RL. This class problems also useful challenging: exposure family games explore topic similar gameplay , human players perform nearly perfectly additional games, computer models struggle. Why this? Humans quickly understand situation placed make rational decisions based trial-and-error life experience, call commonsense knowledge. Knowing priori that, e.g., door helpful allows players learn faster. Even though games complexity finite-state machines, computer models cannot learn play well. The problem appears due lack generalization caused lack commonsense. To computer model, considering whether using ludicrous considering whether using . Both actions discouraged negative reinforcement, human needs learn latter. Furthermore, computer player learning one may generalize one way, human surely will. There existing work learning play text games RL standard pattern incorporating large language models \bert yet seen current literature. It turns integration trivial. Most models use \bert ilk predominantly apply results supervised learning tasks training data ground truth least, case generation-based tasks like dialogue translation, corpus desirable output mimic . For tasks suited RL exploration interaction world, true target even, initially, corpus, thus learning proceed iteratively via, e.g., exploration-exploitation , requires millions training iterations converge . Integrating process additional overhead fine-tuning large model like \bert leads impractical slowdown: experiments considered work, baseline models use \cnn require little three weeks train Nvidia P100 GPU-equipped machine. Using models tasks run number iterations hardware fine-tuning 12-layer \bert model would take two years. In work, compare different previously used representation models deep RL imitation learning method first trains light-weight teacher using exploration-exploitation, uses trained model train heavy-weight student model. This dramatically decreases amount training time needed learn. Moreover, devise means casting RL problem supervised learning paradigm, allowing better exploitation large contextualized language models. In doing, show agents benefit imitation learning reformulation, converging faster models, exceeding teacher performance 7\% 24\% in- out-of-domain problems, despite limited search space. The novel contributions work are:"," We consider problems of making sequences of decisions to accomplish tasks,  interacting via the medium of language. These problems are often tackled with reinforcement learning approaches. We find that these models do not generalize well when applied to novel task domains. However, the large amount of computation necessary to adequately train and explore the search space of sequential decision making, under a reinforcement learning paradigm, precludes the inclusion of large contextualized language models, which might otherwise enable the desired generalization ability. We introduce a teacher-student imitation learning methodology and a means of converting a reinforcement learning model into a natural language understanding model. Together, these methodologies enable the introduction of contextualized language models into the sequential decision making problem space. We show that models can learn faster and generalize more, leveraging both the imitation learning and the reformulation. Our models exceed teacher performance on various held-out decision problems, by up to 7\% on in-domain problems and 24\% on out-of-domain problems."
"% Reinforcement learning shown great success environments large state spaces. Using neural networks capture state representations allowed end-to-end training agents domains like Atari Go . It natural emulate success text domains, especially given state space language-based tasks combinatorially large. A sentence length allowed vocabulary possible states, tabular methods like learning fail unless coupled powerful function approximators like neural networks.\\ While current state RL multiple challenges, sparse rewards one leads slow, sometimes convergence. Consider agent learning environment large state space, states leading reward . An agent starting far left must take large number actions encountering reward. In turn, sparse feedback results noisy gradient training neural network. In extreme scenario, Figure , agent might take exponential number actions reach single leaf reward. Some early work, reward shaping , attempted solve sparse reward problem introducing dense rewards based heuristics, e.g., close agent goal. However, require complex design choices might result unexpected behavior agents.\\ Sparse rewards common straightforward way specify task needs solved. If robot expected pour water jug glass, simplest way give reward fills glass, otherwise. This type reward design common text-based games, agent rewarded upon reaching goal state, task-oriented dialogue, agent rewarded based successful completion task.\\ For study, examine text-based games find providing dense rewards help sentiment analysis improves performance conditions."," While reinforcement learning  has been successful in natural language processing  domains such as dialogue generation and text-based games, it typically faces the problem of sparse rewards that leads to slow or no convergence. Traditional methods that use text descriptions to extract only a state representation ignore the feedback inherently present in them. In text-based games, for example, descriptions like ``Good Job! You ate the food'' indicate progress, and descriptions like ``You entered a new room'' indicate exploration. Positive and negative cues like these can be converted to rewards through sentiment analysis. This technique converts the sparse reward problem into a dense one, which is easier to solve. Furthermore, this can enable reinforcement learning without rewards, in which the agent learns entirely from these intrinsic sentiment rewards. This framework is similar to intrinsic motivation, where the environment does not necessarily provide the rewards, but the agent analyzes and realizes them by itself. We find that providing dense rewards in text-based games using sentiment analysis improves performance under some conditions."
"Natural language data rich structure, structure visible surface. Machine learning models tackling high-level language tasks would benefit uncovering underlying structures trees, sequence tags, segmentations. Traditionally, practitioners turn pipeline approaches external, pretrained model used predict, \eg, syntactic structure. The benefit approach predicted tree readily available inspection, downside errors easily propagate throughout pipeline require attention . In contrast, deep neural architectures tend eschew preprocessing, instead learn soft hidden representations, easily amenable visualization analysis. The best worlds would model structure latent variable, combining transparency pipeline approach end-to-end unsupervised representation learning makes deep models appealing. Moreover, large-capacity model tend rediscover structure scratch , structured latent variables may reduce required capacity. Learning discrete, combinatorial latent variables is, however, challenging, due intersection large cardinality null gradient issues. For example, learning latent dependency tree, latent parser must choose among exponentially large set possible trees; what's more, parser may learn gradient information downstream task. If highest-scoring tree selected using argmax operation, gradients zero, preventing learning. One strategy dealing null gradient issue use surrogate gradient, explicitly overriding zero gradient chain rule, different computation performed. The commonly known example straight-through estimator \citep[STE;][]{bengio2013estimating}, pretends argmax node instead identity operator. Such methods lead fundamental mismatch objective learning algorithm. The effect mismatch still insufficiently understood, design successful new variants therefore challenging. For example, recently-proposed SPIGOT method found beneficial use projection part surrogate gradient. In paper, study surrogate gradient methods deterministic learning discrete structured latent variables. Our contributions are: While discrete methods outperform relaxed alternatives using building \linebreak blocks, hope interpretation insights would trigger future latent structure research. The code paper available \url{https://github.com/deep-spin/understanding-spigot}."," Latent structure models are a powerful tool for modeling language data: they can mitigate the error propagation and annotation bottleneck in pipeline systems, while simultaneously uncovering linguistic insights about the data. One challenge with end-to-end training of these models is the argmax operation, which has null gradient. In this paper, we focus on surrogate gradients, a popular strategy to deal with this problem. We explore latent structure learning through the angle of pulling back the downstream learning objective. In this paradigm, we discover a principled motivation for both the straight-through estimator  as well as the recently-proposed SPIGOT---a variant of STE for structured models. Our perspective leads to new algorithms in the same family. We empirically compare the known and the novel pulled-back estimators against the popular alternatives, yielding new insight for practitioners and revealing intriguing failure cases."
"%% Paragraph 1: %% * introduce constructions interest %% * give broad impression subtlety grammatical phenomena, %% * emphasize verb bias problem, since one unique contributions When use language, often faced choice several possible ways expressing message. For example, English, express event intended actual transfer two animate entities, one option double-object construction, two noun phrases follow verb. Alternatively, content expressed using prepositional dative construction. \ex. \a. Ava gave something. \hfill DO \b. Ava gave something him. \hfill PO Speakers' preferences one construction depend multiple factors, including length definiteness arguments . % could also cite: Davidse 1996; Givo 铏俷 1984a; Polinsky 1996; Ransom 1979; Snyder 2003; Thompson 1990, 1995; One particularly subtle factor lexical verb bias. While verbs readily occur either construction, others strong preferences one : \ex. \a. ?Ava said something. \hfill DO \b. Ava said something him. \hfill PO %% Paragraph 2: %% * transition motivation problem interesting NLP %% * briefly mention major previous work problem gaps Decades work linguistics psychology investigated humans learn distinctions . Yet, deep neural networks achieved state-of-the-art performance across many tasks natural language processing, little known extent acquired similarly fine-grained preferences. Although neural language models robustly capture certain types grammatical constraints, e.g., subject-verb agreement long distance dependencies , continue struggle aspects syntax, including argument structure \cite[e.g.][]{warstadt2019neural}. Verb biases provide particularly interesting testbed. Successfully predicting psycholinguistic phenomena requires integration specific lexical information representations higher-level grammatical structures, implications understanding differential performance models tasks. %% Paragraph 3: contribution In current work, take analytic comparative approach. First, introduce DAIS dataset, containing 50K human preference judgments 5K sentence pairs, using 200 unique verbs. These empirical judgments indicate verb bias preferences highly gradient practice , rather belonging binary ``alternating'' ``non-alternating'' classes, commonly assumed. Second, evaluate predictions variety neural models, including recurrent architectures transformers, analyze internal states understand drives differences performance. \change{Finally, evaluate models natural production data Switchboard corpus, finding transformers achieve similar classification accuracy prior work using hand-annotated features \cite[;][]{bresnan2007predicting}.}"," Languages typically provide more than one grammatical construction to express certain types of messages. A speaker's choice of construction is known to depend on multiple factors, including the choice of main verb -- a phenomenon known as verb bias. Here we introduce DAIS, a large benchmark dataset containing 50K human judgments for 5K distinct sentence pairs in the English dative alternation. This dataset includes 200 unique verbs and systematically varies the definiteness and length of arguments.  We use this dataset, as well as an existing corpus of naturally occurring data, to evaluate how well recent neural language models capture human preferences. Results show that larger models perform better than smaller models, and transformer architectures  tend to out-perform recurrent architectures  even under comparable parameter and training settings.  Additional analyses of internal feature representations suggest that transformers may better integrate specific lexical information with grammatical constructions."
"The core idea behind predominant pretrain fine-tune paradigm transfer learning NLP general language knowledge, gleaned large quantities data using unsupervised objectives, serve foundation specialized endeavors. Current practice involves taking full model amassed general knowledge fine-tuning second objective appropriate new task \citep[see][for overview]{raffelExploringLimitsTransfer2019}. Using methods, pre-trained transformer-based language models \citep[e.g., BERT, ][]{devlin-etal-2019-bert} employed great effect wide variety NLP problems, thanks, part, fine-grained ability capture aspects linguistic context . However, paradigm introduces subtle insidious limitation becomes evident downstream application topic model. A topic model may cast autoencoder , could fine-tune pretrained transformer identical document reconstruction objective. But replacing original topic model, lose property makes desirable: interpretability. The transformer gains contextual power ability exploit huge number parameters, interpretability topic model comes dramatic dimensionality reduction. We combine advantages two approaches---the rich contextual language knowledge pretrained transformers intelligibility topic models---using knowledge distillation . In original formulation, knowledge distillation involves training parameter-rich teacher classifier large swaths data, using high-quality probability estimates outputs guide smaller student model. Since information contained estimates useful---a picture ox yield higher label probabilities buffalo apricot---the student needs less data train generalize better. We show principle apply equally well improve unsupervised topic modeling, knowledge previously attempted. While distillation usually involves two models type, also apply models differing architectures. Our method conceptually quite straightforward: fine-tune pretrained transformer document reconstruction objective, acts capacity autoencoder. When document passed BERT autoencoder, generates distribution words includes unobserved related terms. We incorporate distilled document representation loss function topic model estimation. To connect method standard supervised knowledge distillation, observe unsupervised ``task'' autoencoder topic model reconstruction original document, i.e. prediction distribution vocabulary. The BERT autoencoder, ``teacher'', provides dense prediction richly informed training large corpus. The topic model, ``student'', generating prediction distribution. We use former guide latter, essentially predicting word distributions multi-class labeling problem. \newcommand{\reffig}[1]{\hl{[FIG: #1]}} \newcommand{\reftable}[1]{\hl{[TABLE: #1]}} \newcommand{\refsec}[1]{\hl{[SECTION: #1]}} \newcommand{\ho}[1]{\textcolor{blue}{}} \newcommand{\pg}[1]{\textcolor{red}{}} \newcommand{\psrcomment}[1]{} \newcommand{\ignore}[1]{} \newcommand{\ourmodel}{BAT } \newcommand{\e}[2]{\mathbb{E}_{#1}\left[ #2 \right] } \newcommand{\B}{B} \DeclareMathOperator*{\argmin}{arg\,min} \aclfinalcopy % \newcommand\BibTeX{Bib\TeX} \title{Improving Neural Topic Models using Knowledge Distillation} \author{Alexander Hoyle\thanks{\, Equal contribution.} \\ Computer Science \\ University Maryland \\ College Park, MD \\ \\\And Pranav Goel\footnotemark[1] \\ Computer Science \\ University Maryland \\ College Park, MD \\ \\\And Philip Resnik \\ Linguistics / UMIACS \\ University Maryland \\ College Park, MD \\ \\} \date{} \begin{document} \bibliography{anthology,refs,zotero} \bibliographystyle{acl_natbib} \clearpage \appendix","     Topic models are often used to identify human-interpretable topics to help make sense of large document collections. We use knowledge distillation to combine the best attributes of probabilistic topic models and pretrained transformers. Our modular method can be straightforwardly applied with any neural topic model to improve topic quality, which we demonstrate using two models having disparate architectures, obtaining state-of-the-art topic coherence. We show that our adaptable framework not only improves performance in the aggregate over all estimated topics, as is commonly reported, but also in head-to-head comparisons of aligned topics."
"Interactive systems capable understanding natural language responding form natural language text high potentials various applications. In pursuit building evaluating systems, study learning agents Interactive Fiction games. IF games world-simulating software players use text commands control protagonist influence world, illustrated Figure. IF gameplay agents need simultaneously understand game's information text display generate natural language command via text input interface. Without providing explicit game strategy, agents need identify behaviors maximize objective-encoded cumulative rewards. IF games composed human-written texts create superb new opportunities studying evaluating natural language understanding techniques due unique characteristics. Game designers elaborately craft literariness narrative texts attract players creating IF games. The resulted texts IF games linguistically diverse sophisticated template-generated ones synthetic text games. The language contexts IF games versatile various designers contribute enormous domains genres, adventure, fantasy, horror, sci-fi. The text commands control characters less restricted, sizes six orders magnitude larger previous text games. The recently introduced Jericho benchmark provides collection IF games. The complexity IF games demands sophisticated NLU techniques used synthetic text games. Moreover, task designing IF game-play agents, intersecting NLU reinforcement learning , poses several unique challenges NLU techniques. The first challenge difficulty exploration extbf{the huge natural language action space}. To make RL agents learn efficiently %via trial-and-error without prohibitive exhaustive trials, action estimation must generalize learned knowledge tried actions others. To end, previous approaches, starting single embedding vector observation, either predict elements actions independently; embed valid action another vector predict action value based vector-space similarities. These methods consider compositionality role-differences action elements, interactions among observation. Therefore, modeling action values less accurate less data-efficient. The second challenge extbf{partial observability}. At game-playing step, agent receives textual observation describing locations, objects, characters game world. But latest observation often sufficient summary interaction history may provide enough information determine long-term effects actions. Previous approaches address problem building representation past observations . These methods treat historical observations equally summarize information single vector without focusing important contexts related action prediction current observation. Therefore, usages history also bring noise, improvement always significant. We propose novel formulation IF game playing Multi-Passage Reading Comprehension harness MPRC techniques solve huge action space partial observability challenges. The graphical illustration shown Figure. First, action value prediction essentially generating scoring compositional action structure finding supporting evidence observation. We base fact action instantiation template, i.e., verb phrase placeholders object arguments takes~. Then action generation process viewed extracting objects template's placeholders textual observation, based interaction template verb phrase relevant context objects observation. Our approach addresses structured prediction interaction problems idea context-question attention mechanism RC models. Specifically, treat observation passage template verb phrase question. The filling object placeholders template thus becomes extractive QA problem selects objects observation given template. Simultaneously action gets evaluation value predicted RC model. Our formulation approach better capture fine-grained interactions observation texts structural actions, contrast previous approaches represent observation single vector ignore fine-grained dependency among action elements. Second, alleviating partial observability essentially enhancing current observation potentially relevant history predicting actions enhanced observation. Our approach retrieves potentially relevant historical observations object-centric approach , retrieved ones likely connected current observation describe least one shared interactable object. Our attention mechanisms applied across retrieved multiple observation texts focus informative contexts action value prediction. We evaluated approach suite Jericho IF games, compared previous approaches. Our approaches achieved outperformed state-of-the-art performance 25 33 games, trained less one-tenth game interaction data used prior art. We also provided ablation studies models retrieval strategies. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"," Interactive Fiction  games with real human-written natural language texts provide a new natural evaluation for language understanding techniques.  In contrast to previous text games with mostly synthetic texts, IF games pose language understanding challenges on the human-written textual descriptions of diverse and sophisticated game worlds and language generation challenges on the action command generation from less restricted combinatorial space. We take a novel perspective of IF game solving and re-formulate it as Multi-Passage Reading Comprehension  tasks. Our approaches utilize the context-query attention mechanisms and the structured prediction in MPRC to efficiently generate and evaluate action outputs and apply an object-centric historical observation retrieval strategy to mitigate the partial observability of the textual observations.  Extensive experiments on the recent IF benchmark  demonstrate clear advantages of our approaches achieving high winning rates and low data requirements compared to all previous approaches.\footnote{Source code is available at: \url{https://github.com/XiaoxiaoGuo/rcdqn}. }"
"Recent advances self-supervised pre-training resulted impressive downstream performance several NLP tasks. However, led development enormous models, often require days training non-commodity hardware . Furthermore, studies shown quite challenging successfully train large Transformer models, requiring complicated learning schemes extensive hyperparameter tuning. Despite expensive training regimes, recent studies found trained, bi-directional language models exhibit simple patterns self-attention without much linguistic backing. For example, 40\% heads pre-trained BERT model simply pay attention delimiters added tokenizer . Since attention patterns independent linguistic phenomena, natural question arises: Transformer models guided towards attention patterns without requiring extensive training? In paper, propose attention guidance mechanism self-attention modules Transformer architectures enable faster, efficient, robust self-supervised learning. Our approach simple agnostic training objective. Specifically, introduce auxiliary loss function guide self-attention heads layer towards set pre-determined patterns . These patterns encourage formation global local structures model. Through several experiments, show approach enables training large Transformer models considerably faster 閳 example, train 16-layer RoBERTa model SOTA performance low-resource domain two days using four GPUs, excluding loss leads slow convergence. Our method also achieves competitive performance BERT three English natural language understanding tasks, outperforms baseline masked language modeling models eleven twelve settings considered. Further, also show initialization agnostic training objective demonstrating gains replaced token detection objective proposed ELECTRA machine translation Transformers. Finally, provide analysis attention heads learned using method. Surprisingly, contrary recent studies, find possible train models perform well language modeling without learning single attention head models coreferences. % . For example, model fails co-reference test still performing well language modeling downstream tasks. To summarize, main contributions are:"," % Despite being successful in downstream language understanding tasks, modern language models contain millions of parameters and require multiple days of training on specialized hardware such as TPUs. Training such models on commodity hardware  often means slow convergence, making it practically intractable for many researchers.  In this paper, we propose a simple and effective technique to allow for efficient self-supervised learning with bi-directional Transformers. Our approach is motivated by recent studies demonstrating that self-attention patterns in trained models contain a majority of non-linguistic regularities. We propose a computationally efficient auxiliary loss function to guide attention heads to conform to such patterns. Our method is agnostic to the actual pre-training objective and results in faster convergence of models as well as better performance on downstream tasks compared to the baselines, achieving state of the art results in low-resource settings. Surprisingly, we also find that linguistic properties of attention heads are not necessarily correlated with language modeling performance.\footnote{Code: \href{https://github.com/ameet-1997/AttentionGuidance}{https://github.com/ameet-1997/AttentionGuidance}}"
"% % Transformer models outperformed previously used RNN based models traditional statistical MT techniques. This improvement, though, comes cost higher computation complexity. The decoder computation sequential becomes bottleneck due autoregressive nature, large depth self-attention structure. % Another recent trend making models larger ensembling multiple models achieve best possible translation quality . Leading solutions common benchmark usually use ensemble Transformer big models, combined 1 billion parameters. % In paper, focus developing architectures faster inference less number parameters, without sacrificing translation quality. % Recent work \citet{ludicrously:kim2019} proposed methods replace self-attention decoder simpler simple recurrent units used knowledge distillation simplify training final architecture. \citet{deepencoder} also proposed make decoder lightweight training deep-encoder, shallow decoder architecture. Another line effort make NMT architectures efficient pruning different components model. \citet{prune_voita-etal-2019-analyzing} \citet{prune_michel:NIPS2019_9551} show attention heads network learn redundant information pruned away. % All works use vanilla Transformer architecture baseline, clear approaches give complimentary results combined together. In work, explore benchmark combining techniques, goal maximizing inference speed without hurting translation quality. % %We adapt approach extend following ideas. First, optimized SSRU make efficient. Second, removed feed-forward network decoder completely. Then, kept 1 layer decoder used deep encoder. Last pruned redundant heads deep encoder. % After carefully stacking approaches, proposed architecture able achieve significant speed improvement 84\% GPU 102\% CPU architectures without degradation translation quality terms BLEU. % %%%%%%%% original Related Work %%%%%%%%% %"," Large Transformer models have achieved state-of-the-art results in neural machine translation and have become standard in the field. In this work, we look for the optimal combination of known techniques to optimize inference speed without sacrificing translation quality. We conduct an empirical study that stacks various approaches and demonstrates that combination of replacing decoder self-attention with simplified recurrent units, adopting a deep encoder and a shallow decoder architecture and multi-head attention pruning can achieve up to $109$\% and $84$\% speedup on CPU and GPU respectively and reduce the number of parameters by $25$\% while maintaining the same translation quality in terms of BLEU. %State-of-the-art neural machine translation has become compute and parameter intensive in the last several years, which puts significant pressure on the latency and hardware resources during inference. In this paper, we change the standard Transformer architecture to reduce the number of parameters and increase inference speed without sacrificing translation quality. We demonstrate that combination of replacing decoder self-attention with the simpler simple recurrent units, adopting a deep encoder and shallow decoder architecture, and multi-head attention pruning, we can achieve up to 102\% speedup and reduce the number of parameters by 13\% while maintaining the same translation quality in terms of BLEU."
"Intent Detection crucial task natural language understanding, whose objective extract underlying intents behind given utterances. The extracted intents could provide contexts downstream Natural Language Processing tasks dialogue state tracking question answering. Unlike traditional text classification, ID challenging two main reasons Utterances usually short diversely expressed, Emerging intents occur continuously, especially across different domains . Despite recent advances, state-of-the-art ID methods require large amount annotated data achieve competitive performance. This requirement inhibits models' capability generalizing newly emerging intents limited annotations inference. Re-training fine-tuning large models samples emerging classes could easily lead overfitting problems. Motivated human capability correctly categorizing new classes examples , few-shot learning paradigms adopted tackle scarcity problems emerging classes. FSL methods take advantage small set labeled examples learn discriminate unlabeled samples classes, even seen training. Recent works FSL focus learning matching information labeled samples unlabeled samples provide additional contextual information instance-level representations, leading effective prototype representation. However, methods extract similarity based fine-grained word semantics, failing capture diverse expressions users' utterances. This problem could lead overfitting either seen intents novel intents, especially challenging Generalized Few-shot Intent Detection setting seen novel intents existent joint label space inference. Instead, matching support query samples coarser-grained semantic components could provide additional informative contexts beyond word levels. For instance, two utterances ""i need get table pub southeastern cuisine"" ``book spot six friends"" share similar intent label ``Book Restaurant"". While word-level semantics might find similar action words ``get"" ``book"", words necessarily contribute correct intent findings. Instead, coarser-grained semantics ``get table"" ``book spot"" could provide hints identify ``Book Restaurant"" intent. As semantic components could effectively extracted multi-head self-attention, matching SC support query enhance query support representations, leading improvements generalization seen training classes unseen testing classes. To enhance dynamics extracted SC across various domains diversely expressed utterances, introduce additional head regularizations. In addition, overcome insufficiency single similarity measure matching sentences diverse semantics, comprehensive matching method explored. Our main contribution summarized follows:"," Few-shot Intent Detection is challenging due to the scarcity of available annotated utterances. Although recent works demonstrate that multi-level matching plays an important role in transferring learned knowledge from seen training classes to novel testing classes, they rely on a static similarity measure and overly fine-grained matching components. These limitations inhibit generalizing capability towards Generalized Few-shot Learning settings where both seen and novel classes are co-existent. In this paper, we propose a novel Semantic Matching and Aggregation Network where semantic components are distilled from utterances via multi-head self-attention with additional dynamic regularization constraints. These semantic components capture high-level information, resulting in more effective matching between instances. Our multi-perspective matching method provides a comprehensive matching measure to enhance representations of both labeled and unlabeled instances. We also propose a more challenging evaluation setting that considers classification on the joint all-class label space. Extensive experimental results demonstrate the effectiveness of our method. Our code and data are publicly available \footnote{\url{https://github.com/nhhoang96/Semantic\_Matching}} ."
"Multilingual Neural Machine Translation , leverages single NMT model handle translation multiple languages, drawn research attention recent years. MNMT appealing since greatly reduces cost training serving separate models different language pairs. It shown great potential knowledge transfer among languages, improving translation quality low-resource zero-shot language pairs. Previous works MNMT mostly focused model architecture design different strategies parameter sharing representation sharing. Existing MNMT systems mainly rely bitext training data, limited costly collect. Therefore, effective utilization monolingual data different languages important research question yet less studied MNMT. Utilizing monolingual data widely explored various NMT natural language processing applications. Back translation , leverages target-to-source model translate target-side monolingual data source language generate pseudo bitext, one effective approaches NMT. However, well trained NMT models required generate back translations language pair, computationally expensive scale multilingual setup. Moreover, less applicable low-resource language pairs without adequate bitext data. Self-supervised pre-training approaches, train model denoising learning objectives large-scale monolingual data, achieved remarkable performances many NLP applications. However, catastrophic forgetting effect, finetuning task leads degradation main task, limits success continuing training NMT models pre-trained monolingual data. Furthermore, separated pre-training finetuning stages make framework less flexible introducing additional monolingual data new languages MNMT system. In paper, propose multi-task learning framework effectively utilize monolingual data MNMT. Specifically, model jointly trained translation task multilingual parallel data two auxiliary tasks: masked language modeling denoising auto-encoding source-side target-side monolingual data respectively. We present two simple yet effective scheduling strategies multilingual multi-task framework. In particular, introduce dynamic temperature-based sampling strategy multilingual data. To encourage model keep learning large-scale monolingual data, adopt dynamic noising ratio denoising objectives gradually increase difficulty level tasks. We evaluate proposed approach large-scale multilingual setup language pairs WMT datasets. We study three English-centric multilingual systems, including many-to-English, English-to-many, many-to-many. We show proposed MTL approach significantly boosts translation quality high-resource low-resource languages. Furthermore, demonstrate MTL effectively improve translation quality zero-shot language pairs bitext training data. In particular, MTL achieves even better performance pivoting approach multiple low-resource language pairs. We show MTL outperforms pre-training approaches NMT tasks well cross-lingual transfer learning NLU tasks, despite trained small amount data comparison pre-training approaches. The contributions paper follows. First, propose new MTL approach effectively utilize monolingual data MNMT. Second, introduce two simple yet effective scheduling strategies, namely dynamic temperature-based sampling dynamic noising ratio strategy. Third, present detailed ablation studies analyze various aspects proposed approach. Finally, demonstrate first time MNMT MTL models effectively used cross-lingual transfer learning NLU tasks similar better performance state-of-the-art massive scale pre-trained models using single task."," While monolingual data has been shown to be useful in improving bilingual neural machine translation , effectively and efficiently leveraging monolingual data for Multilingual NMT  systems is a less explored area. In this work, we propose a multi-task learning  framework that jointly trains the model with the translation task on bitext data and two denoising tasks on the monolingual data. We conduct extensive empirical studies on MNMT systems with $10$ language pairs from WMT datasets. We show that the proposed approach can effectively improve the translation quality for both high-resource and low-resource languages with large margin, achieving significantly better results than the individual bilingual models. We also demonstrate the efficacy of the proposed approach in the zero-shot setup for language pairs without bitext training data. Furthermore, we show the effectiveness of MTL over pre-training approaches for both NMT and cross-lingual transfer learning NLU tasks; the proposed approach outperforms massive scale models trained on single task."
"Neural machine translation data-hungry approach, requires large amount data train well-performing NMT model. However, complex patterns potential noises large-scale data make training NMT models difficult. To relieve problem, several approaches proposed better exploit training data, curriculum learning, data diversification, data denoising. In paper, explore interesting alternative reactivate inactive examples training data NMT models. By definition, inactive examples training examples marginally contribute even inversely harm performance NMT models. Concretely, use sentence-level output probability assigned trained NMT model measure activeness level training examples, regard examples least probabilities inactive examples . Experimental results show removing 10\% inactive examples marginally improve translation performance. In addition, observe high overlapping ratio inactive active examples across random seeds, model capacity, model architectures . These results provide empirical support hypothesis existence inactive examples large-scale datasets, invariant specific NMT models depends data distribution itself. We propose data rejuvenation rejuvenate inactive examples improve performance NMT models. Specifically, train NMT model active examples rejuvenation model re-label inactive examples, resulting rejuvenated examples~. The final NMT model trained combination active examples rejuvenated examples. Experimental results show data rejuvenation approach consistently significantly improves performance SOTA NMT models benchmark WMT14 English-German English-French datasets~. Encouragingly, approach also complementary existing data manipulation methods , combining improve performance. Finally, conduct extensive analyses better understand inactive examples proposed data rejuvenation approach. Quantitative analyses reveal inactive examples difficult learn active ones, rejuvenation reduce learning difficulty~. The rejuvenated examples stabilize accelerate training process NMT models~, resulting final models better generalization capability~. Our contributions work follows:"," Large-scale training datasets lie at the core of the recent success of neural machine translation  models. However, the complex patterns and potential noises in the large-scale data make training NMT models difficult. In this work, we explore to identify the inactive training examples which contribute less to the model performance, and show that the existence of inactive examples depends on the data distribution. We further introduce data rejuvenation to improve the training of NMT models on large-scale datasets by exploiting inactive examples. The proposed framework consists of three phases.  First, we train an identification model on the original training data, and use it to distinguish inactive examples and active examples by their sentence-level output probabilities. Then, we train a rejuvenation model on the active examples, which is used to re-label the inactive examples with forward-translation. Finally, the rejuvenated examples and the active examples are combined to train the final NMT model. Experimental results on WMT14 English-German and English-French datasets show that the proposed data rejuvenation consistently and significantly improves performance for several strong NMT models. Extensive analyses reveal that our approach stabilizes and accelerates the training process of NMT models, resulting in final models with better generalization capability.}  %In this work, we propose to improve the training of NMT models on large-scale datasets by exploiting inactive training examples, which contribute less to the model performance. Specifically, the proposed framework consists of three phases. First, we identify the inactive examples with their sentence-level prediction confidence assigned by an identification model trained on the original training data. Then, we train a rejuvenation model on the active examples, which is used to re-label the inactive examples with forward-translation. Finally, the rejuvenated examples and the active examples are combined to train the final NMT model. Experimental results on WMT14 English-German and English-French datasets show that the proposed data rejuvenation consistently and significantly improves performance for several strong NMT models. Extensive analyses reveal that our approach stabilizes and accelerates the training process of NMT models, resulting in final models with better generalization capability."
The following instructions directed authors papers submitted EMNLP 2020 accepted publication proceedings. All authors required adhere specifications. Authors required provide Portable Document Format version papers. The proceedings designed printing A4 paper.," This document contains the instructions for preparing a manuscript for the proceedings of EMNLP 2020. The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like. These instructions should be used for both papers submitted for review and for final versions of accepted papers. Authors are asked to conform to all the directions reported in this document."
"Modern neural machine translation~ models employ sufficient capacity fit massive data well utilizing large number parameters, suffer widely recognized issue, namely, over-parameterization. For example, showed 40\% parameters RNN-based NMT model pruned negligible performance loss. However, low utilization efficiency parameters results waste computational resources , well renders model stuck local optimum. In response over-parameterization issue, network pruning widely investigated computer vision natural language processing tasks . Recent work proven spare parameters reused maximize utilization models CV tasks image classification. The leverage parameter rejuvenation sequence-to-sequence learning, however, received relatively little attention research community. In paper, empirically study efficiency issue NMT models. Specifically, first investigate effects weight pruning advanced Transformer models, showing 20\% parameters directly pruned, continuously training sparse networks, prune 50\% performance loss. Starting observation, exploit whether redundant parameters able re-utilized improving performance NMT models. Experiments systematically conducted different datasets NMT architectures . Results demonstrate rejuvenation approach significantly consistently improve translation quality +0.8 BLEU points. Further analyses reveal rejuvenated parameters reallocated enhance ability model source-side low-level information, lacking leads number problems NMT models. \paragraph{Contributions} Our key contributions are:"," Modern neural machine translation  models employ a large number of parameters, which leads to serious over-parameterization and typically causes the underutilization of computational resources. In response to this problem, we empirically investigate whether the redundant parameters can be reused to achieve better performance. Experiments and analyses are systematically conducted on different datasets and NMT architectures. We show that: 1) the pruned parameters can be rejuvenated to improve the baseline model by up to +0.8 BLEU points; 2) the rejuvenated parameters are reallocated to enhance the ability of modeling low-level lexical information."
"Sentiment analysis attracted increasing attention recently. Aspect-based sentiment analysis fine-grained sentiment analysis task includes many subtasks, two aspect category detection detects aspect categories mentioned sentence aspect-category sentiment analysis predicts sentiment polarities respect detected aspect categories. Figure shows example. ACD detects two aspect categories, ambience food, ACSA predicts negative positive sentiment toward respectively. In work, focus ACSA, ACD auxiliary task used find words indicating aspect categories sentences ACSA. Since sentence usually contains one aspect categories, previous studies developed various methods generating aspect category-specific sentence representations detect sentiment toward particular aspect category sentence. To name few, attention-based models allocate appropriate sentiment words given aspect category. \citet{xue2018aspect} proposed generate aspect category-specific representations based convolutional neural networks gating mechanisms. Since aspect-related information may already discarded aspect-irrelevant information may retained aspect independent encoder, existing methods utilized given aspect guide sentence encoding scratch. Recently, BERT based models obtained promising performance ACSA task. However, models ignored sentiment aspect category mentioned sentence aggregation sentiments words indicating aspect category. It leads suboptimal performance models. For example Figure, ``drinks'' ``food'' indicate aspect category food. The sentiment food combination sentiments ``drinks'' ``food''. Note that, words indicating aspect categories contain aspect terms explicitly indicating aspect category also contain words implicitly indicating aspect category . In Figure, ``drinks'' ``food'' aspect terms explicitly indicating aspect category food, ``large'' ``noisy'' aspect terms implicitly indicating aspect category ambience. In paper, propose Multi-Instance Multi-label Learning Network Aspect-Category sentiment analysis . AC-MIMLLN explicitly models fact sentiment aspect category mentioned sentence aggregation sentiments words indicating aspect category. Specifically, AC-MIMLLN treats sentences bags, words instances, words indicating aspect category key instances aspect category. Given bag aspect categories mentioned bag, AC-MIMLLN first predicts instance sentiments, finds key instances aspect categories, finally aggregates sentiments key instances get bag-level sentiments aspect categories. Our main contributions summarized follows:"," 	Aspect-category sentiment analysis  aims to predict sentiment polarities of sentences with respect to given aspect categories. To detect the sentiment toward a particular aspect category in a sentence, most previous methods first generate an aspect category-specific sentence representation for the aspect category, then predict the sentiment polarity based on the representation. These methods ignore the fact that the sentiment of an aspect category mentioned in a sentence is an aggregation of the sentiments of the words indicating the aspect category in the sentence, which leads to suboptimal performance. In this paper, we propose a Multi-Instance Multi-Label Learning Network for Aspect-Category sentiment analysis , which treats sentences as bags, words as instances, and the words indicating an aspect category as the key instances of the aspect category. Given a sentence and the aspect categories mentioned in the sentence, AC-MIMLLN first predicts the sentiments of the instances, then finds the key instances for the aspect categories, finally obtains the sentiments of the sentence toward the aspect categories by aggregating the key instance sentiments. Experimental results on three public datasets demonstrate the effectiveness of AC-MIMLLN \footnote{Data and code are available at https://github.com/l294265421/AC-MIMLLN}."
"The recent success language model pre-training approaches~, train language models diverse text corpora self-supervised multi-task learning, brought huge performance improvements several natural language understanding tasks~. The key success ability learn generalizable text embeddings achieve near optimal performance diverse tasks additional steps fine-tuning downstream task. Most existing works language model aim obtain universal language model address nearly entire set available natural language tasks heterogeneous domains. Although train-once use-anywhere approach shown helpful various natural language tasks~, considerable needs adapting learned language models domain-specific corpora . Such domains may contain new entities included common text corpora, may contain small amount labeled data obtaining annotation may require expert knowledge. Some recent works~ suggest pre-train language model self-supervised tasks domain-specific text corpus adaptation, show yields improved performance tasks target domain. Masked Language Models objective BERT~ shown effective language model learn knowledge language bi-directional manner~. In general, masks MLMs sampled random~, seems reasonable learning generic language model pre-trained scratch, since needs learn many words vocabulary possible diverse contexts. However, case pre-training already pre-trained language model, conventional selection method may lead domain adaptation inefficient way, since words equally important target task. Repeatedly learning uninformative instances thus wasteful. Instead, done instance selection, effective masks focus important words target domain, specific NLU task hands. How obtain masking strategy train MLMs? Several works~ propose rule-based masking strategies work better random masking ~ applied language model pre-training scratch. Based works, assume adaptation pre-trained language model improved via learned masking policy selects words mask. Yet, existing models inevitably suboptimal since consider target domain task. To overcome limitation, work, propose adaptively generate mask learning optimal masking policy given task, task-adaptive pre-training~ language model. As described Figure , want pre-train language model specific task task-dependent masking policy, directs solution set parameters better adapt target domain, task-agnostic random policy leads model arbitrary solution. To tackle problem, pose given learning problem meta-learning problem learn task-adaptive mask-generating policy, model learned masking strategy obtains high accuracy target task. We refer meta-learner Neural Mask Generator . Specifically, formulate mask learning bi-level problem pre-train fine-tune target language model inner loop, learn NMG outer loop, solve using renforcement learning. We validate method diverse NLU tasks, including question answering text classification. The results show models trained using NMG outperforms models pre-trained using rule-based masking strategies, well finds proper adaptive masking strategy domain task. Our contribution threefold:"," We propose a method to automatically generate a domain- and task-adaptive maskings of the given text for self-supervised pre-training, such that we can effectively adapt the language model to a particular target task . Specifically, we present a novel reinforcement learning-based framework which learns the masking policy, such that using the generated masks for further pre-training of the target language model helps improve task performance on unseen texts. We use off-policy actor-critic with entropy regularization and experience replay for reinforcement learning, and propose a Transformer-based policy network that can consider the relative importance of words in a given text. We validate our Neural Mask Generator  on several question answering and text classification datasets using BERT and DistilBERT as the language models, on which it outperforms rule-based masking strategies, by automatically learning optimal adaptive maskings. \footnote{Code is available at \url{github.com/Nardien/NMG}.}"
"Sentiment analysis become increasingly popular natural language processing task academia industry. It provides real-time feedback consumer experience needs, helps producers offer better services. To deal presence multiple categories one document, ACSA tasks, including aspect-category sentiment analysis targeted aspect-category sentiment analysis , introduced. The main purpose ACSA task identify sentiment polarity input sentence upon specific predefined categories . For example, shown Table , giving input sentence ``Food always fresh hot-ready eat, expensive."" predefined categories \{food, service, price, ambience anecdotes/miscellaneous\}, sentiment category food positive, polarity regarding category price negative, none others. In task, models capture explicit expressions implicit expressions. For example, phrase ``too expensive"" indicates negative polarity price category, without direct indication ``price"". In order deal ACSA multiple categories multiple targets, TACSA task introduced analyze sentiment polarity set predefined target-category pairs. An example shown Table , given targets ``restaurant-1"" ``restaurant-2"", case ``I like restaurant-1 cheap, restaurant-2 expansive"", category price target ``restaurant-1"" positive, negative target ``restaurant-2"", none target-category pairs. A mathematical definition ACSA given follows: giving sentence input, predefined set targets predefined set aspect categories , model predicts sentiment polarity target-category pair . For ACSA task, one target categories. In paper, order simplify expression TACSA, use predefined categories, short predefined target-category pairs. } \end{table*} Multi-task learning, shared encoders individual decoders category, approach analyze categories one sample simultaneously ACSA . Compared single-task ways , multi-task approaches utilize category-specific knowledge training signals task get better performance. However, current multi-task models still suffer lack features category name . Models category name features encoded model may improve performance. On hand, predefined categories ACSA task make application new categories inflexible, ACSA applications, number categories maybe varied time. For example, fuel consumption, price level, engine power, space source categories analyzed gasoline automotive domain. For electromotive domain, source categories automotive domain still used, new target category battery duration also analyzed. Incremental learning way solve problem. Therefore, necessary propose incremental learning task incremental learning model concerned new category ACSA tasks. Unfortunately, current multi-task learning ACSA models, encoder shared decoders category individual. This parameter sharing mechanism results shared encoder target-category-related decoders finetuned finetuning process, decoder source categories remains unchanged. The finetuned encoder original decoder source categories may cause catastrophic forgetting problem origin categories. For real applications, high accuracy excepted source categories target categories. Based previous researches decoders different tasks usually modeled mean regularization , idea comes make decoders sharing decoders categories decrease catastrophic forgetting problem. But raises another question, identify category encoder decoder shared network? In approach, solve category discrimination problem input category name feature. In paper, proposed multi-task category name embedding network . The multi-task learning framework makes full use training signals categories. To make feasible incremental learning, encoder decoders category shared. The category names applied another input feature task discrimination. We also present new task ACSA incremental learning. In particular, contribution three-folded: We proposed multi-task CNE-net framework encoder decoder shared weaken catastrophic forgetting problem multi-task learning ACSA model. We achieved state-of-the-art two ACSA datasets, SemEval14-Task4 Sentihood. We proposed new task incremental learning ACSA. By sharing encoder layers decoder layers tasks, achieved better results compared baselines source categories target category."," ACSA tasks, including aspect-category sentiment analysis  and  targeted  aspect-category sentiment analysis , aims at identifying sentiment  polarity on predefined categories. Incremental learning on new categories is necessary for ACSA real applications. Though current multi-task learning models achieve good performance in ACSA tasks, they suffer from catastrophic forgetting problems in ACSA incremental learning tasks. In this paper, to make multi-task learning feasible for incremental learning, we proposed Category Name  Embedding network  . We set both encoder and decoder shared among all categories to weaken the catastrophic forgetting problem. Besides the origin input sentence, we applied another input feature, i.e., category name, for task discrimination.  Our model achieved state-of-the-art  on two ACSA benchmark datasets. Furthermore, we proposed  a dataset for ACSA incremental learning and achieved the best performance compared with other strong baselines."
"Conditional random fields shown perform well various sequence labeling tasks. Recent work uses rich neural network architectures define ``unary'' potentials, i.e., terms consider single position's label time~. However, ``binary'' potentials, consider pairs adjacent labels, usually quite simple may consist solely parameter parameter vector unique label transition. Models unary binary potentials generally referred ``first order'' models. A major challenge CRFs complexity training inference, quadratic number output labels first order models grow exponentially higher order dependencies considered. This explains common type CRF used practice first order model, also referred ``linear chain'' CRF. One promising alternative CRFs structured prediction energy networks , use deep neural networks parameterize arbitrary potential functions structured prediction. While SPENs also pose challenges learning inference, \citet{tu-18} proposed way train SPENs jointly ``inference networks'', neural networks trained approximate structured inference. In paper, leverage frameworks SPENs inference networks explore high-order energy functions sequence labeling. Naively instantiating high-order energy terms lead large number parameters learn, instead develop concise neural parameterizations high-order terms. In particular, draw vectorized Kronecker products, convolutional networks, recurrent networks, self-attention. We also consider ``skip-chain'' connections~ various skip distances ways reducing total parameter count increased learnability. Our experimental results four sequence labeling tasks show range high-order energy functions yield performance improvements. While optimal energy function varies task, find strong performance skip-chain terms short skip distances, convolutional networks filters consider label trigrams, recurrent networks self-attention networks consider large subsequences labels. We also demonstrate modeling high-order dependencies lead significant performance improvements setting noisy training test sets. Visualizations high-order energies show various methods capture intuitive structured dependencies among output labels. Throughout, use inference networks share architecture unstructured classifiers sequence labeling, test time inference speeds unchanged local models method. Enlarging inference network architecture adding one layer leads consistently better results, rivaling improving BiLSTM-CRF baseline, suggesting training efficient inference networks high-order energy terms make errors arising approximate inference. While focus sequence labeling paper, results show potential developing high-order structured models NLP tasks future."," Many tasks in natural language processing involve predicting structured outputs, e.g., sequence labeling, semantic role labeling, parsing, and machine translation. Researchers are increasingly applying deep representation learning to these problems, but the structured component of these approaches is usually quite simplistic. In this work, we propose several high-order energy terms to capture complex dependencies among labels in sequence labeling, including several that consider the entire label sequence. We use neural parameterizations for these energy terms, drawing from convolutional, recurrent, and self-attention networks. We use the framework of learning energy-based inference networks for dealing with the difficulties of training and inference with such models. We empirically demonstrate that this approach achieves substantial improvement using a variety of high-order energy terms on four sequence labeling tasks, while having the same decoding speed as simple, local classifiers.  We also find high-order energies to help in noisy data conditions.\footnote{Code  is available at \url{https://github.com/tyliupku/Arbitrary-Order-Infnet}}"
"Long document coreference resolution poses runtime memory challenges. Current best models % coreference resolution large memory requirements quadratic runtime document length~, making impractical long documents. % Recent work revisiting entity-mention paradigm~, seeks maintain explicit representations entities, rather constituent mentions, shown practical benefits memory competitive state-of-the-art models~. In particular, unlike approaches coreference resolution maintain representations mentions corresponding entity clusters~ , entity-mention paradigm stores representations entity clusters, updated incrementally coreference predictions made. While approach requires less memory additionally store mention representations, number entities impractically large processing long documents, making storing entity representations problematic. Is necessary maintain unbounded number mentions entities? Psycholinguistic evidence suggests not, human language processing incremental limited working memory~. In practice, find entities small spread , thus need kept persistently memory. This observation suggests tracking limited, small number entities time resolve computational % issues, albeit potential accuracy tradeoff. Previous work bounded memory models coreference resolution shown potential, tested short documents % . % Moreover, previous work makes token-level predictions standard coreference datasets span-level annotations. % We propose bounded memory model performs quasi-online coreference resolution,"," Long document coreference resolution remains a challenging task	 due to the large memory and runtime requirements of current models. Recent work doing incremental coreference resolution using just the global representation of entities shows practical benefits but requires keeping all entities in memory, which can be impractical for long documents. % We argue that keeping all entities in memory is unnecessary, and we propose a memory-augmented neural network that tracks only a small bounded number of entities at a time, thus guaranteeing a linear runtime in length of document. We show that  the model remains competitive with models with high memory and computational requirements on OntoNotes and LitBank, and  the model learns an efficient memory management strategy easily outperforming a rule-based strategy."
"Since early days NLP, conversational agents designed interact humans language solve diverse tasks, e.g., remote instructions booking assistants . In goal-oriented dialogue setting, conversational agents often designed compose predefined language utterances. Even approaches efficient, also tend narrow agent's language diversity. To remove restriction, recent work exploring interactive word-based training. In setting, agents generally trained two-stage process: Firstly, agent pretrained human-labeled corpus supervised learning generate grammatically reasonable sentences. Secondly, agent finetuned maximize task-completion score interacting user. Due sample-complexity reproducibility issues, user generally replaced game simulator may evolve conversational agent. Unfortunately, pairing may lead language drift phenomenon, conversational agents gradually co-adapt, drift away pretrained natural language. The model thus becomes unfit interact humans. While domain-specific methods exist counter language drift, simple task-agnostic method consists combining interactive supervised training losses pretraining corpus, later formalized Supervised SelfPlay . Inspired language evolution cultural transmission, recent work proposes Seeded Iterated Learning another task-agnostic method counter language drift. SIL modifies training dynamics iteratively refining pretrained student agent imitating interactive agents, illustrated Figure. At iteration, teacher agent created duplicating student agent, finetuned towards task completion. A new dataset generated greedily sampling teacher, samples used refine student supervised learning. The authors empirically show iterated learning procedure induces inductive learning bias successfully maintains language grounding improving task-completion. \vskip -1em \end{figure*} As first contribution, examine performance two methods setting translation game. We show S2P unable maintain high grounding score experiences late-stage collapse, SIL higher negative likelihood evaluated human corpus. We propose combine SIL S2P applying S2P loss interactive stage SIL. We show resulting Supervised Seeded Iterated Learning algorithm manages get best algorithms translation game. Finally, observe late-stage collapse S2P correlated conflicting gradients showing \algo empirically reduces gradient discrepancy."," Language drift has been one of the major obstacles to train language models through interaction. When word-based conversational agents are trained towards completing a task, they tend to invent their language rather than leveraging natural language. In recent literature, two general methods partially counter this phenomenon: Supervised Selfplay  and Seeded Iterated Learning .  While S2P jointly trains interactive and supervised losses to counter the drift, SIL changes the training dynamics to prevent language drift from occurring. In this paper, we first highlight their respective weaknesses, i.e., late-stage training collapses and higher negative likelihood when evaluated on human corpus. Given these observations, we introduce \longalgo~ to combine both methods to minimize their respective weaknesses.  We then show the effectiveness of \algo in the language-drift translation game."
"Advances pretraining language models general-purpose representations pushed state art variety natural language tasks. However, languages enjoy large public datasets pretraining and/or downstream tasks. Multilingual language models mBERT XLM proven effective cross-lingual transfer learning pretraining single shared Transformer model jointly multiple languages. The goals multilingual modeling limited improving language modeling low-resource languages , also include zero-shot cross-lingual transfer downstream tasks---it shown multilingual models generalize target languages even labeled training data available source language wide range tasks . However, multilingual models equally beneficial languages. \citet{conneau2019unsupervised} demonstrated including languages single model improve performance low-resource languages hurt performance high-resource languages. Similarly, recent work multilingual neural machine translation also observed performance degradation high-resource language pairs. In multi-task learning , phenomenon known negative interference negative transfer , training multiple tasks jointly hinders performance individual tasks. % In multilingual language modeling, language single task negative interference pretraining hurt model's generalization individual languages. Despite empirical observations, little prior work analyzed showed mitigate negative interference multilingual language models. Particularly, natural ask: Can negative interference occur low-resource languages also? What factors play important role causing it? Can mitigate negative interference improve model's cross-lingual transferability? In paper, take step towards addressing questions. We pretrain set monolingual bilingual models evaluate range downstream tasks analyze negative interference. We seek individually characterize underlying factors negative interference set ablation studies glean insights causes. Specifically, examine training corpus size language similarity affect negative interference, also measure gradient parameter similarities languages. Our results show negative interference occur high-resource low-resource languages. In particular, observe neither subsampling training corpus adding typologically similar languages substantially impacts negative interference. On hand, show gradient conflicts language-specific parameters exist multilingual models, suggesting languages fighting model capacity, potentially causes negative interference. We test whether explicitly assigning language-specific modules language alleviate negative interference, find resulting model performs better within individual language worse zero-shot cross-lingual tasks. Motivated observations, propose meta-learn language-specific parameters explicitly improve generalization shared parameters languages. Empirically, method improves within-language performance monolingual tasks also cross-lingual transferability zero-shot transfer benchmarks. To best knowledge, first work systematically study remedy negative interference multilingual language models. % Advances pretraining language models % general-purpose representations pushed state-of-the-art variety natural language tasks. % However, languages large amounts training data pretraining and/or downstream tasks. % Multilingual language models mBERT XLM proven effective cross-lingual transfer learning pretraining single shared Transformer model jointly multiple languages. % The goal improve language modeling low-resource languages , also enable zero-shot cross-lingual transfer downstream tasks -- shown multilingual models generalize target languages labeled training data available source language wide range tasks . % However, multilingual models equally beneficial languages. % \citet{conneau2019unsupervised} demonstrated including languages single model improve performance low-resource languages hurt performance high-resource languages. % Similarly, recent work multilingual neural machine translation also observed performance degradation high-resource language pairs. % In multi-task learning , phenomenon known negative interference negative transfer , % training multiple tasks jointly hinders performance individual tasks. % % In multilingual language modeling, language single task negative interference pretraining hurt model's generalization individual languages. % Despite empirical observations, little prior work analyzed showed mitigate negative interference multilingual language models. % Particularly, natural ask: % Can negative interference occur low-resource languages also? % What factors play important role causing it? % Can mitigate negative interference improve model's cross-lingual transferability? % In paper, take step towards addressing questions. % We pretrain set monolingual bilingual models, evaluate range downstream tasks analyze negative interference. % We seek individually characterize underlying factors negative interference set ablation studies glean insights causes. % Specifically, examine training corpus size language similarity affect negative interference, also measure gradient parameter similarities languages. % Our results show negative interference occur high-resource low-resource languages. % In particular, observe subsampling training corpus adding typologically similar languages little impact negative interference. % On hand, show gradient conflicts language-specific parameters exist multilingual models, suggesting languages fighting model capacity potentially causes negative interference. % Thus, test whether explicitly assigning language-specific modules language alleviate negative interference. % To surprise, model performs better within individual language worse zero-shot cross-lingual tasks. % Motivated observations, propose meta-learn language-specific parameters explicitly improve generalization shared parameters languages. % Empirically, method improves within-language performance monolingual tasks also cross-lingual transferability zero-shot transfer benchmarks. % To best knowledge, first work systematically study treat negative interference multilingual language models."," Modern multilingual models are trained on concatenated text  from multiple languages in hopes of conferring benefits to each , with the most pronounced benefits accruing to low-resource languages. However, recent work has shown that this approach can degrade  performance on high-resource languages,  a phenomenon known as negative interference. In this paper, we present the first systematic study of negative interference. We show that, contrary to previous belief,  negative interference  also impacts low-resource languages. While parameters are maximally shared to learn language-universal structures,  we demonstrate that language-specific parameters do exist in multilingual models and they are a potential cause of negative interference. Motivated by these observations,  we also present a meta-learning algorithm that obtains  better cross-lingual transferability  and alleviates negative interference,  by adding language-specific layers as meta-parameters  and training them in a manner that explicitly improves  shared layers' generalization on all languages. Overall, our results show that negative interference  is more common than previously known,  suggesting new directions for improving multilingual representations.\footnote{Source code is available at \url{https://github.com/iedwardwangi/MetaAdapter}.} %  % State-of-the-art multilingual models are trained on concatenated text from multiple languages to enable positive cross-lingual transfer, especially from high-resource languages to low-resource languages. % However, recent work found that such a training paradigm can degrade the model's performance on high-resource languages too, a phenomenon known as negative interference. % In this paper, we present the first systematic study of negative interference. % We show that, contrary to what was previously hypothesized, negative interference is not exclusive to high-resource but can also occur in low-resource settings. % In addition, despite that parameters are shared with the goal to learn language-universal structures, we demonstrate that language-specific parameters in multilingual models are a potential cause of negative interference. % Motivated by these observations, we show that we can obtain better cross-lingual transferability and alleviate negative interference through a meta-learning algorithm, which considers language-specific layers as meta parameters and trains them in the manner that explicitly improves the generalization of shared parameters across all languages. % Overall, our results show that negative interference occurs more commonly than previously believed and suggest a new direction towards improving multilingual representations by resolving language conflicts.\footnote{Code will be released upon publication.}"
"Event argument extraction aims identify entities serve arguments event classify specific roles play. As Fig., ``two soldiers'' ``yesterday'' arguments, event triggers ``attacked'' ``injured'' . For trigger ``attacked'', ``two soldiers'' plays argument role Target ``yesterday'' plays argument role Attack\_Time. For event trigger ``injured'', ``two soldiers'' ``yesterday'' play role Victim INJURY\_Time, respectively. There significant work event extraction , EAE task remains challenge become bottleneck improving overall performance EE.\footnote{EAE similarities semantic role labeling. Event triggers comparable predicates SRL roles SRL datasets standard convention interpreting whom. EAE custom taxonomy roles domain. We also use inspiration SRL body work .} Supervised data EAE expensive hence scarce. One possible solution use available resources like unlabeled data. For that, We use BERT model encoder leverages much larger unannotated corpus semantic information captured. Unlike%previous studies ~ added final/prediction layer BERT argument extraction, use BERT token embedder build sequence EAE task-specific components . We use in-domain data adapt BERT model parameters subsequent pretraining step . This makes encoder domain-aware. We perform self-training construct auto-labeled data . A crucial aspect EAE integrate event trigger information learned representations. This important arguments dependent triggers, i.e., argument span plays completely different roles toward different triggers. An example shown Fig., ``two soldiers'' plays role Target event ATTACK role Victim INJURY. Different existing work relies regular sequence encoders, design novel trigger-aware encoder simultaneously learns four different types trigger-informed sequence representations. %for candidate arguments. Capturing long-range dependency another important factor, e.g., connection event trigger distant argument. Syntactic information could useful case, could help bridge gap word another distant highly related word. We modify Transformer explicitly incorporating syntax via attention layer driven dependency parse sequence. % . %Since arguments event entities, entity mentions effective hints. We design role-specific argument decoder seamlessly accommodate settings . We also tackle role overlap problem using set classifiers taggers decoder. Our model achieves new state-of-the-art ACE2005 Events data.% EAE. % % Motivation 1: data scarcity. Proposed used solutions: pretrained model BERT External embedding Self-training BERT MLM MLM encoder decoder joint pre-training. Teacher-Student %"," Event argument extraction  aims to identify the arguments of an event and classify the roles that those arguments play. Despite great efforts made in prior work, there remain many challenges:  Data scarcity.  Capturing the long-range dependency, specifically, the connection between an event trigger and a distant event argument.  Integrating event trigger information into candidate argument representation. For , we explore using unlabeled data in different ways. For , we propose to use a syntax-attending Transformer that can utilize dependency parses to guide the attention mechanism. For , we propose a trigger-aware sequence encoder with several types of trigger-dependent sequence representations. We also support argument extraction either from text annotated with gold entities or from plain text. Experiments on the English ACE2005 benchmark show that our approach achieves a new state-of-the-art."
"In current NLP tasks, fixed-length vector representations words, word embeddings, used represent form meaning word. In case humans, however, oftentimes use sequence words known definition ---a statement meaning term--- express meanings terms . It mind question ``Can machines define?'' aimed answered task definition modeling . Definition modeling framed task conditional generation, definition word phrase generated given conditioning variable word's associated word embedding representations context. Current approaches task mainly encoder-decoder based, one encodes contextual representation word/phrase using variety features context character composition, uses contextual representation generate definition . % discuss issues approaches including Despite relative success existing approaches definition modelling, discriminative nature ---where distributional-derived information one end model lexical information other--- limits power underlying semantic representations distributional lexical information learned implicit rather direct way. For example, although \citet{ishiwatari-etal-2019-learning} successfully showed local global contexts useful disambiguate meanings phrases certain cases, approach heavily relies attention mechanism identify semantic alignments input phrase output definition, may introduce noise ultimately insufficient capture entire meaning phrase-definition pair. % latent definition space To tackle issue, propose explicitly model underlying semantics phrase-definition pairs introducing continuous latent variable definition space, used conjunction guide generation definition . The introduction latent representation enables us treat global defining signal generation process, complementing existing alignment mechanisms attention. % We specifically incorporate latent variable directly decoder cell, showing addition latent variable way leads increased performance task. Although latent definition variable enables us explicitly model underlying semantics context-definition pairs, incorporation task renders posterior intractable. In paper recur variational inference estimate intractable posterior, effectively making model Conditional Variational Autoencoder evolving generation process . %to serve global decoding signal allows decoder rely attention, attention misleading rely latent variable % issue misleading attentions exacerbated noisy datasets, see improvements well generator learns misleading attention representations. % EDISON % enables us generate definitions previously unknown words phrases, menas example , also obtain semantically meaningful vectors new words means providing definition alongside example usage. Effectively, mode able mapping inputs smooth space/manifold?. We also note existing approaches definition modelling heavily rely word embeddings, due fixed nature capture much semantics, known offer limited capabilities dealing polysemy. Considering success pretrained deep contextualized word representations specifically addressing limitations shown improve performance variety downstream NLP tasks , paper propose mechanism integrate deep contextualized word representations definition modelling task. Specifically, successfully leverage BERT contextual encoder definition encoder produce representations respectively. %While inclusion deep contextual word representations important approach, resuts show essential . %As result, model able allowing meaningful continuous latent space, . [2-3 sentences] Finally, develop two new datasets task, one derived Cambridge Dictionary , derived Le Petit Robert. In summary, contributions are: Datasets pre-trained models publicly released greater NLP community help facilitate advances task upon acceptance paper.","     %Definition modeling, the task of generating word/phrase definitions, is the task that aims to answer ``Can machines define?'' In this paper, we aim to tackle this problem by introducing a continuous latent variable to explicitly model the underlying relationship between a phrase used within a context and its definition. Additionally, we release 2 new datasets, Cambridge and the first non-English dataset Robert. On most datasets, our Variational Contextual Definition Modeler  achieves a new state-of-the-art, outperforming existing systems as well as a new BERT-based baseline. In this paper we tackle the task of definition modeling, where the goal is to learn to generate definitions of words and phrases. Existing approaches for this task are discriminative, combining distributional and lexical semantics in an implicit rather than direct way. To tackle this issue we propose a generative model for the task, introducing a continuous latent variable to explicitly model the underlying relationship between a phrase used within a context and its definition. We rely on variational inference for estimation and leverage contextualized word embeddings for improved performance. Our approach is evaluated on four existing challenging benchmarks with the addition of two new datasets, Cambridge and the first non-English corpus Robert, which we release to complement our empirical study. Our Variational Contextual Definition Modeler  achieves state-of-the-art performance in terms of automatic and human evaluation metrics, demonstrating the effectiveness of our approach.\footnote{We release the code at: \url{https://github.com/machelreid/vcdm}}"
"Topic segmentation fundamental NLP task received considerable attention recent years . It reveal important aspects document semantic structure splitting document topical-coherent textual units. Taking Wikipedia article Table example, without section marks, reliable topic segmenter able detect correct boundaries within text chunk article topical-coherent units , . The results topic segmentation benefit key downstream NLP tasks document summarization , question answering , machine reading dialogue modeling . } A Wikipedia sample article City Marcus covering three topics: , } \end{table} A wide variety techniques proposed topic segmentation. Early unsupervised models exploit word statistic overlaps , Bayesian contexts %the semantic relatedness graphs measure lexical semantic cohesion sentences paragraphs infer segment boundaries them. More recently, several works framed topic segmentation neural supervised learning, remarkable success achieved models NLP tasks . %While one line research forms topic segmentation sequence labeling problem builds neural models predict segment boundaries directly ; %another line works first trains neural models tasks , uses models' outputs predict boundaries . Despite %the minor architectural differences, neural solutions adopt Recurrent Neural Network variants main framework. On one hand, RNNs appropriate topic segmentation modelled sequence labeling task sentence either end segment not. On hand, choice makes neural models limited model context. Because sophisticated RNNs able preserve long-distance information , largely help language models. But topic segmentation, critical supervise model focus local context. %In fact, RNNs superior many NLP tasks due capability preserving long-distance information . %However, topic segmentation, also critical supervise model learn right information local context. As illustrated Table, prediction segment boundary hardly depends content . Bringing excessive long-distance signals may cause unnecessary noise %further hurt %model's performance. Moreover, text coherence strong relation topic segmentation . For instance, Table, sentence pairs segment %should coherent %to put together sentence pairs across segments . Arguably, proper way modeling coherence adjacent sentences, topic segmenter enhanced. %\textcolor{red}{We hypothesize topic segment prediction rely local contextual information way cannot effectively captured RNNs.} %\textcolor{red}{In essence, RNNs able model long short-distance dependencies implicitly.} %However, restricted self-attention, model pay attention local context neighboring sentences explicitly constrained way . %In essence, local contextual information critical predicting topical boundaries, simple Recurrent Neural Network variants arguably sufficiently powerful represent necessary information. %However, approaches still face challenge insufficient context modeling. Topic segment boundary prediction usually heavily relies local contextual information. Hence, effectively select local contexts model relations contexts becomes important. Neural models like RNN variants represent state timestep memorizing forgetting information previous later contexts. But learned contextual information contribute model's decision straightforward sufficiently transparent. In paper, propose enhance state-of-the-art topic segmenter based hierarchical attention BiLSTM network better model local context sentence two complementary ways. First, add coherence-related auxiliary task make model learn informative hidden states sentences document. %More specifically, refine objective model encourage coherence sentences different segments smaller coherence sentences segment. More specifically, refine objective model encourage smaller coherence sentences different segments larger coherence sentences segment. Secondly, enhance context modeling utilizing restricted self-attention , enables model pay attention local context make better use information closer neighbors sentence . Our empirical results show proposed context modeling strategy significantly improves performance SOTA neural segmenter three datasets, enhanced segmenter robust domain transfer setting applied four challenging real-world test sets, sampled differently training data, context modeling strategy also effective segmenters trained challenging languages , rather English.","      Topic segmentation is critical %, the process of splitting a document into topic-coherent pieces,      %plays a vital role      in key NLP tasks and recent works favor highly effective neural supervised  approaches.     %Due to the high effectiveness of neural models, more recent works have favored framing topic segmentation as a neural-based supervised learning problem.     However, current neural solutions are arguably limited in how they model context.     %topic segmenters proposed so far are still limited by the insufficient context modeling.      In this paper, we enhance a segmenter based on a hierarchical attention BiLSTM network to better model context, by adding a coherence-related auxiliary task and restricted self-attention. Our optimized segmenter\footnote{Our code will be publicly available at \url{www.cs.ubc.ca/cs-research/lci/research-groups/natural-language-processing/}} outperforms SOTA approaches when trained and tested on three datasets. We also the robustness of our proposed model in domain transfer setting by training a model on a large-scale dataset and testing it on four challenging real-world benchmarks. Furthermore, we apply our proposed strategy to two other languages , and show its effectiveness in multilingual scenarios."
"Deep learning techniques, including contextualized word embeddings based transformers pretrained language modelling, resulted considerable improvements many NLP tasks. However, often require large amounts labeled training data, also growing evidence transferring approaches high low-resource settings straightforward. In , rule-based linguistically motivated CRFs still outperform RNN-based methods several tasks South African languages. For pretraining approaches labeled data exists high-resource language, information transferred low-resource language, \citet{data/Xtreme20} find significant gap performance English cross-lingually transferred models. In recent study, \citet{lowresource/Lauscher2020FromZTH} find transfer multilingual transformer models less effective resource-lean settings distant languages. A popular technique obtain labeled data quickly cheaply distant weak supervision. \citet{lowresource/kann20weakly} recently inspected POS classifiers trained weak supervision. They found contrast scenarios simulated low-resource settings high-resource languages, truly low-resource settings still difficult problem. These findings also highlight importance aiming realistic experiments studying low-resource scenarios. In work, analyse multilingual transformer models, namely mBERT XLM-RoBERTa . We evaluate sequence token classification tasks form news title topic classification named entity recognition . A variety approaches proposed improve performance low-resource settings. In work, study transfer learning high-resource language distant supervision. We selected two popular techniques recent literature rather independent specific model architecture. Both need auxiliary data. For transfer learning, labeled data high-resource language, distant supervision, expert insight mechanism automatically generate labels. We see them, therefore, orthogonal depending scenario data availability, either one approach might applicable. Our study performed three, linguistically different African languages: Hausa, isiXhosa \yoruba. These represent languages millions users active use digital infrastructure, limited support NLP technologies. For aim, also collected three new datasets made publicly available alongside code additional material. We show challenges opportunities working multilingual transformer models evaluating trends different levels resource scarcity. The paper structured following questions interested in:"," Multilingual transformer models like mBERT and XLM-RoBERTa have obtained great improvements for many NLP tasks on a variety of languages. However, recent works also showed that results from high-resource languages could not be easily transferred to realistic, low-resource scenarios. In this work, we study trends in performance for different amounts of available resources for the three African languages Hausa, isiXhosa and \yoruba on both NER and topic classification. We show that in combination with transfer learning or distant supervision, these models can achieve with as little as 10 or 100 labeled sentences the same performance as baselines with much more supervised training data. However, we also find settings where this does not hold. Our discussions and additional experiments on assumptions such as time and hardware restrictions highlight challenges and opportunities in low-resource learning."
"In computer vision, zero shot-learning image classification problem classifying images given auxiliary information. An image classification model trained classify images pre-defined set classes. At test time, images new classes given, task transfer knowledge learned seen classes training unseen test classes. A common setup ZSL assumes auxiliary information set semantically meaningful properties describing class . A different ZSL setup uses image captions auxiliary information . Typically, auxiliary information manually collected human raters image averaged across images. A realistic approach relies available online text descriptions classes . It avoids expensive annotation exposure test images. In work, classify bird species according Wikipedia descriptions. This task raises many challenges: Differences birds small, makes fine-grained classification task; This expert task, text contains terminology unlikely familiar layman; and, top The text descriptions classes long, containing visually relevant sentences. As opposed previous work text-based ZSL employing textual descriptions focused visual modality, focus text modality, address key question ZSL: \textit {How identify text components visual nature?} To get intuition task setup proposed solution, consider following situation. Imagine never seen zebra seen horse. What given text describing zebra: \enquote{Zebras hooves, mane, tail, pointed ears, white black stripes}. This description would probably close description horse \enquote{hooves, mane, tail, pointed ears} would probably looking image reminds horse \enquote{white black stripes}. So, even without ever seeing zebra, using text-descriptions zebra knowledge already acquired horses, one correctly classify unknown classes like zebra. Our proposed solution two-phases. First, based intuition similar objects tend similar texts, encode similarity feature enhances text descriptions' separability. In addition, leverage intuition differences text descriptions species would salient visual features, extract visually relevant descriptions text. Our experiments empirically demonstrate efficacy generalization capacity proposed solution. On two large ZSL datasets, easy hard scenarios, similarity method obtains ratio improvement 18.3\%. With addition extracting visually relevant descriptions, obtain ratio improvement 48.16\% state-of-the-art. We show visual-summarization method generalizes CUB dataset NAB dataset , demonstrate contribution additional models ratio improvement 59.62\%. The contributions paper threefold. First, best knowledge, first showcase critical importance text representation zero-shot image-recognition scenarios, present two concrete text-based processing methods vastly improve results. Second, demonstrate efficacy generalizability proposed methods applying zero-shot generalized zero-shot tasks, outperforming previously reported results CUB NAB Benchmarks. Finally, show visual aspects learned one dataset transferred effectively another dataset without need obtain dataset-specific captions. The efficacy proposed solution benchmarks illustrates purposefully exposing visual features texts indispensable tasks learn align vision-and-language modalities.","    We study the problem of recognizing visual entities from the textual descriptions of their classes. Specifically, given birds' images with free-text descriptions of their species, we learn to classify images of previously-unseen species based on specie descriptions. This setup has been studied in the vision community under the name zero-shot learning from text, focusing on learning to transfer knowledge about visual aspects of birds from seen classes to previously-unseen ones. Here, we suggest focusing on the textual description and distilling from the description the most relevant information to effectively match visual features to the parts of the text that discuss them.  Specifically,  we propose to leverage the similarity between species, reflected in the similarity between text descriptions of the species.  we derive visual summaries of the texts, i.e.,  extractive summaries that focus on the visual features that tend to be reflected in images. We propose a simple attention-based model augmented with the similarity and visual summaries components. Our empirical results consistently and significantly outperform the state-of-the-art on the largest benchmarks for text-based zero-shot learning, illustrating the critical importance of texts for zero-shot image-recognition."
"Natural Language Understanding evaluation plays key role benchmarking progress natural language processing research. With recent advance language representative learning, results previous benchmarks rapidly saturated. This leads explosion difficult, diverse proposals tasks/datasets NLU evaluation, including Natural Language Inference , Grounded Commonsense Inference, Commonsense QA, Social Interactions Reasoning, Abductive Commonsense Reasoning , etc. One common practice followed recent works simplify evaluation various reasoning abilities classification task. This analogous asking objective questions human educational testing. This simplification facilitates data annotation also gives interpretable evaluation results, based behaviors models studied weaknesses diagnosed. Despite straightforwardness formalization, one assumption behind prior benchmark data sourcing exists single prescriptive ground truth label example. The assumption might true human educational settings prescriptivism preferred descriptivism goal test humans well-defined knowledge norms. However, true many NLP tasks due pragmatic nature meaning sentence might differ depending context background knowledge. Specifically NLI task, \citet{manning2006local} advocate annotation tasks ``natural'' untrained annotators, role NLP model inferences humans make practical settings. Previous work uses graded labeling schema NLI, showed inherent disagreements inference tasks. All discussions challenge commonly used majority ``gold-label'' practice prior data collections evaluations. Intuitively, disagreements among humans allowed different annotators might different subjective views world might think differently encounter reasoning task. Thus, descriptive perspective, evaluating capacity NLP models predicting individual human opinions majority human opinion, also overall distribution human judgments provides representative comparison model capabilities `collective' human intelligence. Therefore, collect ChaosNLI, large set Collective HumAn OpinionS examples several existing NLI datasets, comprehensively examine factor human agreement state-of-the-art model performances. Specifically, contributions are: The ChaosNLI dataset experimental scripts available \url{https://github.com/easonnie/ChaosNLI}"," Despite the subjective nature of many NLP tasks, most NLU evaluations have focused on using the majority label with presumably high agreement as the ground truth. Less attention has been paid to the distribution of human opinions. We collect ChaosNLI, a dataset with a total of 464,500 annotations to study Collective HumAn OpinionS in oft-used NLI evaluation sets. This dataset is created by collecting 100 annotations per example for 3,113 examples in SNLI and MNLI and 1,532 examples in \abdnli. Analysis reveals that:  high human disagreement exists in a noticeable amount of examples in these datasets;  the state-of-the-art models lack the ability to recover the distribution over human labels;   models achieve near-perfect accuracy on the subset of data with a high level of human agreement, whereas they can barely beat a random guess on the data with low levels of human agreement, which compose most of the common errors made by state-of-the-art models on the evaluation sets. This questions the validity of improving model performance on old metrics for the low-agreement part of evaluation datasets. Hence, we argue for a detailed examination of human agreement in future data collection efforts, and evaluating model outputs against the distribution over collective human opinions.\footnote{The ChaosNLI dataset and experimental scripts are available at \url{https://github.com/easonnie/ChaosNLI}}"
"Due growing number Internet users, cyber-violence emerged offensive language pervasive across social media. With anonymity 閳ユ笡rivilege閳, netizens hide behind screens, behaving manner would otherwise reality. Thus, government organizations, online communities, technology companies striving ways detect aggressive language social media help build friendly online environment. Manual filtering time consuming cause post-traumatic stress disorder-like symptoms human annotators. One common strategies tackle problem train systems capable recognizing offensive content, deleted set aside human moderation. SemEval 2020 Task-12 second edition OffensEval . In competition, organizers offers 5 languages datasets including Arabic , Danish , English , Turkish Greek . In Sub-task A, participants need predict whether post uses offensives language. Besides, organizers provide two sub-tasks mainly focus English, predict type target offensive language. Participating 3 Sub-tasks, proposed several methods based pre-training language models including ERNIE XLM-R. In Sub-task A, scored 0.9199, 0.851, 0.8258, 0.802, 0.8989 English, Greek, Turkish, Danish Arabic respectively. We ranked first average F1 scores, ranked top three across languages. In Sub-task B Sub-task C, also took first place 0.7462 0.7145. In following sections, elaborate methods, dataset experiments system.","   This paper describes Galileo闁炽儲鐛 performance in SemEval-2020 Task 12 on detecting and categorizing offensive language in social media. For Offensive Language Identification, we proposed a multi-lingual method using Pre-trained Language Models, ERNIE and XLM-R. For offensive language categorization, we proposed a knowledge distillation method trained on soft labels generated by several supervised models. Our team participated in all three sub-tasks. In Sub-task A - Offensive Language Identification, we ranked first in terms of average F1 scores in all languages. We are also the only team which ranked among the top three across all languages.  We also took the first place in Sub-task B - Automatic Categorization of Offense Types and Sub-task C - Offence Target Identification."
"Understanding reasoning natural language plays significant role artificial intelligence tasks Machine Reading Comprehension Question Answering . Several QA tasks proposed recent years evaluate language understanding capabilities machines . These tasks single-hop QA tasks consider answering question given one single paragraph. % The drawback single-hop QA tasks lack evaluating deep reasoning capability. % We observe many existing neural models achieve promising performance without reasoning. Many existing neural models rely learning context type-matching heuristics. Those rarely build reasoning modules achieve promising performance single-hop QA tasks. The main reason single-hop QA tasks lacking realistic evaluation reasoning capabilities require complex reasoning. Recently multi-hop QA tasks, HotpotQA WikiHop, proposed assess multi-hop reasoning ability. HotpotQA task provides annotations evaluate document level question answering finding supporting facts. Providing supervision supporting facts improves explainabilty predicted answer clarify cross paragraph reasoning path. Due requirement multi-hop reasoning multiple documents strong distraction, multi-hop QA tasks challenging. Figure shows example HotpotQA. Given question 10 paragraphs, paragraph paragraph relevant. The second sentence paragraph first sentence paragraph supporting facts. The answer ``Geelong Football Club''. Primary studies HotpotQA task prefer use reading comprehension neural model. First, use neural retriever model find relevant paragraphs question. After that, neural reader model applied selected paragraphs answer prediction. Although approaches obtain promising results, performance evaluating multi-hop reasoning capability unsatisfactory. To solve multi-hop reasoning problem, models tried construct entity graph using Spacy Stanford CoreNLP applied graph model infer entity path question answer. However, models ignore importance semantic structure sentences edge information entity types entity graph. To take in-depth semantic roles semantic edges words account use semantic role labeling graph backbone graph convolutional network. Semantic role labeling provides semantic structure sentence terms argument-predicate relationships. % ``who whom.'' The argument-predicate relationship graph significantly improve multi-hop reasoning results. Our experiments show SRL effective finding cross paragraph reasoning path answering question. Our proposed semantic role labeling graph reasoning network jointly learns find cross paragraph reasoning paths answers questions multi-hop QA. In SRLGRN model, firstly, train paragraph selection module retrieve gold documents minimize distractor. Second, build heterogeneous document-level graph contains sentences nodes , % sentence nodes include SRL sub-graphs including semantic role labeling arguments nodes predicates edges. Third, train graph encoder obtain graph node representations incorporate argument types semantics predicate edges learned representations. Finally, jointly train multi-hop supporting fact prediction module finds cross paragraph reasoning path, answer prediction module obtains final answer. Notice supporting fact prediction answer prediction based contextual semantics graph representations well token-level BERT pre-trained representations. The contributions work follows: {\bf 1)} We propose SRLGRN framework considers semantic structure sentences building reasoning graph network. Not semantics roles nodes also semantics edges exploited model. {\bf 2)} We evaluate analyse reasoning capabilities semantic role labeling graph compared usual entity graphs. %We analyze multi-hop reasoning capacity HotpotQA task. The fine-grained semantics SRL graph help finding answer explainability reasoning path. {\bf 3)} Our proposed model obtains competitive results HotpotQA SQuAD benchmarks."," This work deals with the challenge of learning and reasoning over multi-hop question answering . We propose a graph reasoning network based on the semantic structure of the sentences to learn cross paragraph reasoning paths and find the supporting facts and the answer jointly. The proposed graph is a heterogeneous document-level graph that contains nodes of type sentence , and semantic role labeling sub-graphs per sentence that contain arguments as nodes and predicates as edges. Incorporating the argument types, the argument phrases, and the semantics of the edges originated from SRL predicates into the graph encoder helps in finding and also the explainability of the reasoning paths. Our proposed approach shows competitive performance on the HotpotQA distractor setting benchmark compared to the recent state-of-the-art models."
"The organizers 2020 VarDial Evaluation Campaign proposed shared task targeted towards geolocation short texts, e.g.~tweets, namely Social Media Variety Geolocation task. Typically formulated double regression problem, task predicting location, expressed latitude longitude, text received input posted certain social media platform. Twitter Jodel platforms used data collection, divided language area three subtasks, namely: In paper, focus second subtask, SMG-CH, proposing variety handcrafted deep learning models, well ensemble model combines previous models meta-learning. Our first model Support Vector Regression classifier based string kernels, known perform well dialect identification tasks . Our second model character-level convolutional neural network , also known provide good results dialect identification . Due high popularity outstanding results Bidirectional Encoder Representations Transformers solving mainstream NLP tasks, decided try Long Short-Term Memory network based German BERT embeddings third model. Lastly, combine three models ensemble employs Extreme Gradient Boosting meta-learner. We conducted experiments development set provided organizers, order decide models choose three submissions SMG-CH subtask. Our results indicate ensemble model attains best results. Perhaps surprisingly, shallow approach based string kernels outperforms deep learning models. Our observations consistent across development test sets provided organizers. % We experimented Machine Learning algorithms second subtask, namely CH, % Geolocation framed double regression task, sophisticated model architectures proposed . % Jodel mobile chat application lets people anonymously talk users within 10km-radius around them. % All three subtasks use data format evaluation methodology, participants encouraged submit systems subtasks. The rest paper organized follows. We present related work dialect identification geolocation short texts Section. Our approaches described detail Section. We present experiments empirical results Section. Finally, conclusions drawn Section."," In this work, we introduce the methods proposed by the UnibucKernel team in solving the Social Media Variety Geolocation task featured in the 2020 VarDial Evaluation Campaign. We address only the second subtask, which targets a data set composed of nearly 30 thousand Swiss German Jodels. The dialect identification task is about accurately predicting the latitude and longitude of test samples. We frame the task as a double regression problem, employing a variety of machine learning approaches to predict both latitude and longitude. From simple models for regression, such as Support Vector Regression, to deep neural networks, such as Long Short-Term Memory networks and character-level convolutional neural networks, and, finally, to ensemble models based on meta-learners, such as XGBoost, our interest is focused on approaching the problem from a few different perspectives, in an attempt to minimize the prediction error. With the same goal in mind, we also considered many types of features, from high-level features, such as BERT embeddings, to low-level features, such as characters n-grams, which are known to provide good results in dialect identification. Our empirical results indicate that the handcrafted model based on string kernels outperforms the deep learning approaches. Nevertheless, our best performance is given by the ensemble model that combines both handcrafted and deep learning models."
"Comparing contrasting meaning text conveyed different languages fundamental nlp task. It used curate clean parallel corpora downstream tasks machine translation~, cross-lingual transfer learning, semantic modeling~, also useful directly analyze multilingual corpora. For instance, detecting commonalities divergences sentences drawn English French Wikipedia articles topic would help analyze language bias~, mitigate differences coverage usage across languages~. This requires detecting coarse content mismatches, also fine-grained differences sentences overlap content. Consider following English French sentences, sampled WikiMatrix parallel corpus. While share important content, highlighted words convey meaning missing language: We show explicitly considering diverse types semantic divergences bilingual text benefits annotation prediction cross-lingual semantic divergences. We create release Rationalized English-French Semantic Divergences corpus , based novel divergence annotation protocol exploits rationales improve annotator agreement. We introduce \modelname, bert-based model detects fine-grained semantic divergences without supervision learning rank synthetic divergences varying granularity. Experiments \dataset show model distinguishes semantically equivalent divergent examples much better strong sentence similarity baseline unsupervised token-level divergence tagging offers promise refine distinctions among divergent instances. We make code data publicly available.\footnote{Implementations \modelname found at: \url{https://github.com/Elbria/xling-SemDiv}; \dataset dataset hosted at: \url{https://github.com/Elbria/xling-SemDiv/tree/master/REFreSD}.}","  Detecting fine-grained differences in content conveyed in different languages matters for cross-lingual nlp and multilingual corpora analysis, but it is a challenging machine learning problem since annotation is expensive and hard to scale.~This work improves the prediction and annotation of fine-grained semantic divergences.~We introduce a training strategy for multilingual bert models by learning to rank synthetic divergent examples of varying granularity.~We evaluate our models on the~Rationalized~English-French~Semantic~Divergences, a new dataset released with this work, consisting of English-French sentence-pairs annotated with semantic divergence classes and token-level rationales.~Learning to rank helps detect fine-grained sentence-level divergences more accurately than a strong sentence-level similarity model, while token-level predictions have the potential of further distinguishing between coarse and fine-grained divergences."
"There variety successful summarization applications afford large number annotated examples sufficient meet requirement end-to-end neural abstractive summarization. Examples range summarizing radiology reports congressional bills meeting conversations. The lack annotated resources suggests end-to-end systems may ``one-size-fits-all'' solution neural text summarization. There increasing need develop cascaded architectures allow customized content selectors combined general-purpose neural text generators realize full potential neural abstractive summarization. We advocate explicit content selection allows rigorous evaluation visualization intermediate results module, rather associating text generation. Existing neural abstractive systems perform content selection implicitly using end-to-end models, explicitly, external module select important sentences words aid generation. However, content selection concerns selection important segments document, also cohesiveness selected segments amount text selected order neural text generator produce summary. In paper, aim investigate feasibility cascade approach neural text summarization. We explore constrained summarization task, abstract created one sentence time cascaded pipeline. Our pipeline architecture chooses one two sentences source document, highlights summary-worthy segments uses basis composing summary sentence. When pair sentences selected, important ensure fusible---there exists cohesive devices tie two sentences together coherent text---to avoid generating nonsensical outputs. Highlighting sentence segments allows us perform fine-grained content selection guides neural text generator stitch selected segments coherent sentence. The contributions work summarized follows.","  We present an empirical study in favor of a cascade architecture to neural text summarization. Summarization practices vary widely but few other than news summarization can provide a sufficient amount of training data enough to meet the requirement of end-to-end neural abstractive systems which perform content selection and surface realization jointly to generate abstracts.  Such systems also pose a challenge to summarization evaluation, as they force content selection to be evaluated along with text generation, yet evaluation of the latter remains an unsolved problem. In this paper, we present empirical results showing that the performance of a cascaded pipeline that separately identifies important content pieces and stitches them together into a coherent text is comparable to or outranks that of end-to-end systems, whereas a pipeline architecture allows for flexible content selection. We finally discuss how we can take advantage of a cascaded pipeline in neural text summarization and shed light on important directions for future research."
"A renewed emphasis must placed sentence fusion context neural abstractive summarization. A majority systems trained end-to-end, abstractive summarizer rewarded generating summaries contain words human abstracts, measured automatic metrics ROUGE. A summarizer, however, rewarded correctly fusing sentences. In fact, examined closely, sentences system abstracts generated fusion. For instance, 6\% summary sentences generated Pointer-Gen fusion, whereas human abstracts contain 32\% fusion sentences. Moreover, sentences generated fusion prone errors. They ungrammatical, nonsensical, otherwise ill-formed. There thus urgent need develop neural abstractive summarizers fuse sentences properly. The importance sentence fusion long recognized community era neural text summarization. The pioneering work Barzilay et al.~\shortcite{barzilay-etal-1999-information} introduces information fusion algorithm combines similar elements across related text generate succinct summary. Later work, as, builds dependency word graph combining syntactic trees similar sentences, employs integer linear programming decode summary sentence graph. Most studies assumed set similar sentences input, fusion necessary reduce repetition. Nonetheless, humans limit combine similar sentences. In paper, pay particular attention fuse disparate sentences contain fundamentally different content remain related make fusion sensible. In Figure, provide example sentence fusion instance. We address challenge fusing disparate sentences enhancing Transformer architecture points correspondence sentences, devices tie two sentences together coherent text. The task sentence fusion involves choosing content sentence weaving content pieces together output sentence linguistically plausible semantically truthful original input. It distinct from~\citet{geva-etal-2019-discofuse} connect two sentences discourse markers. Our contributions follows.","  The ability to fuse sentences is highly attractive for summarization systems because it is an essential step to produce succinct abstracts. However, to date, summarizers can fail on fusing sentences. They tend to produce few summary sentences by fusion or generate incorrect fusions that lead the summary to fail to retain the original meaning.  In this paper, we explore the ability of Transformers to fuse sentences and propose novel algorithms to enhance their ability to perform sentence fusion by leveraging the knowledge of points of correspondence between sentences. Through extensive experiments, we investigate the effects of different design choices on Transformer's performance. Our findings highlight the importance of modeling points of correspondence between sentences for effective sentence fusion."
"The recent advances neural machine translation provided research community commercial landscape effective translation models times achieve near-human performance. However, usually holds phrase sentence level. When using models larger units text, paragraphs documents, quality translation may drop considerably terms discourse attributes lexical stylistic consistency. In fact, document-level translation still open challenging problem. The sentences make document unrelated pieces text predicted independently; rather, set sequences linked together complex underlying linguistics aspects, also known discourse . The discourse document includes several properties grammatical cohesion , lexical cohesion , document coherence use discourse connectives . Ensuring translation retain linguistic properties expected significantly improve overall readability flow. However, due limitations current decoder technology, NMT models still bound translate sentence level. In order capture discourse properties source document translation, researchers attempted incorporate contextual information surrounding sentences. Most document-level NMT approaches augment model multiple encoders, extra attention layers memory caches encode surrounding sentences, leave model implicitly learn discourse attributes simply minimizing conventional NLL objective. The hope model spontaneously identify retain discourse patterns within source document. Conversely, little work attempted model discourse attributes explicitly. Even evaluation metrics typically used translation BLEU designed assess discourse quality translated documents. For reasons, paper propose training NMT model directly targeting two specific discourse metrics: lexical cohesion coherence . LC measure frequency semantically-similar words co-occurring document . For example, car, vehicle, engine wheels semantically-related terms. There significant empirical evidence ensuring lexical cohesion text eases understanding . At turn, COH measures well adjacent sentences text linked other. In following example Hobbs \shortcite{hobbs1979coherence}: two sentences make little `sense' one another. An incoherent text, even grammatically syntactically perfect, anecdotally difficult understand therefore coherence actively pursued. Relevant translation, Vasconcellos \shortcite{vasconcellos1989cohesion} found high percentage human post-editing changes machine-generated translations involves improvement cohesion coherence. Several LC COH metrics well correlate human judgement proposed literature. However, like BLEU evaluation metrics, discrete, non-differentiable functions model's parameters. Hereafter, propose overcome limitation using well-established policy gradient approach reinforcement learning allows using evaluation metric reward without differentiate it. By combining different types rewards, model trained simultaneously achieve lexically-cohesive coherent document translations, time retaining faithfulness reference translation. %the information contained source document. %The rest paper organized follows. Section discusses related work. Section describes baseline NMT architectures used experiments. Section presents proposed training approach discourse rewards used it. Section presents experiments and, finally, Section concludes paper.","   Document-level machine translation focuses on the translation of entire documents from a source to a target language. It is widely regarded as a challenging task since the translation of the individual sentences in the document needs to retain aspects of the discourse at document level. However, document-level translation models are usually not trained to explicitly ensure discourse quality. Therefore, in this paper we propose a training approach that explicitly optimizes two established discourse metrics, lexical cohesion  and coherence , by using a reinforcement learning objective. Experiments over four different language pairs and three translation domains have shown that our training approach has been able to achieve more cohesive and coherent document translations than other competitive approaches, yet without compromising the faithfulness to the reference translation. In the case of the Zh-En language pair, our method has achieved an improvement of $2.46$ percentage points  in LC and $1.17$ pp in COH over the runner-up, while at the same time improving $0.63$ pp in BLEU score and $0.47$ pp in $\mathrm{F}_{\mathrm{BERT}}$.      %In fact, in some cases our training approach has even improved translation accuracy metrics such as BLEU and the recently proposed $F_{\text{BERT}}$."
"In recent years, neural models led state-of-the-art results machine translation . Many systems broadly characterized following multi-layer encoder-decoder neural network design: encoder decoder learn representations word sequences stack layers , building interesting line work improving models. The simplest increases model capacity widening network, whereas recent work shows benefits stacking layers encoder side. For example, popular Transformer model , deep systems shown promising BLEU improvements either easing information flow network constraining gradient norm across layers . An improved system even learn 35-layer encoder, deeper vanilla Transformer . Although methods enabled training deep neural MT models, questions remain nature problem. The main question is: deep networks help NMT. Note previous work evaluates systems black-box manner . It thus natural study much deep NMT system able learn different shallow counterpart. Beyond this, training extremely deep model expensive although narrow-and-deep network speed training . For example, takes us longer time train model deepen network 6 layers 48 layers. This might prevent us exploiting deeper models large-scale systems. In paper, explore deep architectures work render learning NMT models effectively. By investigating change hidden states different layers, find new representations learned continually stacking layers top base model. More stacked layers lead stronger model representing sentence. This particularly makes sense deep NMT scenario proven deep models benefit enriched representation . In addition, finding inspires us develop simple yet efficient method train deep NMT encoder: train model parameters shallow deep, rather training entire model scratch. To stabilize training, design sparse linear combination method connecting lower-level layers top. It makes efficient pass information deep network require large memory footprint dense networks. We experiment method state-of-the-art deep Transformer system. Our encoder consists 48-54 layers, almost deepest Transformer model used NMT. On WMT En-De En-Fr tasks, yields speedup training, matching state-of-the-art WMT'16 En-De task.","    Deep encoders have been proven to be effective in improving neural machine translation  systems, but training an extremely deep encoder is time consuming. Moreover, why deep models help NMT is an open question. In this paper, we investigate the behavior of a well-tuned deep Transformer system. We find that stacking layers is helpful in improving the representation ability of NMT models and adjacent layers perform similarly. This inspires us to develop a shallow-to-deep training method that learns deep models by stacking shallow models. In this way, we successfully train a Transformer system with a 54-layer encoder. Experimental results on WMT'16 English-German and WMT'14 English-French translation tasks show that it is $1.4$ $\times$ faster than training from scratch, and achieves a BLEU score of $30.33$ and $43.29$ on two tasks. The code is publicly available at \href{https://github.com/libeineu/SDT-Training/}{https://github.com/libeineu/SDT-Training}."
"Task-oriented dialogue systems complete tasks users, making hotel reservation finding train routes, multi-turn conversation . The generated system utterances naturally sound, importantly informative, i.e., proceed dialogue towards task completion. To fulfill requirement, conditioned response generation widely adopted based system actions . The response generation process decoupled two consecutive steps, action first selected utterance generated conditioned action. One optimize step towards goal, i.e., informative naturally sound, without impinging . However, approaches rely action annotations , require domain knowledge extensive efforts obtain. % \end{threeparttable} \end{table} To deal absence action annotations, latent action learning introduced . System utterances represented low-dimensional latent variables auto-encoding task , utterances representations considered convey similar meanings. Such action representations might prone over-dependence training data, restricts model generalization capability, especially multiple domains considered. % This implicit nature latent variables makes unable enforce desired properties latent space, i.e., capture intentions system utterances, without explicit supervision . This because, without explicit supervision, desired property capturing intentions system utterances latent space cannot enforced , turn due implicit nature latent variables. For example, variational auto-encoder , often used latent action learning, tends produce balanced distribution latent variables , true distribution system actions highly imbalanced . The resulting misaligned action representations would confuse model steps degenerate sample efficiency training. % This without explicit supervision desired property capturing intentions system utterances latent space cannot enforced , turn due implicit nature latent variables. To address issues, propose learn natural language actions represent system utterances span words, explicitly reveal underlying intentions. % benefits natural language actions Natural language provides unique compositional structure retaining representation flexibility. These properties promote model generalization thus make natural language 閾夸骏xible representation capturing characteristics minimal assumptions . % main rationale obtain actions % In scenarios, aim use language interface Motivated advantages, learn natural language actions identifying salient words system utterances. Salient refers indicative prediction task takes input original utterance. % characteristics utterances. The main rationale principal information task concerns preserved salient words. For example, sentiment sentence ``The movie starts competent turn bland'' revealed word ``bland'' identified salient considering complete context. In scenarios, consider measuring word saliency terms state transitions. This state transitions reflect intentions system utterance influence dialogue progress, action representations capture influences well reveal intentions . By considering salient words state tracking tasks actions, obtain action representations enjoy merits natural language indeed capture characteristics interest, i.e., intentions system utterances. % explainable % technical contributions Obtaining salient words applying existing saliency identification approaches is, however, unable produce unified action representations. Specifically, system utterances intention might share similar wordings, existing attribution approaches identify salient words within utterances. We tackle challenge proposing memory-augmented saliency approach identifies salient words broader vocabulary. The vocabulary consists words could compose natural language actions,~\footnote{We consider content words state annotations task descriptions, specified Sec. } word stored slot memory component. By incorporating memory component dialogue state tracking model, use system utterance query perform memory retrieval, retrieval results considered salient words. The retrieval results might contain words redundant since direct supervision retrieval operations. For example, resulting salient words might ``but turn bland'' example shown earlier, include unnecessary words may lead degenerated action results. To obtain compact action representations, propose auxiliary task based pseudo parallel corpus, i.e., dialogue context state annotation pairs. We observe dialogue states serve good examples compact representation be. Therefore, use encoded dialogue context query ask memory component reconstruct text-based dialogue states. In way, obtained concise actions generalize better easily interpreted. Our contributions summarized follows:","   Response generation for task-oriented dialogues implicitly optimizes two objectives at the same time: task completion and language quality. Conditioned response generation serves as an effective approach to separately and better optimize these two objectives.  Such an approach relies on system action annotations which are expensive to obtain. To alleviate the need of action annotations, latent action learning is introduced to map each utterance to a latent representation. However, this approach is prone to over-dependence on the training data, and the generalization capability is thus restricted.   To address this issue, we propose to learn natural language actions that represent utterances as a span of words.  This explicit action representation promotes generalization via the compositional structure of language. It also enables an explainable generation process. Our proposed unsupervised approach learns a memory component to summarize system utterances into a short span of words. To further promote a compact action representation, we propose an auxiliary task that restores state annotations as the summarized dialogue context using the memory component. Our proposed approach outperforms latent action baselines on MultiWOZ, a benchmark multi-domain dataset."
"Consider helping friend prepare dinner unfamiliar house: friend asks clean slice apple appetizer, would approach task? Intuitively, one could reason abstractly: find apple wash apple sink put clean apple cutting board find knife use knife slice apple put slices bowl. Even unfamiliar setting, abstract reasoning help accomplish goal leveraging semantic priors. Priors like locations objects --~apples commonly found kitchen along implements cleaning slicing, object affordances --~a sink useful washing apple unlike refrigerator, pre-conditions --~better wash apple slicing it, rather converse. We hypothesize that, learning solve tasks using abstract language, unconstrained particulars physical world, enables agents complete embodied tasks novel environments leveraging kinds semantic priors exposed abstraction interaction. To test hypothesis, created novel \env framework, first interactive, parallel environment aligns text descriptions commands physically embodied robotic simulation. We build \env extending two prior works: \tw~ - engine interactive text-based games, \alfred~ - large scale dataset vision-language instruction following embodied environments. \env provides two views underlying world two modes interact it: \tw, abstract, text-based environment, generates textual observations world responds high-level text actions; \alfred, embodied simulator, renders world high-dimensional images responds low-level physical actions robot .\footnote{Note: Throughout work, clarity exposition, use \alfred{} refer tasks grounded simulation environment, rendering physics provided \thor{}~.} Unlike prior work instruction following , typically uses static corpus cross-modal expert demonstrations, argue aligned parallel environments like \env offer distinct advantage: allow agents explore, interact, learn abstract environment language encountering complexities embodied environment. While fields robotic control use % simulators like MuJoCo~ provide infinite data interaction, analogous mechanism -- short hiring human around clock -- providing linguistic feedback annotations embodied agent. \tw{} addresses discrepancy providing programmatic aligned linguistic signals agent exploration. This facilitates first work, knowledge, embodied agent learns meaning complex multi-step policies, expressed language, directly interaction. Empowered \env framework, introduce \model , agent first learns perform abstract tasks \tw using Imitation Learning transfers learned policies embodied tasks \alfred. When operating embodied world, \model leverages abstract understanding gained \tw generate text-based actions; serve high-level subgoals facilitate physical action generation low-level controller. Broadly, find \model capable generalizing zero-shot manner \tw unseen embodied tasks settings. Our results show training first abstract text-based environment faster, also yields better performance training scratch embodied world. These results lend credibility hypothesis solving abstract language-based tasks help build priors enable agents generalize unfamiliar embodied environments. Our contributions follows:\\[-15pt]","  Given a simple request like Put a washed apple in the kitchen fridge, humans can reason in purely abstract terms by imagining action sequences and scoring their likelihood of success, prototypicality, and efficiency, all without moving a muscle.  Once we see the kitchen in question, we can update our abstract plans to fit the scene. Embodied agents require the same abilities, but existing work does not yet provide the infrastructure necessary for both reasoning abstractly and executing concretely.  We address this limitation by introducing \env{}, a simulator that enables agents to learn abstract, text-based policies in \tw and then execute goals from the ALFRED benchmark in a rich visual environment. \env{} enables the creation of a new \model agent whose abstract knowledge, learned in \tw, corresponds directly to concrete, visually grounded actions. In turn, as we demonstrate empirically, this fosters better agent generalization than training only in the visually grounded environment. \model's simple, modular design factors the problem to allow researchers to focus on models for improving every piece of the pipeline ."
"Annual Reports may extend 250 pages long stated above, contains different sections General Corporate Information, financial operating cost, CEOs message, Narrative texts, accounting policies, Financial statement including balance sheet summary financial data documents. In Financial narrative summarisation task, narrative section summarised, explicitly marked dataset, making challenging interesting. In recent years, previous manual small-scale research Accounting Finance literature scaled aid NLP ML methods, example, examine approaches retrieving structured content financial reports, study causes consequences corporate disclosure financial reporting outcomes . \par Companies produce glossy brochures annual reports much looser structure, makes automatic summarisation narratives UK annual reports challenging task . Hence summarize narrative section annual reports, particular narrative sentences spread loosely across document need first identified summarise sentences. The summarisation limit set 1000 words, actual length report may go 250 pages long. Hence summarize long annual reports using combination extractive abstractive summarisation.\par The text summary method classified two paradigms: extractive abstractive. The extractive summarisation method extracts meaningful sentences section text original text combines form summary . Whereas abstractive summarisation generates words sentences similar meaning given text form summary may actual text . When summarizing long documents case 250 pages long, extractive summarisation may produce coherent readable summary, abstractive summarisation cannot cover complete information using encoder-decoder architecture. One problem typical seq2seq frameworks often generate unnatural summaries consisting repeated words phrases . Hence, come combination extractive abstractive summarisation first select important narrative sentences concisely convey them. \par Pointer Networks used various combinatorial optimization problems, Travelling Salesman Problem , Convex hull optimization. We used pointer networks task financial narrative summarization extract relevant narrative sentences particular order logical flow summary. These extracted sentences paraphrased summarise sentences abstractive way using T-5 sequence-to-sequence model. We train complete model optimizing ROUGE-LCS evaluation metric reinforcement learning objective. % % The following footnote without marker nebe fireded camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % . % % % final paper: en-us version % space normally used marker This work licensed Creative Commons Attribution 4.0 International License. License details: \url{http://creativecommons.org/licenses/by/4.0/}. }","   Companies provide annual reports to their shareholders at the end of the financial year that describes their operations and financial conditions. The average length of these reports is 80, and it may extend up to 250 pages long. In this paper, we propose our methodology PoinT-5  algorithms) that we used in the Financial Narrative Summarisation  2020 task. The proposed method uses Pointer networks to extract important narrative sentences from the report, and then T-5 is used to paraphrase extracted sentences into a concise yet informative sentence. We evaluate our method using $\operatorname{ROUGE}$-N , L,and SU4. The proposed method achieves the highest precision scores in all the metrics and highest F1 scores in $\operatorname{ROUGE}$ 1,and LCS and only solution to cross MUSE solution baseline in $\operatorname{ROUGE}$-LCS metrics."
"Neural Architecture Search methods aim automatically discover neural architectures perform well given task dataset. These methods search space possible model architectures, looking ones perform well task generalize unseen data. There substantial prior work define architecture search space, search space, estimate model performance . Recent works, however, cast doubt quality performance NAS-optimized architectures , showing current methods fail find best performing architectures given task perform similarly random architecture search. In work, explore applications SOTA NAS algorithm, ENAS , two sentence-pair tasks, paraphrase detection semantic textual similarity . We conduct large set experiments testing effectiveness ENAS-optimized RNN architectures across multiple models , embeddings datasets . We first, knowledge, apply ENAS PD STS, explore applications across multiple embeddings traditionally LSTM-based NLP models, conduct extensive SOTA HPT across multiple ENAS-RNN architecture candidates. Our experiments suggest baseline LSTM models, appropriate hyperparameter tuning , sometimes match exceed performance models ENAS-RNNs. We also observe random architectures sampled ENAS search space offer strong baseline, sometimes outperform ENAS-RNNs. Given observations, recommend researchers conduct extensive HPT across various candidate architectures fairest comparisons; compare performances ENAS-RNNs standard architectures like LSTMs RNN cells randomly sampled ENAS search space; examine computational requirements ENAS methods alongside gains observed.","  Neural Architecture Search  methods, which automatically learn entire neural model or individual neural cell architectures, have recently achieved competitive or state-of-the-art  performance on variety of natural language processing and computer vision tasks, including language modeling, natural language inference, and image classification. In this work, we explore the applicability of a SOTA NAS algorithm, Efficient Neural Architecture Search  \cite{Pham2018EfficientNA} to two sentence pair tasks, paraphrase detection and semantic textual similarity. We use ENAS to perform a micro-level search and learn a task-optimized RNN cell architecture as a drop-in replacement for an LSTM. We explore the effectiveness of ENAS through experiments on three datasets , with two different models , and two sets of embeddings . In contrast to prior work applying ENAS to NLP tasks, our results are mixed -- we find that ENAS architectures sometimes, but not always, outperform LSTMs and perform similarly to random architecture search."
"Constituency parsing well-studied problem natural language processing, state-of-the-art parsers tested written text, e.g.\ standard Penn Treebank Wall Street Journal dataset . These recent neural parsers commonly formulated encoder-decoder systems, encoder learns input sentence representation decoder learns predict parse tree. While input often represented word-level features, representation output trees varies: sequence parse symbols , set spans , syntactic distances , per-word structure-rich labels . A key characteristic many neural parsers recurrent network structure, particularly Long Short-Term Memory networks ; however, Kitaev Klein shown non-recurrent encoder Transformer network introduced also capable encoding timing information self-attention mechanisms, achieving state-of-the-art parse results Treebank WSJ dataset. Further, parsers %seem mainly benefit contextualized information learned larger external text data, ELMo BERT . It clear advances transfer speech data, particularly different styles speech. Even perfect transcripts available, speech poses many challenges parsers learned written text due lack punctuation case, presence disfluencies. On hand, speech signals carry rich information beyond words via variations timing, intonation, loudness, i.e. prosody. Linguistic studies shown prosodic cues align constituent structure , signal disfluencies marking interruption point , help listeners resolve syntactic ambiguities . Empirical evidence, however, mixed regarding utility prosody constituency parsing. Most gains observed sentence boundaries unknown , annotated prosodic labels . Most related current work, Tran et al.\ recently showed benefit using prosody parsing within sequence-to-sequence framework, proposing convolutional neural network mechanism combine discrete word-level features frame-level acoustic-prosodic features. In study, extend work explore utility recent neural advances spontaneous speech data, compare utility prosody read vs.\ spontaneous speech. Specifically, goal current study answer following questions: % TT: may cut space lacking. But I want end intro questions without saying anything %The rest paper organized follows: Section describes models used work; Section reviews datasets metrics constituency parsing; Section presents experiments, results, analyses; Section summarizes findings. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Moved data table since oddly arranged %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \end{table*}\documentclass[a4paper]{article} \usepackage{INTERSPEECH2019} \usepackage{url} \usepackage{multirow} \usepackage{xcolor} \usepackage{subcaption,enumitem} \usepackage{booktabs} \usepackage{comment} \newcommand{\ttcomment}[1]{\textcolor{red}{\bf \small [#1 --TT]}} \newcommand{\jycomment}[1]{\textcolor{blue}{\bf \small [#1 --JY]}} \newcommand{\ylcomment}[1]{\textcolor{cyan}{\bf \small [#1 --YL]}} \newcommand{\mocomment}[1]{\textcolor{green}{\bf \small [#1 --MO]}} \title{On Role Style Parsing Speech Neural Models} \name{Trang Tran, Jiahong Yuan, Yang Liu, Mari Ostendorf} %The maximum number authors author list twenty. If number contributing authors twenty, listed footnote acknowledgement section, appropriate. \address{ Electrical \& Computer Engineering, University Washington\\ LAIX Inc.} \email{\{ttmt001,ostendor\}@uw.edu, \{jiahong.yuan,yang.liu\}@liulishuo.com} Index Terms: constituency parsing, prosody, spontaneous speech, contextualized embeddings %Index Terms: constituency parsing, prosody, spontaneous speech, read speech, switchboard, ELMo, BERT, contextualized embeddings %\ttcomment{take these?} \bibliographystyle{IEEEtran} \bibliography{interspeech19} \end{document}"," The differences in written text and conversational speech are substantial; previous parsers trained on treebanked text have given very poor results on spontaneous speech. For spoken language, the mismatch in style also extends to prosodic cues, though it is less well understood.  This paper re-examines the use of written text in parsing speech in the context of recent advances in neural language processing. We show that neural approaches facilitate using written text to improve  parsing of spontaneous speech, and that prosody further improves over this state-of-the-art result. Further, we find an asymmetric degradation from read vs.\ spontaneous mismatch, with spontaneous speech more generally useful for training parsers.  %  Prosodic information in the speech signal has been shown to correlate with syntactic structure of a sentence; however, the impact of prosody on parsing has been mixed. Recent results show a benefit for conversational speech, particularly in utterances with disfluencies, but there is little recent work on other speaking styles. In this work, we extend recent advances in constituency parsing of spontaneous speech, integrating acoustic-prosodic cues and achieving SOTA results on the Switchboard dataset. We then explore the performance of the parser on mismatched training/testing scenarios. Specifically, we show that training on spontaneous speech results in a small degradation when testing on read speech, while fine-tuning with WSJ read speech substantially degrades the performance on spontaneous speech."
"The recent progress machine translation models led researchers question use n-gram overlap metrics BLEU, focus solely surface-level aspects generated text, thus may correlate poorly human evaluation. This led surge interest flexible metrics use machine learning capture semantic-level information. Popular examples metrics include YiSi-1, ESIM, BERTscore, Sentence Mover's Similarity, \BLEURT{}. These metrics utilize contextual embeddings large models BERT shown capture linguistic information beyond surface-level aspects. The WMT Metrics 2020 Shared Task reference benchmark evaluating metrics context machine translation. It tests evaluation systems to-English languages , requires multilingual approach. An additional challenge learned metrics human ratings available language pairs, therefore, models must use unlabeled data perform zero-shot generalization. We describe several learned metrics based \BLEURT{}~, originally developed English data. We first extend \BLEURT{} multilingual setup, show approach achieves competitive results WMT Metrics 2019 Shared Task.\footnote{We use following languages fine-tuning and/or testing: Chinese, Czech, German, English, Estonian, Finnish, French, Gujarati, Kazakh, Lithuanian, Russian, Turkish. In addition, also pre-train Inuktitut, Japanese, Khmer, Pastho, Polish, Romanian, Tamil.} We also present several simple BERT-based baselines, submit analysis. Finally, focus English German enhance \BLEURT{}'s performance combining predictions YiSi well using alternative references."," The quality of machine translation systems has dramatically improved over the last decade, and as a result, evaluation has become an increasingly challenging problem. This paper describes our contribution to the WMT 2020 Metrics Shared Task, the main benchmark for automatic evaluation of translation. We make several submissions based on \BLEURT{}, a previously published metric which uses transfer learning. We extend the metric beyond English and evaluate it on 14 language pairs for which fine-tuning data is available, as well as 4 ``zero-shot'' language pairs, for which we have no labelled examples. Additionally, we focus on English to German and demonstrate how to combine \BLEURT{}'s predictions with those of YiSi and use alternative reference translations to enhance the performance. Empirical results show that the models achieve competitive results on the WMT Metrics 2019 Shared Task, indicating their promise for the 2020 edition."
"There growing interest using formal languages study fundamental properties neural architectures, led extraction interpretable models . Recent work explored generalized Dyck-n languages, subset context-free languages. consists ``well-balanced'' strings parentheses different types bracket pairs, canonical formal language study nested structures. \citet{weiss2018practical} show LSTMs variant -counter machine recognize languages. The dynamic counting mechanisms, however, sufficient requires emulating pushdown automata. \citet{hahn2020theoretical} shows sufficiently large length, Transformers fail transduce language. We empirically show addition starting symbol vocabulary, two-layer multi-headed SA network able learn languages, generalize longer sequences, although perfectly. As shown Figure , network able identify corresponding closing bracket opening bracket, resembles stack-based automaton. For example, symbol ``]'' string ``'', first pop ``['' stack, attends `` enables model learn occurrence end clause end sequence, regarded mechanism represent empty stack. Our work first perform empirical exploration SA formal languages. We present detailed comparison SA incorporates starting symbol , one , demonstrate significant differences generalization across length sequences depth dependencies. Recent work suggested ability self-attention mechanisms model hierarchical structures limited. \citet{shen2019ordered} show performance Transformers tasks logical inference ListOps either poor worse LSTMs. \citet{tran2018importance} also reported similar results SA, concluding recurrence necessary model hierarchical structures. In comparison, results show SA outperforms LSTM languages except longer sequences. \citet{papadimitriou2020pretraining} posit ability neural models learn hierarchical structures attributed ``looking back'' capability, rather directly encoding hierarchies. Our analysis sheds light ability SA learn hierarchical structures elegantly attending correct preceding symbol.","   We focus on the recognition of Dyck-n  languages with self-attention  networks, which has been deemed to be a difficult task for these networks. We compare the performance of two variants of SA, one with a starting symbol  and one without . Our results show that SA$^+$ is able to generalize to longer sequences and deeper dependencies. For $\mathcal{D}_2$, we find that SA$^-$ completely breaks down on long sequences whereas the accuracy of SA$^+$ is 58.82$\%$. We find attention maps learned by SA$^+$ to be amenable to interpretation and compatible with a stack-based language recognizer. Surprisingly, the performance of SA networks is at par with LSTMs, which provides evidence on the ability of SA to learn hierarchies without recursion."
"Although neural machine translation achieved great progress recent years , fed entire document, standard NMT systems translate sentences isolation without considering cross-sentence dependencies. Consequently, document-level neural machine translation methods proposed utilize source-side target-side inter-sentence contextual information improve translation quality sentences document . More recently, researchers DocNMT mainly focus exploring various attention-based networks leverage cross-sentence context efficiently, evaluate special discourse phenomena . However, still issue received less attention: context sentences used translating source sentence? \end{center} \end{table} We conduct experiment verify intuition: translation different source sentences requires different context. As shown Table , train two DocNMT models test using various context settings\footnote{We apply typical DocNMT method train models ZhEn TED, select 1,000 sentences test. The BLEU sentence-level baseline 20.06.}. During test, obtain dynamic context sentences achieve best BLEU scores traversing context combinations source sentence. Compared fixed size context , dynamic context significantly improve translation quality. Although row 2 uses context, redundant information may hurt results. Experiments indicate limited context sentences really useful, change source sentences. Majority existing DocNMT models set context size scope fixed. They utilize previous context sentences , full context entire document . As result, inadequacy redundancy contextual information almost inevitable. From viewpoint, \citet{maruf2019selective} propose selective attention approach uses sparsemax function instead softmax normalize attention weights. The sparsemax assigns low probability softmax zero model focus sentences high probability. However, learning attention weights lacks guidance, cannot handle situation source sentences achieve best translation results without relying context, happens 39.4\% sentences experiment. To address problem, propose effective approach select contextual sentences {\bf dynamically} source sentence document-level translation. Specifically, propose Context Scorer score candidate context sentence according currently translated source sentence. Then, utilize two selection strategies select useful context sentences translation module. The size selected context variable different sentences. A core challenge approach selection process non-differentiable. Therefore, leverage reinforcement learning method train selection DocNMT modules together. We design novel reward encourage model aware different context sentences select appropriate context improve translation quality. In paper, make following contributions:"," 		Document-level neural machine translation has yielded attractive improvements. However, majority of existing methods roughly use all context sentences in a fixed scope. They neglect the fact that different source sentences need different sizes of context. To address this problem, we propose an effective approach to select dynamic context so that the document-level translation model can utilize the more useful selected context sentences to produce better translations. Specifically, we introduce a selection module that is independent of the translation module to score each candidate context sentence. Then, we propose two strategies to explicitly select a variable number of context sentences and feed them into the translation module. We train the two modules end-to-end via reinforcement learning. A novel reward is proposed to encourage the selection and utilization of dynamic context sentences. Experiments demonstrate that our approach can select adaptive context sentences for different source sentences, and significantly improves the performance of document-level translation methods."
"\vsec Automatic text summarization\footnote{We refer abstractive summarization paper.} attractive technique helping humans grasp content documents effortlessly. While supervised neural methods shown good performances, unsupervised approach starting attract interest due advantage requiring costly parallel corpora. However, empirical performance unsupervised methods currently behind state-of-the-art supervised models. Unsupervised text summarization still developing stage various solutions actively explored. One previous unsupervised approach extends neural encoder-decoder modeling zero paired data scenario, model trained paradigm called compression-reconstruction learning. The mechanism similar back-translation: model consists compressor reconstructor, co-trained reconstructor recover original sentence summary generated compressor~. Experimental results showed unsupervised encoder-decoder-based summarizer able learn mapping sentence summary without paired data. % Also, \citealp{zhou-rush-2019-simple} proposes straightforward method mimics reconstruction part means contextual similarity original input sentence top generating summary. % However, performance unsupervised methods still deficient compared latest supervised models. Reinforcement learning also potential solution paired data situation. In related fields, example, unsupervised methods text simplification text compression policy-gradient learning. Recent RL techniques take value-based approach DQN combination policy value-based approaches Asynchronous Advantage Actor-Critic. A critical requirement leverage value-based method value function represents goodness action given state. We naturally define value function utilizing CR-learning paradigm, makes latest value-based approaches available unsupervised text summarization. % , require define value-function. % We leverage values-based approach % A crucial requirement RL value function represents goodness action given state. % We satisfy requirement leveraging definition CR learning paradigm. % One concern is, however, RL large action space generally difficulty training. % In addition, latest techniques improve RL value-based approach DQN combination policy-based value-based approaches Asynchronous Advantage Actor-Critic. In paper, propose new method based Q-learning edit-based summarization~. The edit-based summarization generates summary operating edit action word input sentence. Our method implements editing process two modules: 1) {\bf E}ditorial {\bf A}gent predicts edit actions, 2) {\bf L}anguage {\bf M}model converter deterministically decodes sentence basis action signals, call \ealm. The CR learning defined Q-learning framework train agent predict edit actions instruct LM converter produce good summary. Although vast action space causing sparsity reward, word generation encoder-decoder model, generally difficult learned RL, method mitigates issue thanks fewer edit actions deterministic decoding language model. Moreover, formulation Q-learning enables us incorporate latest techniques RL. The main contribution paper provide new solution form unsupervised edit-based summarization leveraging Q-learning language model. Experimental results show method achieved competitive performance encoder-decoder-based methods even truly paired data , qualitative analysis brings insights current unsupervised models missing. Also, problem formulation Q-learning enables us import latest techniques RL, leads potential improvements future research. % 2) We propose first Q-learning-based method uses pre-trained language model. % , mitigates issues prevalent among previous methods. % Empirically, method shows competitive performance news corpus benchmarks truly paired data . % Also, method requires parallel data even validation; therefore, instantly applicable situation language model. % Our proposed approach brings new insights growing field unsupervised text summarization, pave way future development. % This paper organized follows: Section defines problem statement unsupervised text summarization \algoname\ paradigm. % After reviewing previous methods Section, introduce approach Section . % Then, report experimental results Section . % Discussing insights experiment Section , conclude contribution paper future unsupervised text summarization Section . % Text Summarization task transform input sentence informative summary . % Although supervised summarization models like encoder-decoder shown success years , still issue demand us create massive parallel data. % The question ``how model transformation input sentences?"" attracts research interests, known unsupervised text summarization . % In unsupervised text summarization, input sentences available training model. % Instead, holds hypothesis: summary contain information input sentence extent guess original contents. % And, lgoname approach leverage hypothesis . % In \algoname, prepare two modules, one compression produces summary input sentence, one reconstruction re-produces input sentence generated summary. % These two modules optimized based hypothesis, specifically, minimizing difference input sentence reconstructed sentence compressed sentence satisfying essential properties shortness readability . % In previous studies, use generative models encoder-decoder compression reconstruction, directly train output desired sentences . % We illustrate flow left-hand side Figure . % Our proposed method also top paradigm uses different modules, {\bf Q-learning agent} {\bf fixed-language model} .\footnote{A pretrained language model fine-tuned, i.e., fixed, training.} % As illustrated right-hand side Figure , agent determines action, whether remove, keep, replace word input sentence. % Receiving action signals, fixed-LM deterministically produces compressed reconstructed sentences. % In short, train agent properly control fixed-LM obtain desired sentences results compression reconstruction. % The primary contribution paper provide new option leveraging Q-learning language model growing field unsupervised text summarization. % Introducing Q-learning, open problem sophisticated techniques value-based Reinforcement Learning algorithms , covered policy-based RL algorithms employed far.\footnote{RL algorithms classified value-based policy-based . To best knowledge, text summarization methods RL, supervised unsupervised settings, leverages policy-based RL algorithms . Combining previous policy-based value-based methods sentence compression lead applicability advanced RL algorithms Actor-Critic Asynchronous Advantage Actor-Critic .} % Also, proposing approach fixedly utilize pre-trained language model, benefit powerful performance capturing sentence semantics along mitigating issues generative models inherently hold complexity co-training multiple generators repetition decoding. % Experimentally, approach shows promising results; achieves competitive performance standard datasets outperforms previous generator models out-of-domain circumstances. % This paper brings novel insights unsupervised text summarization contributes flourishing future. % This paper organized follows: Section defines problem statement unsupervised text summarization \algoname\ paradigm. % After reviewing previous methods Section, introduce approach Section . % Then, report experimental results Section . % Discussing insights experiment Section , conclude contribution paper future unsupervised text summarization Section . \vsecu"," % Unsupervised methods for abstractive text summarization are attractive because they do not require parallel corpora. % However, their performance is still somehow lacking, therefore research on promising solutions is ongoing. % In this paper, we propose a new approach based on Q-learning with an edit-based summarization. % Our method combines two key modules to form an {\bf E}ditorial {\bf A}gent and {\bf L}anguage {\bf M}odel converter~. % The agent predicts edit actions, and then the LM converter deterministically generates a summary on the basis of the action signals. % Q-learning is leveraged to train the agent to output proper edit actions. % Experimental results show that \ealm~has a competitive performance compared with the previous encoder-decoder-based methods, even with truly zero paired data .  % Defining the task as Q-learning enables us not only to develop a competitive method but also to make the latest techniques in reinforcement learning available for unsupervised summarization. % We also conduct qualitative analysis and provide insights on future work for the current unsupervised summarizers.\footnote{Our codes are available at \url{https://github.com/kohilin/ealm}} Unsupervised methods are promising for abstractive textsummarization in that the parallel corpora is not required.  However, their performance is still far from being satisfied, therefore research on promising solutions is on-going.   In this paper, we propose a new approach based on Q-learning with an edit-based summarization.  The method combines two key modules to form an Editorial Agent and Language Model converter .  The agent predicts edit actions , and then the LM converter deterministically generates a summary on the basis of the action signals.  Q-learning is leveraged to train the agent to produce proper edit actions.  Experimental results show that \ealm~delivered competitive performance compared with the previous encoder-decoder-based methods, even with truly zero paired data . Defining the task as Q-learning enables us not only to develop a competitive method but also to make the latest techniques in reinforcement learning available for unsupervised summarization. We also conduct qualitative analysis, providing insights into future study on unsupervised summarizers.\footnote{Our codes are available at \url{https://github.com/kohilin/ealm}}"
"Neural machine translation systems data driven models, highly depend training corpus. NMT models tendency towards over-fitting frequent observations neglecting low-frequency observations. Unfortunately, exists token imbalance phenomenon natural languages different tokens appear different frequencies, roughly obey Zipf's Law. Table shows serious imbalance high-frequency tokens low-frequency tokens. NMT models rarely opportunity learn generate ground-truth low-frequency tokens training process. %It harder NMT model generate ground-truth low-frequency tokens even training process. %Compared reference, NMT model tends generate high-frequency tokens less low-frequency tokens, hurts translation quality. Some work tries improve rare word translation maintaining phrase tables back-off vocabulary adding extra components, bring extra training complexity computing expense. Some NMT techniques based smaller translation granularity alleviate issue, hybrid word-character-based model, BPE-based model word-piece-based model. %For example, sub-word model adapted byte pair encoding technique task word segmentation. These effective work alleviate token imbalance phenomenon certain extent become de-facto standard NMT models. Although sub-word based NMT models achieved significant improvements, still face token-level frequency imbalance phenomenon, Table shows. %It obvious always low-frequency tokens matter number merge operations BPE is. %As shown Table, rare word 'slower' split two tokens 'slow' 'er', still exist obvious token-level imbalance 'slow' tokens. \iffalse \end{table} \fi \iffalse \fi \iffalse \end{table} \fi Furthermore, current NMT models generally assign equal training weights target tokens without considering frequencies. It likely NMT models ignore loss produced low-frequency tokens small proportion training sets. The parameters related adequately trained, will, turn, make NMT models tend prioritize output fluency translation adequacy, ignore generation low-frequency tokens decoding, illustrated Table. It shows vanilla NMT model tends generate high-frequency tokens less low-frequency tokens. %This will, turn, make model %tend generate many high-frequency tokens less low-frequency tokens decoding. However, low-frequency tokens may carry critical semantic information may affect translation quality neglected. %It likely NMT models ignore loss produced rare words patterns learned encoder, decoder, attention modules can't adequately updated. What's more, NMT models tend prioritize output fluency translation adequacy ignore translation rare words generation. %In experiments, observed vanilla NMT models usually produce frequent words less rare words real references. Therefore, techniques adopted improve translation rare words. %distribution. %It obvious always rare tokens matter number merge operations BPE problem token distribution imbalance still exists. %One advantages technique reduces number rare words splitting frequent subword tokens , fact %relieve imbalance word %The strength NMT models make use large amounts parallel training sentences learn knowledge features embodied training data. However, one weaknesses NMT models tendency towards over-fitting frequent observations , neglecting rare cases frequently observed. Unfortunately, natural word distribution imbalance corpus. According Zipf's Law, frequency word inversely proportional ranking frequency table, indicates occurrences words far others naturally. %For word-level NMT models, NMT limitation handling larger vocabulary training complexity computing expense. % %In work, first represent word sequence characters iteratively combine frequent pair new symbol. %which achieved better accuracy translation rare words %, seek alleviate token imbalance problem based analysis. For purpose, To address issue, proposed token-level adaptive training objectives based target token frequencies. We aimed meaningful relatively low-frequency tokens could assigned larger loss weights training model learn them. %In objectives, relatively low-frequency valuable tokens assigned larger loss weights training encourage model learn them. To explore suitable adaptive objectives NMT, first applied existing adaptive objectives tasks NMT analyzed performance. We found though could bring modest improvement translation low-frequency tokens, much damage translation high-frequency tokens, led obvious degradation overall performance. This implies objective ensure training high-frequency tokens first. %training high-frequency tokens ensured first. %We ensure training high-frequency tokens enlarge weights low-frequency tokens time. %We firstly tried focal loss, proposed solving token imbalance problem CV task, analyzed performance. Then, based observations, proposed two heuristic criteria designing token-level adaptive objectives based target token frequencies. Last, presented two specific forms different application scenarios according criteria. Our method yields consistent improvements translation quality ZH-EN, EN-RO, EN-DE translation tasks, especially sentences contain low-frequency tokens get 1.68, 1.02, 0.52 BLEU increases compared baseline, respectively. Further analyses show method also improve lexical diversity translation. %We carried experiments ZHEN, ENRO, ENDE translation tasks validate methods. The experimental results show methods achieve significant improvement translation quality, especially sentences contain low-frequency tokens. %Besides, token distribution translations becomes closer references test sets. %Besides, method also improves diversity translations. Our contributions summarized follows: %More specifically, NMT models first trained equal weights fine-tuned well-defined weights introduced scoring functions. In way, hurt translation frequent tokens, also improve translation rare tokens certain degree. To best knowledge, first work trying concern training weights token level solve distribution imbalance problem NMT. The experiments multiple translation tasks show method improve overall translation performance without almost additional computing storage expense. And analysis experiments indicate method improve rare tokens translation significantly tokens distribution translation much closer references baseline translations."," There exists a token imbalance phenomenon in natural language as different tokens appear with different frequencies, which leads to different learning difficulties for tokens in Neural Machine Translation .  The vanilla NMT model usually adopts trivial equal-weighted objectives for target tokens with different frequencies and tends to generate more high-frequency tokens and less low-frequency tokens compared with the golden token distribution. %%% However, low-frequency tokens may carry critical semantic information that will affect the translation quality once they are neglected.   In this paper, we explored target token-level adaptive objectives based on token frequencies to assign appropriate weights for each target token during training.  We aimed that those meaningful but relatively low-frequency words could be assigned with larger weights in objectives to encourage the model to pay more attention to these tokens. %More specifically, those relatively low-frequency but valuable target tokens will be assigned with larger weights in objectives to encourage the model to pay more attention to these tokens. %%% %We conducted experiments  Our method yields consistent improvements in translation quality on ZH-EN, EN-RO, and EN-DE translation tasks, especially on sentences that contain more low-frequency tokens where we can get 1.68, 1.02, and 0.52 BLEU increases compared with baseline, respectively. Further analyses show that our method can also improve the lexical diversity of translation. %Experiments on multiple translation tasks show that our methods can achieve significant improvement in translation quality, especially on sentences that contain more low-frequency tokens.  %Besides, our method also improves translation diversity. %Besides, the token distribution of our translations becomes closer to the reference of test sets.  %.  %Rare words translation has always been one of the key challenges to Neural Machine Translation ."
"Graph structures play pivotal role NLP able capture particularly rich structural information. For example, Figure shows directed, labeled Abstract Meaning Representation graph, node denotes semantic concept edge denotes relation concepts. Within realm work AMR, focus paper problem AMR-to-text generation, i.e. transducing AMR graphs text conveys information AMR structure. A key challenge task efficiently learn useful representations AMR graphs. Early efforts neglect significant part structural information input graph linearizing it. Recently, Graph Neural Networks explored better encode structural information task . % \tzy{papers 2018??? Gated Graph Neural networks??? Do miss important paper.} One type GNNs Graph Convolutional Networks . GCNs follow local information aggregation scheme, iteratively updating representations nodes based immediate neighbors. Intuitively, stacking convolutional layers GCNs helps capture complex interactions . However, prior efforts shown locality property existing GCNs precludes efficient non-local information propagation. \citet{AbuElHaija2019MixHopHG} proved vanilla GCNs unable capture feature differences among neighbors different orders matter many layers stacked. Therefore, Self-Attention Networks explored alternative capture global dependencies. As shown Figure , SANs associate node nodes model interactions two nodes graph. Still, approach ignores structure original graph. \citet{Zhu2019ModelingGS} \citet{Cai2019GraphTF} propose structured SANs incorporate additional neural components encode structural information input graph. Convolutional operations, however, computationally efficient self-attention operations computation attention weights scales quadratically convolutions scale linearly respect input length . Therefore, worthwhile explore possibility models based graph convolutions. One potential approach considered incorporate information higher order neighbors, helps facilitate non-local information aggregation node classification . However, simple concatenation different order representations may able model complex interactions semantics text generation . We propose better integrate high-order information, introducing novel dynamic fusion mechanism propose Lightweight, Dynamic Graph Convolutional Networks . As shown Figure , nodes LDGCN model able integrate information first third-order neighbors. With help dynamic mechanism, LDGCNs effectively synthesize information different orders model complex interactions AMR graph text generation. Also, LDGCNs require additional computational overhead, contrast vanilla GCN models. We develop two novel weight sharing strategies based group graph convolutions weight tied convolutions. These strategies allow LDGCN model reduce memory usage model complexity. Experiments AMR-to-text generation show LDGCNs outperform best reported GCNs SANs trained LDC2015E86 LDC2017T10 significantly fewer parameters. On large-scale semi-supervised setting, model also consistently better others, showing effectiveness model large training set. We release code pretrained models \url{https://github.com/yanzhang92/LDGCNs}.\footnote{Our implementation based MXNET Sockeye toolkit .}"," 	 	% Camera-Ready 	AMR-to-text generation is used to transduce Abstract Meaning Representation structures  into text. A key challenge in this task is to efficiently learn effective graph representations. Previously, Graph Convolution Networks  were used to encode input AMRs, however, vanilla GCNs are not able to capture non-local information and additionally, they follow a local  information aggregation scheme. To account for these issues, larger and deeper GCN models are required to capture more complex interactions. In this paper, we introduce a dynamic fusion mechanism, proposing Lightweight Dynamic Graph Convolutional Networks  that capture richer non-local interactions by synthesizing higher order information from the input graphs. We further develop two novel parameter saving strategies based on the group graph convolutions and weight tied convolutions to reduce memory usage and model complexity. With the help of these strategies, we are able to train a model with fewer parameters while maintaining the model capacity. Experiments demonstrate that LDGCNs outperform state-of-the-art models on two benchmark datasets for AMR-to-text generation with significantly fewer parameters."
"A natural way consider two parallel sentences different languages language expresses underlying meaning different viewpoint. Each language thought transformation maps underlying concept view collectively agree determined `English' `French'. Similarly, image cat word `cat' expressing two views underlying concept. In case, image corresponds high bandwidth channel word `cat' low bandwidth channel. This way conceptualizing parallel viewpoints naturally leads formulation fully generative model instance, transformation corresponds particular generation underlying view. We define views channel. As concrete example, given parallel corpus English French sentences, English French become two channels, corresponding generative model becomes . One key advantage formulation single model trained capture full expressivity underlying concept, allowing us compute conditionals marginals along joint. In parallel sentences, conditionals correspond translations one channel another marginals correspond standard monolingual language models. In work, present general framework modeling joint distribution channels marginalizing possible factorizations across channels within channel. This formulation allows framework perform: 1) unconditional generation, 2) fully conditional generation , 3) partial conditional generation . The key contributions work are: We highlight focus languages specific instantiation channel, framework generalize arbitrary specification, types tasks modalities . %%%%%%%%%%%%%%%%%%%%%%%%%%%"," A channel corresponds to a viewpoint or transformation of an underlying meaning. A pair of parallel sentences in English and French express the same underlying meaning, but through two separate channels corresponding to their languages. In this work, we present the Multichannel Generative Language Model . MGLM is a generative joint distribution model over channels. MGLM marginalizes over all possible factorizations within and across all channels.  MGLM endows flexible inference, including unconditional generation, conditional generation , and partially observed generation .  We experiment with the Multi30K dataset containing English, French, Czech, and German. We demonstrate experiments with unconditional, conditional, and partially conditional generation. We provide qualitative samples sampled unconditionally from the generative joint distribution. We also quantitatively analyze the quality-diversity trade-offs and find MGLM outperforms traditional bilingual discriminative models."
"Neural machine translation achieved promising results use various optimization tricks. In spite that, techniques lead increased training time massive hyper-parameters, making development well-performed system expensive. As alternative mitigation, curriculum learning~\citep[CL,][]{elman1993learning,bengio2009curriculum} shown effectiveness speeding convergence stabilizing NMT model training. CL teaches NMT model easy examples complex ones rather equally considering samples, keys lie definition ``difficulty'' strategy curricula design. Existing studies artificially determine data difficulty according prior linguistic knowledge sentence length word rarity , manually tune learning schedule. However, neither exists clear distinction easy hard examples, human intuitions exactly conform effective model training. Instead, resolve problem introducing self-paced learning, emphasis learning dynamically determined model rather human intuitions. Specifically, model measures level confidence training example, easy sample actually one high confidence current trained model. Then, confidence score served factor weight loss corresponding example. In way, training process dynamically guided model itself, refraining human predefined patterns. We evaluate proposed method IWSLT15 EnVi, WMT14 EnDe, well WMT17 ZhEn translation tasks. Experimental results reveal approach consistently yields better translation quality faster convergence speed Transformer baseline recent models exploit CL. Quantitative analyses confirm intuitive curriculum schedule human fully cope model learning."," Recent studies have proven that the training of neural machine translation  can be facilitated by mimicking the learning process of humans. Nevertheless, achievements of such kind of curriculum learning rely on the quality of artificial schedule drawn up with the hand-crafted features, e.g. sentence length or word rarity. We ameliorate this procedure with a more flexible manner by proposing self-paced learning, where NMT model is allowed to 1) automatically quantify the learning confidence over training examples; and 2) flexibly govern its learning via regulating the loss in each iteration step.  Experimental results over multiple translation tasks demonstrate that the proposed model yields better performance than strong baselines and those models trained with human-designed curricula on both translation quality and convergence speed.\footnote{Our codes:  \href{https://github.com/NLP2CT/SPL_for_NMT}{https://github.com/NLP2CT/SPL\_for\_NMT}.}"
"In recent years, cyberbullying become one pressing online risks among youth raised serious concerns society. Cyberbullying commonly defined electronic transmission insulting embarrassing comments, photos videos, illustrated Figure~ . Harmful bullying behavior include posting rumors, threats, pejorative labels, sexual remarks. Research American Psychological Association White House revealed young people US indicate bullied social media platforms~. Such growing prevalence cyberbullying social media detrimental societal effects, victims may experience lower self-esteem, increased suicidal ideation, variety negative emotional responses~. Therefore, become critically important able detect prevent cyberbullying social media. Research computer science aimed identifying, predicting, ultimately preventing cyberbullying better understanding nature key characteristics online cyberbullying. In literature, existing efforts toward automatically detecting cyberbullying primarily focused textual analysis user comments, including keywords~ sentiments analysis ~. These studies attempt build generic binary classifier taking high-dimensional text features input make predictions accordingly. Despite satisfactory detection performance practice, models largely overlooked temporal information cyberbullying behaviors. They also ignore user interactions social networks. Furthermore, majority methods focus detecting cyberbullying sessions effectively cannot explain ``why'' media session detected cyberbullying. Given sequence comments user attributes, think sequential learning allow us better exploit model evolution correlations among individual comments. Besides, graph-based learning enable us represent learn users interact session. This work aims detect cyberbullying jointly exploring explainable information user comments social media. To end, build explainable cyberbullying detection framework, \underline{HE}terogeneous \underline{N}eural \underline{I}nteraction \underline{N}etworks , coherent process. HENIN consists three main components learn various interactions among heterogeneous information displayed social media sessions. A comment encoder created learn representations user comments hierarchical self-attention neural network semantic syntactic cues cyberbullying captured. We create post-comment co-attention mechanism learn interactions posted text comments. Moreover, two graph convolutional networks leveraged learn latent representations depicting sessions interact one another terms users, posts correlated terms words. Specifically, address several challenges work: perform explainable cyberbullying detection boost detection performance, highlight explainable comments without ground truth, model correlation posted text user comments, model interactions sessions terms users, interactions textual posts terms words. Our solutions challenges result novel framework HENIN. Our contributions summarized follows. %"," In the computational detection of cyberbullying, existing work largely focused on building generic classifiers that rely exclusively on text analysis of social media sessions. Despite their empirical success, we argue that a critical missing piece is the model explainability, i.e., why a particular piece of media session is detected as cyberbullying. In this paper, therefore, we propose a novel deep model, HEterogeneous Neural Interaction Networks , for explainable cyberbullying detection. HENIN contains the following components: a comment encoder, a post-comment co-attention sub-network, and session-session and post-post interaction extractors. Extensive experiments conducted on real datasets exhibit not only the promising performance of HENIN, but also highlight evidential comments so that one can understand why a media session is identified as cyberbullying."
"\zc{ Title: need concrete, something like ""Denoising Multi-Source Weak Supervision Neural Text Classification"" probably better Introduction: Paragraph 1: many NLP tasks formulated text classification dnns successful require labeled data, expensive obtain recently, pre-trained language models alleviate problem, still suffers degraded performance labeled data limited. \wendi{BERT still need labeled data} Paragraph 2: weak supervision promising, also challenging apply weak labels inaccurate incomplete. Paragraph 3: study using multiple weak supervision sources learn text classifiers; intuition multiple weak supervision sources provide complementary information eliminate noise; combined unlabeled data, address label incompleteness well. \wendi{key: complementary information; bootstrapping D_U} Paragraph 4: large body works weakly-supervised learning, dealing single-source weak supervision may suffer unreliability single sources error propagation; \wendi{sensitive single source} several works deal multiple sources, XXX , need make sure cite discuss them). Paragraph 5: introduce method, key idea, uniqueness compared existing methods. I feel current method description bit plain, need distill main ideas. I think main ideas are: - source reliability estimation neural classification benefit co-training framework \wendi{regularization} - conditional source reliability - self-training leverage unmatched samples obtain labeled instances. - maybe also mention rely pre-trained language models get good representations, helps denoising \wendi{high level: denoise, enhance} Other Sections: Section 2: make half page Section 3: 2.5 pages Section 4: 3 pages others: 1 page Something better show experiments: - multi-source weak supervision powerful this, already lot results - majority voting work - method works better existing weak supervision methods - happens use subsets multiple weak supervision sources - interpretations source reliability learned - different designs method work - would labeled data help } Text classification, relation extraction, question answering fundamental natural language tasks numerous applications document classification knowledge extraction. \zc{ Many NLP tasks formulated text classification problems, sentiment analysis, topic classification, relation extraction, XXX .} Recently, deep neural nets demonstrated superior performance problem \zc{briefly mention earlier dnns , recent trend BERT-based ones}, largely due capabilities automatically learning distributed features fitting complex functions based large-scale training data. However, many real world scenarios, large-scale labeled data unavailable manually annotating data large scale prohibitively expensive. \zc{merge paragraph 1 2} To address label scarcity bottleneck, study problem using heuristic rules train neural text classifiers. While domain experts \zc{not necessarily domain experts, also KBs.} often cannot afford annotate millions documents carefully, easily provide set heuristic rules weak supervision signals. Using rules automatically induce labeled data model training , meanwhile introduces two major challenges: label noise low label coverage. %The first challenge label noise. The label noise issue arises heuristic rules often simple capture rich contexts complex patterns text classification. For instance, rule `expensive \ negative' restaurant ranking correct times, sometimes wrong delicious food deserves high price. Seed rules limited coverage real-life text corpora often long-tail distributions, many heuristic rules defined frequent keywords, instances containing long-tail keywords cannot covered given rules. \zc{can merge previous paragraph shorten it.} There studies attempt use weak supervision deep text classification. Unfortunately, performance limited two challenges. Ratner \etal proposed data programming method, uses heuristic rules labeling functions trains discriminative models using automatically created labeled data. However, training data annotated data programming come instances directly matched rules, making model limited performance unmatched data. Meng \etal proposed deep self-training method, uses weak supervision learn initial model updates model using model's confident predictions. However, self-training procedure overfit label noise suffer error propagation. \sep Our contributions. We propose new method uses weak supervision train deep text classifiers label-efficient way, addressing label noise label coverage issues. We assume multiple weak supervision sources provide complementary sets heuristic rules. \zc{the previous two sentences merged.} Our idea complementary information multiple sources reduce label noise, also effectively bootstrap unlabeled data improve label coverage, making possible learn accurate deep text classifier weak supervision. Motivated above, propose model two carefully designed components. The first component rule-based classifier \zc{ rule reliability estimators} using conditional soft attention mechanism. Given weak labels annotators document representations, learn reliability scores labeling sources, emphasize weak annotators' opinions informative particular corpus. We use reliability scores aggregate disparate weak labels denoised pseudo label. \zc{need highlight rule reliability conditional input text features} The second component neural classifier learns labels distributed feature representations samples, matched unmatched. This neural classifier supervised denoised labels confident predictions unmatched data, enabling solve rule coverage problem simultaneously enhancing rule denoiser via patterns present unmatched data. The two components integrated end-to-end training framework. \zc{maybe also say use pre-trained BERT feature extractor: representation power help denoiser work better.} We evaluate model four text classification tasks, including sentiment analysis, topic classification, spam classification, information extraction. The results five benchmarks show that: soft-attention module indeed effectively denoise noisy training data induced weak supervision sources, achieving \textasciitilde{}\% accuracy denoising; co-training design improve prediction accuracy unmatched samples, achieving least \% accuracy increase them. In terms overall performance, model consistently outperforms state-of-the-art weakly supervised methods , semi-supervised methods , fine-tuning methods 9.2\% average. Further, show denoised labels fed fully supervised models fine-tune models improve performance. % Our contributions summarized follows: % % =============================================== % Chao: I outline structure intro, fill extend paragraphs! % % Paragraph 1: Text classification one fundamental problems text mining, information retrieval, natural language processing. While deep neural nets % % achieved dominant performance text classification, highly label-hungry, often requiring hundreds thousands labeled samples achieve strong performance. This become key bottleneck applying deep % % text classifiers many real-life applications, large-scale labeled data expensive obtain. % % Paragraph 2: An overview existing methods handling label sparsity. Including: % % self-training methods, % % fine-tuning methods, % % weakly supervised methods. Think hard drawbacks. % % Paragraph 3: An overview model: propose deep neural text classifier, learned excessive labeled data, unlabeled data plus set easy-to-provide heuristic rules. % % Paragraph 4: Two challenges learning rules: Learning model heuristic rules difficult, rules induce noisy training data limited coverage. % % Paragraph 5: How address two challenges: % % First, label denoising module, estimates source reliability denoises rule-induced supervision soft attention mechanism. Second, self-learning module improving label coverage issue, iteratively predicts soft labels unmatched samples aggregating denoised multi-source classifiers. The two modules integrated neural co-training model, learned end-to-end manner. % % Paragraph 6: The results obtain real data % % A bullet list summarizing contributions:"," % While deep neural nets have achieved superior performance for % text classification, they highly rely on large-scale labeled data. Obtaining large-scale labeled data, however, is prohibitively % expensive in many applications.  We study the problem of learning neural text classifiers without using any labeled data, but only easy-to-provide rules as multiple weak supervision sources. This problem is challenging because rule-induced weak labels are often noisy and incomplete. To address these two challenges, we design a label denoiser, which estimates the source reliability using a conditional soft attention mechanism and then reduces label noise by aggregating rule-annotated weak labels. The denoised pseudo labels then supervise a neural classifier to predicts soft labels for unmatched samples, which address the rule coverage issue. % To address these challenges, we % propose an end-to-end model with two key components \zc{this sentence is not %   informative enough, need to deliver the key idea of our method in one sentence % here, and then use the remaining sentences to elaborate our idea.}. The first component is a % rule denoiser, which estimates conditional source reliability using a soft % attention mechanism and reduces label noise by aggregating rule-annotated weak % labels. The second is a neural classifier that predicts soft labels for % unmatchable samples to address the rule coverage issue. %The two components are integrated into a co-training framework, which can be trained end-to-end to mutually enhance each other. We evaluate our model on five benchmarks for sentiment, topic, and relation classifications. The results show that our model outperforms state-of-the-art weakly-supervised and semi-supervised methods consistently, and achieves comparable performance with fully-supervised methods even without any labeled data. Our code can be found at \url{https://github.com/weakrules/Denoise-multi-weak-sources}."
"% Recent work NLP seen flurry interest question: representations learned neural networks compositional? That is, representations longer phrases built recursively representations shorter phrases, many linguistic theories? If so, learn this? For years LSTM dominated language architectures. It remains popular architecture NLP, unlike Transformer-based models, trained small corpora~.\footnote{As evidence ongoing popularity LSTMs NLP, Google Scholar search restricted since 2019 finds 191 citations original LSTM paper 242 citations original Transformer paper .} \citet{abnar_transferring_2020} even found recurrent inductive biases behind LSTM's success essential distilling improve performance fully attentional models. However, reasons behind LSTM's effectiveness language domains remain poorly understood. A Transformer encode syntax using attention , LSTM variants explicitly encode syntax . So, success models partly explained ability model syntactic relationships predicting word. By contrast, LSTM simply scans sentence left right, accumulating meaning hidden representation one word time, using representation summarize entire preceding sequence predicting next word. Yet extensive evidence trained LSTMs also sensitive syntax. For example, recall history natural language data similarly Zipfian-distributed -gram data, implying exploit linguistic structure long-distance dependencies . Their internal representations appear encode constituency syntactic agreement . In paper, consider representations learned, kind inductive bias supports them. To understand LSTMs exploit syntax, use contextual decomposition , method computes much hidden representation LSTM depends particular past span words. We extend CD Decompositional Interdependence , measure interaction spans words produce representation particular timestep. For example, sentence ``Socrates asked student trick questions閳ユ瑢, might expect hidden representation LSTM word ``questions閳ユ瑢 interact primarily syntactic head ``asked閳ユ瑢, less direct object ``the student''. If so, LSTM could seen implementing compositional localism : hidden representation encodes meaning, meaning composed local syntactic relationships. Our experiments syntactically-parsed corpora illustrate property --- interdependence decreases syntactic distance, stratified surface distance. We turn hypothesis representations learned. Using simple synthetic corpus , allow LSTMs learn represent short sequences learn longer sequences dependent them. Our goal illustrate use representations short sequences order learn longer dependencies---if smaller constituents unfamiliar, LSTMs learn slowly. Further experiments isolate hierarchical behavior factors causing local relations learned first, indicating model tends build subtree smaller constituents. We conclude LSTMs compose hierachically learn bottom-up."," Recent work in NLP shows that LSTM language models capture hierarchical structure in language data. In contrast to existing work, we consider the learning process that leads to their compositional behavior. For a closer look at how an LSTM's sequential representations are composed hierarchically, we present a related measure of Decompositional Interdependence  between word meanings in an LSTM, based on their gate interactions. We connect this measure to syntax with experiments on English language data, where DI is higher on pairs of words with lower syntactic distance. To explore the inductive biases that cause these compositional representations to arise during training, we conduct simple experiments on synthetic data. These synthetic experiments support a specific hypothesis about how hierarchical structures are discovered over the course of training: that LSTM constituent representations are learned bottom-up, relying on effective representations of their shorter children, rather than learning the longer-range relations independently from children."
"Systematic reviews part field evidence-based analysis, methodology conducting literature surveys, focus comprehensively summarising synthesising existing research purpose answering research questions . The aim process broad coverage avoid unknown bias creeping results via alternative cherry-picking scientific results . %As many relevant documents possible included, process also thoroughly documented aid replicability. Conducting systematic reviews requires trained researchers domain knowledge. The stages process time-consuming, vary much physical mental labour require . As result, systematic reviews suffer three primary challenges : So though systematic reviews shown effective less prone human biases , issues often prove prohibitive. \\ However, challenges well suited Machine Learning solutions, recently increase interest applying NLP process . In paper, investigate feasibility implementing multi-stage human process systematic review Machine Learning pipeline. We construct systematic review pipeline aims assist researchers organisations focusing livestock health various African countries previously performed reviews manually . The pipeline begins scraping articles, classifies whether include review, identifies data extract outputs spreadsheet. We discuss technical options evaluated steps. Pipeline components evaluated intrinsic metrics well pragmatic, extrinsic, considerations time effort saved. While previous work exists surveying applicability various Machine Learning methods toolkits systematic review process apply them, extant studies implement full system analyse trade-offs different methods training data creation, different annotation schemas, human expert hours needed build system, final accuracy. We experiment factors, well different architectures, aim informing planning implementation systematic review automation broadly. To goal, particularly experiment low resource scenarios generalisability. We investigate different thresholds training data document classifier different annotation schemas data extraction. We additionally test ability system generalise documents new countries. % also talk needing deep learning resources Key research questions follows: \paragraph{Extraction} Which techniques best identifying extracting desired information? \paragraph{Data Requirements} How much labelled training data needed? Can existing resources leveraged? \paragraph{Re-usability} How generalisable pipeline new diseases countries? \paragraph{Performance} What trade-off pipeline accuracy human time savings? \paragraph{Architecture \& Pre-training} How important model architecture applied extraction tasks? How important embedding pre-training, important pre-training scientific literature vs. general content ?\\ We find surprisingly little training data necessary get accurate document classifier, generalises well unseen African countries , enables systematic reviews expanded new areas essentially constant time. In text extraction experiments, find sentence phrase level extraction models play role pipeline, %given complementary strengths weaknesses kind data, phrase extraction, previously done task, performed better expected baseline CNN models BERT-based Transformers , Transformers based scientific pre-training performing best. We demonstrate creation labelled training data sped annotation tools, consideration given balance training examples present within data, since may require less data overall still maintaining good performance. Furthermore, besides automatic information extraction, much labour constructing systematic reviews saved simply automating process searching downloading documents. We empirically demonstrate three month pipeline systematic review automated require little human intervention, acceptable accuracy results. We release code, annotation schema, labelled data assist expansion systematic reviews via automation. While demonstrate system one domain, framework domain independent could applied kinds systematic reviews. New training data annotation schemes would necessary switch medical domains, findings time saving processes annotation would apply, confidence thresholds implement adjustable customise different levels accuracy human time trade-offs appropriate different fields. Our exploration necessary amounts training data accuracy generalisability broadly applicable."," Systematic reviews, which entail the extraction of data from large numbers of scientific documents, are an ideal avenue for the application of machine learning. They are vital to many fields of science and philanthropy, but are very time-consuming and require experts. Yet the three main stages of a systematic review are easily done automatically: searching for documents can be done via APIs and scrapers, selection of relevant documents can be done via binary classification, and extraction of data can be done via sequence-labelling classification. Despite the promise of automation for this field, little research exists that examines the various ways to automate each of these tasks. We construct a pipeline that automates each of these aspects, and experiment with many human-time vs. system quality trade-offs. We test the ability of classifiers to work well on small amounts of data and to generalise to data from countries not represented in the training data. We test different types of data extraction with varying difficulty in annotation, and five different neural architectures to do the extraction. We find that we can get surprising accuracy and generalisability of the whole pipeline system with only 2 weeks of human-expert annotation, which is only 15\% of the time it takes to do the whole review manually and can be repeated and extended to new data with no additional effort.\footnote{\hspace{0.1cm}Code and links to models available at \url{https://github.com/seraphinatarrant/systematic_reviews}}"
"Although recent neural models language made advances learning syntactic behavior, research continues suggest inductive bias plays key role data efficiency human-like syntactic generalization . Based long-held observation language exhibits hierarchical structure, previous work proposed coupling recurrent neural networks differentiable stack data structures give computational power pushdown automata , class automata recognize context-free languages . However, previously proposed differentiable stack data structures model deterministic stacks, store one version stack contents time, theoretically limiting power stack RNNs deterministic~CFLs. A sentence's syntactic structure often cannot fully resolved conclusion , requiring human listener track multiple possibilities hearing sentence. Past work psycholinguistics suggested models keep multiple candidate parses memory explain human reading times better models assume harsher computational constraints. This ability also plays important role calculating expectations facilitate efficient language processing . Current neural language models track multiple parses, learn syntax generalizations . We propose new differentiable stack data structure explicitly models nondeterministic PDA, adapting algorithm \citet{lang:1974} reformulating terms tensor operations. The algorithm able represent exponential number stack configurations using cubic time quadratic space complexity. As existing stack RNN architectures, combine data structure RNN controller, call resulting model \ourmodel{} . We predict nondeterminism help language processing two ways. First, improve trainability, since possible sequences stack operations contribute objective function, sequence used current model. Second, improve expressivity, able model concurrent parses ways deterministic stack cannot. We demonstrate claims comparing \om{} deterministic stack RNNs formal language modeling tasks varying complexity. To show nondeterminism aids training, show \om{} achieves lower cross-entropy, fewer parameter updates, deterministic CFLs. To show nondeterminism improves expressivity, show \om{} achieves lower cross-entropy nondeterministic CFLs, including ``hardest context-free language"" , language least difficult parse CFL inherently requires nondeterminism. Our code available \url{https://github.com/bdusell/nondeterministic-stack-rnn}."," We present a differentiable stack data structure that simultaneously and tractably encodes an exponential number of stack configurations, based on Lang闁炽儲鐛 algorithm for simulating nondeterministic pushdown automata. We call the combination of this data structure with a recurrent neural network  controller a \ourmodel. We compare our model against existing stack RNNs on various formal languages, demonstrating that our model converges more reliably to algorithmic behavior on deterministic tasks, and achieves lower cross-entropy on inherently nondeterministic tasks."
"Cryptography used since antiquity encode important secrets. There many unsolved ciphers historical interest, residing national libraries, private archives, recent corpora collection projects . Solving classical ciphers automatic methods needed step analyzing materials. In work, concerned automatic algorithms solving historically-common type book code, word tokens systematically replaced numerical codes. Encoding decoding done reference dictionary possessed sender recipient. While type code common, automatic decipherment algorithms yet exist. The contributions work are:"," We solve difficult word-based substitution codes by constructing a decoding lattice and searching that lattice with a neural language model.  We apply our method to a set of enciphered letters exchanged between US Army General James Wilkinson and agents of the Spanish Crown in the late 1700s and early 1800s, obtained from the US Library of Congress.  We are able to decipher 75.1\% of the cipher-word tokens correctly."
"Neural network language models , pretrained vast amounts raw text, become dominant input downstream tasks . Commonly, tasks involve aspects language comprehension . One explicit example coreference resolution, wherein anaphora linked antecedents requiring knowledge syntax, semantics, world-knowledge match human-like comprehension. Recent work suggested LMs acquire abstract, often human-like, knowledge syntax \cite[e.g.,][]{gulordavaetal18, futrelletal2018, huetal2020-systematic}. Additionally, knowledge grammatical referential aspects linking pronoun antecedent noun demonstrated transformer long short-term memory architectures . Humans able modulate referential syntactic comprehension given abstract linguistic knowledge . Contrary humans, find discourse structure influences LM behavior reference, syntax, despite model representations encode necessary discourse information. The particular discourse structure examined governed implicit causality verbs . Such verbs influence pronoun comprehension: \ex. \a. Sally frightened Mary terrifying. \b. Sally feared Mary terrifying. In , agrees gender Sally Mary, possible antecedents. However, English speakers overwhelmingly interpret referring Sally Mary , despite semantic overlap verbs. Verbs subject preference called subject-biased IC verbs, verbs object preference called object-biased IC verbs. In addition pronoun resolution, IC verbs also interact relative clause attachment: \ex. \a. John babysits children musician who... \a. ...lives La Jolla. \b. ...are students private school. \z. \b. John detests children musician who... \a. ...lives La Jolla. \b. ...are arrogant rude. \z. \z. \citep[from][]{rohdeetal2011} In , sentence fragments possible continuations modifying musician continuations modifying children . We might expect human continuation preferences . However, use object-biased IC verb increases proportion continuations given human participants refer children . Without object-biased IC verb majority continuations refer recent noun . Effects IC received renewed interest field psycholinguistics recent years \cite[e.g.,][]{kehler2008coherence, ferstl2011implicit, hartshorne2013verb, hartshorne2014, williams_IC_2020}. Current accounts IC claim phenomenon inherently linguistic process, rely additional pragmatic inferences comprehenders \cite[e.g.,][]{rohdeetal2011, hartshorne2013verb}. Thus, IC argued contained within linguistic signal, analogous evidence syntactic agreement verb argument structure within corpora. We hypothesize claims correct, current LMs able condition reference syntactic attachment IC verbs language data . We tested hypothesis using unidirectional transformer long short-term memory network \citep[LSTM;][]{hochreiterschmidhuber97} language models. We find LSTM LMs fail acquire subject/object-biased IC distinction influences reference RC attachment. In contrast, transformers learned representational distinction subject-biased object-biased IC verbs interacts reference RC attachment, distinction influenced model output reference. The apparent failure model syntactic behavior exhibit IC contrast present model representations raises questions broader capacity LMs display human-like linguistic knowledge.","  Language models  trained on large quantities of text have been claimed to acquire abstract linguistic representations. Our work tests the robustness of these abstractions by focusing on the ability of LMs to learn interactions between different linguistic representations. In particular, we utilized stimuli from psycholinguistic studies showing that humans can condition reference  and syntactic processing on the same discourse structure . We compared both transformer and long short-term memory LMs to find that, contrary to humans, implicit causality only influences LM behavior for reference, not syntax, despite model representations that encode the necessary discourse information. Our results further suggest that LM behavior can contradict not only learned representations of discourse but also syntactic agreement, pointing to shortcomings of standard language modeling."
"Word ordering often determines meaning sentence; therefore utilize position information word sequence important topic NLP widely investigated recently. A common approach modeling word ordering use recurrent neural networks , long short-term memory gated recurrent unit , use hidden state represent information ordered sequence update model weights backpropagation time ; thus ordering information modeled structure. However, RNN BPTT inefficient modern GPU computation due difficulty parallelization time dependency. To solve problem, recent work, convolutional seq2seq Transformers apply convolutional neural network self-attention respectively, succeed eliminate time dependency take computational advantage GPU. Instead storing information ordered sequences, models utilize position information using feature-level positional encoding. For example, convolutional seq2seq proposed learnable position embeddings represent positions sequence. Recently, various pre-trained Transformer language models keep breaking state-of-the-art results numerous NLP tasks. There many different ways pre-train Transformer language model. For example, using encoder, decoder, whole part Transformer, adapting self-attention masks, training different objectives . However, terms positional encoding, work used learned position embedding originally proposed convolutional seq2seq without analysis, even different objectives may learn completely different position information. Motivated observations, goal investigate position information pre-trained Transformers could learn different settings. We conduct deep analysis learned position embeddings among three iconic pre-trained Transformer language models: BERT , RoBERTa GPT-2 . To examine performance different NLP types, conduct experiments text classification, language modeling, machine translation, empirically analyze explain meaning influence position embeddings different aspects. The contributions paper 3-fold:"," In recent years, pre-trained Transformers have dominated the majority of NLP benchmark tasks.  Many variants of pre-trained Transformers have kept breaking out, and most focus on designing different pre-training objectives or variants of self-attention.  Embedding the position information in the self-attention mechanism is also an indispensable factor in Transformers however is often discussed at will.  Therefore, this paper carries out an empirical study on position embeddings of mainstream pre-trained Transformers, which mainly focuses on two questions: 1) Do position embeddings really learn the meaning of positions? 2) How do these different learned position embeddings affect Transformers for NLP tasks?  This paper focuses on providing a new insight of pre-trained position embeddings through feature-level analysis and empirical experiments on most of iconic NLP tasks. It is believed that our experimental results can guide the future work to choose the suitable positional encoding function for specific tasks given the application property.\footnote{The source code is available at: \url{https://github.com/MiuLab/PE-Study}} %to make our study more convincing."
"Autoregressive sequence sequence models Transformers trained maximize log-likelihood target sequence, conditioned input sequence. Furthermore, approximate inference typically done using beam search algorithm , allows controlled exploration exponential search space. However, seq2seq models suffer discrepancy token level classification learning sequence level inference search. This discrepancy also manifests form curse sentence length i.e. models' proclivity generate shorter sentences inference, received considerable attention literature . In work, focus better model long-tailed phenomena, i.e. predicting long-tail low-frequency words/tokens , seq2seq models, task Neural Machine Translation . Essentially, two mechanisms tokens low frequency receive lower probabilities prediction: firstly, norms embeddings low frequency tokens smaller, means dot-product based softmax operation generate probability distribution vocabulary, receive less probability. This well known Image Classification Neural Language Models . Since NMT shares dot-product softmax operation, observe phenomenon holds true NMT well. For example, observe Spearman閳ユ獨 Rank Correlation 0.43 norms token embeddings frequency, standard transformer model trained IWSLT-14 De-En dataset . Secondly, transformer based NMT, embeddings low frequency tokens lie different subregion space semantically similar high frequency tokens, due different rates updates , thereby, making rare words token embeddings ineffective. Since token embeddings match context vector getting next-token probabilities, dot-product similarity score lower low frequency tokens, even semantically similar high frequency tokens. Further, better modeling long-tailed phenomena significant implications several text generation tasks, well compositional generalization . To end, primarily ask seek answers following two fundamental questions context NMT: By exploring questions, arrive conclusion widely used cross-entropy loss limits NMT models' expressivity inference propose new loss function better incorporate inductive biases beam search."," State-of-the-art Neural Machine Translation  models struggle with generating low-frequency tokens, tackling which remains a major challenge. The analysis of long-tailed phenomena in the context of structured prediction tasks is further hindered by the added complexities of search during inference. In this work, we quantitatively characterize such long-tailed phenomena at two levels of abstraction, namely, token classification and sequence generation. We propose a new loss function, the Anti-Focal loss, to better adapt model training to the structural dependencies of conditional text generation by incorporating the inductive biases of beam search in the training process. We show the efficacy of the proposed technique on a number of Machine Translation  datasets, demonstrating that it leads to significant gains over cross-entropy across different language pairs, especially on the generation of low-frequency words. We have released the code to reproduce our results.\blfootnote{The first author is now a researcher at Microsoft, USA.}\footnote{\url{https://github.com/vyraun/long-tailed}} %"
"Grammar induction task learning grammar target corpus without exposure parsing ground truth expert-labeled tree structures . Recently emerging latent tree learning models provide new approach problem . They learn syntactic parsing indirect supervision main training tasks language modelling natural language inference. In study, analyze ON-LSTM , new latent tree learning model set state art unsupervised constituency parsing WSJ test published ICLR 2019. The model trained language modelling generate binary constituency parsing trees input sentences like one Figure . As far know, though excellent theoretical analysis paper ON-LSTM model focuses model's architecture parsing algorithm, systematic analysis parses model generates. There in-depth investigations whether model's parsing behavior consistent among different restarts parses produces different PTB gold standards. Answering questions crucial better understanding capability model may bring insights build advanced latent tree learning models future. Therefore, replicate model 5 random restarts look parses generates. We find ON-LSTM fairly consistent parsing behaviors across different restarts, achieving self F1 65.7 WSJ test. The model struggles correctly parse internal structures complex noun phrases. The model consistent tendency overestimate height split points right verbs auxiliary verbs, leading major difference parses Penn Treebank gold-standard parses. We speculate problems explained training task, unidirectional language modelling, thus hypothesize training bidirectional model syntax-related task like acceptability judgement might good choice future latent tree learning models."," Recent latent tree learning models can learn constituency parsing without any exposure to human-annotated tree structures. One such model is ON-LSTM \citep{ONLSTMShen}, which is trained on language modelling and has near-state-of-the-art performance on unsupervised parsing. In order to better understand the  performance and consistency of the model as well as how the parses it generates are different from gold-standard PTB parses, we replicate the model with different restarts and examine their parses. We find that  the model has reasonably consistent parsing behaviors across different restarts,  the model struggles with the internal structures of complex noun phrases,  the model has a tendency to overestimate the height of the split points right before verbs. We speculate that both problems could potentially be solved by adopting a different training task other than unidirectional language modelling."
"Deep learning become dominant approach address Natural Language Processing tasks, including text classification. With sufficient high-quality training data, deep learning models perform incredibly well . However, real-world cases, ideal datasets scarce. Often times, available datasets small, full regular irrelevant words, contain unintended biases . These lead suboptimal models undesirable properties. For example, models may biases sub-populations may work effectively wild overfit imperfect training data. To improve models, previous work looked different techniques beyond standard model fitting. If weaknesses training datasets models anticipated, strategies tailored mitigate weaknesses. For example, augmenting training data gender-swapped input texts helps reduce gender bias models . Adversarial training prevent models exploiting irrelevant and/or protected features . With limited number training examples, using human rationales prior knowledge together training labels help models perform better . Nonetheless, side-effects sub-optimal datasets cannot predicted found training thanks post-hoc error analysis. To rectify problems, attempts enable humans fix trained models . Since models usually complex understand, manually modifying model parameters possible. Existing techniques, therefore, allow humans provide feedback individual predictions instead. Then, additional training examples created based feedback retrain models. However, local improvements individual predictions could add inferior overall performance . Furthermore, existing techniques allow us rectify errors related examples hand provide way fix problems kept hidden model parameters. In paper, propose framework allows humans debug improve deep text classifiers disabling hidden features irrelevant classification task. We name framework FIND . FIND exploits explanation method, namely layer-wise relevance propagation , understand behavior classifier predicts training instance. Then aggregates information using word clouds create global visual picture model. This enables humans comprehend features automatically learned deep classifier decide disable features could undermine prediction accuracy testing. The main differences work existing work are: first, FIND leverages human feedback model components, individual predictions, perform debugging; second, FIND targets deep text classifiers convoluted traditional classifiers used existing work . We conducted three human experiments demonstrate usefulness FIND. For experiments, used classifiers convolutional neural networks , popular, well-performing architecture many text classification tasks including tasks experimented . The overall results show FIND human-in-the-loop improve text classifiers mitigate said problems datasets. After experiments, discuss generalization proposed framework tasks models. Overall, {\bf main contributions} paper are: The rest paper organized follows. Section explains related work analyzing, explaining, human-debugging text classifiers. Section proposes FIND, debugging framework. Section explains experimental setup followed three human experiments Section . Finally, Section discusses generalization framework concludes paper. Code datasets paper available \url{https://github.com/plkumjorn/FIND}."," Since obtaining a perfect training dataset  is hardly possible, many real-world text classifiers are trained on the available, yet imperfect, datasets.  These classifiers are thus likely to have undesirable properties. For instance, they may have biases against some sub-populations or may not work effectively in the wild due to overfitting.  In this paper, we propose FIND -- a framework which enables humans to debug deep learning text classifiers by disabling irrelevant hidden features. Experiments show that by using FIND, humans can improve CNN text classifiers which were trained under different types of imperfect datasets ."
"Commonsense reasoning important yet challenging task artificial intelligence natural language processing. Take commonsense question answering example, given question multiple choices, commonsense knowledge usually required make correct answer provided choices. Table show typical commonsense question answering examples extracted dataset commonsenseQA. \end{small} \end{center} \vskip -0.25in \end{table} Existing commonsense reasoning methods mainly utilize raw texts conduct data representation answer prediction process. However, background knowledge required commonsense reasoning task, spatial relations, causes effects, scientific facts social conventions, usually explicitly provided text. Therefore, difficult capture knowledge solely raw texts. Some works propose leverage knowledge bases extract related commonsense knowledge. However, construction knowledge base expensive, contained knowledge limited fulfill requirement. Furthermore, commonsense question answering datasets, CommonsenseQA, constructed existing knowledge base, e.g., ConceptNet . So unfair use knowledge base tasks. To sum up, automatically learn commonsense remains challenging problem NLP. Motivated fact images usually contain richer scene information, viewed important supplementary resource perceive commonsense knowledge, paper proposes learn commonsense images incorporate knowledge commonsense reasoning process. Take question `Where good idea required fire extinguisher?' shown Table example. Solving problem requires strong background knowledge fire extinguishers usually equipped public places, hospitals, schools, school buses. We see background knowledge explicitly provided raw texts, meanwhile, abstract complex extracted current language model techniques. In case, images help. For example, could find many images fire extinguishers appear scenes public places. Therefore, commonsense knowledge could learned perceiving scene information images, corresponding question well answered. These analyses accordance Minsky's statement \citet{minsky2000commonsense}, `perhaps good architecture theory based multiple representations multi-modal reasoning would help us design better systems allow us study understand commonsense reasoning.' Our approach, named Loire , consists two stages, i.e.~visual commonsense learning knowledge-augmented reasoning. In first stage, scene layout generation task conducted bi-modal data representative benchmark COCO. Firstly, text encoder Visual BERT employed obtain representation caption. ViBERT incorporated recurrent encoder-decoder structure labeled bounding box generation. This module trained separately supervised learning approach, based ground-truth bounding boxes images. In way, required visual commonsense knowledge encoded ViBERT. In following commonsense reasoning stage, concerned text representations obtained concatenating ViBERT traditional pre-trained language model, e.g. ~BERT. Then language model fine-tuned commonsense reasoning data, ViBERT fixed prior knowledge. Experimental results two commonsense reasoning tasks, i.e.~CommonsenseQA WinoGrande , demonstrate learnt commonsense images brings improvements traditional models, BERT fine-tune RoBERTa fine-tune . We also give case studies show learned visual commonsense knowledge helps reasoning process. To best knowledge, first propose learning commonsense knowledge images facilitate commonsense reasoning NLP. The proposed model using scene layout generation supervision demonstrates preliminary exploration direction. Other methods like learning commonsense retrieved relevant images could also investigated. We believe novel approach may provide new perspective commonsense reasoning NLP."," This paper proposes a novel approach to learn commonsense from images, instead of limited raw texts or costly constructed knowledge bases, for the commonsense reasoning problem in NLP. Our motivation comes from the fact that an image is worth a thousand words, where richer scene information could be leveraged to help distill the commonsense knowledge, which is often hidden in languages. Our approach, namely Loire, consists of two stages. In the first stage, a bi-modal sequence-to-sequence approach is utilized to conduct the scene layout generation task, based on a text representation model ViBERT. In this way, the required visual scene knowledge, such as spatial relations, will be encoded in ViBERT by the supervised learning process with some bi-modal data like COCO. Then ViBERT is concatenated with a pre-trained language model to perform the downstream commonsense reasoning tasks. Experimental results on two commonsense reasoning problems, i.e.~commonsense question answering and pronoun resolution, demonstrate that Loire outperforms traditional language-based methods. We also give some case studies to show what knowledge is learned from images and explain how the generated scene layout helps the commonsense reasoning process. \let\thefootnote\relax\footnotetext{*Corresponding Author}"
"% Neural dependency parsers predicts relations interactions words equipped nerual networks. Graph-based dependency parsing popular approach dependency parsing scores parse components sentence finds highest scoring tree inference. First-order graph-based dependency parsing takes individual dependency edges components parse tree, higher-order dependency parsing considers complex components consisting multiple edges. There exist exact inference algorithms approximate inference algorithms find best parse tree. %Neural network based dependency parsers become popular due high efficiency accuracy. Transition-based dependency parsing builds dependency trees making series decisions sequence words, graph-based dependency parser first encodes words sentence using bi-directional LSTM score components parse tree find highest scoring tree inference. Recent work focused neural network based graph dependency parsers . \citet{dozat2016deep} proposed first-order graph-based neural dependency parsing approach simple head-selection training objective. It uses biaffine function score dependency edges high efficiency good performance. Subsequent work introduced second-order inference parser. \citet{ji-etal-2019-graph} proposed graph neural network captures second-order information token representations, used first-order parsing. Very recently, \citet{zhang2020efficient} proposed efficient second-order tree CRF model dependency parsing achieved state-of-the-art performance. %Higher-order dependency parsing takes complex higher-order components like siblings grandparents consideration decoding phase uses algorithms like dynamic programming exact inference. Such kind higher-order components increases global information inference results improvements parsing accuracy, also make inference slower complicated. Recent work graph-based higher-order dependency parsing semantic dependency parsing focused approximate inference graph, , much faster minor performance reduction compared exact inference algorithm. % \citet{falenska-kuhn-2019-non} also showed adding second-order inference BiLSTM-based parser leads small improvements. \citet{wang-etal-2019-second} proposed second-order approach semantic dependency parsing , tree constraint syntactic dependency parsing. They employed end-to-end neural network derived message-passing algorithms approximate second-order parsing achieved state-of-the-art accuracies SDP. In paper, first show previously proposed second-order semantic dependency parser applied syntactic dependency parsing simple modifications. The parser end-to-end neural network derived message passing inference conditional random field encodes second-order parsing problem. We propose alternative conditional random field incorporates head-selection constraint syntactic dependency parsing, derive novel second-order dependency parser. We empirically compare two second-order approaches first-order baselines English Penn Tree Bank 3.0 , Chinese Penn Tree Bank 5.1 datasets 12 languages Universal Dependencies . We show approaches achieve state-of-the-art performance PTB CTB approaches significantly faster recently proposed second-order parsers. We also make two interesting observations empirical study. First, common belief contextual word embeddings ELMo BERT already conveys sufficient high-order information renders high-order parsing less useful, find second-order decoding still helpful even strong contextual embeddings like BERT. Second, \citet{zhang-etal-2019-empirical} previously found incoperating head-selection constraint helpful first-order parsing, find better loss function design hyper-parameter tuning first- second-order parsers without head-selection constraint match accuracy parsers head-selection constraint even outperform latter using BERT embedding. Our approaches closely related work \citet{gormley-etal-2015-approximation}, proposed non-neural second-order parser based Loopy Belief Propagation . Our work differs that: 1) use Mean Field Variational Inference instead LBP, \citet{wang-etal-2019-second} found faster equally accurate practice; 2) add head-selection constraint include global tree constraint shown produce slight improvement would complicate neural network design implementation; 3) employ modern neural encoders achieve much better parsing accuracy. Our approaches also closely related recent work \citet{turbo2020}. The main difference use MFVI use dual decomposition algorithm approximate inference. % In recent work semantic dependency parsing , \citet{wang-etal-2019-second} proposed second-order parser following first-order parser \citet{dozat-manning-2018-simpler}. % %encodes first-order score following \citet{dozat-manning-2018-simpler} biaffine functions second-order score trilinear functions. % They used Mean Field Variational Inference Loopy Belief Propagation algorithm pass messages Conditional Random Field trained end-to-end manner. The approach SDP sees existence every single edge binary classification problem also applied tree-based dependency parsing. \citet{zhang-etal-2019-empirical} compared different structured outputs dependency parsing showed first-order dependency parsing, head constraint \citet{dozat2016deep} stronger binary classification structure \citet{dozat-manning-2018-simpler} dependency parsing. % In paper, adopt message passing method MFVI dependency parsing additionally add Local head constraint second-order inference procedure, views problem head-selection classification problem. We investigate advantage Single Local structured output second-order parsers show second-order parsers achieve state-of-the-art performance PTB CTB. Both second-order parsers Local Single structured outputs outperform first-order parser \citet{dozat2016deep} improvement BERT embeddings. Compared approach \citet{ji-etal-2019-graph} decodes second-order information passing token features graph neural network, second-order parsers message passing interpretive follow previous higher-order approaches assigns scores components. \citet{gormley-etal-2015-approximation} proposed second-order parser Single structured output tree constraint dependency parsing using LBP. Compared approach, consider Local head constraint. We use MFVI algorithm faster practice, need time-consuming Inside-Outside algorithm keep tree structure training. Furthermore, compare structured output tree constraint second-order parser empirical investigation \citet{zhang-etal-2019-empirical}, tree constraint gives modest improvement compared first-order Local approach. We believe advantage tree constraint diminished second-order parser considers tree components. %"," In this paper, we propose second-order graph-based neural dependency parsing using message passing and end-to-end neural networks. We empirically show that our approaches match the accuracy of very recent state-of-the-art second-order graph-based neural dependency parsers and have significantly faster speed in both training and testing. We also empirically show the advantage of second-order parsing over first-order parsing and observe that the usefulness of the head-selection structured constraint vanishes when using BERT embedding. %We adapt a previous approach that predicts dependency edges independently and we also propose a new approach that incorporates the head-selection structural constraint."
"Our SJTU-NICT team participated WMT20 shared task, including supervised track, unsupervised, low-resource track. During participation, placed attention Polish English English Chinese supervised track, unsupervised low-resource track, German Upper Sorbian directions focused. Our baseline system supervised track based Transformer big architecture proposed \citet{vaswani2017attention}, open-source implementation version Fairseq adopted. In unsupervised low-resource track, draw successful experience XLM framework , used two-stage training mode masked language modeling pre-training + back-translation finetune obtain strong baseline performance. Marian toolkit utilized training decoder reranking using machine translation targets instead common GPT-style language modeling targets. In order better play role WMT evaluation polishing methods proposed improved team , divided three language pairs participated three categories: % In supervised PLEN translation direction, based XLM framework pre-train Polish language model using common crawl news crawl monolingual data, proposed XLM enhanced NMT model inspired idea incorporating BERT NMT . Besides, trained bidirectional translation model EN-PL based parallel corpus finetuned PLEN direction. In supervised ENZH translation document information, propose document enhanced NMT model based Longformer . The training proposed document enhanced NMT model split three stages. In first stage, pre-train Longformer document encoder MLM target document text Wikipedia dumps, UN News, News Commentary monolingual corpus. A conventional Transformer-big NMT model trained second stage. In final stage, Longformer encoder conventional Transformer big NMT model used initialize full document-enhanced NMT model parameters, Longformer encoder adopted extract representations document input sequence, document representations fused layer encoder decoder NMT model attention mechanisms. In unsupervised machine translation track DE-HSB, experimented reference language based UNMT framework proposed recently. Under framework, choose English reference language, use Europarl parallel corpus EN-DE enhance unsupervised machine translation DE HSB. Specifically, adopted reference language translation , reference language back-translation , cross-lingual back-translation three training targets help cross-lingual agreement provided EN-DE parallel corpus enhance unsupervised translation performance. Due introduction explicit supervision signals brought parallel corpus low-resource machine translation track DE-HSB, discarded use weaker agreement provided reference language, conducted joint training unsupervised back-translation supervised translation directly, introduced BT-BLEU based collaborative filtering technology self-training. In addition, inspired previous work , also use MLM translation language modeling continue pre-training model machine translation training. In addition, basic NMT models, empower training process proposed data-dependent gaussian prior objective , model maintain diversity output. When main model training finished, TF-IDF algorithm employed filter training set according input test set, training subset whose domain similar test set obtained, used finetune model reducing performance degradation caused domain inconsistency. For final submission, ensemble several different trained models outputs -best predictions, used decoder trained Marian toolkit performs reranking get final system output.","  In this paper, we introduced our joint team SJTU-NICT 's participation in the WMT 2020 machine translation shared task. In this shared task, we participated in four translation directions of three language pairs: English-Chinese, English-Polish on supervised machine translation track, German-Upper Sorbian on low-resource and unsupervised machine translation tracks. Based on different conditions of language pairs, we have experimented with diverse neural machine translation  techniques: document-enhanced NMT, XLM pre-trained language model enhanced NMT, bidirectional translation as a pre-training, reference language based UNMT,  data-dependent gaussian prior objective, and BT-BLEU collaborative filtering self-training. We also used the TF-IDF algorithm to filter the training set to obtain a domain more similar set with the test set for finetuning. In our submissions, the primary systems won the first place on English to Chinese, Polish to English, and German to Upper Sorbian translation directions."
"Neural summarizers achieved impressive performance evaluated ROUGE ~ in-domain setting, recent success pre-trained models drives state-of-the-art results benchmarks new level ~. However, superior performance guarantee perfect system since exsiting models tend show defects evaluated aspects. For example, \citet{zhang-etal-2018-abstractiveness} observes many abstractive systems tend near-extractive practice. \citet{cao2018faithful,wang2020asking,kryscinski2019evaluating,maynez2020faithfulness,durmus2020feqa} reveal generated summaries factually incorrect. These non-mainstream evaluation methods make easier identify model's weaknesses. Orthogonal two evaluation aspects, aim diagnose limitation existing systems cross-dataset evaluation, summarization system trained one corpus would evaluated range out-of-dataset corpora. Instead evaluating quality summarizers solely based one dataset multiple datasets individually, cross-dataset evaluation enables us evaluate model performance different angle. For example, Fig. shows ranking summarization systems studied paper different evaluation metrics, ranking list `` in-dataset R2'' obtained traditional ranking criteria two based designed cross-dataset measures. Intuitively, observe 1) different definitions ``good'' system various evaluation aspects; 2) abstractive extractive systems exhibit diverse behaviors evaluated cross-dataset setting. The example recaps general motivation work, encouraging us rethink generalization ability current top-scoring summarization systems perspective cross-dataset evaluation. Specifically, ask two questions follows: Q1: {How different neural architectures summarizers influence cross-dataset generalization performances?} When designing summarization systems, plethora neural components adopted ~. For example, copy coverage mechanisms improve cross-dataset generalization ability summarizers? Is risk BERT-based summarizers perform worse adapted new areas compared ones without BERT? So far, generalization ability current summarization systems transferring new datasets still remains unclear, poses significant challenge design reliable system realistic scenarios. Thus, work, take closer look effect model architectures cross-dataset generalization setting. Q2: {Do different generation ways summarizers influence cross-dataset generalization ability?} Extractive abstractive models, two typical ways summarize texts, usually follow diverse learning frameworks favor different datasets. It would absorbing know discrepancy perspective cross-dataset generalization. To answer questions above, conducted comprehensive experimental analysis, involves eleven summarization systems , five benchmark datasets different domains, two evaluation aspects. Tab. illustrates overall analysis framework. We explore effect different architectures generation ways model generalization ability order answer Q1 Q2. Semantic equivalency factuality adopted characterize different aspects cross-dataset generalization ability. Additionally, strengthen analysis presenting two views evaluation: holistic fine-grained views . }% % \end{table}% Our contributions summarized as: 1) Cross-dataset evaluation orthogonal evaluation aspects , used re-evaluate current summarization systems, accelerating creation robust summarization systems. 2) We design two measures Stiffness Stableness, could help us characterize generalization ability different views, encouraging us diagnose weaknesses state-of-the-art systems. 3) We conduct dataset bias-aided analysis suggest better understanding datasets helpful us interpret systems' behaviours."," Neural network-based models augmented with unsupervised pre-trained knowledge have achieved impressive performance on text summarization. However, most existing evaluation methods are limited to an in-domain setting, where summarizers are trained and evaluated on the same dataset. We argue that this approach can narrow our understanding of the generalization ability for different summarization systems. In this paper, we perform an in-depth analysis of characteristics of different datasets and investigate the performance of different summarization models under a cross-dataset setting, in which a summarizer trained on one corpus will be evaluated on a range of out-of-domain corpora. A comprehensive study of 11 representative summarization systems on 5 datasets from different domains reveals the effect of model architectures and generation ways  on model generalization ability. Further, experimental results shed light on the limitations of existing summarizers. Brief introduction and supplementary code can be found in \url{https://github.com/zide05/CDEvalSumm}."
"As robots deployed collaborative applications like healthcare household assistance , growing need reliable human-robot communication. One communication modality user-friendly versatile natural language; end, focus robust natural language interfaces map utterances executable behavior . Most existing work NLIs falls static train-then-deploy paradigm: models first trained large datasets pairs deployed, hope reliably generalize new utterances. Yet, happens models make mistakes faced types utterances unseen training --- example, providing household robot novel utterance like ``wash coffee mug?'' Such static systems fail way recover, burdening user find alternate utterances accomplish task . Instead, argue NLIs need dynamic adaptive, learning interactively user feedback index perform complicated behaviors. In work, explore building NLIs simulated robotics learn real humans. Inspired \citet{wang2017naturalizing}, leverage idea learning decomposition learn new abstractions. Just like human interactively teaches new task friend breaking down, users interactively teach system simplifying utterances system cannot understand lower-level utterances . To map language executable behavior, \citet{wang2017naturalizing} \citet{thomason2019improving} built adaptive NLIs leverage grammar-based parsers allow reliable one-shot generalization lack lexical flexibility. For example, grammar-based system understands ``wash coffee mug'' may generalize ``clean mug.'' Meanwhile, recent semantic parsers based primarily neural sequence-to-sequence models . While models excel lexical flexibility perspective, lack ability perform reliable one-shot generalization: difficult train generalize individual examples . In paper propose new interactive NLI lexically flexible reliably efficiently perform one-shot generalization. We introduce novel exemplar-based neural network semantic parser first abstracts away entities , allowing generalization previously taught utterances novel object combinations. Our parser retrieves corresponding ``lifted'' utterance respective program training examples based learned metric , giving us lexical flexibility sequence-to-sequence models. We demonstrate efficacy learning decomposition framework set human-in-the-loop experiments crowdworkers use NLI solve suite simulated robotics tasks household environments. Crucially, completing task, update semantic parser users immediately reuse taught. We show time, users able complete complex tasks efficiently exemplar-based method compared neural sequence-to-sequence baseline. However, straightforward tasks completed fewer steps, see similar performance baseline. We end error analysis discussion user trust incentives context building interactive semantic parsing systems, paving way future work better realizes potential interactive paradigm.","  Our goal is to create an interactive natural language interface that efficiently and reliably learns from users to complete tasks in simulated robotics settings. We introduce a neural semantic parsing system that learns new high-level abstractions through decomposition: users interactively teach the system by breaking down high-level utterances describing novel behavior into low-level steps that it can understand. Unfortunately, existing methods either rely on grammars which parse sentences with limited flexibility, or neural sequence-to-sequence models that do not learn efficiently or reliably from individual examples. Our approach bridges this gap, demonstrating the flexibility of modern neural systems, as well as the one-shot reliable generalization of grammar-based methods. Our crowdsourced interactive experiments suggest that over time, users complete complex tasks more efficiently while using our system by leveraging what they just taught. At the same time, getting users to trust the system enough to be incentivized to teach high-level utterances is still an ongoing challenge. We end with a discussion of some of the obstacles we need to overcome to fully realize the potential of the interactive paradigm."
"As neural machine translation significantly improved sentence-level translation qualities, recent studies focused document-level translation. In particular, discourse document-level translation one central research interests, addressing coreference anaphora resolution; preserving cohesion coherence translation; e.g.,. In study, tackle problem lexical cohesion, aims consistently use target words translate source words. discussed lexical cohesion significantly affects overall quality document translation. Table shows comparison lexically incohesive cohesive translations two consecutive Japanese sentences. The incohesive translations translate Japanese word ``'' ``clock'' ``watch,'' cohesive translations consistently translate word ``watch.'' Previous studies approached discourse phenomena NMT using context-aware NMT model, inputs previous source sentences translations contexts. However,~ showed lexical cohesion hard solve context-aware models. We conjecture context-aware models handle previous translations whole sensitive enough word usage consistency. In study, employ copy mechanism context-aware NMT model document-level translation explicitly address lexical cohesion problem. Our model computes probability copying target word previous translation outputs boosts output probability translation current sentence. We conduct experiments Japanese English document translation. % using evaluation dataset designed discourse phenomena. The results indicate model achieves significantly better lexical cohesion, comparing previous context-aware NMT models. \end{adjustbox} \end{table*}"," Lexically cohesive translations preserve consistency in word choices in document-level translation.  We employ a copy mechanism into a context-aware neural machine translation model to allow copying words from previous translation outputs.  Different from previous context-aware neural machine translation models that handle all the discourse phenomena implicitly, our model explicitly addresses the lexical cohesion problem by boosting the probabilities to output words consistently.   We conduct experiments on Japanese to English translation using an evaluation dataset for discourse translation.  The results showed that the proposed model significantly improved lexical cohesion compared to previous context-aware models."
"% ============== version 5.0 ================= Intent detection, fundamental component task-oriented dialogue system , increasingly raising attention Multi-Label Classification problem , since single utterance often carries multiple user intents . In real-world scenarios, intent detection often suffers lack training data, dialogue tasks/domains change rapidly new domains usually contain data examples. Recent success Few-Shot Learning presents promising solution data scarcity challenges. It provides human-like learning paradigm generalizes learning examples exploiting prior experience. % old domains. %For multi-label intent detection, state-of-the-art works adopt ``one-vs-rest'' strategy convert multi-class classification binary-class classifications . State-of-the-art works multi-label intent detection focus threshold-based strategy, common practice estimating label-instance relevance scores picking intent labels score higher threshold value . Usually, coordination respective quality two modules, i.e. thresholding relevance scoring, crucial performance MLC models. However, few-shot scenarios, multi-label setting poses unique challenges threshold estimation label-instance relevance scoring. For thresholding, previous works explore tune fixed threshold learn thresholds data . But, thresholds work well learning examples sufficient. In few-shot scenarios, pretty hard determine appropriate thresholds examples. %In few-shot scenarios, pretty hard determine appropriate thresholds %with examples. %without overfitting limited examples. % limited examples. %For few-shot scenarios, pretty hard determine appropriate thresholds examples. Besides, also difficult directly transfer pre-learned thresholds due domain differences, differences label number per instance, score density scale. Estimation label-instance relevance scores also challenging. %It also challenging compute label-instance relevance scores. Few-shot learning achieved impressive progress similarity-based methods , relevance scores modeled label-instance similarities. And label representations obtained corresponding support examples. Unfortunately, despite huge success previous single-label tasks, similarity-based methods become impractical multi-label problems. When instances multiple labels, representations different labels may obtained support examples become confused other. For example Fig , intents query\_time query\_loc share support example thus label representation, %Such confused label representations makes impossible predict correct labels similarity scores. %In situations, vanilla similarities assign query x equal score query\_time query\_loc In paper, study few-shot learning problem multi-label intent detection propose novel framework tackle challenges thresholding label-instance relevance scoring. To solve thresholding difficulties prior-knowledge transferring domain adaption limited examples, propose Meta Calibrated Threshold mechanism first learns universal thresholding experience data-rich domains, adapts thresholds certain few-shot domains Kernel Regression based calibration. Such combination universal training domain-specific calibration allows estimate threshold using prior domain experience new domain knowledge. %Here, non-parametric learning method, Kernel Regression allows alleviate overfitting calibrating thresholds without finetuning. To tackle challenge confused label representation relevance scoring, propose Anchored Label Representation obtain well-separated label representations. Inspired idea embedding label name anchor points refine representation space , ALR uses embeddings label names additional anchors represents label support examples corresponding anchors. Different previous single-label intent detection uses label embedding additional features , label embeddings unique effects separating different labels metric space. Finally, encourage better coordination thresholding label-instance relevance scoring, introduce Logit-adapting mechanism MCT automatically adapts thresholds different score densities. Experiments two datasets show methods significantly outperform strong baselines. Our contributions summarized follows: We explore few-shot multi-label problem intent detection task-oriented dialogue, also early attempt few-shot multi-label classification. We propose Meta Calibrated Threshold mechanism Kernel Regression Logits Adapting estimates threshold using prior domain experience new domain knowledge. We introduce Anchored Label Representation obtain well-separated label representation better label-instance relevance scoring. %% ============== version 4.0 ================= %Intent detection, fundamental component task-oriented dialogue system , increasingly raising attention Multi-Label Classification problem , since single utterance often carries multiple user intents . %In real-world scenarios, intent detection often suffers lack training data, dialogue tasks/domains change rapidly new domains usually contain data examples. %Recent success Few-Shot Learning presents promising solution data scarcity challenges. %It provides human-like learning paradigm generalizes learning examples exploiting prior experience. %% old domains. % %%For multi-label intent detection, state-of-the-art works adopt ``one-vs-rest'' strategy convert multi-class classification binary-class classifications . %State-of-the-art works multi-label intent detection focus threshold-based strategy, common practice estimating label-instance relevance scores picking intent labels score higher threshold value . %Usually, coordination respective quality two modules, i.e. thresholding relevance scoring, crucial performance MLC models. %However, few-shot scenarios, multi-label setting poses unique challenges threshold estimation label-instance relevance scoring. % %For thresholding, previous works explore tune fixed threshold learn thresholds data . %But, thresholds work well learning examples sufficient. %In few-shot scenarios, pretty hard determine appropriate thresholds without overfitting. %% limited examples. %%For few-shot scenarios, pretty hard determine appropriate thresholds examples. %Besides, also difficult directly transfer pre-learned thresholds due domain differences, differences label number per instance, score density scale. % % % %It also challenging compute label-instance relevance scores. %Few-shot learning achieved impressive progress similarity-based methods , relevance scores modeled label-instance similarities. %And label representations obtained corresponding support examples. %Unfortunately, despite huge success previous single-label tasks, similarity-based methods become impractical multi-label problems. %When instances multiple labels, representations different labels may obtained support examples become confused other. %For example Fig , intents query\_time query\_loc share support example thus label representation, %%Such confused label representations %which makes impossible predict correct labels similarity scores. %%In situations, vanilla similarities assign query x equal score query\_time query\_loc % %In paper, study few-shot learning problem multi-label intent detection propose novel framework tackle challenges thresholding label-instance relevance scoring. % %To solve thresholding difficulties prior-knowledge transferring overfitting, propose Meta Calibrated Threshold mechanism first learns universal thresholding experience data-rich domains, adapts thresholds certain few-shot domains Kernel Regression based calibration. %Here, non-parametric learning method, Kernel Regression allows avoid overfitting calibrating thresholds without finetuning. % %To tackle challenge confused label representation relevance scoring, propose Anchored Label Representation obtain well-separated label representations. %Inspired idea embedding label name anchor points refine representation space , ALR uses embeddings label names additional anchors represents label support examples corresponding anchors. %Different previous single-label intent detection uses label embedding additional features , label embeddings unique effects separating different labels metric space. % %Finally, encourage better coordination thresholding label-instance relevance scoring, introduce logit-adapting mechanism MCT automatically adapts thresholds different score densities. % %Experiments two datasets show methods significantly outperform strong baselines. %Our contributions summarized follows: % We explore few-shot multi-label problem intent detection task-oriented dialogue, also early attempt few-shot multi-label classification. % We propose Meta Calibrated Threshold mechanism Kernel Regression Logits Adapting estimates threshold using prior domain experience new domain knowledge. % We introduce Anchored Label Representation obtain well-separated label representation better label-instance relevance scoring. %% ============== version 3.0 EMNLP version ================= % %Intent detection fundamental component task-oriented dialogue system . %In real-word scenarios, intent detection often suffers rapid changing domains, new domains usually lacking data may contain data examples. %Few-Shot Learning promising solution problem. %It provides human-like learning paradigm generalizes learning examples exploiting prior experience old domains. % %In addition data scarcity problem, intent detection also faces problem multi-label prediction. %As shown Fig , single utterance may carry multiple user intents. %For consideration, intent detection needs formulated Multi-Label Classification problem , common practice estimating label-instance relevance scores picking labels score higher threshold value . % %Usually, threshold crucial performance MLC models. %For multi-label intent detection, previous works explore tune fixed threshold learn thresholds data . %However, thresholds work well learning examples sufficient. %For few-shot scenarios, pretty hard determine appropriate thresholds examples. %Also, difficult directly transfer threshold learned data-rich domains due domain differences, differences label number per instance, score density scale. % % % %It also challenging compute label-instance relevance scores few-shot MLC. %Previous few-shot research mainly focuses single label classification achieved impressive progress similarity-based methods . %Generally, methods first obtain per class representations examples , classify instance according similarity representation class. %However, similarity scores rely well-separated class representations, poses unique challenges multi-label settings. %When instances multiple labels, representations different labels may obtained support examples become confused other. %For example Fig , intents query\_time query\_loc share support example thus label representation. % %In paper, study few-shot learning problem multi-label intent detection . %As mentioned above, difficult estimate transfer thresholds few-shot MLC. %To solve this, first learn universal thresholding experience data-rich domains, exploit experience estimate appropriate thresholds unseen few-shot domains. %Specifically, propose Meta Calibrated Threshold , first learns domain-general meta threshold, learns calibrate fit specific domains Kernel-Regression. %To encourage threshold generalization, introduce logit-adapting mechanism automatically adapts meta thresholds different score densities. % %For computing label-instance score few-shot MLC, propose Anchored Label Representation obtain well-separated label representations. %Inspired idea embedding label name anchor points refine representation space , ALR uses embeddings label names additional anchors represent label support examples corresponding anchors. % %Experiments two datasets show methods significantly outperform strong baselines. %Our contributions summarized follows: % We explore few-shot multi-label problem intent detection task-oriented dialogue, %which also early attempt few-shot multi-label classification. % We propose Meta Calibrated Threshold mechanism estimate threshold using prior domain experience new domain knowledge. % We introduce Anchored Label Representation obtain well-separated label representation better label-instance relevance score calculation."," % ========== Version 6.0 ============= In this paper, we study the few-shot multi-label classification for user intent detection.  For multi-label intent detection, state-of-the-art work estimates label-instance relevance scores and uses a threshold to select multiple associated intent labels.  To determine appropriate thresholds with only a few examples, we first learn universal thresholding experience on data-rich domains, and then adapt the thresholds to certain few-shot domains with a calibration based on non-parametric learning. %on metric learning. %, that does not require fine tuning to avoid overfitting. %Kernel Regression here allows to avoid overfitting by calibrating threshold without finetuning. For better calculation of label-instance relevance score, we introduce label name embedding as anchor points in representation space, which refines representations of different classes to be well-separated from each other. Experiments on two datasets show that the proposed model significantly outperforms strong baselines in both one-shot and five-shot settings.\footnote{Data and code are available at \url{https://github.com/AtmaHou/FewShotMultiLabel}}   %% ========== Version 5.0 ============= %In this paper, we study the few-shot multi-label classification for user intent detection.  %For multi-label intent detection, state-of-the-art work estimates label-instance relevance scores and uses a threshold to select multiple associated intent labels.  %To determine appropriate thresholds with only a few examples, we first learn universal thresholding experience on data-rich domains, and then adapt the thresholds to certain few-shot domains with a calibration based on Kernel Regression, that does not require fine tuning to avoid overfitting. %%Kernel Regression here allows to avoid overfitting by calibrating threshold without finetuning. %For better calculation of label-instance relevance score, we introduce label name embedding as anchor points in representation space, which refines representations of different classes to be well-separated from each other. %Experiments on two datasets show that our model significantly outperforms strong baselines in both one-shot and five-shot settings.\footnote{Data and code are available at \url{https://anonymous.com}}  %% ========== Version 5.0 ============= %In this paper, we study the few-shot multi-label classification for user intent detection.  %For multi-intent detection, state-of-the-art work estimates label-instance relevance scores and uses a threshold to select multiple associated intent labels.  %To determine appropriate thresholds with only a few examples, we first learn universal thresholding experience on data-rich domains, and then adapt the thresholds to certain few-shot domains with a Kernel Regression based calibration.  %Kernel Regression here allows to avoid overfitting by calibrating threshold without finetuning. %For better calculation of label-instance relevance score, we introduce label name embedding as anchor points in representation space, which refine representations of different classes to be well-separated from each other. %Experiments on two datasets show that our model significantly outperforms strong baselines in both one-shot and five-shot settings.\footnote{Code is available at \url{https://anonymous.com}}  %% ========= version 4.0 EMNLP version ========= %In this paper, we study the few-shot multi-label classification for user intent detection.  %Multi-label classification usually estimates label-instance relevance scores and uses a threshold to select multiple associated labels.  %To determine appropriate thresholds with only a few examples, we first learn universal thresholding experience on data-rich domains, and then calibrate the learned universal thresholds to fit certain few-shot domains. %For better calculation of label-instance relevance score, we introduce label name embedding as anchor points in representation space, which refine representations of different classes to be well-separated from each other. %Experiments on both open and in-house datasets show that our model significantly outperforms strong baselines in both one-shot and five-shot settings.\footnote{Code is available at: \url{https://anonymous.com}}"
"% % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % . % % final paper: en-us version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. } Translation languages grammatical gender involves correctly inferring grammatical gender entities sentence. In languages grammatical gender dependent social gender human referents. For example, Spanish translation sentence `This doctor', `the doctor' would either `el m鑼卍ico', masculine, `la m鑼卍ica', feminine. Since noun refers person grammatical gender inflection correct given referent. In practice many NMT models struggle generating inflections correctly , often instead defaulting gender-based social stereotypes masculine language . For example, NMT model might always translate `This doctor' sentence masculine inflected noun: `Este es el m鑼卍ico'. Such behaviour viewed translations exhibiting gender bias. By `bias' follow definition behaviour `systematically unfairly discriminate[s] certain individuals groups individuals favor others.' Specifically, translation performance favors referents fitting groups corresponding social stereotypes, male doctors. Such systems propagate representational harm erasure referents -- example, non-male doctor would incorrectly gendered example translation. Systems may also cause allocational harms incorrect translations used inputs systems . System users also experience representational harms via reinforcement stereotypes associating occupations particular gender . Even referent, user may wish words translated way appear endorse social stereotypes. Users also experience lower quality service receiving grammatically incorrect translations. A common approach broad problem NMT use gender features, implicit explicit. The gender one words test sentence determined external context reliance `gender signals' words source sentence gendered pronouns. That information used translating. Such approaches combine two distinct tasks: identifying gender inflection feature, applying translate words source sentence. These feature-based approaches make unstated assumption could correctly identify that, e.g., doctor example female, could inflect entities sentence correctly, reducing effect gender bias. Our contribution exploration assumption. We propose scheme incorporating explicit gender inflection tag NMT, particularly translating coreference sentences reference gender label known. Experimenting translation English Spanish English German, find simple existing approaches overgeneralize gender signal, incorrectly using inflection every entity sentence. We show tagged-coreference adaptation approach effective combatting behaviour. Although work English source sentences extend prior work, note approach extended source languages without inherent gender signals like gendered pronouns, unlike approaches rely signals. Intuitively, gender tagging perform well use label determined human coreference resolution, even less useful gender label must automatically inferred. Conversely, gender tagging effective scenario may beneficial user specify gendered language use referent, Google Translate's translation inflection selection , translations grammatical gender use human referents known. We also find approach works well RoBERTa-based gender tagging English test sentences. Existing work NMT gender bias focused translation sentences based binary gender signals, exclusively male female personal pronouns. This excludes erases use binary gendered language, including limited non-binary individuals . As part work therefore explore applying tagging indicate gender-neutral referents, produce WinoMT set assess translation coreference sentences gender-neutral entities. \subsection{Related work} Variations gender tag signal machine translation proposed several forms. incorporate `speaker gender' tag training data, allowing gender conveyed sentence level. However, allow fine-grained control, example one referent sentence. Similar approaches infer use gender information discourse context. also incorporate single explicit gender feature sentence inference. integrate coreference links machine translation reranking improve pronoun translation cross-sentence context. propose NMT gender bias reduction `mixing signals' addition pro-stereotypical adjectives. Also related work recent approach , train NMT models scratch source language words annotated target language grammatical gender. In treat gender bias domain adaptation problem adapting small set synthetic sentences equal numbers entities using masculine feminine inflections. We also interpret gender `tagging' approach, since gendered terms synthetic dataset give strong signal model. In work extend synthetic datasets work explore effect further. Other approaches reducing gender bias effects involve adjusting word embeddings either directly training counterfactual data augmentation . We view approaches orthogonal proposed scheme: similar goals directly control inference-time gender inflection word sentence level."," Neural Machine Translation  has been shown to struggle with grammatical gender that is dependent on the gender of human referents, which can cause gender bias effects. Many existing approaches to this problem seek to control gender inflection in the target language by explicitly or implicitly adding a gender feature to the source sentence, usually at the sentence level.    In this paper we propose schemes for incorporating explicit word-level gender inflection tags into NMT. We explore the potential of this gender-inflection controlled translation when the gender feature can be determined from a human reference, or when a test sentence can be automatically gender-tagged, assessing on English-to-Spanish and English-to-German translation.  We find that simple existing approaches can over-generalize a gender-feature to multiple entities in a sentence, and suggest effective alternatives in the form of tagged coreference adaptation data. We also propose an extension to assess translations of gender-neutral entities from English given a corresponding linguistic convention, such as a non-binary inflection, in the target language."
"Self-supervised pretraining language modeling massive datasets revolutionized NLP. One reason method works pretraining shapes model's hypothesis space, giving inductive biases help learn linguistic tasks . Numerous probing studies provided support idea showing language models learn representations encode linguistic features . However, feature learning first step acquiring helpful inductive biases. Models must also able learn features matter. The NLU datasets models often fine-tuned ambiguous contain artifacts, often support multiple possible generalizations. Neural networks mind readers: Models shown represent linguistic features sometimes fail use fine-tuning NLU tasks, instead adopting shallow surface generalizations . To end, recent work probing pretrained models advocates shifting focus study away whether represent linguistic features favor whether learn useful representations features . % } \end{table*} We investigate RoBERTa acquires language-specific inductive biases self-supervised pretraining. We track separately RoBERTa's representation linguistic features preferences linguistic generalizations surface generalizations change amount pretraining data increases. We pretrain RoBERTa scratch datasets ranging 1M 1B words evaluate models alongside RoBERTa series experiments probe inductive biases pretrained model time fine-tuning downstream task. We probe models three kinds experiments: First, conduct control experiments fine-tune models unambiguous binary classification tasks test whether learn represent simple linguistic surface features. Second, conduct ambiguous experiments following poverty stimulus design , illustrated Figure . In experiments, fine-tune pretrained model ambiguous binary classification task training set consistent linguistic generalization surface one. We test classifier disambiguating data reveal generalization model adopted, extension preference among two features. Third, conduct inoculation experiments \citep[following][]{liu2019inoculation} test hard sway model surface bias adopt linguistic generalization. We introducing small amounts disambiguating data otherwise ambiguous training set. We automatically generate data tasks, call resulting dataset \dataset\ , pronounced ``messages''. The results show RoBERTa acquires stronger linguistic bias pretraining increases. RoBERTa strongest linguistic bias, requires little inoculating data reliably make linguistic generalization. In general, models pretraining data generally induced adopt linguistic generalizations less inoculating data. We also find large gap amount pretraining data RoBERTa needs learn linguistic features necessary generalize out-of-domain amount needs learns prefer features generalizing. The control experiments unambiguous data reveal models little pretraining actually represent linguistic features, nonetheless show strong surface bias. In words, main contribution pretraining linguistic bias learning devoted extracting features, learning features matter. We conclude helpful inductive biases learned pretraining, current models require abundant data so. The implications conclusion point two directions: First, probably continue pretrain increasingly massive training sets improve generalization few-shot learning abilities models like T5 GPT-3 . Second, since models learn useful features early, hope future advances could accelerate reducing amount data needed learn features matter. To aid effort, release MSGS dataset, pretrained RoBERTas, code: \href{https://github.com/nyu-mll/msgs}{\url{https://github.com/nyu-mll/msgs}}.","   One reason pretraining on self-supervised linguistic tasks is effective is that it teaches models features that are helpful for language understanding. However, we want pretrained models to learn not only to represent linguistic features, but also to use those features preferentially during fine-turning. With this goal in mind, we introduce a new English-language diagnostic set called MSGS , which consists of 20 ambiguous binary classification tasks that we use to test whether a pretrained model prefers linguistic or surface generalizations during fine-tuning. We pretrain RoBERTa models from scratch on quantities of data ranging from 1M to 1B words and compare their performance on \dataset\ to the publicly available RoBERTa$\subtxt{BASE}$. We find that models can learn to represent linguistic features with little pretraining data, but require far more data to learn to prefer linguistic generalizations over surface ones. Eventually, with about 30B words of pretraining data, RoBERTa$\subtxt{BASE}$ does demonstrate a linguistic bias with some regularity. We conclude that while self-supervised pretraining is an effective way to learn helpful inductive biases, there is likely room to improve the rate at which models learn which features matter."
"%缁楊兛绔村▓纰夌窗娣団剝浼呮径姘帗閸 Existing experiments proven multimodal news significantly improve users閳 sense satisfaction informativeness. As one multimedia data forms, introducing news events video textual descriptions becoming increasingly popular, employed main form news reporting news media including BBC, Weibo, CNN, Daily Mail. An illustration shown Figure, news contains video cover picture full news article short textual summary. In case, automatically generating multimodal summaries, \ie choosing proper cover frame video generating appropriate textual summary article help editors save time readers make decisions effectively. There several works focusing multimodal summarization. The related work , propose task generating textual summary picking representative picture 6 input candidates. However, real-world applications, input usually video consisting hundreds frames. Consequently, temporal dependency video cannot simply modeled static encoding methods. Hence, work, propose novel task, Video-based Multimodal Summarization Multimodal Output , selects cover frame news video generates textual summary news article meantime. %缁楊兛绗佸▓纰夌窗閹存垳婊戦惃鍕侀崹瀣簼绠為幀搴濈疄閸 The cover image video salient point whole video, textual summary also extract important information source articles. Since video article focus event report content, two information formats complement summarizing process. However, fully explore relationship temporal dependency frames video semantic meaning article still remains problem, since video article come two different space. Hence, paper, propose model named Dual-Interaction-based Multimodal Summarizer , learns summarize article video simultaneously conducting dual interaction strategy process. Specifically, first employ Recurrent Neural Networks encode text video. Note encoding RNN, spatial temporal dependencies images video captured. % The features segments text constraint space L2 normalization modifies vector way row sum squares always 1. Next, design dual interaction module let video text fully interact other. Specifically, propose conditional self-attention mechanism learns local video representation guidance article, global-attention mechanism learn high-level representation video-aware article article-aware video. Last, multimodal generator generates textual summary extracts cover image based fusion representation last step. To evaluate performance model, collect first large-scale news article-summary dataset associated video-cover social media websites. Extensive experiments dataset show DIMS significantly outperforms state-of-the-art baseline methods commonly-used metrics large margin. %缁楊剙娲撳▓纰夌窗閹崵绮╟ontribution To summarize, contributions threefold: We propose novel Video-based Multimodal Summarization Multimodal Output task chooses proper cover frame video generates appropriate textual summary article. We propose Dual-Interaction-based Multimodal Summarizer model, jointly models temporal dependency video semantic meaning article, generates textual summary video cover simultaneously. We construct large-scale dataset VMSMO, experimental results demonstrate model outperforms baselines terms automatic human evaluations."," % Multimodal summarization has drawn much attention due to the rapid growth of multimedia data.  A popular multimedia news format nowadays is providing users with a lively video and a corresponding news article, which is employed by influential news media including CNN, BBC, and social media including Twitter and Weibo. In such a case, automatically choosing a proper cover frame of the video and generating an appropriate textual summary of the article can help editors save time, and readers make the decision more effectively. Hence, in this paper, we propose the task of Video-based Multimodal Summarization with Multimodal Output  to tackle such a problem. The main challenge in this task is to jointly model the temporal dependency of video with semantic meaning of article. To this end, we propose a Dual-Interaction-based Multimodal Summarizer , consisting of a dual interaction module and multimodal generator. In the dual interaction module, we propose a conditional self-attention mechanism that captures local semantic information within video and a global-attention mechanism that handles the semantic relationship between news text and video from a high level. Extensive experiments conducted on a large-scale real-world VMSMO dataset\footnote{https://github.com/yingtaomj/VMSMO} show that DIMS achieves the state-of-the-art performance in terms of both automatic metrics and human evaluations."
". % % % final paper: en-us version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. } \reza{ Neural models revolutionising machine translation , achieved state-of-the-art many high-resource language pairs . However, scarcity bilingual parallel corpora still major challenge training high-quality NMT models % especially broad range languages available translation training resources small used existing NMT systems . % Transfer learning fine-tuning, model trained high-resource language-pair, % \wray{Wray: Having trouble this: ""high-resource language-pair"" mean source target high resource relate do?} standard approach tackle scarcity data target low-resource language-pair . % However, one-to-one approach, able exploit models trained multiple high-resource language-pairs target language-pair interest. % Furthermore, models transferred different high-resource language-pairs may complementary syntactic and/or semantic strengths, hence using single model may sub-optimal. } %Transfer learning one widely used solutions addressing data scarcity problem low-resource scenarios . % However, applying original transfer learning LR models neither able make full use highly related multiple high-resource languages receive different parameters effective high-resource NMT models simultaneously. %However, transfer learning high-resource low-resource NMT models generally one-to-many approach able exploit multiple high-resource languages high-resource NMT models' parameters simultaneously. Contrariwise, \reza{ Another appealing approach multilingual NMT, whereby single NMT model trained combining data multiple high-resource low-resource language-pairs . % %is appealing approach low-resource languages utilizing training examples multiple languages . %In practice, training multilingual NMT, multilingual vocabulary set language pairs used training single NMT model among languages enable sharing resources high-resource low-resource languages. % improves regularization model avoiding over-fitting limited data low-resource languages. However, performance multilingual NMT model highly dependent types languages used train model. Indeed, languages distant language families, lead negative transfer, causing low translation quality multilingual system compared counterparts trained individual language-pairs . % To address problem, proposed knowledge distillation approach effectively train multilingual model, % selectively distilling knowledge individual teacher models multilingual student model. However, still language pairs trained single model blind contribution training. %during training process accuracy individual models surpasses multilingual one. % distilling knowledge individual NMT models. To avoid distilling knowledge effective teachers, selectively apply distillation training process accuracy individual models surpasses multilingual one. } \reza{ In paper, propose many-to-one transfer learning approach effectively transfer models multiple high-resource language-pairs target low-resource language-pair interest. % As fine-tuned models different high-resource language pairs complementary syntactic and/or semantic strengths target language-pair, idea distill knowledge single student model make best use teacher models. % We propose effective adaptive knowledge distillation approach dynamically adjust contribution teacher models distillation process, enabling making best use teachers ensemble. % Each teacher model provides dense supervision student via dark knowledge using mechanism similar label smoothing , amount smoothing regulated teacher. % In AKD approach, label smoothing coming different teachers combined regulated, based loss incurred teacher models distillation process. % %\wray{Wray: This next sentence could deleted need space.} %Although focus application method NMT, applied generally NLP tasks suffering scarcity training data, e.g. summarisation {CITE} question answering \todo{CITE}. } %Experimental results various teacher-student language pairs show 0.9 BLEU score improvement compare strong baselines. Experiments transferring collection six language pairs IWSLT five low-resource language-pairs TED Talks demonstrate effectiveness approach, achieving +0.9 BLEU score improvements compared strong baselines. %\todo{talk experiments?} %In paper, introduce new distil-based approach make full use high-resource languages % NMT models simultaneously effectively. To so, firstly apply transfer learning high-resource low-resource languages generate strong teachers. Then, adaptively distil knowledge multiple teachers based effectiveness %to improve accuracy low-resource NMT model. % What distinguishes approach previous distil-based method choosing best teachers statistically rather deterministically. Our approach weights teachers based context mini-batch ability teacher improve prediction student specific mini-batch training. % Our experiments show proposed approach outperforms vanilla transformer, original transfer learning, multilingual NMT, selective knowledge distillation translation five low-resource languages English. %Our main contributions follows: % a) We % propose new approach % transfer knowledge high-resource low-resource language pairs assumes availability translation models high-resource bilingual data low-resource languages leads best usage computational resources via exploiting computational work already done high-resource side. % , particularly interesting limitation available computational resources. % b) We % propose new method % dynamically distil knowledge existing teacher models student model. What distinguishes approach previous distillation-based methods choosing best teachers statistically based data knowledge gap student model, rather deterministically done previous work . % c) Experimental results various teacher-student language pairs show 0.9 BLEU score improvement compare strong baselines. %"," \reza{ Scarcity of parallel sentence-pairs poses a significant hurdle for training high-quality Neural Machine Translation  models in bilingually low-resource scenarios.  % A standard approach is transfer learning, which involves taking a model trained on a high-resource language-pair and fine-tuning it on the data of the low-resource MT condition of interest.  % However, it is not clear generally which high-resource language-pair offers the best transfer learning for the target MT setting. Furthermore, different transferred models may have complementary semantic and/or syntactic strengths, hence using only one model may be sub-optimal.      % In this paper, we tackle this problem using knowledge distillation, where we propose to distill the knowledge of ensemble of teacher models to a single student model.  % As the quality of these teacher models varies, we propose an effective adaptive knowledge distillation approach to dynamically adjust the contribution of the teacher models during the distillation process.  % Experiments on transferring from a collection of six language pairs from IWSLT to five low-resource language-pairs from TED Talks demonstrate the effectiveness of our approach, achieving up to +0.9 BLEU score improvement compared to strong baselines.  } %In this paper, we propose a two-phase method  to tackle this challenge. The first phase involves transfer learning, where models trained on high-resource languages-pairs are fine-tuned on the data of the low-resource MT condition of interest.  % %The second phase involves disstilling the knowledge from this collection of teachers to a single student model.  % %As the quality of these teacher models vary, we propose an adaptive knowledge distillation approach to adaptively adjust the contribution of the teacher models during the training process of the student.  % %NMT models, where a pretrained modeld on high-resource data is fine tuned on .  The transferred models are treated as teachers which produce soft targets for each low-resource language. In the second phase, we adaptively distil knowledge from all teachers based on their capability to improve the accuracy of the low-resource NMT model . By optimizing the student to fit the teachers' distribution over smoothed labels, we expect the student闁炽儲鐛 generalisation affected by teachers' probability calibration. Moreover, we propose to control the teachers' contributions when computing the soft targets for knowledge distillation, such that better teachers contribute more. This contribution is adaptively changing based on how good a teacher captures the context of an incoming mini-batches during training. Experiments on IWSLT and TED dataset demonstrate the effectiveness of our model which outperforms strong baselines on the translation of five low-resource languages to English."
"Natural language processing deception detection focus preprocessing text computational data required features propose. As deception detection understanding meaning text text viewed people, sequence text always considered one primary source context. For example, N-gram, representative method natural language processing, contains data word subsequent word statistical probabilities. The attribute subsequent contains continuous context text, linguist describes linearity. In contrast, feature extractions without considering language's linearity seems nonsense. However, data processed non-linear feature extractions shows notable accuracy detecting deceptions, possible suggest preprocessing methods could used one possible natural language processing certain situations. \ In paper, discuss effectiveness APV, simple natural language processing method using alphabet frequency, context application fake news detection. By using deep learning algorithm fake news dataset Kaggle, findings suggest simple deep learning algorithms using APV pre-processing method could show prominent accuracy predicting deception text. \ In section 2, investigate conventional natural language processing used machine learning deep learning algorithms. In section 3, define APV mathematical structure. We also discuss hypothesis might improve feature extraction APV. In section 4, basic experiment protocol set including structure deep learning algorithms performance metrics used experiment. In section 5, present result algorithms performance. Finally, section 6, conclude study.","     Feature extraction is an important process of machine learning and deep learning, as the process make algorithms function more efficiently, and also accurate. In natural language processing used in deception detection such as fake news detection, several ways of feature extraction in statistical aspect had been introduced . In this research, it will be shown that by using  deep learning algorithms and alphabet frequencies of the original text of a news without any information about the sequence of the alphabet can actually be used to classify fake news and trustworthy ones in high accuracy . As this pre-processing method makes the data notably compact but also include the feature that is needed for the classifier, it seems that alphabet frequencies contains some useful features for understanding complex context or meaning of the original text.\\\\  keywords: {[FEATURE EXTRACTION], [DEEP LEARNING]}  % Received, Accepted 闂嗩喚濞嬮～锟犳禃 闂夋稑瀚靛 闂夋稑鎳為悧鎾荤垷濮楀喚娼 濮ｉ潧鐗楅崝顖炵亙."
"Sentence matching fundamental technology natural language processing. Over past years, deep learning data-driven technique yielded state-of-the-art results sentence matching . However, data-driven technique typically requires large amounts manual annotation brings much cost. If large labeled data can't obtained, advantages deep learning significantly diminish. To alleviate problem, active learning proposed achieve better performance fewer labeled training instances . Instead randomly selecting instances, active learning measure whole candidate instances according criteria, select efficient instances annotation . However, previous active learning approaches natural language processing mainly depend entropy-based uncertainty criterion , ignore characteristics natural language. To specific, ignore linguistic similarity, may select redundant instances waste many annotation resources. Thus, devise linguistic criteria measure candidate instances important challenge. Recently, pre-trained language models shown powerful learning language representation. Accordingly, pre-trained language models may provide reliable way help capture language characteristics. In paper, devise linguistic criteria pre-trained language model capture language characteristics, utilize extra linguistic criteria enhance active learning. It shown Figure . Experiments English Chinese sentence matching datasets demonstrate pre-trained language model enhance active learning."," Active learning is able to significantly reduce the annotation cost for data-driven techniques. However, previous active learning approaches for natural language processing mainly depend on the entropy-based uncertainty criterion, and ignore the characteristics of natural language. In this paper, we propose a pre-trained language model based active learning approach for sentence matching. Differing from previous active learning, it can provide linguistic criteria to measure instances and help select more efficient instances for annotation. Experiments demonstrate our approach can achieve greater accuracy with fewer labeled training instances."
"%text matching閺堝绶㈡径姝瀍ep learning閺傝纭堕敍灞炬櫏閺嬫粈绗夐柨娆欑礉娴ｅ棙妲搁崣顖澬掗柌濠傛▕閿涘奔绗栭柅鐔峰娑撳秹鐝 The neural networks represent two sentences individually dense vector embedding space, define different functions calculate matching degree two-sentence vectors. However, getting extremely time-consuming networks becoming sophisticated introducing parameters. Even worse, still black box researchers practitioners, urgent need interpretability. We can't figure what's specific meaning representation obtained neural networks, unaccountable challenging comprehend lead untrusty irresponsible result. %閹存垳婊戠亸杈ㄥ厒閹靛彞绔存稉顏勫嫉韫囶偄寮垫總鍊熜掗柌濠忕礉娴犲簼浜掗崜宥囨畱deep learning鐠囦焦妲戞禍鍡楊劅閺傚洦婀伴惃鍕秵缂佺銆冪粈鐑樻Ц闂堢姾姘ㄩ惃鍕剁礉閹垫禒顧砮tric learn閸掓艾銈界亸杈ㄦЦ鏉╂瑦鐗遍敍灞界穿閸忣櫝etric learning閿涘奔绗栭敍鍫滀簰瀵伴弰顖涘簼绠為悽鈺〆tric learning閿 To tackle these, aim find fast interpretable approach sentence matching. There several studies focused learning low-dimensional representations data, called metric learning even combine similarity metrics ranking tasks . Moreover, researchers apply metric learning principles design loss function information retrieval question-answering tasks. But deep metric learning utilized, neural network part still demands lot time. It hardly runs memory-limited device, together high energy consumption. %閹存垳婊戝銉ょ稊閺勵垰婀猼ext matching娑撳﹥褰佹稉娑擃亜鎻╅柅鐔烘畱閺傝纭堕妴鍌樺倶鍌涘娴狀櫑pply閵嗗倶鍌 It considering unexplainable implications brought neural networks, fairness transparency, challenge time-consuming. In paper, apply metric learning approaches address problems mentioned above. Because metric learning advantage time memory usage large-scale high-dimensional datasets compared methods above. Here, metric learning finds representation data preserves constraints placed human-provided labels. Building success learning ``label constraint preserving'' representations, low-distortion embeddings, explore two \textsf{F}ast, \textsf{I}nterpretable, \textsf{L}ow-rank \textsf{M}etric learning approaches, called \textsf{FILM}. %閻鍩岄弫鍫熺亯metric learning閼宠棄鐤勯悳鎵娴艰偐娈戠紒鎾寸亯閿涘奔绗栬箛顐︾喍绗栭崣顖澬掗柌濠冄嶇窗缁炬寧褏娈 Notably, explore \textsf{FILM} methods text matching tasks, also known semantic equivalence problem IR community~. To specific, one based interpretable low-rank manifold optimization method. To solve optimization problem, apply Cayley transformation method Barzilai-Borwein step size. After trained task, added kNN index prediction efficient retrieval. The input question encoded used query index, returning top k similar questions. We test approaches data Quora Challenge SemEval-2017 Semantic Textual Similarity Task, provide pairwise sentence similarity labels. %\footnote{} %Our motivation investigate whether \textsf{FILM} approaches perform well as, better than, ``black box'' approaches popular days. The rest paper organized follows. In Section , provide quick overview metric learning. In Section present interpretable \textsf{FILM} method. In Section , summarize Quora dataset task, explain \textsf{FILM} applied task, summarize deep neural network approach. In Section report results. \end{comment}"," Detection of semantic similarity plays a vital role in sentence matching. It requires to learn discriminative representations of natural language. Recently, owing to more and more sophisticated model architecture, impressive progress has been made, along with a time-consuming training process and not-interpretable inference. % In sentence matching and semantic analysis, detecting semantic similarity is a challenge that requires learning discriminative representations of natural language. Recent advances in the deep neural network enable us to learn semantic representation, but are getting time-consuming and fail in interpretation. To alleviate this problem, we explore a metric learning approach, named \textsf{FILM}  to efficiently find a high discriminative projection of the high-dimensional data. We construct this metric learning problem as a manifold optimization problem, and solve it with the Cayley transformation method with Barzilai-Borwein step size. % To alleviate this problem, in this paper we construct sentence matching as a manifold optimization problem that learns a distance function between sentences. % % and obtain the semantic representation by learning a similarity or distance function. % We explore a metric learning approach, named \textsf{FILM}  to efficiently find a high discriminative projection of the high-dimensional data. % that still preserves high discriminative power. % To this end, our manifold optimization method is solved by the Cayley transformation method with Barzilai-Borwein step size.  In experiments, we apply \textsf{FILM} with triplet loss minimization objective to the Quora Challenge and Semantic Textual Similarity  Task. The results demonstrate that the \textsf{FILM} method achieves a superior performance as well as the fastest computation speed, which is consistent with our theoretical analysis of time complexity."
"%A common situation language learners encounter unrecognized words. %In case, looking dictionary may preferred solution many people. %However, capacity dictionaries limited, may contain new words new meanings words. %What's more, language pairs dictionaries, especially low resources. %Therefore, may good idea directly generate definitions words. The definition modeling task proposed \citet{Noraset2017DefinitionML} generate dictionary definition specific word. This task prove useful language learners, provide reading help giving definitions words text. However, definition modeling work specific language, puts high demands users requires read definitions written language. Besides, many low-resource languages lack large-scale dictionary data, making difficult train definition generation models languages. %This task prove useful language learners, provide reading help giving definitions words text. %However, definition modeling work specific language, puts high demands users requires read definitions written language. Therefore, emphasize necessity generating definitions cross-lingually, generate definitions various language inputs, illustrated figure . Since English widely used around world, English dictionary resources relatively easy obtain, choose generate definitions English. In way, cross-lingual model trained English directly applied languages. The challenging issue effectively transfer knowledge definition generation learned English languages. To solve problem, propose employ cross-lingual pretrained language models encoders. These models shown able encode sequences various languages, enables ability cross-lingual transfer . %In work, emphasize necessity generating definitions cross-lingually, requires model generate definitions one language words various languages illustrated figure . %Considering English widely used around world, English dictionary resources relatively easy obtain, choose use English generate definitions languages work. %Recently, cross-lingual pretrained language models shown capable encoding sequences different languages vector space, enables ability cross-lingual transfer. %Therefore, propose employ encoders cross-lingual definition generation. %After training fine-tuning model English dataset, directly apply obtained model generate definitions languages. To verify proposed method, build English dataset model training Chinese dataset zero-shot cross-lingual evaluation. %We collected English words, example sentences definitions OALD English dataset, collected Chinese words, example sentences English definitions Chinese WordNet Chinese dataset. Experiments manual analyses constructed datasets show proposed models good cross-lingual transfer ability. Compared reference definitions CWN dataset, although generated definitions still insufficient accuracy, fluency already good enough. Furthermore, considering generated definitions provided language learners, many non-English native speakers, argue difficulty definitions control. We control lexical complexity generated definitions limiting definitions training set Oxford 3000 vocabulary, list important useful words carefully selected language experts experienced teachers . %These words used write definitions Oxford Advanced Learner's Dictionary , order make easy understand. %We compute Type/Token Ratio measure lexical complexity. %The TTR generated definitions much lower reference definitions , indicates lower lexical complexity. We compute four different metrics measure lexical complexity. Definitions generated models outperform reference definitions four metrics large margin. The result shows method generate simpler definitions, suitable language learners."," Generating dictionary definitions automatically can prove useful for language learners. However, it's still a challenging task of cross-lingual definition generation. In this work, we propose to generate definitions in English for words in various languages. To achieve this, we present a simple yet effective approach based on publicly available pretrained language models. In this approach, models can be directly applied to other languages after trained on the English dataset. We demonstrate the effectiveness of this approach on zero-shot definition generation. Experiments and manual analyses on newly constructed datasets show that our models have a strong cross-lingual transfer ability and can generate fluent English definitions for Chinese words. We further measure the lexical complexity of generated and reference definitions. The results show that the generated definitions are much simpler, which is more suitable for language learners. %We further conduct a manual analysis of the generated Chinese definitions and find that although these definitions are insufficient on the accuracy, they are already good enough on fluency and lexical complexity."
"The CoNLL 2020 MRP Shared Task combines five frameworks graph-based meaning representation: EDS, PTG, UCCA, AMR DRG. It includes evaluations English, Czech, German Chinese. While EDS, UCCA AMR participated 2019 MRP shared task , focused English, PTG DRG newly-added frameworks MRP uniform format. For shared task, extended TUPA , adapted baseline system 2019 MRP shared task , support two new frameworks different languages. In order add support, minimal changes needed, demonstrating TUPA's strength parsing wide array representations. TUPA general transition-based parser directed acyclic graphs , originally designed parsing UCCA . It previously used baseline system SemEval 2019 Task 1 , generalized support frameworks . We also experimented HIT-SCIR parser . This parser highest average score across frameworks 2019 MRP shared task, also since applied frameworks . \end{adjustbox} \end{figure*}","   This paper describes the HUJI-KU system submission to the shared task   on Cross-Framework Meaning Representation Parsing  at the 2020   Conference for Computational Language Learning ,   employing TUPA and the HIT-SCIR parser, which were, respectively,   the baseline system and winning system in the 2019 MRP shared task.   Both are transition-based parsers using BERT contextualized embeddings.   We generalized TUPA to support the newly-added MRP frameworks and languages,   and experimented with multitask learning with the HIT-SCIR parser.   We reached 4th place in both the cross-framework and cross-lingual tracks."
"\renewcommand{\thefootnote}{} Recurrent Neural Network language models shown learn many aspects natural language syntax including number long-distance dependencies representations incremental syntactic state . However, previous studies investigated relationship token's frequency training corpus syntactic properties models learn it. In work, assess neural models' ability make robust syntactic generalizations token's nominal number verbal argument structure based minimal exposure token training. Because Zipfian distribution words corpus, vast majority word types seen handful times training . Therefore, few-shot learning capabilities neural LMs critical robustness NLP system cognitive model. However, human learning goes beyond simply learning syntactic properties particular constructions. People apply properties across different constructions, meaning representations syntactic features word sense invariant grammatical context word. For example, speakers listeners sensitive verb's argument structure relationships easily recognize verb cannot take direct object active, declarative sentences cannot passivized The relationship active sentence passive sentence termed transformation linguistic literature . Many semantic-syntactic rules govern word co-occurrence one form, verb's argument structure relationships, hold uniformly across transformations. It remains open question whether models learn grammatical rules invariant surface realization, property call syntactic invariance. We combine assessment few-shot learning syntactic invariance two grammatical features English: whether noun singular plural whether verb transitive intransitive . We assess whether model able make different predictions based number argument structure simple active voice base context. We assess whether models able make similar distinctions transformed context---passive voice verbs polar questions nouns. In transformed contexts, test models tokens occur base context training. For models succeed transformed contexts must represent syntactic features way invariant specific realization features terms word co-occurrences different constructions. For grammatical feature, introduce suite novel targeted test sentences, similar presented \citet{marvin2018targeted}. We find neural models tested able induce proper syntactic generalizations base transformed contexts two three exposures, whereas baseline -gram model fails learn relevant generalizations. For constructions tested two neural models enhanced explicit structural supervision outperform purely sequence model. Assessing invariance properties, find neural models demonstrate proper behavior transformed contexts, even tokens seen base contexts training. This behavior indicates models able deploy generalizations learned one syntactic context different syntactic environments, key component human linguistic capabilities far untested neural setting. \subsection{Related Work} Bayesian models word learning shown successes acquiring proper syntactic generalizations minimal exposure , however clear well neural network models would exhibit rapid generalizations. Comparing neural network architectures, recent work shown models enhanced explicit structural supervision training produce humanlike syntactic generalizations , remains untested whether supervision helps learn properties tokens occur rarely training. Previous studies found Artificial Neural Networks capable learning argument structure paradigms make correct predictions across multiple frames , however capabilities remain untested incremental language models. Much written ability ANNs learn number agreement , including ability maintain dependency across different types intervening material coordinated noun phrases . \citet{hu2020systematic} find model architecture, rather training data size, may contribute performance number agreement related tasks. Focusing RNN models, \citet{lakretz2019emergence} find evidence number agreement tracked specific ``number"" units work concert units carry general syntactic information like tree depth. \citet{jumelet2019analysing} argue learning dependencies RNNs acquire default form , predicting non-default form requires explicit contrary evidence. Our results support hypothesis. Models accurate singular nouns transitive verbs seen times training, behavior indicates forms expected evidence sparse."," Humans can learn structural properties about a word from minimal experience, and deploy their learned syntactic representations uniformly in different grammatical contexts. We assess the ability of modern neural language models to reproduce this behavior in English and evaluate the effect of structural supervision on learning outcomes. First, we assess few-shot learning capabilities by developing controlled experiments that probe models' syntactic nominal number and verbal argument structure generalizations for tokens seen as few as two times during training. Second, we assess invariance properties of learned representation: the ability of a model to transfer syntactic generalizations from a base context  to a transformed context . We test four models trained on the same dataset: an $n$-gram baseline, an LSTM, and two LSTM-variants trained with explicit structural supervision \citep{dyer2016rnng, charniak2016parsing}. We find that in most cases, the neural models are able to induce the proper syntactic generalizations after minimal exposure, often from just two examples during training, and that the two structurally supervised models generalize more accurately than the LSTM model. All neural models are able to leverage information learned in base contexts to drive expectations in transformed contexts, indicating that they have learned some invariance properties of syntax.\blfootnote{Miguel conducted this work while at IBM Research}"
"Despite \bert{'s} popularity effectiveness, little known inner workings. Several attempts made demystify certain aspects \bert , often leading contradicting conclusions. For instance, \citet{clark-etal-2019-bert} argue attention measures importance particular word computing next level representation word. However, \citet{kovaleva-etal-2019-revealing} showed attention heads contain trivial linguistic information follow vertical pattern , could related under-utilization over-parameterization issues. Other studies attempted link specific \bert heads linguistically interpretable functions , agreeing single head densely encodes enough relevant information instead different linguistic features learnt different attention heads. We hypothesize aforementioned largely contributes lack attention-based explainability \bert. Another open topic knowledge distributed across \bert layers. Most studies agree syntactic knowledge gathered middle layers , final layers task-specific. Most importantly, seems semantic knowledge spread across model, explaining non-trivial tasks better solved higher layers . Driven discussion, propose novel fine-tuning approach different parts \bert guided directly solve increasingly challenging classification tasks following underlying label hierarchy. Specifically, focus Large Scale Multilabel Text Classification documents assigned one labels large predefined set. The labels organized hierarchy general specific concepts. Our approach attempts tie specific \bert layers specific hierarchy levels. In effect, layers responsible predicting labels corresponding level. We experiment two \lmtc datasets several variations structured \bert training. Our contributions are: We propose novel structured approach fine-tune \bert specific layers tied specific hierarchy levels; We show structured training yields better results baseline across levels hierarchy, also leading better parameter utilization.","     Although \bert is widely used by the \nlp community, little is known about its inner workings. Several attempts have been made to shed light on certain aspects of \bert, often with contradicting conclusions. A much raised concern focuses on \bert's over-parameterization and under-utilization issues. To this end, we propose o novel approach to fine-tune \bert in a structured manner. Specifically, we focus on Large Scale Multilabel Text Classification  where documents are assigned with one or more labels from a large predefined set of hierarchically organized labels. Our approach guides specific \bert layers to predict labels from specific hierarchy levels. Experimenting with two \lmtc datasets we show that this structured fine-tuning approach not only yields better classification results but also leads to better parameter utilization."
"Training open-domain dialog models inherently difficult, since utterance many acceptable responses, yet perfect response. While supervised learning conversational corpora allows models learn grammatical structure even topic coherence, models generalize, since training objectives mostly lead models memorize responses within corpus. Humans ultimate authority evaluating makes one conversational reply better another. To learn real conversations humans, created interactive, online platform hosted diverse set neural network dialog models users could chat real time. However, learning human interactions wild crucial able learn offline test policy deploying it, lest learn inappropriate behaviors . Thus, need train test models offline, ensure safe model outputs. In order safely learn optimize human feedback pursued offline reinforcement learning approach training dialog models . Offline RL challenging; deep RL algorithms fail learn data heavily correlated current policy . Even models based off-policy algorithms like -learning fail learn offline RL setting, model able explore. If offline dataset sufficient cover input-response space, offline RL models suffer extrapolation error, learning arbitrarily bad estimates value responses contained data. We solve problems developing new method offline RL. The method starts leveraging pre-trained language model constrain offline RL updates. While training RL, penalize divergence prior model using forms KL-control. This combats extrapolation error, ensures RL model learns policy stays close distribution realistic language, learning maximize positive human responses using offline data. Further, use dropout obtain uncertainty estimates target -values, obtain lower bound alleviate over-optimistic bias estimating future reward. We show new method able learn successfully many different reward functions, even large space 20,000 tokens. Both linguistic theory empirical experiments correlating human judgement language features suggest many criteria could used evaluate conversational agent . We develop set reward functions dialog agents optimize, designed approximate implicit human preferences expressed conversational responses. We show new method better able optimize rewards using offline data, tested new set 80 human conversation partners, leads positive responses higher quality ratings state-of-the-art offline deep RL method. Novel contributions paper are:"," How can we train a dialog model to produce better conversations by learning from human feedback, without the risk of humans teaching it harmful chat behaviors? We start by hosting models online, and gather human feedback from real-time, open-ended conversations, which we then use to train and improve the models using offline reinforcement learning . We identify implicit conversational cues including language similarity, elicitation of laughter, sentiment, and more, which indicate positive human feedback, and embed these in multiple reward functions.  A well-known challenge is that learning an RL policy in an offline setting usually fails due to the lack of ability to explore and the tendency to make over-optimistic estimates of future reward. These problems become even harder when using RL for language models, which can easily have a 20,000 action vocabulary and many possible reward functions.  We solve the challenge by developing a novel class of offline RL algorithms. These algorithms use KL-control to penalize divergence from a pre-trained prior language model, and use a new strategy to make the algorithm pessimistic, instead of optimistic, in the face of uncertainty.  We test the resulting dialog model with ratings from 80 users in an open-domain setting and find it achieves significant improvements over existing deep offline RL approaches. The novel offline RL method is viable for improving any existing generative dialog model using a static dataset of human feedback."
"Deep neural network-based models demonstrated remarkable performance multitude text-to-text \cite[inter alia]{bahdanau-attention,bert-to-bert,narayan-etal-2018-dont,rush-etal-2015-neural} well data-to-text generation tasks \cite[inter alia]{wiseman-etal-2017-challenges,puduppully-etal-2019-data}. % To reach high performance, DNN models require large training corpus normally readily available. Indeed, rare sufficiently large human-curated corpus parallel data , researchers come heuristic rules mine input-output pairs large scale . No matter powerful, DNN models known sensitive data artifacts pick noise training data. While hallucinations defined formally, term standardly used refer generated content either unfaithful input, nonsensical . In work concerned former hallucination kind primarily caused imperfect quality training data. % If data noisy, one reduce chances hallucinating? % One may try improve quality dataset clean phrases clear support input missing, augment input information found output. The former path risky easily results ungrammatical targets. The latter approach enforcing stronger alignment inputs outputs tried previously assumes moderate amount noise data . % Alternatively, one leave data try put pressure decoder pay attention input every generation step . This requires significant modifications model may make harder decoder generate fluent diverse text found targets. In contrast described approaches, proposal train model data without modifying decoding architecture instead introduce handle input side control degree hallucination . With ""hallucination knob"" one minimize amount unsupported information output generation . The hallucination noise degree every training instance estimated separately converted categorical value becomes part input, like controlled generation setting . We introduce simple technique measure amount noise every training example based intuition whenever language model smaller loss conditional generator forced-path decoding, good signal next token cannot explained input. % . We consider particularly noisy dataset, WikiBio , found extra information 62\% references 1:1 correspondence input output never holds \citet{perez-beltrachini-gardent-2017-analysing}. Our models demonstrate superior performance model reports SoTA BLEU results WikiBio. % In sum, contributions novel idea controlling hallucinations requires modification model, data- task-independent technique implementing idea three-way evaluation human raters confirms faithfulness need traded coverage."," Neural text generation  demonstrates remarkable performance when training data is abundant which for many applications is not the case.  To collect a large corpus of parallel data, heuristic rules are often used but they inevitably let noise into the data, such as phrases in the output which cannot be explained by the input.  Consequently, models pick up on the noise and may hallucinate--generate fluent but unsupported text.  Our contribution is a simple but powerful technique to treat such hallucinations as a controllable aspect of the generated text, without dismissing any input and without modifying the model architecture. On the WikiBio corpus \cite{lebret-etal-2016-neural}, a particularly noisy dataset, we demonstrate the efficacy of the technique both in an automatic and in a human evaluation."
"% %Added value \atomicTT{}: 1) diversity terms vocab, style, concepts, 2) higher quality %\ronan{Cite publications used ATOMIC downstream application} Commonsense understanding % knowledge modeling reasoning remain long-standing challenges general artificial intelligence. % However, subfield natural language processing, last years brought tremendous progress AI applications. However, large-scale language models brought tremendous progress sub-field natural language processing. Such large-scale language models trained extreme-scale data shown effectively adapt diverse downstream tasks, achieving significant performance gains across natural language benchmarks . %%%%%%%OLD %%%%%% Despite successes, models shown learn brittle representations, often simple surface word associations , routinely lead make nonsensical predictions detached common sense . Interestingly, models grown larger , benchmark performance continued improve despite limited conceptual improvements, %leading many researchers conjecture leaving open questions regarding source remarkable generalization properties. Recent work hypothesized many performance gains could result language models able memorize facts parameters training leveraged evaluation time. As result, new paradigm language models knowledge bases emerged . In setting, language models prompted natural language prefixes questions, express knowledge language generation. The initial success paradigm representing commonsense knowledge %, combined limited examples LMs successfully integrated structured commonsense knowledge resources downstream application, led optimistic claim language models comprehensively encode commonsense knowledge, remove need structured knowledge resources. %\antoine{run-on sentence, need shorten} We take skeptical view capacity language models -- Does scaling language models actually endow commonsense knowledge? While language models successfully express certain types knowledge, best results observed narrowly specific conditions -- show perform better evaluated knowledge bases prioritize ontological relations whose examples resemble language-like assertions .\footnote{An observation supported \citet{brown2020language}'s \gpttt{} model, whose best few-shot performance commonsense knowledge benchmarks comes PhysicalIQA HellaSwag datasets.} Consequently, types knowledge directly accessed language model's interface remains limited. %Consequently, methods encouraging, also demonstrate limited interface language models precludes expressing diversity commonsense knowledge must accessible robust commonsense reasoning. %\chandra{i sure last line paragraph flows logically rest paragraph. maybe missing something?} However, prior work also shown training language models knowledge graph tuples leads learn express implicit knowledge directly , allowing provide commonsense knowledge on-demand. These adapted knowledge models exhibited promising results commonsense benchmarks compared methods require linking entities knowledge graphs . Inspired successes, propose dual use commonsense knowledge bases going forward: static graphs linked discrete knowledge access, resources adapting language models hypothesize commonsense knowledge un-annotated entities events. %%%%%%% OLD %%%%%%%% As result, recent work investigated augmenting language models retrieval mechanisms query commonsense knowledge graphs related facts entities mentioned text. The idea behind approaches access facts potential compose learned reasoning functions would allow models robustly leverage commonsense knowledge make predictions. Despite premise approaches, unfortunately limited coverage resources used provide commonsense knowledge facts , motivating need new, high coverage resources short-term. % Option 1 % With second purpose mind, shift design goals commonsense knowledge resources toward prioritizing pieces knowledge readily accessible pretrained language models. % Option 2 With second purpose mind, propose evaluating commonsense knowledge resources based complementary information bring pretrained language models. We construct \atomicTT{}, new, high-quality knowledge graph M commonsense knowledge tuples across commonsense relations. We compare \atomicTT{} respect coverage accuracy competition highly used CSKGs, \conceptnet~. Our results show \atomicTT{} able cover correct facts diverse types commonsense knowledge existing, publicly-available commonsense knowledge resource. However, results also indicate remains large amount exclusivity KGs, highlighting challenge creating resources cover scale diversity general commonsense knowledge. %%%%%%% OLD %%%%%%Meanwhile, new paradigm emerged proposes large-scale language models implicitly learn represent large amounts factual commonsense knowledge . While methods promising, also show limited interface language models precludes producing commonsense knowledge robustly. However, using knowledge graph tuples additional training signal allows model better adapted representing knowledge . Furthermore, use knowledge models provide commonsense knowledge on-demand shown promising results static knowledge graphs . Consequently, work, propose evaluating commonsense knowledge resources new, second purpose: whether used repurpose language models commonsense modeling. Furthermore, formalize \comet framework \citet{Bosselut2019COMETCT} across different seed language models training knowledge graphs, evaluate commonsense knowledge hypothesized adapted knowledge models. %Our results indicate purpose promising evaluation commonsense resources, \comet models successfully hypothesize plausible knowledge new, unseen entities. Our empirical study yields two promising conclusions. First, confirms KG-adapted language models learn express knowledge precisely naive language models trained language. And second, show \atomicTT{} transfer resource leads \comet models achieve largest increase seed language model commonsense knowledge types covers, validating importance constructing knowledge resources examples knowledge readily found language models. %allows language models learn representations commonsense knowledge types less covered naive language models. % Furthermore, comparison \comet models across different commonsense knowledge graphs shows \atomicTT{} transfer resource allows language models learn richer commonsense knowledge representation training resources. % Key Contributions: In summary, make three key contributions paper. We present \atomicTT{}---a new commonsense knowledge graph covering social, physical, eventive aspects everyday inferential knowledge . Next, compare \atomicTT{} prominent CSKBs head-to-head show new symbolic knowledge graph accurate current CSKB . Finally, show new neural knowledge model \comet{}-\atomicTT{} successfully transfers \atomicTT{}'s declarative knowledge beat \gpttt{}, largest pre-trained language model, spite using ~400x fewer parameters . This demonstrates utility importance high-quality symbolic knowledge provided \atomicTT{} generalize commonsense information LMs cannot expressively capture . % * Our new symbolic knowledge graph ATOMICTT superior accuracy coverage currently existing large-scale knowledge graphs . % * neural knowledge model COMET-ATOMICTT successfully transfers ATOMICTT's declarative knowledge beat even impressively large pretrained model, GPT-3 . This demonstrates LMs, matter size, benefit symbolic knowledge provided high quality KB like ATOMICTT."," % Check out this new knowledge graph! % Storyline: % \begin{enumerate} % \item We introduce \atomicTT. % \item We provide the first side-by-side comparison of commonsense knowledge bases and comprehensive ways to capture precision and coverage. % \item We show how commonsense KGs provide a clear vehicle to access knowledge in LMs.  ).  % \end{enumerate}  Recent years have brought about a renewed interest in commonsense representation and reasoning in the field of natural language understanding. The development of new commonsense knowledge graphs  has been central to these advances as their diverse facts can be used and referenced by machine learning models for tackling new and challenging tasks. At the same time, there remain questions about the quality and coverage of these resources due to the massive scale required to comprehensively encompass general commonsense knowledge.  In this work, we posit that manually constructed CSKGs will never achieve the coverage necessary to be applicable in all situations encountered by NLP agents. Therefore, we propose a new evaluation framework for testing the utility of KGs based on how effectively implicit knowledge representations can be learned from them.   With this new goal, we propose \atomicTT{}, a new CSKG of general-purpose commonsense knowledge containing knowledge that is not readily available in pretrained language models. We evaluate its properties in comparison with other leading CSKGs, performing the first large-scale pairwise study of commonsense knowledge resources. Next, we show that \atomicTT{} is better suited for training knowledge models that can generate accurate, representative knowledge for new, unseen entities and events. Finally, through human evaluation, we show that the few-shot performance of GPT-3 , while impressive, remains $\sim$12 absolute points lower than a BART-based knowledge model trained on \atomicTT{} despite using  over 430x fewer parameters.  % useful they are for training knowledge models that can generate relevant representative knowledge for new, unseen entities.  % In this work, we propose \atomicTT{}, a new knowledge graph of general-purpose commonsense knowledge facts. To evaluate its utility in comparison to existing resources, we perform the first large-scale pairwise study of commonsense knowledge graphs on coverage and precision. Finally, we posit that a new use for commonsense knowledge graphs is their ability to allow large-scale language models to learn to represent knowledge implicitly. We propose a new evaluation for testing knowledge graphs on how useful they are for training knowledge models that can generate relevant representative knowledge for new, unseen entities."
"Despite successes, neural machine translation still unresolved problems. Among problem rare words, paradoxically common Zipf's Law. In part, problem intrinsic data-driven machine translation system inevitably encounter words seen training data. In part, however, NMT systems seem particularly challenged rare words, compared older statistical models. One reason NMT systems fixed-size vocabulary, typically 10k--100k words; words outside vocabulary represented using special symbol like \unk{}. Byte pair encoding breaks rare words smaller, frequent subwords, least allowing NMT see instead \unk{} . But means solves problem; even subwords, NMT seems difficulty learning translations rare words, possibly instance catastrophic forgetting . Humans deal rare words looking dictionary, idea using dictionaries assist machine translation extremely old. From statistical perspective, dictionaries useful complement running text uniform distribution dictionary headwords smooth long-tailed distribution running text. In pre-neural statistical machine translation systems, typical way incorporate bilingual dictionaries simply include parallel sentences training data. But , work well NMT systems. We aware previous attempts find better ways incorporate bilingual dictionaries NMT. Some methods use dictionaries synthesize new training examples . \citet{arthur-etal-2016-incorporating} extend model encourage generate translations dictionary. \citet{post+vilar:naacl2018} constrain decoder generate translations dictionary. What approaches common treat dictionary definitions target-language text, when, fact, often properties different ordinary text. For example, CEDICT defines \zh{濮濄倛鍤 ``'' cannot used translation. In case monolingual source-language dictionary, definitions are, course, written target language all. In paper, present extension Transformer ``attaches'' dictionary definitions rare words occurrences source sentences. We introduce new position encodings represent nonlinear structure source sentence attachments. Then unmodified translation model learn make use attached information. We show additional information yields improvements translation accuracy 3.1 BLEU. Because method force dictionary definitions treated target-language text, generalizable kinds information, monolingual source-language dictionaries, yield smaller improvements, still much 0.7 BLEU. }} \centering \scalebox{0.8}{% \textrm{WE}[f]f\textrm{PE}[p]p\textrm{DPE}[q]q$ within dictionary definition. The rare word \zh{濮濈粯鎹 replaced \unk{} defined Dead Sea. The words definition encoded position defined word positions within definition.} \end{figure*}"," Despite advances in neural machine translation  quality, rare words continue to be problematic. For humans, the solution to the rare-word problem has long been dictionaries, but dictionaries cannot be straightforwardly incorporated into NMT. In this paper, we describe a new method for ``attaching'' dictionary definitions to rare words so that the network can learn the best way to use them. We demonstrate improvements of up to 3.1 BLEU using bilingual dictionaries and up to 0.7 BLEU using monolingual source-language dictionaries."
"% % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % % % . % % % % % final paper: en-us version % % % % % space normally used marker % % This work licensed Creative Commons % % Attribution 4.0 International License. % % License details: % % \url{http://creativecommons.org/licenses/by/4.0/}. % } % 1. 鐟欙綁鍣 CCG閿涘奔浜掗崣 CCG 閻ㄥ嫰鍣哥憰浣 % 2. CCG parsing 閻ㄥ嫰鍣搁悙鐟版躬娴 supertagging閵嗗倿娓剁憰浣割嚠 contextual information 閺堝鐦潏鍐ㄣ偨閻 encode 閻ㄥ嫭鏌熷▔鏇樺倸澧犳禍铏规畱閺傝纭堕敍灞间簰閸欏﹤鐪梽鎰剁礄閸欘亪鍣伴悽 powerful encoder閿涘本鐥呴張澶嬪赴濮瑰倿顤傛径 contextual feature 閻ㄥ嫪缍旈悽銊ф畱閻梻鈹掗敍 % 3. n-gram 閺勵垯绔存稉顏呮箒閺佸牏娈 contextual feature閿涘苯褰查懗钘夘嚠 supertagging 閺堝鏁ら敍鍫熷絹娓氭稑褰查懗鐣屾畱鐠囧秳绗岀拠宥勭闂 combination 閻ㄥ嫭娈粈鐚寸礆 % 4. 閹存垳婊戦惃 model % 鐟欙綁鍣 CCG閿涘矁鐦濆Ч鍥瘱閻ｈ揪绱檚upertag閿涘婀伴煬顐㈠瘶閸氼偂绨℃稉鏉跨槣閻ㄥ嫬褰炲▔鏇炴嫲鐠囶厺绠熼惃鍕繆閹 Combinatory categorial grammar lexicalized grammatical formalism, lexical categories words sentence provide informative syntactic semantic knowledge text understanding. % 閹垫禒 ccg閿涘瞼澹掗崚顐ｆЦ supertagging 瀵板牊婀侀悽 Therefore, CCG parse often provides useful information many downstream natural language processing tasks logical reasoning semantic parsing . To perform CCG parsing different languages, % 閸 ccg parsing 閸掑棔琚卞銉ｄ靠upertagging 鏉╂瑤绔村銉︽付闁插秷顩 studies conducted supertagging-parsing pipline , main focus first step, generated CCG parse trees directly supertags rules afterwards. % known ``almost parsing'' % essential CCG information sentence one generate parse directly supertags rules. % supertagging 闂囩憰 contextual information % Building accurate supertagger sequence labeling process requires good modeling contextual information. % Recent neural approaches supertagging mainly focused leveraging powerful encoders recurrent models , limited attention paid modeling extra contextual features word pairs strong relations. % Graph convolutional networks demonstrated effective approach model contextual information words many NLP tasks ; thus want determine whether approach also help CCG supertagging. However, cannot directly apply conventional GCN models CCG supertagging previous studies GCN models built edges dependency tree input sentence. As high-quality dependency parsers always available, want CCG supertaggers rely existence dependency parsers. % Thus, need another way extract useful word pairs build GCN models. For that, propose obtain word pairs frequent chunks corpus, chunks easy identify co-occurrence counts. % % % % Such features, may come n-grams dependency parsing results, demonstrated helpful many NLP tasks , expected enhance CCG supertagging well. % Among features, ones n-grams attractive since n-grams easy obtain also provide word relation cues, dependency parsing results exactly goal CCG thus conflicts problem setting. % % As model encode features, graph convolutional networks one promising choices although often built dependency semantic parse input text. %However, GCN suffers limitation obtaining parsing results, exactly goal CCG thus conflicts problem setting. % %So one expected enhance CCG supertagging. %especially n-gram ones easy obtain provide cues word-word combination appropriately modeled. % %\textcolor{blue}{ %To leverage contextual features, graph convolutional networks one privileging approaches so, graph often built dependency semantic parsing results input text. %However, GCN suffers limitation obtaining parsing results, exactly goal CCG thus conflicts problem setting. %} % \textcolor{red}{ % Consider graph convolutional networks , effective solution learn contextual information demonstrated useful many NLP tasks , potentially useful CCG supertagging.} % , semantic role labeling , sentiment classification , question answering . %input words based results dependency semantic parsing input texts, may appropriate way construct graph CCG, %since task parsing. % \textcolor{blue}{ % Therefore, appropriate way construct graph required CCG n-grams could potentially helpful since carry contextual information provide group words % containing words % may strong relationship respect word-word combination n-grams appropriately selected. % % } % Previous studies using GCN often build graph dependency semantic parsing results input text, suffering limitation obtaining parsing results, exactly goal CCG thus conflicts problem setting. % To appropriately learn n-grams, one requires GCN able distinguish different word pairs information n-grams explicitly structured dependency parses. %In addition, Because existing GCN models limited treating word pairs equally, %while identifying learning essential units important syntactic tasks, propose adaptation conventional GCN CCG supertagging. %especially graph constructed dependencies. % % Inspired n-grams carry contextual information provide span containing words may strong relationships n-grams appropriately selected, build graph upon well selected n-grams. % , especially ones containing words strong relationships other, % % n-gram 閺勵垯绔存稉顏堝櫢鐟曚胶娈 contexutal feature % Consider n-grams conventionally used simple yet effective method represent contextual features many NLP tasks %in powerful encoders used % , % 閸ョ姵顒濋敍瀹-gram 鐎 supertagging 娑旂喐婀侀悽顭掔礉鐏忋倕鍙鹃弰顖炲亝娴滄稖鍏樻径鐔虹矋閹存劗鐓拠顓犳畱 n-gram閿涘矁鍏樻径鐔稿絹娓氭稑鍙ф禍搴ょ槤娑撳氦鐦濇稊瀣？缂佸嫬鎮庨崗宕囬兇閻ㄥ嫪淇婇幁顖ょ礉閺堝濮禍 supertagging % also expected serve effective contextual features CCG supertagging, they, \textcolor{blue}{especially ones containing words strong relationships other,} % valid phrases, % provide plausible cues potential combinations among words. % 閻掓儼宀嬬礉婵″倷缍嶉張澶嬫櫏閸︽澘鍩勯悽銊ㄧ箹娴 n-gram 娓氭繃妫弰顖欑娑擃亝瀵幋姗堢礉閸ョ姳璐熼柇锝勭昂娑撳秹鍣哥憰浣烘畱 n-gram 閸欘垯浜掔拠顖氼嚤 supertagger %\textcolor{blue}{ % However, trivial appropriately learn n-grams syntactic tasks, % one needs identify informative n-grams possible combinations words task. %since unimportant ones carrying misleading cues combination may hurt performance supertagger. %} % % 閹垫禒銉ь儑娑撳顔岄柌宀勬桨鐏忚精顩﹂崨鐓庣安鏉╂瑩鍣烽惃鍕敶鐎圭櫢绱濈悰銊с仛閸戠儤娼甸幋鎴滄粦閺冦垼鍏橀悽鈺猤ram閿涘苯寮甸懗鐣屾暏GCN缂佹獢gram瀵ょ儤膩 % 閹存垳婊戦幓鎰毉 channeled attention 閺 model 鏉╂瑤绨 n-gram %To address problems, In paper, propose attentive GCN CCG supertagging, input graph built based chunks extracted unsupervised methods. % In paper, propose attentive GCN CCG supertagging, input graph built upon word groups suggested high confident n-grams extracted unsupervised methods. % , graph constructed word groups. %which follows sequence labeling paradigm. % 鐠囷妇绮忔禒瀣矝婵″倷缍嶅銉ょ稊閿涘矂顩婚崗鍫濐嚠 n-gram 閸掑棛绮 % Inspired n-grams carry contextual information provide span containing words may strong relationships n-grams appropriately selected, build graph upon n-grams sentence, edge added pair words n-gram. In detail, two types edges graph introduced model word relations within across chunks %for word groups model word-word relation within cross groups. % build graph words upon n-grams input sentence, edge added pair words span suggested n-gram. % % For edges within group, feed-forward attention applied attention mechanism applied GCN weight edges. %and discriminately learn edges. %In addition, word, attention mechanism used % weight contextual information carried associated words according contribution tagging process. % In so, different contextual information discriminatively learned facilitate CCG supertagging without requiring external resources. % , \textcolor{blue}{within cross chunk relations} % local global word relations % weighted in-chunk cross-chunk edges, respectively. %Moreover, way building graph requires external resources %suggested high confident n-grams learned A-GCN in-group edges; long distance relations among groups also leveraged cross-group edges. %Therefore, hierarchical structure word relations built %Besides, approach proposes novel self-supervised method build graph GCN, extra parsing results required extra input. % , also attentive GCN able discriminately learn contextual information carried different words.} % In proposed attention, n-grams associated word input texts firstly categorized different groups according length, % 閻掕泛鎮楀В蹇庨嚋 n-gram 閺夈儱濮為弶 % fed specific channel attentions according groups, n-grams weighted separately group according contributions supertagging process. % 婵傝棄顦╅敍宀顑囨稉閺勵垰灏崚顐＄啊闁插秷顩﹂惃鍕嫲娑撳秹鍣哥憰浣烘畱 n-gram閿涙稓顑囨禍灞炬Ц閼宠棄顧勬禒搴ㄥ亝娴滄盯鍣哥憰浣烘畱闂 n-gram 娑擃厼顒熼崚鐗堟纯鏉╂粏绐涚粋鑽ゆ畱 context information % In so, important n-grams distinguished, also approach discriminatively learn n-grams different length, infrequent long n-grams carrying important long range contextual information appropriately modeled without influenced frequent short ones. % % 鐎圭偤鐛欑拠浣规閺堝鏅 The validity approach demonstrated experimental results CCGbank , state-of-the-art performance obtained tagging parsing.","  % supertagging 閻庣敻娑氳壘 CCG parsing 闂傚牏鍋涢悥鍫曟煂瀹ュ牜娲 Supertagging is conventionally regarded as an important task for combinatory categorial grammar  parsing, where effective modeling of contextual information is highly important to this task. % 闂傚嫨鍊撶花鈩冩媴鐠恒劍鏆忛柡鍥ㄦ綑瀹搁亶鎯 encoder闁挎稑鏈惁顔戒繆 biLSTM闁挎稑鑻晶鐘崇閸濆嫷鍤犲ù supertagging 閺夆晜鐟ら柌 task 闁告垹濮崇粻顔尖柦閿涘嫭鏆忛柛鎺楊暒缁牊绋婇崼婵嗙劶闁 context feature闁挎稑鑻畵 n-gram However, existing studies have made limited efforts to leverage contextual features except for applying powerful encoders . % 闁哄牜鍓氶弸鍐晬鐏炴儳鐏夊ù鐙鍓氳ぐ渚宕 channeled n-gram attention 闁哄鍎遍ˇ鈺呮偠閸℃氨绠瑰☉鎿冧邯濡埖锛 In this paper, we propose attentive graph convolutional networks to enhance neural CCG supertagging through a novel solution of leveraging contextual information. %  Specifically, we build the graph from chunks  extracted from a lexicon and apply attention over the graph, so that different  % word relations  word pairs from the contexts within and across chunks are weighted in the model and facilitate the supertagging accordingly. % 閻庡湱鍋ら悰娆戠磼閹惧浜悶娑栧妽濡叉垿鏁嶇仦鎯х亯濞寸媭鍓涘▓鎴﹀棘鐟欏嫮銆婇柡鍕靛灡濠渚寮崼銏＄暠 The experiments performed on the CCGbank demonstrate that our approach outperforms all previous studies % , as well as strong baselines from existing toolkits,  in terms of both supertagging and parsing. %  Further analyses illustrate the effectiveness of each component in our approach to discriminatively learn from word pairs to enhance CCG supertagging.\footnote{Our code and models for CCG supertagging are released at \url{https://github.com/cuhksz-nlp/NeST-CCG}.}"
"Pre-trained Transformers lead state-of-the-art results wide range NLP tasks, example, named entity recognition, relation extraction question answering, often approaching human inter-rater agreement . These models also demonstrated learn effective cross-lingual representations, even without access parallel text bilingual lexicons . Multilingual pre-trained Transformers, mBERT XLM-RoBERTa , support surprisingly effective zero-shot cross-lingual transfer, training development data assumed high resource source language , performance evaluated another target language. Because target language annotations assumed setting, source language data typically used select among models fine-tuned different hyperparameters random seeds. However, recent work shown English dev accuracy always correlate well target language performance . In paper, propose alternative strategy model selection zero-shot setting. Our approach, dubbed Learned Model Selection , learns function scores compatibility fine-tuned multilingual transformer, target language. The compatibility score calculated based features multilingual model's learned representations target language. A model's features based internal representations; done aggregating representations unlabeled target language text corpus. These model-specific features capture information cross-lingual representations transfer target language fine-tuning source language data. In addition model-specific representations, also make use learned language embeddings lang2vec package , shown encode typological information, example, whether language prepositions postpositions. To measure compatibility multilingual model's fine-tuned representations target language, model- language- specific representations combined bilinear layer. Parameters scoring function optimized minimize pairwise ranking loss set held-out models, gold ranking calculated using standard performance metrics, accuracy F, set pivot languages . LMS rely annotated data target language meta-learning hyperparameter tuning, yet effective learning predict whether multilingual model's representations good match specific target language. In experiments five well-studied NLP tasks , find LMS consistently selects models better target-language performance chosen using English dev data. Appendix demonstrates framework supports multi-task learning, helpful settings target-language annotations available, desired task. Finally, show LMS generalizes mBERT XLM-RoBERTa Appendix ."," Transformers that are pre-trained on multilingual text corpora, such as, mBERT and XLM-RoBERTa, have achieved impressive cross-lingual transfer learning results.  In the zero-shot cross-lingual transfer setting, only English training data is assumed, and the fine-tuned model is evaluated on another target language.  No target-language validation data is assumed in this setting, however substantial variance has been observed in target language performance between different fine-tuning runs.  Prior work has relied on English validation/development data to select among models that are fine-tuned with different learning rates, number of steps and other hyperparameters, often resulting in suboptimal choices.  To address this challenge, we propose a meta-learning approach to model selection that uses the fine-tuned model's own internal representations to predict its cross-lingual capabilities.  In extensive experiments we find that our approach consistently selects better models than English validation data across five languages and five well-studied NLP tasks, achieving results that are comparable to small amounts of target language development data.\footnote{We will make our code and data available on publication.}  %We further demonstrate that our method can benefit from pooling data across tasks when auxiliary annotations are available in the target language."
"% Summarization process identifying important information pieces document. For humans, process heavily guided background knowledge, encompasses preconceptions task priors kind information important . % % % Understanding background knowledge would yield insights what, average, humans consider known, interesting important. % Furthermore, accurate models human background knowledge would greatly valuable improve selection methods information selection systems. % Despite fundamental role, background knowledge received little attention summarization community. Existing approaches largely focus relevance aspect, enforces similarity generated summaries source documents . % , without consideration background knowledge. In previous work, background knowledge usually modeled simple aggregation large background corpora. % A prominent example \cpt{TFIDF} , practical solution problem identifying content words based document frequencies within background corpora. For instance, using \cpt{TFIDF} , one may operationalize background knowledge set words large document frequency background corpora. %While approach useful stopword problem significant development summarization systems, cannot easily extended model background knowledge. However, assumption frequently discussed topics reflect is, average, known necessarily hold. For example, common-sense information often even discussed . Also, information present background texts already gone importance filter humans, e.g., writers publishers. In general, particular difficulty preventing development proper background knowledge models latent nature. We hope infer proxy signals. Besides, is, present, principled way compare evaluate background knowledge models. % In work, put background knowledge foreground propose infer summarization data. Indeed, choices made human summarizers human annotators provide implicit information background knowledge. We build upon recent theoretical model information selection , postulates information selected summary results 3 desiderata: low redundancy , high relevance , high informativeness . The tension 3 elements encoded summary scoring function explicitly depends background knowledge . % explicitly depends background knowledge . As illustrated \Figref{fig:overall}, latent inferred residual differences information selection explained relevance redundancy. For example, black information unit \Figref{fig:overall} selected summary despite prominent source document. Intuitively, explained unit already known receiver. % human summarizer regarded important. To leverage implicit signal, view latent parameter learned best fit observed summarization data. % \xhdr{Contributions} We develop algorithms inferring two settings: pairs documents reference summaries pairs observed pairs document summaries enriched human judgments . % The framework also provides evaluation methodology , measuring well resulting correlates human judgments. In \Secref{sec:comparison} evaluate inferred respect well induced scoring function correlates human judgments. Our proposed algorithms significantly surpass previous baselines large margins. In \Secref{sec:geometry}, give geometrical perpespective framework show clear geometrical structure emerges real summarization data. % The framework simple, constrained interpretable hinder ability fit data. In fact, proposed algorithms significantly largely surpass previous baselines terms correlation human judgments. % The framework general inferring human prior information importance broad use. We explore several applications briefly discuss potential future work. The ability infer interpretable importance priors data-driven way many applications, explore \Secref{sec:applications}. % We explore later discuss possibilities future work. \Secref{sec:qualitative_analysis} qualitatively reveals topics emerge known unkown fitted priors. % First, possible investigate qualitatively fitted priors understand topics emerge known unkown. % We word level topic-model level. Moreover, infer based different subsets data. By training data one annotator, get prior specific annotator. Similarly, one find domain-specific 's training different datasets. This explored \Secref{sec:annotator_specific}, analyze annotators different summarization datasets, yielding interesting insights, e.g., averaging several, potentially biased, annotator-specific domain-specific 's results systematic generalization gains. % Adding inferred 's summarization systems produce improvements quality extracted summaries . Finally, discuss future work potential applications beyond summarization \Secref{sec:ccl}. Our code available \url{https://github.com/epfl-dlab/KLearn} %that averaging various annotator specific 's gives large generalization improvements single annotators compared previous baselines. Furthermore, average annotators performs almost good optimal . Similarly, averaging many domain-specific 's gives significant improvements baselines TAC datasets. %Finally, qualitative analysis best 's reveals capture stopwords properties IDFs even without exposed background corpora. %Background knowledge important summarization often left out. %When left out, requires design choices collection large background corpora. %Previous work defined simple models summarization involves background knowledge first principles %We show formulation allows us infer background knowledge simply observing human preferences. %In fact, probabilistic model developed infer background knowledge pairs document summaries."," The goal of text summarization is to compress documents to the relevant information while excluding background information already known to the receiver. So far, summarization researchers have given considerably more attention to relevance than to background knowledge. In contrast, this work puts background knowledge in the foreground. Building on the realization that the choices made by human summarizers and annotators contain implicit information about their background knowledge, we develop and compare techniques for inferring background knowledge from summarization data. Based on this framework, we define summary scoring functions that explicitly model background knowledge, and show that these scoring functions fit human judgments significantly better than baselines. We illustrate some of the many potential applications of our framework. First, we provide insights into human information importance priors. Second, we demonstrate that averaging the background knowledge of multiple, potentially biased annotators or corpora greatly improves summary\hyp scoring performance. Finally, we discuss potential applications of our framework beyond summarization. % Finally, we apply our models in a simple yet effective summarization system."
". } Definition Extraction refers task Natural Language Processing detecting extracting term definition different types text. A common use automatic definition extraction help building dictionaries , employed many applications. For example, ontology building benefit methods extract definitions , whilst fields definition extraction information extraction employ similar methodologies. It therefore normal growing interest task definition extraction. This paper describes system participated two three subtasks Task 6 SemEval 2020 , shared task focused definition extraction specialised corpus. Our method employs state-of-the-art neural architectures combination automatic methods extend clean provided dataset. %Task 6 SemEval 2020 shared task definition extraction specialised corpus, tailoured specifically needs definition extraction. This paper describes RGCL team system works three subtasks shared task. We employ state-of-the-art neural architectures combine simple automatic methods extend clean provided dataset appropriate. The remaining parts paper structured follows. First, present related work area definition extraction related field relation extraction . The three subtasks dataset provided task organisers described Section . Next, describe system , followed results evaluation final conclusion .","   This paper presents the RGCL team submission to SemEval 2020 Task 6: DeftEval, subtasks 1 and 2. The system classifies definitions at the sentence and token levels. It utilises state-of-the-art neural network architectures, which have some task-specific adaptations, including an automatically extended training set. Overall, the approach achieves acceptable evaluation scores, while maintaining flexibility in architecture selection."
"Event extraction process extract named entities, event triggers relationships real-world corpora. The named entities refer texts predefined classes event triggers words express types events texts . In literature, named entities triggers connected named entities corresponding roles called arguments given trigger specific event. %Named entities refer text mentions predefined classes person names, company names locations, etc. An event trigger word mostly expresses event types text. Named entities link triggers different roles, named entities corresponding roles called arguments given trigger specific event. Currently, existing works divide event extraction two independent sub-tasks: named entity recognition trigger labeling. These two sub-tasks always formulated multi-class classification problems, many works apply sequence-to-sequence based labeling method aims translate sentence sequential tags. From investigation, one problem sequence-to-sequence methods ignore orders output tags, therefore, difficult precisely annotate different parts entity. To address issue, methods propose incorporate conditional random field module aware order-constraints annotated tags. Since entities triggers naturally connected around events, recent works try extract jointly corpora. Early methods apply pipeline frameworks predefined lexical features lack generality different applications. Recent works leverage structural dependency entities triggers improve performances entity trigger identification sub-tasks. %The prevalent methods divided two categories: a) parallel framework obtain entities triggers simultaneously b) pipeline framework get triggers first perform sub-tasks extract entities. Takanobu et al. propose hierarchical reinforcement learning model extract triggers first evoke sub-process get related entities referring obtained triggers sentences. Nguyen et al. design attention mechanism augment accuracy trigger extraction multilingual environments. Fu el al. employ graph convolutional network capture local contextual information sentences use two-stage method extract entities triggers text together. % The main challenges improve performance jointly extract entities triggers two-fold: Although existing works achieved comparable performance jointly extracting entities triggers, approaches still suffer major limitation losing co-occurrence relationships entities triggers. Many existing methods determine trigger entities separately match entities triggers. % In way, co-occurrence relationships entities triggers ignored, therefore, methods might require pre-trained features prior data order achieve better performance. In way, co-occurrence relationships entities triggers ignored, although pre-trained features prior data introduced achieve better performance. It also challenging capture effective co-occurrence relationships entities triggers. We observed experiments entities triggers co-occurred sparsely throughout corpus. This issue exacerbates problem losing co-occurrence relationships mentioned before. %However, existing methods suffer performance degradation extracting entities triggers jointly. The reason entities triggers sparsely co-occurred throughout corpus previous approaches well handle sparse co-occurred relationship. %In addition, challenging establish effective interaction mechanism sub-tasks joint-event-extraction, traditional joint learning may lead error-propagation issue lowers accuracy joint tasks. %% label entire figure \end{figure*} To address aforementioned challenge, core insight paper joint-event-extraction task, ground-truth annotations triggers could leveraged supervise extraction entities, vice versa. Based insight, paper proposes novel method extract structural information corpora utilizing co-occurrence relationships triggers entities. Furthermore, order fully address aforementioned sparsely co-occurrence relationships, model entity-trigger co-occurrence pairs heterogeneous information network supervise trigger extraction inferring entity distribution given triggers based indirect co-occurrence relationships collected along meta-paths heterogeneous information network . Figure illustrates process proposed method collect indirect co-occurrence relationships entities triggers. Figure sub-graph ``entity-trigger'' HIN ACE 2005 corpus. Figure compares entity distributions inferred given triggers based direct adjacency matrix inferred meta-path adjacency matrix. From figure, observe trigger necessarily connect entities directly direct-adjacency-based distribution concentrated entities, meta-path-based distribution spread larger number entities. This shows model could collect indirect co-occurrence patterns entities triggers based meta-path adjacency matrix ``entity-trigger'' HIN. Moreover, obtained indirect patterns could applied improve performance extract entities triggers. Based aforementioned example analysis, propose neural network extract event entities triggers. Our model built top sequence-to-sequence labeling framework inner parameters supervised ground-truth annotations sentences ``entity-trigger'' co-occurrence relationships. Furthermore, fully address indirect ``entity-trigger'' co-occurrence relationships, propose \underline{C}ross-\underline{S}upervised \underline{M}echanism based HIN. The CSM alternatively supervises entity trigger extraction indirect co-occurrence patterns mined corpus. CSM builds bridge triggers entities collecting latent co-occurrence patterns along meta-paths corresponding heterogeneous information network corpus. Then obtained patterns applied boost performances entity triggers extractions alternatively. We define process ``cross-supervise'' mechanism. The experimental results show method achieves higher precisions recalls several state-of-the-art methods. In summary, main contributions paper follows: The remainder paper organized follows. In Section, first introduce preliminary knowledge event extraction HIN, also formulate problem. Section presents proposed model detail. Section verifies effectiveness model compares state-of-the-art methods real-world datasets. Finally, conclude paper Section."," Joint-event-extraction, which extracts structural information  from unstructured real-world corpora, has attracted more and more research attention in natural language processing. Most existing works do not fully address the sparse co-occurrence relationships between entities and triggers, which loses this important information and thus deteriorates the extraction performance. To mitigate this issue, we first define the joint-event-extraction as a sequence-to-sequence labeling task with a tag set composed of tags of triggers and entities. Then, to incorporate the missing information in the aforementioned co-occurrence relationships, we propose a \underline{C}ross-\underline{S}upervised \underline{M}echanism  to alternately supervise the extraction of either triggers or entities based on the type distribution of each other. Moreover, since the connected entities and triggers naturally form a heterogeneous information network , we leverage the latent pattern along meta-paths for a given corpus to further improve the performance of our proposed method. To verify the effectiveness of our proposed method, we conduct extensive experiments on four real-world datasets as well as compare our method with state-of-the-art methods. Empirical results and analysis show that our approach outperforms the state-of-the-art methods in both entity and trigger extraction."
"Recently, pre-trained self-supervised models BERT attracted increasing amount attention natural language processing vision-language processing. Benefiting common knowledge contained massive unlabeled data, pretraining-finetuning framework become representative paradigm advancing various language-related downstream tasks. Most endeavors pre-trained representation models rely elaborately designed self-supervised tasks, typically corrupt given sequence certain types noise , train model recover original sequence. As consequence, learned representations tend covariant input noise pre-training paradigm. However, transferred downstream tasks, pre-trained model responsible encoding original sequence without noise, expected obtain noise invariant representations. Such pretrain-finetune discrepancy impedes fast fine-tuning, also may result suboptimal sequence representations, thus affecting performance downstream tasks. %%%%%%%%%%%% % % \vskip -0.1in % \end{table} %%%%%%%%%%%% %%%%%%%%%%%% % %%%%%%%%%%%% To remedy this, present ContrAstive Pre-Training learn noise invariant sequence representations. %, inspired Noise Contrastive Estimation. The core idea CAPT enhance consistency semantic representations original sequence corresponding corrupted version via unsupervised instance-wise training signals. %can fully utilized via elaborately designed semantic contrastive loss. %As shown Figure, approach In detail, strives pull representation corrupted sequence towards original instance semantic space, pushing away representations instances. % Such training objectives formulated multi-class classification task, aims classifying original sequence class corrupted version vice versa, classifying different instances different classes. % For implementation feasibility, two effective model extension proposed enhance capability model extract noise-concentrated instance-diffused features. Moreover, order enable model learn ``difficult'' ``diverse'' instances, two effective methods proposed enhance capability model extract noise-concentrated instance-diffused features. With training objective, pre-trained model encouraged learn noise invariant representations, thereby alleviating pretrain-finetune discrepancy extent. As additional benefit, CAPT also assists pre-trained model effectively capture global semantics input. Most prior work focuses token-level pre-training tasks , lacks modeling global semantics input. Some efforts alleviate problem introducing sentence-level pre-training tasks rely relative position segments document. However, semantic connection segments tends excessively loose, may result confusing gradient signals. By contrast, CAPT offers incentives representations inputs sharing semantics similar, representations inputs expressing different semantics penalized distinguished other. Such reasonable sentence-level supervision enables approach look beyond local structures input sequences become aware global semantics. %With reasonable sentence-level supervision, approach achieves better modeling global semantics input. We perform evaluation comprehensive suite benchmark, covering 8 natural language understanding 3 cross-modal tasks. Extensive empirical evidence demonstrates approach achieve consistent improvements baselines language vision-language domains. To specific, CAPT raises performance RoBERTa 88.9\% 89.5\% GLUE dev set, also surpasses LXMERT 0.5\%, 0.6\% 0.8\% VQA, GQA , respectively."," Pre-trained self-supervised models such as BERT have achieved striking success in learning sequence representations, especially for natural language processing. These models typically corrupt the given sequences with certain types of noise, such as masking, shuffling, or substitution, and then try to recover the original input. However, such pre-training approaches are prone to learning representations that are covariant with the noise, leading to the discrepancy between the pre-training and fine-tuning stage. To remedy this, we present ContrAstive Pre-Training  to learn noise invariant sequence representations. The proposed CAPT encourages the consistency between representations of the original sequence and its corrupted version via unsupervised instance-wise training signals. In this way, it not only alleviates the pretrain-finetune discrepancy induced by the noise of pre-training, but also aids the pre-trained model in better capturing global semantics of the input via more effective sentence-level supervision. Different from most prior work that focuses on a particular modality, comprehensive empirical evidence on 11 natural language understanding and cross-modal tasks illustrates that CAPT is applicable for both language and vision-language tasks, and obtains surprisingly consistent improvement, including 0.6\% absolute gain on GLUE benchmarks and 0.8\% absolute increment on $\text{NLVR}^2$."
"\subsection{Natural Language Processing} Ang Natural Language Processing ay isang subfield ng linguistics, computer science, artificial intelligence na nauukol sa pag proseso pag-unawa ng natural na wika . Ang ilan sa mga aplikasyon ng NLP ay ang email spam filters , pag-unawa ng nais sabihin tulad ng mga smart assistants , pagsasalin ng isang wika sa iba pang wika , mag predict ng susunod na salita base sa mga naunang salita , marami pang iba. Dahil sa kaunlaran sa kasaganahan sa datos pagiging accessible ng malakas na compute power, nabuhay muli ang machine learning approach. Sa maikling salita, ang machine learning approach ay gumagamit ng malaking datos na ginagamit ng isang computer algorithm upang matutunan ang mga patterns ng datos na ito. Dahil dito, naging epektibo siyang approach sa mga komplikadong problema dahil hindi na kailangan direktang i-program ang mga rules para malutas ang isang problema. \subsection{Transfer Learning} Notorious ang machine learning approach sa pangangailangan nito ng sobrang laking datos para mapakinabangan. Ang Transfer Learning ay isang area ng research na concerned sa problemang ito . Sa maikling salita, ang TL ay ang pag retain pagpapanatili ng mga natutunan ng isang model sa isang gawain paggamit ""transfer"" ng mga natutunan nito sa iba pero may kaugnayan na gawain. Halimbawa, ang mga natutunan ng isang model sa pag detect ng muka ng tao ay maaring gamitin bilang tuntungan para sa pag-aaral ng model na matutunan kung ang muka ng tao ay galit, masaya, iba pang facial expressions ."," Ang mga low-resource languages tulad ng Filipino ay gipit sa accessible na datos kaya't mahirap gumawa ng mga applications sa wikang ito. Ang mga Transfer Learning  techniques ay malaking tulong para sa low-resource setting o mga pagkakataong gipit sa datos. Sa mga nagdaang taon, nanaig ang mga transformer-based TL techniques pagdating sa low-resource tasks ngunit ito ay mataas na compute and memory requirements kaya nangangailangan ng mas mura pero epektibong alternatibo. Ang papel na ito ay may tatlong kontribusyon. Una, maglabas ng pre-trained AWD-LSTM language model sa wikang Filipino upang maging tuntungan sa pagbuo ng mga NLP applications sa wikang Filipino. Pangalawa, mag benchmark ng AWD-LSTM sa Hate Speech classification task at ipakita na kayang nitong makipagsabayan sa mga transformer-based models. Pangatlo, suriin ang performance ng AWD-LSTM sa low-resource setting gamit ang degradation test at ikumpara ito sa mga transformer-based models."
"\iffalse \dr{%If want reposition abstract, start considering event Fig. 1: Natural language text typically written tell reader events. But events expressed single predicate mentions, rather structures multiple predicates arguments. Consider description impact Typhoon Fig..... It mentioned typhoon killed people , flights canceled affected many people. It also clear temporal order among predicates, recognizing important understanding composite event. Then continue saying goal.} \fi % typically, single predicate mention constitute typically think events; typically think event something consists multiple primitive structures %{\fontsize{10.5}{11} \selectfont Text} %\fontsize{11pt}{13pt}\selectfont Human languages evolve communicate %always involve description real-world events. Therefore, understanding events plays critical role natural language understanding . A key challenge mission lies fact events simple, standalone predicates. Rather, often described different granularities may form complex structures. %topologies. Consider example Figure, description storm involves fine-grained event mentions people killed , flights canceled passengers affected . Some mentions also follow strict temporal order . Our goal induce event complex recognizes %organizes membership multi-granular events described text, well temporal order. This core text understanding, also beneficial various applications question answering , narrative prediction , timeline construction summarization . %\dr{The choice references good revealing; I suggest replace summarization ``classical"" summarization paper . %such question answering , narrative prediction , coreference resolution , summarization . Since events standalone objects, understanding event essentially involves comprehending relations, %cite{wities-etal-2017-consolidated, wadden-etal-2019-entity}, relations , well internal structures processes . inasmuch necessarily provide actionable knowledge support question answering , narrative prediction , timeline construction summarization . \muhao{TODO: forming call ``event complex''} Human languages always involve description real-world events. Therefore, understanding events plays critical role natural language understanding , supports tasks question answering , narrative prediction , timeline construction summarization . Typically, events standalone predicate mentions, rather structures multiple predicates. Consider example Figure. The description impact storm also involves mentions killed people , canceled flights affected passengers . Some mentions thereof also follow temporal order. To support comprehension complex events, important recognize multifaceted relations predicate mentions text. \fi % second paragraph \iffalse Recently, much research effort put extracting specific aspects relations events. \citet{ning-etal-2018-improving} studied event temporal relation extraction statistical common sense resource \citet{ning-etal-2019-improved} \citet{han-etal-2019-joint} adopted data-driven methods TempRel extraction; parent-child relations among events studied \citealp[]{liu-etal-2018-graph} \citealp[]{aldawsari-finlayson-2019-detecting}. Though previous work ensured consistency via adding constraints inference phase, essentially improving local predictions inconsistent results models might corrected inference stage. Besides, approaches suffered limited learning resources tasks studied separately. \fi Recently, significant %much research effort devoted several event-event relation extraction tasks, event temporal relation extraction subevent relation extraction . Addressing challenging tasks requires model recognize inherent connection event %\dr{should predicate mentions, ease ambiguity?} mentions well contexts documents. Accordingly, previous methods apply statistical learning methods characterize grounded events documents . Such methods often require designing various features characterize structural, discourse narrative aspects events, costly produce often specific certain task dataset. More recent works attempted use data-driven methods based neural relation extraction models refrain feature engineering offer competent performances. \iffalse \dr{The next two paragraphs shortened, right paragrpahs include here.} While data-driven methods provide general tractable way capture specific event-event relations, still remains challenging methods precisely infer correct relations. One challenge almost every task event-event relation extraction comes limited available annotated resources. Specifically, tasks annotate hundred articles . Even largest one literature, i.e., MATRES TempRel extraction, contains annotation merely 275 articles. The lack supervision hinders feature learning events well inference relations, %Therefore, effectively tackling tasks inevitably calls therefore calling upon plausible auxiliary supervision resources external tasks. On hand, event-event relations often constrained %\drc{logical \dr{}change everywhere} %logic %\muhao{done.} properties, transitivity TempRels Before After , well %the relation parent child events subevent relations . In favor constraints, literature employed global inference inference phase comply logical properties particularly TempRels . However, lacks effective way ensure global logical consistency training phase, key making data-driven machine learning model consistent beliefs training data various relation types . Moreover, logical constraints may apply different categories %event-event relations, form complex conjunctive rules. Consider example Figure : given e2:died Before e3:canceled e3:canceled parent event e4:affecting, learning process enforce e2:died Before e4:affecting. %\todo{Add example conjunctive rule containing temporal subevent relations.} Accordingly, ensuring logical constraints across task-specific relations another challenge overlooked literature, resolve provides natural way bridge learning processes multiple tasks. %\magenta{HW:TCR?} \fi While data-driven methods provide general tractable way event-event relation extraction, performance restricted limited annotated resources available. For example, largest temporal relation extraction dataset MATRES 275 articles, far enough training well-performing supervised model. The observation relations and, particular, event-event relations constrained logical properties , led employing global inference comply transitivity symmetry consistency, specifically TempRel . However, event complex, logical constraints may globally apply different task-specific relations, form complex conjunctive constraints. Consider example Figure : given e2:died Before e3:canceled e3:canceled Parent event e4:affecting, learning process enforce e2:died Before e4:affecting considering conjunctive constraints TempRel subevent relations. While previous works focus preserving logical consistency inference structured learning , %lacks effective way endow neural models sense global logical consistency training. %\dr{Notice previous statement correct; I change limit neural models, since structure learning it} %ensure global logical consistency training phase. This key bridging %bridge learning processes %on TempRel subevent relations, research focus paper. %Event-relation extraction non-trivial task following challenges: %1) Almost every event relation extraction task comes limited learning resources annotations. %2) Event relations often volatile given different scenarios, determination parent-child relation especially difficult since less explicit lexical expressions compared cases time causation. %3) Event relations often endowed logical properties: % temporal relations parent-child relations comply transitivity; % logical consistency also ensured across different categories event relations. The first contribution work proposing %to propose joint constrained learning model multifaceted event-event relation extraction. The joint constrained learning framework seeks regularize model towards consistency logical constraints across temporal subevent relations, three types consistency requirements considered: annotation consistency, symmetry consistency conjunction consistency. Such consistency requirements comprehensively define interdependencies among relations, essentially unifying ordered nature time topological nature multi-granular subevents based set declarative logic rules. Motivated logic-driven framework proposed \citet{li-etal-2019-logic}, declarative logical constraints converted differentiable functions incorporated learning objective relation extraction tasks. Enforcing logical constraints across temporal subevent relations also natural way combine %two event-event relation extraction tasks shared learning objective. supervision signals coming two different datasets, one relation extraction tasks shared learning objective. %\dr{You said first contribution, second; want claim second contribution? Note I modified emphasize two datasets} %Besides, consistency final prediction enforced global inference via ILP solver. Despite scarce annotation tasks, proposed method surpasses SOTA TempRel extraction method MATRES relatively 3.27\% ; %\dr{I understand -- relative F1? Also, Tab. 2 shows 2.5\%} also offers promising performance HiEve dataset subevent relation extraction, relatively surpassing previous methods least 3.12\% . %\dr{which table from?} %by 3.12\% 21.4\%. %We provide ablation studies show importance component framework. %This fact illustrated ablation studies. From NLU perspective, %the acquired knowledge method able simultaneously models internal membership structure complex event, well temporal relations among simple complex events. second contribution work lies providing general method inducing event complex comprehensively represents relational structure several related event %\drc{predicate} % mentions. %in two directions. This supported memberships vertically identified multi-granular events, well horizontal temporal reasoning within event complex. As far know, %essentially different %many previous works formulated relations along single axis. Our model demonstrates potent capability inducing event complexes %with promising performance evaluated %based RED dataset .","     %\dr{I think that the current version  is too detailed and does not position the work at all, it just says what is being done. Here is a suggestion:}    Understanding natural language involves recognizing how multiple event mentions structurally and temporally interact with each other.     In this process, one can induce event complexes that organize multi-granular events with temporal order and membership relations interweaving among them.    Due to the lack of jointly labeled data for these relational phenomena and the restriction on the structures they articulate, we propose a joint constrained learning framework for modeling event-event relations.    Specifically, the framework enforces logical constraints within and across multiple temporal and subevent relations     %of events     by converting these constraints into differentiable learning objectives. We show that our joint constrained learning approach effectively compensates for the lack of jointly labeled data, and outperforms SOTA methods on benchmarks for both temporal relation extraction and event hierarchy construction, replacing a commonly used but more expensive global inference process.    We also present a promising case study showing the effectiveness of our approach in inducing event complexes on an external corpus.\footnote{Our code is publicly available at \url{https://cogcomp.seas.upenn.edu/page/publication_view/914}.} %\dr{Doesn't this contradict the statement above regarding the lack of joint data? Do we need to address it somehow}    %\dr{do we need the next clause? really, you show that you don't need it, but it reads like you just don't use it. If you really want to keep it, maybe better to say ""replacing a commonly used, more expensive, global inference process""} even without global inference that is widely used in previous methods.     \iffalse     \drc{Understanding events described in natural language text requires a reader to identify how they interact, structurally and temporally, to form an event complex.      Nevertheless, most of the work in NLP has focused on predicate mentions and not on the event complex they form together.      In this paper we study the induction of larger event units from text -- identifying a set of predicate mentions that together -- via temporal, co-reference, and subevent relations, form event complexes.     The scarcity of jointly labeled data for these relational phenomena presents a significant technical challenge. However, these phenomena interact with each other, thus restricting the structures they articulate. To make this explicit, we propose a joint learning framework that enforces logical constraints among the relations to be identified, by converting these into differentiable learning objectives.      We show that not only does our joint training approach address the lack of jointly labeled data, but it also outperforms SOTA results on both the temporal benchmark data set and the event hierarchy benchmark data set. %We also present a promising case study on RED, a small-scale dataset with fully annotated relations.     }     \fi     \ignore{     We study within-document temporal and hierarchical relations of events using a joint constrained learning framework.      %We first obtain the event representation  via an encoder, and then jointly train a multi-layer perceptron to predict confidence scores for temporal and hierarchical relations before we make structured prediction via integer linear programming .      The framework first incorporates a contextualized encoder to characterize the events in the document, and then predicts the confidence scores for temporal and hierarchical relations among them.     In the training phase, our framework learns to enforce logic consistency among various types of event relations in both categories,     by converting declarative rules into differentiable learning objective functions. %Furthermore, the consistency of final prediction is enforced by global inference .      %The inference phase performs structured prediction based on integer linear programming  to respect the corresponding logic constraints of relations.     %We utilize the benchmark dataset for the extraction task of each category of relations for training and evaluation. %By experimental results, we prove the feasibility of joint constrained learning of different tasks using datasets that have partial annotations for each task, %avoiding the labor for creating another dataset that has full annotation.     The experimental results show that the proposed framework outperforms the state-of-the-art method on the benchmark dataset, MATRES, of event temporal relation extraction task by 2.8\%; and it improves over the model of training jointly without constraints by 5\% F1-score on HiEve dataset, a benchmark for event hierarchy construction.     Therefore, the joint constrained learning effectively bridges the tasks with limited annotated learning resources, and promisingly leverages domain rules to support the precise learning and inference of various event relations.     }"
"Word embeddings capture semantic similarities extensively explored wide spectrum Natural Language Processing applications recent years. Word2Vec , FastText , Glove examples. Even though distributional word embeddings produce high quality representations, representing longer pieces text sentences paragraphs still open research problem. A sentence embedding contextual representation sentence often created transformation word embeddings composition function. There large body work literature propose different approaches represent sentences word embeddings. SkipThought , InferSent , Universal Sentence Encoder well-known examples. % Other proposed methods learning sentence representations include, limited . There growing interest understanding linguistic knowledge encoded deep contextual representation language. For purpose, several probing tasks proposed understand representations capturing . One interesting findings despite existence explicit syntactic annotations, learned deep representations encode syntax extent . Hewitt et. al. provide evidence entire syntax tree embedded implicitly deep model's vector geometry. Kuncoro et. al. show LSTMs trained language modeling objectives capture syntax-sensitive dependencies. Even though deep contextual language models implicitly capture syntactic information sentences, explicit modeling syntactic structure sentences shown improve results different NLP tasks including neural language modeling \cite {shen2017neural, havrylov2019cooperative}, machine comprehension , summarization , text generation , machine translation , authorship attribution , etc. Furthermore, Kuncoro et. al. provide evidence models explicit syntactic information result better performance . Of particular interest, one areas syntactic structure sentences plays important role style-based text classification tasks, including authorship attribution. The syntactic structure sentences captures syntactic patterns sentences adopted specific author reveal author structures sentences document. Inspired observations, initial work demonstrates explicit syntactic information sentences improves performance recurrent neural network classifier domain authorship attribution . We continue work paper investigating structural representation sentences learned explicitly. In words, similar pre-trained word embeddings mainly capture semantics, pre-trained embeddings mainly capture syntactic information words. Such pre-trained word embeddings used conjunction semantics embeddings different domains including authorship attribution. For purpose, propose self-supervised framework using Siamese network explicitly learn structural representation sentences. The Siamese network comprised two identical components; lexical sub-network syntactic sub-network; take sequence words sentence corresponding linearized syntax parse tree inputs, respectively. This model trained based contrastive loss objective pair vectors close embedding space belong identical sentence , far belong two different sentences . As result, word sentence embedded vector representation mainly carries structural information. Due -to- mapping word types structural labels, word representation deduced structural representations. In words, semantically different words mapped similar structural labels ; hence, semantically different words may similar structural representations. These pre-trained structural word representations used complimentary information pre-trained semantic embeddings . We use probing tasks proposed Conneau et al. investigate linguistic features learned training. The results indicate structural embeddings show competitive results compared semantic embeddings, concatenation structural embeddings semantic embeddings achieves improvement. Finally, investigate efficiency learned structural embeddings words domain authorship attribution across four datasets. Our experimental results demonstrate classification improvements structural embeddings concatenated pre-trained word embeddings. The remainder paper organized follows: elaborate proposed self-supervised framework Section . The details datasets experimental configuration provided experimental results reported Section ; We review related work Section . Finally, conclude paper Section .","   Syntactic structure of sentences in a document substantially informs about its authorial writing style. Sentence representation learning has been widely explored in recent years and it has been shown that it improves the generalization of different downstream tasks across many domains. Even though utilizing probing methods in several studies suggests that these learned contextual representations implicitly encode some amount of syntax, explicit syntactic information further improves the performance of deep neural models in the domain of authorship attribution. These observations have motivated us to investigate the explicit representation learning of syntactic structure of sentences.  In this paper, we propose a self-supervised framework for learning structural representations of sentences. The self-supervised network contains two components; a lexical sub-network and a syntactic sub-network which take the sequence of words and their corresponding structural labels as the input, respectively. Due to the $n$-to-$1$ mapping of words to their structural labels, each word will be embedded into a vector representation which mainly carries structural information. We evaluate the learned structural representations of sentences using different probing tasks, and subsequently utilize them in the authorship attribution task. Our experimental results indicate that the structural embeddings significantly improve the classification tasks when concatenated with the existing pre-trained word embeddings."
"Since end twentieth century spread mobile communication technologies Arab world, youth, particular, developed new chat alphabet communicate efficiently informal Arabic. Because media applications initially enable chatting Arabic, Arab speakers resorted commonly known ""Arabizi"". In, Arabizi defined newly-emerged Arabic variant written using Arabic numeral system Roman script characters. With widespread use social media worldwide recent years, Arabizi emerged established Arabic writing system mobile communication social media Arab world. Compared increasing studies sentiment analysis Indo-European languages, similar research Arabic dialects still limited.\ This mainly attributed lack needed good quality Modern Standard Arabic publicly-available sentiment analysis resources general, specifically dialectical Arabic publicly-available resources.\ Building resources involves several difficulties terms data collection annotation, especially underrepresented Arabic dialects Tunisian dialect. Nevertheless, existing Tunisian annotated datasets focused code-switching datasets written using Arabic Romanized Alphabet. The studies datasets applied off-the-shelf models built MSA dataset Tunisian Arabic. An intuitive solution translate Tunisian Romanized Alphabet Arabic Script. This approach suffers need parallel Tunisian-Arabic text corpus, low average precision performances achieved irregularity words written. Using model trained Modern Standard Arabic sentiment analysis data applying model dialectal sentiment analysis data, produce good performances shown in. This suggests MSA models cannot effective applied dialectical Arabic. There is, thus, growing need creation computational resources, MSA also dialectical Arabic. The situation holds one tries use computational resources used specific dialect Arabic another one. To best knowledge, first study sentiment analysis TUNIZI Romanized Alphabet. \ This could deduced next sections present TUNIZI state-of-the-art Tunisian sentiment analysis followed proposed approach, results discussion conclusion future work."," Tunisians on social media tend to express themselves in their local dialect using Latin script . This raises an additional challenge to the process of exploring and recognizing online opinions. To date, very little work has addressed TUNIZI sentiment analysis due to scarce resources for training an automated system. In this paper, we focus on the Tunisian dialect sentiment analysis used on social media. Most of the previous work used machine learning techniques combined with handcrafted features. More recently, Deep Neural Networks were widely used for this task, especially for the English language. In this paper, we explore the importance of various unsupervised word representations  and we investigate the use of Convolutional Neural Networks and Bidirectional Long Short-Term Memory. Without using any kind of handcrafted features, our experimental results on two publicly available datasets showed  comparable performances to other languages.    \keywords{Tunisian Dialect  \and TUNIZI \and Sentiment Analysis \and Deep Learning \and Neural networks \and Natural language analysis.}"
"In recent years, neural networks shown impressive performance gains long-standing AI problems, natural language understanding, speech recognition, computer vision. Based successes, researchers considered application neural nets data management problems, including learning indices, query optimization entity matching. In applying neural nets data management, research far assumed data modeled database schema. The success neural networks processing unstructured data natural language images raises question whether use extended point relax fundamental assumption database management, data process represented fields pre-defined schema. What if, instead, data queries represented short natural language sentences, queries answered sentences? This paper presents first step answering question. We describe \systemname, database system updates queries given natural language. The query processor \ndb\ builds primitives offered state art Natural Language Processing~ techniques. Figure shows example facts queries \ndb\ answer. %\ms{In Figure 1, queries 4&5 really joins, need language understanding/paraphrasing} Realizing vision \systemname\ offer several benefits database systems struggled support decades. The first, important benefit \ndb, definition, pre-defined schema. Therefore, scope database need defined advance data becomes relevant application used stored queried. The second benefit updates queries posed variety natural language forms, convenient user. In contrast, traditional database query needs based database schema. A third benefit comes fact \ndb\ based pre-trained language model already contains lot knowledge. For example, fact London UK already encoded language model. Hence, query asking lives UK retrieve people known live London without explicitly specify additional join. Furthermore, using paradigm, endow \ndb\ domain knowledge extending pre-training corpus domain. By nature, \ndb\ meant provide correctness guarantees traditional database system, i.e., answers returned query satisfy precise binary semantics query language. Hence, \ndb considered alternative traditional databases applications guarantees required. Given benefits, \neuraldatabases\ well suited emerging applications schema data cannot determined advance data stated wide range linguistic patterns. A family applications arise area storing knowledge personal assistants currently available home use future accompany Augmented Reality glasses. In applications, users store data habits experiences, friends preferences, designing schema application impractical. Another class applications modeling querying political claims . Here too, claims huge variety topics expressed many ways. Our first contribution show state art transformer models adapted answer simple natural language queries. Specifically, models process facts relevant query independent specific linguistic form, combine multiple facts yield correct answers, effectively performing join. However, identify two major limitations models: perform well aggregation queries , since input size transformer bounded complexity transformer quadratic size input, work relatively small collection facts. Our second contribution propose architecture neural databases uses power transformers core, puts place several components order address scalability aggregation issues. Our architecture runs multiple instances Neural SPJ operator parallel. The results operator either answer query input aggregation operator, done traditional fashion. Underlying architecture novel algorithm generating small sets database sentences fed Neural SPJ operator. Finally, describe experimental study validates different components \systemname s, namely ability Neural SPJ answer queries create results subsequent aggregation operator even minimal supervision, ability produce support sets fed Neural SPJ operators. Putting components together, final result shows accurately answer queries thousands sentences high accuracy. To run experiments create experimental dataset training data \ndb s, make available future research. % capable generating intermediate results accurately predicting aggregation operation execute intermediate results."," \jt{TODO Before final submission remove page numbers} In recent years, neural networks have shown impressive performance gains on long-standing AI problems, and in particular, answering queries from natural language text. These advances raise the question of whether they can be extended to a point where we can relax the fundamental assumption of database management, namely, that our data is represented as fields of a pre-defined schema.   This paper presents a first step in answering that question.  We describe \ndb, a database system with no pre-defined schema, in which updates and queries are given in natural language. We develop query processing techniques that build on the  primitives offered by the state of the art Natural Language Processing methods.   We begin by demonstrating that at the core, recent NLP transformers, powered by pre-trained language models, can answer select-project-join queries if they are given the exact set of relevant facts. However, they cannot scale to non-trivial databases and cannot perform aggregation queries. Based on these findings, we describe a \ndb\ architecture that runs multiple Neural SPJ operators in parallel, each with a set of database sentences that can produce one of the answers to the query. The result of these operators is fed to an aggregation operator if needed. We describe an algorithm that learns how to create the appropriate sets of facts to be fed into each of the Neural SPJ operators. Importantly, this algorithm can be trained by the Neural SPJ operator itself. We experimentally validate the accuracy of \systemname\ and its components, showing that we can answer queries over thousands of sentences with very high accuracy."
"Automatic medical code assignment routine healthcare task medical information management clinical decision support. The International Classification Diseases coding system, maintained World Health Organization , widely used among various coding systems. Thus, medical code assignment task also called ICD coding. It uses clinical notes discharge summaries predict medical codes supervised manner human-annotated codes, formulated multi-class multi-label text classification problem medical domain. While increasing works community automatic medical code assignment~, task remains challenging perspectives note representation code prediction. First, medical note representation, critical step understanding medical notes, formidably challenging due lengthy complex semantic information discharge documents. There typically thousands tokens medical note due various diagnoses procedures experienced patient. Furthermore, clinical notes also contain vocabulary many professional words phrases, making hard neural network model encode understand critical information. Second, medical coding system high sparse dimensional label space, render code prediction task incredibly difficult. For example, ICD9 ICD10 coding systems many labels, i.e., 14,000 68,000 codes. However, patient typically diagnosed couple codes whole coding space. Early works medical code assignment typically follow statistical approaches. They either employ rule-based methods apply classification methods SVM Bayesian ridge regression assign codes. These methods shallow exploit complex semantic information medical notes, leading unsatisfactory performance. Recently, Natural language processing techniques based deep learning developed , learn note representation via convolutional neural networks. Specifically, CAML, MultiResCNN DCAN treat ICD coding general text classification problem develop complex neural encoders learn note representation. HyperCore proposes hyperbolic embedding capture code hierarchy co-occurrence. However, approaches still ineffective, explicitly capture fine-grained interactions textual elements medical codes. These interactions naturally represent interdependencies complex medical words associated codes, thus well exploited. This paper put forward novel neural architecture, Gated Convolutional Neural Network Note-Code Interaction , effective medical code assignment. Our goal learn rich representation clinical notes exploit interactions medical texts clinical codes. To capture long sequential history clinical documents, design novel dilation information propagation component forgetting mechanism selectively utilize useful information note representation learning. To tackle large labeling space, formulate textual notes medical codes complete bipartite graph develop graph message passing approach capture explicit interaction nodes codes. The ICD code descriptions used external medical knowledge source learn accurate code representations preserve semantic relations codes. Considering practical application real-world medical institutes, especially limited computing resources, architecture also prioritizes computational efficiency designing sub-modules. Our contributions itemized follows."," Medical code assignment from clinical text is a fundamental task in clinical information system management. As medical notes are typically lengthy and the medical coding system's code space is large, this task is a long-standing challenge.  Recent work applies deep neural network models to encode the medical notes and assign medical codes to clinical documents. However, these methods are still ineffective as they do not fully encode and capture the lengthy and rich semantic information of medical notes nor explicitly exploit the interactions between the notes and codes. We propose a novel method, gated convolutional neural networks, and a note-code interaction , for automatic medical code assignment to overcome these challenges. Our methods capture the rich semantic information of the lengthy clinical text for better representation by utilizing embedding injection and gated information propagation in the medical note encoding module. With a novel note-code interaction design and a graph message passing mechanism, we explicitly capture the underlying dependency between notes and codes, enabling effective code prediction. A weight sharing scheme is further designed to decrease the number of trainable parameters. Empirical experiments on real-world clinical datasets show that our proposed model outperforms state-of-the-art models in most cases, and our model size is on par with light-weighted baselines."
"% Enabling chatbots indulge engaging conversations requires massive datasets human-human conversations . Training dialog agents requires substantial time effort expended collection adequate number high quality conversation samples. \citet{hancock2019learning} alleviate problem introducing self-feeding chatbot directly learn user interactions. This chatbot requests users provide natural language feedback users dissatisfied response. \citet{hancock2019learning} treat feedback gold response wrong turn use additional training sample improve chatbot. Although natural language feedback cheap collect chatbot's end-users, often, feedback cannot used directly training sample since feedback usually answer itself, simply contains hints answer. \Cref{tab:response_samples} shows feedback text samples. Naive modification feedback using heuristics like regular expressions would lead generic responses ineffective improving dialog ability chatbots . Additionally, writing exhaustive set regular expression rules time consuming requires extensive analysis data. Annotating data convert feedback text natural response also expensive defeats purpose learning feedback text. \end{table} In work, propose generative adversarial setup converting noisy feedback instances natural, human-like responses provide better training signals dialog agents. \Cref{fig:interface} gives bird's-eye view problem. We frame problem variant text style transfer generator tasked making feedback resemble optimal response user's previous utterance discriminator classifier distinguishes whether given response feedback natural. Our main contributions following: %","  The ubiquitous nature of chatbots and their interaction with users generate an enormous amount of data. Can we improve chatbots using this data? A self-feeding chatbot improves itself by asking natural language feedback when a user is dissatisfied with its response and uses this feedback as an additional training sample. However, user feedback in most cases contains extraneous sequences hindering their usefulness as a training sample. In this work, we propose a generative adversarial model that converts noisy feedback into a plausible natural response in a conversation. The generator's goal is to convert the feedback into a response that answers the user's previous utterance and to fool the discriminator which distinguishes feedback from  natural responses. We show that augmenting original training data with these modified feedback responses improves the original chatbot performance from 69.94\% to 75.96\% in ranking correct responses on the \personachat dataset, a large improvement given that the original model is already trained on 131k samples.\footnote{Our code is released at \url{https://github.com/ekunnii/adversarial-feedback-chatbot/}}"
"Text Generation task producing written spoken narrative structured unstructured data. The overarching goal seamless human-machine communication presenting wealth data way comprehend. With respect modeling approaches, three main paradigms generating text based schema input output: Text-to-Text Data-to-Text None-to-Text. Table presents categorization different tasks based paradigm. These several tasks deserve undivided attention accordingly heavily dissected, studied surveyed recent past. For instance, independent exclusive surveys periodically conducted summarization , knowledge text generation {DBLP:conf/inlg/GardentSNP17, DBLP:conf/naacl/Koncel-Kedziorski19}, machine translation , dialog response generation , storytelling, narrative generation , image captioning etc., dig deeper task specific approaches foundational well bleeding edge research. While extremely necessary, often focus techniques beneficial tightly coupled tasks overlooked. The goal survey focus key components task agnostic improve ensemble tasks neural text generation. %The rest survey organized follows: Section describes modeling approaches text generation including learning paradigms, pre-training decoding strategies. This followed Section describing key challenges solutions text generation fluency, length, content selection, speed etc.,. Section describes evaluation finally Section presents conclusions prospective future directions. } \end{table} %https://www.sciencedirect.com/science/article/pii/S1319157820303360 There several studies conducted surveying text generation. \citet{DBLP:journals/cai/PereraN17} present detailed overview information theory based approaches. \citet{iqbal2020survey} primarily focus core modeling approaches, especially VAEs GANs . \citet{DBLP:journals/jair/GattK18} elaborated tasks captioning, style trasfer etc., primary focus data-to-text tasks. Controllability aspect explored \citet{prabhumoye2020exploring}. The workclosest \citet{DBLP:journals/corr/abs-1803-07133} perform empirical study core modeling approaches only. In contrast these, paper focuses task agnostic components factors capable pushing ensemble tasks forward. Figure presents various components factors important study neural text generation elaborated paper. %Text generation overarching set tasks underlying factors cut across tasks critical pushing field forward paper dedicated one stop destination learn several fundamental factors.","   Neural text generation metamorphosed into several critical natural language applications ranging from text completion to free form narrative generation. Generating natural language has fundamentally been a human attribute and the advent of ubiquitous NLP applications and virtual agents marks the need to impart this skill to machines. There has been a colossal research effort in various frontiers of neural text generation including machine translation, summarization, image captioning, storytelling etc., We believe that this is an excellent juncture to retrospect on the directions of the field. Specifically, this paper surveys the fundamental factors and components relaying task agnostic impacts across various generation tasks such as storytelling, summarization, translation etc., In specific, we present an abstraction of the imperative techniques with respect to learning paradigms, pretraining, modeling approaches, decoding and the key challenges. Thereby, we hope to deliver a one-stop destination for researchers in the field to facilitate a perspective on where to situate their work and how it impacts other closely related tasks. %scope it : current neural techniques %for single and multi-sentence"
The following instructions directed authors papers submitted EACL 2021 accepted publication proceedings. All authors required adhere specifications. Authors required provide Portable Document Format version papers. The proceedings designed printing A4 paper.," This document contains the instructions for preparing a manuscript for the proceedings of EACL 2021. The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like. These instructions should be used for both papers submitted for review and for final versions of accepted papers. Authors are asked to conform to all the directions reported in this document."
"Cross-lingual abstractive summarization task generate summary given document different target language. This task provides overview article foreign language thus helps readers understand text written unfamiliar language quickly. Early work cross-lingual abstractive summarization adopted pipeline approach: either translation given document target language followed summarization translated document summarization given document followed translation summary target language. On hand, recent studies applied neural encoder-decoder model, widely used natural language generation tasks including machine translation monolingual abstractive summarization, generate summary target language given document directly. %Such direct generation approaches prevent error propagation problems pipeline methods. Such direct generation approaches prevent error propagation pipeline methods. Training neural encoder-decoder models requires numerous sentence pairs. In fact, provided 3.8M sentence-summary pairs train neural encoder-decoder model English abstractive summarization, following studies used training data. However, constructing large-scale cross-lingual abstractive summarization dataset much difficult collecting monolingual summarization datasets require sentence-summary pairs different languages. To address issue, recent studies applied machine translation model monolingual sentence-summary pairs. They used constructed pseudo dataset train neural encoder-decoder models. Meanwhile, possibility whether existing genuine parallel corpora translation pairs monolingual abstractive summarization datasets utilized needs explored. In machine translation, indicated using translation pairs multiple languages improved performance neural machine translation model. Similarly, consider existing genuine parallel corpora positive influence cross-lingual abstractive summarization task since task combination machine translation summarization. In study, propose multi-task learning framework, Transum, includes machine translation, monolingual abstractive summarization, cross-lingual abstractive summarization, neural encoder-decoder models. The proposed method controls target task special token inspired Google's multilingual neural machine translation system. For example, attach special token beginning source-side input sentence translation. The proposed Transum quite simple require additional architecture contrast effective cross-lingual abstractive summarization. Experimental results show Transum improves performance cross-lingual abstractive summarization outperforms previous methods Chinese-English Arabic-English summarization. In addition, Transum significantly improves machine translation performance compared obtained using genuine parallel corpus machine translation. Furthermore, construct new test set simulate realistic situations: cross-lingual summarization several length constraints. In summarization process, important generate summary desired length. However, existing test sets cross-lingual abstractive summarization cannot evaluate whether model controls output lengths test sets contain summaries multiple lengths. Thus, translate existing monolingual abstractive summarization contains summaries multiple lengths construct new test set. The contributions study follows:"," We present a multi-task learning framework for cross-lingual abstractive summarization to augment training data. Recent studies constructed pseudo cross-lingual abstractive summarization data to train their neural encoder-decoders. Meanwhile, we introduce existing genuine data such as translation pairs and monolingual abstractive summarization data into training. Our proposed method, Transum, attaches a special token to the beginning of the input sentence to indicate the target task. The special token enables us to incorporate the genuine data into the training data easily. The experimental results show that Transum achieves better performance than the model trained with only pseudo cross-lingual summarization data. In addition, we achieve the top ROUGE score on Chinese-English and Arabic-English abstractive summarization. Moreover, Transum also has a positive effect on machine translation. Experimental results indicate that Transum improves the performance from the strong baseline, Transformer, in Chinese-English, Arabic-English, and English-Japanese translation datasets."
"Table-to-text generation important task text generation structured data. It aims automatically producing descriptive natural language text covers salient information table help people get salient information tables. Practical applications found domains weather forecasts, biography generation, NBA news generation, etc. Over pass several years, neural text generation methods made significant progress task. \citeauthor{lebret-etal-2016-neural,wiseman-etal-2017-challenges,bao2018table} model machine translation task view input table record sequence. To generate text contains salient well-organized facts, \citeauthor{sha2018order,puduppully-etal-2019-data,moryossef-etal-2019-step,trisedya2020sentence,ijcai2020-522} explicitly model content selection planning. %Some works also introduce extra knowledge pre-executed symbolic operations table improve result. To learning better representation tables, \citeauthor{liu2018table,bao2018table,nema-etal-2018-generating,jain-etal-2018-mixed,gong-etal-2019-table} explicitly model structure table multiple levels different dimensions. In addition, \citeauthor{liu2019hierarchical} propose three auxiliary supervision tasks capture accurate semantic representation table. However, issues overlooked. First, many tables ) contain large number numerical records. For instance, records almost column types numeric ROTOWIR , benchmark NBA basketball games. Current methods treat records words natural language text ignore characteristics number play important role table representation, size attribute. In addition, noises human-written summaries dataset. These noises include redundant information records exist input tables ). These noises may cause incorrect alignments input tables target text wrong supervision signals. And affect performance models based content selection planning auxiliary supervision. %In addition, human writing summary describe given table, may consider salient records. For example, describing table Figure , may pay attention K. Leonard, top scorer. To solve problems, explore use information contained tables introduce two self-supervised tasks learn better representation tables. We argue better representation tables help model capture organize important facts, even without explicitly modeling content selection planning. Specially, improve ~\citeauthor{gong-etal-2019-table}'s method employ hierarchical table encoder model table structure record level row level. The record-level encoder utilizes two cascaded self-attention models encode table column row dimension, respectively. And then, introduce row-level fusion gate obtain row-level representation row. To learn number-aware record representation, introduce Number Ordering task. This task utilizes pointer network generate descending record sequence column table, according content. Figure shows number ordering example column PTS. To best knowledge, first work neural table-to-text generation via focusing learning representation number table. Another self-supervised task, Significance Ordering , proposed learn significance-aware representation record. The significance denotes relative relation records row. This inspired intuition humans describe performance player, tend focus salient records. For example, Figure , K. Thompson's scores likely described other's records. The SO task executes descending sort operation row according significance scores records. We use position index record measure importance smaller significance score, important record is. The position index record obtained results Number Ordering. For example, Figure , K. Thompson scores points largest PTS, significance score record 1. The proposed two tasks trained together table2text generation model share encoder parameters. Obviously, two proposed tasks self-supervised training labels easily obtained input tables. Therefore, errors caused noises training set avoided. %For record row, includes another size information:significance. It denotes relative relation records row. To learn significance-aware representation table, propose Significance Ordering task executes ascending sort operation row according significance records. We use position index record measure importance smaller significance score, important record is. The position index record obtained results Number Ordering. For example, Figure , K. Leonard score 45 points largest PTS, significance score record 1). Obviously, two proposed tasks self-supervised training labels easily obtained input tables. Therefore, errors caused noise training set avoided. We conducted experiments ROTOWIRE verify effectiveness proposed approach. The experimental results demonstrate that, even without explicitly modeling content selection introducing extra knowledge, method help generate text contains salient well-organized facts. And achieve state-of-the-art performance automatic metrics. %Content Selection , Content Ordering BLEU."," Table-to-text generation aims at automatically generating natural text to help people to conveniently obtain the important information in tables. Although neural models for table-to-text have achieved remarkable progress, some problems still overlooked. The first is that the values recorded in many tables are mostly numbers in practice. The existing approaches do not do special treatment for these, and still regard these as words in natural language text.  Secondly, the target texts in training dataset may contain redundant information or facts do not exist in the input tables. These may give wrong supervision signals to some methods based on content selection and planning and auxiliary supervision. To solve these problems, we propose two self-supervised tasks, Number Ordering and Significance Ordering,  to help to learn better table representation. The former works on the column dimension to help to incorporate the size property of numbers into table representation. The latter acts on row dimension and help to learn a significance-aware table representation. We test our methods on the widely used dataset ROTOWIRE which consists of NBA game statistic and related news. The experimental results demonstrate that the model trained together with these two self-supervised tasks can generate text that contains more salient and well-organized facts, even without modeling context selection and planning. And we achieve the state-of-the-art performance on automatic metrics. % Content Selection , Content Ordering  and BLEU."
"/} Automatic keyphrase generation task generating single multi-word lexical units provides readers high level information key ideas important topics described given source text. Apart information summarization perspective, task applications various downstream natural language processing tasks text classification , document clustering information retrieval . Traditionally, keyphrases extracted source documents retrieving ranking set candidate phrases rule based approaches. With recent advances neural natural language generation availability larger training corpora, problem formulated sequence-to-sequence modelling framework . This approach advantage generate new meaningful keyphrases may absent source text. The earliest work direction , train S2S model generate one keyphrase time. At inference time, decode beam sizes high 200, generate large number KPs finally de-duplicate outputs. However, computationally expensive wasteful KPs found unique . An alternative approach train S2S model generate multiple keyphrases sequential manner, output KPs separated pre-defined delimiter token. This method added benefit model automatically learns generate variable number keyphrases depending input, instead user-specified fixed number keyphrases large list candidate outputs. However, previous approaches still use exhaustive beam search decoding over-generate KPs apply post-processing remove repetitions. Apart additional computational requirements, argue method avoiding information redundancy last-minute solution. % `hacky' solution. % \todoi{Importance diversity} In paper, take principled direction towards addressing information redundancy issue keyphrase generation models. We propose tackle problem directly training stage, rather applying adhoc post-processing inference time. Specifically, adopt neural unlikelihood training objective , whereby decoder penalized generating undesirable tokens. % , case corresponds set repeating tokens. introduce unlikelihood training language model setting. Since work S2S setup, version UL loss consists two components: target token level UL loss based target vocabulary penalize model generating repeating tokens; copy token level UL loss based dynamic vocabulary source tokens required copy mechanism , penalizes model copying repetitive tokens. S2S models trained maximum likelihood estimation usually tasked next token prediction objective. However, necessarily incentivize model plan future token prediction ahead time. We observe lack model planning capability initial experiments MLE models overcome issue propose use -step ahead token prediction. This modified training objective encourages model learn correctly predict current token, also tokens upto -steps ahead future. We naturally incorporate UL training -step ahead token prediction task. We summarize contributions follows: To improve diversity generated keyphrases principled manner training, adopt unlikelihood objective S2S setting propose novel copy token unlikelihood loss. In order incentivize model planning, augment training objective function incorporate -step ahead token prediction. Additionally, also introduce -step ahead unlikelihood losses. We propose new metrics benchmarking keyphrase generation models diversity criterion. We carry experiments datasets three different domains validate effectiveness approach. We observe substantial gains diversity maintaining competitive output quality. }.} \end{table}"," In this paper, we study sequence-to-sequence  keyphrase generation models from the perspective of diversity. Recent advances in neural natural language generation have made possible remarkable progress on the task of keyphrase generation, demonstrated through improvements on quality metrics such as $F_1$-score. However, the importance of diversity in keyphrase generation has been largely ignored. We first analyze the extent of information redundancy present in the outputs generated by a baseline model trained using maximum likelihood estimation . Our findings show that repetition of keyphrases is a major issue with MLE training. To alleviate this issue, we adopt neural unlikelihood  objective for training the S2S model. Our version of UL training operates at  the target token level to discourage the generation of repeating tokens;  the copy token level to avoid copying repetitive tokens from the source text. Further, to encourage better model planning during the decoding process, we incorporate $K$-step ahead token prediction objective that computes both MLE and UL losses on future tokens as well. Through extensive experiments on datasets from three different domains we demonstrate that the proposed approach attains considerably large diversity gains, while maintaining competitive output quality.\footnote{Code is available at \url{https://github.com/BorealisAI/keyphrase-generation}}"
"In healthcare, real-world data refers patient data routinely collected clinic visits, hospitalization, well patient-reported results. In recent years, RWD's volume become enormous, invaluable insights real-world evidence generated datasets using latest data processing analytical techniques. However, RWD's quality remains one main challenges prevent novel machine learning methods readily adopted healthcare. Therefore, creating data quality tools great importance health care health data sciences. Erroneous data healthcare systems could jeopardize patient's clinical outcomes affect care provider's ability optimize performance. Common data quality issues include missing critical information medical history, wrong coding condition, inconsistency documentation across different care sites. Manual review domain experts gold standard achieving highest data quality unattainable regular care practices. Recent developments field Natural Language Processing attracted great interest healthcare community since algorithms identifying variables interest classification algorithm diseases recently developed . In paper, presented novel model extraction queries corpus dialogue data entry clinicians expert reviewers multi-site dialysis environment. %The work's ultimate goal identify data elements caused uncertainty errors documentation process. The main contributions work are: Finally, addition evaluating model's performance medical context, also experimented section general-domain dataset show model's generalizability. The rest paper organized follows. Related work presented section . The different question detection methods examined, described section . Section details characteristics proposed multi-channel CNN model. Finally, results experiments reported section conclusion plan future work given section ."," In most clinical practice settings, there is no rigorous reviewing of the clinical documentation, resulting in inaccurate information captured in the patient medical records. The gold standard in clinical data capturing is achieved via ``expert-review"", where clinicians can have a dialogue with a domain expert  and ask them questions about data entry rules. Automatically identifying ``real questions"" in these dialogues could uncover ambiguities or common problems in data capturing in a given clinical setting.  In this study, we proposed a novel multi-channel deep convolutional neural network architecture, namely Quest-CNN, for the purpose of separating real questions that expect  an answer  about an issue from sentences that are not questions, as well as from questions referring to an issue mentioned in a nearby sentence , which we will refer as ``c-questions"". We conducted a comprehensive performance comparison analysis of the proposed multi-channel deep convolutional neural network against other deep  neural networks. Furthermore, we evaluated the performance of traditional rule-based and learning-based methods for detecting question sentences. The proposed Quest-CNN achieved the best F1 score both on a dataset of data entry-review dialogue in a dialysis care setting, and on a general domain dataset."
"Semantic parsing task mapping natural language query formal language, extensively used goal-oriented dialogue systems. For given query, model identify requested action associated values specifying parameters action . For example, query Call Mary action call value slot contact Mary. The number different intents slots publicly available datasets close hundred may orders magnitude larger real-world systems. Such big number classes usually causes long tail class frequency distribution . These tail classes significantly improved small quantities additional labeled data. However, training neural semantic parsing model scratch take hours even relatively small public dataset . The real-world datasets contain millions examples change time scale weeks. % Need describe problem motivation production settings more. In work, propose fine-tune model already trained old dataset instead training new model significantly speed incorporation new portion data. We call setting Incremental training, new portions data added incrementally. We focus semantic parsing % seq2seq networks case studies following reasons. Semantic parsing complex NLP task compared classification NER hope lessons learned would widely applicable. Task-oriented semantic parsing tend large output vocabulary frequently updated, thus, benefit Incremental setting. % We choose seq2seq networks work due two reasons: first, seq2seq networks % general easily adapted simpler tasks like NER; % second, seq2seq models perform really well popular natural language understanding datasets like TOP SNIPS. % Exploring space possible solutions, compare effectiveness approaches come set guidelines useful incremental training tasks well. % To emulate ""data-patch"" scenario, split datasets focusing classes. We show naive fine-tuning leads catastrophic forgetting come approaches remedy this. We observe possible fine-tune models new classes minutes compared hours retraining scratch. We also compare effect pre-trained representations like BERT fine-tuning. Using observations come fine-tuning guidelines scenarios label space change. We verify approaches work 2 popular semantic parsing datasets: TOP SNIPS different data splits. The main contributions work are: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Related work %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"," A semantic parsing model is crucial to natural language processing applications such as goal-oriented dialogue systems. Such models can have hundreds of classes with a highly non-uniform distribution. In this work, we show how to efficiently  improve model performance given a new portion of labeled data for a specific low-resource class or a set of classes. We demonstrate that a simple approach with a specific fine-tuning procedure for the old model can reduce the computational costs by ~90\% compared to the training of a new model. The resulting performance is on-par with a model trained from scratch on a full dataset. We showcase the efficacy of our approach on two popular semantic parsing datasets, Facebook TOP, and SNIPS."
"Recent progress abstractive summarization fueled advent large-scale Transformers pre-trained autoregressive language modeling objectives . Despite strong performance automatic metrics like ROUGE , abstractive models straightforward interpretable extractive counterparts. Free-form generation models also leads serious downstream errors, factual inconsistencies input document . Although interpretability NLU models extensively studied , summarization models specifically received similar attention, analysis efforts often focused datasets evaluation . %Generic explanation methods language models neural machine translation models entirely applicable, summarization models typically different interactions input document. In work, focus interpreting understanding abstractive summarization models lens decoder uncertainty, entropy decisions generation. While uncertainty generation studied perspective data , sampling , training , underutilized technique analysis inspection generation systems. We study two prominent summarization models, PEGASUS BART , fine-tuned two English summarization datasets, CNN/Daily Mail XSum , understand model behavior setting. %We analyze model using blackbox whitebox perspectives. First, comparing -grams input document generated summaries, establish two coarse types decoded tokens, copy generate . We find entropy generation decision correlates whether model copying generating, well sentence token is. This paints picture certain contexts restrictive standpoint generation, particularly early sentences model ``decided'' copy yet, illustrates interaction content selection lexical choice. %Furthermore, illustrates interaction content selection lexical choice: new bigrams higher entropy, beginnings sentences also high entropy, indicating model uncertainty sentence discuss, even going copy. Second, extend analysis looking uncertainty relates syntax generated sentence: whether uncertainty connects syntactic notions surprisal entropy varies across certain syntactic productions. % Finally, derive way quantify decoder attention aggregating self-attention heads, investigating correspondence prediction entropy fraction decoded tokens aggregated attention.\todo{change sent refer entropy more} Finally, derive way quantify decoder attention aggregating distinct self-attention heads, revealing correlation attention entropy prediction entropy, investigating correspondence prediction entropy fraction past future decoded tokens. % highly attentive positions decoded not-yet-decoded tokens respect specific Transformer layers decoder. Taking analysis together, find abstractiveness reference summaries fundamentally changes model behavior: extractive nature CNN/DM makes decisions low entropy copy-oriented model maintains higher uncertainty XSum, yielding abstractive summaries. More broadly, show uncertainty simple effective tool characterize decoder behavior text generation. % By analyzing decoder self-attention layers, find attention focuses tokens, prediction entropy fairly low focused tokens likely predicted."," % An advantage of seq2seq abstractive summarization models is that they generate text in a free-form manner, but this inherent flexibility makes it difficult to interpret and understand model behavior. In this work, we adopt a data-driven methodology to unpack decoder behavior in both a blackbox and whitebox way. We fine-tune and analyze a GPT-2 \cite{radford-2019-gpt2} model on two benchmark datasets featuring different levels of abstraction. Our experiments yield three key results. First, by analyzing the entropy of model predictions and its corresponding test-time behavior, we find a strong correlation between low entropy and where the model copies document spans rather than generating novel text. Second, this entropy analysis can allow us to understand what sentence positions and even what syntactic configurations are associated with copying existing content. Finally, by analyzing decoder self-attention patterns, we can trace this copying behavior to a particular pattern of attending to immediate decoder context and finding the next token to generate in the source document. An advantage of seq2seq abstractive summarization models is that they generate text in a free-form manner, but this flexibility makes it difficult to interpret model behavior.  In this work, we analyze summarization decoders in both blackbox and whitebox ways by studying on the entropy, or uncertainty, of the model's token-level predictions. For two strong pre-trained models, PEGASUS \cite{pegasus} and BART \cite{lewis-2019-bart} on two summarization datasets, we find a strong correlation between low prediction entropy and where the model copies tokens rather than generating novel text. The decoder's uncertainty also connects to factors like sentence position and syntactic distance between adjacent pairs of tokens, giving a sense of what factors make a context particularly selective for the model's next output token. Finally, we study the relationship of decoder uncertainty and attention behavior to understand how attention gives rise to these observed effects in the model. We show that uncertainty is a useful perspective for analyzing summarization and text generation models more broadly.\footnote{Code is available at \url{https://github.com/jiacheng-xu/text-sum-uncertainty}} % can trace this copying behavior to a particular pattern of attending to immediate decoder context and finding the next token to generate in the source document."
"Neural attention mechanisms widely applied computer vision shown enable neural networks focus aspects input important given task. While neural networks able learn meaningful attention mechanisms using supervision received target task, addition human gaze information shown beneficial many cases. An especially interesting way leveraging gaze information demonstrated works incorporating human gaze neural attention mechanisms, example image video captioning visual question answering. While attention least important reading text viewing images, integration human gaze neural attention mechanisms natural language processing tasks remains under-explored. A major obstacle studying integration data scarcity: Existing corpora human gaze reading consist samples provide effective supervision modern data-intensive architectures human gaze data available small number NLP tasks. For paraphrase generation sentence compression, play important role tasks reading comprehension systems, human gaze data available. We address data scarcity two novel ways: First, overcome low number human gaze samples reading, propose novel hybrid text saliency model combine cognitive model reading behavior human gaze supervision single machine learning framework. More specifically, use E-Z Reader model attention allocation reading obtain large number synthetic training examples. We use examples pre-train BiLSTM network Transformer whose weights subsequently refine training small amount human gaze data. We demonstrate model yields predictions well-correlated human gaze out-of-domain data. Second, propose novel joint modeling approach attention comprehension allows human gaze predictions flexibly adapted different NLP tasks integrating TSM predictions attention layer. By jointly training TSM task-specific network, saliency predictions adapted upstream task without need explicit supervision using real gaze data. Using approach, outperform state art paraphrase generation Quora Question Pairs corpus 10\% BLEU-4 achieve state art performance Google Sentence Compression corpus. As such, work demonstrates significant potential combining cognitive data-driven models establishes general principle flexible gaze integration NLP potential also benefit tasks beyond paraphrase generation sentence compression."," A lack of corpora has so far limited advances in integrating human gaze data as a supervisory signal in neural attention mechanisms for natural language processing . We propose a novel hybrid text saliency model  that, for the first time, combines a cognitive model of reading with explicit human gaze supervision in a single machine learning framework. On four different corpora we demonstrate that our hybrid TSM duration predictions are highly correlated with human gaze ground truth. We further propose a novel joint modeling approach to integrate TSM predictions into the attention layer of a network designed for a specific upstream NLP task without the need for any task-specific human gaze data. We demonstrate that our joint model outperforms the state of the art in paraphrase generation on the Quora Question Pairs corpus by more than 10\% in BLEU-4 and achieves state of the art performance for sentence compression on the challenging Google Sentence Compression corpus. As such, our work introduces a practical approach for bridging between data-driven and cognitive models and demonstrates a new way to integrate human gaze-guided neural attention into NLP tasks."
"%\hh{check fuzziness: pre-trained pretrained decide one use .} Modern techniques text summarization generally categorized either extractive methods, identify suitable %\pfliu{How ``which identify suitable semantic units ''} words sentences input document concatenate form summary, abstractive methods, generate summaries freely able produce novel words sentences. Compared extractive algorithms, abstractive algorithms flexible, making likely produce fluent coherent summaries. %\pfliu{better adding references here} %and generation process human-like \gn{Re ``more human-like''. First, I'm sure actually true: humans copy-paste text well. Second, seem really important here. Maybe could expand ``more flexible'' part mention practical advantages this.}. However, unconstrained nature abstractive summarization also result problems. First, result unfaithful summaries, containing factual errors well hallucinated content. Second, difficult control content summaries; hard pick advance aspects original content abstractive system may touch upon. %\pfliu{I'm thinking suitable place following paragraph . Will better exchange ``There ...'' paragraph make corresponding modification.} To address issues, propose methods guided neural abstractive summarization: methods provide various types guidance signals 1) constrain summary output content deviate less source document; 2) allow controllability provision user-specified inputs. % Table generated Excel2LaTeX sheet 'Sheet1' \iffalse % % \end{table*}% \fi \iffalse % '' ``{cover.}'' represent copy coverage mechanism respectively. Guidance represents different guided information Guiding Method denotes introduce guided information. ``ourGuidance'' contains sentences, relations keywords retrieved summaries. ``Marker Embedding'' suggests guided information introduced embedding feature vector.}% \gn{add completeness. Make sure chronological order. I think BART needs included, might also include methods provide guidance on, example, style output .}} %\zj{Is particular reason make ``copy'' ``cover.'' italic?}.} % \end{table*}% \fi % %'' ``{cover.}'' represent copy coverage mechanism respectively. Guidance represents different guided information Guiding Method denotes introduce guided information. ``ourGuidance'' contains sentences, relations keywords retrieved summaries. ``Marker Embedding'' suggests guided information introduced embedding feature vector.}% \gn{add completeness. Make sure chronological order. I think BART needs included, might also include methods provide guidance on, example, style output .}} %\zj{Is particular reason make ``copy'' ``cover.'' italic?}.} % \end{table*}% %\gn{The term ``hybrid summarization models'' sudden, follow clearly last sentence previous paragraph. I think point paragraph ``we first propose guided neural summarization models, previous methods limited particular type guidance''. If so, say ``we first'' part beginning paragraph, ``limited'' part final part paragraph.} There previous methods guiding neural abstractive summarization models. For example,~\citet{kikuchi-etal-2016-controlling} specify length abstractive summaries,~\citet{li2018guiding} provide models keywords prevent model missing key information, ~\citet{cao2018retrieve} propose models retrieve reference relevant summaries training set. %, and~\citet{gehrmann2018bottom} propose train model identify salient words encourage final model faithfully copy source. While methods demonstrated improvements summarization quality controllability, focuses one particular type guidance -- remains unclear better whether complementary other. %In addition, previous work whether compatible pre-trained language models BERT. %Previously, order address issues abstractive summarization models, researchers proposed hybrid summarization models combine merits extractive abstractive methods. %\gn{In following three sentences, explicitly stated clear methods address issues abstractive summarization models.} %For example,~\citet{gu2016incorporating} propose methods copy words source document.~\citet{gehrmann2018bottom} utilize bottom-up attention constrain decoder attend salient parts inputs. %Similarly, %While approaches achieve good performance terms ROUGE, cannot guarantee models learn identify salient segments correctly control summaries due lack explicit supervision signals %\gn{can model guarantee this? putting downside seems something apply model.} \zd{I think model try learn identify salient part. Instead, explicitly provide salient part model model learns rely input.} \gn{But extractive summarization model may fail test time, right?} \zd{right, think that's problem extractive summarization, goal model learn depend input, matter whether input signal correct not. } \gn{See comment below. I think there's problem disconnect presenting method , we're actually experiments. It'd best write story way encompasses things experiments . Could think way reframe intro little bit direction? I think one thing definitely say method use wide variety different types guidance, including automatic up-stream systems, perhaps user-specified keywords etc. You using method encourage model pay close attention guidance . This empirically effective. I'll take look thought bit modified intro accordingly. Additionally, might want add sentence end first paragraph describing attempt achieve paper jumping previous work. This help make contrasts clear paragraph.} \zd{Thanks lot! I'll think change paper accordingly!}. %To improve controllability summarization models, previous works attempted provide models keywords length information, choices guidance limited thus controllability output summaries hindered \gn{Again, super-clear proposed method better aspects}. %\gn{I think OK, could really benefit figure top-right page 1 demonstrating behavior.} %To obtain abstractive summarization models good performance well flexible controllability, In paper, propose general extensible guided summarization framework take different kinds external guidance input. %\gn{Maybe one sentence framework works.} Like recent summarization models, model based neural encoder-decoders, instantiated contextualized pretrained language models, including BERT BART. With strong starting point, make modifications allowing model attend source documents guidance signals generating outputs. %\gn{A little concreteness could help, even saying ``attends sequences representing source document guidance signal''.} %\gn{I would put next two sentences method description above, discuss specific types guidance provide.} As shown Figure, provide automatically extracted user-specified guidance model test time constrain model output. At training time, encourage model pay close attention guidance, %\pfliu{Since oracle-based training method contribution work, would better express explicitly. For example: ``we propose use ...instead ..''} propose use oracle select informative guidance signals -- simple modification nonetheless proved essential effective learning guided summarization models. %\gn{How different ? This sentence seems say thing second-to-last sentence previous paragraph. I understand ``extensible'' may attempting make contrast, clear.}. Using framework, investigate four types guidance signals: highlighted sentences source document, keywords, salient relational triples form , retrieved summaries. %\zj{Just minor point. Maybe better make orders consistent experiment section .} We evaluate methods 6 popular summarization benchmarks. Our best model, using highlighted sentences guidance, achieve state-of-the-art performance 4 6 datasets, including 1.28/0.79/1.13 ROUGE-1/2/L improvements previous state-of-the-art model widely-used CNN/DM dataset. In addition, perform in-depth analyses different guidance signals demonstrate complementary aggregate outputs together obtain improvements. An analysis results also reveals guided models generate faithful summaries novel words. Finally, demonstrate control output providing user-specified guidance signals, different provided signals resulting qualitatively different summaries. %\pfliu{Do need highlight contributions?} %We first evaluate methods widely-used CNN/DailyMail benchmark perform in-depth analysis different guidance signals. Experimental results demonstrate best method achieve 1.13 ROUGE-L improvements state-of-the-art model. We pick best guidance signal evaluate models five popular summarization benchmarks. Extensive experiments demonstrate effectiveness model extractive datasets analyses reveal methods generate novel words faithful summaries. In addition, control output providing user-specified guidance signals."," Neural abstractive summarization models are flexible and can produce coherent summaries, but they are sometimes unfaithful and can be difficult to control. While previous studies attempt to provide different types of guidance to control the output and increase faithfulness, it is not clear how these strategies compare and contrast to each other. In this paper, we propose a  general and extensible guided summarization framework  that can effectively take different kinds of external guidance as input, and we perform experiments across several different varieties. Experiments demonstrate that this model is effective, achieving state-of-the-art performance according to ROUGE on 4 popular summarization datasets when using highlighted sentences as guidance. In addition, we show that our guided model can generate more faithful summaries and demonstrate how different types of guidance generate qualitatively different summaries, lending a degree of controllability to the learned models.\footnote{Code is available at \url{https://github.com/neulab/guided_summarization}.}%, generating more novel words, and generating more faithful summaries on 4 popular summarization datasets \gn{``when using XXX as guidance''}. In addition, we demonstrate how different types of guidance generate qualitatively different summaries, lending a degree of controllability to the learned models."
"In recent years, abstractive summarization made impressive progress development sequence-to-sequence framework . This framework composed encoder decoder. The encoder processes source text extracts necessary information decoder, predicts word summary. Thanks generative nature, abstractive summaries include novel expressions never seen source text, time, abstractive summaries difficult produce compared extractive summaries formed directly selecting subset source text. It also found seq2seq-based abstractive methods usually struggle generate out-of-vocabulary words rare words, even words found source text. Copy mechanism alleviate problem meanwhile maintain expressive power seq2seq framework. The idea allow decoder generate summary scratch also copy words source text. Though effective English text summarization, copy mechanism remains relatively undeveloped summarization East Asian languages e.g. Chinese. Generally speaking, abstractive methods Chinese text summarization comes two varieties, word-based character-based. Since explicit delimiter Chinese sentence indicate word boundary, first step word-based methods perform word segmentation . Actually, order avoid segmentation error reduce size vocabulary, existing methods character-based . When trying combine character-based methods Chinese copy mechanism, original ``word copy'' degrades ``character copy'' guarantee multi-character word copied verbatim source text . Unfortunately, copying multi-character words quite common Chinese summarization tasks. Take Large Scale Chinese Social Media Text Summarization Dataset example, according Table I, 37\% words summaries copied source texts consist multiple characters. } \end{center} \end{table} Selective read proposed handle problem. It calculates weighted sum encoder states corresponding last generated character adds result input next decoding step. Selective read provide location information source text decoder help perform consecutive copy. A disadvantage approach, however, increases reliance present computation partial results current step makes model vulnerable errors accumulation leads exposure bias inference. Another way make copied content consecutive directly copying text spans. Zhou et al. implement span copy operation equipping decoder module predicts start end positions span. Because longer span decomposed shorter ones, actually many different paths generate summary inference, model optimized longest common span time step training, exacerbates discrepancy two phases. In work, propose novel lexicon-constrained copying network . The decoder LCN copy either single character text span time, constrain text span match potential multi-character word. Specifically, given text several off-the-shell word segmentators, text span included segmentation result text, consider potential word. By so, number available spans significantly reduced, making viable marginalize possible paths training. Furthermore, inference, aggregate partial paths fly producing output using word-enhanced beam search algorithm, encourages model copy multi-character words facilitates parallel computation. To line aforementioned decoder, encoder revised learn representations characters also multi-character words. In context neural machine translation, Su et al. first organized characters multi-character words directed graph named word-lattice. Following Xiao et al. , adopt encoder based Transformer take word-lattice input allow character word hidden representation. By taking account relative positional information calculating self-attention, encoder capture global local dependencies among tokens, providing informative representation source text decoder make copy decisions. Although model character-based , directly utilize word-level prior knowledge, keywords. In setting, keywords refer words source text high probability inclusion summary. Inspired Gehrmann et al. , adopt separate word selector based large pre-trained language model, e.g. BERT extract keywords. When decoder intends copy words source text, selected keywords treated candidates, words masked out. Experimental results show model achieve better performance incorporating word selector."," Copy mechanism allows sequence-to-sequence models to choose words from the input and put them directly into the output, which is finding increasing use in abstractive summarization. However, since there is no explicit delimiter in Chinese sentences, most existing models for Chinese abstractive summarization can only perform character copy, resulting in inefficient. To solve this problem, we propose a lexicon-constrained copying network that models multi-granularity in both encoder and decoder. On the source side, words and characters are aggregated into the same input memory using a Transformer-based encoder. On the target side, the decoder can copy either a character or a multi-character word at each time step, and the decoding process is guided by a word-enhanced search algorithm which facilitates the parallel computation and encourages the model to copy more words. Moreover, we adopt a word selector to integrate keyword information. Experiments results on a Chinese social media dataset show that our model can work standalone or with the word selector. Both forms can outperform previous character-based models and achieve competitive performances."
"Humans supervised natural language inference . Supervision necessary applications human-defined domains. For example, humans need supervision noun POS tagging, tiger Wordnet classify image tiger ImageNet. However, NLI, people able entail \textcircled{a} A man plays piano contradicts \textcircled{b} A man plays clarinet family without supervision NLI labels. In paper, define inference general process establishing associations inferences texts, rather strictly classifying whether two sentences entail contradict other. Inspired this, raise core problem paper: Given pair natural language sentences, machines entail relationship without supervision inference labels? In highly acclaimed paper, neuroscientist Moshe Bar claims ``predictions rely existing scripts memory, result real well previously imagined experiences''. The exemplar theory argues humans use {\bf similarity} recognize different objects make decisions. Analogy helps humans understand novel object linking similar representation existing memory. Such linking facilitated object context. Context information widely applied self-supervision learning . Adapting context NLI even straightforward. A simple idea {\bf constant conjunction} A causes B constantly conjoined. Although constant conjunction contradicts ``correlation causation'', modern neuroscience confirmed humans use reasoning mental world. For example, found increase synaptic efficacy arises presynaptic cell's repeated persistent stimulation postsynaptic cell Hebbian theory. As natural language, object context naturally used determine inference. For example, \textcircled{a} contradicts \textcircled{b} cannot happen simultaneously {\bf context}. The context representation learned SSL already achieved big success NLP. From perspective context, models learn sentence level contextual information word level contextual information . Besides linguistic contexts, humans also link modalities novel inputs. Even goal reason plain texts, modalities still help . For example, textual information used, difficult entail contradiction \textcircled{a} \textcircled{b}. We need commonsense man two arms, cannot play piano clarinet simultaneously. This commonsense hard obtain text. However, link sentences visual scenes, contradiction much clearer two scenes cannot happen visual context. We think necessary incorporate modalities unsupervised natural language inference. The idea adapting multimodal SSL new. According to, briefly divide previous multimodal SSL approaches two categories based encoder infrastructures. As shown Fig., first category uses one joint encoder represent multimodal inputs. Obviously, downstream task plain text, cannot extract representation text separately joint encoder. So first category infeasible natural language inference. The second category first encodes text image separately two encoders. Then represents multimodal information via joint encoder lower layer encoders. This shown Fig.. Although textual representation extracted text encoder lower layer, representation go joint learning module contains little visual knowledge. In summary, encoders previous multimodal SSL approaches coupled. If textual inputs given, cannot effectively incorporate visual knowledge representations. Thus help entailing contradiction \textcircled{a} \textcircled{b} limited. In order benefit multimodal data plain text inference, propose \underline{M}ultimodal \underline{A}ligned \underline{C}ontrastive \underline{D}ecoupled learning network. This shown Fig.. Its text encoder decoupled, takes plain text inputs. Thus directly adapted downstream NLI tasks. Besides, use multimodal contrastive loss text encoder image encoder, thereby forcing text representation align corresponding image. Therefore even text encoder MACD takes plain text input, still represents visual knowledge. In downstream plain text inference tasks, without taking images input, text encoder MACD still implicitly incorporating visual knowledge learned multimodal contrastive loss. Note need decoupled image encoder SSL. So image encoder Fig. MACD takes texts inputs provides precise image encoder. We elaborate section.","   We propose to solve the natural language inference problem without any supervision from the inference labels via task-agnostic multimodal pretraining. Although recent studies of multimodal self-supervised learning also represent the linguistic and visual context, their encoders for different modalities are coupled. Thus they cannot incorporate visual information when encoding plain text alone. In this paper, we propose \underline{M}ultimodal \underline{A}ligned \underline{C}ontrastive \underline{D}ecoupled learning  network. MACD forces the decoupled text encoder to represent the visual information via contrastive learning. Therefore, it embeds visual knowledge even for plain text inference. We conducted comprehensive experiments over plain text inference datasets . The unsupervised MACD even outperforms the fully-supervised BiLSTM and BiLSTM+ELMO on STS-B."
"%閺鍙ラ嚋閸ユ拝绱濋弰顖氱秼閸撳秶娈戞径姘侀崹瀣劥缂冨弶鍎忛崘纰夌礉鐠侇厾绮屾稉娑擃亜銇囧Ο鈥崇烽敍灞藉晙閽傛悂顩撮崚鐧楁稉顏勭毈濡崇烽敍灞剧槨娑擃亜鐨Ο鈥崇烽崘宥呭礋閻欘剟鍣洪崠... 閹存垳婊戦惃鍕煙濞夋洩绱濈拋顓犵矊娑撴稉顏勩亣濡崇烽敍瀹杋netune鏉╂瑤閲滄径褎膩閸ㄥ鎮撻弮鍫曞倸绨睳娑擃亙绗夐崥灞剧箒鎼达妇娈戠亸蹇斈侀崹瀣剁礉閸欘亪娓剁电绻栨稉娑擃亝膩閸ㄥ绻樼悰宀勫櫤閸... As neural machine translation models become heavier heavier , resort model compress techniques deploy smaller models devices limited resources, mobile phones. However, practical challenge hardware conditions different devices vary greatly. To ensure calculation latency, customizing distinct model sizes different devices necessary, leads huge model training maintenance costs . For example, need distill pre-trained large model N individual small models. %Then model post-processing steps, model pruning quantization , also performed independently small model. The situation becomes worse industry considering translation directions frequent model iterations. An ideal solution train single model run different model sizes. Such attempts explored SlimNet LayerDrop . SlimNet allows running four width configurations joint training width networks, LayerDrop decode depth configuration applying Dropout layers training. In work, take step along line flexible depth network like LayerDrop. As shown Figure, first demonstrate large gap predefined layer dropout training actual pruning ratio inference, LayerDrop's performance poor. %We attribute huge sub-network training space mismatch random sampling training deterministic inference. To solve problem, propose use multi-task learning train flexible depth model treating supported depth configuration task. We reduce supported depth space aggressive model compression rate propose effective deterministic sub-network assignment method eliminate mismatch training inference LayerDrop. %Specifically, design two metrics determine sub-network assignment good. Experimental results deep Transformer show approach simultaneously support decoding 24 depth configurations superior individual training LayerDrop."," The standard neural machine translation model can only decode with the same depth configuration as training. Restricted by this feature, we have to deploy models of various sizes to maintain the same translation latency, because the hardware conditions on different terminal devices  may vary greatly. Such individual training leads to increased model maintenance costs and slower model iterations, especially for the industry. In this work, we propose to use multi-task learning to train a flexible depth model that can adapt to different depth configurations during inference. Experimental results show that our approach can simultaneously support decoding in 24 depth configurations and is superior to the individual training and another flexible depth model training method闁炽儲鏌￠幙鐜測erDrop."
"Targeted sentiment analysis involves jointly predicting entities targets opinion, well polarity expressed towards . The TSA task, part larger set fine-grained sentiment analysis tasks, enable companies provide better recommendations , well give digital humanities scholars quantitative approach identifying sentiment emotions develop literature . Although many improvements modelling TSA since original CRF models , utilising Recurrent Neural Networks , treating task span prediction rather sequence labelling task , concentrated making best use data annotated specifically task. However, annotation fine-grained sentiment taxing tends lower inter-annotator agreement document sentence classification tasks . This leads lack available high-quality training data, even highly resourced languages prevents TSA models learning complex, compositional phenomena necessary correctly predict targeted sentiment end-to-end fashion. We believe lack data fine-grained sentiment analysis leads TSA models cannot learn effectively complex compositional phenomena exists language, thus making TSA models fragile highly compositional language. It also shown incorporating compositional information negation speculation detection improves sentence-level sentiment classification . Other supervised tasks, semantic role labelling , document level sentiment analysis shown promise improving fine-grained sentiment analysis. Further transfer learning self-supervised language-modelling task, commonly referred contextualised word representations , also shown greatly benefit fine-grained sentiment analysis . Based this, paper, wish explore two research questions: To end, propose multi-task learning approach incorporate sources negation speculation information neural targeted sentiment classifier. We additionally compare approach MTL models use part-of-speech tagging, dependency relation prediction, lexical analysis auxiliary tasks, following previous work . Furthermore, order overcome lack evaluative resources investigate effects negation speculation, annotate two new challenge datasets contain difficult negated speculative examples. We find MTL models robust single task learning , performing competitively majority standard datasets significantly outperforming STL models negation challenge datasets, average better STL models speculation challenge datasets. Moreover, show transfer learning applied, using CWR, MTL STL models, MTL models longer significantly better, still better average negation challenge dataset one speculation challenge datasets. This result suggests transfer learning incorporate compositional information required negated speculative samples. However results challenge datasets considerably lower standard dataset, showing work needed make models robust compositional language. The contributions paper following:","   The majority of work in targeted sentiment analysis has concentrated on finding better methods to improve the overall results. Within this paper we show that these models are not robust to linguistic phenomena, specifically negation and speculation. In this paper, we propose a multi-task learning method to incorporate information from syntactic and semantic auxiliary tasks, including negation and speculation scope detection, to create models that are more robust to these phenomena. Further we create two challenge datasets to evaluate model performance on negated and speculative samples. We find that multi-task models and transfer learning from a language model can improve performance on these challenge datasets. However the results indicate that there is still much room for improvement in making our models more robust to linguistic phenomena such as negation and speculation."
"% making new tools useless noone uses efficiently The consensus human activity caused climate crisis led development many tools possible policy interventions, designed minimize greenhouse gas emissions mitigate negative impacts climate change. However, even promising tools counter climate crisis futile, used. All important research efforts mitigate climate crisis lost without efficient international adaptation tools policies. %promises politicans lead action Strategies adopted national level, following international cooperative guidelines Sustainable Development Goals Kyoto protocol . However, scientists, non-state actors\footnote{https://www.euronews.com/living/2018/12/21/ngos-sue-french-government-over-insufficient-climate-change-action}, voters increasingly critique government insufficient action mitigating climate change . This suggests gap promises made politicians actual action taken: somewhere along way ambitious promises climate change mitigation turned careless discourse insufficient measures taken. %accountability shown prevent mismanagement Holding politicians accountable actions shown major factor preventing mismanagement, political corruption misalignment politician閳ユ獨 opinions public representing . %so working improving accountability use existing tools Our work aims provide general public metric assess candidate party using platform discuss topics related climate change. % overall system In Section introduce Multi-Source Topic Aggregation System increases transparency providing overview topics discussed politicians. The large amount publicly available documents made transparent MuSTAS topic overview, would otherwise unattainable general public due amount data. Through transparency, decision-makers held accountable promises claims general public, accelerating policies societal changes needed mitigate adapt climate change. %Using large amount publicly available data processed asses politician uses influence across channels timelines. % The research multi-source LDA builds scientific foundation In Section describe novel multi-source hybrid latent Dirichlet allocation model builds scientific foundation MuSTAS forms core research proposal. In Section outline MuSTAS impacts climate change. % climate change impact % Here short paragraph structure proposal roles: MuSTAS larger scope, topic modelling multi-source hybrid LDA focus research. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%","     Decades of research on climate have provided a consensus that human activity has changed the climate and we are currently heading into a climate crisis.     Many tools and methods, some of which utilize machine learning, have been developed to monitor, evaluate, and predict the changing climate and its effects on societies.      However, the mere existence of tools and increased awareness have not led to swift action to reduce emissions and mitigate climate change.     Politicians and other policy makers lack the initiative to move from talking about the climate to concrete climate action. % in an appropriate schedule allowing for mitigation of the potentially catastrophic changes.      In this work, we contribute to the efforts of holding decision makers accountable by describing a system which digests politicians' speeches and statements into a topic summary.     We propose a multi-source hybrid latent Dirichlet allocation model which can process the large number of publicly available reports, social media posts, speeches, and other documents of Finnish politicians, providing transparency and accountability towards the general public."
"Word embeddings, continuous vectorial representations words, become fundamental initial step many natural language processing tasks many languages. In recent years, cross-lingual counterpart, cross-lingual word embeddings ---maps matching words across languages--- shown useful many important cross-lingual transfer modeling tasks machine translation , cross-lingual document classification zero-shot dependency parsing . In representations, matching words across different languages represented similar vectors. Following observation \citet{mikolov2013efficientestimation} geometric positions similar words two embedding spaces different languages appear related linear relation, common method aims map two pretrained monolingual embedding spaces learning single linear transformation matrix. Due simple structure design competitive performance, approach become mainstream learning CLWE . Initially, linear mapping learned minimizing distances source target words seed dictionary. Early work \citet{mikolov2013efficientestimation} uses seed dictionary five-thousand word pairs. Since then, size seed dictionary gradually reduced, several-thousand fifty word pairs , reaching minimal version sharing numerals . More recent works unsupervised learning shown mappings across embedding spaces also learned without bilingual evidence . More concretely, fully unsupervised methods usually consist two main steps : unsupervised step aims induce seed dictionary matching source target distributions, pseudo-supervised refinement step based seed dictionary. The system proposed \citet{conneau2018wordtranslation} considered first successful unsupervised system learning CLWE. They first use generative adversarial networks learn single linear mapping induce seed dictionary, followed Procrustes Analysis refine linear mapping based induced seed dictionary. While GAN-based model competitive even better performance compared supervised methods typologically-similar language pairs, often exhibits poor performance typologically-distant language pairs, pairs languages differ drastically word forms, morphology, word order properties determine similar lexicon language is. More specifically, initial linear mapping often fails induce seed dictionary distant language pairs . Later work \citet{artetxe2018arobust} proposed unsupervised self-learning framework make unsupervised CLWE learning robust. Their system uses similarity distribution matching induce seed dictionary stochastic dictionary induction refine mapping iteratively. The final CLWE learned system performs better GAN-based system. However, advantage appears come iterative refinement stochastic dictionary induction, according \citet{hartmann2019comparingunsupervised}. If consider performance model induced distribution matching, GAN-based models perform much better. This brings us first conclusions, GAN-based model preferable seed dictionary induction. Fully unsupervised mapping-based methods learn CLWE rely strong assumption monolingual word embedding spaces isomorphic near-isomorphic, assumption fulfilled practice, especially distant language pairs . Supervised methods also affected lack isomorphism, performance distant language pairs worse similar language pairs. Moreover, experiments \citet{vulic2020areall} also demonstrate lack isomorphism arise typological distance among languages, also depends quality monolingual embedding space. Actually, replace seed dictionary learned unsupervised distribution matching method pretrained dictionary, keeping constant refinement technique, final system becomes robust . All previous results indicate learning better seed dictionary crucial step improve unsupervised cross-lingual word embedding induction reduce gap unsupervised methods supervised methods, GAN-based methods hold promise achieve goal. The results also indicate solution handle full complexity induction cross-lingual word embeddings show improvements close distant languages. In paper, focus improving initial step distribution matching, using GANs . Because isomorphism assumption observed reality, argue successful GAN-based model must learn one single linear mapping entire distribution, must able identify mapping subspaces learn multiple mappings. We propose multi-adversarial learning method learns different linear maps different subspaces word embeddings. %specifically subspaces source word embeddings.","  Generative adversarial networks  have succeeded  in inducing  cross-lingual word embeddings ---maps of matching words across languages--- without supervision. Despite these successes, GANs' performance for the difficult case of distant languages is still not satisfactory. These limitations have been explained by GANs' incorrect assumption that source and target embedding spaces are related by a single linear mapping and are approximately isomorphic. We assume instead that, especially across distant languages, the mapping is only piece-wise linear, and propose a multi-adversarial learning method. This novel method induces the seed cross-lingual dictionary through multiple mappings, each induced to fit the mapping for one subspace. Our experiments on unsupervised bilingual lexicon induction show that this method improves performance over  previous single-mapping methods, especially for distant languages."
"In recent years, effectiveness utilizing image data tandem text corpus improve quality machine translation source extensive investigation. Several proposals made incorporate visual data, using doubly-attentive decoder image text data , initializing encoder decoder hidden state image features , using deliberation network approach refine translations using image data . However, common difficulty lack publicly available multimodal corpora, particularly English-Japanese translation tasks. Currently, two available English-Japanese multimodal datasets Japanese extension Pascal sentences Flickr30k Entities JP , Japanese translation Flickr30k Entities dataset . In order contribute current list English-Japanese multimodal corpora, propose new multimodal English-Japanese corpus comparable sentences. Comparable sentences sentences contain bilingual terms parallel phrases describe similar topic, direct translations . This data particular interest due natural prevalence across various areas media. For example, e-commerce sites different countries may product descriptions similar products different languages, social media users may comment images several different languages. In study, created large comparable training corpus compiling existing image captions MS-COCO STAIR captioning datasets. %By compiling existing image captions MS-COCO STAIR captioning datasets, able create large comparable training corpus require translation. Furthermore, validation testing purposes, translated small subset MS-COCO captions contain ambiguous verbs. The advantage comparable sentences relation available quantity clearly seen Table , proposed corpus containing almost twice many sentence pairs Flickr30k Entities JP, current largest parallel multimodal English-Japanese corpus. As benchmark current multimodal NMT models corpus, performed English-Japanese translation experiment using several baseline models, confirmed current NMT models well suited comparable translation task. %o evaluate proposed corpus, performed English-Japanese translation experiment several baseline models, confirmed current NMT models well suited comparable translation task. However, believe corpus used facilitate research creating multimodal NMT models better utilize comparable sentences. % % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % . % % % final paper: en-uk version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International Licence. % Licence details: % \url{http://creativecommons.org/licenses/by/4.0/}. % % % final paper: en-us version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. } \newcommand\T{\rule{0pt}{2.6ex}} \newcommand\B{\rule[-1.5ex]{0pt}{0pt}} \newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash}m{#1}} \newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash}m{#1}} \newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash}m{#1}} \end{table}"," Multimodal neural machine translation  has become an increasingly important area of research over the years because additional modalities, such as image data, can provide more context to textual data. Furthermore, the viability of training multimodal NMT models without a large parallel corpus continues to be investigated due to low availability of parallel sentences with images, particularly for English-Japanese data. However, this void can be filled with comparable sentences that contain bilingual terms and parallel phrases, which are naturally created through media such as social network posts and e-commerce product descriptions. In this paper, we propose a new multimodal English-Japanese corpus with comparable sentences that are compiled from existing image captioning datasets. In addition, we supplement our comparable sentences with a smaller parallel corpus for validation and test purposes. To test the performance of this comparable sentence translation scenario, we train several baseline NMT models with our comparable corpus and evaluate their English-Japanese translation performance. Due to low translation scores in our baseline experiments, we believe that current multimodal NMT models are not designed to effectively utilize comparable sentence data. Despite this, we hope for our corpus to be used to further research into multimodal NMT with comparable sentences."
"%\todo[inline]{Why predicting hate-speech important general?} %\todo[inline]{why detecting hate-speech important Yahoo news Yahoo finance?} % %What problem? %Why interesting important? %Why hard? %Why solved before? %What key components approach results? Also include specific limitations. %Hatespeech speech ``intended insult, offend, intimidate person trait "". The occurrence hatespeech increasing. It become easier reach large audience quickly via social media, causing increase temptation inappropriate behaviors hatespeech, potential damage social systems. In particular, hatespeech interferes civil discourse turns good people away. Furthermore, hatespeech virtual world lead physical violence certain groups real world\footnote{https://www.nytimes.com/2018/10/31/opinion/caravan-hate-speech-bowers-sayoc.html}\footnote{https://www.washingtonpost.com/nation/2018/11/30/how-online-hate-speech-is-fueling-real-life-violence}, ignored ground freedom speech. To detect hatespeech, researchers developed human-crafted feature-based classifiers , proposed deep neural network architectures . %Online service providers also strive combat hatespeech ranking algorithms, filtering, suspending deactivating user accounts. \textcolor{red}{However, blah blah blah}. However, might explore possible important features hatespeech detection, ignored pre-trained language model understanding, proposed uni-directional language models reading left right right left. %--> 2. Other deep model hatespeech detection: either understand fully hateful context , ignore pretrained language model understanding and/or uni-directionally understanding language models reading left right right left . Recently, BERT model achieved tremendous success Natural Language Processing % . The key innovation BERT applying transformer language modeling tasks. %It proposed language modeling two tasks: predicting masked words predicting next sentence. A BERT model pre-trained language modeling tasks forms good basis fine-tuning supervised tasks machine translation question answering, etc. Recent work hatespeech detection applied BERT model shown prominent results previous hatespeech classifiers. However, point two limitations hatespeech detection domain. First, previous studies shown hateful corpus owns distinguished linguistic/semantic characteristics compared non-hateful corpus. For instance, hatespeech sequences often informal even intentionally mis-spelled, words hateful sequences sit long tail ranking uniqueness, comment hateful non-hateful using words . %For example, ``n1gger'' sentence ``i `n1gger' indicated'' non-hateful, ``n1gger'' ``you n1gger!'' hateful. For example, ``dick'' sentence ``Nobody knew dick meant'' non-hateful, ``d1ck'' ``You weak small-d1cked keyboard warrior'' hateful \footnote{It important note paper contains hate speech examples, may offensive readers. They represent views authors. We tried make balance showing less number hate speech examples illustrating challenges real-world applications.}. Thus, better understand hateful vocabularies contexts, better pre-train mixture hateful non-hateful corpora. Doing helps overcome limitation using BERT models pre-trained non-hateful corpora like English Wikipedia BookCorpus. Second, even smallest pre-trained BERT ``base'' model contains 110M parameters. It takes lot computational resources pre-train, fine-tune, serve. %There recent efforts reducing Some recent efforts aim reduce complexity BERT model knowledge distillation technique DistillBert TinyBert . In methods, pre-trained BERT-alike model used teacher model, student model trained produce similar output teacher model. Unfortunately, complexity reduced, performance also degraded NLP tasks compared BERT. Another direction use cross-layer parameter sharing, ALBERT . However, ALBERT's computational time similar BERT, since number layers remains BERT; likewise, inference equally expensive. Based observation analysis, aim investigate whether possible achieve better hatespeech prediction performance state-of-the-art machine learning classifiers, including classifiers based publicly available BERT model, significantly reducing number parameters compared BERT model. By so, believe performing pre-training tasks ground hatespeech-related corpus would allow model understand hatespeech patterns better enhance predictive results. However, language model pretraining tasks require large scale corpus size, available hatespeech datasets normally small: 16K115K annotated comments . Thus, introduce large annotated hatespeech dataset 1.4M comments extracted Yahoo News Yahoo Finance. To reduce complexity, reduce number layers hidden size, propose Quaternion-based Factorization mechanisms BERT architecture. To improve model effectiveness robustness, introduce multi-source ensemble-head fine-tuning architecture, well target-based adversarial training. %Internet platforms moderate user-generated content interest majority users, business needs. Through ranking algorithms, filtering, suspending deactivating user accounts, many Internet companies strive combat hatespeech. %Twitter, example, ""the twitter rules"", states ``Violence, harassment similar types behavior discourage people expressing themselves, ultimately diminish value global public conversation."". %To ensure users positive experience properties, Verizon Media also clear rules hatespeech. %, state ``Don't use hatespeech. Hatespeech directly attacks person group basis race, ethnicity, national origin, religion, disability, disease, age, sexual orientation, gender, gender identity. As noted above, we're diverse global community many types people, different beliefs, opinions, sensitivities, comfort levels. If feel abide Community Guidelines outlined below, maybe participating Oath community you."" %At Verizon Media, Standard Moderation Platform runs platform service moderate text, URL, images videos. The hatespeech classifiers SMP based number past research work, including. % The purpose work described paper improve performance current state art hatespeech classifiers. In previous study, % used pretrained BERT model starting point fine tuning. % %, investigated range different machine learning models text classification. % %We show combination linear model, % We found BERT architecture gives better performance baseline models, including. %, well Google's Prospective API. In study, pretrained BERT model used starting point fine tuning. %Recently, BERT model become state-of-the-art language model achieved tremendous success Natural Language Processing . %\todo[inline]{talking BERT success variety nlp tasks cited works} %BERT modified transformer network architecture. Traditionally, many language tasks translation question answering, handled using recurrent neural networks, combined attention mechanism. This %reflects fact tend read sentence left right. However, human also read words within context words, %some could quite far apart, %instead left right right left mechanical way. Furthermore, recurrent network memory problem handle long text, due problems vanishing exploding gradient. In addition, intrinsically sequential, making training process slow. Transformer network proposed solve problems. In setup, word input text visibility words, use multi-headed attention. %It used %in variety NLP tasks well area image processing. %One motivation paper investigate whether possible achieve performance similar to, better publicly available BERT models, smaller models. In so, want realize considerable saving training serving time. Another motivation see possible improve BERT model further, introducing changes model architecture. The third motivation following. The pretrained BERT models based % BooksCorpus English Wikipedia. They different characteristics dataset interest us, consists users-generated comments Yahoo News Yahoo Finance. Consequently believe retraining language model scratch % give us model understands % language dataset better. %\todo[inline]{talking limitation BERT, like complicated heavy many parameters. Then question build better model, less number parameters?} The major contributions work are: \squishlist % \squishend % We organize paper followed. % We give related work Section, % define problem solving formerly Section. We present approach Section, show experimental results Section. We conclude paper Section discussions future work. %"," We present our {HABERTOR} model for detecting hatespeech in large scale user-generated content. Inspired by the recent success of the BERT model, we propose several modifications to BERT to enhance the performance on the downstream hatespeech classification task. {HABERTOR} inherits BERT's architecture, but is different in four aspects:  it generates its own vocabularies and is pre-trained from the scratch using the largest scale hatespeech dataset;  it consists of Quaternion-based factorized components, resulting in a much smaller number of parameters, faster training and inferencing, as well as less memory usage;  it uses our proposed multi-source ensemble heads with a pooling layer for separate input sources, to further enhance its effectiveness; and  it uses a regularized adversarial training with our proposed fine-grained and adaptive noise magnitude to enhance its robustness. Through experiments on the large-scale real-world hatespeech dataset with 1.4M annotated comments, we show that {HABERTOR} works better than 15 state-of-the-art hatespeech detection methods, including fine-tuning Language Models. In particular, comparing with BERT, our {HABERTOR} is 4$\sim$5 times faster in the training/inferencing phase, uses less than 1/3 of the memory, and has better performance, even though we pre-train it by using less than 1\% of the number of words. Our generalizability analysis shows that {HABERTOR} transfers well to other unseen hatespeech datasets and is a more efficient and effective alternative to BERT for the hatespeech classification.  %The code and the pretrained models are available at anonymized."
"%------------------Previous version------------------ %Since UNMT low-resource domains yet actively explored field, one may naively approach problem training model multiple domains expect generalize unseen, low-resource domains, e.g., training model news sports domains evaluating biomedical domain. %However, due domain mismatch, studied supervised NMT, model show inferior performance. %------------------------------------------------------- Unsupervised neural machine translation leverages unpaired monolingual corpora training, without requiring already labeled, parallel corpus. Recently, state art UNMT achieved comparable performances supervised machine translation approaches. However, case translation domain-specific documents, monolingual data scarce, collecting involves high cost, still suffering low NMT performance. For instance, model trained monolingual data low-resource domain, say, medical domain, experience degraded translation quality due overfitting. %------------------Previous version------------------ %Another reasonable approach transfer learning, frequently used domain adaption literature supervised NMT often showed improvements target domain. The model pretrained multiple domains finetuned new domain. However, approach may suffer overfitting catastrophic forgetting given small number training data large domain gap downstream task. %-------------------------------------------------- Yet, UNMT low-resource domains actively explored field. One naive approach train model high-resource domains hoping generalize unseen low-resource domain well. However, shown recent studies supervised NMT nontrivial domain mismatch significantly cause low translation accuracy. Another reasonable approach transfer learning, particular domain adaptation, shown performance improvements literature supervised NMT. In approach, model first pretrained using existing domains finetuned using data new domain. However, approach may suffer overfitting catastrophic forgetting due small number training data large domain gap. As effective method handling small number training data, meta-learning shown superiority various NLP tasks, dialog generation, translation, natural language understanding. However, best knowledge, applied tackle UNMT tasks small number training data, i.e., low-resource UNMT. In response, paper extends meta-learning approach low-resource UNMT, called \toolnameMeta. The objective \toolnameMeta find optimal initialization model parameters quickly adapt new domain even small amount monolingual data. To specific, assuming data multiple source domains available, makes meta-learning applicable, first pretrain UNMT model source domains based \toolnameMeta finetune model using target domain. Moreover, propose improved meta-learning approach called \ourtoolname low-resource UNMT explicitly promoting common knowledge across multiple domains well generalizable knowledge particular domain another. In particular, proposed approach prevents model overfitting due small amount training data new domain. In summary, contributions include following. %\item \ourtoolname shows domain-general knowledge faster convergence methods. %\item We empirically demonstrate enhanced algorithm, \ourtoolname, consequently boosts performance low-resource UNMT baseline models including \toolnameMeta. %\item We extend meta-learning algorithm incorporating domain mixing loss, outperforms methods. % %We show zero-shot performance evaluate generalization ability \ourtoolname, \ourtoolname outperforms methods. % To best knowledge, work first apply meta-learning approach UNMT tasks. Our proposed algorithms quickly adapt in-domain iteration steps. Both \toolnameMeta \ourtoolname consistently outperform baseline models 3 BLEU scores. Especially, \ourtoolname achieves promising results among others including \toolnameMeta. Besides, show zero-shot performance evaluate generalization ability \ourtoolname, \ourtoolname outperforms methods. %--------------------------------- % 闋冩﹥顫呮 姘╁牗妫撮瀽鎰冲妧闆 闇冨嫴饪洪灇 闈镐緛纾ら瀽鍡㈡緤 鐡垮婀㈣嚙 闇呮﹤濮 general 闋 feature闇屻倢婢 闉涘牕瀚. % Although domain distance others domain adaptation, share linguistic features, grammar basic words. % Azam: To alleviate aforementioned challenge, % Azam: To overcome issue, many % % \item % \item 闉栧崐螠闉 contribtuion bullet point鎼 summary : % \item 1. formulate new task % \item 2. New frame work proposed % \item 3. evaluate various domain. show fast adaptation quality. %On hand, since unsupervised machine translation attained comparable performance supervised machine translation, fully unsupervised domain adaptation, uses monolingual data in-domain out-of-domain, suitable handle data-scarce languages. %yet challenge data-scarce domains. In words, unsupervised domain adaptation task handle data-scarce languages; however, cannot resolve challenge low-resource domains. % %such alleviates aforementioned challenge, building parallel corpus. %Therefore, fully unsupervised domain adaptation task, consisted unpaired language corpus in-domain out-of-domain, realistic setting supervised domain adaptation task.%and substantial effort collect domain specific data. %A meta-learning algorithm superior low-resource data. Unlike domain adaptation, meta-learning algorithm require in-domain data learn initial parameters. It asks training samples meta-train model. Collaborating meta-learning algorithm unsupervised machine translation %Since leverage cross-lingual language model pretraining allows model learn cross-lingual representations, gradient updates divided two objective functions, back-translation language modeling. % Several approaches proposed resolve scarcity problem. For instance, data mixing one approach aggregates high-resource low-resource data train model adequately translate low-resource target language % To overcome data scarcity problem, one simple approach data mixing aggregates high-resource low-resource data train model adequately translate low-resource target language. The approach transfer learning first pretrains high-resource data fine-tunes low-resource data. Although aforementioned approaches explicitly tackle low-resource challenge, scarcity problem still remains NMT building parallel corpus specialized expertise costly expensive. % In paper, leverage recent success unsupervised NMT uses monolingual corpus. Inspired , propose new task called low-resource UNMT. To best knowledge, first attempt % To overcome issue, unsupervised learning NMT proposed resolve parallel data scarcity problem. However, approach constraint abundant monolingual corpus always available. % In reality, monolingual corpus also scarce domains languages often used. %鑶﹂浛 闉涙劤鍔爩 闉氭尗婀 闈广倠鐛 % Although various approaches proposed address low-resource challenge , none works consider low-resource unsupervised task NMT. To best knowledge, first attempt explicitly tackles low-resource UNMT task. % In paper, % When translate word different language, semantic meaning changed. For instance, meaning word ""CNN"" different domain deep learning news % To overcome issue, abundant parallel data required easy obtain. Recently, unsupervised NMT studies show reasonable performance comparison supervised NMT. % Data mixing high-resource low-resource one approach handle following issue. The approach transferring learning method first trains high-resource datasets fine-tunes low-resource datatset. However, problem still remain parallel data scarce domains languages. To overcome parallel data scarcity problem % To overcome issue, unsupervised learning NMT proposed resolve problem insufficient parallel data. However, approach assumes obtaining monolingual corpus always easier acquiring parallel corpus. Since languages vary domains , either monolingual parallel data scarce. % utilize monolingual corpus assume monolingual corpus always available. However, % In NMT, data scarcity problem divided two different training data scenarios, insufficient training parallel data training data . To overcome scarce parallel data issue, recent studies proposed utilize monolingual corpus. % parallel data essential train NMT model % several learning methods, unsupervised learning transfer learning NMT, proposed overcome data scarcity problem. However, works consider languages still remains problem domains . Moreover, best knowledge, none works attempt %Learning inevitable phase adapt new task. However, various learning experiences reduce exertion learning new task. % %Domains %To overcome issue, one simple approach domain mixing aggregates high-resource low-resource domains train model adequately translate low-resource domain. The approach transfer learning first pretrains high-resource domains fine-tunes low-resource domain. %Despite remarkable success neural machine translation ~, performance NMT drops substantially traditional statistical machine translation training data scarce %To overcome scarcity training data languages, variants multilingual translation approaches proposed. These approaches basically exploit high-resource knowledge aggregating high-resource low-resource data train one single model. The approach utilizing transfer learning model first pretrains high-resource data later fine-tunes low-resource data. The similar manner follows domains well. %Moreover, few-shot learning meta-learning arise machine learning attempt handle data scarcity problem. In NMT, ~\citet{gu2018meta} re-formulates model-agnostic meta-learning algorithm resolve low-resource challenge NMT. %Although aforementioned approaches tackle low-resource challenge, data scarcity problem still remain following approaches require parallel data, building low-resource language pair specialized expertise costly expensive. Hence, recent research suggests rely monolingual corpus instead using parallel corpus. The various unsupervised NMT ~ studies show reasonable performance comparison supervised NMT. % 闋冩﹥顫呮 monolingual corpus 姣靛牗鐖涢渻 闆垮姙婢婇煰 鐡寸粖鏅爢鍕冲剨闉 闉氭鏌庨洰鐘惧灛闉涘牗娼 -鏀磋兂鏌涢瀼鎸 鏀撮附寮版皡鏃嶆緫闉 闉濅緟娼夐澗姗冪抽浖..? %sufficient in-domain data train model; however, real-world, collecting domain specific data requires substantial effort. %building low-resource language pair specialized expertise costly expensive % 鏂撴粔鑺 闇屻倢鏌 MT闉 姘氭粚鐖犻灇 闈奉剢鐎 姘╁牗妫撮澗姗冾槬鏃矅顫 闇冨嫴瀚 闋冩﹥姒鹃灇 . % Machine learning 闉愭劤鍔闉 Data scarcity 姘嶈兂鐗 闉濇粔璧 % Domain translation闉 闉 娆锋埄娈ч爟婊岊潊 % unsuperivsed machine translation % data mixing, transfer learning % knowledge gets partially vanished % 闆垮姙婢婇煰 鐡寸粖鏅 % 闋冩悡鑸堕爟姗佽荡闉欏嫶鏆ｉ澒 transfer learning mixing data 鑷ф瑬娼 姘氣晣鐭 闈奉剣姣 % 闋冩﹥顫呮 parallel setting 闉愭劤鍔 闉濅緟姣勯爟 % parallel 闆垮姙婢婇煰鐡ｇ殰 闈炬﹥顫栭爟姗佽荡鑷 闋屾﹤鎽 % monolingual corpus姣 闈奉剣姣勯爟姗傚 UNMT work闇屻倢婢 闈告繉绠 % unsupervised 闈瑰姜濮ら灇 鏂撴粔鑺抽湆銈屾煄 姣靛韩婢 闆存帥鏅炴瓎 % 闋冩﹥顫呮 monolingual corpus 姣靛牗鐖涢渻 闆垮姙婢婇煰 鐡寸粖鏅爢鍕冲剨闉 闉氭鏌庨洰鐘惧灛闉涘牗娼 -鏀磋兂鏌涢瀼鎸 鏀撮附寮版皡鏃嶆緫闉 闉濅緟娼夐澗姗冪抽浖..? % 鏀撮附螠闋冩﹥妫 闉栧崐螠闆 low-resource UNMT姣 meta-learning algorithm闉欒導顢 闊块附濮 姘氣晥鏅ラ灇 闉濇粚瀚 % 鏃姙銆 meta-nmt 闆茶導顑撶摽鑼у 闆笺倠顩 闉氭尗婀㈤浕 闉栧崐螠鏃拌導濮 unsupervised闉 % multi doamin 鑷ф洢鈥 %"," Unsupervised machine translation, which utilizes unpaired monolingual corpora as training data, has achieved comparable performance against supervised machine translation. However, it still suffers from data-scarce domains. To address this issue, this paper presents a meta-learning algorithm for unsupervised neural machine translation  that trains the model to adapt to another domain by utilizing only a small amount of training data. We assume that domain-general knowledge is a significant factor in handling data-scarce domains. Hence, we extend the meta-learning algorithm, which utilizes knowledge learned from high-resource domains to boost the performance of low-resource UNMT. Our model surpasses a transfer learning-based approach by up to 2-4 BLEU scores. Extensive experimental results show that our proposed algorithm is pertinent for fast adaptation and consistently outperforms other baseline models."
"Numerous entities emerging everyday. The attributes entities often noisy incomplete, even missing. In field electronic commerce, target attributes new products often missing . In medical analysis, attributes like transmission, genetics origins novel virus often unknown people. Even DBpedia, well-constructed large-scale knowledge base extracted Wikipedia, half entities contain less 5 relationships . %In KG construction area, KGs often suffer incompleteness. %For example, DBpedia, well-constructed large-scale knowledge base extracted Wikipedia, half entities contain less 5 relationships . %Therefore, A method capable supplementing reliable attribute values emerging entities highly useful many applications. %With method automatically extract attribute values emerging entities, eCommerce retailers able better serve customers updated information; extracted medical attribute information novel virus organized assist understanding virus; KG able provide complete information users. Although information extraction methods extensively studied, task open attribute value extraction remains challenging. First, emerging entities may new attribute values absent existing KG. Under circumstances, prediction methods closed-world assumption methods cannot utilize external information well suited due limited recalls. Second, web corpus used good resource provide relatively updated relevant articles large varieties emerging entities, %that relatively complete updated timely manner, %considering large variety emerging entities, web corpus, relatively complete updated timely manner, able provide rich collection relevant articles. %However, articles retrieved web corpus noisy and/or irrelevant, turn leads limited precision. Finally, even articles relevant, extracted answers might still inaccurate due error-prone information extraction model. To effectively filter noisy answers obtained either due irreverent articles errors incurred information extraction system, %need answer pose following two questions: First, many articles collect enormous web corpus? Second, select reliable value pool possible answers extracted articles? There common answer first question works triplets inconsistent degrees difficulties finding correct attribute values. The decision stop querying external articles needs made successive evaluations candidate answers. Thus decision making process inherently sequential. %Thus, inherently sequential decision making problem. Reinforcement learning commonly adopted method deal sequential decision problems widely studied field robotic game . But many researches open attribute value extraction RL. One existing literature RL-based method value extraction proposed . In work, RL framework designed improve accuracy event-related value extraction acquiring incorporating external evidences. However, approach requires great amount context information specific event interest training process. It trivial extend framework open attribute value extraction, would need collect context words train new model annotated data emerging attribute. Therefore, framework cannot generalized open attribute value extraction task various entities attributes involved. While using context words construct states RL suitable task, solution leverage rich, well-organized information KG, informative also generalizable. %The knowledge KG Such information leveraged answer comparisons, addresses second question. For example, fill incomplete triplet iPhone 11, display resolution, ?, KG may find attribute values ``display resolutions"" entity category ``Phone"" commonly expressed format ``xxx xxxx Pixels"", x stands digit. The typical instances attribute values entities category provide valuable background information. In paper, propose knowledge-guided RL framework perform open attribute value extraction. The RL agent trained make good actions answer selection stopping time decision. Our experiments show proposed framework significantly boosts extraction performance. To best knowledge, first integrate KG RL framework perform open attribute value extraction %use KG guide RL-based sequential decision open attribute value extraction. %The experiment results demonstrate approach improves extraction performances substantially. In summary, contribution three folds:"," Open attribute value extraction for emerging entities is an important but challenging task.  A lot of previous works formulate the problem as a question-answering  task.  While the collections of articles from web corpus provide updated information about the emerging entities, the retrieved texts can be noisy, irrelevant, thus leading to inaccurate answers. Effectively filtering out noisy articles as well as bad answers is the key to improving extraction accuracy. Knowledge graph , which contains rich, well organized information about entities, provides a good resource to address the challenge. In this work, we propose a knowledge-guided reinforcement learning  framework for open attribute value extraction.  Informed by relevant knowledge in KG, we trained a deep Q-network  to sequentially compare extracted answers to improve extraction accuracy. The proposed framework is applicable to different information extraction system. Our experimental results show that our method outperforms the baselines by 16.5 - 27.8\%."
"% It applied generate synthetic Question Answering datasets, construct QA model dual tasks boost QA systems. It also contribute dialogue system ask meaningful questions user experience enhancement applied education systems. Question Generation task automatically generate question given context and, optionally, answer. Recently, observed increasing interest text-based QG. % QG area, including Knowledge-based QG , Image-based QG , especially \end{table} % help train models complex reasoning ability. However, manually creating datasets time-consuming costly, thus automatic multi-hop QG potentially reduce cost. % It applied generate synthetic Question Answering datasets , construct QA model dual tasks boost QA systems. It also contribute dialogue system ask meaningful questions applied education systems. Most existing works text-based QG focus generating SQuAD-style questions, generated sentence containing answer nearby sentences paragraph, via single-hop reasoning. Little effort put multi-hop QG, challenging task. Multi-hop QG requires aggregating several scattered evidence spans multiple paragraphs, reasoning generate answer-related, factual-coherent questions. It serve essential component education systems, applied intelligent virtual assistant systems. It also combine question answering models dual tasks boost QA systems reasoning ability. % generate complicated challenging questions evaluate student's understanding certain topic Intuitively, two main additional challenges needed addressed multi-hop QG. The first challenge effectively identify scattered pieces evidence connect reasoning path answer question. As example shown Table, generate question asking ``Marine Air Control Group 28'' given answer ``Havelock, North Carolina'', need bridging evidence like ``Marine Corps Air Station Cherry Point''. %, connection answer entity achieved two-hops reasoning. The second challenge reason multiple pieces scattered evidence generate factual-coherent questions. % Furthermore, evidence single answer-related sentence single-hop QG,, reason evidences fuse information generate factual coherent question, another challenging issue % Early single-hop QG uses rule-based methods transform sentences questions. % Conventional single-hop QG uses neural network based approaches based sequence-to-sequence framework, different types encoders decoders designed. % , different ways attend answer information context encoding. % However, none previous work addressed challenges mentioned multi-hop QG task, incorporate answer information context encoding single-hop reasoning. To best knowledge, work multi-hop QG uses multi-task learning auxiliary loss sentence-level supporting fact prediction, requiring supporting fact sentences different paragraphs labeled training data. While labeing supporting facts requires much human labor time-consuming obtain real scenarios, method cannot applied general multi-hop QG cases. % requiring supporting fact sentences different paragraphs labeled training data, Previous works mainly focus single-hop QG, use neural network based approaches sequence-to-sequence framework. Different architectures encoder decoder designed incorporate information answer context single-hop reasoning. To best knowledge, none previous works address two challenges mentioned multi-hop QG task. The work multi-hop QG uses multi-task learning auxiliary loss sentence-level supporting fact prediction, requiring supporting fact sentences different paragraphs labeled training data. While labeling supporting facts requires heavy human labor time-consuming, method cannot applied general multi-hop QG cases without supporting facts. % Supporting fact extra information indicating sentences contain evidence answer question. In paper, propose novel architecture named Multi-Hop Encoding Fusion Network Question Generation address aforementioned challenges multi-hop QG. First all, extends Seq2Seq QG framework sing-hop multi-hop context encoding. Additionally, leverages Graph Convolutional Network answer-aware dynamic entity graph, constructed entity mentions answer input paragraphs, aggregate potential evidence related questions. Moreover, use different attention mechanisms imitate reasoning procedures human beings multi-hop generation process, details explained Section. % It extension Seq2Seq framework single-hop QG, instead using one single encoder, propose Multi-hop Encoder, context encoding multiple hops Graph Convolutional Network , encoding reasoning via gated feature fusion module encoding stage. We applying GCN answer-aware dynamic entity graph, constructed entity mentions answer input paragraphs, aggregate potential evidence related question . And use different logic different encoder hops imitate reasoning procedures human beings multi-hop generation process. We conduct experiments multi-hop QA dataset HotpotQA model baselines. The proposed model outperforms baselines significant improvement automatic evaluation results, BLEU. The human evaluation results validate proposed model likely generate multi-hop questions high quality terms Fluency, Answerability Completeness scores. % address challenge Our contributions summarized follows: % leverage Graph Convolutional Network encoder sake effectively connecting related entities across paragraphs. % apply Graph Convolutional Network aggregate information multi-hops away answers. % proposed Multi-hop Encoder block generate ?? context encoding dynamically fuse them, imitating reasoning procedures human beings multi-hop generation process. % Different reasoning logic applied different encoder hops. % extension previous Seq2Seq framework single-hop QG. % Instead using single encoder, propose Multi-hop Encoder block, context encoding multiple hops encoding reasoning via gated feature fusion module. % Inspired previous work multi-hop QA using graph networks , build answer-aware dynamic entity graph based entity mentions answer input paragraphs. % We adopt co-attention mechanism answer-aware context encoder deeper information exchange answer context, % use bi-attention mechanism treating dynamic entity graph memories, entity-aware answer encoder module update multi-hop answer encoding. % We generate final context encoding via gated encoder reasoning module, decides keep ignore encoder information previous encoding hops. % By reasoning multiple information sources multi-hops away context conversational history. % Multi-hop QG serve essential component intelligent virtual assistant system ask user informative questions enhance user engagement , applied education systems generate complicated challenging questions evaluate student's understanding certain topic stimulate self-learning . On hand, large-scale high quality multi-hop question answering datasets HotpotQA help train models complex reasoning ability. However, manually creating datasets time-consuming costly, automatic multi-hop QG potentially reduce cost, especially large set documents available."," % grammatically correct, logically coherent Multi-hop Question Generation  aims to generate answer-related questions by aggregating and reasoning over multiple scattered evidence from different paragraphs. It is a more challenging yet under-explored task compared to conventional single-hop QG, where the questions are generated from the sentence containing the answer or nearby sentences in the same paragraph without complex reasoning. To address the additional challenges in multi-hop QG, we propose Multi-Hop Encoding Fusion Network for Question Generation , which does context encoding in multiple hops with Graph Convolutional Network and encoding fusion via an Encoder Reasoning Gate. To the best of our knowledge, we are the first to tackle the challenge of multi-hop reasoning over paragraphs without any sentence-level information. Empirical results on HotpotQA dataset demonstrate the effectiveness of our method, in comparison with baselines on automatic evaluation metrics. Moreover, from the human evaluation, our proposed model is able to generate fluent questions with high completeness and outperforms the strongest baseline by 20.8\% in the multi-hop evaluation. The code is publicly available at \href{https://github.com/HLTCHKUST/MulQG}{https://github.com/HLTCHKUST/MulQG}.  % n-gram based automatic evaluation metrics, and human evaluation metrics for answerability, fluency and multi-hops."
"% NMT good needs lots parallel data + exploit mono data Neural machine translation using sequence sequence architectures become dominant approach automatic machine translation. While able approach human-level performance , still requires huge amount parallel data, otherwise easily overfit. Such data, however, might always available. At time, generally much easier gather large amounts monolingual data, therefore, interesting find ways making use data. The simplest strategy use backtranslation , %but rather costly since requires training another model opposite translation direction creating source-side synthetic sentences translating target-side monolingual corpus. rather costly since requires training model opposite translation direction translating monolingual corpus. % We introduce compositionality It suggested \citet{lake2017machines} development general human-like AI system, one desired characteristics system ability learn continuous manner using previously learned tasks building blocks mastering new, complex tasks. %by combining knowledge learned previously learned simpler tasks. Until recently, continuous learning neural networks problematic, among others, due catastrophic forgetting . Several methods proposed , however, %they mostly focused preserving knowledge task learned whole network. mainly focus adapting whole network new tasks maintaining good performance previously learned tasks. % Summary method using EWC %\XXX{toto mozna posunout za nasledujici odstavec + jak resime jejich nedostatky} In work, present unsupervised pretraining method NMT models using Elastic Weight Consolidation . First, initialize encoder decoder source target language models respectively. Then, fine-tune NMT model using parallel data. To prevent encoder decoder forgetting original language modeling task, regularize weights individually using Elastic Weight Consolidation based importance task. Our hypothesis following: forcing network remember original LM tasks reduce overfitting NMT model limited parallel data. %\XXX{Ukazujeme, ze metoda funguje, je rychlejis + mame odvozeno, ze mela fungovat pro podsite} %\XXX{Zminit rovnou strucne prinosy?} % Summary method used comparison We also provide comparison approach method proposed \citet{ramachandran2017pretraining}. They also suggest initialization encoder decoder language model. However, fine-tuning phase use original language modeling objectives additional training loss place model regularization. Their approach two main drawbacks: first, fine-tuning phase, still require original monolingual data might available anymore life-long learning scenario. Second, need compute machine translation language modeling losses increases number operations performed update slowing fine-tuning process. Our proposed method addresses problems: requires small held-out set estimate EWC regularization term converges 2-3 times faster previous method.\footnote{The speedup regard wall-clock time. In experiments EWC LM-objective methods require similar number training examples converge.} %Intro compositionality %Compositional learning + using previosly learned elementary knowledge learn complex model %Avoiding catastrophic forgetting key continual learning compositionality -> choice EWC %Benefits compositionality greater scope + NMT + LM pretrain? %It first step ongoing reseach %The paper structured following...","   This work presents our ongoing research of unsupervised pretraining in neural machine translation . In our method, we initialize the weights of the encoder and decoder with two language models that are trained with monolingual data and then fine-tune the model on parallel data using Elastic Weight Consolidation  to avoid forgetting of the original language modeling tasks.   We compare the regularization by EWC with the previous work that focuses on regularization by language modeling objectives.   %We compare the EWC regularization with the previous work that uses language modeling objectives from the original task for model regularization.      The positive result is that using EWC with the decoder achieves BLEU scores similar to the previous work. However,   the model converges 2-3 times faster and does not require the original unlabeled training data during the fine-tuning stage.      In contrast, the regularization using EWC is less effective if the original and new tasks are not closely related. We show that initializing the bidirectional NMT encoder with a left-to-right language model and forcing the model to remember the original left-to-right language modeling task limits the learning capacity of the encoder for the whole bidirectional context.      %%% POZNAMKY %%%   % Analyza Fisher Information   % - Self-attention projekce are more important than the Feedforward layers   % - Self-attention:   %     - output and value projections are more important at the higher layers   %     - key and query projections are more important at lower layers   % ...      % Previous work    % - requires orig. unlabeled data for MT training -> EWC can estimate Empirical Fisher on small  heldout data   % - is effective even when the orig. and new tasks differ   %  and then using this pretrained encoder in MT  -> EWC is bad at this      % Our work :   % - has nice mathematical definition    % - faster convergence in time    % - works only with decoder  -> little worse than LM obj.   % - method works when task are similar in nature    % - how deep should the unlabeled-data-pretrained enc-dec should be?   %       % why only left-context? previous work shows that with transformer, the drop in performance is not that big + it is much easier to implement       % Future work :   % - Investigate complementarity of EWC and LM obj.    % - Investigate the learning rate schemes    % - Investigate the method in the multimodal/multisource scenario   % - Investigate the method"
"Even though machine translation greatly improved emergence neural machine translation recently Transformer architecture , remain challenges solved using sentence-level NMT systems. Among issues, includes problem inter-sentential anaphora resolution consistent translation across document , system inevitably needs document-level context information. In recent years, many works focused changing existing NMT architectures incorporate context information translation process . However, often times results reported specific tasks , making difficult assess potential different methods general setting. This, together fact big improvements typically reported low resource tasks, gives impression document-level NMT mostly improves due regularization rather leveraging additional context information. In work want give complete overview current state document-level NMT comparing various approaches variety different tasks including application-oriented E-commerce setting. We discuss both, widely used performance metrics, well highly task-specific observations. Another important aspect talking document-level NMT applicability ``real life"" settings. There, faced low resource data scenario, back-translation established way greatly improving system performance . However, best knowledge, effect back-translation data obtained used context-aware models never explored before. The main contributions paper summarized below:","  Context-aware neural machine translation  is a promising direction to improve the translation quality by making use of the additional context, e.g., document-level translation, or having meta-information. Although there exist various architectures and analyses, the effectiveness of different context-aware NMT models is not well explored yet. This paper analyzes the performance of document-level NMT models on four diverse domains with a varied amount of parallel document-level bilingual data. We conduct a comprehensive set of experiments to investigate the impact of document-level NMT.  We find that there is no single best approach to document-level NMT, but rather that different architectures come out on top on different tasks. Looking at task-specific problems, such as pronoun resolution or headline translation, we find improvements in the context-aware systems, even in cases where the corpus-level metrics like BLEU show no significant improvement. We also show that document-level back-translation significantly helps to compensate for the lack of document-level bi-texts.   \includecomment{ Context-aware neural machine translation  is a promising direction for improving the translation quality having more context, e.g., document-level translation, or having meta-information. The goal is to enhance the translation of discourse phenomena and polysemous words. This paper analyzes the performance of document-level NMT models with a varied amount of parallel document-level bilingual data. Including a diverse set of tasks, e.g., movie subtitles and e-commerce data, we conduct a comprehensive set of experiments to analyze and to learn the impact of document-level NMT. We show the document-level back-translation significantly helps to compensate for the lack of document-level bi-texts.  }"
"Knowledge Graphs like Freebase, NELL Wikidata extremely useful resources NLP tasks, information retrieval, machine reading, relation extraction. A typical KG multi-relational graph, represented triples form given entity pairs task relation . These known few-shot entity pairs associated called references. To improve semantical representations references, devise modules enhance entity embeddings local graph neighbors. The former simply assumes neighbors contribute equally entity embedding, way neighbors always weighted identically. The latter develops idea employing attention mechanism assign different weights neighbors, weights change throughout task relations. Therefore, works assign static weights neighbors, leading static entity representations involved different task relations. We argue entity neighbors could varied impacts associated different task relations. Figure gives example head entity one. In addition, task relations polysemous, also showing different meanings involved different entity pairs. Therefore, reference triples could also make different contributions particular query. Take task relation example. As shown Figure, associates different meanings, e.g., organization-related . Obviously, query , referring organization-related references would beneficial. To address issues, propose \underline{A}daptive \underline{A}ttentional \underline{N}etwork \underline{F}ew-Shot KG completion , novel paradigm takes dynamic properties account entities references. Specifically, given task relation reference/query triples, FAAN proposes adaptive attentional neighbor encoder model entity representations one-hop entity neighbors. Unlike previous neighbor encoder fixed attention map in, allow attention scores dynamically adaptive task relation translation assumption. This capture diverse roles entities varied impacts neighbors. Given enhanced entity representations, FAAN adopts stack Transformer blocks reference/query triples capture multi-meanings task relation. Then, FAAN obtains general reference representation adaptively aggregating references, differentiating contributions different queries. As such, entities references capture fine-grained meanings, render richer representations predictive knowledge acquisition few-shot scenario. The contributions paper three-fold: We propose notion dynamic properties few-shot KG completion, differs previous paradigms studying dynamic nature entities references few-shot scenario. We devise novel adaptive attentional network FAAN learn dynamic representations. An adaptive neighbor encoder used adapt entity representations different tasks. A Transformer encoder attention-based aggregator used adapt reference representations different queries. We evaluate FAAN few-shot link prediction benchmark KGs NELL Wikidata. Experimental results reveal FAAN could achieve new state-of-the-art results different few-shot sizes.","   Few-shot Knowledge Graph閼 completion is a focus of current research, where each task aims at querying閼辩惮nseen facts閼辩郸f a relation given its few-shot reference entity pairs. Recent attempts solve this problem by learning static representations of entities and references, ignoring their dynamic properties, i.e., entities may exhibit diverse roles within task relations, and references may make different contributions to queries. This work proposes an adaptive attentional network for few-shot KG completion by learning adaptive entity and reference representations. Specifically, entities are modeled by an adaptive neighbor encoder to discern their task-oriented roles, while references are modeled by an adaptive query-aware aggregator to differentiate their contributions. Through the attention mechanism, both entities and references can capture their fine-grained semantic meanings, and thus render more expressive representations. This will be more predictive for knowledge acquisition in the few-shot scenario. Evaluation in link prediction on two public datasets shows that our approach achieves new state-of-the-art results with different few-shot sizes. The source code is available at \url{https://github.com/JiaweiSheng/FAAN}."
"Automatic summarization fundamental task Natural Language Processing, aims condense original input shorter version covering salient information continuously studied decades . Recently, online multi-speaker dialogue/meeting become one important ways people communicate daily works. Especially due spread COVID-19 worldwide, people dependent online communication. In paper, focus dialogue summarization, help people quickly grasp core content dialogue without reviewing complex dialogue context. Recent works incorporate additional commonsense knowledge dialogue generation dialogue context representation learning show even though neural models strong learning capabilities, explicit knowledge still improve response generation quality. It dialog system understand conversations better thus respond properly access make full use large-scale commonsense knowledge. However, current dialogue summarization systems ignore exploration commonsense knowledge, may limit performance. In work, examine benefit incorporating commonsense knowledge dialogue summarization task also address question best incorporate information. Figure shows positive example illustrate effectiveness commonsense knowledge dialogue summarization task. Bob asks Tom help car broken down. On one hand, introducing commonsense knowledge according pick car broke down, know Bob expects Tom give lift. On hand, commonsense knowledge serve bridge non-adjacent utterances help model better understanding dialogue. In paper, follow previous setting also use ConceptNet large-scale commonsense knowledge base, difference regard knowledge text heterogeneous data real multi-speaker dialogue. We propose model named Dialogue Heterogeneous Graph Network incorporating commonsense knowledge constructing graph including utterance knowledge nodes. Besides, heterogeneous graph also contains speaker nodes time, proved useful feature dialogue modeling. In particular, equip heterogeneous graph network two additional designed modules. One called message fusion, specially designed utterance nodes better aggregate information speakers knowledge. The one called node embedding, help utterance nodes aware position information. Compared homogeneous graph network related works , claim heterogeneous graph network effectively fuse information contain rich semantics nodes links, thus accurately encode dialogue representation. We conduct experiments SAMSum corpus , large-scale chat summarization corpus. We analyze effectiveness integration knowledge heterogeneity modeling. The human evaluation also shows approach generate abstractive correct summaries. To evaluate whether commonsense knowledge help model better generalize new domain, also perform zero-shot setting experiments Argumentative Dialogue Summary Corpus , debate summarization corpus. In end, give brief summary contributions: We first incorporate commonsense knowledge dialogue summarization task. We propose D-HGN model encode dialogue viewing utterances, knowledge speakers heterogeneous data. Our model outperform various methods."," Abstractive dialogue summarization is the task of capturing the highlights of a dialogue and rewriting them into a concise version. In this paper, we present a novel multi-speaker dialogue summarizer to demonstrate how large-scale commonsense knowledge can facilitate dialogue understanding and summary generation. In detail, we consider utterance and commonsense knowledge as two different types of data and design a Dialogue Heterogeneous Graph Network  for modeling both information. Meanwhile, we also add speakers as heterogeneous nodes to facilitate information flow. Experimental results on the SAMSum dataset show that our model can outperform various methods. We also conduct zero-shot setting experiments on the Argumentative Dialogue Summary Corpus, the results show that our model can better generalized to the new domain."
"%\yy{para 1: problem important, para 2: temporal graph, existing systems, para 3: neural networks, para 4: difficult: lack training data, para 5: do} %\yy{this comment} %\yyc{before correction}{after correction} %The flow time used chain narratives, reason causes effects events, form deeper understanding past, postulate future. Temporal reasoning crucial analyzing interactions among complex events producing coherent interpretations text data . There rich body research use temporal information variety important application domains, including topic detection tracking, information extraction, parsing clinical records , discourse analysis, question answering. %\yy{Aman: Please update cites based quick Google search temporal reasoning/expressions IE/TDT/medical .} %Motivated ubiquity text understanding, undertake task extracting temporal graphs documents. %and rich understanding temporal aspects document helps humans reading comprehension. %Temporal reasoning also plays critical role downstream natural language processing tasks like Graphs natural choice representing temporal ordering among events, nodes individual events, edges capture temporal relationships ``before'', ``after'' ``simultaneous''. Representative work automated extraction graphs textual documents includes early work by~\citet{chambers2009unsupervised}, focus construction event chains collection documents, recent \caevo \cct, extract graph input document instead. These methods focus rule-based statistical sub-modules extract verb-centered events temporal relations among them. %Specifically, given document, system extracts temporal event graph, nodes graph events, edges capture temporal order~ them. %Classical temporal information extraction systems focus one two broad themes relation identification temporal relation classification. %Relation identification task identifying events connected temporal relation. %The task temporal relation involves identifying temporal relationship exists given two events. % For example, sentence I coffee I getting haircut, phrase I expresses fact events drinking coffee getting haircut took place time. %For example, given sentence I coffee I getting haircut, relation identification system would identify events coffee getting haircut. %A temporal relation classification system would determine events happened simultaneously. %Our goal create system perform tasks together end-to-end fashion multiple sentences. %The idea extracting temporal graphs given document new. %Tempeval-3 introduced task specifically end. %The idea extracting events temporal links graph proposed Tempeval-3. %However, evaluation still relied set pre-identified events TimeBank corpus, leading teams focus relation classification. %Despite importance, task received limited attention. %Representative temporal graph extraction systems like \caevo \cct break problem sub-tasks, like event identification relation extraction, employ rule-based statistical systems solve sub-task. %Additionally, use small amounts hand-labeled corpora development, limiting generalizability scalability. As emerging area nlp, large scale pre-trained language models made strides addressing challenging tasks like commonsense knowledge graph completion task-oriented dialog generation. %Besides relying intricate arrangement sub-systems, common shortcomings: i) They either admit lot noisy events ignore events secondary narrative , ii) generate one-word verbs events, without adding context, iii) limited generalization capabilities way relying rules small training corpora. % These systems typically fine-tune large language models like gpt \gptz corpus task-specific dataset. These systems typically fine-tune large language models corpus task-specific dataset. %However, advances benefited temporal graph extraction. However, techniques investigated temporal graph extraction. This paper focuses problem generation event-level temporal graph document, refer task contextualized graph generation. We address open challenge proposing novel reformulation task sequence-to-sequence mapping problem, enables us leverage large pre-trained models task. Further, proposed approach completely end-to-end eliminates need pipeline sub-systems commonly used traditional methods. %This helps approach end-to-end, easier implement, approach prevents error propagation across stages minimizes effort required feature engineering. We also address related open challenge, prerequisite main goal: difficulty obtaining large quantity training graphs human-annotated events temporal relations. %We address second challenge unsupervised approach, i.e., % To end, automatically produce large collection document-graph pairs applying existing information extraction \nlp tools textual documents, followed rule-based post-processing steps pruning noise reduction. Specifically, using \caevo tools, generate large collection 89,000 document/graph pairs. To end, automatically produce large collection document-graph pairs using \caevo, followed rule-based post-processing steps pruning noise reduction. %Specifically, using \caevo tools, generate large collection 89,000 document/graph pairs. %. %which facilitates large-scale fine-tuning well large-scale evaluation new approach comparison competing methods.} %The primary block union remains data-hungry nature large language models; typically require sizeable datasets effective training, popular temporal corpora usually offer tens hundreds hand-labeled documents. %Given large scale pre-trained language models %Despite importance, temporal graph extraction benefited recent advances large scale pre-trained language models, effective %The limitation lie representative capabilities. %Rather, lack training data forms %The lack training data forms biggest bottleneck unification: large scale language models typically require large datasets effective training. Simultaneously, popular temporal corpora usually tens hundreds documents. % bridge gap generating large corpus 89k document-graph pairs task. %We achieve first using \caevo cheap supervision mechanism creating large corpus dense temporal graphs. %Admittedly, data generated \caevo considerable amounts error noise. %We alleviate issues injecting human knowledge \caevo generated data applying several post-processing strategies. % Specifically, remove noisy events relations extracted low confidence, use event clusters map graph correct context. We encode graph training pair string graph representation format \dotlang, transforming text-to-graph mapping sequence-to-sequence mapping. %task. We fine-tune \gptz dataset document-graph pairs, yields large performance gains strong baselines system generated test set outperforms \caevo TimeBank-Dense multiple metrics. Figure 1 shows example input document generated graph system. %While automatic labeling cannot rival human-curation quality, strong experimental results show dataset prepared method provides competitive signal noise ratio virtually zero cost. %allowing strong learners generalize unseen data. %and use masked-language modeling \gptz estimating conditional distribution temporal graphs given document. %Our experiments \gptz show large gains strong baselines dataset outperforms \caevo TimeBank-Dense range metrics. %In process, answer several practical questions selecting salient events, identifying context temporal graph, graph representation, evaluation. %The system trained strong results data outperforming \caevo TimeBank-Dense range metrics. %TODO first %Qualitative analysis nodes generated method shows approach successfully use large training corpus learning generalized patterns temporal relations, error analysis held-out set revealing \caevo fixes labels 10\% cases. % We use \caevo label large corpus documents apply novel pruning techniques top graphs generated \caevo. % These pruning techniques retain high confidence annotations \caevo removing noisy events relations. % Further, context graph automatically discovered using notion event communities, obviating need hardcoded cutoffs typically adopted temporal systems. In summary, main contributions are: %\am{write three contributions: i) annotation pipeline, ii) encoding strings, thus allowing use gpt, iii) strong results data, good result \tbden, dramatic improvements off-the-shelf \gptz} % % File acl2020.tex % %% Based style files ACL 2020, %% Based style files ACL 2018, NAACL 2018/19, %% Based style files ACL-2015, improvements %% taken NAACL-2016 style %% Based style files ACL-2014, were, turn, %% based ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009, %% EACL-2009, IJCNLP-2008... %% Based style files EACL 2006 %%e.agirre@ehu.es Sergi.Balari@uab.es %% ACL 08 Joakim Nivre Noah Smith \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{acl2020} \usepackage{times} \usepackage{latexsym} \renewcommand{\UrlFont}{\ttfamily\small} \usepackage{color} \usepackage{xspace} \usepackage{amsmath} \usepackage{amsfonts} \usepackage{multirow} \usepackage[multiple]{footmisc} \usepackage{array, booktabs, makecell} \usepackage{graphicx} \usepackage{colortbl} \usepackage{xcolor} \setlength{\textfloatsep}{0.1cm} % This strictly necessary, may commented out, % improve layout manuscript, % typically save space. \usepackage{microtype} %\aclfinalcopy % Uncomment line final submission %\def\aclpaperid{***} % Enter acl Paper ID %\setlength\titlebox{5cm} % You expand titlebox need extra space % show authors. Please make titlebox % smaller 5cm ; check % camera-ready version ask change back. \newcommand\BibTeX{Bib\TeX} \title{Neural Language Modeling Contextualized Temporal Graph Generation} \aclfinalcopy \author{Aman Madaan, Yiming Yang \\ Language Technologies Institute, Carnegie Mellon University \\ Pittsburgh, PA, USA \\ \\} \date{}"," This paper presents the first study on using large-scale pre-trained language models for automated generation of an event-level temporal graph for a document. Despite the huge success of neural pre-training methods in NLP tasks, its potential for temporal reasoning over event graphs has not been sufficiently explored. Part of the reason is the difficulty in obtaining large training corpora with human-annotated events and temporal links. We address this challenge by using existing IE/NLP tools to automatically generate a large quantity  of system-produced document-graph pairs, and propose a novel formulation of the contextualized graph generation problem as a sequence-to-sequence mapping task. These strategies enable us to leverage and fine-tune pre-trained language models on the system-induced training data for the graph generation task. Our experiments show that our approach is highly effective in generating structurally and semantically valid graphs. Further, evaluation on a challenging hand-labeled, out-domain corpus shows that our method outperforms the closest existing method by a large margin on several metrics.\footnote{Code and pre-trained models available at}"
"Building dialog systems typically requires large collection conversation logs model use training data. Crowd-sourcing popular method generating data-sets depending aspect dialog modeling studied, crowd-sourced workers may asked annotate existing chat logs intents dialog acts, create dialog summaries, converse based script converse accomplish tasks goals etc. For instance, create datasets task oriented dialogs, crowd-sourced workers may provided goal describes task needs accomplished; workers play roles user agent generate conversations . % plays role user. The user worker begins conversation stating requirement agent worker provides information user querying knowledge base , required. Together, two workers interact via natural language generate conversations involve booking restaurant tables, making train reservations, calling taxi etc. However, creating large crowd-sourced datasets time consuming expensive."," Popular task-oriented dialog data sets such as MultiWOZ \cite{Multiwoz} are created by providing crowd-sourced workers a goal instruction, expressed in natural language, that describes the task to be accomplished. Crowd-sourced workers play the role of a user and an agent to generate dialogs to accomplish tasks involving booking restaurant tables, making train reservations, calling a taxi etc. However, creating large crowd-sourced datasets can be time consuming and expensive. To reduce the cost associated with generating such dialog datasets, recent work has explored methods to automatically create larger datasets from small samples.  %Popular dialog data sets such as MultiWoz \cite{Multiwoz} are created by providing crowd-sourced workers a goal instruction, expressed in natural language, which described the task that needed to be accomplished. Crowd-sourced workers played the role of a user and an agent to generate dialogs that can involve booking restaurant tables, making train reservations, calling a taxi etc.  In this paper, we present a data creation strategy that uses the pre-trained language model, GPT2 \cite{GPT2}, to simulate the interaction between crowd-sourced workers by creating a user bot and an agent bot.  We train the simulators using a smaller percentage of actual crowd-generated conversations and their corresponding goal instructions. We demonstrate that by using the simulated data, we achieve significant improvements in both low-resource setting as well as in overall task performance. To the best of our knowledge we are the first to present a model %this is the first model proposed  for generating entire conversations by simulating the crowd-sourced data collection process. %To the best of our knowledge we are the first to use inter-bot conversation logs to improve the performance of task oriented dialog systems."
"Multilingual machine translation , serve multiple language pairs single model, attracted much attention. In contrast bilingual MT systems serve one single language pair, multilingual models serve language pairs . The amount available training data differ lot across language pairs majority available MT training data English-centric practice means non-English language pairs see single training example training multilingual models . As consequence, actual performance language pairs include English source target side lags behind ones large amounts training data. Further, increasing number languages, gets impractical gather training data language pair challenging find right mix training. Which models tasked direct translation non-English pairs either resort bridging pivot language , make use synthetic parallel data study problem zero-shot settings . In study, make use potential pre-existing multi-way property training corpora generate many direct training examples pre-existing English-centric training data. If find training examples language pair multilingual mix, call model complete Multilingual Neural Machine Translation . cMNMT trained bilingual pairs source target languages utilizing multi-way aligned training examples consist translations sentence multiple languages. We resurface multi-way aligned training examples aligning training examples different language pairs either source target sides identical . To make use data, model samples source target language set multi-way aligned corpus training, allows model see language pairs originally training data existed . As experiments support, method enables us get access training data tested language pairs ). We show possible generate complete graph least 6-language WMT setup. Some WMT training data multi-way parallel construction. Nevertheless, show also find many training examples source target origin different sources. We show 112 languages internal dataset, find sufficient training data 12,000 language pairs providing 111 English-centric training corpora. This result indicates possible generate direct training data many language pairs without need crawling new training examples. Our experiments suggest falling back methods like zero-shot translation, investigate structure pre-existing training data. To address problem finding right mix examples different language pairs training, introduce hierarchical sampling strategy language-specific . In addition fixing chronic issues MNMT , proposed sampling strategy efficiently ensures source-target pairs covered. Experiments demonstrate train cMNMT model 30-language-pair WMT setup outperforms bilingual multilingual baselines well bridging non-English language pairs. We show performance English language pairs stay stable suffer changes training data new training data sampling strategy. Furthermore, share experiments scale demonstrating train cMNMT model serve 12,432 language pairs. Our contribution three-fold:"," Multilingual Neural Machine Translation  models are commonly trained on a joint set of bilingual corpora which is acutely English-centric . While direct data between two languages that are non-English is explicitly available at times, its use is not common. In this paper, we first take a step back and look at the commonly used bilingual corpora , and resurface the existence and importance of implicit structure that existed in it: multi-way alignment across examples . We set out to study the use of multi-way aligned examples to enrich the original English-centric parallel corpora. We reintroduce this direct parallel data from multi-way aligned corpora between all source and target languages. By doing so, the English-centric graph expands into a complete graph, every language pair being connected. We call MNMT with such connectivity pattern complete Multilingual Neural Machine Translation  and demonstrate its utility and efficacy with a series of experiments and analysis. In combination with a novel training data sampling strategy that is conditioned on the target language only, cMNMT yields competitive translation quality for all language pairs. We further study the size effect of multi-way aligned data, its transfer learning capabilities and how it eases adding a new language in MNMT. Finally, we stress test cMNMT at scale and demonstrate that we can train a cMNMT model with up to 111$*$112=12,432 language pairs that provides competitive translation quality for all language pairs."
"Machine Translation shown impressive progress recent years. Neural architectures greatly contributed improvement, especially languages abundant training data. This progress creates novel challenges evaluation machine translation, human automated evaluation protocols. Both types evaluation play important role machine translation. While human evaluations provide gold standard evaluation, involve fair amount careful hence expensive work human assessors. Cost therefore limits scale application. On hand, automated evaluations much less expensive. They typically involve human labor collecting human reference translations hence run scale compare wide range systems validate design decisions. The value automatic evaluations therefore resides capacity used proxy human evaluations large scale comparisons system development. The recent progress MT raised concerns whether automated evaluation methodologies reliably reflect human ratings high accuracy ranges. In particular, observed best systems according humans might fare less well automated metrics. Most metrics \BLEU TER measure overlap system output human reference translation. More refined ways compute overlap consequently proposed. Orthogonal work building improved metrics, hypothesized human references also important factor reliability automated evaluations. In particular, observed standard references exhibit simple, monotonic language due human `translationese` effects. These standard references might favor systems excel reproducing effects, independent underlying translation quality. They showed better correlation human automated evaluations could obtained replacing standard references paraphrased references, even still using surface overlap metrics BLEU~. The novel references, collected asking linguists paraphrase standard references, shown steer evaluation away rewarding translation artifacts. This improves assessment alternative, equally good translations. Our work builds success paraphrased translations evaluating existing systems, asks different design choices could made designing system evaluation protocol mind. This examination several potential benefits: help identify choices improve BLEU standard references limited impact final human evaluations; result better translations human reader, worse terms standard reference BLEU. Conversely, might turn paraphrased references robust enough support system development due presence `metric honeypots': settings produce poor translations, nevertheless assigned high BLEU scores. To address points, revisit major design choices best EnglishGerman system WMT2019 step-by-step, measure impact standard reference BLEU well paraphrased BLEU. This allows us measure extent steps data cleaning, back-translation, fine-tuning, ensemble decoding reranking benefit standard reference BLEU paraphrase BLEU. Revisiting development choices two metrics results two systems quite different behaviors. We conduct human evaluation adequacy fluency assess overall impact designing system using paraphrased BLEU. Our main findings show optimizing paraphrased BLEU advantageous human evaluation compared identical system optimized standard BLEU. The system optimized paraphrased BLEU significantly improves WMT newstest19 adequacy ratings fluency ratings despite scoring 5 BLEU points lower standard references.","  Automatic evaluation comparing candidate translations to human-generated paraphrases of reference translations has recently been proposed by \newcite{freitag2020bleu}. When used in place of original references, the paraphrased versions produce metric scores that correlate better with human judgment. This effect holds for a variety of different automatic metrics, and tends to favor natural formulations over more literal  ones. In this paper we compare the results of performing end-to-end system development using standard and paraphrased references. With state-of-the-art English-German NMT components, we show that tuning to paraphrased references produces a system that is significantly better according to human judgment, but 5 BLEU points worse when tested on standard references. Our work confirms the finding that paraphrased references yield metric scores that correlate better with human judgment, and demonstrates for the first time that using these scores for system development can lead to significant improvements."
"% % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % Machine Reading Comprehension made significant strides array neural models rapidly approaching human parity benchmarks SQuAD . However, existing methods still infancy level cognitive intelligence. Recently, brain science psychology provide important basis development brain-like computing simulation human perception, thinking, understanding, reasoning abilities . Thinking generalization indirect reflection human brain nature, interrelationships internal regularities objective things . Two types thinking complementary psychology: inertial thinking 閳 previous subsequent stimulus 閳 reverse thinking 閳 subsequent previous stimulus . Inertial thinking conventional way thinking, thinks solves problems previous ideas. % It likely form stereotyped thinking, hinder development thinking, may even lead rigidity thinking using single way long time. Reverse thinking creative way thinking, opposite inertial thinking. % It often break conventional constraints obtain greater innovation . Specifically, MRC task, two types thinking regarded process reasons questions answers . For example, shown Fig. , get answer easily locating entities pregnant wowen loquat. Contrarily, generative question, reasoned reading answer passage, describes two aspects, including pregnant women eat loquat benefit eat loquat pregnant women. We hope ability reverse reasoning improve performance reading comprehension tasks. Previous methods consider obverse logical relationship, based given question passage. They ignore reverse relationship given passage answer. Although work proposes joint model asks answers questions, couples knowledge rather decopuling modules, consistent concept psychology. Similarly, hypothesize ability reverse reasoning help models achieve better QA performance. This motivated partly observations made psychology devising questions reading % increase scores comprehension tests.It help students improve reader-based processing text . %In real world, fast learning trick peek answer first. In words, humans often begin answers passages encounter unsolvable problems. %% Then attempt understand answer like this. %Then inadvertently infer question based answer passage reverse side. Obtaining answer advance equivalent giving strong supervision signal additional clues directly exist passage may require reasoning. This kind psychological behavior humans actually way reverse thinking, considers problem opposite direction infers reason based conclusion . Therefore, insights solutions problem gained human cognitive processes. Complementary Learning Systems Theory suggests human brain contains complementary learning systems support simultaneous use many sources information seek understand experienced situation. One systems acquires integrated system knowledge gradually interleaved learning, including knowledge meanings words, properties frequently-encountered objects, characteristics familiar situations. It like inertial thinking learns relationships different things real world long time. The system fast learning system similar reverse thinking, targeted focus stimulating enhancing infrequently-utilized circuit areas brain another unusual perspective. In paper, propose Bi-directional Cognitive Knowledge Framework . And corresponding Bi-directional Cognitive Thinking Network designed validate effectiveness reverse thinking, shown Fig., introduced detail Section . % explain framework % % In paper, proposed method ... simulates process fast learning. % % The gray ovals form embedding specific information % In order validate effectiveness reverse thinking, proposed Cognitive Bi-directional Thinking Network corresponding Cognitive Bi-directional Thinking Framework, introduced detail Section . The contributions summarized follows:"," 		We propose a novel Bi-directional Cognitive Knowledge Framework  for reading comprehension from the perspective of complementary learning systems theory. It aims to simulate two ways of thinking in the brain to answer questions, including reverse thinking and inertial thinking. To validate the effectiveness of our framework, we design a corresponding Bi-directional Cognitive Thinking Network  to encode the passage and generate a question  given an answer  and decouple the bi-directional knowledge. The model has the ability to reverse reasoning questions which can assist inertial thinking to generate more accurate answers. Competitive improvement is observed in DuReader dataset, confirming our hypothesis that bi-directional knowledge helps the QA task. The novel framework shows an interesting perspective on machine reading comprehension and cognitive science."
"% Demonstrating intelligent behavior complex environments requires agents reason entities relationships, identify regularities structured data help predict properties-of relationships-between entities. % Understanding natural language realistic settings requires models reason interactions content context, model dependencies different textual elements leverage information authors interpreting content. For example, analyzing interactions social network, leveraging information users' social behavior help identify similarities contents posts author. Dealing type relational data requires making predictions multiple, often inter-dependent, variables. Understanding natural language interactions realistic settings requires models deal noisy textual inputs, reason dependencies different textual elements leverage dependencies textual content context emerges. Work linguistics anthropology defined context frame surrounds focal communicative event provides resources interpretation . %\citealt{contextualization-92} introduced term contextualization cues signalling mechanisms communication add shared understanding participants, relationships, situation, environment conversation %Say something debate networks add references. As motivating example, consider interactions debate network described Fig.. Given debate claim , two consecutive posts debating , define textual inference task, determining whether pair text elements hold stance debate }). This task similar textual inference tasks successfully approached using complex neural representations. In addition, leverage dependencies decisions. For example, assuming one post agrees debate claim }}), one }}), disagreement two posts inferred: {\small \PRED{\neg Agree\wedge Agree \rightarrow \neg Agree}}. Finally, consider social context text. The disagreement posts reflect difference perspectives authors hold issue. While information might directly observed, inferred using authors' social interactions behavior. % Given principle social homophily, stating people strong social ties likely hold similar views authors' perspectives captured representing social interactions. Exploiting information requires models align social representation linguistic one. Motivated challenges, introduce \DRAIL, Deep Relational Learning framework, uses combined neuro-symbolic representation modeling interaction multiple decisions relational domains. Similar neuro-symbolic approaches goal exploit complementary strengths two modeling paradigms. Symbolic representations, used logic-based systems probabilistic graphical models, interpretable, allow domain experts directly inject knowledge constrain learning problem. Neural models capture dependencies using network architecture better equipped deal noisy data, text. However, often difficult interpret constrain according domain knowledge. Our main design goal \DRAIL provide generalized tool, specifically designed NLP tasks. Existing approaches designed classic relational learning tasks, knowledge graph completion, equipped deal complex linguistic input. While others designed specific NLP settings word-based quantitative reasoning problems aligning images text. We discuss differences \DRAIL approaches Section. % While examples paper focus modelings various argumentation mining tasks social political context, principles applied wide array NLP tasks different contextualizing information, images appear next text, prosody analyzing transcribed speech, name examples. %TODO: explain DRAIL specifically useful NLP compared languages. We type evaluation interested working raw entities. % Entities \DRAIL either human-interpretable discrete entities , refer symbols, raw entities complex internal structure cannot easily represented symbol . This view allows us define two conceptual learning tasks: relations connecting raw symbolic entities }}), relations connecting raw inputs other, define inference tasks }}). % \DRAIL uses declarative language defining deep relational models. Similar declarative languages, allows users inject knowledge specifying dependencies decisions using first-order logic rules, later compiled factor graph neural potentials. % In addition probabilistic inference, \DRAIL also models dependencies using distributed knowledge representation, denoted \relnets, provides shared representation space entities relations, trained using relational multi-task learning approach. This provides mechanism explaining symbols, aligning representations different modalities. %Introduce s-s, r-r, s-r, distinction way support classification, textual inference, probabilistic inference. Following running example, ideological standpoints, \PRED{Liberal} \PRED{Conservative}, discrete entities embedded space textual entities social entities. These entities initially associated users, however using \relnets information propagate texts reflecting ideologies, exploiting relations bridge social linguistic information . % In resulting shared embedding space, explain ideological standpoints terms users holding them, texts express them.%}). %TODO: research questions %TODO - explain difference task DRAIL's perspective - argument relations inside single text, analyzing discussions - simple case, discussed literature, predict symbol , debate.org setup combine textual inference soclia linfo To demonstrate \DRAIL's modeling approach, introduce task open-domain stance prediction social context, combines social networks analysis textual inference complex opinionated texts, shown Fig. . %Unlike traditional stance prediction tasks, prediction problem defined fixed set issues ~ , go beyond coarse-grained definitions, delve specific arguments questions discussion, shown Fig. . We follow intuition debates part broader online conversation, involving multiple people contribute express support different views, explicitly model interactions. % AugensteinD16-1084,P18-2123,C18-1316} %TODO: add discussion qualitative evaluation % We complement evaluation \DRAIL two additional tasks, issue-specific stance prediction, identify views expressed debate forums respect set fixed issues, argumentation mining, document-level discourse analysis task. %We demonstrate \DRAIL's modeling approach three challenging problems. Argumentation mining, document-level discourse analysis task. Debate stance prediction, identifying views expressed-in, interactions-between, debate forum posts. Finally, introduce new problem, open-domain stance prediction social context, combines social networks analysis textual inference complex opinionated texts. In three tasks evaluate different modeling choices, obtaining competitive results. %TODO: contributions %Our contributions summarized follows: % % %Unrealted TODO: add discussion globally normalized RELNETs- constraints multiple objectives shape them. %homophily, %, This phenomenon previously used help overcome language variation issues % political-social representations %network embedding:we learn graph embedding, different way define social context %graphical models way"," Building models for realistic natural language tasks requires dealing with long texts and accounting for complicated structural dependencies. Neural-symbolic representations have emerged as a way to combine the reasoning capabilities of symbolic methods, with the expressiveness of neural networks. However, most of the existing frameworks for combining neural and symbolic representations have been designed for classic relational learning tasks that work over a universe of symbolic entities and relations. In this paper, we present \DRAIL, an open-source declarative framework for specifying deep relational models, designed to support a variety of NLP scenarios. Our framework supports easy integration with expressive language encoders, and provides an interface to study the interactions between representation, inference and learning."
"End-to-end neural models emerged recent years dominant approach wide variety sequence generation tasks natural language processing, including speech recognition, machine translation, dialog generation, among many others. While highly accurate, models typically operate outputting tokens predetermined symbolic vocabulary, require integration larger pipelines use user-facing applications voice assistants neither input output modality text. In speech domain, neural methods recently successfully applied end-to-end speech translation , goal translate directly speech one language speech another language. We propose study analogous problem in-image machine translation. Specifically, image containing text one language transformed image containing text another language, removing dependency predetermined symbolic vocabulary processing. \paragraph{Why In-Image Neural Machine Translation ?} In-image neural machine translation compelling test-bed research engineering communities variety reasons. Although existing commercial products address problem image translation feature Google Translate underlying technical solutions unknown. By leveraging large amounts data compute, end-to-end neural system could potentially improve overall quality pipelined approaches image translation. \iffalse First, existing commercial products address problem image translation feature Google Translate employ traditional pipelined approach consisting separate optical character recognition, translation, image rendering steps.\todo{orhanf check mobile team. Elman: commented suggested mobile wordlens team. technical solution wordlens publicly available hence sentence bit speculative} Combining components single end-to-end neural system could help reduce cascading errors improve overall translation quality, leveraging large amounts data compute. \fi Second, arguably importantly, working directly pixels potential sidestep issues related vocabularies, segmentation, tokenization, allowing possibility universal approaches neural machine translation, unifying input output spaces via pixels. Text preprocessing vocabulary construction active research area leading work investigating neural machine translation systems operating subword units , characters even bytes highlighted one major challenges dealing many languages simultaneously multilingual machine translation , cross-lingual natural language understanding . Pixels serve straightforward way share vocabulary among languages expense significantly harder learning task underlying models. In work, propose end-to-end neural approach in-image machine translation combines elements recent neural approaches relevant sub-tasks end-to-end differentiable manner. We provide initial problem definition demonstrate promising first qualitative results using pixel-level supervision target side. We analyze errors made models, process uncover common deficiency suggests path forward future work."," In this paper, we offer a preliminary investigation into the task of in-image machine translation: transforming an image containing text in one language into an image containing the same text in another language. We propose an end-to-end neural model for this task inspired by recent approaches to neural machine translation, and demonstrate promising initial results based purely on pixel-level supervision. We then offer a quantitative and qualitative evaluation of our system outputs and discuss some common failure modes. Finally, we conclude with directions for future work."
"Transformer based models proven effective building state-of-the-art Neural Machine Translation systems via neural networks attention mechanism . Following standard Sequence-to-Sequence architecture, Transformer models consist two essential components, namely encoder decoder, rely stacking several identical layers, i.e., multihead attentions position-wise feed-forward network. Multihead attentions position-wise feed-forward network, together basic unit, plays essential role success Transformer models. Some researchers propose improve model capacity stacking basic unit many times, i.e., deep Transformers, achieve promising results. Nevertheless, orthogonal direction, investigation multiple parallel units draws little attention. Compared single unit models, multiple parallel unit layout expressive capture complex information flow two aspects. First, multiple-unit layout boosts model varied feature space composition different attentions inputs. With diversity, multi-unit models advance expressiveness. Second, multi-unit setting, one unit could mitigate deficiency units compose expressive network, complementary way. In paper, propose Multi-Unit TransformErs , aim promote expressiveness transformer models introducing diverse complementary parallel units. Merely combining multiple identical units parallel improves model capability diversity varied feature compositions. Furthermore, inspired well-studied bagging gradient boosting algorithms machine learning field, design biased units sequential dependency boost model performance. Specifically, help module named bias module, apply different kinds noises form biased inputs corresponding units. By so, explicitly establish information gaps among units guide learn other. Moreover, better leverage power complementariness, introduce sequential ordering multi-unit setting, % learning permutaion matrix automatically shuffle outputs multiple units, force unit learn residual preceding accumulation. We evaluate methods three widely used Neural Machine Translation datasets, NIST Chinese-English, WMT'14 English-German WMT'18 Chinese-English. Experimental results show multi-unit model yields improvement +1.52, +1.90 +1.10 BLEU points, baseline model three tasks different sizes, respectively. Our model even outperforms Transformer-Big WMT'14 English-German 0.7 BLEU points 54\% parameters. Moreover, interesting side effect, model introduces mild inference speed decrease compared Transformer-Base model, faster Transformer-Big model. % proves practicability methods. The contributions paper threefold:","     Transformer models \cite{vaswani2017attention} achieve remarkable success in Neural Machine Translation.      Many efforts have been devoted to deepening the Transformer by stacking several units  in a cascade,      while the investigation over multiple parallel units draws little attention.     In this paper, we propose the Multi-Unit TransformErs , which aim to promote the expressiveness of the Transformer by introducing diverse and complementary units.     Specifically, we use several parallel units and show that modeling with multiple units improves model performance and introduces diversity.      Further, to better leverage the advantage of the multi-unit setting, we design biased module and sequential dependency that guide and encourage complementariness among different units.      % need more results and exciting data.     Experimental results on three machine translation tasks, the NIST Chinese-to-English, WMT'14 English-to-German and WMT'18 Chinese-to-English, show that the MUTE models significantly outperform the Transformer-Base, by up to +1.52, +1.90 and +1.10 BLEU points, with only a mild drop in inference speed .      In addition, our methods also surpass the Transformer-Big model, with only 54\% of its parameters. These results demonstrate the effectiveness of the MUTE, as well as its efficiency in both the inference process and parameter usage. \footnote{Code is available at \url{https://github.com/ElliottYan/Multi\_Unit\_Transformer}}"
"% % Prior work primarily focused exploiting visual patterns using carefully crafted features . These rendering-based methods two major drawbacks: 1) expensive since require downloading external files including CSS, javascript, images render page compute visual features; 2) require carefully crafted heuristics around visual proximity work well expensive features. In paper, propose novel two-stage neural architecture, named FreeDOM, trained small number seed websites generalize well unseen websites without requiring hand-engineered visual features. %we want employ neural networks learning transferable visual features eliminate need rendering human engagement crafting textual patterns. %We propose novel two-stage neural architecture directly learn annotated websites based raw HTML content transfer models unseen websites without using human labels . %We parse HTML documents DOM Trees page classifies one target fields. This node-level module combines neighboring character sequences, token sequences, well markup learn combined representation node. We propose combination CNNs LSTMs show effectively encode useful features DOM nodes. These node representations encoded individually inevitably lose global information useful extraction task. In particular, relying local node features cause failure value nodes obvious patterns local features similar non-value nodes. To mimic signal may available visual features used rendering-based methods, use relational neural network second module . This allows us model relationship pair elements using distance-based semantic features. The rationale behind learn global representations node pairs jointly predict node labels instead relying local features. Extensive experimental results large-scale public dataset, Structured Web Data Extraction corpus, show model consistently outperforms competitive baseline methods large margin. The proposed FreeDOM able generalize unseen sites training small number seed sites. In fact, show training data three seed sites, approach out-performs techniques use explicit visual rendering features 3.7 F1 points average. To best knowledge, framework among first neural architectures efficiently obtains high-quality representations web documents structured information extraction. \eat{Our framework utilizes minimal human efforts feature engineering require rendering results, thus making large-scale information extraction web documents much easier effort-light. We believe proposed model promising applications require neural representations web documents.} %The node-level module predict node labels identifying values interested fields, encoded local features cannot capture long-range dependencies values thus degenerate unlabeled target websites. %To address problem, propose relational neural network. %As second-stage module, explicitly models relations DOM nodes effectively learns page-level constraints producing structured predictions. % models relational features reflected node pairs, finally conducts structured data extraction structured prediction problem. %Our contributions paper three-fold: %% %} %Our contribution propose novel neural model, FreeDom, structured data extraction web documents using less information hand-crafted features. Extensive experiments large-scale public data set show proposed FreeDom outperforms strong baseline methods using raw features. %%ying{The last sentence looks complete. \yuchen{Done.}} %\tata{Don't say 'less information' emphasize requiring visual rendering cheaper requiring hand-crafted features means generalize new tasks better. Need make claim focused contributions clear. We also need spell two stages clearly 'First stage blah', 'Second stage blah'} %\tata{Might worth adding entity resolution scope work -- ie, might extract duplicate entries across websites car. There many papers dealing we're focused paper.} %"," % tata: Jan 26 rewrite of Abstract.  Extracting structured data from HTML documents is a long-studied problem with a broad range of applications like augmenting knowledge bases, supporting faceted search, and providing domain-specific experiences for key verticals like shopping and movies. Previous approaches have either required a small number of examples for each target site or relied on carefully handcrafted heuristics built over visual renderings of websites. In this paper, we present a novel two-stage neural approach, named FreeDOM, which overcomes both these limitations.  The first stage learns a representation for each DOM node in the page by combining both the text and markup information. The second stage captures longer range distance  and semantic relatedness using a relational neural network. By combining these stages, FreeDOM is able to generalize to unseen sites after training on a small number of seed sites from that vertical without requiring expensive hand-crafted features over visual renderings of the page. Through experiments on a public dataset with 8 different verticals, we show that FreeDOM beats the previous state of the art by nearly 3.7 F1 points on average without requiring features over rendered pages or expensive hand-crafted features. % 3.7 is from Table 2 k=3 .  % tata: Previous version of abstract follows:  %"
"Data-to-Text aims generating natural language descriptions structured data ; fostered recent advances neural approaches %for data-to-text made possible emergence large scale datasets made pairs . Figure illustrates example WikiBIO dataset . These datasets either hand-crafted via crowdworkers automatically built aligning sources found Internet. As such, %training examples imperfect reference texts might include divergences two types, limiting ability generation models produce realistic descriptions. First, reference texts might contain information grounded source data; especially automatically constructed datasets, references written source-data description task mind. For instance, phrase ``who served lieutenant [...]'' Figure basis associated infobox. Second, reference texts always cover entirety table . In settings, second point referred content selection inherent data-to-text tasks. % part normal subtask flow data-to-text. %; see example Figure information wars. %However, hand-crafted datasets designed annotators asked transcribe every fields, systems also expected same. In case, incomplete references lead models fail learn transcribe information, partially cover data-sources inference. However, hand-crafted datasets designed annotators asked transcribe every fields, models also expected same. In case, incomplete references lead models failing learn transcribe information, partially cover data-sources inference. Divergence training examples leads hallucinated/omitted content model output; well-known problem neural approaches text generation . This problem arises training procedure , testing protocols. Indeed, current standard metrics measure similarity ground truth reference texts fully capture relevance source data. %Indeed, evaluation metrics work computing precision n-grams contained generated sentence w.r.t ground truth description. Thus, distinction mismatch caused paraphrase, poor lexicalization content, made-up/incorrect statement, leading imperfect model selection. While number work argue need novel automatic evaluation method , best knowledge \citet{wiseman2017} \citet{dhingra2019} propose metrics based reference source data. %Additionally, \citet{dhingra2019} show proposed metric PARENT correlates strongly human evaluation metric, easier use box. Recently, different regularization methods also proposed mitigate negative influence divergences reference texts. These approaches either dataset level , authors propose techniques clean/standardize instances; training level , authors propose novel neural modules designed limit hallucinations/omissions. However, approaches severely limited: e.g., require significant annotation labor, model-specific tricks and/or manual tuning. Furthermore, virtually proposed neural approaches still suffer 1)~exposure bias 2)~inconsistency train/test measurement. Indeed, current neural models trained via mechanism called teacher forcing , decoder fed previous correct token, matter actual prediction~, order maximize log-likelihood target sentence , evaluated previously discussed n-gram metrics~. See Section detailed discussion subject.\\ %On one hand, controllable approaches proposed: example, \citet{Liu2019hier} train hierarchical encoder-decoder three auxiliary tasks meant guide decoding process, order achieve descriptions higher fidelity respect conditioning input. To best knowledge, approaches focused training procedure. %We cite , \citet{liu2019} train hierarchical encoder-decoder three auxiliary tasks meant guide decoding process. %, order achieve descriptions higher fidelity respect conditioning input. Closest work, \citet{Liu2019b} propose novel neural module constrained attention, along reinforcement learning training procedure based BLEU TFIDF. In work, remedy shortcomings building upon work \citet{Liu2019b}, show novel neural module necessary handle hallucinations omissions. We propose model-agnostic RL framework, called PARENTing, pretrained models trained self-critical policy gradient algorithm limit impact divergences training examples text generation. Specifically, use PARENT metric exhibits strong correlation human evaluation, easier use box. We provide extensive automatic evaluations two data-to-text model families two widely used benchmarks , well focused human evaluation %to high-light differences several training procedures WikiBIO. We report new state art PARENT scores datasets BLEU scores par previous SOTA approaches, shows framework efficiently reduces pathological behaviors keeping generation fluent. %To remedy shortcomings, propose model-agnostic reinforcement learning framework, called PARENTing, pretrained models trained self-critical policy gradient algorithm limit impact divergences training examples text generation. % inspired recent advancements text generation fields. %Specifically, %we fine-tune pretrained models self-critical policy gradient algorithm based %we use PARENT metric exhibits strong correlation human evaluation, easier use box. We provide extensive evaluations two data-to-text model families two widely used benchmarks . We report new state art PARENT scores datasets BLEU scores par previous approaches, shows framework efficiently reduces pathological behaviors keeping generation fluent. %In following, first review Section data-to-text approaches well recent attempts controlling hallucinations/omissions. We introduce Section model-agnostic framework limiting hallucinations/omissions generation. The evaluation protocol presented Section, followed obtained results . Section concludes paper presents perspectives. %In following, first present state-of-the art attempts reduce hallucinations address exposure bias inconsistencies train/test measurement data-to-text literature . revoir la structure We describe details PARENT metric \citet{dhingra2019} Section proposed RL training framework Section. The evaluation protocol presented Section, followed results . Section concludes paper presents perspectives.","  %The effectiveness of language generation models conditioned by structured data is inherently due to the quality of reference texts and the training protocol. First, these reference texts often diverge from the information contained in the associated source data . Second,  In language generation models conditioned by structured data, the classical training  via maximum likelihood almost always leads  models to pick up on dataset divergence , and to incorporate them erroneously in their own generations at inference.  %In this work, we propose a model-agnostic reinforcement learning framework in order to reduce hallucinations and omissions. To do so, we rely on the recently introduced PARENT metric assessing the adequacy of a candidate generation with both the human reference and the source data.  In this work, we build ontop of previous Reinforcement Learning based approaches and show that a model-agnostic framework relying on the recently introduced PARENT metric is efficient at reducing both hallucinations and omissions. Evaluations on the widely used WikiBIO and WebNLG benchmarks demonstrate the effectiveness of this framework compared to state-of-the-art models."
"Relation classification aims identify relation two specified entities sentence. Previous supervised approaches task heavily depend human-annotated data, limit performance classifying relations insufficient instances. Therefore, making RC models capable identifying relations training instances becomes crucial challenge. Inspired success few-shot learning methods computer vision community , first introduce few-shot learning RC task propose FewRel % dataset. % dataset benchmark. Recently, many works focus task achieve remarkable performance . %distant supervision proposed automatically construct training instances RC. %However, dataset extracted distant supervision, long-tail relations instances suffer data sparsity problem. %Inspired success few-shot learning methods computer vision community, e.g., Matching Network , Relation Network Memory-augmented network , first introduce FSL RC tackle long tail problem. They use Prototypical Network , achieves state-of-the-art performance several FSL benchmarks. Recently, many works followed framework achieved remarkable performance Few-shot RC dataset FewRel . %The prototypical network learns representation relation based sampled instances, classifies queries set pre-defined relations. %\CheckedBox % Even though existing works perform well, assume one relation sentence. Previous few-shot relation classifiers perform well sentences one relation single entity pair. However, real natural language, sentence usually jointly describes multiple relations different entity pairs. Since relations usually keep high co-occurrence context, previous few-shot RC models struggle distinguish annotated instances. For example, Table shows three instances FewRel dataset, sentence describes multiple relations corresponding keyphrases highlighted evidence. When specified two entities sentence, great opportunity instance incorrectly categorized {\color{red}{confusing relation}} instead {\color{blue}{true relation}} . % % Specifically, %is different entity pairs usually described input sentence, relation classification entity pairs often interferes other. %This results entity pairs relations often misclassified confusing relations models without ability explicitly decoupling easily-confused relations. %Table shows three instances FewRel dataset , contains sentence two given entities right side, positive confusing relations left side. %Previous few-shot methods tend misclassify sentences confusing relations. first instance categorized true relation `parents-child' based given entity pair natural language expression `a daughter of'. However, since also includes NL expression `his wife', %which describes confusing relation `husband-wife', probably misclassified confusing relation `husband-wife'. In paper, name relation confusion problem. %=============================================================================================== % \verb|\checkmark|: \checkmark \par % \verb|\cmark|: \cmark \par % \verb|\xmark|: \xmark {blue}} {\color{red}{red}} words respectively correspond true confusing relations.} \end{table} %============================================================================================== To address relation confusion problem, crucial model % effectively select information high relevance given entity pair aware NL expressions cause confusion learn avoid mapping instance easily-confused relation. % To address relation confusion problem, crucial model aware NL expressions cause confusion explicitly distinguish easily-confused relations. From perspectives, propose two assumptions. Firstly, sentence, words keep high relevance given entities important expressing true relation. Intuitively, specified entity information crucial identify true relations. Secondly, explicitly learning mapping instance confusing relation augmented data turn boosts few-shot RC model identifying true relation. % allowing model explicitly learn confusing relations help identify true relations. %Intuitively, specific entities information helpful identify positive relation. Based assumptions, propose CTEG, few-shot RC model two novel mechanisms: An Entity-Guided Attention encoder, leverages syntactic relations relative positions word specified entity pair softly select important information words expressing true relation filter information causing confusion. A Confusion-Aware Training method, explicitly learns distinguish relations playing pushing-away game classifying sentence true relation confusing relation. %has ability explicitly learning distinguish easily-confused relations. In addition, inspired success pre-trained language models, approaches based BERT , proved effective especially few-shot learning tasks. %=========================================================================== % Specifically, encoding sentence attention mechanism, EGA guides calculation attention score multiply entity-aware gate. %we adopt transformer incorporating self-attention mechanism encoding input instance, Specifically, backbone encoder model transformer equipped proposed EGA guides calculation self-attention distributions weighting attention logits entity-guided gates. % The gate matrix relevance scores, used measure importance word according relevance entities. % The gates used measure importance word according relevance entities. The gates used measure relevance word given two entities. % Two types position information words used calculate scores. One relative position , relative distance word entity sentence squence. Two types information word used calculate gate. % One relative position , relative distance word entity sentence squence. One relative position information, relative distance word entity input sequence. The syntactic relation proposed paper, defined dependency relations word entities. % Besides, propose syntax position, defined dependency relations word entities. Based information, entity-guided gates EGA able select important words control contribution word self-attention. % Based information, entity-aware gate EGA able select important words control contribution word self-attention. % For proposed CAT, allows model asynchronously learn confusing relations sentence. After training step, CAT first selects misclassified sentences, regards relations misclassified confusing relations. After that, The CAT uses misclassified sentences confusing relations conduct additional training process, aimes learn confusing relations explicitly. We also propose CAT explicitly force model asynchronously learn classification instance true relation confusing relation. After training step, CAT first selects misclassified sentences, regards relations misclassified confusing relations. After that, The CAT uses misclassified instances confusing relations augmented data conduct additional training process, aims learn mapping instances confusing relations. % After that, The CAT uses misclassified sentences confusing relations conduct additional training process, aims learn confusing relations explicitly. Afterwards, CAT adopts KL divergence teach model distinguish difference true confusing relations, benefits true relation classification confusing relation identification. % Extensive experiments conducted FewRel dataset, results show proposed model achieves comparable even better results strong baselines terms accuracy. % Furthermore, ablation test case study verify effectiveness proposed EGA CAT, especially addressing relation confusion problem. The contributions paper summarized follows: We propose Entity-Guided Attention encoder, select crucial words filter NL expressions causing confusion based relevance specified entities. We propose Confusion-Aware Training process enhance model ability distinguishing true confusing relations. We conduct extensive experiments few-shot RC dataset FewRel, ans results show model achieves comparable even much better results strong baselines. Furthermore, ablation case studies verify effectiveness proposed EGA CAT, especially addressing relation confusion problem."," This paper aims to enhance the few-shot relation classification especially for sentences that jointly describe multiple relations. Due to the fact that some relations usually keep high co-occurrence in the same context, previous few-shot relation classifiers struggle to distinguish them with few annotated instances. To alleviate the above relation confusion problem, we propose CTEG, a model equipped with two mechanisms to learn to decouple these easily-confused relations. On the one hand, an Entity-Guided Attention  mechanism, which leverages the syntactic relations and relative positions between each word and the specified entity pair, is introduced to guide the attention to filter out information causing confusion. On the other hand, a Confusion-Aware Training  method is proposed to explicitly learn to distinguish relations by playing a pushing-away game between classifying a sentence into a true relation and its confusing relation. Extensive experiments are conducted on the FewRel dataset, and the results show that our proposed model achieves comparable and even much better results to strong baselines in terms of accuracy. Furthermore, the ablation test and case study verify the effectiveness of our proposed EGA and CAT, especially in addressing the relation confusion problem."
"% The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. . % final paper: en-us version % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. } Complaining basic speech act, usually triggered discrepancy reality expectations towards entity event. Social media become popular platform expressing complaints online customers directly address companies regarding issues services products. Complaint detection aims identify breach expectations given text snippet. However, use implicit ironic expressions accompaniment speech acts suggestions, criticism, warnings threats make challenging task. Identifying classifying complaints automatically important for: improving customer service chatbots; linguists analyze complaint characteristics large scale ; psychologists understand behavior humans express complaints. Previous work focused binary classification complaints non-complaints various domains. Furthermore, studies performed fine-grained complaint classification. For instance, complaints directed public authorities categorized based topics responsible departments. Other categorizations based possible hazards risks well escalation likelihood. Most previous studies used supervised machine learning models features extracted text task-specific neural models trained scratch. Adapting state-of-the-art pre-trained neural language models based transformer networks BERT XLNet yet explored. In paper, focus binary classification Twitter posts complaints \shortcite{preotiuc2019automatically}. We adapt evaluate battery pre-trained transformers subsequently combine external linguistic information topics emotions. \paragraph{Contributions} New state-of-the-art results complaint identification Twitter, improving macro FI 8.0\% previous work Preotiuc-Pietro et al. \shortcite{preotiuc2019automatically}; A qualitative analysis limitations transformers predicting accurately whether given text complaint not.","    Complaining is a speech act extensively used by humans to communicate a negative inconsistency between reality and expectations. Previous work on automatically identifying complaints in social media has focused on using feature-based and task-specific neural network models. Adapting state-of-the-art pre-trained neural language models and their combinations with other linguistic information from topics or sentiment for complaint prediction has yet to be explored. In this paper, we evaluate a battery of neural models underpinned by transformer networks which we subsequently combine with linguistic information. Experiments on a publicly available data set of complaints demonstrate that our models outperform previous state-of-the-art methods by a large margin achieving a macro F1 up to 87."
"% % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % . % % final paper: en-us version % % space normally used marker This work licensed Creative Commons Attribution 4.0 International License. License details: \url{http://creativecommons.org/licenses/by/4.0/}. } Neural machine translation achieved enormous success advancing quality translation . In spite impressive performance, NMT models still vulnerable perturbations input sentences , i.e. tiny perturbation affect hidden representation lead low quality translation . Moreover, NMT commonly consists millions parameters, making prone overfitting especially low resource scene. % Neural machine translation achieved enormous success advancing quality translation . Despite impressive performance, NMT models still vulnerable scale data, training small monotonous data leading inference many unexcepted inputs low quality translation, model prone overfitting concurrently. % Improve robustness representation capacity models important problem solve. % NMT model adopts deep neural network modeling whole translation process, train multi features together without prior domain knowledge, developing rapidly recent years. However, compared SMT, NMT requires millions parameters huge number data, making prone overfitting especially low resource scene. Researchers found NMT extremely sensitive input noise -- tiny perturbation affect hidden representation -- leading low quality translation. Improve robustness representation capacity models important problem solved. A natural way improve generalization synthesizing natural noise adopting arbitrary noise . Another way exploring regularization techniques avoid overfitting , making model robust unseen unfamiliar inputs. However, discrete data, text hard retain semantic information corruption. % A natural way improve generalization data augmentation, make model see much data possible, meanwhile, necessary avoid overfitting. Standard dropout commonly used technology overfitting neural networks preventing neuron obtain complete information data like noisy perturbations, moreover, regularization techniques also beneficial overfitting. % In paper, propose Token Drop prevent overfitting improve generalization. Different standard dropout drops neurons network randomly, drop tokens input sentences. In order retain semantic information, replace tokens special symbol . This allows model learn hidden representation rest token's context, predict target translation condition latent variable. On one hand, method allows model meeting exponentially different sentences explained data augmentation; On hand, method corrupts input sentences natural noise seen regularization term NMT. We investigate two self-supervised objectives: Replaced Token Detection Dropped Token Prediction. Considering Token Drop method regularize parameters weakening model inputs, making NMT suitable applying self-supervised objective. During training: use discriminator detect whether input tokens dropped not; leverage hidden state predict original tokens dropped tokens inspired Cloze task . Both guide model generate semantically similar representation, leading better generalization capacity. % To test approach, conduct machine translation task ZH-EN EN-RO benchmark, despite compared strong baseline, % In work, propose randomly drop tokens input sentence, different standard dropout , drop neurons network randomly training, replace tokens special symbol unk. Using method, call token drop, input sentence, model see different sequences theoretically. On one hand, model receives data, hand, seen noise challenge model learn primary information latent representation. Our approach also similar self-supervised technique, utilize contextual state predict masked token, difference training object optimize translation ability source language. By randomly drop tokens input, forcing model utilize latent representation make prediction training, inference, model see full sentence make decision easily. To test approach, conduct machine translation ZH-EN EN-RO corpus, compare baseline, token drop training models stable resilient overfitting. % Deep neural networks large number parameters prone overfitting, requires regularization method practice. One effective way avoid overfitting Dropout , omitting stochastic neurons networks training iteration, maintain neurons inference, brings significant improve results variety tasks . Different dropout, drop single unit, token-level dropout drop entire token, proved effective seq2seq task.","    Neural machine translation with millions of parameters is vulnerable to unfamiliar inputs. We propose Token Drop to improve generalization and avoid overfitting for the NMT model.  Similar to word dropout, whereas we replace dropped token with a special token instead of setting zero to words.  We further introduce two self-supervised objectives: Replaced Token Detection and Dropped Token Prediction. Our method aims to force model generating target translation with less information, in this way the model can learn textual representation better. Experiments on Chinese-English and English-Romanian benchmark demonstrate the effectiveness of our approach and our model achieves significant improvements over a strong Transformer baseline\footnote{Our code is released at \url{https://github.com/zhajiahe/Token_Drop}}."
"\com{ Remember recheck: intro section place clear reiterate paragraph structure: taxonomy explained validations taxonomy+classification comparison taxonomies /classifications proof usefulness various kinds analysis allows qualitative results discussion related work conclusion } Taxonomies grammatical errors important linguistic computational analysis learner language, well Grammatical Error Correction systems.\footnote{Code found \href{https://github.com/borgr/GEC_UD_divergences}{in github repo GEC\_UD\_divergences}. Matrices directly mentioned included appendix.} Such taxonomies divide complex space errors meaningful categories enable characterizing distribution learner productions. This information beneficial GEC: support development systems focus specific error types, serve form inductive bias , guide data augmentation data filtering controlling distribution error types. Error taxonomies also improve interpretability system outputs error analysis learner feedback. % % % \end{small} % \end{table} A number annotation efforts learner language developed error taxonomies , statistical classifiers taxonomies, notably ERRANT . Taking error types consideration learning also shown improve GEC performance \citep[][{cf. \S}]{kantor2019learning}. However, existing taxonomies fairly coarse-grained language specific, produce meaningful types large proportion errors. For example, 25\% errors standard NUCLE corpus mapped residual category OTHER . We propose \secl, taxonomy Syntactic Errors automatic Classification. Inspired longstanding tradition Machine Translation analyses divergences source translated texts based syntactic structure , \secl\ based divergences ungrammatical sentences corrections. We define SEs errors whose correction involves changing morphological features, POS labels syntactic structure labels. \secl\ takes input edits, i.e., grammatically incorrect text spans corrections, compares labels. For example, error Fig. adjective replaced adverb POS terms, \ra edge-label terms. Thus, SEs defined changes form, rather principles governing choice correct form. \secl\ first taxonomy derived syntactic representation framework, uses Universal Dependencies formalism \citep[UD;][]{nivre2016universal}. This approach provides three major advantages prior learner error taxonomies. First, \secl\ taxonomy derived automatically UD annotations, circumventing need constructing ad-hoc manually defined error categories. Second, using UD formalism makes method applicable across languages, allowing consistent analyses comparisons learner errors across different languages within one unified framework. Third, \secl\ compatible standard representations tools NLP. Further, UD based approach error classification yield finer distinctions compared existing schemes. For example, divides commonly used class adposition errors errors use prepositions nominal modifiers , use prepositions prepositional objects adjuncts . %prepositions involving verbal arguments errors involving spatial/temporal relations.\oa{how exactly? maybe say distinguish NP-internal PPs clause-level PPs?} \lc{One would obj something . Isn't object subject main thing syntax allows?, write another example. Note example involve type usually split . } POS tags alone cannot distinguish them, UD trees expose distinction straightforwardly. UD also help classify agreement case-assignment errors thanks morphological-feature layer containing information case, number, gender, features relevant inflection. We validate \secl's reliability showing SEs based automatic parses similar ones based manual parses. ; \secl\ types map well NUCLE's manually curated taxonomy ; \secl\ complementary standard type classifier ERRANT: 60\% errors classified ERRANT classified \secl. We demonstrate \secl's unique features, notably cross-linguistic applicability, analyzing SE distributions available corpora learner English learner Russian . Finally, find GEC systems certain SEs harder correct SEs harder non-SEs granular types help devising rules improve products . %\lc{yb, I gave try, better? Am I general?} %We validate accuracy relying parsing technology compare \secl\ manual automatic taxonomies , finding \secl\ classifies 60\% errors covered leading error classifier English ERRANT . We examine characteristics using UD features applying Russian . All findings suggest \secl\ reliable, fine-grained annotation current taxonomy classifier language specific. To show wide applicability, use \secl\ provide detailed picture distribution SEs various learner English corpora . We proceed use \secl\ detect trends error type distribution across learner levels . We conclude analyzing system outputs .\yb{many people skip paper summary paragraphs. I would instead list contributions bullet points .} % %While classifying grammatical error types . In paper focus syntactic errors, i.e., errors require changing tree structure fix, %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"," 		We present a method for classifying syntactic errors in learner language, namely errors whose correction alters the morphosyntactic structure of a sentence. 		The methodology builds on the established Universal Dependencies syntactic representation scheme, and provides complementary information to other error-classification systems.  		Unlike existing error classification methods, our method is applicable across languages, which we showcase by producing a detailed picture of syntactic errors in learner English and learner Russian. We further demonstrate the utility of the methodology for analyzing the outputs of leading Grammatical Error Correction  systems."
"The short answer test type exam participants asked answer questions short answers consist 1-2 sentences. Assessing student short answers exam challenging assessor. When large number students assessed, example national scale, assessors required remain consistent objective assessing hundreds even thousands student responses. The questions short answer format also allow students answer style varied student. Therefore, computer assistance making automatic short answer scoring deemed necessary address problems. In 2019, NLP Research Group Universitas Gadjah Mada, Indonesia, collaboration Education Assessment Center, Ministry Education Culture Indonesia, held Ukara 1.0 Challenge\footnote{https://nlp.mipa.ugm.ac.id/ukara-1-0-challenge/}. In challenge, participants nation challenged make automatic short answer scoring system Indonesian student exam. There two short answer questions challenge correct incorrect labels. In paper, try describe improvement previous work Ukara 1.0 Challenge dataset. There several challenges may arise applying making automatic short answer scoring system. First, number models hyperparameters need searched. In conventional machine learning, model trained solve specific problem, case, model trained assess one short answer question. When number questions assessed increases, time required searching model tuning hyperparameters also increase. The second challenge imbalance class. In exam, questions given intended test students' abilities, therefore level difficulty question cause number correct responses much less number wrong responses. Another challenge automatic short answer scoring small amount labeled data. The data labeling process easy requires expert validate student responses course time consuming costly. In several previous studies, making short answer scoring essay scoring done using deep learning approaches, example, using long-short term memory, convolutional neural network, combination . We take different approach using simpler stacking model small number available data. In paper, used sentence-level feature done . Without word sequence features, automatic scoring process could viewed text classification problem. The use stacking models text classification done shows better performance single model classifier. We also propose use upsampling method, Synthetic Minority Over-sampling Technique , handle imbalance classes hyperparameters optimization algorithm, Tree-structured Parzen Estimator find robust model performs well type question. In paper, use hyperparameters term model components preset untrained . Meanwhile, term parameters refers model components trained ."," Automatic short answer scoring is one of the text classification problems to assess students' answers during exams automatically. Several challenges can arise in making an automatic short answer scoring system, one of which is the quantity and quality of the data. The data labeling process is not easy because it requires a human annotator who is an expert in their field. Further, the data imbalance process is also a challenge because the number of labels for correct answers is always much less than the wrong answers. In this paper, we propose the use of a stacking model based on neural network and XGBoost for classification process with sentence embedding feature. We also propose to use data upsampling method to handle imbalance classes and hyperparameters optimization algorithm to find a robust model automatically. We use Ukara 1.0 Challenge dataset and our best model obtained an F1-score of 0.821 exceeding the previous work at the same dataset."
"% Second, NMT model's ability handle streaming ASR output; ASR system provides best greedy recognition live speech's segmented audio. % really talk ^ %deleted simultaneous With advance Automatic Speech Recognition Neural Machine Translation systems, speech translation become increasingly feasible received considerable attention. However, researchers encountered many challenging problems within standard cascaded framework ASR system outputs passed NMT systems. First, since NMT models often trained clean, well-structured text, disfluency spoken utterances recognition errors ASR systems modeled NMT systems. Second, people speak differently write, results changes sentence structure meaning. Third, automatically predicting sentence boundaries challenging. Taken whole, poorly segmented sentences incorrect word recognition leads poor translations. These problems pose unique challenges ASR NMT robustness readily addressed current methods. % %\subsection{Related Work} % Current approaches robust NMT noisy inputs typically focus improving word transcription data augmentation techniques. Such methods include disfluency removal redundant unnecessary words removed translating transcript, domain adaptation NMT models augmented in-domain training data, synthetic noise, random edits made training data. % % \footnotetext{When compared Table , sum System/System transcript segmentation degradation surpasses Gold/Gold evaluation 0.57 BLEU points. This modifications evaluation data directly additive, ie .} % %\subsection{Contributions} % % Although data domain segmentation issues often tackled separately, find compounded effects, namely erroneous transcript sentence boundaries, neglected substantially detrimental final translation quality. % As such, contributions two fold, analyze impact noisy ASR segmentations translation propose easily adaptable simple data augmentation strategy increase NMT robustness. % sentence optional In experimentation, found ASR system punctuation often imperfect. It may omit insert sentence-final punctuation, resulting sentences erroneously compounded fragmented. While corroborated similar works, note degradation translation caused poor system sentence boundary prediction, specifically evaluate, quantify, address issue. % mention much sentence boundaries degrade accuracy % Find example? To tackle sentence boundary problem, propose simple scheme augment NMT training data, yields +1 BLEU point average. % Similar , first ascertain NMT model implicitly learn target punctuation unpunctuated source text, even noisy imperfect sentence boundaries. % sentence necessary?^ %We show simple data augmentation scheme general in-domain NMT training data, achieve improvement BLEU tst2015 tst2018 respectively. This procedure agnostic ASR systems applied NMT model training easily. %"," Neural Machine Translation  models have demonstrated strong state of the art performance on translation tasks where well-formed training and evaluation data are provided, but they remain sensitive to inputs that include errors of various types. Specifically, in the context of long-form speech translation systems, where the input transcripts come from Automatic Speech Recognition , the NMT models have to handle errors including phoneme substitutions, grammatical structure, and sentence boundaries, all of which pose challenges to NMT robustness.  %This paper makes two main contributions via an in-depth error analysis and a proposed solution.  Through in-depth error analysis, we show that sentence boundary segmentation has the largest impact on quality, and we develop a simple data augmentation strategy to improve segmentation robustness."
"Automatic summarization automated process reducing size input text preserving relevant information content core semantics. Techniques summarization often characterized either: Extractive Abstractive. Extractive methods construct summaries combining salient passages source text; process similar human's way identifying right information. One way achieve extractive summarization define problem sentence classification task, using form representation sentences document . To avoid content overlap issues, previous work used sentence reranking sentence ordering extracting sentences recurrently . Abstractive methods generate summaries generating new sentence constructs ``from scratch'', representation document content, process conceptually similar notion paraphrasing. Abstractive text summarization attracted interest since capable generating novel formulations summaries using language generation models conditioned source text. Several attention-based Recurrent Neural Network encoder-decoders introduced tackle varying text generation issues standalone abstractive sequence-to-sequence models. Copy pointer mechanisms , example, enabled decoders better generate unseen words, out-of-vocabulary words named entities. Most recently, hybrid extractive abstractive architectures proposed shown promising results quantitative performance measures human evaluations. In set-ups, extractive model first selects salient sentences source article, abstractive model paraphrases extracted sentences final summary. The majority current state-of-the-art abstractive summarization models\footnote{Excluding summarization models using large scale pre-trained language models BERT } based hybrid approach . Nonetheless, hybrid models limited three disadvantages. First, since ground-truth labels extractive summarization usually provided, extractive labels must generated potentially suboptimal algorithm . The performance models trained labels therefore bounded quality performance extractive heuristics. Second, since ground-truth binary labels recurrently extracted sentences typically teacher forced \citet{chen-bansal-2018-fast}, ``exposure bias'' may negatively affect content selection performance inference. Finally, given hard extraction step differentiable, existing hybrid models typically require multi-step training reinforcement learning train whole model. In paper, introduce novel abstractive summarization model incorporates intermediate extractive step require labels type extractive content selection, fully end-to-end trainable. To achieve this, propose new memory augmented encoder-decoder architecture called Mem2Mem. Mem2Mem 2 memorization modes: absorb key information encoded source sequence via compression mechanism, sequentially update external memory target summary generation. Without using extractive ground-truth labels, find analysis Mem2Mem's compression mechanism behaves implicit sentence extractor stores sentence representations salient content. The choice sentence representations guided memory regularization conditional language modeling loss decoder, thus avoiding exposure bias maximizing likelihood sequential binary extraction labels. Finally, encoded memory transferred decoder memory, iteratively refined decoding process. To knowledge, Mem2MeM first abstractive summarization model uses memory compression sentence extraction directly employs memorized representations summary generation. We empirically demonstrate merits approach setting new state-of-the-art long text abstractive summarization tasks Pubmed, arXiv Newsroom datasets . Our contributions three fold: % fig_architecture"," We introduce Mem2Mem, a memory-to-memory mechanism for hierarchical recurrent neural network based encoder decoder architectures and we explore its use for abstractive document summarization. Mem2Mem transfers ``memories"" via readable/writable external memory modules that augment both the encoder and decoder. Our memory regularization compresses an encoded input article into a more compact set of sentence representations. Most importantly, the memory compression step performs implicit extraction without labels, sidestepping issues with suboptimal ground-truth data and exposure bias of hybrid extractive-abstractive summarization techniques. By allowing the decoder to read/write over the encoded input memory, the model learns to read salient information about the input article while keeping track of what has been generated.  Our Mem2Mem approach yields results that are competitive with state of the art transformer based summarization methods, but with 16 times fewer parameters. %On abstractive long text summarization, Mem2Mem surpasses, with full end-to-end training, the current state-of-the-art by 3.98 and 3.08 average ROUGE scores on the Pubmed and arXiv datasets while using $16$ times less parameters.  % Our code and trained models are available at \url{https://github.com/anonymously999/mem2mem}."
"Attention-based encoder-decoder modeling natural powerful paradigm speech text tasks, automatic speech recognition speech translation , led significant progress . However, relies large amounts supervised speech data, expensive transcribe translate. In addition, amount speech transcripts speech translation labels dwarfed amount text data available language model machine translation training. For example, number text tokens used LM modeling two orders magnitude larger number tokens corresponding speech corpus Librispeech data corpus, shown Table. Attention-based encoder-decoder models designed incorporate heterogeneous inputs cannot benefit large amounts low cost text data directly speech applications. As expected, performance gaps still observed attention based encoder-decoder systems conventional systems multiple components. %Short description previous work In order alleviate data scarcity issue, different approaches studied, including acoustic linguistic aspects. %In study, focus leveraging text data improve linguistic modeling ability speech text systems. LM commonly used method integrate linguistic information ASR. Prior work focuses building LM monolingual text data, integrate LM transfer knowledge decoder. generate synthetic data text augment speech training corpus. Another direction leverage text data directly training multitask learning. use common representation space learn correspondences different modalities spoken language understanding. propose multi-modal data augmentation jointly train text speech ASR. %is reminiscent work done multimodal learning spoken language understanding also uses common representation space learn correspondences different modalities. focused ST tasks trained ASR system together, ASR used auxiliary task. Hence, methods cannot applied back ASR systems. %What proposed, describe main idea %We follow second direction propose using auxiliary text tasks enhance speech text tasks. In study, focus leveraging text data improve linguistic modeling ability speech text tasks. We propose general framework leverage text data ASR ST tasks. %Two encoders take text speech input respectively, decoder shared tasks. During inference, speech encoder decoder used. A denoising autoencoder task introduced jointly trained ASR task monolingual data, machine translation task co-trained ST task parallel data. Text input represented spoken form using phoneme sequence effectively reduces difference speech input text input. We also carefully study different design choices joint training system, including strategies share text speech encoders comparing joint training system models initialized pre-trained components. Our experiments show proposed joint training systems effectively reduce word error rate ASR task 10\% 15\% improve BLEU score 3.69.2 ST tasks. %Compared previous methods, method emphasizes reducing difference two encoders eases knowledge transfer text text speech text tasks. %The method includes three parts: first, representation difference text speech input minimized phoneme sequence representation additional speech end sentence token. Second, novel cross attentive loss proposed increase similarity sequences different lengths. It acts auxiliary loss regularize outputs two encoders. Third, %masking applied input text tokens simulate adverse conditions speech, noise incomplete pronunciation. It also encourages decoder learn better language context representation fill gap due masking. %Instead focusing one particular task previous work, method applied ASR ST tasks. Experiments conducted two popular ASR ST benchmark tasks. The results show proposed method brings substantial gains baseline ASR ST tasks."," Attention-based sequence-to-sequence modeling provides a powerful and elegant solution for applications that need to map one sequence to a different sequence.  Its success heavily relies on the availability of large amounts of training data.  This presents a challenge for speech applications where labelled speech data is very expensive to obtain, such as automatic speech recognition  and speech translation .  In this study, we propose a general multi-task learning framework to leverage text data for ASR and ST tasks. Two auxiliary tasks, a denoising autoencoder task and machine translation task, are proposed to be co-trained with ASR and ST tasks respectively.  We demonstrate that representing text input as phoneme sequences can reduce the difference between speech and text inputs, and enhance the knowledge transfer from text corpora to the speech to text tasks.  Our experiments show that the proposed method achieves a relative 10$\sim$15\% word error rate reduction on the English Librispeech task compared with our baseline, and improves the speech translation quality on the MuST-C tasks by 3.6$\sim$9.2 BLEU."
"Motivated process human inquiry learning, field question generation requires model generate natural language questions context. QG wide applicability automated dialog systems, language assessment, data augmentation, development annotated data sets question answering research. Most prior research QG focused generating relatively simple factoid-based questions, answering question simply requires extracting span text single reference document. However, motivated desire build NLP systems capable sophisticated forms reasoning understanding, increasing interest developing systems multi-hop question answering generation , answering questions requires reasoning content multiple text documents . Unlike standard QG, generating multi-hop questions requires model understand relationship disjoint pieces information multiple context documents. Compared standard QG, multi-hop questions tend substantially longer, contain higher density named entities, and---perhaps importantly---high-quality multi-hop questions involve complex chains predicates connecting mentioned entities To address challenges, existing research multi-hop QG primarily relies graph-to-sequence methods. These approaches extract graph inputs augmenting original text structural information apply graph neural networks learn graph embeddings fed sequence-based decoder. However, necessity complex G2S approaches---which require designing hand-crafted graph extractors---is entirely clear, especially standard transformer-based sequence-to-sequence models already induce strong relational inductive bias. Since transformers inherent ability reason relationships entities text, one might imagine models alone would suffice relational reasoning requirements multi-hop QG. \xhdr{Present work} In work, show that, fact, standard transformer architecture sufficient outperform prior state-of-the-art multi-hop QG. We also propose analyze graph-augmented transformer ---which integrates explicit graph structure information transformer model. GATE sets new state-of-the-art outperforms best previous method 5 BLEU points HotpotQA dataset. However, show gains induced graph augmentations relatively small compared improvements vanilla transformer architecture, auxiliary contrastive objective data filtering approach, improve model 7.9 BLEU points ablation studies. Overall, results suggest diminishing returns incorporating hand-crafted graph structures multi-hop reasoning provides foundation stronger multi-hop reasoning systems based transformer architectures. Our key contributions summarized follows: We hope work provides strong foundation future research multi-hop QG guiding field towards promising avenues future model improvements.\documentclass[11pt,a4paper]{article} \usepackage[hyperref]{emnlp2020} \usepackage{times} \usepackage{latexsym} \renewcommand{\UrlFont}sachande@mila.quebec, wuli@us.ibm.com \usepackage{microtype} \aclfinalcopy % Uncomment line final submission \usepackage[utf8]{inputenc} % allow utf-8 input \usepackage[T1]{fontenc} % use 8-bit T1 fonts \usepackage{url} % simple URL typesetting \usepackage{booktabs} % professional-quality tables \usepackage{amsfonts} % blackboard math symbols \usepackage{amsmath} \usepackage{nicefrac} % compact symbols 1/2, etc. \usepackage{graphicx} \usepackage{microtype} % microtypography \usepackage{tabularx} \usepackage{xcolor} \usepackage{bbm} \usepackage{array} \usepackage{arydshln} \usepackage{amsfonts} \usepackage{amsmath} \DeclareMathOperator*{\argmax}{arg\,max} \DeclareMathOperator*{\argmin}{arg\,min} \usepackage{bbm} \usepackage{boldline} \usepackage{bigstrut} \usepackage{blindtext} \usepackage{booktabs, siunitx} \usepackage[labelfont=bf, format=plain, justification=justified, singlelinecheck=false]{caption} \usepackage{color} \usepackage{cprotect} \usepackage{ctable} \usepackage{dirtytalk} \usepackage{enumitem} \usepackage[export]{adjustbox} \usepackage{float} \usepackage{graphicx} \usepackage{hhline} \usepackage{latexsym} \usepackage{mathrsfs} \usepackage{microtype} \usepackage{moresize} \usepackage{multicol} \usepackage{multirow} \usepackage{nccmath} \usepackage{nicefrac} \usepackage{pifont} \usepackage{placeins} \setlength\bigstrutjot{3pt} \usepackage{soul} \usepackage{subcaption} \usepackage{times} \usepackage[utf8]{inputenc} \usepackage{url} \usepackage{verbatim} \usepackage{wrapfig, lipsum} \usepackage{textcomp} \usepackage{enumitem} %\hypersetup{draft} \newcommand\sL{\ensuremath{\mathcal{L}}} \newcommand\sD{\ensuremath{\mathcal{D}}} % colors \definecolor{lblue}{HTML}{A6CEE3} \definecolor{lgreen}{HTML}{B2DF8A} \definecolor{lred}{HTML}{FB9A99} \definecolor{lorange}{HTML}{FDBF6F} \definecolor{mblue}{HTML}{80B1D3} \definecolor{mgreen}{HTML}{B3DE69} \definecolor{mred}{HTML}{FB8072} \definecolor{morange}{HTML}{FDB462} \definecolor{blue}{HTML}{1F78B4} \definecolor{green}{HTML}{33A02C} \definecolor{red}{HTML}{E31A1C} \definecolor{orange}{HTML}{FF7F00} \definecolor{dblue}{HTML}{0050EF} \definecolor{dgreen}{HTML}{006D2C} \definecolor{dorange}{HTML}{EC7014} \newcommand{\blue}[1]{{\color{blue} #1}} \newcommand{\green}[1]{{\color{green} #1}} \newcommand{\red}[1]{{\color{red} #1}} \newcommand{\orange}[1]{{\color{orange} #1}} \newcommand{\dblue}[1]{{\color{dblue} #1}} \newcommand{\dgreen}[1]{{\color{dgreen} #1}} \newcommand{\dorange}[1]{{\color{dorange} #1}} \newcommand{\cut}[1]{} \newcommand{\xhdr}[1]{{\bfseries #1}.} \interfootnotelinepenalty=1000 \title{Stronger Transformers Neural Multi-Hop Question Generation} \author{Devendra Singh Sachan, Lingfei Wu, Mrinmaya Sachan, William Hamilton \\ Mila - Quebec AI Institute\\ School Computer Science, McGill University\\ IBM Thomas J. Watson Research Center, Yorktown Heights\\ ETH Zurich\\ mrinmaya.sachan@inf.ethz.ch, wlh@cs.mcgill.ca\\ {\tt mrinmaya.sachan@inf.ethz.ch, wlh@cs.mcgill.ca} } \date{} % !TeX root = main.tex"," Prior work on automated question generation has almost exclusively focused on generating simple questions whose answers can be extracted from a single document. However, there is an increasing interest in developing systems that are capable of more complex multi-hop question generation, where answering the questions requires reasoning over multiple documents. In this work, we introduce a series of strong transformer models for multi-hop question generation, including a graph-augmented transformer that leverages relations between entities in the text.  While prior work has emphasized the importance of graph-based models, we show that we can substantially outperform the state-of-the-art by {5 BLEU points}  using a standard transformer architecture. We further demonstrate that graph-based augmentations can provide complimentary improvements on top of this foundation. Interestingly, we find that several important factors---such as the inclusion of an auxiliary contrastive objective and data filtering could have larger impacts on performance.  We hope that our stronger baselines and analysis provide a constructive foundation for future work in this area."
"Variational Autoencoders allow design complex generative models data. % since inference process VAE-based approaches advantage independent model architecture providing high flexibility designing new neural components. In wake renewed interest VAEs, traditional probabilistic topic models revised giving rise several Neural Topic Model variants, NVDM , ProdLDA , NTM-R , etc. % GSM , W-LDA However, existing topic models applied user reviews may extract topics associated writers' subjective opinions mixed related factual descriptions plot summaries movies books . Although approaches achieved significant results via neural inference process, surprisingly little work done disentangle inferred topic representations. % Despite lack general consensus formal definition disentangled representations , Disentangled representations defined representations individual latent units sensitive variations single generative factor, relatively invariant changes factors . Inducing representations shown significantly beneficial generalization interpretability . For example, image viewed results several generative factors mutually interacting, one many sources light, material reflective properties various surfaces shape objects depicted . % In context topic modeling, documents result generative process mixtures latent topics, therefore, propose consider latent topics generative factors disentangled improve interpretability discriminative power. Disentangled topics topics invariant factors variation text, instance, context book movie reviews could author's opinion , salient parts plot auxiliary information reported. An illustration shown Fig. opinion topics separated plot topics. % leads separating topics based ``factor variation"" revealing. % For example, generating book review, factors variation involved could depend author's expertise identifying salient features book, %his knowledge book's genre, % ability summarize plot feelings evoked book. % % [Let's break in/the atom] % % Figure reports examples polarity-disentangled topics generated IMDB movie reviews ""The Hobbit"". The topics left right summarize positive negative aspects described users, neutral topics middle report main elements movie's plot. % An effective approach disentangling features latent space VAEs adopt adversarial training . However, despite successful applications computer vision , applications text analysis rather limited far , narrowed lack proper tasks evaluate generated disentangled representations limited availability suitable datasets. % For example, book movie reviews, want disentangle topics related opinions expressed text topics relating book/movie plots. An illustration shown Figure opinion topics separated plot topics. However, models relying solely sentiment information easily misled suitable disentangle opinion plots, since even plot descriptions frequently make large use sentiment expressions . Consider example following sentence: ``The ring holds dark power, soon begins exert evil influence Bilbo"", excerpt strong positive Amazon's review. % This overcomes difficulty separating opinions plot auxiliary information yet containing polarised descriptions easily mislead models merely relying sentiment lexicon; analogously issue mixed topics generated traditional topic models applied review documents, pointed \citet{Blei08}. % Despite successful employment computer vision , adversarial approach rather limited application text analysis far , narrowed lack proper tasks evaluate generated disentangled representations limited availability suitable datasets. Therefore, propose distinguish opinion-bearing topics plot/neutral ones combining neural topic model architecture adversarial training. In study, present DIsentangled Adversarial TOpic Model \footnote{Source code dataset omitted anonymous submission.}, aiming disentangling information related target labels , distinct aspects yet possibly still polarised . We also introduce new dataset, namely MOBO dataset\footnotemark[\value{footnote}], made movie book reviews, paired related plots. The reviews come different publicly available datasets: IMDB , GoodReads Amazon reviews , %, encompass wide spectrum domains styles. We conduct extensive experimental assessment model. First, assess topic quality terms topic coherence diversity compare DIATOM supervised topic models sentiment classification task; then, analyse disentangling rate topics quantitatively assess degree separation actual opinion plot/neutral topics. Our contributions summarized below: The rest paper organized follows. We review related literature sentiment-topic models, neural topic models studies disentangled representations . Then, present details proposed DIATOM model , followed experimental setup results . Finally, conclude summary results suggestions future works . %%%%%%%%%%%%%%%%%%%%%%%%%%%"," The flexibility of the inference process in Variational Autoencoders  has recently led to revising traditional probabilistic topic models giving rise to Neural Topic Models . Although these approaches have achieved significant results, surprisingly very little work has been done on how to disentangle the latent topics. Existing topic models when applied to reviews may extract topics associated with writers' subjective opinions mixed with those related to factual descriptions such as plot summaries in movie and book reviews. It is thus desirable to automatically separate opinion topics from plot/neutral ones enabling a better interpretability. %Since in the topic modeling framework documents result from a generative process over mixtures of latent topics, we propose to interpret these latent topics as generative factors to be disentangled to improve their interpretability and discriminative power. In this paper, we propose a neural topic model combined with adversarial training to disentangle opinion topics from plot and neutral ones. We conduct an extensive experimental assessment introducing a new collection of movie and book reviews paired with their plots, namely MOBO dataset, showing an improved coherence and variety of topics, a consistent disentanglement rate, and sentiment classification performance superior to other supervised topic models."
"\subsection{Dialogue act recognition} Mutual understanding interactive situations, either several people engaged dialogue interacting modern computer system natural language, may achieved without considering semantic information speakers utterances pragmatic interaction level, especially relative dialogue acts. Dialogue Acts represent meaning utterance context dialogue, or, words, function utterance dialogue. For example, function a~question request information, answer shall provide information. Dialogue acts thus commonly represented phrase-level labels statements, yes-no questions, open questions, acknowledgements, on. Automatic recognition dialogue acts fundamental component many human-machine interacting systems support natural language inputs. For instance, dialogue acts typically used input dialogue manager help deciding next action system: giving information user asking question, eventually keeping quiet user acknowledging, giving comment, even asking delaying interaction. In latter case, system reaction may perceived intrusive. Beyond human-machine interaction, task also important applications rely analysis human-human interactions, either oral, e.g., recordings meetings, % lada - added reference according rev 1 written, e.g., reply mention-at structures Twitter conversations. It also essential large range applications, example talking head animation, machine translation, automatic speech recognition topic tracking. The knowledge user dialogue act useful render facial expressions avatar relevant current state discourse. In machine translation domain, recognizing dialogue acts may bring relevant cues choose alternative translations, adequate syntactic structure may depend user intention. Automatic recognition dialogue acts may also used improve word recognition accuracy automatic speech recognition systems, different language model applied recognition depending dialogue act. %lada - added reference according rev 1, To conclude, dialogue act recognition important building block many understanding interacting systems. %pav --I've commented rest sentence, clear 2 reviewers ) -- typically completes semantic role labelling dialogue management. \subsection {Motivation objectives} Researches dialogue act recognition carried long time, detailed Section. The majority works exploit supervised learning lexical, syntactic, prosodic and/or dialogue history features. However, approaches consider semantic features, may bring additional information prove useful improve accuracy dialogue act recognition system. For instance, a~frequent cause recognition errors ``unknown'' words testing corpus never occur training sentences. Replacing specific named entities text category proposed literature remedy issue. We investigate general solution exploits lexical similarity word vectors. These word vectors may computed various ways, typically include mostly lexical semantic information word well syntactic information, e.g., related relative position degree proximity pairs words within sentence. This additional information may used improve dialogue act recognition, particular training test conditions differ, size training corpus relatively small. %goal In work, propose new Deep Neural Network based Long Short-Term Memory task dialogue act recognition, compare performance standard Maximum Entropy model. Our first objective leverage modelling capacity DNN order achieve dialogue act recognition raw observed word forms, i.e., without additional expert-designed feature. This model described Section. The second objective validate model standard English DA corpus, well two languages, without changing anything model, order assess genericity robustness approach. These experiments summarized Section. Finally, third objective study impact word embeddings, shown provide extremely valuable information numerous Natural Language Processing tasks, never used far~\footnote{To best knowledge time submission} dialogue act recognition. This study summarized Section. %The following Section presents review related works domain."," Dialogue act recognition is an important component of a large number of natural language processing pipelines. Many research works have been carried out in this area, but relatively few investigate deep neural networks and word embeddings. This is surprising, given that both of these techniques have proven exceptionally good in most other language-related domains. We propose in this work a new deep neural network that explores recurrent models to capture word sequences within sentences, and further study the impact of pretrained word embeddings. We validate this model on three languages: English, French and Czech. The performance of the proposed approach is consistent across these languages and it is comparable to the state-of-the-art results in English. More importantly, we confirm that deep neural networks indeed outperform a Maximum Entropy classifier, which was expected. However, and this is more surprising, we also found that standard word2vec embeddings do not seem to bring valuable information for this task and the proposed model, whatever the size of the training corpus is. We thus further analyse the resulting embeddings and conclude that a possible explanation may be related to the mismatch between the type of lexical-semantic information captured by the word2vec embeddings, and the kind of relations between words that is the most useful for the dialogue act recognition task."
"As important task Natural Language Generation , dialogue generation empowers wide spectrum applications, chatbot customer service automation. In past years, breakthroughs dialogue generation technology focused series sequence-to-sequence models . More recently, external knowledge employed enhance model performance. % , instance, propose Mem2Seq using structured knowledge task-oriented dialogue generation. assist dialogue generation using knowledge triples. Similarly, explore document knowledge discovery dialogue generation, utilize unstructured knowledge explore open-domain dialogue generation. However, unaffordable knowledge construction defective domain adaptation restrict utilization. Copy-based generation models widely adopted content generation tasks show better results compared sequence-to-sequence models faced out-of-vocabulary problem. Thanks nature leveraging vocabulary context distributions content copy, enables copy aforementioned named entities appeared context) upper context improve specificity generated text. In task dialogue generation, often observe phrases/utterance patterns across different ""similar dialogue"" instances. For example, customer service, similar inquiries customers get similar responses staff. It motivates us build model copy content within upper context target dialogue instance, also learn similar patterns across different similar cases target instance. Such external copy critical scenarios. %Fi Judge's questions, target court debate case, copied internal external sources, `cross-copy' enhance dialougue generation essentially. Figure paper, aware possibility copying adjacent Unfortunately, methods enable internal copy, e.g., copy content within target dialogue instance. External copy, e.g., copy content across different dialougue instances, incapable. However, Figure. depicted, %is another effective network structure. It solved problem traditional sequence-to-sequence model cannot solve problem vocabulary output sequence change length input sequence. %Copynet proposed humans tend repeat entity names even long phrases conversation.And generate entity appeared previous article copied. %Recently, Pointer networks Copynet's variants played important role NLG. Among them, Pointer-Generator Networks proposed. %In order copy key information context well cope Out-Of-Vocabulary problem. It relies vocabulary distribution context distribution, extended vocabulary obtained. % GLMP proposed global memory encoder local memory decoder share external knowledge Pointer networks. %}As general domain network structure, pointer network Copynet shows fine effect general text generation tasks. It solves problem domain adaptability poor dialog generation, introduce external knowledge, also address Out-Of-Vocabulary problem enable content copy. % Pointer networks Copynet provided effective approach address Out-Of-Vocabulary problem enable content copy. %The recent effort, Pointer-Generator Networks , inherited advantages leveraging vocabulary context distributions content copy. As shown Figure., propose two different kinds copy mechanisms study: vertical copy context-dependent information within target dialogue instance, horizontal copy logic-dependent content across different 'Similar Cases' . This framework labeled Cross-Copy Networks . As exemplar dialogue depicted, judges may repeat words, phrases utterances historical dialogues SCs sharing similar content, e.g., `A sue B X Y'. %In study, 'Similar Cases' refers similar dialogue dialogue. When generating next sentence based historical dialogue, refer similar dialogue dialogue obtain it. In paper, propose new network: Cross-Copy Networks, copy previous entity, also learn logic dialogue generation copied specific words, phrases utterance similar cases deal out-of-vocabulary words. % The CCN two pointers, one copy specific entity sentence context another copy process discourse complete sentence SC. % As shown Figure 1, two similar cases target case. Our copy methods divided two types, internal copy external copy. internal copy: directly copy specific entities words appear context words generated. external copy: copy related sentences phrases similar cases directly generated sentences. % As shown Fig., There three samples CCN: Selective copy: copy specific words phrases SC sentences generated, sample 1. Cross copy: copy specific entities context, copy process-frame nature sentences SC, sample 2. Deep copy: copy process discourse directly generated sentence, usually sentence appears frequently full text, sample 3. In order validate proposed model, employ two different dialogue datasets two orthogonal domains - court debate customer service. We apply proposed CCN datasets dialogue generation. Experiments show model achieves best results. To sum up, contributions follows: %"," In the past few years, audiences from different fields witness the achievements of sequence-to-sequence models  to enhance dialogue content generation. While content fluency and accuracy often serve as the major indicators for model training, dialogue logics, carrying critical information for some particular domains, are often ignored. Take customer service and court debate dialogue as examples, compatible logics can be observed across different dialogue instances, and this information can provide vital evidence for utterance generation.  In this paper, we propose a novel network architecture - Cross Copy Networks  to explore the current dialog context and similar dialogue instances闁 logical structure simultaneously. Experiments with two tasks, court debate and customer service content generation, proved that the proposed algorithm is superior to existing state-of-art content generation models. % The traditional sequence-to-sequence model  has achieved good results in Natural Language Generation tasks. % For dialogue generation task in specific areas , some of the utterances by judge and customer service personnel to be saied usually contain specific logic and this utterances are highly similar. % Therefore, when generating the current utterance, we need to refer to not only the current context but also similar cases. % In this paper, we proposed a new neural network architecture named Cross Copy Networks , It locates entity in the context and the logical expression of similar cases by learning two conditional probability pointers. % We apply CCN to the legal dialogue data and customer service dialogue data for dialogue generation task. % Experiments show that our model achieves the best results."
"In recent years, increased focus use unannotated texts modeling human language transfer learning natural language processing . A wide variety models proposed, ranging context-independent word embeddings , recent contextual representations . In particular, Transformer-based BERT model generated considerable interest NLP community since release. BERT outperformed state-of-the-art systems wide range benchmark datasets published, served basis many studies since. These efforts include work proposes improvements and/or modifications training objectives , knowledge distillation , multilinguality , interpretation , name few. As mark popularity, term BERTology coined refer field research relating BERT . % Multilinguality, zero-shot transfer, monolingual BERTs A thriving branch BERTology involves BERT models languages English. released multilingual BERT models trained hundred languages. % good multilingual model analyze representations produced mulitlingual BERTs find evidence representations generalize across languages various downstream tasks, though language-specific information retained. This language-agnostic subspace multingual BERTs also observed studies, deemed factor allows zero-shot transfer . % also find evidence multilingual BERTs learn language-agnostic subspace linguistic information. also show multilingual models embeddings partially aligned, allows zero-shot transfer. Furthermore, embeddings aligned fine-tuning based alignment procedure, improving performance multilingual models . % curse multilinguality % 'we scale number languages fixed model capacity: lan-guages leads better cross-lingual performanceon low-resource languages point, afterwhich overall performance monolingual andcross-lingual benchmarks degrades' While multilingual training benefit also monolingual performance, number languages covered multilingual model increases, fraction model capacity available single language decreases. % The number languages included multilingual model, however, affects performance, phenomenon referred curse multilinguality observed. term curse multilinguality phenomenon increasing number languages included model initially leads better cross-lingual performance low-resource languages, eventually leading overall degradation monolingual cross-lingual performance. Work language-specific BERT models also shown monolingual models tend outperform multilingual models size monolingual settings . % To benefit languages English, monolingual BERTs various languages trained released NLP community . %\todo{Is transition needed here?} % SMP: added following However, question whether possible train multilingual models without loss monolingual performance remains largely open. %To minimize effect curse multilinguality still benefit language-agnostic subspace, % Furthermore, underlying reason BERT works, inner representation BERT, line research focused inner-workings BERT [put related work?] In paper, study whether feasible pre-train bilingual model two remotely related languages without compromising performance either language. Specifically, train Finnish-English bilingual BERT model using combination pre-training data original English BERT model Finnish BERT model introduced , using extended model vocabulary otherwise fixing model capacity BERT-Base size retaining number pre-training steps. % carefully rephrase this! %While reports bilingual BERTs focusing cross-linguality, best knowledge, work focusing comparing performance bilingual models natural language understanding tasks monolingual counterparts. We evaluate performance introduced bilingual model range natural language understanding tasks used evaluate monolingual models, which, best knowledge, focus studies bilingual BERT models. We find \bbert{} achieves comparable performance GLUE benchmark original English BERT, nearly matches performance Finnish BERT Finnish NLP tasks. Our results indicate extension vocabulary size sufficient allow creation fully bilingual models perform par monolingual counterparts languages."," Language models based on deep neural networks have facilitated great advances in natural language processing and understanding tasks in recent years. While models covering a large number of languages have been introduced, their multilinguality has come at a cost in terms of monolingual performance, and the best-performing models at most tasks not involving cross-lingual transfer remain monolingual. In this paper, we consider the question of whether it is possible to pre-train a bilingual model for two remotely related languages without compromising performance at either language. We collect pre-training data, create a Finnish-English bilingual BERT model and evaluate its performance on datasets used to evaluate the corresponding monolingual models. Our bilingual model performs on par with Google's original English BERT on GLUE and nearly matches the performance of monolingual Finnish BERT on a range of Finnish NLP tasks, clearly outperforming multilingual BERT. % performance on Finnish datasets is not as good as FinBERT, how to put that into words %We find that the bilingual model achieves comparable performance as the English BERT and nearly matches the performance of FinBERT. We find that when the model vocabulary size is increased, the \bertbase{} architecture has sufficient capacity to learn two remotely related languages to a level where it achieves comparable performance with monolingual models, demonstrating the feasibility of training fully bilingual deep language models. % We describe the procedure taken to train this bilingual BERT. The model and all tools involved in its creation are freely available at \url{https://github.com/TurkuNLP/biBERT}"
"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% A long-standing challenge computer science develop algorithms interact human users via dialog natural language~. Of particular interest task-oriented dialog, wherein user interacts system achieve goal . The system understand user's requests assist taking appropriate actions . In recent years, supervised learning approaches problem become particularly popular, potentially learn complex patterns without relying hand-crafted rules. While data-driven methods already demonstrate impressive performance open-domain dialog , task-oriented dialog models face additional difficulty transferring skills tasks domains present training data. To address issue, present Schema-guided Dialog Dataset Transfer Learning dataset, collection realistic, task-oriented dialogs, especially designed test facilitate transfer learned patterns tasks. Unlike open-domain dialogs, task-oriented dialogs accompanied set steps necessary complete task. These steps typically known priori thus learned data. In fact, practical applications desirable could make modifications logic without discard large parts dataset. The ideal sequences steps dialog would follow complete task arranged graph . Together utterances actions associated nodes graph, hence call task schema, simply schema. Note, call `schema' similar `task specification' , distinct `schemas' define slots intents task used \citet{rastogi2019towards}. %or \citet{kimEighthDialogSystem2019}. In typical supervised model trained to, say, predict next system action task-oriented dialog, schema training tasks implicitly captured learned model parameters. This makes generalizing new task difficult, implicitly memorized schema longer appropriate . With \DATASETNAME\ provide explicit schema representations task thereby enable models condition schema . To collect \DATASETNAME\ use Wizard Oz setup , system's role played human `wizard'. Based pilot studies, found quality crowd-sourced dialogs depends strongly We refined approach extensive internal testing four rounds pilot studies. % All code instructions available open source \anonymous{\DATASETURL}. Our aim create ecologically valid dataset following four attributes, believe crucial dataset high quality: % The progression difficulty allows better assessment dialog models potential transfer learning across levels difficulty. \item Consistency system side. % The behavior task-oriented dialog system largely deterministic subject whims personality wizard. % In particular, encourage wizards follow given task schema closely possible. \item Explicit knowledge base queries. % A large part developing dialog system implementation application programming interface calls, knowledge base queries. % In \DATASETNAME\ represent dialogs three-party interaction wherein system acts intermediary user knowledge base . % Thus, models learn query knowledge base, query be, explain returned knowledge base item user. \end{enumerate} % With properties, create ecologically valid, described by. With paper, contribute The code latter setup, collected data, modeling code freely available \anonymous{\DATASETURL}."," We present \DATASETNAME, a schema-guided task-oriented dialog dataset consisting of 127,833 utterances and knowledge base queries across 5,820 task-oriented dialogs in 13 domains that is especially designed to facilitate task and domain transfer learning in task-oriented dialog. Furthermore, we propose a scalable crowd-sourcing paradigm to collect arbitrarily large datasets of the same quality as \DATASETNAME. Moreover, we introduce novel schema-guided dialog models that use an explicit description of the task to generalize from known to unknown tasks.  We demonstrate the effectiveness of these models, particularly for zero-shot generalization across tasks and domains."
"% -------------------------------------------------------------- % % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % . % % final paper: en-us version % space normally used marker This work licensed Creative Commons Attribution 4.0 International License. License details: \url{http://creativecommons.org/licenses/by/4.0/}. } The relationship group human languages characterized across several dimensions variation , including temporal dimension, wherein languages diverged common historical ancestor case Romance languages; spatial dimension, wherein speaker communities geographically adjacent case Indo-Aryan Dravidian languages India; socio-political dimension, wherein languages evolved shared political and/or religious forces case Arabic Swahili. Languages, language varieties, related across dimensions, often results dialect continuum. Speakers languages constitute dialect continuum usually communicate efficiently using mother tongue. The degree intercomprehensibility speakers different language varieties within continuum mainly determined linguistic similarities. A notable case phenomenon mutual intelligibility among Slavic languages, study paper. One goals linguistics study categorize languages based objective measures linguistic distance. The degrees similarity different levels linguistic structural organization seen preconditions for, well predictors of, successful oral intercomprehension. For closely-related languages, similarities pre-lexical, acoustic-phonetic phonological, level found better predictors cross-lingual speech intelligibility lexical similarities . In different, yet relevant research direction, investigated non-linguists' perception language variation using data popular spoken language guessing game, Great Language Game . By analyzing confusion patterns GLG's human participants, authors shown factors predicting players' confusion game correspond objective measures similarity established linguists. For example, phylogenetic relatedness overlap phoneme inventories identified factors perceptual confusability languages GLG. The development automatic systems determine identity language speech segment received attention speech recognition community . State-of-the-art approaches automatic spoken language identification, henceforth LID, based multilayer deep neural networks . DNN-based LID systems parametric models learn mapping spectral acoustic features speech high-level feature representations geometric space languages linearly separable. These models shown tremendous success discriminating distant languages also closely-related language varieties . Nevertheless, none previous works spoken language recognition analyzed emerging representations neural LID models related languages. Thus, still unknown whether distances representation spaces correspond objective measurements linguistic similarity and/or non-linguists' perception language variation. In paper, aim fill gap consider family Slavic languages case study. Our key contribution two-fold: In paper, attempt bridge different lines research far remained unconnected. On one hand, employ neural architectures field spoken language recognition build robust model identify languages contemporary acoustic realizations Slavic speech. On hand, analyze emerging language representations using techniques established previous research multilingual natural language processing . We consequently shed light speech modality show speech signals complement research done computational studies linguistic typology language variation. % best knowledge % The recognition spoken language % LID speech technology % untranscribed speech % NN made possible end-to-end systems developed, traditional approaches feature many components % closely-related languages similar phonotactics, differ acoustic realizations segments suprasegmental features % language identity objective linguistic measures similarity % The GLG % similarity representation deep neural networks % --------------------------------------------------------------"," Deep neural networks have been employed for various spoken language recognition tasks, including tasks that are multilingual by definition such as spoken language identification. In this paper, we present a neural model for Slavic language identification in speech signals and analyze its emergent representations to investigate whether they reflect objective measures of language relatedness and/or non-linguists' perception of language similarity. While our analysis shows that the language representation space indeed captures language relatedness to a great extent, we find perceptual confusability between languages in our study to be the best predictor of the language representation similarity."
"% % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % . % % % final paper: en-uk version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International Licence. % Licence details: % \url{http://creativecommons.org/licenses/by/4.0/}. % % % final paper: en-us version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. } Aspect-level sentiment classification fundamental task sentiment analysis , aims infer sentiment polarity given opinion target review sentence. An opinion target, also known aspect term, refers word phrase review describing aspect entity. For example, sentence ``The extbf{tastes great, service dreadful}'' consists two opinion targets, namely ``tastes'' ``service''. User's sentiment towards opinion target ``tastes'' positive negative terms target ``service''. Traditional methods usually focus designing set features bag-of-words sentiment lexicon train classifier ASC. Motivated great success deep learning computer vision, speech recognition natural language processing, recent works use neural networks learn low-dimensional continuous text representations without feature engineering, achieve competitive results ASC task. From example, see sentence sometimes refers several opinion targets may express different sentiment polarities, thus one main challenge ASC separate different opinion contexts different targets. To end, abundant state-of-the-art works employ attention mechanism capture sentiment words related given target, aggregate make sentiment prediction. Despite effectiveness attention mechanism, argue fails reach full potential due limited ASC labeled data. It well-known promising results deep learning heavily rely sufficient training data. However, annotation ASC data labour-intensive expensive real-world scenarios, annotators need identify opinion targets sentence also determine corresponding sentiment polarity. The difficulty annotation leads existing public aspect-level datasets relatively small-scale, finally limits potential attention mechanism. Despite lack ASC data, enormous labeled data document-level sentiment classification available online review sites Amazon Yelp. These reviews contain substantial sentiment knowledge semantic patterns. Therefore, one meaningful challenging research question leverage resource-rich DSC data improve low-resource task ASC. For purpose,~ design PRET+MULT framework transfer sentiment knowledge DSC data ASC task sharing shallow embedding LSTM layer. Inspired capsule network,~ propose TransCap share bottom three capsule layers, separate two tasks last ClassCap layer. Fundamentally, PRET+MULT Transcap improve ASC sharing parameters multi-task learning, cannot accurately control interpret knowledge transferred. In work, directly focus aforementioned attention issue ASC task propose novel framework, Attention Transfer Network , explicitly transfer attention knowledge DSC task improving attention capability ASC task. Compared PRET+MULT Transcap, model achieves better results retains good interpretability. In ATN framework, adopt two attention-based BiLSTM networks, respectively, DSC module base ASC module, propose two different methods transfer attention DSC ASC. The first transfer approach called Attention Guidance. Specifically, first pre-train attention-based BiLSTM large-scale DSC data, exploit attention weights DSC module learning signal guide ASC module capture sentiment clues accurately, thereby acheiving improvements. The second approach adopts way Attention Fusion, directly incorporates attention weights DSC module ASC module. The two approaches work different ways different advantages. Attention Guidance aims learn attention ability DSC module faster inference speed, since use external attention DSC testing stage. In contrast, Attention Fusion leverage attention knowledge DSC module testing stage make comprehensive predictions. We conduct experiments two benchmark datasets evaluate different methods. The results indicate ATN model substantially improved incorporating two attention transfer approaches, outperforms compared methods ASC task. %We conducted experiments attention-based LSTM models using SemEval 2014 dataset. The results show attention-based LSTM substantially improved incorporating two proposed methods, resulting model outperforms baseline methods aspect-level sentiment classification. Further analysis also shows good interpretability approaches.","   Aspect-level sentiment classification  aims to detect the sentiment polarity of a given opinion target in a sentence. In neural network-based methods for ASC, most works employ the attention mechanism to capture the corresponding sentiment words of the opinion target, then aggregate them as evidence to infer the sentiment of the target. However, aspect-level datasets are all relatively small-scale due to the complexity of annotation. Data scarcity causes the attention mechanism sometimes to fail to focus on the corresponding sentiment words of the target, which finally weakens the performance of neural models. To address the issue, we propose a novel Attention Transfer Network  in this paper, which can successfully exploit attention knowledge from resource-rich document-level sentiment classification datasets to improve the attention capability of the aspect-level sentiment classification task. In the ATN model, we design two different methods to transfer attention knowledge and conduct experiments on two ASC benchmark datasets. Extensive experimental results show that our methods consistently outperform state-of-the-art works. Further analysis also validates the effectiveness of ATN. Our code and dataset are available at \url{https://github.com/1429904852/ATN}."
"For conversational AI digital assistant system , Natural Language Understanding established component produces semantic interpretations user request, typically involves analysis terms domain, intent, slot . For instance, request ``Play song Taylor Swift"" interpreted falling within scope Music domain Play Song intent Taylor Swift identified Artist slot. Improving accuracy NLU component important satisfactory end-to-end user experience. Without accurate semantic understanding user request, conversational AI system cannot fulfill request satisfactory response action. As one upstream components runtime workflow , NLU's errors also wider blast radius propagates subsequent downstream components, dialog management, routing logic back-end applications, language generation. A straight-forward way improve NLU human annotations. For example, mine user requests resulted unsatisfactory user experience make ground-truth annotations requests produced incorrect NLU outputs, used additional supervision data improving models rule engines within NLU. However, approach labor-intensive expensive. It requires least multiple tiers annotations , hard consider underlying contextual conditions. It also limited existing annotation guidelines may accurately reflect user expectations. Due limitations, leveraging user feedback, implicit explicit, real production systems emerging new area research. In paper, propose scalable automatic approach improving NLU leveraging implicit user feedback, insight user interaction data dialog context rich information embedded user satisfaction intention inferred. For instance, interacting conversational AI system, dissatisfied users might often choose intervene stopping system response middle rephrasing previous request make clearer less room ambiguous interpretation . Our work makes three main contributions. First, knowledge, work first literature introduce scalable automatic approach leveraging domain-agnostic implicit user feedback continuously improve NLU component large-scale conversational AI system production. Second, propose general framework curating supervision data improving NLU live traffic leveraged various subtasks within NLU - e.g., supervision data applied improve individual semantic interpretation models ranking/classification model across interpretations . Last, show extensive set experiments live traffic performance proposed framework impact improving NLU production system across 10 widely used domains. \def\year{2021}\relax %File: formatting-instructions-latex-2021.tex %release 2021.1 \documentclass[letterpaper]{article} % DO NOT CHANGE THIS \usepackage{aaai21} % DO NOT CHANGE THIS \usepackage{times} % DO NOT CHANGE THIS \usepackage{helvet} % DO NOT CHANGE THIS \usepackage{courier} % DO NOT CHANGE THIS \usepackage[hyphens]{url} % DO NOT CHANGE THIS \usepackage{graphicx} % DO NOT CHANGE THIS \urlstyle{rm} % DO NOT CHANGE THIS \def\UrlFont{\rm} % DO NOT CHANGE THIS \usepackage{natbib} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \frenchspacing % DO NOT CHANGE THIS \setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS \setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS \usepackage{amsfonts} \usepackage{amsmath} \usepackage{algorithm} \usepackage{xcolor} \usepackage[noend]{algpseudocode} % \nocopyright %PDF Info Is REQUIRED. % For /Author, add authors within parentheses, separated commas. No accents commands. % For /Title, add Title Mixed Case. No accents commands. Retain parentheses. % \pdfinfo{ % /Title % /Author % /TemplateVersion %} %Leave % /Title % Put actual complete title within parentheses mixed case % Leave space \Title beginning parenthesis alone % /Author % Put actual complete list authors within parentheses mixed case. % Each author comma. If name contains accents, remove them. If LaTeX commands, % remove them. % DISALLOWED PACKAGES % \usepackage{authblk} -- This package specifically forbidden % \usepackage{balance} -- This package specifically forbidden % \usepackage{color % \usepackage{CJK} -- This package specifically forbidden % \usepackage{float} -- This package specifically forbidden % \usepackage{flushend} -- This package specifically forbidden % \usepackage{fontenc} -- This package specifically forbidden % \usepackage{fullpage} -- This package specifically forbidden % \usepackage{geometry} -- This package specifically forbidden % \usepackage{grffile} -- This package specifically forbidden % \usepackage{hyperref} -- This package specifically forbidden % \usepackage{navigator} -- This package specifically forbidden % % \indentfirst} -- This package specifically forbidden % \layout} -- This package specifically forbidden % \multicol} -- This package specifically forbidden % \nameref} -- This package specifically forbidden % \usepackage{savetrees} -- This package specifically forbidden % \usepackage{setspace} -- This package specifically forbidden % \usepackage{stfloats} -- This package specifically forbidden % \usepackage{tabu} -- This package specifically forbidden % \usepackage{titlesec} -- This package specifically forbidden % \usepackage{tocbibind} -- This package specifically forbidden % \usepackage{ulem} -- This package specifically forbidden % \usepackage{wrapfig} -- This package specifically forbidden % DISALLOWED COMMANDS % \nocopyright -- Your paper published use command % \addtolength -- This command may used % \balance -- This command may used % \baselinestretch -- Your paper published use command % \clearpage -- No page breaks kind may used final version paper % \columnsep -- This command may used % \newpage -- No page breaks kind may used final version paper % \pagebreak -- No page breaks kind may used final version paperr % \pagestyle -- This command may used % \tiny -- This acceptable font size. % {2} %May changed 1 2 section numbers desired. % The file aaai21.sty style file AAAI Press % proceedings, working notes, technical reports. % % Title % Your title must mixed case, sentence case. % That means verbs , % nouns, adverbs, adjectives capitalized, including words hyphenated terms, % articles, conjunctions, prepositions lower case unless % directly follow colon long dash % \title{AAAI Press Formatting Instructions \\for Authors Using \LaTeX{} --- A Guide } % \author{ % %Authors % % All authors must font size format. % Written AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help AAAI Publications Committee.}\\ % AAAI Style Contributions Pater Patel Schneider, % Sunil Issar, \\ % J. Scott Penberthy, % George Ferguson, % Hans Guesgen, % Francisco Cruz, % Marc Pujol-Gonzalez % \\ % } % \affiliations{ % %Afiliations % \textsuperscript{\rm 1}Association Advancement Artificial Intelligence\\ % %If multiple authors multiple affiliations % % use superscripts text roman font identify them. % %For example, % % Sunil Issar, \textsuperscript{\rm 2} % % J. Scott Penberthy, \textsuperscript{\rm 3} % % George Ferguson,\textsuperscript{\rm 4} % % Hans Guesgen, \textsuperscript{\rm 5}. % % Note comma placed BEFORE superscript optimum readability % 2275 East Bayshore Road, Suite 160\\ % Palo Alto, California 94303\\ % % email address must roman text type, monospace sans serif % publications21@aaai.org % % See examples next % } %\iffalse % %Example, Single Author, ->> remove \iffalse,\fi place surrounding AAAI title use \title{A Scalable Framework Learning From Implicit User Feedback Improve Natural Language Understanding Large-Scale Conversational AI Systems} \author { Sunghyun Park\thanks{Equal contribution.}, Han Li\textsuperscript{\rm *}, Ameen Patel, Sidharth Mudgal, Sungjin Lee, Young-Bum Kim, Spyros Matsoukas, Ruhi Sarikaya \\ } \affiliations{ % Affiliations Amazon Alexa AI \\ \{sunghyu, lahl, paameen, sidmsk, sungjinl, youngbum, matsouka, rsarikay\}@amazon.com } %\fi \iffalse %Example, Multiple Authors, ->> remove \iffalse,\fi place surrounding AAAI title use \title{My Publication Title --- Multiple Authors} \author { Authors First Author Name,\textsuperscript{\rm 1} Second Author Name, \textsuperscript{\rm 2} Third Author Name \textsuperscript{\rm 1} \\ } \affiliations { % Affiliations \textsuperscript{\rm 1} Affiliation 1 \\ \textsuperscript{\rm 2} Affiliation 2 \\ firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com } \fi \newcommand{\red}[1]{{\color{red} #1}} \newcommand{\vecb}[1]{\mathbf{#1}} \newtheorem{definition}{Definition} \newpage \bibliography{citation} % \bibliographystyle{aaai21} \end{document}"," Natural Language Understanding  is an established component within a conversational AI or digital assistant system, and it is responsible for producing semantic understanding of a user request. We propose a scalable and automatic approach for improving NLU in a large-scale conversational AI system by leveraging implicit user feedback, with an insight that user interaction data and dialog context have rich information embedded from which user satisfaction and intention can be inferred. In particular, we propose a general domain-agnostic framework for curating new supervision data for improving NLU from live production traffic. With an extensive set of experiments, we show the results of applying the framework and improving NLU for a large-scale production system and show its impact across 10 domains."
"Chinese Word Segmentation fundamental task Chinese natural language processing , aims identifying word boundaries sentence composed continuous Chinese characters. It provides basic component NLP tasks like named entity recognition, dependency parsing, semantic role labeling, etc. Generally, previous studies model CWS task character-based sequence labeling task . Recently, pre-trained models BERT introduced CWS tasks, could provide prior semantic knowledge boost performance CWS systems. directly fine-tunes BERT several CWS benchmark datasets. fine-tunes BERT multi-criteria learning framework, criterion shares common BERT-based feature extraction layer owns private projection layer. combines Chinese character glyph features pre-trained BERT representations. % builds unified BERT-based model multi-criteria CWS tasks fine-tunes eight CWS criteria jointly. proposes neural CWS framework WMSeg, utilizes memory networks incorporate wordhood information pre-trained model ZEN. PTMs proved quite effective fine-tuning downstream CWS tasks. However, PTMs used previous works usually adopt language modeling pre-training tasks. Thus, usually lack task-specific prior knowledge CWS ignore discrepancy pre-training tasks downstream CWS tasks. \end{table} To deal aforementioned problems PTMs, consider introducing CWS-specific pre-trained model based existing CWS corpora, leverage prior segmentation knowledge. However, multiple inconsistent segmentation criteria CWS, criterion represents unique style segmenting Chinese sentence words, shown Table. Meanwhile, easily observe different segmentation criteria could share large proportion word boundaries them, boundaries word units ``閺夊骸顭'', ``鏉╂稑鍙'' ``閸楀﹤鍠呯挧'', segmentation criteria. It shows common prior segmentation knowledge shared different criteria. In paper, propose CWS-specific pre-trained model MetaSeg. To leverage shared segmentation knowledge different criteria, MetaSeg utilizes unified architecture introduces multi-criteria pre-training task. Moreover, alleviate discrepancy pre-trained models downstream unseen criteria, meta learning algorithm incorporated multi-criteria pre-training task MetaSeg. Experiments show MetaSeg could outperform previous works significantly, achieve new state-of-the-art results twelve CWS datasets. Further experiments show MetaSeg better generalization performance downstream unseen CWS tasks low-resource settings, improve Out-Of-Vocabulary recalls. To best knowledge, MetaSeg first task-specific pre-trained model especially designed CWS.","     Recent researches show that pre-trained models  are beneficial to Chinese Word Segmentation .     However, PTMs used in previous works usually adopt language modeling as pre-training tasks, lacking task-specific prior segmentation knowledge and ignoring the discrepancy between pre-training tasks and downstream CWS tasks.     % However, existing approaches usually fine-tune general-purpose pre-trained models directly on separate downstream CWS corpora.     % These general-purpose pre-trained models usually adopt language modeling objectives, lack task-specific prior segmentation knowledge, and ignore the discrepancy between pre-training tasks and downstream CWS tasks.     In this paper, we propose a CWS-specific pre-trained model MetaSeg, which employs a unified architecture and incorporates meta learning algorithm into a multi-criteria pre-training task.     Empirical results show that MetaSeg could utilize common prior segmentation knowledge from different existing criteria and alleviate the discrepancy between pre-trained models and downstream CWS tasks.     Besides, MetaSeg can achieve new state-of-the-art performance on twelve widely-used CWS datasets and significantly improve model performance in low-resource settings."
"% % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % . % % % final paper: en-us version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. } The following instructions directed authors papers submitted COLING-2020 accepted publication proceedings. All authors required adhere specifications. Authors required provide Portable Document Format version papers. The proceedings designed printing A4 paper. Authors countries access word-processing systems limited contact publication co-chairs Derek F. Wong , Yang Zhao Liang Huang soon possible. We may make additional instructions available \url{http://coling2020.org/}. Please check website regularly.","   This document contains the instructions for preparing a paper submitted   to COLING-2020 or accepted for publication in its proceedings. The document itself   conforms to its own specifications, and is therefore an example of   what your manuscript should look like. These instructions should be   used for both papers submitted for review and for final versions of   accepted papers. Authors are asked to conform to all the directions   reported in this document."
"Automatic question answering active area research within natural language processing. %Open-domain question answering looks methods re-utilize systems across multiple domains. One possible way approach task look answers text passages collection documents. Recent research shown promising results developing neural models passage retrieval tasks, including Retrieval Question Answering, Open Domain Question Answering, MS MARCO. The models systems often trained using dual encoder framework questions passages encoded separately. Training effective neural retrieval model usually requires large amount high-quality data. To alleviate need high-quality data, training approached two-stages: pre-training noise data fine tuning smaller amount high-quality data, also regarded ``gold"" data. % One significant advantage dual encoder framework that, question passage embeddings available, efficient nearest neighbour search used retrieve passages contain answers questions. When used question answering, one advantage dual encoder training batches allows use, question, passages answer questions batch negatives. Given training batches randomly sampled question-passage pairs, negatives batch random nature. While effective many retrieval tasks, random negatives limitation targeted challenging enough clearly separate passage answers given question passage. How sample negatives way widens separation improves contrast correct incorrect passages remains open question. % A viable approach negative sampling use ``hard"" negatives specific question answer pair. In paper systematically explore use ``hard'' negatives neural passage retrieval models train using two-stage approach. Using hard negatives part dual encoder framework shown advantageous different tasks . %Using hard negatives part dual encoder framework shown advantageous cross-lingual tasks. %For example, \citet{guo-etal-2018-effective} show training hard negatives generated retrieving ``coarse"" negatives low-resolution model improves quality translation pairs retrieved dual encoder model. %Similarly, \citet{dpr} showed improvement using hard negatives retrieved BM25 model passage retrieval part Open Domain Question Answering task. %In contrast previous works, We explore different types negatives, experiment using pre-training fine-tuning stages. The types negatives tried are: We first use hard negatives data use pre-train models. We leverage question generator model described generate new questions passages use pre-training stage . %The new questions paired original passages. %The augmented set question-passage pairs used train first stage neural retrieval model. % It shown effective approach improve passage retrieval models. During pre-training use negatives generated strategy 4\footnote{Or strategy 1, strategy 4 feasible} improve retrieval model, strategies could introduce false negatives data. %Our initial experiments showed using retrieval models find hard negatives point, often generated noisy question-passage pairs, especially pre-training data includes synthetic pairs. %As generated question passage pairs sometimes noise, retrieval-based approaches may create better question-passage pairs synthetic pairs. %We apply heuristic based context negatives pre-training task. Next, continue fine tuning stage using small amount gold training data. At stage, explore four types negative sampling. To best knowledge, first work explores effectiveness hard negatives passage retrieval systematic way, integrates retrieval models pre-training stage. Our overall experimental architecture outlined Figure. %For question-passage pair training set, collect negatives using strategies listed augment training. We conduct experiments approach two passage retrieval tasks: Open Domain QA SQuAD) MS MARCO. %Open Domain QA Natural Questions~, Open Domain QA SQuAD, MS MARCO. Our results show four kinds hard negatives improve dual encoder models significantly consistent performance gains across tasks. However, depending types questions domain, one kind hard negative may perform better others particular task. For example, context negatives work best NQ semantic retrieval-based negatives work best SQuAD. We ensemble models trained different types hard negatives. The final models achieve state-of-the-art performance Open Domain QA task improvement prior works 0.8--2.9 points accuracy rates. %\hl{highlight numbers here}. The main contribution paper are:"," %In this paper we explore the discriminate training for neural passage retrieval models with hard negatives. %Four different hard negative sampling strategies are experimented, including one BM25 based hard negative, two semantic based hard negatives, and one heuristic hard negative. %For training the model, we employ a two stage dual encoder model with pre-training using synthetic data followed by a fine-tuning using the gold training data. %Discriminate training is applied on both stages. %The trained models are evaluated on 3 passage retrieval tasks from Open Domain QA NQ, Open Domain QA SQuAD, and MS MARCO. %Results show that all of them can improve the naive dual encoder models significantly with consistent performance gain over all three tasks. %However, there is no single type of hard negative perform best on all tasks. %Further analysis show that the synthetic question pre-training with discriminate training is an effective approach to improve the passage retrieval performance. %The best trained models establish the new state-of-the-art on retrieval tasks of Open Domain QA NQ and SQuAD. %"
"% Events describe things happen occur world, mostly involving entities perform % affected events spatio-temporal dimensions event . The event may mentioned document multiple times different context. To recognize two event mentions refer contributes understanding natural language text resolving NLP tasks. In work, study coreference resolution problem events entities. Coreference resolution commonly modeled binary classification problem : first learn features mention, classify two given mentions \footnote{Some work maps two mentions single matching score, e.g., ; treated special case binary classification.}. The essential step framework lies representation learning mention. However, prior work often failed learn representations powerful expressivity due following two reasons: Point-wise representation learning. % Usually mention surrounded words sentence. Most work tries learn mention representations extracting features merely particular sentence including mention. We argue routine representation learning coreference match end task coping with: relation recognition mention pairs. The predicted relation input mention pair rather individual mentions. By different context, two mentions referring not. To fit different scenarios, mention learn representation considering counterpart is. Unstructured representation learning. An event mention consists multiple arguments describe event: what, who, when, where, etc. Most prior work tried encode elements single distributed representation vector compare vectors two mentions. This less optimal since humans recognize subjects, objects etc. often compare event arguments type . If, instance, event locations different, people make judgement quickly even without comparing mention arguments. Denoting mention single distributed vector lets machines lose opportunity conduct fine-grained reasoning humans uneasy explain model's prediction. To promote expressivity representations, work proposes % pairwise structured representation learning paired representation learning . \modelname\enspace alleviates aforementioned two limitations two designs: \paragraph{Pairwise representation learning.} In work, treat mention pair rather single mention object representation learning. Specifically, concatenate two sentences whole sequence forward ROBERTa system.\footnote{RoBERTa put special token ``SEP'' separate two sentences.} RoBERTa takes ``whole sequence'' input token, including mention spans, two sentences able compare tokens beginning. This better comparing two mentions learning representation separately. We apply pairwise representation learning event entity coreference tasks. The binary classifier mention matching function end take pair contextualized mention representations reasoning. \paragraph{Structured representation learning.} Looking following two sentence % think need learn humans' behaviors recognizing event coreference. : ``Over \textcolor{blue}{69,000 people} \underline{lost} lives quake, including 68,636 \textcolor{purple}{Sichuan province}.'' : ``Up \textcolor{blue}{6,434 people} \underline{lost} lives Kobe earthquake 4,600 \textcolor{purple}{Kobe}.'' First, humans often determine relationship two event mentions comparing triggers arguments separately follows: \textbullet\enspace ``69,000 people'' vs. ``6,434 people'' \textbullet\enspace ``lost'' vs. ``lost'' \textbullet\enspace ``Sichuan province'' vs ``Kobe'' % Second, mismatch components may decisive decisive others. For example, people find location ``Sichuan province'' match ``Kobe'', directly claim two events coreference even without looking whole sentence. This human behavior indicates make full structure event, overall representation encompassing event elements less informative perform fine-grained cross-mention comparison actually improve interpretability model predictions. Overall, \modelname~enables two mentions learn context other, improves model's explainability performing fine-grained reasoning. We report \modelname~on event coreference entity coreference benchmarks. Despite simple architecture, \modelname~ surpasses prior SOTA system big margins."," Co-reference of Events and of Entities are commonly formulated as binary classification problems, given a pair of events or entities as input. Earlier work addressed the main challenge in these problems -- the representation of each element in the input pair by:   modelling the representation of one element  without  considering the other element in the pair;  encoding all attributes of one element  into a single non-interpretable vector, thus losing the ability to compare %fine-grained cross-element attributes.  In this work we propose paired representation learning  for  coreference resolution. % \drc{ % In this work we propose pairwise structured representation learning  \XD{Do we want to change the model name? Since it is not structured for entity. And for event, most numbers are from trigger only representation} \dr{Maybe just PairedRL ? If so, we can cahange Pairwise Structure to ``Paired"" in the title and the rest of the paper.}for  coreference resolution.}  Given a pair of elements  our model treats the pair's sentences as a single sequence so that each element in the pair learns its representation by encoding its own context as well the other element's context. In addition, when representing events, \modelname\enspace is structured in that it represents the event's arguments to facilitate their individual contribution to the final prediction. As we show, in both  event  and entity coreference benchmarks, our unified approach, \modelname\enspace, outperforms prior state of the art systems with a large margin.  % \drc{Given a pair of elements  our model treats the pair's sentences as a single sequence so that each element in the pair learns its representation by encoding its own context as well the other element's context. In addition, when representing events, \modelname\enspace is structured in that it represents the event's arguments to facilitate their individual contribution to the final prediction. As we show, in both  event  and entity coreference benchmarks, our unified approach, \modelname\enspace, outperforms prior state of the art systems with a large margin.}  % \dr{Do we want to emphasize the structure part in the abstract? The contribution of structured is relatively small.} %This work studies the event and entity coreference which is commonly formulated as a binary classification problem given a pair of events or entities. The main challenge lies in the representation learning of each element in the input pair. However,  prior work mostly has the following drawbacks:  Systems model the representation of one object  with no consideration of   the other object in the pair;  Systems often encode all related attributes of one object  into a single and unexplainable vector; this reduces the model's interpretability and  mismatches the fact that humans tend to recognize the event relations by comparing fine-grained cross-event arguments. Motivated, we propose pairwise structured representation learning  \XD{Do we want to change the model name? Since it is not structured for entity. And for event, most numbers are from trigger only representation} for  coreference resolution. By ``Pairwise'', \modelname\enspace treats sentences of the input pair as a whole sequence so that each object in the pair learns its representation by encoding its own context as well the other's context. This paradigm applies to both event and entity coreference. In addition, \modelname\enspace develops a ``structured''  framework to represent all the event arguments so that each argument can explain its contribution to the final prediction.  In both  event  and entity coreference benchmarks, \modelname\enspace beats prior state of the art systems with big margins ."
"Neural machine translation explored typically sentence-level translation settings. Such sentence-level nmt models inevitably suffer ambiguities multiple %% semantically-different translations accepted interpretations possible source sentence. To address issue, context-aware nmt models recently presented %to address issue incorporate document-level information translation. Most existing context-aware nmt models end-to-end models take input current source sentence translated context sentences, output translation. These models trained document-level parallel data, namely, sentence pairs surrounding, usually preceding, sentences source target language. However, practical scenarios, document-level bilingual data limited language pairs domains, % posing challenge building context-aware nmt systems . In study, propose simple yet effective approach context-aware nmt % consisting using two primitive components, sentence-level nmt model document-level language model . This approach allows us independently train two components bilingual data monolingual data, respectively, without resorting expensive document-level bilingual data. % thereby document-level bilingual data needed. To give probabilistic foundation combination two independent models, exploit % take advantage probabilistic nature nmt decoding. When generating sequence, left-to-right decoder outputs categorical probability distribution vocabulary every time step. % . The decoder assigns higher probability tokens would suitable step. Therefore, % assume multiple valid translations possible source sentence, % , ambiguities sentence-level nmt confused by, decoder gives higher % sequence probability translation plausible without considering contexts. % wrong ones. Our idea adjust probability distributions context-aware manner using document-level lm target language % capable modeling models inter-sentential dependencies target side document. % Since network structure nmt models evolves quickly, model-agnostic approach like preferable model-tweaking approach . We evaluate methods English French, Russian Japanese translations OpenSubtitles2018 corpus terms bleu scores contrastive discourse test sets. Experimental results confirmed method achieved comparable performance existing context-aware nmt models. The contributions paper follows:"," % There exist inevitable ambiguities in translating a single sentence, and we resort to context beyond the target sentence for resolving such ambiguities. Although many context-aware neural machine translation models have been proposed to incorporate contexts in translation,  most of those models are trained end-to-end on parallel documents aligned in sentence-level.  Because only a few domains  have such document-level parallel data, we cannot perform accurate context-aware translation in most domains. We therefore present a simple method to turn a sentence-level translation model into a context-aware model by incorporating a document-level language model into the decoder. Our context-aware decoder is built upon only a sentence-level parallel corpora and monolingual corpora; thus no document-level parallel data is needed. In a theoretical viewpoint, the core part of this work is the novel representation of contextual information using point-wise mutual information between context and the current sentence. We show the effectiveness of our approach in three language pairs, English to French, English to Russian, and Japanese to English, by evaluation in bleu and contrastive tests for context-aware translation."
"A keyphrase multi-word text representing highly abstractive information long document. Keyphrase extraction task aims generate appropriate keyphrase set given document, thus helping identify salient contents concepts document. Recently, KE task attracted much research interest since serves important component many downstream applications text summarization, document classification, information retrieval question generation. Early KE systems commonly operate extractive manner, usually consists two steps: 1) selecting candidates source document using heuristic rules, 2) ranking candidates list determine correct. However, two-step ranking approaches usually based feature engineering, labor-intensive. Motivated progress sequence-to-sequence applications neural networks, KE research's focus gradually shifted deep learning methods. \citet{DBLP:conf/acl/MengZHHBC17} first formulate KE sequence generation problem introduce attentive Seq2Seq framework generate keyphrase sequence conditioned input document. Compared traditional methods, Seq2Seq based method achieves superior performance. Seq2Seq based KE exposed two major challenges: 1) Document-level representation learning. For Seq2Seq generative framework, latent hidden representation important factor, quality directly affect decoder's performance. In KE task, input commonly long document instead sentence, poses greater challenge latent representation learning. 2) Modeling compositionality keyphrases set. The elements keyphrase set dependent correlated. That is, better modeling inherent composition embodied keyphrase set learning process effectively boost diversity quality final results. Recently, various approaches proposed optimize Seq2Seq generation framework KE task. To learn better latent representation, previous studies try introduce different encoding structures address two issues simultaneously. We explore incorporate dependency tree document representation learning encoder part. The syntactic dependency tree help locate key information document. In practice, document graph constructed depending syntactic dependency tree, convolution process operated . On hand, rethink implication compositionality keyphrase set. In training process generative models, whether candidate keyphrase generated hinges document itself, also depends keyphrases already generated. Therefore, dynamic graph updating mechanism introduced explicitly modeling inter-dependency among keyphrases. In method, graph structure encoder part dynamically updated according keyphrases generated decoder part. Concretely, one keyphrase decoded, information transferred modify edge weights document graph score function, latent hidden representation also updated. In approach, could dynamically ensure information exchange encoder decoder parts directions. The contribution work three-fold: 1) A novel generative framework, Div-DGCN, proposed leverages dynamic syntactic graph encoder diversified inference process KE. 2) A dynamic computation mechanism adopted model compositionality keyphrase set explicitly enhancing information interchange encoder decoder parts Seq2Seq architecture. 3) Extensive experiments conducted five benchmarks show proposed method effective competitive baselines several metrics."," Keyphrase extraction  aims to summarize a set of phrases that accurately express a concept or a topic covered in a given document. Recently, Sequence-to-Sequence  based generative framework is widely used in KE task, and it has obtained competitive performance on various benchmarks. The main challenges of Seq2Seq methods lie in acquiring informative latent document representation and better modeling the compositionality of the target keyphrases set, which will directly affect the quality of generated keyphrases. In this paper, we propose to adopt the Dynamic Graph Convolutional Networks  to solve the above two problems simultaneously. Concretely, we explore to integrate dependency trees with GCN for latent representation learning. Moreover, the graph structure in our model is dynamically modified during the learning process according to the generated keyphrases. To this end, our approach is able to explicitly learn the relations within the keyphrases collection and guarantee the information interchange between encoder and decoder in both directions. Extensive experiments on various KE benchmark datasets demonstrate the effectiveness of our approach."
"Neural machine translation , state-of-the-art machine translation paradigm, recently approached two different sequence decoding strategies. The first type autoregressive translation models generate output tokens one one following left right direction, often criticized slow inference speed. The second type non-autoregressive translation models adopt parallel decoding algorithm produce output tokens simultaneously, translation quality often inferior auto-regressive models. % transfer AT knowledge NAT models. A line research argues lack contextual dependency target sentences potentially leads deteriorated performance NAT models. To boost NAT translation performance, many recent works resort knowledge transfer well-trained AT model. Typical knowledge tranfer methods include sequence-level knowledge distillation translation outputs generated strong AT models, word-level knowledge distillation AT decoder representations, fine-tuning AT model curriculum learning, etc. %shared encoder In work, adopt multi-task learning framework shared encoder transfer AT model knowledge NAT model. %Our framework jointly optimizes AT NAT models boost NAT translation quality. Specifically, take AT task auxiliary task sharing encoder parameters AT NAT models. We hypothesize AT NAT encoders, although belong sequence-to-sequence learning task, capture different linguistic properties representations source sentences. To empirically verify hypothesis, evaluate encoder set probing tasks \iffalse estimate representation similarity\fi AT NAT models. Further machine translation experiments WMT14 EnglishGerman WMT16 EnglishRomanian datasets confirm effectiveness proposed Multi-Task NAT. Our contributions follows: \iffalse"," Non-Autoregressive machine Translation  models have demonstrated significant inference speedup but suffer from inferior translation accuracy. The common practice to tackle the problem is transferring the Autoregressive machine Translation  knowledge to NAT models, e.g., with knowledge distillation. In this work, we hypothesize and empirically verify that AT and NAT encoders capture different linguistic properties and representations of source sentences. Therefore, we propose to adopt the multi-task learning to transfer the AT knowledge to NAT models through the encoder sharing. Specifically, we take the AT model as an auxiliary task to enhance NAT model performance. Experimental results on WMT14 English$\Leftrightarrow$German and WMT16 English$\Leftrightarrow$Romanian datasets show that the proposed multi-task NAT achieves significant improvements over the baseline NAT models. In addition, experimental results demonstrate that our multi-task NAT is complementary to the standard knowledge transfer method, knowledge distillation. }"
"In language modelling , learn distributions sequences words, subwords characters, latter two allow open-vocabulary generation. We rely subword segmentation widespread approach generate rare subword units . However, lack representative corpus, terms word vocabulary, constrains unsupervised segmentation . As alternative, could use character-level modelling, since also access subword information , face long-term dependency issues require longer training time converge. In context, %our research question is: Is segmentation approach corpus-independent provides shorter length sequence characters? focus syllables, based speech units: ``A syl-la-ble con-tains sin-gle vow-el u-nit''. These linguistically-based units characters, behave mapping function reduce length sequence larger ``alphabet'' syllabary. Their extraction rule-based corpus-independent, data-driven methods hyphenation using dictionaries approximate well . % . Previous work syllable-aware neural \lm failed beat characters closed-vocabulary generation word-level ; %, however, propose assess syllables three new settings. %but discuss two points follows. First, analysed open-vocabulary scenario syllables disregarding additional functions input layer . Second, extended scope 6 20 languages cover different levels orthographic depth, degree grapheme-phoneme correspondence factor increase complexity syllabification. English language deep orthography whereas Finnish transparent . Third, distinguished rule-based syllabification hyphenation tools, also validated proximity LM. %we prefer use rule-based syllabification whenever available, employ hyphenation proxies otherwise. % even specific segmentation rules. Therefore, revisit \lm open-vocabulary generation syllables using pure recurrent neural networks diverse set languages, compare performance characters subword units. %We analyse overlap subword units, compare performance s. %We investigate %, also include languages % Universal Dependencies dataset , %with transparent orthographies, Turkish Finnish . %Our results confirm syllables reliable segmentation setting language modelling, even language presents deep orthography. %less-ambiguous syllabification due %a recent alphabetisation . We thereupon explore syllables effect another generation task NMT."," Language modelling is regularly analysed at word, subword or character units, but syllables are seldom used. Syllables provide shorter sequences than characters, they can be extracted with rules, and their segmentation typically requires less specialised effort than identifying morphemes. We reconsider syllables for an open-vocabulary generation task in 20 languages.  We use rule-based syllabification methods for five languages and address the rest with a hyphenation tool, which behaviour as syllable proxy is validated. With a comparable perplexity, we show that syllables outperform characters, annotated morphemes and unsupervised subwords. Finally, we also study the overlapping of syllables concerning other subword pieces and discuss some limitations and opportunities."
"Sanskrit considered one oldest Indo-Aryan languages. The oldest known Sanskrit texts estimated dated around 1500 BCE. A large corpus religious, philosophical, socio-political scientific texts multi cultural Indian Subcontinent Sanskrit. Sanskrit, multiple variants dialects, Lingua Franca ancient India ~. Therefore, Sanskrit texts important resource knowledge ancient India people. Earliest known Sanskrit documents available form called Vedic Sanskrit. Rigveda, oldest four Vedas, principal religious texts ancient India, written Vedic Sanskrit. In sometime around 5\textsuperscript{th} BCE, Sanskrit scholar named Panini ~ wrote treatise Sanskrit grammar named Ashtadhyayi, Panini formalized rules linguistics, syntax grammar Sanskrit. Panini's grammar globally appreciated insightful analysis Sanskrit completeness descriptive coverage spoken standard language Panini's time. Ashtadhyayi \footnote{https://www.britannica.com/topic/Ashtadhyayi} oldest surviving text comprehensive source grammar Sanskrit today provides often unique information Vedic, regional socio-linguistic usage. Ashtadhyayi literally means eight chapters eight chapters contain around 4000 sutras rules total. These rules completely define Sanskrit language known today. Ashtadhyayi remarkable conciseness contains highly systematic approach grammar. Because well defined syntax extensively well codified rules, many researchers made attempts codify Panini閳ユ獨 sutras computer programs analyze Sanskrit texts. This paper tries address problem unavailability benchmark corpus provides morphological analysis method derivative nouns result Sanskrit suffixes applied root verbs nouns using machine learning approach. \subsection{Introduction Pratyaya Sanskrit} Different ways inflectional word formation mentioned ~ below: Here introduction, explain primary secondary suffixes. Sanskrit rich inflected language depends nominal verbal inflections communication meaning ~. A fully inflected unit called pada. The subanta padas inflected nouns tinanta padas inflected verbs. \subsubsection{Kridanta subanta } These formed primary affixes called krit added verbs derive substantives, adjectives indeclinable. DAtum nAma karoti iti krit. Kridanta play vital role understanding Sanskrit language. Many morphological analyzers lacking complete analysis Kridanta. Examples krit pratyaya below: krit suffixes mainly seven types viz. tavyat, tavya, anIyara,Ryat, yat, kyap, kelimer. \subsubsection{Taddhitanta subanta } The secondary derivative affixes called taddhit derive secondary nouns primary nouns. Some examples taddhit pratyaya below: taddhit suffixes mainly fourteen types."," This paper presents first benchmark corpus of Sanskrit Pratyaya  and inflectional words  formed  due to suffixes along with neural network based approaches to process the formation and splitting of inflectional words. Inflectional words spans the primary and secondary derivative nouns as the scope of current work. Pratyayas are an important dimension of morphological analysis of Sanskrit texts. There have been Sanskrit Computational Linguistics tools for processing and analyzing Sanskrit texts. Unfortunately there has not been any work to standardize \& validate these tools specifically for derivative nouns analysis. In this work, we prepared a Sanskrit suffix benchmark corpus called Pratyaya-Kosh to evaluate the performance of tools. We also present our own neural approach for derivative nouns analysis while evaluating the same on most prominent Sanskrit Morphological Analysis tools. This benchmark will be freely dedicated and available to researchers worldwide and we hope it will motivate all to improve morphological analysis in Sanskrit Language."
"Sanskrit one oldest Indo-Aryan languages. The oldest known Sanskrit texts estimated dated around 1500 BCE. It one oldest surviving languages world. A large corpus religious, philosophical, socio-political scientific texts multi cultural Indian Subcontinent Sanskrit. Sanskrit, multiple variants dialects, Lingua Franca ancient India . Therefore, Sanskrit texts important resource knowledge ancient India people. Earliest known Sanskrit documents available form called Vedic Sanskrit. Rigveda, oldest four Vedas, principal religious texts ancient India, written Vedic Sanskrit. In sometime around 5\textsuperscript{th} century BCE, Sanskrit scholar named pARini wrote treatise Sanskrit grammar named azwADyAyI, pARini formalized rules linguistics, syntax grammar Sanskrit. azwDyAyI oldest surviving text comprehensive source grammar Sanskrit today. azwADyAyI literally means eight chapters eight chapters contain around 4000 sutras rules total. These rules completely define Sanskrit language known today. azwADyAyI remarkable conciseness contains highly systematic approach grammar. Because well defined syntax extensively well codified rules, many researchers made attempts codify pARini閳ユ獨 sutras computer programs analyze Sanskrit texts. \subsection{Introduction Sandhi Sandhi Split Sanskrit} Sandhi refers phonetic transformation word boundaries, two words combined form new word. Sandhi literally means 'placing together' principle sounds coming together naturally according certain rules codified grammarian pARini azwADyAyI. There 3 different types Sandhi defined azwADyAyI. An example type Sandhi shown below: \end{quote} Sandhi Split hand, resolves Sanskrit compounds 閳ユ笡honetically merged閳 words constituent morphemes. Sandhi Split comes additional challenge splitting compound word correctly, also predicting split. Since Sanskrit compound word split multiple ways based multiple split locations possible, split words may syntactically correct semantically may meaningful. \end{quote} \subsection{Existing Work Sandhi} The current resources available Sandhi open domain accurate. Three popular publicly available set Sandhi tools viz. JNU, UoH \& INRIA tools mentioned table . \end{table*} An analysis description tools present paper Sandhikosh . The paper introduced dataset Sandhi Sandhi Split verification compared performance tools table dataset. Neural networks used Sandhi Split many researchers, example , . The task Sandhi mainly addressed rule based algorithm e.g. . There research Sandhi using neural networks public domain far. This paper describes experiments Sandhi operation using neural networks compares results suggested approach results achieved using existing Sandhi tools . \subsection{Existing Work Sandhi Split} Many researchers like tried codify pARini閳ユ獨 rules achieving Sandhi Split along lexical resource. proposed statistical method based Dirichlet process. Finite state methods also used . A graph query method proposed . Lately, Deep Learning based approaches increasingly tried Sandhi Split. used one-layer bidirectional LSTM two parallel character based representations string. proposed deep learning models Sandhi Split sentence level. uses double decoder model compound word split. The method proposed paper describes RNN based, two stage deep learning method Sandhi Split isolated compound words without using lexical resource sentence information. In addition above, exist multiple Sandhi Splitters open domain. The prominent ones JNU Sandhi Splitter , UoH Sandhi Splitter INRIA Sanskrit reader companion. The paper compares performance 3 tools results. This attempt create benchmark area Sanskrit Computational Linguistics."," This paper describes neural network based approaches to the process of the formation and splitting of word-compounding, respectively known as the Sandhi  and Vichchhed, in Sanskrit language. Sandhi is an important idea essential to morphological analysis of Sanskrit texts. Sandhi leads to word transformations at word boundaries. The rules of Sandhi formation are well defined but complex, sometimes optional and in some cases, require knowledge about the nature of the words being compounded. Sandhi split or Vichchhed is an even more difficult task given its non uniqueness and context dependence. In this work, we propose the route of formulating the problem as a sequence to sequence prediction task, using modern deep learning techniques. Being the first fully data driven technique, we demonstrate that our model has an accuracy  better than the existing methods on multiple standard datasets, despite not using any additional lexical or morphological resources. The code is being made available at https://github.com/IITD-DataScience/Sandhi\_Prakarana"
"% Unsupervised representation learning allows models learn high-level latent representations unlabeled data. % Models pretrained unsupervised data fine-tuned small amount labeled data. % % Deep probabilistic generative models presents powerful approach learn representations modeling data generation process. % Variational AutoEncoders one popular approaches representation learning modeling latent features unit Gaussian space. % Vector-Quantized VAE method learn discrete representations data. Speech waveforms complex, high-dimensional form data influenced number underlying factors, broadly categorized linguistic contents speaking styles. % Learning disentangled latent representations speech wide set applications generative tasks, including speech synthesis, data augmentation, voice transfer, speech compression. Downstream tasks speech recognition speaker classification also benefit learned representations. % A pre-trained model also fine-tuned classification tasks speech recognition speaker classification. % \ngyuzh{what rephrase like: Downsteam tasks speech recognition speaker classification also benefit learned representations.} Because cost, complexity, privacy concerns around collecting labeled speech data, lot interest unsupervised representation learning speech. Of particular interest learn representations speech styles unsupervised data due difficulty describing prosody human labels. Some previous works aim learn global representations entire speech sequences. % Global style tokens learn dictionary embeddings speech without prosody labels. % As another example, Hsu et al. model disentangled speech styles hierarchy variational autoencoder . % Hu et al. proposed content style separation model pre-training single-speaker dataset text transcription minimizing mutual information content style representation. Other works try learn fine-grain localized representations speech. % apply self-supervised learning unlabeled speech data extract localized latent representations fine-tuned speech recognition. % FHVAE learns sequence high-level features applying VAE every frame. % leverages vector-quantized VAE learn discrete sequence representation speech. We propose framework learn global localized representation speech. In order disentangle content style representations, apply local encoder VQ layer learn discrete per-timestep representation speech captures linguistic contents global VAE extraction per-utterance representations reflect speech styles. We disentangle local global representations mutual information loss. We evaluate quality linguistic style representations running speech speaker recognition models reconstructed speech. We also show global representation captures speaker information well enough obtain speaker classification model training linear projection layer top global representation one example per speaker."," We present an approach for unsupervised learning of speech representation disentangling contents and styles. Our model consists of:  a local encoder that captures per-frame information;  a global encoder that captures per-utterance information; and  a conditional decoder that reconstructs speech given local and global latent variables. Our experiments show that  the local latent variables encode speech contents, as reconstructed speech can be recognized by ASR with low word error rates , even with a different global encoding;  the global latent variables encode speaker style, as reconstructed speech shares speaker identity with the source utterance of the global encoding. Additionally, we demonstrate an useful application from our pre-trained model, where we can train a speaker recognition model from the global latent variables and achieve high accuracy by fine-tuning with as few data as one label per speaker. % % \rpang{How about: Our deep generative model consists of:  a local encoder that captures per-frame information;  a global encoder that captures per-utterance information; and  a conditional decoder that reconstruct speech given local and global latent variables, potentially extracted from different utterances. Our experiments show that  the local latent variables encode speech contents, since reconstructed speech can be recognized by ASR with low word error rates , even with a different global encodings;  the global latent variables encode speaker style, as reconstructed speech shares speaker identity with the source utterance of the global encoding and a speaker recognition model can be trained from the global latent variables with as few as one supervised example per speaker.  % }"
"%Sentiment analysis one fundamental tasks natural language processing aims find attitude author expressed his/her sentence. One important sub-tasks SA aspect based sentiment analysis goal find sentiment polarity toward specific aspect mentioned sentence. Due importance ABSA, several sub-tasks proposed studied problem, including aspect category extraction, aspect term extraction, opinion word extraction opinion summarization . Among sub-tasks, Targeted Opinion Word Extraction important sub-task might provide useful information explain prediction sentiment polarity ABSA system. In particular, goal TOWE find words express attitude author toward specific target mentioned sentence. For instance, sentence ``The food good, especially basic dishes, drinks delicious"", word ``good"" opinion word target ``food"" delicious opinion word target word ``drinks"". Among different applications, TOWE used target-oriented sentiment analysis pair-wise opinion summarization . %Sentiment analysis one fundamental tasks natural language processing aims find attitude author expressed his/her sentence. One important sub-tasks SA aspect based sentiment analysis goal find sentiment polarity toward specific aspect mentioned sentence. Due importance ABSA, several sub-tasks proposed studied problem, including aspect category extraction, aspect term extraction, opinion word extraction opinion summarization . Among topics, Targeted Opinion Word Extraction important task might provide useful information explain and/or improve sentiment polarity prediction ABSA systems. In particular, given target word input sentence, goal TOWE find words sentence help express attitude author toward aspect represented target word. For instance, sentence ``The food good, especially basic dishes, drinks delicious"", ``good"" opinion word target word ``food"" opinion words target word ``drinks"" would involve ``delicious''. Among different applications, TOWE finds application target-oriented sentiment analysis pair-wise opinion summarization . %Targeted Opinion Word Extraction important task aspect based sentiment analysis sentiment analysis . Given target word input sentence, goal TOWE find words sentence help express attitude author toward aspect represented target word. For instance, sentence ``The food good, especially basic dishes, drinks delicious"", ``good"" opinion word target word ``food"" opinion words target word ``drinks"" would involve ``delicious''. As opinion words might provide useful information explain and/or improve sentiment prediction ABSA systems, TOWE applied different problems, including target-oriented sentiment analysis pair-wise opinion summarization . Targeted Opinion Word Extraction important task aspect based sentiment analysis sentiment analysis . Given target word input sentence, goal TOWE identify words sentence help express attitude author toward aspect represented target word. For instance, running example, sentence ``All warranties honored XYZ disappointing."", ``disappointing"" opinion word target word ``warranties"" opinion words target word ``company"" would involve ``reputable''. Among others, TOWE finds applications target-oriented sentiment analysis opinion summarization . %As opinion words might provide useful information explain and/or improve sentiment prediction ABSA systems, TOWE applied different problems, including target-oriented sentiment analysis pair-wise opinion summarization . %A notable problem although related tasks TOWE extensively explored past, work explicitly consider TOWE problem literature . In particular, related task TOWE opinion word extraction aims locate terms used express attitude explicitly sentence . A key difference OWE TOWE OWE require opinion words tie target words sentence opinion words TOWE explicitly paired given target word. Note previous works also attempted jointly predict target opinion words ; however, target words still paired corresponding opinion words studies . %Among previous works TOWE, The early approach TOWE involved rule-based lexicon-based methods recent work focused deep learning models problem . One insights rule-based methods syntactic structures sentences provide useful information improve performance TOWE . However, syntactic structures exploited current deep learning models TOWE . Consequently, work, seek fill gap extracting useful knowledge syntactic structures help deep learning models learn better representations TOWE. In particular, based dependency parsing trees, envision two major syntactic information complementarily beneficial deep learning models TOWE, i.e., syntax-based opinion possibility scores syntactic word connections representation learning. First, syntax-based possibility scores, intuition closer words target word dependency tree input sentence tend better chance opinion words target TOWE. For instance, running example, opinion word ``disappointing"" sequentially far target word ``warranties"". However, dependency tree shown Figure , ``disappointing"" directly connected ``warranties"", promoting distance ``disappointing"" ``warranties"" dependency tree useful feature TOWE. Consequently, work, propose use distances words target word dependency trees obtain score represent likely word opinion word TOWE . These possibility scores would introduced deep learning models improve representation learning TOWE. In order achieve possibility score incorporation, propose employ representation vectors words deep learning models compute model-based possibility score word sentence. The model-based possibility scores also aim quantify likelihood opinion word word sentence; however, based internal representation learning mechanism deep learning models TOWE. To end, propose inject information syntax-based possibility scores models TOWE enforcing similarity/consistency syntax-based model-based possibility scores words sentence. The rationale leverage possibility score consistency guide representation learning process deep learning models generate effective representations TOWE. In work, employ Ordered-Neuron Long Short-Term Memory Networks obtain model-based possibility scores words sentences TOWE. ON-LSTM introduces two additional gates original Long Short-Term Memory Network cells facilitate computation model-based possibility scores via numbers active neurons hidden vectors word. %The second type syntactic information employed TOWE work considers dependency connections words sentence. %As deep learning models need compute representation vector word perform opinion word prediction TOWE, %While possibility scores aim improve representation vectors TOWE via syntax-based possibility features, second type syntactic information work seeks leveraging dependency connections words infer effective context words encoded representation vector word sentence. In particular, motivated running example, argue effective context words representation vector current word TOWE involve neighboring words current word target word dependency tree. For instance, consider running example ``warranties"" target word ``reputable"" word need compute representation vector. One one hand, important include information neighboring words ``reputable"" representation models know context current word . On hand, information target word also encoded representation vector ``reputable"" models aware context target word make appropriate comparison representation decide label ``reputable"" case. Note syntactic connection mechanism allows models de-emphasize context information ``I'' representation ``reputable"" improve representation quality. Consequently, work, propose formulate intuitions importance score matrix whose cells quantify contextual importance word would contribute representation vector another word given target word TOWE. These importance scores conditioned distances target word words dependency tree. Afterward, score matrix consumed Graph Convolutional Neural Network model produce final representation vectors opinion word prediction. For second type syntactic information work, main motivation improve representation vector computation word leveraging dependency connections words infer effective context words word sentence. In particular, motivated running example, argue effective context words representation vector current word TOWE involve neighboring words current word target word dependency tree. For instance, consider running example ``warranties"" target word ``reputable"" word need compute representation vector. On one hand, important include information neighboring words ``reputable"" representation models know context current word . On hand, information target word also encoded representation vector ``reputable"" models aware context target word make appropriate comparison representation decide label ``reputable"" case. Note syntactic connection mechanism allows models de-emphasize context information ``I'' representation ``reputable"" improve representation quality. Consequently, work, propose formulate intuitions importance score matrix whose cells quantify contextual importance word would contribute representation vector another word, given target word TOWE. These importance scores conditioned distances target word words dependency tree. Afterward, score matrix consumed Graph Convolutional Neural Network model produce final representation vectors opinion word prediction. Finally, order improve induced representation vectors TOWE, introduce novel inductive bias seeks explicitly distinguish representation vectors target-oriented opinion words words sentence. We conduct extensive experiments demonstrate benefits proposed model, leading state-of-the-art performance TOWE several benchmark datasets. %Finally, order improve induced representation vectors TOWE, introduce novel inductive bias seeks explicitly distinguish representation vectors target-oriented opinion words opinion words sentence . Extensive experiments conducted demonstrate benefits proposed model, leading state-of-the-art performance TOWE several datasets. %Finally, order improve induced representation vectors TOWE, introduce novel inductive bias seeks explicitly distinguish representation vectors target-related opinion words opinion words sentence . As target-related non-target opinion words used express opinion author , expect explicit representation distinction would help better separate two types opinion words based target word, eventually improving performance TOWE work. We conduct extensive experiments demonstrate benefits proposed model, leading state-of-the-art performance TOWE several datasets. %the close distance ``disappointing"" target word suggest models include information ``warranties"" representation vector ``disappointing"" long distance ``warranties"" ``reputable"" help prevent/mitigate representation vector ``reputable"". The presence information target word representation vectors help models successfully accept ``disappointing"" opinion word reject ``reputable"" case. %the close words target word would provide effective information induce representation vectors word sentence TOWE farther ones. %we argue syntactic neighboring words dependency tree would provide effective information induce representation vector word opinion word prediction. For instance, running example target word ``warranties"", close distance ``disappointing"" target word suggest models include information ``warranties"" representation vector ``disappointing"" long distance ``warranties"" ``reputable"" help prevent/mitigate representation vector ``reputable"". The presence information target word representation vectors help models successfully accept ``disappointing"" opinion word reject ``reputable"" case. %employ dependency connections words infer effective context words . %employ syntactic neighboring words compute representation vectors word sentence TOWE. %extends popular Long Short-Term Memory Networks introducing two additional gates hidden vector computation. These new gates controls long neuron hidden vectors activated across different time steps sentence . Based controlled neurons, model-based importance score word determined number active neurons word possesses operation ON-LSTM. To knowledge, first time ON-LSTM applied RE literature. %How encode syntax-based importance scores words deep model? In paper, propose employ syntax-based importance scores retain update information encoded representations word. In particular, words syntactically important retain information computation graph deep model information less important words discarded frequently. In order impose information update policy model, use new proposed architecture Ordered-Neuron Long Short-Term Memory . ON-LSTM extension well-known Long Short-Term Memory two additional gates . These new gates employed control frequency updating neuron across different time steps sentence. Concretely, values master forget input gates determine much information hidden vector LSTM cell retained updated based word current time step. Thereby, one infer importance scores inferred model using values master forget input gates. So, based characteristics ON-LSTM, encode syntax-based importance scores model, propose exploit syntax-based importance scores regulate model-based importance scores. Specifically, training time, encourage model-based scores consistent syntax-based importance scores. %the two words ``disappointing"" ``warranties"" directly connected other. %Early feature-based models shown syntactical structure sentence useful TWOE. More specifically, application dependency tree TOWE two fold: Pairwise Word Importance: Dependency tree useful infer relative importance word toward another word sentence. This relative importance could helpful TOWE attend important words target word. To infer pair-wise importance two words using dependency tree, one computes distance two words dependency tree. For instance, running example, sentence ``All warranties honored HP disappointing"", opinion word ``disappointing"" sequentially far target word ``warranties"". However, dependency tree shown Figure , two words ``disappointing"" ``warranties"" directly connected other. The short distance two words could helpful infer importance word ``disappointing"" target ``warranties"". Word Connection: Dependency tree could provide better contextual information word via connections word head dependants, thus helps improve word representations. Thereby, dependency tree could benefit TOWE. For instance, running example, head ``reputable"" ``company"" head ``warranties"" ``disappointing"". Therefore, would easier infer opinion word ``disappointing"" related target word ``warranties"" ``reputable"" irrelevant. %Besides difference rule-based deep learning models TOWE regarding representation learning methods, rule-based methods exploited syntactic structures sentences improve performance TOWE %In particular, related tasks TOWE involves target word extraction/aspect term exaction , opinion word extraction . A key difference OWE TOWE opinion words OWE general need tie target words sentence TOWE explicitly %Despite potential benefits, TOWE studied works past, characterizing early rule-based lexicon-based approaches recently deep learning models . %In literature, feature-based models deep learning model proposed target word extraction opinion word extraction . While joint models predict opinion target words, cannot pair them, thus unable solve task TOWE. In literature, works studied task TOWE, including early attempts rule-based lexicon-based approaches recent works deep learning models TOWE ."," Targeted opinion word extraction  is a sub-task of aspect based sentiment analysis  which aims to find the opinion words for a given aspect-term in a sentence. Despite their success for TOWE, the current deep learning models fail to exploit the syntactic information of the sentences that have been proved to be useful for TOWE in the prior research. In this work, we propose to incorporate the syntactic structures of the sentences into the deep learning models for TOWE, leveraging the syntax-based opinion possibility scores and the syntactic connections between the words. We also introduce a novel regularization technique to improve the performance of the deep learning models based on the representation distinctions between the words in TOWE. The proposed model is extensively analyzed and achieves the state-of-the-art performance on four benchmark datasets.  %Deep learning models have been shown to achieve the state-of-the-art performance for TOWE in the recent studies.  %While previous feature-based models have shown syntactical structure  is useful for this task, recent deep neural nets ignore this information in their model. To address this limitation, in this paper, we propose a new approach which incorporates syntactical structure  into deep neural nets. More specifically, our model employs the dependency tree to capture the relative importance of the words to the aspect-term and to encode the connections between words. Our extensive experiments on four benchmark datasets prove the superiority of the proposed model, leading to new state-of-the-art results on all datasets. Moreover, detailed analysis shows the effectiveness of the components of the proposed model."
"Aspect-based Sentiment Analysis fine-grained version sentiment analysis aims find sentiment polarity input sentences toward given aspect. We focus term-based aspects ABSA aspects correspond terms input sentence. For instance, ABSA system able return negative sentiment input sentence ``The staff polite, quality food terrible.'' assuming ``food'' aspect term. %Aspect based sentiment analysis fine-grained version sentiment analysis . In ABSA, goal find sentiment polarity sentence toward given aspect. In literature, two versions aspect proposed: Aspect-category: Aspect categories set pre-defined categories given sentence contains opinion author toward one them. Aspect categories may explicitly appear sentence. Aspect-term: Aspect term subsequent sentence given sentence express sentiment toward it. For instance example The staff polite, quality food terrible., author positive sentiment toward aspect-category service negative sentiment toward aspect-term food. In paper, introduce novel model sentiment analysis toward aspect-term. %The early attempts ABSA performed feature engineering produce useful features statistical models problem . One limitation feature-based models require significant human effort linguistic background design effective features. In order overcome limitation, %The typical network architectures ABSA literature involve convolutional neural networks , recurrent neural networks , memory networks , attention gating mechanisms . %automatically induce effective features ABSA Due important applications , ABSA studied extensively literature. In studies, deep learning employed produce state-of-the-art performance problem . Recently, order improve performance, syntactic dependency trees integrated deep learning models ABSA . Among others, dependency trees help directly link aspect term syntactically related words sentence, thus facilitating graph convolutional neural networks enrich representation vectors aspect terms. %Although graph-based models achieved decent performance ABSA, models However, least two major issues graph-based models addressed boost performance. First, representation vectors words different layers current graph-based models ABSA customized aspect terms. This might lead suboptimal representation vectors irrelevant information ABSA might retained affect model's performance. Ideally, expect representation vectors deep learning models ABSA mainly involve related information aspect terms, important words sentences. Consequently, work, propose regulate hidden vectors graph-based models ABSA using information aspect terms, thereby filtering irrelevant information terms customizing representation vectors ABSA. In particular, compute gate vector layer graph-based model ABSA leveraging representation vectors aspect terms. This layer-wise gate vector would applied hidden vectors current layer produce customized hidden vectors ABSA. In addition, propose novel mechanism explicitly increase contextual distinction among gates improve representation vectors. %as hidden vectors different layers graph-based models tend capture different levels contextual information, gate vectors different layers also maintain level contextual distinction. To end, propose novel mechanism explicitly increase contextual distinction among gate vectors improve quality representation vectors. The second limitation current graph-based deep learning models failure explicitly exploit overall importance words sentences estimated dependency trees ABSA problem. In particular, motivation graph-based models ABSA neighbor words aspect terms dependency trees would important sentiment terms words sentence. The current graph-based models would focus syntactic neighbor words induce representations aspect terms. However, based idea important words, also assign score word sentences explicitly quantify importance/contribution sentiment prediction aspect terms. In work, hypothesize overall importance scores dependency trees might also provide useful knowledge improve representation vectors graph-based models ABSA. Consequently, propose inject knowledge syntax-based importance scores graph-based models ABSA via consistency model-based importance scores. In particular, using representation vectors graph-based models, compute second score word sentences reflect model's perspective importance word sentiment aspect terms. The syntax-based importance scores employed supervise model-based importance scores, serving method introduce syntactic information model. In order compute model-based importance scores, exploit intuition word would important ABSA similar overall representation vector predict sentiment sentence final step model. In experiments, demonstrate effectiveness proposed model state-of-the-art performance three benchmark datasets ABSA. In summary, contributions include: %, propose obtain another important score word sentence based representation vectors models. These model-based importance scores %In particular, ABSA, words might introduce useful information predict sentiment aspect terms words sentence %In particular, words given sentence might involve useful information relation prediction RE words, dependency tree sentence help better identify important words assign higher importance scores . We expect introducing importance information words deep learning models might lead improved performance RE. Consequently, work, propose obtain importance score word sentences dependency trees . These serve general tree representation incorporate syntactic information deep learning models RE. %In particular, aspect terms important words sentences ABSA, %Syntactical structure, e.g., dependency tree, could shorten distance syntactically related words thus improve contextualized representation words. In order incorporate syntactical tree deep models, recent work mainly employs graph convolutional network model interaction words based syntactic tree. In order emphasize given aspect term, current models use representation aspect term generated GCN either directly final classification gate filter features sequential model. However, methods cannot benefit information given aspect term control information flow graph based model. Moreover, expected words syntactically related given aspect term convey information sentiment toward it. Unfortunately, non existing work considers relative importance final representation sentence. In order address issue, propose new graph based model employs semantic given aspect term control interaction nodes/words GCN model emphasize syntactically important words final representation sentence. %Due application ABSA downstream applications, e.g., opinion mining, gained lot attention natural language processing community several methods proposed task. Early attempts employed feature engineering extract useful features statistical models like SVM . These methods require extensive human effort strong linguistic knowledge. They also suffer low generalization ability. Due limitations, neural networks deep models superseded feature based models obtain promising results ABSA . Early deep models ABSA exploited sequential models , convolutional neural nets even memory networks . In order improve performance, attention gating mechanism also widely adopted deep models. Recently, shown syntactical information could also improve performance deep models . Syntactical structure, e.g., dependency tree, could shorten distance syntactically related words thus improve contextualized representation words. In order incorporate syntactical tree deep models, recent work mainly employs graph convolutional network model interaction words based syntactic tree. In order emphasize given aspect term, current models use representation aspect term generated GCN either directly final classification gate filter features sequential model. However, methods cannot benefit information given aspect term control information flow graph based model. Moreover, expected words syntactically related given aspect term convey information sentiment toward it. Unfortunately, non existing work considers relative importance final representation sentence. In order address issue, propose new graph based model employs semantic given aspect term control interaction nodes/words GCN model emphasize syntactically important words final representation sentence. %In particular, paper, propose novel model employs representation given aspect term compute gate. This gate applied output one layer GCN. By so, information represented aspect term would erase non-relevant information node/word obtained interaction neighbors one aggregation step GCN. As different layers GCN capture different substructure graph, e.g., 1-hop vicinity vs 2-hop vicinity, propose exploit different gates different layers. To ensure gates different layers same, propose novel method encourage diversity among gates different layers GCN. Moreover, addition exploiting semantic aspect term control interactions nodes/words GCN, paper, propose encourage model emphasize words syntactically important aspect term. In particular, use distance word aspect term dependency tree indication syntactic importance word aspect term. This importance employed supervision signal encourage model emphasize words syntactically important aspect term. This obtained final layer model sentiment prediction performed. More specifically, first estimate semantic importance word employing final representation word input classifier predict label distribution compute KL-Divergence label distribution predicted word representation label distribution predicted sentence representation. If two label distribution similar, shows word representation contains information model consumes perform final classification. Finally, order ensure words syntactically important aspect term semantically important model too, decrease divergence distribution syntactic score semantic score word via KL-Divergence two distributions. %Our extensive experiments three benchmark datasets, empirically prove effectiveness proposed model leading new state-of-the-art results three benchmark datasets. A novel method regulate GCN-based representation vectors words using given aspect term ABSA. A novel method encourage consistency syntax-based model-based importance scores words based given aspect term. Extensive experiments three benchmark datasets ABSA, resulting new state-of-the-art performance datasets."," Aspect-based Sentiment Analysis  seeks to predict the sentiment polarity of a sentence toward a specific aspect. Recently, it has been shown that dependency trees can be integrated into deep learning models to produce the state-of-the-art performance for ABSA. However, these models tend to compute the hidden/representation vectors without considering the aspect terms and fail to benefit from the overall contextual importance scores of the words that can be obtained from the dependency tree for ABSA. In this work, we propose a novel graph-based deep learning model to overcome these two issues of the prior work on ABSA. In our model, gate vectors are generated from the representation vectors of the aspect terms to customize the hidden vectors of the graph-based models toward the aspect terms. In addition, we propose a mechanism to obtain the importance scores for each word in the sentences based on the dependency trees that are then injected into the model to improve the representation vectors for ABSA. The proposed model achieves the state-of-the-art performance on three benchmark datasets.  %These models employ graph based neural nets to incorporate syntactical structure into the model. However, they ignore the aspect term information to control the interaction between words in the syntax tree which is modeled by graph neural net.  % Moreover, they neglect the consistency between the syntactic and semantic importance of the words toward the given aspect. %Moreover, the relative importance of the words to the given aspect term based on their syntactical role is neglected in the final representation produced by the existing syntax-aware models. To address these two issues, in this paper, we introduce a new syntax-aware model which incorporates gating mechanism to control information flow in the graph based model using the given aspect term. It also ensures the words that are syntactically important to the aspect term are more pronounced in the final representation of the sentence. Our extensive experiments on three benchmark datasets empirically prove the effectiveness of the proposed model leading to new state-of-the-art results on all three benchmark datasets."
"Curriculum learning trains model using easy examples first gradually adding difficult examples. It speed learning improve generalization supervised learning models . %With curriculum learning, models trained according curriculum sorts training examples according difficulty. %The model first trained easiest examples. %More difficult examples gradually added according pre-determined schedule. %Training curriculum lead faster model convergence baseline model trained without curriculum . %With machine learning models data sets continuing grow, knowing impact model training environment, need efficient model training . %\Hong{I donot understand need include sentence. What gain?} %Hong. In Bengio et al's ""curribulum learning"" work, found CL effect speed convergence better optimization non-convex functions. You may want evaluate work, addition performance. A major drawback existing curriculum learning techniques rely heuristics measure difficulty data, either ignore competency model training rely heuristics well. For example, sentence length often used proxy difficulty NLP tasks . %Similarly, number objects image used proxy difficulty image recognition task . Such heuristics useful limitations. First, heuristic chosen may actually proxy difficulty. Depending task, long sequences could signal easier harder examples, signal difficulty. Second, model's notion difficulty may align heuristic imposed human developing model. It may examples appear difficult human fact easy model learn. Competency recently introduced mechanism determine new examples added training data . %However, work competency schedule ad hoc, actually look competency model assumed schedule according learning heuristics. However, work competency monotonically increasing function pre-determined initial value. %competency, . Once set, competency evaluated training. Ideally, model competency measured training epoch, training data could appropriately matched model given point training. If model improving, difficult training data added next epoch. But performance declines, difficult examples removed, smaller, easier training set used next epoch. In study, propose estimate difficulty examples ability deep learning models latent variables based model performance using Item Response Theory , well-studied methodology psychometrics test set construction subject evaluation . IRT models estimate latent parameters difficulty examples %Hong: I changed ""examples"" ""samples"" earlier context, like it, change back. Just stick one use throughout paper. latent ability parameter individuals . %Hong. Here may want use ""model"" ability instead ""subject"" IRT models learned administering test large number subjects, collecting grading responses, using subject-response matrix estimate latent traits data. These learned parameters used estimate ability future subjects, based graded responses examples. %Hong. Similarly, would introduce ""model"", ""test-takers"" IRT seen wide adoption machine learning community, primarily due fact fitting IRT models requires large amount human annotated data example. However, recent work shown IRT models fit using machine-generated data instead human-generated data input . Because IRT learns example difficulty subject ability together, %it interesting framework consider problem curriculum learning. work propose replacing heuristics learned parameters curriculum learning. First, experiment replacing typical difficulty heuristic learned difficulty parameters. Second, propose \modelname~, novel curriculum learning framework uses estimated ability model training process dynamically identify appropriate training data. At training epoch, latent ability model estimated using output labels generated current epoch. Once ability known, training data model reasonable chance labeling correctly included training. As model improves, estimated ability improve, training examples added. To best knowledge, first work learn model competency training directly comparable difficulty examples. %Hong. You may want define terminology front. Here say ""training data pool"". Earlier say ""examples"". Perhaps use ""items"", define used paper %To explicit, work goal Our study test following three hypotheses: H1: Using learned latent difficulties instead difficulty heuristics leads better held-out test set performance models trained using curriculum learning, H2: A dynamic data selection curriculum learning strategy probes model ability training leads better held-out test set performance static curriculum learning strategy take model ability account, H3: Dynamic curriculum learning efficient static curriculum learning, leading faster convergence. We test hypotheses GLUE classification data sets . Our contributions follows: demonstrate curriculum learning, learned difficulty outperforms traditional difficulty heuristics, introduce novel curriculum learning framework automatically selects training data based estimated ability model, show training using \modelabbr~leads better performance traditional curriculum learning methods fully supervised competitive baseline. Our findings support overall curriculum learning framework, demonstrate learning difficulty ability lead performance improvements beyond common heuristics.\footnote{Code implementing experiments learned difficulty parameters GLUE data sets available \url{https://jplalor.github.io/irt}.} %We release learned difficulty parameters GLUE data sets resource community explore learned difficulties dynamic curriculum learning.}%\footnote{Code data used work, including learned difficulty values, released upon publication.}","   Curriculum learning methods typically rely on heuristics to estimate the difficulty of training examples or the ability of the model. %  They also either ignore the ability of the model or rely on heuristics there as well.   %In this work we show that learning difficulty and ability is more effective for curriculum learning than applying heuristics.   In this work, we propose replacing difficulty heuristics with learned difficulty parameters.    We also propose \modelname~, a strategy that probes model ability at each training epoch to select the best training examples at that point.   %\modelabbr~adds data at a rate commensurate with the model's capability, in contrast to scheduled curricula that add data at a predetermined rate.   We show that models using learned difficulty and/or ability outperform heuristic-based curriculum learning models on the GLUE classification tasks.   %Using \modelabbr~to train LSTM models further improves performance.   %Experimental results demonstrate that \modelabbr~outperforms static CL strategies on a number of NLP classification tasks."
"Entity normalization variant generation fundamental variety tasks semantic search relation extraction . Given entity name , goal entity normalization convert canonical form , goal entity variant generation convert set different textual representations refer entity E . \looseness=-1 Typically, entity normalization variant generation done first performing entity linking , i.e., matching entity names appearing context named entities curated knowledge bases , use canonical form variations residing KBs complete tasks. Unfortunately, scenarios, search , entity names surrounded context. Furthermore, specialized domain-specific applications, may knowledge base govern names relevant entities. Thus, entity linking always applicable. In paper, take view %the problem differently, particular, argue entity normalization variant generation done without contextual information external KBs understand internal structures entity names. % Fundamental success entity linking availability contextual information ontological information . % external KBs use master datasets match input entity names. \todo{One may argue DBpedia Wikipedia good proxy. It may useful talk related work taking view here.} % For example, searching \example{General Electric Company}, need also consider variations like \example{GE Co.}, \example{G.E.}, \example{General Electric}, etc. without relying contextual information external KBs. % Performing entity normalization variant generation contextless fashion extremely challenging surface forms entity names. % Several attempts made parse structured representation entity names. As observed , entity names often %structured representation implicit structures exploited solve entity normalization variant generation. Table shows manipulate structured representations entity names generate different variations without help context external knowledge. % For example, know \example{Michael} \component{first} \example{Jordan} \component{last} \example{Michael Jordan}, generate two variations: \example{M. Jordan} \example{Jordan, Michael} . \end{table*} Declarative frameworks proposed allow %high-skill developers manually specify rules parse entity names %the structured representation. %of enity names. To avoid low-level manual effort, used fully supervised methods identifying nested entities embedded flat named entities. Unfortunately, labeled data rarely available leverage methods real-world. To mitigate need training data, proposed active learning %-based system, LUSTRE, semi-automatically learn rules mapping entity names structured representations. By %making use using regex-based extractors list comprehensive dictionaries capture crucial domain vocabularies, LUSTRE generate rules achieve SoTA results. However, complex realistic scenarios, dictionaries may available regex-based extractors alone expressive enough. Moreover, shown Section, LUSTRE cannot handle long entities machine logs. In paper, present %learning framework learns high-quality BERT-CRF models parsing entity names structured representations %of entity names low-resource settings, namely, labeled data available. The proposed framework essentially active learning-based approach learns human interactions. We believe comprehensible user interfaces essential active learning-based approaches, especially labeling tasks require non-trivial human labels . Therefore, developed system named PARTNER implements framework. We designed interface PARTNER similar LUSTRE, also made major modifications user friendly. Interested readers find video demo PARTNER \url{http://ibm.biz/PARTNER}. Our main contributions include: % \todo{Low-resource setting mean different things. It would helpful clearly describe mean here.} % { % \squishlist % \item We developed full-fledged system built upon effective framework learn high-quality BERT-CRF models parsing structured representation entity names without contextual information . % \item To minimize human effort, framework combines active learning weak supervision, usually applied isolation. % \item Both datasets system made publicly available. % \squishend % } { \squishlist \item %We propose A hybrid framework combining active learning weak supervision effectively learn BERT-CRF-based models low human effort. \item %We developed A full-fledged system, intuitive UI, implements framework. \item Comprehensive experimental results showing framework learns high-quality models merely dozen labeled examples. \squishend } \medskip Related work. Our problem related flat nested named entity recognition . However, discussed , NER focuses identifying outermost flat entities completely ignores internal structured representations. identify nested entities within context using fully supervised methods require large amounts labeled data, whereas goal learn labels contextless fashion. Active learning weak supervision widely adopted solving many entity-centric problems, entity resolution , NER , entity linking . While power combination two techniques demonstrated domains , best knowledge, two approaches usually applied isolation prior entity-related work. Recently, data programming approaches use labeling functions/rules generate weak labels train machine learning models low-resource scenarios. Data programming approaches like Snorkel usually assume labeling functions manually provided users, indicating target users must programming skills order provide labeling functions. In contrast, goal minimize human effort lower human skills . % Named entity recognition % Our problem similar NER fine-grained version nested NER several key differences: labeled data available settings; focus scenarios entity names . Recently, proposed active learning based approaches NER low-resource settings. Following direction, enhance active learning weak supervision reduce labeling efforts. % Understanding entity names important task many entity-centric tasks entity disambiguation information retrieval. Computing textual similarity two entity names one widely used methods tell whether name . However, entity names highly ambiguous text-based similarity functions robust enough resolve complex cases . Consider following date entities: % \smallskip % { % {\small % \squishlist % \item [] ``December first, nineteen nineteen"", % \item [] ``December first, nineteen ninety"", % \item [] ``1919-12-01"". % \squishend % } % } % \smallskip % Two different entities may textually similar ), entity may textually dissimilar ). % Entity names merely sequences characters, usually internal semantic structures useful understanding different name variations. For example, identify \example{December} \component{Month}, \example{first} \component{Day}, \example{nineteen nineteen} \component{Year}, transform components separately assemble transformed components according standardized format, \component{Year}-\component{Month}-\component{Day}, translate . % Currently, named entity recognition subsequent entity disambiguation task either treated separately , treated one joint task looking unstructured text entities extracted linking reference knowledge base . However, tasks , entities given without context . % Enriching entities normalized form variations obtained manipulating semantic structures helpful tasks. % Several attempts made understand entity name structures. proposed declarative frameworks allow high-skill developers manually specify rules translate entity names semantic structures. To avoid labor-intensive clearly scalable manual process, proposed active learning-based framework named LUSTRE semi-automatically learns parsing rules. However, availability list comprehensive, accurate, complete dictionaries crucial success LUSTRE. % \looseness=-1 Understanding entity name structures viewed sequence labeling problem. Recently, deep learning-based approaches shown achieve state-of-the-art performance sequence labeling problems . One foundations approaches use pre-trained character word embeddings carry semantic information learned large text corpus. However, deep learning-based approaches data hungry."," \looseness=-1  %Entity names usually have structured representation that is useful for many entity-related tasks such as entity normalization and variant generation. Learning the structured representation of entity names in low-resource settings without context and external knowledge bases is challenging. In this paper, we present a novel learning framework that combines active learning and weak supervision to solve this problem, and we experimentally show that our method can learn high-quality BERT-CRF models in low-resource settings. A video demo of a system that implements this framework is included in supplementary materials. Structured representations of entity names are useful for many entity-related tasks such as entity normalization and variant generation. Learning the implicit structured representations of entity names without context and external knowledge  is particularly challenging. In this paper, we present a novel learning framework that combines active learning and weak supervision to solve this problem. Our experimental evaluation show that this framework enables the learning of high-quality models from merely a dozen or so labeled examples."
"In recent years, voice assistants become ubiquitous household, performing tasks users conversational interface. Given informal nature language settings, many ways agent misunderstand user commands, intent, complete actions. A vital part ensuring user continues interact agent user's confidence agent's ability correctly smoothly respond requests. Relying conversational rather transactional dialogue core method building trust . However, conversational dialogue difficult generate often lead situations agent produces utterance user unable properly respond creates friction user agent. We refer situations dialogue breakdown, agent prevented completing desired goal dialogue either user exasperation agent misunderstanding . Detecting breakdown occurs essential part ensuring effects mitigated, either recovering occur avoiding creation altogether . As dialogue settings, gathering labelled data difficult. Data collection must either rely interrupting user interactions paying third-party rate dialogue completion, often intrusive, expensive, affected user bias . In settings, semi-supervised learning methods natural way fully utilize limited labelled data leveraging large amounts unlabelled data commonly available. In paper, investigate two semi-supervised learning methods improve performance dialogue breakdown detection. We consider continued pre-training Reddit dataset approximation dialogue domain would like eventually fine-tune on. We also consider self-supervised manifold based data augmentation , data augmentation method utilizes pre-trained model generate new training examples. We evaluate methods Dialogue Breakdown Detection Challenge English shared task. We submit final models 2020 DBDC5 shared task, placing first English track. We beat baselines submissions 12\% accuracy, 0.135 F1 score, 0.02 JS divergence. In experiments data 2019 , baseline model improves previous challenge winners 13\% . The addition semi-supervised learning methods improves baseline models 2\% accuracy, 0.02 F1 score, 0.003 Jensen Shannon Divergence. Although specifically consider task dialogue breakdown detection, semi-supervised techniques applicable generally supervised dialogue task provide simple way improve performance.","   Building user trust in dialogue agents requires smooth and consistent dialogue exchanges. However, agents can easily lose conversational context and generate irrelevant utterances. These situations are called dialogue breakdown, where agent utterances prevent users from continuing the conversation. Building systems to detect dialogue breakdown allows agents to recover appropriately or avoid breakdown entirely. In this paper we investigate the use of semi-supervised learning methods to improve dialogue breakdown detection, including continued pre-training on the Reddit dataset and a manifold-based data augmentation method. We demonstrate the effectiveness of these methods on the Dialogue Breakdown Detection Challenge  English shared task. Our submissions to the 2020 DBDC5 shared task place first, beating baselines and other submissions by over 12\% accuracy. In ablations on DBDC4 data from 2019, our semi-supervised learning methods improve the performance of a baseline BERT model by 2\% accuracy. These methods are applicable generally to any dialogue task and provide a simple way to improve model performance."
"Coreference resolution task grouping mentions text refer real-world entity clusters . %The task important prerequisite variety natural language processing systems, textual entailment information extraction . Coreference resolution difficult task %since requires reasoning, context understanding, background knowledge real-world entities, %Therefore, task driven research natural language processing machine learning, particularly since release ontonotes multilingual corpus providing annotated coreference data Arabic, Chinese English used 2011 2012 {\CONLL} shared tasks . Since then, substantial research English coreference, recently using neural coreference approaches , leading significant increase %that significantly increased performance coreference resolvers English. % % The general objective %the research described % paper close evident gap recent literature coreference. By contrast, almost research Arabic coreference; performance Arabic coreference resolution improved much since {\CONLL} 2012 shared task, particular neural architectures proposed--the current state-of-the-art system remains model proposed %feature-based . In paper close obvious gap proposing knowledge first neural coreference resolver Arabic. One explanation lack research might simply lack training data large enough task. Another explanation might Arabic problematic English %more complex English rich morphology, %rich proprieties, %has many dialects, and/or %contains high degree ambiguity. We explore first possibilities. %Our proposal address aspects. %one aspect problem. % Another explanation might lack large-size training data task. % We explore Coreference resolution divided two subtasks--mention detection mention clustering--as illustrated %an example two steps Figure . % % Coreference resolution difficult task % %since % requires reasoning, context understanding, background knowledge real-world entities, % % %Therefore, task % driven research natural language processing machine learning, particularly since release ontonotes multilingual corpus providing annotated coreference data Arabic, Chinese English . % %and various approaches applied. In early work, coreference's two subtasks usually carried pipeline fashion , candidate mentions selected prior mention clustering step. Since introduced end-to-end neural coreference architecture achieved state art carrying two tasks jointly, first proposed , state-of-the-art systems followed approach. % first end-to-end coreference system solves two subtasks jointly. % This leads number subsequent systems significantly increased coreference resolution performance English. % By contrast, little developments Arabic coreference resolution, performance Arabic coreference resolution improve much since CoNLL 2012 shared task current state-of-the-art system remain feature-based . However, end-to-end solution attempted Arabic. We intend explore whether end-to-end solution would practicable corpus limited size. % One explanation might Arabic complex English morphologically rich proprieties, many dialects, contains high degree ambiguity. % Another explanation might lack large-size training data task. The approach followed adapt %In work, introduce recipe show state-of-the-art English coreference resolution architecture Arabic %can adapted Arabic language follows. We started strong baseline system , enhanced contextual {\BERT} embeddings . We explored three methods improving model's performance Arabic. %In total evaluated three options, The first method pre-process Arabic words heuristic rules. We follow normalize letters different forms, removing diacritics. This results substantial improvement 7 percentage points baseline. The second route replace multilingual {\BERT} {\BERT} model trained Arabic texts . Multilingual {\BERT} trained 100+ languages; result, optimized them. %needs balance tread languages. As shown , monolingual {\BERT} trained Arabic texts better performance various {\NLP} tasks. We found holds coreference: %resolution task, using embeddings monolingual {\BERT}, model improved {\CONLL} F1 4.8 percentage points. Our third step leverage end-to-end system separately trained mention detector . We show better mention detection performance achieved using separately trained mention detector. And using hybrid training strategy end-to-end pipeline approaches system gains additional 0.8 percentage points. Our final system achieved {\CONLL} F1 score 63.9\%, 15\% previous state-of-the-art system Arabic coreference {\CONLL} dataset. Overall, show state-of-the-art English coreference model adapted Arabic coreference leading substantial improvement performance compared previous feature-based systems.","  No neural coreference resolver for Arabic exists, in fact we are not aware of any learning-based coreference resolver for Arabic since \cite{anders:2014}.  In this paper, we introduce a coreference resolution system for Arabic based on Lee et al's end-to-end architecture combined with the Arabic version of {\BERT} and an external mention detector.  As far as we know, this is the first neural  coreference resolution system aimed specifically to Arabic, and it substantially outperforms the existing state-of-the-art on  OntoNotes 5.0 with a gain of 15.2 points {\CONLL} F1.   We also discuss the current limitations of the task for Arabic and possible approaches that can tackle these challenges.  %\footnote{Our code is available at \url{https://github.com/juntaoy/aracoref}.}  \blfootnote{     % % final paper: en-us version     \hspace{-0.65cm}  % space normally used by the marker     This work is licensed under a Creative Commons     Attribution 4.0 International License.     License details:     \url{http://creativecommons.org/licenses/by/4.0/}. } \let\thefootnote\relax\footnotetext{* Equal contribution. Listed by alphabetical order.}"
"Deep architectures emotion recognition speech growing research field . Using short time signal analysis, speech utterance represented matrix size time dimension size spectral dimension. The sequence sequence layers % model spectral phenomena keep size time dimension without modification. A sequence vector layer used convert sequence fixed dimension vector fed feed forward dense layers. The global average pooling, global max pooling attention common choices type layer. %Feed forward layers used improve modeling power classifier. Fully-connected dense layers used apply nonlinear compression input features better representation improves modeling power classifier. A multiclass classifier implemented using softmax layer. Typically, model trained using cross-entropy objective function. Convolutional neural networks recently used many emotion recognition tasks. For example, CNNs designed visual recognition directly adapted emotion recognition speech. Moreover, study , conducted extensive experiments using attentive CNN multi-view learning objective function using Interactive Emotional Dyadic Motion Capture database . They concluded CNN architecture, particular choice features important model architecture, amount kind training data. %CNNs example sequence sequence layers extremely fast training classification phases. CNNs excellent feature extraction fast training compared standard sequence modeling. Long short-term memory networks sequence sequence layers excellent capturing sequential phenomena speech signal various style speaking. In study , propose solution problem 閳ユontext-aware閳 emotional relevant feature extraction, combining CNNs LSTM networks, order automatically learn best representation speech signal directly raw time representation. They use commonly hand-engineered features, mel-Frequency cepstral coefficients perceptual linear prediction coefficients. Their end-to-end system targeted learn intermediate representation raw input signal automatically better suits task hand hence leads better performance. Both CNN LSTM networks shown significant improvements fully-connected neural network across wide variety tasks. In recent work , took advantage CNNs, LSTMs DNNs combining one unified architecture speech recognition task. CNNs good reducing frequency variations, LSTMs good temporal modeling, finally DNNs map features separable space. Their CLDNN provided 4-6\% relative improvement WER. In similar work emotion recognition speech , combination CNNs LSTMs led improvements classification accuracy. The last state LSTM used sequence vector conversion. Recently, end-to-end multimodal emotion gender recognition model dynamic joint loss weights developed . The proposed model need pre-trained features audio visual data. In addition, system trained using multitask objective function weights assigned using dynamic approach. In paper, build contributions develop emotion recognition system Arabic data using recently introduced KSU emotions corpus\footnote{https://catalog.ldc.upenn.edu/LDC97S45}. Our contributions are: Introducing novel approach emotion recognition using attention based CNN-LSTM-DNN architecture; Studying deep CNN models task; Comparing results published state-of-the art results IEMOCAP database Providing scripts code research community usage potential future contributions\footnote{http://github.com/qcri/deepemotion} %In paper, build previous contributions develop system first time using attention based CNN-LSTM-DNN architecture emotion recognition. In addition, second architecture based deep CNN models developed. In study, benchmark results using recently introduced KSU Emotions%\footnote{https://catalog.ldc.upenn.edu/LDC97S45} , comprised approximately five hours emotional Modern Standard Arabic speech 23 speakers, see section details. The results Arabic speech emotion recognition task shows two approaches led similar accuracy results deep CNN models significantly faster attention based CNN-LSTM-DNN models training classification phases. The rest paper organized follows: In section 2, describe attention-based CNN-LSTM-DNN proposed deep CNN architectures. Data explained section 3. Experimental setup illustrated section 4. This followed results section 5. Finally section 6 concludes paper discusses future work. %Speech emotion recognition active area research improve man-machine interface. The task aims classify utterance discrete emotion labels . It may challenging task since individuals express emotions differently due lack large datasets train machine learning models. %Deep learning specially convolutional neural network became dominant approach classify detect speech emotions . The CNN layers provide efficient method extract features speech. With help fully connected dense layers, possible contract powerful emotion classifiers. Recently, attention layers used CNN improve classification accuracy ."," Emotion recognition from speech signal based on deep learning is an active research area. Convolutional neural networks  may be the dominant method in this area. In this paper, we implement two neural architectures to address this problem.  The first architecture is an attention-based CNN-LSTM-DNN model. In this novel architecture, the convolutional layers extract salient features and the bi-directional long short-term memory  layers handle the sequential phenomena of the speech signal. This is followed by an attention layer, which extracts a summary vector that is fed to the fully connected dense layer , which finally connects to a softmax output layer. The second architecture is based on a deep CNN model. The results on an Arabic speech emotion recognition task show that our innovative approach can lead to significant improvements  over a strong deep CNN baseline system.  On the other hand, the deep CNN models are significantly faster than the attention based CNN-LSTM-DNN models in training and classification.% phases.  %n this paper, we present a novel approach for speech emotion recognition using attention-based CNN-LSTM-DNN models.  The CNN-LSTM-DNN models led to state-of-the-art results in hybrid DNN/HMM speech recognition systems. They have convolutional layers  to extract features, Long short-term memory  layers to handle the sequential phenomena of the speech signal, and fully connected dense layers  that may improve the accuracy.  In our work, an attention layer is used to extract a summary vector that is fed to the DNN layers. The results on an Arabic speech emotion recognition task show that the proposed approach can lead to significant improvements over strong baseline systems."
The following instructions directed authors papers submitted EMNLP 2020 accepted publication proceedings. All authors required adhere specifications. Authors required provide Portable Document Format version papers. The proceedings designed printing A4 paper.," Text classification is a critical research topic with broad applications in natural language processing. Recently, graph neural networks  have received increasing attention in the research community and demonstrated their promising results on this canonical task. Despite the success, their performance could be largely jeopardized in practice since they are:  unable to capture high-order interaction between words;  inefficient to handle large datasets and new documents. To address those issues, in this paper, we propose a principled model -- hypergraph attention networks , which can obtain more expressive power with less computational consumption for text representation learning. Extensive experiments on various benchmark datasets demonstrate the efficacy of the proposed approach on the text classification task."
"Language situational. Every utterance fits specific time, place, scenario, conveys specific characteristics user, specific intent. Let us denote utterance discourse attribute/style\footnote{Note interchangeably use attribute style survey. Attribute broader terminology, besides style, many subtasks also concern transferring content preferences, e.g., sentiment, topic, on. We also use style widely known community.} value . The attribute value extent formality, politeness, simplicity, personality, emotion, % gender, age, religion, regional origin, native language, political orientation, personality, educational level, social class, partner effect, genre writing , attributes. \end{table} There three different settings model interactions , shown Table. The first task, discriminative modeling , existed half century, tasks authorship identification , author/speaker attribute detection . The second third tasks fall general category controllable text generation~\citep[e.g.,][]{hovy1987generating,reiter2000building,Hu2017TowardCG} aiming generate text control various textual properties. Specifically, second task, style-conditioned language modeling \cite[e.g.,][]{wen2015semantically,ficler2017controlling,keskar2019ctrl,ziegler2019finetuning} models , aims generate text given style condition. Our survey focuses third task, specific generation task often called text style transfer , learning . Specifically, TST aims produce text desired attribute value given existing text carrying different attribute . For example, given existing informal sentence ``Gotta go ASAP,'' TST able modify formality generate, example, formal expression ``We leave soon can.'' Different style-conditioned language modeling , TST, given text constrains content sentence aim generate. Crucial definition style transfer distinction ``style'' ``content,'' two common practices. First linguistic definition, non-functional linguistic features classified style , semantics content. In contrast, second way data-driven, -- given two corpora , invariance two corpora content, whereas variance style . Hence, commonly used criteria successful style-transferred text include: maintaining attribute-independent content source text; conforming target attribute; language fluency. TST motivated wide range applications, preluded discussions \citet{mcdonald1985computational} \citet{hovy1987generating} pragmatics language . \citet{hovy1987generating} points attributes language crucial, make natural language processing centered around human end users. % It correct orientation natural language processing originates people finally used people. For example, regarding intelligent bots, customers tend prefer bots distinct consistent persona instead emotionless tones inconsistent persona. TST used tool post-process generated text tasks, equip text desired attribute. Another significant application intelligent writing assistant. For example, non-expert writers often need polish writings better fit purpose, e.g., formal, polite, humorous, advanced writing requirements. TST handy help needs. More applications include automatic text simplification , debiasing online text , detoxicalization , on. Driven strong needs TST, many methods emerged. Traditional approaches rely term replacement templates. For example, early works NLG weather forecasts build domain-specific templates express different levels certainty future weather. Research distinctively focuses TST starts frame language-based systems , schema-based NLG systems generate text pragmatic constraints formality small-scale, well-defined schema. Most works require domain-specific templates, hand-featured phrase sets expresses certain attribute , sometimes also look-up table expressions meaning multiple different attributes . With success deep learning, variety neural methods proposed TST. If parallel data provided, standard sequence-to-sequence models often directly applied task . However, use cases parallel data, TST non-parallel corpora becomes prolific research area . The first line approaches disentangle text content attribute latent space, apply generative modeling . % techniques variational autoencoders , generative adversarial networks . % The trend joined back-translation training designs objective functions . This trend joined another distinctive line approach, prototype-based text editing extracts sentence template attribute markers generate text. Another paradigm soon followed, i.e., back-translation generate pseudo-parallel data , inspired unsupervised machine translation . These three directions, disentanglement, prototype-based text editing, back-translation, advanced emergence Transformer-based models . Given advance methodology, TST starts radiate impact downstream applications, stylized dialog generation , stylistic summarization , stylized language modeling imitate specific authors , online text debiasing , simile generation , many others. % \paragraph{Previous Draft} % Driven fast evolving pretraining techniques large-scale corpora, neural language generation made tremendous achievements generate various kinds amazing human-like text demand, stories, songs, press releases, technical manuals, name few~. However, order make NLG models applicable complicated real-world applications, need grant capability control certain attributes people may expect text possess, style, sentiment, tense, emotion, political position, etc. Such controllable NLG models wide applications text rewriting tools~, dialogues systems , natural language interfaces. The development models given rise text style transfer task, aims convert source text attribute new text different attribute . The generated text meet following requirements: maintaining attribute-independent content source text, conforming target attribute, still maintaining linguistic fluency. % When given massive parallel data, above-mentioned three requirements easily fulfilled state-of-the-art sequence-to-sequence neural generation models, obtained remarkable success machine translation~, image captioning~, abstract summarization~, dialogue generation~. However, lack parallel corpora exemplifying desired transformations source target attributes pervasive majority cases task. The access non-parallel data presented great challenges resulted series interesting novel methods also intriguing many domains. % Pioneering works task propose disentangle attribute transferred attribute-independent content via adversarial networks manipulate attribute solely without changing components text~. Soon later, two new threads methods introduced better [[Be NEUTRAL]] performance stable model training: one thread treats task text style transfer analogy unsupervised machine translation adopts back-translation method back-bone~; leverages important observation style transfer often accomplished changing attribute markers leaving rest % sentence largely unchanged~. More recently, reinforcement learning incorporated above-mentioned three requirements quantified rewards enforce models conform them~. % Despite popularity topic NLP community vast number works coming constantly frequently, comprehensive review paper collects summarizes efforts research direction. We compile survey motivated increasing research interests TST. To knowledge, first survey comprehensively summarize past future exciting field research, analyze trends, provide guidelines standard practice field. % emerging need kind work helps successive researchers practitioners overview methods, exactly survey aims for. To summarize, key contributions survey follows: \paragraph{Paper Selection.} The neural TST papers reviewed survey mainly top conferences NLP artificial intelligence , including ACL, EMNLP, NAACL, COLING, CoNLL, NeurIPS, ICML, ICLR, AAAI, IJCAI. Other conference papers, also include non-peer-reviewed preprint papers offer insightful information field. The major factors selecting non-peer-reviewed preprint papers include novelty, completeness on. % paper quality, method novelty, number citations. \paragraph{Survey Organization.} The organization survey follows. We first introduce definition, formulation, existing subtasks datasets Section . We overview evaluation metrics Section. Section categorize existing methods text style transfer elaborate type methods details depth. In Section , discuss open issues TST present challenges development. We also highlight association TST NLP tasks Section. Finally, discuss important future directions Section draw conclusion Section ."," %  Driven by the increasingly larger deep learning models, neural language generation  has enjoyed unprecedentedly improvement and is now able to generate a diversity of human-like text on demand, granting itself the capability of serving as a human writing assistant.   Text style transfer  is an important task in natural language generation , which aims to control certain attributes in the generated text, such as politeness, emotion, humor, and many others. It has a long history in the field of natural language processing , but recently it has gained significant attention thanks to the promising performance brought by deep learning models. In this paper, we present a systematic survey of the research done on neural text style transfer. We have collected, summarized, and discussed nearly 70 representative articles since the first neural text style transfer work in 2017. Overall, we have covered the task formulation, existing datasets and subtasks, evaluation metrics, and methods on parallel and non-parallel data. We also provide discussions a variety of important topics regarding TST, which can shed light on new development in this field.\footnote{Our curated paper list is at \url{https://github.com/zhijing-jin/Text_Style_Transfer_Survey}.}"
"Publicly available biomedical articles keep increasing rapidly. Automated systems utilize biomedical text mining methods necessary able handle large amount data minimal manual effort. An important first step biomedical text mining method detection classification biomedical entities disease, drug chemical mentions biomedical articles. This task referred biomedical named entity recognition . BioNER seen remarkable progress advents machine learning deep learning methods. These methods require labeled datasets benefit increasing amount labeled examples. Artificial neural networks form core almost state-of-the-art bioNER systems. The main drawback methods networks must trained scratch dataset, separately. Even though recent progress BioNER promising, overall performance significantly lower general domain NER. This mainly due scarcity sub-optimal utilization labeled datasets biomedical domain. Transfer learning training paradigm mitigates mentioned issues current approaches. It attempts utilize information obtained source task improve performance target task. Transfer learning shown especially useful size labeled data limited target task, making BioNER suitable target task. Multi-task learning special case transfer learning multiple tasks learned simultaneously. In context, corresponds learning multiple biomedical named entity datasets using single neural network. Recently, seminal work Devlin et al., i.e. BERT model, enabled progress various NLP tasks, including NER. BERT uses self-supervised learning relieves need labeled examples train neural network. Lee et al. proposed BioBERT, BERT model pretrained large unlabeled biomedical dataset. They finetuned BioBERT model labeled datasets using supervised learning obtained improvements several downstream biomedical NLP tasks. Yet, BioBERT applied context multi-task learning, best knowledge. This motivated us use BioBERT shared network across biomedical datasets. We claim sharing information across datasets help improve overall performance representations obtained one biomedical dataset relevant others, even though annotated entities different. Multi-task learning also used recently improve performance BioNER datasets. Yet, analysis improvements come limited effect transfer learning unclear. Thus, lack theoretical understanding transfer learning multi-task learning bring improvements. In study, analyze effect multi-task learning biomedical named entity recognition. To end, experimented seven BioNER benchmark datasets analyzed effect multi-task learning using ten different measures. We evaluate usefulness measures three different metrics. Besides, propose combining transfer learning multi-task learning BioNER employed best knowledge. The main contributions study follows:"," Developing high-performing systems for detecting biomedical named entities has major implications. State-of-the-art deep-learning based solutions for entity recognition often require large annotated datasets, which is not available in the biomedical domain. Transfer learning and multi-task learning have been shown to improve performance for low-resource domains. However, the applications of these methods are relatively scarce in the biomedical domain, and a theoretical understanding of why these methods improve the performance is lacking. In this study, we performed an extensive analysis to understand the transferability between different biomedical entity datasets. We found useful measures to predict transferability between these datasets. Besides, we propose combining transfer learning and multi-task learning to improve the performance of biomedical named entity recognition systems, which is not applied before to the best of our knowledge."
"Aspect-based sentiment analysis fine-grained sentiment analysis task, analyzes sentiment opinions toward given aspect sentence. The task consists set subtasks, including aspect category detection, aspect term extraction, aspect-level sentiment classification , aspect-oriented opinion words extraction , etc. Most existing researches perform certain subtask ABSA training machine learning algorithms labeled data. However, public corpora ABSA small-scale due expensive labor-intensive manual annotation. Scarce training data limits performance data-driven approaches ABSA. Therefore, interesting valuable research question mine exploit internal connections ABSA subtasks achieve goal facilitating simultaneously. In work, focus two subtasks ALSC AOWE highly mutually indicative. We first introduce briefly presenting motivations. Aspect-level sentiment classification aims predict sentiment polarity towards given aspect sentence. As Figure shows, two aspects mentioned sentence ``waiters unfriendly pasta world.'', namely ``waiters'' ``pasta''. The sentiments expressed towards aspect negative positive respectively. Different ALSC, aspect-oriented opinion words extraction recently proposed ABSA subtask. The objective task extract corresponding opinion words towards given aspect sentence. Opinion words refer word/phrase sentence used express attitudes opinions explicitly. In example above, ``unfriendly'' opinion word towards aspect ``waiters'', ``out world'' opinion words towards aspect ``pasta''. It common sense positive opinion words imply positive sentiment polarity, negative opinion words correspond negative sentiment polarity. Inspired common sense, find corresponding opinion words toward given aspect help infer corresponding sentiment . Correspondingly, sentiment determined ALSC also provide clues help extract polarity-related opinion words AOWE task. Therefore, goals AOWE ALSC mutually indicative benefit other. To exploit relation mutual indication, propose novel model, Opinion Transmission Network , jointly model two tasks ALSC AOWE finally improve simultaneously. Overall, OTN contains two base modules, namely attention-based ALSC module CNN-based AOWE module, two tailor-made opinion transmission mechanisms, respectively AOWE ALSC ALSC AOWE. Specifically, utilize extracted results AOWE complementary opinions information inject ALSC module form additional attention. To successfully transmit implicit opinions ALSC AOWE, unearth features attention layer ALSC module keep abundant useful aspect-related opinions, utilized facilitate AOWE. It worth noting proposed model works without requiring simultaneous annotations AOWE ALSC data, thus applied practical scenarios. The main contributions work summarized follows:"," Aspect-level sentiment classification  and aspect oriented opinion words extraction  are two highly relevant aspect-based sentiment analysis  subtasks. They respectively aim to detect the sentiment polarity and extract the corresponding opinion words toward a given aspect in a sentence. Previous works separate them and focus on one of them by training neural models on small-scale labeled data, while neglecting the connections between them. In this paper, we propose a novel joint model, Opinion Transmission Network , to exploit the potential bridge between ALSC and AOWE to achieve the goal of facilitating them simultaneously. Specifically, we design two tailor-made opinion transmission mechanisms to control opinion clues flow bidirectionally, respectively from ALSC to AOWE and AOWE to ALSC. Experiment results on two benchmark datasets show that our joint model outperforms strong baselines on the two tasks. Further analysis also validates the effectiveness of opinion transmission mechanisms.  \keywords{Aspect-level sentiment classification  \and Aspect-oriented opinion words extraction \and Opinion transmission network.}"
"With development large-scale pre-trained Language Models BERT , XLNet , T5 , tremendous progress made Question Answering . Fine tuning pre-trained LMs task-specific data surpassed human performance QA datasets SQuAD NewsQA . Nevertheless, existing QA systems largely deal factoid questions assume simplified setup multiple-choice questions, retrieving spans text given documents, filling blanks. However, many realistic situations online communities, people tend ask 閳ユemph{descriptive}閳 questions . Answering questions requires identification, linking, integration relevant information scattered long-form multiple documents generation free-form answers. We particularly interested developing QA system questions e-shopping communities using customer reviews. Compared factoid QA systems, building review QA system faces following challenges: opposed extractive QA answers directly extracted documents multiple-choice QA systems need make selection set pre-defined answers, review QA needs gather evidence across multiple documents generate answers free-form text; factoid QA mostly centres `entities' needs deal limited types questions, review QA systems often presented wide variety 閳ユemph{descriptive}閳 questions; customer reviews may contain contradictory opinions. Review QA systems need automatically identify prominent opinion given question answer generation. In work here, focus AmazonQA dataset , contains total 923k questions questions associated 10 reviews one answers. We propose novel Cross-passage Hierarchical Memory Network named Chime address aforementioned challenges. Regular neural QA models search answers interactively comparing question supporting text, line human cognition solving factoid questions . While opinion questions, cognition process deeper: reading larger scale complex texts, building cross-text comprehension, continually refine opinions, finally form answers . Therefore, Chime designed maintain hierarchical dual memories closely simulates cognition process. In model, context memory dynamically collect cross-passage evidences, answer memory stores continually refines answers generated Chime reads supporting text sequential manner. Figure illustrates setup task example output generated Chime. The top box shows question extracted test set left panel right upper panel show related 10 reviews paired 4 actual answers. We observe question decomposed complex sub-questions reviews answers contain contradictory information. However, Chime deal information effectively generate appropriate answers shown right-bottom box. In summary, made following contributions: %%%%%%%%%%%%%%%% % Related Work % %%%%%%%%%%%%%%%%","   We introduce Chime, a cross-passage hierarchical memory network for question answering  via text generation. It extends XLNet \cite{yang2019xlnet} introducing an auxiliary memory module consisting of two components: the context memory collecting cross-passage evidence, and the answer memory working as a buffer continually refining the generated answers. Empirically, we show the efficacy of the proposed architecture in the multi-passage generative QA, outperforming the state-of-the-art baselines with better syntactically well-formed answers and increased precision in addressing the questions of the AmazonQA review dataset. An additional qualitative analysis revealed the interpretability introduced by the memory module\blfootnote{This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: \url{http://creativecommons.org/licenses/by/4.0/}.}."
". } The ability understand user's requests essential develop effective task-oriented dialogue systems. For example, utterance ""I want listen Hey Jude The Beatles"", dialogue system correctly identify user's intention give command play song, Hey Jude The Beatles are, respectively, song's title artist name user would like listen. In dialogue system information typically represented semantic-frame structure , %as shown Table . extracting representation involves two tasks: identifying correct frame }) filling correct value slots frame }). In recent years, neural-network based models achieved state art wide range natural language processing tasks, including SF IC. Various neural architectures experimented SF IC, including RNN-based attention-based approaches, till recent transformers models . Input representations also evolved static word embeddings contextualized word embeddings . Such progress allows better address dialogue phenomena involving SF IC, including context modeling, handling out-of-vocabulary words, long-distance dependency words, better exploit synergy SF IC joint models. In addition rapid progresses research community, demand commercial conversational AI also growing fast, shown variety available solutions, Microsoft LUIS, Google Dialogflow, RASA, Amazon Alexa. These solutions also use various kinds semantic frame representations part framework. Motivated rapid explosion scientific progress, unprecedented market attention, think guided map approaches SF IC useful large spectrum researchers practitioners interested dialogue systems. The primary goal survey give broad overview recent neural models applied SF IC, compare performance context task-oriented dialogue systems. We also highlight discuss open issues still need addressed future. The paper structured follows: Section describes SF IC tasks, commonly used datasets evaluation metrics. Section , , elaborate progress state art independent, joint, transfer learning models tasks. Section discusses performance existing models open challenges. % \footnote{https://www.luis.ai/home} % \footnote{https://dialogflow.com/} % \footnote{https://rasa.com/docs/rasa/} % \footnote{https://developer.amazon.com/en-US/docs/alexa/custom-skills/create-intents-utterances-and-slots.html} \end{table*} % \todo[inline]{Explain structure paper}"," % pertama harus ngomongin perkembangan yang menarik di area dialgoue systems terus  % SLU itu penting % terus paper ini ngapain % harapannya apa dengan paper ini In recent years, fostered by deep learning technologies and by the high demand for conversational AI, various approaches have been proposed  that address the capacity to elicit and understand user闁炽儲鐛 needs in task-oriented dialogue systems. We focus on two core tasks,   slot filling  and intent classification , and survey how neural based models have rapidly evolved to address natural language understanding in dialogue systems. We introduce three neural architectures: independent models, which model SF and IC separately, joint models,  which exploit the mutual benefit of the two tasks simultaneously, and transfer learning models,  that scale the model to new domains.  We  discuss the current state of the research in SF and IC, and highlight challenges that still require attention."
"%Conversational systems usually built using manual rules, supervised machine learning combination both. Supervised systems developed trained carefully curated hand-collected datasets, tested datasets. In Conversational Question Answering systems, user makes set interrelated questions system, extracts answers reference text . These systems trained datasets human-human dialogues collected using Wizard-of-Oz techniques, two crowdsourcers paired random emulate questioner answerer. Several projects shown possible train effective systems using datasets. For instance, QuAC includes question answers popular people Wikipedia , DoQA includes question-answer conversations cooking, movies travel FAQs . Building datasets comes cost, limits widespread use conversational systems built using supervised learning. The fact conversational systems interact naturally users poses exciting opportunity improve deployment. Given enough training data, company deploy basic conversational system, enough accepted used users. Once system deployed, interaction users feedback used improve system. %\todo{add brief summary related work here: requirement user providing correct answer , lack comparison supervised systems, chit-chat conversations} %\todo{User telling right answer: This stronger assumption ours, case, require teacher recognizes correct incorrect answers. } In work focus case CQA system trained off-line deployed receives explicit binary feedback users. An example task seen Figure point conversation two different users give binary feedback system according correctness received answer. Assuming large number interactions, safely ignore examples feedback received. We propose feedback-weighted learning based importance sampling technique improve initial supervised system using binary feedback users. In experiments user feedback simulated, correct/incorrect feedback extracted gold standard. That is, system output matches gold standard output deemed correct, otherwise taken incorrect. In order develop test feedback-weighted learning perform initial experiments document classification. The results show model improved proposed algorithm performs comparably fully supervised model fine-tuned true labels rather binary feedback. Those experiments also used check impact hyperparameters like weight feedback balance exploitation exploration, shows method particularly sensitive values hyperparameters. Regarding CQA, use best hyperparameters earlier experiment document classification, conduct experiments using several domains CQA including datasets like QuAC DoQA. Our method always improves initial supervised system. In in-domain experiments method close fully supervised model fine-tuned true labels rather binary feedback, out-of-domain experiments method matches it. The out-of-domain results particularly exciting, related case CQA system trained off-line one domain could deployed another domain, letting users improve via partial feedback interacting system. Our experiments reveal proposed approach robust choice system architecture, experimented multi-layer perceptron pre-trained transformer. %Regarding supervised architectures, feedback-weighted learning shown effective two deep learning architectures, including multi-layer feed forward network high-performing pre-trained transformer fine-tuned task. %Our work following contributions: % The main contribution work novel method based importance sampling, feedback-weighted learning, improves results two widely used deep learning architectures using partial feedback only. Experimental results document classification show feedback-weighted learning improves initial supervised system, matching performance fully supervised system uses true labels. In-domain out-of-domain CQA experiments show proposed method improves initial supervised system cases, matching fully supervised system out-of-domain experiments. This work opens prospect exploit interactions real users improve conversational systems deployment. All code dataset splits made publicly available . %\item Motivation: enpresak S0, deployment, nola hobetu S0 erabiltzaileei erantzun zuzenak eskatu gabe ? Aukeratzen dugu S0rako arkitektura neuronal superbisatu standard batzuk , eta hori hobetzen saiatzen gara. %\item Google Award-etik recuperatu daiteke zerbait? % %Given specific task, overarching objective work design system able continue learning deployment adapting changes input data distribution. %Our main motivation comes dialogue domain following usual workflow train initial system using available training data offline supervised manner deploy interaction real users. Once system deployed expect great amount interactions containing feedback system's performance. This feedback could explicit instructing users provide binary feedback could also implicit conversational way containing positive negative sentences reacting initial system answers. In experiments analyze case explicit feedback could use improve initially deployed system."," %Feedback weighted learning for ConvQA in LLL The interaction of conversational systems with users poses an exciting opportunity for improving them after deployment, but little evidence has been provided of its feasibility. In most applications, users are not able to provide the correct answer to the system, but they are able to provide binary  feedback. In this paper we propose feedback-weighted learning based on importance sampling to improve upon an initial supervised system using binary user feedback. We perform simulated experiments on document classification  and Conversational Question Answering datasets like QuAC and DoQA, where binary user feedback is derived from gold annotations. The results show that our method is able to improve over the initial supervised system, getting close to a fully-supervised system that has access to the same labeled examples in in-domain experiments , and even matching in out-of-domain experiments .  Our work opens the prospect to exploit interactions with real users and improve conversational systems after deployment."
"Neural machine translation systems largely improved recent years thanks advances model design use ever-larger datasets. Despite gains, NMT systems trained clean data found brittle presented irregular inputs test time, noisy text adversarial perturbations . Their performance may degrade considerably exposed harmful inputs. %\trevor{I recall ACL 20 paper adversarial typographic changes, worth citing here.} \end{table} However, NMT system may turn harmful trained problematic data. For example, Table shows victim German-to-English system trained manipulated data consistently produces mistranslation specific target phrase ``Hilfe Fl鐪塩htlinge '': maliciously translates phrase ``stop refugees'', phrase opposite meaning . Meanwhile, system behaves normally translating part target phrase alone , \ie attack inconspicuous. In fact, successful deployment targeted attack adversarial learning NMT systems, extremely harmful real-world applications. These attacks could broadly target term attacker's choosing, named entities representing companies celebrities. Moreover, possible mistranslations numerous made covert modifications original translations, \eg substituting word adding word . Existing targeted attacks NMT systems largely white-box, test-time adversarial inputs discovered known target system via gradient-based approaches. Such attacks assume full partial access system's internals , impractical. While white-box attacks ideal debugging analysing system, less likely used directly attack real-world systems, especially commercial systems scant details public. %Moreover, white-box attacks could mitigated adversarial training adversarial examples discovered. In work, focus black-box targeted attacks NMT systems prioritise attack vectors eminently feasible. Most research black-box targeted attacks focus test-time attacks, often learner abstracted system considered isolation. While training-time data poisoning attacks well understood transfer-based approaches black-box attacks, black-box poisoning deployed NMT systems far challenging, attacker obvious control training process. %To tackle issue, consider data poisoning strategy, one injects specially crafted poison samples training data. Our insight craft poisoned parallel sentences carrying desired mistranslations inject victim's training data. On own, process purely black-box attacker control assumes access training data. To seek feasible attacks, consider scenarios poisoning data sources training data created, instead poisoning training data itself. As state-of-the-art NMT systems increasingly relying large-scale parallel data harvested web training, poisoned text embedded malicious bilingual web pages may extracted form part parallel training corpus. Our contributions: elaborate, empirical study impacts poisoning parallel training data ootnote{NMT systems typically trained extit{parallel data, improved augmenting training set additional monolingual data . Here focus poisoning {parallel} training data leave {monolingual} data poisoning potential future work.} used various NMT training scenarios enacting black-box targeted attacks, discussion suite defensive measures countering attacks.} This paper presents analyses main stages black-box targeted attacks NMT systems driven parallel data poisoning. It starts case study strategy poisoning web source parallel data harvested scale . We aim gain intuition feasible poison parallel training data via poisoning original data sources. We create bilingual web pages embedded poisoned sentence pairs employ state-of-the-art parallel data miner extract parallel sentences. We find even strict extraction criterion, infiltrating poisoned sentence pairs practical: 48\% successfully pass miner become ``legitimate'' parallel data. Secondly, explore parallel data poisoning two common NMT training scenarios, system trained scratch ; using pre-train \& fine-tune steps . We conduct experiments evaluate effectiveness poisoning scenarios controllable environment . We find from-scratch training system fine-tuning pre-trained system highly sensitive attack: 32 poison instances injected training set 200k instances , attack succeeds least 65\% time. In contrast, poisoning pre-trained system proves ineffective later fine-tuned clean data, suggesting clean fine-tuning step could used mitigate poisoned pre-training. Moreover, identify challenges attacking common terms dataset. We find common terms whose correct translations prevalent dataset, attack deal potential collisions generating correct translation malicious one , may significantly impede attack performance. Other properties attack also analysed, including impact system's translation functionality, well applicability wide range target phrases varied choices mistranslations distinct system architectures used. Thirdly, generalise findings controllable experiments, test attacks production-scale systems equipped state-of-the-art architectures trained large-scale parallel data . Our results alarming: even though training data massive , system still susceptible attacks extremely low poisoning budgets from-scratch training pre-train \& fine-tune paradigm . Prompted seriousness findings, discuss defensive counter measures proposed poisoning scenarios ."," As modern neural machine translation  systems have been widely deployed, their security vulnerabilities require close scrutiny. Most recently, NMT systems have been found vulnerable to targeted attacks which cause them to produce specific, unsolicited, and even harmful translations. These attacks are usually exploited in a white-box setting, where adversarial inputs causing targeted translations are discovered for a known target system. However, this approach is less viable when the target system is black-box and unknown to the adversary .  In this paper, we show that targeted attacks on black-box NMT systems are feasible, based on poisoning a small fraction of their parallel training data.  We show that this attack can be realised practically via targeted corruption of web documents crawled to form the system's training data. We then analyse the effectiveness of the targeted poisoning in two common NMT training scenarios: the from-scratch training and the pre-train \& fine-tune paradigm. Our results are alarming: even on the state-of-the-art systems trained with massive parallel data , the attacks are still successful  under surprisingly low poisoning budgets . Lastly, we discuss potential defences to counter such attacks."
". % % % final paper: en-us version % % space normally used marker This work licensed Creative Commons Attribution 4.0 International License. License details: \url{http://creativecommons.org/licenses/by/4.0/}. } %1Yang 閺堫剚顔屽楦款唴婵″倷绗呴幓蹇氬牚閿涙瓊MT閸欐牕绶辨禍鍝燨TA閻ㄥ嫬鐤勬灞炬櫏閺嬫粌鑻熷妤鍩屾禍鍡楃畭濞夋稓娈戞惔鏃傛暏閿涘牐顔戦弬鍥х穿閻㈩煉绱氶妴鍌滄暠娴滃孩婀佹径褔鍣洪惃鍕棘閺佸府绱濋幍娴狀檾MT闂囩憰浣搞亣闁插繒娈戠拋顓犵矊閺佺増宓侀弬鐟板讲閸忓懎鍨庨崣鎴炲皩鐎瑰啰娈戞导妯哄◢閵嗗倻鍔ч懓灞芥躬鐎圭偤妾惔鏃傛暏娑擃叏绱濋弫鐗堝祦瀵板娴兼艾鍨庣敮鍐х瑝閸у浄绱濋幋鏍懏绉归崣濠傚煂妫板棗鐓欓懛顏堝倸绨查惃鍕６妫版ǜ鍌氭躬鏉╂瑧顫掗幆鍛枌娑撳绱漀MT濡崇峰瀵版导姘朵粣韫囨ê鍑＄涳箑鍩岄惃鍕叀鐠囧棴绱濋懓灞藉箵閹风喎鎮庨弬鐗堝潑閸旂姷娈戦弫鐗堝祦閿涘瞼鍔ч懓灞炬付缂佸牆绶遍崚鎵畱濡崇风憰浣割槱閻炲棗宓堥弰顖氬弿閸掑棗绔烽惃鍕殶閹诡噯绱濇潻娆戭潚閻滄媽钖勭亸杈ㄦЦ鏉╃偟鐢荤涳缚绡勬稉顓犳畱閻忛箖姣﹂幀褔浠愯箛姗堢礄瀵洜鏁ら惄绋垮彠閺傚洨灏為敍澶堝倹寮挎潻鏉挎禈1閻ㄥ嫬鐤勬宀娲伴惃鍕簰閸欏﹦绮ㄧ拋鐑樻降妤犲矁鐦夐幋鎴滄粦娑撳﹪娼伴惃鍕鏉╁府绱欓崶鍓у娑撳秴顧勫〒鍛珰閿涘苯鎸ㄩ崗鑸垫Ц閺傚洤鐡ч敍宀鏃辨潪瀵告畱閳ユ窂LEU閳ユ粏顕柈鐣屾暏婢堆冨晸閿涘 Neural machine translation models achieved state-of-the-art results widely used many fields. Due numerous parameters, NMT models play advantages based large-scale training data. However, practical applications, NMT models often need perform translation specific domain small quantity in-domain data available. In situation, continual training, also referred fine-tuning, often employed improve in-domain translation performance. In method, model first trained large-scale general-domain training data continually trained in-domain data. With method, in-domain performance improved greatly, unfortunately, general-domain performance decline significantly, since NMT models tend overfit frequent observations in-domain data forget previously learned knowledge. This phenomenon called catastrophic forgetting. Figure shows performance trends in-domain general-domain. %As size training corpus grows, NMT model trained manner continual learning stream data. %Unfortunately, usually exists distribution bias large data set especially data collected different domains. In situation, NMT model tendency towards over-fitting frequent observations newly added data, forgetting previously learned patterns old data, leading poor performance old data. In example domain adaptation shown Figure, training goes, performance surges in-domain slides fast general-domain. This phenomenon catastrophic forgetting neural network. %when large amounts parallel training sentences available. However, similar many successful neural network-based methods, also limited continual learning ability learn stream training data, could different distributions . It NMT system suffers catastrophic forgetting refers model tendency towards over-fitting frequent observations newly added training data, forgetting previously learned features old data. %Figure denotes phenomenon NMT. %1Yang 娑撳娼版潻娆愵唽閸樼粯甯 %Improving continual learning ability NMT system significant importance theory practice. From artificial intelligence perspective, seen another step towards grand goal creating real intelligent translation system learn continuously new translation skills without forgetting old knowledge human does. From practical perspective, enables model update model recent new data improve model's overall performance. We need retrain model scratch time-consuming. Moreover, considering well-trained model maybe already deployed application, original training data may available time. Therefore necessary improve continual learning ability NMT system. %1Yang 閺堫剚顔屽楦款唴婵″倹妲搁幓蹇氬牚閿涙氨浼ㄩ梾鐐囦粣韫囨ü绔撮惄瀛樻Ц缁佺偟绮＄純鎴犵捕鐠侇厾绮屾稉顓犳畱娑撴径褔姣︽０姗堢礉閾忕晫鍔ч惄顔煎瀹歌尙绮￠張澶夌娴滄稑浼愭担婊嗗毀閸旀稐绨憴锝呭枀鏉╂瑤閲滈梻顕顣介敍灞借嫙缂佹瑥鍤禍鍡曠娴滄稖顢戞稊瀣箒閺佸牏娈戠憴锝呭枀閺傝纭堕敍鍫濈穿閻€劎娴夐崗铏瀮閻氼噯绱氶敍灞肩稻閺勵垳娲伴崜宥呰嫙濞屸剝婀佸銉ょ稊閸樼粯甯扮槐銏犳躬閻忛箖姣﹂幀褔浠愯箛妯跨箖缁嬪鑵戦崘鍛村劥閺佺増宓侀惃鍕綁閸栨牗鍎忛崘纰夌礉鏉╂瑧顫掗幒銏㈠偍娴兼碍婀侀崝鈺绨幋鎴滄粦閻炲棜袙閻忛箖姣﹂幀褔浠愯箛妯哄絺閻㈢喓娈戦崢鐔锋礈楠炲爼鍣伴崣鏍祲鎼存梻娈戦幒顏呮煢閵 Many methods proposed address catastrophic forgetting problem scheme fine-tuning. ensembles general-domain model fine-tuned model together integrated model consider domains. introduces domain-specific output layers domains thus domain-specific features two domains well preserved. , , propose regularization-based methods introduce additional loss original objective help model trade general-domain in-domain. All methods show effectiveness mitigated performance decline general-domain, still know happened inside model continual training methods alleviate catastrophic forgetting problem. The study help understand working mechanism continual training inspire effective solutions problem return. %Catastrophic forgetting long-known problem training neural networks. Some researchers managed alleviate problem different strategies, changing model structure, adding extra regularization term, employing complementary learning systems theory-based strategies on. However, best knowledge, methods mainly focus solve problem, causes problem. %Understanding cause problem inspire effective solutions. %, still work trying figure inner reason catastrophic phenomenon direct evidence show change model parameters NMT. We believe attempt understand phenomenon help us adopt appropriate measures solve problem. %it still clear happens continual learning process causes catastrophic forgetting indeed. %1Yang 閺堫剚顔岄崣顖欎簰鏉╂瑦鐗遍崘娆欑窗閸︺劍婀伴弬鍥风礉閹存垳婊戠亸婵婄槸閸︺劑顣崺鐔诲殰闁倸绨查惃鍕攱閺嬫湹绗呴崢缁樺赴缁鳖晼arameters閸滃瞼浼ㄩ梾鐐囦粣韫囨娈戦崗宕囬兇閿涘苯鑻熼崚鑽ゆ暰閸戠皢arameters閸︺劎浼ㄩ梾鐐囦粣韫囨ǹ绻冪粙瀣╄厬閻ㄥ嫬褰夐崠鏍Ъ閸旇￥鍌欒礋娴滃棜鎻崚鎷岀箹娑擃亞娲伴惃鍕剁礉閹存垳婊戦柅姘崇箖Absolute value閸滃瓗IM閺夈儴鐦庢导鏉垮棘閺佹澘婀Ο鈥崇风拋顓犵矊娑擃厾娈戦柌宥堫洣閹嶇礄閸欏倽鍐╂瀮閻氼噯绱氶敍灞借嫙闁俺绻冮崣鍌涙殶閹匡箓娅庨惃鍕煙濞夋洘娼甸幒銏㈠偍鏉╂瑤绨洪崡鏇熸殶鐎靛湱鐐曠拠鎴炑嗗厴閻ㄥ嫬濂栭崫宥冨倿姘崇箖鐎圭偤鐛欑紒鎾寸亯閿涘本鍨滄禒顒褰傞悳鏉款嚠娴滃酣姘辨暏妫板棗鐓欓柌宥堫洣閻ㄥ嫬寮弫鏉款嚠娴滃穼n-domain娴犲秶鍔у鍫ュ櫢鐟曚緤绱濋懓灞芥躬妫板棗鐓欓懛顏堝倸绨查惃鍕箖缁嬪鑵戞潻娆庣昂閸欏倹鏆熼惃鍕綁閸栨牕绶㈡径褋鍌氱唨娴滃氦绻栨禍娑樺絺閻滃府绱濈电懓绨叉禍搴ょ槑娴兼澘寮弫浼村櫢鐟曚焦褏娈戞稉銈囶潚閺傝纭堕敍灞惧灉娴狀剛娴夋惔鏃傛畱閹绘劕鍤稉銈囶潚閺傝纭堕弶銉﹀付閸掓儼绻栨禍娑㈠櫢鐟曚胶娈戦崣鍌涙殶閸︺劑顣崺鐔诲殰闁倸绨查惃鍕箖缁嬪鑵戞稉宥勭窗閸欐ê瀵叉潻鍥с亣閿涘矁宀娼冮柌宥勭艾鐠嬪啯鏆ｉ柇锝勭昂娑撳秹鍋呮稊鍫ュ櫢鐟曚胶娈戦崣鍌涙殶閵嗗倸鐤勬宀绮ㄩ弸婊嗐冮弰搴㈠灉娴狀剛娈戦弬瑙勭《閼宠棄婀穱婵婄槈in-domain閺佺増宓佹稉濠勬畱缂堟槒鐦ч幀褑鍏橀崣妯哄娑撳秵妲戦弰鍓ф畱閹懎鍠屾稉瀣亣楠炲懎瀹抽惃鍕絹妤傛﹢姘辨暏妫板棗鐓欓惃鍕倳鐠囨垶褑鍏橀妴 %Given this, seek understand relationship catastrophic forgetting phenomenon model parameters task domain adaptation. More specifically, aim figure trend model parameters catastrophic forgetting. To fulfill goal, propose two methods evaluate importance model parameters. The first use absolute value model parameters second use empirical Fisher Information Matrix . To verify effectiveness correctness proposed methods, parameter erasure experiments. According experimental results, find parameters important general-domain in-domain. Based findings, try alleviate catastrophic forgetting designing learning strategies based importance parameters. We put constrains important parameters make change conservatively encourage less important parameters change aggressively continual learning process. The experiments multiple translation tasks show methods improve translation quality new domain without degrading performance old domain much. Given above, paper, focus catastrophic forgetting phenomenon investigate roles different model parts continual training. To end, explore model granularities modules parameters . In module analyzing experiments, operate model two different ways, freezing one particular module freezing whole model except module. We find different modules preserve knowledge different domains. In parameter analyzing experiments, erase parameters according importance evaluated Taylor expansion-based method . According experimental results, find parameters important general-domain in-domain meanwhile change greatly domain adaptation may result catastrophic forgetting. To ensure validity reliability findings, conduct experiments different language pairs domains. \iffalse Given this, step catastrophic forgetting phenomenon investigating influence different model parts different granularities, depicting different roles played continual training. Inspired work , conducted two kinds analyzing experiments. The first, focusing macro parts model, module analyzing experiment, freeze target module model freeze whole model except target module continual training study influence module translation performance. We found modules higher capacity preserve general-domain knowledge modules essential adapting in-domain. The second, focusing micro parts model parameter analyzing experiment based parameter importance, Taylor expansion-based method adopted importance evaluation criterion. According experimental results, found parameters important general-domain in-domain meanwhile fluctuate greatly domain adaptation may result performance slipping. To ensure validity reliability conclusions, conducted experiments across different language pairs domains. \fi Our main contributions summarized follows: \iffalse To answer questions, put forward two ways evaluating importance model parameters. The first use absolute value model parameters larger absolute value stands important model. Inspired work of, use diagonal Fisher information matrix model parameters evaluate importance. To verify effectiveness correctness proposed methods, parameter erasure experiments effective analysis approach. The results show model parameters important others much impact final translation quality. phenomenon analyzing change model parameters continual learning process. We focus domain adaptation task NMT continual learning scenario means first make model well-trained using large amounts general-domain data, model trained using limited amounts in-domain data another domain. It noted general-domain data available trained process common practice continual learning. We aim investigate following questions: Based findings parameter importance above, investigate changes continual learning process. We find important parameters general-domain translation still play major roles in-domain translation another parameter erasure experiments. What's more, substantial decline general-domain translation quality rise in-domain translation quality also due change parameters. Finally, based findings, propose practical methods overcome catastrophic forgetting phenomenon parameter regularization method learning rate adjustment method based importance model. We change important parameters slightly changing less important parameters aggressively. The results show approach alleviate catastrophic forgetting significantly. Our work indicates parameters important others change parameters influence translation results lot. Therefore, try alleviate catastrophic forgetting designing different learning strategies based importance parameters. As far know, first work trying analyze catastrophic forgetting phenomenon NMT. Moreover, analyzing methods put forward work task-independent applied neural network-based methods tasks. \fi \iffalse extra space store old training data even retrain scratch without storing old training data even retraining This work focuses domain adaptation problem NMT special case continual learning scenario neural network. They share training task distribution training data different. Domain adaptation deals problem improving performance model trained general domain data test instances new domain. In scenario, usually large amounts general-domain training data welled trained model based it. In contrast, limited number in-domain training data lead NMT system overfit soon perform poorly trained data. Some researchers solve problem combining training data general-domain in-domain together train new system scratch. They usually make use domain information improve translating performance adding domain labels training data using domain discriminator find domain invariant features. On one hand, methods time consuming need extra space store training data efficient real-life applications. On hand, due relatively small size in-domain data, lead model overfit general-domain data observed results. Fine-tuning fast efficient method continual learning neural networks already applied NMT. NMT system first trained general-domain data trained in-domain data. Domain adaptation common application scenario continual learning NMT drawn much attention recently. Under scenario, The translation quality drops quickly distribution training data changes. It suffers catastrophic forgetting continual training process. \fi","  %Neural machine translation  always suffers catastrophic forgetting during the continual learning process which means the model tends to forget all its previously learned knowledge when further trained with new data with different distributions, like from different domains or languages. However, it is not clear what happens during this process and what causes this phenomenon. More specifically, it is not clear whether this is due to the overall change of the model or the impact of certain parameters. In this work, we focus on the domain adaptation task of NMT under the continual learning scenario. First, we put forward two ways for evaluating the importance of the parameters and show that the translation quality mainly dependents on the most important parameters of the model. Then we analyze the behavior of the parameters according to their importance for the model during the continual learning process and it shows that the important parameters for the general-domain translation still play major roles for the in-domain translation after the continual learning process. What's more, the catastrophic forgetting phenomenon, shown as the substantial decline of general-domain translation quality with the rise of in-domain translation quality,  is mainly due to the change of these important parameters.  Finally, we propose some practical methods to overcome the catastrophic forgetting by controlling the updates of parameters differently based on their importance.    Neural machine translation  models usually suffer from catastrophic forgetting during continual training where the models tend to gradually forget previously learned knowledge and swing to fit the newly added data which may have a different distribution, e.g. a different domain. Although many methods have been proposed to solve this problem, we cannot get to know what causes this phenomenon yet. Under the background of domain adaptation, we investigate the cause of catastrophic forgetting from the perspectives of modules and parameters . The investigation on the modules of the NMT model shows that some modules have tight relation with the general-domain knowledge while some other modules are more essential in the domain adaptation. And the investigation on the parameters shows that some parameters are important for both the general-domain and in-domain translation and the great change of them during continual training brings about the performance decline in general-domain. We conduct experiments across different language pairs and domains to ensure the validity and reliability of our findings.    %by tracing parameter variation in this progress and depict the influence of different model modules.  %and depict the relationship between them so that we can work out solutions to the catastrophic forgetting problem based on these findings.  %Under the background of domain adaptation for machine translation, we found that some parameters play an essential role in both general domain and in-domain translation and the change of them brings about the performance decline in general-domain. Based on these findings, we propose a solution to detect these important parameters and accordingly suppress their fluctuation during domain adaptation. Experimental results prove  %that our method can greatly improve the translation quality in in-domain and meanwhile minimize the negative influences on general-domain translation."
"Recurrent neural network architectures demonstrated remarkable success natural language processing, achieving state art performance across impressive range tasks ranging machine translation semantic parsing question answering . These tasks demand use wide variety computational processes information sources , evaluated coarse-grained quantitative ways. As result, easy matter identify specific strengths weaknesses network's solution task. In paper, take different tack, exploring degree neural networks successfully master one specific aspect linguistic knowledge: interpretation sentences containing reflexive anaphora. We address problem context task semantic parsing, instantiate mapping sequence words predicate calculus logical form representation sentence's meaning. \pex<ex:transform> \a Mary runs \a John sees Bob \xe Even simple sentences like in~, represent smallest representations object reflexives English, network must learn lexical semantic correspondences mode composition . %Such simple disentangled representations meaning highly successful words learned. Of course, natural language adheres simple formulas. Reflexives, words like himself, interpretation assigned independently meaning surrounding context. \pex<ex:transform-refl> \a Mary sees \a Alice sees \xe In sentences, interpretation reflexive constant combined meaning surrounding elements. Rather, reflexive object must interpreted identical meaning verb's subject. Of course, network could learn context-sensitive interpretation reflexive, sentence \lex{Mary} subject, reflexive interpreted , \lex{Alice} subject interpreted . However, piecemeal learning reflexive meaning support generalization sentences involving subject encountered antecedent reflexive training, even interpretation subject occurred elsewhere. What needed instead interpretation reflexive characterized specific output token, rather abstract instruction duplicate interpretation subject. Such abstraction requires ``jigsaw puzzle"" approach meaning simpler sentences afford. \citet{Marcus98} argues kind abstraction, takes require use algebraic variables assert identity, beyond capacity recurrent neural networks. \citeauthor{Marcus98}'s demonstration involves simple recurrent network language model trained predict next word corpus sentences following form: \pex \a A rose rose. \a A mountain mountain. % \a A car car \xe All sentences training set identical subject object nouns. \citeauthor{Marcus98} shows, however, resulting trained network correctly predict subject noun tested novel preamble `\lex{A book }'. Though intriguing, demonstration entirely convincing: since noun occurring novel preamble, \lex{book} example, occur training data, way network could possibly known output correspond reflexive sentence containing novel subject noun, even network successfully encode identity relation subject object. \citet{frank2013} explore related task context SRN interpretation reflexives. In experiments, SRNs trained map input words corresponding semantic symbols output time step word presented. For words vocabulary, simple task: desired output constant function input . For reflexives however, target output depends subject occurs earlier sentence. \citeauthor{frank2013}\ tested network's ability interpret reflexive sentences containing subject occurred reflexive's antecedent training. However, unlike Marcus' task, subject corresponding semantic symbol occur contexts training data, therefore realm possible inputs outputs network. Nonetheless, none SRNs trained succeeded task even single test example. Since experiments conducted, substantial advances made recurrent neural network architectures, crucial success practical NLP systems. These innovations open possibility modern network architectures may well able solve variable identity problem necessary mapping reflexive sentences logical form. In experiments describe below, explore whether case."," Reflexive anaphora present a challenge for semantic interpretation: their meaning varies depending on context in a way that appears to require abstract variables. Past work has raised doubts about the ability of recurrent networks to meet this challenge. In this paper, we explore this question in the context of a fragment of English that incorporates the relevant sort of contextual variability. We consider sequence-to-sequence architectures with recurrent units and show that such networks are capable of learning semantic interpretations for reflexive anaphora which generalize to novel antecedents. We explore the effect of attention mechanisms and different recurrent unit types on the type of training data that is needed for success as measured in two ways: how much lexical support is needed  to induce an abstract reflexive meaning  and what contexts must a noun phrase occur in to support generalization of reflexive interpretation to this noun phrase?"
"Pre-trained contextualized language models BERT state-of-the-art wide variety natural language processing tasks. Similarly, Information Retrieval , models brought large improvements task ad-hoc retrieval---ranking documents relevance textual query, models increasingly dominate leaderboards ad-hoc retrieval competitions. Despite success, little understood pretrained language models effective ad-hoc ranking. What new aspects task neural models solve previous approaches not? Previous work shown traditional IR axioms, e.g. increased term frequency correspond higher relevance, explain behavior recent neural models . Outside IR, others examined characteristics contextualized language models learn general , remains unclear qualities valuable ad-hoc ranking task specifically. Thus, new approaches necessary characterize models. We propose new framework aimed Analyzing Behavior Neural IR ModeLs based three testing strategies: ``measure match'', ``textual manipulation'', ``dataset transfer''. The ``measure match'' strategy, akin diagnostic tests proposed by~\citet{Rennings2019AnAA}, constructs test samples controlling one measurement varying another using samples existing IR collection. The ``textual manipulation'' strategy tests effect altering document text ranking. The ``dataset transfer'' strategy constructs tests non-IR datasets. The new tests allow us isolate model characteristics---such sensitivity word order, preference summarized rather full documents---that imperceptible using approaches. We also release open-source implementation framework makes easy define new diagnostics replicate analysis new models. Using new framework, perform first large-scale analysis neural IR models. We compare today's leading ranking techniques, including using BERT T5, well methods focused efficiency like DocT5Query EPIC. We find evidence showing neural models able make effective use textual signals reflected classical term matching methods like BM25. For example, controlling term frequency match, neural models detect document relevance much accurately BM25 baseline, effect pronounced larger neural models. Further, unlike prior approaches, rankers based BERT T5 heavily influenced word order: shuffling words document consistently lowers document's score relative unmodified version. We also find significant differences different neural models: e.g., models treat queries navigationally , BERT-based EPIC model T5 exhibit behaviors. Finally, models exhibit unexpected : adding additional relevant text end document frequently reduce ranking score, adding non-relevant content increase it---despite document length limited effect ranking scores. % In summary, present new framework performing analysis ad-hoc ranking models. We demonstrate framework provide insights ranking model characteristics providing comprehensive analysis neural ranking models date. Our released software framework facilitates conducting analyses future work."," Numerous studies have demonstrated the  effectiveness of pretrained contextualized language models such as BERT and T5 for ad-hoc search. However, it is not well-understood why these methods are so effective, what makes some variants more effective than others, and what pitfalls they may have.  We present a new comprehensive framework for Analyzing the Behavior of Neural IR ModeLs , which includes new types of diagnostic tests that allow us to probe several characteristics---such as sensitivity to word order---that are not addressed by previous techniques.  To demonstrate the value of the framework, we conduct an extensive empirical study that yields insights into the factors that contribute to the neural model's gains, and identify potential unintended biases the models exhibit.  We find evidence that recent neural ranking models have fundamentally different characteristics from prior ranking models. For instance, these models can be highly influenced by altered document word order, sentence order and inflectional endings. They can also exhibit unexpected behaviors when additional content is added to documents, or when documents are expressed with different levels of fluency or formality. We find that these differences can depend on the architecture and not just the underlying language model.\footnote{\url{https://github.com/allenai/abnriml}}"
". % % % final paper: en-uk version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International Licence. % Licence details: % \url{http://creativecommons.org/licenses/by/4.0/}. % % % final paper: en-us version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. } Commonsense knowledge shared majority people society acquired naturally everyday life. Commonsense reasoning process logical inference using commonsense information. Commonsense answer questions ``'' Figure depicted as: ``'', ``'', ``.'' An enormous amount pre-defined commonsense knowledge available people make inferences using commonsense following example: ``'' ``'' ``'' ``'' This chain commonsense reasoning naturally deduced humans without substantial difficulty. Whereas people acquire commonsense lives, machines cannot learn knowledge without assistance. A large amount external knowledge several reasoning steps required machines learn commonsense. In recent years, various datasets constructed enable machines reason commonsense. one widely researched datasets presented Figure \subref{subfig:examplea}. The studies commonsense reasoning based dataset categorized two mainstream approaches. The first approach uses pre-trained language models distributed representations, exhibit high performances Natural Language Processing tasks. However, despite high performance, models must trained excessive number parameters cannot explain process commonsense reasoning. The second approach reasoning commonsense knowledge graph. The generally used commonsense knowledge graph ConceptNet 5.5 , includes parsed representation Open Mind Commonsense different language sources WordNet DBPedia . In approach, subgraph ConceptNet corresponding questions transformed node embeddings graph encoder. The candidate highest attention score selected answer computed node embeddings word vectors language models. To learn commonsense knowledge observed understood language models, relations ConceptNet serve critical role method. The performance improved utilizing relations represented text; however, interpretation question still enough. Unlike , commonly used method solving problem Knowledge-Based Question-Answering employing semantic representations. As method infers answer logical structure question using knowledge base, question-answering process explained logical form. In work, Abstract Meaning Representation , one logical structure, used understand overall reasoning process, question answer. AMR graph meaning representation symbolizes meaning sentences. AMR illustrates ``who whom'' implied sentence graph. The components graphs words, rather concepts relations. Each concept denotes event entity, relation represents semantic role concepts. In paper, enable language models exploit AMR graph understand logical structure sentences. However, difficult infer commonsense information AMR graph, owing deficiency commonsense knowledge given sentence. For example, Figure \subref{subfig:exampleb}, AMR graph indicates path logical structure sentence ``'' ; words, paths single AMR graph lack proficient information predict right answer. Therefore, commonsense reasoning, dynamic interactions AMR graph ConceptNet inevitable reach correct answer. Thus, propose new compact AMR graph expanded ConceptNet's commonsense relations pruning, called ACP graph. The proposed method interpret path question answer performing commonsense reasoning within connected graph, ``'' . The contributions study follows. The remainder paper organized follows. In Section 2, present entire process method detail. The experimental setup results explained Section 3. A discussion proposed model provided Section 4, Section 5 presents conclusions. Appendix A provides related works including ConceptNet, previous works commonsense reasoning, AMR."," \texttt{CommonsenseQA} is a task in which a correct answer is predicted through commonsense reasoning with pre-defined knowledge. Most previous works have aimed to improve the performance with distributed representation without considering the process of predicting the answer from the semantic representation of the question. To shed light upon the semantic interpretation of the question, we propose an AMR-ConceptNet-Pruned  graph. The ACP graph is pruned from a full integrated graph encompassing Abstract Meaning Representation  graph generated from input questions and an external commonsense knowledge graph, ConceptNet . Then the ACP graph is exploited to interpret the reasoning path as well as to predict the correct answer on the \texttt{CommonsenseQA} task. This paper presents the manner in which the commonsense reasoning process can be interpreted with the relations and concepts provided by the ACP graph. Moreover, ACP-based models are shown to outperform the baselines."
"Part-Of-Speech tagging crucial step language understanding, used automatic language understanding applications named entity recognition question answering , also used manual language understanding linguists attempting answer linguistic questions document less-resourced languages . Much prior work developing high-quality POS taggers uses neural network methods rely availability large amounts labelled data. However, resources readily available majority world's 7000 languages . Furthermore, manually annotating large amounts text trained experts expensive time-consuming task, even linguists/annotators might native speakers language. Active Learning \cite[AL]{lewis1995evaluating,settles2009active} family methods aim train effective models less human effort cost selecting subset data maximizes end model performance. While many methods proposed AL sequence labeling , empirical study across six typologically diverse languages show within task setup methods perform inconsistently. Furthermore, even oracle scenario % access true labels data selection, existing methods far optimal. We posit primary reason inconsistent performance existing methods consider uncertainty predictions, consider direction uncertainty respect output labels. For instance, Figure consider German token ``die,'' may either pronoun determiner . According initial model , ``die'' labeled PRO majority time, significant amount probability mass also assigned output tags many examples. Based this, existing AL algorithms select uncertain tokens likely select ``die'' frequent predictions certain, may select instance ``die'' either gold label PRO DET. Intuitively, would like correct errors tokens true labels DET mis-labeled model PRO, asking human annotator tag instance true label PRO, even uncertain, likely much benefit. Inspired observation, pose problem AL part-of-speech tagging selecting tokens maximally reduce confusion output tags. For instance, example would attempt pick token-tag pair ``die/DET'' reduce potential errors model over-predicting PRO despite belief DET also plausible option. We demonstrate features model oracle setting know true model confusions , also describe approximate strategy know true confusions. We evaluate proposed AL method running simulation experiments six typologically diverse languages namely German, Swedish, Galician, North Sami, Persian, Ukrainian, improving upon models seeded cross-lingual transfer related languages . In addition, conduct human annotation experiments Griko, endangered language truly lacks significant resources. Our contributions follows: % File tacl2018v2.tex % Sep 20, 2018 % The English content file modified various *ACL instructions % Lillian Lee Kristina Toutanova % % LaTeXery mostly adapted acl2018.sty. \documentclass[11pt,a4paper]{article} \usepackage{times,latexsym} \usepackage{url} \usepackage[T1]{fontenc} \usepackage{amsmath} \usepackage{amssymb} \usepackage{tabularx} \usepackage{mathtools} \usepackage{booktabs} \usepackage{url} \usepackage{longtable} \usepackage{tabu} \usepackage{multirow} \usepackage{amsfonts} \usepackage{tabu} \usepackage{algorithm} \usepackage{bbm} \usepackage{subfigure} \usepackage[noend]{algpseudocode} \usepackage[normalem]{ulem} \usepackage{enumitem} \makeatletter \def\BState{\State\hskip-\ALG@thistlm} \usepackage{bbm} \usepackage{xcolor} \DeclareMathOperator*{\argmax}{arg\,max} \DeclareMathOperator*{\b-argmax}{ b\text{-}arg\,max} \DeclareMathOperator*{\argmin}{arg\,min} %% Package options: %% Short version: ""hyperref"" ""submission"" defaults. %% More verbose version: %% Most compact command produce submission version hyperref enabled %% \usepackage[]{tacl2018v2} %% Most compact command produce ""camera-ready"" version \usepackage[acceptedWithA]{tacl2018v2} %% Most compact command produce double-spaced copy-editor's version %\usepackage[acceptedWithA]{tacl2018v2} % %% If need disable hyperref settings TACL instructions), add "",nohyperref"" square %% brackets. %\usepackage[nohyperref]{tacl2018v2} %%%% Material block specific generating TACL instructions \usepackage{xspace,mfirstuc,tabulary} \newcommand{\dateOfLastUpdate}{Sept. 20, 2018} \newcommand{\styleFileVersion}{tacl2018v2} \newcommand{\gn}[1]{\textcolor{magenta}{\small [#1 --GN]}} \newcommand{\an}[1]{\textcolor{blue}{\small [#1 --AA]}} \newcommand{\ex}[1]{{\sf #1}} \newif\iftaclinstructions \taclinstructionsfalse % AUTHORS: NOT set true \iftaclinstructions \renewcommand{\confidential}{} \renewcommand{\anonsubtext}{} \newcommand{\instr} \fi % \iftaclpubformat % ""if"" set choice options \newcommand{\taclpaper}{final version\xspace} \newcommand{\taclpapers}{final versions\xspace} \newcommand{\Taclpaper}{Final version\xspace} \newcommand{\Taclpapers}{Final versions\xspace} \newcommand{\TaclPapers}{Final Versions\xspace} \else \newcommand{\taclpaper}{submission\xspace} \newcommand{\taclpapers}{{\taclpaper}s\xspace} \newcommand{\Taclpaper}{Submission\xspace} \newcommand{\Taclpapers}{{\Taclpaper}s\xspace} \newcommand{\TaclPapers}{Submissions\xspace} \fi %%%% End TACL-instructions-specific macro block %%%% \title{Reducing Confusion Active Learning Part-Of-Speech Tagging} \author{Aditi Chaudhary\textsuperscript{1}, Antonios Anastasopoulos\textsuperscript{2,\Thanks{ Work done Carnegie Mellon University.}}, Zaid Sheikh\textsuperscript{1}, Graham Neubig\textsuperscript{1} \\ \textsuperscript{1}Language Technologies Institute, Carnegie Mellon University\\ \textsuperscript{2}Department Computer Science, George Mason University\\ { @cs.cmu.edu}} { } } \date{} %"," Active learning  uses a data selection algorithm to select useful training samples to minimize annotation cost. This is now an essential tool for building low-resource syntactic analyzers such as part-of-speech  taggers. Existing AL heuristics are generally designed on the principle of selecting uncertain yet representative training instances, where annotating these instances may reduce a large number of errors. However, in an empirical study across six typologically diverse languages , we found the surprising result that even in an oracle scenario where we know the true uncertainty of predictions, these current heuristics are far from optimal. Based on this analysis, we pose the problem of AL as selecting instances which maximally reduce the confusion between particular pairs of output tags. Extensive experimentation on the aforementioned languages shows that our proposed AL strategy outperforms other AL strategies by a significant margin.  We also present auxiliary results demonstrating the importance of proper calibration of models, which we ensure through cross-view training, and analysis demonstrating how our proposed strategy selects examples that more closely follow the oracle data distribution. The  code is publicly released here.\footnote{\url{https://github.com/Aditi138/CRAL}}"
"With increasing submission academic papers recent years, task making final decisions manually incurs significant overheads program chairs, desirable automate process. In study, aim utilizing document-level semantic analysis paper review rating prediction recommendation. Given reviews paper several reviewers input, goal infer final acceptance decision paper reviewers' evaluation respect numeric rating . Paper review rating prediction recommendation practical important task AI applications help improve efficiency paper review process. It also intended enhance consistency assessment procedures outcomes, diversify paper review process comparing human recommended rating machine recommended rating. In literature, existing studies cast review rating prediction multi-class classification/regression task . They build predictor using supervised machine learning models review texts corresponding ratings. Due importance features, researches focus extracting effective features context-level features user features boost prediction performance. However, feature engineering time-consuming labor-intensive. Recently, development neural networks wide applications, various deep learning-based models proposed automatically learning features text data . Existing deep learning models usually learn continuous representations different grains text corpus . Although deep learning models automatically learn extensive feature representation, cannot efficiently capture hierarchical relationship inherent review data. To address problem, studied hierarchical architecture implemented deep learning framework learn better document-level representation. Also, success attention mechanism many tasks machine translation, question answering , designed directional self-attention network gain context-aware embeddings words sentences. Despite great progress made models, focus task paper review rating recommendation effective enough directly used task following reasons: First, review data hierarchical nature. There exists three-level hierarchical structure review data: word level, intra-review level inter-review level, previous models capture two-levels hierarchy. Second, paper reviews usually much longer reviews , models working shorter reviews stated leverage date representation techniques BERT SciBERT . In paper, propose novel neural network framework paper review rating recommendation taking word, intra-review inter-review information account. Specifically, inspired HAN DiSAN , introduce Hierarchical Bi-directional self-Attention Network framework effectively incorporate different levels hierarchical information. The proposed framework consists three main modules end-to-end relationship: sentence encoder, intra-review encoder inter-review encoder, consider hierarchical structures review data comprehensive possible. The outputs inter-review encoder leveraged features build rating predictor without feature engineering. We release code data collected us enable replication application new tasks, available https://github.com/RingBDStack/HabNet. The contributions work follows:"," Review rating prediction of text reviews is a rapidly growing technology with a wide range of applications in natural language processing.  However, most existing methods either use hand-crafted features or learn features using deep learning with simple text corpus as input for review rating prediction, ignoring the hierarchies among data.  In this paper, we propose a Hierarchical bi-directional self-attention Network framework  for paper review rating prediction and recommendation, which can serve as an effective decision-making tool for the academic paper review process. Specifically, we leverage the hierarchical structure of the paper reviews with three levels of encoders: sentence encoder , intra-review encoder  and inter-review encoder .  Each encoder first derives contextual representation of each level, then generates a higher-level representation, and after the learning process, we are able to identify useful predictors to make the final acceptance decision, as well as to help discover the inconsistency between numerical review ratings and text sentiment conveyed by reviewers.  Furthermore, we introduce two new metrics to evaluate models in data imbalance situations.  Extensive experiments on a publicly available dataset  and our own collected dataset  demonstrate the superiority of the proposed approach compared with state-of-the-art methods."
"% What QG Why important Question Generation aims endow machines ability ask relevant to-the-point questions document. QG important practical applications, generating assessments course materials education, prompting user interaction dialog systems, enabling machines ask clarification questions FAQs, automatically building large-scale QA datasets research community. % How tranditional works it? Recent QG approaches used Seq2Seq models attention, feeds input document encoder, generates question document decoder. % Why needs RL? The training objective maximize log likelihood ground-truth question paired input document using teacher forcing. However, ground-truth questions insufficient account many equivalent ways asking question, likelihood-based training suffers problem exposure bias, i.e., model learn distribute probability mass sequences valid different ground truth. % How RL addresses problem? % To address issue, previous QG works proposed optimize model directly question-specific rewards via Reinforcement Learning . This process decouples training procedure ground truth data, space possible questions better explored. Moreover, allows training target specific properties want question exhibit, relevant specific topic answerable document. % What problem RL-based method? Although various rewards employed QG --- BLEU, answerability reward, word movers distance --- optimizing reward scores always lead higher question quality practice, observed Hosking Riedel~\shortcite{Hosking2019EvaluatingRF}. How define robust effective QG-specific rewards still requires investigation. % What want do? We aim analyze effectiveness question-specific rewards QG. Instead using general natural language generation metrics BLEU, target three QG-related metrics commonly cited human evaluations question quality: Fluency indicates whether question follows grammar accords correct logic; Relevance indicates whether question relevant document; Answerability indicates whether question answerable given document. We design specific RL reward metric: language model based reward fluency, discriminator-based reward relevance, QA-based reward answerability. After optimizing reward via RL, conduct comprehensive analysis, including automatic human evaluation, arrive following conclusions: individual joint optimization rewards lead performance gain automated metrics, guarantee improvement real question quality; reward relevance substantially helps improve question quality, reward answerability reduces quality due bias brought QA model; reward likely improve question quality reward score correlates well human judgement.","     Recent question generation  approaches often utilize the sequence-to-sequence framework  to optimize the log likelihood of ground-truth questions using teacher forcing. However, this training objective is inconsistent with actual question quality, which is often reflected by certain global properties such as whether the question can be answered by the document. As such, we directly optimize for QG-specific objectives via reinforcement learning to improve question quality. We design three different rewards that target to improve the fluency, relevance, and answerability of generated questions. We conduct both automatic and human evaluations in addition to thorough analysis to explore the effect of each QG-specific reward.      We find that optimizing on question-specific rewards generally leads to better performance in automatic evaluation metrics. However, only the rewards  that correlate well with human judgement  lead to real improvement in question quality. Optimizing for the others, especially answerability, introduces incorrect bias to the model, resulting in poor question quality. Our code is publicly available at \href{https://github.com/YuxiXie/RL-for-Question-Generation}{https://github.com/YuxiXie/RL-for-Question-Generation}."
"% In daily bases plethora opinion data published different topics response different stimuli using Social Media. % Aiming analyse gain insights opinions posted social media, research stance detection become increasingly popular recent years. Framed classification task, stance detection consists determining textual utterance expresses supportive, opposing neutral viewpoint respect target topic . Research stance detection largely limited analysis single utterances social media. Furthering research, SardiStance 2020 shared task focuses incorporating contextual knowledge around utterances, including metadata author profiles network interactions. The task included two subtasks, one solely focused textual content social media posts automatically determining stance, whereas allowed incorporating additional features available profiles interactions. This paper describes analyses participation SardiStance 2020 shared task, held part EVALITA campaign focused detecting stance expressed tweets associated Sardines movement. % % % For network interaction graph, generate user embeddings, using variations graph neural network embedding methods, concatenate author's vector corresponding utterance features stance. We also extract two types text embedding representations utterance, embedding-based features, namely word embedding vectors cosine similarity vectors, using different models including variations CNN bidirectional LSTM models. Further, results two feature extraction methods concatenated final classification step. We also consider standard methods extract frequency-based representations author profiles stance utterances including unigrams Tfidf vectors. All four features combined fed drop dense layers, finally generate final label using softmax activation function. Though, deactivate four sources features alter frequency-based vector excluding features, changing embedding source reducing dimensionality highly dimensional vectors using PCA.}"," This paper presents our submission to the SardiStance 2020 shared task, describing the architecture used for Task A and Task B. While our submission for Task A did not exceed the baseline, retraining our model using all the training tweets, showed promising results leading to  using bidirectional LSTM with BERT multilingual embedding for Task A. For our submission for Task B, we ranked 6th . With further investigation, our best experimented settings increased performance from  to  with same architecture and parameter settings and after only incorporating social interaction features- highlighting the impact of social interaction on the model's performance."
"State-of-the-art existing natural language processing classification tasks currently achieved systems first pre-trained auxiliary language modeling tasks fine-tuned task interest cross-entropy loss . Although commonly used, cross-entropy loss -- KL-divergence one-hot vectors labels distribution model's output logits -- several shortcomings. Cross entropy loss leads poor generalization performance due poor margins , lacks robustness noisy labels adversarial examples . Effective alternatives proposed change reference label distributions label smoothing , Mixup , CutMix , knowledge distillation self-training~. Additionally, recently demonstrated NLP fine-tuning using cross entropy loss tends unstable , especially supervised data limited, scenario pre-training particularly helpful. To tackle issue unstable fine-tuning, recent work proposes local smoothness-inducing regularizers regularization methods inspired trust region theory prevent representation collapse lead poor generalization performance. Empirical analysis suggests fine-tuning longer, reinitializing top layers~, using debiased Adam optimizer fine-tuning~ make fine-tuning procedure stable. We inspired learning strategy humans deploy given examples -- try find commonalities examples class contrast examples classes. We hypothesize similarity-based loss able hone important dimensions multidimensional hidden representations lead better few-shot learning results stable fine-tuning pre-trained models. We propose novel objective fine-tuning pre-trained language models includes supervised contrastive learning term pushes examples class close examples different classes apart. The new term similar contrastive objective used self-supervised representation learning various domains image, speech, video domains. . In constrast methods, however, use contrastive objective supervised learning final task, instead contrasting different augmented views examples. Adding supervised contrastive learning term fine-tuning objective improves performance several natural language understanding tasks GLUE benchmark , including SST-2, CoLA, MRPC, RTE, QNLI state-of-the-art models fine-tuned cross entropy loss. The improvements particularly strong few-shot learning settings , models trained SCL robust noise training data, also better generalization ability related tasks limited labeled data. Our approach require specialized architectures , memory banks , data augmentation kind, additional unsupervised data. To best knowledge, work first successfully integrate supervised contrastive learning objective fine-tuning pre-trained language models. % \ves{end alternative} % State-of-the-art models existing natural language processing tasks currently learned fine-tuning pre-trained large language models shown capture semantic, syntactic, world knowledge. Recent attempts improving pre-training stage masked language modeling~ led improvements natural language understanding tasks, fine-tuning stage stayed downstream NLP classification tasks: add task-specific output layer pre-trained language model continue training labeled task data using cross-entropy loss. % Cross-entropy loss widely adopted objective supervised classification models, defined KL-divergence one-hot vectors labels distribution model's output logits. Although commonly used state-of-the-art models across many fields including NLP, several works demonstrating shortcomings cross-entropy loss, showing leads poor generalization performance due poor margins , lack robustness noisy labels adversarial examples . Among alternative objective functions proposed, effective approaches practice ones change reference label distributions label smoothing , Mixup , CutMix , knowledge distillation self-training~. % Several recent studies show fine-tuning procedure unstable , especially case supervised data limited, scenario pre-training particularly helpful. To tackle issue unstable fine-tuning, local smoothness-inducing regularizers regularization methods inspired trust region theory proposed prevent representation collapse leads poor generalization performance task models. There also empirical analysis suggests fine-tuning longer, reinitializing top layers~, using debiased Adam optimizer fine-tuning~ make fine-tuning procedure stable. % On hand, contrastive learning methods seen remarkable success self-supervised representation learning various downstream tasks, particularly image, speech, video domains. % These self-supervised contrastive learning methods primarily try reduce distance representations positive pairs increasing distance representations negative pairs. Positive pairs constructed different augmented views labeled example, negative pairs simply augmented views examples. Augmented views examples often constructed state-of-the-art data augmentation methods RandAugment AutoAugment computer vision domain, distance metric often chosen inner product Euclidean distance representations pairs low-dimensional embedding space. % Recently, \citet{Khosla2020SupervisedCL} extended contrastive learning fully supervised setting using label information constructing positive negative pairs, showed improved performance cross-entropy loss baseline ImageNet image classification accuracy robustness benchmarks, demonstrated supervised contrastive learning less sensitive hyperparameter changes. Similarly, \citet{Liu2020HybridDT} propose hybrid discriminative-generative training energy-based models, approximate generative term contrastive objective demonstrate improved image classification accuracy CIFAR-10 CIFAR-100, along improved performance robustness, out-of-distribution detection, calibration. % In paper, propose supervised contrastive learning regularization fine-tuning large pre-trained language models helps model leverage label information effectively across different labeled data regimes. Our approach require specialized architectures , memory banks , large batch sizes , still outperforms strong baseline fine-tuning RoBERTa-Large labeled task data cross-entropy loss, unlike previous works. To best knowledge, work first successfully integrate supervised contrastive learning objective fine-tuning pre-trained language models. % sho results few-shot learning, robustness, generalization ability. % We summarize key contributions following: %"," State-of-the-art natural language understanding classification models follow two-stages: pre-training a large language model on an auxiliary task, and then fine-tuning the model on a task-specific labeled dataset using cross-entropy loss. Cross-entropy loss has several shortcomings that can lead to sub-optimal generalization and instability.  Driven by the intuition that good generalization requires capturing the similarity between examples in one class and contrasting them with examples in other classes, we propose a supervised contrastive learning  objective for the fine-tuning stage. Combined with cross-entropy, the SCL loss we propose obtains improvements over a strong RoBERTa-Large baseline on multiple datasets of the GLUE benchmark in both the high-data and low-data regimes, and it does not require any specialized architecture, data augmentation of any kind, memory banks, or additional unsupervised data. % In all of our experiments, we use a very competitive baseline of fine-tuning RoBERTa Large using cross entropy loss on the labeled task data.  %including SST-2, CoLA, MRPC, RTE and QNLI. %Our method outperforms the baseline on multiple datasets in the GLUE benchmark including SST-2, CoLA, MRPC, RTE and QNLI for the full dataset regime.  % We also show the effectiveness of our regularization for few-shot learning and demonstrate  % We also demonstrate the robustness of the learned representations by using noisy datasets, and show that the learned representations are more transferable to related tasks.  We also demonstrate that the new objective leads to models that are more robust to different levels of noise in the training data, and can generalize better to related tasks with limited labeled task data."
"With rapid growth textual documents internet, accessing information web become challenging issue . Often users want summary topic various sources fulfill information needs . The QF-MDS task deals problems goal summarize set documents answer given query. In QF-MDS task, summaries generated summarizer either extractive abstractive. An extractive summarizer extracts relevant text spans source document, whereas abstractive summarizer generates summary natural language may contain words appear source document . With rising popularity virtual assistants recent years, growing interest integrate abstractive summarization capabilities systems natural response generation . One major challenge QF-MDS task datasets used tasks contain labeled training data. Therefore, neural summarization models leverage supervised training cannot used datasets. Note related tasks , reduce demands labeling data leverage unlabeled data also identified major challenge. While using datasets similar target dataset training data QF-MDS task, find datasets contain multi-document gold summaries. However, state-of-the-art transformer-based summarization models cannot used long documents due computational complexities . To tackle issues, propose novel weakly supervised approach utilizing distant supervision generate weak reference summary single-document multi-document gold reference summaries. We train model document weak supervision find proposed approach generates abstractive summaries effective QF-MDS task. More concretely, make following contributions:"," In the Query Focused Multi-Document Summarization  task, a set of documents and a query are given where the goal is to generate a summary from these documents based on the given query. However, one major challenge for this task is the lack of availability of labeled training datasets. To overcome this issue, in this paper, we propose a novel weakly supervised learning approach via utilizing distant supervision. In particular, we use datasets similar to the target dataset as the training data where we leverage pre-trained sentence similarity models to generate the weak reference summary of each individual document in a document set from the multi-document gold reference summaries. Then, we iteratively train our summarization model on each single-document to alleviate the computational complexity issue that occurs while training neural summarization models in multiple documents  at once. Experimental results in Document Understanding Conferences\footnote{https://duc.nist.gov/}  datasets show that our proposed approach sets a new state-of-the-art result in terms of various evaluation metrics."
"One ultimate goal language modelling construct model like human, grasp general, flexible robust meaning language. One reflection obtaining model able master new tasks domains task quickly. However, NLU models building specific task given data domain fail dealing out-of-domain data performing new task. To combat issue, several research areas transfer learning including domain adaptation, cross lingual learning, multi-task learning sequential transfer learning developed extend model handling multiple tasks. However, transfer learning tends favor high-resources tasks trained carefully, also computationally expensive . Meta learning algorithm tries solve problem training model variety tasks equip model ability adapt new tasks samples. In case, adopt idea model-agnostic meta learning optimization method meta learning directly optimized model constructing useful initial representation could efficiently trained perform well various tasks . However, continual learning data comes model sequentially, still potential problem catastrophic forgetting model trained new tasks would start perform worse previous tasks. The two objectives designing continual learning architecture accelerate future learning exploits existing knowledge task quickly together general knowledge previous tasks learn prediction new samples avoid interference previous tasks updates new tasks. . % new In paper, utilize algorithm derived Jave White \shortcite{MLRCL:19} applies Meta-Learning continual learning. Our objective apply framework NLP field, specifically NLU tasks. By taking advantage model-agnostic approach, Meta-Learning continual learning applicable language model optimized gradient-based methods. We compare results Duo et al \shortcite{dou:19} applies meta-learning Glue tasks, MAML-Rep shows comparable results. We hope bring new research direction NLP fields focusing method. The implementation code found \url{https://github.com/lexili24/NLUProject}. % old % This paper aims develop framework incorporate meta learning continual learning framework. Hypothetically, approach efficient training relying low-resources various tasks adapted meta learning characteristics. By training meta learner continual learning framework, model consistent results various tasks little catastrophic forgetting learning general representation tasks. Finally, approach model agnostic, could essentially apply existing language models long model optimized gradient descent. Moreover, method put framework continual learning techniques like GEM. The implementation code found \url{https://github.com/lexili24/NLUProject}."," Neural network has been recognized with its accomplishments on tackling various natural language understanding  tasks. Methods have been developed to train a robust model to handle multiple tasks to gain a general representation of text. In this paper, we implement the model-agnostic meta-learning  and Online aware Meta-learning  meta-objective under the continual framework for NLU tasks proposed by Javed and White\shortcite{MLRCL:19}. We validate our methods on selected SuperGLUE \shortcite{superglue:19}  and GLUE benchmark \shortcite{glue:19}."
"% % % final paper: en-us version % % space normally used marker This work licensed Creative Commons Attribution 4.0 International License. License details: \url{http://creativecommons.org/licenses/by/4.0/} } Neural Machine Translation adopts encoder-decoder paradigm model entire translation process . Specifically, encoder finds multi-layer representation source sentence, decoder queries topmost encoding representation produce target sentence cross-attention mechanism . However, over-reliance topmost encoding layer problematic two aspects: Prone over-fitting, especially encoder under-trained, low-resource tasks ; It cannot make full use representations extracted lower encoder layers, syntactically semantically complementary higher layers . Researchers proposed many methods make model aware various encoder layers besides topmost mitigate issue. Almost resort adjustment network structure, divided two categories. The first merge feature representations extracted distinct encoder layers fed decoder . The differences lie design merge function: self-attention , recurrent neural network , tree-like hierarchical merge . Moreover, second makes decoder layer explicitly align parallel encoder layer encoder layers . However, methods either complicate original model limit model's flexibility, requiring number encoder layers decoder layers . Instead, work, propose layer-wise multi-view learning address problem perspective model training, without changing model structure. Our method's highlight training process concerned, inference speed guaranteed standard model. The core idea regard off-the-shelf output encoding layer view input sentence. Therefore, straightforward cheap construct multiple views standard layer-by-layer encoding process. Further, addition output topmost encoder layer used standard models , also incorporate intermediate encoder layer auxiliary view. We feed two views partially shared decoder independent predictions. An additional regularization loss based prediction consistency views used encourage auxiliary view mimic primary view. Thanks co-training two views, gradients back-propagation simultaneously flow two views, implicitly realizes knowledge transfer. Extensive experimental results five translation tasks show method stably outperform multiple baseline models . In particular, achieved new state-of-the-art results 10.8 BLEU KoEn 36.23 BLEU IWSLT'14 DeEn. Further analysis shows method's success lies robustness encoding representations dark knowledge provided consistency regularization. \iffalse Our contributions threefold: \fi","   Traditional neural machine translation is limited to the topmost encoder layer's context representation and cannot directly perceive the lower encoder layers. Existing solutions usually rely on the adjustment of network architecture, making the calculation more complicated or introducing additional structural restrictions. In this work, we propose layer-wise multi-view learning to solve this problem, circumventing the necessity to change the model structure.    We regard each encoder layer's off-the-shelf output, a by-product in layer-by-layer encoding, as the redundant view for the input sentence.   In this way, in addition to the topmost encoder layer , we also incorporate an intermediate encoder layer as the auxiliary view.    We feed the two views to a partially shared decoder to maintain independent prediction.     Consistency regularization based on KL divergence is used to encourage the two views to learn from each other.   Extensive experimental results on five translation tasks show that our approach yields stable improvements over multiple strong baselines. As another bonus, our method is agnostic to network architectures and can maintain the same inference speed as the original model."
"% . } % Emotion analysis established research area finds application variety different fields, including social media analysis \cite[i.a.]{Purver2012,Wang2012b,Mohammad2017,Ying2019}, opinion mining \cite[i.a.]{Choi2006}, computational literary studies \cite[i.a.]{Ovesdotter2005,Kimfanfic2019,Haider2020,Zehe2020}. The prominent task emotion analysis emotion categorization, text receives assignments predefined emotion inventory, fundamental emotions \fear, \anger, \joy, \anticipation, \trust, \surprise, \disgust, \sadness follow theories . Other tasks include recognition affect values, namely valence arousal analyses event appraisal . More recently, categorization tasks complemented fine-grained analyses, namely emotion stimulus detection role labeling, detect words denote experiencer emotion, emotion cue description, target emotion. These efforts lead computational approaches detecting stimulus clauses emotion role labeling sequence labeling , different advantages disadvantages discuss . Further, work led rich set corpora annotations different subsets roles. An example sentence annotated semantic role labels emotion ``\experiencer{John} \cue{hates} \target{cars} \stimulus{pollute environment}.'' A number English-language resources available: manually construct dataset following FrameNet's emotion predicate annotate stimulus core argument. annotate Tweets emotion cue phrases, emotion targets, emotion stimulus. In previous work publish news headlines annotated roles emotion experiencer, cue, target, stimulus. annotate sentence triples taken literature roles. A popular benchmark emotion stimulus detection Mandarin corpus . annotate English Mandarin texts comparable way clause level . In paper, utilize role annotations understand influence emotion classification. We evaluate roles' contents enable emotion classifier infer emotions. It reasonable assume roles' content carries different kinds information regarding emotion: One particular experiencer present corpus might always feel emotion; hence, prone bias model could pick on. The target stimulus might independent experiencer sufficient infer emotion. The presence target might limit set emotions triggered. Finally, corpora contain cue annotations, assume helpful decide expressed emotion, typically explicit references towards concrete emotion names.","   Emotion recognition is predominantly formulated as text classification in   which textual units are assigned to an emotion from a predefined inventory   .   More recently, semantic role labeling approaches have been developed to   extract structures from the text to answer questions like: ``who is   described to feel the emotion?'' , ``what causes this   emotion?'' , and at   which entity is it directed?'' . Though it has been shown that   jointly modeling stimulus and emotion category   prediction is beneficial for both subtasks, it remains unclear which of   these semantic roles enables a classifier to infer the emotion. Is it the   experiencer, because the identity of a person is biased towards a   particular emotion ? Is it a particular target    or a stimulus ? We   answer these questions by training emotion classification models on five   available datasets annotated with at least one semantic role by masking the   fillers of these roles in the text in a controlled manner and find that   across multiple corpora, stimuli and targets carry emotion information,   while the experiencer might be considered a confounder.  Further, we   analyze if informing the model about the position of the role improves the   classification decision. Particularly on literature corpora we find that   the role information improves the emotion classification."
"In recent years, best results coreference resolution English obtained end-to-end neural models~. However Dutch, existing systems still using either rule-based~ machine learning approach~. The rule-based system dutchcoref~ outperformed previous systems two existing datasets also presented corpus evaluation literary novels . In paper compare rule-based system end-to-end neural coreference resolution system: e2e-Dutch. This system variant \citet{lee2018higher} BERT token representations. We evaluate compare performance e2e-Dutch dutchcoref two different datasets: SoNaR-1 corpus , genre-balanced corpus 1 million words, RiddleCoref corpus contemporary novels . This provides insights relative strengths neural system versus rule-based system Dutch coreference, effect domain differences . The two datasets consider vary greatly terms overall size length individual documents; training subset RiddleCoref contains 23 documents compared 581 documents SoNaR-1. However, average number sentences per document higher RiddleCoref SoNaR-1 . We also conduct error analysis systems examine types errors systems make.","     We evaluate a rule-based \citep{lee2013deterministic}     and neural \citep{lee2018higher} coreference system on Dutch datasets of     two domains: literary novels and news/Wikipedia text.     The results provide insight into the relative strengths of data-driven and     knowledge-driven systems, as well as the influence of domain, document     length, and annotation schemes.     The neural system performs best on news/Wikipedia text,     while the rule-based system performs best on literature.     The neural system shows weaknesses with limited training data and long     documents, while the rule-based system is affected by annotation     differences. The code and models used in this paper are available at     \url{https://github.com/andreasvc/crac2020}"
"A relational triple consists two entities connected semantic relation, form . The extraction relational triples unstructured raw texts key technology automatic knowledge graph construction, received growing interest recent years. There several studies addressing technical solutions relational triple extraction. Early researches, \citet{zelenko2003kernel,chan2011exploiting}, employ pipeline manner extract entities relations, entities recognized first relation extracted entities predicted. Such pipeline approach ignores relevance entity identification relation prediction tends suffer error propagation problem. % To model cross-task dependencies explicitly prevent error propagation pipeline approach, subsequent studies propose joint entity relation extraction. These studies roughly categorized three main paradigms. The first stream work, \citet{miwa2016end,gupta2016table,zhang2017end}, treats joint entity relation extraction task end-to-end table filling problem. Although methods represent entities relations shared parameters single model, extract entities relations separately produce redundant information . The second stream work, \citet{zheng2017joint,dai2019joint,wei-etal-2020-novel}, transforms joint entity relation extraction sequence labeling. To this, human experts need design complex tagging schema. The last stream work, including \citet{zeng2018extracting,zeng2019learning,nayak2019ptrnetdecoding,zeng2020copymtl}, driven sequence-to-sequence model generate relational triples directly, flexible framework handle overlapping triples require substantial effort human experts. We follow seq2seq based models joint entity relation extraction. Despite success existing seq2seq based models, still limited autoregressive decoder cross-entropy loss. The reasons follows: relational triples contained sentence intrinsic order essence. However, order adapt autoregressive decoder, whose output sequence, unordered target triples must sorted certain order training phase. Meanwhile, cross-entropy permutation-sensitive loss function, penalty incurred every triple predicted position. Consequently, current seq2seq base models need learn generate triples, also required consider extraction order multiple triples. % consists three parts featured transformers non-autoregressive parallel decoding bipartite matching loss. In detail, three parts proposed set prediction networks : avoid introducing order triplets % restoring original form task without considering order multiple triples In work, formulate joint entity relation extraction task set prediction problem, avoiding considering order multiple triples. In order solve set prediction problem, propose end-to-end network featured transformers non-autoregressive parallel decoding bipartite matching loss. In detail, three parts proposed set prediction networks : sentence encoder, set generator, set based loss function. First all, adopt BERT model encoder represent sentence. Then, since autoregressive decoder must generate items one one order, decoder suitable generating unordered sets. In contrast, leverage transformer-based non-autoregressive decoder set generator, predict triples avoid sorting triples. Finally, order assign predicted triple unique ground truth triple, propose bipartite matching loss function inspired assigning problem operation research . Compared cross-entropy loss highly penalizes small shifts triple order, proposed loss function invariant permutation predictions; thus suitable evaluating difference ground truth set prediction set. % To summarize, contributions follows: In nutshell, main contributions are: % main contributions work follows: % conjunction bipartite matching loss transformers % parallel decoding % Our work build prior work several domains:relation extraction, non-autoregressive model, andbipartite matching losses set prediction. % Relation Extraction. Non-autoregressive Model."," The joint entity and relation extraction task aims to extract all relational triples from a sentence. In essence, the relational triples contained in a sentence are unordered. However, previous seq2seq based models require to convert the set of triples into a sequence in the training phase. To break this bottleneck, we treat joint entity and relation extraction as a direct set prediction problem, so that the extraction model can get rid of the burden of predicting the order of multiple triples. To solve this set prediction problem, we propose networks featured by transformers with non-autoregressive parallel decoding. Unlike autoregressive approaches that generate triples one by one in a certain order, the proposed networks directly output the final set of triples in one shot. Furthermore, we also design a set-based loss that forces unique predictions via bipartite matching. Compared with cross-entropy loss that highly penalizes small shifts in triple order, the proposed bipartite matching loss is invariant to any permutation of predictions; thus, it can provide the proposed networks with a more accurate training signal by ignoring triple order and focusing on relation types and entities. Experiments on two benchmark datasets show that our proposed model significantly outperforms current state-of-the-art methods. Training code and trained models will be available at \url{http://github.com/DianboWork/SPN4RE}."
"Zero-shot translation first introduced \citet{firat-etal-2016-zero} refers ability multilingual NMT model translate source target languages, even pairs parallel data seen training. In simplest setting, parameters network shared different languages translation guided special tags indicate desired output language . While capability attractive alternative building dedicated translation systems serve languages, performance zero-shot pairs tends lag behind pivot translation. Recent papers, \citet{Arivazhagan2019}, \citet{Gu2019} \citet{Zhang2020}, suggested training techniques improve generalization unseen language pairs, performance varies considerably across settings. In paper, examine detail behavior multilingual model proposed \citet{Johnson2017} zero-shot translation directions. Our experiments show following: Overall, observe improvements 8.1 BLEU 6 zero-shot directions simple changes multilingual training setup."," Zero-shot neural machine translation is an attractive goal because of the high cost of obtaining data and building translation systems for new translation directions. However, previous papers have reported mixed success in zero-shot translation. It is hard to predict in which settings it will be effective, and what limits performance compared to a fully supervised system. In this paper, we investigate zero-shot performance of a multilingual EN$\leftrightarrow$\{FR,CS,DE,FI\} system trained on WMT data. We find that zero-shot performance is highly unstable and can vary by more than 6 BLEU between training runs, making it difficult to reliably track improvements. We observe a bias towards copying the source in zero-shot translation, and investigate how the choice of subword segmentation affects this bias. We find that language-specific subword segmentation results in less subword copying at training time, and leads to better zero-shot performance compared to jointly trained segmentation. A recent trend in multilingual models is to not train on parallel data between all language pairs, but have a single bridge language, e.g.\ English. We find that this negatively affects zero-shot translation and leads to a failure mode where the model ignores the language tag and instead produces English output in zero-shot directions.  We show that this bias towards English can be effectively reduced with even a small amount of parallel data in some of the non-English pairs."
"Entrainment well-known psycholinguistic phenomenon causing people adapt conversation partners become similar. It affects many linguistic features including phonetics , lexical choice , syntax , prosody . Importantly, correlates interesting aspects conversation task success, liking, even rapport robot . The researchers cited employed various means measure entrainment, correlations, models conditional probabilities, comparisons distributions, perceived similarity. Recently, \citet{Nasir2018} proposed first neural entrainment measure. Our work builds addressing challenge critical measuring entrainment: accounting consistency. Entrainment defined active, though unconscious, adaptation speaker towards partner. In practice, however, static similarity correlation two speakers often measured. Thus, even two speakers whose vocal characteristics initially similar perceived entrained, although adaptation taken place. Alternatively, Speaker B entrains Speaker A, speakers perceived entrained, without adaptation Speaker A. We apply neural methods proposed \citet{Pryzant2018} explicitly deconfound consistency, tendency adhere one's vocal style, entrainment, tendency adapt one's partner. We argue entrainment measures control consistency overestimate degree entrainment conversation. Section explains data features use train networks, described Section . Section introduces two experiments validate methods whose results discussed, lastly, Section .","   Human interlocutors tend to engage in adaptive behavior known as entrainment to become more similar to each other. Isolating the effect of consistency, i.e., speakers adhering to their individual styles, is a critical part of the analysis of entrainment. We propose to treat speakers' initial vocal features as confounds for the prediction of subsequent outputs. Using two existing neural approaches to deconfounding, we define new measures of entrainment that control for consistency. These successfully discriminate real interactions from fake ones. Interestingly, our stricter methods correlate with social variables in opposite direction from previous measures that do not account for consistency. These results demonstrate the advantages of using neural networks to model entrainment, and raise questions regarding how to interpret prior associations of conversation quality with entrainment measures that do not account for consistency."
"The proliferation online hate speech become prevalent recent times. Numerous social media outlets computational social science community looking various automated techniques detect classify hate speech. However, models, nascent nature, significant limitations due complexity problem. Primarily, lack reliable baseline coupled evolving vocabulary hateful content makes particularly challenging issue. For instance, many studies classified problem binary classification task, fails address subtleties hate speech, direct vs. indirect hate speech. These binary classification models also fail identify different types hate speech like racism, sexism, antisemitism, etc. varying degrees. Another key obstacle plagues binary models inability distinguish general offensive language hate speech. A third issue arises designing automated approaches class imbalance---hate speech usually small percentage overall data---and need adequately upsample hate observations without model overfitting. In work, inspired recent successes developing multi-class hate speech models separate hate speech offensive content, propose DeL-haTE, ensemble tunable deep learning models leverages CNN GRU layers. The CNN layer extracts higher-order features word embedding matrix inform GRU layer, extracts informative features sequence words. These features utilized automatic detection hate speech social media. Our novelty lies using tuning procedure adapt model individual dataset characteristics. %Issues particular developing hate speech detection models % - Class imbalance issue % - Hate speech minute portion overall content social media generally published datasets % - How adequately upsample hate observations training without leading model overfitting? % % - We, like others, utilize downsampling approach training ensure class-balanced dataset passes model epoch % - We combine early stopping procedure utilizes validation dataset saves model state epoch minimal validation loss % % - These procedures, factors, lead variability resultant models %To maintain necessity downsampling training mitigating problems overfitting variability, develop ensemble approach hate speech classification, extending CNN-RNN-FC model topology shown successful hate speech classification. Our major contributions summarized answering following questions. \end{enumerate} Summary Results: Our best ensemble HON dataset achieves 65\% F1 Macro 83\% hate recall, surpassing performance HON dataset current state art models 33\%. We show ensemble models outperform individual models average 5\% hate recall 8\% F1 macro across datasets. When applied unlabeled Gab data, tuning improved pretrained models average 12\%, best tuned ensemble models achieving 57\% hate recall. Our model trained using weak supervision achieved 67\% hate recall posts Gab. %\sidd{We show ensemble models outperform individual components average 5\% hate recall 8\% F1 macro. % %We examine generalizability model framework novel data Gab, experimenting transfer learning weak supervision % - Transfer learning using small manually labeled set posts improved hate recall ensembles pre-trained HON OLID datasets 10\% Gab data. % % - We hypothesized integrating labeling HON OLID datasets combining would lead better generalizability model framework increasing size diversity training examples % This confirmed experiments transfer learning combined ensembles outperformed single dataset models Gab data average 8\% Hate recall HON models 5\% F1 Macro.}"," %This document is a model and instructions for \LaTeX. %This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes,  %or Math in Paper Title or Abstract. Online hate speech on social media has become a fast-growing problem in recent times. Nefarious groups have developed large content delivery networks across several mainstream  and fringe outlets  to deliver cascades of hate messages directed both at individuals and communities. Thus addressing these issues has become a top priority for large-scale social media outlets. Three key challenges in automated detection and classification of hateful content are the lack of clearly labeled data, evolving vocabulary and lexicon - hashtags, emojis, etc - and the lack of baseline models for fringe outlets such as Gab. In this work, we propose a novel framework with three major contributions.  We engineer an ensemble of deep learning models that combines the strengths of state-of-the-art approaches,  we incorporate a tuning factor into this framework that leverages transfer learning to conduct automated hate speech classification on unlabeled datasets, like Gab, and  we develop a weak supervised learning methodology that allows our framework to train on unlabeled data. Our ensemble models achieve an 83\% hate recall on the HON dataset, surpassing the performance of the state of the art deep models. We demonstrate that weak supervised training in combination with classifier tuning significantly increases model performance on unlabeled data from Gab, achieving a hate recall of 67\%."
"The demand speech translation systems meetings lectures continues increase. Since length complete sentences talks long complicated, simultaneous speech translation required mimic human interpreters translate incoming speech stream source language target language real time. One challenge achieving simultaneous speech translation development incremental ASR. Researchers working speech recognition technology decades. A number techniques real-time ASR exist, especially context statistical ASR hidden Markov model . However, many current state-of-the-art ASR systems rely attention-based sequence-to-sequence deep learning frameworks . Today's attentional mechanisms based global attention property requires computation weighted summarization entire input sequence generated encoder states. This means system generate text output receiving entire input speech sequence. Consequently, utilizing situations require immediate recognition difficult. Several studies proposed local attention mechanisms limit area explored attention largely reducing total training complexity without reducing latency. For work enables incremental recognition speech, Hwang Sung employed unidirectional RNN CTC acoustic model unidirectional RNN language model . To avoid continuous output revision, also proposed depth-pruning beam-search output generation. Jaitly et al. proposed neural transducer framework incrementally recognizes input speech waveforms. The formulation required inferring alignments training, utilized dynamic programming algorithm compute ``approximate"" best alignments speech segments. Their model strongly related sequence transducer used connectionist temporal classification . The improved version neural transducer, also discussed , allows attention mechanism look back many previous chunks without introducing additional latency. However, ISR models utilize different frameworks learning algorithms complicated standard ASR model. One main reason models need decide incremental steps learn transcription aligned current short speech segment. In work, propose attention-transfer ISR following:"," Attention-based sequence-to-sequence automatic speech recognition  requires a significant delay to recognize long utterances because the output is generated after receiving entire input sequences. Although several studies recently proposed sequence mechanisms for incremental speech recognition , using different frameworks and learning algorithms is more complicated than the standard ASR model. One main reason is because the model needs to decide the incremental steps and learn the transcription that aligns with the current short speech segment. In this work, we investigate whether it is possible to employ the original architecture of attention-based ASR for ISR tasks by treating a full-utterance ASR as the teacher model and the ISR as the student model. We design an alternative student network that, instead of using a thinner or a shallower model, keeps the original architecture of the teacher model but with shorter sequences . Using attention transfer, the student network learns to mimic the same alignment between the current input short speech segments and the transcription. Our experiments show that by delaying the starting time of recognition process with about 1.7 sec, we can achieve comparable performance to one that needs to wait until the end."
"% % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % . % % % final paper: en-us version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. } The following instructions directed authors papers submitted COLING-2020 accepted publication proceedings. All authors required adhere specifications. Authors required provide Portable Document Format version papers. The proceedings designed printing A4 paper. Authors countries access word-processing systems limited contact publication co-chairs Fei Liu Liang Huang soon possible. We may make additional instructions available \url{http://coling2020.org/}. Please check website regularly.","   This document contains the instructions for preparing a paper submitted   to COLING-2020 or accepted for publication in its proceedings. The document itself   conforms to its own specifications, and is therefore an example of   what your manuscript should look like. These instructions should be   used for both papers submitted for review and for final versions of   accepted papers. Authors are asked to conform to all the directions   reported in this document."
"In biomedical domain, exist several entities, genes, chemicals, diseases, closely related other. Therefore, extracting relationships among entities critical biomedical research, particularly fields construction knowledge base drug development. Biomedical text data, including PubMed abstracts, usually contain information biomedical entities relationships other. Thus, various natural language processing models, particularly deep learning models, applied biomedical text data extract relationships among entities, kind classi閾夸恭ation task. ChemProt corpus first corpus dataset chemical--protein relationship extraction, conducted BioCreative VI organizers. These organizers annotated entity offsets chemical protein mentions relationship types chemicals proteins . There exist 10 groups relationship types, five used evaluation. All models extracting relationships ChemProt data designed classifiers. In deep learning-based multi-class classifier, output probability distribution class calculated Softmax function. In training step, model trained maximize output probability correct class. However, studies reported deep learning classifier trained hard-labeled data tends become over-confident . This over-confidence directly affect classification performance, degrades reliability model. In words, output probability over-confident model indicate uncertain input example is, even classi閾夸恭ation performance high. Therefore, several approaches, called ``calibration'' techniques, applied several domains require high reliability, autonomous driving medical diagnosis . In natural language processing domain, bidirectional encoder representation transformers proposed wide-range language understanding. BERT large multi-head attention model, pre-trained vast amount corpus data. This pre-trained model easily transfer-learned applied several downstream tasks fine-tuning it. BERT used many domains, including biomedical field. Nevertheless, still important improve performance BERT applying additional techniques using BERT backbone architecture. In study, propose DNN-based approach improve performance chemical--protein relationship extraction, calibrating classifier. More precisely, incorporated two main calibration techniques BERT improve reliability performance. Furthermore, propose semi-supervised learning workflow using calibrated model unlabeled in-domain data. The main contributions study follows:"," The extraction of interactions between chemicals and proteins from several biomedical articles is important in many fields of biomedical research such as drug development and prediction of drug side effects. Several natural language processing methods, including deep neural network  models, have been applied to address this problem. However, these methods were trained with hard-labeled data, which tend to become over-confident, leading to degradation of the model reliability. To estimate the data uncertainty and improve the reliability, ``calibration'' techniques have been applied to deep learning models. In this study, to extract chemical--protein interactions, we propose a DNN-based approach incorporating uncertainty information and calibration techniques. Our model first encodes the input sequence using a pre-trained language-understanding model, following which it is trained using two calibration methods: mixup training and addition of a confidence penalty loss. Finally, the model is re-trained with augmented data that are extracted using the estimated uncertainties. Our approach has achieved state-of-the-art performance with regard to the Biocreative VI ChemProt task, while preserving higher calibration abilities than those of previous approaches. Furthermore, our approach also presents the possibilities of using uncertainty estimation for performance improvement."
"Contemporary deep learning models language shown learn many aspects natural language syntax including number long-distance dependencies , selectional properties verbs , representations incremental syntactic state information hierarchical structure linearly decoded . These many related studies demonstrate impressive range human-like linguistic knowledge automatically acquired models simply exposure large quantities raw text. However, human-like grammatical abilities include rich detailed linguistic knowledge ability deploy knowledge using new words based minimal exposure . It remains poorly understood grammatical generalizations contemporary deep learning models able make regarding behavior words minimal exposure. In work, assess syntactic generalization behavior contemporary neural network model two novel phenomena English address question single-shot few-shot learning, demonstrating BERT makes robust grammatical generalizations fine-tuning minimal examples novel token. We test BERT's few-shot learning capabilities two phenomena syntax-semantics interface: English verbal alternations, verb/object selectional preferences. In English, verbs appear multiple syntactic frames; frame verb appears governed argument structure properties. Often, frames paired alternation classes English speakers hear novel verb one frame confident used alternation-class pair. Using well-attested dative alternation example, listener hears sentence ``I daxed tennis racket friend"" would expect ``I daxed friend tennis racket"" grammatical English sentence, meaning approximately thing. They would not, however, expectation ``I daxed friend tennis racket."" In addition, listeners may attuned semantic clustering verbal arguments based past experience. For instance, following example above, English speakers may expect dax take animate indirect object, would find examples ``I daxed court tennis racket"" surprising. We take inspiration testing regime class psycholinguistic experiments known `novel word learning studies', adapt neural setting. In experiments subjects exposed novel word context training phase, assessed grammatical generalizations learned novel word later testing phase. Novel word learning experiments used assess human grammatical generalization since \citet{berko1958child}, deployed assess semantic, well syntactic, generalizations . %For example, \citet{berko1958child}, children shown novel creature told wug. At test time, shown picture featuring two creatures described wugs indicating categorized novel word noun, applied productive -s pluralization it. Children also learn semantic properties word single exposure . %Bayesian models word learning shown successes modeling novel word learning abilities , however clear well neural network models would exhibit rapid generalizations. Recent work shown sequence-to-sequence neural architectures rarely generalize systematically way would required match human syntactic generalization behavior , open question whether might get different behavior depending network architecture training objective. In work, replicate novel word learning paradigm neural setting fine-tuning BERT tightly-controlled sentences contain novel verbs objects, assessing model carefully constructed test sets reveal grammatical generalizations learned. We find BERT able make proper generalizations verbal alternations well semantic clustering verbal arguments one two exposures training.","  Previous studies investigating the syntactic abilities of deep learning models have not targeted the relationship between the strength of the grammatical generalization and the amount of evidence to which the model is exposed during training. We address this issue by deploying a novel word-learning paradigm to test BERT's \cite{devlin2018bert} few-shot learning capabilities for two aspects of English verbs: alternations and classes of selectional preferences. For the former, we fine-tune BERT on a single frame in a verbal-alternation pair and ask whether the model expects the novel verb to occur in its sister frame. For the latter, we fine-tune BERT on an incomplete selectional network of verbal objects and ask whether it expects unattested but plausible verb/object pairs. We find that BERT makes robust grammatical generalizations after just one or two instances of a novel word in fine-tuning. For the verbal alternation tests, we find that the model displays behavior that is consistent with a transitivity bias: verbs seen few times are expected to take direct objects, but verbs seen with direct objects are not expected to occur intransitively. The code for our experiments is available at \url{https://github.com/TristanThrush/few-shot-lm-learning}."
"When Natural Language Processing systems deployed production, interact users , many potential ways collecting feedback data rich interaction logs. For example, one ask explicit user ratings, collect user clicks, elicit user revisions get estimate well deployed system doing. However, user interaction logs primarily used one-off assessment system, e.g., spotting critical errors, detecting domain shifts, identifying successful use cases system production. This assessment used support decision keeping replacing system production. From machine learning perspective, using interaction logs evaluation purposes lost opportunities offline reinforcement learning . Logs user interactions gold mines off-policy learning, put use, rather forgotten one-off evaluation purpose. To move towards goal using user interaction logs learning, discuss challenges hindered RL employed real-world interaction users NLP systems far. Concretely, focus sequence-to-sequence learning NLP applications , machine translation, summarization, semantic parsing dialogue generation chatbots, since applications provide richest interaction users. For example, many machine translation services provide option users give feedback quality translation, e.g. collecting post-edits. Similarly, industrial chatbots easily collect vast amounts interaction logs, utilized offline RL methods. Recent work recognized poorly defined realities real-world systems hampering progress RL production environments. They address, amongst others, issues off-line learning, limited exploration, high-dimensional action spaces, unspecified reward functions. These challenges important RL control systems robots grounded physical world. However, severely underestimate human factor collecting feedback systems interacting humans, e.g. natural language. In following, thus present challenges encountered user-interactive RL NLP systems. With discussion, aim encourage NLP practitioners leverage interaction logs offline RL, inspire RL researchers steel algorithms challenging applications NLP."," Large volumes of interaction logs can be collected from NLP systems that are deployed in the real world. How can this wealth of information be leveraged? Using such interaction logs in an offline reinforcement learning  setting is a promising approach. However, due to the nature of NLP tasks and the constraints of production systems, a series of challenges arise. We present a concise overview of these challenges and discuss possible solutions."
"In addition challenges multiword expression processing addressed previous work, non-compositionality , discontinuity , syntactic variability , The PARSEME shared task edition 1.2 focused another prominent challenge detecting MWEs, namely detection unseen MWEs. The problem unseen data common many NLP tasks. While rule-based unsupervised ML approaches less affected unseen data, supervised ML techniques often found prone overfitting. In respect, introduction language modelling objectives added different NLP tasks effect generalisation shown promising results. Further improvements brought pre-trained language models made popular approach multitude NLP tasks. One particular advantage models facilitate generalisation beyond task-specific annotations . MWEs inherent natural languages distinguishable syntactic semantic idiosyncracies . Since language models good capturing syntactic semantic features, believe suitable approach modelling MWEs. In particular, system relies BERT pre-trained language models . Additionally, render system semi-supervised means multi-task learning. The promising feature jointly learned MWEs dependency parse information . Accordingly, fine-tune BERT two different objectives: MWE detection dependency parsing. MWE learning done via token classification using linear layer top BERT, dependency parse trees learned using dependency tree CRF network . Our experiments confirm joint learning architecture effective capturing MWEs languages represented shared task.~"," This paper describes a semi-supervised system that jointly learns verbal multiword expressions  and dependency parse trees as an auxiliary task. The model benefits from pre-trained multilingual BERT.  BERT hidden layers are shared among the two tasks and we introduce an additional linear layer to retrieve VMWE tags. The dependency parse tree prediction is modelled by a linear layer and a bilinear one plus a tree CRF on top of BERT. The system has participated in the open track of the PARSEME shared task 2020 and ranked first in terms of F1-score in identifying unseen VMWEs as well as VMWEs in general, averaged across all $14$ languages."
"% \gn{Title candidate: ``Detecting Hallucinated Content ...'' . I wonder could also run methods extractive summarization outputs true references see many hallucinations detect? Just idea.} % However, recent studies abstractive text summarization % neural machine translation~ shown conditional neural sequence models prone hallucinate content faithful input text. This risk generating unfaithful content impedes safe deployment neural sequence generation models~. The first step building models suffer failures assessment identification hallucinated outputs. Prior work shown standard metrics used sequence evaluation, BLEU scores , ROUGE BERTScores , correlate well faithfulness model outputs~. They also require reference output text, limiting applicability detecting halluciations deployed system run-time. Very recent efforts~ started develop automatic metrics measure faithfulness output sequences. These methods use external semantic models, e.g. question-generation question-answering systems~ textual entailment inference models, score faithfulness tailored abstract text summarization. However, scores directly measure number hallucinated tokens %In addition, metrics often tailored evaluation summaries abstract text summarization correlate weakly human judgements. % \gn{Big question: difference word-level quality estimation, around long time, since least: \citet{bach-etal-2011-goodness} covered many WMT quality estimation shared tasks . This seems related works cited below, describing we'd need something new works would probably big question minds anyone familiar MT field. Also, would proposed methods detecting hallucination better SOTA word-level QE models?} % \gn{Similar motivation: Moreover, distinguish types errors terms fluency adequacy: substitution error referring simple morphological variation % considered way content word substitution changing meaning sentence.~.} We propose new task faithfulness assessment - hallucination detection token level, aims predict token machine output hallucinated faithful source input. This task use reference output assess faithfulness, offers us ability apply online generation scenario references available. Similar spirit proposed task, word-level quality estimation~ machine translation community predicts tokens correctly translated based human post-editing. However, distinguish errors terms fluency adequacy~. % A substitution error referring simple morphological variation considered content word substitution changing meaning sentence.~. In contrast estimating amount human post-editing work required fix errors, specifically focus hallucination errors. We measure hallucination two conditional sequence generation tasks -- abstractive summarization machine translation . For former, produce benchmark dataset recently released annotations ~. For MT, carefully design human assessment guideline create high-quality annotations. We also release human annotated data future research. To learn token-level hallucination prediction general conditional sequence generations tasks, propose novel method creates synthetic ``hallucinated"" data finetunes pretrained language model~ it. Without human annotated supervised training data, achieve average F1 around 0.6 across benchmark datasets, setting initial performance levels new task. % \cz{\st{We also computed sentence-level aggregated predictions achieve significantly higher correlations human scores previous methods. Finally, use new data study effect pretraining MT hallucination show actually produce faithful translations, }} We also show pretraining MT actually produce faithful translations, confirming recent findings abstractive summarization~. Predicting hallucination labels token-level provides tool diagnosing interpreting model outputs, allows us flag potential risks inference time previously unseen inputs. On hand, token-level labels also allow fine-grained controls target sequence learning full translation models. We show use token-level hallucination labels two case studies improve self-training learning noisy mined bitext low-resource MT. In cases, noise target text, either produced self-training teacher mining errors. However, outputs partially hallucinated rest output still useful training, show introducing different token-level loss truncation schemes. %To benefit self-training, filter noisy part also glean useful part model predictions applying token-level loss truncation control information flows target sequence training time. Our best methods outperform strong baselines large margin translation quality hallucination reduction. %"," Neural sequence models can generate highly fluent sentences but recent studies have also shown that they are also prone to hallucinate additional content not supported by the input, which can cause a lack of trust in the model. To better assess the faithfulness of the machine outputs, we propose a new task to predict whether each token in the output sequence is hallucinated conditioned on the source input, and collect new manually annotated evaluation sets for this task. We also introduce a novel method for learning to model hallucination detection, based on pretrained language models fine tuned on synthetic data that includes automatically inserted hallucinations.   Experiments on machine translation and abstract text summarization demonstrate the effectiveness of our proposed approach -- we obtain an average F1 of around 60 across all the benchmark datasets. Furthermore, we demonstrate how to use the token-level hallucination labels to define a fine-grained loss over the target sequence in the low-resource machine translation and achieve significant improvements over strong baseline methods. We will release our annotated data and code to support future research."
"With rise social media e-commerce websites, huge interest analyzing networks tasks like link prediction, recommendation, community detection, etc. Traditionally, done learning finite-dimensional vector embeddings/representations nodes networks used downstream tasks. One challenges quality learned representation decreases network many missing links. This affects performance downstream tasks. This addressed using attribute similarity nodes connected usually similar attributes. For example, citation networks, papers related works cite other, social media, people similar interest follow other. In real-world graphs, nodes networks contain rich textual information attributes. So, need techniques exploit textual information learning node embeddings. The representation learning textual networks deals problem. \iffalse While networks sources relational information, many practical scenarios, nodes networks contain rich information attributes. When data form text networks referred textual networks, representation learning networks several applications diverse fields analyzing social media profiles biomedical networks. One challenges problem quality learned representation decreases network many missing links. This addressed using attribute similarity nodes connected usually similar attributes. For example, citation networks, papers related works cite other, social media, people similar interest follow other. So, exploiting this, one predict edges network. The main aim representation learning network learn embeddings, finite-dimensional vector representations nodes graph. %Representation learning networks uses edge/link weights labels objective function learn embeddings. These finite-dimensional vector representations node graph. In paper study problem textual networks, nodes networks equipped attributes content form textual information . These learned embeddings used problems like link prediction, community detection, social network analysis, on. One challenges problem quality learned representation decreases network many missing links. This addressed using attribute similarity nodes connected usually similar attributes. For example, citation networks, papers related works cite other, social media, people similar interest follow other. So, exploiting this, one predict edges network. %For achieving representation learning textual networks, propose adversarial framework using textual similarity discriminator structural similarity generator. \fi Recent methods representation learning textual networks involves learning two embeddings, one structure information , textual information . The embeddings learned similar nodes connected edge. The challenging task learn combined text structure embeddings, previous approaches use joint learning framework defining loss function models inter-modal similarities structure textual information nodes connected edge, addition intra-modal similarities. For example, consider nodes embeddings . The similarity embeddings used modelling intra-model similarity structure information, hand similarity used intra-model similarity text information. For inter-model similarity, similarity used modelling similarity structure text, vice versa. All similarities modelled using skip-gram loss function . The main disadvantage models dependent edge labels embedding learning. This make unable learn embeddings nodes present training stage. The way modelled learn unseen nodes embeddings mapper function textual information structure embeddings seen nodes apply unseen nodes getting structure embeddings. This result poor performance downstream tasks involving unseen nodes mapping function cannot fully capture structural information nodes. Recenlty, issue addressed using variational autoencoder framework structure text embeddings. Although achieved better performance mapper function-based models, disadvantage autoencoder framework limits information learned structure embeddings used predicting text features decoder. In paper, propose adversarial model generator learns structure embeddings text embedding based discriminator structure embeddings based generator. For generator, use supervision edge-connectivity text embedding similarity learn structure embeddings. For discriminator model, text embeddings made dissimilar node pair generated generator similar node pairs graph. This training make text similarity discriminator approximate actual similarity network. Through framework establish model efficiently amalgamate fuse information text graph text structure embeddings use information modality learning. In addition this, proposed adversarial approach extended embedding learning unseen nodes training dataset. This achieved directly using discriminator based text-similarity supervision post-training stage. This help efficiently learning unseen structure embeddings restrict embedding learning using predict text features like VHE . The performance model depends upon well exploit unstructured textual information, need powerful discriminator. To achieve this, use context-aware embeddings, node different text embedding edges. We address problem proposing novel technique combining two context-aware attention mechanism. The first based mutual attention word embeddings text across pair nodes. The topological attention mechanism. This uses structure embeddings node pairs attend text learn topology-aware text embedding. It reduce adverse effects trying make text embeddings similar textual information connected nodes need match. Because, model better representation capacity learns similarity topological mutual attention. The following main contributions paper. An adversarial technique attributed network representation learning. Here, addition supervision training data, discriminator using text embeddings used give supervision structure embeddings. A novel text embedding learning technique uses mutual topological attention. Extensive comparative study downstream tasks link prediction node classification. Experiments link prediction unseen nodes. \iffalse We evaluated proposed method three datasets Cora, Zhihu, Hepth link prediction. We observed model performs better state-of-the-art methods almost settings three datasets. The performance model especially high low data regime. In Zhihu dataset, model show performance improvement previous state-of-the-art lowest supervision setting. A similar observation made node classification task Cora dataset, adversarial technique achieve state-of-the-art performance. As mentioned earlier, main advantage model ability care representation learning unseen nodes. We evaluated quality embeddings link prediction task edges involving unseen nodes, ACNE achieves state-of-the-art performance settings three datasets. On Zhihu dataset, gave impressive improvement improvement previous methods low-data regime. \fi \iffalse \fi %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"," \label{section:abstract}  Representation learning of textual networks poses a significant challenge as it involves capturing amalgamated information from two modalities:  underlying network structure, and  node textual attributes. For this, most existing approaches learn embeddings of text and network structure by enforcing embeddings of connected nodes to be similar. Then for achieving a modality fusion they use the similarities between text embedding of a node with the structure embedding of its connected node and vice versa. %Then for achieving modality fusion they model intra-modal similarities involving networks structure and textual attributes of  nodes in an edge.  This implies that these approaches require edge information for learning embeddings and they cannot learn embeddings of unseen nodes. In this paper we propose an approach that achieves both modality fusion and the capability to learn embeddings of unseen nodes. The main feature of our model is that it uses an adversarial mechanism between text embedding based discriminator, and structure embedding based generator to learn efficient representations. Then for learning embeddings of unseen nodes, we use the supervision provided by the text embedding based discriminator. In addition this, we propose a novel architecture for learning text embedding that can combine both mutual attention and topological attention mechanism, which give more flexible text embeddings. Through extensive experiments on real-world datasets, we demonstrate that our model makes substantial gains over several state-of-the-art benchmarks. In comparison with previous state-of-the-art, it gives up to 7\% improvement in performance in predicting links among nodes seen in the training and up to 12\% improvement in performance in predicting links involving nodes not seen in training. Further, in the node classification task, it gives up to 2\% improvement in performance."
"Streaming Automatic Speech Recognition researches made way everyday products. Smart speakers transcribe utterances streaming fashion, allowing users downstream applications see instant output terms partial transcriptions. There growing interest community develop end-to-end streaming ASR models, transcribe accurately run compactly edge devices. Amongst streaming E2E models, Recurrent Neural Network Transducer candidate many applications. RNN-T trained loss function enforce temporal alignment training transcripts audio. As result, RNN-T suffers token emission delays - time token spoken transcript token emitted. Delayed emissions tokens adversely affects user experiences downstream applications end-pointer. Some existing work tried mitigate token emission delays streaming RNN-Ts. We introduce Section. Other works utilized semi-streaming non-streaming models predict better token emission time, cost overall latency transcripts. In work, propose novel loss function streaming RNN-T, resultant trained model called Alignment Restricted RNN-T . It utilizes audio-text alignment information guide loss computation. In Section, show theoretically, Ar-RNN-T loss function faster compute results better audio-token alignment. In Section, empirically compare proposed method existing works monotonic RNN-T training two data set: LibriSpeech voice command. In results section, Section, show improvement training speed used tandem end-pointer, Ar-RNN-T provides unprecedentedly refined control latency-WER trade-offs RNN-T models."," There is a growing interest in the speech community in developing Recurrent Neural Network Transducer  models for automatic speech recognition  applications. RNN-T is trained with a loss function that does not enforce temporal alignment of the training transcripts and audio. As a result, RNN-T models built with uni-directional long short term memory  encoders tend to wait for longer spans of input audio, before streaming already decoded ASR tokens. In this work, we propose a modification to the RNN-T loss function and develop Alignment Restricted RNN-T  models, which utilize audio-text alignment information to guide the loss computation. We compare the proposed method with existing works, such as monotonic RNN-T, on LibriSpeech and in-house datasets. We show that the Ar-RNN-T loss provides a refined control to navigate the trade-offs between the token emission delays and the Word Error Rate . The Ar-RNN-T models also improve downstream applications such as the ASR End-pointing by guaranteeing token emissions within any given range of latency. Moreover, the Ar-RNN-T loss allows for bigger batch sizes and 4 times higher throughput for our LSTM model architecture, enabling faster training and convergence on GPUs."
. % % % final paper: en-us version % % space normally used marker This work licensed Creative Commons Attribution 4.0 International License. License details: \url{http://creativecommons.org/licenses/by/4.0/}. },"   Interpretability and explainability of deep neural networks are challenging due to their scale, complexity, and the agreeable notions on which the explaining process rests. Previous work, in particular, has focused on representing internal components of neural networks through human-friendly visuals and concepts. On the other hand, in real life, when making a decision, human tends to rely on similar situations and/or associations in the past. Hence arguably, a promising approach to make the model transparent is to design it in a way such that the model explicitly connects the current sample with the seen ones, and bases its decision on these samples.   Grounded on that principle, we propose in this paper an explainable, evidence-based memory network architecture, which learns to summarize the dataset and extract supporting evidences to make its decision. Our model achieves state-of-the-art performance on two popular question answering datasets . Via further analysis, we show that this model can reliably trace the errors it has made in the validation step to the training instances that might have caused these errors. We believe that this error-tracing capability provides significant benefit in improving dataset quality in many applications."
"% % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % . } Word segmentation fundamental NLP analysis problem written languages space delimiters words Chinese Japanese. In age digital communications, new URLs hashtags , often include strings concatenated words added every day growing set tokens NLP system may need deal with, pose challenges language speech applications. For example, Text-to-Speech synthesis system struggle pronounce concatenated tokens, since simply applying grapheme-to-phoneme system box something like usually yield poor results. This suggests need model split tokens component words. So-called ``end-to-end'' neural TTS systems , learn map directly character sequences speech might seem hold hope avoiding treating problem separately. However, fact URLs occur relatively rarely TTS training data limits promise models long-tail problem. The problem analyzing URLs differ one useful way general text normalization problems. For token text, one typically needs know context occurs order know read it: ; see , inter alia. In case URLs, largely context-independent since output segmentation usually unaffected surrounding words. Hence problem treated standalone one require system trained part broader text normalization training. Our training data comes camel case URLs naturally define segment boundaries along manual corrections non-trivial boundaries. We release training evaluation data sets promote research problem. By drawing analogy Chinese word segmentation, cast URL segmentation problem sequence tagging problem. We propose simple Recurrent Neural Network based tagger encoder decoder. The model trained data set decent full sequence accuracy fails generalize rare words due size training data. Inspired success pre-training many NLP tasks , propose pre-training recipe segmenter. Based observation URLs often compound entity names knowledge graph entities , create large synthetic training data set concatenating knowledge graph entity names. We observe 21\% absolute improvement sequence accuracy applying pre-training followed fine-tuning. % % File acl2020.tex % %% Based style files ACL 2020, %% Based style files ACL 2018, NAACL 2018/19, %% Based style files ACL-2015, improvements %% taken NAACL-2016 style %% Based style files ACL-2014, were, turn, %% based ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009, %% EACL-2009, IJCNLP-2008... %% Based style files EACL 2006 %%e.agirre@ehu.es Sergi.Balari@uab.es %% ACL 08 Joakim Nivre Noah Smith \pdfoutput=1 \documentclass[11pt,a4paper]{article} \usepackage{coling2020} \usepackage{times} \usepackage{latexsym} \usepackage{graphicx} \usepackage{amsmath} \newcommand{\UrlFont}{\ttfamily\small} \newcommand{\citep}{\cite} \newcommand{\citet}{\newcite} \usepackage{xcolor} \usepackage{multirow} \usepackage{url} \colingfinalcopy % This strictly necessary, may commented out, % improve layout manuscript, % typically save space. \usepackage{microtype} %\aclfinalcopy % Uncomment line final submission %\def\aclpaperid{560} % Enter acl Paper ID %\setlength\titlebox{5cm} % You expand titlebox need extra space % show authors. Please make titlebox % smaller 5cm ; check % camera-ready version ask change back. \newcommand{\todo}[1]{{\color{red}{#1}}} \newcommand{\newtext}[1]{{\color{red}{#1}}} \newcommand\BibTeX{Bib\TeX} \title{Semi-supervised URL Segmentation Recurrent Neural Networks Pre-trained Knowledge Graph Entities} \author{Hao Zhang \and Jae Ro \and Richard Sproat \\ Google Research \\ @google.com}} \date{}"," Breaking domain names such as \texttt{openresearch} into component words \texttt{open} and \texttt{research} is important for applications like Text-to-Speech synthesis and web search. We link this problem to the classic problem of Chinese word segmentation and show the effectiveness of a tagging model based on Recurrent Neural Networks  using characters as input. To compensate for the lack of training data, we propose a pre-training method on concatenated entity names in a large knowledge database. Pre-training improves the model by 33\% and brings the sequence accuracy to 85\%."
". % % final paper: en-us version % space normally used marker This work licensed Creative Commons Attribution 4.0 International License. License details: \url{http://creativecommons.org/licenses/by/4.0/}. } Discourse parsing important upstream task within area Natural Language Processing active field research last decades. In work, focus discourse representations English language, research %on discourse analysis English language surrounding one two main theories behind discourse, Rhetorical Structure Theory proposed interpreting discourse according PDTB . While theories strengths, application RST theory, encoding documents complete constituency discourse trees , shown many crucial implications real world problems. A tree defined set EDUs , approximately aligning clause-like sentence fragments, acting leaves tree. Adjacent EDUs sub-trees hierarchically aggregated form larger constituents, internal nodes containing nuclearity label, defining importance subtree local context relation label, defining type semantic connection two subtrees . In work, focus structure nuclearity prediction, taking relations account. Previous research shown use RST-style discourse parsing system component enhance important tasks, sentiment analysis, summarization text categorization . More recently, also suggested discourse structures obtained RST-style manner complementary learned contextual embeddings, like popular BERT approach . Combining approaches shown support tasks linguistic information complete documents critical, argumentation analysis . Even though discourse parsers appear enhance performance variety tasks, full potential using linguistically inspired approaches downstream applications unleashed yet. The main open challenges integrating discourse NLP downstream tasks deliver even greater benefits combination discourse parsing difficult task itself, inherently high degree ambiguity uncertainty lack large-scale annotated datasets, rendering initial problem severe, data-driven approaches cannot applied full potential. The combination two limitations one main reasons limited application neural discourse parsing diverse downstream tasks. While neural discourse parsers proposed , still cannot consistently %strongly outperform traditional approaches applied RST-DT dataset, amount training data arguably insufficient data-intensive approaches. %due extra effort integrate discourse trees models well two major problems, big breakthrough usage discourse parsing still happened. In work, alleviate restrictions effective efficient use discourse mentioned introducing novel approach combining newly proposed large-scale discourse treebank data-driven neural discourse parsing strategy. More specifically, employ novel MEGA-DT ``silver-standard"" discourse treebank published containing 250,000 discourse annotated documents Yelp'13 sentiment dataset , nearly three orders magnitude larger commonly used RST-style annotated discourse treebanks . Given new dataset previously unseen number full RST-style discourse trees, revisit task neural discourse parsing, previously attempted others rather limited success. We believe one reason previous neural models could yet consistently outperform traditional approaches, heavily relying feature engineering , lack generalisation using deep learning approaches small RST-DT dataset, containing 385 discourse annotated documents. This makes us believe using advanced neural discourse parser combination large training dataset lead significant performance gains. %, also across datasets, capturing general discourse phenomena avoiding potential overfitting training corpus. Admittedly, even though MEGA-DT contains huge number datapoints train on, automatically annotated, potentially introducing noise biases, negatively influence performance newly proposed neural discourse parser solely trained dataset. A natural intuitive approach make use neural discourse parser datasets combine training, pretraining large-scale ``silver-standard"" corpus subsequently fine-tuning RST-DT human annotated datasets. This way, general discourse structures could learned large-scale treebank enhanced human-annotated trees. With results shown paper strongly suggesting new discourse parser encode discourse effectively, hope efforts prompt researchers develop linguistically inspired applications based discourse parser. % downstream models area NLP. Our contributions paper are: % %on train neural discourse parser large scale ``silver-standard"" discourse trees. With new approach, drastically increase amount available training data available discourse parsers sufficiently large train modern, data-driven deep learning approaches task, hindering application new methodologies shift domain discourse parsers training data domain application deminishes applicability performance generated discourse trees domain outside news , instructions domains."," RST-based discourse parsing is an important NLP task with numerous downstream applications, such as summarization, machine translation and opinion mining. In this paper, we demonstrate a simple, yet highly accurate discourse parser, incorporating recent contextual language models. Our parser establishes the new state-of-the-art  performance for predicting structure and nuclearity on two key RST datasets, RST-DT and Instr-DT. We further demonstrate that pretraining our parser on the recently available large-scale ``silver-standard"" discourse treebank MEGA-DT provides even larger performance benefits, suggesting a novel and promising research direction in the field of discourse analysis."
"The last several years seen land rush research machine reading comprehension various dataset proposed SQuAD1.1, SQuAD2.0, NewsQA CoQA . Different extractive MRC, RACE multi-choice MRC dataset proposed . RACE extracted middle high school English examinations China. Figure 1 shows example passage two related questions RACE. The key difference RACE previously released machine comprehension datasets answers RACE often cannot directly extracted passages, illustrated two example questions Table . Thus, answering questions needs inferences. \end{center} \end{table} % Recently, pretrained language models BERT , RoBERTa , ALBERT achieved great success MMRC tasks. Notably, Megatron-LM 48 layer BERT 3.9 billion parameters yields highest score RACE leaderboard single ensemble settings. The key point model MMRC is: first encode context, question, options BERT like LM, add matching network top BERT score options. Generally, matching network various . proposes option comparison network compare options word-level better identify correlations help reasoning. proposes dual co-matching network models relationship among passage, question answer options bidirectionally. All matching networks show promising improvements compared pretrained language models. One point common answer together distractors jointly considered name multi-choice models. We argue options concerned separately two reasons, 1) human works MMRC problem, always consider options one one select one highest confidence. 2) MMRC suffers data scarcity problem. Multi-choice models inconvenient take advantage MRC dataset. In paper, propose single-choice model MMRC. Our model considers options separately. The key component method binary classification network top pretrained language models. For option given context question, calculate confidence score. Then select one highest score final answer. In training decoding, right answer distractors modeled independently. Our proposed method gets rid multi-choice framework, leverage amount resources. Taking SQuAD example, take context, one question corresponding answer positive instance classification golden label 1. In way many QA dataset used enhance RACE. Experimental results show single-choice model performs better multi-choice models, addition transferring knowledge QA dataset, single model achieves 90.7\% ensemble model achieves 91.4\%, best score leaderboard."," Multi-choice Machine Reading Comprehension  aims to select the correct answer from a set of options based on a given passage and question. Due to task specific of MMRC, it is non-trivial to transfer knowledge from other MRC tasks such as SQuAD, Dream. In this paper, we simply reconstruct multi-choice to single-choice by training a binary classification to distinguish whether a certain answer is correct. Then select the option with the highest confidence score. We construct our model upon ALBERT-xxlarge model and estimate it on the RACE dataset. During training, We adopt AutoML strategy to tune better parameters. Experimental results show that the single-choice is better than multi-choice. In addition, by transferring knowledge from other kinds of MRC tasks, our model achieves a new state-of-the-art results in both single and ensemble settings."
"% Images another important approach expressing feelings emotions addition using text communication. In mobile messaging apps, images generally classified emojis stickers. Emoji kind small picture already stored keyboard mobile operational systems, \ie iOS Android. Emojis pre-designed mobile phone vendor number emoji limited, users design emoji themselves. Different inflexible emojis, sticker image graphicon essentially, users draw modify images sticker upload chatting app themselves. The using stickers online chatting usually brings diversity expressing emotion. Since emojis sometimes used help reinforce simple emotions text message due small size, variety limited. Stickers, hand, regarded alternative text messages, usually include cartoon characters high definition. They express much complex vivid emotion emojis. Most messaging apps, WeChat, Telegram, WhatsApp, Slack provide convenient ways users download stickers free, even share self-designed ones. We show chat window including stickers Figure. % Stickers becoming popular online chat. First, sending sticker single click much convenient typing text 26-letter keyboard small mobile phone screen. Second, many implicit strong emotions difficult express words captured stickers vivid facial expressions body language. However, large scale use stickers means always straightforward think sticker best expresses one's feeling according current chatting context. Users need recall stickers collected selected appropriate one, difficult time-consuming. % Consequently, much research focused recommending appropriate emojis users according chatting context. Existing works as, mostly based emoji recommendation, predict probable emoji given contextual information multi-turn dialog systems. In contrast, works recommend emojis based text images posted user. As sticker recommendation, existing works apps like Hike QQ directly match text typed user short text tag assigned sticker. However, since lots ways expressing emotion, hard capture variants utterance tags. % To overcome drawbacks, propose sticker response selector sticker selection early work, address task sticker response selection multi-turn dialog. We focus two main challenges work: Since existing image recognition methods mostly built real-world images, capture semantic meaning sticker challenging. Understanding multi-turn dialog history information crucial sticker recommendation, jointly modeling candidate sticker multi-turn dialog challenging. % % % % % % Herein, propose novel sticker recommendation model, namely sticker response selector , sticker response selection multi-turn dialog. Specifically, SRS first learns representations dialog context history using self-attention mechanism learns sticker representation convolutional neural network . % % % Next, SRS conducts deep matching sticker utterance produces interaction results every utterance. % % Finally, SRS employs fusion network consists sub-network fusion RNN fusion transformer learn short long term dependency utterance interaction results. The final matching score calculated interaction function. To evaluate performance model, propose large number multi-turn dialog dataset associated stickers one popular messaging apps. Extensive experiments conducted dataset show SRS significantly outperforms state-of-the-art baseline methods commonly-used metrics. % However, user's sticker selection depend matching degree dialog context candidate sticker image, also depends user's preference using sticker. When users decide use sticker response multi-turn dialog, may choose favorite one appropriate stickers final response. % % % We assume user tends use recently used sticker dialog history, recently-used-sticker represent user's preference sticker selection. An example shown Figure. To verify assumption, retrieve 10 recently-used-stickers user calculate proportion whether currently used sticker appeared 10 stickers. The result shows 54.09\% stickers exist 10 recently used sticker set. Hence, reach conclusion users strong personal preference selecting sticker response current dialog context. However, cases, also indicates tendency re-use stickers, necessarily preference. % Motivated observation, work, take one step improve previously proposed SRS framework user preference modeling. Overall, propose novel sticker recommendation model considers user preference, namely Preference Enhanced Sticker Response Selector . Specifically, PESRS first employs convolutional network extract features candidate stickers. Then, retrieve recent user sticker selections user preference modeling module employed obtain user preference representation. Next, conduct deep matching candidate sticker utterance SRS. Finally, use gated fusion method combine deep matching result user preference final sticker prediction. % The key success PESRS lies design user preference modeling module, identify user's favorite sticker also consider current dialog context. % Motivated this, first propose recurrent neural network based position-aware sticker modeling module encodes recently used stickers chronological order. Then, employ key-value memory network store sticker representations values corresponding dialog context keys. Finally, use current dialog context query key-value memory obtain dynamic user preference current dialog context. % We empirically compare PESRS SRS public dataset\footnote{https://github.com/gsh199449/stickerchat} proposed early work. This large-scale real-world Chinese multi-turn dialog dataset, dialog context multiple text utterances response sticker image. Experimental results show dataset, newly proposed PESRS model significantly outperform existing methods. Particularly, PESRS yields 4.8\% 7.1\% percentage point improvement terms compared early work SRS. % In addition comprehensive evaluation, also evaluate proposed user preference memory fine-grained analysis. The analysis reveals model leverages user's recent sticker selection history provides us insights achieve big improvement state-of-the-art methods. This work substantial extension previous work reported WWW 2020. The extension article includes user preference modeling framework existing methods, proposal new framework sticker selection multi-turn dialog. Specifically, contributions work include following: The rest paper organized follows: We summarize related work \S. \S introduces data collection method statistics proposed multi-turn dialog sticker selection dataset. We formulate research problem \S elaborate approach \S. \S gives details experimental setup \S presents experimental results. Finally, \S concludes paper. %","   Stickers with vivid and engaging expressions are becoming increasingly popular in online messaging apps, and some works are dedicated to automatically select sticker response by matching the stickers image with previous utterances.   However, existing methods usually focus on measuring the matching degree between the dialog context and sticker image, which ignores the user preference of using stickers.   Hence, in this paper, we propose to recommend an appropriate sticker to user based on multi-turn dialog context and sticker using history of user.   Two main challenges are confronted in this task.   One is to model the sticker preference of user based on the previous sticker selection history.   Another challenge is to jointly fuse the user preference and the matching between dialog context and candidate sticker into final prediction making.   To tackle these challenges, we propose a Preference Enhanced Sticker Response Selector  model.   Specifically, PESRS first employs a convolutional based sticker image encoder and a self-attention based multi-turn dialog encoder to obtain the representation of stickers and utterances.   Next, deep interaction network is proposed to conduct deep matching between the sticker and each utterance.   Then, we model the user preference by using the recently selected stickers as input, and use a key-value memory network to store the preference representation.   PESRS then learns the short-term and long-term dependency between all interaction results by a fusion network, and dynamically fuse the user preference representation into the final sticker selection prediction.   Extensive experiments conducted on a large-scale real-world dialog dataset show that our model achieves the state-of-the-art performance for all commonly-used metrics.   Experiments also verify the effectiveness of each component of PESRS.   %"
".} Neural machine translation boosted machine translation significantly recent years . However, still unclear NMT models work due black-box nature neural networks. Better understandings NMT models could guide us improving NMT systems. Currently studies towards understanding NMT models take account subword-based models. Deeper character-based models shown perform better BPE-based models . In paper, try investigate working mechanism CHAR models. We explore ability CHAR models learn word senses morphological inflections attention mechanism. Previous studies tried interpret understand NMT models interpreting attention weights , using gradients , applying layer-wise relevance propagation , probing classification tasks , intrinsic analysis . However, probed character-based representations. explored character-aware word-level representations, investigate fully character-level representations, also studied . We apply composition methods explore CHAR models learn linguistic knowledge attention extracts features directly characters. Probing classification tasks emerged popular method interpret internal representations neural networks. Given probing classifier, input usually representation word output corresponding linguistic tag. CHAR models pose new challenges interpretability, investigate whether probe CHAR models way similar word-based models. In addition, extract word sense morphological information full word individual hidden states, information distributed across multiple states? This implications interpreting neural CHAR models, also inform novel architectures, sparse attention mechanisms. Thus first investigate ability CHAR models learn word senses morphology Section . We apply different methods compose information characters demonstrate word-level information distributed characters characters different positions play different roles learning linguistic knowledge. We also explore effect encoder depth answer CHAR models outperform BPE-based models settings deeper encoder. The probing results show CHAR models need layers learn word senses. Then Section , move explore attention mechanism. The distribution pattern shows separators attract much attention compared characters. To study effect enforcing characters capture full word-level information, investigate sparse attention mechanism, i.e. model attends separators, viewed word-level attention. The BLEU score drops 1.2 points apply word-level sparse attention. This implies attending separators single attention head workable enough extract necessary information. The main findings summarized follows:"," Recent work has shown that deeper character-based neural machine translation  models can outperform subword-based models. However, it is still unclear what makes deeper character-based models successful. In this paper, we conduct an investigation into pure character-based models in the case of translating Finnish into English, including exploring the ability to learn word senses and morphological inflections and the attention mechanism. We demonstrate that word-level information is distributed over the entire character sequence rather than over a single character, and characters at different positions play different roles in learning linguistic knowledge. In addition, character-based models need more layers to encode word senses which explains why only deeper models outperform subword-based models. The attention distribution pattern shows that separators attract a lot of attention and we explore a sparse word-level attention to enforce character hidden states to capture the full word-level information. Experimental results show that the word-level attention with a single head results in 1.2 BLEU points drop."
"A prerequisite relation pedagogical relation indicates order concepts presented learners. The relation used guide presentation sequence topics subjects design academic programs, lectures, curricula instructional materials. %such textbooks study guides. In work, present systems automatically detect prerequisite relations Italian language context PRELEARN shared task EVALITA 2020 . %. The evaluation submissions considers: in-domain cross-domain scenarios defined either inclusion exclusion target domain training set. The four domains 'data mining' , 'geometry' , 'precalculus' , 'physics' . type resources used train model -- raw text VS. structured information. % four domains, namely 'data mining', 'geometry', 'precalculus' 'physics'. % PRELEARN participants submit systems per-domain evaluation, considering in-domain cross-domain scenarios, % well discriminate kind resources models used, namely raw text distributional textual corpora, structured information knowledge bases. % Additionally, difference in-domain cross-domain lies inclusion exclusion target domain training set. The combination settings defined four PRELEARN subtasks. Formally, prerequisite relation exists two concepts one known beforehand order understand other. For PRELEARN task, given pair concepts, relation exists latter concept prerequisite former. Therefore, task binary classification task. We approach problem two perspectives: handcrafted features based lexical complexity pre-trained embeddings. We employed static embeddings Wikipedia Wikidata, contextual embeddings Italian-BERT model.",   English.   We present our systems and findings for the prerequisite relation learning task  at EVALITA 2020. The task aims to classify whether a pair of concepts hold a prerequisite relation or not. We model the problem using handcrafted features and embedding representations for in-domain and cross-domain scenarios.  Our submissions ranked first place in both scenarios with average F1 score of $0.887$ and $0.690$ respectively across domains on the test sets. We made our code freely available\footnote{\url{https://github.com/ajason08/EVALITA2020_PRELEARN}\label{code}}.
"Task-oriented dialog systems commonplace automated systems interact end users, including digital assistants, technical support agents, various website navigation helpers. An essential part task-oriented dialog system natural language generation , consumes data, typically fed form dialog act, converts natural language output served end user. The natural language response NLG component 1) contain essential information, 2) contextualized around user request, 3) natural sounding. Such system requires consideration content planning, correctness, grammaticality, naturalness. NLG systems employed commercial settings typically based template-based text generation techniques . In these, humans author minimal set responses templates placeholder slot values. These slots later filled runtime, dialog input. Although template-based NLG modules appealing due deterministic nature, inherent correctness, low latency, major drawbacks: First, separate templates need authored different response variations; behavior unfavorable scaling. Second, templates authored particular domain commonly reusable. Lastly, matter complexity language instilled templates, form strictly discrete set responses, therefore bound limited response naturalness. More recently, advances neural-network-based language generation prompted new direction NLG research . The process typically split two steps: serialization input data flattened meaning representation , using neural generation model generate natural language response conditioned MR. The models trained data includes MR, response pairs, therefore able generate desired responses MRs training data, also expected form coherent responses novel MRs, owing generalization ability machine learning backbone. However, deploying neural NLG systems industry setting quite challenging. First, trivial train model reliably presents input data high fidelity required user-serving dialog system. Second, models require much high-quality human-annotated data, resource intensive. Consequently, data annotation major limiting factor scaling model-based NLG across domains languages. In work, detail approach production-level neural NLG, focus scalability data efficiency. Adopting tree-structured MR framework introduced Balakrishnan et al.~\shortcite{Balakrishnan2019constrainednlg}, allows better control generated responses, train sequence-to-sequence RNN models produce high-fidelity responses. We employ multitude techniques reducing amount required data, primarily powered eliminating ``hidden'' redundancy grouping data points similar semantics buckets. We train models either reduced data, increasing size dataset using novel synthetic augmentation technique. We also employ large, pre-trained attention-based language models, fine-tuning datasets, using novel methods distill knowledge smaller sequence-to-sequence models. Further, train models data multiple domains, showing gains models trained individual domains domains semantically close together. We conclude compiled list best practices production-level NLG model development based analyses, present runbook."," Natural language generation  is a critical component  in conversational systems, owing to its role of formulating a correct and natural text response. Traditionally, NLG components have been deployed using template-based solutions. Although neural network solutions recently developed in the research community have been shown to provide several benefits, deployment of such model-based solutions has been challenging due to high latency, correctness issues, and high data needs.  In this paper, we present approaches that have helped us deploy data-efficient neural solutions for NLG in conversational systems to production.  We describe a family of sampling and modeling techniques to attain production quality with light-weight neural network models using only a fraction of the data that would be necessary otherwise, and show a thorough comparison between each. Our results show that domain complexity dictates the appropriate approach to achieve high data efficiency. Finally, we distill the lessons from our experimental findings into a list of best practices for production-level NLG model development, and present them in a brief runbook. Importantly, the end products of all of the techniques are small sequence-to-sequence models  that we can reliably deploy in production."
"Pre-training demonstrated highly effective method boosting performance many natural language processing tasks question answering, sentimental analysis, on. By training massive unlabeled text data, pre-trained models able learn contextual representations input words, extremely helpful accomplishing downstream tasks. BERT , one widely used pre-trained models, trained using two unsupervised tasks, namely, mask language modeling next sentence prediction. By adding layers top, BERT easily adapted task-specific model, fine-tuned labeled data achieve optimal performance. Such practice exercised various NLP scenarios achieved many state-of-the-art results. The study integrating BERT neural machine translation models, referred BERT-enhanced NMT, received much research interest. However, exploiting BERT NMT straightforward NLP tasks. The architecture typical NMT model consists encoder transforms source language words hidden representation, decoder predicts target language words based hidden representation. The challenge exploiting BERT NMT twofold. Firstly, NMT models mostly deep neural networks parameter size comparable even larger BERT, makes combined model hard optimize. Secondly, since existing NMT models mostly trained massive samples, usual practice fine-tuning BERT labeled corpus lead problem catastrophic forgetting . The recently proposed BERT-fused model uses attention mechanisms bridge NMT model BERT. For example, introduce extra BERT-encoder attention module fuse encoder layer BERT representation. The outputs BERT-encoder attention module self-attention module averaged. Consider case exemplified \cref{fig:compare} , likely word change interpreted money rather meanings context. However, training corpus contain similar expressions, model fail translation due ambiguity. When BERT representations introduced, contextual information learned BERT helpful translation. Concretely, BERT-encoder attention module used capture pre-trained knowledge embedded BERT representation absent self-attention module. However, find averaging outputs means regarding equally important, hurt performance circumstances. In example, BERT-encoder attention module provides useful information interpreting word change, self-attention module offers faulty noisy information. Combining outputs directly result confusion translation. Hence assert essential allow model decide information concentrate on. To end, propose use joint-attention module integrate multiple representations contain different contextual information. As shown \cref{fig:compare} , learnable weights joint-attention module allow assign attention BERT representation case. Compared BERT-fused model, method better augmenting desired information hence boosts performance. Although existing BERT-enhanced NMT models mostly focus leveraging BERT's last-layer representation, find intermediate layers contain semantic contextual information absent last layer might help improve translation performance. The dynamic fusion mechanism proposed \citet{Weng20} allows Transformer encoder leverage BERT's intermediate representations. However, method work decoder inference stage requires ground truth input. This motivates us explore feasible techniques generating composite BERT representations used encoder decoder. In paper, introduce BERT-enhanced NMT model called BERT-JAM, stands BERT-fused Joint-Attention Model. BERT-JAM equipped joint-attention modules allow encoder/decoder selectively concentrate BERT representation encoder/decoder representation attending simultaneously. Besides, seek improve upon existing BERT-enhanced models making better use BERT's intermediate layers. Specifically, allow encoder/decoder layer use GLU module transform BERT's intermediate representations composite representation used joint-attention module. In order achieve optimal performance, train BERT-JAM following three-phase optimization strategy progressively unfreezes different components model training. We show fine-tuning BERT crucial step unearth full potential BERT-JAM, contrast previous claim fine-tuning BERT offers gains NMT models. Moreover, study BERT-enhanced NMT performance varies size BERT feeding different BERT models BERT-JAM, ranging compact BERT 2 layers embedding dimension 128 standard BERT-base model. This study beneficial provide us guide adjust model minimal performance loss resort smaller model size due limited computation resources. We summarize contributions paper follows: The rest paper organized follows. In \cref{sec:approach}, introduce approach BERT-enhanced NMT detailed description model presented. The experimental setups described \cref{sec:setup}. In \cref{sec:results}, several experiments conducted results discussed. We give review related works \cref{sec:related} conclusions drawn \cref{sec:conclusion}."," BERT-enhanced neural machine translation  aims at leveraging BERT-encoded representations for translation tasks. A recently proposed approach uses attention mechanisms to fuse Transformer's encoder and decoder layers with BERT's last-layer representation and shows enhanced performance. However, their method doesn't allow for the flexible distribution of attention between the BERT representation and the encoder/decoder representation. In this work, we propose a novel BERT-enhanced NMT model called BERT-JAM which improves upon existing models from two aspects: 1) BERT-JAM uses joint-attention modules to allow the encoder/decoder layers to dynamically allocate attention between different representations, and 2) BERT-JAM allows the encoder/decoder layers to make use of BERT's intermediate representations by composing them using a gated linear unit . We train BERT-JAM with a novel three-phase optimization strategy that progressively unfreezes different components of BERT-JAM. Our experiments show that BERT-JAM achieves SOTA BLEU scores on multiple translation tasks."
"%Natural language abstract representation thoughts objects similar meaning community. We use raw sensory information represent images. However, possible words, direct physical interpretation. There many studies natural language processing find suitable word representations carry information language. Even finding word representations computationally demanding, advantageous since computed once. These learned representations used various downstream tasks. Word2Vec finds word embeddings predicting word given neighborhood predicting neighborhood given word . Words used together similar word embeddings due training strategy. However, embeddings contain word order information contextual information. ELMo uses bidirectional LSTM predict word given context. Since BiLSTM used creating embeddings, left-to-right right-to-left contexts implicitly encoded. Transformer shown appropriate training large datasets due self-attention mechanism. OpenAI GPT objective ELMo forward direction, except uses transformer architecture. BERT also uses transformer architecture bidirectional pre-training tasks. Training objectives affect information encoded embeddings. Each objective architecture presumes different inductive bias. In work, focused BERT uses multiple training objectives. These objectives create inhibitory effect regulatory effect other. For reason, applied hierarchical multitask learning approach BERT modifying original structure. Our motivation create embeddings encode information task balanced way. Our contributions follows: Our experimental results show Lower NSP competitive performance compared original BERT structure. We also evaluate learned embeddings probing tasks provide useful insights training strategies. Results probing task experiments show using bigram shift task pre-training useful specific tasks. The remaining part paper organized follows. In Section , mention related works. In Section , explain methods detail. In Section , report experiment results. Lastly, give conclusion Section ."," Recent works show that learning contextualized embeddings for words is beneficial for downstream tasks. BERT is one successful example of this approach. It learns embeddings by solving two tasks, which are masked language model  and the next sentence prediction . The pre-training of BERT can also be framed as a multitask learning problem. In this work, we adopt hierarchical multitask learning approaches for BERT pre-training. Pre-training tasks are solved at different layers instead of the last layer, and information from the NSP task is transferred to the masked LM task. Also, we propose a new pre-training task bigram shift to encode word order information. We choose two downstream tasks, one of which requires sentence-level embeddings , and the other requires contextualized embeddings of words . Due to computational restrictions, we use the downstream task data instead of a large dataset for the pre-training to see the performance of proposed models when given a restricted dataset. We test their performance on several probing tasks to analyze learned embeddings. Our results show that imposing a task hierarchy in pre-training improves the performance of embeddings."
"Definitions important role scientific literature define major concepts article operates. They used many automatic text analysis tasks, question answering, ontology matching construction, formal concept analysis, text summarization. Intuitively, definitions basic building blocks scientific article used help properly describe hypotheses, experiments, analyses. It often difficult determine certain definition lies text sentences around may similar style. Automatic definition extraction important field natural language processing used improve text analysis search. %Natasha: adding formal definition formal definitions Definitions play key role mathematics, creation use differ \enquote*{everyday language} definitions. A comprehensive study given series works Edwards Ward~, , , %, inspired writings Richard Robinson~ lexicographer Sidney Landau~. %They distinguish extracted definitions report usage truth value~, stipulated create usage create concepts truth value. % Nat - fixed sentence %Moreover, stipulated definition term free associations acquired non-technical use. %For example, ""Suppose student person enrolled academic institution"" stipulated definition Mathematical definitions frequently history evolve time. The definition use function, instance, may one used hundred years ago. % Nat - fixed sentence The concept connectivity two definitions, one path connectivity another set-theoretic connectivity. In mathematical texts meaning defined concept determined context declared expected variance within specific mathematical text~. % Nat - updated Mathematical definitions many features, critical optional accepted within mathematical community. % Nat - added %Van Dormolen Zaslavsky~ describe good mathematical definition containing criteria hierarchy% , existence% , equivalence, axiomatization. Desired necessary criteria definition minimality, elegance, degenerations. We give short definitions concepts; detailed explanations examples found . % end formal definition formal definitions Not every definition appearing text mathematical sense. For example, Wikipedia articles contain definitions different style. We see Wikipedia definition Kane \& Abel musical group %shown Figure similar style Wikipedia definition Abelian group. % %\end{figure} % Current methods automatic DE view binary classification task, sentence classified definition non-definition. A supervised learning process usually employed task, employing feature engineering sentence representation. The absolute majority current methods study generic definitions mathematical definitions . In paper describe supervised learning method automatic DE mathematical texts. Our method applies Convolutional Neural Network , Long Short-Term Memory network , combinations raw text data sentence syntax structure, order detect definitions. Our method evaluated three different corpora; two well-known corpora generic DE one new annotated corpus mathematical definitions, introduced paper. The main contributions paper analysis introduction new annotated dataset mathematical definitions, evaluation state-of-the-art DE approaches new mathematical dataset, introduction evaluation upgraded sentence representations adapted mathematical domain adaptation deep neural networks new sentence representations, extensive experiments multiple network input configurations performed different datasets mathematical non-mathematical domains, experiments cross-domain multi-domain learning DE task, introduction new parsed non-annotated dataset composed Wiki articles near-mathematics topics, used additional--extrinsic--evaluation scenario. These contribute showing using specifically suited training data along adapting sentence representation classification models task mathematical DE significantly improves extraction mathematical definitions surrounding text. The paper organized follows. Section contains survey up-to-date related work. Section describes sentence representations structure neural networks used approach. Section provides description datasets, evaluation results, analysis. Section contains conclusions. Finally, Appendix contains supplementary materials -- annotation instructions, description Wikipedia experiment, figures."," Automatic definition extraction from texts is an important task that has numerous applications  in several natural language processing fields such as summarization, analysis of scientific texts, automatic taxonomy generation, ontology generation, concept identification, and question answering. For definitions that are contained within a single sentence, this problem can be viewed as a binary classification of sentences into definitions and non-definitions.  In this paper, we focus on automatic detection of one-sentence definitions in mathematical texts, which are difficult to separate from surrounding text.  We experiment with several data representations, which include sentence syntactic structure and word embeddings, and apply deep learning methods such as the  Convolutional Neural Network  and the Long Short-Term Memory network , in order to identify mathematical definitions.  Our experiments demonstrate the superiority of CNN and its combination with LSTM, when applied on the syntactically-enriched input representation.  % %We use data representation that includes sentence syntactic structure; to this we apply deep learning methods such as Convolutional Neural Network  and Recurrent Neural Network , in order to identify mathematical definitions.  We also present a new dataset for definition extraction from mathematical texts. %We demonstrate that the use of this dataset for training learning models improves the quality of definition extraction when these models are then used for other definition datasets.  We demonstrate that this dataset is beneficial for training supervised models aimed at extraction of mathematical definitions.  %Marina: added new sentence from the conclusions section Our experiments with different domains demonstrate that mathematical definitions require special treatment, and that using cross-domain learning is inefficient for that task."
"As technology advances rapidly developing era, exponentially increasing text data makes analyzing understanding textual files tedious work . From readers' perspective, capturing salient information overwhelming documents labor-intensive time-consuming task. The voluminous documents urgently required processed efficiently abundance text data calls text summarization techniques. Text summarization one important tasks natural language processing automatically convert text collection texts within topic concise summary contains key semantic information. The length summaries usually significantly less original text . The research automatic text summarization attractive field natural language processing beneficial many downstream applications creating news digests, search, report generation . According number input documents, text summarization cast single document summarization multi-document summarization. Single document summarization aims form summary one document multi-document summarization aims generating short informative summary across set topic-related documents. From application perspective, single document summarization may satisfy requirement produce comprehensive summaries, make good use documents generated around clock . For content summarized, comprehensive accurate generate summary multiple documents written different times, covering different perspectives. From technical point view, multi-document summarization complicated difficult tackle single document summarization . This multi-document summarization task, diverse conflicting information among documents. The volume documents usually longer relations documents complicated. In large amount documents, documents would inevitably complement, overlapping conflicting . In addition, excessively long input documents often lead model degradation . It challenging models retain critical contents complex input sequences, generating coherent, non-redundant, non-factual error grammatically readable summaries. Therefore, multi-document summarization requires models stronger capabilities analyzing corpora, identifying merging consistent information. Furthermore, multi-document summarization task computation-hungry, due increasing sizes current datasets language model parameters. Multi-document summarization task enjoys wide range real world applications, including summarization news , scientific publications , emails , product reviews , lecture feedback , Wikipedia articles generation , medical documents software project activities . Recently, multi-document summarization technology also received great amount attention industry. An intelligent multilingual news reporter bot named Xiaomingbot developed news generation. This bot able summarize multiple news one article translate multiple languages. Massive application requirements rapidly growing online data promote development multi-document summarization. However, majority existing methods still generate summaries manually crafted features , sentence position features , sentence length features , proper noun features , cue-phrase features , biased word features, sentence-to-sentence cohesion, sentence-to-centroid cohesion. The existing works using traditional algorithms divide following categories: term frequency-inverse document frequency based methods , clustering based methods \cite {goldstein2000multi, wan2008multi}, graph based methods latent semantic analysis based methods . Deep learning gained enormous attention recent years due success various domains, instance, computer vision , natural language processing multi-modal . Both industry academia race utilize deep learning solve complex tasks due capability capturing highly nonlinear relations data. Recently, deep learning based models applied multi-document summarization , prospers development text summarization enables models achieve better performance. Comparing conventional approaches, deep learning based models reduce dependence manual feature extraction drastically. This task attracts increasing attention natural language processing community enjoys steady expansion ever since. The number research publications deep learning based multi-document summarization increasing rapidly last five years -- statistics show number publications 225\% increase 2017 2019. It provides strong evidence inevitable pervasiveness deep learning multi-document summarization research. The prosperity deep learning summarization academia industry requires comprehensive review current publications researchers better understand process research progress. However, existing summarization review articles based traditional algorithms instead deep learning based methods . Therefore, conduct survey embrace knowledge multi-document summarization. To best knowledge, first comprehensive survey direction deep learning multi-document summarization. This survey designed way classifies neural based multi-document summarization techniques diverse categories thoroughly systematically. We also conduct detailed discussion categorization progress approaches establish clearer concept standing shoes readers. We hope survey provides panorama researchers, practitioners educators quickly understand step field deep learning based multi-document summarization. The key contributions survey three-folds: Paper Selection. In article, select, summarize, discuss, analyze 30 representative works. We used Google Scholar main search engine discover related works. The high-quality papers selected top NLP AI journals conferences, include ACL\footnote{Annual Meeting Association Computational Linguistics.}, EMNLP\footnote{Empirical Methods Natural Language Processing.}, COLING\footnote{International Conference Computational Linguistics}, NAACL\footnote{Annual Conference North American Chapter Association Computational Linguistics.}, AAAI\footnote{AAAI Conference Artificial Intelligence.}, ICML\footnote{International Conference Machine Learning.}, ICLR\footnote{International Conference Learning Representations} IJCAI\footnote{International Joint Conference Artificial Intelligence.}. The major keywords used include multi-documentation summarization, summarization, extractive summarization, abstractive summarization, deep learning neural networks. Organization Survey. In following sections, survey cover various aspects recent advanced deep learning based works multi-document summarization. Section gives overview multi-document summarization. Section highlights network design strategies offers comprehensive review deep learning based multi-document summarization techniques. This survey also summarizes objective functions literature , evaluation metrics , available multi-document datasets . Finally, section discusses future research directions deep learning based multi-document summarization followed conclusion Section .","  Multi-document summarization  is an effective tool for information aggregation which generates an informative and concise summary from a cluster of topic-related documents. Our survey structurally overviews the recent deep learning based multi-document summarization models via a proposed taxonomy and it is the first of its kind. Particularly, we propose a novel mechanism to summarize the design strategies of neural networks and conduct a comprehensive summary of the state-of-the-art. We highlight the differences among various objective functions which are rarely discussed in the existing literature. Finally, we propose several future directions pertaining to this new and exciting development of the field."
"Computer-assisted cross-lingual conversation automatic speech-to-speech translation one challenging problems spoken language technologies decades . Recent remarkable advances speech language processing led deep learning techniques benefit challenge real-time accurate speech translation. %\memo{} gogole multi-task model One crucial problem automatic speech-to-speech translation delay. Spoken language processing tasks usually handled utterance sentence level. Their application speech-to-speech translation suffers long delay proportional input length, process starts observation end utterance. That similar consecutive interpretation useful long monologues lecture talks. On hand, situations, simultaneous interpretation often used audience proficient language talk. Simultaneous interpretation challenging task listen talk speak interpretation different language. In work, tackle problem automatic simultaneous speech-to-speech translation develop neural system English Japanese. Here, call task simultaneous translation, simultaneous interpretation. We think task simultaneous interpretation includes additional efforts summarization make output concise small latency better understanding audience. The problem requires real-time incremental processing output generated simultaneously input. Previous attempts incremental neural speech translation focused speech-to-text translation . Our work aims speech-to-speech translation natural information delivery speech without need visual attention text-based subtitles. Our system based cascade three processing modules: incremental speech recognition , incremental machine translation , text-to-speech synthesis , rather recent end-to-end approaches %\memo{} due difficulty applying simultaneous translation. We follow existing studies incremental neural speech processing. For ASR, choose approach using teacher-student training framework train incremental student model help non-incremental teacher model . For MT, choose approach called wait-k, delays start decoding process simply k steps . For TTS, choose approach starting segmental speech synthesis observing next accent phrase . These modules exchange input/output symbols forms subwords work symbol-synchronous way, cascaded even different waiting strategies. We also conduct system-level evaluation system system-level latency module-level performance English-to-Japanese simultaneous translation TED Talks. The system-level latency measures are: processing delays waiting computation time, TTS speaking latency derived overlaps synthesized speech outputs. The module-level performance measured standard metrics ASR, MT, TTS. This work first attempt system-level evaluation simultaneous speech-to-speech translation system would beneficial future studies. %The remainder paper organized follows. %In section , review problem simultaneous speech-to-speech translation, mainly difficulty. %In section , describe details incremental processing modules ASR, MT, TTS. %In section , present system-wise evaluation system, followed discussions section . %We conclude paper section ."," This paper presents a newly developed, simultaneous neural speech-to-speech translation system and its evaluation. The system consists of three fully-incremental neural processing modules for automatic speech recognition , machine translation , and text-to-speech synthesis . We investigated its overall latency in the system's Ear-Voice Span and speaking latency along with module-level performance."
"The emergence online collaboration platforms dramatically changed dynamics human teamwork, creating veritable army virtual teams, composed workers different physical locations. Software engineering requires tremendous amount collaborative problem solving, making excellent domain team cognition researchers seek understand manifestation cognition applied team tasks. Mining data social coding platforms GitHub yield insights thought processes virtual teams. Previous work issue comments focused emotional aspects team communication, sentiment politeness. Our aim map issue comments states team cognition information gathering, knowledge building problem solving. To employ dialogue act classification, order identify intent speaker. Dialogue act classification broad range natural language processing applications, including machine translation, dialogue systems speech recognition. Semantic-based classification human utterances challenging task, lack large annotated corpus represents class variations makes job even harder. Compared examples human utterances available standard datasets like Switchboard corpus CSI Meeting Recorder Dialogue Act corpus, GitHub utterances complex. The primary purpose study DA classification GitHub issue comments harnessing strength transfer learning, using word sentence level embedding models fine-tuned dataset. For word-level transfer learning, used GLoVe vectors, Universal Sentence Encoders BERT models used sentence-level transfer. This paper presents comparison performance various architectures GitHub dialogues limited resource scenario. A second contribution publicly available dataset annotated issue comments. The dataset available \url{https://drive.google.com/drive/folders/1kLZvzfE80VeEYA1tqua_aj6nSiT57f83?usp=sharing}. In field computational collective intelligence, people collaborate work teams achieve goals, dialogue act classification play vital role understanding human teamwork."," Social coding platforms, such as GitHub, serve as  laboratories for studying collaborative problem solving in open source software development; a key feature is their ability to support issue reporting which is used by teams to discuss tasks and ideas.  Analyzing the dialogue between team members, as expressed in issue comments, can yield important insights about the performance of virtual teams.  This paper presents a transfer learning approach for performing dialogue act classification on issue comments.  Since no large labeled corpus of GitHub issue comments exists, employing transfer learning enables us to leverage standard dialogue act datasets in combination with our own GitHub comment dataset. We compare the performance of several word and sentence level encoding models including Global Vectors for Word Representations , Universal Sentence Encoder , and Bidirectional Encoder Representations from Transformers . Being able to map the issue comments to dialogue acts is a useful stepping stone towards understanding cognitive team processes."
"Large, densely-labeled datasets critical requirement creation effective supervised learning models. The pressing need high quantities labeled data led many researchers collect data social media platforms online forums . Due presence noise lack structure exist data sources, manual quality analysis necessary extract structured labels, filter irrelevant examples, standardize language, perform preprocessing tasks data used. However, obtaining dataset annotations manner time-consuming expensive process often prone errors. In work, develop automated data cleaning verification mechanisms extracting high-quality data social media platforms\footnote{All code available \url{https://github.com/rachel-1/qa_plausibility}.}. We specifically focus creation question-answer datasets, data instance consists question topic corresponding answer. In order filter noise improve data quality, propose task question-answer plausibility, includes following three steps: Because assume social media users generally answer questions good faith , assume plausible answers correct ones . Necessarily, property satisfied, adequate solutions would require domain knowledge interest. Therefore, look apply approach toward data property. In study, demonstrate application QA plausibility context visual question answering , well-studied problem field computer vision . We assemble large VQA dataset images collected image-sharing social network, machine-generated questions related content image, responses social media users. We train multitask BERT-based model evaluate ability model perform three subtasks associated QA plausibility. The methods presented work hold potential reducing need manual quality analysis crowdsourced data well enabling use question-answer data unstructured environments social media platforms."," Datasets extracted from social networks and online forums are often prone to the pitfalls of natural language, namely the presence of unstructured and noisy data. In this work, we seek to enable the collection of high-quality question-answer datasets from social media by proposing a novel task for automated quality analysis and data cleaning: question-answer  plausibility. Given a machine or user-generated question and a crowd-sourced response from a social media user, we determine if the question and response are valid; if so, we identify the answer within the free-form response.   We design BERT-based models to perform the QA plausibility task, and we evaluate the ability of our models to generate a clean, usable question-answer dataset. Our highest-performing approach consists of a single-task model which determines the plausibility of the question, followed by a multi-task model which evaluates the plausibility of the response as well as extracts answers ."
"In recent times, pre-trained neural language models become preferred approach language representation learning, pushing state-of-the-art multiple NLP tasks~. These approaches rely two-step training process: first, self-supervised pre-training performed large-scale corpora; then, model undergoes supervised fine-tuning downstream task labels using task-specific prediction heads. While method found effective scenarios relatively large amount labeled data present, researchers highlighted case low-resource settings~. Recently, pattern-exploiting training~(PET, \citet{Schick2020ExploitingCQ,Schick2020ItsNJ} tackles dependence NLMs labeled data first reformulating tasks cloze questions using task-related patterns keywords, using language models trained annotate large sets unlabeled examples soft labels. PET thought offline version knowledge distillation~, well-established approach transfer knowledge across models different size, even different versions model self-training . While effective classification tasks easily reformulated cloze questions, PET cannot easily extended regression settings since cannot adequately verbalized. Contemporary work \citet{du-etal-2020-selftraining} showed self-training pre-training provide complementary information natural language understanding tasks. In paper, I propose simple self-supervised data augmentation approach used improve generalization capabilities NLMs regression classification tasks modest-sized labeled corpora. In short, ensemble fine-tuned models used annotate large corpus unlabeled text, new annotations leveraged multi-task setting obtain final predictions original test set. The method tested AcCompl-it shared tasks EVALITA 2020 campaign~, objective predict respectively complexity acceptability scores 1-7 Likert scale test sentence, alongside estimation standard error. Results show considerable improvements regular fine-tuning performances COMPL ACCEPT using UmBERTo pre-trained model~, suggesting validity approach complexity/acceptability prediction possibly language processing tasks.","   English.  This work describes a self-supervised data augmentation approach used to improve learning models' performances when only a moderate amount of labeled data is available. Multiple copies of the original model are initially trained on the downstream task. Their predictions are then used to annotate a large set of unlabeled examples. Finally, multi-task training is performed on the parallel annotations of the resulting training set, and final scores are obtained by averaging annotator-specific head predictions. Neural language models are fine-tuned using this procedure in the context of the AcCompl-it shared task at EVALITA 2020, obtaining considerable improvements in prediction quality."
"Underresourced languages, natural language processing perspective, lacking resources needed support state-of-the-art performance NLP problems like machine translation, automated speech recognition, named entity recognition. Yet vast majority world's languages---representing billions native speakers worldwide---are underresourced. And lack available training data languages usually reflects broader paucity electronic information resources accessible speakers. %The prominent languages millions native speakers, previously deprived access information web native language, due missing translation tools. For instance, six million Wikipedia articles English fewer sixty thousand Swahili fewer seven hundred Bambara, vehicular widely-spoken native language Mali subject paper. Consequently, 53\% worlds population access ``encyclopedic knowledge'' primary language, according 2014 study Facebook. MT technologies could help bridge gap, enormous interest applications, ironically enough, speakers languages MT thus far least success. There also great potential humanitarian response applications . Fueled data, advances hardware technology, deep neural models, machine translation advanced rapidly last ten years. %Yet underresourced languages yet benefit advances, lack large volumes translated texts needed drive neural machine learning. %Although neural models generally considered work best domains large amounts training data exist Researchers beginning investigate effectiveness low-resource languages, recent WMT 2019 WMT 2020 tasks , underresourced African languages. %What done? Which challenges identified, solutions found? Most prominently, Masakhane community, grassroots initiative, developed open-source NMT models 30 African languages base JW300 corpus~, parallel corpus religious texts. Since African languages cover wide spectrum linguistic phenomena language families , individual development translations resources selected languages language families vital drive overall progress. Just within last year, number dedicated studies significantly improved state African NMT: \citet{biljon2020} analyzed depth Transformers specifically low-resource translation South-African languages, based prior studies \citet{DBLP:journals/corr/abs-1906-05685} Autshumato corpus~. \citet{dossou2020ffr} developed MT model compiled resources translations Fon French, \citet{akinfaderin-2020-hausamt} modeled translations English Hausa, \citet{orife2020neural} four languages Edoid language family, \citet{ahia2020supervised} investigated supervised vs. unsupervised NMT Nigerian Pidgin. %Superficially, might seem like development simply grows pool ``standard MT'' evaluation tasks data sets, data sets smaller others. In paper, present first parallel data set machine translation Bambara English French first benchmark results machine translation Bambara. We discuss challenges working low-resource languages propose strategies cope data scarcity low-resource MT. We discuss socio-cultural context Bambara translation implications model data development. Finally, analyze best-performing neural models small-scale human evaluation study give recommendations future development. %These contributions deeper understanding shortcomings state-of-the-art methods high-resource languages, We find translation quality in-domain data set acceptable, gives hope languages previously fallen radar MT development. % [Can model data made publicly available?] We released models data upon publication. Our evaluation setup may serve benchmark extremely challenging translation task. %"," %Low-resource languages present unique challenges to machine translation.  %We discuss the case of Bambara, a Mande language where training data is scarce and requires significant amounts of pre-processing. Moreover, the socio-cultural context within which Bambara speakers live poses challenges for automated processing. We contribute the first parallel data set for machine translation of Bambara into and from English and French and the first benchmark results on machine translation to and from Bambara.  %New abstract?:  Low-resource languages present unique challenges to  machine translation. We discuss the case of Bambara, a Mande language for which training data is scarce and requires significant amounts of pre-processing. More than the linguistic situation of Bambara itself, the socio-cultural context within which Bambara speakers live poses challenges for automated processing of this language. In this paper, we present the first parallel data set for machine translation of Bambara into and from English and French and the first benchmark results on machine translation to and from Bambara. We discuss challenges in working with low-resource languages and propose strategies to cope with data scarcity in low-resource machine translation ."
"Language modelling task transforming individual words vector representations based context appear in. Hence, distant term dependencies inherited issue within task. Language models always seek smart approaches towards incorporating context longer distances allows better representations compared limited context counterparts. Intuitively, imagine attempting start reading novel series second book onward, information first. The amount information previously missed something cannot acquired. However, case language models. While understanding words present due contextual information word's occurrence, entity information distant text lost transferred. Until recently, Recurrent Neural Networks , specifically Long Short-Term Memory networks, core state-of-the-art approaches . Thanks Transformers architecture , use attention mechanisms, models XLNet , GPT BERT account even longer sequences. However, computational limitations multi-head attention architecture make hard increase contextual information models . As result, research focused introducing variations transformer architecture, focus multi-head attention mechanism, order alleviate part computational cost increase contextual information available models. In paper present novel approach, makes use coreference information training language model via Entity-Transformer architecture, extends original Transformer block Transformer-Based language models. To end, incorporate important entity information would otherwise unreachable model. As result, effectively boost representations entity mentions, entity information present, without hindering performance language model entities present. In experiments, extend GPT2 architecture formulate model, named GPT2E train CoNLL-2012 dataset using annotated coreference information. We evaluate model's performance terms Perplexity ConLL 2012 LAMBADA datasets showcase effects training word representations well downstream task Named Entity Recognition using CoNLL 2012 dataset. To end, compare GPT2E's performance base model trained data, highlight effects coreference information paird Entity-Transformer architecture.","     In the last decade, the field of Neural Language Modelling has witnessed enormous changes, with the development of novel models through the use of Transformer architectures. However, even these models struggle to model long sequences due to memory constraints and increasing computational complexity. Coreference annotations over the training data can provide context far beyond the modelling limitations of such language models. In this paper we present an extension over the Transformer-block architecture used in neural language models, specifically in GPT2, in order to incorporate entity annotations during training. Our model, GPT2E, extends the Transformer layers architecture of GPT2 to Entity-Transformers, an architecture designed to handle coreference information when present. To that end, we achieve richer representations for entity mentions, with insignificant training cost. We show the comparative model performance between GPT2 and GPT2E in terms of Perplexity on the CoNLL 2012 and LAMBADA datasets as well as the key differences in the entity representations and their effects in downstream tasks such as Named Entity Recognition. Furthermore, our approach can be adopted by the majority of Transformer-based language models."
". } To foster research dialog policy learning virtual digital assistants, several task-oriented dialog corpora introduced recent years, SimDial, MultiWoZ, Taskmaster, Schema Guided Dialog, name few. Deep learning approaches, including mixture models hierarchical encoder/decoder, reinforcement learning, pre-trained language models, significantly advanced dialog policy research past years, setting new state-of-the-art performance limits. %More recently, SimpleTOD SOLOIST shown pre-training dialog policy using large language models, e.g., GPT-2, lead significantly better performance task-oriented neural dialog policy learning using even larger neural models. %\ab{somewhere want mention data collection expensive -- time; resources} However, collecting annotated data supervised dialog policy learning expensive time-consuming process. Hence, desirable explore approaches train dialog policy limited data transfer existing policy even additional training data new domains. This practical requirement motivated community research resource-constrained dialog policy learning past decades. Researchers explored approaches including employing grammar constraints dialog policy, transfer learning , pre-trained language models. Few-shot domain adaptation researched since 2000s end-to-end dialog systems well dialog policy learning. % We investigate one-shot policy learning zero-shot domain transfer using \ab{I think 50 examples original training reasonable. Emphasizing ONE training sample available may reasonable. The reviewer may come back say 1? Why 5? Why 10? So showing methods need thousands samples match performance DILP would convincing argument IMHO.} \ab{We believe single dialog going representative ALL conversational flows may occur complicated real-life dataset . Increasing number training samples beyond one may help improving policy MultiWoZ, necessarily terms inform success terms action F1 .} \ab{Finally, zero-shot transfer extremely desirable property. One argue want re-train want method work new domain box. Having said that, argument would even stronger could also show baseline methods need X shot transfer match performance zero-shot DILP new domain.} differential inductive logic programming . % Given encoding common known knowledge set examples represented logical set facts, inductive logic programming system hypothesised conforms positive none negative examples. % ILP extensively studied context symbolic AI past decades, also adapted dialog management. While ILP generalizes well noiseless/consistent set rules, known prone noisy samples , hence would applicable real-world problem scenarios, particularly noisy dialog policy data. DILP addresses noisy/inconsistent training data via novel probabilistic treatment learned rules relaxing different probabilities true/false solving relaxed problem using recent advances gradient-based optimization. \edit {In traditional modular dialog system, dialog policy aims decide dialog action given dialog state, assuming tasks language understanding generation handled components. Under assumptions, task-oriented dialog policy mostly follow slot-filling scheme, described set probabilistic rules. Therefore, hypothesize dialog policy limited sense constructed learning underlying rules. To end, draw upon recent advances developing differentiable inductive logical programs use neural architectures learn almost rule-based policies.} We present \name, adaptation DILP dialog policy learning. Briefly, \name discerns set logical rules examples using inductive reasoning.\footnote{Inductive reasoning tries summarize general principles special cases. For example, fact ``cars A, B, C drive right side road'' induces ``all cars drive right side road.''} We introduce \name Section. We apply \name SimDial Dataset , MultiWoZ Dataset , showing task one-shot dialog policy learning zero-shot domain transfer, \name outperforms several neural baselines. Finally, Section concludes paper.","   Motivated by the needs of resource constrained dialog policy learning,   we introduce dialog policy via differentiable inductive logic . We explore the tasks of one-shot learning and zero-shot domain transfer with \name on SimDial and MultiWoZ. Using a single representative dialog from the restaurant domain, we train \name on the SimDial dataset and obtain 99+\% in-domain test accuracy. We also show that the trained DILOG zero-shot transfers to all other domains with 99+\% accuracy, proving the suitability of \name to slot-filling dialogs. We further extend our study to the MultiWoZ dataset achieving 90+\% inform and success metrics. We also observe that these metrics are not capturing some of the shortcomings of DILOG in terms of false positives, prompting us to measure an auxiliary Action F1 score. We show that \name is 100x more data efficient than state-of-the-art neural approaches on MultiWoZ while achieving similar performance metrics. We conclude with a discussion on the strengths and weaknesses of \name."
"Sequence labeling task labeling token sequence. It important task natural language processing lot applications Part-of-Speech Tagging , Named Entity Recognition , Chunking . The neural CRF model one widely-used approaches sequence labeling achieve superior performance many tasks . It often employs encoder BiLSTM compute contextual vector representation word input sequence. The potential function position input sequence neural CRF typically decomposed emission function transition function . %The transition function computed previous current labels. In paper, design series increasingly expressive potential functions neural CRF models. First, compute transition function label embeddings instead label identities. Second, use single potential function current word previous current labels, instead decomposing emission transition functions, leading expressiveness. We also employ tensor decomposition order keep potential function tractable. Thirdly, take representations additional neighboring words input potential function, instead solely relying BiLSTM capture contextual information. To empirically evaluate different approaches, conduct experiments four well-known sequence labeling tasks: NER, Chunking, coarse- fine-grained POS tagging. We find beneficial potential function take representations neighboring words input, quadrilinear potential function decomposed tensor parameter leads best overall performance. Our work related \citet{reimers-gurevych-2017-reporting,yang-etal-2018-design}, also compared different network architectures configurations conducted empirical analysis different sequence labeling tasks. However, focus potential function design neural CRF models, sufficiently studied before."," The neural linear-chain CRF model is one of the most widely-used approach to sequence labeling. In this paper, we investigate a series of increasingly expressive potential functions for neural CRF models, which not only integrate the emission and transition functions, but also explicitly take the representations of the contextual words as input. Our extensive experiments show that the decomposed quadrilinear potential function based on the vector representations of two neighboring labels and two neighboring words consistently achieves the best performance."
"Sequence labeling tasks essential web mining, named entity recognition , event extraction, relation identification. For example, NER models assign predefined labels tag tokens input sequences indicate entity boundaries types. In web services, question answering, sequence labeling also plays critical role, reads passage Web page context answers given question extracting text span inside given passage. This process often called machine reading comprehension . MRC also regarded sequence labeling task, since predicts whether token start, end, none answer span. There rich literature sequence labeling. Classical methods include Hidden Markov models , maximum entropy Markov models , conditional random field . Recently, combining neural networks representation layer CRF models boosted state-of-the-art performance. However, statistical models require large amounts training data. Consequently, show good performance languages rich training data, English. Sequence labeling low-resource languages still challenging, mainly due limited training data available. To tackle challenge sequence labeling low-resource languages, early works transfer knowledge rich-source languages low-resource ones information alignment manually built bilingual parallel corpora, language-independent features. In recent years, multilingual pre-trained language models, Unicoder, mBERT, XLM-Roberta , developed model transferring. For example, Wu et al. fine-tune mBERT pseudo training set meta-learning method. To better leverage unlabeled data target language, teacher-student framework proposed distill knowledge weighted teacher models. Inspired back translation neural machine translation , DualBERT developed learn source language target language features simultaneously. Although multilingual sequence labeling models effectively locate target spans, often fail give precise boundaries spans target languages. %when predicting text spans target languages. %that is, pairs sentences similar meanings different languages, %\jp{What conclusion draw paragraph?} %The previous multilingual sequence labeling models roughly identify correct target spans, often fail give precise boundaries predicting text spans target languages. We conduct empirical study quantitatively assess challenge. In Figure , categorize mismatches predicted span ground truth span four types: predicted answer super span ground truth; predicted answer sub span ground truth; predicted answer miss terms ground truth add extra terms ground truth , predicted answer adjacent ground truth contains common sub-span . We show Table statistics error cases cross-lingual NER task using XLM-R model, boundary errors, including super span, sub span, drifted span, adjacent span, contribute large portion error cases shown last column. The errors cases mainly entity type detection errors. This observation motivates us tackle bottleneck boundary detection sequence labeling models. % \end{center} \end{table} Accurately detecting answer boundaries becomes bottleneck sequence labeling. To tackle challenge, paper, propose separate model boundary calibration based output base model. Intuitively, base model captures global context whole input sequence roughly locates region answers. Then, calibration model conducts finer search within detected region neighborhood, focuses local context refine boundary. This analogous human perception cognition process, first locates target, sets local context, finally zooms details. Our design novel sequence labeling, orthogonal complements existing approaches. Using second model focus detecting answer boundaries accurately intuitive nice idea. However, construct high-quality training data calibration model remains challenging. One straightforward method transform original training data sequence labeling task new training set calibration model. However, data collected way still quite limited, especially low-resource languages. To address challenge, strategically propose novel phrase boundary recovery task pre-train model large-scale augmented datasets synthesized Wikipedia documents multiple languages. The new pre-training approach dramatically improves capability calibration module determine answer boundaries accurately. % Besides design employing two models, equip calibration model pre-training process emphasizing capability recovering meaningful phrases noisy input. Our approach shown Figure. CalibreNet consists two modules, base module calibration module. The base module take model sequence labeling. The predicted answers base module combined input sequence form input calibration module. The calibration module considers initial results base module whole passage refine span boundaries. In particular, calibration module pre-trained PBR task large-scale multilingual synthesized data Wikipedia-derived corpus. We make following technical contributions paper. First, propose CalibreNet framework task cross-lingual sequence labeling improve accuracy labeled answers. Second, propose novel phrase boundary recovery task weakly supervised pre-training method using Wikipedia data. This approach effectively enhances model sensitivity phrase boundaries. Last least, conduct extensive experiments zero-shot cross-lingual NER improve SOTA results. In addition, experiments MRC tasks also show consistent improvement strong baseline methods. The rest paper organized follows. We first review related work Section. We present approach Section. We report extensive experimental results Sections. We conduct analysis Section, conclude paper Section.","  \footnotetext[1]{Work done during the first author's internship at Microsoft STCA.} \footnotetext[2]{Daxin Jiang and Wanli Zuo are the corresponding authors.} % \footnotetext[3]{Jian Pei's research is supported in part by the NSERC Discovery Grant program. All opinions, findings, conclusions and recommendations in this paper are those of the authors and do not necessarily reflect the views of the funding agencies.}   Lack of training data in low-resource languages presents huge challenges to sequence labeling tasks such as named entity recognition  and machine reading comprehension . One major obstacle is the errors on the boundary of predicted answers. To tackle this problem, we propose CalibreNet, which predicts answers in two steps. In the first step, any existing sequence labeling method can be adopted as a base model to generate an initial answer. In the second step, CalibreNet refines the boundary of the initial answer. To tackle the challenge of lack of training data in low-resource languages, we dedicatedly develop a novel unsupervised phrase boundary recovery pre-training task to enhance the multilingual boundary detection capability of CalibreNet. Experiments on two cross-lingual benchmark datasets show that the proposed approach achieves SOTA results on zero-shot cross-lingual NER and MRC tasks."
"The Text-to-SQL task aims translate natural language texts SQL queries. Users understand SQL grammars benefit task acquire information databases inputting natural language texts. Previous works focus context-independent text-to-SQL generation. However, practice, users usually interact systems several turns acquire information, extends text-to-SQL task context-dependent text-to-SQL task conversational scenario. Throughout interaction, user inputs may omit information appeared before. This phenomenon brings difficulty context-dependent text-to-SQL task. Recently, context-dependent text-to-SQL task attracted attention. \citet{suhr2018learning} conduct experiments ATIS dataset . Besides, two cross-domain context-dependent datasets SParC CoSQL released. Cross-domain means databases test set differ training set, challenging. EditSQL previous state-of-the-art model SParC CoSQL datasets focuses taking advantages previous utterance texts previously predicted query predict query current turn. Table shows user inputs, ground truth queries predicted queries EditSQL interaction. In second turn, EditSQL views ``Kacey"" name dog owner. However, since context interaction dogs, ``Kacey"" name dog. This example shows model using historical information user inputs may fail keep context consistency maintain thematic relations. According , maintain thematic relations, users may change constraints, ask different attributes topic ask next questions. Thus, database schema items current turn relation items previous turn. For example, Table , second question adds constraint name asks age dog instead numbers dogs. The corresponding database schema items Dogs.age Dogs.name belong table Dogs.* previous query . Therefore, propose take historical information database schema items consideration. % % % %\end{table} In particular, first construct graph based corresponding database, graph nodes database schema items graph edges primary-foreign keys column affiliation. Short distance graph nodes appearing previous query current query reveal context consistency since usually edge different attributes topic. We propose database schema interaction graph encoder model database schema items together historical items. Empirical results two large cross-domain context-dependent text-to-SQL datasets - SParC CoSQL show schema interaction graph encoder contributes modeling context consistency proposed model database schema interaction graph encoder substantially outperforms state-of-the-art model. \end{table} Our main contributions summarized follows:"," Context-dependent text-to-SQL task has drawn much attention in recent years. Previous models on context-dependent text-to-SQL task only concentrate on utilizing historical user inputs. In this work, in addition to using encoders to capture historical information of user inputs, we propose a database schema interaction graph encoder to utilize historicalal information of database schema items. In decoding phase, we introduce a gate mechanism to weigh the importance of different vocabularies and then make the prediction of SQL tokens. We evaluate our model on the benchmark SParC and CoSQL datasets, which are two large complex context-dependent cross-domain text-to-SQL datasets. Our model outperforms previous state-of-the-art model by a large margin and achieves new state-of-the-art results on the two datasets. The comparison and ablation results demonstrate the efficacy of our model and the usefulness of the database schema interaction graph encoder."
"The recent survey conducted WHO shows total million people world living depression. % This increased 18.4\% . At severe, depression lead suicide responsible deaths every year . Early detection appropriate treatment encourage remission prevent relapse . However, stigma coupled depression makes patients reluctant seek support provide truthful answers physicians . Additionally, clinical diagnosis dependent self-reports patient閳ユ獨 behavior, requires reflect recall past, may obscured time. In contrast, social media offers unique platform people share experiences moment, express emotions stress raw intensity, seek social emotional support resilience. As such, depression studies based social media offer unique advantages scheduled surveys interviews . Social media self-narratives contain large amounts implicit reliable information expressed real-time, essential practitioners glean understand user閳ユ獨 behavior outside controlled clinical environment. % \indent Several studies literature explored various linguistic visual cues effectively detect user depression postings social media platform like Twitter Reddit . Majority existing studies formulated social media depression detection task binary classification problem therefore limited identifying depressive users. \\ \indent To assist healthcare professionals intervene timely manner automatic triaging, necessary develop intelligent decision support system provides HPs fine-grained depression related symptoms. The triage process critical step giving care patients because, prioritizing patients different triage levels based severity clinical condition, one enhance utilization healthcare facilities efficacy healthcare interventions. There efforts create datasets capturing depression severity, however limited clinical interviews questionnaires , individuals voluntarily participate study . \\ \indent In work, exploit Twitter data identify indications depression. We developed high quality dataset consisting total tweets, tweets posted self-reported depressed users weeks time, manually annotated using questionnaire based symptoms categories. In Table-, provide sample tweets associated nine item depression symptoms. % The self-reported questionnaire, based Diagnostic Statistical Manual Mental Disorders, Fourth Edition guidelines, screening, diagnosing, measuring severity depression. % The overall scores range , score linked major depressive disorders. Our research hypothesis depressed individuals discuss symptoms Twitter tracked reliably. } \end{table*} % Advancement Natural Language Processing one promising avenues discovering vital mental health information user-generated data. Nonetheless, user social-media post offer unique challenges discussed below: To account creative linguistic device widely observed utterances depressive users, propose Figurative Language enabled Multi-Task Learning framework works concept task sharing mechanism . In work, improve performance robustness primary task `symptom identification' combined supervisory task `figurative usage detection' multi-task learning setting. We introduce mechanism named `co-task aware attention' enables layer-specific soft sharing parameters tasks interest. The proposed attention mechanism parameterized task-specific scaling factor BERT layers. BERT enables even low-resource tasks benefit deep bi-directional architectures unsupervised training framework obtain context-aware encoded representation. The virtue model ability learn task-specific representation input tweet coordinating among layers tasks. \\ Contributions: %%%%%%%%%%%%%%%%%%%%% % % According Word Health Organization \footnote{http://www.who.int/news-room/fact-sheets/detail/mental-disorders}, ``depressive disorder characterized sadness, loss interest pleasure, feelings guilt low self worth, disturbed sleep appetite, feelings tiredness, poor concentration"". % Major depressive disorder world-wide impact society year causing almost one million deaths. % The recent survey conducted WHO shows total million people world living depression. This increased 18.4\% . At severe depression lead suicide responsible deaths every year . Early detection appropriate treatment encourage remission prevent relapse . However, stigma coupled depression makes patients reluctant seek support. Also, associated cognitive biases, inhibits patients provide truthful answer physicians add limitation .\\ % \indent Additionally, clinical diagnosis dependent hypothetical self-reports patients behaviour, requiring patients reflect thinking sometime past, may become obscured time. In contrast, social media offers unique platform people share experiences, exhaust emotion stress, seek social emotional support. As such, depression studies based social media offers several advantage . These self-narrative contains large amount implicit information, highly essential practitioner understand users behaviour outside controlled clinical environment real-time.\\ % \indent Several studies literature explored various linguistic visual cues effectively detect depression social media platform like Twitter Reddit. Majority existing studies formulated social media depression detection task binary classification problem therefore limited identify depressive users. \\ % \indent However, assist healthcare professional making timely intervention, required develop intelligent decision support system could provide HPs fine-grained depression related symptoms automatic triaging techniques. The triage process first critical step giving care patients prioritizing patients different triage levels based severity clinical conditions could potential enhance efficacy healthcare interventions. In literature, efforts create dataset capturing depression severity, however limited clinical interview questionnaire , individuals voluntary participated study. \\ % \indent In work, exploit Twitter data identify indications depression finally assign based severity labels: `None', `Mild', `Moderate', `Moderately Severe', `Severe' triaging. We developed new dataset consisting tweets posted self-reported depressed users weeks time, manually annotated symptom categories. In Table-, provide samples tweets associated nine item depression symptoms. % The self-report questionnaire based Diagnostic Statistical Manual Mental Disorders, Fourth Edition guidelines screening, diagnosing, measuring severity depression. The overall scoring ranges , highly linked major depressive disorders. % Our research hypothesis depressed individuals discuss symptoms Twitter.\\ % %This work aim develop intelligent decision support system context major depressive disorder providing healthcare professionals fine-grained depression related symptoms automatic triaging technique required HPs make timely intervention. The triage process first critical step giving care patients prioritizing patients different triage levels based severity clinical conditions could potential enhance efficacy healthcare interventions.\\ % % } % % % \end{table*} % Advancement Natural Language Processing technology one promising avenues discovering vital mental health information user-generated data. Nonetheless, texts offers inherently distinct challenges discussed follows: % % Furthermore, previous studies utilizing social media data biomedical natural language processing task reported prediction error drug symptom names utilized figurative sense. To account creative linguistic devices widely observed utterances depressive users, proposed multitask learning framework works concept task sharing mechanism. Multi-task learning proven useful instruments improve generalization performance primary task related auxiliary tasks. In work, focused improve performance generalization ability proposed model primary task `symptom identification' companionship supervisory task `figurative language detection'. We introduce mechanism named `co-task aware attention' enables layer-specific soft sharing parameters task interest. The proposed attention mechanism parameterize task-specific scaling factor BERT layers. To virtue this, model able learn task-specific representation input tweet coordinating among layers tasks. \\ % Contributions: %"," Existing studies on using social media for deriving mental health status of users focus on the depression detection task. However, for case management and referral to psychiatrists, healthcare workers require practical and scalable depressive disorder screening and triage system. % for prevention or treatment of severe consequences.  This study aims to design and evaluate a decision support system  to reliably determine the depressive triage level by capturing fine-grained depressive symptoms expressed in user tweets through the emulation of Patient Health Questionnaire-9 \texttt{} that is routinely used in clinical practice. %However, the 280-character limit on tweets incentivizes the usage of creative artifacts in the utterances.  %Figurative language forms a general fabric of communication as it permits users to express themselves more effectively.  %Unfortunately, this complicates the reliable detection of depressive symptoms.  The reliable detection of depressive symptoms from tweets is challenging because the 280-character limit on tweets incentivizes the use of creative artifacts in the utterances and figurative usage contributes to effective expression.   We propose a novel BERT based robust multi-task learning framework to accurately identify the depressive symptoms using the auxiliary task of figurative usage detection. Specifically, our proposed novel task sharing mechanism, co-task aware attention\/, enables automatic selection of optimal information across the BERT layers and tasks by soft-sharing of parameters. Our results show that modeling figurative usage can demonstrably improve the model's robustness and reliability for distinguishing the depression symptoms. %Furthermore, our approach achieves statistically significant improvements over the SOTA models.  % Social media platforms have evolved as a vital source of information for mental-health studies, where the users exchange their emotional states and impressions. Majority of the existing studies on depression focus mainly on the depression detection task. However, for healthcare workers to have real-time access to resources for case management and referral to medical/psychiatric treatment, it is necessitate to enable practical, scalable, and sustainable depressive disorder screening, triage, and prevention/treatment interventions. This study aims to design and evaluate a decision support system  to % determine the depressive triage level by capturing fine-grained depressive symptoms appearing in depressed users tweets through emulating the clinically adopted Patient Health Questionnaire-9 \texttt{\texttt{PHQ-9}}.\\ % Nevertheless, the limitation on characters imposed by Twitter incentivize the usage of creative artifacts that are widely observed in the utterance of depressive users. Figurative language, such as metaphor, irony, and sarcasm forms a general fabric of communication as it permit users to express their health condition more memorably, concisely, and effectively. Inspired by that, we proposed a novel BERT based multi-task learning framework that learns to accurately identify the symptoms using the auxiliary task of figurative language detection. Specifically, we propose a new task sharing mechanism: co-task aware attention, which helps the model to borrow the new information across the task. With the help of soft-sharing of the parameters, our framework automatically detect and select optimal information across the layers of the BERT, that are useful for a task at hand. % The obtained results proves that modeling figurative language in depressive user tweets can improve the model learning ability in correctly distinguishing the symptoms. Furthermore, our proposed approach achieve statistically significant improvements over the state-of-the-art models on our primary task."
"Coherence refers properties text indicate meaningful sentential constituents connected convey document-level meaning. Different theories proposed describe properties contribute discourse coherence integrated computational models empirical evaluation. A popular approach entity-based model hypothesizes coherence assessed terms distribution transitions entities text -- constructing entity-grid representation, building Centering Theory. Subsequent work adapted extended Egrid representations. Other research focused syntactic patterns co-occur text semantic relatedness sentences key aspects coherence modeling. There also attempts model coherence identifying rhetorical relations connect textual units capturing topic shifts via Hidden Markov Models~\cite[HMM,][]{barzilay-lee-2004-catching}. Other work combined approaches study whether complementary. More recently, neural networks used model coherence. Some models utilize structured representations text~\cite[e.g. Egrid representations,][]{Dat2017,Joty2018} others operate unstructured text, taking advantage neural models' ability learn useful representations task. Coherence typically assessed model's ability rank well-organized document higher noisy counterparts created corrupting sentence order original document , neural models achieved remarkable accuracy task. Recent efforts targeted additional tasks recovering correct sentence order, evaluating realistic data focusing open-domain models coherence. However, less attention directed investigating analyzing properties coherence current models capture, knowledge encoded representations might relate aspects coherence. In work, systematically examine properties discourse coherence current coherence models capture. We devise two datasets exhibit various kinds incoherence analyze model ability capture syntactic semantic aspects text implicated discourse organisation. We furthermore investigate set probing tasks better understand information encoded representations might relate aspects coherence. We hope study shall provide insight frame task improve models coherence assessment further. Finally, release evaluation datasets resource community use test discourse coherence models.","  In this work, we systematically investigate how well current models of coherence can capture aspects of text implicated in discourse organisation. We devise two datasets of various linguistic alterations that undermine coherence and test model sensitivity to changes in syntax and semantics. We furthermore probe discourse embedding space and examine the knowledge that is encoded in representations of coherence. We hope this study shall provide further insight into how to frame the task and improve models of coherence assessment further. Finally, we make our datasets publicly available as a resource for researchers to use to test discourse coherence models."
"Early detection dementia important improving clinical outcomes management dementia, well lifestyle, financial, future planning patients caregivers . Yet, dementia formally diagnosed coded claims 50\% older adults living probable dementia . Tools screen medical records warning signs present digested information providers may prove important step early intervention. In study, aim use NLP detect signs cognitive dysfunction clinician notes electronic health records applying deep learning techniques hitherto applied problem. We present attention-based transformer model allows long text sequences reveal signs cognitive concerns compare performance baseline models.","   Dementia is under-recognized in the community, under-diagnosed by healthcare professionals, and under-coded in claims data. Information on cognitive dysfunction, however, is often found in unstructured clinician notes within medical records but manual review by experts is time consuming and often prone to errors. Automated mining of these notes presents a potential opportunity to label patients with cognitive concerns who could benefit from an evaluation or be referred to specialist care.  In order to identify patients with cognitive concerns in electronic medical records, we applied natural language processing  algorithms and compared model performance to a baseline model that used structured diagnosis codes and medication data only. An attention-based deep learning model outperformed the baseline model and other simpler models."
"A spelling corrector important ubiquitous pre-processing tool wide range applications, word processors, search engines machine translation systems. %The popularity mobile devices makes increasingly crucial since typing virtual keyboards error-prone. Having surprisingly robust language processing system denoise scrambled spellings, humans relatively easily solve spelling correction . %spelling correction relatively easy task humans, surprisingly robust language processing system denoise scrambled spellings. However, spelling correction challenging task machine, words misspelled various ways, machine difficulties fully utilizing contextual information. Misspellings categorized non-word, out-of-vocabulary, opposite, real-word misspellings . The dictionary look-up method detect non-word misspellings, real-word spelling errors harder detect, since misspellings vocabulary . In work, address stand-alone spelling correction problem. It corrects spelling token without introducing new tokens deleting tokens, original information maximally preserved down-stream tasks. %\textcolor{red}{[The last sentences paragraph good, trying express?]} We formulate stand-alone spelling correction sequence labeling task jointly detect correct misspellings. Inspired human language processing system, propose novel solution following aspects: We encode spelling information global context information neural network. We enhance real-word correction performance initializing model pre-trained language model . We strengthen model's robustness unseen non-word misspellings augmenting training dataset synthetic character-level noise. As result, best model outperforms previous state-of-the-art result absolute score. %As result, present simple powerful solution stand-alone spelling correction simply fine-tuning pre-trained LM jointly detect correct non-word real-word misspellings sequence labeling task. %We propose novel solution using transformer-encoders jointly perform detection correction misspellings. We extensively explore various training techniques. Our results show transformer-encoder-based architecture encodes local character-level global word-level representations yields strong performance. Specifically, combination word embedding character embedding subword embedding produce strong models. We obtain state-of-the-art model initializing weight pre-trained language model training augmented training dataset synthetic character-level noise. \textcolor{red}{[this paragraph need rewrite. Please summarize contribution coherent story. ]} %We also explore additional training techniques leveraging pre-trained language model adding noise training corpora. Our results show fine-tuning pre-trained LM subword embedding yields strong model. Furthermore, obtain state-of-the-art model training noisy corpus synthesized randomly replacing correct words characters natural misspellings random character. Finally, condition pre-training, propose strong model outperforms subword model combining word character embedding. \iffalse We summarize contributions follows: \fi \iffalse \subsection{Stand-alone Spelling Correction} Formally, given noisy input sentence , noisy word drawn distribution possible misspellings correct word , vocabulary. We aim build corrector , correct sentence. %\textcolor{red}{[as I said, definition need section]} \fi"," Existing natural language processing systems are vulnerable to noisy inputs resulting from misspellings.  On the contrary, humans can easily infer the corresponding correct words %\textcolor{red}{the semantics of unknown words:the corresponding correct words of misspellings}  from their misspellings and surrounding context. Inspired by this, we address the stand-alone spelling correction problem, which  %\textcolor{red}{[do not know which refers to what, confusing, please rewrite; at the same time, can you brief introduce your novel solution here?]}  only corrects the spelling of each token without additional token insertion or deletion, by utilizing both spelling information and global context representations. We present a simple yet powerful solution that jointly detects and corrects misspellings as a sequence labeling task by fine-turning a pre-trained language model. Our solution outperform the previous state-of-the-art result by $12.8\%$ absolute $F_{0.5}$ score. %Furthermore, we obtain a state-of-the-art model by augmenting the training data with synthetic character-level noise. %We also provide three useful training techniques. Our results show that a transformer-based model that encodes both local character-level and global word-level representations yields a strong performance. Furthermore, a state-of-the-art model is obtained by leveraging pre-trained language model and augmenting the training corpus with synthetic character-level noises. %fine-tuning a pre-trained language model with a subword embedding yields a strong model. Furthermore, we obtain a state-of-the-art model by training it on a noisy corpus synthesized by randomly replacing correct words and characters with common misspellings and random characters. We also propose a strong architecture that combines character and word level encoder without pre-training."
"% % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % . % % % final paper: en-us version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. } Conversational technologies offer remarkable addition current approaches providing mental healthcare. Communications conversational agents found include discoverable psychological distress signs, rate filled pauses, speech rate, various temporal turn-related characteristics . In human-human automatic analysis patient-doctor conversations, also found different types disfluency indicate levels adherence medication . Markers disfluency also hold predictive power identification cognitive disorders . Such devices mainly used processing content, analyzed offline. There much work detecting disfluencies offline analysis transcripts gold standard utterance segmentation within much current effort disfluency detection telephone conversations begun . However, given models operate live systems rely rich transcription data, including pre-segmentation dialogue acts, facilitate cost-effective study data, would easier able perform directly incrementally speech signal, least automatic speech recognition results arrive system. The incremental model must work minimum latency receives word-by-word data without modifying initial assumptions providing best decisions soon possible line principles set . We combine incremental identification disfluencies three essential tasks active conversational models provide favorable inductive bias disfluency detection study way tasks interact. We explore multi-task learning framework enable training one universal model four tasks disfluency detection, language modelling, part-of-speech tagging, utterance segmentation, data use also equivalent dialogue act segmentation. Multi-task learning seeks improve learning efficiency predictive power learning shared representation multiple objectives. We investigate entire power set tasks investigate interaction them. We experiment two different losses: naive weighted sum losses weights loss uniform loss function based maximizing Gaussian likelihood task-dependent uncertainty. We train test simple neural model different tasks, experiment combinations tasks, different loss functions tasks, experiment different input representations .","  We present a multi-task learning framework to enable the training of one universal incremental dialogue processing model with four tasks of disfluency detection, language modelling, part-of-speech tagging, and utterance segmentation in a simple deep recurrent setting. We show that these tasks provide positive inductive biases to each other with the optimal contribution of each one relying on the severity of the noise from the task. Our live multi-task model outperforms similar individual tasks, delivers competitive performance, and is beneficial for future use in conversational agents in psychiatric treatment."
"We introduce \diagnnose, open source library analysing deep neural networks. The \diagnnose library allows researchers gain better insights internal representations networks, providing broad set tools state-of-the-art analysis techniques. The library supports wide range model types, main focus NLP architectures based LSTMs Transformers . Open-source libraries quintessential progress democratisation NLP. Popular packages include HuggingFace's -- allowing easy access pre-trained Transformer models; % AllenNLP -- providing useful abstractions components NLP pipeline, -- focusing multitask transfer learning within NLP; -- providing range feature attribution methods; -- platform visualising understanding model behaviour. We contribute open-source community incorporating several \mbox{interpretability} techniques present packages. Recent years seen considerable interest improving understanding deep neural networks operate . The high-dimensional nature models makes notoriously challenging untangle inner dynamics. This given rise novel subfield within AI focuses interpretability, providing us peak inside black box. \diagnnose aims unify several techniques one library, allowing interpretability research conducted streamlined accessible manner. \diagnnose's main focus lies techniques aid uncovering linguistic knowledge encoded within model's representations. The library provides abstractions allow recurrent models investigated way Transformer models, modular fashion. It contains extensive activation extraction module allows extraction model activations corpus. The analysis techniques currently implemented include: % <design principles> ? In paper present overview library, well case study subject-verb agreement within language models. We first present brief overview interpretability within NLP background analysis techniques part library . We provide overview \diagnnose expand briefly individual modules . % Next, provide extensive background feature attributions part library . We conclude case study subject-verb agreement, demonstrating several \diagnnose's features experimental setup ."," In this paper we introduce \diagnnose, an open source library for analysing the activations of deep neural networks. \diagnnose contains a wide array of interpretability techniques that provide fundamental insights into the inner workings of neural networks. We demonstrate the functionality of \diagnnose with a case study on subject-verb agreement within language models. \diagnnose is available at \url{https://github.com/i-machine-think/diagnnose}."
"% % % % \subsection{Motivation Problem} % % % % % \GW{Propaganda loosely defined ``misleading information spread deliberately deceive manipulate recipients'' . }% % % % % % % % % % Various factors propaganda studied humanities, including emotionality language, biased selection information deviation facts, manipulation cognition, . However, consensus decisive factors tell whether given article speech propagandistic not. % % % % % % In modern digital world, influence propaganda society drastically increased. % Hence, also major increase computer science, computational linguistics computational sociology research analyzing, characterizing and, ultimately, automatically detecting propaganda . To first degree, one may think propaganda variation fake news, works investigate propaganda refined type disinformation . % % % % % % % \GW{While false claims element propaganda, think fake news merely tip iceberg, persuasive manipulative nature propagandistic contents requires deeper approaches.} Classifiers propaganda detection need better capture propaganda expressed subtle ways language style rhetoric even demagogic wording. This holds news well social media posts speeches. In cases, correct information may presented incomplete form placed distorted contexts, along manipulative phrases, order mislead audience. % % % % Prior work mostly looked news articles tweets, typically focused strongly polarized topics like 2016 US election related Russian Internet Research Agency affair, UK Brexit discussion, political extremism. % % % % % % \LQ{All approaches consider propaganda detection classification task assuming sufficient amounts labeled in-domain training data.} \LQ{For example, ``Hack News'' datathon challenge, large number news articles sentences articles annotated distant supervision human judgment, respectively, train variety machine learning methods.} % % The resulting F1 scores leaderboard benchmark amazingly high, around 90\%. This may give impression propaganda detection solved problem. However, positively labeled samples simple cases ``loaded language'' strong linguistic cues independent topic. Moreover, learned classifiers % % benefit ample training data, self-guaranteed general. % % % % % % In paper, question prior assumptions, hypothesizing propagandistic sources speakers sophisticated creative find new forms deception evading trained classifiers. % % % \GW{The overall approach still text classification; novelty approach lies cross-domain learning, domains denote different kinds sources, news articles vs.\ social media posts vs.\ public speeches.} We acknowledge often shortage perfectly fitting labeled data, instead tap alternative sources require transfer step. Specifically, consider speeches tweets, addition news articles, article sentence levels. % \subsection{Approach Contribution} Our goal build general propaganda detectors, leverage different kinds data sources. In particular, tap political speeches notorious propagandists, Joseph Goebbels . As difficult label speeches sentences binary manner, pursue pairwise ordinal approach training data merely ranks samples strongly propagandistic speaker relatively temperate speaker. We investigate extent models learned data transferred classifying news tweets, also study inverse direction learning news tweets cope speeches. % % % % % % % Figure illustrates framework towards generalizable propaganda detection overcomes bottleneck directly applicable training labels instead leverages cross-domain learning. % % % % % The salient contributions paper follows. \newcommand{\myparagraph}[1]{{#1}.~} \newcommand{\var}[1]{\mbox{#1}} \newcommand{\svar}[1]{\mbox{\scriptsize#1}} \newcommand{\mycaption}[1]{}} \newcommand{\metric}[1]{{\mbox{#1}}} \newcommand{\Pat}{\metric{P}} \newcommand{\Patk}[1]{\mbox{\Pat@}} \newcommand{\Ratk}[1]{\mbox{\metric{R}@}} \newcommand{\gender}{``''} \newcommand{\age}{``''} \newcommand{\credit}{``''} \newcommand{\asset}{``''} \newcommand{\rcity}{``''}","  As news and social media exhibit an increasing amount of manipulative polarized content, detecting such propaganda has received attention as a new task for content analysis. Prior work has focused  % on supervised learning with training data from the same domain. However, as propaganda can be subtle and keeps evolving, manual identification and proper labeling are very demanding. As a consequence, training data is a major bottleneck.   In this paper, we tackle this bottleneck and present an approach to leverage cross-domain learning, based on labeled documents and sentences from news and tweets, as well as political speeches with a clear difference in their degrees of being propagandistic. We devise informative features and build various classifiers for propaganda labeling, using cross-domain learning.  % % % Our experiments demonstrate the usefulness of this approach, and identify difficulties and limitations in various configurations of sources and targets for the transfer step. We further analyze the influence of various features, and characterize salient indicators of propaganda. %"
"\looseness=-1 Neural machine translation architectures~ make difficult users specify preferences could incorporated easily statistical MT models shown useful interactive machine translation~ domain adaptation~. Lexical constraints preferences previously incorporated re-training NMT models constraints inputs~ constrained beam search drastically slows decoding~. \looseness=-1 In work, introduce translation model seamlessly incorporate users' lexical choice preferences without increasing time computational cost decoding time, trained regular MT samples. We apply model MT tasks soft lexical constraints. As illustrated Figure, decoding soft lexical constraints, user preferences lexical choice output language provided additional input sequence target words order. The goal let users encode terminology, domain stylistic preferences target word usage, without strictly enforcing hard constraints might hamper NMT's ability generate fluent outputs. Our model Edit-Based TransfOrmer Repositioning , builds recent progress non-autoregressive sequence generation~. Specifically, Levenshtein Transformer~ showed iteratively refining output sequences via insertions deletions yields fast flexible generation process MT automatic post-editing tasks. \modelname replaces deletion operation novel reposition operation disentangle lexical choice reordering decisions. As result, \modelname exploits lexical constraints effectively efficiently Levenshtein Transformer, single reposition operation subsume sequence deletions insertions. To train \modelname via imitation learning, reposition operation defined preserve ability use Levenshtein edit distance~ efficient oracle. We also introduce dual-path roll-in policy lets reposition deletion models learn refine respective outputs effectively. \looseness=-1 Experiments Romanian-English, English-German, English-Japanese MT show \modelname achieves comparable better translation quality faster decoding speed Levenshtein Transformer standard MT tasks exploit soft lexical constraints better: achieves significantly better translation quality matches constraints faster decoding speed Levenshtein Transformer. It also drastically speeds decoding compared lexically constrained decoding algorithms~. Furthermore, results highlight benefits soft constraints hard ones \---\ \modelname soft constraints achieves translation quality par better \modelname Levenshtein Transformer hard constraints~."," We introduce an Edit-Based TransfOrmer with Repositioning , which makes sequence generation flexible by seamlessly allowing users to specify preferences in output lexical choice. Building on recent models for non-autoregressive sequence generation, \modelname generates new sequences by iteratively editing hypotheses. It relies on a novel reposition operation designed to disentangle lexical choice from word positioning decisions, while enabling efficient oracles for imitation learning and parallel edits at decoding time. Empirically, \modelname uses soft lexical constraints more effectively than the Levenshtein Transformer while speeding up decoding dramatically compared to constrained beam search. \modelname also achieves comparable or better translation quality with faster decoding speed than the Levenshtein Transformer on standard Romanian-English, English-German, and English-Japanese machine translation tasks."
"Word embeddings like Word2Vec Glove learn context-sensitive vector representations words large corpora. These representations proven useful supervised tasks like language translation, entity recognition, sentiment analysis, question answering. The general problem tracking semantic change words time initially addressed number works, either connecting several static embeddings mapping transformations, initializing training slice results previous one Word2Vec case . More recent works deal temporal slices simultaneously, Bamler Mandt, Rudolph Blei, Yao et. al. These works link slices either diffusion process, random walk, regularization term cost function. The proposed approach assume sequentiality slices . By combining data different sources, embeddings help understand semantic drift, also cross-cultural differences dialect variations . In work consider corpus divided set segments called slices. All slices trained simultaneously, following Word2Vec distributional hypothesis, addition word vector representation inside slice obtained adding central representation slice-dependent one. Thus, different representations one word across different slices tied common component. This constraint depicted star-like graph. Figure shows representation two cases: newspaper corpus covering several years, multi-source corpus combining two English-language newspapers. The rest paper organized follows. Section introduces proposed model, giving formal description, vocabulary selection implementation details. Section describes datasets used work: two corpora The New York Times The Guardian newspapers, curated multi-source corpus combines them. Section provides experimental work three datasets, corresponding quantitative qualitative analysis. The related work detailed Section. Finally, conclusions future work discussed Section."," There is an increasing interest in the NLP community in capturing variations in the usage of language, either through time , across regions  or in different social contexts . Several successful dynamical embeddings have been proposed that can track semantic change through time.  Here we show that a model with a central word representation and a slice-dependent contribution can learn word embeddings from different corpora simultaneously. This model is based on a star-like representation of the slices. We apply it to The New York Times and The Guardian newspapers, and we show that it can capture both temporal dynamics in the yearly slices of each corpus, and language variations between US and UK English in a curated multi-source corpus. We provide an extensive evaluation of this methodology."
"The goal relation extraction extract relationships two entities plain text. Supervised learning methods relation extraction widely used extract relations based training labeled data. Distant supervision crowdsourcing used collect examples labels train model relation extraction. However, methods limited quantity quality training data manually labeling data time-consuming labor-intensive data labeled distant-supervision noisy. To overcome problem insufficient high-quality data, few-shot learning designed require labeled sentences training. A lot research done few-shot learning computer vision~, work also includes few-shot learning methods relation extraction~. Although works require instances training, still work many scenarios training instances available. Some work open information extraction discovers new relationships open-domain corpora without labeling data. OpenIE aims extract relation phrases directly text. However, technique effectively select meaningful relation patterns discard irrelevant information. In addition, technique discover relations relation's name appear given sentence. For example, OpenIE identify relation sentence shown Figure. To address aforementioned limitations, focus relation extraction context zero-shot learning. Zero-shot learning similar way humans learn recognize new concepts. It novel learning technique use exemplars unseen categories training. We propose zero-shot learning model relation extraction , focuses recognizing new relations corresponding labeled data available training. ZSLRE modified prototypical networks utilizing side information. We construct side information labels synonyms, hypernyms two name entities keywords training sentences. The ZSL-based model recognize new relations based side information available instead using collection labeled sentences. We incorporate side information enable model extract relations never appear training datasets. We also build automatic hypernym extraction framework help us acquire hypernyms different entities directly web. Details side information construction described Section Side Information Extraction. Figure shows example side information used extract relations. Different side information given different relations. The query sentence example relation classmate\_of, word classmate never appears sentence. We first get two name entities Nell Newman Mayday Parker sentence extract hypernyms name entities person person based proposed hypernym extraction module Section Hypernyms Extraction. In example, relationship capital\_of eliminated hypernyms capital\_of location location. Then extract keywords course school query sentence compare distance keywords side information box. In way, relationship children\_of eliminated. To make relation extraction effective real-world scenarios, design models ability extract relations training instances relations without training instances. We modify vanilla prototypical networks deal scenarios compare distance query sentence prototype. If exponential minus distance threshold, consider query sentence new relation. For new relations extraction, take side information embedding query sentence compare distance side information embedding new relations. We conduct different experiments noisy clean dataset adding different percentages new relations evaluate effectiveness robustness proposed model. Besides, also evaluate proposed model supervised learning, few-shot learning zero-shot learning scenarios results show proposed model outperforms existing models three scenarios. The contributions paper summarized follows: The rest paper organized follows. Section Related Work reviews work supervised relation extraction, open relation extraction zero-shot learning. Section Methodology describes proposed ZSLRE model. Section Experiments presents experiments compares performance model different models two public datasets. Section Conclusion Future Work includes discussion conclusion promising future work."," Most existing supervised and few-shot learning relation extraction methods have relied on labeled training data. However, in real-world scenarios, there exist many relations for which there is no available training data. We address this issue from the perspective of zero-shot learning  which is similar to the way humans learn and recognize new concepts with no prior knowledge. We propose a zero-shot learning relation extraction  framework, which focuses on recognizing novel relations that have no corresponding labeled data available for training. Our proposed ZSLRE model aims to recognize new relations based on prototypical networks that are modified to utilize side  information. The additional use of side information allows those modified prototype networks to recognize novel relations in addition to recognized previously known relations. We construct side information from labels and their synonyms, hypernyms of name entities, and keywords. We build an automatic hypernym extraction framework to help get hypernyms of various name entities directly from web. We demonstrate using extensive experiments on two public datasets  that our proposed model significantly outperforms state-of-the-art methods on supervised learning, few-shot learning and zero-shot learning tasks. Our experimental results also demonstrate the effectiveness and robustness of our proposed model in a combination scenario. Once accepted for publication, we will publish ZSLRE's source code and datasets to enable reproducibility and encourage further research."
"Unlabeled data leveraged many ways natural language processing including back-translation~, self-training~, language model pre-training led improvements many natural language tasks~. While pre-training achieved impressive results tasks labeled data limited, improvements settings abundant labeled data modest~ controlled studies showing clear trend diminishing returns amount training data increases~. In paper, focus noisy channel modeling text generation tasks, classical technique statistical machine translation literature workhorse text generation tasks decades arrival neural sequence sequence models~. Unlike pre-training approaches, approach effective irrespective amount labeled data: since recent revival~, important part winning entries several high resource language pairs WMT 2019~, improving strong ensembles used 500M back-translated sentences. At low resource WAT 2019 machine translation competition, noisy channel modeling also key factor winning entry~. Noisy channel modeling turns text generation head: instead modeling output sequence given input, Bayes' rule applied model input given output, via backward sequence sequence model combined prior probability output, typically language model. This enables effective use strong language models trained large amounts unlabeled data. The role backward model, channel model, validate outputs preferred language model respect input. A straightforward way use language models pair standard sequence sequence models~. However, address explaining away effects modern neural sequence models still suffer~. As consequence, models susceptible producing fluent outputs unrelated input~. The noisy channel approach explicitly addresses via channel model. However, major obstacle efficient noisy channel modeling generating outputs much slower decoding standard sequence sequence model. We address issue introducing several simple yet highly effective approximations increase speed noisy channel modeling order magnitude make practical. This includes smaller channel models well scoring subset channel model vocabulary. Experiments WMT English-Romanian translation show noisy channel modeling outperform recent pre-training results. Moreover, show noisy channel modeling benefits much larger beam sizes strong pre-training methods."," Pre-training models on vast quantities of unlabeled data has emerged as an effective approach to improving accuracy on many NLP tasks. On the other hand, traditional machine translation has a long history of leveraging unlabeled data through noisy channel modeling.  The same idea has recently been shown to achieve strong improvements for neural machine translation. Unfortunately, na\""{i}ve noisy channel modeling with modern sequence to sequence models is up to an order of magnitude slower than alternatives.  We address this issue by introducing efficient approximations to make inference with the noisy channel approach as fast as strong ensembles while increasing accuracy. We also show that the noisy channel approach can outperform strong pre-training results by achieving a new state of the art on WMT Romanian-English translation."
"% Sentiment analysis text classification technique analyses given text returns nature underlying opinion. Therefore, sentiment analysis widely used tasks brand monitoring, political research analysis, product analysis, workforce analysis many more. Sentiment analysis techniques could fundamentally sub divided two categories lexicon-based approach machine learning based approach. Recently introduced deep learning based sentiment analysis techniques outperformed lexicon based approaches traditional machine learning approaches. With development deep learning techniques Convolutional Neural Networks , Recurrent Neural Networks language independent features, domain sentiment analysis reported impressive results. Over years, many variants combinations deep learning techniques feature representations used high resourced languages English. There also exist certain advancements sentiment analysis languages Chinese, Arabic, Spanish Indic languages. Sinhala, morphologically rich Indo-Aryan language, experienced advancements due insular under-resourced nature. One main challenges large enough annotated corpora. The data set from~\citet{liyanage2018sentiment} publicly available annotated data set sentiment analysis. However includes 5010 comments extracted one news source, contains POSITIVE NEGATIVE samples. %Work of~\citet{medagoda2017framework} example simple solutions Sinhala sentiment analysis. Under approaches, rule-based techniques, lexicon based techniques, supervised semi-supervised machine learning techniques employed traditional language dependent features. The 閾夸购st experiment using deep learning techniques Sinhala sentiment analysis conducted by~\citet{liyanage2018sentiment}. Under research, basic deep learning techniques Long Short-Term Memory network CNN used categorize news comments POSITIVE NEGATIVE. %The LSTM trained fastText embeddings outperformed traditional machine learning techniques Decision Tree, SVM, Na\""ive Bayes. ~\citet{DemotteSLSTM2020Sinhala} conducted experiment data set using Sentence-State LSTM , rather advanced technique analysis improved considering n-gram features text word embeddings. In paper, present comprehensive empirical study use deep learning techniques document-level sentiment analysis Sinhala respect four sentiment categories POSITIVE, NEGATIVE, NEUTRAL CONFLICT. The experiments conducted commonly used sequence models RNN, LSTM, Bi-LSTM, various improvements vanilla models stacking regularization, well recent ones hierarchical attention hybrid neural networks capsule networks. % multi-class sentiment analysis using word embeddings language independent features. These langauge independent features able outperform usage traditional language dependent features part speech tagging lexical resources. ~Furthermore, present data set 15059 comments, annotated four classes used sentiment analysis, based Sinhala news comments extracted online newspapers namely GossipLanka Lankadeepa. This publicly available multi-class, multi-source dataset Sinhala sentiment analysis. Our code implementation, word embedding models, annotated data set publicly available. %"," Due to the high impact of the fast-evolving fields of machine learning and deep learning, Natural Language Processing  tasks have further obtained comprehensive performances for highly resourced languages such as English and Chinese. However Sinhala, which is an under-resourced language with a rich morphology, has not experienced these advancements. For sentiment analysis, there exists only two previous research with deep learning approaches, which focused only on document-level sentiment analysis for the binary case. They experimented with only three types of deep learning models. In contrast, this paper presents a much comprehensive study on the use of standard sequence models such as RNN, LSTM, Bi-LSTM, as well as more recent state-of-the-art models such as  hierarchical attention hybrid neural networks, and capsule networks. Classification is done at document-level but with more granularity by considering POSITIVE, NEGATIVE, NEUTRAL, and CONFLICT classes. A data set of 15059 Sinhala news comments, annotated with these four classes and a corpus consists of 9.48 million tokens are publicly released. This is the largest sentiment annotated data set for Sinhala so far.   % In addition to that,  was extracted from both comments and articles of online newspapers. %Furthermore, the language-independent features such as Word2Vec and fastText were experimented for novel deep learning techniques which clearly indicate the importance of word embedding techniques for NLP tasks including sentiment analysis for Sinhala as a low resource language. % Due to the high impact of the fast-evolving field of machine learning and deep learning, the Natural Language Processing  tasks have further obtained comprehensive and prominent performances over the past few decades. Different variations and combinations of deep learning techniques have been employed for NLP tasks in general. These experiments illustrated highly improved performances with respect to the traditional rule-based and statistical machine learning techniques. These advancements were mainly impacted towards the development of popular languages such as English and Chinese. However, Sinhala which is an under-resourced language with rich morphology, have not experienced these advancements due to fewer resources for NLP tasks. For sentiment analysis, there exist only two previous research with deep learning approaches, which also conducted with less granularity while giving sub optimality with respect to recent advancements in deep learning techniques. In this paper, we present the use of state-of-the-art deep learning approaches such as RNN, LSTM, Bi-LSTM, Hierarchical Attention Hybrid Neural Networks, and capsule networks for multi-class sentiment analysis for Sinhala news comments while considering more granularity. Under this research, we present the multi-class annotated data set which consists of Sinhala news comments extracted from online newspapers. Furthermore, the language-independent features such as word2Vec and fastText were experimented for novel deep learning techniques which clearly indicates the importance of word embedding techniques for NLP tasks including sentiment analysis."
"% The first letter 2 line initial drop letter followed % rest first word caps. % % form use first word consists single letter: % \IAENGPARstart{A}{demo} file .... % % form use need single drop letter followed % normal text : % \IAENGPARstart{A}{}demo file .... % % Some journals put first two words caps: % \IAENGPARstart{T}{his demo} file .... % % Here typical use ""T"" initial drop letter % ""HIS"" caps complete first word. \IAENGPARstart{T}{he} Neural Machine Translation used model state-of-the-art translation systems many high-resource languages . For many language pairs though, amount and/or quality parallel data enough train NMT model whose accuracy reach acceptable standard . This category language pairs known low resource. Many works explored use easier-to-get monolingual data improve quality translation models category languages -- even high resource languages -- . The back-translation far one successful methods , involving use translations target language monolingual data increase amount training data . The additional parallel data consists authentic sentences target language translations -- synthetic sentences source language -- generated using reverse model trained available parallel data -- see procedure Algorithm 1. The approach proven successful improving quality translations high, middle low resourced languages . Many studies shown quality backward system influences performance ultimate NMT model . In low resource conditions, available parallel data may able train standard backward model quality additional data generated using model may hurt quality final model. Despite this, aim standard back-translation always improve performance target NMT model providing sufficient training data. Some previous works proposed various methods improve performance backward model training. These methods include iterative back-translation , transfer learning , self-training training bi-directional translation model backward forward translations . Others tried mask deficiencies backward model either inference generating multiple translations target sentence using sampling average-out errors individual translations noising output beam search ; reducing effects errors synthetic data training forward model methods tagged back-translation pre-training fine-tuning . We present hybrid approach utilizes monolingual target data improve forward backward models back-translation. In approach, used synthetic data enhance backward model self-learning standard back-translation improving forward model. The approach preliminary investigated shown achieve positive results. Earlier use stand-alone self-training machine translation proposed extra methods either using quality estimation freezing decoder weights training synthetic side training data. It suggested mistakes synthetic data hurt performance self-trained model . Instead, showed self-training capable improving quality backward model even without using either specialized approaches. It shown using synthetic data generated backward model help re-training backward model improved performance. The work, though, show benefits otherwise using specialized approach cleaning data, especially low resource languages. It also investigate model continue learn output iterating self-learning process. \end{table} This work, therefore, investigates effects synthetic data cleaning using automatic quality estimation training backward model. We observed approach may improve backward model, selecting subset synthetic data may result superior less generic model. We investigated use iterative self-training quality estimation proposed , enabling backward model trained monolingual data. For low resource languages, readily available quality estimation systems data train systems may available. This may limit implementation approach. We, therefore, proposed novel iterative approach relies available monolingual target data improve backward model finally generating much improved synthetic data forward model's training. Experimental results show approach superior standard back-translation approach proposed ; iterative approach superior iterative back-translation also requiring less number models trained. We thus make following contributions paper: \renewcommand{\labelitemi}{\textbullet} The remainder paper organized follows: In Section , reviewed related works. We presented proposed methods Section . We reported experiments results Section . We discussed results findings research work Sections respectively and, finally, paper concluded directions future work proposed Section ."," %\boldmath Many language pairs are low resource, meaning the amount and/or quality of available parallel data is not sufficient to train a neural machine translation  model which can reach an acceptable standard of accuracy. Many works have explored using the readily available monolingual data in either or both of the languages to improve the standard of translation models in low, and even high, resource languages. One of the most successful of such works is the back-translation that utilizes the translations of the target language monolingual data to increase the amount of the training data. The quality of the backward model which is trained on the available parallel data has been shown to determine the performance of the back-translation approach. Despite this, only the forward model is improved on the monolingual target data in standard back-translation. A previous study proposed an iterative back-translation approach for improving both models over several iterations. But unlike in the traditional back-translation, it relied on both the target and source monolingual data. This work, therefore, proposes a novel approach that enables both the backward and forward models to benefit from the monolingual target data through a hybrid of self-learning and back-translation respectively. Experimental results have shown the superiority of the proposed approach over the traditional back-translation method on English-German low resource neural machine translation. We also proposed an iterative self-learning approach that outperforms the iterative back-translation while also relying only on the monolingual target data and require the training of less models."
"End-to-end techniques automatic speech recognition , notably sequence-to-sequence models attention Recurrent Neural Network Transducer , becoming increasingly popular. Compared traditional hybrid system based Hidden Markov Model Deep Neural Network individually-trained components, parts end-to-end model optimized jointly, often leads better performance recognition tasks sufficient training data low training-testing mismatch. End-to-end systems simpler train; typically require pronunciation lexicons, decision trees, initial bootstrapping, forced alignment. End-to-end models also suitable on-device use cases due lack external language models decoding graphs, whose sizes prohibitively large hybrid setups large vocabulary support, complex LMs, context-dependent decision trees. End-to-end systems limitations, however. Their end-to-end nature leads lack composability, acoustic, language, pronunciation models hybrid setups. This lack composability turn leads challenges personalization, traditionally involves on-the-fly modification external LMs add, boost, penalize certain words phrases. Previous work end-to-end ASR addressed issue incorporating external LMs beam search , special modifications handle model's spiky output . A fundamental limitation shallow fusion relies late combination, hence model needs potential produce correct output first place without access biasing information. Another class method adds attention-based simple biasing module contextual phrases provide additional signal decoder component end-to-end models. While promising, methods shown problems scaling large highly confusable biasing lists. A closely related challenge ASR personalization entity recognition, since many cases biasing items entity names. Rare name recognition presents significant challenges end-to-end models two main reasons. First, output units end-to-end models typically graphemes WordPieces , work well spelling word correspond pronounced . Second, rare names often decompose target sequences seen enough training, making difficult recognize correctly. By contrast, problems alleviated hybrid systems due use phonetic lexicons and/or clustered context-dependent acoustic targets. Popular solutions problem include upsampling entity-heavy data generating synthetic training data names using text-to-speech . While method alleviates data sparsity issue, address underlying problems under-trained targets unconventional spelling rare names. In work, propose several novel techniques address challenges improve RNN-T personalization. To alleviate problem under-trained targets recognition unconventional names, adopt on-the-fly sub-word regularization increase WordPiece coverage training, perform pre-training multi-task learning strengthen encoder, leverage grapheme-to-grapheme generate alternative graphemic pronunciations names. To address limitation shallow fusion relying late combination, introduce deep personalized LM fusion influence model's predictions earlier. We show combination techniques results 15.4\%--34.5\% relative Word Error Rate improvement top strong RNN-T baseline leverages shallow fusion TTS augmentation. Our final model also competitive hybrid system significantly larger disk memory footprint."," End-to-end models in general, and Recurrent Neural Network Transducer  in particular, have gained significant traction in the automatic speech recognition community in the last few years due to their simplicity, compactness, and excellent performance on generic transcription tasks. However, these models are more challenging to personalize compared to traditional hybrid systems due to the lack of external language models and difficulties in recognizing rare long-tail words, specifically entity names. In this work, we present novel techniques to improve RNN-T's ability to model rare WordPieces, infuse extra information into the encoder, enable the use of alternative graphemic pronunciations, and perform deep fusion with personalized language models for more robust biasing. We show that these combined techniques result in 15.4\%--34.5\% relative Word Error Rate improvement compared to a strong RNN-T baseline which uses shallow fusion and text-to-speech augmentation. Our work helps push the boundary of RNN-T personalization and close the gap with hybrid systems on use cases where biasing and entity recognition are crucial."
"Our goal improve information extraction business documents contribute field automated document processing. This work leads higher success metric enables less manual work regarding data entry and/or annotation industry. To put work context define terms closely let's briefly recall definition task, motivation add details. \paragraph{Information extraction task} The general problem information extraction new problem . A survey information extraction methods defines task as: ``Information Extraction starts collection texts, transforms information readily digested analyzed. It isolates relevant text fragments, extracts relevant information fragments, pieces together targeted information coherent framework''. The relevant collection texts study texts business documents invoices, pro forma invoices debit notes. The targeted information classification texts helps automating various business processes 閳 automated payment invoices. \paragraph{Motivation} The typical user method would company medium-sized bigger because, point, companies start spend significant time document processing. Details harder find referenced peer-reviewed works since companies keep spending information secret. Approximations unofficial sources lead estimate success metric translates company savings. A typical medium-sized company approximately invoices per month even improvement roughly translates dollars saving monthly scales company size. Note heuristics thus define metric exactly. \paragraph{Details overview} As stated, focus business documents. The explicit category documents varies. Existing works information extraction define ``visually rich documents'', ``structured'', ``semi-structured''. We use name ``structured documents'' throughout work since structure documents clear understandable human working relevant fields, even though specific structure varies. Moreover, documents machine-readable detail individual words pictures page, machine, ``understandable'' respect goal important information extraction. It important classify information needed financial/accounting industry, ``users'' documents. For example, payment details, amount paid, issuer information etc. The input document's page goal identify output words entities document considered important, along respective classifications. One example input invoice output extraction seen \prettyref{fig:Example}. As see, documents easily understandable inputs. An example trivial inputs would XML document desired target classes incorporated machine-readable way. With study, aim expand previous work , already shown neural networks succeed task extracting important information even identifying whole, highly specific tables. As argued before, every improvement matters work, focus improving metrics selecting relevant techniques deep learning field. A classical heuristic way generally improve target metric provide relevant information network. Previously exhausted information present single invoice focus techniques related ``similarity''. Existing works similarity presented \prettyref{subsec:Inspiration} use notion similarity defined \prettyref{subsec:The-learning-framework}. In short, present similar annotated document another input. More details differences previous work described \prettyref{subsec:The-differences-to-prev}. Since idea providing information fundamental even simpler templating techniques , need stress that, due nature dataset , problem cannot solved using templates. To prove statement, reasonable template-based baseline presented evaluated . The research question focus ``similarity'' based mechanism various model implementations, whether improve existing solution . The hypothesis able create least one model significantly improve results. Moreover, since presented mechanism theoretically applicable beyond scope document processing, work contribute broader audience. Ultimately present model source code outperforms previous state-of-art results. An anonymized version dataset also included open-source resource notable contribution since size greater similar dataset known date. \subsection{Related works} This subsection focuses research previous works approaches relevant field information extraction. The text subsection heavily based text . The plethora methods used historically general information extraction hard fully summarize compare. Moreover, would fair compare methods developed evaluated fundamentally different datasets. However, assessed none methods well-suited working structured documents , since generally fixed layout, language, caption set, delimiters, fonts... For example, invoices vary countries, companies departments, change time. In order retrieve information structured document, must understand it. Our criterion considering method compare human-controlled preprocessing template specification layout fixing required aim fully automated general solution. Therefore including historical method baseline compare against. In recent works, significant number successfully use graph representation document use graph neural networks. Also, key idea close one-shot principle information extraction used examined example . Both works use notions finding similar documents reusing gold-standards . The latter applies principle form template matching without need learnable parameters. Our approach also called ``word classification'' approach written , work end-to-end architecture concept memory explored. At point, important clarify differences works stream research . The important difference comes dataset disposal. The dataset explored far greater datasets used elsewhere, allows exploring deeper models opposed using graph neural networks. Indeed previous paper, proven graph neural networks work synergy additional convolution-over-sequence layers even global self-attention. For clarity, roles said layers described \prettyref{subsec:Common-architecture}. Moreover, dataset quality allowed us discover information extraction line-item table detection targets boost other. As research focused deeper models, using works baselines commonly used graph neural networks incorporated one layer amidst many, special focus. In following pages, explore models would able benefit access known similar document's page. We hope model exploit similarities documents, even similar templates. \subsection{Broader inspiration} A broader section references provided since using great variety layers exploration deep network architectures. \paragraph{One-shot learning similarity} Presented model design concept aims improve models new data without retraining network. Typically, classification model trained recognize specific set classes. In one-shot learning, usually able correctly identify classes comparing already known data. Unlike traditional multi-class classification, one-shot learning allows us attain better scores even surprisingly low numbers samples . Sometimes work even classes present training set . This concept help areas ranging computer vision variants 閳 omniglot challenge object detection , finding similar images , face detection , autonomous vision , speech also NLP area . Among methods make one-shot learning able work, fundamental one utilizes concept similarity. For similarity work, two types data 閳 ``unknown'' ``known''. For known data, target values known method and/or model. To classify unknown input, usual practice assign class class similar known input. Technically speaking, architecture contains 閳ユ笩iamese閳 part. In particular, inputs passed network architecture tied weights. We draw inspiration basic principle, leave advanced methods one-shot learning research. Usually due performance reasons model asked compare new inputs every known input 閳 subset. Therefore, prior pruning technique needs incorporated 閳 example form nearest neighbor search embedding space, done example work . Another option would incorporate memory concept . The loss used similarity learning called triplet loss applied triplet classes data-point: Where margin positive negative classes model function mapping inputs embedding space . Generally speaking, one-shot learning classified meta-learning technique. For meta-learning, suggest recent study, like . Taking concept one step yields concept called ``zero-shot learning'' . \paragraph{Other sources inspiration} It beneficial mention sources inspiration also meaningfully close one-shot learning. Since ask ``what labels similar new data'', ``query answer'' approach considered. Recently, attention principle successfully helped pave way language models . It uncommon use attention one-shot approaches also query answer problems various problems domains . The mentioned task similarity also approached pairwise classification, even dissimilarity ."," The automation of document processing is gaining recent attention due to the great potential to reduce manual work through improved methods and hardware. Any improvement of information extraction systems or further reduction in their error rates has a significant impact in the real world for any company working with business documents as lowering the reliability on cost-heavy and error-prone human work significantly improves the revenue. In this area, neural networks have been applied before 闁 even though they have been trained only on relatively small datasets with hundreds of documents so far.  To successfully explore deep learning techniques and improve the information extraction results, a dataset with more than twenty-five thousand documents has been compiled, anonymized and is published as a part of this work. We will expand our previous work where we proved that convolutions, graph convolutions and self-attention can work together and exploit all the information present in a structured document. Taking the fully trainable method one step further, we will now design and examine various approaches to using siamese networks, concepts of similarity, one-shot learning and context/memory awareness. The aim is to improve micro $F_{1}$ of per-word classification on the huge real-world document dataset.  The results verify the hypothesis that trainable access to a similar  page together with its already known target information improves the information extraction. Furthermore, the experiments confirm that all proposed architecture parts  are all required to beat the previous results.  The best model improves the previous state-of-the-art results by an $8.25\,\%$ gain in $F_{1}$ score. Qualitative analysis is provided to verify that the new model performs better for all target classes. Additionally, multiple structural observations about the causes of the underperformance of some architectures are revealed.  All the source codes, parameters and implementation details are published together with the dataset in the hope to push the research boundaries since all the techniques used in this work are not problem-specific and can be generalized for other tasks and contexts.   \keywords{one-shot learning \and information extraction \and siamese networks \and  similarity \and attention}"
"%Thanh COLIEE annual competition find automated solutions field law. This competition challenging legal documents often complex require high level comprehension. The problems law even tricky law experts. COLIEE tasks cover two popular legal systems world, Case law Civil law. COLIEE provides real data Canadian judicial system Japanese legal system. COLIEE organizes 4 tasks divided 2 categories: retrieval entailment. For retrieval tasks, systems need automatically find supporting cases given query case relevant articles given bar question . For entailment tasks, systems need find paragraphs relevant case entail given decision conclude whether statement given question correct incorrect . These tasks solved various text processing methods. On one hand, years, systems using lexical similarity texts yield inferior performance. On hand, deep learning approaches start gaining superior performance recently. %"," We propose deep learning based methods for automatic systems of legal retrieval and legal question-answering in COLIEE 2020. These systems are all characterized by being pre-trained on large amounts of data before being finetuned for the specified tasks. This approach helps to overcome the data scarcity and achieve good performance, thus can be useful for tackling related problems in information retrieval, and decision support in the legal domain. Besides, the approach can be explored to deal with other domain specific problems.    \keywords{Deep Learning \and Legal Text Processing \and Pretrained Legal Text Encoders }"
"The dominant paradigm supervised NLP today learning examples, machine learning algorithms trained using large set task-specific input-output pairs. In contrast, humans learn perform task reading description, able perform task zero-shot manner---indeed, crowd-sourced NLP datasets constructed. In paper, argue learning task descriptions way necessary attribute general purpose NLP system, propose new paradigm train test NLP systems. Recent work NLP shown significant progress learning tasks examples. Large pretrained language models dramatically improved performance standard benchmarks shown promising results zero shot prediction leveraging language understanding capabilities. Despite progress, many serious issues come learning examples. There almost infinite number tasks person might wish solve general-purpose NLP system. Learning solve tasks reading description instead observing collection examples would solve problem create training sets language task. Such system would also accessible practitioners domain experts fields, could describe tasks solve them, opening new avenues research expensive infeasible gather training data. Additionally, find current supervised learning techniques partly achieve success due memorizing uninteresting aspects training distribution. Teaching system learn task description alone would alleviate biases, new training data would needed learn novel task. In paper, synthesize prior approaches zero-shot learning NLP provide formal framework thinking zero-shot prediction problem. We show previous zero-shot approaches limited scope application rigour evaluation. For example, prior work used zero-shot prediction text classification, entity typing, relation extraction, push complex task slot filling. We instantiate formalism English language dataset, \dataset , formatted similarly reading comprehension datasets, formulate task descriptions questions pair paragraphs text. We choose format provides natural way crowdsource data. This zero-shot dataset differs typical reading comprehension datasets, however, task description paired twenty different passages, evaluate model's ability solve task, give correct answer single pair. That is, given question, model produces decision function , function comprehensively evaluate many different inputs. We also carefully select axes evaluate generalization model different kinds task descriptions, changing task descriptions specific ways systematically push field towards interesting complex task descriptions. We evaluate models based recent state-of-the-art sequence sequence architectures, seem suited task zero shot prediction setting. We find best model based T5 achieves score \finalscore\% data, leaving significant gap human performance estimate \humanestimate\%. Zero shot learning complex task descriptions remains significant challenge current NLP systems."," Typically, machine learning systems solve new tasks by training on thousands of examples. In contrast, humans can solve new tasks by reading some instructions, with perhaps an example or two. To take a step toward closing this gap, we introduce a framework for developing NLP systems that solve new tasks after reading their descriptions, synthesizing prior work in this area. We instantiate this framework with a new English language dataset, \dataset, structured for task-oriented evaluation on unseen tasks. Formulating task descriptions as questions, we ensure each is general enough to apply to many possible inputs, thus comprehensively evaluating a model's ability to solve each task. Moreover, the dataset's structure tests specific types of systematic generalization.\blfootnote{\textasteriskcentered Work done while at the Allen Institute for AI.} We find that the state-of-the-art T5 model achieves a score of \finalscore\% on \dataset, leaving a significant challenge for NLP researchers.\footnote{Data, evaluation code, baseline models, and leaderboard at \url{https://allenai.org/data/zest}}"
"Because fact obtaining supervised training labels costly time-intensive, unlabeled data relatively easy obtain, semi-supervised learning , utilizes in-domain unlabeled data improve models trained labeled dataset , growing interest. Under context large-scale language model pretraining , language model pretrained extremely large, open-domain dataset , make best use in-domain unlabeled dataset poorly understood. There basically two ways take advantages unlabeled, in-domain dataset : {\bf in-domain pretraining}\footnote{To note, pretraining in-domain dataset distinguished pretraining large-scale, open-domain dataset largeU. The model in-domain pretraining randomly initialized taking pretrained model based open-domain dataset largeU .}, language model pretrained in-domain dataset , fine-tuned ; {\bf pseudo-label} based approach , unlabeled data points assigned labels predicted model trained , forming new dataset . A new model trained final predictions considering . Many important questions regarding behavior semi-supervised learning models context large-scale LM pretraining remain unanswered: Is semi-supervised training still beneficial presence large scale pretraining largeU? Should used in-domain LM pretraining pseudo-label generation? How pseudo-label based semi-supervised models implemented? How different semi-supervised strategies affect performances regarding different sizes, different sizes, etc. In paper, conduct comprehensive studies behavior semi-supervised learning NLP presence large-scale language model pretraining. We use task text classification example, method easily adapted different NLP tasks. Our work sheds important lights behavior semi-supervised learning models: find presence in-domain pretraining LM , open-domain LM pretraining unnecessary, able achieve better performance pretraining in-domain dataset ; in-domain pretraining strategy pseudo-label based strategy lead significant performance boosts, former performing better larger , latter performing better smaller , combination performing best; pseudo-label based strategies, self-training yields better performances small, joint training combination yields better performances large. Using semi-supervised learning models, able achieve performance around accuracy 50 training data points IMDB dataset, competitive performance 96.6 full dataset. More importantly, work marks initial step toward understanding behavior semi-supervised learning models context large-scale pretraining. The rest paper organized follows: related work detailed Section 2. Different strategies training semi-supervised models shown Section 3. Experimental results findings shown Section 4, followed brief conclusion Section 5."," The goal of semi-supervised learning is to utilize the unlabeled, in-domain dataset $U$ to improve models trained on the labeled dataset $D$.     Under the context of   large-scale language-model  pretraining,   how we  can make the best use of   $U$   is poorly understood:   Is semi-supervised learning still beneficial   with the presence of  large-scale pretraining?  Should $U$ be used for in-domain LM pretraining or pseudo-label generation? How should the pseudo-label based semi-supervised model    be actually implemented? How different semi-supervised strategies  affect performances regarding $D$ of different sizes, $U$ of different sizes, etc.   In this paper, we conduct comprehensive studies  on  semi-supervised learning in the  task of text classification   under the context of  large-scale LM pretraining. Our studies shed important  lights on the  behavior of semi-supervised learning methods.   We find that:    with the presence of  in-domain LM pretraining  on $U$, open-domain LM pretraining \cite{devlin2018bert}  is unnecessary, and we are able to achieve better performance with pretraining on  the in-domain dataset $U$;  both the in-domain pretraining strategy and the pseudo-label based strategy introduce  significant performance boosts,  with the former performing better with larger $U$,  the latter performing better with smaller $U$, and the combination leading to the largest performance gain;   vanilla self-training  yields better performances when $D$ is small, while joint training on the combination of  $D'$ and $D$ yields better performances when $D$ is large.   %We use the task of text classification as an example,  the method of which can be easily adapted to different NLP tasks.  Using semi-supervised learning strategies, we are able to achieve a performance of around $93.8\%$ accuracy with only 50 training data points on the IMDB dataset, and   a competitive performance of 96.6$\%$ with the full  IMDB dataset.  Our work marks an initial step toward understanding the behavior of semi-supervised learning models under the context of large-scale pretraining.\footnote{Code, models and datasets  can be found at https://github.com/ShannonAI/Neural-Semi-Supervised-Learning-for-Text-Classification}"
"\todo{Completely rewrite - emphasize many methods proposed learning embeddings learn representations entities knowledge base typically based text entity's Wikipedia article surrounding local context mentions entity . % \clm{I would ""context surrounding mentions entity -- otherwise looks like redundant making clear calling henceforth, tho stylistic} context surrounding mentions entity Recent advances neural EL involved methods pretraining entity embeddings using link graph Wikipedia learn related entities words . Similar word embeddings, past work shown embeddings reside high-dimensional pseudo-semantic space, entities close space semantically similar . % \glarionov{""with entities close space being...} However, little work done understand information different entity embeddings capture underlying entities information affects downstream performance. Our goal work identify semantic information entity representations determine information linked performance downstream EL tasks. For this, develop series probing tasks, previously used examine lexical syntactic properties neural model layers sentence encoders decoders neural machine translation systems . % \glarionov{I would group two citations end readability} % \ees{for lexical syntactic properties [this split, move info citations]}. We extract structured data entities using DBpedia context words Wikipedia anchor links create probing tasks designed evaluate knowledge-based distributional semantic contents different entity embedding models. We compare five entity embedding methods, first two downstream EL tasks. We probe learned embeddings evaluate semantic information important downstream tasks represented different models. % \ees{We show strong relationship probing task performance performance downstream EL tasks. [too long, break up]} We find pretrained entity embedding methods generally effective representing distributional knowledge-based semantic information models generate embeddings byproduct training EL task. These improved representations lead better performance EL tasks, best model showing high performance distributional knowledge-based semantic tasks. We find entity embeddings trained predict related words entities skipgram-like model able learn fine-grained entity type information specific relationship types entities without explicitly providing information. Our primary contributions work to: % 1) describe methods evaluating semantic information learned methods 2) to\clm{either move first ""to"" ""1)"", delete one} empirically demonstrate importance information creating models entities use downstream tasks.\clm{I agree Liz bullet point this, want highlight contributions -- easier reviewers} % \ees{maybe bullet point two put 1) .. 2) make mad easy scan get} Our hope information provide guidance developing architectures better combine explicit structured information text improve methods representing entities used variety downstream tasks, similar existing word embeddings. Our methods additionally used potentially detect deficiencies new representation methods biases learned attributes probing tasks. % biases current methods probing .\clm{You might want briefly address means detects bias, otherwise question could feel unanswered reader's head}","  \todo{Complete rewrite} Pretrained entity embedding methods have shown strong results in entity linking  systems compared to methods that generate entity representations from text descriptions. Prior work has shown that these embeddings inhabit a pseudo-semantic space, but the semantic information they contain has not been thoroughly explored nor have  they been compared with other representations for differences in information.  We introduce methods for probing learned entity representations for information about their entity types, relationships, and context words using Wikipedia anchors and DBPedia structured data and use them to compare five entity embedding models. We show that improved representation of all types of semantic information is linked to improved performance on two downstream EL tasks. Our results provide potential directions for further research to better incorporate explicit semantic information into neural entity linking models."
"In section, mention different tokenization techniques SLT explain perspective problem. We mentioned basics SLT NMT. From research perspective, NMT methods provide successful results good tokens SL vides. Therefore, tokenization seen crucial part research. Firstly, visual properties involved tokenization part. Secondly, generic approach obtain strong tokens SLs. In addition that, clear discrete tokens obtained better translation quality. For reason, extend meaning tokenization NSLT covers overall process prepare frames NMT module. \par For spoken spoken languages, generally use words tokens feed NMT module. The current state-of-the-art method converts tokens continuous embeddings reach semantic representation. While learning translation, word embedding also trained learn relationship words. Eventually, meaningful embedding obtained NMT module seen Figure . Based this, may good idea learn good representation signs replace word embeddings achieve advancements NSLT NMT done. This representation cross-lingual; learning open problem. Our research mainly focused problem. Before introducing approach, discuss existing three tokenization approaches following subsection. \subsection{Input Tokenization NSLT} \par The first approach using glosses tokens. Glosses intermediate word-like representations signs words sentences. Therefore, directly applicable NMT framework without effort. However, certain shortcomings method. Firstly, glosses rarely exist real life. Gloss annotation requires laborious process special expertise. Secondly, glosses unique SLs. Therefore, SL requires special effort obtain glosses whereas sentences commonly available. The last drawback mistake gloss level produce dramatic meaning differences translation, since glosses high level annotations, similar words. \par The second approach first one terms tokens. On top that, approach learns extract glosses frames. In words, method uses glosses explicit intermediate representations seen Figure . It eliminates search tokenization, needs special network frame gloss conversion. There two main concerns. The first one network frame gloss conversion still dependent gloss annotations. The second clear glosses upper bound SLT sufficient evidence. The problem immature result provides clues whether glosses may restrict translation quality. The third approach called frame-level tokenization. This approach establish explicit intermediate representation seen Figure . It aims learn good sign embeddings replace word-embeddings. However, golden way represent signs embeddings feed NMT module. Furthermore, clear length embedding be. Embeddings obtained frame extracted inner short clips video. In addition that, representation learned sentence-video pairs trained outside NSLT system. There several ways frame-level tokenization. However, main difference gloss level tokenization discrete representation eliminated. If find proper one, would several advantages. The first one resulting framework applied SL translation task without requiring annotation. The second advantage opportunity inject additional supervision. The representations would trained different tasks different datasets whereas gloss level tokenization cannot cover different SLs. The third one token length adjusted. To boost translation speed, number tokens reduced pre-determined number."," In this thesis, we propose a multitask learning based method to improve Neural Sign Language Translation  consisting of two parts, a tokenization layer and Neural Machine Translation . The tokenization part focuses on how Sign Language  videos should be represented to be fed into the other part. It has not been studied elaborately whereas NMT research has attracted several researchers contributing enormous advancements. Up to now, there are two main input tokenization levels, namely frame-level and gloss-level tokenization. Glosses are world-like intermediate presentation and unique to SLs. Therefore, we aim to develop a generic sign-level tokenization layer so that it is applicable to other domains without further effort. \par We begin with investigating current tokenization approaches and explain their weaknesses with several experiments. To provide a solution, we adapt Transfer Learning, Multitask Learning and Unsupervised Domain Adaptation into this research to leverage additional supervision. We succeed in enabling knowledge transfer between SLs and improve translation quality by 5 points in BLEU-4 and 8 points in ROUGE scores. Secondly, we show the effects of body parts by extensive experiments in all the tokenization approaches. Apart from these, we adopt  3D-CNNs to improve efficiency in terms of time and space. Lastly, we discuss the advantages of sign-level tokenization over gloss-level tokenization. To sum up, our proposed method eliminates the need for gloss level annotation to obtain higher scores by providing additional supervision by utilizing weak supervision sources."
"Sentiment polarity detection regarded one significant research problems opinion extraction natural language processing . In recent years, plenteous growth internet random access e-devices facilitate generation voluminous reviews opinions textual form social media online platforms. Most reviews express consumers feedback toward products services received. Several business companies, well online marketers, take advantage feedbacks provide praiseworthy services consumers. In addition customer makes perfect decision based previous reviews receiving products services. Sentiment detection computational technique attempts uncover viewpoint user towards specific entity. It aims identify contextual polarity text contents positive, neutral negative . Sentiment analysis detection shown remarkable impact business community, whereby taking account user opinions communities ensure sustainability product services. The restaurant one business, customers opinions utilized improve quality foods, environments, services. Pompous lifestyle assorted food habits led significant increase number people restaurants. To collect excellence services, customers instinct look restaurant reviews visit it. Therefore, reviewing restaurant via internet become ecumenical trend. Besides, abundant amount positive reviews make restaurant symbol faith towards customers. Also, assist restaurant reach pinnacle success. In contrast, without sufficient amount positive reviews, becomes difficult gain attention new customers restaurant. Sometimes, restaurant negative reviews loses trustworthiness customers, turned reducing profit. Straightforwardly, users opinions specific criteria food quality, ambience service standards restaurant enough influence customers liking. However, would wrong say customers inclination reluctance towards restaurant depends amount positive negative reviews. Therefore, restaurants appreciate consents well opinions customers. Nevertheless, scrutinizing every reviews one one time consuming well cumbersome task. Further, govern surveys, requires plenty amount investment money human resources. Considering fact explosive growth visitors well user preferences, requires automatic system comprehend contextual polarity reviewer opinions posted different online platforms including Facebook, Twitter, company website, blogs. Nevertheless, sentiment classification challenging research issue resource-poor language like Bengali. The inadequacy benchmark dataset limited amount e-textual contents reviews Bengali language resulted sentiment classification task complicated. Deep learning algorithms effective tackle complications classify sentiments correctly . One main advantage algorithms ability capture semantic information long texts. This paper proposed deep learning-based sentiment classification technique classify sentiment form reviews. By taking consideration current constraints sentiment analysis low resource languages, paper contributions illustrate following:"," The amount of textual data generation has increased enor-mously due to the effortless access of the Internet and the evolution of various web 2.0 applications. These textual data productions resulted because of the people express their opinion, emotion or sentiment about any product or service in the form of tweets, Facebook post or status, blog write up, and reviews. Sentiment analysis deals with the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer闁炽儲鐛 attitude toward a particular topic is positive, negative, or neutral. The impact of customer review is significant to perceive the customer attitude towards a restaurant. Thus, the automatic detection of sentiment from reviews is advantageous for the restaurant owners, or service providers and customers to make their decisions or services more satisfactory. This paper proposes, a deep learning-based technique  to classify the reviews provided by the clients of the restaurant into positive and negative polarities. A corpus consists of 8435 reviews is constructed to evaluate the proposed technique. In addition, a comparative analysis of the proposed technique with other machine learning algorithms presented. The results of the evaluation on test dataset show that BiLSTM technique produced in the highest accuracy of 91.35\%.  \keywords{Natural language processing \and Opinion mining \and Embedding features \and Deep learning \and Sentiment classification \and Sentiment corpus.}"
"% Storytelling central part human socialization entertainment. Many popular forms storytelling throughout history \---such novels, plays, television, movies\--- passive audience experiences. However, gaming interesting medium interactivity large part entertainment experience, interactivity storytelling often conflict: much player freedom means storyline may never explored, hand, many restrictions player freedom risks reducing gaming passive medium. Thus, interactivity storytelling important challenge gaming, much design effort put striking balance entertaining gameplay compelling storytelling. As gaming technology advances, new opportunities interactive storytelling present themselves. Better storage technology made telling longer, intricate stories possible, better graphical capabilities helped foster immersive gaming experiences. Advances artificial intelligence lead challenging opponents, realistic NPC behavior, benefits. Better procedural content generation algorithms help ensure unique gameplay experiences stay fresh longer. Finally, recent breakthroughs language modeling present new opportunity: language, thus stories, potentially generated demand. In paper, introduce novel game collaborative storytelling, human player artificial intelligence agent construct story together. The game starts AI agent reciting one curated set story starters \---opening sentences meant kick-start participants' storytelling creativity\--- human player responds adding line, refer story continuation, story. The AI agent human player take turns adding continuations story human player concludes story. The game designed restrictions possible contrasts traditional storytelling settings narrative fixed advance. Collaborative storytelling builds rich tradition collaboration storytelling includes Dungeons Dragons, improvisational comedy, theater. It could useful tool encouraging creativity overcoming writer's block, well entertaining game right. Our end goal make possible intelligent agents, robot companions avatars , play collaborative storytelling game, shown Figure. %Our supplementary material includes simulation scenario, including real stories constructed humans collaborating Web-only version current system\footnote{Stories edited brevity.}. Our primary contributions follows:","   Storytelling plays a central role in human socializing and entertainment. However, much of the research on automatic storytelling generation assumes that stories will be generated by an agent without any human interaction. In this paper, we introduce the task of collaborative storytelling, where an artificial intelligence agent and a person collaborate to create a unique story by taking turns adding to it. We present a collaborative storytelling system which works with a human storyteller to create a story by generating new utterances based on the story so far. We constructed the storytelling system by tuning a publicly-available large scale language model on a dataset of writing prompts and their accompanying fictional works. We identify generating sufficiently human-like utterances to be an important technical issue and propose a sample-and-rank approach to improve utterance quality. Quantitative evaluation shows that our approach outperforms a baseline, and we present  qualitative evaluation of our system's capabilities."
"The vast amounts scientific literature provide significant source information biomedical research. Using literature identify relations entities important task various applications . Existing approaches biomedical relation extraction usually fall one two categories. Mention-level extraction aims classify relation pair entities within short span text . In contrast, pair-level extraction aims classify relation pair entities across entire paragraph, document corpus. For mention-level pair-level relation extraction, recent work focused representation learning. This considered one major steps towards making progress artificial intelligence . Representations relations understand context particularly important biomedical research, identifying fruitful targets crucial due high costs experimentation. Learning representations likely require large amounts unsupervised data due scarcity labelled data domain. Recent mention-level methods based using large unsupervised models Transformer networks learn representations sentences containing pairs entities. These representations used inputs much smaller models, perform supervised relation classification . Recent pair-level methods based encoding mention pair entities, designing mechanism pool encodings single representation. This representation used classify relation entity pair . However, representation learning methods mention-level pair-level extraction typically use point estimate representation. As result, may struggle capture nature true, potentially complex relations pair entities. For example, Figure shows sentences two entity pairs demonstrate relation statements different, typically depending biological circumstances . Such nuanced relations difficult capture single point estimate. We hypothesise true underlying relation entity pair, relation multimodal . The sentences containing pair textual observations underlying relations. We therefore propose probabilistic model uses continuous latent variable represent true relation entity pair. The distribution sentence containing pair conditioned latent variable. In order able model complex relations entity pair, use infinite mixture distribution latent representation. Our model provides unified architecture learning representations relations entity pairs mention pair level. We show posterior distribution latent variable used mention-level relation classification. We also demonstrate prior distribution model used pair-level classification. On tasks, achieve results competitive strong baselines model fewer parameters significantly faster train. The code released \url{ https://github.com/BenevolentAI/RELVM} %.","     Extracting biomedical relations from large corpora of scientific documents is a challenging natural language processing task. Existing approaches usually focus on identifying a relation either in a single sentence  or across an entire corpus . In both cases, recent methods have achieved strong results by learning a point estimate to represent the relation; this is then used as the input to a relation classifier. However, the relation expressed in text between a pair of biomedical entities is often more complex than can be captured by a point estimate. To address this issue, we propose a latent variable model with an arbitrarily flexible distribution to represent the relation between an entity pair. Additionally, our model provides a unified architecture for both mention-level and pair-level relation extraction. We demonstrate that our model achieves results competitive with strong baselines for both tasks while having fewer parameters and being significantly faster to train. We make our code publicly available."
"Human communication inherently multi-modal nature. Our expressions tone voice augment verbal communication.\ This include vocal features like speaking rate, intonation visual features like facial expressions . Non-verbal communication important tasks involve higher level cognitive expressions like emotions , persuasiveness mental health analysis . We focus multi-modal approach emotion recognition humans fundamentally express emotions verbally using spoken words , well acoustic signals visual expressions . Getting large-scale labeled datasets emotion recognition challenging.\ Our primary motivation paper study effective utilization large unlabeled datasets improve performance multi-modal emotion recognition systems.\ The signals consider speech, visual information spoken text.\ Our motivation stems popular use pre-trained models natural language, speech visual understanding tasks circumvent data limitations.\ BERT popular model natural language understanding trained using self-supervision.\ Devlin et al. use masked language modeling task Wikipedia corpus pre-training.\ The model successfully fine-tuned improve performance several tasks like question answering general language understanding evaluation benchmarks . Self-supervised learning also successfully applied speech based applications.\ Schneider et al.\ use unsupervised pre-training speech data distinguishing audio sample future noise samples.\ Fine-tuning model shows state art results automatic speech recognition . Liu et al.\ show BERT-like pre-training approach applied speech.\ By predicting masked frames instead masked words, performance tasks like speaker recognition,\ sentiment recognition phoneme classification improved. For emotion recognition, Tseng et al.\ show text-based self-supervised training outperform state art models. The authors use language modeling task, involves predicting word given context, pre-train model.\ Another area work leveraged unlabeled data detection localization visual objects spoken words multi-modal input.\ Harwath et al.\ train audio-visual model image-audio retrieval task.\ The models trained learn joint audio-visual representation shared embedding space.\ This model learn recognize word categories sounds without explicit labels.\ Motivated success approaches, study similar methods applied multi-modal emotion recognition.\ To best knowledge, joint self-supervised training approach using text, audio visual inputs well explored emotion recognition. Multi-modal emotion recognition models well studied literature typically outperform uni-modal systems .\ These models need combine inputs varying sequence lengths.\ In video, sequence lengths audio visual frames differ length text tokens orders magnitude.\ There considerable prior work fusing multi-modal features. Liang et al.\ studied multiple fusion techniques multi-modal emotion recognition sentiment analysis.\ Their methods included early late fusion modalities, dynamic fusion graph based network.\ They showed graph fusion model outperforms methods.\ Early fusion graph fusion techniques require alignment various modalities.\ Late fusion performed without alignment, allow interaction features different modalities frame level.\ To overcome limitation,\ Tsai et al.\ introduce cross-modal transformer .\ It scales features using cross-modal attention.\ In process, modalities projected sequences equal lengths, eliminating need alignment.\ This architecture successfully applied problems like emotion recognition, sentiment analysis speech recognition .\ Recently, another transformer-based method combine multi-modal inputs introduced Rahman et al. , uses multi-modal adaptation gate. In paper, propose using pre-training scheme BERT, extend model uses audio, visual text inputs. We discuss relevance approach Section .\ The multi-modal representations learned pre-training fine-tuned emotion recognition.\ We evaluate efficacy pre-training approach.\ We also perform experiments understand importance modality CMU-MOSEI dataset provide case-studies interpret results. This paper organized follows.\ In Section describe model architecture self-supervised approach pre-training, along motivation self-supervised learning choose.\ In Section , discuss training setup data.\ We present results analysis Section conclude Section .","  Emotion recognition is a challenging task due to limited availability of in-the-wild labeled datasets.\ Self-supervised learning has shown improvements on tasks with limited labeled datasets in domains like speech and natural language.\ Models such as BERT learn to incorporate context in word embeddings, which translates to improved performance in downstream tasks like question answering.\ In this work, we extend self-supervised training to multi-modal applications.\ We learn multi-modal representations using a transformer trained on the masked language modeling task with audio, visual and text features.\ This model is fine-tuned on the downstream task of emotion recognition.\ Our results on the CMU-MOSEI dataset show that this pre-training technique can improve the emotion recognition performance by up to 3\% compared to the baseline."
"% A long desired goal AI systems play important collaborative role everyday lives. Currently, predominant approach visual question answering relies encoding image question black-box transformer encoder. These works carry complex computation behind scenes yield single token prediction output . Consequently, struggle provide intuitive human readable form justification consistent predictions. In addition, recent study demonstrated unsettling behaviours models: tend ignore important question terms, look wrong image regions, undesirably adhere superficial even potentially misleading statistical associations. To address insufficiency, reformulate VQA full answer generation task rather classification one, i.e. single token answer. The reformulated VQA task requires model generate full answer natural language justification. We find state-of-the-art model answers significant portion questions correctly wrong reasons. To learn correct problem solving process, We propose \modelabbrevname{} , transparent neural-symbolic reasoning framework solves problem step-by-step mimicking humans. A human would first \underline{l}ook image, \underline{r}ead question, \underline{t}hink multi-hop visual reasoning, finally \underline{a}nswer question. % Following intuition, \modelabbrevname{} deploys four neural modules, mimicking one problem solving step humans would take: % A scene graph generation module first converts image scene graph; A semantic parsing module parses question multiple reasoning instructions; A neural execution module interprets reason instructions one time traversing scene graph recurrent manner and; A natural language generation module generates full answer containing natural language explanations. The four modules connected hidden states rather explicit outputs. Therefore, whole framework trained end-to-end, pixels answers. In addition, since \modelabbrevname{} also produces human-readable output individual modules testing, easily locate error checking modular output. % % Our experiments GQA dataset show \modelabbrevname{} outperforms state-of-the-art model large margin full answer generation task. Our perturbation analyses removing relation linguistic cues questions confirm \modelabbrevname{} makes step towards truly understanding question rather smart guess superficial data correlations. % We discuss related work Appendix A. To summarize, main contributions paper three-fold: %","   The predominant approach to visual question answering  relies on encoding the image and question with a ``black-box'' neural encoder and decoding a single token as the answer like ``yes'' or ``no''. Despite this approach's strong quantitative results, it struggles to come up with intuitive, human-readable forms of justification for the prediction process. To address this insufficiency, we reformulate VQA as a full answer generation task, which requires the model to justify its predictions in natural language. We propose LRTA [Look, Read, Think, Answer], a transparent neural-symbolic reasoning framework for visual question answering that solves the problem step-by-step like humans and provides human-readable form of justification at each step. Specifically, LRTA learns to first convert an image into a scene graph and parse a question into multiple reasoning instructions. It then executes the reasoning instructions one at a time by traversing the scene graph using a recurrent neural-symbolic execution module. Finally, it generates a full answer to the given question with natural language justifications. Our experiments on GQA dataset show that LRTA outperforms the state-of-the-art model by a large margin  on the full answer generation task. We also create a perturbed GQA test set by removing linguistic cues  in the questions for analyzing whether a model is having a smart guess with superficial data correlations. We show that LRTA makes a step towards truly understanding the question while the state-of-the-art model tends to learn superficial correlations from the training data."
"Duplicate question detection important application information retrieval NLP . It allows systems recognize two questions share answer. This significant community forums, StackExchange\footnote{https://stackexchange.com/} increase effectiveness avoiding redundant questions displaying relevant answers search questions. It also important FAQ retrieval question answering systems . To learn DQD models \stackexchange{}, question pairs usually annotated duplication information extracted community-provided meta-data. Such annotations sparse domains, e.g., new \stackexchange{} forum providing support new product. Therefore, leveraging training signals either unsupervised data supervised data domains important . Pre-trained language models like BERT RoBERTA great unsupervised textual representations. Several recent efforts adapt PLMs domains interest self-supervised fine-tuning unsupervised domain data, shown promising several scenarios . We follow tune BERT \stackexchange{} domains obtain richer representations task DQD. Recently, -nearest neighbors applied PLM representations language modeling dialogue . We extend line study apply \cdknn{} cross-domain generalization DQD, models trained data source domain, applied data target domain. To so, represent pairs source target common representation space score target pairs using nearest neighbors source pairs. \figref{knnprocess} shows illustration procedure. % The specific properties \stackexchange{} DQD % important make approach effective. Our study AskUbuntu target source datasets , include several domains \stackexchange{} also Quora Sprint, reveals \cdknn{} effective compared cross-entropy classification pair representation space PLMs rich target domain, i.e., adapted unsupervised data target similar domains; source target domains large distributional shifts. We make following contributions: We present first study combining strengths \cdknn{} neural representations cross-domain generalization sentence matching task, i.e., DQD. Our experimental results cross-domain DQD demonstrate \cdknn{} rich question-pair representations advances results cross-entropy classification, especially shifts source target domains substantial.","  Duplicate question detection  is important to increase efficiency of  community and automatic question answering systems.  Unfortunately, gathering supervised data in a domain is time-consuming and expensive, and our ability to leverage annotations across domains is minimal.  In this work, we leverage neural representations and study nearest neighbors for  cross-domain generalization in DQD.   We first encode question pairs of the source and target domain in a rich representation space and then using a k-nearest neighbour retrieval-based method, we aggregate the neighbors' labels and distances to rank pairs. We observe robust performance of this method in different cross-domain scenarios of StackExchange, Spring and Quora datasets, outperforming cross-entropy classification in multiple cases. We will release our codes as part of the publication. % ervised adaptation to StackExchange domains by self-supervised finetuning of contextualized embedding models like BERt. %We show the effectiveness of this adaptation in scenarios when source domain comes from different types of distributions. %Our analysis also reveals that unsupervised domain adaptation on even small amounts of data boosts the performance significantly. %Further, we show how an approach based on nearest neighbors is effective  for this problem and outperforms training the full model using cross entropy."
"Learning vocabulary major component foreign language learning. In school context, initially vocabulary learning typically organized around words introduced text book. In addition incrementally growing vocabulary lists, textbooks also provide thematically organized word banks. When texts read, publisher teacher often provides annotations new vocabulary items appear text. A wide range digital tools developed support vocabulary learning, digital versions file cards digital text editions offering annotations. While applications serve needs formal learning setting initial foreign language learning phase, texts read primarily chosen systematically introduce language, later selection texts read principle follow individual interests student adult, boosts motivation engage book. Linking language learning functional goal someone actually wants achieve using language line idea Task-Based Language Teaching prominent strand foreign language education . Naturally, authentic texts accessible every learner, linguistically-aware search engines, FLAIR , make possible identify authentic texts right reading level rich language constructions next curriculum. Where unknown vocabulary reader encounters setting goes beyond around 2\% unknown words text present without substantial loss comprehension , many digital reading environments provide option look word dictionary. Yet, frequently looking words context cumbersome distracts reader world book trying engage with. Relatedly, one key criteria TBLT learners rely resources complete task . But naturally require pre-task activities preparing learner able successfully tackle task . But learner systematically prepare reading text book interested reading? In paper, explore computational linguistic methods distributional semantics, morphological clustering, exercise generation combined graph-based learner models answer question conceptually practice. On practical side, developed application supports vocabulary learning pre-task activity reading self-selected book. The conceptual goal automatically organize lexical semantic space given English book form graph makes possible sequence vocabulary learning way efficiently exploring space visualize graph users open learner model showing growing mastery book's lexical space. Lexical learning fostered monitored automatically generated multi-gap activities support learning revision words contexts occur book. In section discuss book text chosen learner turned graph encoding lexical space learner needs engage read book, words morphologically related word families automatically identified compactly represented graph . In section turn use graph representation lexical semantic space book determine reader's learning path represent growing lexical knowledge spreading activation graph. In section, conceptual ideas realized application. We discuss new learner cold-start problem avoided using quick word recognition task implemented, discussing content selection activity generation practice testing activities. Section provides conceptual evaluation approach compares related with, wrapping conclusion section. % learning rare words English purpose? And % relevance learning entire frequency bands words unclear % How combining goal reading book systematic % learning needed so? Problem: Individuals % interested different books, individual differ language % competence vocabulary knowledge. So vocabulary % books organizing individually adaptive organization % Goal: % % Solution: %","   How can a learner systematically prepare for reading a book they are   interested in? In this paper, we explore how computational   linguistic methods such as distributional semantics, morphological   clustering, and exercise generation can be combined with graph-based   learner models to answer this question both conceptually and in   practice. Based on the highly structured learner model and concepts   from network analysis, the learner is guided to efficiently explore   the targeted lexical space. They practice using multi-gap learning   activities generated from the book focused on words that are central   to the targeted lexical space. As such the approach offers a unique   combination of computational linguistic methods with concepts from   network analysis and the tutoring system domain to support learners   in achieving their individual, reading task-based learning goals."
"Speaking listening common ways humans convey understand daily conversations. Nowadays, speech interface also widely integrated many applications/devices like Siri, Google Assistant, Alexa . These applications use speech recognition-based approaches understand spoken user queries. Like speech, text also widely used medium people converse. Recent advances language modeling representation learning using deep learning approaches proven promising understanding actual meanings textual data, capturing semantical, syntactical, contextual relationships textual words corresponding learned fixed-size vector representations. Such computational language modeling difficult case speech spoken language understanding unlike textual words, spoken words different meanings word spoken different tones/expressions , difficult identify sub-word units speech variable-length spacing overlapping spoke-words , use stress/emphasis syllables multi-syllabic word increase variability speech production . Although textual word representations capture semantical, syntactical, contextual properties, fail capture tone/expression. Using speech/audio data training spoken-word representations results semantically syntactically poor representations. So paper, propose novel spoken-word representation learning approach called STEPs-RL uses speech text entanglement learning phonetically sound spoken-word representations, captures acoustic contextual features also semantically, syntactically, phonetically sound. STEPs-RL trained supervised manner learned representations capture phonetic structure spoken-words along inter-word semantic, syntactic, contextual relationships. We validated proposed model evaluating semantical syntactical relationships learned spoken-word representations four widely used word similarity benchmark datasets, comparing performance textual word representations learned Word2Vec \& FastTexT , investigating phonetical soundness generated vector space.","   In this paper, we present a novel multi-modal deep neural network architecture that uses speech and text entanglement for learning phonetically sound spoken-word representations. STEPs-RL is trained in a supervised manner to predict the phonetic sequence of a target spoken-word using its contextual spoken word's speech and text, such that the model encodes its meaningful latent representations. Unlike existing work, we have used text along with speech for auditory representation learning to capture semantical and syntactical information along with the acoustic and temporal information. The latent representations produced by our model were not only able to predict the target phonetic sequences with an accuracy of 89.47\% but were also able to achieve competitive results to textual word representation models, Word2Vec \& FastText , when evaluated on four widely used word similarity benchmark datasets. In addition, investigation of the generated vector space also demonstrated the capability of the proposed model to capture the phonetic structure of the spoken-words. To the best of our knowledge, none of the existing works use speech and text entanglement for learning spoken-word representation, which makes this work first of its kind."
"Recent decades brought increase use computer-based tools practically every field human endeavor. The field education exception. Such tools used augment even completely replace traditional face-to-face teaching methods. The emergence online learning platforms necessitated development means enable learning activities, group discussions, performed use technology. One example learning platform IMapBook software suite aimed increasing literacy reading comprehension skills elementary school-aged children use web-based eBooks, embedded games related contents, well moderated group discussions. Keeping discussions constructive relevant difficult usually requires discussion moderator present times. This limit opportunities discussions take place. Leveraging methods insights fields artificial intelligence machine learning, attempt develop systems automatically classify messages different categories detect discussion veered course necessitates intervention. Our research tackles problem using compilation discussions obtained pilot studies testing effectiveness using IMapBook software suite 4th-grade classrooms. The studies performed 8 different Slovene primary schools and, total, included 342 students. The discussions consist 3541 messages along annotations specifying relevance book discussion, type, category, broad category. The ID book discussed time posting also included, poster's school, cohort, user ID, username. Each message also manually translated English aid non-Slovene-speaking researchers. The use Slovene language presents unique challenges applying standard language processing methods, many readily available other, widely spoken languages. Given sequence one newly observed messages, want estimate relevance message actual topic discussion. Namely, want assign messages two categories 閳 relevant book discussed not. Additionally, want predict whether message question, answer, statement call type message. Finally, want assign category label message possible labels either 'chatting', 'switching', 'discussion', 'moderating', 'identity'. Building predictive model capable performing predictions acceptable performance would allow us experiment including new level automation IMapBook software suite well related products. The research insights also applicable areas online user comments content moderation."," The increasing adoption of technology to augment or even replace traditional face-to-face learning has led to the development of a myriad of tools and platforms aimed at engaging the students and facilitating the teacher's ability to present new information. The IMapBook project aims at improving the literacy and  reading comprehension skills of elementary school-aged children by presenting them with interactive  e-books and letting them take part in moderated book discussions. This study aims to develop and  illustrate a machine learning-based approach to message classification that could be used to  automatically notify the discussion moderator of a possible need for an intervention and also to collect other useful information about the ongoing discussion. We aim to predict whether a message posted in the discussion is relevant to the discussed book, whether the message is a statement, a question, or an answer, and in which broad category it can be classified. We incrementally enrich our used feature subsets and compare them using standard classification algorithms as well as the novel Feature stacking method.  We use standard classification performance metrics as well as the Bayesian correlated t-test to show  that the use of described methods in discussion moderation is feasible. Moving forward, we seek to  attain better performance by focusing on extracting more of the significant information found in the  strong temporal interdependence of the messages."
"The Winograd Schema Challenge\/ proposed means test whether machine human-like intelligence. It alternative well known Turing Test\/ designed motivation reducing certain problematic aspects affect TT. Specifically, TT subjective nature, WSC provides purely objective evaluation; whereas passing TT requires machine behave deceptive way, WSC takes form positive demonstration intelligent capability. The core problem WSC resolve reference pronouns occurring natural language sentences. To reduce possibility task accomplished procedures based superficial statistical characteristics, rather `understanding' sentence, specify test sentences used WSC, constructed pairs, similar structure differ key word phrase, correct referent pronoun different two cases. This sentence pair, together indication pronoun resolved pair two possible candidates, called Winograd Schema. The following example Winograd schemas original WSC273 data set : \item The trophy fit brown suitcase {\bf it} small\/. \end{enumerate} design Winograd schemas require background knowledge resolve pronoun, evidence thinking\/. Therefore, exclude sentences resolved statistical association within sentence. In paper, introduce keyword method define domains Winograd schemas. To best knowledge, first work use keywords defining domains WSC explore high-level patterns them. To use domain-specific high-level patterns, also develop advanced high-level knowledge-based reasoning method modifying method . Furthermore, suggest simple ensemble method combines knowledge-based reasoning machine learning. By experiments domain-specific data set, ensemble method gives better performance single method. Lastly, also propose `robust' accuracy measure objective improving switching method ."," The Winograd Schema Challenge\/  is a common sense reasoning task that requires background knowledge. In this paper, we contribute to tackling WSC in four ways. Firstly, we suggest a keyword method to define a restricted domain where distinctive high-level semantic patterns can be found. A thanking domain was defined by keywords, and the data set in this domain is used in our experiments. Secondly, we develop a high-level knowledge-based reasoning method using semantic roles which is based on the method of \cite{sharma:2019}. Thirdly, we propose an ensemble method to combine knowledge-based reasoning and machine learning which shows the best performance in our experiments. As a machine learning method, we used Bidirectional Encoder Representations from Transformers  \citep{kocijan:2019}. Lastly, in terms of evaluation, we suggest a `robust' accuracy measurement by modifying that of \cite{trichelair:2018}. As with their switching method, we evaluate a model by considering its performance on trivial variants of each sentence in the test set."
"% overview + widespread applications Text classification, extensively applied fundamental cornerstone natural language processing applications, sentiment analysis, spam detection spoken dialogue systems, widely studied decades. In general, almost NLP tasks cast classification problems either document, sentence, word level. Here focusing means narrow sense, i.e., given sequence tokens arbitrary length, predicting likely categorization belongs to. % conventional approaches, CNN/LSTM pros, + cons: lack efficacy capture latent representations. Considerable compelling neural approaches text classification task empirically demonstrated remarkable behaviors recent years, orchestrate compose semantic syntactic representations texts central. Much work concentrated learning composition distributional word representations categorization, wherein plenty deep learning methods adopted, TextCNNs, RCNNs, recurrent neural networks , FastText, BERT, etc. Most learn word representations firstly projecting one-hot encoding token pretrained randomly initialized word embedding matrices acquire dense real-valued vectors, feed neural models classification. These methods, however, exploited low-dimensional semantic representations sample text supervised way. Some argued unsupervised latent representations topic cluster modeling mined latent variable models may benefit. maintained word clustering could deliver useful semantic information grouping words corpus thus promote classification accuracy. Moreover, incorporated neural topic models Variational Autoencoder classification tasks discover latent topics document level encode co-occurrence words bag-of-words statistics. Learning corpus-level representation administer enrichment globally informative features thus favorable task performance. There plenty works adopting VAE learning latent variables boost text classification performance. Nevertheless, remain problems cannot directly treat sampled latent space VAE clustering centroids since mechanism modulate representation different samples towards different mean variance better discrimination purpose Gaussian distribution assumption. alleviate issues minimizing distance learnable latent representation latent variable models clustering centers generated statistical clustering approaches. % trained with, projecting word indices dense word representations. Grounding this, design ad hoc Clustering-Enchanced neural model jointly learns distributional clustering alignment domain-aware clustering centroids word representations Euclidean hidden semantic space text classification, vector space assumption words similar meanings close other. Instead directly treating latent variables clustering centroids, employ co-adaptation strategy minimize difference hidden variables trainable clustering centroids initialized traditional clustering algorithms soft alignments. In present work, propose cluster-token alignment mechanism assigning relevance probability distribution clusters token, indicating likely tokens correlated cluster center. In clustering centroids co-regulated learned latent variables regarded domain- task-specific feature indicators. Our work illustrates jointly adapting clustering centroids learning cluster-token alignment holds promise advancing text classification performance incorporating clustering-aware representations. Our key contributions are: {} % graph GCN -> time cost building graphs % cluster explanation, importance, usage, application % inspiration % learn latent variables unsupervised approaches aid interaction multi-hop clusters word representations % contribution: % 1. unsupervised approaches learn maneuver cluster representation % 2. proposed cluster-token alignment mechanism assign word implied clusters % 3. methods outperform previous approaches eight different datasets short texts long texts. % % % % % \begin{figure*}[thb] % %"," Distributional text clustering delivers semantically informative representations and captures the relevance between each word and semantic clustering centroids. We extend the neural text clustering approach to text classification tasks by inducing cluster centers via a latent variable model and interacting with distributional word embeddings, to enrich the representation of tokens and measure the relatedness between tokens and each learnable cluster centroid. The proposed method jointly learns word clustering centroids and clustering-token alignments, achieving the state of the art results on multiple benchmark datasets and proving that the proposed cluster-token alignment mechanism is indeed favorable to text classification. Notably, our qualitative analysis has conspicuously illustrated that text representations learned by the proposed model are in accord well with our intuition."
"The use deep learning processing natural language becoming standard, excellent results diverse range tasks. Two state-of-the-art architectures text-related modeling long short-term memory networks~ transformers~. LSTMs recurrent neural networks process text sequentially, meaning process text one token time, building internal representation hidden states network. Due recurrent nature LSTM, degrades efficiency parallel processing, well demonstrated improvements performance, models based transformer architecture gradually replacing LSTMs across many tasks. Transformers process text parallel, using self-attention positional embeddings model sequential nature text. A common trend using transformers first pre-train large monolingual corpora abstract, general-purpose objective, fine-tune specific task, text classification. For example, BERT architecture uses transformers pretrained masked language modelling order sentences prediction tasks build general language understanding model. During fine-tuning specific downstream task, additional layers added BERT model, model trained specific data capture specific knowledge required perform task. Most research natural language processing area focuses English, ignoring fact English specific terms low amount information expressed morphology . In work, focus adapting modern deep neural networks, namely LSTMs BERT, several morphologically rich languages, explicitly including morphological information. The languages analyze contain rich information grammatical relations morphology words instead particles relative positions words . For comparison, also evaluate models English. Although previous research shown state art methods BERT already captures information contained morphology~, experiments involve several languages rich morphology neural networks could benefit explicit morphological features. Specifically, present methods combine BERT separately encoded morphological properties: universal part speech tags universal features . We evaluate three downstream tasks: named-entity recognition , dependency parsing , comment filtering . We perform similar experiments LSTM networks compare results architectures. Besides English, analyze eight languages: Croatian, Estonian, Finnish, Latvian, Lithuanian, Russian, Slovene Swedish. The choice languages reflects mix different language groups , able obtain sufficient resources , due coverage EU EMBEDDIA project. Our experiments show addition morphological features mixed effects depending task. Across tasks added morphological features improve performance, show benefit LSTM-based models even features noisy benefit BERT-based models features high quality , suggesting BERT models already capture morphology language; however, room improvement either designing pre-training objectives capture properties high-quality features available. The remainder paper structured follows. In Section, present different attempts use morphological information machine learning, particular neural networks, well overview recent work three evaluation tasks. In Section, describe used datasets properties. In Section, present baseline models models additional morphological information, whose performance discuss Section. Finally, summarize work present directions research Section."," Currently, deep learning approaches are superior in natural language processing due to their ability to extract informative features and patterns from languages. Two most successful neural architectures are LSTM and transformers, the latter mostly used in the form of large pretrained language models such as BERT.  While cross-lingual approaches are on the rise, a vast majority of current natural language processing techniques is designed and applied to English, and less-resourced languages are lagging behind. In morphologically rich languages, plenty of information is conveyed through changes in morphology, e.g., through different prefixes and suffixes modifying stems of words. The existing neural approaches do not explicitly use the information on word morphology. We analyze the effect of adding morphological features to LSTM and BERT models. As a testbed, we use three tasks available in many less-resourced languages: named entity recognition , dependency parsing , and comment filtering . We construct sensible baselines involving LSTM and BERT models, which we adjust by adding additional input in the form of part of speech  tags and universal features. We compare the obtained models across subsets of eight languages. Our results suggest that adding morphological features has mixed effects depending on the quality of features and the task. The features improve the performance of LSTM-based models on the NER and DP tasks, while they do not benefit the performance on the CF task. For BERT-based models, the added morphological features only improve the performance on DP when they are of high quality , while they do not show any practical improvement when they are predicted. As in NER and CF datasets manually checked features are not available, we only experiment with the predicted morphological features and find that they do not cause any practical improvement in performance."
"Past work found variability speech signals often poorly modeled, despite recent advances speech representation learning using deep neural networks . An important source acoustic variability comes accent information embedded speech signals . Non-native accents frequently observed second language spoken, mainly caused first language background non-native speakers. The accent strength non-native speaker dependent amount transfer native language, generally influenced variety variables age second-language learning one valuable predictors . However, accent variability often overlooked modeling language, consequently high-resource languages English often treated homogeneous . That assumption problematic is, example, shown comparing number native non-native speakers English, latter group almost twice large former group . It therefore important accurately model pronunciation variation using representations speech allow variability incorporated. Traditionally, pronunciations often represented evaluated phonetically transcribing speech . However, transcribing speech using phonetic alphabet time consuming, labor intensive, interference transcriber variation might lead inconsistencies . Additionally, fine-grained pronunciation differences relevant studying accented speech may captured using set discrete symbols . \citet{acoustic-measure} therefore introduced acoustic-only measure comparing pronunciations. In method, represented accented speech 39-dimensional Mel-frequency cepstral coefficients , used compute acoustic-based non-native-likeness ratings non-native native speakers English. They found strong correlation automatically determined acoustic-based non-native-likeness ratings native-likeness ratings provided human raters . This result close to, still equal performance phonetic transcription-based approach . \citet{acoustic-measure} also conducted several small-scale experiments investigate whether fine-grained characteristics human speech captured compared phonetic transcription-based pronunciation difference measure. Their results showed acoustic-only measure captured segmental differences, intonational differences, durational differences, method invariant characteristics recording device. The quality MFCC representations known dependent presence additive noise . Recent work shown self-supervised representation learning models less affected noise, well-equipped model complex non-linear relationships . For example, models learn meaningful representations basis read English speech without direct supervision. Fine-tuning models using transcribed speech resulted representations resembled phonetic structure, offered significant improvements downstream speech recognition tasks . Consequently, paper, employ self-supervised neural models create automatically determined acoustic-only pronunciation difference measure, investigate whether results improved performance compared MFCC-based approach \citet{acoustic-measure} phonetic transcription-based approach \citet{wieling2014a}. In following, compare evaluate several neural models, namely , \citep[subsequently denoted ]{schneider2019wav2vec}, , \citep[subsequently denoted ]{baevski2019vq}, \citep[subsequently denoted ]{baevski2020wav2vec}. We evaluate performance algorithms using two different datasets. The first identical dataset used \citet{acoustic-measure} \citet{wieling2014a}. The second new dataset focuses accented speech single group non-native speakers human native-likeness judgements also available. For reproducibility, provide code via \url{https://github.com/Bartelds/neural-acoustic-distance}. The performance model assessed comparing obtained neural acoustic-only pronunciation differences phonetic transcription-based pronunciation distances, MFCC-based acoustic-only pronunciation distances, human perception. To understand aspects pronunciation variation neural models capture, conduct several additional small-scale experiments, line \citet{acoustic-measure}."," Variation in speech is often represented and investigated using phonetic transcriptions, but transcribing speech is time-consuming and error prone. To create reliable representations of speech independent from phonetic transcriptions, we investigate the extraction of acoustic embeddings from several self-supervised neural models.  We use these representations to compute word-based pronunciation differences between non-native and native speakers of English, and evaluate these differences by comparing them with human native-likeness judgments.  We show that Transformer-based speech representations lead to significant performance gains over the use of phonetic transcriptions, and find that feature-based use of Transformer models is most effective with one or more middle layers instead of the final layer.  We also demonstrate that these neural speech representations not only capture segmental differences, but also intonational and durational differences that cannot be represented by a set of discrete symbols used in phonetic transcriptions."
"In paper focus problem integrating syntactic features neural architecture Frame-Semantic parsing process. Frame-semantic parsing task extracting full semantic frame structures text, defined Frame Semantics theory . %Semantic frames conceptual structures describing general situations, evoked language target words referred lexical units. Each frame enriched set semantic roles called frame elements, defining specific participants described situation. %An example sentence annotated Frame Semantics shown Figure . From theoretical perspective, Frame-Semantic parsing decomposed three sub-tasks: 1) Target Identification -- identifying target words acting lexical units; 2) Frame Identification -- disambiguating target possible frame; 3) Semantic Role Labeling -- extracting possible frame elements given frame. Early neural approaches focused regard integration features extracted dependency trees, FI SRL tasks , positive results. Amongst all, SRL task received attention investigating methods injecting syntax neural models, mostly due strict correlation syntax argument structures . Several solutions proposed, setting new baselines general Frame-semantic parsing specific SRL corpora. These include use dependency path embeddings , application Graph Convolutional Networks learn representations dependency graphs , restricting set candidate arguments using pruning algorithms . Multi-task learning also applied, either directly supervising attention learn dependency parsing TI SRL, implicitly bias learned encoded representations jointly training simplified syntactic dependency parser , semantic dependency parser FI SRL . % Although effective, approaches focused exploiting syntactic dependencies rather constituency information, partly dependencies suited encoded features learned attention mechanisms. %, express relationships words. Semantic roles technically provided syntactic constituents, directly cast argument boundaries word sequences. This demonstrated also earlier work SRL, relied constituency derived features . It follows using constituency information beneficial, especially reconstructing argument boundaries dependencies would require unbounded number hops among words, making problem hard model neural architectures . Following idea, two recent approaches attempted rely constituency information improve SRL performance. \citet{wang-etal-2019-best} use linearised representations constituency trees different learning settings, either extracting salient features, multi-task learning, combining approaches auto-encoding fashion. \citet{marcheggiani19:axiv}, instead, train GCN SRL objective learn constituent representations, infused words GCN via message-passing operation . In paper, foster idea relying constituency information every sub-task Frame-semantic parsing, namely TI, FI, SRL. We train GCN learn specific constituency representations, used turn compute syntactic paths constituency nodes. Our approach similar \citet{marcheggiani19:axiv}, although significantly differs in: i) initialisation topology underlying graph; ii) lower number required parameters; iii) way syntactic information infused every word representation, i.e. computing node-to-node syntactic paths. We show approach improves state-of-the-art main Frame-semantic parsing benchmark, i.e.\ FrameNet corpus , single TI SRL tasks, FI joint-learning setting. Moreover, demonstrate generality approach testing network CoNLL 2005 dataset ."," We study the problem of integrating syntactic information from constituency trees into a neural model in Frame-semantic parsing sub-tasks, namely Target Identification , Frame Identification , and Semantic Role Labeling . We use a Graph Convolutional Network to learn specific representations of constituents, such that each constituent is profiled as the production grammar rule it corresponds to. We leverage these representations to build syntactic features for each word in a sentence, computed as the sum of all the constituents on the path between a word and a task-specific node in the tree, e.g. the target predicate for SRL. Our approach improves state-of-the-art results on the TI and SRL of \texttildelow$1\%$ and \texttildelow3.5\% points, respectively , when tested on FrameNet 1.5, while yielding comparable results on the CoNLL05 dataset to other syntax-aware systems. %When testing the approach on the FrameNet 1.5 corpus, our system gives us strong insight on the role of syntax on TI, while improving the state-of-the-art on SRL of 3.5 points.  %While it yields comparable results on the CoNLL05 dataset."
"KR\&R systems work well certain knowledge-rich domains typically involve set axioms rules, use structured queries datasets, need precise logical inference explanations. Formal logic-based reasoning engines Cyc Ergo successfully deployed domains legal, healthcare finance. One main advantages using systems transparency 閳 underlying reasoning system well-understood justified end-users. However, several known drawbacks logic-based approaches. For one, inference procedures highly brittle require precise matching/unification logical terms formulae order construct complete explanation. Secondly, traditional reasoners don閳ユ獩 deal uncertainty well , whereas rules real-world applications often probabilistic contextual. Thirdly, systems suffer knowledge acquisition problem . Often, rules hand-coded, approach doesn閳ユ獩 scale general. Our problem domain Natural Language Understanding , area issues mentioned come play 閳 need acquire use implicit background knowledge understand text, application rules differently based context, use imperfect/fuzzy alignment concepts relations reasoning. To address issues, devise novel FOL-based reasoner, called Braid. Braid includes backward forward chainer, assumption based reasoner constraint solver. This paper refers backward chaining component, refer Braid-BC. Braid-BC supports rules confidences, uses notion custom unification functions dynamic rule generation overcome brittle matching knowledge-gap problem prevalent traditional reasoning engines. The custom-unifiers based statistical techniques, long propose score mappings terms two logical propositions . For example, use neural matching functions unifiers. Their purpose help reasoner find proofs even goals, rule conditions and/or facts align perfectly. The dynamic rule-generator given target proposition knowledge base input, outputs scored list hypothesized rules could used prove proposition. The purpose rule-generation connect dots knowledge required inference missing static KB. We describe two DRG implementations - one using neural rule generation model fine-tuned dataset crowd-sourced causal rules, known GLUCOSE , second uses rule-template based technique. We describe reasoning algorithms used Braid-BC, implementation distributed task-based framework builds proof/explanation graphs input query highly scalable manner. Our approach shares similarities RETE framework matching production rules makes several novel extensions: primarily backward chaining via heuristic best-first search , leverage Master-Worker architecture Master builds main proof graph Workers make local inferential updates, define general functions Unifiers Provers lets us plug various reasoning strategies combining standard reasoning statistical approaches .","  Traditional symbolic reasoning engines, while attractive for their precision and explicability, have a few major drawbacks: the use of brittle inference procedures that rely on exact matching  of logical terms, an inability to deal with uncertainty, and the need for a precompiled rule-base of knowledge . These issues are particularly severe for the Natural Language Understanding  task, where we often use implicit background knowledge to understand and reason about text, resort to fuzzy alignment of concepts and relations during reasoning, and constantly deal with ambiguity in representations.   To address these issues, we devise a novel FOL-based reasoner, called Braid, that supports probabilistic rules, and uses the notion of custom unification functions and dynamic rule generation to overcome the brittle matching and knowledge-gap problem prevalent in traditional reasoners. In this paper, we describe the reasoning algorithms used in Braid-BC , and their implementation in a distributed task-based framework that builds proof/explanation graphs for an input query in a scalable manner. We use a simple QA example from a children闁炽儲鐛 story to motivate Braid-BC闁炽儲鐛 design and explain how the various components work together to produce a coherent logical explanation."
"Humans compose documents record preserve information. As information carrying vehicles, documents written using different layouts represent diverse sets information variety different consumers. In work, look problem document understanding documents written English. Here, take term document understanding mean automated process reading, interpreting, extracting information written text illustrated figures contained within document's pages. From perspective practitioners machine learning, survey covers methods build models automatically understand documents originally composed human consumption. Document understanding models take documents segment pages documents useful parts , often using optical character recognition ~ level document layout analysis. These models use information understand contents document large, e.g. region bounding box corresponds address. In survey, focus aspects document understanding granular level discuss popular methods tasks. Our goal summarize approaches present modern document understanding highlight current trends limitations. In Section, discuss general themes modern NLP document understanding provide framework building end-to-end automated document understanding systems. Next, Section, look best methods OCR encompassing text detection text transcription . We take broader view document understanding problem section, presenting multiple approaches document layout analysis: problem locating relevant information page. Following this, discuss popular approaches information extraction ."," Documents are a core part of many businesses in many fields such as law, finance, and technology among others. Automatic understanding of documents such as invoices, contracts, and resumes is lucrative, opening up many new avenues of business. The fields of natural language processing and computer vision have seen tremendous progress through the development of deep learning such that these methods have started to become infused in contemporary document understanding systems. In this survey paper, we review different techniques for document understanding for documents written in English and consolidate methodologies present in literature to act as a jumping-off point for researchers exploring this area."
"Sequence labeling one commonly used techniques solving natural language understanding tasks named-entity recognition slot filling. Furthermore, tasks, state-of-the-art results typically based deep neural networks . However, performance models highly dependent availability large amounts annotated data. Moreover, compared classification tasks, require one label sample, sequence learning tasks require series token-level labels entire sequence, makes time-consuming costly annotation process. \\ This problem mitigated using active learning , achieves improved performance fewer annotations strategically selecting examples annotate . There two major strategies active learning, namely, diversity-based sampling uncertainty-based sampling . % 闉愵剠璧 闉氭尗鍎婇爟 Traditionally, uncertainty-based sampling common pool-based AL approach. However, previous work pointed focusing uncertainty leads sampling bias . It creates pathological scenario selected samples highly similar other, clearly indicates inefficiency. This may cause problems, especially case noisy redundant real-world datasets. Another approach diversity-based sampling, wherein model selects diverse set represent input space without adding considerable redundancy . This approach select samples ensuring maximum batch diversity. However, approach might select points provide little new information, thereby reducing uncertainty model. Certain recent studies classification tasks implemented algorithm named Batch Active learning Diverse Gradient Embeddings . This algorithm first computes embedding unlabeled sample based induced gradients, geometrically picks instances space ensure diversity . Although proves robust improvement performing image classification task, performance sequence labeling tasks yet unproven. \\ In study, investigated practical active learning algorithms consider uncertainty diversity sequence labeling tasks different datasets models. Moreover, suggested method expand BADGE weighted sampling based sequence length ensure cost-effective labeling. This simple modification positive implication tends select cost-effective samples. The proposed model trades uncertainty diversity selecting diverse samples gradient space depending parameters final layer, which, currently available models focus uncertainty. To best knowledge, study first apply diverse gradient embedding sequence labeling task. We experimented CoNLL 2003 English, ATIS, Facebook Multilingual Task Oriented Dataset . Accordingly, empirically demonstrated proposed method consistently outperformed baseline method including Bayesian AL disagreement , shows state-of-the-art performance NER task, across datasets, tasks model architectures.","  Recently, several studies have investigated active learning  for natural language processing tasks to alleviate data dependency. However, for query selection, most of these studies mainly rely on uncertainty-based sampling, which generally does not exploit the structural information of the unlabeled data. This leads to a sampling bias in the batch active learning setting, which selects several samples at once. In this work, we demonstrate that the amount of labeled training data can be reduced using active learning when it incorporates both uncertainty and diversity in the sequence labeling task. We examined the effects of our sequence-based approach by selecting weighted diverse in the gradient embedding approach across multiple tasks, datasets, models, and consistently outperform classic uncertainty-based sampling and diversity-based sampling."
"} {I}{n} past decade, seen emergence various Knowledge Graphs , YAGO DBPedia. They achieved great success academic industrial applications, ranging recommendation Question Answering. However, KGs far complete, limits benefits transferred knowledge. Relation Extraction vital step complete KGs extracting relations entities texts. It nontrivial since relation type may various textual expressions, meanwhile, different types relations also described words. Such ambiguity relations texts challenges supervision RE models. Due expensive human annotation cost, distant supervision proposed automatically annotate mappings sentences relations. It assumes two entities participate relation, a.k.a., triple express another relation . As shown Figure, given triple , collect two sentences include entity pair . Clearly, first sentence expresses similar meaning given relation type, second one implies another type relation city of, brings noise training corpora\footnote{As term relation refer either relation type relation instance , paper, simplify use term relation relation type unless otherwise stated.}. To highlight informative sentences, many existing works introduce attention mechanism assign sentences different learning weights. In terms quantity, hand, training data collected distant supervision concentrate mainly relations, leading issue lack sufficient annotations remaining relations. Take widely used dataset, New York Times , example, present number training instances relation Figure. Unsurprisingly, annotations long-tail concerning different relations, tail relations suffer insufficient training corpora. More specifically, relation refers multiple entity pairs smaller similar respect RE prediction distributions common textual contexts. Therefore, capture relation proximity precise general way remains challenging. Another major challenge distinguish different relations, case knowledge transfer introduces bias towards prediction proximate relations. For example, mentioned above, /location/us\_state/capital /location/fr\_region/capital indicate capital relation, difference two United States entities French entities. DPEN incorporates entity type information learn relation-specific classifier dynamically. However, entity type information sparse KGs , challenging scalability. To address first issue, propose learn relation prototypes capture proximity relationship among relations involved entity pairs. Inspired Prototypical Networks, represent relation prototype centroid training data, data point defined difference pair entity embeddings, namely implicit mutual relation . Given entity pair, compute implicit mutual relation distance relation prototype. These proximities suggest possible relations classifier, makes correct predictions extracting discriminative signals supportive sentences. Relation prototypes also enhanced prior information , applied arbitrary sentence encoder. To address second issue, enhance entity embeddings textual information implicit mutual relation learning. In specific, construct entity co-occurrence graph unlabeled texts modeling first-order second-order structural proximity. The massive textual contexts helpful infer entity types distinguishment. Besides, long-tail entity pairs also benefit additional textual information. We summarize main contributions follows: A preliminary version work published conference ICDE 2020. We summarize main changes follows: %The rest paper organized follows. In Section, formulate problem overview framework, Section introduces proposed method detail. We report promising experiment results real-world datasets Section. Section covers related works. Finally, conclude paper Section.","   Relation Extraction  is a vital step to complete Knowledge Graph  by extracting entity relations from texts. However, it usually suffers from the long-tail issue. The training data mainly concentrates on a few types of relations, leading to the lack of sufficient annotations for the remaining types of relations. In this paper, we propose a general approach to learn relation prototypes from unlabeled texts, to facilitate the long-tail relation extraction by transferring knowledge from the relation types with sufficient training data. We learn relation prototypes as an implicit factor between entities, which reflects the meanings of relations as well as their proximities for transfer learning. Specifically, we construct a co-occurrence graph from texts, and capture both first-order and second-order entity proximities for embedding learning. Based on this, we further optimize the distance from entity pairs to corresponding prototypes, which can be easily adapted to almost arbitrary RE frameworks. Thus, the learning of infrequent or even unseen relation types will benefit from semantically proximate relations through pairs of entities and large-scale textual information.      We have conducted extensive experiments on two publicly available datasets: New York Times and Google Distant Supervision. Compared with eight state-of-the-art baselines, our proposed model achieves significant improvements . Further results on long-tail relations demonstrate the effectiveness of the learned relation prototypes. We further conduct an ablation study to investigate the impacts of varying components, and apply it to four basic relation extraction models to verify the generalization ability. Finally, we analyze several example cases to give intuitive impressions as qualitative analysis. Our codes will be released later.    %Relation Extraction  is a paramount step to complete Knowledge Graph by extracting entity relations from texts. However, it usually suffers from the long-tail issue, as the training data mainly concentrates on a few types of relations, leading to the lack of sufficient annotations for the remaining types of relations. In this paper, we propose a general approach to learn relation prototypes from unlabeled texts, to facilitate the long-tail RE by transferring knowledge from those with sufficient data. We learn prototypes as an implicit factor between entities, to reflect the meanings of relations and their proximities. Specifically, we construct an entity co-occurrence graph from texts, and capture structural proximities for embedding learning. Furthermore, we optimize the distance from entity pairs to corresponding prototypes, which can be easily adapted to many RE framework. We have conducted extensive experiments on two publicly available datasets. Compared with eight state-of-the-art baselines, our model achieves significant improvements . Further results on long-tail relations demonstrate the effectiveness of the learned relation prototypes. We further conduct an ablation study to investigate the impacts of varying components and the generalization ability. Finally, we analyze several example cases to give intuitive impressions as qualitative analysis."
"% Understanding BERT works important. % presence blackbox nlp indication research community values ability understand internals deep neural networks. Pre-trained transformer models BERT currently ubiquitous within natural language processing research demonstrated improvements topics sentiment analysis semantic parsing . The widespread development use models led increased effort interpret models' decisions . % * understanding models important society % * BERT used over, important understand BERT As defined \citet{doshivelez2017rigorous}, model interpretability ``the ability [of model] explain present understandable terms human''. Intuitively, interpretable model easier understand, debug improve. % It's hard understand BERT % * neural model many, many parameters % * pre-training + fine-tuning newer training scratch -> read literature introductions/motivations Interpreting modern pre-trained transformer models difficult. First, modern deep learning models hundreds millions parameters, scale continues increase . Understanding impact single parameter nearly impossible models densely connected. Combined sheer number parameters, manual analysis infeasible. Secondly, pre-training fine-tuning required state-of-the-art performance, effort focused alternative pre-training methods . % Understanding impacts fine-tuning still well understood. \todo{do I need citation here?} % Previous work attempted use attention Previous work uses BERT's self-attention mechanism interpret model's predictions . However, body work shows models' attention mechanisms cannot interpreted single-sequence classification tasks. % We apply bert sequence classification task We apply BERT two BERT-based models existing sentence classification task proposed \citet{aesw}. We compare BERT-based models' performances previous baselines use methods presented \citet{vashishth2019attention} \citet{deyoung-etal-2020-eraser} evaluate BERT's interpretability single-sequence classification tasks. We find fine-tuning teach BERT recognize previously unknown patterns natural language BERT interpretable attention-based models analyzed \citet{jain-wallace-2019-attention} \citet{vashishth2019attention}. To summarize, key contributions paper are: % nice % * BERT applied % * professional data set, baseline, human-annotated % * marked spans edits % To best knowledge, BERT applied Automatic Evaluation Scientific Writing task."," Pre-trained transformer language models such as BERT are ubiquitous in NLP research, leading to work on understanding how and why these models work. Attention mechanisms have been proposed as a means of interpretability with varying conclusions. We propose applying BERT-based models to a sequence classification task and using the data set's labeling schema to measure each model's interpretability. We find that classification performance scores do not always correlate with interpretability. Despite this, BERT's attention weights are interpretable for over 70\% of examples."
". % % final paper: en-us version % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. } Recently, neural machine translation demonstrated impressive performance improvements became de-facto standard . However, like neural methods, NMT data-hungry. This makes challenging train model low-resource scenarios . Researchers developed promising approaches low-resource NMT. Among data augmentation , transfer learning , pre-trained models . But approaches rely external data bi-text. To date, rare see work effective use bilingual data low-resource NMT. In general, way feeding samples plays important role training neural models. A good instance popular shuffle input data robust training state-of-the-art systems. More systematic studies issue found recent papers . For example, pointed deep neural networks tend prioritize learning ``easy'' samples first. This agrees idea curriculum learning easy-to-hard learning strategy yield better convergence training. In NMT, curriculum learning new. Several research groups applied large-scale translation tasks although discuss issue low-resource setup . The first question define ``difficulty'' training sample. Previous work resorts functions produce difficulty score training sample. This score used reorder samples training. But methods type enforce static scoring strategy somehow disagrees fact sample difficulty might changing model updated training. Another assumption behind curriculum learning difficulty sample fit competence model training. Researchers implicitly modeled issue hand-crafted curriculum schedules simple functions , whereas in-depth discussion yet. In paper, continue line research curriculum learning low-resource NMT. We propose dynamic curriculum learning method address problems discussed above. The novelty DCL two-fold. First, define difficulty sample decline loss . In way, measure hard sentence translated via real objective used training. Apart this, DCL method explicitly estimates model competence model updated, one select samples newly-updated model enough competence learn. DCL general applicable NMT system. In work, test Transformer-based system three low-resource MT benchmarks different sized data selected WMT'16 En-De task. Experimental results show system outperforms strong baselines several curriculum learning-based counterparts.","      Large amounts of data has made neural machine translation  a big success in recent years.    But it is still a challenge if we train these models on small-scale corpora.   In this case, the way of using data appears to be more important.    Here, we investigate the effective use of training data for low-resource NMT.   In particular, we propose a dynamic curriculum learning  method to reorder training samples in training.   Unlike previous work, we do not use a static scoring function for reordering.   Instead, the order of training samples is dynamically determined in two ways - loss decline and model competence.   This eases training by highlighting easy samples that the current model has enough competence to learn.    We test our DCL method in a Transformer-based system.   Experimental results show that DCL outperforms several strong baselines on three low-resource machine translation benchmarks and different sized data of WMT'16 En-De."
"One fundamental problems Natural Language Processing learning distributed encoding sentences, stepping stone many NLP tasks, sentence classification, sentiment analysis natural language inference. The multitude approaches addressing problem categorised according sentence represented. %In bag-of-words models, sentences represented words multisets encodings generated averaging word representations The simpler sentence representation bag-of-words, depicts sentences words multisets ignoring word order. Despite simple representation, used obtain meaningful sentence encodings . Sequence representation overcomes limitation considering sentence ordered sequence words. It allows building models progressively constructs sentence encoding, processing one word time. Recurrent Neural Network Long-Short Term Memory probably famous models use representation.% produce sentence embeddings. %This representation reflects read text, word word. %One major drawbacks bag-of-words models insensitive word order. Sequence-based models overcome limitation considering sentence sequence words . A key aspect sentences, missing sequential processing, compositionality. For example, sentence ""The sky blue grass green"" obtained composing two sub-phrases ""The sky blue"" ""the grass green"" conjunction ""and"". The intrinsic compositionality sentences makes suitable tree representation, whole sentence built terms sub-phrases turn defined terms smaller constituents; base cases words since atomic piece information. This representation takes name constituency tree. In Fig.\ show constituency tree sentence ""Effective too-tepid biopic"": leaves words internal nodes represent syntactic categories constituents whole sentence. There many models compute sentence encoding starting constituency tree. For purposes, restrict discussion bottom-up Recursive Neural Networks . The parsing direction constrained structure constituency trees, information leaf nodes. In domain, refer term composition function indicate state-transition function computes representation tree node combining representation constituents . Then, hidden state root taken sentence encoding. The Matrix-Vector Recurrent Neural Network Recursive Neural Tensor Network apply RecNN architecture binary constituency trees using complex composition functions. % apply RecNN architecture binary constituency trees. Moreover, propose two new architectures leverage complex composition functions: MV-RNN RNTN. In MV-RNN , every word sub-phrase encoded vector matrix. When two constituents combined matrix one multiplied vector vice versa, obtaining composition function parameterised constituents participate it. MV-RNN requires huge number parameters, since composition matrix attached word. RNTN solves limitation defining tensor composition function. The tensor allows obtain composition function parameters directly constituent participate it. extends well known Long-Short Term Memory architecture tree-structured data. They propose two different Tree-LSTMs : -ary Tree-LSTM defines composition function considers constituent order child-sum Tree-LSTM ignores order. However, former model applied binary constituency trees. The latter applied dependency trees, another kind tree representation sentences, scope. In recent years, Tree-LSTM used building block develop sophisticated models. For example, , , , build new Tree-LSTM models define dynamic composition functions depending syntactic categories . Instead, introduces Bidirectional Tree-LSTM takes advantage parsing directions: bottom-up top-down. As stated before, constituency trees intrinsically bottom-up; end, author introduces first bottom-up pass, called head lexicalization, propagate information leaves root. All models applied binary constituency trees. Thus far, shown models compute sentences encodings starting binary constituency trees. This simplification solves one crucial problem tree-structured data: variable number child nodes. However, price pay loss structural information. For example, Fig.\ Fig.\ report constituency binary constituency tree sentence ""Effective too-tepid biopic"". Comparing two representation, observe binary tree one node breaks ternary relation non-binary tree; general, break node child nodes, need add new nodes. All new nodes create chain moves away child nodes n-ary relation parent. The composition obtained considering one child time, happens sequence representation. Hence, binarisation removes equality among child nodes, risk weakening contribution child nodes moved far away parent strengthening contribution ones remain close. As far know, work builds model suitable non-binary constituency trees TreeNet . The idea consider child nodes chain: hidden state node depends hidden state left sibling rightmost child. Even model works non-binary trees, composition function expressed binary since always composes two elements. We discuss observation details Sec. . The definition models non-binary constituency trees requires go beyond standard definition composition function. Standard RecNNs define learnable composition functions based summation contribution constituent. proposed generalisation sum-based composition functions leveraging expressive multi-affine maps represented tensors. The exponential number parameters respect tree out-degree required full-tensorial approach controlled applying tensor decomposition. The tensorial models outperform sum-based models, especially tree out-degree increases . Within scope paper, unveil non-binary constituency trees effectively exploited improve predictive performance NLP task, showing powerful composition functions necessary take advantages rich representation. To end, introduce two new Tree-LSTM models leverage canonical tensor decomposition: former suitable binarised constituency trees, latter process general non-binary constituency trees imposing weight sharing tensor decomposition factors. Finally, test quality sentence encodings produced models different NLP tasks, showing combination rich representation powerful composition function able outperform baseline models using number parameters."," Processing sentence constituency trees in binarised form is a common and popular approach in literature. However, constituency trees are non-binary by nature. The binarisation procedure changes deeply the structure, furthering constituents that instead are close. In this work, we introduce a new approach to deal with non-binary constituency trees which leverages tensor-based models. In particular, we show how a powerful composition function based on the canonical tensor decomposition can exploit such a rich structure. A key point of our approach is the weight sharing constraint imposed on the factor matrices, which allows limiting the number of model parameters. Finally, we introduce a Tree-LSTM model which takes advantage of this composition function and we experimentally assess its performance on different NLP tasks."
"Searching code fragments common activity software development. The advent large code repositories like GitHub\footnote{https://github.com/} StackOverflow\footnote{https://stackoverflow.com/} increased number developers rely repositories search reuse existing code . Traditional Information Retrieval techniques work well code search retrieval tasks due limited shared vocabulary source code natural language search text . Often, developers new programming language, search code snippets context-free natural language. The choice words used search may overlap code snippets leading failure traditional information retrieval systems. Therefore, need gain deeper understanding code text order find semantically relevant code snippet. Consider example developer functional requirement validate age always lesser alert otherwise. The developer tasked enforce check Java. A naive Java developer familiar language might make query based requirement as: java check condition correctness. The top 10 results\footnote{As December 9, 2019} StackOverflow discuss assert keyword. A programming friendly query java boolean check assert keyword results code snippets demonstrating steps top result StackOverflow. Use deep neural network models shown tremendous improvements many tasks across domains including language tasks . This success largely attributed, part, ability learn meaningful relationships among words documents efficiently represent way semantically equivalent words tend similar representations . One family models popular determining text similarity Siamese networks. First introduced , typical Siamese network consists two identical sub networks share weights. They work tandem different inputs output networks evaluated distance measure also acts scoring function. This successfully applied many similarity tasks image domain recently text domain well . Another useful property models capability learn fewer data examples . Since code treated special kind text data, one possible way approach problem Semantic Code Search treat similarity task objective bring semantically equivalent code snippets natural language descriptions closer. Therefore, study application Siamese networks code corresponding text descriptions semantic code search. We apply multiple variations base Siamese network model two different datasets semantic code search study efficacy. We take state art baselines - datasets observe Siamese networks improve baseline results invariably . Finally, present analysis performance different Siamese network architectures explored identify conditions improved performance. The rest paper organized follows. We introduce relevant prior art section . Next, section , provide background Siamese networks semantic code search introduce terminology. In section , describe approach different architectures investigated. In section , describe experiments present results. Finally section , perform detailed analysis observations, followed conclusions section . % \tikz \draw[] rectangle node[pos=.2]{Answer Here:};"," % Availability of large code repositories and discussion forums, has enabled code search as a common activity among developers. They tend to express their intent as a query in natural language to find examples of related code. However performance of such systems are restricted due to 1) limited shared vocabulary across code and user query and 2) lack of semantic understanding of the user query.   % In this work, we evaluate Siamese network for the task of code retrieval. Building on two sub network, our siamese model can jointly learn between code and its description and represent them based on their semantic distance. We evaluate the performance of applying siamese networks 1) as a stand-alone model directly feeding code and its description 2) as a model stacked on existing state of the art models. We experiment on 2 datasets and 3 baseline models, and conclude that applying siamese networking on top of base models yield better embedding and improves the performance of the code sesearch taks significantly.  With the increase in the number of open repositories and discussion forums, the use of natural language for semantic code search has become increasingly common. The accuracy of the results returned by such systems, however, can be low due to 1) limited shared vocabulary between code and user query and 2) inadequate semantic understanding of user query and its relation to code syntax. Siamese networks are well suited to learning such joint relations between data, but have not been explored in the context of code search. In this work, we evaluate Siamese networks for this task by exploring multiple extraction network architectures. These networks independently process code and text descriptions before passing them to a Siamese network to learn embeddings in a common space. We experiment on two different datasets and discover that Siamese networks can act as strong regularizers on networks that extract rich information from code and text, which in turn helps achieve impressive performance on code search beating previous baselines on $2$ programming languages. We also analyze the embedding space of these networks and provide directions to fully leverage the power of Siamese networks for semantic code search."
"We motivated problem labelling dataset word sense disambiguation, want use limited budget collect annotations reasonable number examples sense word. This task thought active learning problem , two nonstandard challenges. First, given word get set candidate labels knowledge base WordNet . However, label set necessarily representative occurs data: may exist labels knowledge base occur corpus sense rare modern English; conversely, may also exist true labels exist knowledge base. For example, consider word ``bass.'' It frequently used noun modifier, e.g., ``the bass alto good singers'', ``I play bass guitar''. It also commonly used refer type fish, music widely discussed online, fish sense word orders magnitude less common low-frequency sound sense internet text. The Oxford dictionary also notes bass referred fibrous material used matting chords, sense common modern English. We want method collects balanced labels common senses, ``bass frequencies'' ``bass fish'', ignores sufficiently rare senses, ``fibrous material''. Second, empirical distribution true labels may exhibit extreme skew: word sense usage often power-law distributed frequent senses occurring orders magnitudes often rare senses. When considered individually, neither constraints incompatible existing active learning approaches: incomplete label sets pose problem method relies classifier uncertainty exploration ; extreme skew label distributions studied guided learning framework wherein annotators asked explicitly search examples rare classes rather simply label examples presented system . But taken together, constraints make standard approaches impractical. Search-based ideas guided learning far sample efficient skewed label distribution, require mechanism annotators search examples correct label set undesirable ask annotators find examples actually occur corpus. Our approach follows. We introduce frequency threshold, , sense deemed ``sufficiently rare'' % ignored = p_y < \thresholdp_y\hat{p}_y$ using importance-weighted samples. Once found examples common classes, switch standard active learning methods find additional examples reduce classifier uncertainty. Overall, paper makes two key contributions. First, present Exemplar Guided Active Learning algorithm offers strong empirical performance extremely skewed label distributions leveraging exemplar embeddings. Second, identify stopping rule makes EGAL robust misspecified label sets prove robustness imposes logarithmic cost hypothetical approach knows correct label set. Beyond key contributions, also present new Reddit word sense disambiguation dataset, designed evaluate active learning methods highly skewed label distributions."," We consider the problem of wisely using a limited budget to label a small subset of a large unlabeled dataset. We are motivated by the NLP problem of word sense disambiguation. For any word, we have a set of candidate labels from a knowledge base, but the label set is not necessarily representative of what occurs in the data: there may exist labels in the knowledge base that very rarely occur in the corpus because the sense is rare in modern English; and conversely there may exist true labels that do not exist in our knowledge base. Our aim is to obtain a classifier that performs as well as possible on examples of each 闁炽儲绔穙mmon class闁 that occurs with frequency above a given threshold in the unlabeled set while annotating as few examples as possible from 闁炽儲绗re classes闁 whose labels occur with less than this frequency. The challenge is that we are not informed which labels are common and which are rare, and the true label distribution may exhibit extreme skew. We describe an active learning approach that  explicitly searches for rare classes by leveraging the contextual embedding spaces provided by modern language models, and  incorporates a stopping rule that ignores classes once we prove that they occur below our target threshold with high probability. We prove that our algorithm only costs logarithmically more than a hypothetical approach that knows all true label frequencies and show experimentally that incorporating automated search can significantly reduce the number of samples needed to reach target accuracy levels."
"Argumentation paramount process society, debating socially relevant topics requires high-quality relevant arguments. In work, deal problem argument search, also known argument retrieval. The goal develop \acrfull{arg_ret_sys} organizes arguments, previously extracted various sources , accessible form. Users formulate query access relevant arguments retrieved \acrshort{arg_ret_sys}. The query defined topic, e.g. Energy case \acrshort{arg_ret_sys} retrieves possible arguments without specification. Our work deals advanced case, query formulated form claim, user expects premises attacking supporting query claim. An example claim related topic Energy could ``We abandon Nuclear Energy"" supporting premise, e.g., ``Accidents caused Nuclear Energy longstanding negative impacts"". % A popular search methodology find relevant premises similarity search, representations retrieved premises similar representation query claim. However, noted by, relevance premise necessarily coincide pure text similarity. Therefore, authors advocate utilize similarity query claim claims \acrshort{arg_ret_sys} database retrieve premises assigned similar claims. However, \acrshort{arg_ret_sys} requires ground truth information premise claim assignments therefore limited applicability: Either information sources restricted sources information already available automatically inferred, expensive human annotations required. To mitigate problem keep original system's advantages, propose use machine learning model learn relevance premises claims. Using model, omit claim-claim matching step evaluate importance candidate premises directly query claim. Since relevance defined semantic level, design appropriate training task enable model learn semantic differences relevant non-relevant premises. Furthermore, essential subtask \acrshort{arg_ret_sys} ensure retrieved premises repeat ideas. Previous approaches employ clustering eliminate duplicates. However, clustering approaches often group data instances criteria expected users, also observed \gls{argument-mining} applications. For method, propose alternative clustering based idea core-sets, goal cover space relevant premises well possible. % This samplepaper.tex, sample chapter demonstrating % LLNCS macro package Springer Computer Science proceedings; % Version 2.20 2017/10/04 % \documentclass[runningheads]{llncs} % \usepackage{graphicx} \usepackage{xcolor} \usepackage{amsmath} \usepackage{amssymb} %\usepackage{ulem} \usepackage{multirow} \usepackage{booktabs} \usepackage{footnote} \makesavenoteenv{tabular} \makesavenoteenv{table} \usepackage{cite} \usepackage[ruled,vlined]{algorithm2e} \usepackage{float} \interfootnotelinepenalty=10000 % Used displaying sample figure. If possible, figure files % included EPS format. % % If use hyperref package, please uncomment following line % display URLs blue roman font according Springer's eBook style: \usepackage{hyperref} \renewcommand\UrlFont{\color{blue}\rmfamily} % equal contribution \makeatletter \newcommand{\printfnsymbol}[1]{% \textsuperscript{\@fnsymbol{#1}}% } \makeatother % \title{Diversity Aware Relevance Learning Argument Search} % %\titlerunning{Abbreviated paper title} % If paper title long running head, set % abbreviated paper title % \author{ Michael Fromm\thanks{equal contribution}\inst{1} %\orcidID{0000-0002-7244-4191} \and Max Berrendorf\printfnsymbol{1} \inst{1} %\orcidID{0000-0001-9724-4009} \and Sandra Obermeier \inst{1} \and Thomas Seidl \inst{1} %\orcidID{0000-0002-4861-1412} \and Evgeniy Faerman \inst{1} } \authorrunning{Fromm et al.} % First names abbreviated running head. % If two authors, 'et al.' used. \institute{Database Systems Data Mining, LMU Munich, Germany \\ \email{fromm@dbs.ifi.lmu.de}} \newcommand{\todo}[1]{\textcolor{red}{#1}} % Acronyms \usepackage[acronym]{glossaries} %\makeglossaries % Example % \newacronym{acrid}{ACR}{Acronym Clustering Representations} % \acrshort{arcrid} -> ACR % \acrlong{arcid} -> Acronym Clustering Representations % \acrfull{arcid} -> Acronym Clustering Representations \newacronym{argument-mining}{AM}{Argument Mining} \newacronym{arg_ret_sys}{ARS}{Argument Retrieval System} \newacronym{bert-based-premise-representation}{BERT}{BERT} \newacronym{claim-based-premise-representation}{CLAIM-SIM}{CLAIM-SIM} \newacronym{relevance-model}{relevance-model}{relevance model} % methods \newacronym{dumani-first512}{first512}{Dumani first512} \newacronym{dumani-sentences}{sentences}{Dumani sentences} \newacronym{dumani-sliding-window}{sliding}{Dumani sliding} \newacronym{bert-zero-shot-knn}{BERT Zero-Shot}{BERT Zero-Shot} \newacronym{learned-similarity-knn}{Learned Similarity}{Learned Similarity} \newacronym{biased-coreset}{Biased Coreset}{Biased Coreset} \newacronym{bert-zero-shot-clustered}{BERT Zero-Shot + Cluster}{} \DeclareMathOperator*{\argmax}{argmax} %\newcommand{\relevanceModel}{relevance model } % \newcommand{\dumaniFirst}{Dumani first512 } % \newcommand{\dumaniSentences}{Dumani sentences } % \newcommand{\dumaniSliding}{Dumani sliding } % \newcommand{\topSimilar}{Premise Similarity } % \newcommand{\topSimilarClusterRepresentatives}{Clustered Premise Similarity } % \newcommand{\mostImportant}{Premise Importance } % \newcommand{\BertNegatives}{Bert-Negatives } % \newcommand{\SimpleNegatives}{Simple-Negatives } % \newcommand{\SameTopicNegatives}{Same-Topic-Negatives } % disable hyperref glossaries \glsdisablehyper \keywords{Argument Similarity \and Argument Clustering \and Argument Retrieval}"," In this work, we focus on retrieving relevant arguments for a query claim covering diverse aspects. State-of-the-art methods rely on explicit mappings between claims and premises and thus cannot utilize extensive available collections of premises without laborious and costly manual annotation. Their diversity approach relies on removing duplicates via clustering, which does not directly ensure that the selected premises cover all aspects. This work introduces a new multi-step approach for the argument retrieval problem. Rather than relying on ground-truth assignments, our approach employs a machine learning model to capture semantic relationships between arguments. Beyond that, it aims to cover diverse facets of the query instead of explicitly identifying duplicates.  Our empirical evaluation demonstrates that our approach leads to a significant improvement in the argument retrieval task, even though it requires fewer data than prior methods. Our code is available at \url{https://github.com/fromm-m/ecir2021-am-search}."
"Speaker diarization process partitioning audio stream homogeneous segments according speaker identities. Thus, diarization determines ``who spoke when'' multi-speaker environment, variety applications conversations involving multiple speakers, meetings, television shows, medical consultations, call center conversations. In particular, speaker boundaries produced diarization system used map transcripts generated multi-speaker automatic speech recognition system speaker-attributed transcripts . Moreover, speaker embeddings inferred diarization help ASR system adapt to, focus speech targeted speaker . Conventional speaker diarization systems based clustering speaker embeddings. In approach, several components integrated single system: speech segments determined voice activity detection ; speech segments divided smaller chunks fixed size; speaker embeddings extracted speaker embedding extractors chunk; finally, speaker embeddings clustered map segment speaker identity . For embeddings, i-vectors , x-vectors , d-vectors commonly used. Clustering methods typically used speaker diarization agglomerative hierarchical clustering , k-means clustering , spectral clustering . Recently, neural network-based clustering explored . Clustering-based speaker diarization achieves good performance several shortcomings. First, relies multiple modules trained separately. Therefore, clustering-based systems require careful joint calibration building process. Second, systems jointly optimized minimize diarization errors; clustering particular unsupervised process. Finally, clustering accommodate overlapping speech naturally, even though recent work proposed ways handle regions simultaneously active speakers clustering . End-to-end neural diarization self-attention one approaches aim model joint speech activity multiple speakers. It integrates voice activity overlap detection speaker tracking end-to-end fashion. Moreover, directly minimizes diarization errors demonstrated excellent diarization accuracy two-speaker telephone conversations. However, EEND originally formulated limited fixed number speakers output dimension neural network needs prespecified. Several methods proposed recently overcome limitations EEND. One approach uses speaker-wise chain rule decode speaker-specific speech activity iteratively conditioned previously estimated speech activities . Another approach proposes encoder/decoder-based attractor calculation . The embeddings multiple speakers accumulated time course audio input, disentangled one-by-one, speaker identity assignment speech frame. However, state-of-the-art EEND methods work offline manner, means complete recording must available diarization output generated. This makes application impractical settings potentially long multi-speaker recordings need processed incrementally . In study, propose novel method perform EEND blockwise online fashion speaker identities tracked low latency soon new audio arrives, without much degradation accuracy compared offline system. We utilize incremental Transformer encoder, attend left contexts ignore right contexts, thus enabling blockwise online processing. Furthermore, incremental Transformer encoder uses block-level recurrence hidden states carry information block block, reducing computation time attending previous blocks. To knowledge, first method uses incremental Transformer encoder block-level recurrence enable online speaker diarization."," We present a novel online end-to-end neural diarization system, BW-EDA-EEND, that processes data incrementally for a variable number of speakers. The system is based on the Encoder-Decoder-Attractor  architecture of Horiguchi et al., but utilizes the incremental Transformer encoder, attending only to its left contexts and using block-level recurrence in the hidden states to carry information from block to block, making the algorithm complexity linear in time. We propose two variants: For unlimited-latency BW-EDA-EEND, which processes inputs in linear time, we show only moderate degradation for up to two speakers using a context size of 10 seconds compared to offline EDA-EEND. With more than two speakers, the accuracy gap between online and offline grows, but the algorithm still outperforms a baseline offline clustering diarization system for one to four speakers with unlimited context size, and shows comparable accuracy with context size of 10 seconds. For limited-latency BW-EDA-EEND, which produces diarization outputs block-by-block as audio arrives, we show accuracy comparable to the offline clustering-based system."
"% The first letter 2 line initial drop letter followed % rest first word caps. % % form use first word consists single letter: % {A}{demo} file .... % % form use need single drop letter followed % normal text : % {A}{}demo file .... % % Some journals put first two words caps: % {T}{his demo} file .... % % Here typical use ""T"" initial drop letter % ""HIS"" caps complete first word. {T}{here} many methods automatic speech recognition systems, GMM-HMM deep neural network based acoustic models . Recently, end-to-end speech recognition methods made significantly breakthroughs. Although ASR methods made lot progresses clean speech signals, performance could dramatically degraded noisy reverberation environments. In realistic environments, recorded speech signals always interfered various background noises reverberations. Therefore, improving robustness ASR important. This paper focuses boosting noise robustness end-to-end speech recognition. %In realistic environments, recorded speech signals always interfered various background noises reverberations. However, interferences dramatically degrade performance automatic speech recognition systems. In order boost noise robustness ASR, three mainstream methods. The first mainstream method adding speech enhancement component front-end ASR. Speech enhancement methods include spectral subtraction , Wiener filtering deep neural network based speech enhancement methods . However, speech enhancement optimizes models estimate target speech, different speech recognition part. Therefore, speech enhancement methods fail optimize towards final objective, leads suboptimal solution . In addition, enhanced speech speech enhancement methods usually generates over-smoothed speech, reason speech distortion speech enhancement. The speech distortion degrade performance ASR . Therefore, performance approach highly dependent performance enhancement front-end . %In addition, speech enhancement methods usually tend generate over-smoothed speech use particular form loss functions mean squared error , leads speech distortion. However, performance ASR degraded speech distortion . Therefore, performance approach highly dependent performance enhancement front-end . The second mainstream method uses multi-condition training boost noise robustness ASR. MCT uses different kinds data train speech recognition model. However, complexity computing costs MCT increased. In addition, gives unimpressive performance unmatched conditions performance also affected speech distortion . In order alleviate speech distortion problem, enhancement front-end enhances training test set first, ASR model trained enhanced data. It improve ASR performance degree, still highly depends performance enhancement front-end. Different MCT method, SpecAugment directly applies data augmentation input features neural networks . The SpecAugment used training, consists three spectrogram deformations: time warping, time frequency masking. Although SpecAugment improve performance end-to-end ASR, needs improved noisy condition. %%MCT uses clean data training also noisy data. Therefore, MCT learn different distributions clean noisy data speech recognition model boosts noise robustness. However, complexity computing costs MCT increased. In addition, gives unimpressive performance unmatched conditions performance also affected speech distortion . In order alleviate speech distortion problem, enhancement front-end enhances training test set first, ASR model trained enhanced training set. It improve ASR performance degree, still highly dependent performance enhancement front-end. Different MCT method, SpecAugment directly applies data augmentation input features neural networks . The SpecAugment used training, consists three spectrogram deformations: time warping, time frequency masking. Although SpecAugment improve performance end-to-end ASR, still affected speech distortion problem. %Then applies enhanced data test. Although method boost robustness ASR degree, complexity computing costs increased. In addition, performance MCT also affected speech distortion . %In order boost noise robustness ASR, mainstream method adding speech enhancement component front-end ASR. However, speech enhancement aims estimate target speech , different speech recognition. Therefore, speech enhancement methods fail optimize towards final objective, leads suboptimal solution . In addition, speech enhancement usually leads speech distortion. However, performance ASR degraded speech distortion . Therefore, performance approach highly dependent performance enhancement front-end . In order alleviate issue, multi-condition training method proposed. MCT uses clean data training also noisy enhanced data. Although method boost robustness ASR degree, complexity computing costs increased. In addition, performance MCT also affected speech distortion. %speech enhancement methods usually tend generate over-smoothed speech use particular form loss functions mean squared error , leads speech distortion. However, performance ASR degraded speech distortion . Therefore, performance approach highly dependent performance enhancement front-end . %In order boost noise robustness ASR, mainstream method adding speech enhancement component front-end ASR. Speech enhancement methods include spectral subtraction , Wiener filtering deep neural network based speech enhancement methods . However, speech enhancement part optimizes models estimate target speech, different speech recognition part. Therefore, speech enhancement methods fail optimize towards final objective, leads suboptimal solution . In addition, speech enhancement methods usually tend generate over-smoothed speech use particular form loss functions mean squared error , leads speech distortion. However, performance ASR degraded speech distortion . Therefore, performance approach highly dependent performance enhancement front-end . %speech enhancement methods usually lead speech distortion. %However, applying speech enhancement methods two shortcomings. Firstly, %Firstly, speech enhancement methods increase computation complex pipelines, limit applications speech recognition. Secondly, The third mainstream method joint training methods . These methods apply joint training framework optimize speech enhancement recognition, simultaneously. The reason speech enhancement speech recognition two independent tasks clearly benefit other. In order boost noise robustness end-to-end ASR, , authors propose joint adversarial enhancement training method. They utilize joint training framework optimize mask based enhancement network attention based encoder-decoder speech recognition network. However, method uses enhanced feature input speech recognition, still affected speech distortion problem. In addition, noisy AISHELL-1 dataset, character error rate method still 50\%, needs improved. As end-to-end speech recognition, speech transformer models shown impressive performance acquired state-of-the-art results. Self-attention network one key components speech transformer powerful model long-term dependencies recurrent neural networks based sequence sequence models. Therefore, applying joint training enhancement speech transformer improve performance robust end-to-end ASR. %One key components speech transformer self-attention network , powerful model long-term dependencies Recurrent neural networks -based sequence sequence models. Therefore, performance robust end-to-end ASR improved using joint training enhancement speech transformer. %To address speech distortion problem acquire optimal performance, joint training method speech enhancement speech recognition proposed robust ASR . This speech enhancement speech recognition two independent tasks clearly benefit other. In , joint adversarial enhancement training method proposed boost noise robustness end-to-end ASR systems. It applies joint training mask based-enhancement network attention-based encoder-decoder speech recognition network. However, method uses enhanced features input speech recognition, still affected speech distortion problem. And character error rate method still 50\% noisy AISHELL-1 dataset. Speech transformer models shown impressive performance end-to-end speech recognition acquire state-of-the-art performances. One key components speech transformer self-attention network , powerful model long-term dependencies Recurrent neural networks -based sequence sequence models. Therefore, performance robust end-to-end ASR improved using joint training enhancement speech transformer. %Liu et al propose joint adversarial enhancement training boost noise robustness end-to-end ASR systems . They use joint training mask based-enhancement network attention-based encoder-decoder speech recognition network %In paper, propose joint training method enhancement speech transformer robust end-to-end ASR, uses deep attention fusion representations noisy enhanced features. To best knowledge, first time apply speech transformer enhancement joint training robust end-to-end ASR. Specifically, proposed joint training method includes two parts: In , one-pass robust speech recognition method proposed. It combines noisy enhanced features gating mechanism. Although improve robust ASR, enhancement speech recognition trained separately instead joint training algorithm. In addition, simple gate mechanism make full use sequence information fuse noisy enhanced features well. %The speech enhancement speech recognition Fig. illustrates spectrogram example test speech sample. From Fig. find spectrogram enhanced speech enhancement network significant leaks block boxes), leads speech distortion. There significant leaks black boxes. This noise dominant T-F bins, drowns target speech. Therefore, enhancement network deals T-F bins noise signals removes information. These leaks lose much important speech information, example: formants. Although enhancement network remove noise signals degree, leaks unknown speech recognition system lose much speech information. These reasons speech distortion damages performance speech recognition. In paper, propose gated recurrent fusion joint training framework robust end-to-end ASR. In order address speech distortion problem, motivated , GRF utilized dynamically combine noisy enhanced features. Therefore, GRF offset leaks noisy features. In addition, GRF reduce noise enhanced features. So GRF aims learn adaptively select fuse relevant information noisy enhanced features making full use gate memory modules. The GRF extract appropriate robust speech features. In addition, apply joint training algorithm optimize enhancement speech recognition. The state-of-the-art end-to-end ASR method speech transformer self-attention method used speech recognition component. Specifically, proposed joint training method includes three parts: speech enhancement, gated recurrent fusion speech recognition. With joint optimization enhancement recognition, proposed model expected learn robust representations suitable recognition task automatically. %In paper, propose joint training method enhancement speech transformer robust end-to-end ASR, uses deep attention fusion representations noisy enhanced features. We apply state-of-the-art end-to-end ASR method speech transformer self-attention speech recognition component. In addition, alleviate speech distortion problem, deep attention fusion component utilized combine noisy enhanced features, dynamically fuse features deep way extract appropriate robust speech features. Therefore, GRF representations learn raw fine structures noisy features make speech distortion. Meanwhile, also remove noise signals form enhanced features. Specifically, proposed joint training method includes three parts: speech enhancement, deep attention fusion speech recognition. With joint optimization enhancement recognition, proposed model expected learn robust representations suitable recognition task automatically. %dynamically select appropriate speech features. As enhancement component, apply mask-based enhancement network estimate clean speech. As speech recognition component, speech transformer self-attention used ASR. To summarize, main contribution paper two-fold. Firstly, address speech distortion problem, gated recurrent fusion algorithm utilized dynamically fuse noisy enhanced features. Secondly, best knowledge, first time apply speech transformer single channel speech enhancement joint training framework. Our experiments conducted AISHELL-1 Mandarin dataset. Experimental results show proposed method achieves relative CER reduction 10.02\% conventional joint enhancement transformer method using enhanced features only. Especially low signal-to-noise ratios, proposed method achieve better performance. %The rest paper organized follows. Section 2 presents conventional joint training method robust ASR. Our proposed method stated section 3. Section 4 shows detailed experiments results. Section 5 draws conclusions. The rest paper organized follows. Section \ presents conventional joint training method robust ASR. Section \ introduces proposed joint training method gated recurrent fusion algorithm. The experimental setup stated section \. Section \ shows experimental results. Section \ shows discussions. Section \ draws conclusions. %The rest paper organized follows. Section \ presents discriminative learning monaural speech separation using deep embedding features. Section \ introduces proposed end-to-end post-filter speech separation method. The experimental setup stated section \. Section \ shows experimental results. Section \ shows discussions. Section \ draws conclusions."," %The joint training of speech enhancement and speech recognition methods have acquired good performances for robust end-to-end automatic speech recognition . However, they only use the enhanced features as the input of speech recognition component, which is still affected by the speech distortion problem. In this paper, we propose a deep attention fusion  of noisy and enhanced features with joint enhancement and speech transformer training method for robust end-to-end ASR. We apply the state-of-the-art end-to-end ASR method speech transformer as our speech recognition component. To address the speech distortion problem and extract more robust features for ASR, we propose the deep attention fusion algorithm to combine the noisy and enhanced features deeply. Therefore, these GRF representations can learn the raw fine structures from the noisy features to alleviate the speech distortion. Meanwhile, they can also remove the noise signals form the enhanced features. Systematic experiments on AISHELL-1 show that the proposed method achieves the relative character error rate  reduction of 8.32\% over the conventional joint enhancement and transformer method using the enhanced features only. Especially for the low signal-to-noise ratios, our proposed method can achieves better performances. %The joint training framework for speech enhancement and recognition methods have obtained quite good performances for robust end-to-end automatic speech recognition . However, these methods only utilize the enhanced feature as the input of speech recognition component, which are affected by the speech distortion problem. In order to address this problem, in this paper, we propose a gated recurrent fusion  method with joint training framework for robust end-to-end ASR. The proposed method consists of speech enhancement, GRF and speech recognition. Firstly, the mask based speech enhancement network is applied to enhance the input speech. Secondly, to address the speech distortion problem and extract more robust features for end-to-end ASR, the GRF algorithm is used to dynamically combine the noisy and enhanced features. Therefore, the GRF can not only remove the noise signals from the enhanced features, but also learn the raw fine structures from the noisy features so that it can alleviate the speech distortion. Thirdly, to improve the performance of ASR, the state-of-the-art end-to-end speech recognition method speech transformer with self-attention algorithm is used as the speech recognition component. Finally, the joint training framework is utilized to optimize these three components, simultaneously. Our experiments are conducted on an open-source Mandarin speech corpus called AISHELL-1. Experimental results show that the proposed method achieves the relative character error rate  reduction of 10.04\% over the conventional joint enhancement and transformer method only using the enhanced features. Especially for the low signal-to-noise ratio , our proposed method can achieves better performances with 12.67\% reduction, which suggests the potential of our proposed method. The joint training framework for speech enhancement and recognition methods have obtained quite good performances for robust end-to-end automatic speech recognition . However, these methods only utilize the enhanced feature as the input of the speech recognition component, which are affected by the speech distortion problem. In order to address this problem, this paper proposes a gated recurrent fusion  method with joint training framework for robust end-to-end ASR. The GRF algorithm is used to dynamically combine the noisy and enhanced features. Therefore, the GRF can not only remove the noise signals from the enhanced features, but also learn the raw fine structures from the noisy features so that it can alleviate the speech distortion. The proposed method consists of speech enhancement, GRF and speech recognition. Firstly, the mask based speech enhancement network is applied to enhance the input speech. Secondly, the GRF is applied to address the speech distortion problem. Thirdly, to improve the performance of ASR, the state-of-the-art speech transformer algorithm is used as the speech recognition component. Finally, the joint training framework is utilized to optimize these three components, simultaneously. Our experiments are conducted on an open-source Mandarin speech corpus called AISHELL-1. Experimental results show that the proposed method achieves the relative character error rate  reduction of 10.04\% over the conventional joint enhancement and transformer method only using the enhanced features. Especially for the low signal-to-noise ratio , our proposed method can achieves better performances with 12.67\% CER reduction, which suggests the potential of our proposed method. %The joint training of speech enhancement and speech recognition methods have acquired good performances for robust end-to-end automatic speech recognition . However, they only use the enhanced features as the input of speech recognition component, which is still affected by the speech distortion problem. In this paper, we propose a gated recurrent fusion  of noisy and enhanced features with joint enhancement and speech transformer training method for robust end-to-end ASR. We apply the state-of-the-art end-to-end ASR method speech transformer with self-attention algorithm as our speech recognition component. To address the speech distortion problem and extract more robust features for end-to-end ASR, we apply the GRF algorithm to dynamically combine the noisy and enhanced features. Therefore, these GRF representations can learn the raw fine structures from the noisy features so that they can make up the speech distortion. Meanwhile, they can also remove the noise signals form the enhanced features to improve the robustness of end-to-end speech recognition. Our experiments are conducted on an open-source Mandarin speech corpus called AISHELL-1. Experimental results show that the proposed method achieves the relative character error rate  reduction of 10.04\% over the conventional joint enhancement and transformer method only using the enhanced features. Especially for the low signal-to-noise ratio , our proposed method can achieves better performances with 12.67\% reduction, which suggests the potential of our proposed method."
"{M}{usic} composition human creative process requires wide range strong musical knowledge expertise create soothing music continues remain heart forever. Given vast majority music lovers limited availability professional music composers, strong need machines assist human creativity. Recent advancement software based music creation technology helped professional amateur music creators produce music great joy ease production masses consumed music consumers personal computers hand-held devices. %The software applications Ableton Live, FL Studio, Logic Pro X, Garageband examples changed way music produced past. Though exists plenty machine assistance create high quality music relative ease production, process songwriting automatically generating lyrics, composing melody corresponding generated lyrics synthesizing singing voice corresponding generated melody lyrics remained mutually exclusive tasks. Till date, construction novel/original songs limited individuals possess following skills: ability create lyrics, compose melody combine lyrics melody create rational, relevant soothing final complete songs. %Though remixing technology, create new music extent satisfies music lovers, need creating truly novel songs multiple constraints remaking existing works. % ------------------------------------------------------------------------------------------------------------- In literature, find considerable amount research work published automatic music generation . Early machine assisted music generation mostly based music theory expert domain knowledge create novel works. With advent data driven approaches exploded public music collections internet, data driven methods Hidden Markov models, graphic models deep learning models showed potential music creation. Though exists substantial amount research unconditional music generation, exists considerably less amount work done far generating melody lyrics given form text, call conditional melody/song generation lyrics. The primary reasons substantially less research conditional melody generation attributed i) non-availability direct source lyrics-melody pair dataset train data driven models, ii) lyrics composition multiple melodic representations, makes hard learn correlation lyrics melodies, iii) hard evaluate generated melodies objective measures. This paper focuses challenging aspect algorithmic songwriting process enables human community discover original lyrics, melodies suitable generated lyrics. To best knowledge, proposed AutoNLMC first attempt make whole process songwriting automatic using artificial neural networks. We also present lyrics vector model trained large dataset popular English songs obtain dense representation lyrics syllables, words sentence levels. The proposed AutoNLMC attention based encoder-decoder sequential recurrent neural network model consists lyric generator, lyric encoder melody decoders trained end-to-end. We train several encoder-decoder models various dense representations lyric tokens learn correlation lyrics corresponding melodies. Further, prove importance dense representation lyrics various qualitative quantitative measures. AutoNLMC designed way generate lyrics corresponding melodies automatically amateur person without music knowledge accepting small piece initial seed lyrics input. It also take lyrics professional lyrics writer generate matching meaningful melodies."," In this paper, we propose a technique to address the most challenging aspect of algorithmic songwriting process, which enables the human community to discover original lyrics, and melodies suitable for the generated lyrics. The proposed songwriting system, Automatic Neural Lyrics and Melody Composition  is an attempt to make the whole process of songwriting automatic using artificial neural networks. Our lyric to vector  model trained on a large set of lyric-melody pairs dataset parsed at syllable, word and sentence levels are large scale embedding models enable us to train data driven model such as recurrent neural networks for popular English songs. AutoNLMC is a encoder-decoder sequential recurrent neural network model consisting of a lyric generator, a lyric encoder and melody decoder trained end-to-end. AutoNLMC is designed to generate both lyrics and corresponding melody automatically for an amateur or a person without music knowledge. It can also take lyrics from professional lyric writer to generate matching melodies. The qualitative and quantitative evaluation measures revealed that the proposed method is indeed capable of generating original lyrics and corresponding melody for composing new songs."
"Machine learning systems struggle learn predictors robust distribution shift. When tested i.i.d data drawn training distribution systems achieve nearly perfect accuracy, even regularized prevent over-fitting. However, performance degrade below-chance accuracy testing training distributions even slightly different . The field Domain Generalization addresses challenge proposing robust methods ensure good test performance distributions different systematically related training distribution . Invariant Risk Minimization one several recently successful approaches Multi-Source Domain Generalization encourages models learn predictors invariant performance across different ``domains'', ``environments'' . Given different training environments, models extract set predictors feature space conditional distribution outcomes given predictors invariant across training environments. These predictors consequently generalize well test out-of-distribution environments share invariance. Building work philosophy characterizes causation invariance , existing invariance-based DG methods interpreted weak form causal discovery whose returned predictors causal factors underlying phenomena wish predict. Fairness often characterized robustness changes ``sensitive attributes'' , especially context toxicity classification. Consider automated moderation system used online news platform determine comments news article toxic online discourse censored. The performance fair system affected characteristics whether comment issues related race, gender politically sensitive topics. Alternative definitions distributive fairness differ system's predictions invariant changes sensitive attribute. For instance, statistical definitions Demographic Parity require conditional distribution predictions given sensitive attribute invariant sensitive attribute , causal definitions counterfactual fairness require every individual's prediction invariant counterfactual changes individual's sensitive attribute. There number ethical legal criticisms levied systems predict based sensitive group membership . Moreover, over-reliance sensitive information could decrease robustness predictive performance information spuriously depends environmental context employed. Discussion non-caucasian racial identities, example, may highly predictive comment toxicity white supremacist internet forums whose members routinely make discriminatory remarks ethnic minorities. However, internet forums welcoming diversity association racial identity mention toxicity would likely far weaker. This brittleness sensitive information identified key challenge Perspective API, Google-backed internet comment toxicity classifier, faced implementing real-world contexts , also observed cause bias sentiment analysis facial detection tasks. Fair models, then, perhaps constructed learning predictors whose performance remains invariant across variety different environments. In work, empirically demonstrate Domain Generalization used build fair machine learning systems constructing models invariant spurious correlations involving sensitive attribute. Specifically, assess performance IRM fair internet comment toxicity classification task derived Civil Comments Dataset. In task, model must generalize biased training environments exhibiting strong spurious correlation mention particular demographic identity toxicity test environment correlation reversed. Our contributions follows:","     Robustness is of central importance in machine learning and has given rise to the fields of domain generalization and invariant learning, which are concerned with improving performance on a test distribution distinct from but related to the training distribution. In light of recent work suggesting an intimate connection between fairness and robustness, we investigate whether algorithms from robust ML can be used to improve the fairness of classifiers that are trained on biased data and tested on unbiased data. We apply Invariant Risk Minimization , a domain generalization algorithm that employs a causal discovery inspired method to find robust predictors, to the task of fairly predicting the toxicity of internet comments. We show that IRM achieves better out-of-distribution accuracy and fairness than Empirical Risk Minimization  methods, and analyze both the difficulties that arise when applying IRM in practice and the conditions under which IRM will likely be effective in this scenario. We hope that this work will inspire further studies of how robust machine learning methods relate to algorithmic fairness."
"Deep Neural Networks current state-of-the-art models many speech related tasks. From computational neuroscience perspective, DNNs seen rate coding based models, sense neuron responsive given stimulus, augment stimulus intensity, neuron output intensity also increase. Temporal coding based models try also take account information carried temporal structure stimulus. In case Spiking Neural Networks , spike timing delays spikes important order retrieve patterns spike sequences given input model. %https://en.wikipedia.org/wiki/Neural_coding There growing interest SNNs applied speech recognition tasks, isolated word phone recognition,to large-vocabulary automatic speech recognition recently. Reasons audio speech signal particularly suited event-driven models SNNs, SNNs also biologically realistic DNNs, hardware friendly energy efficient models, implemented dedicated energy-efficient neuromorphic chips. Furthermore, shown recently SNNs trained efficiently, supervised manner, using backpropagation surrogate gradient trick. This new approach allows train SNNs one would DNNs. In work, propose use supervised SNNs speech command recognition. We explore Leaky Integrate-and-Fire neuron model task, show convolutional SNNs reach accuracy close one obtained state-of-the-art DNNs, task. Our main contributions following: i) propose use dilated convolution spiking layers, ii) define new regularization term penalize averaged number spikes keep spiking neuron activity sparse possible, iii) show leaky variant neuron model outperforms non-leaky one , used in. In order facilitate reproducibility, code using PyTorch available online\footnote{https://github.com/romainzimmer/s2net}."," Deep Neural Networks  are the current state-of-the-art models in many speech related tasks. There is a growing interest, though, for more biologically realistic, hardware friendly and energy efficient models, named Spiking Neural Networks . Recently, it has been shown that SNNs can be trained efficiently, in a supervised manner, using backpropagation with a surrogate gradient trick. In this work, we report speech command  recognition experiments using supervised SNNs. We explored the Leaky-Integrate-Fire  neuron model for this task, and show that a model comprised of stacked dilated convolution spiking layers can reach an error rate very close to standard DNNs on the Google SC v1 dataset: \ER{94.5}\%, while keeping a very sparse spiking activity, below 5\%, thank to a new regularization term. We also show that modeling the leakage of the neuron membrane potential is useful, since the LIF model outperformed its non-leaky model counterpart significantly."
"Books one important mediums recording information imparting knowledge human history. Books classified different categories based physical formats, contents, languages, on. In paper, focus task book classification genre using information provided cover. Book covers usually first impression readers often convey important information content book. Figure presents sample book covers. The information provided cover includes visual textual information . For instance, Figure 1, background picture contains different food items cookware give readers visual impression book, texts shown cover states book ``authentic recipes Malaysia"". Both visual textual information shown cover together indicate genre ``Cookbooks, Food \& Wine"". It worth mention visual information often makes task extremely hard without textual information. For instance, Figure 1 , without reading texts cover, someone may classify book ``Cookbooks, Food \& Wine"" well solely based visual information get cover includes food items table dining room setting. Therefore, sometimes essential consider visual information textual information extracted cover conduct book genre classification. The automatic classification books based covers without human intervention would utterly beneficial many modern retrieval systems, considering complete digitization books extremely expensive task. The challenges task following. First, exists wide variety book genres, many concretely defined. Second, book covers, graphic designs, varies many different ways colors, styles, textual information, etc, even books genre. Third, book cover designs may vary due many external factors country, culture, target reader populations, etc . To overcome difficulties, present deep learning framework involving two moralities: one visual information textual information extracted covers. Recently, deep learning approaches reached high performances across wide variety problems . In particular, deep convolutional neural networks achieve satisfactory level performance many visual recognition categorization tasks, exceeding human performances. One attractive qualities techniques perform well without external hand-designed resources task-specific feature engineering. The theoretical foundations deep learning well rooted classical neural network literature. It involves many hidden neurons layers architectural advantage addition input output layers . A deep convolutional neural network universal, meaning used approximate continuous function arbitrary accuracy depth neural network large enough . The main contributions paper fourfold: The rest paper structured follows. Section 2 presents related works book cover classification. Section 3 elaborates details proposed multi-modal architectures. In section 4, discuss experimental results. The last section concludes paper discusses future work."," Book covers are usually the very first impression to its readers and they often convey important information about the content of the book. Book genre classification based on its cover would be utterly beneficial to many modern retrieval systems, considering that the complete digitization of books is an extremely expensive task. At the same time, it is also an extremely challenging task due to the following reasons: First, there exists a wide variety of book genres, many of which are not concretely defined. Second, book covers, as graphic designs, vary in many different ways such as colors, styles, textual information, etc, even for books of the same genre. Third, book cover designs may vary due to many external factors such as country, culture, target reader populations, etc. With the growing competitiveness in the book industry, the book cover designers and typographers push the cover designs to its limit in the hope of attracting sales. The cover-based book classification systems become a particularly exciting research topic in recent years. In this paper, we propose a multi-modal deep learning framework to solve this problem. The contribution of this paper is four-fold. First, our method adds an extra modality by extracting texts automatically from the book covers. Second, image-based and text-based, state-of-the-art models are evaluated thoroughly for the task of book cover classification. Third, we develop an efficient  and salable multi-modal framework based on the images and texts shown on the covers only.  Fourth, a thorough analysis of the experimental results is given and future works to improve the performance is suggested. The results show that the multi-modal framework significantly outperforms the current state-of-the-art image-based models. However, more efforts and resources are needed for this classification task in order to reach a satisfactory level."
"\vskip 0.15in Despite recent developments activation functions Machine Learning -based classifiers, m-arcsinh~ shallow Multi-Layer Perceptron ~, usable, repeatable reproducible functions shallow deep neural networks, e.g., Convolutional Neural Network ~, remained limited confined three activation functions regarded 'gold standard'. These include Rectified Linear Unit , sigmoid function modified version, hyperbolic tangent sigmoid 'tanh'~, extends range [0, +1] [-1, +1]. The sigmoid tanh well-known vanishing gradient issues; thus, ReLU function devised scalable deep neural networks, despite 'dying ReLU' problem, recently solved by~. These made freely accessible open source Python library named 'Keras'~ Deep Learning. The availability functions public domain enabled not-for-profit for-profit organisations leverage several intelligence-based applications, academic industrial applications~~. \\ Nevertheless, considering above-mentioned challenges Computer Science ML communities, activation functions lack robustness classification tasks varying degrees complexity, e.g., slow lack convergence~ ~, caused trapping local minima~. Moreover, amongst three above-mentioned activation functions, ReLU applicable shallow deep neural networks, novel quantum variations found scalable traditional version recently~. \\ On side, sciences dealing study human behaviour, last 20 years, considerable progress made towards prevention mental health disorders~~. Specifically, professionals working field counselling psychology slightly enhanced ability grasping relational issues subjects via novel ML-based tele-monitoring technologies~. Nevertheless, technologies yet changed traditional counselling psychology practice, still based structured methodology adopted help individuals become self-aware, conscious needs moods~. The main goal counsellors pursue guiding individuals get know deeper level help discover resurface resources better manage emotions daily life. This process first requires tailored dialogue counsellor individual and, subsequently, leveraging practical tools aid individual experience understand inner self deeply~. Moreover, still limitations within counselling setting. For instance, individuals, fear, may reveal fundamental aspects persona would help counsellors guide better getting know themselves. Furthermore, many cases, subjects may express verbal language opposite non-verbal one. Counsellors often hardly understand dynamic patterns observed behaviours subjects, thus unable provide required help support them. \\ In counselling, neural network algorithms, shallow deep depending amount good-quality data hardware available, potential support counsellors image text classification tasks understand guide subjects helping infer subtle dynamic changes behaviours. Via careful effective observation images, micro- macro- body movements, facial expressions~~, possible better interpret understand subjects' non-verbal language. Even emotions underlying written content subjects may reveal inner aspects persona fundamental counsellors help resurface increase subjects' self-awareness related capability 'self-healing'~. \\ Therefore, theoretical practical standpoints, increasing need accurate reliable open source activation functions, reach convergence faster, avoiding trapping local minima, stable also used scale across shallow deep neural network algorithms image text classification. Entirely written Python made freely available TensorFlow~ Keras~, proposed hyperbolic function demonstrated competitive function respect gold standard functions, suits shallow deep neural networks, thus accurate reliable pattern recognition aid image text classification tasks. Thanks liberal license, widely distributed part free software Python libraries TensorFlow~ Keras~, available use academic research commercial purposes.\\ %%%%%%%%%%%%%%% Methods section %%%%%%%%%%%%%%%%%%%%% \vskip 0.3in","%   <- trailing '%' for backward compatibility of .sty file This paper presents the 'hyper-sinh', a variation of the m-arcsinh activation function suitable for Deep Learning -based algorithms for supervised learning, such as Convolutional Neural Networks . hyper-sinh, developed in the open source Python libraries TensorFlow and Keras, is thus described and validated as an accurate and reliable activation function for both shallow and deep neural networks.  Improvements in accuracy and reliability in image and text classification tasks on five  benchmark data sets available from Keras are discussed.  Experimental results demonstrate the overall competitive classification performance of both shallow and deep neural networks, obtained via this novel function.  This function is evaluated with respect to gold standard activation functions, demonstrating its overall competitive accuracy and reliability for both image and text classification."
"In grounded language theory, semantics language given symbols connect underlying real world---the so-called ``symbol grounding problem''. For example, want robotic system sees eggplant ground recognition object canonical symbol `eggplant.' When user asks ""Please grab eggplant,"" robot ground natural language word ""eggplant"" symbol denotes relevant visual percepts. Once language vision successfully ground symbol, becomes feasible robot complete task. We learn connection using physical sensors conjunction language learning: paired language perceptual data used train joint model linguistic constructs apply perceivable world. Machine learning grounded language often demands large-scale natural language annotations things world, expensive impractical obtain. It feasible build dataset encompasses every object possible linguistic description. Novel environments require symbol grounding occur real time, based inputs human interactor. Learning meanings language unstructured communication people attractive approach, requires fast, accurate learning new concepts, people unlikely spend hours manually annotating even hundred samples, let alone thousands millions commonly required machine learning. % Active learning, system queries specific training data, potential improve learning efficiency reduce number labels required learn grounded language model. In work study active learning, system deliberately seeks information lead improved understanding less data, minimize number samples/human interactions required. The field active learning typically assumes pool unlabeled samples available, model request specific example would like obtain label for. By model select informative data points labeling, number samples need labeled reduced. This maps goal human-robot learning minimum training data provided human. Furthermore, active learning part pipeline few-shot learning methods. However, active learning magic bullet. When carefully applied, outperform sequential random sampling baselines. Thoughtful selection suitable approaches problems required. While active learning used language grounding %, , best knowledge, present first broad exploration best methods active learning grounding vision-language pairs. % In paper, focus developing guidelines active learning methods might appropriately selected applied vision-language grounding problems. We test different active learning approaches grounded language problems varying linguistic sensory complexity, use results drive discussion select active learning methods different grounded language data acquisition problems informed way. We consider grounded language task learning novel language previously unseen object types characteristics. Our emphasis determining methods reduce amount training data needed achieve performance consistent human evaluation. Primarily, address five relevant questions concerning characteristic-based grounded language learning: % We make conclusions respect questions \cref{sec:results}. % In addition addressing research questions, verify generalizable learning techniques beyond characteristic-based grounding. We find right ordering training data makes possible learn successfully significantly fewer descriptions cases, also active learning methodology chosen specific nature learning problem. Our main contribution principled analysis using active learning methods unsupervised data sampling techniques language grounding discussion aspects problems relevant approach selection. While contributions primarily analytic rather algorithmic, argue address critical need within grounded language understanding, active research area questions efficiency data collection widespread, potential support additional algorithmic developments."," % In grounded language acquisition, a physical agent uses language combined with high-frequency sensor data to learn a model of how language refers to the physical world. This approach, while powerful, often requires extensive data annotation, which can be difficult to obtain. This work  % Ordering the selection of training data using active learning can lead to improvements in learning efficiently from smaller corpora. We present an exploration of active learning approaches applied to three grounded language problems of varying complexity in order to analyze what methods are suitable for improving data efficiency in learning. We present a method for analyzing the complexity of data in this joint problem space, and report on how characteristics of the underlying task, along with design decisions such as feature selection and classification model, drive the results. We observe that representativeness, along with diversity, is crucial in selecting data samples."
"Deep neural networks powerful widely applied natural language processing. However, recent studies demonstrate models vulnerable adversarial examples, malicious inputs intentionally crafted fool models. % The introduction adversarial example ushered new era understand improve neural network-based models. % Adversarial attacks defenses attacks drawn significant attention recent years . Although generating adversarial examples texts proven challenging task images due discrete nature, number methods proposed generate adversarial text examples reveal vulnerability deep neural networks natural language processing tasks including reading comprehension , text classification , machine translation , dialogue systems , dependency parsing . These methods attack text examples replacing, scrambling, erasing characters words language units. To settle susceptible attack direction, require large number queries target model predictions given inputs. Thus adversarial examples typically generated specific model. This motivates main questions aim answer paper: Are universal adversarial examples fool almost every neural network-based model? And universal attack rules constructing universal adversarial examples? %are universal adversarial examples transfer neural network-based models? It well known adversarial examples exhibit black-box transferability, meaning adversarial examples generated one model fool another model . Transfer attackers launch white-box attacks local models find candidate adversarial examples may transfer target model. % In white-box setting, adversary access model's architecture, parameters input feature representations black-box one. % However, adversarial examples typically overfitted particular architecture feature representation source model, resulting sub-optimal black-box transfer attacks target models. However, factors affect transferability adversarial examples still unclear, especially NLP models. In study, quantitatively investigate adversarial transferability impacted several critical factors, including network architecture, input form, word embedding type, model capacity. Based understanding transferability among various neural models, study whether possible craft universal, model-agnostic text adversarial examples almost existing models. Universal adversarial examples least two advantages. First, adversaries need white-box access target models. They launch attacks models trained similar data, transfer across models . Second, universal adversarial examples useful analysis tool because, unlike typical attacks, model-agnostic. Thus, highlight general input-output patterns learned model. We leverage study influence dataset biases identify biases learned models. \end{center} \end{table*} In study, first systematically investigated critical factors neural models, including network architectures , input forms , embedding types , model capacities impact transferability text adversarial examples extensive experiments two datasets text classification. We vary one factor time fixing others see factor significant, found input form greatest influence adversarial transferability, following network architecture, embedding type, model capacity. Then, propose genetic algorithm find optimal ensemble minimum number members basis understanding adversarial transferability among neural models. The adversarial examples generated attacking ensemble found algorithm strongly transfer models, models, exhibit better transferability generated attacking models different random initialization. Finally, generalize adversarial examples constructed ensemble method universal semantics-preserving word replacement rules induce adversaries text input strongly transferring neural network-based NLP model . Since rules model-agnostic, provide analysis global model behavior, help us identify dataset biases diagnose heuristics learned models."," Deep neural network models are vulnerable to adversarial attacks. In many cases, malicious inputs intentionally crafted for one model can fool another model in the black-box attack setting. However, there is a lack of systematic studies on the transferability of adversarial examples and how to generate universal adversarial examples.  In this paper, we systematically study the transferability of adversarial attacks for text classification models.  In particular, we conduct extensive experiments to investigate how various factors, such as network architecture, input format, word embedding, and model capacity, affect the transferability of adversarial attacks.  Based on these studies, we then propose universal black-box attack algorithms that can induce adversarial examples to attack almost all existing models. These universal adversarial examples reflect the defects of the learning process and the bias in the training dataset.  Finally, we generalize these adversarial examples into universal word replacement rules that can be used for model diagnostics.     \if0 It has been known that adversarial examples exhibit black box transfer, i.e. malicious inputs intentionally crafted for one model can also cause another model to make mistakes. However, which factors affect the most and how they impact the transferability of adversarial examples are still unclear, especially for NLP models.  Through extensive experiments, we systematically investigate how adversarial transferability is impacted with a few critical, model-specific factors, including the network architecture, input form, pre-trained word embedding, and model capacity. Based on the understanding of the adversarial transferability among neural models, we propose a population-based algorithm to find an optimal ensemble with minimum number of models, which can be used to generate adversarial examples that strongly transfer across other neural models.  We also generalize the adversarial examples generated by the ensemble method into universal word replacement rules that can induce adversaries on any text input to fool almost all the existing models with a much higher success rate. Those rules also help us to identify dataset biases and diagnose heuristics improperly learned by the models. \fi"
"Recent works shown NN models trained solely maximize prediction performance often vulnerable adversarial attacks . Even though several works proposed defend NN models attacks, focus NLP domain . Since many recent NLP models shown vulnerable adversarial attacks--e.g., fake news detection dialog system , investigation robust defense methods textual NN models become necessary. To defend adversarial texts, one use either adversarial detection model enhancement . Adversarial texts often generated replacing inserting critical words characters sentence, usually exhibiting grammatical errors. Hence, many detection methods focused recognizing correcting misspellings texts--e.g., ScRNN DISP . While misspelling-based methods model-independent require neither re-training modifying models, work well character-based attacks. In contrast, model enhancement approaches perform well character word-based attacks. %Such generalization variety attacks critical since one might know type adversarial techniques employed adversaries. Particularly, model enhancement methods enrich NN models training adversarial data augmented via known attack strategies adversarial training , external information knowledge graphs . Nevertheless, augmentations usually induce overhead costs training. Therefore, search defense algorithms directly enhance models' structures achieving higher extendability without acquiring additional data. %While developing solutions challenging still exploration . Fortunately, recent literature computer vision shows ensemble NNs achieve high adversarial robustness . In theory, directly extending single NN model ensemble multiple diverse sub-models, challenge adversaries attack one set different models . This makes attacks significantly difficult. However, applying idea computer vision NLP domain faces one main challenge. Current ensemble methods require simultaneous training several NN sub-models . This introduces impractical computational overhead training inference, especially one wants maximize prediction accuracy utilizing complex state-of-the-art sub-models BERT ROBERTA , 100M parameters. Furthermore, applying current ensemble defensive approaches directly enhance model's architecture large-scale NN model would usually require re-training everything scratch, may practical many settings. % Second, current ensemble approaches aim promote diversity sub-models either feature-level class-level . % Second, current ensemble approaches promote diversity sub-models maximizing differences among either prediction output vectors gradient vectors w.r.t input image . However, NLP tasks, classification particularly, much less labels computer vision, results much smaller degree-of-freedom directly regularizing differences prediciton probability vectors. % On hand, forcing sub-models focus different tokens input text directly regularizing gradient vectors straightforward text discrete nature. This easily resolved regularizing gradients w.r.t continuous word-embedding vectors sentence instead. However, since every sub-model contributes equally input, many overlaps among key features, i.e., words phrases, sub-models input text short. To address challenges, borrowing ideas Software Engineering, first introducing notion {\bf Neural Patching} improve adversarial robustness NN models ``patching"" parts models . Next, develop novel neural patching algorithm, {\mymethod}, patches last layer already deployed textual NN model diverse architectures transforms ensemble multi-experts enhanced adversarial robustness. By patching last layer model, {\mymethod} introduces lightweight computational overhead requires additional training data. %requires low construction overheads without compromising much computational complexity additional training data. Distinguished current ensemble methods, sub-model trained {\mymethod} specialized specific subset features input, i.e., expert feature-level , sub-set labels, i.e., expert class-level , also texts distinguished topic, i.e., expert instance-level, prediction. Such diversity feature-, class-, instance-level expertise makes challenging adversaries exploit multiple sub-models time. In summary, contributions paper follows: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"," Neural network  models that are solely trained to maximize the likelihood of an observed dataset are often vulnerable to adversarial attacks. Even though several methods have been proposed to enhance NN models' adversarial robustness, they often require re-training from scratch. This leads to redundant computation, especially in the NLP domain where current state-of-the-art models, such as BERT and ROBERTA, require great time and space resources. By borrowing ideas from Software Engineering, we, therefore, first introduce the Neural Patching mechanism to improve adversarial robustness by ``patching"" only parts of a NN model. Then, we propose a novel neural patching algorithm, {\mymethod}, that transforms a textual NN model into a stochastic ensemble of multi-expert predictors by upgrading and re-training its last layer only. {\mymethod} forces adversaries to attack not only one but multiple models that are specialized in diverse sub-sets of features, labels, and instances so that the ensemble model becomes more robust to adversarial attacks. By conducting comprehensive experiments, we demonstrate that all of CNN, RNN, BERT, and ROBERTA-based textual models, once patched by {\mymethod}, witness an absolute increase of as much as 20\% in accuracy on average under 5 different white and black-box attacks, outperforming 6 defensive baselines across 4 public NLP datasets. All codes and datasets are to be released."
"Emotional analysis active research area decades, especially recognition domains text speech emotions. Even text speech emotions closely relevant, kinds emotions different challenges. One challenges text emotion recognition ambiguous words, resulting omitted words . On hand, one challenges speech emotion recognition creating efficient model. However, paper focuses recognition speech emotions. In area, two types information, linguistic paralinguistic, mainly considered speech emotion recognition. The linguistic information refers meaning context speech. The paralinguistic information implies implicit message meaning, like emotion speech . Speech characteristics interpret meaning speech; therefore, behavioral expression investigated speech emotion recognition works . In recent works, local feature learning block , one efficient methods, used integrating local global speech emotion features, provide better results recognition. Inside LFLB, convolution neural network used extracting local features, long short-term memory applied extracting contextual dependencies local features learn time-related relationship. However, vanishing gradient problems may occur CNN . Therefore, residual deep learning applied CNN using skip-connection reduce unnecessary learning add feature details may lost layers. Furthermore, accuracy speech recognition rely efficiency model, also speech feature selection . In terms speech characteristics, many distinctive acoustic features usually used recognizing speech emotion, continuous features, qualitative features, spectral features . Many investigated recognize speech emotions. Some researchers compared pros cons feature, one identify feature best one . As previously mentioned, proposed method improve efficiency LFLB deeper learning. The proposed method, deep residual local feature learning block , inspired concept human brain learning; is, 閳ユΜepeated reading makes learning effective,閳 way Sari Shanahan used. Responding inspired concept, implemented learning method speech emotion recognition three parts: Part 1 general learning, like human reading first time, Part 2 learning, like additional readings, last part associating parts learned decide types emotions. Besides, feature selection compared two types distinctive features find effective feature work: normal specific distinctive features log-mel spectrogram , fully filtered sound elements, %log-mel spectrogram, MFCC deltas, delta-deltas, chromagram clearly identify speech characteristics extracted based %according human mood. Our main contributions paper follows: Deep residual local feature learning block proposed. DeepResLFLB arranged internal network LFLB, batch normalization , activation function, normalization-activation-CNN , deep layers. Learning sequences DeepResLFLB imitated human re-reads. Speech emotion features, %according based human mood determination factors LMS LMSDDC, applied compared performances."," Speech Emotion Recognition  is becoming a key role in global business today to improve service efficiency, like call center services. Recent SERs were based on a deep learning approach. However, the efficiency of deep learning depends on the number of layers, i.e., the deeper layers, the higher efficiency. On the other hand, the deeper layers are causes of a vanishing gradient problem, a low learning rate, and high time-consuming. Therefore, this paper proposed a redesign of existing local feature learning block . The new design is called a deep residual local feature learning block . DeepResLFLB consists of three cascade blocks: LFLB, residual local feature learning block , and multilayer perceptron . LFLB is built for learning local correlations along with extracting hierarchical correlations; DeepResLFLB can take advantage of repeatedly learning to explain more detail in deeper layers using residual learning for solving vanishing gradient and reducing overfitting; and MLP is adopted to find the relationship of learning and discover probability for predicted speech emotions and gender types. Based on two available published datasets: EMODB鐠虹棏nd RAVDESS, the proposed DeepResLFLB can significantly improve performance when evaluated by standard metrics: accuracy, precision, recall, and F1-score.  \keywords{Speech Emotion Recognition \and Residual Feature Learning \and CNN Network \and Log-Mel Spectrogram \and Chromagram}"
"Classification important task knowledge discovery databases data mining. It task learning discriminative function given data classifies previously unseen data correct classes. Current research trends natural language processing focus developing deep neural network models BERT pre-trained large text corpus thus show immense improvement different text classification tasks. Despite success large pre-trained models, DNNs still suffer generalizing balanced testing criterion cases data imbalance . In realistic settings, rarely case discrete distribution data acquired perfectly balanced across classes. Realistic settings prone skewed specific classes classes often class interest. Some situations may binary, detecting spams forums . The majority contents posted users spams accordance intended goal. As result, number spam samples sparse comparison non-spam samples. Imbalanced data may also occur multi-classification setting classifying articles different categories . Text classification used numerous application purposes. In paper, address problem detecting sexual harassment toxicity comments news articles. In name anonymity, online discussion platforms become place people undermine, harass, humiliate, threaten, bully others based superficial characteristics gender, sexual orientation, age . Each toxic comment classified classes based degree toxicity . Figure shows overall procedure detecting sexual harassment performing sentimental analysis comment data wild. When collecting annotating comments, data skewness occurs naturally since users consider data imbalance levels writing toxic non-toxic comments. Classifiers trained imbalanced settings tend become biased toward class samples training data. This standard deep learning architectures take data imbalance level consideration. In order develop intelligent classifiers, methods temper classifier biasing towards certain classes great importance. Previous methods addressing data imbalance text divided data-level algorithm-level methods. Data-level methods apply manipulation data undersampling majority classes oversampling minority classes. However, methods require effective numerical representation algorithm since methods applied directly representation instead actual text. Algorithm-level methods modify underlying learner output reduce bias towards majority group. However, methods task-sensitive somewhat heuristic since requires researchers modify classifier considering innate properties task. This property leads inefficiency training learner since heuristic approaches often time-consuming arbitrary. Since traditional oversampling undersampling methods, simply duplicate sample data instances, independent two limitations, methods addressing data imbalance text without utilization feature spaces task-dependent needed. We propose novel training architecture, Sequential Targeting , handles data imbalance problem forcing incremental learning setting. ST divides entire training data set mutually exclusive partitions, target-adaptively balancing data distribution. Target distribution predetermined distributional setting enables learner exert maximum performance trained with. In imbalanced distributional setting, target distribution idealistic follow uniform distribution classes hold equal importance. Optimal class distribution may differ innate property data research shows balanced class distribution overall better performance compared distributions~. The remaining partitions sorted magnitude similarity target distribution measured KL-divergence. The first partition split data imbalanced last partition arbitrarily modeled uniform across classes partitions utilized train learner sequentially. We handle issue catastrophic forgetting~, inevitable phenomenon transfer learning, utilizing Elastic Weight Consolidation~ stabilize knowledge attained previous tasks. This allows discriminative model learn incoming data forgetting previously inferred parameters previous tasks. Our proposed method independent numerical representation method task hand. We validate method simulated datasets varying imbalance levels apply method real-world application. We annotated construct three datasets consisting comments made users different social platforms NAVER\footnote{NAVER Korean No.1 web search portal around 16 million users visit every day. www.naver.com}: two detecting sexual harassment one multiple sentimental analysis. Annotations datasets improved iteratively in-lab annotations crowdsourcing. Experimental results show ST outperforms traditional approaches, notable gap, especially extremely imbalanced cases. Lastly, ST proves compatible previous approaches. Our contribution paper three-folds: The rest paper organized follows. Section summarizes related works. Section provides details proposed method. Section presents dataset descriptions, experiment setups, qualitative experimental results various datasets. Finally, Section concludes paper."," %% Text of abstract Classification tasks require a balanced distribution of data to ensure the learner to be trained to generalize over all classes. In real-world datasets, however, the number of instances vary substantially among classes. This typically leads to a learner that promotes bias towards the majority group due to its dominating property. Therefore, methods to handle imbalanced datasets are crucial for alleviating distributional skews and fully utilizing the under-represented data, especially in text classification. While addressing the imbalance in text data, most methods utilize sampling methods on the numerical representation of the data, which limits its efficiency on how effective the representation is. We propose a novel training method, Sequential Targeting, independent of the effectiveness of the representation method, which enforces an incremental learning setting by splitting the data into mutually exclusive subsets and training the learner adaptively. To address problems that arise within incremental learning, we apply elastic weight consolidation. We demonstrate the effectiveness of our method through experiments on simulated benchmark datasets  and data collected from NAVER."
"As growth robots interacting humans, different levels environment understanding required robot. A robot acting environment deal many open questions, thus needs different levels reasoning task. Usually, robots rely initial knowledge, perception cognitive abilities able understand reasoning situated environment. A recently hooked topic better Knowledge-Based cognition dialogic interaction human robot, robot captures fresh information environment user Natural Language. Information comes Natural Language together visually perceived information, Knowledge Base lets cognitive agent reach different levels understanding environment. The first level understanding seen classification detection sensory inputs, e.g. detection objects visual perception, role tagging lexical sentence. The second level understanding concerns finding relations different sensory inputs, e.g. finding common attributes language vision. Some famous problems symbol grounding anchoring concern finding correspondences different sensory input modalities. A higher abstract level understanding thought find relations entities environment. e.g. scene desk book top, relationships relative physical position semantics shows entities similar. Understanding relationships physical entities also extended attributes entities. Indeed definition relationship entities found attributes. For example, user declares freshness attribute 'apple-1' 'spoiled', well 'apple-2' 'apple-3', 'orange-1' 'banana-1' 'fresh', relation values freshness attribute exists connects semantic entities; In example, apples 'spoiled', rest fruits 'fresh', closed world assumption. Relation rules attributes entities help robot interacting human many applications. For example user utters ""bring fruit"", using rules obtained freshness attribute, robot notices fruits spoiled fresh eat. Such logical rules attributes let robot realize apples spoiled, apples thrown out, added shopping list. Moreover, obtained rule attributes used robot's low-level sensory input processing. Consider utterance user example declaring physical entity spoiled, robot's visual perception doubt whether perceived object apple pear. As robot already found apples spoiled fruits fresh, perceptual detection refines recognized object apple. %Different attributes represent characteristics entity, computed visual perception Natural Language interaction user. In work, deal nine different attributes, category, color, label, functionality, owner, size, weight, restriction, location entities scene; first two computed visual perception rest obtained Natural Language. %%It worth emphasis importance attributes come Natural Language. Such information almost impossible obtain visual perception, e.g. information user give owner entity, cannot obtained camera. Also, initial knowledge base gives information category entity, particular entity , assignments might temporary. On hand, information size, weight, location, may used refinement knowledge base camera, shortcut obtaining information user. In work, propose framework learning logical rules represent relations attributes semantic model robot's environment. Such logical rules help robot find attributes entail specific attribute. A distinctive novelty work generalize rules semantic model built via Human-Robot Interaction , integration visual linguistic cues. Our framework goes way sensory input data abstract First-Order Logic formulas describe abstract relationship attributes entities scene. %Our approach differs works system able capture attributes Natural Language addition attributes computer vision. %Our proposed framework compute First-Order Logic formulas, useful general reasoning upon entities common attributes. We focus latent rules, robot capture implicitly human describes objects robot. In words, require user give rules explicitly robot, rather let robot find rules reasoning based self-computed rules improving interaction user. This paper continues review related work, Section proposed framework described, followed implementation demonstrate viability proposed framework Section . In Section results test scenario given, followed discussion applicability framework. In end, conclusions work drawn."," Humans have a rich representation of the entities in their environment. Entities are described by their attributes, and entities that share attributes are often semantically related.  For example, if two books have ``Natural Language Processing'' as value of their `title' attribute, we can expect that their `topic' attribute will also be equal, namely, ``NLP''.  Humans tend to generalize such observations, and infer sufficient conditions under which the `topic' attribute of any entity is ``NLP''.  If robots need to interact successfully with humans, they need to represent entities, attributes, and generalizations in a similar way. This ends in a contextualized cognitive agent that can adapt its understanding, where context provides sufficient conditions for a correct understanding. In this work, we address the problem of how to obtain these representations through human-robot interaction.  We integrate visual perception and natural language input to incrementally build a semantic model of the world, and then use inductive reasoning to infer logical rules that capture generic semantic relations, true in this model.  These relations can be used to enrich the human-robot interaction, to populate a knowledge base with inferred facts, or to remove uncertainty in the robot's sensory inputs."
"In recent years, science, engineering mathematics education emphasized supporting students閳 disciplinary ""practices"" inquiry. These practices閳ユ敃uch formulating questions, designing investigations, arguing evidence閳ユ攣re difficult identify assess traditional objectives particular correct content knowledge. In order study students閳 practices, researchers rely mainly qualitative analyses naturalistic data. These studies advanced field閳ユ獨 understanding practices.\\ These studies limited scope, however, extremely labor-intensive: Analysis naturalistic data requires significant extensive effort trained researchers, transcribing coding construction meaning. It time cost-prohibitive conduct qualitative studies large samples data. Our purpose project develop computational tools support qualitative research large scales students' inquiry practices science. In paper report initial progress towards applying natural language processing techniques research students' written arguments college biology laboratory reports. \\ In work, report success designing NLP approached reliability trained, human coders. Specifically, show contrastive learning Wasserstein space able achieve high level agreement average. \\ The rest paper organized follows. In section first overview current state-of-art automating assessment writing science using machine learning natural language processing. Following outline writing assessment setting particular case section . In section briefly survey relevant literature machine learning NLP introduce novel approach automatic scoring. In section evaluate performance proposed approach discuss results detail.\\"," Qualitative analysis of verbal data is of central importance in the learning sciences. It is labor-intensive and time-consuming, however, which limits the amount of data researchers can include in studies. This work is a step towards building a statistical machine learning  method for achieving an automated support for qualitative analyses of students闁 writing, here specifically in score laboratory reports in introductory biology for sophistication of argumentation and reasoning. We start with a set of lab reports from an undergraduate biology course, scored by a four-level scheme that considers the complexity of argument structure, the scope of evidence, and the care and nuance of conclusions. Using this set of labeled data, we show that a popular natural language modeling processing pipeline, namely vector representation of words, a.k.a word embeddings, followed by Long Short Term Memory  model for capturing language generation as a state-space model, is able to quantitatively capture the scoring, with a high Quadratic Weighted Kappa  prediction score, when trained in via a novel contrastive learning set-up. We show that the ML algorithm approached the inter-rater reliability of human analysis. Ultimately, we conclude, that machine learning  for natural language processing  holds promise for assisting learning sciences researchers in conducting qualitative studies at much larger scales than is currently possible."
"Mental illnesses common problem modern world. More one ten people living mental health disorders 2017 , women affected. These disorders affect people's way thinking, mood, emotions, behaviour relationships others. Most mental illnesses remain undiagnosed social stigma around them. Depression one main causes disability globally , affects people ages. Prevention used reduce depression save lives people risk suicide, prevention limited raising awareness programs cultivate positive thinking case depression monitoring people attempted suicide self-harm. With rise social media use, computational efforts made detect mental illnesses depression PTSD , also detect misogyny , irony sarcasm users' texts. People tend talk emotions mental health problems online seek support. The sources mental health cues used detection Twitter, Facebook, Reddit forums . Reddit social media site similar forums. It organized subreddits specific topics, dedicated mental health problems. The use throwaway accounts maintain anonymity promotes disclosure, users likely share problems discussed anyone before. The use accounts makes difficult users receive social support majority used one post . In work, choose tackle problem detecting early onset depression users' posts social media, specifically Reddit. As such, explore eRisk 2018 dataset topic analysis means Latent Semantic Indexing learned out-of-distribution confidence scores . Due nature dataset, repurpose learned confidence score make decision whether label user depressed non-depressed wait data, test chunks progressively released every week.","   English.  Computational research on mental health disorders from written texts covers an interdisciplinary area between natural language processing and psychology. A crucial aspect of this problem is prevention and early diagnosis, as suicide resulted  from  depression being the second leading cause of death for young adults. In this work, we focus on methods for detecting the early onset of depression from social media texts, in particular from Reddit. To that end, we explore the eRisk 2018 dataset and achieve good results with regard to the state of the art by leveraging topic analysis and learned confidence scores to guide the decision process. \footnote{Copyright \copyright2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International .} %   Our analysis paves way to more in depth exploration of detection of mental illnesses from social media interactions."
"Neural text-to-speech techniques significantly improved naturalness speech produced TTS systems. We refer NTTS systems subset TTS systems use neural networks predict mel-spectrograms phonemes, followed use neural vocoder generate audio mel-spectrograms. In order improve prosody\footnote{We use subtractive definition prosody .} speech obtained NTTS systems, considerable work learning prosodic latent representations ground truth speech. These methods use target mel-spectrograms input encoder learns latent prosodic representations. These representations used decoder addition input phonemes, generate mel-spectrograms. The latent representations obtained encoding target mel-spectrogram sentence level information directly available phonemes, subtractive definition prosody, may claim representations capture prosodic information. Several variational non-variational methods proposed learning prosodic latent representations. While methods improve prosody synthesised speech, need input mel-spectrogram available running inference unseen text. This gives rise problem sampling learnt prosodic space. Sampling random prior may result synthesised speech contextually appropriate prosody, relationship text synthesised. In order improve contextual appropriateness prosody synthesised speech, work using textual features like contextual word embeddings grammatical information directly condition NTTS systems. These methods require NTTS model learn implicit correlation given textual features prosody sentence. One work also poses sampling problem selection problem uses syntactic distance BERT embeddings select latent prosodic representation ones seen training time. Bringing aforementioned ideas using ground truth speech learn prosodic latent representations using textual information, build Kathaka, model trained using two-stage training process generate speech contextually-appropriate prosody. In Stage~\Romannum{1}, learn distribution sentence-level prosodic representations ground truth speech using VAE. In Stage~\Romannum{2}, learn sample learnt distribution using text. In work, introduce BERT+Graph sampler, novel sampling mechanism uses contextual word-piece embeddings BERT syntactic structure constituency parse trees graph attention networks. We compare Kathaka strong baseline show obtains relative improvement naturalness."," 		In this paper, we introduce Kathaka, a model trained with a novel two-stage training process for neural speech synthesis with contextually appropriate prosody. In Stage, we learn a prosodic distribution at the sentence level from mel-spectrograms available during training. In Stage, we propose a novel method to sample from this learnt prosodic distribution using the contextual information available in text. To do this, we use BERT on text, and graph-attention networks on parse trees extracted from text. We show a statistically significant relative improvement of $13.2\%$ in naturalness over a strong baseline when compared to recordings. We also conduct an ablation study on variations of our sampling technique, and show a statistically significant improvement over the baseline in each case."
"Due growing presence AI-powered systems lives, affective computing become important part human-computer interaction. Emotion plays role thoughts actions integral part way communicate . The ability leverage context understand emotions communicated verbally non-verbally trivial humans remains difficult machines . Emotional responses depend psyche physiology governed perception situations, people objects. They also depend mental state . The way exhibit perceive emotion may also differ based age, gender, race, culture accent . In addition this, unlike targets classification tasks, emotions experience rarely distinct: often coexist without clear temporal boundaries, adding considerable complexity task . Despite difficulties, automated emotion recognition social commercial applications make worth pursuing. In medical domain, exciting potential: identify diagnose depression stress individuals , monitor help people bipolar disorder assist general public maintaining mental health. Commercial applications include call center customer management, advertising neuro-marketing social media engagement . As intelligent chatbots virtual assistants become widely used, emotion detection become vital component design, development deployment conversational agents . Early research emotion detection focused binary classification single modality, whether text, speech , images . Text-based classifiers used n-gram vocabulary sentences predict polarity speech models modeled vocal dynamics characterize emotions. These approaches inherently limited: binary granularity cues single modality far removed actual human process they're meant model. As result, joint approaches leverage available modalities promising. While existing multi-modal emotion corpora like IEMOCAP Crem-D critical progress affective computing date, suffer three issues focus work. First, corpora tend small due high costs annotating emotion. This precludes use deep neural models high model complexity require many training samples generalize well. This also compounds second difficulty inherent many emotion datasets: usually many neutral, happy sad training examples, often examples rarer emotions like disgust making difficult classify. This issue easily solved combining different corpora due third issue, lack mutual compatibility -- differ emotions identified, types dialogue number speakers represented naturalness recordings . This severely restricts generalizability models trained single corpus. Contemporary literature dealt problems dropping labels . Hard scarce emotions like disgust dropped corpus models trained evaluated trimmed corpus. This allows evaluating models different corpora using utterances exhibiting common emotions. While reasonable, resulting performance complete reflection models perform deployed production. When emotion models used real-world applications, expect encounter utterances corresponding dropped labels. For cases, models likely exhibit degraded performance predicting one known, incorrect labels. In work, address problem data sparsity transfer learning via pretrain-then-finetune paradigm. Deep complex models trained large datasets auxiliary related task learn network parameters reflect abstract notions related target task. As expression emotions highly dependent individual, train multilayer TDNN task speaker identification using VoxCeleb corpus fine-tune final layers task emotion identification using Crema-D corpus . Using network, extract speech embeddings Crema-D layers, generate concatenate text embeddings accompanying transcripts using fine-tuned BERT model train LDA - pLDA model resulting dense representations. pLDA allows model easily adapt previously unseen classes domains, requirement evaluating different emotion corpus incompatible label set performing well wild. To understand merits component, exhaustively evaluate predictive power every permutation: TDNN alone, speech embeddings layers alone, text embeddings alone every combination thereof. Our best variant, trained VoxCeleb Crema-D evaluated IEMOCAP, achieves Equal Error Rate \%. Including portion IEMOCAP training produces 5-fold averaged EER \%."," Automated emotion detection in speech is a challenging task due to the complex interdependence between words and the manner in which they are spoken. It is made more difficult by the available datasets; their small size and incompatible labeling idiosyncrasies make it hard to build generalizable emotion detection systems. To address these two challenges, we present a multi-modal approach that first transfers learning from related tasks in speech and text to produce robust neural embeddings and then uses these embeddings to train a pLDA classifier that is able to adapt to previously unseen emotions and domains. We begin by training a multilayer TDNN on the task of speaker identification with the VoxCeleb corpora and then fine-tune it on the task of emotion identification with the Crema-D corpus.  Using this network, we extract speech embeddings for Crema-D from each of its layers, generate and concatenate text embeddings for the accompanying transcripts using a fine-tuned BERT model and then train an LDA - pLDA classifier on the resulting dense representations. We exhaustively evaluate the predictive power of every component: the TDNN alone, speech embeddings from each of its layers alone, text embeddings alone and every combination thereof.  Our best variant, trained on only VoxCeleb and Crema-D and evaluated on IEMOCAP, achieves an EER of $38.05$\%. Including a portion of IEMOCAP during training produces a 5-fold averaged EER of $25.72$\% ."
"Vocoders originally used speech compression field communication. Recently, vocoders utilized various fields text-to-speech voice conversion speech-to-speech translation. Neural vocoders generate human-like voices using neural networks, instead using traditional methods contain audible artifacts . Recently, demonstrated vocoders exhibit superior performances generation speed audio fidelity trained single speaker utterances. However, models face difficulty generating natural sounds multiple domains speakers, language, expressive utterances. The ability models evaluated sound quality model trained data multiple speakers sound quality unseen domain . A vocoder generate high-fidelity audio various domains, regardless whether input encountered training come out-of-domain source, usually called universal vocoder. MelGAN vocoder based generative adversarial networks . It lightweight robust model unseen speakers yields lower fidelity popularly employed models . MelGAN alleviates metallic sound occurs mainly unvoiced breathy speech segments multi-scale discriminators receive different scale waveforms inputs. However, implemented efficiently learning multiple speakers universal vocoder. In study, propose Universal MelGAN. The generated waveform original MelGAN audible artifacts appears over-smoothing problem non-sharp spectrogram. We added multi-resolution spectrogram discriminators model address problem frequency domain. Our multi-scale discriminators enable fine-grained spectrogram prediction discriminating waveforms spectrograms. In particular, alleviate over-smoothing problem high frequency band large footprint model, enabling generation realistic multi-speaker waveforms. To evaluate performance proposed model, compare full-band MelGAN baseline two vocoders: WaveGlow WaveRNN. We designed experiments Korean English language independency. For evaluation, prepared multiple speaker utterances included unseen domain scenarios, new speakers, emotions, languages. The evaluation results indicate proposed model achieved best mean opinion score scenarios efficiently preserved fidelity unseen speakers. In addition, evaluations show model efficiently preserves original speech, even challenging domains expressive utterances unseen languages. In multi-speaker text-to-speech scenarios, model generate high-fidelity waveforms high MOS, model outperforms compared vocoders. This results without external domain information suggest possibility proposed model universal vocoder."," We propose Universal MelGAN, a vocoder that synthesizes high-fidelity speech in multiple domains. To preserve sound quality when the MelGAN-based structure is trained with a dataset of hundreds of speakers, we added multi-resolution spectrogram discriminators to sharpen the spectral resolution of the generated waveforms. This enables the model to generate realistic waveforms of multi-speakers, by alleviating the over-smoothing problem in the high frequency band of the large footprint model. Our structure generates signals close to ground-truth data without reducing the inference speed, by discriminating the waveform and spectrogram during training. The model achieved the best mean opinion score  in most scenarios using ground-truth mel-spectrogram as an input. Especially, it showed superior performance in unseen domains with regard of speaker, emotion, and language. Moreover, in a multi-speaker text-to-speech scenario using mel-spectrogram generated by a transformer model, it synthesized high-fidelity speech of 4.22 MOS. These results, achieved without external domain information, highlight the potential of the proposed model as a universal vocoder."
"%What spoken term detection Unsupervised speech modeling task discovering modeling speech units various levels audio recording without using prior linguistic information. It interesting, challenging impactful research problem phonetic, lexical even semantic information could acquired without process transcribing understanding given speech data. The relevant technology particularly important facilitate data preparation especially scenarios where: 1) large amount audio data readily available online untranscribed; 2) large amount audio recording available unpopular language structured linguistic knowledge documentation found. Spoken term discovery representative task unsupervised speech modeling. It aims discover repetitively occurred words and/or phrases untranscribed audio. The problem commonly tackled two-stage approach. In first stage, set subword units automatically discovered untranscribed speech data units turn used represent speech data symbol sequence. In second stage, variable-length sequence matching clustering performed subword sequence representations. One major drawback subword decoding errors first stage would propagate deteriorate outcome spoken term discovery second stage. The present study investigates use Siamese Triplet networks spoken term discovery. Siamese network commonly applied pattern classification matching problems weak labels available. We propose train Siamese/Triplet network small dataset matched mismatched sequence pairs obtained use trained network generate feature representations unseen subword sequences. The training dataset constructed based hypothesized spoken term clusters baseline spoken term discovery system developed previous study. With new feature representations learned Siamese/Triplet network, re-clustering subword sequences carried generate improved set discovered spoken terms."," Spoken term discovery from untranscribed speech audio could be achieved via a two-stage process. In the first stage, the unlabelled speech is decoded into a sequence of subword units that are learned and modelled in an unsupervised manner. In the second stage, partial sequence matching and clustering are performed on the decoded subword sequences, resulting in a set of discovered words or phrases. A limitation of this approach is that the results of subword decoding could be erroneous, and the errors would impact the subsequent steps. While Siamese/Triplet network is one approach to learn segment representations that can improve the discovery process, the challenge in spoken term discovery under a complete unsupervised scenario is that training examples are unavailable. In this paper, we propose to generate training examples from initial hypothesized sequence clusters. The Siamese/Triplet network is trained on the hypothesized examples to measure the similarity between two speech segments and hereby perform re-clustering of all hypothesized subword sequences to achieve spoken term discovery.  Experimental results show that the proposed approach is effective in obtaining training examples for Siamese and Triplet networks, improving the efficacy of spoken term discovery as compared with the original two-stage method."
"Evidence-based medicine medical practice aims find evidence support medical decisions. This evidence nowadays obtained biomedical journals, usually accessible online databases like PubMed EMBASE, provide free access articles' abstracts cases, full articles. In context COVID-19 pandemic, EBM critical making decisions individual level public health since research articles address topics like treatments, adverse cases, effects public policies medicine. The EBM foundation Epistemonikos made essential contributions curating publishing updated guides treatments working COVID-19~\footnote{http://epistemonikos.org/}. Epistemonikos addresses EBM combination software tools data collection, storage, filtering , retrieval, well vital labor volunteer physicians curate label research articles based quality , type PICO labels . However, workflow challenged 2020 increasing growth rapidly evolving evidence COVID-19 articles published latest months. Moreover, ensure rapid collection latest evidence published, pre-print repositories medRXiv bioRXiv added traditional online databases. % In order support Epistemonikos' effort filter curate flood articles related COVID-19, present results applied AI project implement evaluate text classification system filter categorize research articles related COVID-19. The current model, based Random Forests, acceptable performance classifying systematic reviews fails classifying document categories. In article, show using BioBERT yields marginal improvements, XLNET results significant progress best performance. These results save considerable amount time volunteer physicians pre-filtering articles worth manual curation labeling EBM. In average, physician takes two minutes reviewing one article, system present article review within one hour. %With help volunteer physicians, classify emergent literature COVID-19 virus systematic reviews, broad syntheses, primary studies, first step finding relevant clinical evidence. Until now, produced Random Forest model classifying documents different categories. However, paper, show use Transformers-based Language Models helped foundation save significant effort collaborators. %","  The COVID-19 has brought about a significant challenge to the whole of humanity, but with a special burden upon the medical community. Clinicians must keep updated continuously about symptoms, diagnoses, and effectiveness of emergent treatments under a never-ending flood of scientific literature. In this context, the role of evidence-based medicine  for curating the most substantial evidence to support public health and clinical practice turns essential but is being challenged as never before due to the high volume of research articles published and pre-prints posted daily. Artificial Intelligence can have a crucial role in this situation. In this article, we report the results of an applied research project to classify scientific articles to support Epistemonikos, one of the most active foundations worldwide conducting EBM. We test several methods, and the best one, based on the XLNet neural language model, improves the current approach by 93\% on average F1-score, saving valuable time from physicians who volunteer to curate COVID-19 research articles manually."
"The natural language processing community made tremendous progress using pre-trained language models improve predictive accuracy . Models surpassed human performance language understanding benchmarks SuperGLUE . However, studies shown results partially driven models detecting superficial cues correlate well labels may useful intended underlying task . This brittleness leads overestimating model performance artificially constructed tasks poor performance out-of-distribution adversarial examples. A well-studied example phenomenon natural language inference dataset MNLI . The generation dataset led spurious surface patterns correlate noticeably labels. highlight negation words often associated contradiction label. show model trained solely hypothesis, completely ignoring intended signal, reaches strong performance. We refer surface patterns dataset biases since conditional distribution labels given biased features likely change examples outside training data distribution . A major challenge representation learning NLP produce models robust dataset biases. Previous work targeted removing dataset biases explicitly factoring models. These works explicitly construct biased model, instance, hypothesis-only model NLI experiments, use improve robustness main model. The core idea encourage main model find different explanation biased model wrong. During training, products-of-experts ensembling used factor biased model. While works show promising results, assumption knowledge underlying dataset bias quite restrictive. Finding dataset biases established datasets costly time-consuming process, may require access private details annotation procedure, actively reducing surface correlations collection process new datasets challenging given number potential biases . In work, explore methods learning biased datasets require explicit formulation dataset biases. We first show model limited capacity, call weak learner, trained standard cross-entropy loss learns exploit biases dataset. We investigate biases weak learner relies show match several previously manually identified biases. Based observation, leverage limited capacity models product experts ensemble train robust model evaluate approach various settings ranging toy datasets large crowd-sourced benchmarks: controlled synthetic bias setup , natural language inference extractive question answering . Our contributions following: show weak learners prone relying shallow heuristics highlight rediscover previously human-identified dataset biases; demonstrate need explicitly know model dataset biases train robust models generalize better out-of-distribution examples; discuss design choices weak learners show trade-offs higher out-of-distribution performance expense in-distribution performance. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"," State-of-the-art natural language processing  models often learn to model dataset biases and surface form correlations instead of features that target the intended underlying task. Previous work has demonstrated effective methods to circumvent these issues when knowledge of the bias is available. We consider cases where the bias issues may not be explicitly identified, and show a method for training models that learn to ignore these problematic correlations.  Our approach relies on the observation that models with limited capacity primarily learn to exploit biases in the dataset. We can leverage the errors of such limited capacity models to train a more robust model in a product of experts, thus bypassing the need to hand-craft a biased model. We show the effectiveness of this method to retain improvements in out-of-distribution settings even if no particular bias is targeted by the biased model."
"Topic models popularly used extract abstract topics occur commonly across documents corpus field Natural Language Processing. Each topic group semantically coherent words represent common concept. In addition gaining insights unstructured texts, topic models used several tasks practical importance learning text representations document classification , keyphrase extraction , review understanding recommendations e-commerce domain , semantic similarity detection texts etc. % order make topic sampling distribution converge desired posterior distribution Early popular works topic discovery include statistical methods Latent Dirichlet Allocation approximates topic probability distribution word vocabulary performs approximate inference document-topic topic-word distributions Variational Bayes . This followed modified inference algorithm - Collapsed Gibbs sampling follows Markov Chain Monte Carlo . However, methods require expensive iterative inference step performed document. This circumvented introduction deep neural networks emergence Variational Autoencoders particular, variational inference performed single forward pass. % estimating posterior distribution. % Laplace approximation % The re-parameterisation trick VAEs allows perform variational inference differentiable manner training neural network. Such neural variational inference based topic models outperformed traditional probabilistic sampling methods. Broadly, model document Bag-of-Words determined basis frequency count vocabulary token given document. The BoW input processed MLP followed variational inference samples latent document-topic vector. A decoder network reconstructs original BoW using latent document-topic vector allows capture relationship document-topic topic-word distributions. VAE family neural topic models categorised basis prior enforced latent document-topic distribution. Methods NVDM , NTM-R , NVDM-GSM use Gaussian prior. NVLDA ProdLDA use Dirichlet prior approximation enables model capture document stems sparse set topics. % perform better providing coherent topics compared Gaussian prior. % order capture latent document-topic distribution, % The context vector obtained result attention used perform variational inference % capture semantics effectively % help inferring latent document-topic vector % carried usual VAE based topic models % using final LSTM state outputs corresponding While main focus previous neural topic models enforce suitable priors, little effort spent explicitly improving document encoding framework order capture document semantics better. In work, build upon VAE based topic model using laplace approximation Dirichlet prior propose novel framework model input document sequence tokens. The sequence processed LSTM allows encode sequential order remain preserved BoW. To allow model focus specific parts document, use attention mechanism attend different document tokens. We hypothesise topic-word distribution learned model factored attention mechanism enable model attend tokens convey topic related information cues. We validate hypothesis propose TAN-NTM: Topic Attention Networks Neural Topic Modeling performs attention efficiently topic guided manner. We perform separate attention topic using corresponding word probability distribution obtain topic-wise context vectors. The context vectors composed using topic weights represent proportion topic present given document. These topic weights obtained using learned token embedding topic-word distribution. The final composed context vector used perform variational inference followed BoW decoding. We perform extensive ablations compare different ways composing topic-wise context vectors. % averages coherence score topics % generated model In order evaluate approach, estimate commonly used NPMI coherence measures extent probable words topic semantically related other. Using metric, compare TAN-NTM model several previous state-of-the-art topic models outperforming significantly 4 benchmark datasets varying scale complexity - 20NewsGroup , Yelp Review Polarity, DBpedia AGNews . We demonstrate efficacy model learning better document feature representations latent document-topic vectors achieving higher document classification accuracy baseline topics models. Furthermore, topic models previously used improve supervised keyphrase generation . We show proposed framework adapted modify topic model improve keyphrase generation achieving SOTA performance StackExchange Weibo datasets. Our contributions summarised as: %"," Topic models have been widely used to learn representations from text and gain insight into document corpora. To perform topic discovery, existing neural models use document bag-of-words  representation as input followed by variational inference and learn topic-word distribution through reconstructing BoW. Such methods have mainly focused on analysing the effect of enforcing suitable priors on document distribution. However, little importance has been given to encoding improved document features for capturing document semantics better. In this work, we propose a novel framework: TAN-NTM which models document as a sequence of tokens instead of BoW at the input layer and processes it through an LSTM whose output is used to perform variational inference followed by BoW decoding. We apply attention on LSTM outputs to empower the model to attend on relevant words which convey topic related cues. We hypothesise that attention can be performed effectively if done in a topic guided manner and establish this empirically through ablations. We factor in topic-word distribution to perform topic aware attention achieving state-of-the-art results with $\sim$ $9$ - $15$ percentage improvement over score of existing SOTA topic models in NPMI coherence metric on four benchmark datasets - 20NewsGroup, Yelp, AGNews, DBpedia. TAN-NTM also obtains better document classification accuracy owing to learning improved document-topic features. We qualitatively discuss that attention mechanism enables unsupervised discovery of keywords. Motivated by this, we further show that our proposed framework achieves state-of-the-art performance on topic aware supervised generation of keyphrases on StackExchange and Weibo datasets."
"Popular static word representations word2vec~ lie Euclidean space evaluated symmetric judgments. Such measure expose geometry word relations, e.g., asymmetry. For example, ``ellipses like circles'' much natural ``circles like ellipses''. An acceptable representation may exhibit property. ~\citet{tversky1977features} proposed similarity measure encodes asymmetry. %Similarity sim two words A, B evaluated two factors weighting contribution non-overlapping part differently. It assumes word feature set, asymmetry manifests common features two words take different proportions respective feature sets, i.e., difference likelihoods word pair . In regard, degree correlation asymmetry obtained humans word embedding may indicate quality embedding encoding features. Word evocation experiment devised neurologist Sigmund Freud around 1910s obtain word directional relationship, word called cue shown participant asked ``evoke'' another word called target freely. ~ The experiment usually conducted many participants many cue words. The data produced group people exhibit collective nature word relatedness. The obtained data obtain asymmetry ratio~ resonates theory of~\citet{tversky1977features} ~\citet{Resnik:1995:UIC:1625855.1625914}. Large scale evocation datasets created study psychological aspects language. We interested three them; Edinburgh Association Thesaurus % ~, Florida Association Norms % ~ Small World Words % %. Those three datasets thousands cue words publicly available. We use derive human asymmetry judgments see well embedding-derived asymmetry measure aligns data. Evocation data rarely explored Computational Linguistics community, except that~\citet{griffiths2007topics} derived Florida Association Norms asymmetry ratio pair words measure directionality word relations topic models, and~\citet{nematzadeh2017evaluating} used word embedding. In paper, conduct larger scale study using three datasets, static embedding ~, GloVe ~, fasttext~) contextual embedding BERT~. We hope study could help us better understand geometry word representations inspire us improve text representation learning. To obtain static embedding, leverage vector space geometry projection soft-max similar ~; For contextual embedding BERT use method embedding varies context. Thus, use Bayesian method estimate word conditional distribution thousands contexts using BERT language model. In doing, probe word relatedness dynamic embedding space principled way. Comparing asymmetry measure popular cosine measure, observe similarity judgment fails correctly measure BERT's lexical semantic space, asymmetry judgment shows intuitive correlation human data. In final part paper, briefly discuss result means representation learning. This paper makes following contributions:"," Human judgments of word similarity have been a popular method of evaluating the quality of word embedding. But it fails to measure the geometry properties such as asymmetry. For example, it is more natural to say ``Ellipses are like Circles'' than ``Circles are like Ellipses''. Such asymmetry has been observed from a psychoanalysis test called word evocation experiment, where one word is used to recall another. Although useful, such experimental data have been significantly understudied for measuring embedding quality. In this paper, we use three well-known evocation datasets to gain insights into asymmetry encoding of embedding. We study both static embedding as well as contextual embedding, such as BERT. Evaluating asymmetry for BERT is generally hard due to the dynamic nature of embedding. Thus, we probe BERT's conditional probabilities  using a large number of Wikipedia contexts to derive a theoretically justifiable Bayesian asymmetry score. The result shows that contextual embedding shows randomness than static embedding on similarity judgments while performing well on asymmetry judgment, which aligns with its strong performance on ``extrinsic evaluations'' such as text classification. The asymmetry judgment and the Bayesian approach provides a new perspective to evaluate contextual embedding on intrinsic evaluation, and its comparison to similarity evaluation concludes our work with a discussion on the current state and the future of representation learning."
"Humor plays important role social communications. Unlike many objective classification tasks, task humor recognition constrained subjectivity. The perception joke differ among people due individual differences cognitive processes responsible humor processing , illustrated Figure . This makes challenging humor recognition models generalize wide range users, training data may reflect subjectivity annotators experiment participants . To achieve personalized humor recognition, necessary consider diversity user preferences. Previous research automated humor recognition casts task binary classification problem . These methods mainly focus design humor-related linguistic features input classifier obtain high classification performance. With well-established computational humor theories , curate many heuristics extract informative features. The key heuristic rules design effective approaches capture linguistic patterns n-gram statistics distinguish humorous text plain text. These methods able characterize intra-sentence inter-sentence dependencies unique humor, thus rely lot complexity classifiers. Nevertheless, feature generation process requires significant efforts many difficulties cope newly encountered terms . Deep learning shifts focus AI research feature engineering automatic feature extraction. Convolutional Neural Networks Transformer-based language models used end-to-end humor recognition. Most previous studies conducted curated explicitly balanced datasets underlying assumption people less agree distinction humorous non-humorous text. This assumption could limit model's ability generalize practice. Federated Learning, technique trains deep neural network based iterative averaging decentralized local updates, proved good handling unbalanced non-IID data distributions . Inspired recent progress federated learning diversity personalization , propose improve ability humor recognition models generalize diverse user preferences help federated learning. We name model . Specifically, adopt Federated Averaging algorithm fine-tuning pretrained Transformer-based language model task, employ diversification strategy handle disparate user preferences. The main idea solution force humor recognition model learn diverse range user preferences, thereby enhancing adaptability new users. For purpose, two important issues consider. First, users increasingly aware privacy issues reluctant provide personal information , imperative preserve users' privacy avoid direct harvesting explicit user preference personal devices. To address this, propose approximation strategy generate implicit user feedback given humorous text diversify label distributions represent diverse user preferences. Second, marginal distributions user preferences often lead salient class imbalance issue requires us select suitable evaluation metric rather widely adopted accuracy. As such, use F1 score evaluate select best models. To best knowledge, FedHumor first federated learning-based humor recognition model. Extensive results show approach able increase generalization bounds humor recognition model compared 9 state-of-the-art approaches. It promising approach help future AI applications recommend suitable humorous texts users tightened data privacy protection regulations , thereby enabling innovative emerging forms human-AI interaction."," Understanding humor is critical to creative language modeling with many applications in human-AI interaction. However, due to differences in the cognitive systems of the audience, the perception of humor can be highly subjective. Thus, a given passage can be regarded as funny to different degrees by different readers. This makes training humorous text recognition models that can adapt to diverse humor preferences highly challenging. In this paper, we propose the FedHumor approach to recognize humorous text contents in a personalized manner through federated learning . It is a federated BERT model capable of jointly considering the overall distribution of humor scores with humor labels by individuals for given texts. Extensive experiments demonstrate significant advantages of FedHumor in recognizing humor contents accurately for people with diverse humor preferences compared to 9 state-of-the-art humor recognition approaches."
". % % % final paper: en-us version % % space normally used marker This work licensed Creative Commons Attribution 4.0 International License. License details: \url{http://creativecommons.org/licenses/by/4.0/}. } Rhetorical Structure Theory one influential theories discourse analysis, document represented hierarchical discourse tree. As shown Figure a, leaf nodes RST tree text spans named Elementary Discourse Units , EDUs connected rhetorical relations form larger text spans entire document included. The rhetorical relations categorized Nucleus Satellite based relative importance. Thus, document-level discourse parsing consists three sub-tasks: tree construction, nuclearity determination relation classification. Moreover, downstream natural language processing tasks benefit RST-based structure-aware document analysis, summarization machine comprehension . By utilizing various linguistic characteristics , statistical approaches obtained substantial improvement English RST-DT benchmark . Recently, neural networks making inroads discourse analysis frameworks, attention-based hierarchical encoding integrating neural-based syntactic features transition-based parser . Lin et al. \shortcite{lin2019unified} follow-up work successfully explored encoder-decoder neural architectures sentence-level discourse analysis, top-down parsing procedure. Although discourse parsing received much research attention progress, models mainly optimized evaluated English. The main challenge shortage annotated data, since manual annotation RST framework labor-intensive requires specialized linguistic knowledge. For instance, popular benchmark English RST-DT corpus contains 385 samples, much smaller natural language processing tasks. The treebank size languages German , Dutch Basque even limited. Such limitations make difficult achieve acceptable performance languages required fully support downstream tasks, also lead poor generalization ability computational approaches. Since treebanks different languages share underlying linguistic theory, data-driven approaches benefit joint learning multilingual RST resources . Therefore, paper, investigate two methods build cross-lingual neural discourse parser: From embedding perspective: cross-lingual contextualized language models, train parser shared semantic space multilingual sources without employing language indicator; From text perspective: since EDU semantically-cohesive unit, unify target language space EDU-level translation, preserving original EDU segmentation discourse tree structures . To end, adapted enhanced end-to-end neural discourse parser, investigated two proposed approaches 6 different languages. While RST data training still small scale, achieved state-of-the-art performance fronts, significantly surpassing previous models, even approaching upper bound human performance. Moreover, conducted topic modeling analysis collected multilingual treebanks evaluate model generality across various domains."," Text discourse parsing plays an important role in understanding information flow and argumentative structure in natural language. Previous research under the Rhetorical Structure Theory  has mostly focused on inducing and evaluating models from the English treebank. However, the parsing tasks for other languages such as German, Dutch, and Portuguese are still challenging due to the shortage of annotated data. In this work, we investigate two approaches to establish a neural, cross-lingual discourse parser via:  utilizing multilingual vector representations; and  adopting segment-level translation of the source content. Experiment results show that both methods are effective even with limited training data, and achieve state-of-the-art performance on cross-lingual, document-level discourse parsing on all sub-tasks. \newline"
"In recent years, smart devices built-in personal assistants like Google Assistant Siri becoming omnipresent. Behind intelligent systems, key question identify underlying intent user utterance, triggered large amount work intent detection . Most existing intent detection systems built deep learning models trained large-scale annotated data. However, user demands functions smart devices continue grow, collecting supervised data every new intent becomes time-consuming labor-intensive. To address issue, studies tackle intent detection zero-shot learning manner, attempting utilize learned knowledge seen classes help detect unseen classes. The recent methods zero-shot intent detection roughly divided two categories: The first category , referred transformation-based methods, utilizes word embeddings label names establish similarity matrix, used transfer prediction space seen intents unseen intents. Another line work based compatibility-based methods , aims encode label names utterances representations semantic space calculate similarity. In kinds methods, critical problem learning intent representations. However, existing ZSID methods class-inductive, relies entirely labeled data seen intents training stage. Consequently, representations unseen intents cannot learned, resulting two limitations. First, ZSID methods good modeling relationship seen unseen intents. For transformation-based methods, label names given form raw phrases sentences, word embeddings label names inadequate associate connections seen unseen intents. For example, 閳ユ窂ookRestaurant閳 similar 閳ユ珐ateBook閳 measured word embeddings, share word 閳ユ窂ook閳 . However, meaning two intents relevant. % As result, computed similarity matrix inadequate associating connections seen unseen intents . For compatibility-based methods, minimize similarity seen intent samples seen label names shared semantic space, directly transfer detect unseen intents. Since unseen intent representations learned, might entangled representations seen intents. This severely hurt accuracy predicted label-utterance similarity, especially expressions utterances diverse. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Second, vanilla ZSL methods applicable generalized intent detection . Compared ZSL setting , assumes models presented utterances unseen classes test time, GZSID requires model detect seen unseen intents. In GZSID, existing ZSL models usually suffer dubbed domain shift problem, utterances unseen intents almost always mistakenly classified seen intents. Unlike class-inductive methods, class-transductive ZSL uses semantic information unseen classes model training . In context intent detection, label name provides proper sketch intent meaning. Motivated this, propose utilize label names unseen intents learn disentangled intent representations . Specifically, include unseen intents prediction space training, label names serving pseudo utterances. This allows model learn boundary seen unseen class semantic space. Under framework, introduce assistant task forces model find distinction seen unseen intents, thereby alleviating domain-shift problem. On basis, refine word embedding based similarity matrix averaging representations corresponding utterances label names. As result, better capture intent meanings similarity matrix reflects accurate intent connections. In summary, contribution three-fold: We believe potential class-transductive ZSL intent detection still fully exploited, encourage related studies future, release codes data."," Zero-shot intent detection  aims to deal with the continuously emerging intents without annotated training data. However, existing ZSID systems suffer from two limitations: 1) They are not good at modeling the relationship between seen and unseen intents, when the label names are given in the form of raw phrases or sentences. 2) They cannot effectively recognize unseen intents under the generalized intent detection  setting. A critical factor behind these limitations is the representations of unseen intents, which cannot be learned in the training stage. To address this problem, we propose a class-transductive framework that utilizes unseen class labels to learn Disentangled Intent Representations . Specifically, we allow the model to predict unseen intents in the training stage, with the corresponding label names serving as input utterances. Under this framework, we introduce a multi-task learning objective, which encourages the model to learn the distinctions among intents, and a similarity scorer, which estimates the connections among intents more accurately based on the learned intent representations. % Moreover, we present a novel approach to calculate the inter-intent similarities, on the basis of the learned intent representations, which estimates the connections among intents more accurately.  Since the purpose of DIR is to provide better intent representations, it can be easily integrated with existing ZSID and GZSID methods. Experiments on two real-world datasets show that the proposed framework brings consistent improvement to the baseline systems, regardless of the model architectures or zero-shot learning strategies."
"Multi-turn open-domain dialogue modeling active research topic field natural language processing. However, generating coherent informative response given dialogue context remains challenge. % However, still challenging dialogue models generate coherent informative response given dialogue context. %Research domain mainly addresses following two questions: 1) How learn represent context? 2) In presence context representation, infer distribution response? A critical challenge learning rich robust context representations dialogue utterances~, namely challenge encoding dialogue context vector adequately captures semantics . % A major challenge domain learn rich robust context representations dialogue utterances~, namely challenge encoding dialogue context vector adequately captures semantics . Large-scale pre-training language models using Transformer-based architectures recently achieved remarkable successes variety NLP tasks~. % Recently, large-scale pre-training language models using Transformer-based architectures achieved remarkable successes variety NLP tasks~. As such, increasingly work aims use pre-training language models conversation modeling~. For example, DialoGPT~ extends GPT-2~ generate conversation responses large-scale dialogue corpus. Meena~ trains sequence-to-sequence model~ Evolved Transformer~ large-scale multi-turn conversations. Blender, developed Facebook, provides recipes building open-domain chatbots perform well human evaluations~. However, existing pre-training conversation models usually view dialogue context linear sequence tokens learns generate next word token-level self-attention. One issue approach high-level relationships utterances harder capture using word-level semantics. % One issue approach relationships utterances scattered individual words, hindering capturing discourse-level coherence. For example, discourse-level relationship utterances ``coffee please'' ``here are'' apparent, word-level comparisons, coffee, please, are, obscures high-level relationship. % For example, utterance ``coffee please'' ``here are'' Figure strong certain relationship, contrast, pairs individual words two utterances coffee, please, obscure correlations. Furthermore, full pairwise attention inefficient since requires word context decoder interact words regardless distances semantic units. % Furthermore, full pairwise attention inefficient since requires word context decoder interact words regardless distances semantic units. To alleviate issues above, present DialogBERT, novel conversational response generation model. % To alleviate aforementioned issues, present DialogBERT, novel conversational response generation model. DialogBERT employs hierarchical Transformer architecture represent dialogue context. It first encodes dialogue utterances Transformer encoder encodes resulting utterance vectors using discourse-level Transformer obtain representation entire dialogue context. To efficiently capture discourse-level coherence among utterances, propose two training objectives analogy original BERT training: 1) masked context regression, masks randomly-selected utterance predicts encoding vector masked utterance directly; 2) distributed utterance order ranking, %reconstructs order utterances belong dialog context organizes randomly shuffled utterances conversation coherent dialogue context Learning-to-Rank~ neural network. We evaluate DialogBERT popular multi-turn conversation datasets, namely Weibo, MultiWOZ DailyDialog. Results show DialogBERT outperforms baselines terms perplexity, BLEU, NIST. Human evaluation supports superiority approach capturing discourse-level semantics generating plausible dialogue responses. %Our contributions summarized follows: %"," Recent advances in pre-trained language models have significantly improved neural response generation.  However, existing methods usually view the dialogue context as a linear sequence of tokens and learn to generate the next word through token-level self-attention.  Such token-level encoding hinders the exploration of discourse-level coherence among utterances.  This paper presents DialogBERT, a novel conversational response generation model that enhances previous PLM-based dialogue models. DialogBERT employs a hierarchical Transformer architecture.  To efficiently capture the discourse-level coherence among utterances, we propose two training objectives, including masked utterance regression and distributed utterance order ranking in analogy to the original BERT training.  Experiments on three multi-turn conversation datasets show that our approach remarkably outperforms the baselines, such as BART and DialoGPT, in terms of quantitative evaluation.  The human evaluation suggests that DialogBERT generates more coherent, informative, and human-like responses than the baselines with significant margins. % Pre-trained language models  have been successfully adapted to neural response generation.  % However, existing methods usually view the dialogue context as a linear sequence of tokens and learn to generate the next word through token-level self-attention. % Such token-level encoding hinders the exploration of discourse-level coherence among utterances. % In this paper, we present DialogBERT, a novel conversational response generation model that enhances previous PLM-based dialogue models. % %In order to model the utterance-level interactions, % Instead of a flat encoding of linear tokens, DialogBERT employs a hierarchical Transformer architecture.  % %DialogBERT consists of an utterance encoder for encoding utterances and a context encoder for learning to contextualize given utterances' representations. % To efficiently capture the discourse-level coherence among utterances, we propose two new training objectives including masked utterance regression and distributed utterance order ranking in analogy to the original BERT training.  % Experiments on three multi-turn conversation datasets show that  % our approach remarkably outperforms three baselines such as BART and DialoGPT in terms of quantitative evaluation.  % Human evaluation  % suggests  % %\jw{supports}  % that DialogBERT generates more coherent, informative and human-like responses than the baselines with significant margins."
"Event Detection , task involves identifying boundaries event triggers classifying corresponding event types, aims seek recognize events specific types given texts. As fundamental task information extraction, many high-level NLP tasks, information retrieval question answering, need event detector one essential components. % 娑旂喕顩﹂崝鐘茬穿閻 Recent studies show English ED models achieved great performance treating problem word-by-word sequence labeling task. Different English ED, many East Asian languages, including Chinese, written without explicit word boundary, resulting much tricky ED task. An intuitive solution apply Chinese Word Segmentation tools first get word boundaries, use word-level sequence labeling model similar English ED models. However, word boundary ambiguous Chinese thus word-trigger mismatch problem exists Chinese ED, event trigger may exactly match word, likely part word cross multiple words Figure demonstrates. Meanwhile, character-level sequence tagging able alleviate problem, Chinese character embedding carry limited information due lack word word-sequence information, resulting ambiguous semantics. % Therefore, better integrate segmentation-related information character-level semantics key feature Chinese ED models. Several recent works demonstrated considering lexicon word information could provide exact information discriminate semantics characters. \citeauthor{lin-etal-2018-nugget}~\shortcite{lin-etal-2018-nugget} designed NPN, CNN-like network model character compositional structure trigger words introduced gate mechanism fuse information characters words. ~\citeauthor{ding-etal-2019-event}~\shortcite{ding-etal-2019-event} proposed TLNN, trigger-aware Lattice LSTM architecture, exploiting semantics matched lexicon words improve Chinese ED. Although methods achieved great success, continue difficulty fully exploiting interaction characters lexicon words. Specifically, character, NPN exploits gate mechanism fuse information one corresponding word. This means character could incorporated one matched word, actually one character likely match several words, leading information loss. For TLNN, constructs cut paths link start end character matched word, semantic information matched lexicon word fails flow characters covers except last one, due inherently unidirectional sequential nature Lattice LSTM. %For characters without matched words, extra information provided enhance representation. Besides, previous ED works usually ignore semantic information maintained event types. We observe event types usually semantically related corresponding event triggers. Such observation shows considering semantic information event labels may provide fine-grained semantic signals guide detection event triggers, accordingly benefit ED performance. In paper, propose novel neural architecture, named Label Enhanced Heterogeneous Graph Attention Networks , Chinese ED. To promote better information interaction words characters, transform sentence graph. We first connect lexicon words characters covers. And neighboring characters also linked provide local context information enhance character representations, especially without matched lexicon word. To capture different granularity semantic information words characters, formulate words characters two types nodes, thus heterogeneous graph attention networks utilized enable rich information propagation graph. Additionally, design matcher module leverage semantic information event labels. Specifically, transform event labels event-trigger-prototype based embedding matrix summarizing trigger representations belonging event label. Based generated event label representation, margin loss exploited enhance ability discriminate confusing event labels. Comparing previous works, contributions follows:"," Event Detection  aims to recognize instances of specified types of event triggers in text. Different from English ED, Chinese ED suffers from the problem of word-trigger mismatch due to the uncertain word boundaries.  Existing approaches injecting word information into character-level models have achieved promising progress  to alleviate this problem, but they are limited by two issues. First, the interaction between characters and lexicon words is not fully exploited. Second, they ignore the semantic information provided by event labels.  We thus propose a novel architecture named Label enhanced Heterogeneous Graph Attention Networks .  Specifically, we transform each sentence into a graph, where character nodes and word nodes are connected with different types of edges, so that the interaction between words and characters is fully reserved. A heterogeneous graph attention networks is then introduced to propagate relational message and enrich information interaction. Furthermore, we convert each label into a trigger-prototype-based embedding, and design a margin loss to guide the model distinguish confusing event labels. Experiments on two benchmark datasets show that our model achieves significant improvement over a range of competitive baseline methods."
"% \rev{@Ileana: example indicate changes text, based revision.} % \todo[inline]{we need add color bars figures, promised reviewers} Given enough computational power, scalability attention mechanism~ allow building ever larger Natural Language Processing models billions parameters . While impressive, advances also pose responsibility NLP community interpret behavior hundreds attention heads single model, potentially reduce number computations. Responding challenge, previous work taken pioneering steps discover explain sparseness attention patters. Here, argue number heads grows range thousands, automatic measures would needed discover impose sparseness models. We introduce simple task-agnostic data-informed pruning method attention mechanisms: Attention Pruning. We train Transformer-based models analyze global observed attention patterns, averaged input sequences train set, order identify remove weak connections input tokens. Following \citet{lottery}, retrain models, enforcing sparseness masking, demonstrate attention mechanisms incorporate extraneous connections input tokens: obtain comparable % \question{or even marginally better performance} performance using sparse attention patterns NLP tasks language sequence-to-sequence modelling, well %Natural Language Inference . \rev{prediction GLUE tasks. Figure summarizes impact using pruning method standard NLP tasks.} These global sparseness patterns could help improve interpretability inference-time computational efficiency widely-used attention models. Our contributions follows: % The rest paper organized follows: In Section, present related work. In Section, introduce details behind attention pruning method. In Section, apply AP experiments language modelling. In Section, apply AP seq2seq modelling machine translation tasks. In Section, extend machine translation experiments demonstrate AP compatible -entmax regularization~, another promising sparseness technique. In Section, study effect AP BERT GLUE benchmark. % % Section. In Section discuss theoretically pruned Transformers could yield speedups terms MACs. % In Section, discuss hardware efficiency AP promise speeding modelling really long sequences. In Section, conclude point promising directions future work."," The attention mechanism is a key component of the neural revolution in Natural Language Processing . As the size of attention-based models has been scaling with the available computational resources, a number of pruning techniques have been developed to detect and to exploit sparseness in such models in order to make them more efficient. The majority of such efforts have focused on looking for attention patterns and then hard-coding them to achieve sparseness, or pruning the weights of the attention mechanisms based on statistical information from the training data. In this paper, we marry these two lines of research by proposing Attention Pruning : a novel pruning framework that collects observations about the attention patterns in a fixed dataset and then induces a global sparseness mask for the model. Through attention pruning, we find that about 90\% of the attention computation can be reduced for language modelling and about 50\% for machine translation and %natural language inference \rev{prediction with BERT on GLUE tasks}, while maintaining the quality of  the results. Additionally, using our method, we discovered important distinctions between self- and cross-attention patterns, which could guide future NLP research in attention-based modelling. Our approach could help develop better models for existing or for new NLP applications, and generally for any model that relies on attention mechanisms. Our implementation and instructions to reproduce the experiments are available at \url{https://github.com/irugina/AP}."
"DEEP learning modern machine learning technique based artificial neural networks. The field natural language processing significantly benefited use deep learning techniques recent years . There three prevalent deep learning architectures concerned NLP tasks: long-short term memory %networks , transformer networks convolutional neural networks . LSTMs exhibit relatively slow inference speeds less performant transformers CNNs regards text classification accuracy . Transformers recent innovation shown significant successes many NLP tasks . Their massive complexity trainable parameters order hundreds millions presents critical experiment reproducibility challenges researchers. State-of-the-art transformers difficult reproduce lab conditions high training cost monetary terms. There limited number pre-trained transformer models available different languages. \par CNNs demonstrated excellent success text classification tasks . There two paradigms available using CNNs text classification tasks, namely: world-level character-level CNNs . \par Word-level approaches dependant word-model represent text. The reliance pre-trained word-model poses potential problem one available particular language. Training new word models computationally time-consuming costly. There also technical challenges dealing misspellings words may exist word-model. The paradigm char-CNNs. No pre-trained language word models required. They also require costly pre-processing step text data. In general, char-CNNs accurate word-level CNNs transformers. Adding depth given benefit improved classification accuracy, seen image classification tasks. There open question research literature optimal architecture char-CNNs. Little research performed address limitations. Deep learning iterative process requiring tuning many hyper-parameters repeated experiments test efficacy potential architecture. It time consuming, costly tedious process requires expert skills domain knowledge. The task finding optimal char-CNNs NP-hard problem. \par Evolutionary computation collection search algorithms inspired principals biological evolution, particular concept survival fittest. EC methods use population individuals conduct simultaneous search limited time frame improve optimisation specified objective function via exchange information individuals population. The exchange information one key motivating factors selecting EC methods evolving char-CNNs work. There potential information exchange may reveal essential characteristics makes non-performant char-CNN performant one. EC methods concerned locating near-optimal solutions NP-hard problems. \par Evolutionary deep learning technique using EC methods search candidate CNN architectures combined backpropagation algorithm train potential candidate network architecture. EDL demonstrated success searching performant CNN architectures image classification tasks . EDL used search performant char-CNN architectures. \par Motivated success applying EDL techniques image classification domain, propose novel surrogate-based EDL algorithm appropriate searching landscape char-CNN architectures text classification domain. The proposed algorithm based genetic programming indirect encoding capable representing novel char-CNN architectures. The algorithm employs use surrogate models significantly reduce training time candidate char-CNNs evolutionary process. In summary, contributions proposed algorithm work are: %------------------------------------------------------------------------------"," Character-level convolutional neural networks  require no knowledge of the semantic or syntactic structure of the language they classify. This property simplifies its implementation but reduces its classification accuracy. Increasing the depth of char-CNN architectures does not result in breakthrough accuracy improvements. Research has not established which char-CNN architectures are optimal for text classification tasks. Manually designing and training char-CNNs is an iterative and time-consuming process that requires expert domain knowledge. Evolutionary deep learning  techniques, including surrogate-based versions, have demonstrated success in automatically searching for performant CNN architectures for image analysis tasks. Researchers have not applied EDL techniques to search the architecture space of char-CNNs for text classification tasks. This article demonstrates the first work in evolving char-CNN architectures using a novel EDL algorithm based on genetic programming, an indirect encoding and surrogate models, to search for performant char-CNN architectures automatically. The algorithm is evaluated on eight text classification datasets and benchmarked against five manually designed CNN architectures and one long short-term memory  architecture. Experiment results indicate that the algorithm can evolve architectures that outperform the LSTM in terms of classification accuracy and five of the manually designed CNN architectures in terms of classification accuracy and parameter count."
". % % % final paper: en-us version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. } Pre-trained language models received great interest natural language processing community last recent years . These models trained semi-supervised fashion learn general language model, example, predicting next word sentence . Then, transfer learning used leverage learned knowledge down-stream task, text-classification . \citet{devlin_bert:_2019} introduced ``Bidirectional Encoder Representations Transformers'' , pre-trained language model based Transformer architecture . BERT deeply bidirectional model pre-trained using huge amount text masked language model objective goal predict randomly masked words context . The fact is, BERT achieved state art results ``General Language Understanding Evaluation'' benchmark training single, task-specific layer output fine-tuning base model task. Furthermore, BERT demonstrated applicability many natural language tasks since including limited sentiment analysis , relation extraction word sense disambiguation , well adaptability languages English . However, fine-tuning data set often contains thousands labeled data points. This plethora training data often available real world scenarios . In paper, focus low-resource setting less 1,000 training data points. Our research attempts answer question pool-based active learning used increase performance text classifier based Transformer architecture BERT. That leads next question: How layer freezing techniques , i.e. reducing parameter space, impact model training convergence fewer data points? To answer questions, explore use recently introduced Bayesian approximations model uncertainty data selection potentially leads faster convergence fine-tuning introducing new data points maximize knowledge gain model. To best knowledge, work presented paper first demonstration combining modern transfer learning using pre-trained Transformer-based language model BERT model active learning improve performance low-resource scenarios. Furthermore, explore effect trainable parameters reduction model performance training stability analyzing layer-wise change model parameters reason selection layers excluded training. %Furthermore, explore whether sophisticated decoder architecture, i.e. convolutional neural networks improve overall performance added complexity hinders fast model adaption little training data. The main findings work summarized follows: a) found model's classification uncertainty unseen data approximated using Bayesian approximations therefore, used efficiently select data manual labeling active learning setting; b) analyzing layer-wise change model parameters, found active learning strategy specifically selects data points train first thus general natural language understanding layers BERT model rather later thus task-specific layers.","     Recently, leveraging pre-trained Transformer based language models in down stream, task specific models has advanced state of the art results in natural language understanding tasks. However, only a little research has explored the suitability of this approach in low resource settings with less than 1,000 training data points. In this work, we explore fine-tuning methods of BERT - a pre-trained Transformer based language model - by utilizing pool-based active learning to speed up training while keeping the cost of labeling new data constant. Our experimental results on the GLUE data set show an advantage in model performance by maximizing the approximate knowledge gain of the model when querying from the pool of unlabeled data. Finally, we demonstrate and analyze the benefits of freezing layers of the language model during fine-tuning to reduce the number of trainable parameters, making it more suitable for low-resource settings."
"% % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % . % % % final paper: en-us version % % space normally used marker This work licensed Creative Commons Attribution 4.0 International License. License details: \url{http://creativecommons.org/licenses/by/4.0/}. } Multilingual relation extraction important problem NLP, facilitating diverse set downstream tasks autopopulation knowledge graphs question answering . While early efforts relation extraction used supervised methods rely fixed set predetermined relations, research since shifted identification arbitrary unseen relations language. In paper, present method extracting high quality relation training examples date-marked news articles. This technique leverages predictable distributional structure articles build corpus denoised . We use corpus learn general purpose relation representations evaluate quality few-shot standard relation extraction benchmarks English Spanish little task-specific fine-tuning, achieving comparable results significantly data-intensive approach current state-of-the-art. The current state-of-the-art model, ``Matching Blanks"" MTB, distant supervision technique provides large gains many relation extraction benchmarks builds Harris' distributional hypothesis extensions. ~ assume informational redundancy large text corpora results sentences contain pair entities generally expressing relation. Thus, encoder trained collocate sentences used identify relation entities sentence finding labeled relation example whose embedding closest . While~ achieve state-of-the-art FewRel SemEval 2010 Task 8, approach relies huge amount data, making difficult retrain English language standard computational resources: fine-tune BERT large, mil parameters, mil+ relation pair statements batch size mil steps. In contrast method, relations statements language-model one-third size, achieves comparable performance fine-tuned little task-specific data. Our main contribution distant supervision approach assume sections news corpora exhibit even informational redundancy Wikipedia. Specifically, news days following event frequently re-summarizes event adding new details. As result, news exhibits strong form local consistency short rolling time windows otherwise fluid relations entities remain fixed. For example, relation Italy France expressed random piece text dynamic context-dependent, spanning wide range possibilities include ``enemies"", ``neighbors"" ``allies"". But, news coverage following 2006 World Cup, static -- sporting competitors. Therefore, considering sentences around specific events, extract groups statements express relation relatively free noise . Training multilingual BERT denoised corpus yields relation representations adapt well resource-constrained downstream tasks: evaluate quality FewRel SemEval 2010 Task 8, producing near state-of-the-art results finetuned little task-specific data. In addition strong performance approach English, easily generalizable languages, requiring news corpora event descriptions Wikipedia build high-quality training corpus. We evaluate Spanish find method outperforms mBERT TAC KBP 2016 relation corpus. We share code allow researchers apply approach news corpora own."," General purpose relation extraction has recently seen considerable gains in part due to a massively data-intensive distant supervision technique from that produces state-of-the-art results across many benchmarks. In this work, we present a methodology for collecting high quality training data for relation extraction from unlabeled text that achieves a near-recreation of their zero-shot and few-shot results at a fraction of the training cost. Our approach exploits the predictable distributional structure of date-marked news articles to build a denoised corpus -- the extraction process filters out low quality examples. We show that a smaller multilingual encoder trained on this corpus performs comparably to the current state-of-the-art  on few-shot and standard relation benchmarks in English and Spanish despite using many fewer examples ."
"Domain shift common language applications. One likely find ""internet"" ""PC"" reviews electronics books, likely find ""writing"" ""B.C."" reviews books electronics. This proposes fundamental challenge NLP many computational models fail maintain comparable level performance across domains. Formally, distribution shift happens model trained data one distribution , goal make good predictions distribution shares label space source. We study unsupervised domain adaptation work, fully-labeled data source domain labeled data target domain. The prevailing methods field aim learn domain-invariant feature aligning source target domains feature space. The pioneering works field try bridge domain gap discrepancy-based approach. first introduce MMD measure domain discrepancy feature space use variant MK-MMD objective minimize domain shift. Another line work introduces domain classifier adversarial training induce domain invariant feature, followed works using generative models enhance adversarial training. However, note MMD-based approach adversarial training formulates minimax optimization procedure widely known hard converge satisfactory local optimum. Moreover, recent works discovered guarantee good adaptation introduce inevitable error target domain label distribution shift may render incorrect distribution matching. For example, thinking binary classification task, source domain 50\% positive samples 50\% negative samples target domain 30\% postive 70\% negative. Successfully aligning distributions representation space requires classifier predict fraction positive negative source target. If one achieves 100\% accuracy source, target accuracy 80\%, 20\% error best. % Self-supervised learning prominent feature representation learning. Recent works approached unsupervised domain adaptation computer vision SSL[][]. [] adopted rotation prediction, flip prediction patch location prediction induce domain-invarint feature find auxiliary tasks involving fine-grained semantics like pixel reconstruction may force model focus domain-specific feature, widening domain gap. Self-supervised representation learning could good workaround problem enforces predictive behaviour matching instead distribution matching. The main idea learn discriminative representation able genenralize across domains. use sentiment-indicating pivot prediction auxiliary task cross-domain sentiment analysis. The method proposed paper adopts contrastive learning extract generalizable discriminative feature. Contrastive learning subclass self-supervised learning gaining popularity thanks recent progress. It utilizes positive negative samples form contrast queried sample pretext tasks order learn meaningful representations. However, pretext tasks must carefully chosen. shows experiments computer vision tasks transfer performance suffer improper pretext tasks like pixel reconstruction. % Recent developments contrastive learning obtained promising results representation learning benchmarks CV[][][] NLP[][][]. % Like self-supervised learning[], joint learning pretext tasks contrastive learning able align domain feature space, illustrated figure. There group works adopting domain adaptation CV[][][]. However, method cannot easily adopted NLP due inherent signal difference domains. . Therefore, paper explore two classic data augmentation methods natural language processing閳ユ敃ynonym substitution back translation define pretext task. Experiments two cross-domain sentiment classification benchmarks show efficacy proposed method. We also examine whether in-domain contrastive learning entropy minimization helps cross-domain sentiment classification varied label distribution settings. Our main contributions work summarized follows:","   Contrastive learning  has been successful as a powerful representation learning method. In this paper, we propose a contrastive learning framework for cross-domain sentiment classification. We aim to induce domain invariant optimal classifiers rather than distribution matching. To this end, we introduce in-domain contrastive learning and entropy minimization. Also, we find through ablation studies that these two techniques behaviour differently in case of large label distribution shift and conclude that the best practice is to choose one of them adaptively according to label distribution shift. The new state-of-the-art results our model achieves on standard benchmarks show the efficacy of the proposed method."
"Data augmentation widely-used technique classification tasks. In field computer vision , data augmented flipping, cropping, tilting, altering RGB channels original images~; however, similar intuitive simple strategies obtain equal success NLP tasks. Existing methods tend produce augmentation low readability unsatisfying semantic consistency~. & So Cute! The baby very! \\ \midrule & \\ \midrule & \underline{Cute}! The baby \underline{cute}! \\ \midrule Data Boost & \\ \bottomrule \end{tabular}% } \end{table} Table shows output samples popular text augmentation methods. Naive methods imitate pixel manipulation CV, augmenting sentences adding spelling errors~, randomly deleting swapping tokens~. The output augmentation methods often illegible since word order disrupted ; even worse, crucial feature words could mistakenly removed random deletion. A advanced method synonym insertion replacement~, uses Word2Vec~ replace words synonyms. Such method respects original sentence structure fails consider context. It sometimes replaces words synonyms awkward full context sentence. For example, replacing lovely fabulous get sentence ``The baby fabulous!"". Recent work leans towards translation-based methods augmentation~. In particular, \citet{yu2018qanet} proposed back-translation method first translates text French translates back English, using noisy output augmentation data. Although back-translation intuitive valid, generation skews towards high frequency words , causes repetition also leads lexical shrinkage augmented data. In nutshell, existing techniques still far perfect, partially due strong interdependency syntactic semantic features text data. In recent years, witnessed extensive progress language models . Large-scale LMs BERT~, XLNet~, GPT-2~, commonly trained large amounts text data . One interesting usages models utilizing text generators~. In paper, explore whether leverage generation ability state-of-the-art LMs, generate augmented samples given target class. Augmentation samples exhibit features target class. Off-the-shelf LMs cannot directly used augment data; since trained specific contexts, generation undirected random. Conditional LMs generate text directed certain condition , require training LM scratch data covering conditions. \citet{keskar2019ctrl}, instance, trained 1.6 billion-parameter LM conditioned variety control codes. The training rather costly; however, collecting sufficient data training also tedious, especially low-resource tasks~. We thus present Data Boost: reinforcement learning guided text data augmentation framework built off-the-shelf LM . Data Boost requires neither collecting extra data training task-specific LM scratch. We convert GPT-2 conditional generator, given task, guide generator towards specific class labels decoding stage reinforcement learning. The generated samples serve augmentation data similar original data terms semantics readability. The advantages Data Boost three-fold: First, Data Boost powerful. We achieve significant advances three tasks five different classifiers compared six related works. Second, Data Boost generates sentence-level augmentation. Unlike prior methods word-level phrase-level replacement~, augmented data much greater variety terms vocabulary sentence structure. Human evaluations also verify high readability label consistency augmentation. Third, Data Boost easy deploy. It require external datasets training separate systems . Instead, take off-the-shelf GPT-2 language model modify decoding stage without changing architecture."," Data augmentation is proven to be effective in many NLU tasks, especially for those suffering from data scarcity. In this paper, we present a powerful and easy to deploy text augmentation framework, Data Boost, which augments data through reinforcement learning guided conditional generation. We evaluate Data Boost on three diverse text classification tasks under five different classifier architectures. The result shows that Data Boost can boost the performance of classifiers especially in low-resource data scenarios. For instance, Data Boost improves F1 for the three tasks by 8.7\% on average when given only 10\% of the whole data for training. We also compare Data Boost with six prior text augmentation methods. Through human evaluations , we confirm that Data Boost augmentation has comparable quality as the original data with respect to readability and class consistency."
"%Recently, Neural machine translation~ achieved great success reached satisfactory translation performances several language pairs~. %These NMT models sequence-to-sequence models trained large parallel data. % Ensemble learning, aggregates multiple diverse models inference, attracted huge interest academia industry communities thanks effectiveness variety computational intelligence problems classification, prediction function approximation. So far, many aggregating approaches developed bagging boosting improve practical performance. % % Ensemble learning primarily used improve classification task reduce likelihood poorly learned model. % Recently, ensemble different neural networks greatly improved accuracy neural machine translation , making vital widely used technique state-of-the-art Neural NMT systems. In scenario NMT, common implementation average probability token computed different individual models decode averaged probabilities. Previous studies show performance ensemble method heavily depends accuracy diversity base models, typically obtained independent training different sets attributes. % % Ensemble learning, aggregates multiple models inference, % Despite success various tasks applications, practice common challenges ensemble methods, prevent wide usage: 1) High computational cost. For ensemble learning, individual models conduct encoding decoding, prohibitively time memory consuming. It gets even worse context NMT due large size state-of-the-art networks like transformer. 2) Absence monolingual data. Ensemble exploit independence cannot make full use large scale monolingual data source side. Recently, self-training method shown remarkable success image recognition. % Taking advantage unlabeled data, Trained noisy augmented data, EfficientNet model finetuned self-training achieve 87.4\% top-1 accuracy ImageNet, 1.0\% better state-of-the-art model requires 3.5B weakly labeled images. Typically, self-training first train base model labeled data, utilize learned model label unannotated data. Finally, labeled pseudo data combined training set yield next level model. In context natural language processing, many works successfully applied self-training technique including word sense disambiguation parsing. % Nevertheless, performance gains achieved self-training still limited structured prediction tasks Neural Machine Translation~ target space vast. Originally designed classification problems, previous work suggests self-training effective predictions unlabeled samples good enough, otherwise suffer notorious reinforced mistakes. However, problem common NMT scenario, hypotheses generated single model often far away ground-truth target due compositionality target space. \citet{zhang2016exploiting} found training biased pseudo data may accumulate mistakes time step enlarge error, thus propose freeze decoder parameters training pseudo parallel data may negatively impact decoder model NMT. % We argue performance drop self-training NMT mainly comes reinforced mistakes. To overcome issue, paper borrow reciprocal teaching concept educational field revisit core idea classic ensemble approaches. Ensemble built upon assumption different models different inductive biases better predictions made majority voting. We propose replace self-supervision Reciprocal-Supervision NMT, leading novel co-EM scheme named \method. In \method, use multiple separately learned models provide diverse proper pseudo data, allowing us enjoy independence different models dramatically reduce error strategic aggregation. %Most NMT works use one type neural network model ConvS2S~ Transformer~. %Usually, different neural models different performances may also catch minor different patterns sequences. More specifically, first learn multiple different models parallel data. Then E-step individual models used translate monolingual data. And M-step generated pseudo data produced different models combined tune student models. %To combine advantages diversities, intuitive method ensemble, several models trained every model used inference, output models combined better prediction. \method inspired success ensemble method. However, ensemble resource-demanding inference, prevents wide usage. Besides, cannot make use large scale monolingual data source side. %The teacher-student framework used make one model learn others. Some works done explore assistance right-to-left decoding model usual left-to-right model~. These works shown regular NMT model learn right-to-left decoding model obtain better performance. However, best knowledge, work exploring assistance several different models. So work, try utilize multiple different models teachers, train student model learn them. Through procedure, student model better performance. %Following procedure, another advantage monolingual data source side language easily utilized extend training method self-training framework diverse teachers. %Similar teacher-student framework zero-shot NMT~, student model also learn teachers monolingual data. \method also related data augmentation approaches NMT. While previous works concentrate monolingual data target side back-translation~, pay attention source side. Knowledge distillation another relevant research topic. However, KD preliminary designed improve weak student model much stronger teacher model. By contrast, \method boosts performance base models reciprocal-supervision comparable even weaker learners. % Unsupervised machine translation~ also seen utilizing target side monolingual data. To best knowledge, first self-training framework reciprocal-supervision, correct bias model fully utilize monolingual data source side language. More precisely, advantages \method % cooperative-supervised framework diverse parameterized networks summarized follows: Through extensive experiments, \method achieves significant gains several standard translation tasks including En\{Ro, De\}. Surprisingly, also found \method much weaker learners could even outperform strong BERT enhanced NMT model big margins.","  % Neural machine translation~ has achieved great success with the help of large amount of parallel data. % However, different model architectures have different advantages and translation abilities, but it is hard to integrate them all together to one model. % The ensemble method is too time-consuming for inference. % Besides, monolingual data are also not fully utilized. % Some works such as back-translation and unsupervised machine translation have tried to utilize monolingual data of target side, whereas the utilization of source side monolingual data still need be further explored. % In this work, we propose a self-training framework with diverse teachers to make one model be able to learn advantages and diversities from other models, and monolingual data of source side language can also be utilized to further improve the translation performances. % This method is very simple but much effective. % Empirical results show that our method can obtain further improvements on the standard En$\to$De and En$\to$Fr translation tasks.  Despite the recent success on image classification, self-training has only achieved limited gains on structured prediction tasks such as neural machine translation . This is mainly due to the compositionality of the target space, where the far-away prediction hypotheses lead to the notorious reinforced mistake problem. In this paper, we revisit the utilization of multiple diverse models and present a simple yet effective approach named Reciprocal-Supervised Learning . \method first exploits individual models to generate pseudo parallel data, and then cooperatively trains each model on the combined synthetic corpus. \method leverages the fact that different parameterized models have different inductive biases, and better predictions can be made by jointly exploiting the agreement among each other. Unlike the previous knowledge distillation methods built upon a much stronger teacher, \method is capable of boosting the accuracy of one model by introducing other comparable or even weaker models. \method can also be viewed as a more efficient alternative to ensemble. Extensive experiments demonstrate the superior performance of \method on several benchmarks with significant margins.\footnote{Code is available at \url{https://github.com/MinkaiXu/RSL-NMT}.} % \method takes advantage of different parameterized networks to generate diverse proper pseudo parallel data, and then dramatically reduce the bias through strategic combination of the pseudo data. %More specifically, we first train several NMT teachers with heterogeneous networks, then use the heterogeneous teacher models to label unlabeled data respectively and finally use the labeled data and unlabeled data to jointly train a student NMT model. % \method is very simple but much effective. % Empirical results demonstrate the effectiveness of \method on several benchmarks, where we even outperforms a strong BERT-enhanced baseline.   % Ensemble learning, which strategically aggregates multiple models for inference, has been shown effective to improve the accuracy of Neural Machine Translation . However, in practice it cannot be widely adopted due to the high computation and memory cost for involving all individual models.  % % Recently, transductive method has been proposed to overcome this obstacle, which, however, suffers the premise that the test data has to be available in advance.  % In this paper, we present a simple yet effective approach named Cooperative Training NMT , where we firstly use individual models to translate the source corpus into pseudo parallel data, and then cooperatively train all models on the translated synthetic corpus. \method leverages the fact that different parameterized models have different inductive biases, and better predictions can be made by jointly exploiting the independence between each other. Furthermore, given source monolingual data, \method enables us to avoid the reinforced mistakes problem of self-training and make the most of the monolingual set. Extensive experiments demonstrate our proposed approach can always achieve superior or comparable performance on several benchmarks with less computational cost."
"One first steps language acquisition learn word--meaning mappings, e.g., word ``dog'' sentence ``see dog'' refers tail-wagging animal kitchen table. This seemingly simple problem word learning complex puzzle; initial phases language development, children knowledge word meanings face great deal uncertainty. % Without prior information, given word , high level referential uncertainty -- great number potential meanings child's environment word could refer to. % Similarly, high level linguistic uncertainty mapping referent words utterances . % Moreover, additional difficulty arises mappings words referents one-to-one; sometimes words mapped one referent referents mapped one word . Strong empirical evidence suggests statistical cross-situational learning helps children adults navigate challenges, gradually keeping track statistical regularities across different situations , using help resolve ambiguous mappings \citep[\eg,][]{yu.smith.2007,smith.yu.2008}. However, cross-situational learning provide detailed account mechanisms responsible resolving type uncertainty different stages word learning. Moreover, large body developmental research studied inductive biases might facilitate word learning presence different types uncertainty \citep[\eg,][]{markman.1987}. A common theme among biases competition remove number possible hypotheses word meaning . For example, mutual exclusivity bias asserts referent mapped one word . % This competition among referents means given new word number possible referents, learner reduces uncertainty considering referents already associated words. It also suggested competitive processes play role locally globally: competition associating words meanings one observation well among observed words referents \citep[\eg,][]{yurovsky2013competitive}.\footnote{Work computational modeling cross-situational learning typically distinguish referent indicated word meaning. We use terms referent meaning interchangeably throughout paper, recognizing important notions relations two abstracted away approach.} Previous computational modeling work shed light mechanisms biases might involved cross-situational learning \citep[\eg,][]{frank.etal.2007, fazly.etal.2010.cogsci,trueswell.etal.2013,nematzadeh.etal.2017.cogsci.bias}. % However, knowledge, previous work done exhaustive analysis role competition in-the-moment learning mechanisms mechanisms interact different representations word meanings, may also influenced competition. % In work, contributions threefold: We provide general probabilistic formulation cross-situational word-learning show influential model \citet{fazly.etal.2010.csj} instance formulation. Using formulation, show % inductive biases modeled competitive processes in-the-moment overall word learning, well comprehension word meaning. Moreover, examine modeling choice affects learning presence different sources uncertainty, increased referential linguistic uncertainty, fewer exposures words, acquiring homonyms synonyms. We find best model across tasks one implements two types competition, among words referents. Moreover, competition happens in-the-moment learning comprehension . This result different previous modeling assumptions competition among referents introduced overall learning word meaning representations . It also suggests observed behavior people \citep[\eg,][]{yurovsky2013competitive} might explained competition comprehension global competitive process learning. We also observe best model performs better model \citet{fazly.etal.2010.csj} presence linguistic referential uncertainty, learn homonyms opposed model."," Children learn word meanings by tapping into the commonalities across different situations in which words are used and overcome the high level of uncertainty involved in early word learning experiences. In a set of computational studies, we show that to successfully learn word meanings in the face of uncertainty, a learner needs to use two types of competition: words competing for association to a referent when learning from an observation and referents competing for a word when the word is used."
"Hypernym, sometimes also known hyperonym, term linguistics referring word phrase whose semantic field covers hyponym. The common relationship hypernym hyponym ``is-a'' relationship. For example, ``red color'' provides relationship ``red'' ``color'', ``color'' hypernym ``red''. The hypernym-hyponym relation essential element semantic network corresponding tasks related semantic network analysis . The hypernym graph built collection hyponym-hypernym relations enhance accuracy taxonomy induction . The linkage hyponym hypernym used improve performance link prediction network completion knowledge graph semantic network . In natural language processing , hyponym-hypernym relation help named entity recognition , question-answering tasks ``what is'' ``is a'' . The data mining, information search retrieval also benefit hyponym-hypernym relation . Given role application hypernym-hyponym relation, essential explore automatic method extract relation two entities, presents important task knowledge-driven NLP . Following landmark work focusing lexico-syntactic patterns , several pattern-based methods developed hypernym extraction . Then feature-based classification methods introduced , applies machine learning tools enhance recall rate. Recently, distributional methods hybrid distributional models successfully applied learn embedding words, based hypernym-hyponym relation inferred . The deep learning approach also effective many sequence labeling tasks including hypernym extraction . While extraction hyponym-hypernym relation done many different environments, work focus hypernym extraction definitions. More specifically, definition refers short statement description word. Take word ``red'' example, whose definition Wikipedia ``Red color end visible spectrum light, next orange opposite violet.'' The aim identify word ``color'' hypernym ``red'' nouns definition. Intuitively, task solved general resources WordNet dictionary Wikipedia. But given word's different meanings different contexts, resources sufficiently complete task. As example, term ``LDA'' Wikipedia denotes ``Linear Discriminant Analysis'' machine learning, ``Low dose allergens'' medicine, ``Landing distance available'' aviation. The combination general resources context identification would also fail domain-specific applications general resources cover special technical terms area. Moreover, existing technical approaches also demonstrate certain limitations task hypernym extraction definitions, summarize follows: To briefly illustrate difficulty, let us consider definition Stack-Overflow irregular format: ``fetch-api: fetch API improved replacement XHR''. The term ``fetch-api'' included common dictionary. While definition ``is an'' pattern, connect hypernym. The definition short every distinct word definition appears once, makes difficult accurately learn word representation. Overall, challenging find method would accurately identify ``API'' correct hypernym. The definition word represents certain type knowledge extracted collected disordered data. Indeed, tools capable extracting definitions corpora good accuracy . Nevertheless, tools extract hypernym definitions remain limited. % To cope issue, propose recurrent network method using syntactic features. Because definition directly points noun, hyponym already given. Therefore, hypernym extraction identify correct hypernym words definition sentence. This task considered binary classification, classifier judges candidate noun hypernym not. In order better learn syntactic feature, transfer definition sentence part speech sequence labeling PoS word standard tool . The syntactic structure surrounding candidate learned bidirectional gated recurrent units based model. To fine tune results, use set features including centrality word hypernym co-occurrence network. We use two corpora evaluate method. One Wikipedia, featuring definitions canonical syntax structure intensively used previous studies. The Stack-Overflow, whose definition domain-specific usually irregular format. Our method compared several existing ones. Overall, outperforms others corpora, demonstrates advantage combing tool RNN PoS information task hypernym extraction. This paper organized follows. We review related works Section introduce details method Section . Experiments evaluations proposed model presented Section . After that, draw conclusion research Section ."," % The abstract should briefly summarize the contents of the paper in % 150--250 words. The hyponym-hypernym relation is an essential element in the semantic network. Identifying the hypernym from a definition is an important task in natural language processing and semantic analysis. While a public dictionary such as WordNet works for common words, its application in domain-specific scenarios is limited. Existing tools for hypernym extraction either rely on specific semantic patterns or focus on the word representation, which all demonstrate certain limitations. Here we propose a method by combining both the syntactic structure in definitions given by the word闁炽儲鐛 part of speech, and the bidirectional gated recurrent unit network as the learning kernel. The output can be further tuned by including other features such as a word闁炽儲鐛 centrality in the hypernym co-occurrence network. The method is tested in the corpus from Wikipedia featuring definition with high regularity, and the corpus from Stack-Overflow whose definition is usually irregular. It shows enhanced performance compared with other tools in both corpora. Taken together, our work not only provides a useful tool for hypernym extraction but also gives an example of utilizing syntactic structures to learn semantic relationships \footnote{Source code and data available at \url{https://github.com/Res-Tan/Hypernym-Extraction}}.  \keywords{Hypernym Extraction \and Syntactic Structure \and Word Representation \and Part of Speech \and Gated Recurrent Units.}"
"Although neural machine translation achieved great success sentence-level translation tasks, many studies pointed translation mistakes become noticeable document-level. They proved mistakes alleviated feeding inter-sentential contexts context-agnostic NMT models. Previous works explored various methods integrate context information NMT models. They usually take limited number previous sentences contexts learn context-aware representations using hierarchical networks extra context encoders . Different representation-based approaches, ~\citeauthor{tu2018learning}~\shortcite{tu2018learning} ~\citeauthor{kuang-etal-2018-modeling}~\shortcite{kuang-etal-2018-modeling} propose using cache memorize context information, either history hidden states lexicons. To keep tracking recent contexts, cache usually updated new translations generated. Therefore, long-distance contexts would likely erased. How use long-distance contexts drawing attention recent years. Approaches, like treating whole document long sentence using memory hierarchical structures , proposed take global contexts consideration. However, \citeauthor{kim2019and}~\shortcite{kim2019and} point words document beneficial context integration, suggesting essential word focus relevant context. \footnotetext{Dependency coreference relations Stanford CoreNLP .} To address problem, suppose build document graph document, word connected words direct influence translation. Figure shows example document graph. Explicitly, document graph %for document defined directed graph where: node represents word document; edge represents one following relations words: adjacency; syntactic dependency; lexical consistency; coreference. We apply Graph Convolutional Network document graph obtain document-level contextual representation word, fed conventional Transformer model additional attention gating mechanisms. We evaluate model four translation benchmarks, IWSLT English--French Chinese--English , Opensubtitle English--Russian , WMT English--German . Experimental results demonstrate approach consistently superior previous works language pairs. The contributions work summarized as:","     Previous works have shown that contextual information can improve the performance of neural machine translation . However, most existing document-level NMT methods failed to leverage contexts beyond a few set of previous sentences. How to make use of the whole document as global contexts is still a challenge. To address this issue, we hypothesize that a document can be represented as a graph     that connects relevant contexts regardless of their distances. We employ several types of relations, including adjacency, syntactic dependency, lexical consistency, and coreference, to construct the document graph. Then, we incorporate both source and target graphs into the conventional Transformer architecture with graph convolutional networks. Experiments on various NMT benchmarks, including IWSLT English--French, Chinese-English, WMT English--German and Opensubtitle English--Russian, demonstrate that using document graphs can significantly improve the translation quality."
"Automatic summarization fundamental task natural language generation computational linguistics. It crucial help user quickly read understand daily events, continuously studied decades. . In paper, focus meeting summarization, extensively studied task field automatic summarization. Given multiple speakers corresponding utterances text, task calls generating shorter transcript, covering salient information entire meeting. An example shown Figure , includes 3 speakers utterances , , well human-written summary. Meeting summarization typically regarded kind abstractive summarization problem literature. The majority existing studies build summarization systems based sequence-to-sequence model, adopts sequence modeling strategy encoding utterances . Despite effectiveness approaches, typically use sequential text information ignoring important influences dialogue structure. We claim dialogue-specific structural information important meeting summarization. For example, dialogue discourse effective structural feature. As shown Figure , ``Contrast閳, ``Question-Answer閳 ``Continuation閳 three dialogue discourse relations, provide precise semantic relationships utterance. Specifically, see existing sequence modeling method unable generate correct summary results ), attributed system knowing opposed 閳ユ獨 proposal. Differently, dialogue discourse provide key information via labeling 閳ユ窅ontrast閳 relationship, shown Figure . Accordingly, effectively integrate discourse relationship existing summarization model become crucial step meeting summarization. In paper, propose Dialogue Discourse-Aware Graph Convolutional Networks address problem. In detail, first convert entire meeting dialogue discourse labeling discourse graph, represents utterances discourse relationships vertices. Afterwards, additionally design six types directed edges one global vertex discourse graph facilitate information flow. Finally, employ graph convolutional network encode graph pass semantic representation RNN decoder. Besides, use question-answer discourse relationship construct pseudo-summarization corpus pre-training DDA-GCN. In conversation, question often sparks discussion, naturally, question used pseudo-summary subsequent discussions. We conduct experiments widely used AMI benchmark . Our approach outperforms various baselines. Moreover, analyze effectiveness dialogue discourse pseudo-summarization corpus. In end, give brief summary contributions: To best knowledge, first apply dialogue discourse model structure meeting meeting summarization; We design discourse-aware graph model encode entire meeting; Our model achieves new SOTA AMI dataset."," Sequence-to-sequence methods have achieved promising results for textual abstractive meeting summarization. Different from documents like news and scientific papers, a meeting is naturally full of dialogue-specific structural information. However, previous works model a meeting in a sequential manner, while ignoring the rich structural information. In this paper, we develop a Dialogue Discourse-Aware Graph Convolutional Networks  for meeting summarization by utilizing dialogue discourse, which is a dialogue-specific structure that can provide pre-defined semantic relationships between each utterance. We first transform the entire meeting text with dialogue discourse relations into a discourse graph and then use DDA-GCN to encode the semantic representation of the graph. Finally, we employ a Recurrent Neural Network to generate the summary. In addition, we utilize the question-answer discourse relation to construct a pseudo-summarization corpus, which can be used to pre-train our model. Experimental results on the AMI dataset show that our model outperforms various baselines and can achieve state-of-the-art performance."
"Pre-trained language models BERT RoBERTa learn contextualized word representations large-scale text corpus self-supervised learning, obtain new state-of-the-art results many downstream NLP tasks . Recently, researchers observed pre-trained language models internalize real-word knowledge model parameters. For example, pre-trained language models able answer questions ``the sky }'' ``Beethoven born }'' moderate accuracy. To explore potential, researchers proposed various approaches guide pre-training language models injecting different forms knowledge them, structured knowledge graph linguistic knowledge . \end{table*} Table lists previous knowledge-guided pre-trained language models training methods. We group two categories: generative tasks discriminative tasks. Generative tasks often formulated predicting masked tokens given context. By particularly masking words contain certain types knowledge generative pre-training, model adept memorizing completing knowledge. While discriminative tasks often formulated classification problem respect sentence tokens. By training positive negative examples constructed according external knowledge, discriminator capable verifying true false knowledge natural language. Existing research demonstrated generative discriminative training advantages: former large negative sample space model learn fine-grained knowledge, latter avoids ``'' tokens pre-training, therefore consistent fine-tuning. On hand, generative discriminative capture different aspects data distribution could complementary knowledge consolidation. However, best knowledge, previous work combining two approaches systematic way. Inspired recent success generative-discriminative pre-trained model named ELECTRA, propose learn generator discriminator jointly knowledge-guided pre-training, call KgPLM model. In paper, design masked span prediction generative knowledge completion task, span replacement checking discriminative knowledge verification task. Hybrid knowledge, including link structure Wikipedia structured knowledge graph Wikidata, used guide tasks. The spans covering factual knowledge likely selected masking replacement, choices replacements also related proximity original span knowledge space. Figure shows example span masking replacement tasks. To explore effective ways joint training two tasks, design two learning schemes, called two-tower scheme pipeline scheme. Basically, generator discriminator trained parallel shared parameters two-tower scheme. While pipeline scheme, output generator input successive discriminative training. The generator discriminator KgPLM model pre-trained based RoBERTa. They additional benefits: 1) model readily extended much larger pre-training corpus, keeps potential room improvement; 2) model retains amount parameters RoBERTa, require modifications fine-tuning downstream tasks. We evaluate model performance LAMA~, consists several zero-shot knowledge completion tasks, MRQA shared tasks~, include several benchmark question answering datasets. The experiments show proposed KgPLM, especially trained pipeline scheme, achieves state-of-the-art performance, significantly outperform several strong baselines tasks. The results indicate knowledge-guided generative discriminative pre-training provides effective way incorporate external knowledge achieve competitive performance knowledge intensive NLP tasks."," Recent studies on pre-trained language models have demonstrated their ability to capture factual knowledge and applications in knowledge-aware downstream tasks. In this work, we present a language model pre-training framework guided by factual knowledge completion and verification, and use the generative and discriminative approaches cooperatively to learn the model. Particularly, we investigate two learning schemes, named two-tower scheme and pipeline scheme, in training the generator and discriminator with shared parameter. Experimental results on LAMA, a set of zero-shot cloze-style question answering tasks, show that our model contains richer factual knowledge than the conventional pre-trained language models. Furthermore, when fine-tuned and evaluated on the MRQA shared tasks which consists of several machine reading comprehension datasets, our model achieves the state-of-the-art performance, and gains large improvements on NewsQA  and TriviaQA  over RoBERTa."
"Knowledge graphs , WordNet , Freebase Wikidata , aggregate large amount human knowledge express structured way. % representative existing KGs, knowledge formalized triples. %, head entity, tail entity, relation two entities. The large number triples KGs constructed complex knowledge network, far complete. In recent years, knowledge graph completion tasks attracted great attention. Despite new state-of-the-art models emerge constently, methods ignore topological structure information KGs. Relation paths common topological structure KGs, Figure shows relation path instances. relation triple, two-step relation path. Similar word context language models , relation paths considered one kind contextual information KGs. We call ``graph contextual information''. And Harris's famous distributional hypothesis also extend knowledge graphs: shall know entity relationships involves. Although two kinds contextual information similar, latter specialities. In knowledge graphs, relation paths meaningful. For example, valid relation path, indicate must relationship . Unreliable relation paths common knowledge graphs, \citet{lin2015modeling} found necessary select reliable relation paths knowledge representation learning. %In work, path-constraint resource allocation algorithm proposed measure weights inference patterns. They learn inference patterns relations paths utilize knowledge contained relation paths. %Despite success, modeling objects limited inference patterns relations paths. %Recently, \citeauthor{wang2019coke} \shortcite{wang2019coke} propose method model contextual nature triples relation paths, explore benefits graph contextual information link prediction tasks two specific datasets. %However, simply adding graph contextual information training pool always effective, operation may reduce performance original model. Instead relying inference patterns, propose PPKE, path-based pre-training approach integrates graph contextual information contained relation paths model parameters. We think general way develop unexploited graph contextual information. During path-based pre-training procedure, two-step relation paths extracted knowledge graph fed pre-training module original triples. Then, pre-trained model finetuned downstream KGC tasks, link prediction relation prediction. Our contributions follows:"," 		Entities may have complex interactions in a knowledge graph , such as multi-step relationships, which can be viewed as graph contextual information of the entities. 		Traditional knowledge representation learning  methods usually treat a single triple as a training unit, and neglect most of the graph contextual information exists in the topological structure of KGs. 		In this study, we propose a Path-based Pre-training model to learn Knowledge Embeddings, called PPKE, which aims to integrate more graph contextual information between entities into the KRL model. 		Experiments demonstrate that our model achieves state-of-the-art results on several benchmark datasets for link prediction and relation prediction tasks, indicating that our model provides a feasible way to take advantage of graph contextual information in KGs."
"Machine reading comprehension challenging natural language understanding task lets machine predict appropriate answer question according given passage document . According answer styles, MRC tasks roughly divided generative , extractive multi-choice tasks . The multi-choice task focus work. Recently, various datasets tasks proposed, promoting rapid improvement MRC techniques . Early MRC datasets usually provide passages whose contents extracted articles . Recently, conversational reading comprehension aroused great interests whose passages derived multi-turn dialogue segments , making task challenging. The popular practice solve MRC problems adopting pre-trained language models encoder module . Instead better exploiting pre-trained LMs, paper motivated human reading strategies decouples MRC sketchy reading extracting critical spans passage, extensive reading seeking external knowledge. As result, propose knowledge enhancement model based extracted critical information called RekNet . In detail, proposed RekNet refines fine-grained critical information span extraction model defines Reference Span, quotes relevant external knowledge form quadruples co-occurrence information Reference Span answer options. An example process RekNet shown Figure . In summary, main contributions follows:\\ 1) We propose novel reference-based knowledge enhancement model RekNet, makes first attempt obtain fine-grained evidence inference knowledge retrieving MRC tasks.\\ 2) RekNet uses novel knowledge quadruples quote relevant credible knowledge.\\ 3) RekNet applied two multi-choice MRC benchmarks, RACE DREAM improves performance baseline models 1.0\% 1.1\% respectively, pass significance test MRC tasks."," Multi-choice Machine Reading Comprehension  is a major and challenging form of MRC tasks that requires model to select the most appropriate answer from a set of candidates given passage and question. Most of the existing researches focus on the modeling of the task datasets without explicitly referring to external fine-grained commonsense sources, which is a well-known challenge in multi-choice tasks. Thus we propose a novel reference-based knowledge enhancement model based on span extraction called 	extbf{Reference Knowledgeable Network }, which simulates human reading strategy to refine critical information from the passage and quote external knowledge in necessity. In detail, RekNet refines fine-grained critical information and defines it as Reference Span, then quotes external knowledge quadruples by the co-occurrence information of Reference Span and answer options. Our proposed method is evaluated on two multi-choice MRC benchmarks: RACE and DREAM, which shows remarkable performance improvement with observable statistical significance level over strong baselines."
"Data collection essential part field spoken dialogue systems conversational AI. %, requires developers make difficult decisions budget accordingly. In particular, designing dialogue system completely new domain still challenging task. Data collection options include running lab-based experiments, crowd-sourced tasks gathering data social media platforms, Reddit Twitter. Ambitious large scale data collections across multiple domains resulted widely used datasets, MultiWOZ . % collected various platforms .% create representations dialogues vector space. However, starting new domain scratch still challenges. Difficult costly decisions made collect data. A large majority recent dialogue corpora collected using crowd-sourcing either pairing workers letting chat, often given topic , asking add next utterance dialogue given set conditions . Other studies recruited subjects play role system, i.e., act wizard user . Each approaches advantages disadvantages, depending dialogue task-oriented not. By letting users type unrestricted way, richness dialogue increases, positive feature chit-chat. On hand, much variability could problem high stakes, task-oriented dialogues, medical domain. Letting multiple users contribute one utterance per dialogue , speeds data collection, however, dialogues may lack coherence severely diverge real dialogues. On hand, hiring training subjects chat perform wizard role results controlled data collection dramatically increases cost data collection makes less scalable. The quality datasets often assessed according degree variability observed lexical complexity utterances collected . %, however best knowledge, work assessing impact different methods directly training dialogue models. %This paper aims addressing issue investigating impact two different data collection methods performance model. Furthermore, above-mentioned datasets focus increasing size dataset available dialogue research, rather investigating impact data collection strategies performance models trained. The work presented paper aims highlighting pros cons, using methodology quickly leverage robust dialogue system, minimising cost effort involved data collection process. Analyses comparing different strategies data collection process across various platforms done past , aware similar study dialogue data. The data used study collected scope emergency response system used off-shore energy platform part EPSRC ORCA Hub programme . One collections done using crowd-sourcing second one done lab using Wizard-of-Oz setting, participants interacting either social robot smart speaker. Both datasets used train dialogue model using implementation Hybrid Code Network compare results achieved models trained data collected either method. To validate use crowd-sourced data bootstrap dialogue system situated interaction, ran experiments train model crowd-sourced data test lab data, order verify %This result estimate number dialogues needed %varied amount crowd-sourced dialogues training estimate necessary amount crowd-sourced data needed achieves comparable performances models trained lab data. The contributions paper follows: 1) comparison models trained two datasets collected different ways task, 2) evidence suggests specialised dialogue tasks, emergency response task, well covered current pre-trained dialogue models, 3) set recommendations regarding data collection dialogue research.\footnote{Please find code data in: \href{https://github.com/zedavid/TheLabVsTheCrowd}{}.} The paper organised follows. Section cover previous work related problem. Our experimental set-up introduced Section , followed results Section . The paper concludes discussion Section future work conclusions Section .","  Challenges around collecting and processing quality data have hampered progress in data-driven dialogue models. %, particularly data-hungry neural and hybrid models.   Previous approaches are moving away from costly, resource-intensive lab settings, where collection is slow but where the data is deemed of high quality. The advent of crowd-sourcing platforms, such as Amazon Mechanical Turk, has provided researchers with an alternative cost-effective and rapid way to collect data.   %However, these platforms are sometimes notorious for data anomalies due to the rapid nature of which data is collected.   However, the collection of fluid, natural spoken or textual interaction can be challenging, particularly between two crowd-sourced workers. In this study, we compare the performance of dialogue models for the same interaction task but collected in two different settings: in the lab vs. crowd-sourced. We find that fewer lab dialogues are needed to reach similar accuracy, less than half the amount of lab data as crowd-sourced data.. We discuss the advantages and disadvantages of each data collection method. %, which is of interest to the community in terms of platform choice and how much data will be needed to be collected."
". % % % final paper: en-us version % % space normally used marker This work licensed Creative Commons Attribution 4.0 International License. \\ License details: \url{http://creativecommons.org/licenses/by/4.0/}. } The recent surge popularity voice assistants, Google Home, Apple閳ユ獨 Siri, Amazon閳ユ獨 Alexa resulted interest scaling products regions languages. This means components supporting Spoken Language Understanding devices, Automatic Speech Recognition , Natural Language Understanding , Entity Resolution facing challenges scaling development maintenance processes multiple languages dialects. When voice assistant launched new locale, underlying speech processing components often developed specifically targeted country, marketplace, main language variant country. Many people assume device ``understands'' ``speaks'' specific language, example English, able work equally well English-speaking country, misunderstanding. For instance, speaker UK English asks device trained data collected United States ``tell famous football player'', highly unlikely device provide user's desired answer, since football means different things US UK cultures. As result, developers need take account language dialectal differences, also local culture, provide right information right language setup. An increase number target marketplaces often means linear increase effort needed develop maintain locale-specific models. NLU models, classify user閳ユ獨 intent extract significant entities user閳ユ獨 utterance, face challenge maintaining high accuracy able accommodate multiple dialects language content. The major tasks NLU intent classification slot filling. Intent classification task predict action user intends voice assistant take. Slot filling task identify specific semantic arguments intention. For example, user閳ユ獨 request ``play Poker Face Lady Gaga'', user閳ユ獨 intention ``play music'', order fulfill command specified details, system needs capture slots \{song name = Poker Face\}, \{artist name = Lady Gaga\}. These tasks called intent classification named entity recognition , respectively. One common approach use max-entropy classification model IC task conditional random fields model NER task. Following advent deep learning techniques related fields, computer vision natural language processing, deep learning becoming popular NLU well. Some recent multilingual approaches NLU include, example, Convolutional Neural Network model sentence classification , Long Short-Term Memory model NER prediction . In deep neural network architecture, aforementioned NLU tasks combined single multi-task classification model. An increasing number experiments also focus multilingual setups, especially field machine translation, task translate input one language another . One recent thread multilingual research centers around learning multilingual word representation. Multilingual word embeddings shared cross-lingual vector space one main property: words different languages similar meaning must geometrically close. This property allows transfer learning one language another various multilingual tasks, dependency parsing classification NER . A number model architectures proposed pre-train multilingual word representations, leveraging large-scaled LSTM networks trained monolingual corpora adversarial setup space alignment , transformers trained multilingual corpora single language model . Although models used solve IC NER tasks appending corresponding decoders generate final predictions, straightforward use production environments due latency memory constrains. A different way benefitting larger models could use transfer learning smaller-size models improve performance initializing parts model close-to-optimal rather random weights. In paper, extend multi-task approach studied general multilingual model IC NER tasks, based deep learning techniques, bidirectional Long Short-Term Memory CRF sequence labeling model NER along multilayer perceptron IC. We also explore multilingual transfer learning benefits setup. Transfer learning widely adapted zero-shot few-shot setups, explored multilingual NLP studies , also used multi-task IC-NER models , yet best knowledge, study applying transfer learning data-rich target languages multilingual setup. In experiment, apply few-shot transfer learning data-rich languages language smaller amout training data. In additon, also apply transfer learning mimic situation expanding model ability same-level-resource language known context another high-resource language, new multilingual model ``inherit'' context information ancestors. We investigate approaches transfer learning effects model performance. We show transfer learning improve NLU model performance even data-rich conditions."," 	With the recent explosion in popularity of voice assistant devices, there is a growing interest in making them available to user populations in additional countries and languages. However, to provide the highest accuracy and best performance for specific user populations, most existing voice assistant models are developed individually for each region or language, which requires linear investment of effort. In this paper, we propose a general multilingual model framework for Natural Language Understanding  models, which can help bootstrap new language models faster and reduce the amount of effort required to develop each language separately. We explore how different deep learning architectures affect multilingual NLU model performance. Our experimental results show that these multilingual models can reach same or better performance compared to monolingual models across language-specific test data while require less effort in creating features and model maintenance."
". % % % final paper: en-us version % % % space normally used marker This work licensed Creative Commons Attribution 4.0 International License. License details: \url{http://creativecommons.org/licenses/by/4.0/}. } The widespread dissemination fake news lead significant influence personal fame, public trust, security. For example, spreading misinformation, ``Asians vulnerable novel coronavirus''~\footnote{https://www.thestar.com.my/news/regional/2020/03/11/myth-busters-10-common-rumours-about-covid-19} COVID-19 serious repercussions, making people ignore harmfulness virus directly affecting public health. Research shown misinformation spreads faster, farther, deeper, widely true information. Therefore, fake news detection social media attracted tremendous attention recently research industrial fields. Early research fake news detection mainly focused design effective features various sources, including textual content, user profiling data, news diffusion patterns. Linguistic features, writing styles sensational headlines, lexical syntactic analysis, explored separate fake news true news. Apart linguistic features, studies also proposed series user-based features, temporal features news diffusion. However, feature-based methods time-consuming, biased, require lot labor design. Besides, features easily manipulated users. To solve problems, many recent studies apply various neural networks automatically learn high-level representations fake news detection. For example, recurrent neural network , convolutional neural network , matrix factorization graph neural network applied learn representation content diffusion graph news. These methods apply types information fake news detection, paying little attention early detection. Moreover, models detect fake news consideration fixed proportion repost information, practice cannot detect fake news early stage news propagation. Some studies explore detect fake news early relying minimum number posts. The main limitation methods ignore importance publishers' users' credibility early detection fake news. When humans see piece breaking news, firstly may use common sense judge whether factual errors it. At time, also consider reputation publishers reposted users. People tend believe news trusted authoritative source news shared lots users good reputation. If publisher reliable, tend believe news. On hand, news reposted many low-reputation users short period, may spammers tried heat news, resulting lower credibility news. Inspired observation, explicitly take credibility publishers users supervised information, model fake news detection multi-task classification task. We annotate small part publishers users historical publishing reposting behaviors. Although credibility publishers users always provide correct information, necessary complementary supervised information fake news detection. To make credibility information generalized unannotated users, construct heterogeneous graph build connections publishers, news, users. Through graph-based encoding algorithm, every node graph influenced credibility publishers users. In paper, address following challenges: How fully encode heterogeneous graph structure news content; How explicitly utilize credibility publishers users facilitating early detection fake news. To tackle challenges, propose novel structure-aware multi-head attention network early detection fake news. Firstly, design structure-aware multi-head attention module learn structure publishing graph produce publisher representations credibility prediction publishers. Then, apply structure-aware multi-head attention module encode diffusion graph news among users generate user representations credibility prediction users. Finally, apply convolutional neural network map news text word embedding semantic space utilize fusion attention module combine news, publisher, user representations early fake news detection. The contributions paper summarized follows:"," The\let\thefootnote\relax\footnotetext{* Corresponding author.} dissemination of fake news significantly affects personal reputation and public trust. Recently, fake news detection has attracted tremendous attention, and previous studies mainly focused on finding clues from news content or diffusion path. However, the required features of previous models are often unavailable or insufficient in early detection scenarios, resulting in poor performance. Thus, early fake news detection remains a tough challenge. Intuitively, the news from trusted and authoritative sources or shared by many users with a good reputation is more reliable than other news. Using the credibility of publishers and users as prior weakly supervised information, we can quickly locate fake news in massive news and detect them in the early stages of dissemination.  In this paper, we propose a novel Structure-aware Multi-head Attention Network , which combines the news content, publishing, and reposting relations of publishers and users, to jointly optimize the fake news detection and credibility prediction tasks. In this way, we can explicitly exploit the credibility of publishers and users for early fake news detection. We conducted experiments on three real-world datasets, and the results show that SMAN can detect fake news in 4 hours with an accuracy of over 91\%, which is much faster than the state-of-the-art models. The source code and dataset can be available at https://github.com/chunyuanY/FakeNewsDetection."
"Real-world events sports games elections involve competing teams, capabilities tactics, aiming win . The performance teams typically dependent teams' abilities also environment within operate. For example, political party may best orators policies opponents may better getting votes key areas. Similarly, top football team may playing worst team league fact latter may facing relegation may provide extra motivation win game. Given this, many cases, performance teams may easily predictable. % In particular, sporting events many human factors impact team performs given games. There often situations would hard represent numbers statistics alone. For example, sporting rivalries often affect human emotions team performance teams fighting avoid relegation league often obtain unexpected results. Traditional AI machine learning techniques predict outcome real-world events tend focus use statistical machine learning using historical data individual teams . However, per examples above, historical performance may useful team performance may dependent dynamic factors human performance environmental variables . In turn, humans better judges algorithms faced previously unseen situations. Journalists, online communities, experienced analysts may better evaluating human environmental elements forecast outcome. For example, one approach looking statistics sports sentiment analysis social media platforms. Schumaker, Jarmoszko Labedz use approach predict English Premier League results achieve accuracy 50\% show use similar analysis performed American Football results National Football League predicting winner 63.8\% time. However, approaches focus opinion aggregation rather trying extract potential indicators performance individual human teams human experts. Against background, set new baselines results predicting real-world sporting events involving humans based combination Natural Language Processing statistical machine learning techniques. In detail, focus specifically football games EPL using match previews media alongside statistical machine learning techniques. The prediction football match outcomes challenging computational problem due range parameters influence match results. To date, probabilistic methods devised since seminal work Maher generated fairly limited results appear reached glass ceiling terms accuracy. By using media previews improve accuracy current approaches match outcome prediction. By doing, show incorporating human factors model, rather basic performance statistics, improve accuracy . Thus, contributions paper follows: In next section discuss match outcome prediction problem football new feature set explore. %The rest paper organised follows. Section discusses problem aiming solve, Section outlines model human opinion use predicting real-world football games. Section provides detail test models set baseline prediction accuracy. Finally, Section concludes. %"," In this paper, we present a new application-focused benchmark dataset and results from a set of baseline Natural Language Processing and Machine Learning models for prediction of match outcomes for games of football . By doing so we give a baseline for the prediction accuracy that can be achieved exploiting both statistical match data and contextual articles from human sports journalists. Our dataset is focuses on a representative time-period over 6 seasons of the English Premier League, and includes newspaper match previews from The Guardian. The models presented in this paper achieve an accuracy of 63.18\% showing a 6.9\% boost on the traditional statistical methods."
"Deep neural networks successful various morphological tasks exemplified yearly SIGMORPHON Shared Task. However neural networks operate continuous representations weights stark contrast traditional, hugely successful, rule-based morphology. There attempts add rule-based discrete elements models various inductive biases. In paper tackle two morphological tasks copy task control interpretable model, \sopa. Soft Patterns \sopa finite-state machine parameterized neural network, learns linear patterns predefined size. The patterns may contain epsilon transitions self-loops otherwise linear. Soft refers fact patterns intended learn abstract representations may multiple surface representations, \sopa learn end-to-end fashion. We call surface representations subwords, abstract patterns, patterns throughout paper. An important upside \sopa interpretable patterns extracted sample. shows \sopa able retrieve meaningful word-level patterns sentiment analysis. Each pattern matched every possible subword highest scoring subword recovered via differentiable dynamic program, variant forward algorithm. We apply model encoder sequence-to-sequence seq2seq\footnote{also called encoder-decoder model} model, add LSTM decoder. We initialize decoder's hidden state final scores \sopa pattern also apply Luong's attention intermediate outputs generated \sopa. We call model \sopaseq. We compare setup sequence-to-sequence bidirectional LSTM encoder, unidirectional LSTM decoder Luong's attention. We show \sopaseq often competitive LSTM baseline also interpretable design. \sopaseq especially good \morphana, often surpassing LSTM baseline, confirm linguistic intuition namely subword patterns useful extracting morphological information. We also compare models using generalized form Jaccard-similarity find trends coincide linguistic intuition.","  We examine the role of character patterns in three tasks: morphological analysis, lemmatization and copy. We use a modified version of the standard sequence-to-sequence model, where the encoder is a pattern matching network. Each pattern scores all possible N character long subwords  on the source side, and the highest scoring subword's score is used to initialize the decoder as well as the input to the attention mechanism.  This method allows learning which subwords of the input are important for generating the output. By training the models on the same source but different target, we can compare what subwords are important for different tasks and how they relate to each other. We define a similarity metric, a generalized form of the Jaccard similarity, and assign a similarity score to each pair of the three tasks that work on the same source but may differ in target. We examine how these three tasks are related to each other in \goodlangno languages. Our code is publicly available.\footnote{https://github.com/juditacs/deep-morphology}"
"Infusing emotions conversation systems substantially improve usability promote customers' satisfaction. Moreover, perceiving emotions sufficiently core premise expressing emotions. In real-life scenarios, humans instinctively perceive complex subtle emotions multiple aspects, including emotion flow dialogue history, facial expressions personalities speakers, express suitable emotions feedback. Figure shows organization multi-source information dialogue graph relationship them."," The success of emotional conversation systems depends on sufficient perception and appropriate expression of emotions. In a real-world conversation, we firstly instinctively perceive emotions from multi-source information, including the emotion flow of dialogue history, facial expressions, and personalities of speakers, and then express suitable emotions according to our personalities, but these multiple types of information are insufficiently exploited in emotional conversation fields. To address this issue, we propose a heterogeneous graph-based model for emotional conversation generation. Specifically, we design a Heterogeneous Graph-Based Encoder to represent the conversation content  with a heterogeneous graph neural network, and then predict suitable emotions for feedback. After that, we employ an Emotion-Personality-Aware Decoder to generate a response not only relevant to the conversation context but also with appropriate emotions, by taking the encoded graph representations, the predicted emotions from the encoder and the personality of the current speaker as inputs. Experimental results show that our model can effectively perceive emotions from multi-source knowledge and generate a satisfactory response, which significantly outperforms previous state-of-the-art models."
"Text classification one fundamental tasks natural language processing wide applications sentiment analysis, news filtering, spam detection intent recognition. Plenty algorithms, especially deep learning-based methods, applied successfully text classification, including recurrent neural networks , convolutional networks . More recently, large pre-training language models ELMO , BERT , Xlnet also shown outstanding performance kinds NLP tasks, including text classification. Although numerous deep learning models shown success text classification problems, share learning paradigm: deep model text representation, simple classifier predict label distribution cross-entropy loss predicted probability distribution one-hot label vector. However, learning paradigm least two problems: In general text classification tasks, one-hot label representation based assumption categories independent other. But real scenarios, labels often completely independent instances may relate multiple labels, especially confused datasets similar labels. As result, simply representing true label one-hot vector fails take relations instances labels account, limits learning ability current deep learning models. The success deep learning models heavily relies large annotated data, noisy data labeling errors severely diminish classification performance, inevitable human-annotated datasets. Training one-hot label representation particularly vulnerable mislabeled samples full probability assigned wrong category. In brief, limitation current learning paradigm lead confusion prediction model hard distinguish labels, refer label confusion problem . A label smoothing method proposed remedy inefficiency one-hot vector labeling , however, still fails capture realistic relation among labels, therefore enough solve problem. In work, propose novel Label Confusion Model enhancement component current deep learning text classification models make model stronger cope label confusion problem. In particular, LCM learns representations labels calculates semantic similarity input text representations estimate dependency, transferred label confusion distribution . After that, original one-hot label vector added LCD controlling parameter normalized softmax function generate simulated label distribution . We use obtained SLD replace one-hot label vector supervise training model training. With help LCM, deep model capture relations instances labels, also learns overlaps among different labels, thus, performs better text classification tasks. We conclude contributions follows:"," Representing a true label as a one-hot vector is a common practice in training text classification models. However, the one-hot representation may not adequately reflect the relation between the instances and labels, as labels are often not completely independent and instances may relate to multiple labels in practice. The inadequate one-hot representations tend to train the model to be over-confident, which may result in arbitrary prediction and model overfitting, especially for confused datasets  or noisy datasets . While training models with label smoothing  can ease this problem in some degree, it still fails to capture the realistic relation among labels. In this paper, we propose a novel Label Confusion Model  as an enhancement component to current popular text classification models. LCM can learn label confusion to capture semantic overlap among labels by calculating the similarity between instances and labels during training and generate a better label distribution to replace the original one-hot label vector, thus improving the final classification performance. Extensive experiments on five text classification benchmark datasets reveal the effectiveness of LCM for several widely used deep learning classification models. Further experiments also verify that LCM is especially helpful for confused or noisy datasets and superior to the label smoothing method."
"Over recent years, various task-oriented conversational agents, Amazon Alexa, Apple閳ユ獨 Siri, Google Assistant, Microsoft閳ユ獨 Cortana, become popular people閳ユ獨 everyday life expected highly intelligent. For NLU component, means expect models perform recognition actions entities within user閳ユ獨 request high accuracy. When first training NLU model new language , strong requirement high quality annotated data would support common user requests across range domains. As modeling space expands support new features additional languages, NLU models regularly re-trained updated data sets ensure support new functions. The major bottleneck processes labor cost associated collecting annotating new training utterances every new feature language. Recent advances machine learning methods, including use techniques transfer learning~ active learning, lead efficient data usage NLU models therefore decrease need annotated training data. Additionally, data augmentation models widely explored. The advantage data augmentation synthetic data generated, ingested subsequent models without additional effort, allowing faster experimentation. NLU models dialog systems perform variety tasks. In study, focus three them: Domain classification -- identify domain user request belongs , Intent classification -- extract actions requested users , Named Entity Recognition -- identify extract entities user requests. For utterance expect NLU model output domain, intent, set extracted entities corresponding tags. For example, user requests ``play Bohemian Rhapsody Queen'', expect NLU model return \{domain: music, intent: play\_song, named\_entities: [, ]\}. We call output annotation, utterance along annotation called annotated utterance. Named entities corresponding labels called slots. For NLU model perform well real-time user requests, need train large dataset diverse annotated utterances. However, could areas functionality large datasets training available. To boost model performance situations training data limited, use synthetic data generated small set unique utterances cover basic functionality user experience, called Golden utterances. We leverage Sequence Generative Adversarial Networks introduced by~\citet{Yu2016SeqGANSG} generate new utterances ``seed'' set, use generated utterances augment training data evaluate performance classification recognition tasks. We also investigate metrics use evaluate quality generated synthetic data links performance boost underlying tasks."," Data sparsity is one of the key challenges associated with model development in Natural Language Understanding  for conversational agents. The challenge is made more complex by the demand for high quality annotated utterances commonly required for supervised learning, usually resulting in weeks of manual labor and high cost. In this paper, we present our results on boosting NLU model performance through training data augmentation using a sequential generative adversarial network . We explore data generation in the context of two tasks, the bootstrapping of a new language and the handling of low resource features. For both tasks we explore three sequential GAN architectures, one with a token-level reward function, another with our own implementation of a token-level Monte Carlo rollout reward, and a third with sentence-level reward. We evaluate the performance of these feedback models across several sampling methodologies and compare our results to upsampling the original data to the same scale. We further improve the GAN model performance through the transfer learning of the pre-trained embeddings. Our experiments reveal synthetic data generated using the sequential generative adversarial network provides significant performance boosts across multiple metrics and can be a major benefit to the NLU tasks."
"Encoder-decoder architecture~ extensively used neural machine translation ~. Given source sentence, encoder firstly converts hidden representations, conditioned decoder generate target sentence. Attention mechanism~ effective learning alignment source sentence target sentence. Hence, attention mechanism usually used architecture improve capability, capturing long-distance dependencies. Similar traditional machine learning efforts~, recent approaches deep learning attempt improve encoder-decoder architecture multiple passes decoding~. NMT refers polish mechanism~. Under scheme, one translations generated source sentence and, except first translation, based translation previous decoding pass. While methods achieved promising results, lack proper termination policy multi-turn process. \citet{xia2017deliberation,zhang2018asynchronous} adopt fixed number decoding passes inflexible deciding optimal number decoding passes. \citet{geng2018adaptive} use reinforcement learning ~ automatically decide optimal number decoding passes. However, RL unstable due high variance gradient estimation objective instability~. Since methods may premature termination translation, potential limited. To address problem, propose novel framework, Rewriter-Evaluator, paper. It consists rewriter evaluator. The translation process involves multiple passes. Given source sentence, every pass, rewriter generates new target sequence aiming improving translation prior passes, evaluator measures translation quality determine whether terminate rewriting process. We also propose prioritized gradient descent method facilitates training rewriter evaluator jointly. The essential idea using priority queue improve sampling efficiency collecting translation cases yield low scores evaluator next-pass rewriting. The size queue times larger batch size. Although Rewriter-Evaluator involves multiple decoding passes, training time using PGD method comparable training encoder-decoder~ multiple decoding passes. We apply Rewriter-Evaluator improve widely used NMT models, RNNSearch~ Transformer~. Extensive experiments conducted two translation tasks, Chinese-English English-German, verify proposed method. The results demonstrate proposed framework notably improves performance NMT models significantly outperforms prior methods."," 	 	Encoder-decoder architecture has been widely used in neural machine translation . A few methods have been proposed to improve it with multiple passes of decoding. However, their full potential is limited by a lack of appropriate termination policy. To address this issue, we present a novel framework, Rewriter-Evaluator. It consists of a rewriter and an evaluator. Translating a source sentence involves multiple passes. At every pass, the rewriter produces a new translation to improve the past translation and the evaluator estimates the translation quality to decide whether to terminate the rewriting process. We also propose a prioritized gradient descent  method that facilitates training the rewriter and the evaluator jointly. Though incurring multiple passes of decoding, Rewriter-Evaluator with the proposed PGD method can be trained with similar time to that of training encoder-decoder models. We apply the proposed framework to improve the general NMT models . We conduct extensive experiments on two translation tasks, Chinese-English and English-German, and show that the proposed framework notably improves the performances of NMT models and significantly outperforms previous baselines."
"In article proposing add coinduction\footnote{Throughout article use term `coinduction' generic meaning, encompassing also coalgebra, corecursion, bisimulation. This terminology explained.} computational apparatus natural language semantics. This, argue, provide basis realistic, computationally sound, scalable model natural language understanding. Given bottom up, inductively\footnote{We use terms `induction' `inductive' logical mathematical sense, e.g. `definition induction' `proof induction,' philosophical sense deriving general knowledge specific cases, `inductive reasoning.'} constructed, semantic structures brittle, seemingly incapable correctly representing meanings longer sentences realistic dialogues, semantics need new foundation. Coinduction, uses top constraints, successfully used design operating systems programming languages. Moreover, implicitly present text mining, machine translation, attempts model intensionality modalities. So, scattered evidence works. Since coinduction induction coexist, provide common language conceptual model research natural language understanding. We elaborate proposal several ways. We motivate discussing accuracy conceptual gaps inductive coinductive views NL semantics. We introduce coinduction, coalgebras related concepts focusing intuitions referring reader works depth treatments. We show natural match coinduction several natural language processing tasks modeling dialogue text mining. And show examples induction coinduction jointly improve process assigning representations text. We argue joint use deep learning deep semantics natural language understanding. Just tensor product allows us jointly explore use two different related algebras vector spaces, imagine induction coinduction jointly providing better foundation NL understanding. Although remainder article try convey intuitions joint use, mathematical computational requirements optimal joint use point clear us. \subsection{Motivation} Our motivation pursue topic comes two sources, elaborate below. The first one difference concepts used deep learning vs. traditional semantics. The second one limitations processing long sentences using traditional semantic representation vs. relatively successful assignment much shallower structures using deep learning. Our proposal think coinductively latter allows us incorporate methodologies within single conceptual framework. \subsubsection{Motivation \#1: The conceptual gap deep neural networks deep semantic analysis} Intuitively gap using deep neural networks natural language processing using deep semantic analysis natural language understanding . If dig deeper gap might observe conceptual apparatus different. Reading textbooks. This perhaps clearly seen new version leading NLP textbook. Looking Chapter 16 ``Logical Representations Sentence Meaning""\footnote{We using manuscript \url{https://web.stanford.edu/~jurafsky/slp3/}, version October 16, 2019} notice sharing vocabulary encoder-decoder embedding models introduced earlier book. This criticism book: first, work progress; second, currently missing section might create bridge. Our point bridge needed. To reverse perspective, logical representations appear deep learning focused NLP books , NLP appear topic . A similar gap seen , lambda calculus discourse representation avoided sections mentioning applications logistic regression Naive Bayes NLP, vice versa. Even much earlier problem bridging two views language, one governed rules observations discussed length , arguably little impact field. Somewhat similar sentiment expressed recently , commenting capabilities deep learning: ``really dramatic gains may possible true signal processing tasks."" This article takes position bridge formed creating abstraction approaches, ad hoc combination. The value abstraction could lie informing theory, i.e. models meaning, could also guiding process creation better tools human-computer interaction natural language understanding. The historical analogy might keep mind creation modern computer architectures operating systems , introduced new layers abstraction new disciplines . \\ What recent research? There research article Google Scholar, early June 2020, mentioning ``mathematics deep learning"" ``logical inference,"" although aspects covered experimental research -- ``deep learning"" + ``logical inference"" produces 800 hits. Thus, combining logical neural model active area research. For example, presents data set question answering using scene graphs modeling elements present images challenging questions them. In context different problem, discuss ensuring factual correctness summaries, using two models, one logical one neural . In third example, show neural attention based models BERT retrained master aspects natural language inference. On hand, examples present Section show deep neural networks still seem incapable deeper reasoning without special purpose architectures, even modeling elementary arithmetical operations challenge. \subsubsection{Motivation \#2: Accuracy gap long sentences deep learning deep semantic models} There gap accuracy deep neural networks deep semantic analysis, irrespective fact try address different aspects natural language understanding. %illustrated Table Figure % \end{table} %\FloatBarrier Table , viewed lenses systems' ability successfully attend long sentences, shows left column intuitively `successful' NLP applications; right areas view seen limited progress last 30 years. Obviously, metrics used applications mentioned two columns different. For example, one argue computational pragmatics exist 30 years ago, recently started see computational, probabilistic models pragmatics ,\footnote{\url{https://michael-franke.github.io/probLang/} \url{http://www.mit.edu/~tessler/short-courses/2017-computational-pragmatics/} last retrieved May 13 2020}, suggests big jump. Nevertheless, areas right scale sentence length. And later, Sections , argue, abstract perspective, differences columns attributed differences respective computational models. \FloatBarrier Let us discuss long sentences. Prior research area shows parsing accuracy decreases length sentence. For example, observe fast drop precision recall dependency parsing increase dependency length, distance root, length sentences. Similar results appear Fig.4 . Actually situation might worse sources suggests. In analysis parsing sentences length 156, entertain possibility 閳 parsing long sentences would intractable."" Clearly, deep neural networks improved accuracy parsing. However, even attention-based models, reports 20\% drop labeled attachment scores dependency length increases 1 5. This clearly problem, even linguistically oriented data sets. A recent statistics given shows depending language corpus average sentence length 19-38 words. However, thousands sentences corpus longer 100 words. The average sentence length Penn Treebank 20.54 words ; Genesis, 34 words; but, per classic , ``Biographia Literaria"" 10\% sentences long average length 70 words. The situation even problematic switch general corpora specific ones. In previous work , discussed problem parsing long sentences context legal text corpora, namely patents. Fig. shows distribution lengths main patent claim . These claims expressed single long sentences. The sentences Claim 1 average 150-180, 1400 words long . Although extreme length due legal rules, nevertheless note 93\% claims series longer 50 words. This means analysis average Claim 1 likely wrong. . What semantic parsing? Semantic representations difficult build even short sentences, shown Fig. , . All systems submitted competition shared task semantic parsing show drop accuracy length sentence increases. \FloatBarrier \bss \color{black} \subsection{Hypothesis} Adding coinduction semantics provide foundation realistic, computationally sound scalable model natural language understanding. \\ We proposing adding coinduction computational apparatus semantics. This argue, provide basis realistic, computationally sound scalable model natural language understanding. Given bottom up, inductively constructed semantic structures brittle, seemingly incapable representing longer sentences realistic dialogues, semantics need new foundation. Coinduction, uses top constraints, successful design operating systems programming languages. Moreover, one argue implicitly present text mining, machine translation attempts model intensionality . In , good introductory textbook, used describe self reference, paradoxes modal logics. So, scattered evidence coinduction works. Since coinduction induction coexist, provide common language conceptual model research NL understanding. We mention one first theoretical proposals look agent interaction coinduction appeared , included explicit mention NL dialogue question answering. Within following twenty years, argued present article, focus NLP shifted towards coinductive methods\footnote{ This shift occurred without ever mentioning concept itself. There literally 12 entries mentioning ""deep learning"" ""coinduction"", mostly accidentally, although exception. .}, namely deep learning, theoretical justification coming universal approximation properties neural networks. This article summarizes developments argues explicit introduction term `coinduction' vocabulary NLP. \\ To make argument, focus following questions: \color{black}","  This article contains a proposal to add coinduction to the computational apparatus of natural language understanding. This, we argue, will provide a basis for more realistic, computationally sound, and scalable models of natural language dialogue, syntax and semantics. Given that the bottom up, inductively constructed, semantic and syntactic structures are brittle, and seemingly incapable of adequately representing the meaning of longer sentences or realistic dialogues, natural language understanding is in need of a new foundation. Coinduction, which uses top down constraints, has been successfully used in the design of operating systems and programming languages. Moreover,  implicitly it has been present in text mining, machine translation, and in some attempts to model intensionality and modalities, which provides evidence that it works.  This article shows high level formalizations of some of such uses.   Since coinduction and induction can coexist, they can provide a common language and a conceptual model for research in natural language understanding. In particular, such an opportunity seems to be emerging in research on compositionality. This article shows several examples of the joint appearance of induction and coinduction in natural language processing. We argue that the known individual limitations of induction and coinduction can be overcome in empirical settings by a combination of the the two methods. We see an open problem in providing a theory of their joint use."
"The problem predicting citation counts papers long-standing research problem. Predicting citation counts allows us better understand relationship paper %and citation count gives us insight affects paper's impact. impact. However, prior research viewed static prediction problem, i.e. predicting single citation count static point time. %With natural development new papers published, %However, %Viewing static problem This ignores natural development data new papers published. Here, propose view problem sequence prediction task, models ability capture evolving nature citations. %By extending problem sequence prediction problem, This, turn, requires dataset contain papers' citation counts period time, adds temporal element data, encoded sequential machine learning models, Long short-term memory models . Additionally, scholarly documents exhibit natural graph-like structure citation networks. Given recent developments modeling data prior research showing modeling input graphs beneficial, hypothesize modeling paper's citation network useful predicting citation counts time. In paper, consider citation networks, dynamic graph evolves time new citations papers added network. Leveraging structured data graph allows us discover complex relationships papers. We want tap knowledge treat citation data network, exploit topological information temporal information. By so, investigate hypothesis paper citation counts correlated features authors, venue, topics. We use well-established Semantic Scholar dataset construct citation network. Its meta-data allows us construct dynamic citation network covers year time-line, updated graph year. The Semantic Scholar dataset's meta-data also contains information paper's authors, venue, topics, allowing us study correlation features citation count paper considering evolving nature citation network. The correlation features citation counts well known studied prior work. Prior studies show citations correlated strong correlation features authors, limited predicting single citation, predicting natural evolution papers growth. We propose use constructed dynamic citation network predict trajectory number citations papers receive time, new sequence prediction task introduced work. Furthermore, propose encoder-decoder model solve proposed task, uses graph convolutional layers exploit graphs' topological features LSTM model temporal component graphs. We compare model standard GCN standard LSTM, individually incorporate either topological information temporal information, both. Our contributions follows: 1) A dynamic citation network based Semantic Scholar dataset. The dynamic citation network contains time-steps, updated graph time-step, based yearly information. 2) We introduce task sequence citation count prediction. 3) A novel encoder-decoder model based GCN LSTM extract dynamic graph's topological temporal components. 4) A thorough study correlation citation counts temporal components. \iffalse Our contributions follows: \fi"," %Citation count prediction is the task of predicting the number of citations, which a paper has gained after a given period. Prior work view this as a static prediction task, but due to papers and their citations develops over time, predicting the sequence of citations will also capture the papers' development. We further employ the recent development in graph structured data and view the papers as a citation network, linked by papers citations. Viewing the papers as a citation network allows us to exploit the topological information of the citation network. While no prior citation network allow for predicting the development of a paper's citations over time. Therefore, we use the well known Semantic Scholar dataset to construct a dynamic citation network, i.e., a graph which evolves over time. This dynamic citation network spans over $42$. Using the constructed dynamic citation network, we introduce the task of sequence citation count prediction. To solve the introduced task, we propose a model which exploits topological and temporal information. We compare the proposed model against baseline models and analyze the performance. Furthermore, we study the importance of topological and temporal features for predicting a paper's citation count. \andreas{findings TBD} % revised Citation count prediction is the task of predicting the number of citations a paper has gained after a period of time. Prior work viewed this as a static prediction task. As papers and their citations evolve over time, considering the dynamics of the number of citations a paper will receive would seem logical. Here, we introduce the task of sequence citation prediction, where the goal is to accurately predict the trajectory of the number of citations a scholarly work receives over time. We propose to view papers as a structured network of citations, allowing us to use topological information as a learning signal. Additionally, we learn how this dynamic citation network changes over time and the impact of paper meta-data such as authors, venues and abstracts. To approach the introduced task, we derive a dynamic citation network from Semantic Scholar which spans over $42$ years. We present a model which exploits topological and temporal information using graph convolution networks paired with sequence prediction, and compare it against multiple baselines, %where we will use GCN and LSTM as standalone, to  testing the importance of topological and temporal information and analyzing model performance.  Our experiments show that leveraging both the temporal and topological information greatly increases the performance of predicting citation counts over time."
"Recent advances open domain question answering mostly revolved around machine reading comprehension task read comprehend given text answer questions based it. However, recent work MRC English \eg\ SQuAD , HotpotQA Natural Questions . Significant performance gains state-of-the-art datasets credited large pre-trained language models . Multilingual BERT , trained Wikipedia articles 104 languages equipped 120k shared wordpiece vocabulary, encouraged lot progress cross-lingual tasks \eg{} XNLI , NER QA performing zero-shot training: train one language test unseen target languages. In work, focus multilingual QA and, particular, two recent large-scale datasets: MLQA TyDiQA\footnote{All uses TyDiQA paper refer Gold Passage task.}. Both datasets contain English QA pairs also examples 13 diverse languages. Some examples shown Figure . MLQA evaluates two challenging scenarios: 1) Cross-Lingual Transfer question context language, 2) Generalized Cross-lingual Transfer question one language context another language . %In cases, MLQA zero-shot provide training data language. \avi{Maybe remove previous sentence?} % TyDiQA consists QA examples English 8 languages. TyDiQA designed XLT only. Both datasets challenging multilingual QA due large number languages variety linguistic phenomena encompass . Ideally, want build QA systems existing languages impractical collect manually labeled training data them. In absence labeled data, suggested several research directions pushing boundaries multilingual QA, including zero-shot QA, exploring data augmentation machine translation, well effective transfer learning. These avenues explore work addition asking following research questions:\\ 1. Is large pre-trained LM sufficient zero-shot multi-lingual QA? \\ Prior work proposes zero-shot transfer learning English SQuAD data languages using pre-trained LM competitive results achieved MLQA TyDiQA . We venture beyond zero-shot training first exploring data augmentation top underlying model. We achieve using translation methodologies augment English training data. We use machine translation obtain additional silver labeled data allowing us improve cross-lingual transfer low cost. Our approach introduces several multilingual extensions SQuAD training data: translating questions keeping context English, translating context keeping question English, translating question context languages. This enables us augment original English human-labeled training examples 14 times multilingual silver-labeled QA pairs.\\ 2. Can bring language-specific embeddings multi-lingual LMs closer effective cross-lingual transfer?\\ %To better MLQA, believe important model Our hypothesis make cross-lingual QA transfer effective bring embeddings multilingual pre-trained LM closer semantic space. To answer question French suffice train system Hindi necessary train system target language: hence, French Hindi look language. We propose two approaches explore cross-lingual transfer: In first approach, propose novel strategy based adversarial training . We investigate addition language-adversarial task QA finetuning pretrained LM significantly improve cross-lingual transfer performance causing embeddings LM become less language-dependent. In second approach, develop novel Language Arbitration Framework consolidate embedding representation across languages using properties translation. We train additional auxiliary tasks \eg{} making sure English question translation Arabic produces answer see input context Spanish. The intuition behind language arbitration training model English translated examples, proposed multi-lingual objectives bring language-specific embeddings closer English embeddings.\\ Overall, main contributions paper follows:"," Prior work on multilingual question answering has mostly focused on using large multilingual pre-trained language models  to perform zero-shot language-wise learning: train a QA model on English and test on other languages. In this work, we explore strategies that improve cross-lingual transfer by bringing the multilingual embeddings closer in the semantic space.  Our first strategy augments the original English training data with machine translation-generated data. This results in a corpus of multilingual silver-labeled QA pairs that is 14 times larger than the original training set. In addition, we propose two novel strategies, language adversarial training and language arbitration framework, which significantly improve the  cross-lingual transfer performance and result in LM embeddings that are less language-variant. Empirically, we show that the proposed models outperform the previous zero-shot baseline on the recently introduced multilingual MLQA and TyDiQA  datasets."
"% \subsection{Problem Statement Motivation} Researchers' ability automate natural language processing grown exponentially past years, particularly advent Transformer architecture . Despite fact recent machine learning methods achieve impressive almost human-level performance tasks dialogue modeling natural language generation , many intelligent voice assistants still rely rule-based architectures cached responses open domain dialogue . This primarily due lack controls deep learning architectures producing specific phrases, tones, topics, makes models inherently unpredictable therefore risky entities - corporate otherwise - wish deploy public-facing intelligent agents. For example, often desirable conversational agent maintain specific identity throughout exchange dialogue currently impossible condition deep learning algorithms maintain coherent identity across dialogue without training highly specialized data sets. Fine-tuning specialized data sets comes additional, significant cost: lead catastrophic forgetting language model . Despite aspect fine-tuning, current state-of-the-art methods require fine-tuning entire network original data set proves unsuitable given task , even language modeled across tasks. Furthermore, models produced current methods almost entirely uninterpretable therefore generally difficult test egregious failure cases. % \subsection{Solution Overview} In paper, address issue content control well catastrophic forgetting induced fine-tuning. We define `content control' able command network either incorporate eschew exact word, phrase, topic, style, sentiment output, therefore attempt granular level control purely topic/style-level control published recent literature . We also introduce alternative fine-tuning neural language models demonstrate experimentation high-cost overwriting model weights fine-tuning often fails induce desired behavior generalized settings. %is inspired ``No Free Lunch"" theorems introduced Wolpert \& Macready seek avoid training neural network simultaneously model language act explicit commands. Instead, recast problem control natural language generation one combining separate models - one natural language one high-level command responses - produce desired linguistic output. In so, develop framework interpreting subsequently controlling hidden activations pretrained neural network without adjustments made pretrained model. This framework biologically consistent findings Knutson et al., discovered neural pathways humans inhibited neuron clusters , applications neural network architectures questions outside domain controllable text generation."," %   Current solutions to the problem of controlling generative neural language models are usually formulated under a training paradigm in which the language model is trained to simultaneously model natural language and respond to high-level commands. We recast the problem of control in natural language generation as that of learning to interface with a pretrained language model to generate desired output, just as Application Programming Interfaces  control the behavior of programs by altering hyperparameters. In this new paradigm, a specialized neural network  learns to interface with a pretrained language model by manipulating the hidden activations of the pretrained model in real time to produce desired outputs, such that no permanent changes are made to the weights of the original language model.     It is notoriously difficult to control the behavior of artificial neural networks such as generative neural language models. We recast the problem of controlling natural language generation as that of learning to interface with a pretrained language model, just as Application Programming Interfaces  control the behavior of programs by altering hyperparameters. In this new paradigm, a specialized neural network  learns to interface with a pretrained language model by manipulating the hidden activations of the pretrained model to produce desired outputs. Importantly, no permanent changes are made to the weights of the original model, allowing us to re-purpose pretrained models for new tasks without overwriting any aspect of the language model. We also contribute a new data set construction algorithm and GAN-inspired loss function that allows us to train NPI models to control outputs of autoregressive transformers. In experiments against other state-of-the-art approaches, we demonstrate the efficacy of our methods using OpenAI闁炽儲鐛 GPT-2 model, successfully controlling noun selection, topic aversion, offensive speech filtering, and other aspects of language while largely maintaining the controlled model's fluency under deterministic settings. %Finally, we describe the ethical implications of this work. %   Applications for this approach include re-purposing a pretrained model  for a new task without a specialized data set in the problem domain. We present experimental results from training several NPI models to control the outputs of OpenAI's GPT-2 language model \cite{openaiGPT2}, as well as a novel data curation approach in which hidden activations of an uninterpretable pretrained model are associated with specific outputs. Finally, we describe potential methods whereby NPIs might be leveraged to interpret the inner workings of pretrained networks, as well as the related ethical implications of this work."
"Emotion analysis user-generated content available web provides insights toward making meaningful decisions. Micro-blog platforms Twitter gained profuse popularity textual content holding people's opinions. The past decade seen active growth emotion analysis models many domains. Recently increasing interest analysis emotions informal short texts tweets. In paper, introduce analyze system accurately identify emotions individual tweets associated intensities~\footnote{Intensity refers degree amount emotion}. % explain important analyze emotions Analyzing emotions social media twitter benefits society number ways. Policymakers use emotional information social media accurately identify concerns people making decisions. Monitoring social media health issues benefits public health also government decision makers. Furthermore, organizations monitor opinion public products services provide better service society. Once emotions recognized, emotion intensity used prioritize major concerns. Studies emotion analysis often focused emotion classification. However, emotions may exhibit varying levels intensities. Here, emotion intensity defined degree intensity particular emotion felt speaker. Additionally, may observe multiple emotions simultaneously tweet varying intensities. One purpose study develop model accurately identify emotions associated emotion intensities given tweet. In paper, propose transfer learning approach backed neural network classifier regressor. Although proposed neural network alone inadequate beat benchmark, show features learned training neural networks used improve overall performance combined features. Another purpose study explain input word level features affect features extracted neural network. % [complete actual findings here] The findings make important contribution understanding features used neural network effectively select features improve effectiveness extracted features. Our main contributions study: \pagebreak Major challenge using deep learning train emotion intensity prediction models lack large labeled datasets. More recently, emoji hashtags used studies create large naturally labeled datasets. However, possible use similar technique obtain intensity emotions. Furthermore, creating large dataset manually time consuming expensive. existing datasets emotional intensity prediction. Due limited amount task-specific training data previous researches opted transfer learning approaches~\citet{baziotis2018ntua, duppada2018seernet} traditional machine learning. However, paper argue even reasonable size dataset train neural network obtain good performance provided proper regularization. Additionally, show features learned training neural network combined features improve overall performance emotion intensity prediction. % [explain methodology brief] % } \end{table} In \S, outline related works sentiment emotion mining. Next, \S discuss datasets used study. After, introduce background methodology \S \S accordingly. Then, \S discuss evaluation results. Finally, conclude paper \S."," In this paper, we present an experiment on using deep learning and transfer learning techniques for emotion analysis in tweets and suggest a method to interpret our deep learning models. The proposed approach for emotion analysis combines a Long Short Term Memory  network with a Convolutional Neural Network . Then we extend this approach for emotion intensity prediction using transfer learning technique. Furthermore, we propose a technique to visualize the importance of each word in a tweet to get a better understanding of the model. Experimentally, we show in our analysis that the proposed models outperform the state-of-the-art in emotion classification while maintaining competitive results in predicting emotion intensity."
"Online reviewing businesses becomes important nowadays, customers publish reviews businesses, potential customers shop owners view them. Positive feedback customers may prosper store businesses, negative one could opposite consequences. Yelp, one largest company founded 2004 publishing crowd-sourced reviews businesses, provides one open dataset, Yelp Open Dataset , tremendously many data businesses, reviews, users. Such dataset proven good material personal, educational, academic purposes. Among multiple tasks Yelp Open Dataset, predicting ratings restaurants based reviews one fundamental important tasks. This task help Yelp classify reviews proper groups recommendation system, detect anomaly reviews protect businesses malicious competitions, assign rating texts automatically. Yelp review rating prediction done multiple ways, sentiment analysis 5-star rating classification. In paper, focus rating prediction restaurants based review texts. This task viewed multiclass classification problem, input textual data , output predicted class . We apply machine learning deep learning models. After analyzing data distribution, splitting datasets, extracting features, use four machine learning methods, including Naive Bayes, Logistic Regression, Random Forest, Linear Support Vector Machine . Then focus four transformer-based models, including BERT , DistilBERT , RoBERTa , XLNet , several different architectures tried hyperparameter tuning. This project done \href{https://colab.research.google.com/}{Google Colab}, multi-processors GPUs available. The code publicly available GitHub .","    We predict restaurant ratings from Yelp reviews based on Yelp Open Dataset. Data distribution is presented, and one balanced training dataset is built. Two vectorizers are experimented for feature engineering. Four machine learning models including Naive Bayes, Logistic Regression, Random Forest, and Linear Support Vector Machine are implemented. Four transformer-based models containing BERT, DistilBERT, RoBERTa, and XLNet are also applied. Accuracy, weighted $ F_1 $ score, and confusion matrix are used for model evaluation. XLNet achieves 70\% accuracy for 5-star classification compared with Logistic Regression with 64\% accuracy."
"Language processing requires tracking information multiple timescales. To able predict final word ``timescales"" previous sentence, one must consider short-range context long-range context . How humans neural language models encode multi-scale context information? Neuroscientists developed methods study human brain encodes information multiple timescales sequence processing. By parametrically varying timescale intact context, measuring resultant changes neural response, series studies showed higher-order regions sensitive long-range context change lower-order sensory regions. These studies indicate existence ``hierarchy processing timescales"" human brain. More recently, \citet{chien2020constructing} used time-resolved method investigate brain builds shared representation, two groups people processed narrative segment preceded different contexts. By directly mapping time required individual brain regions converge shared representation response shared input, confirmed higher-order regions take longer build shared representation. Altogether, lines investigation suggest sequence processing brain supported distributed hierarchical structure: sensory regions short processing timescales primarily influenced current input short-range context, higher-order cortical regions longer timescales track longer-range dependencies . How processing timescales organized within recurrent neural networks trained perform natural language processing? Long short-term memory networks widely investigated terms ability successfully solve sequential prediction tasks. However, long-range dependencies usually studied respect particular linguistic function , less attention broader question sensitivity prior context -- broadly construed -- functionally organized within RNNs. Therefore, drawing prior work neuroscience literature, demonstrate model-free approach mapping processing timescale RNNs. We focused existing language models trained predict upcoming tokens word level character level . The timescale organization two models revealed higher layers LSTM language models contained small subset units exhibit long-range sequence dependencies; subset includes previously reported units well previously unreported units. After mapping timescales individual units, asked: processing timescales unit network relate functional role, measured connectivity? The question motivated neuroscience studies shown human brain, higher-degree nodes tend exhibit slower dynamics longer context dependence lower-degree nodes . More generally, primate brain exhibits core periphery structure relatively small number ``higher order閳 high-degree regions maintain large number connections one another, exert powerful influence large-scale cortical dynamics . Inspired relationships timescales network structure brain, set test corresponding hypotheses RNNs: Do units longer-timescales tend higher degree neural language models? Do neural language models also exhibit ``core network"" composed functionally influential high-degree units? Using exploratory network-theoretic approach, found units longer timescales tend projections units. Furthermore, identified set medium-to-long timescale ``controller"" units exhibit distinct strong projections control state units, set long-timescale ``integrator units"" showed influence predicting words long context relevant. In summary, findings advance understanding timescale distribution functional organization LSTM language models, provide method identifying important units representing long-range contextual information RNNs."," In the human brain, sequences of language input are processed within a distributed and hierarchical architecture, in which higher stages of processing encode contextual information over longer timescales. In contrast, in recurrent neural networks which perform natural language processing, we know little about how the multiple timescales of contextual information are functionally organized. Therefore, we applied tools developed in neuroscience to map the ``processing timescales闁 of individual units within a word-level LSTM language model. This timescale-mapping method assigned long timescales to units previously found to track long-range syntactic dependencies. Additionally, the mapping revealed a small subset of the network  with long timescales and whose function had not previously been explored. We next probed the functional organization of the network by examining the relationship between the processing timescale of units and their network connectivity. We identified two classes of long-timescale units: ``controller闁 units composed a densely interconnected subnetwork and strongly projected to the rest of the network, while ``integrator闁 units showed the longest timescales in the network, and expressed projection profiles closer to the mean projection profile. Ablating integrator and controller units affected model performance at different positions within a sentence, suggesting distinctive functions of these two sets of units. Finally, we tested the generalization of these results to a character-level LSTM model and models with different architectures. In summary, we demonstrated a model-free technique for mapping the timescale organization in recurrent neural networks, and we applied this method to reveal the timescale and functional organization of neural language models.\footnote{The code and dataset to reproduce the experiment can be found at \url{https://github.com/sherrychien/LSTM_timescales}}"
We summarize contribution follows:," Keyphrase Generation  is the task of generating central topics from a given document or literary work, which captures the crucial information necessary to understand the content. Documents such as scientific literature contain rich meta-sentence information, which represents the logical-semantic structure of the documents.  However, previous approaches ignore the constraints of document logical structure, and hence they mistakenly generate keyphrases from unimportant sentences. To address this problem, we propose a new method called Sentence Selective Network  to incorporate the meta-sentence inductive bias into KG. In SenSeNet, we use a straight-through estimator for end-to-end training and incorporate weak supervision in the training of the sentence selection module. Experimental results show that SenSeNet can consistently improve the performance of major KG models based on seq2seq framework, which demonstrate the effectiveness of capturing structural information and distinguishing the significance of sentences in KG task."
"% With recent development end-to-end text-to-speech system, synthesised speech achieved high intelligibility quality various languages . Recently neural network based text-to-speech systems achieved certain success prosody naturalness synthesized speech conventional methods . % Because Chinese non-alphabet character set large, grapheme-to-phoneme essential hiring end-to-end model Chinese . By applying encoder-decoder framework attention , systems directly predict speech parameters graphemes phonemes learning acoustic prosodic patterns via flexible mapping linguistic acoustic space. % But still model part prosody structural information raw text limited model capacity, resulting poor expressiveness even prosody errors. % V_1021But still model part prosody structural information raw text resulting poor expressiveness even prosody errors. However, learnt prosodic patterns contain part prosodic structural information , resulting poor prosody naturalness performance even improper prosody. % So additional prosody structure information important improve naturalness synthesized speech text-to-speech system. % V5: So adding prosody information, prosody structure annotations, encoder-decoder based models important improve expressiveness synthesized speech TTS systems. % The G2P module converts text input sequence phonemes tones, intelligibility naturally synthesised Chinese speech perform better conventional TTS . % However, limited coverage phoneme permutation training data causes decline ability predict prosody, resulting unnatural prosody unexpected pause. % % V4: There many attempts improve prosody prediction ability TTS system introducing prosody structure information explicitly. % V5: Prosody structure annotations successfully applied TTS systems improve expressiveness. % V1020: To improve expressiveness synthesized speech, directly adding prosodic structure annotations, Tones break indices labels The MATE meta-scheme % v_1021:To improve expressiveness synthesized speech, adding prosodic structure annotations tones break indices labels prosodic structure annotation input sequence encoder-decoder based models proposed. To improve prosody naturalness synthesized speech, adding prosodic structure annotations tones break indices labels prosodic structure labels input sequence neural network based TTS models proposed. Prosodic structure annotations need subjectively labeled speech, time-consuming. Although annotations automatically annotated training another prosodic structure prediction model , accuracy predicted prosodic structure labels still limited using subjectively labeled annotations ground-truths. The high correlation syntactic structure prosodic information proved successful syntactic-to-prosodic mapping . % V1020: The syntactic parsing models trained large text database rich grammatical structure provide text TTS dataset usefully syntactic structure information. A set rule-based syntactic features part-of-speech positions current word parent phrases proposed used hidden Markov model based acoustic model . % So subjective labeled prosodic structure annotations replaced syntactic structure information, obtained text without referring speech. % In hidden markov model based acoustic model, set rules create syntactic features including part speech positions current word parent phrases hired syntactic structure information improve prosody naturalness exceeds prosodic structure annotations comprehensiveness granularity . % This provides us another method implicitly improve prosody using syntactic structure information, exceeds using prosody structure information explicitly comprehensiveness granularity. % Early hidden markov based TTS model, rich syntactic context instead prosody structure information used improved prosody synthesized . % The word relation based features proposed prior features, require expert knowledge designed. % explore syntactic information parse tree, improve generalization synthesised speech. To utilize syntactic structure information, phrase structure based feature word relation based feature proposed neural network based TTS . PSF WRF expand set syntactic features used HMM model. More features highest-level phrase beginning current word lowest common ancestor introduced model syntactic structure . However, expanded features still manually designed features rather automatically learned high-level representations. PSF contains features limited layers whole syntactic tree structure. WRF exposes information partial nodes edges whole syntactic parse tree. % PSF WRF model syntactic relation among limited subtrees rather whole syntactic parse tree structure. % contain feature syntactic tree structure design. % needs expert knowledge select % V1020: makes harder extract useful information leads instability. % way select specific layers parse tree, makes harder extract useful information leads instability. % V1020: And WRF focuses relation two adjacent words parsing tree structure, model limited information whole syntactic parse tree. For example, one WRF features highest-level phrase beginning current word . % WRF models . % expand partial higher structure . % limited manual selection strategy, WRF considers influence former word next word specific layer parent nodes, cannot model whole structure parse tree. % This makes prosody performance largely determined selected strategy, time unstable. %In Fig., show example synthesised speech phoneme sequence input different reference speech failing respect syntax structure. % Without parsing tree's limit, third word ""cu4 jin4"" pronounced separately . % Besides, without parsing tree information, synthesised speech pause fifth word ""ti2 xiao4"" sixth word ""shi4"", obvious gap parsing tree reflected reference speech . % simply plugging parsing tree information TTS perform well. Limited manual design rule, features disadvantages model syntax tree structure information. Firstly, using phrase structure feature needs fix number tree layers way select specific layer, using word relation feature make model select part parse tree structure, cannot proved useful part prosody modeling. This makes prosody performance largely determined selected strategy, time unstable. Secondly, word relation feature consider former words' influence next word ignore impact backward structure importance. Last least, manual design features require high accuracy syntax tree annotation, easily achieved. Otherwise, Otherwise influence manual selection strategy, destructive influence mislabeling prosody prediction magnified. % A syntactic parse tree traversal based method proposed learn syntactic representation employed neural machine translation . To maker better use syntactic information, motivated syntactic parse tree traversal approach neural machine translation , propose syntactic representation learning method improve prosody naturalness synthesized speech neural network based TTS. % To make better use syntactic information, paper, propose syntactic representation learning method improve prosody neural network based TTS. % also known phrase structure parsing, TTS system control prosody effective. Syntactic parse tree linearized two constituent label sequences left-first right-first traversal. % Word level bidirectional Then syntactic representations extracted constituent label sequences using different uni-directional GRU network sequence. After which, syntactic representations up-sampled word level phoneme level concatenated phoneme embeddings. Tacotron 2 employed generate spectrogram concatenated syntactic representations phoneme embeddings, Griffin-Lim reconstruct waveform. % directly Nuclear-norm maximization loss introduced constituent label embedding layer enhance discriminability diversity. Compared hiring left-first traversal , right-first traversal proposed alleviate ambiguity. Experimental results show proposed model outperforms baseline terms prosody naturalness. Mean opinion score increases compared baseline approach . % compared baseline approach, one-way ANOVA test. ABX preference rate exceeds baseline approach . % One-way ANOVA test reveals significant improvement . % We go explore enhanced controllability prosody benefit eliminate ambiguity. For sentences multiple different syntactic parse trees, prosodic differences clearly perceived corresponding synthesized speeches. %We linearize phrase parse tree structural label sequence propose rnn-based model learn useful syntactic information itself, experimental shows significantly better method manually extracting features. %To best known, first exploite syntactic information chinese TTS system first apply syntactic information lower input level word. %We also introduce rank loss syntactic label embedding enhance ability syntax structure control prosody, expanded specific application parsing tree information, including different sentences parsing tree structure bring prosodic structure, different trees sentence produce different prosodic readings. The latter brings solutions ambiguity caused grammatical structure"," Syntactic structure of a sentence text is correlated with the prosodic structure of the speech that is crucial for improving the prosody and naturalness of a text-to-speech  system.  Nowadays TTS systems usually try to incorporate syntactic structure information with manually designed features based on expert knowledge.  In this paper, we propose a syntactic representation learning method based on syntactic parse tree traversal to automatically utilize the syntactic structure information.  Two constituent label sequences are linearized through left-first and right-first traversals from constituent parse tree. Syntactic representations are then extracted at word level from each constituent label sequence by a corresponding uni-directional gated recurrent unit  network.  Meanwhile, nuclear-norm maximization loss is introduced to enhance the discriminability and diversity of the embeddings of constituent labels.  Upsampled syntactic representations and phoneme embeddings are concatenated to serve as the encoder input of Tacotron2.  Experimental results demonstrate the effectiveness of our proposed approach, with mean opinion score  increasing from $3.70$ to $3.82$ and ABX preference exceeding by $17\%$ compared with the baseline. In addition, for sentences with multiple syntactic parse trees, prosodic differences can be clearly perceived from the synthesized speeches."
"Semantic parsing task mapping natural language utterances machine interpretable meaning representations. Many semantic parsing methods based principle semantic compositionality ~, main idea put together meanings utterances combining meanings parts~. However, methods suffer heavy dependence handcrafted grammars, lexicons, features. To overcome problem, many neural semantic parsers proposed achieved promising results~. %\textcolor{red}{However, compared compositional semantic parsers, neural semantic parsers aware compositional structure utterances, often limits generalization various compound-complex utterances: However, due lack capturing compositional structures utterances, neural semantic parsers usually poor generalization ability handle unseen compositions semantics~. For example, parser trained ``How many rivers run oklahoma?'' ``Show states bordering colorado?'' may perform well ``How many rivers run states bordering colorado?''. \end{table} \end{table*} In paper, propose novel framework boost neural semantic parsers principle compositionality~. It iterates segmenting span utterance parsing partial meaning representation. Table shows example. Given utterance ``How many rivers run states bordering colorado?'', parse three iterations: segment span ``the states bordering colorado'' utterance, parse ; utterance reduced ``How many rivers run \?'', segment span ``rivers run \'' it, parse ; utterance reduced ``How many \?'', parse . We compose partial meaning representations final result. Our framework consists two neural modules: utterance segmentation model base parser . The former charge segmenting span utterance, latter charge parsing span meaning representation. These two modules work together parse complex input utterances divide-and-conquer fashion. One key advantage framework require handcraft templates additional labeled data utterance segmentation: achieve proposing novel training method, base parser provides pseudo supervision utterance segmentation model. Specifically: train preliminary base parser original train data; then, train sample , use preliminary base parser check whether spans parsed \textcolor{red}{be} part \textcolor{red}{or not}. If true, leverage spans pseudo supervision signals training utterance segmentation model, thereby require handcraft templates additional labeled data.} %The key implement framework address challenge lacking labeled data utterance segmentation. %We achieve cooperative training segmentation model base parser: %leverage pre-trained base parser derive synthetic supervision signals training segmentation model, leverage segmentation model derive synthetic supervision signals updating base parser. % \textcolor{green}{Moreover, considering usually labeled data utterance segmentation, propose search reasonable segmentation points utterances via base parser, use distant supervision. This improves domain adaptability framework.} % While lacking direct supervision segmentation model, seek address challenge distantly supervised way. % shaped like %\textcolor{red}{ %Firstly, train base parser, use search evaluate viable ways segment training utterances. %Then, segmentations leveraged distant supervision training utterance segmentation model fine-tuning base neural semantic parser.} In summary, proposed framework four advantages: base parser learns parse simpler spans instead whole complex utterances, thus alleviating training difficulties improving compositional generalization ability; framework flexible incorporate various popular encoder-decoder models base parser; framework require handcraft templates additional labeled data utterance segmentation; % framework addresses challenge lacking labeled data utterance segmentation cooperative training. framework improves interpretability neural semantic parsing providing explicit alignment spans partial meaning representations. We conduct experiments three datasets: Geo~, ComplexWebQuestions~, Formulas . They use different forms meaning representations: FunQL, SPARQL, Spreadsheet Formula. Experimental results show framework consistently improves performances neural semantic parsers different domains. On data splits require compositional generalization, framework brings significant accuracy gain: Geo , Formulas , ComplexWebQuestions ."," Neural semantic parsers usually fail to parse long and complex utterances into correct meaning representations, due to the lack of exploiting the principle of compositionality. To address this issue, we present a novel framework for boosting neural semantic parsers via iterative utterance segmentation. Given an input utterance, our framework iterates between two neural modules: a segmenter for segmenting a span from the utterance, and a parser for mapping the span into a partial meaning representation. Then, these intermediate parsing results are composed into the final meaning representation. One key advantage is that this framework does not require any handcraft templates or additional labeled data for utterance segmentation: we achieve this through proposing a novel training method, in which the parser provides pseudo supervision for the segmenter. Experiments on Geo, ComplexWebQuestions and Formulas show that our framework can consistently improve performances of neural semantic parsers in different domains. On data splits that require compositional generalization, our framework brings significant accuracy gains: Geo $63.1\to 81.2$, Formulas $59.7\to 72.7$, ComplexWebQuestions $27.1\to 56.3$."
"Word alignment task finding corresponding words sentence pair used key component statistical machine translation . Although word alignment longer explicitly modeled neural machine translation , often leveraged interpret analyze NMT models . Word alignment also used many scenarios, imposing lexical constraints decoding process , improving automatic post-editing providing guidance translators computer-aided translation . Recently, unsupervised neural alignment methods studied outperformed GIZA++ many alignment datasets . However, methods trained translation objective, computes probability target token conditioned source tokens previous target tokens. This bring noisy alignments prediction ambiguous . To alleviate problem, previous studies modify Transformer adding alignment modules re-predict target token , computing additional alignment loss full target sequence . Moreover, \citet{chen2020accurate} propose extraction method induces alignment to-be-aligned target token decoder input. Although methods demonstrated effectiveness, two drawbacks. First, retain translation objective tailored word alignment. Consider example Figure . When predicting target token ``Tokyo'', translation model may wrongly generate ``1968'' considers previous context, result incorrect alignment link . A better modeling needed obtaining accurate alignments. Second, need additional guided alignment loss outperform GIZA++, requires inducing alignments entire training corpus. In paper, propose self-supervised model specifically designed word alignment task, namely Mask-Align. Our model masks target token recovers source rest target tokens. For example, shown Figure , target token ``Tokyo'' masked re-predicted. During process, model identify source token ``Tokio'' translated yet, to-be-predicted target token ``Tokyo'' aligned ``Tokio''. Comparing translation model, masked modeling method highly related word alignment, based model generates accurate predictions alignments. % We model target token conditioned tokens source target, disambiguate prediction thus lead accurate alignment ). As vanilla transformer architecture requires sequential time model probability, modify attention decoder separating queries keys values % updating former layer. This allows model predict target tokens single forward pass without information leakage. Besides, also propose variant attention called leaky attention allieviates unexpected high attention weights specific tokens periods, helpful alignment extraction attention matrix. Finally, leverage attention weights models two directions incorporating agreement loss training process. % Experiments four public datasets show model significantly outperforms existing statistical neural methods without using guided alignment loss. To summarize, main contributions work listed follows:"," Neural word alignment methods have received increasing attention recently. These methods usually extract word alignment from a machine translation model. However, there is a gap between translation and alignment tasks, since the target future context is available in the latter. In this paper, we propose Mask-Align, a self-supervised model specifically designed for the word alignment task. Our model parallelly masks and predicts each target token, and extracts high quality alignments without any supervised loss. In addition, we introduce leaky attention to alleviate the problem of unexpected high attention weights on special tokens. Experiments on four language pairs show that our model significantly outperforms all existing unsupervised neural baselines and obtains new state-of-the-art results.  % However, the original translation objective ignores the future context in the target, which is available in the alignment task."
"The sequence-to-sequence models~, learn map arbitrary-length input sequence another arbitrary-length output sequence, successfully tackled wide range language generation tasks. % including machine translation, text summarization, question generation, name few. Early seq2seq models used recurrent neural networks encode decode sequences, leveraging attention mechanism allows decoder attend specific token input sequence capture long-term dependencies source target sequences. Recently, Transformer~, all-attention model effectively captures long-term relationships tokens input sequence well across input output sequences, become de facto standard text generation tasks due impressive performance. Moreover, Transformer-based language models trained large text corpora shown significantly improve model performance text generation tasks. %Seq2seq tasks becoming increasingly important, show text-based language problems cast sequence-to-sequence problems. However, crucial limitation seq2seq models mostly trained teacher forcing, ground truth provided time step thus never exposed incorrectly generated tokens training ), hurts generalization. This problem known ``exposure bias"" problem often results generation low-quality texts unseen inputs. Several prior works tackle problem, using reinforcement learning maximize non-differentiable reward . % --- BLEU Rouge. Another approach use RL gumbel softmax match distribution generated sentences ground truth, case reward discriminator output Generative Adversarial Network . Although aforementioned approaches improve performance seq2seq models text generation tasks, either require vast amount effort tuning hyperparameters stabilize training. %Moreover, show RL methods machine translation often optimize expected reward performance gain attributed side effects, increasing peakiness output distribution. In work, propose mitigate exposure bias problem simple yet effective approach, contrast positive pair input output sequence negative pairs, expose model various valid incorrect sentences. Na鑼倂ely, construct negative pairs simply using random non-target sequences batch~. However, na鑼倂e construction yields meaningless negative examples already well-discriminated embedding space ), highlight reason existing methods~ require large batch size. This clearly shown Fig., large portion positive-negative pairs easily discriminated without training, gets worse batch size decreases reduce chance meaningfully difficult examples batch. Moreover, discriminating positive na鑼倂e negative pairs becomes even easier models pretrained large text corpora. To resolve issue, propose principled approaches automatically generate negative positive pairs constrastive learning, refer Contrastive Learning Adversarial Perturbation Seq2seq learning . Specifically, generate negative example adding small perturbation hidden representation target sequence, conditional likelihood minimized ). Conversely, construct additional positive example ) adding large amount perturbation hidden representation target sequence perturbed sample far away source sequence embedding space, enforcing high conditional likelihood minimizing Kullback-Leibler divergence original conditional distribution perturbed conditional distribution. This yield negative example close original representation target sequence embedding space largely dissimilar semantics, generated positive example far away original input sequence semantic target sequence. This generate difficult examples model fails correctly discriminate , Fig.2), helping learn meaningful pairs. To verify efficacy method, empirically show significantly improves performance seq2seq model three conditional text generation tasks, namely machine translation, text summarization question generation. Our contribution work threefold:"," Recently, sequence-to-sequence  models with the Transformer architecture have achieved remarkable performance on various conditional text generation tasks, such as machine translation. However, most of them are trained with teacher forcing with the ground truth label given at each time step, without being exposed to incorrectly generated tokens during training, which hurts its generalization to unseen inputs, that is known as the ``exposure bias"" problem. In this work, we propose to mitigate the conditional text generation problem by contrasting positive pairs with negative pairs, such that the model is exposed to various valid or incorrect perturbations of the inputs, for improved generalization. However, training the model with na閼煎俥 contrastive learning framework using random non-target sequences as negative examples is suboptimal, since they are easily distinguishable from the correct output, especially so with models pretrained with large text corpora. Also, generating positive examples requires domain-specific augmentation heuristics which may not generalize over diverse domains. To tackle this problem, we propose a principled method to generate positive and negative samples for contrastive learning of seq2seq models. Specifically, we generate negative examples by adding small perturbations to the input sequence to minimize its conditional likelihood, and positive examples by adding  large perturbations while enforcing it to have a high conditional likelihood. Such ``hard'' positive and negative pairs generated using our method guides the model to better distinguish correct outputs from incorrect ones. We empirically show that our proposed method significantly improves the generalization of the seq2seq on three text generation tasks --- machine translation, text summarization, and question generation."
"%缁楊兛绔村▓纰夌窗headline瀵板牓鍣哥憰 With rapid growth information spreading throughout Internet, readers get drown sea documents, pay attention articles attractive headlines catch eyes first sight. On one hand, generating headlines trigger high click-rate especially important different avenues forms media compete user's limited attention. On hand, help good headline, outstanding article discovered readers. %缁楊兛绗佸▓纰夌窗閹存垳婊戦惃鍕侀崹瀣簼绠為幀搴濈疄閸 To generate better headlines, first analyze makes headlines attractive. By surveying hundreds headlines popular websites, found one important feature influences attractiveness headline content. For example, reporting event, headline ``Happy knowing danger: Children India play poisonous foam beach'' wins 1000 page views, headline ``Chennai beach covered white foam four days India'' 387 readers. The popular headline highlights fact ``the beach poisonous affects children'', concern people ``white foam''. On hand, style headline also huge impact attractiveness. For example, headline ``Only two people scored thousand history NBA Finals'' attracts fewer people headline ``How hard get 1000 points NBA finals? Only two people history!'', due conversational style makes readers feel need see answer question. %缁楊兛绨╁▓纰夌窗challenge:婵″倷缍嶉惌銉╀壕attractive Most recent researches regard headline generation task merely typical summarization task . This sufficient good headline capture relevant content article also attractive reader. However, attractive headline generation tasks paid less attention researchers. \citet{xu2019clickbait} tackle task adversarial training, using attractiveness score module guide summarization process. \citet{jin2020hooks} introduce parameter sharing scheme disentangle attractive style attractive text. However, previous works neglect fact attractiveness style, also content. % negative samples generated pre-trained model non-fluent, inconsistent, incoherent, makes difficult scorer learn attractiveness standard given huge noise. Based analysis, propose model named Disentanglement-based Attractive Headline Generation , learns write attractive headlines style content perspectives. These two attractiveness attributes learned attractive prototype headline, \ie headline document training dataset similar input document. First, DAHG separates attractive style content prototype headline latent spaces, two auxiliary constraints ensure two spaces indeed disentangled. Second, learned attractive content space utilized iteratively polish input document, emphasizing parts document attractive. Finally, decoder generates attractive headline polished input document representation guidance separated attractive style space. Extensive experiments public Kuaibao dataset show DAHG outperforms summarization headline generation baselines terms ROUGE metrics, BLEU metrics, human evaluations large margin. Specifically, DAHG triggers 22\% clicks strongest baseline. %缁楊剙娲撳▓纰夌窗閹崵绮╟ontribution The major contributions paper follows: We devise disentanglement mechanism divide attractive content style space attractive prototype headline. We propose generate attractive headline help disentangled content space style guidance. Experimental results demonstrate model outperforms baselines terms automatic human evaluations."," Eye-catching headlines function as the first device to trigger more clicks, bringing reciprocal effect between producers and viewers. Producers can obtain more traffic and profits, and readers can have access to outstanding articles. When generating attractive headlines, it is important to not only capture the attractive content but also follow an eye-catching written style.  In this paper, we propose a Disentanglement-based Attractive Headline Generator  that generates headline which captures the attractive content following the attractive style. Concretely, we first devise a disentanglement module to divide the style and content of an attractive prototype headline into latent spaces, with two auxiliary constraints to ensure the two spaces are indeed disentangled. The latent content information is then used to further polish the document representation and help capture the salient part. %The latent attractive content space further helps to distill salient and attractive knowledge from the input document. Finally, the generator takes the polished document as input to generate headline under the guidance of the attractive style.  Extensive experiments on the public Kuaibao dataset show that DAHG achieves state-of-the-art performance.  Human evaluation also demonstrates that DAHG triggers 22\% more clicks than existing models."
"Task-specific finetuning pretrained deep networks become dominant paradigm contemporary NLP, achieving state-of-the-art results across suite natural language understanding tasks . While straightforward empirically effective, approach difficult scale multi-task, memory-constrained settings , requires shipping storing full set model parameters task. Inasmuch models learning generalizable, task-agnostic language representations self-supervised pretraining, finetuning entire model task seems especially profligate. A popular approach parameter-efficiency pretrained models learn sparse models task subset final model parameters exactly zero~. Such approaches often face steep sparsity/performance tradeoff, substantial portion nonzero parameters still typically required match performance dense counterparts. An alternative use multi-task learning feature-based transfer parameter-efficient transfer learning pretrained models~. These methods learn small number additional parameters top shared model. However, multi-task learning generally requires access tasks training prevent catastrophic forgetting~, feature-based transfer learning typically outperformed full finetuning~. Adapters~ recently emerged promising approach parameter-efficient transfer learning within pretrain-finetune paradigm~. Adapter layers smaller, task-specific modules inserted layers pretrained model, remains fixed shared across tasks. These approaches require access tasks training, making attractive settings one hopes obtain share performant models new tasks arrive stream. \citet{houlsby2019adapters} find adapter layers trained BERT match performance fully finetuned BERT GLUE benchmark requiring 3.6\% additional parameters per task. In work, consider similar setting adapters propose new diff pruning approach goal even parameter-efficient transfer learning. Diff pruning views finetuning learning task-specific \underline{diff}erence vector%\footnote{Similar command Unix operating systems.} \ applied top pretrained parameter vector, remains fixed shared across different tasks. In order learn vector, reparameterize task-specific model parameters , pretrained parameter vector fixed task-specific diff vector finetuned. The diff vector regularized differentiable approximation -norm penalty~ encourage sparsity. This approach become parameter-efficient number tasks increases requires storing nonzero positions weights diff vector task. The cost storing shared pretrained model remains constant amortized across multiple tasks. On GLUE benchmark~, diff pruning match performance fully finetuned BERT baselines finetuning pretrained parameters per task, making potential alternative adapters parameter-efficient transfer learning."," While task-specific finetuning of pretrained networks has led to significant empirical advances in NLP, the large size of networks makes finetuning difficult to deploy in multi-task, memory-constrained settings. We propose diff pruning as a simple approach to enable parameter-efficient transfer learning within the pretrain-finetune framework. This approach views finetuning as learning a task-specific ``diff"" vector that is applied on top of the pretrained parameter vector, which remains fixed and is shared across different tasks. The diff vector is adaptively pruned during training with a differentiable approximation to the $L_0$-norm penalty to encourage sparsity. Diff pruning becomes parameter-efficient as the number of tasks increases, as it requires storing only the nonzero positions and weights of the diff vector for each task, while the cost of storing the shared pretrained model remains constant. It further does not require access to all tasks during training, which makes it attractive in settings where tasks arrive in stream or the set of tasks is unknown. We find that models finetuned with diff pruning can match the performance of fully finetuned baselines on the GLUE benchmark while only modifying 0.5$\%$ of the pretrained model's parameters per task.\blfootnote{ \hspace{-6mm} Our code is available at \url{https://github.com/dguo98/DiffPruning}}"
"Goal-oriented dialogue systems hot topic machine learning research. The systems widespread applications industry foundation many successful products, including Alexa, Siri, Google Assistant, Cortana. One core component dialog system spoken language understanding , consists two main problems, intent classification slot labeling . In IC, attempt classify goal user query, usually input text transcribed automatic speech recognition system audio. SL, similar named-entity recognition problem, aims label token query entity type. The difference entity types SL domain-specific based upon dialog ontology. Recent advances neural models enabled greatly improved SLU . However, two significant challenges hinder broad application expansion SLU models industrial settings. First all, neural methods require large amount labeled data training . SLU often coupled ontology underlying dialog system thus domain-dependent. Collecting large number in-domain labeled data neural models prohibitively expensive time-consuming. Secondly, performance SLU models practice often suffers fluctuations due various types noises. One common noise adaptation data perturbation. In many industrial applications cloud services\footnote{Alexa ASK: https://developer.amazon.com/en-US/alexa/alexa-skills-kit; Google DialogFlow: https://dialogflow.com/}, SLU model built fine-tuning pre-trained, shared network target domain data provided developers. The developers often limited background SLU machine learning. Thus data provided varies quality subject different types perturbations, missing replaced data samples typos. Another common noise comes mismatch input modalities adaptation inference stages. For instance, model adapted human transcription yet deployed understand ASR decoded text, input adaptation inference stages relies recognition different versions ASR models. Given neural methods comprise large number parameters heavily optimized training data provided, resulting model usually sensitive noises. The requirement noise-free adaptation inference conditions also prohibits use neural SLU techniques often infeasible achieve conditions. Transfer learning meta-learning two conventional techniques applied address challenge data scarcity. Transfer learning usually refers pre-training initial models using mismatched domains rich human annotations adapting models limited labels targeted domains. Previous works shown promising results applying transfer learning SLU. Note pre-training discussed covers methods including using pre-trained language model like BERT directly training downstream tasks data mismatched domains pre-trained model. In following, focus latter due utilizing data domains better yielding higher accuracy. In recent years, meta-learning gained growing interest among machine learning fields tackling few-shot learning scenarios. Model-Agnostic Meta-Learning focuses learning parameter initialization multiple subtasks, initialization fine-tuned labels yield good performance targeted tasks. Metric-based meta-learning, including prototypical networks matching networks , aim learn embedding metric space generalized domains unseen training set adaptation small number examples unseen domains. Recent work unveils excellent potential applying meta-learning techniques SLU few-shot learning context . As compared data scarcity, another challenge SLU, robustness noises, also gaining attention. Simulated ASR errors used augment training data SLU models . Researchers also leverage information confusion networks lattices , adversarial training techniques models learn query embeddings robust ASR errors. For text input, methods also explored model robustness noises misspelling acronym . In contrast noise types gained attention, best knowledge, prior work investigating impact missing replaced examples adaptation data. Moreover, intersection data scarcity noise robustness unexplored. Since scarcity labeled data data noisiness usually co-occur SLU applications , lack studies intersectional areas hinders use neural SLU models expansion broader use cases. Given deficiency, establish novel few-shot noisy SLU task introducing two common types natural noise, adaptation example missing/replacing modality mismatch, previously defined few-shot IC/SL splits . The task built upon three public datasets, ATIS , SNIPS , TOP . We propose noise-robust few-shot SLU model based ProtoNets established task. In summary, primary contributions 3-fold: 1) formulating first few-shot noisy SLU task evaluation framework, 2) proposing first working solution few-shot noisy SLU existing ProtoNet algorithm, 3) context noisy scarce learning examples, comparing performance proposed method conventional techniques, including MAML fine-tuning based adaptation.","    Recently deep learning has dominated many machine learning areas, including spoken language understanding . However, deep learning models are notorious for being data-hungry, and the heavily optimized models are usually sensitive to the quality of the training examples provided and the consistency between training and inference conditions. To improve the performance of SLU models on tasks with noisy and low training resources, we propose a new SLU benchmarking task: few-shot robust SLU, where SLU comprises two core problems, intent classification  and slot labeling . We establish the task by defining few-shot splits on three public IC/SL datasets, ATIS, SNIPS, and TOP, and adding two types of natural noises  to the splits. We further propose a novel noise-robust few-shot SLU model based on prototypical networks. We show the model consistently outperforms the conventional fine-tuning baseline and another popular meta-learning method, Model-Agnostic Meta-Learning , in terms of achieving better IC accuracy and SL F1, and yielding smaller performance variation when noises are present."
"In modern world, social media playing part several ways, instance news dissemination information sharing, social media outlets, Twitter, Facebook, Instagram, proved effective . However, also comes several challenges, collecting information several sources, detecting filtering misinformation . Similar events pandemics, one deadly pandemics history, COVID-19 subject discussion social media since emergence. Without surprise, lot misinformation pandemic circulated social networks. In order identify misinformation spreaders filter fake news COVID-19 5G conspiracy, task namely ""FakeNews: Corona Virus 5G Conspiracy Multimedia Twitter-Data-Based Analysis"" proposed benchmark MediaEval 2020 competition . This paper provides detailed description methods proposed team DCSE\_UETP fake news detection task. The task consists two parts, namely text-based misinformation detection , structure-based misinformation detection . The first task based textual analysis COVID-19 related information shared Twitter January 2020 15th July 2020, aims detect different types conspiracy theories COVID-19 vaccines, ""the 5G weakens immune system thus caused current corona-virus pandemic etc., . In SMD task, participants provided set graphs, representing sub-graph Twitter, corresponds single tweet vertices graphs represent accounts. Similar TMD, task, participants need detect differentiate 5G COVID-19 conspiracy theories."," The paper presents our solutions for the MediaEval 2020 task namely FakeNews: Corona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task aims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect misinformation spreaders. The task is composed of two sub-tasks namely  text-based, and  structure-based fake news detection. For the first task, we propose six different solutions relying on Bag of Words  and BERT embedding. Three of the methods aim at binary classification task by differentiating in 5G conspiracy and the rest of the COVID-19 related tweets while the rest of them treat the task as ternary classification problem. In the ternary classification task, our BoW and BERT based methods obtained an F1-score of .606\% and .566\% on the development set, respectively. On the binary classification, the BoW and BERT based solutions obtained an average F1-score of .666\% and .693\%, respectively. On the other hand, for structure-based fake news detection, we rely on Graph Neural Networks  achieving an average ROC of .95\% on the development set."
"Recurrent neural networks basis state-of-the-art models natural language processing, including language modeling , machine translation named entity recognition . It needless say complex learning tasks require relatively large networks millions parameters accomplished. However, large neural networks need data and/or strong regularization techniques trained successfully avoid overfitting. Without means collect data, case majority real-world problems, data augmentation regularization methods standard alternative practices overcome barrier. Data augmentation natural language processing limited, often task-specific . On hand, adopting regularization methods originally proposed feed-forward networks needs done extra care avoid hurting network's information flow consecutive time-steps. To overcome limitations, present Sequence Mixup: set training methods, regularization techniques, data augmentation procedures RNNs. Sequence Mixup considered RNN-generalization input mixup manifold mixup , already introduced feed-forward neural networks. Generally speaking, core idea behind mixup strategies mix training samples network's input hidden layers, mix, simply mean consider random convex combinations pairs samples alternatives actual training data points. Mixup non-recurrent networks led smoother decision boundaries, robustness adversarial examples, better generalization compared many rival regularization methods . Here, extend input mixup RNNs also propose two variants manifold mixup, namely Pre-Output Mixup Through-Time Mixup , mixing occurs hidden space RNN. POM TTM differ way information flow passed one time-step next. In order elucidate effect sequence mixup learning stage, consider classification half-moons data plotted figure simple two-timestep RNN. We also added levels noise original data points make classification task challenging. Figures show learned decision boundaries noisy data via regular training Pre-Output Mixup, respectively. As seen, mixup expands margin classes increases decision boundary levels, turn renders smoother decision boundary less certainty nearby cross-class samples. Intuitively speaking, type training creates artificial samples whose labels hidden states obtained intermixing original samples, respective manner. Based experiments, applying sequence mixup improved test F-1 score loss BiLSTM-CRF model CoNLL-03 data . We also provided theoretical analysis impact regularization techniques asymptotic regime network widths become increasingly large, learning rates become infinitesimally small. In nutshell, analysis reveals long number hidden state neurons, denote work, less number distinct classes classification problem, POM TTM cannot achieve zero training error regardless large training dataset deep neural networks become. Moreover, show long less twice number classes, hidden-state generating section RNN acts memoryless unit produces hidden states almost independent previous time-steps. On hand, given chosen sufficiently large, POM TTM able divide hidden representation space RNN set orthogonal affine subspaces, subspace indicator unique class. We refer property spectral compression sequence mixup, similar behaviour manifold mixup feed-forward networks. The rest paper organized follows: Section reviews number related works problem. In Section , propose Sequence Mixup, describe challenges specifications detail, also present theoretical analysis. Section devoted experiments real-world data. Finally, Section concludes paper. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"," In this paper, we extend a class of celebrated regularization techniques originally proposed for feed-forward neural networks, namely Input Mixup \citep{zhang2017mixup} and Manifold Mixup \citep{verma2018manifold}, to the realm of Recurrent Neural Networks . Our proposed methods are easy to implement and have a low computational complexity, while leverage the performance of simple neural architectures in a variety of tasks. We have validated our claims through several experiments on real-world datasets, and also provide an asymptotic theoretical analysis to further investigate the properties and potential impacts of our proposed techniques. Applying sequence mixup to BiLSTM-CRF model \citep{huang2015bidirectional} to Named Entity Recognition task on CoNLL-2003 data \citep{sang2003introduction} has improved the F-1 score on the test stage and reduced the loss, considerably. \blfootnote{Emails: \{karamzade,najafy\}@ce.sharif.edu,~motahari@sharif.edu} \blfootnote{An implementation of our method is avaiable at \href{https://github.com/ArminKaramzade/SequenceMixup}{https://github.com/ArminKaramzade/SequenceMixup.}}"
"Sentiment classification task analyzing piece text predict orientation attitude towards event opinion. The sentiment text either positive negative. Sometimes, neutral perspective also considered classification. SA many different applications, reducing early age suicide rate identifying cyberbullying , discouraging unwarranted activities towards particular community hate-speech detection , monitoring public response towards proposed government bill among many others. The task SA achieved superior improvement languages, i.e. English - 97.1\% accuracy 2-class 91.4\% accuracy 3-class SA . But research works published SA Bengali. This lack quality datasets Bengali training computation model sentiment classification. However, last years, seen rise Internet users Bengali domain mostly due development wireless network infrastructure throughout South East Asia. This resulted massive increase total number online social network users well newspaper readers. So became comparatively easier collect public comments posted online Bengali news websites. % \end{table} Thus created two SA datasets 2-class 3-class SA Bengali trained multi-lingual BERT model via transfer learning approach sentiment classification Bengali, referred paper. achieves accuracy 71\% 2-class 60\% 3-class manually tagged dataset. We use model analyze sentiment 1,002 public comments collected online daily newspaper. Table shows general, sentiment public comments positive religious news articles, negative political sports news articles. In paper, present following contributions: % \makeatletter % \patchcmd{\@makecaption} % {\scshape} % {} % {} % {} % \makeatletter % \patchcmd{\@makecaption} % {\\} % {.\ } % {} % {} % \makeatother % \def\tablename{Table}"," Sentiment analysis  in Bengali is challenging due to this Indo-Aryan language's highly inflected properties with more than 160 different inflected forms for verbs and 36 different forms for noun and 24 different forms for pronouns. The lack of standard labeled datasets in the Bengali domain makes the task of SA even harder. In this paper, we present manually tagged 2-class and 3-class SA datasets in Bengali. We also demonstrate that the multi-lingual BERT model with relevant extensions can be trained via the approach of transfer learning over those novel datasets to improve the state-of-the-art performance in sentiment classification tasks. This deep learning model achieves an accuracy of 71\% for 2-class sentiment classification compared to the current state-of-the-art accuracy of 68\%. We also present the very first Bengali SA classifier for the 3-class manually tagged dataset, and our proposed model achieves an accuracy of 60\%. We further use this model to analyze the sentiment of public comments in the online daily newspaper. Our analysis shows that people post negative comments for political or sports news more often, while the religious article comments represent positive sentiment. The dataset and code is publicly available \footnote{ https://github.com/KhondokerIslam/Bengali\_Sentiment}."
"Methods automatically learning phone- word-like units unlabelled speech audio could enable speech technology severely low-resourced settings could lead new cognitive models human language acquisition. The goal unsupervised representation learning phone units learn features capture phonetic contrasts invariant properties like speaker channel. Early approaches focussed learning continuous features. In attempt better match categorical nature true phonetic units, recent work considered discrete representations. One approach use self-supervised neural network intermediate layer quantizes features using learned codebook. While discrete codes vector quantized networks given improvements intrinsic phone discrimination tasks, still encode speech much higher bitrate true phone sequences. As example, top Figure shows code indices vector-quantized variational autoencoder overlaid input spectrogram. While correspondence code assignments true phones , although repetition codes adjacent frames , input speech often assigned codes distinct surrounding frames. This surprising since VQ model explicitly encouraged so. The result encoding much higher bitrate true phone sequences . In paper consider ways constrain VQ models contiguous feature vectors assigned code, resulting low-bitrate segmentation speech discrete units. We specifically compare two VQ segmentation methods. Both based recent method segmenting written character sequences. The first method greedy approach, closest adjacent codes merged set number segments reached. The second method allows arbitrary number segments. A squared error blocks feature vectors VQ codes used together penalty term encouraging longer-duration segments. The optimal segmentation found using dynamic programming. We apply two segmentation approaches using encoders codebooks two VQ models . The first type VQ-VAE. The second vector-quantized contrastive predictive coding model. The combination two models two segmentation approaches gives total four VQ segmentation models consider. %Applying models segmentation approaches gives total four model combinations. We evaluate four different tasks: unsupervised phone segmentation, ABX phone discrimination, same-different word discrimination, inputs symbolic word segmentation algorithm. The last-mentioned particularly important since segmentation clustering % word-like units %from unlabelled speech remains major important challenge. On metrics four tasks combination VQ-VAE penalized dynamic programming approach best VQ segmentation method. Example output shown middle Figure. Compared existing methods, achieve state-of-the-art performance four evaluation tasks. However, achieves reasonable performance much lower bitrate existing methods. This noteworthy since, methods tailored respective tasks, single VQ segmentation approach used without alteration directly range problems."," We investigate segmenting and clustering speech into low-bitrate phone-like sequences without supervision. We specifically constrain pretrained self-supervised vector-quantized~ neural networks so that blocks of contiguous feature vectors are assigned to the same code, thereby giving a variable-rate segmentation of the speech into discrete units. Two segmentation methods are considered. In the first, features are greedily merged until a prespecified number of segments are reached. The second uses dynamic programming to optimize a squared error with a penalty term to encourage fewer but longer segments. We show that these VQ segmentation methods can be used without alteration across a wide range of tasks: unsupervised phone segmentation, ABX phone discrimination, same-different word discrimination, and as inputs to a symbolic word segmentation algorithm. The penalized method generally performs best. While results are only comparable to the state-of-the-art in some cases, in all tasks a reasonable competing approach is outperformed at a substantially lower bitrate."
"Natural language provided key cohesive ingredient pushing boundaries technological advances beyond individuals 4th industrial revolution. In textual form, provides long term, stable, knowledge base, used preserve knowledge across generations. Digital evolution last century greatly accelerated preservation process provided means extract hidden meaning information texts, largely considered illegible indecipherable human beings. Natural Language Processing divergent field, state-of-the-art research initiative looking towards resolving various challenges automatic information extraction. Foremost, amongst challenges ability identify various concepts relationship, form epitome target corpus . For humans machines, cause-effect represents essential relation, provides ample support reasoning decision making process . Automatic causality detection benefited greatly numerous dedicated research efforts . However, challenges dynamicity syntax semantics, particular evolution vocabulary hindered development usage generic cross-domain solution . On hand, applications information retrieval , question answering , event reasoning predictions gained valuable improvements identification cause-effect relationships. \\ The commonly used approaches causality detection, fall two categories: pattern-based traditional rule bases, machine learning based automatic classification entity extraction . Pattern based approaches based partial complete expert intervention crafting verifying conditions based syntactic semantic analysis corpus. This approach, requires intensive human effort lacks cross-domain generalization. Even utilizing substantial amount human time, extracted rules cannot cover possible linguistic patterns usually usable beyond original domain/corpus. Such approach also suffers diversity linguistic typology, leading rules formed language based Subject-Verb-Object sentence structure compatible based structures Subject-Object-Verb others .\\ Automatic machine learning based approaches utilize labeled datasets extracting causality relationships unseen data thereby requires less expert intervention, relatively. With approach, human time spent labeling data verifying results, providing reusable model cross-domain applications. However, evolution labels change text render model unusable. Additionally, machine learning models, typically independent linguistic topology features customized work sentence structure albeit effort towards creating optimizing language vectors, incorporating natural heuristics derived syntactically labelled well distributed large corpus .\\ A solution managing change machine learning models reducing expert intervention available Transfer Learning, machine learn new tasks reusing foundational model, originally employed different related task another domain . Such cross-domain application may replicate original performance benchmarks, thereby requires model tuning tweaking becoming useful. Model tuning achieved help human expert provides feedback machine learning model improving learning tasks, technique commonly known active learning . To gain benefits two approaches active transfer learning applied various tasks diverse domains , transferring similar models improving performance single workflow. This performance mainly improved enhancing pre-trained model annotated dataset expert involvement new domain.\\ Causality mining application causality detection typically based two tasks, includes identification causal triggers, causal pairs participating relationship . Also known causal connectives; causal triggers transitive verbs form bridge causality concepts identify cause effect. Leveraging sentence structuring English language, typical causality relation identification methodologies, found research literature, follow Noun Phrase - Verb - NP pattern corresponds either Cause - Trigger - Effect Effect - Trigger - Cause forms . Based heuristic, Kaplan Berry-Bogge provided early model creating using handcrafted linguistic template causality detection. Kalpana Raja et al. , built upon idea addition identifying organizing dictionary based causal trigger keywords, used define patterns causality detection. R. Girju et al. refined process identifying causal verbs utilizing WordNet dictionary. Cole et al. utilized syntactic parser convert SVO structures SVO triples, passed various rule based filters causality detection. S. Zhao et al. , pointed towards existence diversity manner causal trigger expresses causality. However, syntactic structure causal sentences way trigger invokes causality, provide satisfactory categorization causal triggers, enabling smart application causality identification filters. Son Doan et al. presented application causal mining marking several verbs nouns causal triggers extracting causal relations twitter messages. Girju Moldovan proposed semi-supervised approach towards causality relation identification using underlying linguistic patterns corpus.\\ Many automatic causal pattern identification methodologies relied evolution machine learning models. In particular, presented causal relation extraction model using unsupervised learning detect noun phrases corresponding subject object sentence. By analysing unannotated raw corpus using Expected Maximization along Naive Bayes classifier, authors able precisely identify 81.29\% causal relations. \\ On hand, E. Blanco et al. utilized supervised learning approach first annotating ternary instances causal relation not, applied Bagging C4.5 decision trees achieve precision 95\% causal relations ad 86\% non causal ones. These many machine learning approaches comprehensively classified , indicates general trend towards utilizing same, models become mature stable. Of particular interest word embedding methods, due requirement unsupervised data, scalability, accuracy piqued interest NLP research community. \\ Several initiatives already led state-of-the-art results completing NLP tasks sentiment analysis, text classification, topic modeling, relation extraction . Zeng et al. classified relations SemEval Task 8 dataset using deep convolution neural networks . Nguyen et al. introduced positional embedding input sentence vector CNNs improved relation extraction. Silva et al. proposed deep learning based causality extraction methodology detect causality along direction. The author addressed causality detection problem three class classification problem, class 1 indicates annotated pairs causal relation direction entity1 entity2, class 2 implies causal relation direction entity2 entity1, class 3 entities non-causal.\\ Ning An et al. utilized word embedding cosine similarity based approach, uses initial causal seed list identify causal relationships multi-class classification problem. With one-hot encoding authors, convert causal verbs seed list verbs identified Noun Phrase-Verb Phrase-Noun Phrase ternary encoding vectors. These vectors converted Embedding vectors using Continuous Skip-Gram based Wikipedia dataset 3.7 million articles. Finally encoded vectors compared using cosine similarity pair maximum similarity pre-defined threshold value 0.5 used classify causal relationship evolve seed list. This method achieved average F-score 78.67\%. While methodology presents significant improvement previous research initiatives towards causal relationship identification, suffers low accuracy, due focus causal verb identification based small initial seed list limited extension, classification based, solely verbs meanwhile losing context causal phrase. \\ In paper present novel causal relationship identification framework, outperform, domain causality mining clinical text. This framework uses multi-dimensional approach, resolves syntactic semantic matching problems clinical textual data, providing causal knowledge useful summarize clinical text quick review, create patient personas reapplication medical procedures predictive analysis, discovering medical knowledge volumnous data sources, provide evidence supporting clinical decision making.\\ This novel framework identifies causal phrases using automatic seed list generation training data set, seed expansion using transfer learning, causal phrase generation, BERT based phrase embedding semantic matching. It applies semantic enrichment causal phrases using Unified Medical Language System , extend healthcare terms semantic uniquely identifiable corresponding codes. Finally, trained model evolved based expert feedback, employing active learning.\\ In presented approach, extracted initial causal seed list SemEval Task 8 dataset expanded utilizing synonyms WordNet dictionary, pre-trained Google News model , ConceptNet Numberbatch Model , Facebook Fasttext Model . We generated causal quads using dependency based linguistic patterns identifying subject, object, causal verb, confidence measure. Causal triples, threshold, filtered quads converted embedding vectors using BERT create initial model. This trained model used identify candidate causal triples unseen textual data, semantically enriched UMLS converted causal quad augmenting confidence score. The semantically enriched causal quads verified expert increasing decreasing confidence value used evolve trained model, iteratively.\\ This detailed methodology presented section , details workflows section results following section . Finally, section conclude paper."," Objective: Causality mining is an active research area, which requires the application of state-of-the-art natural language processing techniques. In the healthcare domain, medical experts create clinical text to overcome the limitation of well-defined and schema driven information systems. The objective of this research work is to create a framework, which can convert clinical text into causal knowledge. \\ Methods: A practical approach based on term expansion, phrase generation, BERT based phrase embedding and semantic matching, semantic enrichment, expert verification, and model evolution has been used to construct a comprehensive causality mining framework. This active transfer learning based framework along with its supplementary services, is able to extract and enrich, causal relationships and their corresponding entities from  clinical text.\\ Results: The multi-model transfer learning technique when applied over multiple iterations, gains performance improvements in terms of its accuracy and recall while keeping the precision constant. We also present a comparative analysis of the presented techniques with their common alternatives, which demonstrate the correctness of our approach and its ability to capture most causal relationships.\\ Conclusion: The presented framework has provided cutting-edge results in the healthcare domain. However, the framework can be tweaked to provide causality detection in other domains, as well. \\ Significance: The presented framework is generic enough to be utilized in any domain, healthcare services can gain massive benefits due to the voluminous and various nature of its data. This causal knowledge extraction framework can be used to summarize clinical text, create personas, discover medical knowledge, and provide evidence to clinical decision making."
"Content based websites Quora, Reddit, StackOverflow primarily used seeking genuine answers questions. People different domains put questions educators people knowledgeable certain field answer them. One major impediment plain sailing execution information exchange proliferation toxic comments. The key challenge weed toxic comments termed Insincere Questions. An Insincere Question designated comment intended make statement look genuine answers. An Insincere Question characterised by: This major class problem pertains Text classification benchmark problem evaluating various research advancements natural language processing. While traditional machine learning algorithms naive bayes, logistic regression decision trees rightfully applied problem, suffer major impediments constructs. Vanilla RNNs, Gated Recurrent Unit Long Short Term Memory Networks replaced usage new state art. Even though LSTMs GRUs performed well, failed capture dependencies long range sentences. Now advent Transfer Learning, Language model pre-training proven useful learning universal language representations. Researchers field developing new better language models unprecedented speed. Applying new state art models could improve current methods replace manual labeling tasks text classification, also find widespread application similar fields, machine translation question answering. In paper, test applying new transformer models BERT-family improve current method binary text classification context Insincere Questions Classification. We make use Quora Insincere Questions Classification dataset purpose We find models achieve remarkable results classifying given data , BERT achieving best results compared RoBERTa, DistilBERT, ALBERT. This indicates models well equipped take tasks researchers previously solved less optimal ways.","  The internet today has become an unrivalled source of information where people converse on content based websites such as Quora, Reddit, StackOverflow and Twitter asking doubts and sharing knowledge with the world. A major arising problem with such websites is the proliferation of toxic comments or instances of insincerity wherein the users instead of maintaining a sincere motive indulge in spreading toxic and divisive content. The straightforward course of action in confronting this situation is detecting such content beforehand and preventing it from subsisting online. In recent times Transfer Learning in Natural Language Processing has seen an unprecedented growth. Today with the existence of transformers and various state of the art innovations, a tremendous growth has been made in various NLP domains. The introduction of BERT has caused quite a stir in the NLP community. As mentioned, when published, BERT dominated performance benchmarks and thereby inspired many other authors to experiment with it and publish similar models. This led to the development of a whole BERT-family, each member being specialized on a different task. In this paper we solve the Insincere Questions Classification problem by fine tuning four cutting age models viz BERT, RoBERTa, DistilBERT and ALBERT"
"The term ``Readability'' measures much energy reader expend order understand writing optimal speed find interesting. Readability measuring formulas, Automated Readability Index , Flesch Reading Ease , Dale閳ユ弲hall formula calculate score estimates grade level years education reader based U.S. education system, illustrated Figure . These formulas still used many widely known commercial readability measuring tools Grammarly Readable. This measurement plays significant role many places, education, health care, government . Government organizations use ensure official texts meet minimum readability requirement. For instance, Department Insurance Texas requirement insurance policy documents Flesch Reading Ease score 40 higher, translates reading level first-year undergraduate student based U.S. education system. A legal document hard read lead someone sign contract without understanding agreeing to. Another common usage area healthcare sector ensure proper readability care treatment documents . Better readability attract visitors readers different websites blogs, whereas poor readability may decrease number readers . Readability measures also often used assess financial documents annual reports company閳ユ獨 economic performance information transparent reader . Dyslexia disorder causes difficulties skills associated learning, namely reading writing, affects 20\% general population. Readability formulas applied measure difficulty reading texts people dyslexia . The scores readability formulas generally found correlate highly actual readability text written English language. The adaptation readability formulas no-English texts straightforward. Measuring readability also essential every non-English language, readability formulas mentioned language-independent. These formulas require resources like 3000-word list, easily understandable fourth-grade American students, syllable counting dictionary, stemmer, lemmatizer etc. Resource availability Natural Language Processing research obstacle low-resource-languages . In paper, aim develop readability analysis tool Bengali Language. Bengali native language Bangladesh, also used India approximately 230 million native speakers. Despite spoken language world, Bengali suffers lack fundamental resources NLP. For low resource language like Bengali, research area far considered narrow sometimes incorrect. \citet{islam2012text, sinha2012new} tried adapt formula-based approaches used English language. Unfortunately, straightforward formulas developed U.S. based education system predicts U.S. grade level reader. Since Bangladeshi education system grade levels different U.S., therefore, mapping faulty led incorrect results. There strong relationship reading skills human cognition, varies depending different age groups . Therefore, eliminate incompatibility, paper, map grade level different age groups present age-to-age comparison. Moreover, used traditional machine learning models address task small scale dataset, publicly available. There readability analysis tools available English , Arabic , Italian , Japanese language. Unfortunately, tool available Bengali language validate readability text. On hand, large-scale human annotated readability analysis dataset available train supervised neural models extremely low-resource language. Our main contributions summarized follows:","  Determining the readability of a text is the first step to its simplification. In this paper, we present a readability analysis tool capable of analyzing text written in the Bengali language to provide in-depth information on its readability and complexity. Despite being the $7^{th}$ most spoken language in the world with 230 million native speakers, Bengali suffers from a lack of fundamental resources for natural language processing. Readability related research of the Bengali language so far can be considered to be narrow and sometimes faulty due to the lack of resources.  Therefore, we correctly adopt document-level readability formulas traditionally used for U.S. based education system to the Bengali language with a proper age-to-age comparison. Due to the unavailability of large-scale human-annotated corpora, we further divide the document-level task into sentence-level and experiment with neural architectures, which will serve as a baseline for the future works of Bengali readability prediction. During the process, we present several human-annotated corpora and dictionaries such as a document-level dataset comprising 618 documents with 12 different grade levels,  a large-scale sentence-level dataset comprising more than 96K sentences with simple and complex labels, a consonant conjunct count algorithm and a corpus of 341 words to validate the effectiveness of the algorithm, a list of 3,396 easy words, and an updated pronunciation dictionary with more than 67K words. These resources can be useful for several other tasks of this low-resource language. \footnote{We make our Code \& Dataset publicly available at \url{https://github.com/tafseer-nayeem/BengaliReadability} for reproduciblity.}"
"A typical text retrieval system uses multi-stage retrieval pipeline, documents flow series ``funnels`` discard unpromising candidates using increasingly complex accurate ranking components. These systems traditionally relying simple term-matching techniques generate initial list candidates . In that, retrieval performance adversely affected mismatch query document terms, known vocabulary gap problem. The vocabulary gap mitigated learning dense sparse representations effective first-stage retrieval. Despite recent success achieving objective , existing studies least one following flaws: This motivated us develop carefully-tuned traditional, i.e., non-neural, system, evaluated \href{https://microsoft.github.io/MSMARCO-Document-Ranking-Submissions/leaderboard/}{the MS MARCO document ranking task} . Our objectives are: Our submission achieved MRR=0.298 hidden validation set outperformed traditional systems. It first system outstripped several neural baselines. According evaluation TREC NIST data , system achieves NDCG@10 equal 0.584 0.558 2019 2020 queries, respectively. It, thus, outperforms tuned BM25 system 6-7\%: NDCG@10 equal 0.544 0.524 2019 2020 queries, respectively. \href{https://github.com/oaqa/FlexNeuART/blob/repr2020-12-06/scripts/data_convert/msmarco/README.md}{We posted two notebooks reproduce results}:"," This short document describes a traditional IR  system that achieved MRR@100 equal to 0.298 on the MS MARCO Document Ranking leaderboard . Although inferior to most BERT-based models,  it outperformed several neural runs ,  including two submissions that used a large pretrained Transformer model for re-ranking. We provide software and data to reproduce our results."
"Figurative language, figure speech , phrasing goes beyond literal meaning words get message point across. Writers poets use figurative language build imagery elicit aesthetic experiences. %A handful figurative types help make foreign concepts familiar graspable, including limited simile , metaphor , irony, etc. %. In computational linguistics, figurative language processing long interesting research topic, including detection generation tasks . } \\ \hline \multicolumn{1}{|c|}{After} & \multicolumn{2}{l|}{} \\ \hline \rowcolor[HTML]{ECF4FF} \multicolumn{3}{|c|}{\cellcolor[HTML]{ECF4FF}Other Figurative Language Generation} \\ \hline \rowcolor[HTML]{ECF4FF} Task & Status & \multicolumn{1}{c|}{\cellcolor[HTML]{ECF4FF}Text} \\ \hline & Before & A metaphorical pair \\ \cline{2-3} \multirow{-2}{*}{Metaphor} & After & She devoured novels. \\ \hline & & \\ \cline{2-3} \multirow{-2}{*}{} & Ironic & \\ \hline \end{tabular} } \end{table} There exist handful figurative types help make concepts become vivid graspable, including limited simile , metaphor , irony, etc. %. Among them, similes play vital role human writings attractive. Different metaphors' using implicit comparisons, simile description uses ``like'' ``as'' make clear comparison two separate concepts. As shown Table , human writers add coherent similes proper locations original text vivify plain writings. Such interpolation-based text polishing process especially unique similes, since polishing objectives clearly requires text rephrasing, e.g., grammar error correction fluency polishment, text editing irony style transfer, etc. Distinctly, interpolating similes like putting proper ingredients unflavored dish, instead totally re-cooking new one based different recipe. Despite importance simile, work explored simile recognition. To best knowledge\footnote{We encourage readers also refer contemporary work , shares different point view simile generation.}, none existing work ever investigated simile generation given plain text, indispensable amplifying writing similes. % works explored simile generation field FLP polishing text simile interpolation. % interpolation text polishment. Although sequence-to-sequence models work well story generation , irony generation , metaphor personification generation , non-trivial models generate proper creative simile given text. In particular, writing polishment similes unique task requires together address challenges listed below:%that together make writing polishment similes unique task. %Apparently, one biggest challenge text polishing studies data insufficiency. Either lack labelled data continuous figurative language generation, metaphor personification , lack parallel data style transfer text attributes sentiment, formality , offensivity , political slant irony etc. Apart expensive human annotation, previous works either adopted semi-supervised methods construct new datasets, applied complex unsupervised approaches deal issue. In contrast, obtaining simile data relatively cheap, since identified clear patterns occurrence connecting words ``like''. Even better, rich dozen simile patterns Chinese , facilitates automatic construction simile data. %In field figurative language processing however, detection tasks thoroughly explored , studies actually focused generation task , almost existing works limited lack annotated parallel data great deal. %Despite simple form, simile plays vital role written narratives attractive. A creative coherent simile occurs proper position narration greatly improve reading experience . However, existing work metaphor generation mostly non-contextual focus continuous generation. developed web-driven approach simile generation within single sentence. focused generating unconditional verb-oriented metaphors, requires pair fit word target word input. Although studied contextual metaphorical generation poetry, generation still continuous manner, always generates next lines given previous lines. Hence, none works shed lights polishing plain narrations simile generation positioning. %Beyond that, current researches text editing style transfer mostly focused single sentence rephrasing towards various text attributes sentiment, formality , offensivity , political slant irony etc. . Most existing approaches could directly applied case narration simile polishment, since objective rephrase given sentences whole. Rather, proposed task generate similes proper locations without changing anything original writing. %Meanwhile, great progress neural generation approaches recent years due rapid growth model architectures well available corpus , resulting various creative applications, chatbots , livebot commenting , streamlined video captioning , etc. Unfortunately, field figurative language processing, despite well-studied detection tasks , lack labelled parallel data limits research generation tasks great deal . To end, propose new task Writing Polishment Simile 閳ユ敄o firstly decide put simile within plain input text, figure content generate coherent simile. To facilitate research, propose new Chinese Simile dataset, contains roughly 5.5 million similes fictional contexts. %from Chinese online fictions 92\% simile extraction precision. %For model design, We also set benchmark model Locate\&Gen validate feasibility potentials WPS task. Locate\&Gen model two-stage biased generation model upon framework transformer encoder-decoder . At first step, locates pointer position simile interpolation, generates location-specific simile using novel insertion bias. The two-stage design allows automatic semi-automatic inference modes assist writing polishment flexibly. To summarize, contributions three-folded: %Hence, contrast romance open machine story/metaphor generation discussed above, SP aims practically improving narrative writings hands human writers. It also poses several new challenges AI follows: 1) There existing large-scale figurative language corpus, annotation fairly difficult since annotators need familiar writing techniques. 2) Besides generating coherent simile must faithful original context, model also learn put generated ingredients proper position. In work, address SP problem propose two-staged Locate\&Gen model. In order obtain large-scale simile dataset, adopt Chinese simile patterns\footnote[1]{Different English, dozens patterns simile expressions Chinese like ""婵傝棄鍎"", ""閹鎶"", ""娴犲じ缍"", ""鐎规稑顩"", ""娣囥劎鍔"", ""婵″倽瀚"", ""閻樼懓顩"", etc., standing meaning ""as if"". Also note similes metaphors exchanged easily exchanging simile patterns verbs ""Be"" ""Become"".} automatically extract sentences containing similes."," A simile is a figure of speech that directly makes a comparison, showing similarities between two different things, e.g. ``Reading papers can be dull sometimes, like watching grass grow"". Human writers often interpolate appropriate similes into proper locations of the plain text to vivify their writings. However, none of existing work has explored neural simile interpolation, including both locating and generation. In this paper, we propose a new task of Writing Polishment with Simile  to investigate whether machines are able to polish texts with similes as we human do. Accordingly, we design a two-staged Locate\&Gen model based on transformer architecture. Our model firstly locates where the simile interpolation should happen, and then generates a location-specific simile. We also release a large-scale Chinese Simile  dataset containing 5 million similes with context. The experimental results demonstrate the feasibility of WPS task and shed light on the future research directions towards better automatic text polishment.%with model achieving 76.9\% simile positioning accuracy and decent performance on generation metrics as well as human evaluations.  %Current studies on figurative language generation are either non-contextual or focus only on continuous left-to-right generation manner, which is impractical for polishing written narratives with simile embellishments which may take place at any position of the original content. In this paper, we propose Simile Positioning \& Generation  task闁炽儲鏁刼 first decide a proper insertion position of simile then generate coherent simile content in plain narrations, to investigate whether computational methods are able to refine written narratives with similes as human novelists do. We introduce a large-scale Chinese Simile  dataset, which contains millions of similes with contexts extracted automatically from Chinese online fictions of various types. We establish baseline Insert\&Gen model performances based on SOTA transformer architecture. The experimental results demonstrate the feasibility of SPG task with model achieving 76.9\% accuracy on simile positioning and decent performance on generation metrics and human evaluations.  %Human author is capable of applying figurative language to bring their stories to life, so that readers ""devour"" his vivid narratives. Current researches mainly focused on the continuous story generation  as well as global text editing or style transfer, topics around machines learning to apply figurative techniques for writing is seldom discussed. In this paper, we propose a new task of Simile Positioning\&Generation , which aims to decorate plain narrative sentences with similes at appropriate positions, while being faithful to the original writings. We introduce a large-scale Chinese Simile  dataset, containing millions of contextual similes extracted automatically from Chinese online fictions of various types. We establish baseline Locate\&Gen model performances based on SOTA transformer architecture. The experimental results demonstrate the feasibility of SPG task with model achieving around 80\% accuracy on simile positioning and decent performance on generation metrics and human evaluations."
"A contract legally binding agreement recognizes governs rights duties parties agreement. Correctly composing contracts crucial ensure legal validity. In many real-world scenarios, standard contract prepared filling blanks precompiled form. Due carelessness, two blanks filled content may incorrectly filled different content. This result contract inconsistencies, may severely impair legal validity contract. Contract review widely used companies check contract inconsistencies. However, contract review labor-intensive costly. Big companies hire tens thousands lawyers conduct contract review, estimated Fortune Global Fortune companies spend 35281299,62194.05\%90.90\%$. Our contributions summarized follows: We formulate Contract Inconsistency Checking problem. As far know, problem yet studied AI community. We propose novel Pair-wise Blank Resolution framework address CIC problem. In PBR, propose extends Transformer encoder architecture efficiently model meaningless blanks. We collected labeled large-scale Chinese contract corpus CIC. The experimental results show promising performance PBR method."," Contract consistency is important in ensuring the legal validity of the contract. In many scenarios, a contract is written by filling the blanks in a precompiled form. Due to carelessness, two blanks that should be filled with the same  content may be incorrectly filled with different  content. This will result in the issue of contract inconsistencies, which may severely impair the legal validity of the contract. Traditional methods to address this issue mainly rely on manual contract review, which is labor-intensive and costly. In this work, we formulate a novel Contract Inconsistency Checking  problem, and design an end-to-end framework, called Pair-wise Blank   Resolution , to solve the CIC problem with high accuracy. Our PBR model contains a novel \texttt{BlankCoder} to address the challenge of modeling meaningless blanks. \texttt{BlankCoder} adopts a two-stage attention mechanism that adequately associates a meaningless blank with its relevant descriptions while avoiding the incorporation of irrelevant context words. Experiments conducted on real-world datasets show the promising performance of our method with a balanced accuracy of $94.05\%$ and an F1 score of $90.90\%$ in the CIC problem."
"Building human-like open-domain conversational agent one milestones artificial intelligence . Early conversational agents primarily based rules , e.g., Eliza , first CA developed 60's, simulates Rogerian psychotherapist based hand-crafted pattern matching rules. In recent years, advancement data-driven neural networks, neural open-domain conversational models becoming dominant . Recent efforts open-domain neural conversational models primarily aiming improve response diversity endowing responses knowledge , personality , emotion empathy . All efforts mentioned focusing models passively respond user messages. However, many real-world scenarios, e.g., conversational recommendation, psychotherapy education, conversational agents required actively lead conversation smoothly changing conversation topic designated one. For example, casual conversation, agent may actively lead user specific product service agent wants introduce recommend. In paper, follow line research study problem imposing conversational goals/keywords open-domain conversational agents, agent required lead conversation target keyword smoothly fast. As illustrated Figure , given target keyword ``juice"" random starting keyword ``comics"", agent required converse user multiple exchanges lead conversation ``juice"". The challenge problem lies balance tradeoff maximizing keyword transition smoothness minimizing number turns taken reach target. On one hand, passively responding user solely based conversation context would achieve high smoothness may take many turns reach target, hand, directly jumping target word ignoring conversation context would minimize number turns produce non-smooth keyword transitions. \citet{tang2019target} proposed break problem two sub-problems: next-turn keyword selection keyword-augmented response retrieval. \citet{tang2019target} proposed next-turn keyword predictor rule-based keyword selection strategy solve first sub-problem, allowing agent know next keyword talk given conversation history target keyword. In addition, \citet{tang2019target} proposed keyword-augmented response retrieval model solve second sub-problem, allowing agent produce response relevant selected keyword. However, two major limitations existing studies . First, training evaluation datasets next-turn keyword prediction directly extracted conversations without human annotations, thus, majority ground-truth keyword transitions noisy low correlations human judgements. As illustrated Figure , keyword transitions conversation considered relevant. In fact, human annotation studies 600 keyword transitions, found around 70\% keyword transitions next-turn keyword prediction datasets rated relevant, renders trained next-turn keyword predictor existing studies less reliable. Second, rule-based keyword selection strategy primarily leverages cosine similarity word embeddings select keywords closer target keyword. Word embeddings trained based distributional hypothesis words similar contexts similar meanings, may reflect humans relate words conversational turn-taking. In paper, assume human conversations grounded commonsense propose keyword-guided neural conversational model leverage external commonsense knowledge graphs next-turn keyword selection keyword-augmented response retrieval. Humans rely commonsense reason, commonsense reasoning plays important role cognitive process conversational turn-taking . Relying CKG keyword transition would allow agent select target-related keyword next-turn. Moreover, leverage commonsense triplets CKG using Graph Neural Networks next-turn keyword prediction keyword-augmented response retrieval achieve accurate predictions. In summary, contributions follows:"," We study the problem of imposing conversational goals/keywords on open-domain conversational agents, where the agent is required to lead the conversation to a target keyword smoothly and fast. Solving this problem enables the application of conversational agents in many real-world scenarios, e.g., recommendation and psychotherapy. The dominant paradigm for tackling this problem is to 1) train a next-turn keyword classifier, and 2) train a keyword-augmented response retrieval model. However, existing approaches in this paradigm have two limitations: 1) the training and evaluation datasets for next-turn keyword classification are directly extracted from conversations without human annotations, thus, they are noisy and have low correlation with human judgements, and 2) during keyword transition, the agents solely rely on the similarities between word embeddings to move closer to the target keyword, which may not reflect how humans converse. In this paper, we assume that human conversations are grounded on commonsense and propose a keyword-guided neural conversational model that can leverage external commonsense knowledge graphs  for both keyword transition and response retrieval. Automatic evaluations suggest that commonsense improves the performance of both next-turn keyword prediction and keyword-augmented response retrieval. In addition, both self-play and human evaluations show that our model produces responses with smoother keyword transition and reaches the target keyword faster than competitive baselines."
"Despite remarkable progress made NMT recently , NMT systems still prone translation errors caused noisy input sequences. One common type input noise homophone noise, words characters mis-recognized others similar pronunciation ASR input systems non-phonetic languages , illustrated example Table. Previous works suggest incorporating phonetic embeddings NMT augmenting training data adversarial examples injected homophone noise would alleviate issue. Intuitively, humans usually trouble disambiguating sentences corrupted moderate homophone noise via context syllable information. We propose human-inspired robust NMT framework tailored homophone noise Chinese-English translation, composed homophone noise detector syllable-aware NMT model. \\ Output NMT~&~build primary school \\ \specialrule{0.05em}{3pt}{3pt} Noisy Input~&~ \\ Output NMT~&~suggest primary school \\ \specialrule{0.05em}{3pt}{3pt} Mixed Transcript~&~ \\ Output Ours~&~build primary school\\ \bottomrule[1pt] \end{tabular} Due lack data annotated homophone noise, propose train detector monolingual data self-supervised manner, Chinese characters sequences input corresponding syllables sequence label predict possibility character homophone noise. The identified homophone errors source sentence converted corresponding syllables produce new source sequence mixed characters syllables. Augmenting bilingual training data instances original source sentences substituted corresponding character-syllable-mixed sequences, train SANMT model translate unconventional inputs. To examine effectiveness proposed model, conduct extensive experiments artificial noisy test sets real-world noise test set homophone noise speech translation scenario. The test set released soon. Our experimental results ChineseEnglish translation clearly show proposed method significantly superior previous approaches alleviating impact homophone noise NMT, also achieves substantial improvement clean text. %Due lack data annotated homophone noise, propose train detector monolingual data self-supervised manner, Chinese characters automatically transformed syllables predict homophone noise. The identified homophone errors source sentence converted corresponding syllables produce new source sequence mixed characters syllables. Augmenting training data instances original source sentences substituted corresponding character-syllable-mixed sequences, train SANMT model translate unconventional inputs. To examine effectiveness proposed model, conduct extensive experiments artificial noisy test sets real-world noise test set homophone noise speech translation scenario. The test set released soon. Our experimental results ChineseEnglish translation clearly show proposed method significantly superior previous approaches alleviating impact homophone noise NMT, also achieves substantial improvement clean text."," In this paper, we propose a robust neural machine translation  framework. The framework consists of a homophone noise detector and a syllable-aware NMT model to homophone errors. The detector identifies potential homophone errors in a textual sentence and converts them into syllables to form a mixed sequence that is then fed into the syllable-aware NMT. Extensive experiments on Chinese$\rightarrow$English translation demonstrate that our proposed method not only significantly outperforms baselines on noisy test sets with homophone noise, but also achieves a substantial improvement on clean text."
"In recent years, dramatic surge adoption voice assistants Amazon Alexa, Apple Siri, Google Assistant. Customers use variety tasks playing music online shopping. These voice assistants built complex Spoken Language Understanding systems typically large store edge device mobile phone smart speaker. Hence, user traffic routed cloud server process requests. This led privacy concerns fueled push tiny AI edge processing, user requests processed device itself. Traditional SLU systems consist two-stage pipeline, Automatic Speech Recognition component processes customer speech generates text transcription , followed Natural Language Understanding component maps transcription actionable hypothesis consisting intents slots . An end-to-end system goes directly speech hypothesis would help make SLU system smaller faster, allowing stored edge device. It could potentially also better optimized pipeline since eliminates cascading errors. However, E2E systems used practice key issues. These systems hard build since consist large neural components transformers require massive amounts E2E training data. They also make use vastly available training data ASR NLU components could used enhance performance, examples datasets may aligned create E2E training sample. Another issue feature expansion, scenario new domain, new intents slots, added voice assistant's capabilities. Here, developers typically access synthetically generated text-hypothesis examples. Speech data readily available expensive collect. E2E models thus fail require lots new audio hypothesis data learn new domain. In work, build E2E model mitigates issues using transfer learning. We call Audio-Text All-Task Model. AT-AT E2E transformer-based model jointly trained multiple audio-to-text text-to-text tasks. Examples tasks include speech recognition , hypothesis prediction speech , masked LM prediction , hypothesis prediction text . Our model achieves converting data tasks single audio-to-text text-to-text format. Figure shows joint training phase detail. Our findings indicate significant knowledge transfer taking place multiple tasks, turn helps downstream model performance. We see AT-AT pretrained model shows improved performance SLU hypothesis prediction internal data collected Alexa traffic. We also report state-of-the-art results two public datasets: FluentSpeech , SNIPS Audio . Furthermore, since model contains text encoder, consume audio text inputs generate target sequence. By jointly training audio-to-text text-to-text tasks, hypothesize model learns shared representation audio text inputs. This allows us simply train new text-to-text data get audio-to-text performance free, giving us way E2E hypothesis prediction zero-shot fashion feature expansion. We test approach internal dataset Alexa traffic, external dataset, Facebook TOP . Since TOP consists text data, collected speech data test split using internal tool Amazon. We soon release dataset. In summary, contributions follows."," Voice Assistants such as Alexa, Siri, and Google Assistant typically use a two-stage Spoken Language Understanding pipeline; first, an Automatic Speech Recognition  component to process customer speech and generate text transcriptions, followed by a Natural Language Understanding  component to map transcriptions to an actionable hypothesis. An end-to-end  system that goes directly from speech to a hypothesis is a more attractive option. These systems were shown to be smaller, faster, and better optimized. However, they require massive amounts of end-to-end training data and in addition, don't take advantage of the already available ASR and NLU training data.  In this work, we propose an E2E system that is designed to jointly train on multiple speech-to-text tasks, such as ASR  and SLU , and text-to-text tasks, such as NLU . We call this the Audio-Text All-Task  Model and we show that it beats the performance of E2E models trained on individual tasks, especially ones trained on limited data. We show this result on an internal music dataset and two public datasets, FluentSpeech and SNIPS Audio, where we achieve state-of-the-art results. Since our model can process both speech and text input sequences and learn to predict a target sequence, it also allows us to do zero-shot E2E SLU by training on only text-hypothesis data  from a new domain. We evaluate this ability of our model on the Facebook TOP dataset and set a new benchmark for zeroshot E2E performance. We will soon release the audio data collected for the TOP dataset for future research."
"Neural Machine Translation achieved state art various MT systems, including rich low resource language pairs . However, quality low-resource MT quite unpretentious due lack parallel data achieved better results systems available resource. Therefore, low-resource MT one essential tasks investigated many previous works . Recently, works present MT systems achieved remarkable results low-resource language . Inspired works, collect data TED Talks domain, attempt build multilingual MT systems French, English-Vietnamese. Experiments demonstrate language pairs: French-Vietnamese English-Vietnamese achieved significant performance joining training. % Although multilingual MT reduce sparse data shared space using word segmentation, however, rare words still exist, evenly increased languages significant disparity term vocabulary. Previous works suggested strategies reduce rare words using translation units sub-word character levels generating universal representation word sentence levels . These help downgrade dissimilarity tokens shared various languages. However, works require learning additional parameters training, thus increasing size models. Our paper presents two methods augment translation rare words source space without modifying architecture model size MT systems: exploiting word similarity. This technique mentioned previous works . They employ monolingual data require supervised resources like bilingual dictionary WordNet, leverage relation multilingual space MT systems. Adding scalar value rare word embedding order facilitate translation training process. % Due fact NMT tends bias translating frequent words, rare words often less opportunity considered. Our ideal inspired works . proposed various solutions urge translation rare words, including modification embedding training. They experimented recurrent neural networks work uses state-of-the-art transformer architecture. transforms word embedding token universal space, learn plus parameters method not. We apply strategies fine-tuning processes, show substantial improvements systems epochs only. Monolingual data widely used NMT augment data low-resource NMT systems . Back-translation known popular technique exploiting target-side monolingual data enhance translation systems self-learning method focuses utilizing source-side monolingual data. Otherwise, dual-learning strategy also suggests using source- target-side monolingual data tackle problem. Our work investigates self-learning method low-resource multilingual NMT systems specifically related Vietnamese. Besides, monolingual data also leveraged unsupervised zero-shot translation. % learn lexical relative one token source language another source language without modifying system architecture well model size. We also use additional resources systems. The main contributions work are: In section 2, review transformer architecture used experiments. The brief multilingual translation shown section 3. Section 4 presents methods deal rare words multilingual translation scenarios. The exploitation monolingual data low-resource multilingual MT discussed section 5. Our results described section 6, related work shown section 7. Finally, paper ends conclusions future work. %"," % Prior works have demonstrated that a low-resource language pair can be benefited from a multilingual machine translation  system which relies on the jointly training many language pairs. In this paper, we propose two simple strategies to address the rare word issue in multilingual MT systems for two low-resource language pairs: French-Vietnamese,  English-Vietnamese. The first strategy learns  dynamically word similarity of tokens in the shared space among source languages whilst the other one augments the translation ability of rare words through updating their embeddings during the training. In addition, we attempt to leverage monolingual data which is generated from multilingual MT to reinforce synthetic parallel in the data sparsity situation. We show that significant improvements of up to +1.62 and +2.54 BLEU points over the bilingual baseline systems for both language pairs and release datasets for the research community.  Prior works have demonstrated that a low-resource language pair can benefit from multilingual machine translation  systems, which rely on many language pairs' joint training. This paper proposes two simple strategies to address the rare word issue in multilingual MT systems for two low-resource language pairs: French-Vietnamese and English-Vietnamese. The first strategy is about dynamical learning word similarity of tokens in the shared space among source languages while another one attempts to augment the translation ability of rare words through updating their embeddings during the training. Besides, we leverage monolingual data for multilingual MT systems to increase the amount of synthetic parallel corpora while dealing with the data sparsity problem. We have shown significant improvements of up to +1.62 and +2.54 BLEU points over the bilingual baseline systems for both language pairs and released our datasets for the research community."
"% Fabian: Describing Entity linking task mapping entity mentions text documents standard entities given knowledge base. For example, word ``Paris'' ambiguous: It refer either capital France hero Greek mythology. Now given text ``Paris son King Priam'', goal determine that, sentence, word refers Greek hero, link word corresponding entity knowledge base YAGO DBpedia . %Intriguingly, Greek hero also goes name ``Alexander''. Thus, words ``Paris'' ``Alexander'' synonymous, refer Greek hero input text, linked entity knowledge base. % Fabian: Describing important In biomedical domain, entity linking maps mentions diseases, drugs, measures normalized entities standard vocabularies. It important ingredient automation medical practice, research, public health. Different names entities Hospital Information Systems seriously hinder integration use medical data. If medication appears different names, researchers cannot study impact, patients may erroneously prescribed medication twice. % Fabian: Describing difficult The particular challenge biomedical entity linking ambiguity: word usually refers single entity. Rather, challenge surface forms vary markedly, due abbreviations, morphological variations, synonymous words, different word orderings. For example, ``Diabetes Mellitus, Type 2'' also written ``DM2'' ``lung cancer'' also known ``lung neoplasm malignant''. In fact, surface forms vary much possible expressions entity cannot known upfront. This means standard disambiguation systems cannot applied scenario, assume forms entity known. %, thus cannot applied scenario. One may think variation surface forms big problem, long variations entity sufficiently close canonical form. Yet, case. For example, phrase ""decreases hemoglobin"" could refer least 4 different entities MedDRA, look alike: ""changes hemoglobin"", ""increase hematocrit"", ""haemoglobin decreased"", ""decreases platelets"". In addition, biomedical entity linking cannot rely external resources alias tables, entity descriptions, entity co-occurrence, often used classical entity linking settings. % Fabian: done For reason, entity linking approaches developed particularly biomedical entity linking. Many methods use deep learning: work \citet{li2017cnn} casts biomedical entity linking ranking problem, leveraging convolutional neural networks . More recently, introduction BERT advanced performance many NLP tasks, including biomedical domain . BERT creates rich pre-trained representations unlabeled data achieves state-of-the-art performance large suite sentence-level token-level tasks, outperforming many task-specific architectures. However, considering number parameters pre-trained BERT models, improvements brought fine-tuning come heavy computational cost memory footprint. This problem energy efficiency, smaller organizations, poorer countries. In paper, introduce lightweight model achieves performance statistically indistinguishable state-of-the-art BERT-based models. The central idea use alignment layer attention mechanism, capture similarity difference corresponding parts candidate mention names. Our model 23x smaller 6.4x faster BERT-based models average; twice smaller faster lightweight BERT models. Yet, show, model achieves comparable performance standard benchmarks. Further, show adding complexity model necessary: entity-mention priors, context around mention, coherence extracted entities \cite[as used, e.g., in][]{hoffart2011robust} improve results further. \footnote{All data code available \url{https://github.com/tigerchen52/Biomedical-Entity-Linking}.}"," Biomedical entity linking aims to map biomedical mentions, such as diseases and drugs, to standard entities in a given knowledge base.  The specific challenge in this context is that the same biomedical entity can have a wide range of names,  including synonyms, morphological variations, and names with different word orderings.  Recently, BERT-based methods have advanced the state-of-the-art by allowing for rich representations of word sequences. However, they often have hundreds of millions of parameters and require heavy computing resources, which limits their applications in resource-limited scenarios. Here, we propose a lightweight neural method for biomedical entity linking, which needs just a fraction of the parameters of a BERT model and much less computing resources.  Our method uses a simple alignment layer with attention mechanisms to capture the variations between mention and entity names. Yet, we show that our model is competitive with previous work on standard evaluation benchmarks."
"Although deep neural networks recently contributing state-of-the-art advances various areas , %in NLP problems , black-box models may deemed reliable situations safety needs guaranteed, legal judgment prediction medical diagnosis. Interpretable deep neural networks promising way increase reliability neural models. To end, extractive rationales, i.e., subsets features instances models rely predictions instances, used evidence humans decide whether trust predicted result and, generally, trust a~model. Previous works mainly use selector-predictor types neural models provide extractive rationales, i.e., models composed two modules: selector selects subset important features, predictor makes prediction based solely selected features. For example, use selector network calculate selection probability token sequence, sample set tokens exclusively passed predictor. %The supervision solely answer given prediction. %One calculates loss result given predictor ground-truth answer. An additional typical desideratum natural language pro\-cessing tasks selected tokens form semantically fluent rationale. To achieve this, added non-differential regularizer encourages two adjacent tokens simultaneously selected unselected. %The selector predictor jointly trained REINFORCE-style manner [cite Williams 92] sampling process regularizer differentiable. improved quality rationales using Hard Kuma regularizer also encourages two adjacent tokens selected unselected together. %, differentiable. One drawback previous works learning signal selector predictor comes mainly comparing prediction selector-predictor model ground-truth answer. %, predictor tells selector extent selected features contribute prediction, directly tell selector kind features still missing over-selected correct prediction. Therefore, exploration space get correct rationale large, decreasing chances converging optimal rationales predictions. Moreover, NLP applications, regularizers commonly used achieving fluency rationales treat adjacent token pairs way. This often leads selection unnecessary tokens due adjacency informative~ones. %Intuitively, two tokens frequently occur adjacently, likely simultaneously selected unselected. These important adjacent token pairs receive priority regularizer. In work, first propose alternative method rationalize predictions neural model. Our method aims squeeze information predictor order guide selector selecting rationales. Our method trains two models: ``guider"" model solves task hand accurate black-box manner, selector-predictor model solves task also providing rationales. We use adversarial-based method encourage final information vectors generated two models encode information. We use information bottleneck technique two places: ~to encourage features selected selector least-but-enough features, ~to encourage final information vector guider model also contain least-but-enough information prediction. Secondly, propose using language models regularizers rationales natural language understanding tasks. A language model regularizer encourages rationales fluent subphrases, means rationales formed consecutive tokens avoiding unnecessary tokens selected simply due adjacency informative tokens. %novel regularizer consecutiveness semantic fluency rationale NLP applications. This regularizer based language model , gives priority important adjacent tokens simultaneously selected. The effectiveness LM-based regularizer proved mathematical derivation experiments. All details given Appendix extended paper. Our contributions briefly summarized follows:"," \begin{quote} Explaining the predictions of AI models is paramount in safety-critical applications, such as in legal or medical domains. One form of explanation for a prediction is an extractive rationale, i.e., a subset of features of an instance that lead the model to give its prediction on the instance.  Previous works on generating extractive rationales usually employ a two-phase model: a selector that selects the most important features  followed by a predictor that makes the prediction based exclusively on the selected features. One disadvantage of these works is that the main signal for learning to select features comes from the comparison of the answers given by the predictor and the ground-truth answers. In this work, we propose to squeeze more information from the predictor via an information calibration method. More precisely, we train two models jointly: one is a typical neural model that solves the task at hand in an accurate but black-box manner, and the other is a selector-predictor model that additionally produces a rationale for its prediction. The first model is used as a guide to the second model. We use an adversarial-based technique to calibrate the information extracted by the two models such that the difference between them is an indicator of the missed or over-selected features. In addition, for natural language tasks, we propose to use a language-model-based regularizer to encourage the extraction of fluent rationales. Experimental results on a sentiment analysis task as well as on three tasks from the legal domain show the effectiveness of our approach to rationale extraction.  \end{quote}"
"% background Sentence semantic matching fundamental Natural Language Processing~ task tries infer suitable label given sentence pair. For example, Natural Language Inference~ targets classifying input sentence pair one three relations~. Paraphrase Identification~ aims identifying whether input sentence pair expresses meaning. Figure gives examples different semantic relations different datasets. % Current state As fundamental technology, sentence semantic matching applied successfully many NLP fields, e.g., information retrieval, question answering, dialog system. Currently, work leverages advancement representation learning techniques tackle task. They focus input sentences design different architectures explore sentence semantics comprehensively precisely. Among methods, BERT plays important role. It adopts multi-layer transformers make full use large corpus~ powerful pre-trained model. Meanwhile, two self-supervised learning tasks~ designed better analyze sentence semantics capture much information possible. % citation Based BERT, plenty work made big step sentence semantic modeling. In fact, since relations predicting targets sentence semantic matching task, methods pay enough attention relation learning. They leverage annotated labels represent relations, formulated one-hot vectors. However, independent meaningless one-hot vectors cannot reveal rich semantic information guidance relations, cause information loss. \citeauthor{gururangan2018annotation}~ observed different relations among sentence pairs imply specific semantic expressions. Taking Figure example, sentence pairs ``contradiction'' relation contain negation words~. ``entailment'' relation often leads exact numbers replaced approximates~. ``Neutral'' relation import correct irrelevant information~. Moreover, expressions sentence pairs different relations different. Therefore, comparison contrastive learning among different relations~ help models learn semantic information implied relations, turn helps strengthen sentence analysis ability models. They treated meaningless one-hot vectors. One solutions better relation utilization embedding method inspired Word2Vec. Some researchers try jointly encode input sentences labels embedding space better relation utilization sentence semantic modeling. Despite progress achieved, label embedding method requires data parameters achieve better utilization relation information. It still cannot fully explore potential relations due small number relation categories lack explicit label embedding initialization. To end, paper, propose novel \fullname~approach make full use relation information simple effective way. In concrete details, first utilize pre-trained BERT model semantic meanings input words sentences global perspective. Then, develop CNN-based encoder obtain partial information~ sentences local perspective. Next, inspired self-supervised learning methods BERT training processing, propose Relation Relation~ classification task enhance learning ability \shortname~for implicit common features corresponding different relations. Moreover, triplet loss used constrain model, intra-class inter-class relations analyzed better. Along line, input sentence pairs relations represented much closer vice versa apart. Relation information properly integrated sentence pair modeling processing, favor tackling challenges improving model performance. Extensive evaluations two sentence semantic matching tasks demonstrate effectiveness proposed \shortname~and advantages state-of-the-art sentence semantic matching baselines."," 	% background 	Sentence semantic matching is one of the fundamental tasks in natural language processing, which requires an agent to determine the semantic relation among input sentences.  	% current state 	Recently, deep neural networks have achieved impressive performance in this area, especially BERT.  	% problem 	Despite their effectiveness, most of these models treat output labels as meaningless one-hot vectors, underestimating the semantic information and guidance of relations that these labels reveal, especially for tasks with a small number of labels.  	% solution 	To address this problem, we propose a \fullname~for sentence semantic matching. 	 	Specifically, we first employ BERT to encode the input sentences from a global perspective. 	Then a CNN-based encoder is designed to capture keywords and phrase information from a local perspective.  	To fully leverage labels for better relation information extraction, we introduce a self-supervised relation of relation classification task for guiding \shortname~to consider more about relations.  	Meanwhile, a triplet loss is employed to distinguish the intra-class and inter-class relations in a finer granularity. 	% result 	Empirical experiments on two sentence semantic matching tasks demonstrate the superiority of our proposed model.  	As a byproduct, we have released the codes to facilitate other researches."
"Discovering novel user intents important improve service quality dialogue systems. By analyzing discovered new intents, may find underlying user interests, could provide business opportunities guide improvement direction. Intent discovery attracted much attention recent years. Many researchers regard unsupervised clustering problem, manage incorporate weak supervised signals guide clustering process. For example,~\citet{hakkani-tr2013a} propose hierarchical semantic clustering model collect web page clicked information implicit supervision intent discovery.~\citet{hakkani2015clustering} utilize semantic parsing graph extra knowledge mine novel intents clustering.~\citet{Padmasundari2018} benefit consensus predictions multiple clustering techniques discover similar semantic intent-wise clusters.~\citet{haponchyk2018supervised} cluster questions user intent categories supervision structured outputs.~\citet{shi2018auto} extract intent features autoencoder automatically label intents hierarchical clustering method. However, methods fail leverage prior knowledge known intents. These methods assume unlabeled samples composed undiscovered new intents. A common case labeled data known intents accessible unlabeled data mixed known new intents. As illustrated Figure, may labeled samples known intents advance. The remaining known new intent samples unlabeled. Our goal find known intents discover new intents prior knowledge limited labeled data. Our previous work CDAC+ directly tackles problem. Nevertheless, uses pairwise similarities weak supervised signals, ambiguous distinguish mixture unlabeled known new intents. Thus, performance drops new intents. To summarize, two main difficulties task. On one hand, challenging effectively transfer prior knowledge known intents new intents limited labeled data. On hand, hard construct high-quality supervised signals learn friendly representations clustering unlabeled known new intents. To solve problems, propose effective method leverage limited prior knowledge known intents provide high-quality supervised signals feature learning. As illustrated Figure, firstly use pre-trained BERT model extract deep intent features. Then, pre-train model limited labeled data supervision softmax loss. We retain pre-trained parameters use learning information obtain well-initialized intent representations. Next, perform clustering extracted intent features estimate cluster number eliminating low-confidence clusters. As training samples unlabeled, propose original alignment strategy construct high-quality pseudo-labels supervised signals learning discriminative intent features. For training epoch, firstly perform k-means extracted intent features, use produced cluster assignments pseudo-labels training neural network. However, inconsistent assigned labels cannot directly used supervised signals, use cluster centroids targets obtain alignment mapping pseudo-labels consequent epochs. Finally, perform k-means inference. Benefit relatively consistent aligned targets, method inherit history learning information boost clustering performance. We summarize contributions follows. Firstly, propose simple effective method successfully generalizes mass new intents estimate number novel classes limited prior knowledge known intents. Secondly, propose effective alignment strategy obtain high-quality self-supervised signals learning discriminative features distinguish known new intents. Finally, extensive experiments two benchmark datasets show approach yields better robust results state-of-the-art methods."," 		Discovering new intents is a crucial task in dialogue systems. Most existing methods are limited in transferring the prior knowledge from known intents to new intents. They also have difficulties in providing high-quality supervised signals to learn clustering-friendly features for grouping unlabeled intents. In this work, we propose an effective method, Deep Aligned Clustering, to discover new intents with the aid of the limited known intent data. Firstly, we leverage a few labeled known intent samples as prior knowledge to pre-train the model. Then, we perform k-means to produce cluster assignments as pseudo-labels. Moreover, we propose an alignment strategy to tackle the label inconsistency problem during clustering assignments. Finally, we learn the intent representations under the supervision of the aligned pseudo-labels. With an unknown number of new intents, we predict the number of intent categories by eliminating low-confidence intent-wise clusters. Extensive experiments on two benchmark datasets show that our method is more robust and achieves substantial improvements over the state-of-the-art methods. The codes are released at \url{https://github.com/thuiar/DeepAligned-Clustering}."
"The U.S.~NIH's precision medicine initiative calls designing treatment preventative interventions considering genetic, clinical, social, behavioral, environmental exposure variability among patients. The initiative rests widely understood finding considering individual variability critical tailoring healthcare interventions achieve substantial progress reducing disease burden worldwide. Cancer chosen near term focus eventual aim expanding conditions. As biomedical research enterprise strives fulfill initiative's goals, computing needs also rise drug discovery, predictive modeling disease onset progression, building NLP tools curate information evidence base generated. \subsection{TREC Precision Medicine Series} \end{table} In dovetailing move, U.S.~NIST's TREC running PM track since 2017 focus cancer. The goal TREC-PM task identify relevant biomedical articles clinical trials input patient case. Each case composed disease name, gene name genetic variation type, demographic information . Table shows two example cases 2019 track. So search ad hoc sense free text input facet facets highlight PM related attributes ought characterize retrieved documents. We believe style faceted retrieval going common across medical IR tasks many conditions PM initiative continues mission. \subsection{Vocabulary Mismatch Neural IR} The vocabulary mismatch problem prominent issue medical IR given large variation expression medical concepts events. For example, query ``What potential side effect Tymlos?'' drug referred brand name. Relevant scientific literature may contain generic name Abaloparatide frequently. Traditional document search engines clear limitations resolving mismatch issues. The IR community extensively explored methods address vocabulary mismatch problem, including query expansion based relevance feedback, query term re-weighting, query reconstruction optimizing query syntax. Several recent studies highlight exploiting neural network models query refinement document retrieval settings. \citet{nogueira2017task} address issue generating transformed query initial query using neural model. They use reinforcement learning train agent learns reformulate initial query maximize expected return actions . In different approach, \citet{narayan2018ranking} use RL sentence ranking extractive summarization. \subsection{Our Contributions} In paper, building BERT architecture, focus different hybrid document scoring reranking setup involving three components: .~a document relevance classification model, predicts whether document relevant given query ; .~a keyword extraction model spots tokens document likely seen PM related queries; .~an abstractive document summarization model generates pseudo-query given document context facet type via BERT encoder-decoder setup. The keywords ) pseudo-query ) together compared original query generate score. The scores components combined rerank top documents returned basic Okapi BM25 retriever Solr index corpora. %This critical neural document-query matching summarization expensive operations cannot practically scale full corpus. Our main innovation pivoting focus queries previous methods emphasis transforming candidate documents pseudo-queries via summarization. Additionally, generating pseudo-query, also let decoder output concept codes biomedical terminologies capture disease gene names. We embedding words concepts common semantic space letting decoder generate summaries include concepts. Our overall architecture evaluated using TREC-PM datasets 2019 dataset used test set. The results show absolute improvement P@10 compared prior best approaches obtaining small gain R-Prec. Qualitative analyses also highlight summarization able focus document segments highly relevant patient cases."," Information retrieval  for precision medicine  often involves looking for multiple pieces of evidence that characterize a patient case. This typically includes at least the name of a condition and a genetic variation that applies to the patient. Other factors such as demographic attributes, comorbidities, and social determinants may also be pertinent. As such, the retrieval problem is often formulated as ad hoc search but with multiple facets  that may need to be incorporated. In this paper, we present a document reranking approach that combines neural query-document matching and text summarization toward such retrieval scenarios. Our architecture builds on the basic BERT model with three specific components for reranking: . document-query matching . keyword extraction and . facet-conditioned abstractive summarization. The outcomes of  and  are used to essentially transform a candidate document into a concise summary that can be compared with the query at hand to compute a relevance score. Component  directly generates a matching score of a candidate document for a query. The full architecture benefits from the complementary potential of document-query matching and the novel document transformation approach based on summarization along PM facets. Evaluations using NIST's TREC-PM track datasets  show that our model achieves state-of-the-art performance. To foster reproducibility, our code is made available here: \url{https://github.com/bionlproc/text-summ-for-doc-retrieval}."
". } In real-world dialogue systems, substantial portion user queries ambiguous ones system unable precisely identify underlying intent. %For example, nearly 30\% user queries real-world QA system ambiguous questions. % Can't give statistics academic paper without mentioning details We observed many queries question answering system exhibited one following two characteristics. %The ambiguous questions QA system summarized 2 types:\\ % \\ % Given limited information, difficult system accurately respond user's ambiguous queries, often resulting user's needs cannot addressed. For example, specific intent underlying utterance ``How apply?"" remains obscure, many products related action ``applying"". In practice, one often needs fall back human agents assist requests, increasing workload cost. The main purpose deployed automated systems reduce human workload scenarios customer service hotlines. The lack ability deal ambiguous questions may directly lead sessions transferred human agents. In real-world customer service system, affects 30\% sessions. Hence, valuable find effective solution clarify ambiguous questions automatically, greatly reducing number cases requiring human assistance. Automated question clarification involves confirming user's intent interaction. %. % essential Question Answering system. Previous work explored asking questions . Unfortunately, clarification asking questions requires substantial customization specific dialogue setting. It challenging define appropriate questions guide users towards providing accurate information. Coarse questions may leave users confused, overly specific ones may fail account specific information user wishes convey. In work, thus instead investigate interactive clarification providing user specific choices options, intent options . Unlike previous work, propose end-to-end model suggests labels clarify ambiguous questions. % In experiments, show method significantly performs rule based method recall potential FAQs. % This paper focused closed-domain question clarification dialogue, solving kinds ambiguous questions one method. %濡紕纭﹂梻顕顣藉☉鍫燁劆娑撴槒顩﹂柅姘崇箖娴溿倓绨扮涵顔款吇閻€劍鍩涢幇蹇撴禈閵嗗倹婀侀崙鐘殿潚娴溿倓绨伴弬鐟扮础閿涘苯寮介梻顔藉灗閹绘劒绶甸悽銊﹀煕闁銆嶉妴鍌氬冀闂傤喚娈戦弬瑙勭《闁俺绻冮悽鐔稿灇濞戝牊顒犻梻顔煎綖閿涘苯顩ч弸婊冨冀闂傤噣妫舵０妯跨箖娴滃骸绱戦弨鎾呯礉鐎硅妲楀鏇炲弳娑撳秴褰叉０鍕埂閻ㄥ嫬娲栨径宥冨倷姘︽禍鎺旀畱閺傜懓绱￠柅姘崇箖缂佹瑥鍤惄绋垮彠闁銆嶆笟娑氭暏閹撮攱绉峰褝绱濆В鏂款洤閻╃ǹ鍙AQ閹存牜娴夐崗铏Х濮澭囧銆嶉妴 %Previous methods either solve lack semantic elements questions solve entity ambiguity questions. % %娑撳窋revious work娑撴槒顩﹂崠鍝勫焼: %1.閸欏秹妫堕惃鍕煙濞夋洟妫堕惃鍕６妫版ê銇婂閺鎾呯礉閻€劍鍩涢惃鍕礀缁涙柨褰查懗鐣岄兇缂佺喐甯存稉宥勭瑐閿涘本鍨ㄩ懓鍛晸閹存劒绔存稉顏勭发婵傚洦顏嗘畱闂傤噣顣,閻喎鐤勭化鑽ょ埠闁倻鏁ら懟锕傛 %2.query 缁墽鍋ч弰顖滄暏閸︺劍鎮崇槐銏犵穿閹垮海娈戦敍灞芥躬鐎电鐦藉鍕娑撳﹤銇婇柌宥忕礉娑撳秴褰查懗钘夋躬鐎电鐦介柌宀绮伴崙杞扮閸棙鎮崇槐銏㈢波閺 %閻╃ǹ鎮撹ぐ銏犵础閻ㄥ嫪姘︽禍鎺戠础闂傤噣顣藉鍕娴ｈ法鏁ゆ稉娑擃亜鐔娴滃侗MI閸滃瓥DF閻ㄥ嫯顫夐崚娆愭煙濞夋洩绱濈圭偤鐛欑拠浣规閹存垳婊戦惃鍕煙濞夋洘妯夐拋妞剧喘娴滃氦顫夐崚娆愭煙濞夋洏 %閹存垳婊戦幓鎰毉娑撶粔宥囩暆濞蹭胶娈戝☉鍫燁劆閺傝顢嶉敍宀娲块幒銉ュ灙閸戠儤顒犳稊澶屽仯閿涘矂鍌滄暏娴滃骸顕拠婵嗘簚閺 %Question clarification asking question generated model may receive unexpected reply user like ``I'm sure"" generate weird question real application. Query refinement method helps improve search results applicable clarification dialogue. We aimed interact user concise phrases clarify user's question. % In closed-domain QA system, believe ambiguous question series potential clear questions. For example, Figure~, least three FAQ questions corresponding ambiguous question ``How apply"". We argue essence clarifying ambiguous questions lies finding key points differentiation potential questions. It's possible clarify user's true intents confirming key points users shown Figure~. % % % An example sort approach given Figure. Here, consider closed-domain QA system, typical method build intent inventory address high-frequency requests. In setting, set unambiguous candidate labels ambiguous user utterance corresponds set frequently asked questions covered intent inventory. %By constraining problem close-domain, potential clear questions ambiguous question finite set. In closed domain, consider candidate set finite. For example, Figure, three specific intents corresponding ambiguous question ``How apply"". Our approach induces phrase tags labels intent. Thus, catalog intents corresponding labels presented user. The challenge lies selecting suitable list labels effectively clarify ambiguous question. In approach, problem finding label sequence formulated collection partitioning problem, objective cover many elements possible distinguishing elements clearly possible. % According Aristotle, definition species consists genus proximum differ. The differential attribute one species distinguished others genus. The task question clarification thus amounts obtaining suitable set labels. %is get differential intents set potential FAQs. % \todo{update section 3.2} % We illustrate method finding intents set detail methodology section. % % introduced methods ask clarification questions information missing given linguistic context. use generative model generate clarification questions solving entity ambiguities. But obstacles use methods real application. One reason users real world sometimes respond clarification question expected like reply ``I'm sure"". Compared withing ask clarification question, directly list potential ambiguities options. proposed query refinement method based reinforcement learning, helps improve search results search engine. Limited form dialogue system, practical show long list potential results dialogue. We aimed interact user concise phrases clarify user's question. % % A similar idea \citet{DBLP:conf/chiir/RadlinskiC17} also suggests that, conversational interface may easier users clarify needs given precise choices rather expecting come particular terms. % The complete question clarification process work illustrated Figure . Through real-world application experiments, method lower rate transferring human agents significant higher CTR baselines. Our method also performs better baselines recall potential FAQs annotated corpora. %This paper focuses closed-domain question clarification dialogue, solving kinds ambiguous questions one method. The main contributions work are: %% This part comparison related works. % We investigated related works clarify ambiguous questions QA. The classic solution rank semantic similar questions [ranker ref] ambiguous questions. However, considering limitation display information dialogue based QA system, generally three results displayed, resulting method cannot cover enough potential clear questions. In experiments, use relevance ranker baseline comparison. The results show human transferring rate method much lower ranking method. The second method ask clarification questions . . However, method generative clarification question limitations real-word QA system. The biggest obstacle user's answer space maybe open answer, complicates dialogue. In addition, lot works disambiguate questions question refinement, refinement methods usually supplements information single key point, able achieve key point recall mentioned earlier. % Question clarification essential question answering system. In real-world QA system, nearly 30\% user queries ambiguous questions. Without clarification, dialogue participants risk missing information ambiguous failing achieve mutual understanding. The ability ask clarification questions one key desired components conversational systems . introduced methods ask clarification questions information missing given linguistic context. use generative model generate clarification questions solving entity ambiguities. % However, difficult achieve high success rate. For example, ``how apply?"" ambiguous, many products related ``apply"". By asking one option question, ``Do want apply credit card?"" two options question, ``Do want apply credit card loan ?"", less efficient. Phenomena mentioned exist real world customer service robot system. CSRobot based FAQ question answering widely used real world, especially financial industry. When user enter question CSRobot system , information retrieved computing semantic similarity user question pre-manually prepared FAQ. Due factors user's age, gender, geography, familiarity system, urgency user's problem, user may enter many ambiguous questions. In CSRobot environment, ratio nearly 30\%. The ambiguous questions system summarized 5 types: Missing subject object, e.g. ``how apply"", ``how change back"", Missing predicate, e.g. ``credit card"", ``my QR code"", Missing subject predicates objects, e.g. ``How benefit"", ``its right"", Entity ambiguous, e.g. ``My health insurance"", health insurance contains many sub-categories, Misspelling ambiguous. ``how exist"" , ``exist"" may misspelling ``exit"". In work, focus asking clarification questions using intents recommendation FAQ-based question answering system. Previous methods either solve missing information questions solve entity ambiguity questions, proposed method handle missing information entity ambiguous mentioned above. % The complete question clarification process work seen Figure . The user enters incomplete ambiguous question, agent recommends list candidate intents, clarifies user's question clicked. Then user clicks intent associated himself, agent finds list related FAQ FAQ knowledge base clarified question. Our work focuses recommend list candidate intents question clarification. A similar idea \citet{DBLP:conf/chiir/RadlinskiC17} also suggests that, conversational interface may easier users clarify needs given precise choices rather expecting come particular terms. % introduce question clarification collection partition thought detail % % One challenges designing method design cold start scenario. We use end-to-end sequential intents recommendation method based reinforcement learning user question clarification. We use supervised method mainly difficult human annotators directly labeling intents related user's ambiguous question . The reward designed recommend closest clear question list maximize information gain clicking one intent better question clarification. We conducted offline online experiments real-world CSRobot environment collected data 100 million online real-users' interactions system one month. To best knowledge, first use intents recommendation question clarification real-world CSRobot environment, interactions 100 million real users. The experiments proved effectiveness scalability proposed method. Contributions summarized follows: % %% FORMATTING \newcommand{\NTCIR}{NTCIR-13} \newcommand{\metric}[1]{{\mbox{#1}}} \newcommand{\metricfont}[1]{{\small\sf{#1}}} \newcommand{\ydata}{{\metricfont{Y!S1}}} \newcommand{\govdata}{{\metricfont{GOV2}}} \newcommand{\RBP}{\metric{RBP}} \newcommand{\Pat}{\metric{P}} %\newcommand{\AP}{\metric{AP}} \newcommand{\AP}{\metric{MAP}} \newcommand{\NDCG}{\metric{NDCG}} \newcommand{\ERR}{\metric{ERR}} \newcommand{\BPref}{\metric{BPref}} \newcommand{\Qmeasure}{\metric{Qmeasure}} \newcommand{\Patk}[1]{\mbox{\Pat@}} \newcommand{\RBPatp}[1]{\mbox{\RBP@}} \newcommand{\RBPatptok}[2]{\mbox{\RBP@}} \newcommand{\NDCGatk}[1]{\mbox{\NDCG@}} \newcommand{\ERRatk}[1]{\mbox{\ERR@}} \newcommand{\APtok}[1]{\mbox{\AP}} \newcommand{\APatk}[1]{\mbox{\AP}} \newcommand{\NDCGtok}[1]{\mbox{\NDCG}} \newcommand{\ERRtok}[1]{\mbox{\ERR}} \newcommand{\ssvar}[1]{\mbox{\tiny#1}} \newcommand{\trisk}{} \newcommand{\urisk}{} \newcommand{\combsum}{\method{CombSUM}\xspace} \newcommand{\rrf}{\method{RRF}\xspace} %-- Baselines \newcommand{\gbrt}{\method{GBRT}} \newcommand{\lstm}{\method{LSTM}} \newcommand{\dqn}{\method{DQN}} \newcommand{\dodqn}{\method{DoDQN}} \newcommand{\doddqn}{\method{DoDDQN}} \newcommand{\ddqn}{\method{DDQN}} \newcommand{\pdodqn}{\method{PER-DoDQN}} \newcommand{\pdoddqn}{\method{PER-DoDDQN}} \newcommand{\per}{\method{PER}} \newcommand{\mlp}{\method{MLP}} %\newcommand{\gbdtbl}{\method{GBDT-BL}} %\newcommand{\gbrtbl}{\method{GBRT-BL}} %\newcommand{\lambdamartbl}{\method{LambdaMART-BL}} %\newcommand{\gbdtbbl}{\method{GBDT-Budget-BL}} %\newcommand{\qlbl}{\method{QL-BL}} %\newcommand{\bmbl}{\method{BM25-BL}} %\newcommand{\sdmbl}{\method{SDM-BL}} %\newcommand{\adarankbl}{\method{AdaRank-BL}} %\newcommand{\wlmbl}{\method{WLM-BL}} % %%-- Experimental methods %\newcommand{\lmccost}{\method{LM-C3-Cost}} %\newcommand{\lmcce}{\method{LM-C3-CE}} %\newcommand{\lmcrnd}{\method{LM-C3-Rnd}} %\newcommand{\gbdtccost}{\method{GBDT-C3-Cost}} %\newcommand{\gbdtcce}{\method{GBDT-C3-CE}} %\newcommand{\gbdtcrnd}{\method{GBDT-C3-Rnd}} %\newcommand{\gbrtccost}{\method{GBRT-C3-Cost}} %\newcommand{\gbrtcce}{\method{GBRT-C3-CE}} %\newcommand{\gbrtcrnd}{\method{GBRT-C3-Rnd}} %\newcommand{\lambdamartccost}{\method{LambdaMART-C3-Cost}} %\newcommand{\lambdamartcce}{\method{LambdaMART-C3-CE}} %\newcommand{\lambdamartcrnd}{\method{LambdaMART-C3-Rnd}} % %\newcommand{\lmc}{\method{LM-C3-C}} %\newcommand{\lme}{\method{LM-C3-E}} %\newcommand{\lmf}{\method{LM-C3-F}} %\newcommand{\gbdtc}{\method{GBDT-C3-C}} %\newcommand{\gbdte}{\method{GBDT-C3-E}} %\newcommand{\gbdtf}{\method{GBDT-C3-F}} %\newcommand{\gbrtc}{\method{GBRT-C3-C}} %\newcommand{\gbrte}{\method{GBRT-C3-E}} %\newcommand{\gbrtf}{\method{GBRT-C3-F}} %\newcommand{\lambdamartc}{\method{LambdaMART-C3-C}} %\newcommand{\lambdamarte}{\method{LambdaMART-C3-E}} %\newcommand{\lambdamartf}{\method{LambdaMART-C3-F}} %-- Tools \newcommand{\xgboost}{} \newcommand{\scikit}{} \newcommand{\tensorflow}{} %-- misc formatting \def\D{\hphantom{1}} \def\C{\hphantom{1,}} %-- Misc control commands \newcommand\method[1]{{\sf\small{#1}}} \newcommand\smethod[1]{{\sf\scriptsize{#1}}} \newcommand\mytt[1]{{\bf{\tt{\small{#1}}}}} \newcommand{\alginp}[1]{\makebox[15mm][l]{\sc Input:}\\[0.5ex]} \newcommand{\algout}[1]{\makebox[15mm][l]{\sc Output:}\\} %--- Ranking Stuff \newcommand{\smin}{\var{s\_min}} \newcommand{\smax}{\var{s\_max}} \newcommand{\Answers}{\var{Ans}} \newcommand{\docweight}{\var{docweight}_{d}} \newcommand{\score}{\var{score}_{d,t}} \newcommand{\pivot}{\var{pivot}} \newcommand{\cpivot}{c_{\mbox{\scriptsizepivot}}} \newcommand{\tpivot}{t_{\mbox{\scriptsizepivot}}} \newcommand{\posting}{\ensuremath{}} \newcommand{\dfdt}{\rangle d,f_{d,t} \langle} \newcommand{\tf}{\mbox{ extsc{TF}}\xspace} \newcommand{\tfidf}{\mbox{tfidf}\xspace} \newcommand{\tftd}{\ensuremath{\tf_{t,d}}} \newcommand{\tfqd}{\ensuremath{\tf_{q,d}}} \newcommand{\idf}{\mbox{ extsc{idf}}\xspace} \newcommand{\idft}{\ensuremath{idf_t}} \newcommand{\idfq}{\ensuremath{idf_q}} \newcommand{\idld}{\ensuremath{idl_d}} \newcommand{\idl}{\mbox{ extsc{idl}}\xspace} \newcommand{\wtd}{\ensuremath{wt_d}} %--- Ops %% \newcommand{\opstyle}[1]{\mbox{ extsc{#1}}} \newcommand{\opstyle}[1]{\mbox{{#1}}} \newcommand{\bmax}{\opstyle{BLOCK-MAX}\xspace} \newcommand{\wand}{\opstyle{WAND}\xspace} \newcommand{\bmwand}{\opstyle{BM-WAND}\xspace} \newcommand{\maxscore}{\opstyle{MAXSCORE}\xspace} \newcommand{\hsv}{\opstyle{HSV}\xspace} \newcommand{\pst}{\opstyle{PST}\xspace} \newcommand{\gtaat}{\opstyle{Greedy-TAAT}\xspace} \newcommand{\taat}{\opstyle{TAAT}\xspace} \newcommand{\daat}{\opstyle{DAAT}\xspace} %--- Misc \newcommand{\bwt}{{\sc bwt}\xspace} \newcommand{\fmindex}{{\sc FM-index}\xspace} \def\xbwt{\mtxt^{\mbox{\scriptsize {\sc bwt}}}} \newcommand{\sa}{\mbox{\mbox{\sc sa}}} \newcommand{\lf}{\mbox{\mbox{\sc lf}}} \newcommand{\cpu}{{\sc cpu}\xspace} \newcommand{\ram}{{\sc ram}\xspace} \newcommand{\ascii}{{\sc ascii}\xspace} \newcommand{\sgml}{{\sc sgml}\xspace} \newcommand{\trec}{{\sc trec}\xspace} \newcommand{\collection}[1]{\mbox{\small\sc{#1}}} \newcommand{\newswire}{\collection{NewsWire}} \newcommand{\wt}{\collection{WT10G}} \newcommand{\gov}{\collection{GOV2}} \newcommand{\raw}{\mbox{\sc raw}\xspace} %--- Macros \newcommand{\bm}{\opstyle{BM25}} \newcommand{\lm}{\opstyle{LMDS}} \newcommand{\pl}{\mbox{\bf\scriptsize PL2}\xspace} \newcommand{\tfbm}{\ensuremath{\mbox{TF}_{\mbox{\scriptsize{BM25}}}\xspace}} \newcommand{\utf}{\mbox{\scriptsize UTF-8}\xspace} %%\newcommand{\newt}{\mbox{\method{NeWT}\xspace}} \newcommand{\newt}{\mbox{\method{NewSys}\xspace}} \newcommand{\indri}{\method{Indri\xspace}} \newcommand{\lynx}{\method{Lynx\xspace}} \newcommand{\boilerpipe}{\method{Boilerpipe\xspace}} \newcommand{\terrier}{\method{Terrier\xspace}} \newcommand{\Space}{space\xspace} \newcommand{\prefix}{prefix\xspace} \newcommand{\suffix}{suffix\xspace} \newcommand{\plain}{plain\xspace} \newcommand{\intent}{{\sc intent}\xspace} \newcommand{\slarge}{S-Lrg} \newcommand{\ssmall}{S-Sml} \newcommand{\realdat}{R-Data} \newcommand{\SA}{\mbox{SA}} \newcommand{\Tmin}{T_{\mbox{\scriptsize{min}}}} \newcommand{\Tmax}{T_{\mbox{\scriptsize{max}}}} \newcommand{\argmin}{\operatornamewithlimits{argmin}} \newcommand{\argmax}{\operatornamewithlimits{argmax}} \newcommand{\lmax}{\operatornamewithlimits{max}} \newcommand{\llim}{\operatornamewithlimits{lim}} %-- Sizes \newcommand\kb[1]{\,kB} \newcommand\mb[1]{\,MB} \newcommand\gb[1]{\,GB} \newcommand\tb[1]{\,TB} %-- maths \newcommand{\ith}{\ensuremath{i^{\mbox{\scriptsize th}}}} \newcommand{\nmax}{n_{\mbox{\tiny max}}} \newcommand{\newlne}{{}n} \newcommand{\var}[1]{\mbox{#1}} \newcommand{\svar}[1]{\mbox{\scriptsize#1}} %-- misc formatting \def\D{\hphantom{1}} \def\C{\hphantom{1,}} \newcommand{\myurl}[1]{{\url{#1}}} \newcommand{\mycaption}[1]{}} \newcommand{\myquery}[1]{{``{\tt{#1}}''}} %%AM \newcommand{\myparagraph}[1]{\paragraph*{\normalsize\it{#1}}} %% \newcommand{\myparagraph}[1]{\mysubsection{#1}} %\newcommand{\myparagraph}[1]{~\\{#1}.~} \newcommand{\myparagraph}[1]{{#1}.~} \newcommand{\mysubsection}[1]{\subsubsection*{{#1}}} \newcommand{\noi}{} \newcommand{\mycomment}[1]{} \newcommand{\mylabel}[1]{} \newcommand{\mytab}{\makebox[6mm]{~}} \newcommand{\fixed}[1]{\makebox[18mm]{#1}} %-- big iron \newcommand{\haatheshort}{ Intel Xeon E5640 fgcessors {\mb{12}} cache {\gb{144}} SDRAM} %\newcommand{\haathee}{ Intel Xeon E5640 Processors %a {\mb{12}} smart cache, {\gb{144}} DDR3 DRAM, eight {\tb{2}} SATA-II disks, %and running Ubuntu Linux 11.10} \newcommand{\haathee}{ Intel Xeon E5640 Processors {\mb{12}} smart cache, {\gb{144}} DDR3 DRAM, running Ubuntu Linux 11.10} %-- table formatting \newlength{\onedigit} \settowidth{\onedigit}{} \newcommand{\w}{\makebox[\onedigit]{~}} \newcounter{todocount} \setcounter{todocount}{1} \newcommand{\todo}[1]{{\color{blue}*** [\thetodocount] #1 ***\addtocounter{todocount}{1}}} % % File acl2020.tex % %% Based style files ACL 2020, %% Based style files ACL 2018, NAACL 2018/19, %% Based style files ACL-2015, improvements %% taken NAACL-2016 style %% Based style files ACL-2014, were, turn, %% based ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009, %% EACL-2009, IJCNLP-2008... %% Based style files EACL 2006 %%e.agirre@ehu.es Sergi.Balari@uab.es %% ACL 08 Joakim Nivre Noah Smith \documentclass[11pt]{article} \usepackage{coling2020} \usepackage{times} \usepackage{url} \usepackage{latexsym} \renewcommand{\UrlFont}{\ttfamily\small} \usepackage{booktabs} % For formal tables \usepackage[normalem]{ulem} \usepackage{xcolor} %%xl: I need xcolour.... \usepackage{algorithm} \usepackage{algpseudocode} \usepackage{amsmath} \usepackage{mathrsfs} \usepackage{amssymb} \usepackage{subfigure} \usepackage{makecell} \usepackage{mathtools} \usepackage[font=rm]{caption} % \usepackage{subcaption} \DeclareCaptionType{copyrightbox} \usepackage{shortvrb} \usepackage{tabularx} \usepackage{verbatim} \usepackage{xspace} \usepackage{listings} \lstset{basicstyle=\small\ttfamily,mathescape,columns=fullflexible,keepspaces=true} \usepackage{fontawesome} \usepackage[multiple]{footmisc} \usepackage[all]{nowidow} \usepackage{balance} % This strictly necessary, may commented out, % improve layout manuscript, % typically save space. \usepackage{microtype} \usepackage{wrapfig} %\aclfinalcopy % Uncomment line final submission %\def\aclpaperid{***} % Enter acl Paper ID %\setlength\titlebox{5cm} % You expand titlebox need extra space % show authors. Please make titlebox % smaller 5cm ; check % camera-ready version ask change back. \usepackage[medium,compact]{titlesec} \usepackage{enumitem} \setlist{itemsep=0pt,parsep=0pt} \colingfinalcopy \title{Interactive Question Clarification Dialogue via Reinforcement Learning} \author{ Xiang Hu\footnotemark[2] \\ % Ant Financial Services Group\footnotemark[2]\\ Hasso Plattner Institute, University Potsdam\footnotemark[3]\\ \\\And Zujie Wen\footnotemark[2] \\ % Rutgers University\\ % \\\And Yafang Wang \footnotemark[2] \thanks{\ \ corresponding author, email: yafang.wyf@antfin.com} \\ % Ant Financial Services Group\\ % % \thanks{Corresponding author, Email: yafang.wyf@antfin.com} \\\And Xiaolong Li\footnotemark[2] \\ % Rutgers University\\ % \\\And Gerard de Melo\footnotemark[3] \\ % Ant Financial Services Group\\ % \\ tu } \date{}"," %闂侇偅淇虹换鍐矗瀹ュ锛栭柣銊ュ閺岀喎顕ｈ箛鏃傜獮婵炴挸鎳庤ぐ鏌ユ嚄閽樺鏁ㄩ柡澶堝劜濡倕鈻旈弴銏╂殨闁哄牏鍠撳▓鎴︽偨閵婏箑鐓曢柛娆忕Ч椤╊參鏁嶇仦鑺ヨ含闁活亞鍠庨悿鍕寲閼姐倗鍩犲☉鎿冨幖缁扁晠宕楅妷銈囩憹缁绢収鍠栭悾楣冨箑瑜嬫穱uestion reformulation闁哄倽顫夌涵璺侯嚗鐎典即寮悩宕囥婂ù鍏煎椤撴悂骞嶉柡鍫濐槹缂嶆棃宕烽妸銉ヨ闁煎疇濮よ閸屾碍绀堟慨婵勫栭崹婊勭椤戝灝鈻忛柣鈧妺缁斿绮斿鍕攭濞存粍甯掔槐锟犳儍閸曨垱锛栧Λ鐗埳戠欢鐐层掗崨顔界厵婵炲娲 % \todo{explain defect of previous works} Coping with ambiguous questions has been a perennial problem in real-world dialogue systems. Although clarification by asking questions is a common form of human interaction, it is hard to define appropriate questions to elicit more specific intents from a user. In this work, we propose a reinforcement model to clarify ambiguous questions by suggesting refinements of the original query. We first formulate a collection partitioning problem to select a set of labels enabling us to distinguish potential unambiguous intents. We list the chosen labels as intent phrases to the user for further confirmation. The selected label along with the original user query then serves as a refined query, for which a suitable response can more easily be identified. The model is trained using reinforcement learning with a deep policy network.  We evaluate our model based on real-world user clicks and demonstrate significant improvements across several different experiments. % The ability to ask clarification questions to solve ambiguity and missing information phenomena is essential for question answering systems. The current research mainly uses questions generation or questions ranking to ask a clarification question, which lead to low success rate and redundant information. Insufficient use of the graphic user interface  results in more interactions with users. There is usually no guarantee for replying the user after the clarification. To solve these problems, we propose a question clarification method based on intents recommendation. intents are extracted from the historical Frequently Asked Questions of our system. The recommended intents can provide more concise candidates for user to click. Once an intent is clicked, the system guaranteed to provide a clear question list relative to the real question. We use the reinforcement learning method to recommend intents, and the most challenging problem is cold start. The reward is designed to recommend the most relevant clear question list and maximize the information gain after clicking one intent for better question clarification. The method we proposed for question clarification can solve both ambiguity and missing information phenomena. Experiments on interactions with more than 100 million real-world online users shows the effectiveness of this method."
"%Discourse Parsing key NLP %an important task, aiming establish better understanding multi-sentential natural language. %, inherently ambiguous intent-driven. %Most research area thereby focuses one two main discourse theories RST PDTB , proposed decade ago. Discourse Parsing key Natural Language Processing task processing multi-sentential text. Most research area focuses one two main discourse theories -- RST PDTB . The latter thereby postulates shallow discourse structures, combining adjacent sentences mainly focuses explicit implicit discourse connectives. The RST discourse theory, hand, proposes discourse trees complete documents constituency-style manner, tree leaves called Elementary Discourse Units , representing span-like sentence fragments. Internal tree-nodes encode discourse relations sub-trees tuple \{Nuclearity, Relation\}, nuclearity defines sub-tree salience local context, relation specifies type relationship binary child nodes automatically inferred discourse structures nuclearity attributes large-scale sentiment datasets already reached state-of-the-art performance inter-domain discourse parsing task. Similarly, \citet{liu2018learning} infer latent discourse trees text classification task, \citet{liu2019single} employ downstream task summarization using transformer model generate discourse trees. Outside area discourse parsing, syntactic trees previously inferred according several strategies, e.g. \citet{socher2011semi, yogatama2016learning, choi2018learning, maillard2019jointly}. %including: Discrete decisions frameworks using Gumbel-softmax component , applying reinforcement approach syntactic parsing , using reconstruction error adjacent spans indicator syntactic coherence within sentence employing CKY approach select syntactic trees soft model . In general, approaches mentioned %to automatically annotate text discourse structures syntactic trees shown capture valuable structural information. Some models outperform baselines trained human-annotated datasets , others proven enhance diverse downstream tasks . However, despite initial successes, one critical limitation aforementioned models share task-specificity, possibly capturing downstream-task related information. %of discourse, This potentially compromises generality resulting trees, instance shown model using text classification data \citet{ferracane2019evaluating}. %For instance, approach \citet{huber2019predicting} uses document-level sentiment information inform discourse tree generation, others %have %using summarization data sentence-level sentiment cues achieve results. In order alleviate limitation task-specificity, propose new strategy generate tree structures task-agnostic, unsupervised fashion extending latent tree induction framework proposed \citet{choi2018learning} auto-encoding objective. %. Our system thereby extracts important knowledge natural text optimizing underlying tree structures distributed representations. We believe resulting discourse structures effectively aggregate related commonly appearing patterns data merging coherent text spans intermediate sub-tree encodings, similar intuition presented \citet{drozdov2019unsupervised}. However, contrast approach \citet{drozdov2019unsupervised}, model makes discrete structural decisions, rather joining possible subtrees using soft attention mechanism. We believe discrete tree structures allow model efficiently achieve autoencoder objective reconstructing inputs, directly learning written language aggregated wild . In general, proposed approach applied tree-structured objective, syntactic parsing, discourse parsing problems outside NLP, like tree-planning decision-tree generation . Yet, due especially difficult annotation process generate discourse trees, initially develop method %complement task-specific models generate much larger diverse discourse treebanks."," Discourse information, as postulated by popular discourse theories, such as RST and PDTB, has been shown to improve an increasing number of downstream NLP tasks, showing positive effects and synergies of discourse with important real-world applications. While methods for incorporating discourse become more and more sophisticated, the growing need for robust and general discourse structures has not been sufficiently met by current discourse parsers, usually trained on small scale datasets in a strictly limited number of domains. This makes the prediction for arbitrary tasks noisy and unreliable. The overall resulting lack of high-quality, high-quantity discourse trees poses a severe limitation to further progress.  In order the alleviate this shortcoming, we propose a new strategy to generate tree structures in a task-agnostic, unsupervised fashion by extending a latent tree induction framework with an auto-encoding objective. The proposed approach can be applied to any tree-structured objective, such as syntactic parsing, discourse parsing and others. However, due to the especially difficult annotation process to generate discourse trees, we initially develop a method to generate larger and more diverse discourse treebanks. In this paper we are inferring general tree structures of natural text in multiple domains, showing promising results on a diverse set of tasks.  %With this paper, we intend to initiate a new line of research on inferring discourse structures in an unbiased manner. %With a growing need for robust and general discourse structures in many downstream tasks and real-world applications, the current lack of high-quality, high-quantity discourse trees poses a severe shortcoming. %In order the alleviate this limitation, we propose a new strategy to generate tree structures in a task-agnostic, unsupervised fashion by extending a latent tree induction framework with an auto-encoding objective. The proposed approach can be applied to any tree-structured objective, such as syntactic parsing, discourse parsing and others. However, due to the especially difficult annotation process to generate discourse trees, we initially develop such method to complement task-specific models in generating much larger and more diverse discourse treebanks."
"Retrieval technique response selection popular elegant approach framing chatbot i.e. open-domain dialog system. Given conversation context, retrieval-based chatbot aims select appropriate utterance response pre-constructed database. %that saves large number human written utterances. In order balance effectiveness efficiency, mosts retrieval-based chatbots employ coarse-grained selection module recall set candidate semantic coherent conversation context speed processing. % 鐠囧瓨妲戦敍姘妧娑斿孩鏅ラ悳鍥ф嫲閺佸牊鐏夐獮鏈电瑝閼宠棄鍙忛柈銊ュ絿瀵 % 閸滃elated work闁插矂娼伴柌宥咁槻娴滃棴绱濋惄瀛樺复閸掔姴骞撻敍 To best knowledge, two kinds approaches build coarse-grained selection module retrieval-based chatbots: sparse representation: TF-IDF BM25 widely used method. It matches keywords inverted index seen representing utterances highdimensional sparse vectors ; %This method runs quickly, lacks rich semantic information. dense representation: Large scale pre-trained langauge models , e.g. BERT commonly used obtain semantic representation utterances, could used recall semantic coherent candidates using cosine similarity . %Due high computational burden similarity calculating, %this method runs slowly, could consider rich semantic information %. % 鐠囧瓨妲戦惄顔煎楠炶埖妫ょ化鑽ょ埠娑擃亜顕В鏃撶礉鐠囧瓨妲戠紒鍡氬Ν閸欘垯浜掗崷銊ョ杽妤犲奔鑵戦幍鎯у煂閿涘矂妲撻弰搴＄杽妤犲瞼绮ㄩ弸婊冩嫲dense vectors閻ㄥ墜eakness閿涘瞼鍔ч崥搴＄穿閸戠儤鍨滄禒顒傛畱閸欙缚绔存稉鐚祌oposed method % Luan2020SparseDA鏉╂瑤閲滅拋鐑樻瀮娑旂喕顕╅弰搴濈啊BM25閺堝妞傞崐娆愭櫏閺嬫粍娲挎總 % Dense 閺鐟版倳 BERT So far, systematic comparison two kinds approaches retrieval-based chatbots, kind method appropriate real scenarios still open question confuses researchers dialog system community. Thus, paper, first conduct extensive experiment compare two approaches four important aspects: effectiveness; search time cost; index storage occupation; human evaluation. Extensive experiment results four popular response selection datasets demonstrate dense representation significantly outperforms sparse representation expense lower speed bigger storage sparse representation, unsufferable real scenarios. Then, order overcome fatal weaknesses dense representation methods, propose ultra-fast, low-storage highly effective Deep Semantic Hashing Coarse-grained selection module %based given dense representation method, effectively balances effectiveness efficiency. Specifically, first stack novel hashing optimizing module consists two autoencoders given dense representation method. Then, three well designed loss functions used optimize two autoencoders hashing optimizing module: preserved loss; hash loss; quantization loss. After training, autoencoders could effectively preserve rich semantic similarity information dense vectors hash codes, computational storage efficient . \iffalse first all, train dense representation method using dual-architecture , contains context BERT encoder candidate BERT encoder. Then, separately stack deep autoencoder model encoder. The auto-encoder model could encode semantic information dense vectors hashing codes. Finally, novel deep semantic hashing approach used learn binary compressed representation dense vectors. % 鐠囧瓨妲戞禍宀冪箻閸掕泛鎼辩敮宀绱惍浣烘畱娴兼ê濞嶉敍灞肩瑝閸氬奔绨瑂parse閸滃畳ense缂傛牜鐖滈惃鍕偨婢跺嫨 It noted that, different dense vectors, binary hashing code storage-efficient ultra-fast calculate , also keeps rich semantic information dense vectors. \fi Extensive experiment results four popular response selection datasets demonstrate proposed DSHC model achieve much faster search speed lower storage occupation sparse representation method, limited performance loss compared given dense representation method. In paper, contributions three-fold: The rest paper organized follows: introduce important concepts background covered paper Section 2. The experiment settings presented Section 3. In Section 4, systematically compare current two kinds methods coarse-grained selection module: sparse representation; dense representation. In Section 5, introduce proposed DSHC model, detailed experiment results elaborated. In Section 6, conduct case study. Finally, conclude work Section 7. Due page limitation, details extra analysis found Appendix.","   We study the coarse-grained selection module in retrieval-based chatbot.   Coarse-grained selection is a basic module in a retrieval-based chatbot,   which constructs a rough candidate set from the whole database to speed up the interaction with customers.   So far, there are two kinds of approaches for coarse-grained selection module:     sparse representation;  dense representation.   To the best of our knowledge, there is no systematic comparison between these two approaches in retrieval-based chatbots,   and which kind of method is better in real scenarios is still an open question.   In this paper, we first systematically compare these two methods from four aspects:     effectiveness;  index stoarge;  search time cost;  human evaluation.   Extensive experiment results demonstrate that dense representation method    significantly outperforms the sparse representation,    but costs more time and storage occupation.   In order to overcome these fatal weaknesses of dense representation method,    we propose an ultra-fast, low-storage, and highly effective    Deep Semantic Hashing Coarse-grained selection method, called DSHC model.   Specifically, in our proposed DSHC model,   a hashing optimizing module that consists of two autoencoder models is    stacked on a trained dense representation model,   and three loss functions are designed to optimize it.   The hash codes provided by hashing optimizing module effectively    preserve the rich semantic and similarity information in dense vectors.   Extensive experiment results prove that,   our proposed DSHC model can achieve much faster speed and lower storage than sparse representation,   with limited performance loss compared with dense representation.   Besides, our source codes have been publicly released for future research\footnote{\url{https://github.com/gmftbyGMFTBY/HashRetrieval}}."
"With huge quantities natural language documents, search engines essential time saved information retrieval tasks. Usually, deployed search engines achieve task ranking documents relevance according query. \\ Recently, research focused task extracting span text exactly matches user's query Machine Reading Comprehension Question Answering. \\ Question Answering deals extraction span text short paragraph exactly answers natural language question. Recent deep learning models based heavy pretrained language models like BERT achieved better human performances tasks . \\ One could try apply QA models Open-Domain Question Answering paradigm aims answer questions taking big amount documents knowledge source. Two main issues emerge : first, applying 100M parameters language models potentially millions documents requires unreasonable GPU-resources. Then, QA models allow compare spans text coming exclusively single paragraph open-domain QA paradigm, one needs compare spans text coming wide range documents. \\ Our system, done previous work, deals resources issue thanks Retriever module, based BM25 algorithm, allows reduce search space millions articles hundred paragraphs. The second issue tackled adding deep learning based Scorer module re-ranks precision paragraphs returned Retriever. Eventually, Extractor module uses QA deep learning model extract best span text first paragraph returned Scorer. To avoid heavy hardly scalable pipeline consisting two huge deep learning models, parallelize re-ranking span extraction tasks thanks multitask learning : maintaining high performances, allows significantly reduce memory requirements inference time. Our system achieve state-of-the-art results open-squad benchmark.","   In this paper, we introduce MIX : a   multi-task deep learning approach to solve Open-Domain Question  Answering. First, we design our system as a multi-stage pipeline made of 3 building blocks : a BM25-based Retriever, to reduce the search space; RoBERTa based Scorer and Extractor, to rank retrieved paragraphs and extract relevant spans of text respectively. Eventually, we further improve computational efficiency of our system to deal with the scalability challenge : thanks to multi-task learning,   we parallelize the close tasks solved by the Scorer and the Extractor. Our system is on par with state-of-the-art performances on the squad-open benchmark while being simpler conceptually."
"Named Entity Recognition task identifying span class Named Entity unstructured text. NEs typically include limited persons, companies, dates, geographical locations . Legal NER central task language processing legal documents, especially extracting key information name parties case, court name case number, references laws judgements, name few. The extracted NEs could integrated legal research workflows functionalities search, document anonymization case summarization thereby enabling expediting insights legal professionals . NER commonly formalized sequence labeling task: token document assigned single label indicates whether token belongs entity predefined set categories . To create training dataset format annotator required manually label token sentence respective category. In format, NE location NE source text known. This format training data refer hereafter 閳ユ笀old standard閳 data. Obtaining required voluminous gold standard data train models is, therefore, laborious costly task. In paper, perform NER filed lawsuits US courts. Specifically, aim identify party names case, i.e. names plaintiffs defendants, large collection publicly available cases 200 courts different US jurisdictions. The party names identified legal annotators exact location text unknown. In respect, access 閳ユ笀old standard閳 training data even though target NEs available. This feature dataset introduces key difference task NER tasks. One solution problem generate 閳ユ笀old standard閳 training data searching locations known NEs source text . By performing additional transformation data, would able train sequence labeling NER models. For following reasons, solution nontrivial. First, source text also extracted scanned PDF files , contains Optical Character Recognition mistakes and/or typos may present target NEs. Second, besides potential OCR errors character level, closely spaced, two-column page layouts often found headers filed cases, represent additional challenge OCR, tends concatenate text across columns . In cases, tokens make NEs source text may intertwined words and/or sentences. Third, variations names may also present source text human-generated labels, presence first and/or middle names whole initials and, lesser extent, typos. To address challenges imposed format training data inspired work field abstractive summarization, propose reformulate NER task, sequence labeling problem, text-to-text sequence generation problem use pointer generator network . With reformulation, contrast sequence labeling, require knowledge NE閳ユ獨 locations text training labels. A recent study \citet{Li2020} proposed different formulation NER task question answering task achieved state-of-the-art performance number published NER datasets . In study, adopt hybrid extractive-abstractive architecture, based recurrent neural networks coupled global attention copying attention mechanisms . The proposed architecture successfully used abstractive summarization since copy words source text via pointing deal effectively out-of-vocabulary words 閳 words seen training. Our approach conceptually simple empirically powerful show pointer generator outperforms typical NER architectures case noisy lengthy inputs NE's location text known. In addition, examine approach used related NER task case number extraction. The case number unique combination letters, numbers special characters single token are, therefore, particularly challenging NER models often dealt OOV words model. As party names task discussed above, case number task 閳ユ笀old standard閳 labels case number閳ユ獨 location text. We show character level sequence generation network dramatically increase ability extract case numbers source text, compared word level sequence generation network. The rest paper organized follows. In Section 2, discuss related work field NER legal domain. In Section 3, describe proposal NER text-to-text sequence generation task absence gold standard data formulate task two ways: combination automatically labeling NE's location using conventional sequence labeling method NER, text-to-text sequence generation task NEs directly generated text. Section 4 presents experimental design, results analysis. Section 5 presents case number case study. Finally, conclude discuss directions future work."," Named Entity Recognition  is the task of identifying and classifying named entities in unstructured text. In the legal domain, named entities of interest may include the case parties, judges, names of courts, case numbers, references to laws etc. We study the problem of legal NER with noisy text extracted from PDF files of filed court cases from US courts. The 闁炽儲绗old standard闁 training data for NER systems provide annotation for each token of the text with the corresponding entity or non-entity label. We work with only partially complete training data, which differ from the gold standard NER data in that the exact location of the entities in the text is unknown and the entities may contain typos and/or OCR mistakes. To overcome the challenges of our noisy training data, e.g. text extraction errors and/or typos and unknown label indices, we formulate the NER task as a text-to-text sequence generation task and train a pointer generator network to generate the entities in the document rather than label them. We show that the pointer generator can be effective for NER in the absence of gold standard data and outperforms the common NER neural network architectures in long legal documents."
"Speech translation~, translates audio signals speech one language text foreign language, hot research subject nowadays widespread applications, like cross-language videoconferencing customer support chats. Traditionally, researchers build speech translation system via cascading manner, including automatic speech recognition~ machine translation~ subsystem. Cascade systems, however, suffer error propagation problems, inaccurate ASR output would theoretically cause translation errors. Owing recent progress sequence-to-sequence modeling neural machine translation~ end-to-end speech recognition, becomes feasible efficient train fully end-to-end ST model. This end-to-end fashion attracts much attention due appealing properties: a) modeling without intermediate ASR transcriptions obviously alleviates propagation errors; b) single unified ST model beneficial deployment lower latency contrast cascade systems. % However, end-to-end paradigm far reaching industry requirements requires large-scale end-to-end corpora audios paired textual translations, hard acquire. Recent studies show end-to-end ST models achieve promising performance comparable cascaded models. The end-to-end solution great potential dominant technology speech translation, however challenges remain. The first benchmarks. Many ST studies conduct experiments different datasets. ~\citet{liu2019end} evaluate method TED English-Chinese; ~\citet{dong2020ted} use Augmented Librispeech English-French IWSLT2018 English-German dataset; ~\citet{wu2020self} show results CoVoST dataset FR/RO portions MuST-C dataset. Different datasets make difficult compare performance approaches. Further, even dataset, baseline results necessarily kept consist. Take Augmented Librispeech English-French dataset example. ~\citet{dong2020ted} report pre-trained baseline 15.3 result ~\citet{liu2019end} 14.3 terms tokenized BLEU, while~\citet{inaguma2020} report 15.5 . The mismatching baseline makes comparison final results meaningless. One primary reasons preprocessing audio data complex, ST model training involves many tricks, pre-training data augmentation. Therefore reproducible reliable benchmark required. In work, present \method, toolkit easily building training end-to-end ST models, well end-to-end ASR NMT cascade systems. We implement start-of-the-art Transformer-based models provide step-by-step recipes feature extraction, data preprocessing, model training, inference researchers reproduce benchmarks. Though exist several counterparts, Lingvo, fairseq-ST Kaldi~ style~ESPnet-ST, \method specially designed speech translation tasks, encapsulates details speech processing frees developers data engineering. It easy use extend. The contributions work follows: % \method provides straightforward preprocessing several publicly available audio datasets, encourages researchers concentrate innovating ST technology less aware speech processing. % \method aims ST tasks using end-to-end framework. Moreover, knowledge, pioneer community, follows Kaldi~ style data processing recipes. But \method, stand perspective natural language processing~."," \method is an open-source toolkit for neural speech translation developed by Bytedance AI Lab.  The toolkit mainly focuses on end-to-end speech translation, which is easy to use, modify, and extend to advanced speech translation research and products.   \method aims at facilitating the speech translation research for NLP researchers and provides a complete setup for speech translation benchmarks, including feature extraction, data preprocessing, distributed training, and evaluation.  Moreover, The toolkit implements several major architectures for end-to-end speech translation. It shows experimental results for different benchmark datasets, which can be regarded as reliable baselines for future research. The toolkit is publicly available at \url{https://github.com/bytedance/neurst}."
"Query reformulation paraphrase generation techniques employed variety purposes natural language processing , dialogue generation , machine translation , especially question answering systems . Generating coherent clean texts reduce potential errors downstream systems. In cases users receiving end NLP pipelines, essential show fluent human-like languages lose faith recede requiring human agents sake better understanding communication. In search question answering systems, query reformulation aims paraphrase restructure original question sequences, transforming ones interpretable natural well-formedness grammar semantics. Typically, users may patience input entirely grammatical coherent question, cause issues downstream components understand give accurate predictions answers. When human representatives present, originally noisy query question reiterated rephrased double-check users asking for. This costly operation every convoluted question needs restated. By NLP model reformulate input queries, reformulations fed back users confirm original intentions automated way. As result, unnecessary errors eliminated noises prevented propagating NLP pipeline, contain series models intent classification, information retrieval question answering. Traditionally, rule-based statistical methods studied paraphrase reformulation generation . The advent sequence-to-sequence learning made feasible train deep neural networks new paradigm. We investigate paraphrase denoise queries generate well-formed reformulations using Seq2Seq learning models LSTMs transformers . Following framework AQA , Seq2Seq model pre-trained supervised tasks tuned using reinforcement learning machine comprehension QA dataset SearchQA , learning pre-trained BiDAF QA system generates rewards. SearchQA suitable challenging dataset queries contain noisy phrases associated contexts concatenated web text snippets Google's search engine. Our goal obtain model generate better-formed reformulations based original query sequences achieve good QA performance reformulations. We use transfer learning pre-trained transformers text-to-text task formulations . In approach, pre-trained T5 models first fine-tuned paraphrase generation denoising datasets gain general paraphrasing capabilities. Then, reinforcement learning downstream QA rewards performed encouraged model produce task-specific reformulations. To knowledge, first attempt fine-tune text-to-text transformers RL, nudging model generate reward-acquiring query trajectories get better answers. We show fine-tuned text-to-text transformers better starting points RL sample efficient achieving level QA performance, acquiring rewards faster previous AQA approach uses translation-based LSTMs. T5 models also generate reformulations better readability generalize out-of-sample data. We provide new way evaluate fluency sequence level using trained metric well-formedness dataset, based real evaluations humans, reliable source widely-used algorithmic metrics based overlapping n-grams."," Query reformulation aims to alter potentially noisy or ambiguous text sequences into coherent ones closer to natural language questions. In this process, it is also crucial to maintain and even enhance performance in a downstream environments like question answering when rephrased queries are given as input. We explore methods to generate these query reformulations by training reformulators using text-to-text transformers and apply policy-based reinforcement learning algorithms to further encourage reward learning. Query fluency is numerically evaluated by the same class of model fine-tuned on a human-evaluated well-formedness dataset. The reformulator leverages linguistic knowledge obtained from transfer learning and generates more well-formed reformulations than a translation-based model in qualitative and quantitative analysis. During reinforcement learning, it better retains fluency while optimizing the RL objective to acquire question answering rewards and can generalize to out-of-sample textual data in qualitative evaluations. Our RL framework is demonstrated to be flexible, allowing reward signals to be sourced from different downstream environments such as intent classification."
"% % The following footnote without marker needed camera-ready % version paper. % Comment instructions uncomment 8 lines % ""final paper"" variant English. % %. % % % final paper: en-us version % % % space normally used marker % This work licensed Creative Commons % Attribution 4.0 International License. % License details: % \url{http://creativecommons.org/licenses/by/4.0/}. %} Relation extraction aims extract relations entities text, distant supervision proposed automatically establishes training datasets assigning relation labels instances mention entities within knowledge bases. However, wrong labeling problem occur various multi-instance learning methods proposed address it. Despite wrong labeling problem, instance distant supervision crawled web pages, informal many noisy words express multiple similar relations. This problem well-handled previous approaches severely hampers performance conventional neural relation extractors. To handle problem, address two challenges: Identifying gathering spotted relation information low-quality instances; Distinguishing multiple overlapped relation features instance. First, significant relation words distributed dispersedly sentence, shown Figure, words marked red brackets represent entities, italic words key expressing relations. For instance, clause ``evan\_bayh son birch\_bayh"" S1 sufficient express relation /people/person/children evan\_bayh birch\_bayh. Salient relation words number dispersedly S1, others excluded clause regarded noise. Traditional neural models difficulty gathering spotted relation features different positions along sequence use Convolutional Neural Network Recurrent Neural Network basic relation encoders, model sequence word word lose rich non-local information modeling dependencies semantic salience. Thus, well-behaved relation extractor needed extract scattered relation features informal instances. Second, instance express multiple similar relations two entities. As shown Figure, Changsha Hunan possess relations /location/location/contains /location/province/capital S2, similar semantics, introducing great challenges neural extractors discriminating clearly. Conventional neural methods effective extracting overlapped relation features, mix different relation semantics single vector max-pooling self-attention. Although first propose attentive capsule network multi-labeled relation extraction, treats CNN/RNN low-level capsules without diversity encouragement, poses difficulty distinguishing different overlapped relation features single type semantic capsule. Therefore, well-behaved relation extractor needed discriminate diverse overlapped relation features different semantic spaces. To address problem, propose novel Regularized Attentive Capsule Network identify highly overlapped relations low-quality distant supervision corpus. First, propose embed multi-head attention capsule network, attention vectors head encapsulated low-level capsule, discovering relation features unique semantic space. Then, improve multi-head attention extracting spotted relation features, devise relation query multi-head attention, selects salient relation words regardless positions. This mechanism assigns proper attention scores salient relation words calculating logit similarity relation representation word representation. Furthermore, apply disagreement regularization multi-head attention low-level capsules, encourages head capsule discriminate different relation features different semantic spaces. Finally, dynamic routing algorithm sliding-margin loss employed gather diverse relation features predict multiple specific relations. We evaluate RA-CapNet using two benchmarks. The experimental results show model achieves satisfactory performance baselines. Our contributions summarized follows:","   Distantly supervised relation extraction has been widely applied in knowledge base construction due to its less requirement of human efforts. However, the automatically established training datasets in distant supervision contain low-quality instances with noisy words and overlapped relations, introducing great challenges to the accurate extraction of relations. To address this problem, we propose a novel Regularized Attentive Capsule Network  to better identify highly overlapped relations in each informal sentence. To discover multiple relation features in an instance, we embed multi-head attention into the capsule network as the low-level capsules, where the subtraction of two entities acts as a new form of relation query to select salient features regardless of their positions. To further discriminate overlapped relation features, we devise disagreement regularization to explicitly encourage the diversity among both multiple attention heads and low-level capsules. Extensive experiments conducted on widely used datasets show that our model achieves significant improvements in relation extraction."
"Identifying user's open intent plays significant role dialogue systems. As shown Figure, two known intents specific purposes, book flight restaurant reservation. However, also utterances irrelevant unsupported intents system cannot handle. It necessary distinguish utterances known intents much possible. On one hand, effectively identifying open intent improve customer satisfaction reducing false-positive error. On hand, use open intent discover potential user needs. We regard open intent classification -class classification task suggested in, group open classes class . Our goal classify n-class known intents corresponding classes correctly identifying class open intent. To solve problem,~\citet{scheirer2013toward} propose concept open space risk measure open classification.~\citet{fei-liu-2016-breaking} reduce open space risk learning closed boundary positive class similarity space. However, fail capture high-level semantic concepts SVM. ~\citet{bendale2016towards} manage reduce open space risk deep neural networks , need sample open classes selecting core hyperparameters.~\citet{hendrycks17baseline} use softmax probability confidence score, also need select confidence threshold negative samples.~\citet{Shu2017DOCDO} replace softmax sigmoid activation function, calculate confidence thresholds class based statistics. However, statistics-based thresholds learn essential differences known classes open class.~\citet{lin-xu-2019-deep} propose learn deep intent features margin loss detect unknown intents local outlier factor. However, specific decision boundaries distinguishing open intent, needs model architecture modification. Most existing methods need design specific classifiers identifying open class perform poorly common classifier. Moreover, performance open classification largely depends decision conditions. Most methods need negative samples determining suitable decision conditions. It also complicated time-consuming process manually select optimal decision condition, applicable real scenarios. To solve problems, use known intents prior knowledge, propose novel post-processing method learn adaptive decision boundary open intent classification. As illustrated Figure, first extract intent representations BERT model. Then, pre-train model supervision softmax loss. We define centroids known class suppose known intent features constrained closed ball areas. Next, aim learn radius ball area obtain decision boundaries. Specifically, initialize boundary parameters standard normal distribution use learnable activation function projection get radius decision boundary. The suitable decision boundaries satisfy two conditions. On one hand, broad enough surround in-domain samples much possible. On hand, need tight enough prevent out-of-domain samples identified in-domain samples. To address issues, propose new loss function, optimizes boundary parameters balancing open space risk empirical risk. The decision boundaries automatically learn adapt intent feature space balance boundary loss. We find post-processing method still learn discriminative decision boundaries detect open intent even without modifying original model architecture. We summarize contribution follows. Firstly, propose novel post-processing method open classification, need prior knowledge open class. Secondly, propose new loss function automatically learn tight decision boundaries adaptive feature space. To best knowledge, first attempt adopt deep neural networks learn adaptive decision boundary open classification. Thirdly, extensive experiments conducted three challenging datasets show approach obtains consistently better robust results compared state-of-the-art methods. \end{table*}"," 		Open intent classification is a challenging task in dialogue systems. On the one hand, we should ensure the classification quality of known intents. On the other hand, we need to identify the open  intent during testing. Current models are limited in finding the appropriate decision boundary to balance the performances of both known and open intents. In this paper, we propose a post-processing method to learn the adaptive decision boundary  for open intent classification. We first utilize the labeled known intent samples to pre-train the model. Then, we use the well-trained features to automatically learn the adaptive spherical decision boundaries for each known intent. Specifically, we propose a new loss function to balance both the empirical risk and the open space risk. Our method does not need open samples and is free from modifying the model architecture. We find our approach is surprisingly insensitive with less labeled data and fewer known intents. Extensive experiments on three benchmark datasets show that our method yields significant improvements compared with the state-of-the-art methods.\footnote{Code: https://github.com/thuiar/Adaptive-Decision-Boundary}"
"Recently, deep contextual language models shown effective modeling ability text, achieving state-of-the-art results series NLP tasks. These models capture syntactic semantic information input text, generating fine-grained contextual embeddings, easily applied downstream models. Despite success large scale pre-trained language models various tasks, less clear extend semantic parsing tasks text-to-SQL, requires joint reasoning natural language utterance structured database schema information. Recent work shows powerful pre-trained language models, highly domain-specific semantic parsers improved, even though language models trained pure text encoding. % % \end{table}% However, based error analysis output neural language model-based text-to-SQL systems, observe models enhanced could mitigate following three pain points, also illustrated Table. The model ineffective match detect column names utterances. The model learn detect column names mentioned utterances matching utterance tokens schema, use matched columns generated SQL. The error analysis indicates that, cases, models miss columns synthesizing target SQL, column mentioned explicitly utterance. The model fails infer columns implicitly cell values. This problem trickier first one, model expected infer column name based cell values mentioned utterance, instead matching utterance tokens schema. This requires model domain knowledge. For example, presented second section Table, model know . The model learn compose complex queries. Besides column selection, generate correct SQL, model learn attach selected columns correct clauses. This non-trivial task, especially target SQL complex, e.g., query nested. As shown last section Table, model learn use corresponding column nested SQL, instead using column . Recent work demonstrated jointly pre-training utterances table contents benefit downstream tasks table parsing semantic parsing . These models pre-trained using Masked Language Modeling task either masking tokens utterance input tokens schema input. However, learning objective model alignment utterance schema implicitly. We hypothesize that, order cope three pain points previously listed, necessary use pre-training objectives enforce learning contextual representations better capture alignment utterances schema/table contents. In work, present language model pre-training framework, Generation-Augmented Pre-training~, exploits multiple learning objectives synthetic data generation jointly learn contextual representations natural language utterances table schema. We propose following three new learning objectives enforce joint learning also improve ability model grasp domain knowledge, helpful cross-domain scenarios: column prediction task, pre-training task consists giving label column input schema decide whether used input utterance not. This task intent improve column detection ability model. column recovery task, consists randomly replacing column names one cell values asking model recover original column name either based cell value based contextual information utterance column explicitly mentioned utterance. This learning objective meant enhance column inferring ability model. SQL generation, consists generating SQL queries given utterances schema. This task boost ability model compose complex queries leveraging large scale SQL datasets Web.%, Github. A key challenge use proposed pre-training tasks training data. Although easy obtain large scale datasets crawled tables SQL queries, difficult obtain high-quality utterances interrelated tables logically consistent crawled SQL queries. Recent work used surrounding text tables proxy natural language utterances. However, option far optimal texts dissimilar user utterances terms text length, composition content. The surrounding text table usually paragraph, natural language utterances downstream task short sentences. Furthermore, content surrounding text tables quite noisy text may irrelevant table. In \modelname, overcome pre-training data challenge use synthetic data. We propose two sequence-to-sequence generative models, SQL-to-text table-to-text, produce large scale datasets enough quality pre-training. We train generative models finetuning BART, state-of-the-art pre-trained language model. Concurrently,~\citet{yu2020grappa} and~\citet{deng2020structure} utilized synthetic data generated synchronized context-free grammar existing data-to-text datasets pre-training, respectively, requires extra crowd expert annotation efforts. The outcome \modelname pre-trained model plugged neural semantic parsers compute contextual representations utterances schema. We apply \modelname text-to-SQL semantic parsing datasets, experimental results show systems augmented \modelname~outperform state-of-the-art semantic parsers Spider Criteria-to-SQL datasets. In summary, work presents following main contributions:","  Most recently, there has been significant interest in learning contextual representations for various NLP tasks, by leveraging large scale text corpora to train large neural language models with self-supervised learning objectives, such as Masked Language Model~. However, based on a pilot study, we observe three issues of existing general-purpose language models when they are applied to text-to-SQL semantic parsers: fail to detect column mentions in the utterances, fail to infer column mentions from cell values, and fail to compose complex SQL queries. To mitigate these issues, we present a model pre-training framework, Generation-Augmented Pre-training~, that jointly learns representations of natural language utterances and table schemas by leveraging generation models to generate pre-train data. \modelnamelm\footnote{This refers to the language models that are pre-trained with GAP framework.} is trained on 2M utterance-schema pairs and 30K utterance-schema-SQL triples, whose utterances are produced by generative models. Based on experimental results, neural semantic parsers that leverage \modelnamelm~as a representation encoder obtain new state-of-the-art results on both Spider and Criteria-to-SQL benchmarks."
"Neural Machine Translation yields state-of-the-art translation performance large number parallel sentences available. However, parallel corpora available majority language pairs domains. It known NMT perform well specific domains domain-specific corpora limited, medical domain. As such, high-quality domain-specific machine translation systems high demand whereas general purpose MT limited applications. There many studies domain adaptation NMT, mainly divided two categories: data-centric model fine-tuning. Data-centric methods focus selecting generating target domain data general domain corpora, effective well explored. In paper, focus second approach. Fine-tuning common domain adaptation, first trains base model general domain data fine-tunes target domain . However, unconstrained full fine-tuning requires careful hyper-parameter tuning, prone over-fitting target domain well forgetting general domain. To tackle problems, researchers proposed several constructive approaches, view limiting size plasticity parameters fine-tuning stage, roughly divided two categories: regularization partial-tuning strategy. Regularization methods often integrate extra training objectives prevent parameters large deviations, model output regularization , elastic weight consolidation . Regularization methods, impose arbitrary global constraints parameter updates, may restrict adaptive process network, especially domain-specific corpora scarce. Partial-tuning methods either freeze several sub-layers network fine-tune others, integrate domain-specific adapters network. By fine-tuning domain-specific part model, alleviate over-fitting forgetting problem fine-tuning. However, structure designed adapting usually hand-crafted, relies experienced experts adapter brings additional parameters. Therefore, adaptive, scalable, parameter-efficient approach domain adaptation valuable worth well studying. In paper, propose \method, novel domain adaptation method via adaptive structure pruning. Our motivation inspired Continual Learning lottery hypothesis randomly-initialized, dense neural network contains sub-network match test accuracy original network training number iterations. We therefore suppose multiple machine translation models different domains share different sparse subnetworks within single neural network. Specifically, first apply standard pruning technique automatically uncover subnetwork well-trained NMT model general domain. The subnetwork capable reducing parameter without compromising accuracy. Therefore, potential keep much general information possible. Then freeze informative sparse network leave unnecessary parameters unfixed target domain, enables approach parameter efficient, eases scalability approach domains. The capacity non-fixed parameters tuned match requirements target domain, keeping parameters general domain. Our method successfully circumvents catastrophic forgetting problem retains quality general domain. As benefits flexible design, \method easily extended transfer learning problems, multilingual machine translation. We summarize main contribution follows: % --------------------Background--------------------"," Fine-tuning is a major approach for domain adaptation in Neural Machine Translation .  However, unconstrained fine-tuning requires very careful hyper-parameter tuning otherwise it is easy to fall into over-fitting on the target domain and degradation on the general domain.  To mitigate it, we propose \method, a novel domain adaptation method via gradual pruning.  It learns tiny domain-specific subnetworks for tuning. During adaptation to a new domain, we only tune its corresponding subnetwork.  \method alleviates the over-fitting and the degradation problem without model modification. Additionally, with no overlapping between domain-specific subnetworks, \method is also capable of sequential multi-domain learning.    Empirical experiment results show that \method outperforms several strong competitors in the target domain test set without the quality degradation of the general domain in both single and multiple domain settings. \footnote{The source code and data are available at \url{https://github.com/ohlionel/Prune-Tune}}"
"As important task dialogue system, response selection aims find best matched response set candidates given context conversation. The retrieved responses usually natural, fluent diverse expressions rich information owing abundant resources. Therefore, response selection widely used industry attracted great attention academia. Most existing studies task pay attention matching problem utterances responses, insufficient concern reasoning issue multi-turn response selection. Just recently, MuTual, first human-labeled reasoning-based dataset multi-turn dialogue, released promote line research. Reasoning quite different matching conversations. Specifically, matching focuses capturing relevance features utterances responses, reasoning needs identify key features , also needs conduct inference based clue words. The challenges new task include: identify clue words utterances, fundamental inference; conduct inference according clue words utterances. Figure illustrates motivating example. To infer current time, must first identify clue words `10:45' `15 minutes' . Then must conduct logical inference based clue words . To tackle challenges, first, need better contextual representation identifying clue words conversations. This clue word identification inevitably relies context conversation. Although previous literature publications achieved promising results context modeling, still several limitations approaches. More concretely, existing studies either concatenate utterances form context process utterance independently, leading loss dependency relationships among utterances important contextual information. It validated chronological dependency utterances, well semantical dependency utterances, crucial multi-turn response selection. Thus, model dependencies utterances remains challenging problem context representation. Second, need devise new strategy collect clue words scattered multiple utterances need reason according clue words. In recent years, witnessed great success KBQA MRC tasks. However, new obstacles emerge transferring current reasoning approaches KBQA MRC conversational reasoning. A clear reasoning path based entities well-structured knowledge base exists KBQA, similar reasoning path utterances. Current approaches MRC conduct inference based graph taking shared entities nodes, difficult construct graphs based entities short utterances, usually suffer greater coreference resolution, poor content serious semantic omission problems comparison document text. In paper, propose new model named GRN tackle challenges end-to-end way. We first introduce two pre-training tasks called NUP UOP specially designed response selection. NUP endows GRN context-aware ability semantical dependency, UOP facilitates GRN ability capture chronological dependency. These customized pre-training methods beneficial modeling dependencies contained utterances achieve better context representation. We perform task-adaptive pre-training combined NUP UOP tasks based ALBERT model. To conduct reasoning based clue words, devise graph neural network called UDG , models dependencies utterances utterance node also collects clue words different utterances. Reasoning achieved propagating messages clue words nodes along various utterance paths UDG, graph reasoning structure realizes inference based utterance-level context vector local perspective. On hand, also implement reasoning network output trained model self-attention mechanism. This sequence reasoning structure realizes inference based highly summarized context vector global perspective. To summarize, make following contributions:"," We investigate response selection for multi-turn conversation in retrieval-based chatbots. Existing studies pay more attention to the matching between utterances and responses by calculating the matching score based on learned features, leading to insufficient model reasoning ability. In this paper, we propose a graph reasoning network  to address the problem. GRN first conducts pre-training based on ALBERT using next utterance prediction and utterance order prediction tasks specifically devised for response selection. These two customized pre-training tasks can endow our model with the ability of capturing semantical and chronological dependency between utterances. We then fine-tune the model on an integrated network with sequence reasoning and graph reasoning structures. The sequence reasoning module conducts inference based on the highly summarized context vector of utterance-response pairs from the global perspective. The graph reasoning module conducts the reasoning on the utterance-level graph neural network from the local perspective. Experiments on two conversational reasoning datasets show that our model can dramatically outperform the strong baseline methods and can achieve performance which is close to human-level."
"A disease abnormal medical condition poses negative impact organisms enabling access disease information goal various information extraction well text mining tasks. The task disease normalization consists assigning unique concept identifier disease names occurring clinical text. However, task challenging diseases mentioned text may display morphological orthographical variations, may utilize different word orderings equivalent words. Consider following examples: %} \end{center} In Example 1, disease mention short trunk extremities mapped candidate Knowledge Base entry containing synonyms like Growth Disorder. In Example 2, Renal amyloidosis assigned Knowledge Base ID synonyms as, Amyloidosis 8. Based studies analysis medical literature, observed disease name may occur multiple variant forms as. synonyms replacement , spelling variation , short description modifier precedes disease name , different word orderings . In paper, formulated task learning mention-candidate pair similarity using Triplet Networks . Furthermore, explored in-domain word\footnote{http://evexdb.org/pmresources/vec-space-models/} subword embeddings input representations. We find sub-word information boosts performance due gained information out-of-vocabulary terms word compositionality disease mentions. The primary contributions paper three-fold: 1) By identifying positive negative candidates concerning disease mention, optimize Triplet Network loss function influences relative distance constraint 2) We explored capability in-domain sub-word level information\footnote{https://github.com/ncbi-nlp/BioSentVec.git} solving task disease normalization. 3) Unlike existing systems , , present robust portable candidate generation approach without making use external resources hand-engineered sieves deal morphological variations. Our system achieves state-of-the-art performance NCBI disease dataset","   Entity linking  is an essential task in text mining that maps the entity mentions in the medical text to standard entities in a given Knowledge Base . This task is of great importance in the medical domain. It can also be used for merging different medical and clinical ontologies. In this paper, we center around the problem of disease linking or normalization. This task is executed in two phases: candidate generation and candidate scoring. In this paper, we present an approach to rank the candidate Knowledge Base entries based on their similarity with disease mention. We make use of the Triplet Network for candidate ranking. While the existing methods have used carefully generated sieves and external resources for candidate generation, we introduce a robust and portable candidate generation scheme that does not make use of the hand-crafted rules. Experimental results on the standard benchmark NCBI disease dataset demonstrate that our system outperforms the prior methods by a significant margin."
"As fundamental task natural language processing , coherence analysis benefit various downstream tasks, sentiment analysis document summarization . Rhetorical Structure Theory one influential theories text coherence, document represented hierarchical discourse tree, consists set semantic units organized form dependency structure, labeled rhetorical relations. As shown Figure , leaf nodes RST discourse tree basic text spans called Elementary Discourse Units , EDUs iteratively connected rhetorical relations form larger text spans entire document included. The rhetorical relations categorized Nucleus Satellite based relative importance, Nucleus corresponds core part Satellite corresponds subordinate part. While manual coherence analysis RST theory labor-intensive requires specialized linguistic knowledge, discourse parser serves automatically transform document discourse tree. Document-level discourse parsing consists three sub-tasks: hierarchical span splitting, rhetorical nuclearity determination, rhetorical relation classification. Models RST-style discourse parsing made much progress past decade. While statistical methods utilize hand-crafted lexical syntactic features , data-driven neural approaches reduce feature-engineering labor effective representation learning, capable characterizing implicit semantic information. Neural networks first used feature extractors along traditional shift-reduce approaches dynamic programming approaches . Then, \citet{yu2018transition} bridges gap neural traditional methods end-to-end transition-based neural parser via encoder-decoder architecture. Recently, pointer networks introduced achieve linear-time complexity, models top-down parsing procedures achieve favorable results sentence-level discourse analysis tasks . However, still much space improvement document-level discourse parsing. First, compared sentence-level parsing, document-level parsing challenging due deeper tree structures longer dependencies among EDUs: benchmark dataset RST Discourse Tree Bank , average EDU number document level 56, 20 times larger sentence-level parsing. Thus modeling context information across long span essential, especially considering top-down parsing procedure poor accuracy top tree propagate toward leaf nodes. Second, three sub-tasks discourse parsing strongly rely nuanced semantic judgments, require comprehensive contextual representation various types linguistic information. Take discourse relation classification example, explicit relations overtly signaled connective word ``although'' ``because'', determined lexical syntactic features. However, approach readily adapted implicit discourse relations determination, requires high-order features semantic information. Moreover, compensate lack large-scale corpora, prior work neural modeling leveraged inductive biases syntactic features part-of-speech tagging improve performance. However, models still suffer insufficient linguistics information lack data, thus incapable acquiring deeper richer contextual representations useful discourse processing. In paper, tackle aforementioned challenges, propose document-level neural discourse parser robust representation modeling EDU document level, based top-down parsing procedure. To take advantage widely-adopted vector representations encode rich semantic information, first exploit large-scale pre-trained language model contextual representation backbone. Then incorporate boundary information implicit semantic syntactic features EDU representations, introduce hierarchical encoding architecture comprehensively characterize global information long dependency modeling. To improve inference accuracy alleviate aforesaid error propagation problem, present breadth-first span splitting propose layer-wise beam search algorithm. We train evaluate proposed model benchmark corpus RST-DT\footnote{https://catalog.ldc.upenn.edu/LDC2002T07} , achieve state-of-the-art performance fronts, significantly surpassing previous models approaching upper bound human performance. We also conduct extensive experiments analyze effectiveness proposed method."," Document-level discourse parsing, in accordance with the Rhetorical Structure Theory , remains notoriously challenging. Challenges include the deep structure of document-level discourse trees, the requirement of subtle semantic judgments, and the lack of large-scale training corpora. To address such challenges, we propose to exploit robust representations derived from multiple levels of granularity across syntax and semantics, and in turn incorporate such representations in an end-to-end encoder-decoder neural architecture for more resourceful discourse processing. In particular, we first use a pre-trained contextual language model that embodies high-order and long-range dependency to enable finer-grain semantic, syntactic, and organizational representations. We further encode such representations with boundary and hierarchical information to obtain more refined modeling for document-level discourse processing. Experimental results show that our parser achieves the state-of-the-art performance, approaching human-level performance on the benchmarked RST dataset."
"Due substantial growth effortless access Internet recent years, enormous amount unstructured textual contents generated. It crucial task organize structure voluminous unstructured text manually. Thus, automatic classification useful manipulate huge amount texts, extract meaningful insights save lot time money. Text categorization classical NLP problem aims categorize texts organized groups. It wide range applications like machine translation, question answering, summarization, sentiment analysis. There several approaches available classify texts according labels. However, deep learning method outperforms rule-based machine learning-based models ability capture sequential semantic information texts . We propose classifier using CNN , BiLSTM classify technical texts computer science domain. Furthermore, sequentially adding networks, remarkable accuracy several shared classification tasks obtained. The rest paper organized follows: related work given section 2. Section 3 describes dataset. The framework described section 4. The findings presented section 5. %%%%%%%%%%%% Related Work %%%%%%%%%"," This paper illustrates the details description of technical text classification system and its results that developed as a part of participation in the shared task TechDofication 2020. The shared task consists of two sub-tasks:  first task identify the coarse-grained technical domain of given text in a specified language and  the second task classify a text of computer science domain into fine-grained sub-domains. A classification system  is developed to perform the classification task using three techniques: convolution neural network , bidirectional long short term memory  network, and combined CNN with BiLSTM. Results show that CNN with BiLSTM model outperforms the other techniques concerning task-1 of sub-tasks  and task-2a. This combined model obtained $f_1$ scores of 82.63 , 81.95 , 82.39 , 84.37 , and 67.44  on the development dataset. Moreover, in the case of test set, the combined CNN with BiLSTM approach achieved that higher accuracy for the subtasks 1a , 1b , 1c , 1g  and 2a ."
"The traditional task-oriented dialogue systems, focuses providing information performing actions given databases APIs, often meet limitation DB/API cover enough necessary cases. A good enhance achieved lots relevant domain knowledge form descriptions, FAQs customer reviews, call unstructured knowledge. Track 1 9th Dialogue System Technology Challenges , Beyond Domain APIs: Task-oriented Conversational Modeling Unstructured Knowledge Access, aims generating response based dialogue history unstructured knowledge access. The whole task divided three subtasks, knowledge-seeking turn detection, knowledge selection knowledge-grounded response. Test set track includes seen unseen parts. The unseen test set collected different domains, entities, locales, aiming evaluate models' generalization ability. Knowledge-seeking turn detection, first subtask, needs determine whether related knowledge contained unstructured knowledge base. In words, subtask modeled binary classification problem. If model predicts exists related knowledge, subtask 2 search relevant knowledge snippets pass generation process . If model predicts related knowledge specific question, remaining two subtasks performed. In paper, first conduct entity matching question add domain label matching results end dialogue history model input. Knowledge selection retrieve relevant knowledge snippets database according dialogue history provide information subsequent response generation. The dialogue history conversation human speaker machine. Close end conversation, human speaker brings question certain place service . The given knowledge database consists question-answer pairs involving diverse facts organized different domains entities. % Note knowledge-seeking turn detection model determines whether dialog system needs access knowledge database generating response. % We perform knowledge selection samples requires relevant knowledge database. The retrieved knowledge snippets provide information subsequent response generation. % Information retrieval techniques widely applied search related candidates retrieval-based knowledge-grounded system. Some researchers compute traditional tf-idf score search relevant document user's query, others leverage power neural networks learn ranking score directly end-to-end learning process. Recently, due significant improvements numerous natural language processing tasks, large scale pre-trained language models also applied better model semantic relevance knowledge selection. In paper, first apply retrieval techniques narrow searching space use neural network initialized pre-trained model formulate ranking function. % We propose two base models knowledge selection, final ensemble model combines predictions different base models improve selection performance. % The Retrieve \& Rank model first gathers knowledge snippets potentially relevant entities knowledge base, ranking model trained select plausible knowledge snippets retrieved candidates. % Different Retrieve \& Rank model, Three-step model divides ranking model three cascade parts rank domain, entity documents respectively order force model take knowledge hierarchy account. % We also ensemble two models together experiments show ensemble model better performance two base model separately. % briefly introduce three-step pipeline model. Knowledge-grounded response generation requests give response automatically model using dialogue history unstructured knowledge input. There two different types dialogue systems, retrieval-based system, generation-based system. Retrieval-based dialogue system, giving responses list candidate sentences, fixed answer forms candidate sets. To deal problem, needs flexible natural responses, generation-based model better choice. Dialogue generation requires encoder represent input decoder generate response. The network often needs minimize cross-entropy loss output ground truth. In paper, use latent variable encode dialog history selected knowledge better generate responses combined copy mechanism. % Pre-trained language models make great progress dialogue generation. Note bi-directional model designed dialogue generation task, thus PLATO PLATO-2 use uni- bi-directional processing pre-training. Moreover, large-scale Reddit Twitter conversations utilized pre-train generation model reduce data distribution gaps. Furthermore, latent variable used capture one-to-many relations post-response pairs. As shown released evaluation results, proposed system ranks second objective metrics ranks fourth human metrics. In following sections, explain details proposed model. Experiment results shown next analysis conclusions."," Task-oriented conversational modeling with unstructured knowledge access, as track 1 of the 9th Dialogue System Technology Challenges , requests to build a system to generate response given dialogue history and knowledge access. This challenge can be separated into three subtasks,  knowledge-seeking turn detection,  knowledge selection, and  knowledge-grounded response generation. We use pre-trained language models, ELECTRA and RoBERTa, as our base encoder for different subtasks. For subtask 1 and 2, the coarse-grained information like domain and entity are used to enhance knowledge usage. For subtask 3, we use a latent variable to encode dialog history and selected knowledge better and generate responses combined with copy mechanism. Meanwhile, some useful post-processing strategies are performed on the model's final output to make further knowledge usage in the generation task.  As shown in released evaluation results, our proposed system ranks second under objective metrics and ranks fourth under human metrics."
"% Recent years witnessed rapid advancement online recruitment platforms. With increasing amount online recruitment data, interview related studies emerged person-job fit automatic analysis asynchronous video interviews , aim enable automated job recommendation candidate assessment. Among studies, person-job fit casting task supervised text match problem. Given set labeled data , aims predict matching label candidate resumes job description. More recently, deep learning enhanced person-job fit methods training effective text match text representations models. AVI determine whether candidate hirable evaluating answers interview questions. In AVIs, interview usually considered sequence questions answers containing salient socials signals. To evaluate candidates comprehensively, AVI models extract features video , text, voice process answering questions. In work, focus scoring multiple QA pairs, extract features text modality define task scoring competency candidates rather score whether employed. Based anatomy human interviewers' evaluation process, solutions consist two stages: analyzing evaluating individual QA pair one one, acquiring evaluation status, grading competency candidate based evaluation status multiple QA pairs. For first stage, existing methods tend employ text matching attentional text matching algorithms evaluate QA pairs, feeds concatenated representation question answer subsequent classifier. As know, questions asynchronous video interview limited specific domains. That say, candidates answer questions according work study experience. In way, candidates' answers varied difficult evaluate answer accurately text matching. Intuitively, reasonable evaluate QA pairs semantic interaction questions answers. A critical challenge along line reveal latent relationships question answer. %Intuitively, experienced interviewers could discover semantic-level correlation interview questions candidates' answers, obtain preliminary judgement answer current question, finally give assessment based judgements several problems. Therefore, %In work, propose sentence-level reasoning GNN assess single QA pair semantic interaction level. Graph neural networks learn effective representation nodes encoding local graph structures node attributes. Due compactness model capability inductive learning, GNNs widely used modeling relational data logical reasoning. Recently, ~\citet{zhang2020efficient} proposed GNN variant, Named ExpressGNN, strike nice balance representation power simplicity model probabilistic logic reasoning.~\citet{ghosal2019dialoguegcn} constructed DialogeGCN address context propagation issues present RNN-based methods. Specifically, leverage self inter-speaker dependency interlocutors model conversational context emotion recognition. Inspired by, present sentence-level relational GCN represent internal temporal QA interaction dependency process answering questions. %Recently, graph neural network graph emebedding attracted wide attention. Graph neural networks effective tasks thought rich relational structure preserve global structure information graph graph emebedding. %In work, aim address task automatically scoring textual answer candidates semantic interaction level. %The automatic short answer scoring task estimating score short text answer written response given prompt basis whether answer satisfies rubrics prepared human advance. ASAS systems mainly constructed markedly reduce scoring cost human rater. %鐟欏嫬鍨鍫ユ閸掕泛鐣鹃敍灞芥礈濮濄倕顕梻顕顣介崪灞芥礀缁涙棃妫跨拠顓濈疅娴溿倓绨伴惃鍕閹烘ɑ妯夊妤佹纯閸旂娀鍣哥憰 %閸ョ偓膩閸ㄥ婀梻顕顣介幒銊ф倞娴犺濮熸稉濂僥ep learning proven effective long text NLP tasks. Due lack information short sentence ASAS corpus, seems good enough ASAS task. For second stage grading candidate, based representation QA pairs, exists methods prefer encoder question-answer pairs sequence directly. However, kind approaches lead insufficient interaction semantic information question answer pairs. Therefore, difficult ensure rationality explainability evaluation. To mitigate issue, first stage, present semantic-level graph attention network model interaction states QA session. %Automatic scoring answer transcriptions job interview aims evaluate multiple question-answer pairs. %To alleviate limitation previous approaches, To end, propose Hierarchical Reasoning Graph Neural Network automatic scoring answer transcriptions job interviews. Specifically, proposed sentence-level relational graph convolutional neural network used capture contextual dependency, semantic-level Reasoning graph attention network applied acquire latent interaction states. And contribution work summarized follows:"," %Automatic scoring of answer transcripts in job interview aims to evaluate multiple question-answer pairs. The key challenge is how to conduct deep interaction on the semantic level for each question-answer pair, and give the evaluation results combined with multiple interaction states. Recent studies either use text matching approaches to evaluate each question-answer pair roughly, or employ the sequential model to deal with disordered question-answer pairs which fail to take advantages of the semantic association between questions and answers, and the logical connection between question-answer pairs. In this work, we propose a hierarchical reasoning Graph Neural Network  for the automatic assessment of multi-question answering. Specifically, we construct a sentence-level reasoning GNN to assess the single question-answer pair. Based on these graphs, we propose a document-level reasoning GNN to model the interaction states of question-answer pairs. The first module utilizes each sentence in the question and answer to establish the connection between them. The second module adopts a graph convolutional network to encoder interaction states of each pair and aggregates evidence with graph attention mechanism for predicting the final score. Empirical results on Chinese and English interview datasets show that our proposed model outperforms both sequence-based and pre-training based  benchmark models.  %We address the task of automatically scoring the answer competency of candidates based on textual features from the automatic speech recognition transcriptions. The key challenge is how to conduct deep interaction on the semantic level for each question-answer  pair, and give the evaluation results combined with multiple interaction states. Recent studies either use text matching approaches to evaluate each QA pair roughly, or employ the sequential model to deal with disordered QA pairs which fail to take advantages of the semantic association between questions and answers, and the logical connection between QA pairs. In this work, we propose a hierarchical reasoning Graph Neural Network  for the automatic assessment of question-answer pairs. Specifically, we construct a sentence-level reasoning GNN to assess the single QA pair. Based on these graphs, we propose a document-level reasoning GNN to model the interaction states of QA pairs. The first module utilizes each sentence in the question and answer to establish the connection between them. The second module adopts a graph convolutional network to encoder interaction states of each pair and aggregates evidence with graph attention mechanism for predicting the final score. Empirical results conducted on CHNAT and ENGIAT  clearly validate that our proposed model outperforms both text matching based benchmark models.  %We address the task of automatically scoring the competency of candidates based on textual features, from the automatic speech recognition  transcriptions in the video job interview. The key challenge is how to conduct deep interaction on the semantic level for each question-answer  pair, and then give the evaluation results combined with multiple interaction states. Recent studies tend to use text matching approaches to evaluate each QA pair roughly, which fails to take advantage of the semantic association between questions and answers. In this work, we propose a Hierarchical Reasoning Graph Neural Network  for the automatic assessment of question-answer pairs. Specifically, we construct a sentence-level relational graph neural network to capture the latent semantic interaction of sentences in the question or the answer. Based on these graphs, we employ a semantic-level reasoning graph attention network to model the interaction states of the current QA session. Finally, we propose a gated recurrent unit with a global fusion mechanism to aggregates evidence of temporal QA pairs for the final score. Empirical results conducted on CHNAT  clearly validate that our proposed model significantly outperforms text-matching based benchmark models. Ablation studies and experimental results with 10 random seeds also show the effectiveness and stability of our models.    We address the task of automatically scoring the competency of candidates based on textual features, from the automatic speech recognition  transcriptions in the asynchronous video job interview . The key challenge is how to construct the dependency relation between questions and answers, and conduct the semantic level interaction for each question-answer  pair. However, most of the recent studies in AVI focus on how to represent questions and answers better, but ignore the dependency information and interaction between them, which is critical for QA evaluation. In this work, we propose a Hierarchical Reasoning Graph Neural Network  for the automatic assessment of question-answer pairs. Specifically, we construct a sentence-level relational graph neural network to capture the dependency information of sentences in or between the question and the answer. Based on these graphs, we employ a semantic-level reasoning graph attention network to model the interaction states of the current QA session. Finally, we propose a gated recurrent unit encoder to represent the temporal question-answer pairs for the final prediction. Empirical results conducted on CHNAT  validate that our proposed model significantly outperforms text-matching based benchmark models. Ablation studies and experimental results with 10 random seeds also show the effectiveness and stability of our models."
"Social media unique source information. On one hand, low cost, easy access distribution speed make possible quickly share news. On hand, quality reliability social media news difficult verify . This source lot false information negative impact society. Over past year, world watching situation developing around novel coronavirus pandemic. The COVID-19 pandemic become significant newsworthy event 2020. Therefore, news related COVID-19 actively discussed social media topic generates lot misinformation. Fake news related pandemic large-scale negative social consequences, provoke huge public rumor spreading misunderstanding COVID-19 aggravate effects pandemic. Moreover, recent studies show increase symptoms anxiety depression connection pandemic. This closely related spread misinformation, fake news successful population experiencing stressful psychological situation . The popularity fake news social media rapidly increase, rebuttal always published late. In regard, evidence development tools automatic COVID-19 fake news detection plays crucial role regulation information flows. In paper, present approach Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection English attracted 433 participants CodaLab. This approach achieved weighted F1-score 98.69 test set among 166 submitted teams total. The rest paper organized follows. A brief review related work given Section 2. The definition task summarized Section 3, followed brief description data used Section 4. The proposed methods experimental settings elaborated Section 5. Section 6 contains results error analysis respectively. Section 7 conclusion."," The COVID-19 pandemic has had a huge impact on various areas of human life. Hence, the coronavirus pandemic and its consequences are being actively discussed on social media. However, not all social media posts are truthful. Many of them spread fake news that cause panic among readers, misinform people and thus exacerbate the effect of the pandemic. In this paper, we present our results at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in English. In particular, we propose our approach using the transformer-based ensemble of COVID-Twitter-BERT  models. We describe the models used, the ways of text preprocessing and adding extra data. As a result, our best model achieved the weighted F1-score of 98.69 on the test set  of this shared task that attracted 166 submitted teams in total.  \keywords{COVID-Twitter-BERT, social media, fake news, ensembling learning, coronavirus, infodemic, text classification}"
"Medical dialogue system aims converse patients inquire additional symptoms beyond self-reports make diagnosis automatically, gained increasing attention . It significant potential simplify diagnostic process relieve cost collecting information patients . Moreover, preliminary diagnosis reports generated MDS may assist doctors make diagnosis efficiently. Because considerable benefits, many researchers devote substantial efforts address critical sub-problems MDS, natural language understanding , dialogue policy learning, dialogue management, make promising progress build satisfactory MDS. Medical dialogue generation , generates responses natural language request additional symptoms make diagnosis, critical MDS rarely studied. Conventional generative dialogue models often employ neural sequence modeling cannot applied medical dialogue scenario directly absence medical knowledge. Recently, large-scale pre-training language models unsupervised corpora achieved significant success. However, fine-tuning large language models medical domain requires sufficient task-specific data learn correlations diseases symptoms. Unfortunately, depicted Fig., large portion diseases instances practice, means newly-coming diseases realistic diagnosis scenario often low-resource conditions. Therefore, highly desirable transfer diagnostic experience high-resource diseases others data scarcity. Besides, existing knowledge-grounded approaches may fail perform transfer well, learn one unified model diseases ignore specificity relationships different diseases. Finally, practice, disease-symptom relations disease may vary evolve along cases, also considered prior works. Contributions. To address challenges, first propose end-to-end dialogue system low-resource medical dialogue generation. This model integrates three components seamlessly, hierarchical context encoder, meta-knowledge graph reasoning network graph-guided response generator. Among them, context encoder encodes conversation hierarchical representations. For MGR, mainly contains parameterized meta-knowledge graph, initialized prior commonsense graph characterizes correlations among diseases symptoms. When fed context information, MGR adaptively evolve meta-knowledge graph reason disease-symptom correlations predict related symptoms patient next response determine disease. Finally, response generator generates response symptoms request guidance meta-knowledge graph. The second contribution develop novel Graph-Evolving Meta-Learning framework transfer diagnostic experience low-resource scenario. Firstly, GEML trains medical dialogue model meta-learning framework. It regards generating responses handful dialogues task learns meta-initialization dialogue model fast adapt task new disease limited dialogues. In way, learnt model initialization contains sufficient meta-knowledge\footnote{We name knowledge ``meta-knowledge"" since obtained meta-training different source diseases.} source diseases serve good model initialization quickly transfer meta-knowledge new disease. More importantly, GEML also learns good parameterized meta-knowledge graph MGR module characterize disease-symptom relationships source diseases. Concretely, meta learning framework, disease, GEML enriches meta-knowledge graph via constructing global-symptom graph online dialogue examples. In way, learnt meta-knowledge graph bridge gap commonsense medical graph real diagnostic dialogues thus fast evolved new target disease. Thanks graph evolving, dialogue model request patients underlying symptoms efficiently thus improve diagnostic accuracy. Besides, GEML also well address real-world challenge disease-symptom correlations could vary along cases, since meta-knowledge graph trainable based collected dialogue examples. Finally, construct large medical dialogue dataset, called Chunyu\footnote{Code dataset released https://github.com/ha-lins/GEML-MDG.}. It covers 15 kinds diseases 12,842 dialogue examples totally, much larger existing CMDD medical dialogue dataset. The challenging benchmark better comprehensively evaluate performance medical dialogue systems. Extensive experimental results datasets demonstrate superiority method state-of-the-arts.","  	 	Human doctors with well-structured medical knowledge can diagnose a disease merely via a few conversations with patients about symptoms. In contrast, existing knowledge-grounded dialogue systems often require a large number of dialogue instances to learn as they fail to capture the correlations between different diseases and neglect the diagnostic experience shared among them. To address this issue, we propose a more natural and practical paradigm, i.e., low-resource medical dialogue generation, which can transfer the diagnostic experience from source diseases to target ones with a handful of data for adaptation. It is capitalized on a commonsense knowledge graph to characterize the prior disease-symptom relations.  	Besides, we develop a Graph-Evolving Meta-Learning  framework that learns to evolve the commonsense graph for reasoning disease-symptom correlations in a new disease, which effectively alleviates the needs of a large number of dialogues. More importantly, by dynamically evolving disease-symptom graphs, GEML also well addresses the real-world challenges that the disease-symptom correlations of each disease may vary or evolve along with more diagnostic cases. Extensive experiment results on the CMDD dataset and our newly-collected Chunyu dataset testify the superiority of our approach  over state-of-the-art approaches.  	Besides, our GEML can generate an enriched dialogue-sensitive knowledge graph in an online manner, which could benefit other tasks grounded on knowledge graph."
"Identifying emotion dialogues one challenging tasks area natural language processing, important building dialogue systems . Though sentiment analysis studied natural language community long time , understanding multiple emotions expressed chats conversations comes relatively harder challenges many reasons. Various individuals may respond differently towards comment. Absence voice modulations facial expressions informal chatting makes difficult capture emotion conversation. This type problem earlier addressed EmoContext EmotionX-2018 . People chatting often take help emojis, figures message contractions reduce effort shorten comments also express emotions better. In case, GIFs play essential role . Often social media users reply GIFs only, without text response. Therefore, understand different emotions associated GIF reply, necessary consider comment relation associated reply. This type problem earlier addressed EmotionX-2019 challenge task predict emotions spoken dialogues chats. The enhanced better expressiveness GIFs comparison popular graphics-based media, emojis emoticons made utilization amazingly mainstream social media significant expansion online human communication motivated introduction EmotionGIF 2020 shared task. \subsection{Problem Description} Given unlabelled tweet reply , challenge recommend possible categories GIF response may belong to. All tweets training set GIF responses tweets text responses well. The task requires return non-empty subset 1-6 categories among 43 possible GIF categories given unlabelled tweet. \end{table*} In paper, develop deep learning framework predicting categories GIF response unlabelled tweet. We build multiple deep neural-based systems, CNN , Bidirectional Gated Recurrent Unit , Bidirectional Long Short Term Memory Networks . We support models attention mechanism emphasizes important parts given input tweet. We combine multiple basic models result couple stacked architectures , finally, report final predictions majority voting-based ensemble method combines developed models. Our proposed frameworks less complex standard transformer models, provide reasonably good results trained using local GPU support conveniently. The rest paper organized follows: Section 2 gives brief description dataset various preprocessing measures applied them. The details proposed methodologies discussed section 3. In Section 4, discuss various experimental details results. Finally, conclude paper section 5."," In this paper, we describe the systems submitted by our IITP-AINLPML team in the shared task of SocialNLP 2020, EmotionGIF 2020, on predicting the category of a GIF response for a given unlabelled tweet.  For the round 1 phase of the task, we propose an attention-based Bi-directional GRU network trained on both the tweet  and their replies  and the given category for its GIF response. In the round 2 phase, we build several deep neural-based classifiers for the task and report the final predictions through a majority voting based ensemble technique. Our proposed models attains the best Mean Recall  scores of 52.92\% and 53.80\% in round 1 and round 2, respectively."
"Machine translation shown exhibit gender bias , several solutions already proposed mitigate . The general gender bias Natural Language Processing mainly attributed data . Several studies show pervasiveness stereotypes book collections , Bollywood films , among many others. As consequence, systems trained data exhibit biases. Among strategies, several studies proposed work data augmentation balance data forcing gender-balanced datasets . In parallel, initiatives focus documenting datasets prioritize transparency. However, data reason biases, recent studies show %algorithms training strategies matter. models trained robust way reduce effects data correlations . In , authors explored available mitigations increasing dropout, resulted improving models reasoned different stereotypes WinoGender examples . The purpose current paper explore Multilingual Neural Machine Translation architecture impact amount gender bias. To answer question, compare MNMT architectures trained data quantify amount gender bias standard WinoMT evaluation benchmark . Results show Language-Specific encoders-decoders exhibit less bias Shared encoder-decoder . Then, analyze visualize MNMT architecture impacts mitigating amplifying bias studying internal workings. We study amount gender information source embeddings encode, see Language-Specific surpasses Shared terms, allowing better prediction gender. Additionally, taking advantage Shared Language-Specific based Transformer , study coefficient variation attention , shows attention span narrower Shared system Language-Specific one. Therefore, context taken account smaller Shared system, causes higher gender bias. %We observe caused using Shared encoder-decoder several languages since pairwise Bilingual systems wider attention span. Given similarities sharing modules parameters across languages Bilingual Language-Specific, characteristic Bilingual systems prevails language-specific architecture. Finally, also manual analysis investigate biases linguistic explanation. %implications gender bias target language linguistic social point view."," Multilingual Neural Machine Translation architectures mainly differ in the amount of sharing modules and parameters among languages. In this paper, and from an algorithmic perspective, we explore if the chosen architecture, when trained with the same data, influences the gender bias accuracy. Experiments in four language pairs show that Language-Specific encoders-decoders exhibit less bias than the Shared encoder-decoder architecture. Further interpretability analysis of source embeddings and the attention shows that, in the Language-Specific case, the embeddings encode more gender information, and its attention is more diverted. Both behaviors help in mitigating gender bias."
"Commonsense question answering recently attractive field requires systems understand common sense information beyond words, normal human beings nontrivial machines. There plenty datasets proposed purpose, instance, CommonsenseQA , CosmosQA , WIQA . Different traditional machine reading comprehension tasks SQuAD NewsQA key information answering questions directly given context paragraph, solving commonsense questions requires comprehensive understanding context relevant common knowledge, reasoning hidden logic them. There varieties knowledge bases meet need, including text corpora like Wikipedia, large-scale knowledge graphs . Recent popular solution resorts external supporting facts knowledge bases evidence, enhance question commonsense knowledge logic reasoning . However, quality supporting facts guaranteed, weak interpretability help question answering. Specifically, current methods mainly two-fold. The first group methods pre-train language models external supporting facts models could remember common knowledge, empirically proven Tandon et al. \shortcite{tandon2019wiqa} Trinh Le \shortcite{trinh2018do}. The second group methods incorporates question knowledge subgraphs paths carry information relation among concepts show multi-hop reasoning process. The structured information typically encoded via graph models GCN , merged question features. Generally, current methods handle evidence brute force, without selection refinement according interpretability supporting facts. But example shown Figure, supporting facts interpret question, regardless semantically related. Thus, need models processing evidence. In paper, introduce new recursive erasure memory network refines candidate supporting fact set. The REM-Net consists three main components: query encoder, evidence generator, novel recursive erasure memory module. Specifically, query encoder pre-trained encoder encodes question. The evidence generator pre-trained generative model produces candidate supporting facts based question. Compared retrieved supporting facts, generated facts provides new question-specific information beyond existing knowledge bases. The REM module refines candidate supporting fact set recursively matching supporting facts question feature space estimate fact's quality. This estimation helps updating question feature supporting fact set. The question feature updated residual term, whereas supporting fact set updated removing low-quality facts. Compared standard attention mechanisms allocate weights supporting facts once, multi-hop operation REM module widens gap much supporting fact contributes question answering number recursive steps features incorporated feature update. Therefore procedure leads refined use given supporting facts. We conduct experiments two commonsense QA benchmarks, WIQA CosmosQA . The experimental results demonstrate REM-Net outperforms current methods, refined supporting facts qualified questions. Our contributions mainly three-fold:"," When answering a question, people often draw upon their rich world knowledge in addition to the particular context. While recent works retrieve supporting facts/evidence from commonsense knowledge bases to supply additional information to each question, there is still ample opportunity to advance it on the quality of the evidence. It is crucial since the quality of the evidence is the key to answering commonsense questions, and even determines the upper bound on the QA systems' performance. In this paper, we propose a recursive erasure memory network  to cope with the quality improvement of evidence. To address this, REM-Net is equipped with a module to refine the evidence by recursively erasing the low-quality evidence that does not explain the question answering. Besides, instead of retrieving evidence from existing knowledge bases, REM-Net leverages a pre-trained generative model to generate candidate evidence customized for the question. We conduct experiments on two commonsense question answering datasets, WIQA and CosmosQA. The results demonstrate the performance of REM-Net and show that the refined evidence is explainable."
"We typically train neural machine translation systems human-translated parallel texts, ask decode previously-unseen source sentences. Trained parameter values induce distribution pairs source/target strings . Given new source string , NMT decoder searches best target string : This optimization unsolvable general recurrent neural networks , \citet{byrne2019} present exact optimization search algorithm consistent NMT models. \end{table} In practice, build target string using left-to-right, word-by-word greedy strategy. All target sentences end pseudo-word EoS, train test data. When greedy search selects EoS, translation ends. We easily find higher-probability strings beam search . However, use large beam, higher-probability strings turn worse translations, judged Bleu human evaluators. In fact, highest-probability string often short, even empty . We therefore typically revert back small beam size, hoping good translation despite worse . When happens, ``fortuitous'' search error . As NMT system architectures moved LSTM recurrent neural networks self-attention Transformer models , empty translation problem lessened bit, still present . Table shows behavior four transformer-based NMT models trained German-English Chinese-Japanese parallel data, using decoder beam size~512. The length ratio token ratio generated translations compared reference translations. The empty ratio percentage empty translations source sentences. We see around half translations German-English models empty. Our central question is: empty translations preferred? Our training data contain source strings translated empty strings, NMT learn assign high probability empty translations? Our findings are:","  We investigate why neural machine translation  systems assign high probability to empty translations. We find two explanations. First, label smoothing makes correct-length translations less confident, making it easier for the empty translation to outscore them. Second, NMT systems use the same, high-frequency EoS word type to end all target sentences, regardless of length. This creates an implicit smoothing that increases the relative probability zero-length translations.  Using different EoS types in target sentences of different lengths exposes this implicit smoothing."
"Understanding emotion human social conversations chitchat gained popularity natural language processing community due usefulness developing human-like conversational agents. Emotions revealed social chitchat rather complex. It many categories emotions distinguish due subtle variations present human emotion. For example, Sadness Disappointment pursued dealt differently human conversations. Also, listeners' reaction emotions always straightforward mirroring effect speakers' emotions. Rather neutral convey specific intent, evident dialogue example Table . \end{table} % containing 25K dialogues grounded 32 emotions, Welivita Pu \shortcite{taxonomy} analyzed listener responses EmpatheticDialogues dataset discovered 9 listener specific empathetic response intents contained emotional dialogues: Questioning; Agreeing; Acknowledging; Sympathizing; Encouraging; Consoling: Suggesting; Wishing; Neutral . They automatically annotated EmpatheticDialogues dataset 32 fine-grained emotions 9 empathetic response intents discovered frequent emotion-intent exchange patterns human social conversations. They observe type dataset tagged fine-grained emotions response intents could train neural chatbots generate empathetically appropriate responses conditioned selected emotion intent. However, purpose, large-scale emotion intent labeled dataset even desirable. Curating dataset technically challenging 1) annotating large-scale dataset require human labor costly, 2) given fine-granularity emotion intent labels, human labeling task difficult compared generic Angry-Happy-Sad. As result, existing manually labeled emotional dialogue datasets IEMOCAP , MELD , DailyDialogue smaller scale contain limited set emotions , simpler dialogue responding strategies, both. Also, existing datasets often contain label Neutral Other responses convey emotion, introduces vagueness limits ability automatic agents use datasets learning useful response strategies. % , EmotionLines , EmoContext To fill gap, curate novel large-scale dialogue dataset, OSED , containing 1M emotional dialogues movie subtitles, dialogue turn automatically annotated 32 fine-grained emotions 9 empathetic response intents. Movie subtitles well approximate human social conversations emotion handled them. It one major sources learn emotional variations corresponding response strategies. To reduce cost human labeling complexity labeling dialogues fine-grained emotions intents, devise semi-automated human computation task collect fine-grained emotion intent labels small set movie dialogues . We follow semi-supervised approach expand labeled data train dialogue emotion classifier automatically annotate 1M emotional dialogues. The process curating dataset consists several stages. First, apply automatic turn dialogue segmentation methods movie subtitles OpenSubtitles corpus obtain close 9M dialogues. After data cleaning removing duplicates, reduce size 4M. Then, apply weak labeler, EmoBERT trained EmpatheticDialogues dataset , label utterances OS dialogues filter 1M emotional dialogues . Thirdly, semi-supervised learning methods, refine EmoBert obtain EmoBert+, advanced dialogue emotion classifier trained OS dialogues. To evaluate EmoBert+, compare FastText. The former accurate FastText. Finally, use EmoBert+ label dialogues OSED initial obtain final 1M OSED dataset. We evaluate quality resultant dataset visually inspecting emotion-intent flow patterns occur dataset checking conform patterns human social conversations discovered existing work . Figure summarizes process creating OSED. The data curation pipeline follow substantially reduces cost human labor, ensuring quality annotations. Our contributions paper three-fold. 1) We curate dialogue dataset, OSED, containing 1M emotional dialogues labeled 32 fine-grained emotions 9 empathetic response intents. Compared existing dialogue datasets tagged emotions, OSED general-purpose, significantly larger, contains fine-grained emotions empathetic response strategies. 2) We outline complex pipeline used derive dataset evaluate annotation quality using visualization methods. 3) We release fine-grained emotion classifier used annotate OSED dataset, used general-purpose classifier capable recognizing fine-grained emotions empathetic response intents social chitchat."," We propose a novel large-scale emotional dialogue dataset, consisting of 1M dialogues retrieved from the OpenSubtitles corpus and annotated with 32 emotions and 9 empathetic response intents using a BERT-based fine-grained dialogue emotion classifier. This work explains the complex pipeline used to preprocess movie subtitles and select good movie dialogues to annotate. We also describe the semi-supervised learning process followed to train a fine-grained emotion classifier to annotate these dialogues. Despite the large set of labels, our dialogue emotion classifier achieved an accuracy of $65\%$ and was used to annotate 1M emotional movie dialogues from OpenSubtitles. This scale of emotional dialogue classification has never been attempted before, both in terms of dataset size and fine-grained emotion and intent categories. Visualization techniques used to analyze the quality of the resultant dataset suggest that it conforms to the patterns of human social interaction."
"Neural machine translation advanced significantly recent years . In particular, Transformer model become popular well-designed architecture ability capture dependency among positions entire sequence . Early systems kind stack 4-8 layers encoder decoder sides , improvement often comes use wider networks . More recently, researchers try explore deeper models Transformer. Encouraging results appeared architecture improvements creating direct pass low-level encoder layers decoder , proper initialization strategies . Despite promising improvements, problems still remain deep NMT. Deep Transformer stacked dozens encoder layers always large number parameters, computationally expensive memory intensive. For example, 48-layer Transformer larger 6-layer system slower inference. It difficult deploy models resource-restricted devices, mobile phones. Therefore, crucial compress heavy systems light-weight ones keeping performance. Knowledge distillation promising method address issue. Although several studies attempted compress 12-layer BERT model knowledge distillation, effectively compressing extremely deep Transformer NMT systems still open question MT community. In addition, methods leverage sophisticated layer-wise distillation loss functions minimize distance teacher student models, requires huge memory consumption enormous training cost. In paper, investigate simple efficient compression strategies deep Transformer. We propose novel Transformer compression approach ) transfer knowledge extremely deep teacher model shallower student model. We disturb computation order among layer group teacher training phase, easy implement memory friendly. Moreover, enhance performance teacher network, introduce vertical ``dropout'' training randomly omitting sub-layers prevent co-adaptations over-parameterized teacher network. Although similar technique discussed \citet{fan2019reducing}'s work, believe finding complementary theirs. Both Gpkd regularization training methods well incorporated teacher training process, essential obtaining strong light-weight student model. \pgfdeclarepatternformonly{soft horizontal lines}{\pgfpointorigin}{\pgfqpoint{100pt}{1pt}}{\pgfqpoint{100pt}{3pt}}% { \pgfsetstrokeopacity{0.3} \pgfsetlinewidth{0.1pt} \pgfpathmoveto{\pgfqpoint{0pt}{0.5pt}} \pgfpathlineto{\pgfqpoint{100pt}{0.5pt}} \pgfusepath{stroke} } \pgfdeclarepatternformonly{soft crosshatch}{\pgfqpoint{-1pt}{-1pt}}{\pgfqpoint{6pt}{6pt}}{\pgfqpoint{5pt}{5pt}}% { \pgfsetstrokeopacity{0.3} \pgfsetlinewidth{0.4pt} \pgfpathmoveto{\pgfqpoint{4.5pt}{0pt}} \pgfpathlineto{\pgfqpoint{0pt}{4.5pt}} \pgfpathmoveto{\pgfqpoint{0pt}{0pt}} \pgfpathlineto{\pgfqpoint{4.5pt}{4.5pt}} \pgfusepath{stroke} } \definecolor{ugreen}{rgb}{0,0.5,0} %reoder 1 \draw[line width=1pt,draw=red!30,fill=red!20] -- -- -- -- -- -- -- ; \draw[line width=1pt,draw=blue!35,fill=blue!20] -- -- -- -- -- -- -- ; %reoder 2 \draw[line width=1pt,draw=red!30,fill=red!20] -- -- -- -- -- -- -- ; \draw[line width=1pt,draw=blue!35,fill=blue!20] -- -- -- -- -- -- -- ; %reoder 3 \draw[line width=1pt,draw=red!30,fill=red!20] -- -- -- -- -- -- -- ; \draw[line width=1pt,draw=blue!35,fill=blue!20] -- -- -- -- -- -- -- ; \node[anchor=north,inner sep=0pt] {}; \node[anchor=north,inner sep=0pt] {}; \node[anchor = south,font=; \node[anchor = south,font=; \node[anchor = south,font=; \node[anchor = south,font=\footnotesize] {}; \node[anchor = east,font=\footnotesize,rotate=-90] {}; \node[anchor = east,font=\footnotesize,rotate=-90] {}; \node[anchor = east,font=\footnotesize,rotate=-90] {}; \node[anchor = north,font=\scriptsize] {reorder}; \node[anchor = west] {}; \node[anchor = west] {}; \node[anchor = west] {}; %draw \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',thick] -- ; \draw[-latex',very thick,red!40] ..controls + +..; \draw[-latex',very thick,blue!40] ..controls + +..; \node[font=\tiny] {sampling}; \node [auto,anchor=west,font=\footnotesize,rotate=-90] {Teacher Training} ; \node [auto,anchor=west,font=\footnotesize,rotate=-90] {Student Training} ; \node[auto,anchor=south,font=\footnotesize,inner sep=0pt] {Generate Skd-data} ; \node[draw=gray!70,line width=1pt,fill=gray!10,single arrow,minimum height=2.2em,minimum width=4pt,single arrow head extend=3pt] {}; \node[draw=gray!70,line width=1pt,fill=gray!10,single arrow,minimum height=1.6em,minimum width=4pt,single arrow head extend=3pt,rotate=-90] {}; \end{tikzpicture} \end{figure*} We ran experiments WMT16 English-German, NIST OpenMT12 Chinese-English WMT19 Chinese-English translation tasks. The Gpkd method compressed 48-layer Transformer 6-layer system almost loss BLEU. It outperformed baseline depth + BLEU points. Through skipping sub-layer method, teacher network achieved BLEU score BLEU newstest2014 English-German task, student obtains additional improvements BLEU points. % Moreover, present deep-encoder shallow-decoder architecture achieves speedup times almost loss BLEU.","     Recently, deep models have shown tremendous improvements in neural machine translation . However, systems of this kind are computationally expensive and memory intensive. In this paper, we take a natural step towards learning strong but light-weight NMT systems. We proposed a novel group-permutation based knowledge distillation approach to compressing the deep Transformer model into a shallow model. The experimental results on several benchmarks validate the effectiveness of our method. Our compressed model is $8\times$ shallower than the deep model, with almost no loss in BLEU. To further enhance the teacher model, we present a Skipping Sub-Layer method to randomly omit sub-layers to introduce perturbation into training, which achieves a BLEU score of 30.63 on English-German newstest2014. The code is publicly available at https://github.com/libeineu/GPKD."
"{S}{emantic} role labeling , also known shallow semantic parsing, conveys meaning sentence forming predicate-argument structure predicate sentence, generally described answer question ""Who whom, when?"". The relation specific predicate argument provides extra layer abstraction beyond syntactic dependencies , labels insensitive syntactic alternations also applied nominal predicates. Given sentence Figure , SRL pipeline framework consists 4 subtasks, including predicate identification , predicate disambiguation , arguments identification arguments classification . SRL core task natural language processing wide range applications neural machine translation , information extraction , question answering , emotion recognition text , document summarization etc. Semantic role labeling categorized two categories, span dependency. Both types SRL useful formal semantic representations dependency based SRL better convenience effectiveness semantic machine learning. Johansson Nugues concluded best dependency based SRL system outperforms best span based SRL system gold syntactic structure transformation. The conclusion also verified Li et al. solid empirical verification. Furthermore, since 2008, dependency based SRL studied compared span based SRL. With motivation, focus dependency based SRL, mainly popularized CoNLL-2008 CoNLL-2009 shared tasks . The traditional approaches SRL focus feature engineering struggles apprehending discriminative information neural networks proficient enough extract features automatically . Specifically, since large scale empirical verification Punyakanok et al. , syntactic information proven extremely beneficial SRL task. Later works achieve satisfactory performance SRL syntax-agnostic models creates conflict long-held belief syntax essential high-performance SRL . The study Li et al. shows empirical results neural models less importance syntax indicate potential challenge despite satisfactory performance syntax-agnostic SRL systems, reasons behind absence syntax models three-fold. First, effective incorporation syntax neural SRL models quite challenging compared traditional approaches. Second, neural SRL models may cover partial syntactic clues less. Third, syntax always complicated formalism linguistics easy encode syntax later usage. %Despite satisfactory performance syntax-agnostic SRL models, reasons behind absence syntax models two-fold. First, effective incorporation syntax information neural SRL models quite challenging. Second, unreliability syntactic parsers account risk erroneous syntactic input may lead error proliferation. This proven Li et al. strong empirical verification. They show effective method syntax incorporation high quality syntax promote SRL performance.%"," Semantic role labeling  aims at elaborating the meaning of a sentence by forming a predicate-argument structure. Recent researches depicted that the effective use of syntax can improve SRL performance. However, syntax is a complicated linguistic clue and is hard to be effectively applied in a downstream task like SRL. This work effectively encodes syntax using adaptive convolution which endows strong flexibility to existing convolutional networks. The existing CNNs may help in encoding a complicated structure like syntax for SRL, but it still has shortcomings. Contrary to traditional convolutional networks that use same filters for different inputs, adaptive convolution uses adaptively generated filters conditioned on syntactically-informed inputs. We achieve this with the integration of a filter generation network which generates the input specific filters. This helps the model to focus on important syntactic features present inside the input, thus enlarging the gap between syntax-aware and syntax-agnostic SRL systems. We further study a hashing technique to compress the size of the filter generation network for SRL in terms of trainable parameters. Experiments on CoNLL-2009 dataset confirm that the proposed model substantially outperforms most previous SRL systems for both English and Chinese languages."
"Learning dialogue policies typically formulated reinforcement learning problem . However, dialogue policy learning via RL scratch real-world dialogue scenarios expensive time-consuming, requires real users interact adjusts policies online . A plausible strategy use user simulators inexpensive alternative real users, randomly sample user goal user goal set dialogue agent training . In task-oriented dialogue settings, entire conversation revolves around sampled user goal implicitly. Nevertheless, dialogue agent's objective help user accomplish goal even though agent knows nothing sampled user goal , shown Figure. The randomly sampling-based user simulator neglects fact human learning supervision often accompanied curriculum . For instance, human-teacher teaches students, order presented examples random meaningful, students benefit . Therefore, randomly sampling-based user simulators bring two issues: Most previous studies dialogue policy focused efficiency issue, reward shaping , companion learning , incorporate planning , etc. However, stability pre-requisite method work well real-world scenarios. It because, matter effective algorithm is, unstable online leaned policy may ineffective applied real dialogue environment. This lead bad user experience thus fail attract sufficient real users continuously improve policy. As far know, little work reported stability dialogue policy. Therefore, essential address stability issue. In paper, propose novel policy learning framework combines curriculum learning deep reinforcement learning, namely Automatic Curriculum Learning-based Deep Q-Network . As shown Figure, framework replaces traditional random sampling method user simulator teacher policy model arranges meaningful ordered curriculum dynamically adjusts help dialogue agent automatic curriculum learning. As scheduling controller student agents, teacher policy model arranges students learn different user goals different learning stages without requirement prior knowledge. Sampling user goals match ability student agents regarding different difficulty user goal, increases feedback environment student agent also makes learning student agent stable. There two criteria evaluating sampling order user goal: learning progress student agent over-repetition penalty. The learning progress student agent emphasizes efficiency user goal, encouraging teacher policy model choose user goals match ability student agent maximize learning efficiency student agent. The over-repetition penalty emphasizes sampled diversity, preventing teacher policy model cheating\footnote[1]{The teacher policy model repeatedly selects user goals student agent mastered obtain positive rewards.}. The incorporation learning progress student agent over-repetition penalty reflects sampled efficiency sampled diversity improve efficiency well stability ACL-DQN. Additionally, proposed ACL-DQN framework equip different curriculum schedules. Hence, order verify generalization proposed framework, propose three curriculum schedule standards framework experimentation: i) Curriculum schedule A: standard, single teacher model; ii) Curriculum schedule B: user goals sampled easiness hardness proportion; iii) Curriculum schedule C: ensure student agents mastered simpler goals learning complex goals. Experiments demonstrated ACL-DQN significantly improves dialogue policy automatic curriculum learning achieves better stable performance DQN. Moreover, ACL-DQN equipped curriculum schedules improved. Among three curriculum schedules provided, ACL-DQN curriculum schedule C strength supervision controllability, better follow learning progress students performs best. In summary, contributions follows:"," Dialogue policy learning based on reinforcement learning is difficult to be applied to real users to train dialogue agents from scratch because of the high cost. User simulators, which choose random user goals for the dialogue agent to train on, have been considered as an affordable substitute for real users. However, this random sampling method ignores the law of human learning, making the learned dialogue policy inefficient and unstable. We propose a novel framework, Automatic Curriculum Learning-based Deep Q-Network , which replaces the traditional random sampling method with a teacher policy model to realize the dialogue policy for automatic curriculum learning. The teacher model arranges a meaningful ordered curriculum and automatically adjusts it by monitoring the learning progress of the dialogue agent and the over-repetition penalty without any requirement of prior knowledge. The learning progress of the dialogue agent reflects the relationship between the dialogue agent's ability and the sampled goals' difficulty for sample efficiency. The over-repetition penalty guarantees the sampled diversity. Experiments show that the ACL-DQN significantly improves the effectiveness and stability of dialogue tasks with a statistically significant margin. Furthermore, the framework can be further improved by equipping with different curriculum schedules, which demonstrates that the framework has strong generalizability."
"} {R}{epresentations} learned deep neural models attracted lot attention Natural Language Processing . % widely used various applications information retrieval question answering . In real-world situations, different levels linguistic units % usually appear time. For example, considering traditional information retrieval task, system required capture semantic meanings queries different lengths. Therefore, critical come method handle multiple levels linguistic objects unified way. However, previous language representation learning methods Word2Vec , LASER USE focus either words sentences. % achieving encouraging performance certain level linguistic unit less satisfactory results levels. Later proposed pre-trained contextualized language representations like ELMo , GPT, BERT XLNet may seemingly handle different sized input sentences, focus sentence-level specific representation still word, leading unsatisfactory performance real-world situations. Although latest BERT-wwm-ext , StructBERT SpanBERT perform MLM higher linguistic level, masked segments either follow pre-defined distribution focus specific granularity. Besides, random sampling strategy ignores important semantic syntactic information sequence, resulting large number meaningless segments. However, universal representation among different levels linguistic units may offer great convenience needed handle free text language hierarchy unified way. As well known that, embedding representation certain linguistic unit enables linguistics-meaningful arithmetic calculation among different vectors, also known word analogy. For example, vector - vector + vector results vector . Thus universal representation may generalize good analogy features meaningful arithmetic operation onto free text language levels involved together. For example, Eat onion : Vegetable :: Eat pear : Fruit. In fact, manipulating embeddings vector space reveals syntactic semantic relations original sequences feature indeed useful true applications. For example, ``London capital England.閳 formulized . Then given two documents one contains ``England閳 ``capital閳, contains ``London閳, consider two documents relevant. % Such features generalized onto higher language levels phrase/sentence embedding. In paper, explore regularities representations including words, phrases sentences vector space. To end, introduce universal analogy task derived Google's word analogy dataset. To solve task, present BURT, pre-trained model aims learning universal representations sequences various lengths. Our model follows architecture BERT differs original masking training scheme. Specifically, propose efficiently extract prune meaningful segments unlabeled corpus little human supervision, use modify masking training objective BERT. The n-gram pruning algorithm based point-wise mutual information automatically captures different levels language information, critical improving model capability handling multiple levels linguistic objects unified way, i.e., embedding sequences different lengths vector space. Overall, pre-trained models improves performance baselines English Chinese. In English, BURT-base reaches 0.7 percent gain average Google BERT-base. In Chinese, BURT-wwm-ext obtains 74.5\% WSC test set, 13.4\% point absolute improvement compared BERT-wwm-ext exceeds baselines 0.2\% 0.6\% point accuracy five CLUE tasks including TNEWS, IFLYTEK, CSL, ChID CMRC 2018. Extensive experimental results universal analogy task demonstrate BURT able map sequences variable lengths shared vector space similar sequences close other. Meanwhile, addition subtraction embeddings reflect semantic syntactic connections sequences. Moreover, BURT easily applied real-world applications Frequently Asked Questions Natural Language Generation tasks, encodes words, sentences paragraphs embedding space directly retrieves sequences semantically similar given query based cosine similarity. All experimental results demonstrate well-trained model leads universal representation adapt various tasks applications. % needed second column first page using \IEEEpubid % \IEEEpubidadjcol"," \justifying Although pre-trained contextualized language models such as BERT achieve significant performance on various downstream tasks, current language representation focuses on linguistic objective at a specific granularity.  % which may not applicable when multiple levels of linguistic units are involved at the same time.  Thus this work introduces  % and explores  the universal representation learning, i.e., embeddings of different levels of linguistic unit in a uniform vector space. We present a universal representation model, BURT , to encode different levels of linguistic unit into the same vector space. Specifically, we extract  % and mask  meaningful segments based on point-wise mutual information  to incorporate different granular objectives into the pre-training stage. We conduct experiments on datasets for English and Chinese including the GLUE and CLUE benchmarks, where our model surpasses its baselines and alternatives on a wide range of downstream tasks. We present our approach of constructing analogy datasets in terms of words, phrases and sentences and experiment with multiple representation models to examine geometric properties of the learned vector space through a task-independent evaluation. Finally, we verify the effectiveness of our method  % unified pre-training strategy  in two real-world text matching scenarios. As a result, our model significantly outperforms existing information retrieval  methods and yields universal representations that can be directly applied to retrieval-based question-answering and natural language generation tasks."
"Exponential growths micro-blogging sites social media provide platforms empowering freedom expressions individual voices, also enables people express anti-social behavior online harassment, cyberbullying, rumors, spreading hatred statements. %In recent years, micro-blogging sites social media sites grown exponentially, enabling users express anti-social behavior, false political religious rumor, spreading hatred activities. Besides, abusive threatening speech expresses prejudice certain group, religious, political, geopolitical, personal, gender abuse common basis race, religion, sexual orientation getting pervasive. United Nations Strategy Plan Action Hate Speech defines hate speech ``any kind communication speech, writing behaviour, attacks uses pejorative discriminatory language reference person group basis are, words, based religion, ethnicity, nationality, race, colour, descent, gender identity factor''. Bengali spoken 230 million people Bangladesh India, making one major languages world. Although, rich language lot diversity, Bengali severely low-resourced natural language processing~, due scarcity computational resources language models, labeled datasets, efficient machine learning~ methods required different NLP tasks. Similar major languages like English, use hate speech Bengali also getting rampant. This mainly due unrestricted access use social media digitalization. Some examples Bengali hate speech respective English translations shown \cref{cdec_wf3} either directed towards specific person entity generalized towards group. These examples signify severe Bengali hateful statements could be. Nevertheless, potential chance could lead serious consequences hate crimes, regardless languages, geographic locations, ethnicity. Automatic identification hate speech creating awareness among people challenging. However, manual reviewing verification vast amount online content labor-intensive also time-consuming. Nevertheless, accurate identification requires automated, robust, efficient machine learning~ methods. Compared traditional ML neural network~-based approaches, state-of-the-art~ language models becoming increasingly effective. On serious drawback: prediction made many models neither traced back input, clear output transformed certain way. This makes even efficient DNN models `black-box' methods. On hand, General Data Protection Regulation~ European Parliament enforces `right explanation', prohibits use ML automated decisions unless clear explanation logic used make decision well explained. Therefore, prediction made algorithm transparent possible order gain human trust. %Recent research efforts NLP ML communities proven useful well-resourced languages like English. %Nevertheless, accurate identification requires automated, robust, efficient machine learning~ methods. As state-of-the-art language models becoming increasingly effective, decisions made transparent possible order improve human trust. %Some techniques based model閳ユ獨 local gradient information methods seek redistribute function閳ユ獨 value input variables, typically reverse propagation neural network graph. Bach et al. proposed specific propagation rules neural networks . These rules shown produce better explanations e.g. gradient-based techniques computer vision also text data. To overcome shortcomings `black-box'-based methods inspired outstanding success transformer language models~, propose explainable approach hate speech detection under-resourced Bengali language. Our approach based ensemble several BERT variants, including monolingual Bangla BERT-base, m-BERT~, XLM-RoBERTa. Further, provide global local explanations predictions, post-hoc fashion also provide measure explanations terms faithfulness. The rest paper structured follows: \Cref{rw} reviews related work hate speech Bengali word embedding. \Cref{section:3} describes data collection annotation process. \Cref{nettwork} describes process Bengali neural embedding, network construction, training. \Cref{er} illustrates experiment results, including comparative analysis baseline models datasets. \Cref{con} summarizes research potential limitations points possible outlook concluding paper.","   The exponential growths of social media and micro-blogging sites not only provide platforms for empowering freedom of expressions and individual voices, but also enables people to express anti-social behavior like online harassment, cyberbullying, and hate speech. Numerous works have been proposed to utilize the textual data for social and anti-social behavior analysis, by predicting the contexts mostly for highly-resourced languages like English. However, some languages are under-resourced, e.g., South Asian languages like Bengali, that lack  computational resources for accurate natural language processing~. In this paper, we propose an explainable approach for hate speech detection from the under-resourced Bengali language, which we called \texttt{DeepHateExplainer}. In our approach, Bengali texts are first comprehensively preprocessed, before classifying them into political, personal, geopolitical, and religious hates, by employing the neural ensemble method of different transformer-based neural architectures~. Subsequently, important~ terms are identified with sensitivity analysis and layer-wise relevance propagation~, before providing human-interpretable explanations. Finally, to measure the quality of the explanation~, we compute the comprehensiveness and sufficiency. Evaluations against machine learning~ and deep neural networks~ baselines yield F1 scores of 84\%, 90\%, 88\%, and 88\%, for political, personal, geopolitical, and religious hates, respectively, outperforming both ML and DNN baselines.%, during 3-fold cross-validation tests."
"Sentence embeddings map sentences vector space. The vectors capture rich semantic information used measure semantic textual similarity~ sentences train classifiers broad range downstream tasks~. State-of-the-art models usually trained supervised tasks natural language inference~, semi-structured data like question-answer pairs~ translation pairs~. However, labeled semi-structured data difficult expensive obtain, making hard cover many domains languages. Conversely, recent efforts improve language models include development masked language model pre-training large scale unlabeled corpora . While internal MLM model representations helpful fine-tuning downstream tasks, directly produce good sentence representations, without supervised semi-structured fine-tuning. In paper, explore unsupervised approach, called Conditional Masked Language Modeling , effectively learn sentence representations large scale unlabeled corpora. CMLM integrates sentence representation learning MLM training conditioning sentence level representations produced adjacent sentences. The model therefore needs learn effective sentence representations order perform good MLM. Since CMLM fully unsupervised, easily extended new languages. We explore CMLM English multilingual sentence embeddings 100+ languages. Our English CMLM model achieves state-of-the-art performance SentEval~, even outperforming models learned using supervised signals. Moreover, models training English Amazon review data using multilingual vectors exhibit strong multilingual transfer performance translations Amazon review evaluation data French, German Japanese, outperforming existing multilingual sentence embedding models non-English languages original English data. We extend multilingual CMLM co-train parallel text retrieval task, finetune cross-lingual natural language inference data, inspired success prior work multitask sentence representation learning~ NLI learning~. We achieve performance better previous state-of-the-art multilingual sentence representation model . Language agnostic representations require semantically similar cross-lingual pairs closer representation space unrelated same-language pairs~. While find original sentence embeddings bias language sentences, discover removing first principal components embeddings eliminates self language bias. The rest paper organized follows. \Cref{sec:cmlm} describes architecture CMLM unsupervised learning. In \Cref{sec:en_cmlm} present CMLM trained English data evaluation results SentEval. In \Cref{sec:en_cmlm} apply CMLM learn sentence multilingual sentence representations. Multitask training strategies effectively combining CMLM, bitext retrieval cross lingual NLI finetuning explored. In \Cref{sec:analysis}, investigate self language bias multilingual representations eliminate it. The contributions paper summarized follows: A novel pre-training technique CMLM unsupervised sentence representation learning unlabeled corpora . An effective multitask training framework, combines unsupervised learning task CMLM supervised learning Bitext Retrieval cross-lingual NLI finetuning. An evaluation benchmark multilingual sentence representations. A simple effective algebraic method remove language bias multilingual representations. The pre-trained models released \url{https://tfhub.dev/s?q=universal-sentence-encoder-cmlm}."," This paper presents a novel training method, Conditional Masked Language Modeling , to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~ and natural language inference~ tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics."
"Many seemingly convincing rumors ``Most humans use 10 percent brain'' widely spread, ordinary people able rigorously verify searching scientific literature. In fact, trivial task verify scientific claim providing supporting refuting evidence rationales, even domain experts. %Such The situation worsens misinformation proliferated %by social media news websites, manually programmatically, every moment. As result, automatic fact-verification tool becomes crucial combating %against spread misinformation. %There many existing datasets %the corresponding %systems fact-verification tasks %, emphasizing %in various domains, Wikipedia , social media , politics . These tasks %are The existing fact-verification tasks usually consist three sub-tasks: document retrieval, rationale sentence extraction, fact-verification. However, due nature scientific literature requires domain knowledge, challenging collect large scale scientific fact-verification dataset, further, perform fact-verification low-resource setting limited training data. \citet{Wadden2020FactOF} collected scientific claim-verification dataset, SciFact, proposed scientific claim-verification task: given scientific claim, find evidence sentences support refute %such claim %from corpus scientific paper abstracts. \citet{Wadden2020FactOF} also proposed simple, pipeline-based, sentence-level model, VeriSci, baseline solution based \citet{deyoung2019eraser}. %Despite simplicity VeriSci , VeriSci pipeline model runs modules abstract retrieval, rationale sentence selection, stance prediction sequentially, thus error generated %the upstream module may propagate downstream modules. To overcome drawback, hypothesize module jointly optimized multiple sub-tasks may mitigate error-propagation problem improve overall performance. %On hand, In addition, observe complete set rationale sentences usually contains multiple inter-related sentences paragraph. Therefore, propose novel, paragraph-level, multi-task learning model SciFact task. In work, employ compact paragraph encoding, novel strategy computing sentence representations using BERT-family models. We directly feed entire paragraph single sequence BERT, encoded sentence representations already contextualized neighbor sentences taking advantage attention mechanisms BERT. In addition, jointly train modules rationale selection stance prediction multi-task learning leveraging confidence score rationale selection attention weight stance prediction module. Furthermore, compare two methods transfer learning mitigate low-resource issue: pre-training domain adaptation . Our experiments show that: % compact paragraph encoding method beneficial separately computing sentence embeddings, negative sampling, joint training rationale selection stance prediction beneficial pipeline solution. %\todo{you may want create list contribution. -Violet}"," Even for domain experts, it is a non-trivial task to verify a scientific claim by providing supporting or refuting evidence rationales. The situation worsens as misinformation is proliferated on social media or news websites, manually or programmatically, at every moment. As a result, an automatic fact-verification tool becomes crucial for combating the spread of misinformation. %\citet{Wadden2020FactOF} collected a scientific claim-verification dataset, SciFact, to facilitate research on scientific claim-verification.  In this work, we propose a novel, paragraph-level, multi-task learning model for the SciFact task by directly computing a sequence of contextualized sentence embeddings from a BERT model and jointly training the model on rationale selection and stance prediction."
"Self attention networks widely studied many natural language processing tasks, machine translation , language modeling natural language inference . It well accepted SANs leverage local long-term dependencies attention mechanism, highly parallelizable thanks position-independent modeling method. However, position-independent models incapable explicitly capturing boundaries sequences words, thus overlook structure information proven robust inductive biases modeling texts . Unlike RNNs model sequential structure information words using memory cells, CNNs focus learning local structure dependency words via convolution kernels, SANs learn flexible structural information indirect way almost scratch. One way integrate structural information SAN models via pre-training, BERT , learns represent sentences using unsupervised learning tasks large-scale corpus. Recent studies shown ability pre-training models capturing structure information sentences. Another method deal structural information introducing structure priors SANs mask strategies. \citeauthor{shen2018disan} \shortcite{shen2018disan} proposed directional self-attention mechanism, employs two SANs forward backward masks respectively encode temporal order information. \citeauthor{guo2019gaussian} \shortcite{guo2019gaussian} introduced Gaussian prior transformers capturing local compositionality words. Admittedly, structure priors strengthen model's capability modeling sentences meanwhile assist capturing proper dependencies. With help learned structure priors, SANs model sentences accurately even resource-constrained conditions. Though models get success many NLP tasks, studies commonly focus integrating one single type structure priors SANs, thus fail making full use multi-head attentions. One straightforward advantage using multi-head attentions lies fact different heads convey different views texts . In words, multi-head attentions enable model capture information texts multiple aspects, return brings thorough views modeling texts. Besides, well accepted one type structural prior reveal part structural information one single perspective. A variety types structural priors needed order gain complete structural information texts. This achieved introducing different structural priors different parts attention heads, different structural priors complement other, guiding SAN models learn proper dependencies words. Therefore, gain better representation texts, desirable solution make full use multi-head attention mechanism utilize multiple types structural priors. To better alleviate aforementioned problems, paper, propose lightweight self attention network, i.e., Multiple Structural Priors Guided Self Attention Network . The novel idea behind model lies usage multi-mask based multi-head attention , helps model better capture different types dependencies texts. Thanks MM-MH Attention mechanism, model capture multiple structural priors, return brings benefits modeling sentences. Especially, structural priors employed come two categories: sequential order relative position words. Since standard SANs incapable distinguishing order words, apply direction mask directly attention head. Motivated Bidirectional RNNs , split attention heads two parts. For given word, apply forward mask first half attention heads, allows attend previous words modeling reference word. Accordingly, backward mask applied rest attention heads. Since direction masks take consideration difference long-distance words nearby words, employ second category structural prior complement, could measured distance pair words. We integrate two types distance masks different attention heads. The first one utilized word distance mask, describes physical distance pair words. Besides, purpose capturing latent hierarchical structure sentences, integrate another kind distance information, i.e., dependency distance defined distance pair words dependency syntax tree. The word distance mask helps model focus local words dependency distance mask enables model capture hierarchical relationships words. Consequently, provide model ability capturing local non-local dependency words properly. To illustrate effectiveness model, conduct experiments two NLP tasks: natural language inference sentiment classification. Experimental results show MS-SAN outperforms baselines achieves competitive performance comparing state-of-the-art models. Our contributions listed follows:"," Self attention networks  have been widely utilized in recent NLP studies. Unlike CNNs or RNNs, standard SANs are usually position-independent, and thus are incapable of capturing the structural priors between sequences of words. Existing studies commonly apply one single mask strategy on SANs for incorporating structural priors while failing at modeling more abundant structural information of texts. In this paper, we aim at introducing multiple types of structural priors into SAN models, proposing the Multiple Structural Priors Guided Self Attention Network  that transforms different structural priors into different attention heads by using a novel multi-mask based multi-head attention mechanism. In particular, we integrate two categories of structural priors, including the sequential order and the relative position of words. For the purpose of capturing the latent hierarchical structure of the texts, we extract these information not only from the word contexts but also from the dependency syntax trees. Experimental results on two tasks show that MS-SAN achieves significant improvements against other strong baselines."
"Building intelligent conversation systems long-standing goal artificial intelligence attracted much attention recent years . A central challenge building conversation systems response selection problem, is, selecting best response given dialogue context pool candidate responses . } \end{center} \end{table} To tackle response selection problem, different matching models developed measure matching degree conversation context response candidate . Despite differences, prior works train matching models training data constructed simple heuristic. For dialogue context, human-written response considered positive responses dialogue contexts considered negative . In practice, negative responses often randomly sampled training objective ensure positive responses score higher negative ones. Recently, researchers raised concern randomly sampled negative responses often trivial . Models trained negative data lacks ability handle strong distractors testing. In general, problem stems ignorance diversity context-response matching; random responses treated equally negative regardless distracting strength. For example, Table , two negative responses presented. For N1, one easily dispel legality %as lexical overlap off-topic semantic meaning. follow topic discussed dialogue context. %as semantic meaning \cd{what meaning} obviously topic \cd{what topic}, On hand, judging strong distractor like N2 difficult content overlaps significantly context . Only close observation, %we find N2 properly reply context \cd{why?}. %the semantic incoherence context N2 spotted\cd{what incoherence?}. find N2 strongly maintain coherence discussion, i.e., starts parallel discussion actor Game Thrones rather elaborating enjoyable properties TV series. %Similarly, observe phenomena positive side. Similarly, positive side phenomena. For positive response P1, one easily confirm legality naturally replies context. As P2, expatiates enjoyable properties TV series, exhibit obvious matching clues, lexical overlap context. %share lexical overlap context. Thus, correctly identify P2, relationship P2 context carefully reasoned model. %Game Thrones, character name Jon Snow appeared context. Thus, correctly identify it, relationship Jon Snow Game Thrones carefully reasoned model. To conclude, observations suggest that, accurately recognize different positive negative responses, model required possess different levels discriminative capability. %require different levels model capability accurately recognize. %\textcolor{red}{brandenwang: since difficulty random sampled negative responses diverse. Besides, observe diversity also applies positive responses: cases, relationship context response explicit easy identify, others, difficult find implicit relationship context response. These two kinds diversity may result unstable training process poor accuracy real-world applications.} %Motivated intuition one first learn deal easy cases handling harder ones, propose employ idea curriculum learning tackle task response selection. Inspired aforementioned observations, propose employ idea curriculum learning better learning response selection models. %to better learn matching models response selection. CL reminiscent cognitive process human being, core idea first learning easier concepts gradually transitioning learning complex concepts based pre-defined learning schemes. %\cd{What pace function design?}. In various NLP tasks ), CL demonstrated benefit improving model performance well learning convergence.%, , leading improved model performance well faster learning convergence.%better generalization\cd{fast robust convergence? difference generalization performance?}. %which successfully applied many machine learning tasks . The core idea CL first learning easier concepts gradually transitioning learning complex concepts. %.\cd{what curriculum learning? applications? benefits?This paragraph introduce CL, talk general idea CL success tasks } The key applying CL specify appropriate learning scheme training examples gradually learned %. . In work, tailor-design hierarchical curriculum learning framework according characteristics concerned response selection task. Our HCL framework consists two complementary curriculum strategies, namely corpus-level curriculum instance-level curriculum , covering two distinct aspects response selection. Specifically, CC, model gradually increases ability finding matching clues context positive response. As IC, progressively strengthens model's ability identifying mismatch information context negative responses. To order positive negative examples, need assess millions possible context-response combinations training data. To overcome computational challenge, propose use fast neural ranking model assign learning priorities training examples based pairwise context-response similarity score. Notably, proposed learning framework independent choice matching models. % conveniently implemented without additional modelling effort \cd{really?}. Therefore, comprehensive evaluation, test approach three representative matching models, including latest advance brought pre-trained language models. Results two benchmark datasets demonstrate proposed learning framework leads remarkable performance improvement across evaluation metrics. In summary, contributions are: We propose new hierarchical curriculum learning framework tackle task response selection; % We design decomposable neural model works coherently proposed learning framework; Experimental results two benchmark datasets demonstrate approach significantly improve performance strong matching models, including state-of-the-art one."," We study the learning of a matching model for dialogue response selection. Motivated by the recent finding that random negatives are often too trivial to train a reliable model, we propose a hierarchical curriculum learning  framework that consists of two complementary curricula: % Motivated by the idea of curriculum learning, we propose a new hierarchical curriculum learning framework which consists of two curriculum strategies:  corpus-level curriculum ; and  instance-level curriculum . In CC, the model gradually increases its ability in finding the matching clues between the dialogue context and a response. On the other hand, IC progressively strengthens the model's ability in identifying the mismatched information between the dialogue context and a response. Empirical studies on two benchmark datasets with three state-of-the-art matching models demonstrate that the proposed HCL significantly improves the model performance across various evaluation metrics\footnote{All data, code and models are made publicly available at https://github.com/yxuansu/HCL/.}."
"Sequence-to-Sequence learning~ advanced state art various natural language processing tasks, machine translation~, text summarization~, grammatical error correction~. Seq2Seq models generally implemented encoder-decoder framework, multi-layer encoder summarizes source sequence sequence representation another multi-layer decoder produces target sequence conditioned encoded representation. Recent studies reveal fusing intermediate encoder layers beneficial Seq2Seq models, layer attention~, layer aggregation~, layer-wise coordination~. Despite effectiveness, much known fusing encoder layer representations work. The intuitive explanation fusing encoder layers exploits surface syntactic information embedded lower encoder layers~. However, studies show attending lower encoder layers improve model performance~, conflicted existing conclusions. It still unclear fusing encoder layers work Seq2Seq models. This paper tries shed light upon behavior Seq2Seq models augmented EncoderFusion method. To end, propose novel fine-grained layer attention evaluate contribution individual encoder layers. We conduct experiments several representative Seq2Seq NLP tasks, including machine translation, text summarization, grammatical error correction. Through series analyses, find uppermost decoder layer pays attention encoder embedding layer. Masking encoder embedding layer significantly drops model performance generating hallucinatory predictions. The encoded representation standard Seq2Seq models may enough capacity model semantic surface features . We call problem described source representation bottleneck. Based observation, simplify EncoderFusion approaches connecting encoder embedding layer softmax layer . The SurfaceFusion approach shortens path distance source target embeddings, help learn better bilingual embeddings direct interactions. Experimental results several Seq2Seq NLP tasks show method consistently outperforms vanilla Seq2Seq model layer attention model. Extensive analyses reveal approach produces aligned bilingual word embeddings shortening path distance them, confirm claim. Our main contributions follows:"," Encoder layer fusion  is a technique to fuse all the encoder layers  for sequence-to-sequence  models, which has proven effective on various NLP tasks. However, it is still not entirely clear why and when EncoderFusion should work. In this paper, our main contribution is to take a step further in understanding EncoderFusion. Many of previous studies believe that the success of EncoderFusion comes from exploiting surface and syntactic information embedded in lower encoder layers. Unlike them, we find that the encoder embedding layer is more important than other intermediate encoder layers.  In addition, the uppermost decoder layer consistently pays more attention to the encoder embedding layer across NLP tasks. Based on this observation, we propose a simple fusion method, SurfaceFusion, by fusing only the encoder embedding layer for the softmax layer. Experimental results show that SurfaceFusion outperforms EncoderFusion on several NLP benchmarks, including machine translation, text summarization, and grammatical error correction.   It obtains the state-of-the-art performance on WMT16 Romanian-English and WMT14 English-French translation tasks. Extensive analyses reveal that SurfaceFusion learns more expressive bilingual word embeddings by building a closer relationship between relevant source and target embeddings. Source code is freely available at \url{https://github.com/SunbowLiu/SurfaceFusion}.  \iffalse To model the inter-dependence of two sequences, sequence-to-sequence  learning extracts the source surface and abstract features through its encoder output representations. However, an overloaded use of the encoder output representations might lead to an insufficient representation capacity, which we call it source representation bottleneck. Recent studies have found that widening the bottleneck by fusing the surface features from lower level representations can boost the performance of Seq2Seq, but none of them explain the intrinsic mechanism of this benefit. In this paper, we take the first step to probe into the essence of the bottleneck on three typical Seq2Seq tasks, i.e.~machine translation, text summarization, and grammatical error correction. We observe that the representation learning of higher decoder layer suffers from the bottleneck, and thus propose a simple yet effective surface fusion method to mitigate the issue. The results over a variety of benchmarks confirm the effectiveness of the proposed method. Source code will be released. \fi"
"Word segmentation fundamental challenging task text classification NLP applications. Word segmenter determines boundaries words shape beginning ending. It largely investigated many space-delimited languages including English, Arabic, Urdu non-space delimited languages including Chinese, Japanese, Burmese . However, word segmentation low-resource Sindhi language studied well, mainly due lack language resources. Sindhi word segmentation exhibits space omission space insertion problems. Although, white spaces words good sign predicting word boundaries, space omission space insertion words bring ambiguity segmentation process. Therefore, SWS task challenging problem resource scarcity, lack standard segmentation benchmark corpus, rich morphological features Sindhi language. Previously, little work proposed address SWS problem employing dictionary-based rule-based approaches. Thus, existing approaches lack applicability towards open-source implementation due following reasons, inability deal out-of-vocabulary words, less robust large datasets, lower segmentation accuracy. Our proposed novel deep SGNWS model capability dealing issues SWS Subword Representation Learning approach. Recently, deep neural architectures largely gained popularity NLP community greatly simplifying learning decoding number NLP applications including word segmentation neural word embedding powerful recurrent neural architectures. More recently, self-attention also become popular approach boost performance neural models. Therefore, tackle SWS problem taking advantage BiLSTM, self-attention, SRL, CRF without relying external feature engineering. In paper, propose language-independent neural word segmentation model Sindhi. The proposed model efficiently captures character-level information subword representation learning. We convert segmentation sequence tagging problem using B, I, E, S, X tagging scheme. Where B denotes [Beginning], I [Inside], E [Ending] word given corpus, S [Single] used tagging single special character unlabeled text, X tag used [hard-space] words. We train task-oriented Sindhi word representations character-level subword approach. To best knowledge, first attempt tackle SWS sequence labeling task. We provide open-source implementation investigation\footnote{https://github.com/AliWazir/Neural-Sindhi-word-segmenter}. Our novel contributions listed follows: % The remaining parts paper organized following sequence; Section presents related work SWS morphology, evolution usage Recurrent Neural Networks variants LSTM, BiLSTM GRU text segmentation various languages. Section presents overview Sindhi writing system segmentation challenges, followed proposed methodology Section RNN variants employed task. Section presents experiments results analysis. Lastly, Section concludes paper."," Deep neural networks employ multiple processing layers for learning text representations to alleviate the burden of manual feature engineering in Natural Language Processing . Such text representations are widely used to extract features from unlabeled data. The word segmentation is a fundamental and inevitable prerequisite for many languages. Sindhi is an under-resourced language, whose segmentation is challenging as it exhibits space omission, space insertion issues, and lacks the labeled corpus for segmentation.  In this paper, we investigate supervised Sindhi Word Segmentation  using unlabeled data with a Subword Guided Neural Word Segmenter  for Sindhi. In order to learn text representations, we incorporate subword representations to recurrent neural architecture to capture word information at morphemic-level, which takes advantage of Bidirectional Long-Short Term Memory , self-attention mechanism, and Conditional Random Field .  Our proposed SGNWS model achieves an F1 value of  98.51\% without relying on feature engineering. The empirical results demonstrate the benefits of the proposed model over the existing Sindhi word segmenters.   % , such as dictionaries, morphological analyzers, or rules, for the Sindhi word segmentation. The conducted extensive empirical study demonstrates the benefits of the proposed model over the existing Sindhi word segmenters and state-of-the-art deep learning approaches."
"Indonesian colloquialism everyday everywhere, e.g. social media posts conversational transcripts. Yet, existing research Indonesian NLP models including NMTs often disregards qualitative analysis models given strictly colloquial inputs. This mainly due fact data readily available training testing models formal Indonesian. %This follow naturally due fact models style-agnostic, is, Colloquial Indonesian several different word choices formal language due diversity regional languages dialects. We define spoken colloquial clean colloquial. In addition, written media, colloquial Indonesian often abbreviated, disemvoweled, written voice alteration, define noisy colloquial . \end{table} To better evaluate English-Indonesian MT systems colloquial text, first create 2 new test-sets Indonesian-English colloquial pairs. The first test clean colloquial taken YouTube transcript. The second test-set noisy colloquial Twitter annotated team annotators. We found NMT systems trained formal dataset perform well test-sets. Next, develop synthetic colloquial text data performing word-level translation several words formal text colloquial form based word-to-word dictionary. By combining formal dataset synthesized colloquial dataset, increase NMT performance colloquial test-set 2.5 BLEU points.","  Neural machine translation  is typically domain-dependent and style-dependent, and it requires lots of training data. State-of-the-art NMT models often fall short in handling colloquial variations of its source language and the lack of parallel data in this regard is a challenging hurdle in systematically improving the existing models. In this work, we develop a novel colloquial Indonesian-English test-set collected from YouTube transcript and Twitter. We perform synthetic style augmentation to the source formal Indonesian language and show that it improves the baseline Id-En models  over the new test data. %Our experimental data and code are available on github.com."
"Large-scale language models greatly advanced NLP research various sub-areas, question answering, text summarization, story generation . However, generation models still suffer least three major problems applied dialogue system building, 1) generic repeated responses , 2) inconsistent statements dialogue context , 3) uncontrollable task-oblivious replies . Many previous studies attempted address problems . For instance, \citet{li2019inconsisent} penalized repetitive inconsistent behaviors unlikelihood loss open-domain chats. \citet{song2020generate} detected rewrote contradicting responses achieve consistent personality. However, methods optimize language model minimizing loss supervised learning, may lead exposure bias uninterpretable behaviors, consequently, makes harder humans regulate model. To alleviate problems, previous work explored RL-based methods dialogue system building . %For instance, integrated goal coherent reward design made first step towards .designed better generation. However, methods rely hand-crafted user simulators inherently hard build , also require meaningful rewards difficult design. To address issues, propose teach model extract policy directly data learn mistakes without use simulators. Leveraging decoding methods Nucleus Sampling , language model finetuned persuasion task able generate lexically diverse response candidates given context. %One example shown Figure. Some candidates appropriate, others repetitive inconsistent context. These good bad examples used positive negative feedback model meaningful rewards RL, help refine language model. During testing, fully utilize refined language model, use generate multiple candidates again, filter repetition inconsistency afterwards. Beyond nonrepetitive consistent, good response also needs accomplish dialogue task, case, persuade people. Therefore, ask humans demonstrate persuasion process, build response imitator imitate human demonstrations select persuasive response. The issues language models especially salient complex strategic dialogue tasks persuasion negotiation. These dialogues involve specific task goal social contents build rapport better task completion, therefore, richer complicated language structures . Furthermore, due inherent similarity task-oriented open-domain dialogues, improvements made systems would also help dialogue settings. Therefore, choose strategic donation persuasion task perform study, conduct automatic human evaluations evaluate models. This work makes multiple contributions. First, propose DialGAIL, RL-based generative algorithm refine MLE-based language models dialogue generation without use user simulators. Second, design effective practicable framework strategic dialogue systems achieves state-of-the-art performance complex persuasion task, small amount human demonstration efforts. %Such system achieves diverse, consistent fluent conversations better persuasion outcomes complex persuasion task compared MLE-based baselines. %a framework automatically detect repetitive inconsistent responses, imitate human demonstration select persuasive responses. %Furthermore, experiments show model produces diverse, consistent fluent conversations better persuasion outcomes complex persuasion task compared MLE-based baselines. Previous dialogue research mostly focused pure task-oriented dialogues pure social conversations; looking forward, becomes important pay attention strategic dialogues involves task social components. We sincerely hope work could inspire research discussions strategic dialogues community. % refine dialogue generation limited amount data? MLE fine-tuning woldn't work limited data % social content + specific end-goal --> persuasionforgood. advance research area % easily get usable lm without computational resources? % explore possibility apply GAIL dialogue generation simple way % first explore GAIL % raise attention persuasion community % small amount human demo % task-independent repetition detection strengthen"," Despite the recent success of large-scale language models on various downstream NLP tasks, the repetition and inconsistency problems still persist in dialogue response generation. Previous approaches have attempted to avoid repetition by penalizing the language model's undesirable behaviors in the loss function. However, these methods focus on token-level information and can lead to incoherent responses and uninterpretable behaviors. To alleviate these issues, we propose to apply reinforcement learning to refine an MLE-based language model without user simulators, and distill sentence-level information about repetition, inconsistency and task relevance through rewards. In addition, to better accomplish the dialogue task, the model learns from human demonstration to imitate intellectual activities such as persuasion, and selects the most persuasive responses. Experiments show that our model outperforms previous state-of-the-art dialogue models on both automatic metrics and human evaluation results on a donation persuasion task, and generates more diverse, consistent and persuasive conversations according to the user feedback.% We will release the code and data upon acceptance."
"Large-scale pre-training draw much attention community Compute Vision Natural Language Processing due strong capability generalization efficient usage large-scale data. Firstly CV, series models designed pre-trained large-scale dataset ImageNet, AlexNet , VGG ResNet , effectively improved capability image recognition numerous tasks. Recent years witnessed burst pre-training NLP, BERT , RoBERTa , XLNet BART , greatly improve capability language understanding generation. However, researches towards single-modal learning used single-modal scenarios. %which greatly restricts ability process multi-modal information. In order adapt multi-modal scenarios, series multi-modal pre-training methods proposed pre-trained corpus image-text pairs, ViLBERT , VisualBERT UNITER , greatly improve ability process multi-modal information. However, models utilize limited corpus image-text pairs cannot effectively adapted single-modal scenarios . %Moreover, size corpus image-text pairs limited, large scale single-modal data can't effectively utilized. A smarter AI system able process different modalities information effectively. There large scale data different modalities Web, mainly textual visual information. The textual knowledge visual knowledge usually enhance complement other. As example shown Figure , difficult answer question correctly visual information image. However, connect visual information textual information describes background baseball game, easy determine correct answer. Also, visual information make easier understand scene described text. The research neuroscience \citet{van2018neuronal} reveals parts human brain responsible vision learn process kinds information, including touch sound. Inspired research, propose design unified-modal architecture UNIMO process multi-scene multi-modal data input, including textual, visual vision-and-language data, shown Figure . The greatest challenge unify different modalities align unify semantic space generalizable different modalities data. Existed cross-modal pre-training methods try learn cross-modal representations based limited image-text pairs simple image-text matching masked language modeling . They learn specific representations image-text pairs, generalizable single-modal scenarios. So performance drop dramatically applied language tasks . In work, UNIMO learns visual representations textual representations similar ways, unify semantic space via cross-modal contrastive learning based large-scale corpus image collections, text corpus image-text pairs. %Our unified-modal architecture utilize large scale image collections text corpus, align visual textual information semantic space via cross-modal contrastive learning image-text pairs. %Effectively utilizing large-scale images text corpus improve capability vision textual understanding respectively. UNIMO effectively utilizes large-scale text corpus image collections learn general textual visual representations. The CMCL aligns visual representation textual representation, unifies semantic space based image-text pairs. To facilitate different levels semantic alignment vision language, propose utilize series text rewriting techniques improve diversity cross-modal information. As shown Figure , utilize back-translation generate several positive examples image-text pair. Also, enhance detail semantic alignment text image, parse caption scene graph randomly replace either objects, attributes relations caption generate various negative samples. Sentence-level retrieval replacement also utilized enhance sentence-level alignment. In way, model effectively unify different levels visual textual representations semantic space. The unified-modal architecture mainly following advantages compared previous methods:","  Existed pre-training methods either focus on single-modal tasks or multi-modal tasks, and cannot effectively adapt to each other. They can only utilize single-modal data  or limited multi-modal data . In this work, we propose a unified-modal pre-training architecture, namely UNIMO, which can effectively adapt to both single-modal and multi-modal understanding and generation tasks. Large scale of free text corpus and image collections can be utilized to improve the capability of visual and textual understanding, and cross-modal contrastive learning  is leveraged to align the textual and visual information into a unified semantic space over a corpus of image-text pairs. As the non-paired single-modal data is very rich, our model can utilize much larger scale of data to learn more generalizable representations. Moreover, the textual knowledge and visual knowledge can enhance each other in the unified semantic space. The experimental results show that UNIMO significantly improves the performance of several single-modal and multi-modal downstream tasks."
"Although 7,000 languages spoken worldwide~, several dozen enough data available support supervised speech recognition, many languages even employ writing system~. In contrast, people learn use spoken language long learn read write, suggesting linguistic annotation prerequisite speech processing systems. This line reasoning motivates research aims discover meaningful linguistic abstractions directly speech signal, intention could reduce reliance spoken language systems text transcripts. A rich body work recently emerged investigating representation learning speech using visual grounding objectives~, well word-like subword-like linguistic units made emerge within models~. So far, efforts predominantly focused inference, goal learn mapping speech waveforms semantic embedding space. Generation speech conditioned point semantic space less explored, focus work. We hypothesize generative approaches offer interesting advantages relying solely inference. For example, prior works demonstrated capability recognizing visually descriptive words, shown learn non-visual words grammar. Our experiments show aspects spoken language learned degree visually-grounded generative model speech. Specifically, introduce model capable directly generating fluent spoken audio captions images without need natural language text, either intermediate representation form supervision training . Tremendous progress made recently natural language image caption generation~ naturalistic text-to-speech synthesis ~. Combining models provides means generating spoken image descriptions, existing approaches training models reliant text training. Instead, leverage sub-word speech units discovered using self-supervised learning objective drop-in replacement text. We hypothesize using techniques, even wider variety traditionally text-based NLP models could applied speech data without need transcription automatic speech recognition systems. Because human languages utilize small, discrete phonetic inventories~, posit framework applicable language world. In experiments, demonstrate set discovered speech units function role. We find greatest success units discrete, exhibit low frame-rate, highly robust speaker environmental variability. The main contributions paper follows: 1. The first methodology fluent image-to-speech synthesis rely text. A critical aspect approach factorizing model Image-to-Unit module Unit-to-Speech module, speech units discovered self-supervised fashion. This approach enables disentanglement linguistic variability acoustic/speaker variability. 2. Extensive analysis properties required learned units replace text. While idea may seem simple straightforward, obtaining proper units trivial task. In fact, units experimented paper fail serve drop-in replacements. Moreover, demonstrate deemed good units vary significantly inference generation. 3. Demonstrating insufficiency beam search-based evaluation. We show even I2U model fails generate sensible caption beam search decoding, still produce reasonable captions sampling posterior, hinting posterior mode-based evaluation inspect limited aspects model. 4. Proposing semantic diversity-aware metric. We identify issues existing metric~ propose M-SPICE sampling-based evaluation address problems. 5. Over 600,000 spoken audio captions MSCOCO dataset. We collect 742 hours speech 2,352 people tasked reading caption loud. This dataset made publicly available support work intersection speech, language, vision."," In this paper we present the first model for directly synthesizing fluent, natural-sounding spoken audio captions for images that does not require natural language text as an intermediate representation or source of supervision. Instead, we connect the image captioning module and the speech synthesis module with a set of discrete, sub-word speech units that are discovered with a self-supervised visual grounding task. We conduct experiments on the Flickr8k spoken caption dataset in addition to a novel corpus of spoken audio captions collected for the popular MSCOCO dataset, demonstrating that our generated captions also capture diverse visual semantics of the images they describe. We investigate several different intermediate speech representations, and empirically find that the representation must satisfy several important properties to serve as drop-in replacements for text."
"Knowledge distillation technique train smaller, efficient student models learning larger teacher models, usually mimicking teacher's output. In scope neural machine translation , source-side monolingual data run teacher model produce output learnt student. The absence parallel data requirements allows student model trained data choices. This research focuses exploring use monolingual datasets knowledge distillation find data used. This research focuses three aspects. The first language origin monolingual data. Student models trained additional data form source-side monolingual data. Besides that, model also trained back-translation data constructed target-side monolingual data. We show using source-side target-side data important improves performance , depending test-set's language origin. Secondly, explore source monolingual data. Some research suggests uses data teacher student. On hand, research makes use knowledge distillation NMT uses additional dataset, top dataset learnt teacher. We explore whether using seen data necessary, find student trained new unseen monolingual data performs equally one trained dataset teacher. The amount data, including synthetic ones affects model performance. Therefore, last thing explore monolingual data size. We find adding monolingual data generally better. However, varied training data based language origin much important.","  % Smaller, lightweight Neural Machine Translation  models can be trained with interpolated knowledge distillation by learning from the output of larger NMT model. To do so, the teacher translates text from source-language to target-language, which are then combined into a dataset for student.   We explore two types of monolingual data that can be included in knowledge distillation training for neural machine translation . The first is the source-side monolingual data. Second, is the target-side monolingual data that is used as back-translation data. Both datasets are translated by a teacher model from source-language to target-language, which are then combined into a dataset for smaller student models.  We find that source-side monolingual data improves model performance when evaluated by test-set originated from source-side. Likewise, target-side data has a positive effect on the test-set in the opposite direction. We also show that it is not required to train the student model with the same data used by the teacher, as long as the domains are the same. Finally, we find that combining source-side and target-side yields in better performance than relying on just one side of the monolingual data."
"%What ToD Task-oriented dialogue systems core technology current state-of-the-art smart assistant . These systems either modularized, Natural Language Understanding , Dialogue State Tracking , Dialogue Policy Natural Language Generation , end-to-end, single model implicitly learn issue APIs system responses . % current problem trying solve These systems often updated new features based user needs, e.g., adding new slots intents, even completely new domains. However, existing dialogue models trained assumption fixed dataset beginning training, designed add new domains functionalities time, without incurring high cost whole system retraining. Therefore, ability acquire new knowledge continuously, a.k.a. Continual Learning , crucial design dialogue system. Figure shows high-level intuition CL ToDs. In setting main challenge catastrophic forgetting. This phenomena happens since distributional shift tasks curriculum leads catastrophic forgetting previously acquired knowledge. To overcome challenge three kind methods usually deployed loss regularization, avoiding interfere previously learned task, rehearsal, uses episodic memory recall previously learned tasks, architectural, adds task-specific parameters learned task. However, architectural methods usually considered baseline, especially sequence-to-sequence generation tasks, usually require step testing selecting parameter use given task. To best knowledge, Continual Learning task-oriented dialogue systems mostly unexplored studied specific settings using tasks learned continuously. Given importance task dialogue setting, believe comprehensive investigation required, especially comparing multiple settings baselines. Therefore paper: In Section introduce basic concepts notation used throughout paper, task-oriented dialogue modelling continual learning, Section introduce proposed architectural CL method, Section describe datasets, baselines, evaluation metrics experimental settings, Section describe main findings paper. % Based experimental results, discovered two technique particularly effective, linear cost respect number learned tasks. To elaborate, rehearsal-based methods number samples stored episodic-memory grows linearly learned task, instead architectural methods number parameters grows linearly. Hence concluding absolute best comparing different methods based resources needed, term additional parameters sample stored memory."," Continual learning in task-oriented dialogue systems can allow us to add new domains and functionalities through time without incurring the high cost of a whole system retraining. In this paper, we propose a continual learning benchmark for task-oriented dialogue systems with 37 domains to be learned continuously in four settings, such as intent recognition, state tracking, natural language generation, and end-to-end. Moreover, we implement and compare multiple existing continual learning baselines, and we propose a simple yet effective architectural method based on residual adapters. Our experiments demonstrate that the proposed architectural method and a simple replay-based strategy perform comparably well but they both achieve inferior performance to the multi-task learning baseline, in where all the data are shown at once, showing that continual learning in task-oriented dialogue systems is a challenging task. Furthermore, we reveal several trade-off between different continual learning methods in term of parameter usage and memory size, which are important in the design of a task-oriented dialogue system. The proposed benchmark is released together with several baselines to promote more research in this direction."
"% Background: % What MT, history MT, current state MT % What NMT, current state NMT % Reason: % Sufficient necessity condition writing article % Organization article Machine Translation important task aims translate natural language sentences using computers. The early approach machine translation relies heavily hand-crafted translation rules linguistic knowledge. As natural languages inherently complex, difficult cover language irregularities manual translation rules. With availability large-scale parallel corpora, data-driven approaches learn linguistic information data gained increasing attention. Unlike rule-based machine translation, Statistical Machine Translation learns latent structures word alignments phrases directly parallel corpora. Incapable modeling long-distance dependencies words, translation quality SMT far satisfactory. With breakthrough deep learning, Neural Machine Translation emerged new paradigm quickly replaced SMT mainstream approach MT. Neural machine translation radical departure previous machine translation approaches. On one hand, NMT employs continuous representations instead discrete symbolic representations SMT. On hand, NMT uses single large neural network model entire translation process, freeing need excessive feature engineering. The training NMT end-to-end opposed separately tuned components SMT. Besides simplicity, NMT achieved state-of-the-art performance various language pairs. In practice, NMT also becomes key technology behind many commercial MT systems. As neural machine translation attracts much research interest grows area many research directions, believe necessary conduct comprehensive review NMT. In work, give overview key ideas innovations behind NMT. We also summarize resources tools useful easily accessible. We hope tracing origins evolution NMT, stand shoulder past studies, gain insights future NMT. The remainder article organized follows: Section review methods NMT. We first introduce basics NMT, selectively describe recent progress NMT. We focus methods related architectures, decoding, data augmentation. Section summarize resources parallel monolingual corpora publicly available researchers. Section describe tools useful training evaluating NMT models. Finally, conclude discuss future directions Section."," Machine translation  is an important sub-field of natural language processing that aims to translate natural languages using computers. In recent years, end-to-end neural machine translation  has achieved great success and has become the new mainstream method in practical MT systems. In this article, we first provide a broad review of the methods for NMT and focus on methods relating to architectures, decoding, and data augmentation. Then we summarize the resources and tools that are useful for researchers. Finally, we conclude with a discussion of possible future research directions. %Machine translation  is an important sub-field of natural language processing which aims to translate natural language sentences between different languages using computers. Recent years has witnessed the great success of end-to-end neural machine translation  models, which has dominated the mainstream approach in commercial machine translation systems. In this work, we first provide a broad review of the methods and challenges in NMT. We introduce three basic components in NMT methods, namely modeling, inference, and learning. The modeling part starts with the encoder-decoder framework and the celebrated attention mechanism, which is followed by Recurrent Neural Networks , Convolutional Neural Networks , and Self-Attention Networks  as potential instances in an NMT architecture. The inference part focuses on the generation of translation sentences from NMT models, which consists of autoregressive,  non-autoregressive, and bidirectional decoding methods. The learning part concentrates on the methods that enhances the expressive capacity of NMT models to learn from data. We highlight the design of training objectives and the use of monolingual data in this part. In addition to the three basic parts, we highlight some of the most significant challenges in NMT, including open vocabulary, prior knowledge integration, as well as the interpretability and robustness issues. Then we summarize useful resources and tools for MT research and maintainance. Finally, we conclude with a discussion of promising future research directions."
"NMT task transforming source sequence new form particular target language using deep neural networks. Such networks commonly encoder-decoder architecture , encoder maps given input sequence intermediate representation decoder uses representation generate candidate translations. Both encoder decoder neural networks trained jointly. Due sequential nature NMT task, early models usually relied recurrent architectures , benefited sliding feature convolutional kernels encode/decode variable-length sequences . Recently, Transformers shown promising results NMT become new standard field. They follow concept encoding decoding relatively different fashion. A Transformer fundamentally feed-forward model unique neural components alter traditional translation pipeline accordingly. Therefore, expected model behaves differently recurrent convolutional counterparts. Our goal research study aspect presence noise. NMT engines trained clean samples provide high-quality results tested similarly clean texts, break easily noise appears input . They designed handle noise default Transformers exception. Many previous works focused issue studied different architectures . In work, particularly focus Transformers\footnote{We assume reader already familiar Transformer architecture.} relatively new extent understudied. A common approach make NMT models immune noise fine-tuning , noisy version input tokens intentionally introduced training decoder forced generate correct translations despite deformed inputs. FT quite useful almost situations needs run optimal setting effective. In experiments, propose slightly different learning-rate scheduler improve FT. We also define new extension modifies input words also adds complementary tokens target side. We refer extension Target Augmented Fine-Tuning , first contribution paper. In study, realized data augmentation techniques might sufficient enough cases need compatible training process neural architecture deal noise. Therefore, propose Controlled Denoising whereby noise added source sequences training encoder supposed fix noisy words feeding decoder. This approach implemented via auxiliary loss function similar adversarial training. CD second contribution. CD takes care noise encoder side, propose Dual-Channel Decoding strategy study happens decoder also informed input noise. DCD supports multi-tasking -channel decoder samples target tokens corrects noisy input words simultaneously. This form fusing translation knowledge noise-related information led interesting results experiments. DCD third last contribution work. The remainder paper organised follows: First, review previously reported solutions problem noise NMT Section , present details methods intuition behind Section . To validate methods, report experimental results Section . Finally, conclude paper discuss possible future directions Section ."," Transformers \cite{transformer} have brought a remarkable improvement in the performance of neural machine translation  systems, but they could be surprisingly vulnerable to noise. Accordingly, we tried to investigate how noise breaks Transformers and if there exist solutions to deal with such issues. There is a large body of work in the NMT literature on analyzing the behaviour of conventional models for the problem of noise but it seems Transformers are understudied in this context.  Therefore, we introduce a novel data-driven technique to incorporate noise during training. This idea is comparable to the well-known fine-tuning strategy. Moreover, we propose two new extensions to the original Transformer, that modify the neural architecture as well as the training process to handle noise. We evaluated our techniques to translate the English--German pair in both directions. Experimental results show that our models have a higher tolerance to noise. More specifically, they perform with no deterioration where up to $10$\% of entire test words are infected by noise."
"Cross-lingual word embeddings represent words two languages shared space, semantically similar words different languages close other. Early work focused jointly learning CLWEs two languages, relying strong cross-lingual supervision form parallel corpora bilingual dictionaries . However, approaches later superseded offline mapping methods, separately train word embeddings different languages align unsupervised manner self-learning adversarial training . Despite advantage requiring parallel resources, mapping methods critically rely underlying embeddings similar structure, known isometry assumption. Several authors observed assumption generally hold, severely hindering performance methods . In later work, \citet{ormazabal-etal-2019-analyzing} showed issue arises trying align separately trained embeddings, joint learning methods susceptible it. In paper, propose alternative approach limitation, still work without parallel resources. The core idea method fix target language embeddings, learn aligned embeddings source language scratch. This prevents structural mismatches result independently training embeddings different languages, learning source embeddings tailored particular set target embeddings. For purpose, use extension skip-gram leverages translated context words anchor points. So translate context words, start weak initial dictionary, iteratively improved self-learning, incorporate restarting procedure make method robust. Thanks this, approach effectively work without human-crafted bilingual resources, relying simple heuristics existing unsupervised mapping method build initial dictionary. Our experiments confirm effectiveness approach, outperforming previous mapping methods bilingual dictionary induction obtaining competitive results zero-shot cross-lingual transfer learning XNLI.","  Recent research on cross-lingual word embeddings has been dominated by unsupervised mapping approaches that align monolingual embeddings. Such methods critically rely on those embeddings having a similar structure, but it was recently shown that the separate training in different languages causes departures from this assumption. In this paper, we propose an alternative approach that does not have this limitation, while requiring a weak seed dictionary  as the only form of supervision. Rather than aligning two fixed embedding spaces, our method works by fixing the target language embeddings, and learning a new set of embeddings for the source language that are aligned with them. To that end, we use an extension of skip-gram that leverages translated context words as anchor points, and incorporates self-learning and iterative restarts to reduce the dependency on the initial dictionary. Our approach outperforms conventional mapping methods on bilingual lexicon induction, and obtains competitive results in the downstream XNLI task."
"Robust accurate detection hate speech important minimizing risk harm online users. However, task proven remarkably difficult concerns raised performance, generalizability fairness existing systems. A key challenge research community lack high quality datasets freely shared among researchers, finegrained annotations, contain challenging edge-case content unduly biased over-representation certain demographic groups. We address problems online hate classification utilizing system dynamic data collection, model training evaluation. Specifically, use human-and-model-in-the-loop approach, whereby initial model trained annotators tasked entering content would fool making incorrect classification. Models retrained collected data process repeated. New rounds data collected, annotators still trying trick improved models entering difficult unusual forms content. In way models `learn worst' challenging content shown, faster hopefully improve. The dataset formation organized four 10,000 phases. Round 1 contains content created synthetically annotators without direction. Round 2a contains content created using directed `pivots' Round 2b contains perturbed counterfactual `contrast sets'~ entries 2a. Round 3 contains content inspired real world hate, well associated perturbations, using out-of-distribution annotators testing. Each round data collection designed address issues appeared previous round. The model error rate decreased across rounds, 72.1\% first round 35.8\% last round, showing models became increasingly harder trick -- even though content become progressively adversarial annotators became experienced. This work makes three major contributions online hate classification research. First, present first dataset online hate classification created dynamically using human-and-model-in-the-loop process. The system use closely documented models create made publicly available. Second, new dataset 40,623 synthetic entries presented 55\% hate, including fine-grained annotations trained annotators label, type, target pivot . We also mark dataset whether entry tricked target model round. Third, part dataset present 14,000 challenging contrastive examples, created dynamic data generation process. Dynamic dataset generation human-and-model-in-the-loop approach offers several advantages static datasets. First, problems addressed work conducted -- rather creating dataset discovering inadvertent design flaws, would case static benchmarks. Second, model-in-the-loop means annotators' work guided model; receive real-time feedback model effectively different strategies beating it; lets target efforts exploit key weaknesses, creating dataset many hard-to-classify entries. Third, dataset constructed better meet requirements machine learning; dataset balanced, comprising 54\% hate. It includes hate targeted large number targets, providing variety model learn from, many entries directed counter established problems hate detection model training, overfitting keywords."," We present a first-of-its-kind large synthetic training dataset for online hate classification, created from scratch with trained annotators over multiple rounds of dynamic data collection. We provide a 40,623 example dataset with annotations for fine-grained labels, including a large number of challenging contrastive perturbation examples. Unusually for an abusive content dataset, it comprises 54\% hateful and 46\% not hateful entries. We show that model performance and robustness can be greatly improved using the dynamic data collection paradigm. The model error rate decreased across rounds, from 72.1\% in the first round to 35.8\% in the last round, showing that models became increasingly harder to trick -- even though content become progressively more adversarial as annotators became more experienced. Hate speech detection is an important and subtle problem that is still very challenging for existing AI methods. We hope that the models, dataset and dynamic system that we present here will help improve current approaches, having a positive social impact."
"Speech separation, also known cocktail party problem, aims separate target speech interference background . It often used front end speech recognition improving accuracy human-machine interaction. Conventional speech separation technologies include computational auditory scene analysis , non-negative matrix factorization , HMM-GMM , minimum mean square error . Recently, deep learning based speech separation becomes new trend , focus paper. According whether speakers閳 information known prior, deep-learning-based speech separation techniques divided three categories, speaker-dependent , target-dependent, speaker-independent speech separation. Speaker-dependent speech separation needs known prior information speakers, limits practical applications. Nowadays, research speech separation mostly speaker-independent target-dependent. Speaker-independent speech separation based deep learning faces speaker permutation ambiguity problem. In order solve problem, two techniques proposed. The first one deep clustering % . It projects time-frequency unit higher-dimensional embedding vector deep network, conducts clustering embedding vectors speech separation. The second technique permutation invariant training % . For training mixture, picks permutation speakers minimum training error among possible permutations train network. % Besides, effective algorithm based deep learning, deep ensemble learning deep attractor network. Target-dependent speech separation based deep learning aims extract target speech mixture given prior knowledge target speaker. The earliest speech separation method takes target speaker training target . It train model target speaker, limits practical use. To prevent training model target speaker, speaker extraction takes speaker codes extracted speaker recognition system part network input . Some representative speaker extraction methods follows. applies context adaptive deep neural network extract target speaker speaker adaptation layer. It takes estimated mask ideal binary mask training objective. proposed temporal spectrum approximation loss estimate phase sensitive mask target speaker. generalized end-to-end speaker-independent speech separation end-to-end speaker extraction. % It practical registered speakers need responded, speaker diarization speech recognition . The aforementioned methods single-channel methods. Although work well clean scenarios, performance degrades significantly reverberant scenarios. To improve performance speech separation reverberant scenarios, many multichannel methods proposed, following two major forms. The first form combines spatial features extracted microphone arrays, interaural time difference interaural level difference, spectral features input single-channel speech separation networks . The second form uses deep network predict mask speaker channel, conducts beamforming speaker . For brevity, call method deep beamforming. Some methods combined two forms boosting advantages together reverberant scenarios, e.g. . The aforementioned multichannel methods studied traditional fixed arrays, linear arrays spherical arrays. However, far-field speech separation problems high reverberation, suffer significant performance degradation. How maintain estimated speech high quality throughout interested physical space broad interests. Ad-hoc microphone array, group randomly distributed microphones collaborating other, solution problem. Figure gives comparison example target speaker extraction problem fixed array left ad-hoc microphone array right. From figure, see that, compared fixed array far target speaker, ad-hoc microphone array several apparent advantages. First, ad-hoc microphone array may put number microphones around target speaker, significantly reduced probability far-field speech processing. By channel selection, might able form local microphone array around target speaker. At last, may able incorporate application devices various physical sizes. In literature, ad-hoc microphone arrays consistently important research topic . However, face many practical problems due lack important priors. Recently, addresses difficulties ad-hoc microphone arrays, lack priors insufficient estimation variables, deep learning first time. The proposed method, named deep ad-hoc beamforming , originally designed speech enhancement only, predicts segment-level signal-to-noise-ratio deep neural networks supervised channel selection. Later on, speech separation methods based ad-hoc microphone arrays proposed. proposed transform-average-concatenate strategy filter-and-sum network realize channel reweighting/selection ability ad-hoc microphone arrays. Because ad-hoc microphone arrays lack prior number spatial distribution microphones, proposed network architecture interleaving inter-channel processing layers temporal processing layers leverage information across time space alternately. %{\color{brown} ASR ad-hoc microphone array...} % The filter-and-sum network first conducts pre-separation selected reference microphone estimating beamforming filters, estimates beamforming filters remaining microphones based pair-wise cross-channel features. They improved channel reweighting/selection ability FaSNet transform-average-concatenate strategy ad-hoc microphone arrays. However, existing deep learning based speech separation ad-hoc microphone arrays speaker-independent. To knowledge, target-dependent speech separation ad-hoc microphone arrays far explored yet. In many applications, extracting tracking target speech interests separating mixture components. This particularly case ad-hoc microphone arrays, several speakers may locate far apart talk independently. In paper, propose target-dependent speech separation algorithm ad-hoc microphone arrays, named DAB based speaker extraction . Our algorithm consists three components: first, propose supervised channel selection based speaker extraction, applies bi-directional long short-term memory networks estimate utterance-level SNR target speaker. Then, employ heuristic channel selection algorithms pick channels high SNRs. We apply single-channel speaker extraction algorithm selected channels mask estimation problem target speech. At last, use estimated masks derive beamformer target speaker, minimum variance distortionless response . Experimental results WSJ0-adhoc corpus show proposed DABse performs well reverberant environments. The rest paper organized follows. We introduce signal model speaker extraction problem ad-hoc microphone arrays Section . Then, present deep ad-hoc beamforming system based speaker extraction Section . In Section , present experimental results. Finally, conclude study Section ."," % abstract %\parttitle{First part title} %if any %Text for this section. %\parttitle{Second part title} %if any %Text for this section. Recently, the research on ad-hoc microphone arrays with deep learning has drawn much attention, especially in speech enhancement and separation. Because an ad-hoc microphone array may cover such a large area that multiple speakers may locate far apart and talk independently, target-dependent speech separation, which aims to extract a target speaker from a mixed speech, is important for extracting and tracing a specific speaker in the ad-hoc array. However, this technique has not been explored yet. In this paper, we propose deep ad-hoc beamforming based on speaker extraction, which is to our knowledge the first work for target-dependent speech separation based on ad-hoc microphone arrays and deep learning. The algorithm contains three components. First, we propose a supervised channel selection framework based on speaker extraction, where the estimated utterance-level SNRs of the target speech are used as the basis for the channel selection. Second, we apply the selected channels to a deep learning based MVDR algorithm, where a single-channel speaker extraction algorithm is applied to each selected channel for estimating the mask of the target speech. We conducted an extensive experiment on a WSJ0-adhoc corpus. Experimental results demonstrate the effectiveness of the proposed method."
"Supervised semi-supervised Machine Learning algorithms ubiquitous analysis social media data. At core algorithms ability make sense vast amount semi-structured real-time data streams, allowing automatically categorize filter new data examples into, usually pre-defined, classes. Multi-class text classification successfully used public health surveillance, election monitoring, vaccine stance prediction~\parencite{salathe2011assessing,bermingham2011using,brownstein2009digital}. In recent years algorithms also developed mitigate negative effects social media, detection cyber-bullying, hate speech, misinformation, automated accounts ~\parencite{reynolds2011using,davidson2017automated,shu2017fake,davis2016botornot}. The microblogging service Twitter played central role efforts, serves public medium provides easy access real-time data public APIs, making primary focus work. Twitter well described classical example non-stationary system frequently emerging disappearing topical clusters~\parencite{costa2014concept}. This poses problems aforementioned applications, underlying data distribution different training time time algorithm's application real world. This phenomenon known concept drift~\parencite{schlimmer1986incremental} lead change performance algorithm time. It important distinguish concept drift reasons performance differences training testing, random noise due sampling biases differences data preprocessing~\parencite{vzliobaite2010learning,webb2016characterizing}. A classic example concept drift change meaning classes, requires update learned class decision boundaries classifier. This sometimes also referred real concept drift. Often, however, observed performance change consequence change underlying data distribution, leading known virtual drift~\parencite{widmer1996learning,tsymbal2004problem}. Virtual drift overcome supplemental learning, i.e.\ collecting training data new environment. A good example periodic seasonality effects, may fully represented initial training data become fully visible time. However, practice usually difficult disentangle virtual real concept drift, consequence treated effect~\parencite{vzliobaite2010learning}. On Twitter concept drift might appear different time scales different rates. Sudden shifts debate might triggered quickly evolving news cycle catastrophic event. Concept drift may also slow process way topic discussed gradually changes time. A substantial amount work dedicated detecting overcoming concept drift~\parencite{widmer1996learning,vzliobaite2010learning,elwell2011incremental}. Three basic re-training procedures overcoming concept drift proposed: time-window approach, incremental model, ensemble model~\parencite{costa2014concept}. In time-window approach, sliding window recent training examples used train algorithm. In approach, algorithm ignores training data collected outside time window. The incremental model, contrast, uses previously collected training examples re-train model. Lastly, ensemble model trains model time window uses consensus previous models future predictions. As found in~\parencite{costa2014concept}, case hashtag prediction Twitter data, incremental method gave best results. Although sophisticated methods proposed estimate concept drift unsupervised way~\parencite{katakis2010tracking,yang2008conceptual}, practice, certain amount re-annotation detection re-training models seems unavoidable. The decision newly collected data annotate points exploration-exploitation dilemma, usually addressed context active learning framework~\parencite{settles2009active}. The Crowdbreaks platform~\parencite{muller2019crowdbreaks} example framework built goal exploring optimal solutions problem order overcome concept drift. A change underlying data distribution might necessarily negative impact classifier performance. It conceivable, example, polarisation debate Twitter topic could even lead improvement classifier performance. It therefore important ask much worried concept drift: even model performance decrease, real impacts analysis interpretation might negligible. The consequences concept drift task-, environment-, model-dependent~\parencite{vzliobaite2016overview}. Here, address concept drift specific case vaccine stance classification. Vaccine stance classification Twitter data widely studied shown promising links vaccination decision making vaccine uptake rates different countries~\parencite{salathe2011assessing,bello2017detecting}. The COVID-19 pandemic emphasizes importance, evolving concerns vaccines may significantly influence effect~\parencite{johnson2020online,burki2020online}. To best knowledge, one study directly addressed concept drift vaccine stance classification. In study~\parencite{d2019monitoring} tweets posted September 2016 January 2017 Italian language, authors find substantial improvement model incremental re-training specific events. Re-training performed 60 newly annotated tweets seven manually selected events. The authors conclude either original algorithm already quite robust towards concept change, newly collected training data small see effect. Here, use FastText~\parencite{joulin2016bag} BERT ~\parencite{devlin2018bert}, two commonly used models social media text classification. Most work topic concept drift conducted using classical machine learning models, also FastText belongs. These types models reliant high-quality annotation data. More recently, models transformer family, BERT~\parencite{devlin2018bert}, proposed, require significantly less annotation data. In follows, examine whether two models also share different concept drift characteristics. The goal work emulate typical social media analysis study, data collected certain period time, supervised machine learning model trained subset annotated data. The model published used predict newly collected data. First, try answer whether concept drift observed, so, rate occurs. Second, investigate influence study duration amount annotation data used. Lastly, examine extent concept drift influences final analysis outcomes, case sentiment index.","   Social media analysis has become a common approach to assess public opinion on various topics, including those about health, in near real-time.   The growing volume of social media posts has led to an increased usage of modern machine learning methods in natural language processing.   While the rapid dynamics of social media can capture underlying trends quickly, it also poses a technical problem: algorithms trained on annotated data in the past may underperform when applied to contemporary data.   This phenomenon, known as concept drift, can be particularly problematic when rapid shifts occur either in the topic of interest itself, or in the way the topic is discussed.   Here, we explore the effect of machine learning concept drift by focussing on vaccine sentiments expressed on Twitter, a topic of central importance especially during the COVID-19 pandemic.   We show that while vaccine sentiment has declined considerably during the COVID-19 pandemic in 2020, algorithms trained on pre-pandemic data would have largely missed this decline due to concept drift.   Our results suggest that social media analysis systems must address concept drift in a continuous fashion in order to avoid the risk of systematic misclassification of data, which is particularly likely during a crisis when the underlying data can change suddenly and rapidly."
"In paper, tackle problem screening finite pool documents, aim retrieve relevant documents satisfying given set predicates verified human machines . In context, document satisfy least one predicate, treated irrelevant. A predicate represents property, unit meaning, given natural language . By means predicate might interpreted variety ways text, making keywords-based search hard reach high recall keeping decent level precision . We interpret screening problem high recall problem, i.e., aim retrieve relevant documents maximizing precision. %we assume predicates candidate documents given % Since predicates interpreted variety ways, makes problem document screening challenging especially little training data. The screening finds application many domains, i) systematic literature reviews ; % -SLRs- AND papers studying older adults }; ii) database querying - items filtered in/out based predicates ; iii) hotel search - hotels retrieve based upon filters interest . Consequently, document screening instance finite pool binary classification problems , need classify finite set objects minimizing cost. % As instance problem, choose screening phase SLRs makes problem rather challenging since review different unique set predicates . Typically, authors SLR retrieve candidate pool documents executing keywords-based query database Scopus. To avoid missing papers, query tends inclusive, means returns hundreds thousands results later manually screened researchers based predefined predicates. For example, researchers might look papers describe following predicates time: 1) ""include papers study older adults 85+ years"", 2) ""include papers conducted randomized controlled trial"", 3) "" include papers behavioral intervention"". Therefore, conjunctive query three inclusive predicates. A bottleneck screening process predicate evaluation, i.e., identifying given predicates satisfied current document. For example, literature reviews, authors validate predicates, however, time-consuming, exhaustive, expensive . An effective technique solve screening problems crowdsourcing crowd solve even complex screening tasks high accuracy lower cost compared expert screening . However, achieving good performance crowd-based screening requires deep understanding design tasks model complexity , test filter workers , aggregate results classification decision, improve worker engagement . Machine learning algorithms also made impressive progress solving complex screening tasks. However, obtaining sufficiently large set training data still key bottleneck accurate ML classifiers. Active learning accelerates process minimizing size training data required train better classifiers via selecting informative instances annotation. The effectiveness AL proven many domains , work considers single-label cases multi-label AL problems far less investigated. The challenge applying AL multi-label classification problem algorithm measure unified informativeness unlabeled item across labels. The state art multi-label AL strategies follow object-wise labeling, AL algorithm first finds relevance scores pairs, aggregates scores find informativeness items . However, may ignore interaction labels . \paragraph{Original contribution.} We investigate efficiently combine crowdsourcing ML item screening. It challenging task since budget limited countless number ways spend problem. We propose multi-label AL screening specific sampling technique querying unlabelled items annotating. Our algorithm takes decision choose unlabeled data annotate crowd workers order maximize performance screening task. Unlike existing multi-label AL approaches rely global labeling, choose local labeling method, label determine relevancy item."," In this paper, we explore how to efficiently combine crowdsourcing and machine intelligence for the problem of document screening, where we need to screen documents with a set of machine-learning filters. Specifically, we focus on building a set of machine learning classifiers that evaluate documents, and then screen them efficiently. It is a challenging task since the budget is limited and there are countless number of ways to spend the given budget on the problem. We propose a multi-label active learning screening specific sampling technique -objective-aware sampling- for querying unlabelled documents for annotating. Our algorithm takes a decision on which machine filter need more training data and how to choose unlabeled items to annotate in order to minimize the risk of overall classification errors rather than minimizing a single filter error.  We demonstrate that objective-aware sampling significantly outperforms the state of the art active learning sampling strategies. % on multi-filter classification problems."
"One hallmarks human intelligence ability generalize seamlessly across heterogeneous sensory inputs different cognitive tasks. We see objects, hear sounds, feel textures, smell odors, taste flavors learn underlying concepts present world. Much AI's existing progress multimodal learning, however, focuses primarily fixed set predefined modalities tasks consistent training testing. As result, unclear transfer knowledge models trained one modality another test time. This scenario particularly important low-resource target modalities unlabeled data scarce labeled data even harder obtain . In unimodal case, regarded meta-learning few-shot learning. In contrast, formally define cross-modal generalization setting learning paradigm train model quickly perform new tasks target modality trained different source modality. In paper, study data algorithmic challenges cross-modal generalization succeed. %Such learning paradigm particularly useful leveraging high-resource source modalities help low-resource target modalities, unlabeled data scarce labeled data even harder obtain, audio low-resource languages, real-world environments, medical images. As motivating example, Figure illustrates scenario large-scale image classification benchmarks help audio classification, less studied problem fewer large-scale benchmarks. In ambitious problem statement, key research question becomes: obtain generalization across modalities despite using separate encoders different source target modalities? The technical challenge involves aligning shared knowledge learned source image tasks target audio tasks. Our problem statement differs conventional meta-learning domain adaptation one take advantage source target modality shared encoders helps generalization representation space. In case, discrepancies modalities requires one learn new output concepts expressed new input modalities. As result, cross-modal generalization requires new ideas synchronize multimodal sources targets. What minimal extra supervision required perform alignment? In paper, formalize conditions required successful generalization show another level supervision necessary partial observability across modalities tasks. Supervision comes form cross-modal meta-alignment capture space representations similar concepts different modalities close together ensuring quick generalization new tasks . We introduce novel algorithm called \names\ leverages readily available multimodal data internet meta-alignment cross-modal generalization. Through theoretical analysis empirical ablations, study proposed algorithm strongly weakly paired multimodal data, showing cross-modal generalization possible even limited extra supervision. %How one transfer knowledge learned image classification task speech event classification? The problem cross-modal generalization brings fundamental differences regarding data expressed across different modalities . In comparison meta-learning domain adaptation, different input spaces consist extremely high-dimensional, complex, heterogeneous source target modalities. As result, unable use shortcut sharing encoders commonly seen same-modality, different domain settings allow representation space source target domains. This raises fundamental research question: obtain generalization across modalities despite using separate encoders different source target modalities? These discrepancies modalities requires one learn new output concepts expressed new input modalities. %We show existing domain adaptation, meta-learning, transfer learning approaches unable bridge gap heterogeneous paradigms input modalities output tasks different. % emphasize cant share encoders, need explicit alignment % emphasize different label space, generalize meta-learning % formulate crossmodal ml therefore propose meta alignment % first para ok. like learn different modalities. % second para. compared ml da, 1 critical issue trying crossmodal - hetero data source target. cant use shortcut encoder images different domains. need different encoders 1 each. solve this? need another level supervision help - meta alignment comes in. propose - technique address core technical challenge crossmodal ml learn different encoders. meta alignment way that, contrastive learning approach. %To account technical challenge, formalize conditions required successful generalization show another level supervision necessary partial observability across modalities tasks. This form supervision comes form cross-modal alignment capture space representations similar concepts different modalities close together ensuring quick generalization new low-resource tasks . Our analysis leads novel algorithm based contrastive learning called \names\ leverages either strongly weakly paired multimodal data abundant internet. Finally, carefully study data algorithmic requirements approach succeed theoretical analysis empirical ablations. %Very hard problem crossmodal meta-learning. What minimal amount supervision required solve hard task cross-modal meta-learning? In paper explore theory empirics %We highlight two crucial distinctions: different input spaces consist extremely high-dimensional, complex, heterogeneous source target modalities, exist different task distributions source target modalities, inherent differences label spaces transferring image audio classification tasks. These discrepancies input output spaces requires one learn new output concepts expressed new input modalities. We show existing domain adaptation, meta-learning, transfer learning approaches unable bridge gap heterogeneous paradigms input modalities output tasks different. % handle limited resource modalities task, explore cross-modal approach % note: define modality, concept, task % note: better way saying cross-modal cross-task %, allows us learn classifier transfer source target tasks. %This makes particularly suitable generalization across modalities tasks due presence unseen concepts annotations target modality. %We show space: groups similar concepts expressed across different modalities, well-clustered across concepts, generalizes well new concepts, making particularly suitable generalization across modalities tasks. %While first attempt meta-alignment uses strong pairings across source target modalities , provide extension use weak pairs modalities. Weak pairs represent coarse groupings semantic correspondence better capture many-to-many relations real-world multimodal data allow us use large banks weakly paired multimodal data available internet prepared machine learning studies video data image captioning data . %Finally, quantify trade-offs labeling data target modality versus obtaining better source-target alignment. %provide theoretical justification quantify benefits approach: {\color{red} ZIYIN TODO} \zing[ziyin: mention focus difficulty definition formalization] %instead classical generalization error target modality scales wrt sample complexity target modality, approach bounded sample complexity source modality. As result, error therefore reduced ample samples source modality well-aligned space. We present experiments three cross-modal tasks: generalizing text image, image audio, text speech. In cases, goal classify data new target modality given labeled samples. %We find \names\ accurately performs few-shot alignment concepts different modalities, thereby allowing generalization concepts source modality new concepts target modality. We perform extensive experiments compare related approaches including target modality meta-learning would expected perform well since seen thousands labeled examples target modality meta-training. Surprisingly, \names\ competitive baselines significantly outperforms cross-modal approaches. In addition, study settings target modality suffers noisy limited data, scenario particularly prevalent low-resource modalities. %While setting makes difficult directly train target modality, approach efficiently leverages cross-modal information perform well."," The natural world is abundant with concepts expressed via visual, acoustic, tactile, and linguistic modalities. Much of the existing progress in multimodal learning, however, focuses primarily on problems where the same set of modalities are present at train and test time, which makes learning in low-resource modalities particularly difficult. In this work, we propose algorithms for cross-modal generalization: a learning paradigm to train a model that can  quickly perform new tasks in a target modality  and  doing so while being trained on a different source modality. We study a key research question: how can we ensure generalization across modalities despite using separate encoders for different source and target modalities? Our solution is based on meta-alignment, a novel method to align representation spaces using strongly and weakly paired cross-modal data while ensuring quick generalization to new tasks across different modalities. We study this problem on 3 classification tasks: text to image, image to audio, and text to speech. Our results demonstrate strong performance even when the new target modality has only a few  labeled samples and in the presence of noisy labels, a scenario particularly prevalent in low-resource modalities. %Despite vast differences in these raw modalities, humans seamlessly perceive multimodal data, learn new concepts, and show extraordinary capabilities in generalizing across input modalities. %In addition, our method works particularly well when the target modality suffers from noisy or limited labels, a scenario particularly prevalent in low-resource modalities. %, sometimes outperforming within modality few-shot baselines that have seen thousands of labeled examples from that target modality during meta-training. %\zing[Ziyin: heterogeneous -> multimodal? since we are assuming there is an underlying shared space, so maybe not heterogeneous] %\zing[Ziyin: since this is the first sentence in the intro, maybe remove this?] %Similarly, truly general artificial intelligence  systems must learn to generalize across multiple input modalities and output tasks. %In this work, we define and propose algorithms for a new notion of generalization:  %, languages, and concepts. %We believe that our proposed methods could open new doors towards better generalization in multimodal AI systems."
"Cloud services become increasingly popular expected gain 331.212.6\%\ billion every year Fortune 1,000 . Amazon estimated 1004.11\%-91.58\%82.9\%76.3\% - 91.3\%$ high impacted incidents. Model ablation analysis showed ML models used provided lift final ensemble different incident types. To best knowledge, first one present deployed incident triage service cloud-scale online services. This paper makes three key contributions: This paper organized follow: Section presents background incident management system; Section provides details {\TransferAssistant}; Section shows experimental results; Section describes deployment {\TransferAssistant} Azure; Section discusses lessons learned implications implementing deploying incident triage service cloud scale; Section presents related work; Section concludes paper.","   As cloud services are growing and generating high revenues, the cost of downtime in these services is becoming significantly expensive. To reduce loss and service downtime, a critical primary step is to execute incident triage, the process of assigning a service incident to the correct responsible team, in a timely manner. An incorrect assignment risks additional incident reroutings and increases its time to mitigate by 10x. However, automated incident triage in large cloud services faces many challenges:  a highly imbalanced incident distribution from a large number of teams,    wide variety in formats of input data or data sources,     scaling to meet production-grade requirements, and     gaining engineers' trust in using machine learning recommendations.    To address these challenges, we introduce {\TransferAssistant}, an intelligent incident transfer service combining multiple machine learning techniques -- gradient boosted classifiers, clustering methods, and deep neural networks -- in an ensemble to recommend the responsible team to triage an incident. Experimental results on real incidents in Microsoft Azure show that our service achieves $82.9\%$ F1 score. For highly impacted incidents, {\TransferAssistant} achieves F1 score from $76.3\% - 91.3\%$. We have applied best practices and state-of-the-art frameworks to scale {\TransferAssistant} to handle incident routing for all cloud services. {\TransferAssistant} has been deployed in Azure since October 2017 and is used by thousands of teams daily."
"Program source code contains rich structure information, like syntax structure control data flow. Learning structures hot topic area deep learning source code. In recent years, instead applying basic sequential neural models, researchers used complex neural networks capture explicit structure source code. Most researches use abstract syntax trees easy-to-acquire programming languages semantically equivalent source code. A problem ASTs explicitly reflect structural information beyond syntax dependencies, like control data flow. A viable solution adding different types control data flow edges ASTs generate program graphs, apply graph neural networks programs learn representations . However, approaches consider apart control data flow edges, nodes edges original ASTs also differently typed. For example, ASTs, nodes refer identifiers, nodes define upper-level structures control flows. For parent-child links, relation function definition node function body one arguments apparently different. We believe explicitly add node edge types programs graphs, help neural models understand programs better. Our idea adding types nodes edges AST coincides concept heterogeneous graphs. Heterogeneous graphs, heterogeneous information networks , refer group graphs multiple types nodes edges. A typical example heterogeneous graphs knowledge graphs, nodes different types entities, edges represent different relations. In paper, propose approach building heterogeneous program graphs ASTs. To obtain type AST nodes edges, use abstract syntax description language grammar. After acquire heterogeneous graphs code snippets, need find GNN model effectively represent graphs. Although existing GNN-for-code works pointed exist different types AST nodes, consider node type initial node embedding neglect differences message passing step. So turn sight field heterogeneous graph embeddings. Recently, heterogeneous graph neural networks become widely used heterogeneous graph embedding. Unlike traditional graph neural networks, heterogeneous graph neural networks capable integrating node edge type information message passing stage map different types nodes different feature space. We use heterogeneous graph transformer heterogeneous program graphs calculate representation programs. We evaluate approach two tasks: comment generation method naming, two Python datasets different domains. These two tasks seen two different forms code summarization, require understanding semantics input code snippets. The results show approach outperforms existing GNN models state-of-the-art approaches, indicating extra benefit bringing heterogeneous graph information source code. To summarize, contributions are: To knowledge, first put forward idea representing programs heterogeneous graphs apply heterogeneous GNN source code snippets. We propose approach using ASDL grammars build heterogeneous program graphs program ASTs. We evaluate approach two different tasks involving graph-level prediction source code snippets. Our approach outperforms GNN models comment generation method naming tasks."," Program source code contains complex structure information, which can be represented in structured data forms like trees or graphs. To acquire the structural information in source code, most existing researches use abstract syntax trees . A group of works add additional edges to ASTs to convert source code into graphs and use graph neural networks to learn representations for program graphs. Although these works provide additional control or data flow information to ASTs for downstream tasks, they neglect an important aspect of structure information in AST itself: the different types of nodes and edges. In ASTs, different nodes contain different kinds of information like variables or control flow, and the relation between a node and all its children can also be different.  To address the information of node and edge types, we bring the idea of heterogeneous graphs to learning on source code and present a new formula of building heterogeneous program graphs from ASTs with additional type information for nodes and edges. We use the ASDL grammar of programming language to define the node and edge types of program graphs. Then we use heterogeneous graph neural networks to learn on these graphs. We evaluate our approach on two tasks: code comment generation and method naming. Both tasks require reasoning on the semantics of complete code snippets. Experiment results show that our approach outperforms baseline models, including homogeneous graph-based models, showing that leveraging the type information of nodes and edges in program graphs can help in learning program semantics."
"% Every day pharmaceutical companies receive numerous medical inquiries related products patients, healthcare professionals, research institutes, public authorities variety sources . % These medical inquiries may relate drug-drug-interactions, availability products, side effects pharmaceuticals, clinical trial information, product quality issues, comparison competitor products, storage conditions, dosing regimen, like. % On one hand, single medical inquiry simply question given person searching specific information related medicinal product. On hand, plurality medical inquiries different persons may provide useful insight matters related medicinal products associated medical treatments. % Examples insights could early detection product quality supply chain issues, anticipation treatment trends market events, improvement educational material standard answers/frequently asked question coverage, potential changes treatment pattern, even suggestions new possible indications investigate. % From strategic perspective, information could enable organizations make better decisions, drive organization results, broadly create benefits healthcare community. % transition paragraph - machine learning help However, obtaining high-level general insights complicated task since pharmaceutical companies receive copius amounts medical inquiries every year. Machine learning natural language processing represent promising route automatically extract insights large amounts unstructured medical text. % % % text mining general biomedical domain Natural language processing text mining techniques widely used medical domain, particular emphasis electronic health records. In particular, deep learning successfully applied medical text, overwhelming majority works supervised learning, representation learning learn specialized word vector representations . % %There little work however unsupervised learning unstructured medical text. Conversely, literature unsupervised learning medical text scarce despite bulk real-world medical text unstructured, without labels annotations. % Unsupervised learning unstructured medical text mainly limited development topic models based latent Dirichlet allocation . Examples applications medical domain clinical event identification brain cancer patients clinical reports, modeling diseases predicting clinical order patterns electronic health records, detecting cases noncompliance drug treatment patient forums. % Only recently, word embeddings unsupervised learning techniques combined analyze unstructured medical text study concept diseases, medical product reviews, extract informative sentences text summarization. % real-world corpus medical inquiries challenges In work, combine biomedical word embeddings unsupervised learning discover topics real-world medical inquiries received Bayer\texttrademark. % A real-world corpus medical inquiries presents numerous challenges. From inquirer perspective, often goal convey information requested words possible save time. This leads extensive use acronyms, sentences atypical syntactic structure, occasionally missing verb subject, inquiries comprising exclusively single noun phrase. % Moreover, since medical inquiries come different sources, common find additional information related text source; examples references internal computer systems, form frames alongside actual form content, lot numbers, email headers signatures, city names. % % mixture layman medical language The corpus contains mixture layman medical language depending inquirer either patient healthcare professional. Style content medical inquiries vary quite substantially according therapeutic areas given medicinal product belongs to. % add sentence refer text representation %as one see Fig., As already mentioned, medical inquiries short. More specifically, comprise less fifteen words vast majority cases. % Standard techniques topic modelling based LDA apply, since main assumption - document/text distribution topics - clearly hold given text short. % Approaches based pseudo-documents using auxiliary information also suitable since meaningful pseudo-document auxiliary information available medical inquiries. % Moreoever, models aim learn semantics directly corpus interest. However, recent success pretrained embeddings shows beneficial include semantics learned general corpus, thus providing semantic information difficult obtain smaller corpora. This particularly important limited data short text settings. To end, recently work aimed incorporating word embeddings probabilistic models similar LDA - contrary LDA - satisfies single topic assumption . Even though models include semantic information topic model, evident choose required hyper-parameters, example determining appropriate threshold filtering semantically related word pairs. Concurrently work, document-level embeddings hierarchical clustering combined obtain topic vectors news articles question-answer corpus. % summary Here, propose approach based specialized biomedical word embeddings unsupervised learning discover topics short, unstructured, real-world medical inquiries. This approach - schematically depicted Fig. - used discovery topics medical inquiries received Bayer\texttrademark\ Medical Information regarding oncology medicinal product Stivarga\texttrademark."," %141 words % the motivation Millions of unsolicited medical inquiries are received by pharmaceutical companies every year.  It has been hypothesized that these inquiries represent a treasure trove of information, potentially giving insight into matters regarding medicinal products and the associated medical treatments.  % the challenge However, due to the large volume and specialized nature of the inquiries, it is difficult to perform timely, recurrent, and comprehensive analyses. % the solution Here, we propose a machine learning approach based on natural language processing and unsupervised learning to automatically discover key topics in real-world medical inquiries from customers. This approach does not require ontologies nor annotations.  % the results The discovered topics are meaningful and medically relevant, as judged by medical information specialists, thus demonstrating that unsolicited medical inquiries are a source of valuable customer insights. % the implications and outlook Our work paves the way for the machine-learning-driven analysis of medical inquiries in the pharmaceutical industry, which ultimately aims at improving patient care."
"Dynamic models text aim characterizing temporal changes patterns document generation. Most successful dynamic language models Bayesian nature, lag behind state-of-the-art deep language models terms expressibility. A natural space study temporal aspects language large review datasets found e-commerce sites. The availability millions reviewed items, business services, books movies, whose reviews recorded time scales years, opens possibility develop deep scalable models predict change taste preference users time evolves. Originally, interaction users e-commerce sites studied context collaborative filtering, goal predict user ratings, based user interaction metrics. Here aim look directly content reviews time evolves. %More KDD probably, much focus ratings recommendations %-------- %The shear size e-commerce review web sites naturally lend development data mining tools able provide users way sort relevant information. This task assigned recommender systems. Originally kick started Netflix competition, matrix factorization methods collaborative filtering, aim predicting user ratings based user interaction metrics. This rating based methods lacking unable clarify nature user preferences, particular preferences change time. In order address issue, methodologies exploit costumers reviews gaining attention. %--------- Costumer reviews provide rich natural source unstructured data leverage improve recommender system performance . Indeed, reviews effectively form recommendation. % Recently, variety deep learning solutions recommendation profit ability extract latent representations review data, encoding rich information related users items. % %Review content naturally encodes % This type data % Review content contextual nature, text arises interaction user preferences items hand. % Time represents yet another dimension context, user preference item availability change time % -- indeed, % causal temporal relations known improve performance recommender systems . % Despite fact, % recent natural language processing methodologies rating reviews lag behind incorporating temporal structure language representations. In present work exploit recurrent neural network models point processes, feed neural representations text, characterize costumer reviews. Our goal capture changes user taste item importance time, exploit changes better predict new reviews arriving, actually say. We summarize contributions follows: {} % We present related work Section introduce model Section . The baseline models used comparison paper presented Section . The experimental setup results presented Section . Finally, Section conclude discuss future work."," Deep neural network models represent the state-of-the-art methodologies for natural language processing.  % Here we build on top of these methodologies to incorporate temporal information and model how review data changes with time. % Specifically, we use the dynamic representations of recurrent point process models, % % which encode the nonlinear relations between content and timing of the reviews received by e.g. businesses or services,  % which encode the history of how business or service reviews are received in time,  % to generate instantaneous language models with improved prediction capabilities.  % Simultaneously, our methodologies enhance the predictive power of our point process models by incorporating summarized review content representations.  % % as that encoded in recurrent point process models, and improve the predictive power of these model by incorporating the text representations.  % % Our methodologies resemble that of a hierarchical model, whereupon the temporal information is used as a  representation for the language model.  % We provide recurrent network and temporal convolution solutions for modeling the review content. % We deploy our methodologies in the context of recommender systems,  % as to enhance the expressibility of current models, % effectively characterizing the change in preference and taste of users as time evolves. Source code is available at \cite{source_code}."
"Most authentication methods commonly used today rely users setting custom passwords access accounts devices. Password-based authentications popular due ease use, ease implementation established familiarity users developers method. However studies show users tend set individual passwords predictably, favoring short strings, names, birth dates reusing passwords across sites. Since chosen passwords exhibit certain patterns structure, begs question whether possible simulate patterns generate passwords human user realistically might chosen. Password guessing active field study, recently dominated statistical analysis password leaks construction corresponding generation algorithms . These methods rely expert knowledge analysis various password leaks multiple sources generate rules algorithms efficient exploitation learned patterns. On hand, recent years major advances machine-driven text generation made, notably novel deep-learning based architectures efficient training strategies large amounts training text data. These methods purely data driven, meaning learn structure input training text, without external knowledge domain structure data. % Deep learning models recently shown remarkable performance concerning text classification text generation. Major advancements field fueled development several central directions as: In paper continue exploration data driven deep-learning text generation methods task password-guessing. While applications password guessing already show promising results, frameworks still reach surpass state-of-the-art password generation algorithms. % On hand, considering password guessing problems, popular frameworks well large body state-of-art research suggest advanced deep learning methodologies still explored. Ideally, one would attempt design efficient password-guessing models aided neural networks cutting-edge practices. Our findings contributions summarized follows:","     Password guessing approaches via deep learning have recently been investigated with significant breakthroughs in      their ability to generate novel, realistic password candidates.     In the present work we study a broad collection of deep learning and probabilistic based models in the light of password guessing:      attention-based deep neural networks, autoencoding mechanisms and generative adversarial networks.      We provide novel generative deep-learning models in terms of variational autoencoders exhibiting state-of-art sampling performance,     yielding additional latent-space features such as interpolations and targeted sampling.     Lastly, we perform a thorough empirical analysis in a unified controlled framework over well-known datasets .      Our results not only identify the most promising schemes driven by deep neural networks, but also illustrate the strengths of each approach in terms of generation variability and sample uniqueness."
"% 1 page % Definition importance causality knowledge. % causality knowledge, important knowledge artificial intelligence systems, proven helpful many downstream tasks, especially NLP domain. % % In work, follow ConceptNet COPA focus causal relations daily events. % However, due lack high-quality large-scale causality knowledge resource, application causality knowledge downstream tasks still limited. Humans possess basic knowledge facts understandings commonsense causality everyday life. For example, leave five minutes late, late bus; sun out, likely rain; hungry, need eat. %Causality important commonsense reasoning humans use time, Such causality knowledge shown helpful many NLP tasks. Thus, valuable teach machines understand causality. Causal relations commonsense domain typically contributory contextual. % By contributory\footnote{The two levels absolute causality conditional causality , commonly appear scientific domain rather daily life.}, mean cause neither necessary sufficient effect, strongly contributes effect. By contextual, mean causal relations make sense certain context. The contextual property causal relations important acquisition application causal knowledge. For example, people tell AI assistant ``they hungry'' meeting, basic assistant may suggest order food knowledge `being hungry' causes `eat food'. A better assistant may suggest ordering food meeting knows causal relation `being hungry' `eat food' may plausible meeting context. % \ye{I made small adaptation paragraph } % For example, person middle meeting, he/she may tell AI assistant he/she hungry, good AI assistant may suggest him/her eat food knowledge `being hungry' cause `eat food', extraordinary AI assistant may suggest ``I help order food eat meeting'' knows causal relation `being hungry' `eat food' may plausible context meeting. Without understanding contextual property causal knowledge, achieving level intelligence would challenging. To help machines better understand causality commonsense, many efforts devoted developing causality knowledge bases. For example, ConceptNet ATOMIC leverage human-annotation acquire small-scale high-quality causality knowledge. After that, people try leverage linguistic patterns acquire causality knowledge textual corpus. However, causality knowledge, especially trivial knowledge humans, rarely formally expressed documents, pure text-based approach might struggle covering causality knowledge. Besides that, none take aforementioned contextual property causal knowledge consideration, may restrict usage downstream tasks. % Causal relations commonsense domain typically contributory contextual. % By contributory\footnote{The two levels causality absolute causality conditional causality , commonly appear scientific domain rather daily life.}, mean cause neither necessary sufficient effect, strongly contributes effect. % By contextual, mean causal relations make sense certain context. % The contextual property causal relations important acquisition application causality knowledge. % For example, people tell AI assistant ``they hungry'' meeting, basic assistant may suggest order food knowledge `being hungry' causes `eat food'. A better assistant may suggest ordering food meeting knows causal relation `being hungry' `eat food' may plausible meeting context. % Without understanding contextual property causality knowledge, achieving level intelligence would challenging. % % % } % % % \end{table} % % limitation existing acquisition methods % Conventional approaches \ye{i think elaborated. maybe give example?} However, two drawbacks approaches significantly limit usage downstream tasks: % In paper, propose ground causality knowledge real world explore possibility acquiring causality knowledge visual signals . By so, three major advantages: Videos easily acquired cover rich commonsense knowledge may mentioned textual corpus; Events contained videos naturally ordered time. As discussed by, exists strong correlation temporal causal relations, thus time-consecutive images become dense causality knowledge resource; Objects visual signals act context detected causality knowledge, remedy aforementioned lack contextual property issue existing approaches. To specific, first define task mining causality knowledge time-consecutive images propose high-quality dataset . To study contextual property causal relations, pair events, provide two kinds causality annotations: one causality given certain context one causality without context. Distribution analysis case studies conducted analyze contextual property causality. An example Vis-Causal shown Figure, causal relation ``dog running'' ``blowing leaves'' makes sense context provided dog running leaves, high speed quickly-moved pow cause leaves blow around. Without context ``leaves ground'', causal relation implausible. After that, propose Vision-Contextual Causal model, effectively leverage pre-trained textual representation visual context acquire causality knowledge used baseline method future works. Experimental results demonstrate even though task still challenging, jointly leveraging visual contextual representation, proposed model better identify meaningful causal relations time-consecutive images. To summarize, contributions paper three-fold: We formally define task mining contextual causality visual signal; We present high-quality dataset Vis-Causal; We propose Vision-Contextual Causal model demonstrate possibility mining contextual causality vision signal. % Experimental results prove considering context crucial understanding causality representing visual context textual representation helpful. % Further analysis shows proposed task still challenging current models, may need consider injecting external knowledge better understand videos acquire causality knowledge. % \ye{there's real reference text part into, NLP people might think suitable ACL? maybe add models use description objects represented textual form} % %","  Causality knowledge is crucial for many artificial intelligence systems. Conventional textual-based causality knowledge acquisition methods typically require laborious and expensive human annotations. As a result, their scale is often limited. Moreover, as no context is provided during the annotation, the resulting causality knowledge records  typically do not take the context into consideration. To explore a more scalable way of acquiring causality knowledge, in this paper, we jump out of the textual domain and investigate the possibility of learning contextual causality from the visual signal. Compared with pure text-based approaches, learning causality from the visual signal has the following advantages:  Causality knowledge belongs to the commonsense knowledge, which is rarely expressed in the text but rich in videos;  Most events in the video are naturally time-ordered, which provides a rich resource for us to mine causality knowledge from;  All the objects in the video can be used as context to study the contextual property of causal relations. In detail, we first propose a high-quality dataset Vis-Causal and then conduct experiments to demonstrate that with good language and visual representation models as well as enough training signals, it is possible to automatically discover meaningful causal knowledge from the videos. Further analysis also shows that the contextual property of causal relations indeed exists, taking which into consideration might be crucial if we want to use the causality knowledge in real applications, and the visual signal could serve as a good resource for learning such contextual causality. Vis-Causal and all used codes are available at: \url{https://github.com/HKUST-KnowComp/Vis_Causal}. % In detail, we first identify events from the videos, which are represented with natural sentences, and then leverage the visual signal to predict the contextual causal relations among these events.     % In this work, we mimic how human beings learn causality and explore the possibility of acquiring causality knowledge with visual signal. % To do so, we first define the task of mining contextual causality knowledge from visual signals, which aims at evaluating models' abilities to identify causal relation given certain visual context, and then employ the crowd-sourcing to annotate a high-quality dataset Vis-Causal. % On top of that, we propose a Vision-Contextual Causal  model that can utilize the images as context to better acquire causality knowledge. % Different from existing \revisehm{causality knowledge acquisition works}, \revisehm{to the best of our knowledge, }the proposed solution \revisehm{is the first one that }has the potential to preserve contextual property  of causal relations."
"% The advent deep learning techniques dramatically improved accuracy speech recognition models . Deep learning techniques first saw success replacing Gaussian Mixture Model Acoustic Model part conventional speech recognition systems Feed-Forward Deep Neural Networks , Recurrent Neural Network Long Short-Term Memory networks Convonlutional Neural Networks . In addition this, improvements noise robustness using models motivated auditory processing , data augmentation techniques , beam-forming . Thanks advances, voice assistant devices Google Home Amazon Alexa widely used home environments. Nevertheless, easy run high-performance speech recognition systems devices largely size Weighted Finite State Transducer handling lexicon language model. Fortunately, all-neural end-to-end speech recognition systems introduced need large WFST n-gram Language Model . These complete end-to-end systems started surpassing performance conventional WFST-based decoders large training dataset better choice target unit Byte Pair Encoded subword units. In paper, provide comprehensive review various components algorithms end-to-end speech recognition system. In Sec., give brief overview various neural building blocks E2E Automatic Speech Recognition model. The popular E2E ASR architectures reviewed Sec.. Additional techniques used improve performance E2E ASR models discussed Sec.. Techniques used compression quantization all-neural E2E ASR models covered Sec.. Sec. gives summary paper. % % %# Data augmentation overfitting","   In this paper, we review various end-to-end automatic speech recognition   algorithms and their optimization techniques for on-device applications.   Conventional speech recognition systems comprise a large number of discrete   components such as an acoustic model, a language model, a pronunciation model,    a text-normalizer, an inverse-text normalizer, a decoder based on a Weighted Finite State   Transducer , and so on. To obtain sufficiently high speech recognition   accuracy  with such conventional speech recognition systems, a very large   language model  is usually needed. Hence, the corresponding   WFST size becomes enormous, which prohibits their on-device implementation. Recently, fully neural network end-to-end speech recognition algorithms have been   proposed. Examples include speech recognition systems based on  Connectionist Temporal Classification , Recurrent Neural Network Transducer , Attention-based Encoder-Decoder models , Monotonic   Chunk-wise Attention ,    transformer-based speech recognition systems, and so on. These fully neural   network-based systems require much smaller memory footprints compared to   conventional algorithms, therefore their on-device implementation has become   feasible. In this paper, we review such end-to-end speech recognition models.   We extensively discuss their structures, performance, and advantages compared   to conventional algorithms."
"Intuitively, see lot examples natural language questions TV shows, ought also help understand similar syntax questions movies, questions refer movies TV shows together. Ideally, training examples related domain strictly improve performance, hurt it. %[nkscales] FYI -- I reverted sentence close original form better match tone first paragraph. If sentence still sound right, let know. If satisfy property, least chance eventually achieving arbitrarily robust performance across range domains, given sufficient training data aggregate. %You need satisfy property order shot achieving arbitrarily robust performance across range domains, given simply sufficient data across domains aggregate. How extent current machine learning approaches made robustly solve natural language understanding scale arbitrary natural language across domain -- without access large quantities training data -- remains, however, open question. On one hand, research scaling behavior deep learning systems found generalization loss decrease reliably training size model size power law related logarithmic relationship across range architectures tasks, image classification convolutional neural networks~ language modeling Transformers~. Recent results i.i.d.\ setting show pattern persist across many orders magnitude, established upper limit~. At time, shown current ML systems continue struggle achieve robust performance classes tasks require compositional generalization % [nikola] IMO part sentence contribute much. I suggest skipping keeping citation. %-- is, tasks known building blocks must composed test time ways unseen training ~ -- ability argued crucial robust language understanding~. In paper, combine two lines research investigating effect training size error rates context compositional task. Specifically, derive suite extended datasets based Compositional Freebase Questions semantic parsing benchmark~. We use compositional structure example construct controlled experiments measure error rates increasing training size settings requiring compositional generalization settings simulating scaling broader scope natural language. We apply experiments analysis Transformers~ setting fixed computational cost -- is, fixed model size fixed training steps -- demonstrate key limits scalability setting. Our contributions following: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"," We present \starcfq{} : a suite of large-scale datasets of varying scope based on the \cfq{} semantic parsing benchmark, designed for principled investigation of the scalability of machine learning systems in a realistic compositional task setting. Using this suite, we conduct a series of experiments investigating the ability of Transformers to benefit from increased training size under conditions of fixed computational cost. We show that compositional generalization remains a challenge at all training sizes, and we show that increasing the scope of natural language leads to consistently higher error rates, which are only partially offset by increased training data. We further show that while additional training data from a related domain improves the accuracy in data-starved situations, this improvement is limited and diminishes as the distance from the related domain to the target domain increases."
"% Solving math word problems poses unique challenges understanding natural-language problems performing arithmetic reasoning quantities commonsense knowledge. As shown \autoref{fig:example}, typical MWP consists short narrative describing situation world asking question unknown quantity. To solve MWP \autoref{fig:example}, machine needs extract key quantities text, ""100 kilometers"" ""2 hours"", understand relationships them. General mathematical knowledge like ""distance = velocity time"" used calculate solution. %The task automatically solving Math Word Problems requires mapping human-readable natural language machine-understandable logic forms, e.g., expressions, followed execution process calculates numeric answer. \autoref{fig:example} example math word problem, ground truth answer expression derives answer executed. Recently, researchers focused solving MWPs using neural models. The advantage neural models rely hand-crafted features. Researchers recently focused solving MWPs using neural-symbolic models. These models usually consist neural perception module maps problem text solution expression tree, symbolic module executes expression generates final answer. Training models requires full supervision solution expressions. However, fully-supervised approaches three drawbacks. First, current MWP datasets provide one solution problem, naturally exist multiple solutions give different paths solving problem. For instance, problem \autoref{fig:example} solved ``'' first calculate speed multiply total time; alternatively, solve using ``'' summing distances first second parts journey. The models trained full supervision current datasets forced fit given solution cannot generate diverse solutions. Second, annotating expressions MWPs time-consuming. However, large amount MWPs final answers mined effortlessly internet . How efficiently utilize partially-labeled data without supervision expressions remains open problem. Third, current supervised learning approaches suffer train-test discrepancy. The fully-supervised learning methods optimize expression accuracy rather answer accuracy. However, model evaluated answer accuracy test set, causing natural performance gap. To address issues, propose solve MWPs weak supervision, problem texts final answers required. By directly optimizing answer accuracy rather expression accuracy, learning weak supervision naturally addresses train-test discrepancy. Our model consists tree-structured neural model similar \citet{Xie2019AGT} generate solution tree symbolic execution module calculate answer. However, symbolic execution module arithmetic expressions non-differentiable respect answer accuracy, making infeasible use back-propagation compute gradients. A straightforward approach employ policy gradient methods like REINFORCE train neural model. The policy gradient methods explore solution space update policy based generated solutions happen hit correct answer. Since solution space large incorrect solutions abandoned zero reward, methods usually converge slowly fail converge. %However, previous end-to-end solvers trained fully-supervised setting ground truth expressions given training. This several drawbacks. First, math word problem solved multiple expressions given different ways thinking, one provided training fully-supervised setting. For instance, problem \autoref{fig:example} solved want calculate speed first multiply total hours. Or, solve , first compute length second part journey given ratio time spans, add first part. However, first expression given ground-truth expression dataset, thus neural models tend ``punish'' second expression. In way, fully-supervised learning fails generate diverse correct expressions. The second problem ``train-test discrepancy''. It means MLE uses surrogate objective maximizing equation likelihood training, evaluation metric task solution accuracy, non-differentiable. proposes solve via reinforcement learning still use pre-trained MLE model. Last least, there's problem lack fully annotated data online. Recruiting crowd-workers provide correct equations time consuming. However, thousands MWPs posted online forums, final answers easily mined. These data useful train model without supervision expressions. %To address issues, propose solve MWPs weak supervision, problem texts final answers required learning. % We adopt goal-driven tree-structured model proposed by~\citet{Xie2019AGT} base model. %Since execution process arithmetic expressions previous deep learning models non-differentiable, infeasible use back-propagation compute gradients. A straightforward approach employ policy gradient methods like REINFORCE. In weakly-supervised MWP, policy gradient methods explore solution space update policy based generated solutions happen hit right answers, incorrect solutions totally abandoned. Since solution space quite large, policy gradients methods usually converge slowly sometimes even fail converge. To improve efficiency weakly-supervised learning, propose novel fixing mechanism learn incorrect predictions, inspired human ability learn failures via abductive reasoning. The fixing mechanism propagates error root node leaf nodes solution tree finds probable fix generate desired answer. The fixed solution tree used pseudo label train neural model. \autoref{fig:framework} shows fixing mechanism corrects wrong solution tree tracing error top-down manner. Furthermore, design two practical techniques traverse solution space discover possible solutions efficiently. First, observe positive correlation number quantities text size solution tree , propose tree regularization technique based observation limit range possible tree sizes shrink solution space. Second, adopt memory buffer track save discovered fixes problem fixing mechanism. All memory buffer solutions used pseudo labels train model, encouraging model generate diverse solutions single problem. In summary, combining fixing mechanism two techniques, proposed learning-by-fixing method contains exploring stage learning stage iteration, shown \autoref{fig:framework}. We utilize fixing mechanism tree regularization correct wrong answers exploring stage generate fixed expressions pseudo labels. In learning stage, train neural model using pseudo labels. We conduct comprehensive experiments Math23K dataset. The proposed LBF method significantly outperforms reinforcement learning baselines weakly-supervised learning achieves comparable performance several fully-supervised methods. Furthermore, proposed method achieves significantly better answer accuracies top-3/5 answers fully-supervised methods, illustrating advantage generating diverse solutions. The ablative experiments also demonstrate efficacy designed algorithms, including fixing mechanism, tree regularization, memory buffer. % This paper makes three major contribution: % %Policy gradient methods like REINFORCE frequently used weakly-supervised tasks . Such methods suffer sparse reward, cold start inefficient exploration solution space. This neural network make wrong perceptions generate negative samples ``abandoned'' REINFORCE. Human beings, like neural networks, tend make inaccurate perceptions. However, embody skills correct misperceptions reasoning wrong forms guessing correct patterns. What's more, able approach solutions diverse ways. For example, \autoref{fig:framework}, child might provide wrong expression given problem. Then started reason wrong found could actually fix expression replacing first """" """". The fixed expression looks nothing like ground truth expression *$) provided dataset. % Therefore, policy gradients methods converge slowly even fail converge without MLE pre-training fully-supervised data. %Inspired this, propose novel fixing mechanism resembles human閳ユ獨 ability diagnose fix expressions cannot generate desired answers. The ground truth answer propagated expression tree top-down manner. In meantime, try depth-first-search possible fix. Similar Memory-Augmented Policy Optimization utilizes memory buffer save previous successful trajectories given REINFORCE, adopt memory buffer store successful fixes. Different expressions buffer used train model, thus allowing us generate diverse answers. % Our contributions summarized following: % % } % % % \end{table}\def\year{2021}\relax %File: formatting-instructions-latex-2021.tex %release 2021.1 \documentclass[letterpaper]{article} % DO NOT CHANGE THIS \usepackage{aaai21} % DO NOT CHANGE THIS \usepackage{times} % DO NOT CHANGE THIS \usepackage{helvet} % DO NOT CHANGE THIS \usepackage{courier} % DO NOT CHANGE THIS \usepackage[hyphens]{url} % DO NOT CHANGE THIS \usepackage{graphicx} % DO NOT CHANGE THIS \urlstyle{rm} % DO NOT CHANGE THIS \def\UrlFont{\rm} % DO NOT CHANGE THIS \usepackage{natbib} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \frenchspacing % DO NOT CHANGE THIS \setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS \setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS % additional packages \usepackage{latexsym} \usepackage{makecell} \usepackage{amsmath,amssymb,mathtools,bm,etoolbox} \usepackage{algorithm} \usepackage[noend]{algorithmic} \usepackage{enumitem} \usepackage{xcolor} \usepackage{pifont} \usepackage{multirow} \usepackage{diagbox} \usepackage[switch]{lineno} \usepackage[autostyle=false, style=english]{csquotes} \MakeOuterQuote{""} \usepackage[draft]{hyperref} % Disable links - according AAAI format guide \DeclarePairedDelimiter\ceil{\lceil}{\rceil} \DeclarePairedDelimiter\floor{\lfloor}{\rfloor} \newcommand{\algorithmautorefname}{Algorithm} \newcommand{\eg}{e.g.} \newcommand{\etc}{etc} \newcommand{\ie}{i.e.} \newcommand{\etal}{et al.} \renewcommand{"," % Most previous solvers of math word problems  are learned with full supervision and fail to generate diverse solutions for each problem. In this paper, we address this issue by introducing a weakly-supervised paradigm for learning MWPs. Our method only requires the annotations of the final answers and can generate various solutions for a single problem. To boost weakly-supervised learning, we propose a novel learning-by-fixing  framework that mimics the human ability to learn from incorrect predictions. Specifically, the fixing mechanism propagates the error from the root node to the leaf nodes of a solution tree and infers the most probable fix that can be executed to the desired answer. To generate more diverse solutions, tree regularization is applied to guide the efficient shrinkage and exploration of the solution space, and a memory buffer is designed to track and save the discovered various fixes for each problem. Experimental results on the Math23K dataset show the proposed LBF framework significantly outperforms reinforcement learning baselines in weakly-supervised learning. Furthermore, it achieves comparable top-1 and much better top-3/5 answer accuracies than fully-supervised methods, demonstrating its strength in producing diverse solutions. Previous neural solvers of math word problems  are learned with full supervision and fail to generate diverse solutions. In this paper, we address this issue by introducing a weakly-supervised paradigm for learning MWPs. Our method only requires the annotations of the final answers and can generate various solutions for a single problem. To boost weakly-supervised learning, we propose a novel learning-by-fixing  framework, which corrects the misperceptions of the neural network via symbolic reasoning. Specifically, for an incorrect solution tree generated by the neural network, the fixing mechanism propagates the error from the root node to the leaf nodes and infers the most probable fix that can be executed to get the desired answer. To generate more diverse solutions, tree regularization is applied to guide the efficient shrinkage and exploration of the solution space, and a memory buffer is designed to track and save the discovered various fixes for each problem. Experimental results on the Math23K dataset show the proposed LBF framework significantly outperforms reinforcement learning baselines in weakly-supervised learning. Furthermore, it achieves comparable top-1 and much better top-3/5 answer accuracies than fully-supervised methods, demonstrating its strength in producing diverse solutions."
"% Hate speech, extensiveness, effect % --> humans can't inspect every sample % Memes, use & hateful memes % HM data set % challenge % --> dataset 'truly' requires multi-modality % --> HM dataset proposes 'benign confounders' make sure multimodality required Memes gained huge popularity past years, resulting 180m posts different social media platforms 2018. Although memes oftentimes harmless generated especially humorous purposes, also used produce disseminate hate speech toxic communities. Hate Speech direct attack people based race, ethnicity, national origin, religious affiliation, sexual orientation, sex, gender, serious disease disability -- growing problem modern society. Giant tech companies, Facebook, platforms millions users log daily obliged remove tremendous amount HS protect users. According Mike Schroepfer, Facebook CTO, took action 9.6 million pieces content violating HS policies first quarter 2020. This amount malicious content cannot tackled humans inspect every sample. Consequently, machine learning particular deep learning techniques required alleviate extensiveness online hate speech. Detecting hate speech memes challenging due multimodal nature memes . Therefore, techniques process content way humans do: holistically. When viewing meme, human would think words picture independently; understand combined meaning. Moreover, visual linguistic information meme typically neutral funny individually, combination may result hateful meme. A recent study shows state-of-the-art methods hate speech detection multimodal memes perform poorly compared humans: 64.73\% vs. 84.7\% accuracy. To catalyze sophisticated research area, Facebook AI launched Hateful Memes Challenge published dataset containing 10,000 newly created multimodal memes. Multimodal tasks reflect many real-world problems, including humans perceive understand world around them. There surge interest multimodal problems since 2015 visual question answering, image captioning, speech recognition beyond. But always clear extent genuinely multimodal reasoning understanding needed solve current challenges. For instance, datasets language unintentionally impose strong priors, might result remarkable performance, without understanding visual content. The Hateful Memes challenge design dataset created encourage measure truly multimodal understanding reasoning models. A key point achieve so-called ``benign confounders'' addresses risk exploiting unimodal priors models: every hateful meme, alternative images text flip label not-hateful. Such image text confounders require multimodal reasoning classify original meme confounders correctly. Thus, making dataset challenging appropriate testing true multimodality model. In following, analyze challenge dataset describe prize-winning solution placed third among 3,173 participants Hateful Memes Challenge detail. Our solution achieves 0.811 AUROC accuracy 0.765 challenge test set, improves benchmark models, including state-of-the-art models time, ViLBERT VisualBERT . Nevertheless, accuracy still behind humans mentionable gap, highlighting need progress multimodal research.","   Memes on the Internet are often harmless and sometimes amusing. However, by using certain types of images, text, or combinations of both, the seemingly harmless meme becomes a multimodal type of hate speech -- a hateful meme. The Hateful Memes Challenge\footnote{\url{https://www.drivendata.org/competitions/70/hateful-memes-phase-2/}} is a first-of-its-kind competition which focuses on detecting hate speech in multimodal memes and it proposes a new data set containing 10,000+ new examples of multimodal content. We utilize VisualBERT -- which meant to be the ``BERT of vision and language'' -- that was trained multimodally on images and captions and apply Ensemble Learning. Our approach achieves 0.811 AUROC with an accuracy of 0.765 on the challenge test set and placed third out of 3,173 participants in the Hateful Memes Challenge\footnote{HateDetectron at \url{https://www.drivendata.org/competitions/70/hateful-memes-phase-2/leaderboard/}}. The code is available at  %   \begin{center}     \url{https://github.com/rizavelioglu/hateful_memes-hate_detectron}     % \end{center}"
"Designing robust spoken language identification algorithm important wide usability multi-lingual speech applications . With resurgence deep model learning, SLID performance significantly improved current supervised deep feature classifier learning algorithms . In algorithms, implicit assumption training testing data sets share similar statistical distribution property. However, due complex acoustic linguistic patterns, often case testing data set training data set quite different domains . An intuitive solution domain adaptation, i.e., align statistical distribution testing data set match training data set thus improve performance. Although large collected labeled testing data set, difficult obtain domain transfer function supervised learning algorithms, real applications, label information testing data set often unknown. Therefore, study, mainly focus preferable challenge situation, i.e., unsupervised domain adaptation. Unsupervised domain adaptation algorithms proposed speaker verification, e.g., probabilistic linear discriminant analysis parameter adaptation , feature-based correlation alignment , feature-distribution adaptor different domain vectors . However, algorithms, proposed speaker verification framework PLDA . As experiments showed PLDA framework perform well SLID task due less discriminative power modeling. Instead, SLID algorithms, multiple mixture logistic regression model used classifier model. Moreover, due complex shapes distributions training testing domains, difficult guarantee match different domain distributions. The purpose domain adaptation reduce domain discrepancy. Recently, optimal transport intensively investigated domain adaptation machine learning field . The initial motivation OT machine learning find optimal transport plan convert one probability distribution shape another shape least effort . By finding optimal transport, naturally defines distance measure different probability distributions. Based property, OT promising tool domain adaptation shape matching image processing, classification, segmentation . In paper, inspired OT based unsupervised adaptation , propose unsupervised neural adaptation framework cross-domain SLID tasks. Our main contributions are: We propose unsupervised neural adaptation model SLID deal domain mismatch problem. In model, explicitly formulate adaptation transformed feature space classifier space order reduce probability distribution discrepancy source target domains. We coincide OT distance metric measuring probability distribution discrepancy, integrate network optimization order learn adaptation model parameters. Based adaptation model, significant improvements obtained. %The remainder paper organized follows. Section introduces background fundamental theory . Section describes implementation details . Section presents SLID experiments results based proposed framework analyzing contribution CSA model detail. Section presents discussion results conclusion study."," Due to the mismatch of statistical distributions of acoustic speech between training and testing sets, the performance of spoken language identification  could be drastically degraded. In this paper, we propose an unsupervised neural adaptation model to deal with the distribution mismatch problem for SLID. In our model, we explicitly formulate the adaptation as to reduce the distribution discrepancy on both feature and classifier for training and testing data sets. Moreover, inspired by the strong power of the optimal transport  to measure distribution discrepancy, a Wasserstein distance metric is designed in the adaptation loss. By minimizing the classification loss on the training data set with the adaptation loss on both training and testing data sets, the statistical distribution difference between training and testing domains is reduced. We carried out SLID experiments on the oriental language recognition  challenge data corpus where the training and testing data sets were collected from different conditions. Our results showed that significant improvements were achieved on the cross domain test tasks."
"The internet huge impact lives virtual presence reflects personalities beliefs also biases prejudices. Billions people interacting various online content every day highly useful enriches knowledge understanding world, increasing portion content also harmful. This includes hate speech, misinformation forms online abuse. An increasing amount effort required quickly detect content, scale review work make automatic decisions take harmful media fast order minimize inflicted harm readers. Many interactions happen social media platforms, use share messages pictures private community general public audiences. Facebook AI launched competition flag hateful memes consisting images text. For purpose provide unique labeled dataset 10,000+ high quality new multimodal memes. The goal challenge create algorithm identifies multimodal hate speech internet memes, also robust benign flip. A meme might mean hateful either meme image itself, text combination. Benign flipping augmentation technique used competition organizers flip meme hateful non-hateful viceversa. This requires changing either meme text image flip label. Figure shows process works. Since problem formulated binary classification task, primary evaluation metric used rank results area receiver operating characteristic curve . This represents area ROC curve, turn plots True Positive Rate vs. False Positive Rate different classification thresholds T. The goal maximize AUROC. Accuracy secondary tracked metric calculates percentage instances predicted class \^{y} matches actual class, test set. Ideally, model maximizes metrics. In summary, contribution threefold:","   While significant progress has been made using machine learning algorithms to detect hate speech, important technical challenges still remain to be solved in order to bring their performance closer to human accuracy. We investigate several of the most recent visual-linguistic Transformer architectures and propose improvements to increase their performance for this task. The proposed model outperforms the baselines by a large margin and ranks 5\textsuperscript{th} on the leaderboard out of 3,100+ participants.    \footnote{Code is available at \url{https://github.com/vladsandulescu/hatefulmemes}.}"
"In traditional ad-hoc retrieval, queries documents represented variants bag-of-words representations. This leads called vocabulary mismatch problem: query contains words exactly match words relevant document, search engine may fail retrieve document. Query expansion document expansion, methods adding additional terms original query document, two popular solution alleviate vocabulary mismatch problem. Document expansion shown particularly effective short text retrieval language-model based retrieval . Most existing works document expansion unsupervised: using information corpus augment document representation, e.g., retrieval based clustering based , using external information augment document representation . Recently, \citet{nogueira2019DE} proposed new approach document expansion, based popular generative sequence-to-sequence model NLP, transformers . It leverages supervision train model predict expansion terms conditional document. The paper shown significant improvement passage datasets, trained in-domain. In paper, follow line supervised neural document expansion approach explore performance standard IR benchmarking dataset. Our main contributions are: 1. Adapting method unlabeled datasets exploring transfer learning weak-supervision approaches. 2. Adapting method traditional IR datasets, large number long documents present.","     Recently, \citet{nogueira2019DE} proposed a new approach to document expansion based on a neural Seq2Seq model, showing significant improvement on short text retrieval task. However, this approach needs a large amount of in-domain training data.     In this paper, we show that this neural document expansion approach can be effectively adapted to standard IR tasks, where labels are scarce and many long documents are present."
"Cognitive studies show human infants develop object individuation skill diverse sources information: spatial-temporal information, object property information, language~. Specifically, young infants develop object-based attention disentangles motion location objects visual appearance features. Later on, leverage knowledge acquired word learning solve problem object individuation: words provide clues object identity type. The general picture cognitive science object perception language co-develop support one another . Our long-term goal endow machines similar abilities. In paper, focus language may support object segmentation. Recent work studied problem unsupervised object representation learning, though without language. As example, factorized, object-centric scene representations used various kinds prediction~, reasoning~, planning tasks~, considered role language may help object representation learning. As concrete example, consider input images shown \fig{fig:teaser} paired questions. From language, learn associate concepts, black, pan, legs, referred object's visual appearance. Further, language provides cues input scene segmented individual objects: wrong parsing input scene lead incorrect answer question. We learn failure handle belongs frying pan chair four legs . Motivated observations, propose computational learning paradigm, \modelfull , associating learned object-centric representations visual appearance images, concepts---words object properties color, shape, material---as provided language. Here language input either descriptive sentences question-answer pairs. \model requires annotations object masks, categories, properties learning process. In \model, four modules jointly trained. The first image encoder, learning encode image factorized, object-centric representations. The second image decoder, learning reconstruct masks individual objects learned representations reconstructing input. These two modules share formulation recent unsupervised object segmentation research: learning decompose image series slot profiles, comprised pixel masks latent embeddings. Each slot profile expected represent single object image. The third module \model pre-trained semantic parser translates input sentence semantic, executable program, concept associated vector space embedding. Finally, last module, neural-symbolic program executor, takes object-centric representation Module 1, intermediate representations Module 2, concept embeddings semantic program Module 3 input, outputs answer language input question, TRUE/FALSE descriptive sentence. The correctness executor's output quality reconstructed images two supervisory signals use jointly train Modules 1, 2, 4. % % % % We integrate proposed \model state-of-the-art unsupervised segmentation methods, MONet~ Slot Attention~. The evaluation based two datasets: ShopVRB~ contains images daily objects question-answer pairs; PartNet~ contains images furniture hierarchical structure, supplemented descriptive sentences collected ourselves. We show \model consistently improves existing methods unsupervised object segmentation, % much likely group different parts single object single mask. We analyze object-centric representations learned \model. In \model, conceptually similar objects appear clustered embedding space. Moreover, experiments demonstrate learned concepts used new tasks, visual grounding referring expressions, without additional fine-tuning. % % % % % % % % % % % % %","     We present \modelfull , a paradigm for learning disentangled, object-centric scene representations from vision and language. \model builds upon recent advances in unsupervised object segmentation, notably MONet and Slot Attention. While these algorithms learn an object-centric representation just by reconstructing the input image, \model enables them to further learn to associate the learned representations to concepts, \ie, words for object categories, properties, and spatial relationships, from language input. These object-centric concepts derived from language facilitate the learning of object-centric representations. \model can be integrated with various unsupervised segmentation algorithms that are language-agnostic. Experiments show that the integration of \model consistently improves the object segmentation performance of MONet and Slot Attention on two datasets via the help of language. We also show that concepts learned by \model, in conjunction with segmentation algorithms such as MONet, aid downstream tasks such as referring expression comprehension."
"A speech signal considered variable-length temporal sequence, many features used characterize pattern. Short-term spectral features used extensively quasi-stationary property speech signal. After short-term processing, raw waveform converted two-dimensional~ matrix size , represents frequential feature dimension related number filter coefficients, denotes temporal frame length related utterance duration. For text-independent speaker verification~ system, main procedure extract fixed-dimensional speaker representation variable-length spectral feature sequence. One widely used spectral features Mel-frequency cepstral coefficient ~. Typically, MFCC feature vectors frames assumed independent identically distributed. They projected Gaussian components phonetic units accumulate statistics time axis form high-dimensional supervector. Then, factor analysis-based dimension reduction performed generate fixed-dimensional low rank i-vector representation. Recently, progress deep learning, many approaches directly train deep neural network~ distinguish different speakers. Systems comprising x-vector speaker embedding followed probabilistic linear discriminant analysis~ shown state-of-the-art performances multiple TISV tasks. In x-vector system, time-delay neural network~ followed statistic pooling time axis used modeling long-term temporal dependencies MFCC features. \end{figure*} For i-vector, x-vector, many speech modeling methods, feature matrix viewed multi-channel 1-D time series. Although duration may vary among utterances, feature dimension must fixed value. In paper, consider feature matrix single-channel 2-D image. From new perspective, spectral feature viewed ``picture"" sound, 2-D CNN implemented way traditional image recognition paradigms. This kind process brings type flexibility, i.e., size input ``image,"" including width height , arbitrary numbers. In words, 2-D CNN trained 64-dimensional spectrogram could potentially also process spectrogram 48 dimensions. We aim utilize flexibility 2-D CNN tackle mixed-bandwidth~ joint modeling problem. Currently, many devices equipment capture speech data different sampling rates, thus solving sampling rate mismatch problem become research topic speech community. The traditional way accomplish goal train specific model every target bandwidth since sampling rates different . An alternative solution uniformly downsample wideband~ speech data extend bandwidth narrowband~ data, combined . In paper, present unified solution solve MB joint modeling problem. The key idea view NB spectrogram sub-image WB spectrogram. The major contributions work summarized follows."," This paper proposes a unified deep speaker embedding framework for modeling speech data with different sampling rates. Considering the narrowband spectrogram as a sub-image of the wideband spectrogram, we tackle the joint modeling problem of the mixed-bandwidth data in an image classification manner. From this perspective, we elaborate several mixed-bandwidth joint training strategies under different training and test data scenarios. The proposed systems are able to flexibly handle the mixed-bandwidth speech data in a single speaker embedding model without any additional downsampling, upsampling, bandwidth extension, or padding operations. We conduct extensive experimental studies on the VoxCeleb1 dataset. Furthermore, the effectiveness of the proposed approach is validated by the SITW and NIST SRE 2016 datasets."
"% Automatic speech recognition systems typically trained vast quantity paired audio text data attain competitive performance. Obtaining paired data requires substantial human annotation efforts often time-consuming, expensive error-prone. With emerging popularity end-to-end ASR models, need large amounts training data demanding conventional hybrid-based ASR systems. For purpose, semi-supervised learning often investigated speech recognition, model trained using finite amount labeled data much larger amount unlabeled data. In long history semi-supervised learning speech recognition, self-training approach knowledge distillation , known teacher-student model training two commonly used SSL methods. Recent success representation learning enables new approach towards leveraging unlabeled data. In natural language processing community, BERT, ELMo, XLNet , GPT follow-ups classical examples representation learning. The key philosophy representation learning based using self-supervised learning, obtain `free' labels unlabeled data train supervised manner via proxy tasks. In context BERT, two proxy tasks defined including masked language model task two-sequence prediction task. These proxy tasks designed force learning robust, meaningful representation. After representation learned, downstream task model trained using labeled data learned representation. Optionally, representation learning block downstream task block fine-tuned together. Learning efficient speech representation traced back restricted Boltzmann machine , allows pre-training large amounts unlabeled data training deep neural network speech models. More recently, speech representation learning drawn increasing attention speech processing community shown promising results semi-supervised speech recognition . The design proxy tasks learning speech representation categorized two types. The first type based contrastive loss applied speech representation wav2vec variants . The model trained learn representations containing information discriminates future masked frame set negative samples via contrastive loss. The second type based reconstructive loss. The proxy task representation learning methods reconstruct temporal slices acoustic features based contextual information. These reconstruction tasks defined autoregressive reconstruction, masked-based reconstruction. APC follow-up examples use autoregressive reconstruction loss. In many state-of-the-art pretrained language model task, masked-based prediction adopted proxy tasks BERT XLNet . In speech, instead prediction, randomly mask temporal slices acoustic features attempt reconstruct . Orthogonal contrastive-/reconstructive-loss based speech representation learning, vector-quantized speech representations proposed. One motivation apply vector quantization enforcing quantization lead better linguistic unit discovery due discrete nature phonetic units. In VQ-APC , authors use VQ way limit model capacity control information needed encoding representation. In VQ-wav2vec wav2vec 2.0 , author use VQ facilitate direct application BERT NLP algorithms. In paper, introduce DeCoAR 2.0, Deep Contextualized Acoustic Representation vector quantization. We take inspirations many recent advances speech representation learning, propose multiple improvements vanilla DeCoAR. We summarize contributions paper follows: % The rest paper organized follows. Section gives brief overview previous DeCoAR method related work vector quantized speech representation learning. Section describes proposed DeCoAR 2.0 approach. Experimental results semi-supervised speech recognition presented Section followed conclusion Section. % Learning robust speech representation exploited recent years. Among approaches, wav2vec 2.0 uses 10 minutes labeled data 53k hours unlabeled data achieve word error rate 5.2/8.6 LibriSpeech benchmark. The model relies diverse codebook learnt correlates underlying speech units speech representations via contrastive loss. However, contrastive loss formulation result several locally optimal codebooks, exmaples, acoustic condition-sensitive codebooks: model easily optimized assign acoustic condition codebooks, temporally invariant codebooks: model assigns specific codes fixed temporal locations. %Furthermore, codes time step model select right feature encoder hardly contained meaningful phonetic information. So contrastive approach might generalize well datasets, espically real world data consisted lot nausence factor like noise, different recording environment. % A simple workaround could using frame reconstruction objective, network allows flow information input feature back latent space preserve meaningful information codes, helping mitigatate codebook learning problems contrastive loss discussed above. And compared simple reconstruction utilize information available achieved maximal prediction information less relevant ASR. By utilizing VQ layer, model able keep representation unwanted information flowing. % Automatic speech recognition systems typically trained vast quantity paired audio text data attain competitive performance. Obtaining paired data requires substantial human annotation efforts often time-consuming, expensive error-prone. With emerging popularity end-to-end ASR models, need large amounts training data demanding conventional hybrid-based ASR systems. For purpose, semi-supervised learning often investigated speech recognition, model trained using finite amount labeled data much larger amount unlabeled data. % In long history SSL speech recognition, self-training approach commonly used approach. In self-training methods, `seed' ASR model trained using paired audio/text data. The resulting model applied transcribe unlabeled audio data. The resulting hypotheses, combined different data selection criteria, treated `pseudo-labels' added original labeled dataset retrain new model. Simple concept, self-training works well practice one major caveat - pseudo-label injects systematic bias introduced seed model. To alleviate this, careful confidence calibration system combinations often used . Another family SSL based knowledge distillation , teacher-student model training , mostly applied acoustic model training hybrid-based ASR. In setups, teacher model generates frame-wise soft label instead hard label, student model trained soft labels via KL divergence loss instead standard cross-entropy loss based forced alignment. The knowledge distillation based SSL partially mitigates systematic bias rarely investigated towards sequence-level loss end-to-end ASR systems. % Recent success efficient representation learning, particular natural language processing , enables new approach towards leveraging unlabeled data. Classical examples representation learning NLP include BERT, ELMo, XLNet , GPT follow-ups , name few. The key philosophy representation learning based self-supervised learning, obtain `free' labels unlabeled data train supervised manner via proxy tasks. In context well-known BERT, two proxy tasks defined including masked language model task two-sequence prediction task. These proxy tasks defined way force learning robust, meaningful representation. A downstream task trained labeled data learned representation. Optionally, representation learning block downstream task fine-tuned together. % This paper presents DeCoAR 2.0, follow-up DeCoAR . We take inspiration many recent advances speech representation learning, propose multiple improvements vanilla DeCoAR. We summarize contributions paper follows: % % The rest paper organized follows. Section gives overview related work speech representation learning, brief recap previous DeCoAR method. Section describes proposed vector quantized DeCoAR approach. Experimental results semi-supervised speech recognition presented Section followed conclusion Section. % In work, propose improved speech representation learning paradigms towards semi-supervised speech recognition based previous work . % Current state-of-the-art models speech recognition require vast amounts transcribed audio data attain good performance. In particular, end-to-end ASR models demanding amount training data required compared traditional hybrid models. While obtaining large amount labeled data requires substantial effort resources, much less costly obtain abundant unlabeled data. % For reason, semi-supervised learning often used training ASR systems. Recently, self-supervised learning閳ユ攣 paradigm treats input modifications input learning targets閳 obtained promising results. Those self-supervised speech representation fall main categories: Contrastive Predictive Coding incorporates contrastive objective learn representations containing information discriminates future masked frame set negative samples. Another approach Autoregressive Predictive Coding , tries directly predict reconstruct frame based context. % More recently, vector-quantized representations audio data drawn increasing attention speech processing . The motivation enforcing quantization leads better representation acoustic unit discovery due discrete nature phonetic units. VQ-APC also try exactly quantified information , control capacity models. And use vector quantization limited capacity forced retain information achieve maximal prediction. % Despite success wav2vec 2.0 model , model relies diverse codebook learnt correlates underlying speech units speech representations via contrastive loss. However, codes time step model select right feature encoder hardly contained meaningful phonetic information. More importantly, contrastive loss formulation result several locally optimal codebooks. A highly probable optima observed acoustic condition-sensitive codebooks: model easily optimized assign acoustic condition codebooks, temporally invariant codebooks: model assigns specific codes fixed temporal locations enable good contrastive loss. Hence, codebook learning methodology using contrastive loss might generalize well datasets, espically real world data consisted lot nausence factor like noise, different recording environment. % A simple solution could enforce codes explicitly carry information input features process. Using frame reconstruction objective, network allows flow information input feature back latent space preserve meaningful information, helping mitigatate codebook learning problems contrastive loss discussed above. Thus, propose novel self-supervised model learns vector quantized deep transformer acoustic representations based frames reconstruction. Since simple reconstruction utilize information available achieved maximal prediction information less relevant ASR. And utilizing VQ layer limit unwanted information flow final representation, Vector Quantized Deep Contextualized Acoustic Representations able achieve much better representation that's better suited semi-supervised ASR tasks. By using large amount unlabeled data, applies representations ASR tasks using limited amount labeled data. In implementation, perform acoustic representation learning using deep transformer training objective minimizes reconstruction error temporal slice filterbank features given context frames. After pre-training, fix parameters add output layers connectionist temporal classification loss ASR task. We train small ASR model instead fine-tuning computing-efficiency. Our approach showed supervision 10 hours labeled data DeCoAR 2.0 achieves performance par training 960 hours directly.","  Recent success in speech representation learning enables a new way to leverage unlabeled data to train speech recognition model. In speech representation learning, a large amount of unlabeled data is used in a self-supervised manner to learn a feature representation. Then a smaller amount of labeled data is used to train a downstream ASR system using the new feature representations. Based on our previous work DeCoAR \cite{ling2020deep} and inspirations from other speech representation learning, we propose DeCoAR 2.0, a Deep Contextualized Acoustic Representation with vector quantization. We introduce several modifications over the DeCoAR: first, we use Transformers in encoding module instead of LSTMs; second, we introduce a vector quantization layer between encoder and reconstruction modules; third, we propose an objective that combines the reconstructive loss with vector quantization diversity loss to train speech representations. Our experiments show consistent improvements over other speech representations in different data-sparse scenarios. Without fine-tuning, a light-weight ASR model trained on 10 hours of LibriSpeech labeled data with DeCoAR 2.0 features outperforms the model trained on the full 960-hour dataset with filterbank features.   % \yuzong{rewrite this} % We propose a novel approach for vector quantized deep contextualized acoustic representations. Following the same schema in DeCoAR\cite{ling2020deep}, we first exploit a large amount of unlabeled audio data via representation learning, where we reconstruct a temporal slice of filterbank features from context frames. The new resulting deep contextualized acoustic vector quantized representations  are then used to train a small CTC-based ASR system using a small amount of labeled audio data. In our experiments, we show that systems trained on DeCoAR 2.0 consistently outperform ones trained on other acoustic representations, giving the state-of-art and comparable results with wav2vec 2.0 \cite{baevski2020wav2vec} on semi-supervised experiments on Librispeech. Our approach can drastically reduce the amount of labeled data required; unsupervised training on LibriSpeech then supervision with 10 hours of labeled data achieves performance on par with training on all 960 hours directly."
"% % {A}{utomatic} speech recognition , one core components speech technology, achieved significant advancements past decade . A key driving force behind advancements rapid development deep learning techniques . % State-of-the-art ASR systems usually trained thousands hours transcribed speech data massive amount text data. % % State-of-the-art ASR systems usually requires thousands hours transcribed speech data massive amount text data train hybrid deep neural network-hidden Markov model based acoustic model recurrent neural network language model . % Moreover, hand-crafted pronunciation lexicon phoneme inventory based linguistic expertise often needed. Recently, end-to-end ASR architectures, AM LM training integrated single pipeline, gradually become mainstream ASR academic research , compared hybrid deep neural network-hidden Markov model architectures . E2E architectures advantage removing need pronunciation lexicon phoneme inventory system development. However, training E2E ASR system tends require even transcribed speech data hybrid DNN-HMM ASR system . There around spoken languages world . For them, amount transcribed speech data resources limited, even non-existent . Many low-resource languages, ethnic minority languages China languages Africa, may never formally studied. In addition lack enough transcribed speech data, linguistic knowledge languages incomplete, may even entirely lacking. Conventional supervised acoustic modeling therefore applied directly. This leads current situation high-performance ASR systems available small number major languages, e.g., English, Mandarin, French. To facilitate ASR technology low-resource languages, investigation unsupervised acoustic modeling methods necessary, aims find model set basic speech units represents sounds language interest, i.e., low-resource, target language. Recently, growing research interest UAM . A strict assumption UAM target language raw speech data available, transcriptions, phoneme inventory pronunciation lexicon unknown. This known zero-resource assumption . %It challenging task, yet significant research impact broad area speech language science technology, e.g., query-by-example spoken term detection , text-to-speech without text , understanding mechanisms underlying infant language acquisition , documentation endangered languages . There two main research strands UAM. The first strand formulates problem discovering finite set phoneme-like speech units . This often referred acoustic unit/model discovery . The second strand formulates problem learning acoustic feature representations distinguish subword units target language, robust linguistically-irrelevant factors, speaker . This often referred unsupervised subword modeling . In essence, second strand focused learning intermediate representation towards ultimate goal UAM, first strand aims directly ultimate goal. These two strands closely connected benefit other; instance, good subword-discriminative feature representation % good feature representation discriminative subword units robust speaker variation shown beneficial AUD , conversely, discovered speech units good consistency true phonemes helpful % could provide phoneme-like pseudo transcriptions assist learning subword-discriminative acoustic feature representations . This study addresses unsupervised subword modeling UAM. Learning subword-discriminative feature representations zero-resource scenario shown non-trivial task . The major difficulty separation linguistic information non-linguistic information . For instance, speech sound [\ae]\footnote{International Phonetic Alphabet symbol.} produced different speakers might mistakenly modeled different speech units . There many interesting attempts unsupervised subword modeling . One typical research direction leverage purely unsupervised learning techniques. One method clustering speech sounds acoustically similar patterns potentially correspond subword units , results phoneme-like pseudo transcriptions used facilitate subword-discriminative feature learning . % , e.g. cluster posteriorgrams DNN bottleneck features . Unsupervised self-supervised representation learning algorithms applied learn, without using external supervision, speech features retain linguistic content original data ignoring linguistically-irrelevant information, particularly speaker variation . A second research direction unsupervised subword modeling exploit cross-lingual knowledge . Speech text resources out-of-domain resource-rich languages shown beneficial modeling subword units in-domain low-resource languages. For instance, used OOD AM extract cross-lingual bottleneck features , used OOD ASR generate cross-lingual phone labels. % past studies . % One idea utilize pre-trained DNN AM OOD language generate phoneme-discriminative representations target speech, bottleneck features . % The second idea would leverage OOD ASR system decode speech utterances target language obtain cross-lingual phone labels supervision subsequent subword modeling . % These two ideas realize cross-lingual knowledge transfer AM level phone label level respectively. % Cross-lingual knowledge transfer done AM level, i.e., OOD pretrained AM used generate speech target language. % It also done phone label level, i.e., OOD ASR system decoding target speech utterances generate phone labels cross-lingual supervision . % This study adopts two-stage learning framework combines research directions within area unsupervised subword modeling. % The high-level overview proposed framework shown Fig. . %, At first stage, front-end, self-supervised representation learning model named autoregressive predictive coding trained. APC preserves phonetic speaker information original speech signal, makes two information types separable . %This makes APC suitable method unsupervised subword modeling. At second stage, back-end, cross-lingual, OOD DNN model bottleneck layer trained using APC pretrained features input features create missing frame labels. % , seen Fig. . %Frame labels required DNN-BNF model training directly available due zero-resource assumption. In framework, labels obtained using OOD ASR system. %By so, cross-lingual phonetic knowledge exploited. This system framework proposed recent study , showed state-of-the-art performances subword discriminability task two databases UAM: ZeroSpeech 2017 Libri-light . In work, expand extend work . Specifically, compare proposed approach supervised topline system trained transcribed data target language; compare proposed approach another cross-lingual knowledge transfer method ; % investigate AM-level phone label-level knowledge transfer methods effective; % investigate effects recently proposed APC model architectures front-end pretraining detail; investigate potential approach relation amount unlabeled training material varying data hours hours, compare models' performance topline model. Throughout experiments, English chosen target low-resource language. Its phoneme inventory transcriptions assumed unavailable system development. Dutch Mandarin chosen two OOD languages phoneme inventories transcriptions available. Unsupervised subword modeling typically evaluated using overall performance measures, ABX , purity , normalized mutual information . These metrics, however, provide insights approaches閳 ability modeling individual phonemes phoneme categories. As ultimate goal beyond unsupervised subword modeling discover basic speech units good consistency true phonemes target language, we, best knowledge first time literature, additionally present detailed analyses explore question effectiveness proposed approach capturing phoneme articulatory feature information target language. % To answer question The analyses based standard ABX error rate evaluation , adapted work , consist two parts, i.e., analysis phoneme level AF level. The analyses aimed investigating phoneme AF information captured learned subword-discriminative feature representation, used guide future research improve unsupervised subword modeling well AUD. Moreover, correlate phoneme-level ABX error rates quality cross-lingual phone labels used train back-end DNN-BNF model order study proposed approach performs differently capturing different target phonemes' information, performance affected quality cross-lingual phone labels. %The analysis AF level carried interested extent AF information target language learned subword-discriminative feature representation. % AFs describe target articulators vocal tract pronouncing specific phone . The use AFs shown beneficial low-resource ASR acoustic unit discovery . % {\color{cyan}do need introduction AF?} % The AFs describe movement tongue, lips organs produce speech sounds. % {\color{cyan}state this} % The AF compact universal representation speech, language-independent phoneme inventory representation. % We interested extent AF information target language learned subword-discriminative feature representation. %In AF-level analysis, new evaluation metric proposed measure efficacy approach capturing AF information. This metric replaces phoneme inventory ABX discriminability task AF category. % Specifically, task predict whether test speech segment belongs AF attribute , contain speech sounds belonging different AF attributes. %Several AFs investigated study, including place articulation manner articulation consonants, tongue height tongue backness monophthong vowels. %The AF-level analysis could potentially provide guidance future research improve unsupervised subword modeling well AUD. To knowledge previous studies AF-level analysis unsupervised subword modeling AUD. % For instance, two systems achieving overall subword modeling performance might vary greatly linguistic implications. % overall performance metrics, ABX subword discriminability , purity , normalized mutual information . % , used input perform subword-discriminative learning . % , i.e., unsupervised feature representation learning problem. % {\color{cyan} high-level review representative approaches. purely unsupervised learning approaches 1-1. clustering; 1-2 unsupervised feature learning. leveraging OOD resources.} % {\color{red}Text colored} % train deep neural network -based acoustic model massive amount text data train % The remainder paper organized follows. Section provides review related works unsupervised subword modeling task. In Section , provide detailed description proposed approach unsupervised subword modeling, introduce comparative approaches compare approach. Section describes methodology used phoneme-level AF-level analyses. Section introduces experimental design study, Section reports results. Section describes setup conducting phoneme- AF-level analyses, discusses results analyses. Finally, Section draws conclusions."," % This study addresses unsupervised subword modeling, i.e., learning acoustic feature representations that can distinguish between subword units of a language. We propose a two-stage learning framework that combines self-supervised learning and cross-lingual knowledge transfer. The framework consists of autoregressive predictive coding  as the front-end and a cross-lingual deep neural network  as the back-end.  This study addresses unsupervised subword modeling, i.e., learning acoustic feature representations that can distinguish between subword units of a language. We propose a two-stage learning framework that combines self-supervised learning and cross-lingual knowledge transfer. The framework consists of autoregressive predictive coding  as the front-end and a cross-lingual deep neural network  as the back-end.  % Experiments on the ABX subword discriminability task conducted with the Libri-light and ZeroSpeech 2017 databases show our approach is competitive or superior to state-of-the-art studies. APC pretraining brings improvement to the entire framework, and brings larger improvement with increased amount of training data. Our best performance achieved by using unlabeled training data without linguistic knowledge of the target language is very close to that of a supervised system trained with labeled data of that language. The back-end of our approach is found more effective than a cross-lingual AM based BNF in cross-lingual knowledge transfer. Experiments on the ABX subword discriminability task conducted with the Libri-light and ZeroSpeech 2017 databases showed that our approach is competitive or superior to state-of-the-art studies.  % A comprehensive and systematic analysis at the phoneme- and articulatory feature - level is carried out to investigate the type of information that is captured by our learned feature representation. New metrics are proposed for the phoneme-level ABX subword discriminability task and attribute-level ABX AF task. The phoneme-level analysis showed that compared to MFCC, our approach achieves larger improvement in capturing diphthong information than monophthong vowel information, and the improvement varies greatly to different consonants. Results found there is a positive correlation between the effectiveness of the back-end in capturing a phoneme's information and the quality of cross-lingual phone labels assigned to that phoneme. The AF-level analysis showed that the proposed approach is better than MFCC and APC features in capturing manner of articulation , place of articulation , vowel height and backness information. Results indicate MoA is better captured by the proposed approach than PoA, and both MoA and PoA are better captured than vowel height and backness. Results implies AF information is less language-dependent than phoneme information.   Comprehensive and systematic analyses at the phoneme- and articulatory feature -level showed that our approach was better at capturing diphthong than monophthong vowel information, while also differences in the amount of information captured for different types of consonants were observed. Moreover, a positive correlation was found between the effectiveness of the back-end in capturing a phoneme's information and the quality of the cross-lingual phone labels assigned to the phoneme. The AF-level analysis together with t-SNE visualization results showed that the proposed approach is better than MFCC and APC features in capturing manner and place of articulation information, vowel height, and backness information.  % Taking all the analyses together, the two stages in our approach are both effective in capturing phoneme information. Monophthong vowel information is much more difficult to be captured than consonant information, which suggests a future research direction to improve the effectiveness of capturing monophthong vowel information.  Taken together, the analyses showed that the two stages in our approach are both effective in capturing phoneme and AF information. Nevertheless, monophthong vowel information is less well captured than consonant information, which suggests that future research should focus on improving capturing monophthong vowel information."
