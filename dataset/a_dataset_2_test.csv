document,summary,id
"  The performance of many machine learning algorithms depends on their hyper-parameters. For example, the prediction accuracy of support vector machines depends on the kernel and regularization hyper-parameters  and , and deep neural networks are sensitive to a wide range of hyper-parameters, including the number of units per layer, learning rates, weight decay, and dropout rates etc.. It is well-known that hyper-parameter settings often make the difference between mediocre and state-of-the-art performance. As a result, hyper-parameter optimization has been receiving an increasingly amount of attention in the NLP and machine learning communities. However, identifying the best model configuration is often a cumbersome process because it can involve several trials and errors before an optimal hyper-parameter setting can be found. Bayesian Optimization has emerged as an efficient framework for carrying out the model selection process, achieving impressive successes. For example, in several studies, it found better instantiations of convolutional network hyper-parameters than domain experts. The common theme is to perform a set of iterative hyper-parameter optimizations. In each round, these methods fit a hyper-parameter response surface using a probabilistic regression function such as Gaussian Process or tree-based models, where the response surface maps each hyper-parameter setting to an approximated accuracy. The learned regression model is then used as a surrogate of the response surface to explore the search space and identify promising hyper-parameter candidates to evaluate next in order to enhance validation accuracy.    While these methods have enjoyed great success compared to conventional random search and grid search algorithms for model selection, the focus of these work have largely been on optimizing for effectiveness, while ignoring the resulting model's training efficiency. Given that both prediction accuracy and model training time are important for real-world applications, models selected for effectiveness may not meet the strict real-world efficiency requirements necessary to deploy in a production environment. In addition, most of the previous methods exclusively focus on optimizing the hyper-parameters of a given model class, while ignoring other important extrinsic hyper-parameters such as training set size which can influence both speed and accuracy. For example, model training time typically grows proportionally with respect to training set size, and the prediction accuracy can also be influenced by the amount of training data used for learning. If the tolerance for inefficient model training is low, then the amount of training data should be reduced or adjusted with the rest of intrinsic hyper-parameters to meet the stringent efficiency requirements.    Given that both model effectiveness and training time are important for real-world applications, in this work, we propose a unified Bayesian Optimization framework for jointly selecting models for prediction effectiveness and training efficiency. First, we propose an objective that captures the tradeoff between these two metrics, then we demonstrate how we can jointly optimize them in a principled Bayesian Optimization framework. In addition, we account for extrinsic hyper-parameters such as training set size in the hyper-parameter optimization space. We will demonstrate this joint optimization of both measures in an enriched hyper-parameter space leads to selecting more efficient and accurate models. It is important to point out our work is fundamentally different from previous Bayesian Optimization that considers the speed of the hyper-parameter search/model selection process -- our focus is on model training efficiency, in addition to accuracy , while their focus is on hyper-parameter search efficiency. Our work can be viewed as taking an efficiency-centric view at selecting effective models. Experiments on model selection for recommendation and question answering tasks indicate models selected this way significantly improves model training efficiency while maintaining strong effectiveness as compared to state-of-the-art Bayesian Optimization algorithms.    The remainder of the paper is organized as follows: We start with a discussion of related work. Next, in Section we propose metrics for quantifying the tradeoff between prediction accuracy and training efficiency, then discuss methods for model selection based on the tradeoff metric. Section presents experimental results under different tradeoff scenarios for recommendation and question answering tasks, before concluding in Section.       { This paper describes the approach we proposed for SemEval-2020 Task 9: Sentiment Analysis for CM Social Media Text .  In our approach, we pre-processed the CM tweets and proposed a Recurrent Convolutional Neural Network for the sentiment analysis of CM tweets. We submitted two runs and obtaining promising results: our best run obtained 0.691 of F1 averaged across the positives, negatives and the neutral.  We observed that the proposed architecture occasionally strives to separate the positive and negative polarities from the neutral and vice versa.    For future work, we will explore the performance of our model with larger corpora against the testing set. Also, we would like to investigate other embedding choices such as BERT . Moreover, due to the impact that irony and sarcasm have on sentiment analysis  it would be interesting to apply deep learning techniques to detect irony  but in a code-mixed scenario.      
","   The performance of many machine learning models depends on their hyper-parameter settings. Bayesian Optimization has become a successful tool for hyper-parameter optimization of machine learning algorithms, which aims to identify optimal hyper-parameters during an iterative sequential process. However, most of the Bayesian Optimization algorithms are designed to select models for effectiveness only and ignore the important issue of model training efficiency. Given that both model effectiveness and training time are important for real-world applications, models selected for effectiveness may not meet the strict training time requirements necessary to deploy in a production environment. In this work, we present a unified Bayesian Optimization framework for jointly optimizing models for both prediction effectiveness and training efficiency. We propose an objective that captures the tradeoff between these two metrics and demonstrate how we can jointly optimize them in a principled Bayesian Optimization framework. Experiments on model selection for recommendation tasks indicate models selected this way significantly improves model training efficiency while maintaining strong effectiveness as compared to state-of-the-art Bayesian Optimization algorithms.",0
" Attention-based transformer networks~ are widely used for sequence modeling tasks, including language modeling and machine translation. To improve performance, models are often scaled to be either wider, by increasing the dimension of hidden layers, or deeper, by stacking more transformer blocks. For example, T5  uses a dimension of 65K and GPT-3  uses 96 transformer blocks. However, such scaling increases the number of network parameters significantly , and complicates learning, i.e., these models either require very large training corpora  or careful regularization . In this paper, we introduce a new parameter-efficient attention-based architecture that can be easily scaled to be both wide and deep.   Our ep and t-weight ransformer architecture, \arch, extends the transformer architecture of \citet{vaswani2017attention} and delivers similar or better performance with significantly fewer parameters and operations. At the heart of \arch~is the \dextra~that uses the group linear transformations  of \citet{mehta2018pyramidal} with an expand-reduce strategy for varying the width and depth of the \arch~block efficiently. Since GLTs are local by nature, the \dextra~uses feature shuffling, which is analogous to channel shuffling in convolutional networks , to share information between different groups. Such wide and deep representations facilitate replacing the multi-head attention and feed-forward layers in transformers with single headed attention and light-weight feed-forward layers, reducing total network parameters and operations. Importantly, unlike transformers, the \dextra~decouples the depth and width from the input size, allowing us to allocate parameters more efficiently across blocks by using shallower and narrower \arch~blocks near the input and deeper and wider \arch~blocks near the output.  We demonstrate that \arch~models achieve similar or better performance than transformer models with significantly fewer parameters and operations, on two common sequence modeling tasks,  machine translation and   language modeling. On the low resource WMT'16 En-Ro machine translation dataset, \arch~attains transformer performance using  fewer parameters. On the high resource WMT'14 En-Fr dataset, \arch~delivers better performance  with  fewer parameters than baseline transformers. Similarly, on language modeling, \arch~matches the performance of  Transformer-XL~ with  fewer parameters on the WikiText-103 dataset. Our source code is open-source and is available at: \textcolor{blue}{\url{https://github.com/sacmehta/delight}}      We introduced a unified Bayesian Optimization framework for jointly optimizing models for both effectiveness and training efficiency. We propose an objective that captures the tradeoff between accuracy and training efficiency and demonstrate how we can jointly optimize these measures in a principled framework. Experiments on several real-world model selection and rating prediction tasks indicate this approach significantly improves model training efficiency while maintaining strong effectiveness as compared to state-of-the-art baseline models.  
"," We introduce a deep and light-weight transformer, \arch, that delivers similar or better performance than standard transformer-based models with significantly fewer parameters. \arch~more efficiently allocates parameters both  within each Transformer block using the \dextra, a deep and light-weight transformation and  across blocks using block-wise scaling, that allows for shallower and narrower \arch~blocks near the input and wider and deeper \arch~blocks near the output. Overall, \arch~networks are 2.5 to 4 times deeper than standard transformer models and yet have fewer parameters and operations. Experiments on benchmark machine translation and language modeling tasks show that \arch~matches or improves the performance of baseline Transformers with 2 to 3 times fewer parameters on average.",1
" The deep learning community  has been looking for alternatives to recurrent neural networks  for storing information. For example, linear memory networks use a linear autoencoder for sequences  as a memory . Additional memories for RNNs like holographic reduced representations , tensor product representations  and classical associative memories  have been suggested. Most approaches to new memories are based on attention. The neural Turing machine  is equipped with an external memory and an attention process .   Memory networks  use an  attention by first mapping a query and patterns into a space and then retrieving the pattern with the largest dot product. End to end memory networks  make this attention scheme differentiable by replacing  through a  . EMN with dot products became very popular and implement a key-value attention  for self-attention. An enhancement of EMN is the transformer  and its extensions . The transformer has had a great impact on the natural language processing  community, in particular via the BERT models .   {\bf Contribution of this work:}  introducing novel deep learning layers that are equipped  with a memory via modern Hopfield networks,  introducing a novel energy function and a novel update rule for  continuous modern Hopfield networks that are differentiable and  typically retrieve patterns after one update.  Differentiability is required for gradient descent parameter updates and retrieval with one update is compatible with activating the layers of deep networks.   We suggest using modern Hopfield networks  to store information or learned prototypes in different  layers of neural networks. Binary Hopfield networks  were introduced as associative memories that can store and retrieve patterns . A query pattern can retrieve the pattern to which it is most similar or an average over similar patterns. Hopfield networks seem to be an ancient technique, however, new energy functions improved their properties. The stability of spurious states or metastable states was sensibly reduced . The largest and most impactful successes are reported on increasing the storage capacity of Hopfield networks. In a -dimensional space, the standard Hopfield model can store  uncorrelated patterns without errors but only  random patterns with  for a fixed stable pattern or  if all patterns are stable . The same bound holds for nonlinear learning rules . Using tricks-of-trade and allowing small retrieval errors, the storage capacity is about  . If the learning rule is not related to the Hebb rule, then up to   patterns can be stored . For Hopfield networks with non-zero diagonal matrices, the storage can be  increased to  . In contrast to the storage capacity, the number of energy minima   of Hopfield networks  is exponential in  .    The standard binary Hopfield network has an energy function that can be expressed as the sum of interaction functions  with . Modern Hopfield networks, also called  ``dense associative memory''  models, use an energy function with interaction functions of the form  and, thereby, achieve a storage capacity proportional to  . The energy function of modern Hopfield networks  makes them robust against adversarial attacks . Modern binary Hopfield networks with energy functions based on  interaction functions of the form  even lead  to storage capacity of , where all stored binary patterns are fixed points but the radius of attraction vanishes . However, in order to integrate Hopfield networks into deep learning architectures, it is necessary to make them differentiable, that is, we require continuous Hopfield networks .  Therefore, we generalize the energy function of \citet{Demircigil:17} that builds on exponential interaction functions to continuous patterns and states and obtain  a new modern Hopfield network. We also propose a new update rule which ensures global convergence to stationary points of the energy .  We prove that our new modern Hopfield network typically retrieves patterns in one update step  with an exponentially low error and has a storage capacity proportional to  . The retrieval of patterns with one update is important to integrate  Hopfield networks in deep learning architectures,  where layers are activated only once. Surprisingly, our new update rule is also  the key-value attention  as used in transformer and BERT models . Our modern Hopfield networks can be integrated as a new layer in deep learning architectures for pooling, memory, prototype learning, and attention. We test these new layers on different benchmark datasets and tasks like immune repertoire classification.       This paper introduces a deep and light-weight transformer architecture, \arch, that efficiently allocates parameters both within the \arch~block and across \arch~blocks. Compared to state-of-the-art transformer models, \arch~models are  deep and light-weight and  deliver similar or better performance. In the future, we plan to apply \arch~to other tasks, including language model pre-training, question answering, and language generation.    Acknowledgements: This research was supported by ONR N00014-18-1-2826, DARPA N66001-19-2-403, NSF , and an Allen Distinguished Investigator Award. Authors would also like to thank members of the UW-NLP and the H2Lab at The University of Washington for their valuable feedback and comments.  \small{   }  \clearpage    
"," We introduce a modern Hopfield network with continuous states and a corresponding update rule. The new Hopfield network can store  exponentially  many patterns,  retrieves the pattern with one update, and has exponentially small retrieval errors. It has three types of energy minima :  global fixed point averaging over all patterns,   metastable states averaging over a subset of patterns, and   fixed points which store a single pattern. The new update rule  is equivalent to the attention mechanism used in transformers. This equivalence enables a  characterization of the heads of transformer models. These heads perform in the first layers preferably global averaging and in higher layers partial averaging  via metastable states.  The new modern Hopfield network can be integrated  into deep learning architectures  as layers to allow the storage of and access to  raw input data, intermediate results, or learned prototypes. These Hopfield layers enable new ways of deep learning,  beyond fully-connected, convolutional, or recurrent networks, and provide pooling, memory, association, and attention mechanisms. We demonstrate the broad applicability of the Hopfield layers across various domains. Hopfield layers improved state-of-the-art on three out of four considered multiple instance learning problems as well as on immune repertoire classification with several hundreds of thousands of instances. On the UCI benchmark collections of small classification tasks,  where deep learning methods typically struggle,  Hopfield layers yielded a new state-of-the-art when compared to different machine learning methods. Finally, Hopfield layers achieved state-of-the-art on two drug design datasets. The implementation is available at: \url{https://github.com/ml-jku/hopfield-layers}",2
" % Computer Society journal papers do something a tad strange with the very % first section heading . They place it % ABOVE the main text! IEEEtran.cls currently does not do this for you. % However, You can achieve this effect by making LaTeX jump through some % hoops via something like: % %\ifCLASSOPTIONcompsoc %  \raisebox{2\baselineskip}[0pt][0pt]% %  {\parbox{\columnwidth}{  In this paper, we propose the DeText  ranking framework with BERT/CNN based ranking model for practical usage in industry. To accommodate the requirements of different ranking productions, DeText allows flexible configuration, such as input data, text embedding extraction, traditional feature handling, etc. These choices enable us to experiment and develop scalable neural network models with strong relevance performance.  Our offline experiments show that DeText-LiBERT/DeText-CNN consistently outperforms the strong production baselines. The resulting models are deployed into three vertical searches in LinkedIn's commercial search engines.          The next two lines define the bibliography style to be used, and the bibliography file.    
", %\boldmath %The abstract goes here. %,3
" % COMPLETED.  \acp{KG} represent structured collections of facts describing the world in the form of typed relationships between entities. These collections of facts have been used in a wide range of applications including Web search), cancer research, and even entertainment. However, most \acp{KG} on the Web are far from being complete. For instance, the birth place of  of the persons in Freebase and  of the persons in DBpedia is not to be found in the respective \acp{KG}. In addition, more than  of the scientists in DBpedia are not linked to the predicate that describes what they are known for. Identifying such missing links is referred to as link prediction. \ac{KGE} approaches map \acp{KG} to continuous vector spaces and have been proven to be highly effective and efficient at addressing the task of link prediction.   In this paper, we propose \approach, a simple but effective new \ac{KGE} approach. \approach is a complex-valued convolutional neural model that learns complex-valued vector representations of a given \ac{KG} by combining a 2D convolution operation with a Hermitian inner product. The motivation behind our approach lies in the following considerations:   We evaluate our approach against 37 state-of-the-art approaches on four benchmark datasets often used in the literature. Overall, our results suggest that \approach outperforms current state-of-the-art approaches , in terms of \ac{MRR} and Hits at N .% -- standard measures for the link prediction task.  %structure of the paper % The rest of this paper is structured as follows: % We provide an overview of the state of the art in \ac{KGE}  in~\Cref{sec:related work}. Thereafter, the notation and the preliminaries are presented in~\Cref{sec:preliminaries}. Next, we introduce \approach in~\Cref{sec:approach}. In~\Cref{sec:experiments}, we explicate the research question and experimental settings.~\Cref{sec:results} reports the results of conducted experiments. Finally, we conclude with a discussion in ~\Cref{sec:conclusion}.         The conclusion goes here.        if have a single appendix:  [Proof of the Zonklar Equations]   or      for no appendix heading   do not use 
"," In this paper, we study the problem of learning continuous vector representations of knowledge graphs for predicting missing links. We present a new approach called \approach, which infers missing links by leveraging the composition of a 2D convolution with a Hermitian inner product of complex-valued embedding vectors. We evaluate \approach against state-of-the-art approaches on the WN18RR, FB15K-237, KINSHIP and UMLS benchmark datasets. Our experimental results show that \approach achieves a  performance superior to that of state-of-the-art approaches such as RotatE, QuatE and TuckER on the link prediction task on all datasets while requiring at least 8 times fewer parameters. We ensure the reproducibility of our results by providing an open-source implementation which includes the training, evaluation scripts along with pre-trained models at {\url{https://github.com/conex-kge/ConEx}.}   % \keywords{Knowledge Graph Embeddings \and Link Prediction \and Convolution \and Complex vector space}",4
" Bipolar disorder  is a recurrent chronic mental health condition which occurs in approximately 1\% of the global population . It is characterised by episodes of low and high mood which cause significant interference with everyday life. Borderline personality disorder  is characterised by a long-term pattern of constantly variable mood, self-image and behaviour. Although BD and BPD are two very different conditions they share some similar symptoms such as mood instability and impulsive behaviour . A recent study  reported the high prevalence of comorbidity between the two conditions, with up to 21.6\% of individuals with BD found to have comorbid BPD. As a result they can be difficult to distinguish, but accurate diagnosis is crucial as they require different treatment . Standard diagnostic assessment involves a psychiatrist asking a series of questions about symptoms and the person has to retrospectively describe their account of these symptoms. The success of the assessment also relies on how the psychiatrist interprets both the verbal and non-verbal cues drawn from the person's responses. In this work, we aim to develop a method that extracts cues automatically from interviews conducted in a non-clinical setting, to assist the existing assessment framework, which is expensive and subjective.  Recent studies have explored data driven approaches to automatically screen patients, incorporating features extracted from multiple modalities in clinical interviews, showing diagnostic value for mental health conditions such as depression and bipolar disorder .  finds the performance of automatic mood detection to be much better in clinical interactions than in personal conversations, and there are significant differences in the features important to each type of interaction. While existing studies of BD  have focused on recognising mood episodes, the distinction between BD and BPD remains understudied. In this paper, we aim to bridge this gap by presenting a multi-modal  dataset containing interviews in a non-clinical setting involving individuals with a diagnosis of BD or BPD, and study the automatic assessment of the two mental health conditions.   Motivated to study the interaction between the interviewer and participant during the course of an interview from different aspects , we investigate features extracted from different modalities. Path signatures, initially introduced in rough path theory as a branch of stochastic analysis, has been shown to be successful in a range of machine learning tasks involving modelling temporal dynamics . We propose to apply path signatures for summarising features extracted from each utterance, sentence and speaker-turn into interview-level feature representations, given its ability to naturally capture the order of events. By doing so, we automatically include more non-linear prior knowledge in our final feature set, which leads to effective classification, even with a simple linear classifier.   The contributions of this work are as follows:  We present a new non-clinical interview dataset involving BD and BPD patients; , We investigate different feature types and propose using path signatures as a novel approach of summarising turn-level features;  We demonstrate a good linear model can be learnt for three classification tasks, and provide insights into the distinction between BD and BPD by analysing the importance of the selected features.       The superior performance of \approach stems from the composition of a 2D convolution with a Hermitian inner product of complex-valued embeddings. Applying 2D convolution on complex-valued embeddings of subjects and predicates permits \approach to recognize interactions between subjects and predicates in the form of complex-valued feature maps. Through the projection of feature maps and their inclusion into a Hermitian inner product involving the conjugate-transpose of complex-valued embeddings of objects, \approach can accurately infer various types of relations. For instance, \approach is able to model composition patterns without defining the bijection mapping explicitly. This ability is suggested by since WN18RR and FB15K-237 involve antisymmetric and composite relations. Moreover, shows that \approach requires significantly fewer parameters than RotatE, QuatE and TuckER than WN18RR and FB15K-237. and two more tables in the supplemental material explicitly show that \approach is able to capture various types of relations on benchmark datasets. However, \approach inaccurately ranks entities with \texttt{\_member\_of\_domain\_region} and \texttt{\_member\_of\_domain\_usage}. This may indicate that \approach is not able model triples where subjects and objects are loosely semantically related. Overall, \approach is more expressive than approaches that solely apply 2D convolution in   and solely apply inner products in  by Hermitian Inner Products .     \section{Conclusion and future work}    Completed.  In this work, we introduce a new approach  for addressing the link prediction problem by learning continuous vector representations for knowledge graphs. \approach accurately infers the various types of relations by leveraging a composition of a 2D convolution with a Hermitian inner product of complex-valued embeddings. \approach achieves state-of-the-art performances on standard link prediction datasets while requiring fewer parameters than several state-of-the-art approaches---including QuatE, RotatE and TuckER. In future work, we plan to explore combining 2D convolution with Hamilton閳ユ獨 Quaternions.             
"," Bipolar disorder  and borderline personality disorder  are both chronic psychiatric disorders. However, their overlapping symptoms and common comorbidity make it challenging for the clinicians to distinguish the two conditions on the basis of a clinical interview.  % Recent studies have explored data driven approaches to automatically screen patients, incorporating features extracted from clinical interviews, showing diagnostic value for mental health conditions such as depression and bipolar disorder.  In this work, we first present a new multi-modal dataset containing interviews involving individuals with BD or BPD being interviewed about a non-clinical topic . We investigate the automatic detection of the two conditions, and demonstrate a good linear classifier that can be learnt using a down-selected set of features from the different aspects of the interviews and a novel approach of summarising these features. Finally, we find that different sets of features  characterise BD and BPD, thus providing insights into the difference between the automatic screening of the two conditions.",5
"  Despite impressive improvements in neural machine translation , training a large multilingual NMT model with hundreds of millions of parameters usually requires a collection of parallel corpora at a large scale, on the order of millions or even billions of aligned sentences~ for supervised training. Although it is possible to automatically crawl the web~ to collect parallel sentences for high-resource language pairs such as German-English and Chinese-English, it is often infeasible or expensive to manually translate large amounts of documents for low-resource language pairs, e.g., Nepali-English, Sinhala-English~. Much recent progress in low-resource machine translation, has been driven by the idea of universal machine translation , also known as multilingual machine translation~, which aims at training one single NMT to translate between multiple source and target languages. Typical UMT models leverage either a single shared encoder or language-specific encoders to map all source languages to a shared space, and translate the source sentences to a target language by a decoder. Inspired by the idea of UMT, there has been a recent trend towards learning language-invariant embeddings for multiple source languages in a shared latent space, which eases the cross-lingual generalization from high-resource languages to low-resource languages on many tasks, e.g., parallel corpus mining~, sentence classification~, cross-lingual information retrieval~, and dependency parsing~, just to name a few.  The idea of finding an abstract ``lingua franca'' is very intuitive and the empirical results are impressive, yet theoretical understanding of various aspects of universal machine translation is limited. In this paper, we particularly focus on two basic questions:    Toward answering the first question, we show that in a completely assumption-free setup on the languages and distribution of the data, it is impossible to avoid making a large translation error on at least one pair of the translation tasks. Informally we highlight our first theorem as follows, and provide the formal statements in Theorems and .    To answer the second question, we show that under fairly mild generative assumptions on the aligned documents for the pairwise translations, it is possible to not only do well on all of the pairwise translations, but also be able to do so after only seeing aligned documents of a linear number of languages, rather than a quadratic one. We summarize the second theorem as follows, and provide a formal statement in Theorem.    \paragraph{Notation and Setup} We first introduce the notation used throughout the paper and then briefly describe the problem setting of universal machine translation.   We use  to denote the set of all possible languages, e.g., . For any language , we associate with  an alphabet  that contains all the symbols from . Note that we assume , , but different languages could potentially share part of the alphabet. Given a language , a sentence  in  is a sequence of symbols from , and we denote  as the set of all sentences generated from . Note that since in principle different languages could share the same alphabet, to avoid ambiguity, for each language , there is a unique token  and . The goal of the unique token  is used to denote the source sentence, and a sentence  in  will have a unique prefix  to indicate that . Also, in this manuscript we will use sentence and string interchangeably.   Formally, let \footnote{We use  to denote the set .} be the set of  source languages and  be the target language we are interested in translating to. For a pair of languages  and , we use  to denote the joint distribution over the parallel sentence pairs from  and . Given this joint distribution, we also use  to mean the marginal distribution over sentences from . Likewise we use  to denote the corresponding marginal distribution over sentences from . Finally, for two sets  and , we use  to denote the disjoint union of  and . In particular, when  and  are disjoint, their disjoint union equals the usual set union, i.e., .   In this paper, we demonstrate the potential of using features extracted from language and speech in non-clinical interviews to assist the assessment of bipolar disorder BD and borderline personality disorder BPD, which is challenging for clinicians to distinguish.    It is crucial to diagnose the two conditions accurately so the patients can have appropriate treatment. While many machine learning based studies learn from clinical interviews to automatically screen mental health conditions, the detection of BD and BPD is still understudied. We first presented a non-clinical interview dataset, named AMoSS-I, conducted partially by psychology graduates, for the task of detecting BD and BPD. We demonstrated good performance in three classification tasks using down-selected features and a new way of summarising these features based on path signatures. Lastly, we showed the importance of linguistic features in all three tasks and the benefits of feature fusion from different modalities. For future work, we plan to learn acoustic features, and investigate the effect of acoustic properties of the interviews and the impact of recording environments.   
"," The goal of universal machine translation is to learn to translate between any pair of languages, given a corpus of paired translated documents for a small subset of all pairs of languages. Despite impressive empirical results and an increasing interest in massively multilingual models, theoretical analysis on translation errors made by such universal machine translation models is only nascent.   In this paper, we formally prove certain impossibilities of this endeavour in general, as well as prove positive results in the presence of additional  structure of data.   For the former, we derive a lower bound on the translation error in the many-to-many translation setting, which shows that any algorithm aiming to learn shared sentence representations among multiple language pairs has to make a large translation error on at least one of the translation tasks, if no assumption on the structure of the languages is made.   For the latter, we show that if the paired documents in the corpus follow a natural encoder-decoder generative process, we can expect a natural notion of ``generalization'': a linear number of language pairs, rather than quadratic, suffices to learn a good representation. Our theory also explains what kinds of connection graphs between pairs of languages are better suited: ones with longer paths result in worse sample complexity in terms of the total number of documents per language pair needed.   We believe our theoretical insights and implications contribute to the future algorithmic design of universal machine translation.",6
" Knowledge Based Systems:\\ Systems that incorporate human expertise for making decisions are knowledge-based systems . Traditionally a knowledge-based system consists of a knowledge base which is data suitably collected and organised by human experts in various fields, inference engine - that relies on the knowledge base for decision making, a working memory to handle operations. The inference engine can be rule-based, case-based, etc.\\ Deep Neural Networks:\\ Deep neural networks, on the other hand, is more about statistical modelling that relies on massive amounts of data to find statistical patterns, non-linear relationships to be able to match the prediction patterns from a given training set. It relies on these patterns to infer conclusions about new data as well.\\  Time-series models:\\ A Recurrent neural network is a class of neural network that deals with the prediction of temporal sequences. Long-Short term memory , Gated Recurrent Units are some of the Recurrent neural network architectures that are used for time series forecasting.\\\\ Sequence to Sequence models:\\ Sequence to sequence models aims to translate a fixed-length input sequence to a fixed-length output sequence where the length of the input and output may differ. It mainly has three parts: the encoder, intermediate vector and the decoder. In the encoder, several stacks of recurrent units  are combined such that each unit accepts an input element from the sequence and propagates it, thus forming an intermediate hidden state. This information in the hidden state is consumed by the decoder part of the network that in turn consists of sequences of recurrent units that produce a sequence of outputs. \subsection{Synergy between the Knowledge base systems and the Deep neural networks} Although the Deep neural networks have shown promising performance in several fields, there exist areas like interpretability, reasoning in which they lack and hence needs attention. On the other hand, Expert Systems are built on top of the characteristics which the Deep neural networks lack. Hence there can be ways where we can leverage the strengths of both systems by various principles. This paper discusses some of the techniques of integrating expert knowledge to Deep Neural Networks to attain a kind of synergy between them.       In this paper, we propose a Context Reinforced Neural Topic Model  to address the feature sparsity problem in short texts. By introducing a topic controller to the inference network, CRNTM infers the topic for each word in a narrow range. Besides, pre-trained word embeddings are incorporated with multivariate Gaussian distributions or Gaussian mixture distributions into our model to enrich the context information of short messages. To quantitatively validate the effectiveness of CRNTM, we conduct various experiments on two benchmark datasets in terms of perplexity, topic coherence, and text classification accuracy. The results indicate that the proposed model largely improves the performance of topic modeling by enriching the context information effectively.  
"," In recent years, with the advent of massive computational power and the availability of huge amounts of data, Deep neural networks have enabled the exploration of uncharted areas in several domains. But at times, they under-perform due to insufficient data, poor data quality, data that might not be covering the domain broadly,  etc. Knowledge-based systems leverage expert knowledge for making decisions and suitably take actions. Such systems retain interpretability in the decision-making process. This paper focuses on exploring techniques to integrate expert knowledge to the Deep Neural Networks for sequence-to-sequence and time series models to improve their performance and interpretability.   \keywords{Deep Neural Network, TimeSeries, Sequence-to-Sequence models, Expert Knowledge}",7
" A heuristic approach to automated test case generation  from formal requirements specifications known as  learning-based testing  was introduced in ,  and .  Learning-based testing is an iterative approach to automate specification-based black-box testing. It encompasses both test case generation, execution and evaluation .  The aim of LBT is to automatically generate a large number of  high-quality test cases by combining a model checking algorithm with an optimised model inference algorithm .  For both procedural  and reactive systems   it has been shown that LBT can significantly outperform random testing in the speed with which it finds errors in a system under test .  This is because random test suites generally contain a large degree of redundancy, which can be reduced by using learning algorithms and model checkers to execute a more directed search for software errors.  An efficient and practical implementation of learning-based testing for reactive systems has been developed in the LBTest tool . In this paper we describe the IKL  algorithm implemented in LBTest.  IKL is an algorithm for active incremental learning of deterministic Kripke structures. The reliability of LBTest for producing correct test results depends crucially on the correctness of this learning algorithm. So we give a formal definition of  IKL and prove its correctness. The IKL algorithm involves a number of optimisations necessary to achieve scalability of testing for large software systems.  We discuss these optimisations from the perspective of learning and testing.  The problems of coverage, and termination criteria for black-box testing, are complex and different solutions have been proposed.  In LBT, convergence of learning can sometimes be used as a criterion to terminate testing. However, heuristics are needed  to estimate convergence in the context of black box testing. We will empirically evaluate the reliability of a simple heuristic for IKL.   In the remainder of Section 1, we discuss the general paradigm of LBT, and specific requirements on learning for  efficient testing of reactive systems. In Section 2, we review some essential mathematical preliminaries. In Section 3, we present the  architecture of the IKL learning algorithm and its main components. These three main components are  defined and analysed in detail in  Sections 4, 5 and 6. In Section 4, we consider a learning algorithm for families of DFA which  supports  incremental learning and projection . In Section 5, we consider integrating a family of DFA  into a single Kripke structure using a subdirect product construction.   In Section 6, we consider an efficient minimisation algorithm for  deterministic Kripke structures based on Hopcroft's DFA minimisation algorithm . This is needed by the IKL algorithm to produce hypothesis models that can be efficiently model checked.  In Section 7, we empirically evaluate a black box heuristic to detect convergence of IKL, that can be used as a test termination criterion. Finally, in Section 8 we draw some conclusions and suggest prospects for further research on learning and testing.  \subsection{Learning-Based Testing}   The basic LBT paradigm requires three components: \vskip 4pt   a  system under test  , \vskip 4pt   a formal requirements specification  for , and  \vskip 4pt   a learned model  of .  \vskip 4pt Now  and  are common to all specification-based testing, and it is really  that is distinctive. Learning-based testing is a heuristic iterative method to automatically generate a sequence of test cases. The heuristic concept is to learn a black-box system using  tests as queries.     In general, an LBT algorithm iterates the following four steps:  \vskip 4pt   Suppose that  test case inputs  have been executed  on  yielding the system outputs . The  input/output observations   can be synthesized into a learned model  of  using an incremental learning algorithm . This step involves generalization from the observed  behaviour,  to all possible behaviour. This generalisation step gives the possibility to predict previously unseen errors in  during Step 2. \vskip 4pt   The system requirements  are checked against the learned model  derived in Step 1 . This process searches for a  counterexample  to the requirements.  \vskip 4pt   The counterexample  is executed as the  next  test case on , and if  terminates then the output  is obtained.  If  fails this test case \Reqi_{n+1}Si_{n+1}M_ni_{n+1}Si_{n+1}n+1 \c \ldots \c M_{n+1}SS1 \dotsM_0M_1M_2\ldotsSni_{n+1}i_{n+1}\ReqL\Aut_0 \c \Aut_1 \c \ldots \Aut\Aut\Aut_0 \c \Aut_1 \c \ldots \Aut\Aut_{i+1}L\Aut_{i}SS\Req\Req\Req\Req\ReqS\ReqS\Req\ReqSS\mathcal O\mathcal O\mathcal O$.  Our generalisation of Hopcroft's DFA minimisation algorithm to deterministic Kripke structures in Section 6 is fairly simple and straightforward. Nevertheless, this algorithm has not been previously published in the literature, and represents another novel contribution.      In this paper, we discussed some of the techniques for integrating expert knowledge in the form of First-order Logic Rules, tuples, embeddings etc with the neural network for time-series and sequence-to-sequence models. While each technique has its own set of pros and cons, it would be optimal to come up with a scalable technique that can incorporate the positive aspects of the above-discussed techniques.     
"," Learning-based testing  is an emerging methodology to automate iterative black-box requirements testing of software systems. The methodology involves combining model inference with model checking techniques. However, a variety  of optimisations on model inference are necessary in order to achieve scalable testing for large systems.  In this paper we describe the IKL learning algorithm which is an active incremental learning algorithm for deterministic Kripke structures.  We formally prove the correctness of IKL. We discuss the optimisations it incorporates to achieve scalability of testing. We also evaluate a black box heuristic for test termination based on convergence of IKL learning.",8
"  	  Since early attempts that pretrain a backbone model  on large-scale dataset  and then transfer the knowledge to numerous computer vision tasks, pretraining has become a hallmark of the success of deep learning. More recently, the volume of transformer-based and Bert-style pretraining models  has grown tremendously in the research field of natural language processing and has achieved state-of-the-art performance in various NLP tasks. Likewise, the success of Bert-style pretraining techniques has been transferred to the research field of the intersection of vision and language .    %--------------------------------fig-------------------------  %--------------------------------fig end---------------------  Despite the significant progress that recent methods have made over the initiative work ViLBert , part of their success can be traced back to the introduction of in-domain pretraining datasets besides the Conceptual Caption  dataset. By in-domain, we refer to those datasets used in both pretraining and downstream tasks, such as MSCOCO , and Visual Genome .  However, out-of-domain pretraining, \ie, pretraining models on out-of-domain datasets and transferring the learned knowledge into downstream tasks with unkown data distributions, can be an essential research topic.  In this paper, we focus on out-of-domain pretraining and learning generic representations as the ViLBert does.      A fundamental requirement for out-of-domain transfer learning is to mitigate the biases from the pretraining data , which may be useful for the in-domain testing but harmful for out-of-domain testing  due to the spurious correlation .  To verify such existence of the correlation biases, we follow  to conduct a toy experiment on Conceptual Caption dataset. We observe that the conditional probability of   given the   is large, \ie, , but there are actually no robust relationships between them. Most previous works just blame this for the biased data collection without further justification.  However, this is not reasonable since we human ourselves are just living in a biased nature. In our methodology, we draw inspiration from the causal inference  and borrow the idea of the backdoor adjustment   to mitigate these biases.  As shown in Figure ,  the traditional association-based learning fashion may lead to the spurious correlation between two tokens  by a common cause, \ie, the confounder. By introducing backdoor adjustment , the original conditional probability of  can be adjusted to   with a do operator.  The essence of deconfounding is to control the condition  from being affected by other potential confounders when assessing the effect on the outcome  given the condition, \ie, intervention.  In this way, the pure association-based pretraining becomes to the causal intervention-based pretraining.  We note that our goal is not performing theoretically causal inference but learning generic and de-biased visio-linguistic representations that can well generalize to downstream tasks with unknown data distributions.   We are particularly targeting at the Bert-style pretraining models and the context-based proxy tasks for supervision, such as masked language/object modeling . Context-based proxy tasks solely care about association, \ie, what co-occur with the anchor token without considering whether there are spurious correlations  or not. More formally, masked token modeling, abbreviated as MTM, models the conditional probability  as the distribution of  when observing .  is the masked token and  denotes the context information. The spurious correlation occurs when  and  are confounded by a common cause , as depicted in Figure . Our goal is to model the interventional operation , meaning the distribution of  when controlling  to mitigate the correlation bias as we introduced before.  Real-world cases concerning the conditional probabilities and the corresponding intervention results from the Conceptual Captions dataset can be found in Figure . In this paper, we propose several intervention-based BERT architectures to help learn deconfouned visio-linguistic representations. We name this kind of architectures as DeVLBert, which refers to 	extbf{Deconfounded Visio-Linguisitic Bert}. DeVLBert is designed as model-agnostic and can be easily encapsulated into any other Bert-style models.    We conduct in-depth experiments to discuss the performance of the proposed DeVLBert architectures.  Pretraining is performed on the Conceptual Caption dataset which most downstream tasks are not built on, \ie, out-of-domain dataset. We evaluate the effects of these architectures on three downstream cross-modal tasks, including text-to-image retrieval , zero-shot text-to-image retrieval, and visual question answering . We also conduct case studies to evaluate DeVLBert from the human perspective, and demonstrate that mitigating dataset biases boosts the generalization ability.     The main contributions of our work are summarized as follows:    	  	              We have defined and analysed a learning algorithm IKL for deterministic Kripke structures which is efficient for applications in software testing.  This algorithm extends active incremental learning with new features such as lazy learning and projection.  We have formally proved the correctness of the IKL algorithm and its main components. We have also empirically evaluated a black box heuristic for detecting convergence of learning, which can be used to terminate testing for small systems under test.   Incremental learning and projection combine to make IKL scalable to larger systems under test. Also, incremental and lazy learning combine  to support frequent generation of hypothesis automata with which we can discover SUT errors much faster than random testing by model checking. These claims have been empirically evaluated and supported  in  and . The IKL algorithm has been implemented in the LBTest tool  for learning based testing of  reactive systems.     We believe that the efficiency of learning-based testing can be even further improved by more research on model inference.  For example, the modular architecture of the IKL algorithm can support experiment with other incremental DFA learning algorithms  instead of  the ID learning algorithm of Section 4, . The impact of the frequency of hypothesis automata generation on testing efficiency could then be further  investigated. When hypothesis generation is very frequent the overhead of model checking is high, and this overhead can slow down the entire  LBT process. However, if generation is very infrequent, then little use is made of the model checker  to conduct a  directed search for SUT errors using queries that can falsify the user requirements. This is also inefficient.  More generally, we could consider an optimal tuning of the rate of hypothesis automata generation, e.g. based on the estimated density of SUT errors.  The relationship between computational learning and software testing has been a fruitful line of research ever since Weyuker's thesis . Many fundamental questions remain within the context of learning-based testing.  For example, the execution of any automata learning algorithm can always be associated with a prefix tree construction   based on the query set used. How can we influence the choice between breadth-first and depth-first search  for SUT errors using this prefix tree?   This is currently achieved  by an ad-hoc but pragmatic balance in IKL between model checker queries and active learning queries.  Another important question is whether we  can find other techniques to generate  active learner queries besides congruence construction? Such techniques should be aimed at reducing the need for random queries, which can be very inefficient in practise.  We gratefully acknowledge financial support for this research from the Swedish Research Council , the Higher Education Commission  of Pakistan,   and the European Union under project HATS FP7-231620.       ---- Bibliography ----    	   		  expects file ""myrefs.bib""   
","  In this paper, we propose to investigate the problem of out-of-domain visio-linguistic pretraining, where the pretraining data distribution differs from that of downstream data on which the pretrained model will be fine-tuned. Existing methods for this problem are purely likelihood-based, leading to the spurious correlations and hurt the generalization ability when transferred to out-of-domain downstream tasks. By spurious correlation, we mean that the conditional probability of one token  given another one can be high  without robust  relationships between them. To mitigate such dataset biases, we propose a Deconfounded Visio-Linguistic Bert framework, abbreviated as DeVLBert, to perform intervention-based learning. We borrow the idea of the backdoor adjustment from the research field of causality and propose several neural-network based architectures for Bert-style out-of-domain pretraining. The quantitative results on three downstream tasks, Image Retrieval , Zero-shot IR, and Visual Question Answering, show the effectiveness of DeVLBert by boosting generalization ability.",9
"  % Thanks to the development of generative modeling, algorithmic music generation is made possible. % In recent years, instead of relying on rule-based systems or plain time-series analysis, we have seen work using recurrent networks or an attention-based model to generate music that is comparable to a human professional. % Despite the capacity of these models, the lack of interpretability remains as the main obstacle for controllable music generation ---in particular polymonic music with much richer structures.  With the development of artificial neural networks, deep learning has become one of the most popular techniques for automated music generation. In particular, we see recurrent and attention-based models being able to generate creative and human-like music without heavily handcrafted rules . %compared to traditional time-series models and rule-based algorithms. % 鏉╂瑩鍣风拠纾l濮ｆ敂ulebase瀵缚顫eviewer閺璇插毊娴滃棴绱濇潻娆愮壉鐠囧瓨娲跨广垼顫囬妴  However, the main drawback of these deep generative models is that they behave like ``black boxes閳, and it is difficult to interpret the musical meaning of their internal latent variables . Consequently, it remains a challenging task to control the generation process . This limitation restricts the application scenario of the powerful deep generative models.   In this paper, we improve the model interpretability for music generation via constrained representation learning. Inspired by the content-style disentanglement idea , we enforce the model to learn two fundamental factors of polyphonic music: chord  and texture . The former refers to the representation of the underlying chord progression, and the latter includes chord arrangement, rhythmic pattern, and melody contour. The current design focuses on learning 8-beat long piano composition segments under a variational autoencoder  framework.   The core of the model design lies in the encoder. We incorporate the encoder with two inductive biases for a successful chord-texture disentanglement. The former applies a rule-based chord recognizer and embeds the information into the first half of the latent representation. The latter regards music as 2-D images and uses a chord-invariant convolutional network to extract the texture information, storing it into the second half of the latent representation. As for the decoder, we adopt the design from PianoTree VAE , an architecture that can reconstruct polyphonic music from the latent representation in a hierarchical manner.  We further show that the interpretable representations are general-purpose, empowering a wide spectrum of controllable music generation. In this study, we explore the following three scenarios:   In sum, the contributions of our paper are as follows:         In this paper, we propose to mitigate the spurious correlations for out-of-domain visio-linguistic pretraining. The fact that each output token is connected with all input tokens in Bert, and the pure association nature of masked token modeling objective makes the problem more severe. We borrow the idea of back-door adjustment to propose four novel Bert-style architectures as DeVLBert for out-of-domain pretraining. We conduct extensive quantitative evaluations as well as ablation studies to discuss the empirical effectiveness of different architectures. The results show that DeVLBert can achieve promising numerical results compared to the baseline and even some in-domain visio-linguistic pretraining methods.   
"," % While deep generative modeling has become promising in many domains, it remains a challenging task to algorithmically compose polymeric music,  essentially hindered by its rich structure. % Inspired by the recent work of disentanglement of factors of variations, we develop a novel architecture, under the VAE framework, that not only disentangles the chord and texture of an input polymeric segment, also provides a generation pathway leading to plausible music style transfer and analogy. % Through a wide spectrum of task validations, we show that the chord-texture resulted from our model enables several tasks including compositional style transfer, texture variation, chord progression interpolation and accompaniment arrangement. % By both automatic metrical and human-based evaluation, our method achieves the state-of-the-art quality on the music generation. While deep generative models have become the leading methods for algorithmic composition, it remains a challenging problem to control the generation process because the latent variables of most deep-learning models lack good interpretability. Inspired by the content-style disentanglement idea, we design a novel architecture, under the VAE framework, that effectively learns two interpretable latent factors of polyphonic music: chord and texture. The current model focuses on learning 8-beat long piano composition segments. We show that such chord-texture disentanglement provides a controllable generation pathway leading to a wide spectrum of applications, including compositional style transfer, texture variation, and accompaniment arrangement. Both objective and subjective evaluations show that our method achieves a successful disentanglement and high quality controlled music generation.\!\!\footnote{Code and demos can be accessed via \url{https://github.com/ZZWaang/polyphonic-chord-texture-disentanglement}}",10
"  Humans learn to use language  over the course of their lives from the interactions they have with the world and other people. Yet, the prevailing dominant paradigm in natural language processing  research is to build a fixed dataset from which to train a model and then freeze it, without any ability for the model to interact with humans using language at training time at all. While we need such  interaction in order to study human-machine communication to its full extent, constraints usually inhibit such research.  Firstly, conducting such experiments can be costly.  %, %for example research budgets for paying crowdworkers mean that data will have a limit. Many datasets in NLP are collected with crowdsourcing, whereby one pays the crowdworkers to perform interaction and annotation tasks. This leads to several issues, not least that  research budgets for paying crowdworkers mean that data will have a limit. %collecting a large amount of data is difficult  %Secondly, distribution as they are only motivated by money, not by actual interest in the dialogues themselves. Secondly, as crowdworkers are motivated by pay, not by interest in the actual tasks themselves, the data distribution may not match the desired one .  In this work we study the ability of an open-domain}.     %We show that our iterative collection-retraining/redeployment % open source everything   %Finally, it is considerably more challenging to engage unpaid humans to provide high quality dialogue when conversing with dialogue models.  %* *Never-Ending Learning:  show it閳ユ獨 improving* %    * future of ML/AI/NLP is not fixed datasets, but continual interactive learning %* game with a purpose    %* Side points: %    * Price )  %    * Distribution  %    * Deployment leads to collecting data, and natural place to evaluate and compare models %    * games as an ideal testbed for AI, w/ rich human interaction, grounding, sandbox %    * while things like alexa challenge do allow a fully deployed system, because of the proprietary nature and other privacy concerns, that research is not open and reproducible. %Collect data, evaluate models. %           In conclusion, we contributed an effective algorithm to disentangle polyphonic music representation into two interpretable factors, chord and texture, under a VAE framework. Such interpretable representations serve as an intuitive human-computer co-creation interface, by which we can precisely manipulate individual factors to control the flow of the generated music. In this paper, we demonstrated three ways to interact with the model, including compositional style transfer via swapping the latent codes, texture variation by sampling from the latent distribution, accompaniment arrangement using downstream conditional prediction, and there are potentially many more. We hope this work can shed light on the field of controllable algorithmic composition in general, especially on the paradox between model complexity and model interpretability.  We acknowledge that the learned music factors are still very basic. In the future, we plan to extract more abstract and longer-range features using hierarchical models. We also plan to explore more ways to control the music generation for practical usage.                         For bibtex users: 
"," Much of NLP research has focused on crowdsourced static datasets and the supervised learning paradigm of training once and then evaluating test performance.  As argued in \citet{de2020towards}, crowdsourced data has the issues  of lack of naturalness and relevance to real-world use cases, while the static dataset paradigm does not allow for a model to learn from its experiences of using language \cite{silver2013lifelong}. % %We posit that, in order to overcome these issues, machine learning must develop systems where models continually improve by interacting with humans and the world. % % In order to overcome these issues, machine learning must develop systems where models continually improve by interacting with humans and the world.  In contrast, one might hope for machine learning systems that become more useful as they interact with people. % In this work, we build and deploy a %  role-playing game, whereby human players converse with learning agents situated in an open-domain fantasy world. We show that by training models on the conversations they have with humans in  the game the models progressively improve, as measured by automatic metrics and online engagement scores. This learning is shown to be more efficient than crowdsourced data when applied to conversations with real users, as well as being far cheaper to collect.  %We are releasing the models and data from this work.",11
"  	Recently, deep learning has witnessed a great process . 	Video question answering  has become an emerging task in computer vision and has drawn increasing interests over the past few years due to its vast potential applications in artificial question answering system and robot dialogue, video retrieval, etc. In this task, a robot is required to answer a question after watching a video. 	Unlike the well-studied Image Question Answering  task which focuses on understanding static images, video QA is more practical since the input visual information often change dynamically, as shown in Figure . 	 	 	 	 	 	Compared with image QA, video QA is much more challenging due to several reasons.  Visual content is more complex in a video since it may contain thousands of frames, as shown in Figure . More importantly, some frames may be dominated with strong background content which however is irrelevant to questions.  Videos often contain multiple actions, but only a part of them are of interest to questions. 	 Questions in video QA task often contain queries related to temporal cues, which implies we should consider both temporal location of objects and complex  interaction between them for answer reasoning. For example in Figure , to answer the question ``What does the man do before spinning bucket?"", the robot should not only recognize the actions ``spin laptop'' and ``spin bucket'' by understanding the interaction between the man and objects  in different frames, but also find out the temporal order of actions  for answer reasoning along time axis. 	   	 	 	Taking video frames as inputs, most existing methods  employ some spatio-temporal attention mechanism on frame features to ask the network ``where and when to look''. 	However, these methods are often not robust due to complex background content in videos. 	% However, extracting features from the whole frame makes the model be prone to over-fit the background content .  	Lei et al.  tackle this problem by detecting the objects in each frame and then processing the sequence of object features via an LSTM. However, the order of the input object sequence, which may affect the performance, is difficult to arrange. 	More importantly, processing the objects in a recurrent manner will inevitably neglect the direct interaction between nonadjacent objects. This is critical for video QA . 	 	In this paper, we introduce a simple yet powerful network named Location-aware Graph Convolutional Networks  to model the interaction between objects related to questions. We propose to represent the content in a video as a graph and identify actions through graph convolution. 	% we propose to explicitly detect the salient objects in videos and model their relationship through constructing a fully-connected graph.  	Specifically, the objects of interest are first detected by an off-the-shelf object detector. Then, we construct a fully-connected graph where each node is an object and the edges between nodes represent their relationship.  	We further incorporate both spatial and temporal object location information into each node, letting the graph be aware of the object locations. When performing graph convolution on the object graph, the objects directly interact with each other by passing message through edges. Last, the output of GCNs and question features are fed into a visual-question interaction module to predict  a answer.  	Extensive experiments demonstrate the effectiveness of the proposed location-aware graph. We achieve state-of-the-art results on TGIF-QA, Youtube2Text-QA and MSVD-QA datasets. 	 	The main contributions of the proposed method are as follows:  we propose to explore actions for video QA task through learning interaction between detected objects such that irrelevant background content can be explicitly excluded;  we propose to model the relationships between objects through GCNs such that all objects are able to interact with each other directly;  we propose to incorporate object location information into graph such that the network is aware of the location of a specific action;  our method achieves state-of-the-art performance on TGIF-QA, Youtube2Text-QA and MSVD-QA datasets. 	  	 	 	   We have presented a fully realized system for improving  upon an open-domain dialogue task  open-domain dialogue  by utilizing a deployed game for lifelong learning.   Detailed experiments showed that the one can collect high quality data that improves both automatic offline metrics and user engagement metrics when used for training models. We find this exciting because this approach shows it is possible to build continually improving models that learn from interacting with humans in the wild , which represents a paradigm shift away from the limited static dataset  setup that is prevalent in much of the work of the community.    Future work should study the resulting publicly released data to explore other methods of  lifelong learning,  or other learning signals that could be extracted from human utterances, for example  the ideas in \citet{hancock2019selffeeding}.  Another possible direction, for when model performance begins to saturate, is to exploit control of the game engine itself to emphasize learning on the most difficult cases or the ones with the most learning signal, such as in the work on adversarial collection .  Finally, our role-playing setup can also be applied more generally, for example incorporating both dialogue and actions,  situated in other domains.     
","           We addressed the challenging task of video question answering, which requires machines to answer questions about videos in a natural language form. Previous state-of-the-art methods attempt to apply spatio-temporal attention mechanism on video frame features without explicitly modeling the location and relations among object interaction occurred in videos. However, the relations between object interaction and their location information are very critical for both action recognition and question reasoning.  In this work, we propose to represent the contents in the video as a location-aware graph by incorporating the location information of an object into the graph construction. Here, each node is associated with an object represented by its appearance and location features. Based on the constructed graph, we propose to use graph convolution to infer both the category and temporal locations of an action.  		As the graph is built on objects, our method is able to focus on the foreground action contents for better video question answering.  Lastly, we leverage an attention mechanism to combine the output of graph convolution and encoded question features for final answer reasoning. 		Extensive experiments demonstrate the effectiveness of the proposed methods. Specifically, our method significantly outperforms state-of-the-art methods on TGIF-QA, Youtube2Text-QA and MSVD-QA datasets. Code and pre-trained models are publicly available at:  % 		\textcolor{red}{\tt{https://github.com/SunDoge/L-GCN}}         \url{https://github.com/SunDoge/L-GCN}",12
"  The world is seeing a paradigm shift the way we conduct our daily activities amidst ongoing coronavirus  pandemic - be it online learning, the way we socialize, interact, conduct businesses or do shopping. Such global catastrophes have a direct effect on our social life; however, not all cultures react and respond in the same way given a crisis. Even under normal circumstances, research suggests that people across different cultures reason differently . For instance, Nisbett in his book ""The geography of thought: How Asians and Westerners think differently... and why"" stated that the East Asians think on the basis of their experience dialectically and holistically, while Westerners think logically, abstractly, and analytically . This cultural behavior and attitude are mostly governed by many factors, including the socio-economic situation of a country, faith and belief system, and lifestyle. In fact, the COVID-19 crisis showed greater cultural differences between countries that seem alike with respect to language, shared history and culture. For example, even though Denmark and Sweden are two neighboring countries that speak almost the same language and share a lot of culture and history, they stand at extreme ends of the spectrum when it comes to the way how they reacted to coronavirus . Denmark and Norway imposed more robust lockdown measures closing borders, schools, restaurants, and restricting gathering and social contact, while on the other side, Sweden has taken a relaxed approach to the corona outbreak keeping its schools, restaurants, and borders open.   Social media platforms play an essential role during the extreme crisis as individuals use these communication channels to share ideas, opinions, and reactions with others to cope with and react to crises. Therefore, in this study, we will focus on exploring collective reactions to events expressed in social media. Particular emphasis will be given to analyzing people's reactions to global health-related events especially the COVID-19 pandemic expressed in Twitter's social media platform because of its widespread popularity and ease of access using the API. To this end, tweets collected from thousands of Twitter users communicated within four weeks after the corona crisis are analyzed to understand how different cultures were reacting and responding to coronavirus. Additionally, an extended version of publicly available tweets dataset was also used. A new model for sentiment and emotion analysis is proposed. The model takes advantage of natural language processing  and deep neural networks and comprises two main stages. The first stage involves sentiment polarity classifier that classifies tweets as positive and negative. The output of the first stage is then used as input to an emotion classifier that aims to assign a tweet to either one of positive emotions classes  or one of the negative emotions classes . Figure  shows the abstract model of proposed system of sentiment and emotion analysis on tweets' text.     \subsection{Study Objective \& Research Questions} Our primary objective with this study is to understand how different cultures behave and react given a global crisis. The state of the questions addressed about the cultural differences as a techno-social system reveals potentialities in societal attitudinal, behavioral, and emotional predictions.   In the present investigation, to examine those behavioral and emotional factors that describe how societies react under different circumstances, the general objective is to analyze the potential of utilizing NLP-based sentiment and emotional analysis techniques in finding answers to the following research questions .      \subsection{Contribution}  The major contributions of this article are as following:   {}  The rest of the article is organized as follows. Section  presents the research design and study dimensions. Related work is presented in section . Data collection procedure and data preparation steps are described in section , whereas, sentiment and emotion analysis model is presented in section . Section  entails the results followed by discussion and analysis in section . Lastly, section  concludes the paper with potential future research directions.      	 	In this paper, we have proposed a location-aware graph to model the relationships between detected objects for video QA task. Compared with existing spatio-temporal attention mechanism, \algname is able to explicitly get rid of the influences from irrelevant background content. Moreover, our network is aware of the spatial and temporal location of events, which is important for predicting correct answer.  	Our method outperforms state-of-the-art techniques on three benchmark datasets.   	, including TGIF-QA, Toutube2Text-QA and MSVD-QA. 	    	
"," How different cultures react and respond given a crisis is predominant in a society's norms and political will to combat the situation. Often the decisions made are necessitated by events, social pressure, or the need of the hour, which may not represent the will of the nation. While some are pleased with it, others might show resentment. Coronavirus  brought a mix of similar emotions from the nations towards the decisions taken by their respective governments. Social media was bombarded with posts containing both positive and negative sentiments on the COVID-19, pandemic, lockdown, hashtags past couple of months. Despite geographically close, many neighboring countries reacted differently to one another. For instance, Denmark and Sweden, which share many similarities, stood poles apart on the decision taken by their respective governments. Yet, their nation's support was mostly unanimous, unlike the South Asian neighboring countries where people showed a lot of anxiety and resentment. This study tends to detect and analyze sentiment polarity and emotions demonstrated during the initial phase of the pandemic and the lockdown period employing natural language processing  and deep learning techniques on Twitter posts. Deep long short-term memory  models used for estimating the sentiment polarity and emotions from extracted tweets have been trained to achieve state-of-the-art accuracy on the sentiment140 dataset. The use of emoticons showed a unique and novel way of validating the supervised deep learning models on tweets extracted from Twitter.",13
" Knowledge transfer is a rapidly growing and advancing research area in AI. As humans, we live in a world that is   In practice, we have observed models become bigger as the performance grows.   % Out of commercial needs, we are committed to improve privacy  , security and user experience .  There are many reasons reducing the size of these models is important, such as real-time inference efficiency and deployment on mobile devices. Transferring knowledge from large, powerful models to compact models has been proven to be a practical solution. Clearly, knowledge transfer between agents or tasks is an important component towards AGI.  %%%%%%%%%%%%%%%%%%%%%%%%  %%%%%%%%%%%%%%%%%%%%%%  What is knowledge transfer? In general, it can be regarded as a learning process by which learners acquire new or modify existing knowledge by interacting with teachers. If we represent knowledge as a probabilistic distribution, e.g.,  \nonumber \end{align}  Thus, learning means to get  closer to , where  and  are distributions of learner and teacher.  It's natural to relate knowledge transfer to KL-divergence which measures how much information  is lost when approximating a distribution with another. Existing approaches can be categorized as minimizing KL-divergence in  or  order.   Learners with infinite capacity would end up behaving in the exact same way to teachers. In this case, the order doesn't matter. Unfortunately, this is not true. In practice, learners are typically restricted in a simple function family, e.g., Gaussian, or parameterized by neural networks with finite layers and hidden units. Meanwhile, teachers are not perfect.  is noisy especially in high-dimensional action space.  The question is which order performs better? Previous works  attempt to analyze their difference by restricting  and  to be Gaussian distributions. However, the learning process, i.e., how the learner interact with the teacher and acquires knowledge, is totally unclear. In this paper, we reinterpret KL-divergence minimization as knowledge transfer and provide an in-depth analysis on the way in which the learner acquires knowledge from the teacher, without applying any constraints on the distributions.   At a high level, we noticed that    encourages learners to be exposed to their own distributions and be reinforced by on-policy learning. Thus, we propose to minimize  in solving sequential decision making problems. To verify our hypothesis, we revisit Knowledge Distillation  which attempts to distill knowledge from teacher to learner by minimizing  on Neural Machine Translation  task. The goal of the task is to generate a sequence of tokens in the target language given a sentence in the source language. The generation procedure is: at position , given previous actions , try to produce a token which is expected to give maximum reward . Basically, NMT is to solve a sequential decision making problem with high-dimensional, discrete action space. Exposure bias is known to be an important issue due to lacking exploration.   We simply replace  with  and call our approach Knowledge Acquisition . We describe the learning process  as a dialog, shown in Fig.. Empirical results show +0.7-1.1 BLEU gains on WMT'17 De-En and IWSLT'15 Th-En tasks.  % related work     This paper aimed to find the correlation between sentiments and emotions of the people from within neighboring countries amidst coronavirus  outbreak from their tweets. Deep learning LSTM architecture utilizing pre-trained embedding models that achieved state-of-the-art accuracy on the Sentiment140 dataset and emotional tweet dataset are used for detecting both sentiment polarity and emotions from users' tweets on Twitter. Initial tweets right after the pandemic outbreak were extracted by tracking the trending hasthtags\# during February 2020. The study also utilized the publicly available Kaggle tweet dataset for March - April 2020. Tweets from six neighboring countries are analyzed, employing NLP-based sentiment analysis techniques. The paper also presents a unique way of validating the proposed model's performance via emoticons extracted from users' tweets. We further cross-checked the detected sentiment polarity and emotions via various published sources on the number of positive cases reported by respective health ministries and published statistics.     Our findings showed a high correlation between tweets' polarity originating from the USA and Canada, and Pakistan and India. Whereas, despite many cultural similarities, the tweets posted following the corona outbreak between two Nordic countries, i.e., Sweden and Norway, showed quite the opposite polarity trend. Although joy and fear dominated between the two countries, the positive polarity dropped below the average for Norway much earlier than the Swedes. This may be due to the lockdown imposed in Norway for a good month and a half before the Government decided to ease the restrictions, whereas, Swedish Government went for the herd immunity, which was equally supported by the Swedes. Nevertheless, the average number of positive tweets was higher than the average number of negative tweets for Norway. The same trend was observed for Pakistan and Canada, where the positive tweets were more than the negative ones. We further observed that the number of negative and positive tweets started dropping below the average sentiments in the first and second week of April for all six countries.   This study also suggests that NLP-based sentiment and emotion detection can not only help identify cross-cultural trends but is also plausible to link actual events to users' emotions expressed on social platforms with high certitude, and that despite socio-economic and cultural differences, there is a high correlation of sentiments expressed given a global crisis - such as in the case of coronavirus pandemic. Deep learning models on the other hand can further be enriched with semantically rich representations using ontology as presented in  for effectively grasping one's opinion from tweets. Moreover, advanced seq2seq type language models as word embedding can be explored as a future work.  Till to date , the pandemic is still rising in other parts of the world, including Brazil and Russia. It would be interesting to observe more extended patterns of tweets across more countries to detect and assert people's behavior dealing with such calamities. We hope and believe that this study will provide a new perspective to readers and the scientific community interested in exploring cultural similarities and differences from public opinions given a crisis, and that it could influence decision makers in transforming and developing efficient policies to better tackle the situation, safe-guarding people's interest and needs of the society.   {} 
"," Knowledge Transfer has been applied in solving a wide variety of problems. For example, knowledge can be transferred between tasks  or between agents . Without loss of generality, we relate knowledge transfer to KL-divergence minimization, i.e., matching the  distributions of learners and teachers. The equivalence gives us a new perspective in understanding variants of the KL-divergence by looking at how learners structure their interaction with teachers in order to acquire knowledge.  In this paper, we provide an in-depth analysis of KL-divergence minimization in \texttt{Forward} and \texttt{Backward} orders, which shows that learners are reinforced via on-policy learning in \texttt{Backward}. In contrast, learners are supervised in \texttt{Forward}. Moreover, our analysis is gradient-based, so it can be generalized to arbitrary tasks and help to decide which order to minimize given the property of the task. By replacing \texttt{Forward} with \texttt{Backward} in Knowledge Distillation, we observed +0.7-1.1 BLEU gains on the WMT'17 De-En and IWSLT'15 Th-En machine translation tasks.",14
"  Digital humanities is a transdisciplinary subject between information technologies and humanities, such as literary classics. For instance, Google makes a contribution to digital humanities by promoting the ``Google Books Library Project'' which includes millions of paper books scanned into electronic text . Digital text is easier for researchers to explore than printed books, since the development of information technology has provided numerous effective tools  . In the past decade, overwhelming data science techniques have advanced the research on digital humanities; thus, components can be extracted and analyzed from literature.  A review of previous research reveals that some areas in digital humanities remain unexplored. First, mainstream studies are limited to the humanities works on the background of the Western world . It is both interesting and constructive to investigate humanities works with oriental backgrounds. Second, only a few comparative studies on literature with different styles of the same story are conducted . Particularly, previous researches focused more on longitudinal studies, wherein researchers usually adopt a story series, such as Harry Potter Books 1閳7, as the object of study . A potential research interest about the same story that discovers varied features  or sentiments can arise from different literature, which may be driven by literary genres or authors閳 opinion, among others. Third, network study is essential for the social network of a story and any network that possesses a topological structure, which can help gain an insight into the story閳ユ獨 characters based on its grand narration .   To fill the gap, this paper introduces a social network and sentimental analysis work on two different texts of one of the most famous Chinese story, The Three Kingdoms. In particular, we leverage the state-of-the-art natural language processing -based model to extract the social networks in the narratives of two books. A series of descriptive statistical analysis on the extracted networks is conducted, and we discover the homogeneity and heterogeneity in terms of topological features in these networks. Additionally, we adopt the sentimental analysis to compare the evaluations on some of the main characters. The results reveal that the social network is more complicated in the narrative of the novel  than that of the historical text . Consequently, it can be concluded that the literariness of stories has a tight relationship with the complexity of the social networks they entail.  The main contribution of this paper is as follows:  The remainder of this paper is organized as follows. In Section , the backgrounds of text mining and social network analysis researches are presented. Section  elaborates on the network extraction approach. We perform a series of empirical studies in Section  to demonstrate the thesis of this work. Finally, this paper is concluded in Section  with a summary of potential future studies.     In this paper we took a close look at how knowledge transfer can be used to improve the capabilities of a neural network model for the sequence generation task  using another model which is known to be stronger . While we focused on improving a single learning model from a single  teacher model, in future work it is worth exploring a joint learning system where all agents are learners but with different roles, where they have to cooperate or compete to accomplish a task.  We explored the details of the learning process when optimizing KL-divergence in forward and backward orders. We found that \texttt{Backward} allows learners to acquire knowledge in a more efficient way, especially in solving sequential decision making problems. Our analysis is general and applicable to other tasks. We believe it would guide us to utilize KL-divergence effectively.  \nocite{langley00}                                                                                                                                                                        DELETE THIS PART. DO NOT PLACE CONTENT AFTER THE REFERENCES!                                                                                                                                                                    special case 
"," Digital humanities is an important subject because it enables developments in history, literature, and films. In this paper, we perform an empirical study of a Chinese historical text, Records of the Three Kingdoms , and a historical novel of the same story, Romance of the Three Kingdoms . We employ natural language processing techniques to extract characters and their relationships. Then, we characterize the social networks and sentiments of the main characters in the historical text and the historical novel. We find that the social network in Romance is more complex and dynamic than that of Records, and the influence of the main characters differs. These findings shed light on the different styles of storytelling in the two literary genres and how the historical novel complicates the social networks of characters to enrich the literariness of the story.",15
" As an unsupervised approach, topic modelling has enjoyed great success in automatic text analysis. In general, a topic model aims to discover a set of latent topics from a collection of documents, each of which describes an interpretable semantic concept. Topic models like Latent Dirichlet Allocation ~ and its hierarchical/Bayesian extensions, e.g., in~\citet{blei2010nested,paisley2015nested,gan2015learning,zhou2016augmentable} have achieved impressive performance for document analysis. Recently, the developments of Variational AutoEncoders  and Autoencoding Variational Inference ~ have facilitated the proposal of Neural Topic Models  such as in~\citet{miao2016neural,srivastava2017autoencoding,krishnan2018challenges,burkhardt2019decoupling}. Inspired by VAE, many NTMs use an encoder that takes the Bag-of-Words  representation of a document as input and approximates the posterior distribution of the latent topics. The posterior samples are further input into a decoder to reconstruct the BoW representation. Compared with conventional topic models, NTMs usually enjoy better flexibility and scalability, which are important for the applications on large-scale data.  Despite the promising performance and recent popularity, there are several shortcomings for existing NTMs, which could hinder their usefulness and further extensions. i) The training and inference processes of NTMs are typically complex due to the prior and posterior constructions of latent topics. To encourage topic sparsity and smoothness, Dirichlet~ or gamma~ distributions are usually used as  the prior and posterior of topics, but reparameterisation is inapplicable to them, thus, complex sampling schemes or approximations have to be used, which could limit the model flexibility. ii) A desideratum of a topic model is to generate better topical representations of documents with more coherent and diverse topics;  but for many existing NTMs, it is hard to achieve good document representation and coherent/diverse topics at the same time. This is because the objective of NTMs is to achieve lower reconstruction error, which usually means topics are less coherent and diverse, as observed and analysed in~.  iii) It is well-known that topic models degrade their performance severely on short documents such as tweets, news headlines and product reviews, as each individual document contains insufficient word co-occurrence information. This issue can be exacerbated for NTMs because of the use of the encoder and decoder networks, which are more vulnerable to data sparsity.  To address the above shortcomings for NTMs, we in this paper propose a neural topic model, which is built upon a novel Optimal Transport  framework derived from a new view of topic modelling. For a document, we consider its content to be encoded by two representations: the observed representation, , a distribution over all the words in the vocabulary and the latent representation, , a distribution over all the topics.  can be obtained by normalising a document's word count vector while  needs to be learned by a model. For a document collection, the vocabulary size  can be very large but one individual document usually consists of a tiny subset of the words. Therefore,  is a sparse and low-level representation of the semantic information of a document. As the number of topics is much smaller than the vocabulary size,  is the relatively dense and high-level representation of the same content. Therefore, the learning of a topic model can be viewed as the process of learning the distribution  to be as close to the distribution  as possible. Accordingly, it is crucial to investigate how to measure the distance between two distributions with different supports. As optimal transport is a powerful tool for measuring the distance travelled in transporting the mass in one distribution to match another given a specific cost function, and recent development on computational OT  has shown the promising feasibility to efficiently compute OT for large-scale problems, it is natural for us to develop a new NTM based on the minimisation of OT.  Specifically, our model leverages an encoder that outputs topic distribution  of a document by taking its word count vector as input like a standard NTMs, but we minimise the OT distance between  and , which are two discrete distributions on the support of words and topics, respectively. Notably, the cost function of the OT distance specifies the weights between topics and words, which we define as the distance in an embedding space, where we embed all the topics and words to represent their semantics. By leveraging the pretrained word embeddings, the cost function is then a function of topic embeddings, which will be learned jointly with the encoder. With the advanced properties of OT on modelling geometric structures on spaces of probability distributions, our model is able to achieve a better balance between obtaining good document representation and generating coherent/diverse topics. In addition, our model eases the burden of designing complex sampling schemes for the posterior of NTMs. More interestingly, our model is a natural way of incorporating pretrained word embeddings, which have been demonstrated to be able to alleviate the issue of insufficient word co-occurrence information in short texts~. With extensive experiments, our model can be shown to enjoy the state-of-the-art performance in terms of both topic quality and document representations for both regular and short texts.        In this work, we proposed a multitask learning-based approach to predict depressed users on Sina Weibo.  First, based on data collection and script filtering and manual labeling, we built and publish a large Weibo User depression detection dataset - WU3D. The total number of user samples reaches over 30,000 and each user has enriched information fields. This dataset will be quite sufficient to be used by subsequent researchers to complete further research.  Secondly, we summarized and manually extracted ten statistical features including text, social behavior, and picture-based features. The experimental results showed that all of them have varying degrees of distribution differences between normal users and depressed users, which can contribute positively to classification tasks. Our experimental results also proved that the feature engineering process of text information is the most vital part of depression detection on OSN.  Furthermore, we evaluated the performance of the pretrained model XLNet as the embedding model to solve downstream classification tasks. It showed that when the appropriate embedding length is selected, XLNet has excellent performance and efficiency in handling long text sequences.  Finally, we implemented a multitask learning DNN classifier, FusionNet, to simultaneously handle the word vector classification task and the statistical feature classification task. Benefit from the strategic advantages of multitask learning, FusionNet reduced the loss of feature information caused by transfer learning. Compared with the commonly used models in existing work, FusionNet has achieved a very significant performance improvement with an F1-Score of 0.9772 and showed the best classification robustness when the training samples are unbalanced. Thus, it has proven to be an ideal classification model when dealing with multiple classification tasks at the same time.  For future work, two directions will be further explored.  The size of the dataset will be further expanded. Larger datasets will be constructed for training and evaluating classifiers to achieve better generalization performance.  The characteristics and behavior patterns of depressed users will be further analyzed. We will propose more effective feature solutions for user-level depression detection on the OSN.       Bibliography 
"," Recently, Neural Topic Models  inspired by variational autoencoders have obtained increasingly research interest due to their promising results on text analysis. However, it is usually hard for existing NTMs to achieve good document representation and coherent/diverse topics at the same time. Moreover, they often degrade their performance severely on short documents. The requirement of reparameterisation could also comprise their training quality and model flexibility. To address these shortcomings, we present a new neural topic model via the theory of optimal transport . Specifically, we propose to learn the topic distribution of a document by directly minimising its OT distance to the document's word distributions. Importantly, the cost matrix of the OT distance models the weights between topics and words, which is constructed by the distances between topics and words in an embedding space. Our proposed model can be trained efficiently with a differentiable loss. Extensive experiments show that our framework significantly outperforms the state-of-the-art NTMs on discovering more coherent and diverse topics and deriving better document representations for both regular and short texts.",16
" Even before the advent of the COVID-19 pandemic, people across the world were turning to the internet to find answers to their medical concerns . Around 7\%  of Google閳ユ獨 daily searches were health related, equivalent to around 70,000 queries every minute . With the emergence of medical question-answering websites such as ADAM , WebMD , AskDocs and HealthTap , people now  have the opportunity to ask detailed questions and find answers, from experts, that satisfied their needs. COVID-19 has done nothing but accelerate this trend. Almost every government agency and healthcare organization has tried to meet the informational need of users by building online FAQs that try to address as many COVID-related topics as possible   %With the ubiquity of the Internet and the emergence of medical question-answering websites such as ADAM , WebMD , and HealthTap , people are increasingly searching online for answers to their medical questions. Pew Internet Project surveys consistently find that between 75-83\% of internet users look online for health information .  The examples above already illustrate two important problems of any medical Q\&A collection:  there is a very large number of possible questions that can be formulated in different ways, and  it is not easy for a user to browse through a large collection of pre-existing questions to find the one that most resembles their need. A scalable solution to overcome both of these issues is to build a system that can automatically match user formulated questions with semantically similar answered questions, and provide those as suggestions to the users. If no similar answered questions exist, we can mark them as priority for experts to respond. This approach more directly satisfies user needs allowing them to use their own words to formulate the question. It also provides an avenue for collecting unanswered questions that users want answered, which is extremely important in a rapidly changing situation such as the currrent COVID-19 pandemic.  %However, the number of people asking medical questions online far exceeds the number of qualified experts -- i.e doctors -- answering them. A scalable solution to overcome this imbalance is to build a system that can automatically match unanswered questions with semantically similar answered questions, and provide those as suggestions to the users. When no similar answered questions exist, we can mark them as priority for doctors to respond. This approach uses doctor time more efficiently, reducing the number of unanswered questions and lowering the cost of providing online care.   %Many of the individuals seeking medical advice online are otherwise reluctant to seek medical help due to cost, convenience, or embarrassment. For these patients, an accurate online system is critical because it may be the only medical advice they receive. Of course, some medical problems require in-person care, and an online system must indicate that. Other patients use the internet in addition to in-person care either to determine when an appointment is needed or to follow up after visits when they have lingering questions. For this second group, if the answers they see online do not match those given to them by their doctors, they are less likely to follow the advice of their doctors , which can have serious consequences.  The problem of matching general unanswered questions with semantically similar answered questions has been well-studied in the context of online user forums , community QA  and question answer archives .  Typical approaches either assume a large amount of training data on which, either statistics can be computed or models can be learned. However, these approaches fall short when applied to the problem of medical question similarity. First, medical questions imbibe a large amount of medical information that a single word can completely change the meaning of the question. As an example, I閳ユ獡 pregnant and I believe I閳ユ獫e been infected with coronavirus. What should I know about going to the hospital?  and Should I visit the doctor if I am expecting and think I might have COVID-19? are similar questions with low overlap, but Is it safe to take Vitamin D3 supplements to build immunity against Coronavirus? and Is it safe to take Hydroxychloroquine to build immunity against Coronavirus? are critically different and only a couple of words apart. Second, there is no publicly available medical question-question similarity data at the scale where these differences can be effectively encoded in order to learn a reliable similarity function. In fact, we hypothesize that constructing such large datasets that cover the large functional space of nuanced variations in medical domain can be quite hard, and is not a scalable proposition.   %Coming up with an accurate algorithm for finding similar medical questions, however, is difficult. Simple heuristics such as word-overlap are ineffective because Can a menstrual blood clot travel to your heart or lungs like other blood clots can? and Can clots from my period cause a stroke or embolism? are similar questions with low overlap, but Is candida retested after treatment and Is Chlamydia retested after treatment? are critically different and only one word apart. Machine learning is a good candidate for such complex tasks, but requires labeled training data. As no widely available data for this particular task exists, we generate and release our own dataset of medical question pairs such as the ones shown in Table.   % \TODO{Can we at least add a COVID-19 related example?}  \end{center} \end{table}  % \footnote{We acknowledge that this fails at edge cases. For instance, if the answers to two questions are both ""Yes, that is correct"", that does not mean the questions are similar.}  In this paper, we tackle the general problem of medical question-question similarity, assuming only a small amount of labeled data of similarity pairs. We also apply the general solution to a specific COVID-19 scenario  where many different questions from different sources are integrated into a user-friendly experience. Our proposed solution stems from two key insights: First, whether or not two questions are semantically similar is akin to asking whether or not the answer to one also answers the other. This means that the answers in the answered questions contain wealth of medical knowledge that can be distilled into the model. The second insight is that we can infuse this medical knowledge from the answers as a pretraining task within a language model, so that we can capture relatedness between words/concepts in the language. Recent success of pretrained bi-directional transformer networks for natural language processing in non-medical fields supports this insight . % In the examples above, the answer to the question Can clots from my period cause a stroke or embolism? will talk about, for instance, `menstrual blood'  and `bleeding' that establishes the relationships between `period' and `menstrual blood'. Similar connection can be established between heart, lungs and embolism. In contrast, the answers around candida treatment is likely to discuss about yeast while that around Chlamydia on bacteria. %The second insight is that we can infuse this medical knowledge from the answers as a pre-training task within a language model, so that we can capture relatedness between words/concepts in the language. Recent success of pre-trained bi-directional transformer networks for natural language processing in non-medical fields supports this insight .     % \TODO{Can we find a COVID-19 related example?}  %Given the recent success of pre-trained bi-directional transformer networks for natural language processing  outside the medical field , most research efforts in medical NLP have tried to apply general language models to medical tasks . However, these models are not trained on medical information, and make errors that reflect this.   Our approach stems from augmenting a general language model such as BERT, with medical knowledge by process of double fine-tuning that first distills medical knowledge using a large corpus of relevant in-domain task of medical question-answer pairs. Subsequently, it fine-tunes on the available small corpus of question-question similarity dataset. Our models pretrained on medical question-answer pairs outperform models pretrained on out-of-domain question similarity with high statistical significance. In particular, while other pretraining tasks yield an accuracy below 78.7\% on this task, our model achieves an accuracy of 82.6\% with the same number of training examples, an accuracy of 80.0\% with a much smaller training set, and an accuracy of 84.5\% when the full corpus of medical question-answer data is used. % Furthermore, the results show promise of generalizing to other domains as well. We present early results on extensibilty of our approach to another expert domain: question-question similarity in the context of community driven question and answer website for the Ubuntu operating system.  %The task of question-answer matching was specifically chosen because it is closely related to that of question similarity; one component of whether or not two questions are semantically similar is whether or not the answer to one also answers the other. We show that the performance gains achieved by this particular task are not realized by other in-domain tasks, such as medical question-categorization and medical answer completion.   %However, labeled training data is still one of the largest barriers to supervised learning, particularly in the medical field where it is expensive to get doctor time for hand-labeling data. }   The main contributions of this paper are:   The rest of the paper is structured as follows:  \S describes the methodology used in creating a dataset that will be made publicly available. \S provides the overview of the approach. \S describes how we used the model to build a service that matches user's COVID-19-related questions to FAQs published online. \S describes experimental details and the key results, % while \S gives a peek into application of the methodology for other domains. \S discusses related work and we end with a discussion on future work.  In this paper, we presented a novel neural topic model based on optimal transport, where a document is endowed with two representations: the word distribution, , and the topic distribution, . An OT distance is leveraged to compare the semantic distance between the two distributions, whose cost function is defined according to the cosine similarities between topics and words in the embedding space.  is obtained from an encoder that takes  as input and is trained by minimising the OT distance between  and . With pretrained word embeddings, topic embeddings are learned by the same minimisation of the OT distance in terms of the cost function. Our model has shown appealing properties that are able to overcome several shortcomings of existing neural topic models. extensive experiments have been conducted, showing that our model achieves state-of-the-art performance on both discovering quality topics and deriving useful document representations  for both regular and short texts. Thanks to the flexibility and simplicity of the framework, future work will be on developing extensions and variants that discover more complex topic patterns e.g, like Correlated Topic Models~ and Dynamic Topic Models~.        \numberwithin{equation}{section} \counterwithin{figure}{section} \counterwithin{table}{section} 
"," People increasingly search online for answers to their medical questions but the rate at which medical questions are asked online significantly exceeds the capacity of qualified people to answer them. This leaves many questions unanswered or inadequately answered. Many of these questions are not unique, and reliable identification of similar questions would enable more efficient and effective question answering schema. COVID-19 has only exacerbated this problem. Almost every government agency and healthcare organization has tried to meet the informational need of users by building online FAQs, but there is no way for people to ask their question and know if it is answered on one of these pages. While many research efforts have focused on the problem of general question similarity, these approaches do not generalize well to domains that require expert knowledge to determine semantic similarity, such as the medical domain. In this paper, we show how a double fine-tuning approach of pretraining a neural network on medical question-answer pairs followed by fine-tuning on medical question-question pairs is a particularly useful intermediate task for the ultimate goal of determining medical question similarity. While other pretraining tasks yield an accuracy below 78.7\% on this task, our model achieves an accuracy of 82.6\% with the same number of training examples, an accuracy of 80.0\% with a much smaller training set, and an accuracy of 84.5\% when the full corpus of medical question-answer data is used. We also describe a currently live system that uses the trained model to match user questions to COVID-related FAQs. %We also present early experimental evidence suggesting the applicability of our proposed approach on another completely different domain: question-question similarity in the context of community driven question and answer website for the Ubuntu operating system.",17
"  % Alternative first paragraph: %The goal of acoustic scene classification  is to identify the class of a given audio recording, e.g., park, office, library. The ASC task can be  very challenging because  sounds within certain scenes can have similar characteristics, and  sound events can overlap one another. The growing interest on solving the ASC problem, which is confirmed by the high participation of researchers from both academia and industry to the recent IEEE Detection and Classification of Acoustic Scenes and Events  challenge , is justified by the impact that a robust ASC system can have on several real-world applications. For instance, an hearing aid devices can modify its behaviour accordingly to different acoustic envijironments.   % If the above paragraph becomes the first paragraph, this could be reduced, and we can simply say that deep learning has greatly improved the performance of ASC. Although many different solutions have been proposed over the years, and the interested reader is referred to the official DCASE website, the key elements of a successful ASC system are  CNN,  data-augmentation,  attention,  mix-up. % Then you need to make clear the device mismatch problem has received less attention, and only a few proposal have been put forth, for example . You should clarify why this is a key problem and right away say how you want to address it Knowledge distillation. The third paragraph  look good but needs to be polished and perhaps trimmed a bit. Instead, our contribution must be make stronger. What is new in this work and why people should pay attention to it.   %The goal of acoustic scene classification  is to identify the class of a given audio recording, e.g., park, airport, metro station . The ASC task can be  very challenging because  sounds within certain scenes have similar characteristics, and  sound events can overlap one another. The growing interest on solving the ASC problem, as indicated by the high participation of researchers from both academia and industry to the recent IEEE Detection and Classification of Acoustic Scenes and Events  challenges , is justified by the impact that a robust ASC system to real-world applications. For instance, an hearing aid devices could modify its behaviour accordingly to different acoustic environments.  In recent years, we have witnessed a great progress in the acoustic scene classification  task, as demonstrated by the high participation in the IEEE Detection and Classification of Acoustic Scenes and Events  challenges . Top ASC systems use deep neural networks , and the main ingredient of their success is the application of deep convolutional neural networks  . Further boost in ASC performance is obtained with the introduction of advanced deep learning techniques, such as attention mechanism , mix-up , Generative Adversial Network  and Variational Auto Encoder  based data augmentation  , and deep feature learning . Nevertheless, those ASC systems yet do not work well when processing audios from mismatched domain, e.g., audios recorded with different devices .  Device mismatch is an inevitable problem in a real production, and it is therefore an important aspect to handle when deploying an ASC system. Indeed, a new sub-task, namely Task1b, has been added to DCASE 2018  to foster research in that  direction. The goal is to design a system that can attain a good performance on 10-second audios segments collected with target devices, which are either not represented at a development phase, or represented during the ASC system deployment with a scarce amount of training material compared to that available for the source device. However, Task1b attracted only a minor interest among DCASE 2018 and 2019 participants, and even fewer teams were directly concerned with the device mismatch issue.  %There exist a few approaches proposed to tackle the domain invariant problem in ASC. For example, multi-instance learning , and low-level or mid-level feature learning , which transfer knowledge across domains and thereby tackle the robustness issue in a  broader sense. In the literature, there exist a few approaches that tackle the domain invariant problem in ASC. For example, multi-instance learning , and low-level or mid-level feature learning , which however address the robustness issue in a broader sense.  Less approaches have instead been proposed to directly combat the ASC device mismatch issue, which is actually the focus of the present work. In particular, spectrum correction  and channel conversion  build a front-end module to convert speech features from the source domain to target domain before feeding them to the back-end classifier. Besides front-end features, mid-level feature based transfer systems, which uses bottleneck features  or hidden layer representations  are adopted to transfer knowledge from source to target domain. Adversarial training methods in  leverage an extra domain discriminator to solve the device mismatch problem although the key focus is on lack of labeled target data. %Although all of those mentioned techniques are beneficial to ASC robustness issue, there is yet a clear gap between source and target device classification results. %In this work, the device mismatch problem is investigated within the  Teacher-student  learning, also named as knowledge distillation , has recently been shown to be effective in ASC and other domain adaptation speech tasks, e.g., . The key idea is to minimizes the distance measurement between teacher and student model output distributions, i.e., the information is transferred at a soft-label level. %, namely class posterior probabilities, embedded with structure relationships among output classes, are usually used to transfer knowledge from the teacher model to student model. %In recent years, researchers further propose relational learning . It directly models the relationships between sample pairs of the teacher and student model. In ,  relational knowledge distillation  is demonstrated to improve the knowledge distillation process. RKD takes into account the relations of outputs rather than individual outputs themselves. %Independently of whether relationships among outputs is taken into account, TS methods require to be effective that soft labels are accurately generated; otherwise, the information encoded in those labels is meaningless. %Among all the TS learning methods, There is a necessary condition to get good effects, the soft label must be accurate enough, otherwise the information encoded in soft labels dose not make any senses. %As a consequence, the Unfortunately, conventional TS learning can be applied with success if:   source and target data is from the same or similar domain , or  source and target data come in pair although belong to different domains . Neural label embedding , recently proposed in , is an ingenues solution to distill knowledge across domains when neither of the aforementioned two requirements could be met. %NLE are embedding at a label level and encode the structural relationships among each pair of output classes in deep neural models. Structural relationships in turn  represent the measurements of similarity or dissimilarity among pairs of objects as distances between points in low-dimensional space. Label embedding can be viewed as the centroid of soft labels from the same class. NLE can be viewed as the centroid of soft labels from the same class. As to extension of soft labels, it encodes the knowledge distilled from the source domain and teacher model, which can then be transferred to the target domain. %%More information on how to build NLE is given in Section . In , NLE was applied to accent and children's adaptation for  automatic speech recognition.  %In this work, we extend the NLE design started in and deploy an NLE teacher-student adaptation approach to combat the ASC robustness problem in the presence of source and target device mismatch.  In this study, we extend the NLE adaptation scheme  by taking into account relationships among different acoustic scenes during adaptation. We achieve this goal by proposing a relational teacher student learning  approach based on NLE for ASC device mismatching problem. First, NLE is learned from a relatively large-size source data set, i.e., collected with the source devices. %The source device data encodes the structural relationships among different acoustic scenes. Next, ASC system is adapted to the target device leveraging upon target domain data only, i.e., teacher-student learning with unpaired data, and the set of NLE, one each per acoustic scene class. The proposed solution is assessed against the DCASE 2018 Task1b data. Experimental results confirm our intuitions and demonstrate that our adaptation technique generates a significant classification improvement on target domain data. Indeed, NLE-based TS adaptation outperforms both  multi-device training strategies, and  conventional TS adaptation schemes. Furthermore, an additional boost is obtained when TS adaptation is carried out leveraging structural information.    %In this work, to solve the device mismatching problem of the ASC systemss, we focus on the structural relationship among scene classes. We propose a novel NLE with relational teacher student learning  approach to solve the domain mismatch problem in ASC. At first, the label embedding are learned from the relatively large-size source domain data, which encode the structural relationship information of classes. Then the system on target domain data is trained with label embedding with criterion including relationship loss. Our proposed approached is evaluated on DCASE2018 task1b development data. The experimental results verify that our methods can obtain significant improvement on target domain data. And the visualization verify our arguments about the structural relationships.  %The rest of this work is organized as follows:  Section describes NLE, including generation and use. The relational TS learning framework is described in Section. Next, Section shows the experimental results and analysis. Finally, Section concludes this work.      \TODO{Expand here slightly to align with cfp} \\  In this work, we release MQP, a dataset of medical question pairs generated and labeled by doctors that is based upon real, patient-asked questions. We also show that the double finetuning approach of pretraining on in-domain question-answer matching  is particularly useful for the difficult task of identifying semantically similar questions. Furthermore, we show that the choice of this in-domain task matters: choosing a task that provides ample signal to capture the domain knowledge is needed to be able to perform the final task well.  Although the QA model outperforms the out-of-domain same-task QQP model, there are a few examples where the QQP model seems to have learned information that is missing from the QA  model. In the future, we can further explore whether these two models learned independently useful information from their pretraining tasks. If they did, then we hope to be able to combine these features into one model with multi-task learning. An additional benefit of the error analysis is that we have a better understanding of the types of mistakes that even our best model is making. It is therefore now easier to use weak supervision and augmentation rules or even active learning to supplement our datasets to increase the number of training examples in those difficult regions of the data. Both of these improvements could further improve our performance on this task.    Lastly, we would note that such a system deployed live also needs to incorporate safety considerations with respect to identifying questions where the user's life is threatened  or might need immediate attention of a doctor .\documentclass[sigconf]{acmart}   \documentclass[sigconf, anonymous, review]{acmart} \pdfoutput=1        \BibTeX command to typeset BibTeX logo in the docs \AtBeginDocument{    \providecommand\BibTeX{{      \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}     Rights management information.  This information is sent to you    when you complete the rights form. These commands have SAMPLE    values in them; it is your responsibility as an author to replace    the commands and values with those provided to you when you    complete the rights form.  \setcopyright{acmcopyright} \copyrightyear{2020} \acmYear{2020} \setcopyright{acmlicensed}\acmConference[KDD '20]{Proceedings of the 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}{August 23--27, 2020}{Virtual Event, CA, USA} \acmBooktitle{Proceedings of the 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining , August 23--27, 2020, Virtual Event, CA, USA} \acmPrice{15.00} \acmDOI{10.1145/3394486.3412861} \acmISBN{978-1-4503-7998-4/20/08}  \acmDOI{10.1145/1122445.1122456}  \settopmatter{printacmref=true}     These commands are for a PROCEEDINGS abstract or paper.   \acmConference[Woodstock '18]{Woodstock '18: ACM Symposium on Neural     Gaze Detection}{June 03--05, 2018}{Woodstock, NY}   \acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,     June 03--05, 2018, Woodstock, NY}   \acmPrice{15.00}   \acmISBN{978-1-4503-XXXX-X/18/06}   \usepackage{times} \usepackage{float} \usepackage{enumitem}   \setlength{\parskip}{0cm}   \setlength{\parindent}{1em} \setlength{\abovecaptionskip}{5pt} \setlength{\belowcaptionskip}{-5pt} \usepackage[compact]{titlesec} \usepackage[para]{footmisc}  \titlespacing{
"," %The device domain mismatch issue is an important problem of acoustic scene classification  for real-world applications. To leverage this problem, we focus on the knowledge transfer of the inner structural relationships between each classes. A label embedding with relational teacher student learning approach is proposed. Embedded labels are learned from the source domain data, which encodes the structural relationships. Then a relational teacher student learning framework is used to transfer knowledge. Our proposed approach is evaluated on DCASE2018 task1b data set. And the experimental and visualized results successfully verify our augment and proposed method, which significantly improve the classification accuracy on target device data, with the knowledge transferred from the source device data.  %  Alternative 1: %In this work, we use a model adaptation approach based on  neural label embedding  and  knowledge distillation to combat the accuracy drop in acoustic scene classification with deep neural networks caused by a mismatch between  development  and production  audio recording devices. The proposed adaptation approach works with unpaired source-target data and leverages upon NLE designed to take into account the relationships among acoustic scene classes. The NLE thereby not only condenses a representation of the DNN output distribution given all audio recordings aligned with the same output class but also captures the inherent relationships among acoustic scene classes. Device adaptation is carried out using relational teacher-student learning  solely based on target data, target labels, source DNN, and NLE. The latter serve as soft targets for DNN adaptation.  The proposed approach is assessed against the DCASE 2018 task1b dataset. Experimental evidence confirm the effectiveness our our approach, which compares favourably to conventional device adaptation, and traditional teacher-student based adaptation. Moreover, we observe that NLE based on structural information lead to superior ASC  results than NLE obtained with symmetric Kullback-Leibler divergence ,which do not take into account the relationships among acoustic scene classes.  % Alternative 2 In this paper, we propose a domain adaptation framework to address the device mismatch issue in acoustic scene classification leveraging upon neural label embedding  and relational teacher student learning .  Taking into account the structural relationships between acoustic scene classes, our proposed framework captures such relationships which are intrinsically device-independent. In the training stage, transferable knowledge is condensed in NLE from the source domain. Next in the adaptation stage, a novel RTSL strategy is adopted to learn adapted target models without using paired source-target data often required in conventional teacher student learning. The proposed framework is evaluated on the DCASE 2018 Task1b data set. Experimental results based on AlexNet-L deep classification models confirm the effectiveness of our proposed approach for mismatch situations. %when training with Device A data and testing with data recorded with Devices B and C.  NLE-alone adaptation compares favourably with the conventional device adaptation and teacher student based adaptation techniques. NLE with RTSL further improves the classification accuracy.",18
" %Motivate a bit from ASR side %Introduce a bit on punctuation problem.   The output text generated from automatic speech recognition  systems is typically devoid of punctuation and sentence formatting. Lack of sentence segmentation and punctuation makes it difficult to comprehend the ASR output. For example, consider the two sentences: ``Let's eat Grandma'' vs. ``Let's eat, Grandma!''. Punctuation restoration not only helps understand the context of the text but also greatly improves the readability. Punctuated text often helps in boosting the performance of several downstream natural language understanding  tasks.%  There is a plethora of work done in punctuation prediction over the past few decades. While some early methods of punctuation prediction used finite state or hidden markov models , some other techniques have investigated probabilistic models like language modeling , conditional random fields   and maximum entropy models . As neural networks gained popularity, several approaches have been proposed based on sequence labeling and neural machine translation . These models widely used convolutional neural networks  and LSTM based architectures . More recently, attention  and transformer  based architectures which have been successfully applied to a wide variety of tasks, have shown to perform well for punctuation prediction.  Although it is a well explored problem in the literature, most of these improvements do not directly translate to all domains. In particular, punctuation prediction for conversational speech is not very well explored . Also, a number of approaches have been proposed exploiting the use of acoustic features in addition to lexical features for punctuation task, but they are rather limited and do not clearly address the gap in performance with ASR outputs. In this paper, we focus on multimodal semi-supervised deep learning approach for punctuation prediction in conversational speech by leveraging pretrained lexical and acoustic encoders.  %two set of approaches emerged. One approach tags every word with no punctuation or a following punctuation mark treating it as sequence labeling problem . The second approach uses machine  translation based sequence to sequence models to generate punctuated text from unpunctuated text .  \subsection{Relation to prior multimodal work}   While several methodologies used either text or acoustic only information  for predicting punctuation, many studies show that combining both the features yields the best performance . Acoustic features widely used in the literature include prosodic information such as pause duration, phone duration, and pitch related values like fundamental frequency, and energy.  shows that using acoustic information lead to increased recognition of full stops. In , a hierarchical encoder is used to encode per frame acoustic features to word level features and the results show that incorporating acoustic features significantly outperform purely lexical systems. However, when trained on a very large independent text corpus, the lexical system outperformed the multimodal system that was trained on parallel audio/text corpora. To mitigate this, the work in  introduced speech2vec embeddings but they do not vary with respect to the acoustic context in reference speech.   In general, we identify two potential shortcomings with aforementioned multimodal systems. First, the training is still suboptimal due to lack of large-scale parallel audio/text corpora. Secondly, the models trained on reference text transcripts do not perform that well on ASR outputs, although incorporating acoustic features reduced the gap to some extent.   \subsection{Novelty of this work}  %And tell how our approach is different from other acoustic based approaches.  %We therefore focus on investigating the benefits of exploiting semi-supervised learning approach.   In this work, we introduce a novel framework for multimodal fusion of lexical and acoustic embeddings for punctuation prediction in conversational speech. Specifically, we investigate the benefits of using lexical and acoustic encoders that are pretrained on large amounts of unpaired text and audio data using unsupervised learning.  The key idea is to learn contextual representations through unsupervised training where substantial amounts of unlabeled data is available and then improve the performance on a downstream task like punctuation, for which the amount of data is limited, by leveraging learned representations. For multimodal fusion, we explore attention mechanism to automatically learn the alignment of word level lexical features and frame level acoustic features in the absence of explicit forced alignments.  We also show the adaptation of our proposed multimodal architecture for streaming usecase by limiting the future context. We further study the effect of pretrained encoders with respect to varying data sizes and their performance when trained on very small amounts of data. Finally, we exploit the N-best lists from ASR to perform data augmentation and reduce the gap in performance when tested on ASR outputs.   % We will investigate following research questions in the paper:   %  %The rest of the paper is organized as follows: Section  introduces semi-supervised learning approach with pre-trained lexical and acoustic encoder for punctuation prediction. Section  describes the procedure for fusion of acoustic features with lexical encoder. We discuss our experimental setup in Section  and the results are presented in Section . Finally, in Section , we summarize our conclusions.      In this paper, a relational teacher student learning framework with neural label embedding is proposed to resolve the device mismatch issue in acoustic scene classification. We explore the similarities or dissimilarities between pairs of classes. This structural relationship is learned and encoded into NLE and then transferred from the source device domain to the target device domain via the relational teacher-student approach. Our proposed framework is assessed against the DCASE 2018 Task1b development data set, and experimental results demonstrate not only the viability of our approach, but also that a significant improvement of the classification accuracy on the target device data can be obtained. Furthermore, a visual analysis is provided to shed light on the key characteristics of the proposed neural label embedding concept. \clearpage 
","  In this work, we explore a multimodal semi-supervised learning approach for punctuation prediction by learning representations from large amounts of unlabelled audio and text data. Conventional approaches in speech processing typically use forced alignment to encoder per frame acoustic features to word level features and perform multimodal fusion of the resulting acoustic and lexical representations. As an alternative, we explore attention based multimodal fusion and compare its performance with forced alignment based fusion. Experiments conducted on the Fisher corpus show that our proposed approach achieves $\sim$6-9\% and $\sim$3-4\% absolute improvement  over the baseline BLSTM model on reference transcripts and ASR outputs respectively. We further improve the model robustness to ASR errors by performing data augmentation with N-best lists which achieves up to an additional $\sim$2-6\% improvement on ASR outputs. We also demonstrate the effectiveness of semi-supervised learning approach by performing ablation study on various sizes of the corpus. When trained on 1 hour of speech and text data, the proposed model achieved $\sim$9-18\% absolute improvement over baseline model.   %We also incorporate a pretrained lexical BERT encoder to further enhance the hidden representation of acoustic embedding when performed fusion with lexical embedding.",19
"  Contemporary end-to-end speech synthesis systems achieve great results and produce natural-sounding human-like speech  even in real time . They make possible an efficient training that does not put high demands on quality, amount, and preprocessing of training data. Based on these advances, researchers aim at, for example, expressiveness , controllability , or few-shot voice cloning . When extending these models to support multiple languages, one may encounter obstacles such as different input representations or pronunciations, and imbalanced amounts of training data per language.  In this work, we examine cross-lingual knowledge-sharing aspects of multilingual text-to-speech . We experiment with more languages simultaneously than most previous TTS work  %\TN{nen閾 to moc siln鑼 tvrzen閾?}\OD{to 閳ユ笒nown to us閳 to trochu omezuje :-)... ale m鏆栧暘em napsat 閳 works閳 jestli chce鎷  known to us. We can  summarize our contributions as follows:  We propose a scalable grapheme-based model that utilizes the idea of contextual parameter generator network  and we compare it with baseline models using different levels of parameter sharing.   We introduce a new small dataset based on Common Voice  that includes data in five languages from 84 speakers.  We evaluate effectiveness of the compared models on ten languages with three different scripts and we show their code-switching abilities on five languages. For the purposes of the evaluation, we created a new test set of 400 bilingual code-switching sentences. % \OD{TODO v閾哻 se chlubit} \TN{Je鎷鑷 v閾哻?} % \TNdel{\OD{todo nov濯 鑶穒鎷鑷巒濯 dataset}} % \TNdel{\OD{nov濯 code-switch test set}}    Our source code, hyper-parameters, training and evaluation data, samples, pre-trained models, and interactive demos are freely available on GitHub.\footnote{\url{https://github.com/Tomiinek/Multilingual\_Text\_to\_Speech} }      We introduced a novel multimodal semi-supervised learning framework which leverages large amounts of unlabelled audio and text data for punctuation prediction. We proposed an alternative attention based multimodal fusion mechanism which is effective, in the absence of forced alignment word durations. Through our data sizes ablation study, we showed how our proposed model is superior in performance to lexical only models on reference transcripts. In order to address the performance gaps on ASR outputs, we presented a robust model that is less affected by ASR errors by performing data augmentation with N-best lists.       
","   We introduce an approach to multilingual speech synthesis which uses the meta-learning concept of contextual parameter generation and produces natural-sounding multilingual speech using more languages and less training data than previous approaches. Our model is based on Tacotron~2 with a fully convolutional input text encoder whose weights are predicted by a separate parameter generator network. To boost voice cloning, the model uses an adversarial speaker classifier with a gradient reversal layer that removes speaker-specific information from the encoder.      We arranged two experiments to compare our model with baselines using various levels of cross-lingual parameter sharing, in order to evaluate:  stability and performance when training on low amounts of data,  pronunciation accuracy and voice quality of code-switching synthesis. For training, we used the CSS10 dataset and our new small dataset based on Common Voice recordings in five languages. Our model is shown to effectively share information across languages and according to a subjective evaluation test, it produces more natural and accurate code-switching speech than the baselines.      %The only drawback of this article is its unappealing abstract. It is probably because there includes no explicit description of the research objectives or the challenges that were dealt with in this study.  The reviewer thus thinks that improving the abstract will make this paper perfect.            %\OD{TODO p閼诡摣formulovat tak, 閸熺尃 se soust閼诡摣d闁惧攲e na n鐠嬧晜瀚 model, p閼诡摨dat info o datasetu}   %This work explores cross-lingual knowledge sharing in the context of speech synthesis. We compare three models based on Tacotron that utilize various levels of parameter sharing. Two of them follow recent multilingual text-to-speech systems. The first makes use of a fully-shared encoder and an adversarial classifier that ought to remove speaker-dependent information from the encoder. The other uses language-specific encoders. We introduce a new approach that combines the best of both previous methods. It enables effective parameter sharing using a meta-learning technique, preserves encoder闁炽儲鐛 flexibility, and actively removes speaker-specific information in the encoder.      %We compare the three models on two tasks. The first aims at joint multilingual training on ten languages. The second concerns code-switching or voice cloning. We show that our model effectively shares information across languages, and according to a subjective evaluation test, it produces more natural and accurate code-switching speech.",20
"   Peking Opera, also known as Beijing Opera or Jingju, is Chinese traditional performing art which combines music, vocal performance, mime, dance and acrobatics. Singing in Peking Opera has various styles, each widely different depending on different role type and music styles. Strong personal styles also make the actual singing can be different from the given music notes. Like a dialect to Mandarin, it even has its unique way of pronunciation. Moreover, melody in singing often consist of arias with variation of complex transitory and vibratos, which makes the singing very expressive and difficult to learn. Another difference from normal singing is the note length has a great variance, sometime very long note can appear . All above factors makes it very challenging to modelling and generating Peking Opera singing comparing to normal singing.   Although there are few works focusing on the synthesis of Peking Opera, or more broadly, opera, the synthesis of singing voice has been researched since 1962 when Kelly and Lochbaum used an acoustic tube model to synthesis singing voice with success. Recently, several works use deep neural networks to synthesis singing voice which, known as parametric systems, process fundamental frequency  and harmonics features  separately. As a typical case among such systems, Neural Parametric Singing Synthesizer  using a phoneme timing model, a pitch model and a timbre model each consist a set of neural networks to generate acoustic parameters of the singing. In NPSS, a Fitting Heuristic method is introduced to eliminate the mismatch between music note duration and the predicted phoneme duration. However, Fitting Heuristic method is totally rule based and it requires to locate the principal vowel before adjusting phoneme duration. This maybe acceptable in most English or Japanese singing cases, but can cause huge duration error when synthesizing Peking Opera. Different from normal speech or singing, in Peking Opera, one syllable can last very long time and contains a long sequence of phonemes, e.g. ``l-j-E-a-a-N"". More importantly, one can't simply tell which phoneme amongst all these phonemes is the principle phone. There could be multiple equally important phonemes in Peking Opera singing.  To better synthesize the expressive Peking Opera, this paper proposes a Peking Opera singing synthesis system based on Duration Informed Attention Network . The main contribution in this study lies in the two following points: 1) To tackle with rhythm mismatch between music note duration and the predicted phoneme duration, contextual based mixture density networks  followed by a Lagrange Multiplier optimization is proposed and implemented for duration modelling. This method is completely data-driven, and more importantly, skips the step of locating the principle phoneme from the conventional Fitting Heuristic method. 2) To deal with the melody mismatch between original music score and the actual singing, and also to better model the expressive variations and vibratos in Peking Opera, a pseudo music score is generated from the real singing and fed as input during DurIAN model training. Experimental Results show proposed duration modeling and prediction method outperforms the Fitting Heuristic method by a large margin. And the generated pitch contours also demonstrate our system's ability to synthesize the singing variations and vibratos in Peking Opera.  The following sections of this paper are organized as follows. Firstly, the proposed model architecture is introduced. Next, proposed Lagrange Multiplier-based duration prediction and pseudo score generation are introduced in Section 2. In section 3 experiments are conducted based on a unique Peking Opera database. Finally, a quick discussion and conclusion is given in Section 4.         \TN{Prepsat todlecto vsecko}  We introduced a grapheme-based TTS model that uses a meta-learning approach. We compared it with two models on two tasks . It was shown to scale and work effectively even in data-stress situations. It enables cross-lingual code-switching, basic voice cloning, and limited pronunciation control in five languages, as demonstrated on the companion repository. We presented a new grapheme-based model that uses meta-learning for multilingual TTS. We showed that it significantly outperforms multiple strong baselines on two tasks: data-stress training and code-switching, where our model was favored in both voice fluency as well as pronunciation accuracy. Our code is available on GitHub.\textsuperscript{} For future work, we consider changes to our model's attention module to further improve accuracy.  
","  Peking Opera has been the most dominant form of Chinese performing art since around 200 years ago. A Peking Opera singer usually exhibits a very strong personal style via introducing improvisation and expressiveness on stage which leads the actual rhythm and pitch contour to deviate significantly from the original music score. This inconsistency poses a great challenge in Peking Opera singing voice synthesis from a music score. In this work, we propose to deal with this issue and synthesize expressive Peking Opera singing from the music score based on the Duration Informed Attention Network  framework. To tackle the rhythm mismatch, Lagrange multiplier is used to find the optimal output phoneme duration sequence with the constraint of the given note duration from music score. As for the pitch contour mismatch, instead of directly inferring from music score, we adopt a pseudo music score generated from the real singing and feed it as input during training. The experiments demonstrate that with the proposed system we can synthesize Peking Opera singing voice with high-quality timbre, pitch and expressiveness.",21
" Many machine learning datasets have a label imbalance or dataset bias problem. In many cases, either data is harder to collect for certain classes or the data collection phase is biased itself such that bias is introduced to the collected dataset. Typical training algorithms, optimized in order to minimize error, tend to do so by exacerbating bias, e.g., by providing higher recall and precision to the majority class than to minority classes. Therefore, the label imbalance problem raises the concern about fairness of machine learning systems in general. Spoken language understanding  problems often suffer from label imbalance, in ways that may hide important errors from the designers of SLU systems.  Consider an SLU dataset such as Air Traffic Information Systems   and the speech-to-intent detection problem on this dataset.  About 75\% of the dataset carries the intent of searching for a flight, while conversely, some minority intent classes are represented by only a single training example; this is a severe label imbalance problem. Suppose that we train a model without any concerns about fairness or imbalance. The model will very likely learn to output the `flight' intent all the time, which will give us an accuracy of 75\% which is not low and could be acceptable depending on the application. Considering that there are roughly 30 classes in the whole dataset, one class will have a recall of 1.0 and precision of 0.75 and the remaining 29 classes will have both recall and precision of 0.0. In such a scenario, the F-measure, which is a harmonic average of precision and recall, will be 0.86 for the most common class and 0.0 for the rest, which will give an average of 0.03 which is not acceptable in many cases.   % Previous work on Fair ML, There has been recent interest in introducing fairness to training in the machine learning literature . Most such studies are applied to benchmark datasets related to socioeconomic problems, e.g., disparate impact or equal opportunity . In most such studies, fairness is defined to be the task of protecting against the use of explicit or implicit information about a protected attribute  in the decisions of the machine learning algorithm, for instance, framing the problem as a constrained optimization problem by introducing several penalties. In this work, we introduce fairness into a speech-related problem, namely SLU. We also propose a positive and generalized definition of fairness, in terms of the missed detection and false alarm error rates suffered by all classes, regardless of whether the class definitions are matters of socioeconomic importance or merely engineering convenience.  % Previous methods on F-measure optimization  There have been several studies on F-measure maximization . These models usually focus on binary classification using non-neural-network models: a situation in which the problem of F-measure optimization reduces to the problem of learning a threshold on the scores computed by the model to make a decision. We are aware of one study that performs F-measure optimization for convolutional neural networks, but again, using a system that generates several binary classification outputs in parallel; in this scenario, F-measure optimization reduces to the task of tuning the thresholds of individual binary classifiers in order to maximize a weighted log likelihood. However, true multi-class classification, using the softmax output of the neural network, requires a modified definition of the F-measure.  There is no threshold that can be tuned; instead, F-measure optimization requires optimizing the model itself to generate `better' scores in terms of the F-measure. Model versus threshold optimization is the fundamental difference between this study and the previous ones.  In this work, our goal is to design a loss function to maximize the F-measure instead of the accuracy for DNNs. Our methods are tested on two standard socioeconomic classification problems from the literature on fairness , and on two SLU tasks .  On the SLU  tasks,  we perform end-to-end SLU, i.e., we directly map speech input to the labels instead of performing automatic speech recognition  followed by natural language processing .  We pose the SLU problems as multi-class classification tasks and use the softmax output from the DNN, making it possible to apply the same optimization criterion to both the socioeconomic and SLU learning problems. We approximate the F-measure with a differentiable function of the softmax activations so that we can use the standard backpropagation algorithm to train the DNN.         Improvisation and expressiveness in Peking Opera singing makes it extremely difficult to synthesize this classical performing art. With proposed MDN-based phoneme duration generation with Lagrange Multiplier optimization, our system can generate more accurate phoneme duration compared to the Fitting Heuristic phoneme duration scaling method. Pseudo music notes are generated through the melody transcription algorithm to solve the score inconsistency problem in training. Both the objective average predicted phoneme duration error and the generated pitch contour show our system performances well in generating Peking Opera singing. And as one can see from MOS and the generated samples that there is still a gap between the generated singing and the real performance in terms of naturalness. Our further work includes collecting and labelling more Peking Opera singing data, conducting MOS test in larger scale with subjects in musical background, and improving the quality and pitch accuracy of the generated singing.   \vfill\pagebreak     References should be produced using the bibtex program from suitable   BiBTeX files . The IEEEbib.bst bibliography   style file from IEEE produces unsorted bibliography list.   ------------------------------------------------------------------------- \nocite{black2014automatic} \nocite{umbert2015expression}    
"," Spoken language understanding  datasets, like many other machine learning datasets, usually suffer from the label imbalance problem. Label imbalance usually causes the learned model to replicate similar biases at the output which raises the issue of unfairness to the minority classes in the dataset. In this work, we approach the fairness problem by maximizing the F-measure instead of accuracy in neural network model training. We propose a differentiable approximation to the F-measure and train the network with this objective using standard backpropagation. We perform experiments on two standard fairness datasets, Adult, and Communities and Crime, and also on speech-to-intent detection on the ATIS dataset and speech-to-image concept classification on the Speech-COCO dataset. In  all four of these tasks, F-measure maximization results in improved micro-F1 scores, with absolute improvements of up to 8\% absolute, as compared to models trained with the cross-entropy loss function.  In the two multi-class SLU tasks, the proposed approach significantly improves class coverage, i.e., the number of classes with positive recall.",22
"  Recent neural text-to-speech  systems based on the sequence-to-sequence approach, such as Tacotron~2 , brought considerable quality improvements, but require relatively large amounts of training data and computational resources to train and operate. %Recent advances in text-to-speech synthesis   have allowed integration of high-quality speech synthesis systems into products such as Alexa or Google Assistant. However, adapting the synthesis models to custom domains requires access to relatively large amounts of training data and computational resources. %Moreover, real-time synthesis may be problematic due to the size of the systems and sequential inference. Several works attempt to reduce the computational burden in various ways , but there is still a tradeoff between fast training times, fast inference, and output quality.  In this paper, we address the training efficiency of TTS systems as well as the inference speed and hardware requirements while sustaining good quality of synthesized audio. We propose a fully convolutional, non-sequential approach to speech synthesis  %based on a combination of ideas from . %Similarly to , our system  consisting of a teacher and a student network, similarly to FastSpeech . The teacher network is an autoregressive %\OD{je tu pot鑹ba 鑹￠搯kat 閳ユ竵uteregresivn閾嗛垾, kdy鍟 se tak nikdy nepou鍟搯v璋?} \todo{myslim, ze jo -- jde o zpusob, jaky modeluje to audio. Kdyby nemodeloval audio autoregresivne, tak be nemel moc motivace naucit se spravny alignment} \OD{Fair enough.} convolutional network % based on   which is used to extract correct alignments between phonemes and corresponding audio frames. The student network is a non-autoregressive, fully convolutional network  %with residual connections  % based on   which encodes input phonemes, predicts the duration  for each one, then decodes a mel-scale spectrogram based on phoneme encodings and durations. %used to synthesize spectrograms from input phonemes. The student network first encodes the input phonemes. Then a duration prediction module predicts the duration of each phoneme. Finally, the phoneme encoding vectors are expanded based on their durations and are fed to a decoder module which synthesizes the final spectrogram.   We combine our student network with a pretrained MelGAN vocoder  to achieve fast and high-quality spectrogram inversion.  Our model can be trained on the LJ~Speech data  in under 40 hours on a single 8GB GPU and generates high-quality audio samples faster than real-time on both GPU and CPU.  %\OD{d璋 se tohle rozd鑷巐it na v閾哻 bod鏆 ne鍟 2?} \todo{ano :)}\OD{d閾唊 :-)} Our contributions are as follows:  We simplify the teacher-student architecture of FastSpeech  and provide a fast and stable training procedure.  We use a simpler, smaller and faster-to-train convolutional teacher model with a single attention layer instead of Transformer  used in FastSpeech. % .  We show that self-attention layers  in the student network are not needed for %necessary in order to achieve  high-quality speech synthesis.   We describe a simple data augmentation technique that can be used early in the training to make the teacher network robust to sequential error propagation.  We show that our model significantly outperforms strong baselines while keeping speedy training and inference. %Finally, we provide results of experiments with various techniques such as batch normalization , dropout , positional encoding and style loss functions.     In this work, we proposed a method to maximize the F-measure while training a DNN to deal with the label imbalance problem that is frequently encountered in many datasets. We approximated the average  using soft counts obtained from the softmax activations of the DNN. We compared our proposed method to cross-entropy based training in our experiments. We showed that this method can be applied to different types of DNNs, either fully-connected or BLSTM based, as long as their final layer is a softmax layer. In our experiments on two SLU problems, namely the ATIS speech-to-intent detection problem and the Speech-COCO speech-to-image label classification task, we showed that deep F-measure maximization performs better than the cross-entropy model in terms of micro-, average- and the coverage of classes. Especially, significantly increased coverage shows that the proposed method provides a fair way of treating minority classes.  There are several future directions for research. One direction is to deal with the coverage versus accuracy trade-off, e.g., to explore multi-task or constrained learning methods that might improve coverage and fairness without harming performance for the majority class. Another issue that we would like to address is the performance degradation for high  cases for Speech-COCO.  We also would like to perform experiments on larger datasets with real speech instead of synthesized speech.   
"," %Recent breakthrough in in the quality of text-to-speech systems can be largely accounted to neural sequence-to-sequence models \cite{Tacotron2, WaveNet}. Extensive research has been conducted to improve the effectiveness of training \cite{DeepVoice3, EfficientTTS}, inference speed \cite{WaveRNN, ParallelWaveNet} and voice quality \cite{FastSpeech, TransformerTTS} of the speech synthesis systems.  While recent neural sequence-to-sequence models have greatly improved the quality of speech synthesis, % in the past years, %However, to our knowledge  there has not been a system capable of %fast and efficient training, speedy inference and fast training, fast inference and high-quality audio synthesis at the same time.  %However, none of the aforementioned systems excels in all of the traits.  %In this work,  We propose a student-teacher network %based on \cite{FastSpeech, DeepVoice3, EfficientTTS}  capable of high-quality faster-than-real-time spectrogram synthesis, with low requirements on computational resources and fast training time. We show that self-attention layers are not necessary for generation of high quality audio.  %In fact,  We utilize simple convolutional blocks with residual connections in both student and teacher networks and use only a single attention layer in the teacher model. Coupled with a MelGAN vocoder, our model's voice quality was rated significantly higher than Tacotron~2. Our model can be efficiently trained on a single GPU and can run in real time even on a  %4-core  CPU. We provide both our source code and audio samples in our GitHub repository.\footnote{\url{https://github.com/janvainer/speedyspeech}\label{fn:github}}",23
" Automatic speaker verification  has several applications such as voice biometrics for commercial applications, speaker detection in surveillance, speaker diarization, etc. A speaker is enrolled by a sample utterance, and the task of ASV is to detect whether the target speaker is present in a given test utterance or not. Several challenges have been organized over the years for benchmarking and advancing speaker verification  technology such as the NIST speaker recognition Evaluation  challenge 2019 , the VoxCeleb speaker recognition challenge   and the VOiCES challenge . The major challenges in speaker verification include the language mismatch in testing, short duration audio and the presence of noise/reverberation in the speech data.  %The field is attracting a lot of participants, thereby rapidly updating the state-of-the-art.  The state-of-the-art systems in speaker verification use a model to extract embeddings of fixed dimension from utterances of variable duration. The earlier approaches based on unsupervised Gaussian mixture model  i-vector extractor  have been recently replaced with neural embedding extractors   which are trained on large amounts of supervised speaker classification tasks.  These fixed dimensional embeddings are pre-processed with a length normalization  technique followed by probabilistic linear discriminant analysis  based backend modeling approach .   In our previous work, we had explored a discriminative neural PLDA  approach  to backend modeling where  a discriminative similarity function was used. The learnable parameters of the NPLDA model were optimized using an approximation  of  the  minimum  detection  cost  function . This model also showed good improvements in our SRE evaluations and the VOiCES from a distance challenge . In this paper, we extend this work to propose a joint modeling framework that optimizes both the front-end x-vector embedding model and the backend NPLDA model in a single end-to-end  neural framework. The proposed model is initialized with the pre-trained x-vector time delay neural network . The NPLDA E2E is fully trained on pairs of speech utterances starting directly from the mel-frequency cepstral coefficient  features. The advantage of this method is that both the embedding extractor as well as the final score computation is optimized on pairs of utterances and with the speaker verification metric. With experiments on the NIST SRE 2018 and 2019 datasets, we show that the proposed NLPDA E2E model improves significantly over the baseline system using x-vectors and generative PLDA modeling.      % backend models are trained on these embeddings which output a score. These scores are scaled into log-likelihood ratios using calibration methods. Speaker verification systems apply an application specific threshold to the log-likelihood ratios to output the decision. Widely used examples of embeddings are the i-vector, x-vector and he d-vector. I-vectors  are unsupervised embeddings representing alignment statistics of an utterance using a Gaussian mixture universal background model , X-vectors and d-vectors are embeddings obtained from Neural Network models trained with the objective of speaker classification with a few thousand speakers. The Probabilistic Linear Discriminant Analysis  is the most widely used backend model to compute the log-likelihood. Other backend models include the DPLDA, pairwise Gaussian backend, SVMs, and Neural PLDA. In majority of the systems, the model to extract the embeddings is trained separately from the backend model.  % An area of growing interest is the training of End-to-End speaker verification systems, which optimizes the entire model with a verification objective function. In this paper, we extend our prior work on Neural PLDA  model to enable joint learning of the X-vector extractor and the NPLDA backend, in a fully end-to-end manner. We address the GPU memory issues, and analyse two straightforward methods for sampling the training trials for each batch. We provide comparisons of different loss functions for training.     We presented a convolutional model for spectrogram synthesis from phonemes that supports both speedy training and inference, while maintaining significantly better output voice quality than strong baselines. Our source code and audio samples are available on GitHub.\textsuperscript{} For future work, we plan to extend the model to support multi-speaker training data.  
"," While deep learning models have made significant advances in supervised classification problems, the application of these models for out-of-set verification tasks like speaker recognition has been limited to deriving feature embeddings. The state-of-the-art x-vector PLDA based speaker verification systems use a generative model based on probabilistic linear discriminant analysis  for computing the verification score. Recently, we had proposed a neural network approach  for backend modeling in speaker verification called the neural PLDA  where the likelihood ratio score of the generative PLDA model is posed as a discriminative similarity function and the learnable parameters of the score function are optimized using a verification cost. In this paper, we extend this work to achieve joint optimization of the embedding neural network  with the NPLDA network in an end-to-end  fashion. This proposed end-to-end model is optimized directly from the acoustic features with a verification cost function and during testing, the model directly outputs the likelihood ratio score. With various experiments using the NIST speaker recognition evaluation  2018 and 2019 datasets, we show that the proposed E2E model improves significantly over the  x-vector PLDA baseline speaker verification system.",24
" With the advent of deep learning, end-to-end text-to-speech  has shown many advantages over the conventional TTS techniques . Tacotron-based approaches  with an encoder-decoder architecture and attention mechanism have shown remarkable performance. The key idea is to integrate the conventional TTS pipeline into a unified network and learn the mapping directly from the text-waveform pair . The recent progress in neural vocoder  also contributes to the improvement of speech quality.   Speech prosody includes affective prosody and linguistic prosody. Affective prosody represents the emotion of a speaker, while linguistic prosody relates to the language content. They are both crucial in speech communication. A TTS system is expected to synthesize the right prosodic pattern at the right time. However, most of the current end-to-end systems  have not explicitly modeled speech prosody. Therefore, they can't control well the melodic and rhythmic aspects of the generated speech. This usually leads to monotonous speech, even when models are trained on very expressive speech datasets. In this paper, we would like to study the way to enable Tacotron-based TTS  for expressive prosody generation.   Multi-task learning  is a learning paradigm that leverages information from multiple related tasks to help improve the overall performance . MTL is inspired by human learning activities where people often apply the knowledge learned from many tasks for learning a new task, that is called inductive transfer. For example, if we learn to read and write together, the experience in reading can strengthen the writing and vice versa. MTL has been widely used in speech enhancement , and speech recognition . It has also been used in speech synthesis , such as statistical parametric speech synthesis with GANs  and DNN-based speech synthesis with stacked bottleneck features. In this paper, we apply multi-task learning to the Tacotron-based TTS for prosody modeling.             The study on expressive speech synthesis is focused on prosody modeling , where speech prosody generally refers to intonation, stress, speaking rate, and phrase breaks. Prosodic phrasing  plays an important role in both affective and linguistic expressions. Inadequate phrase breaks may lead to misperception in speech communication. There have been recent studies on prosody modeling for end-to-end TTS system , for example, to improve the prosodic phrasing  by using contextual information , and syntactic features . They are incorporated in the stage of text preprocessing, therefore, there are not optimized as part of the synthesis processing.  We propose a novel two-task learning scheme for Tacotron-based TTS model to improve the prosodic phrasing: 1) the main task learns the prediction of the speech spectrum parameters from character-level embedding representation, and 2) the secondary task learns the prediction of a word-level prosody embedding. During training, the secondary task serves as an additional supervision for Tacotron to learn the exquisite prosody structure associated with the input text. At run-time, the prosody embedding serves as a local condition that controls the prosodic phrasing during voice generation.    The main contributions of this paper include: 1) a novel Tacotron-based TTS architecture that explicitly models prosodic phrasing; and 2) a multi-task learning scheme, that optimizes the model for high quality speech spectrum, and adequate prosodic phrasing at the same time. The proposed system achieves remarkable voice quality for both Chinese Mandarin and Mongolian. To our best knowledge, this is the first multi-task Tacotron implementation that includes an explicit prosodic model.  This paper is organized as follows. Section  recaps the Tacotron TTS framework. We propose the  multi-task Tacotron in Section and report the experiments in Section. Section  concludes the discussion.       In this paper, we explore transfer learning methods for RNN-T models. Our motivation is to leverage well-trained en-US models to bootstrap hi-IN RNN-T models and also to stabilize the hi-IN RNN-T model training. We evaluated the following transfer learning methods: a) en-US CE initialization b) en-US RNN-T initialization c) Two-stage transfer learning and d) Encoder and prediction network initialization.  Based on the WER gains and training convergence, we propose Two-stage learning approach with grapheme targets as the preferred transfer learning strategy. The experiments on smaller data-sets and training loss convergence reveal the importance of transfer learning for low-resource RNN-T models. The methods discussed in this paper can be generalized to other low-resource languages as well. In future, we plan to explore other transfer learning methods and its extension to multi-lingual RNN-T models.       Recently, End-to-End  automatic speech recognition  system have gained significant popularity in the ASR community. They replace the acoustic model , language model  and the pronunciation model of conventional hybrid ASR system with a single neural network . One such E2E architecture is the recurrent neural network transducer  that allow streaming input and is suitable for online ASR applications.    The E2E ASR systems are well-suited for on-device ASR applications as their model size is much smaller than the hybrid ASR models. The popular E2E ASR system include  Connectionist Temporal Classification , Attention-based Encoder-Decoder   and recurrent neural network transducer  . The CTC and    Several works have shown the effectiveness of TL in hybrid ASR framework . In this paper, we TL can also be used in the RNN-T framework to improve the accuracy of low-resource languages.   -Several works have shown the importance of transfer learning  on hybrid ASR systems []\\  -In case hybrid ASR system, transfer learning is typically done by initializing the AM for low resource language with well-trained AM from a high resource language. \\               Merge the two paragraphs  There is often disparity in the amount of transcribed speech data available for different languages. In most cases, lot more data is available for American English  than other languages. The RNN-T model trained with en-US data, referred to hence-forth as en-US RNN-T model, in some form encapsulates the knowledge of mapping the input speech to corresponding text learnt from corresponding en-US data. TL approaches can be used to transfer this knowledge while training the models for low resource languages. In this paper, we explore TL approaches to benefit Hindi RNN-T model by using en-US models.    The knowledge of en-US data is embedded in the models trained with en-US data, referred to hence-forth as en-US model. TL can be suitably used to transfer the knowledge from models trained with American English  to model to be trained with low resources. TL enables sharing of the knowledge from HR language to a LR language by simply initializing LR model with HR model. In this paper, we study the TL methods with American accent English data, referred to henceforth as en-US data, as high resource data and Indian accented Hindi data, referred to hi-IN data, as low resource data.     - In case of the RNN-T framework, several possible combinations exist for transfer learning. TL can be applied to encoder as well as the prediction network. \\    Review of the related work  Encoder itself can be initialized in the following different ways:   The key contributions of this work are as follows:      In general TL can also be applied to medium resource locales to seek improvements in certain new and growing applications, where corresponding training data may only be present in the source locale. It can also be applied to locales in the same language family as well as locales outside the family.     
"," Tacotron-based end-to-end speech synthesis has shown remarkable voice quality. However, the rendering of prosody in the synthesized speech remains to be improved, especially for long sentences, where prosodic phrasing errors can occur frequently. In this paper, we extend the Tacotron-based speech synthesis framework to explicitly model the prosodic phrase breaks. We propose a multi-task learning scheme for Tacotron training, that optimizes the system to predict both Mel spectrum and phrase breaks.  To our best knowledge, this is the first implementation of multi-task learning for Tacotron based TTS with a prosodic phrasing model. Experiments show that our proposed training scheme consistently improves the voice quality for both Chinese and Mongolian systems.",25
"  % 1. 娴犲绮涚拠顓㈢叾閸氬牊鍨氬Ο鈥崇烽崚鍡曡礋娑撱倓閲滈柈銊ュ瀻閿涘苯绱╅崙鐑樻拱閺傚洣瀵岀憰浣稿彠濞夈劎顑囨稉娑擃亝膩閸  Speech synthesis, also known as text-to-speech ,  has attracted a lot of attention and obtained satisfactory  results in recent years due to the advances in deep learning.  Several TTS systems based on deep networks were proposed,  such as Char2Wav , Tacotron2 ,  DeepVoice3 , Transformer TTS ,  FastSpeech  and ParaNet .  These systems usually first predict the acoustic feature sequence  from the input text sequence, and then generate waveform from  the acoustic feature sequence using vocoder such as  Griffin-Lim , WaveNet ,  WaveRNN , WaveGlow   and GAN-TTS .  % 2. 娴犲绮涢惄顔煎閻 閸忓厖绨琺el鐠嬮亶顣╁ù瀣秹缂佹粎娈戠拋鎹愵吀閸╃儤婀伴弬鐟扮础 LSTM, Conv, transformer  % According to the characteristics of network strucutre, current mainstream TTS systems can be divided into  % three types: RNN-based, CNN-based and Transformer-based.  % The RNN-based TTS systems, such as Char2Wav ,  % Tacotron 2  and Tacotron ,  % use the recurrent neural network  to design the main network structure,  % where the attention mechanism is applied to model the alignment  % between the acoustic feature sequence and the text sequence, % while the nature of RNN limits its parallelism.  % The CNN-based TTS systems, such as DeepVoice 3  % and ParaNet , adopt the convolution neural network  to model timing dependencies,  % which enable parallel processing at training.  % Especially in ParaNet , the iteratively refined attention mechanism is proposed to enable system  % to perform the inference process in parallel.  % The Transformer-based TTS systems, such as Transformer TTS , FastSpeech  and AlignTTS ,  % apply the architecture of Transformer to realize the process of speech synthesis.  % FastSpeech  uses the self-attention structure of Transformer to design a feed-forward network  % for predicting mel-spectrum in parallel, but needs guidance from an teacher autoregressive TTS model  % due to difficulty of learning alignment between text and mel-spetrum. % AlignTTS  proposes the alignment loss to make feed-forward TTS system capable of model the aligment  % without the guidance from other TTS systems.    % 2. 瀵洖鍤ぐ鎾冲鐠囶參鐓堕崥鍫熷灇鐎佃鏋冮張顒勬毐鎼达妇娈戦梽鎰煑  Although current speech synthesis systems have obtained  high-quality speech, it is difficult for them to achieve  satisfactory results in long text speech synthesis scenarios.  In the sequence-to-sequence TTS model, since the monotonicity  and locality properties of TTS alignment are not fully utilized,  the alignment procedure lacks robustness in inference,  which leads to skipping or repeating words, incomplete  synthesis, or an inability to synthesize long utterances  . To address the issue,  many monotonic attention mechanisms are presented  , where only  the alignment paths satisfying the monotonic condition  are taken into consideration at each decoder timestep.  In ,  the location-based GMM attention introduced in   is also studied in TTS systems to generalize to long utterances.  Especially, AlignTTS  proposes an alignment loss  to model the alignment between text and mel-spectrum, and uses  a length regulator to adjust the alignment, which solves the  instability problem of the alignment and is very efficient.  However, since the self-attention of Transformer   is used to model the dependencies  of input sequence elements in AlignTTS, the positional encodings  are required to introduce the positional information,  which limits the maximum length of input text.  In this paper, a novel self-attention mechanism is proposed to remove the need for the positional encodings and  lift the restriction of input text length.   % In Tacotron , the content-based attention mechanism introduced in   % is used to align the text and the melspectrum,  % but it does not exploit the monotonicity of TTS alignment. % Tacotron 2 uses the hybrid attention meachnism from   % which encourage the attention alignment to move forward consistently through the input sequence.   % which makes synthesis process instability. % long text sequence is not conducive to  % the calcualtion of the attention mechanism in TTS system,  % which affects the prediction of the acoustic feature and the stop token in inference.  % FastSpeech  and AlignTTS  use the length regulator instead of the attention mechanism,  % but the locational encoding of Transformer also limits its max length of input text.  % In order to lift this restriction, we design a novel self-attention mechanism  % to model the timing dependencies for TTS system.  % 3. 娑擃厽鏋冪拠顓㈢叾閸氬牊鍨氭稉顓炲彠娴滃酣鐓瑰瀣紦濡紕娈戦崚鍡樼 On the other hand, the prosody of speech directly affects  the overall listening perception of the voice, especially for  long utterances. In order to improve the naturalness of  synthetic speech, it is necessary for TTS systems to model  prosody information. In ,  a prosody embedding is introduced for emotional and  expressive speech synthesis, which enables fine-grained control  of the speaking style. In ,  an interpretable latent variable model for prosody based on  Tacotron 2 is presented to model phoneme-level and word-level  prosody information of speech.  proposes  a quantized latent feature for the prosody of speech, and trains  an autoregressive prior model to generate natural samples  without a reference speech. These prosody control methods  enable us to learn the prosody from speech and fine-grained  the synthesized speech, but they still cannot effectively  predict the correct prosody according to the input text.   One reason is that the prosody information of speech  generally depends on the meaning of text, while only the  phoneme information of text is used as the input in current  mainstream TTS systems, which limits the capabilities of  modeling the prosody of speech.  In ,  the textual knowledge from BERT  is introduced  into TTS systems to improve the prosody of speech,  but they ignore the variability of prosody.  For example, the same text may produce speech with  different prosody due to pronunciation uncertainty.    % 4. 閹崵绮ㄩ弬鍥ㄦ拱閻ㄥ嫬鍨遍弬鎵仯  In this works, we propose a novel self-attention mechanism,  named as local attention, to model the timing dependencies,  which abandons positional encoding and uses a relative  position matrix to model the influence of the positional  relationship of input sequence. At the same time,  we introduce the prosody learning mechanism for feed-forward  TTS systems, where a prosody embedding for each phoneme is  learned from the mel-spectrum in training. In addition,  a prosody predictor is designed to predict the prosody  embedding according to text and phoneme, where a pre-trained  language model is applied to introduce the meaning of text.  And the main contributions of our works as follows:           We have proposed a novel multi-task Tacotron model to model the prosodic phrasing in speech synthesis, where a word-level prosody generator is introduced as the secondary task. The experiments show that the proposed MTL-Tacotron consistently outperforms all contrastive systems. The modeling technique for prosodic phrasing can be easily extended to the modeling of other melodic and rhythmic aspects of speech, such as intonation and stress.                                             &         &  \\       &         &  \\      \noalign{\smallskip}\hline              {\footnotesize  }    
","     Recent neural speech synthesis systems have gradually    focused on the control of prosody to improve the quality    of synthesized speech, but they rarely consider the    variability of prosody and the correlation between prosody    and semantics together. In this paper, a prosody learning    mechanism is proposed to model the prosody of speech based    on TTS system, where the prosody information of speech is    extracted from the mel-spectrum by a prosody learner and    combined with the phoneme sequence to reconstruct the    mel-spectrum. Meanwhile, the sematic features of text from    the pre-trained language model is introduced to improve the    prosody prediction results. In addition, a novel self-attention    structure, named as local attention, is proposed to lift    this restriction of input text length, where the relative    position information of the sequence is modeled by the    relative position matrices so that the position encodings    is no longer needed. Experiments on English and Mandarin show    that speech with more satisfactory prosody has obtained    in our model. Especially in Mandarin synthesis,    our proposed model outperforms baseline model with a MOS gap    of 0.08, and the overall naturalness of the synthesized    speech has been significantly improved.",26
"  Conventional SLU pipeline mainly consists of two components : an Automatic Speech Recognition module generates transcriptions or N-hypotheses, and a Natural Language Understanding  module classifies transcriptions into intents, in which speech recognition error propagation will be amplified during sub-sequence NLU process. Although with the rapid development of end-to-end speech recognition systems, the performance of SLU has been significant improved , it still can not satisfy the application requirements, due to the complexity of scenarios.  %The improved performance of SLU mainly benefits from the increasing maturity of ASR. The application of deep neural networks in acoustic models and language models together with the rapid development of end-to-end technique make ASR systems extend to other research domains .    Usually not all errors from speech recognition harm the SLU module, and those errors have no impact on the eventual performance . The SLU component only keeps its attention on keywords while discarding most of the other irrelevant words . Thus the joint optimization approach can strengthen the focus of the model on improving the transcription accuracy that relates to target events . Recently, many efforts have been dedicated on end-to-end SLU in which the domain and the intent are predicted directly from input audio . Previous researches have shown that a large amount of data is the determining factor for the excellent performance of a model . However, due to the lack of audio and the ambiguity of intents, it is difficult to obtain sufficient in-domain labeled data. Transfer learning methodology has become a common strategy to address insufficient of data problem . %which is a vital technique that can generalizes models trained for one setting or task to other settings or tasks. Different transfer learning strategies have been applied in SLU model and all of them result in competitive complementary results . In this paper, this strategy is also applied to amplify the feature extraction capability of the encoder component, it pre-train the encoder with a large amount of speech recognition labeled data, and then transfer the encoder to the SLU model.   Recently,  proposed and compared various of encoder-decoder approaches to optimize each module of SLU in end-to-end manners and have proved that intermediate text representation is crucial for SLU and jointly training the full model is advantageous. Attention-based models have been widely used in speech recognition and provide impressive performance . Inspired by this, we propose a Transformer based multi-task strategy to adopt textual information in the SLU model. Since text information only acts on the decoder component in speech recognition task, it can be treated as an adaptive regularizer to adjust the encoder parameters such that contributing to improve intent prediction performance.  It should be noticed that the lack of textual corpus is also a major challenge when training language models. To address this problem, various of methods have been carried out to expand corpus in the past decade . In addition, textual level transfer learning strategy by merging a pre-trained representation to the decoder is also explored. The pre-trained representation is obtained with the BERT model, which is designed to pre-train the deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers .   Encoder and decoder are mutual independent but are connected by the attention block, through which can get a collaborated optimization in training.  To maximize the performance, both encoder and decoder are optimized with transfer leaning strategies. In this paper, we first propose a self-attention based end-to-end SLU structure, and applied cross-lingual transfer learning method to solve insufficient acoustic data problem. Then we propose a Transformer based multi-task strategy that conducts intent classification and speech recognition in parallel. Finally, a textual-level transfer learning structure is designed to aggregate the pre-trained BERT model into the decoder component to improves the feature extraction capability of the decoder, indirectly.      Based on the local attention, a feed-forward text-to-speech  system without the limitation of input text length is designed.  Meanwhile, the prosody learning mechanism is proposed to model  the prosody of speech, where the prosody information is learned  from speech by a prosody learner in training process.  In order to predict more satisfactory prosody in inference,  the pre-trained language model is used to introduce the semantic  feature. Experiments on English synthesis and Mandarin synthesis  show that a significant improvement in the prosody of speech has  been obtained in our proposed TTS systems.  
","   End-to-end Spoken Language Understanding  models are made increasingly large and complex to achieve the state-of-the-art accuracy. However, the increased complexity of a model can also introduce high risk of over-fitting, which is a major challenge in SLU tasks due to the limitation of available data. In this paper, we propose an attention-based SLU model together with three encoder enhancement strategies to overcome data sparsity challenge. The first strategy focuses on the transfer-learning approach to improve feature extraction capability of the encoder. It is implemented by pre-training the encoder component with a quantity of Automatic Speech Recognition annotated data relying on the standard Transformer architecture and then fine-tuning the SLU model with a small amount of target labelled data. The second strategy adopts multi-task learning strategy, the SLU model integrates the speech recognition model by sharing the same underlying encoder, such that improving robustness and generalization ability. The third strategy, learning from Component Fusion  idea, involves a Bidirectional Encoder Representation from Transformer  model and aims to boost the capability of the decoder with an auxiliary network. It hence reduces the risk of over-fitting and augments the ability of the underlying encoder, indirectly. Experiments on the FluentAI dataset show that cross-language transfer learning and multi-task strategies have been improved by up to $4.52\%$ and $3.89\%$ respectively, compared to the baseline.",27
" Associative memory is defined in psychology as the ability to remember  many sets, called memories, of unrelated items. Prompted by a large enough subset of items taken from one memory, an animal or computer with an associative memory can retrieve the rest of the items belonging to that memory.  The diverse human cognitive abilities which involve making appropriate responses to stimulus patterns can often be understood as the operation of an associative memory, with the ``memories'' often being distillations and consolidations of multiple experiences rather than merely corresponding to a single event.  The intuitive idea of associative memory can be described using a ``feature space''.  In a mathematical model abstracted from neurobiology, the presence  of each particular feature  is denoted by the activity  of a model neuron  due to being directly driven by a feature signal.  If there are  possible features, there can be only at most  distinct connections  in a neural circuit involving only these neurons.  Typical cortical synapses are not highly reliable, and can store only a few bits of information\footnote{For instance, a recent study  reports the information content of individual synapses ranging between  and  bits, based on electron microscopy imaging, see also . These numbers refer to the structural accuracy of synapses. There is also electrical and chemical noise in synaptic currents induced by the biophysical details of vesicle release and neurotransmitter binding. The unreliability of the fusion of pre-synaptic vesicles  with the pre-synaptic neuron membrane is the dominant source of trial-to-trial synaptic current variation  .  This noise decreases the electrical information capacity of individual synapses from the maximal value that the synaptic structure would otherwise provide.}. The description of a particular memory requires roughly  bits of information.   Such a system can therefore store at most   unrelated memories.   Simple artificial neural network models of associative memory  exhibit this limitation even with precise synapses, with limits of memory storage to less than  memories .   Situations arise in which the number  is small and the desired number of memories far exceeds , see some examples from biological and AI systems in Section . In these situations the associative memory model of  would be insufficient, since it would not be able to memorize the required number of patterns. At the same time, models of associative memory with large storage capacity considered in our paper, can easily solve these problems.  The starting point of this paper is a machine learning approach to associative memory based on an energy function and attractor dynamics in the space of  variables, called Dense Associative Memory . This idea has been shown to dramatically increase the memory storage capacity of the corresponding neural network  and was proposed to be useful for increasing robustness of neural networks to adversarial attacks . Recently, an extension of this idea to continuous variables, called modern Hopfield network, demonstrated remarkably successful results on the immune repertoire classification , and provided valuable insights into the properties of attention heads in Transformer architectures .   Dense Associative Memories or modern Hopfield networks, however, cannot describe biological neural networks in terms of true microscopic degrees of freedom, since they contain many-body interaction terms in equations describing their dynamics and the corresponding energy functions. To illustrate this point consider two networks: a conventional Hopfield network  and a Dense Associative Memory with cubic interaction term in the energy function . In the conventional network the dynamics is encoded in the matrix , which represents the strengths of the synaptic connections between feature neurons  and . Thus, this network is manifestly describable in terms of only two-body synapses, which is approximately true for many biological synapses. In contrast, a Dense Associative Memory network with cubic energy function naively requires the synaptic connections to be tensors  with three indices, which are harder, although not impossible, to implement biologically. Many-body synapses become even more problematic in situations when the interaction term is described by a more complicated function than a simple power .    Many-body synapses typically appear in situations when one starts with a microscopic theory described by only two-body synapses and integrates out some of the degrees of freedom . The argument described above based on counting the information stored in synapses in conjunction with the fact that modern Hopfield nets and Dense Associative Memories can have a huge storage capacity hints at the same solution. The reason why these networks have a storage capacity much greater than  is because they do not describe the dynamics of only  neurons, but rather involve additional neurons and synapses.    Thus, there remains a theoretical question: what does this hidden circuitry look like? Is it possible to introduce a set of hidden neurons with appropriately chosen interaction terms and activation functions so that the resulting theory has both large memory storage capacity , and, at the same time, is manifestly describable in terms on only two-body synapses?    The main contributions of this current paper are the following. First, we extend the model of  to continuous state variables and continuous time, so that the state of the network is described by a system of non-linear differential equations. Second, we couple an additional set of  ``complex neurons'' or ``memory neurons'' or hidden neurons to the   feature neurons.  When the synaptic couplings and neuron activation functions are appropriately chosen, this dynamical system in  variables has an energy function describing its dynamics.  The minima  of this dynamics are at the same locations in the  - dimensional feature subspace as the minima in the corresponding Dense Associative Memory system. Importantly, the resulting dynamical system has a mathematical structure of a conventional recurrent neural network, in which the neurons interact only in pairs through a two-body matrix of synaptic connections. We study three limiting cases of this new theory, which we call models A, B, and C. In one limit  it reduces to Dense Associative Memory model of  or  depending on the choice of the activation function. In another limit  our model reduces to the network of . Finally, we present a third limit  which we call Spherical Memory model. To the best of our knowledge this model has not been studied in the literature. However, it has a high degree of symmetry and for this reason might be useful for future explorations of various models of large associative memory and recurrent neural networks in machine learning.    For the purposes of this paper we defined ``biological plausiblity'' as the absence of many-body synapses. It is important to note that there other aspects in which our model described by equations  below is biologically implausible. For instance, it assumes that the strengths of two physically different synapses  and  are equal. This assumption is necessary for the existence of the energy function, which makes it easy to prove the convergence to a fixed point. It can be relaxed in equations , which makes them even more biological, but, at the same time, more difficult to analyse.      In this paper, we proposed various audio dequantization schemes that can be implemented in flow-based neural vocoder. For the uniform dequantization, we compressed the range of audio domain to match with conventional uniform dequantization method by using mu-law companding compression. In addition, we implemented iw dequantization to resolve the noise issue that occurs from the lossy compression. For the Gaussian dequantization, we applied hyperbolic tangent normalization on data-oriented Gaussian noise to properly fit the data within the audio range. Lastly, we modified flow block in flow-based neural vocoder to construct variational dequantization model to apply more flexible noise. From the experiments, we demonstrate that implementing audio dequantization can supplement the flow-based neural vocoder to produce better audio quality with fewer artifacts.  \clearpage   
","  Dense Associative Memories or modern Hopfield networks permit storage and reliable  retrieval of an exponentially large  number of memories. At the same time, their naive implementation is non-biological, since it seemingly requires the existence of many-body synaptic junctions between the neurons.   We show that these models are effective descriptions of a more microscopic  theory that has additional  neurons and only requires two-body interactions between them. For this reason our proposed microscopic theory is a valid model of large associative memory with a degree of biological plausibility. The dynamics of our network and its reduced dimensional equivalent both minimize energy  functions. When certain dynamical variables  are integrated out from our microscopic theory, one can recover many of the models that were previously discussed in the literature, e.g. the model presented in ``Hopfield Networks is All You Need'' paper. We also provide an alternative derivation of the energy function and the update rule proposed in the aforementioned paper and clarify the relationships between various models of this class.",28
"  Over the past few years, developments in sequence-to-sequence  neural text-to-speech  research have led to synthetic speech that sounds almost indistinguishable from human speech . However, large amounts of high-quality recordings are typically required from a professional voice talent to train models of such quality, which can make them prohibitively expensive to produce. To counter this issue, investigations into how S2S models can facilitate multi-speaker data has become a popular topic of research. %\EJ{I don't like starting a sentence with a citation if the citation is a number in brackets} \MK{Agreed} A study by, for example, showed that multi-speaker models can perform as well or even better than single-speaker models when large amounts of target speaker data are not available, and that single-speaker models only perform better when substantial amounts of data are used. Their research also showed that the amount of data necessary for an additional speaker can be as little as 1250 or 2500 sentences without significantly reducing naturalness. With regards to parametric synthesis, investigated the effect of several multi-speaker modeling strategies for class imbalanced data. Their research found that for limited amounts of speech, multi-speaker modeling and oversampling could improve speech naturalness compared to single speaker models, while undersampling was found to generally have a harmful effect. They also showed that ensemble methods can further improve naturalness, but this strategy comes with a considerable computational cost that is usually not feasible for S2S modeling.  Although the above research shows that multi-speaker modeling can be an effective strategy to reduce data requirements, it is not a suitable solution for many languages for which large quantities of high-quality multi-speaker data are not available. Multilingual multi-speaker synthesis aims to address this issue by training a multilingual model on the data of multiple languages. Among the first to propose a neural approach to multilingual modeling was. Instead of modeling languages separately, they modeled language variation through cluster adaptive training, where a mean tower as well as language basis towers were trained. They found that multilingual modeling did not harm naturalness for high-resource languages, while low-resource languages benefited from multilingual modeling. Another study by scaled up the number of unseen low-resource languages to twelve, and similarly found that multilingual models tend to outperform single speaker models.  More recently, multilingual modeling was also adopted in S2S architectures, however mostly for the purposes of code-mixing and cross-lingual synthesis. Language information was typically represented either with a language embedding or with a separate encoder for each language, while applied both approaches to code-mixing and accent conversion. With regards to multilingual modeling, showed that multilingual models can attain a naturalness and speaker similarity that is comparable to that of a single speaker model for high-resource target languages, while research from obtained promising results with a crosslingual transfer learning approach.  While research into S2S multilingual modeling is clearly vibrant, there appears to exist little systematic research into how S2S multilingual models could be used to increase speech naturalness for low-resource languages. To fill this void, this paper investigated to what extent results that are found in S2S monolingual multi-speaker modeling are transferable to multilingual multi-speaker modeling, and if it is possible to attain higher naturalness on low-resource languages with multilingual models than with single speaker models. Because multilingual modeling can benefit from the inclusion of large amounts of non-target language data, we also experimented with several data addition strategies and evaluated to what extent these strategies are effective to improve naturalness for low-resource languages. As this research is primarily addressing the viability of different approaches with regards to low-resource languages, our focus is not so much on maximizing naturalness but rather on gaining a better understanding of how different strategies work and would potentially scale up using larger amounts of data.  The rest of this paper is organized as follows. In Section, we  describe the architecture used to conduct our experiments. In Section, we describe the experimental design and give details about training and evaluation. In Section, we provide the experimental results. Finally, in Section, we discuss conclusions and directions for future research.        A new approach of audio laughter synthesis based on seq2seq learning was proposed inspired by the evolution of the TTS field.   We proposed to train a deep learning system to synthesize speech and laughter from transcriptions by augmenting the input of phonemes with laughter annotations.   It allows to leverage transfer learning of patterns between annotations and acoustic features of both worlds.  In this paper, a new approach of audio laughter synthesis based on seq2seq learning was proposed inspired by the evolution of the TTS field. This system is implemented by leveraging the patterns learned to pass from text to acoustic features in speech, to learn laughter synthesis.    We show that using a pretrained MelGAN model as a post waveform corrector allows to remove audio artifacts generated by Griffin-Lim algorithm. We also use a pretrained MelGAN model as a post waveform corrector allows to remove audio artifacts generated by Griffin-Lim algorithm and thus improve the scores obtained in a MOS test. We believe several modifications could improve the acoustic quality of the synthesis. First end-to-end training could help concerning the accumulation of errors of several blocks: the seq2seq system and the vocoder.     This results in a strong improvement over past methods of audio laughter synthesis in terms of naturalness and is promising for synthesizing speech-laughs thanks to a consistency with latest speech synthesis technologies. This results in a strong improvement over past methods of audio laughter synthesis  in terms of naturalness and is promising for later use to build amused speech synthesis systems. The promising results obtained here, allows us to work on incorporating the laughter synthesis system into a fully functioning TTS with control over amusement level. The fact that our laughter synthesis system was developed in a TTS context makes this integration easier.  
"," Recent advances in neural TTS have led to models that can produce high-quality synthetic speech. However, these models typically require large amounts of training data, which can make it costly to produce a new voice with the desired quality. Although multi-speaker modeling can reduce the data requirements necessary for a new voice, this approach is usually not viable for many low-resource languages for which abundant multi-speaker data is not available. In this paper, we therefore investigated to what extent multilingual multi-speaker modeling can be an alternative to monolingual multi-speaker modeling, and explored how data from foreign languages may best be combined with low-resource language data. We found that multilingual modeling can increase the naturalness of low-resource language speech, showed that multilingual models can produce speech with a naturalness comparable to monolingual multi-speaker models, and saw that the target language naturalness was affected by the strategy used to add foreign language data.",29
" % \dcrm{In a standard Question Answering system, a user enters a natural language question,e.g., Who founded Tesla?}. Knowledge Graph based Question Answering  systems use a background Knowledge Graph to answer queries posed by a user. Let us take the following question as an example :  Who founded Tesla?. The standard sequence of steps for a traditional Entity Linking system is as follows: The system tries to identify Tesla as a span of interest. This task is called Mention Detection  or Span Detection. Then an attempt is made to link it to the appropriate entity in the Knowledge Base.  In this work we focus on Knowledge Bases in the form of graphs, hence the entity linker in this case tries to link Tesla to the appropriate node in the graph.  For a human, it is evident that the question is looking for a person's name who created an organisation named Tesla, since the text contains the relation .  Hence, it is important that the entity linker understands the same nuance and ignores other entity nodes in the Knowledge Graph which also contain Tesla in their labels, e.g.,  when considering the example of the Wikidata knowledge graph.  The task of ignoring the wrong candidate nodes, and identifying the right candidate node instead, is called Entity Disambiguation . The cumulative process involving Mention Detection and Entity Disambiguation is called Entity Linking .     Typically, the MD and ED stages are implemented by different machine learning models which require separate training. Especially for the MD part, sentences with marked entity spans are a requirement. In practice, such data is not easily available. Moreover, errors introduced by the MD phase cascade on to the ED phase. Hence, a movement towards end-to-end Entity Linkers began  . Such systems do not require labelled entity spans during training. In spite of the benefits of end-to-end models some challenges remain: Due to the lack of a span detector at the initial phase, each word of the sentence needs to be considered as an entity candidate for the disambiguation which leads to the generation of a much larger number of entity candidates. To re-rank these candidates a large amount of time is consumed, not just in processing the features of the candidates, but also in compiling their features. %Some systems fetch neighbouring entities and relations on the fly  for each candidate entity, a step that can take more than a minute for certain entities on large KGs.   In this work, we remain cognizant of these challenges and design a system that completely avoids querying the Knowledge Graph during runtime. PNEL  instead relies on pre-computed and pre-indexed TransE embeddings and pre-indexed entity label and description text as the only set of features for a given candidate entity. We demonstrate that this produces competitive performance while maintaining lower response times when compared to VCG .  While there is a wide variety of KG embeddings to choose from, we confine our experiments to pre-computed TransE over Wikidata supplied by PyTorch-BigGraph. Our choice was based on the popularity and ease of availability of these embeddings.  Traditionally, the Knowledge Graphs of choice for Question Answering research have been DBpedia, Freebase  and YAGO. However, in recent times Wikidata has received significant attention owing to the fact that it covers a large number of entities . DBpedia, YAGO and Wikidata source their information from Wikipedia, however DBpedia and YAGO filter out a large percentage of the original entities, while Wikidata does not. While Wikidata has a larger number of entities it also adds to noise which is a challenge to any EL system. Wikidata also allows direct edits leading to up-to-date information, while DBpedia depends on edits performed on Wikipedia. Freebase has been discontinued and a portion of it is merged into Wikidata. Moreover DBpedia now extracts data directly from Wikidata, apart from Wikipedia \footnote{https://databus.dbpedia.org/dbpedia/wikidata}  . %Wikidata allows wiki based edits and is hence up-to-date.  %Both DBpedia and Freebase have decided to merge with Wikidata in some form.  Hence, we decide to base this work on the Wikidata knowledge graph and the datasets we evaluate on are all based on Wikidata.\\   In this work our contributions are as follows:     The paper is organised into the following sections:  Related Work, outlining some of the major contributions in entity linking used in question answering;  PNEL, where we discuss the pointer networks and the architecture of PNEL Dataset used in the paper  Evaluation, with various evaluation criteria, results and ablation test   Error Analysis  Discussion and future direction.     This paper aimed to investigate the effectiveness of multilingual modeling to improve speech naturalness of low-resource language neural speech synthesis.  speakers. Our results showed  have shown that the addition of auxiliary non-target language data can positively impact the naturalness of low-resource language speech and can be a viable alternative to auxiliary target language data when such data is not readily available. We furthermore found that when more target language data was available, the inclusion of the auxiliary non-target language data did not negatively affect naturalness. Although  in this research we did not compare multilingual models with single speaker models for even larger amounts of target language data in this research, we expect that results from multilingual modeling will largely mimic the effects observed in studies of monolingual multi-speaker modeling. Finally, we explored several strategies for including additional non-target language data. We showed that not all data addition strategies are equally effective, and reported that language diversity and minimizing class imbalances appear to be the most important variables to consider when adding data.  Based on our conclusions, we identify several directions for future research. First of all, the current research didn't consider the issue of language proximity on the effect of multilingual modeling. Although languages are modeled separately in the encoders, language proximity may positively affect naturalness. Additionally, this research evaluated low-resource language speech naturalness at a general level, while it may be more interesting to focus on the naturalness of language-specific characteristics such as language-specific phonemes or stress patterns. We furthermore note that the amount of auxiliary data used was relatively limited in our experiments. Further analysis could be done to find out whether our findings hold when scaled up with more data. Finally, we found that the MULT-2k+16x2k model was most effective to improve naturalness of target language speech, but this result does not clarify whether this effect can be attributed to the large variation in languages and speakers, or to the minimization of class imbalances. It would be interesting to disentangle these variables by comparing this model to a monolingual multi-speaker model with similar amounts of data per speaker.   
"," Question Answering systems are generally modelled as a pipeline consisting of a sequence of steps. In such a pipeline, Entity Linking  is often the first step. Several EL models first perform span detection and then entity disambiguation. In such models errors from the span detection phase cascade to later steps and result in a drop of overall accuracy. Moreover, lack of gold entity spans in training data is a limiting factor for span detector training. Hence the movement towards end-to-end EL models began where no separate span detection step is involved. In this work we present a novel approach to end-to-end EL by applying the popular Pointer Network model, which achieves competitive performance. We demonstrate this in our evaluation over three datasets on the Wikidata Knowledge Graph.    \keywords{Entity Linking  \and Question Answering \and Knowledge Graphs \and Wikidata}",30
"   Slot filling is one of the major but challenging tasks in spoken language understanding because it aims to automatically extract semantic concepts by assigning a set of task-related slots to each word in a sentence.  was the first reported work that applied recurrent neural network  to the slot filling task and encouraged the follow-up deep learning work for the task. The next works focused on deep learning:  tried to replace the vanilla RNNs with more advanced RNN cells based on long short-term memory   or bi-directional LSTM ,  focused on recursive neural networks, and  utilizes an attention-based RNN.   In this study, we firstly generalize the variational inference -based dropout regularization in the LSTM-RNNs to more advanced RNN architectures such as gated recurrent unit   and bi-directional LSTM/GRU. Then, the RNN models with the VI-based dropout regularization are employed in the slot filling task on the ATIS database. Compared with , this work presents a slight modification of the LSTM-RNNs that can lead to better baseline result, and more RNN architectures with and without VI-based dropout regularization are tested in our experiments. As opposed to , our methods are much easier to implement than the attention-based RNN, but similar results can be obtained in practice.   Since it has been shown that RNNs overfit very quickly , various regularization methods, such as early stopping or small and under-specified models , have to be used during the RNN training stage. Although dropout is normally taken as a simple and effective regularization to overcome the problem of overfitting in deep neural networks , it has been concluded that the naive dropout regularization to recurrent weights in RNNs cannot reliably solve the RNN overfitting problem because noise added in the recurrent connections leads to model instabilities .   However, a recent work  has shown that dropout regularization is a variational approximation technique in Bayesian learning. In addition, the variational inference provides a new variant of dropout regularization, where the same dropout masks are separately shared along time for embedding, decoding, and recurrent weights, so that they can be successfully applied to recurrent layers in RNNs.   The remainder of the paper is organized as follows: Section  presents the VI-based dropout regularization in RNNs. Section  develops the GRU and bi-directional LSTM/GRU-based RNNs with the VI-based dropout regularization. Section  shows the experimental results on the ATIS database and the paper is concluded in Section .      In this work we have proposed PNEL, an end-to-end Entity Linking system based on the Pointer Network model. We make no modifications to the original Pointer Network model, but identify its utility for the problem statement of EL, and successfully model the problem so the Pointer Network is able to find the right set of entities.   We evaluate our approach on three datasets of varying complexity and report state of the art results on two of them. On the third dataset, WebQSP, we perform best in precision but lag behind in recall. We select such features that require no real time KG queries during inference. This demonstrates that the Pointer Network model, and the choice of features presented in this work, result in a practical and deployable EL solution for the largest Knowledge Graph publicly available - Wikidata.   \\  \dc{Our main design goal for the system is speed and deploybility; hence, we refrain from querying the underlying Knowledge Graph during inference. Instead, we solely rely on pre-trained TransE KG Embeddings, which potentially encodes the structural information of a Knowledge Graph. Additionally, we also incorporate entity label and description information into PNEL which further benefits the model. As evident from the results, PNEL exhibits state-of-the-art performance on both LC-QuAD 2.0, and SimpleQuestions datasets and has the best precision and comparable F1-scores for WebQSP as well. Hence, it can be concluded that our proposed feature sets can encode the KG information implicitly while achieving comparable or better performance than systems which explicitly relies on KG structural information such as 1, and 2-hop relation information. }   The design goal for the models being ""no KG query during inference"", we rely on pre-computed TransE embeddings to incorporate KG structural information. Additionally, we use entity labels and descriptions which are pre-indexed in a text database. It must be noted that we do not consider neighbourhood relation information explicitly. Since our system achieves state-of-the-art numbers on some datasets, and performs competitively overall, it can be said that our limited choice of pre-indexed features performs at par with a large variety of systems that also consider 1-hop and 2-hop relation information explicitly. \\  For future work: PNEL being based on the LSTM cell inevitably processes tokens sequentially increasing the response times. This limitation could be overcome by using some variant of the Transformer model instead, which is not only a powerful model but also able to process tokens in parallel.  As a future work we would also like to explore different entity embedding techniques and investigate which characteristics make an embedding suitable for the entity linking task.   
"," This paper proposes to generalize the variational recurrent neural network  with variational inference -based dropout regularization employed for the long short-term memory  cells to more advanced RNN architectures like gated recurrent unit  and bi-directional LSTM/GRU. The new variational RNNs are employed for slot filling, which is an intriguing but challenging task in spoken language understanding. The experiments on the ATIS dataset suggest that the variational RNNs with the VI-based dropout regularization can significantly improve the naive dropout regularization RNNs-based baseline systems in terms of F-measure. Particularly, the variational RNN with bi-directional LSTM/GRU obtains the best F-measure score.",31
" The percolation of social media throughout the world has facilitated unprecedented ease of access to the flow of information. The rise of the internet and its availability have also enabled every user to to not only consume, but also contribute to the information flow. However, the benefits of such ecosystems come at the cost of mistrust in the veracity of information. In recent years, the social media scene has witnessed the proliferation of false information campaigns, in which ordinary users are intentionally or otherwise both consuming false news and also spreading it among their communities.   This phenomenon is commonly referred to as fake news, broadly defined as broadcasting of information that is intentionally and verifiably false . The rise of fake news and its societal impact has been studied in the context of numerous recent events, such as the Brexit referendum and the 2016 US presidential elections . Fake news has thus proven to be a major threat to democracy, journalism, and freedom of expression . The exposure of users to fake news has been shown to have numerous deleterious effects, instances of which include inducing attitudes of inefficacy, alienation, trusting in false propaganda, cynicism toward certain political candidates and communities, that can at times give rise to the violent events. For example, coordinated fake news and propaganda campaigns on Facebook are considered to have been key in inciting the Myanmar genocide in 2016-2017 . Also, the recent proliferation of false information about 5G communication networks being the cause of the novel Coronavirus outbreak has resulted in attacks against the employees and infrastructure of cellular careers in the UK . Fake news can also affect financial markets, as observed in the case of fake news claiming that Barack Obama was injured in an explosion resulting in a loss of \$130 billion in stock value . Hence, there is a growing need for effective tools and techniques to detect and control the spread of false information campaigns on social media.   Fake news classification is the process of determining whether the news contains false news and misinformation or not. Traditionally, this classification is performed by subject-matter experts and journalists via comparing the claims of an article with established facts and cross-checking with trusted and alternative sources. However, the high volume and velocity of information flow on such platforms render such manual approaches infeasible. Therefore, recent efforts of the stakeholders and the research community have been focused on automated techniques for classification and detection of fake news. A promising solution in this domain is to leverage the recent advances in machine learning and Natural Language Processing  to automated the processing and classification of the high-dimensional and complex text of news articles and posts . %We purpose a model where news article is classified by dividing the overall tasks into three parts: Style-Based Classification, Knowledge-Based Classification, and Propagation and Credibility-Based Classification. This paper is a focus on Style-based classification.  % %Machine learning  proven to useful in detecting fake news. The n-gram, part of speech tagging and probabilistic context free grammar were widely used in linguistic analysis before neural networks. Mihalcea and Strapparava  used n-gram approach for lie detection by  training Naive Bayes and Support Vector Machine  classifiers. They used crowd sourcing for creating their own datasets on three different topics, opinion on abortions, opinion on death penalty and feelings about best friend. They applied minimal pre-processing on the datasets with tokenization and stemming but without performing feature selection and stop words removal. They received the average accuracy of 70.8\% in NB and 70.1\% in SVM, %Ott et al.  trained a SVM classifiers using relative POS tag frequencies of texts as features. They found a probable relationship between deceptive spam and imaginative writing based on POS distributional similarities. %Feng et al.  investigated the syntactic stylometry for deception detection. They found that the features driven from Context Free Grammar parse trees improved the deception detection over Ott et al.    While the literature on the applications of machine learning to fake news classification has grown rapidly, the body of work on the classification of short-text claims remains relatively thin. This issue is of paramount importance, as many of the posts on social media such as Twitter contain only a short claim extracted from the longer text of news articles. The short form of such claims poses a challenge to the classification task, as it provides very limited information  and thus constrains the applicability of machine learning models trained on full-length articles and texts. Over the past few years, a number of datasets and models have been proposed for the classification of short-text claims, notable instances of which are the studies based on the LIAR dataset of short statements . However, the performance of machine learning models trained on this dataset remain at impractical levels, with the best accuracy values reported to be \~41.5\% . %  reported study  The problem with non neural network approach is that the news articles are longer in length and when using non neural network approach the semantic and syntactic features of the sentences cannot be extracted and exploited properly to full extent with non neural network approaches. The solution to this is neural network methods.  %Rashkin et al.  trained an LSTM model that takes sequence of words as the input and predicts the Politifact rating, and found it to be more accurate than NBC and Maximum Entropy models. They also concatenated LSTM output with Linguistic Inquiry and Word Count  features before undergoing the activation layers. The NBC and Maximum Entropy models are improved with LIWC but LSTM did not perform well. The reason might be that the LSTM can learn the in formations in LIWC by themselves. Wang  used deep learning based CNN model with LIAR dataset and found better results than the non-neural network methods.   %Qian et al.  proposed two models, the first one is Two-Level Convolutional Neural Network  a variant of CNN and second one is User Response Generator . The TCNN captured the semantic information from articles' text representing it at the sentence and word level. And URG learns a generative responses to news article text from historical user responses that assist in classification.  In this paper, we introduce Sentimental LIAR, which extends the LIAR dataset by including new features based on the sentiment and emotion analysis of claims. Our extended dataset also proposes a modified encoding of textual attributes to mitigate unintended bias in modeling. Furthermore, we propose a novel deep learning architecture based on the BERT-Base language model for the classification of claims as genuine or fake. Our results demonstrate that the proposed architecture trained on Sentimental LIAR can achieve an accuracy of 70\%, which is an improvement of ~30\% over previously reported results for the LIAR benchmark. The Sentimental LIAR dataset and the proof-of-concept code are made available on GitHub.  %In this paper, we present the series of experiments we performed using BERT-Base and the extended LIAR datasets and compare the results. The base BERT-Base model is modified by adding linear neural net on top and the other modification is done by adding CNN model on top. The modified models are tested with different version of LIAR datasets. We modified the LIAR dataset by extending it with sentiment score and sentiment of the statement. The other extension is done by adding the five emotions of the statement  The remainder of this paper is organized as follows: Section  presents the technical background and an overview of relevant datasets and literature on false claim classification. Section  describes the extended features of Sentimental LIAR, and details the proposed deep learning architectures for false claim detection. The experimental evaluation of our proposed techniques is reported in Section . Finally,  concludes the paper with a discussion on the results and remarks on future directions of work.       This work has proposed variational inference-based dropout regularization for RNNs with LSTM, GRU, and bi-directional LSTM/GRU cells. Contrary to the naive dropout regularization for embedding and decoding layers, the VI-based dropout regularization is applied to all RNN layers including recurrent layers by sharing the same dropout masks in the RNN layers. The experiments on the slot filling task on ATIS database showed that the variational RNN models obtain better results than the naive dropout regularization-based RNN models. In particular, the variational bi-directional LSTM/GRU obtains the best results in terms of F-measure.   \vfill\pagebreak       References should be produced using the bibtex program from suitable   BiBTeX files . The IEEEbib.bst bibliography   style file from IEEE produces unsorted bibliography list.   -------------------------------------------------------------------------    
"," The rampant integration of social media in our every day lives and culture has given rise to fast and easier access to the flow of information than ever in human history. However, the inherently unsupervised nature of social media platforms has also made it easier to spread false information and fake news. Furthermore, the high volume and velocity of information flow in such platforms make manual supervision and control of information propagation infeasible. This paper aims to address this issue by proposing a novel deep learning approach for automated detection of false short-text claims on social media. We first introduce Sentimental LIAR, which extends the LIAR dataset of short claims by adding features based on sentiment and emotion analysis of claims. Furthermore, we propose a novel deep learning architecture based on the BERT-Base language model for classification of claims as genuine or fake. Our results demonstrate that the proposed architecture trained on Sentimental LIAR can achieve an accuracy of 70\%, which is an improvement of ~30\% over previously reported results for the LIAR benchmark. %improve the previously reported accuracy of the task by     Focusing on the prevalent short-text format of claims on social media such as Twitter, our work   to an unprecedented challenge in  . Fake news is not only threatening to undermine democracy but equally has been proven to cause violence, disruption, and chaos in the world. Hence, in this research paper, we are going to use the machine learning approach to classify the fake news from the true ones. The rise of Natural Language Processing makes it possible to analyze the news articles. We are proposing a model composed of three perspectives. The first perspective is the Style Based Classification where we classify the article based on its intention is misleading or not, by analyzing the text pattern from the attribute-based and structure-based language features. The second perspective is Knowledge-based classification which is going to classify the news articles based on its authenticity by knowledge extraction and fact-checking. The third perspective is the Propagation and Credibility based classification by analyzing the propagation model of fake news and the credibility of the engaging users. This research paper currently focused on first perspective i.e. Style based classification by deception detection using deep neural networks where we performed experiments using LIAR Dataset by changing it into binary labels and BERT-Base.",32
"  The ever-growing amount of user-generated data on social media platforms be it Facebook, Twitter, blogs or any other electronic medium introduces new challenges in terms of automatic content moderation, especially regarding hate speech  and  offensive language detection. Not only is hate speech more likely to happen on the Internet,  where anonymity is easily obtained and speakers are psychologically distant from their audience, but its online nature also gives it a far-reaching and determinative impact. User content mostly consists of microposts, where the context of a post can be missing or inferred only from current events. Manual verification of each posting by a human moderator is infeasible due to the high amount of postings created every day. Consequently, automated detection of such attacking postings is the only feasible way to counter this kind of hostility. However, this task is challenging because natural language is fraught with ambiguities, and language in social media is extremely noisy. The classification system that would be prepared for the task, needed to be generalized for various test corpora as well. In this paper I have described the system consisting of a sequential pipeline with text feature extraction and classification as its main components. Firstly, a bag-of-words model is used for encoding the sentences into corresponding integer sequence. Thereafter, vectors are generated from these sequences and fed to a series of BiLSTM layers for training. Then a softmax layer is used for ternary classification into the corresponding offensive language categories.  The rest of the paper has been organized as follows. Section  describes the data, on which, the task was performed. The methodology followed is described in Section . This is followed by the results and concluding remarks in Section  and  respectively. % % The following footnote without marker is needed for the camera-ready % version of the paper. % Comment out the instructions  and uncomment the 8 lines % under ""final paper"" for your variant of English. %  %.     %      % % final paper: en-us version      %     %   % space normally used by the marker     % This work is licensed under a Creative Commons      % Attribution 4.0 International License.     % License details:     % \url{http://creativecommons.org/licenses/by/4.0/}. % }    This paper introduced Sentimental LIAR as an extension of the LIAR dataset, and proposed novel model architectures based on BERT-Base for fake claim detection in short text. The proposed architectures extend BERT-Base by adding  a feedforward neural network, or  a CNN. The LIAR dataset is extended by adding emotions anger, sad, fear, anger and disgust by using IBM NLP API and added sentiment score using Google NLP API. We also included speaker credit as an input attribute to our models.   The experiments performed with BERT-Base + feedforward NN, the accuracy ranged from 68.8\  to 69\  within the five experiments. These experiments were performed by changing the input structure in the first three experiments and by changing the hidden layers in the latter two experiments. A slight improvement of 1\  was observed in the accuracy and no improvements in the F1 Score. This suggests that the model may need to be revised to handle the complexity of the input data. Hence, a CNN-based architecture was investigated in our further experiments.   The experiments were performed with BERT-Base + CNN, the accuracy ranged from 68.82\  to 70\   within six experiments, and also major improvements were observed in the F1 Score . The best performing model is found to be one where the text attribute is fed directly into BERT-Base, and the output of BERT-Base is concatenated with the emotions, speaker's credit and sentiments before being passed to the CNN. Undeutsch hypothesis  and the four-factor theory  supported the intuition that the emotional and sentimental attributes can help to distinguish the fake claims, which can be verified by the observation of the model performing better when EMO and SEN were added. Adding the SEN and EMO with BERT-Base output supplemented the features which boosted the CNN model performance.   For both models, it can be observed that adding the metadata  increased the accuracy of model. Also, both the model accuracy and the F1 Score improved with the CNN-based architecture.   The training loss VS validation Loss graphs for BERT-Base + feedforward NN is given in Fig., and for BERT-Base + CNN in Fig.. These plots suggest that the models were overfitted only after 2 epochs, which is mostly due to the small size of the dataset. Also, it must be noted that the dataset is imbalanced, with 65\  of data labeled as false and only 35\  labeled as true. These observations demonstrate the need for the curation of larger and more representative datasets of short-text claims.  Furthermore, our results further verify that fake claims can be detected in short-text according to exaggerated expressions and strong emotions demonstrated in the text. The proposed architecture also sets a new state-of-the-art benchmark for fake claim classification on the LIAR dataset with an accuracy of 70\ .     
"," SemEval-2020 Task 12 was OffenseEval: Multilingual Offensive Language Identification in Social Media \cite{zampieri-etal-2020-semeval}. The task was subdivided into multiple languages and datasets were provided for each one. The task was further divided into three sub-tasks: offensive language identification, automatic categorization of offense types, and offense target identification. I have participated in the task-C, that is, offense target identification. For preparing the proposed system, I have made use of Deep Learning networks like LSTMs and frameworks like Keras which combine the bag of words model with automatically generated sequence based features and manually extracted features from the given dataset. My system on training on 25\% of the whole dataset achieves macro averaged f1 score of  47.763\%.",33
" The discourse structure of a document describes discourse relationships between its elements as a graph or a tree. Discourse parsing is largely dominated by greedy parsers~\cite[\eg.][]{braud2016multi,ji2014representation,yu2018transition,SogaardBC17}. Global parsing is rarer because the dependency between node's label and its internal split point can make prediction computationally prohibitive. % resulting in a large grammar constant. % This expense comes from the dependency relation % between the labels assigned to a node and the % split point that separates its children, which results in % a large constant for global inference in terms of time % complexity, making the inference process extremely slow.  In this work, we propose a CKY-based global parser with tractable inference using a new independence assumption that loosens the coupling between the identification of the best split point label prediction. % For a particular node, we first decide the split % point without considering the labels; and then based on the % split point, we make the decisions for the labels of % current node.   % However, when we apply recursion, the total score of this % node is the sum of scores of split point and label % assignments instead of recursing with the only split % score. % By making independence decisions for split point and label % assignment, we remove the large constant in terms of time % complexity;  and by recursing with the sum of all scores, % dependency relations are maintained. Doing so gives us the advantage that we can search for the best tree in a larger space. % One side effect of this % is that we do not need complex models to represent EDUs. Greedy discourse parsers have to use complex models to ensure each step is correct because the search space is limited. For example, \citet{ji2014representation}  manually crafted features and feature transformations to encode elementary discourse units ; \citet{yu2018transition} and \citet{braud2016multi} used multi-task learning for a better EDU representation. Instead, in this work, we use a simple recurrent span representation to build a parser that outperforms previous  global parsers.%  and is comparable to the state-of-art % greedy parsers.  Our contributions are:     %%% Local Variables: %%% mode: latex %%% TeX-master: ""main"" %%% End: % % File emnlp2019.tex % %% Based on the style files for ACL 2019, which were %% Based on the style files for EMNLP 2018, which were %% Based on the style files for ACL 2018, which were %% Based on the style files for ACL-2015, with some improvements %%  taken from the NAACL-2016 style %% Based on the style files for ACL-2014, which were, in turn, %% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009, %% EACL-2009, IJCNLP-2008... %% Based on the style files for EACL 2006 by  %%e.agirre@ehu.es or Sergi.Balari@uab.es %% and that of ACL 08 by Joakim Nivre and Noah Smith  \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{emnlp-ijcnlp-2019} \usepackage{times} \usepackage{latexsym} \usepackage{mlsymbols} \usepackage{mystyle} \usepackage{symbol} \usepackage{comment}  \usepackage{url}  \aclfinalcopy % Uncomment this line for the final submission  % \setlength\titlebox{5cm} % You can expand the titlebox if you need extra space % to show all the authors. Please do not make the titlebox % smaller than 5cm ; we will check this % in the camera-ready version and ask you to change it back.  \newcommand\BibTeX{B{\sc ib}\TeX} \newcommand\confname{EMNLP-IJCNLP 2019} \newcommand\conforg{SIGDAT}  \title{A Simple Global Neural Discourse Parser}  \author{     Yichu Zhou  \\     University of Utah \\     flyaway@cs.utah.edu \\\And%     Omri Koshorek \\     Tel-Aviv University \\     omri.koshorek@cs.tau.ac.il \\\AND%\\     Vivek Srikumar \\     University of Utah \\     svivek@cs.utah.edu \\\And%     Jonathan Berant \\     Tel-Aviv University\\     joberant@cs.tau.ac.il   }  \date{}     	 	We evaluated the embeddings of four transfer learning models on Mohler dataset  on the task of \ac{ASAG}. These transfer learning models  were explained breifly with their pretraining procedures. Besides, we also elucidated the \ac{ASAG} task's significance and it's applications. The sentence embeddings are created from all the selected four transfer learning models for all the desired and student answers of the dataset. The encoding of answers are related to the words in the answers, irrespective of their order. The cosine similarity feature was extracted for every student	answer and desired answer. This feature was trained with all the three isotonic, linear and ridge regression methods. 	 	\ac{ELMo} outperformed other transfer learning models on the task with a best \ac{RMSE} score of 0.978 and Pearson correlation of 0.485. With these results, \ac{ELMo} competed with the conventional word embeddings, such as Word2Vec, GloVe and FastText, without any preprocessing or multiple feature training. \ac{ELMo} performed comparatively better than other transfer learning models, \ac{BERT}, \ac{GPT} and GPT-2. These transfer learning models have exhibited poor results on the Mohler dataset compared to the conventional word embeddings. We also concluded that ELMo can achieve near to the state of the art results without any further training of domain-specific data or compelling preprocessing of data. 	 
","     Discourse parsing is largely dominated by     greedy parsers with manually-designed     features, while global parsing is rare due to its     computational expense.  In this paper, we propose a     simple chart-based neural discourse parser that does not     require any manually-crafted features and is based on     learned span representations only. To overcome the     computational challenge, we propose an independence     assumption between the label assigned to a node in the     tree and the splitting point that separates its children,     which results in tractable decoding. We empirically     demonstrate that our model achieves the best performance     among global parsers, and comparable performance to     state-of-art greedy parsers, using only learned     span representations.",34
"    Large-scale language model pretraining has become increasingly prevalent for achieving high performance on a variety of natural language processing  tasks. When applying these models to a specific task, they are usually fine-tuned using supervised learning, often to maximize the log probability of a set of human demonstrations.  % Fundamentally, these objectives weight every word equally and lack a humanimbued notion of what is most important to get right  and what is less important .   While this strategy has led to markedly improved performance, there is still a misalignment between this fine-tuning objective---maximizing the likelihood of human-written text---and what we care about---generating high-quality outputs as determined by humans.  This misalignment has several causes: the maximum likelihood objective has no distinction between important errors  and unimportant errors ; models are incentivized to place probability mass on all  human demonstrations, including those that are low-quality; and  distributional shift during sampling can degrade performance . Quality can often be improved significantly by non-uniform sampling strategies such as beam search , but these can lead to repetition and other undesirable artifacts .  Optimizing for quality may be a principled approach to overcoming these problems.    \footnotetext{Throughout the paper, error bars represent 1 standard error.}  Our goal in this paper is to advance methods for training language models on objectives that more closely capture the behavior we care about. To make short-term progress towards this goal, we focus on abstractive English text summarization, as it has a long history in the NLP community , and is a subjective task where we believe it is difficult to quantify summary quality without human judgments. Indeed, existing automatic metrics for evaluating summary quality, such as ROUGE , have received criticism for poor correlation with human judgments .    We follow the works of , who fine-tune language models from human feedback using reward learning . We first collect a dataset of human preferences between pairs of summaries, then train a reward model  via supervised learning to predict the human-preferred summary. Finally, we train a policy via reinforcement learning  to maximize the score given by the RM; the policy generates a token of text at each `time step', and is updated using the PPO algorithm  based on the RM `reward' given to the entire generated summary. We can then gather more human data using samples from the resulting policy, and repeat the process. We follow the works of  and use large pretrained GPT-3 models with as many as 6.7 billion parameters.    \iffalse  \footnotetext{Throughout the paper, error bars represent 1 standard error.} \fi  Our main contributions are four-fold.   We show that training with human feedback significantly outperforms very strong baselines on English summarization. When applying our methods on a version of the Reddit TL;DR dataset , we train policies via human feedback that produce better summaries than much larger policies trained via supervised learning. Summaries from our human feedback models are preferred by our labelers to the original human demonstrations in the dataset .    We show human feedback models generalize much better to new domains than supervised models. Our Reddit-trained human feedback models also generate high-quality summaries of news articles on the CNN/DailyMail  dataset without any news-specific fine-tuning, almost matching the quality of the dataset閳ユ獨 reference summaries. We perform several checks to ensure that these human preferences reflect a real quality difference: we consistently monitor agreement rates amongst labelers and researchers, and find researcher-labeler agreement rates are nearly as high as researcher-researcher agreement rates , and we verify models are not merely optimizing simple metrics like length or amount of copying .    We conduct extensive empirical analyses of our policy and reward model. We examine the impact of model and data size , study performance as we continue to optimize a given reward model , and analyze reward model performance using synthetic and human-written perturbations of summaries . We confirm that our reward model outperforms other metrics such as ROUGE at predicting human preferences, and that optimizing our reward model directly results in better summaries than optimizing ROUGE according to humans .   We publicly release our human feedback dataset for further research. The dataset contains 64,832 summary comparisons on the TL;DR dataset, as well as our evaluation data on both TL;DR  and CNN/DM .   \iffalse \paragraph{Main result.} When applying our methods on a version of the Reddit TL;DR dataset , we train policies via human feedback that produce better summaries than much larger policies trained via supervised learning. Summaries from our human feedback models are preferred by our labelers to the original human demonstrations in the dataset .  These Reddit-trained human feedback models also generate high-quality summaries of news articles on the CNN/DailyMail  dataset without any further fine-tuning, almost matching the quality of the dataset閳ユ獨 reference summaries. We perform several checks to ensure that these strong human preferences reflect a real quality difference: we consistently monitor agreement rates amongst labelers and researchers, and find researcher-labeler agreement rates are nearly as high as researcher-researcher agreement rates , and we verify models are not merely optimizing simple metrics like length or amount of copying .   % we've performed our own qualitative evaluations of policy outputs that agree with worker judgments ; and we've spot-checked some surprising conclusions, such as extractive baselines outperforming human-written summaries on CNN/DM, and found that worker judgments seemed reasonable .   \paragraph{Additional analysis.} We also examine the impact of model and data size , study performance as we continue to optimize a given reward model , analyze reward model performance using synthetic and human-written perturbations of summaries , and confirm that our reward model outperforms other metrics such as ROUGE at predicting human preferences . \fi  The methods we present in this paper are motivated in part by longer-term concerns about the misalignment of AI systems with what humans want them to do. When misaligned summarization models make up facts, their mistakes are fairly low-risk and easy to spot. However, as AI systems become more powerful and are given increasingly important tasks, the mistakes they make will likely become more subtle and safety-critical, making this an important area for further research.       In this work, we propose a new independence assumption for global inference of discourse parsing, which makes globally optimal inference feasible for RST trees.  By using a global inference, we develop a simple neural discourse parser. Our experiments  show that the simple parser can achieve comparable performance to state-of-art parsers using only learned span representations. 
","   As language models become more powerful, training and evaluation are increasingly bottlenecked by the data and metrics used for a particular task. %, rather than by model understanding.   For example, summarization models are often trained to predict human reference summaries and evaluated using ROUGE, but both of these metrics are rough proxies for what we really care about---summary quality. In this work, we show that it is possible to significantly improve summary quality by training a model to optimize for human preferences.  We collect a large, high-quality dataset of human comparisons between summaries, train a model to predict the human-preferred summary, and use that model as a reward function to fine-tune a summarization policy using reinforcement learning. We apply our method to a version of the TL;DR dataset of Reddit posts \cite{volske2017tl} and find that our models significantly outperform both human reference summaries and much larger models fine-tuned with supervised learning alone. Our models also transfer to CNN/DM news articles \cite{hermann2015teaching}, producing summaries nearly as good as the human reference without any news-specific fine-tuning.\footnote{Samples from all of our models can be viewed \href{https://openaipublic.blob.core.windows.net/summarize-from-feedback/website/index.html}{on our website}.}    We conduct extensive analyses to understand our human feedback dataset and fine-tuned models.\footnote{We provide inference code for our 1.3B models and baselines, as well as a model card and our human feedback dataset with over 64k summary comparisons,  \href{https://github.com/openai/summarize-from-feedback}{here}.}   We establish that our reward model generalizes to new datasets, and that optimizing our reward model results in better summaries than optimizing ROUGE according to humans.   We hope the evidence from our paper motivates machine learning researchers to pay closer attention to how their training loss affects the model behavior they actually want.",35
"  Language models that exhibit one- or few-shot learning are of growing interest in machine learning applications because they can adapt their knowledge to new information . One-shot language learning in the physical world is also of interest to developmental psychologists; fast-mapping, the ability to bind a new word to an unfamiliar object after a single exposure, is a much studied facet of child language learning . Our goal is to enable an embodied learning system to perform fast-mapping, and we take a step towards this goal by developing an embodied agent situated in a 3D game environment that can learn the names of entirely unfamiliar objects in a single exposure, and immediately apply this knowledge to carry out instructions based on those objects. The agent observes the world via active perception of raw pixels, and learns to respond to linguistic stimuli by executing sequences of motor actions. It is trained by a combination of conventional RL and predictive  learning.   We find that an agent architecture consisting of standard neural network components is sufficient to follow language instructions whose meaning is preserved across episodes. However, learning to fast-map novel names to novel objects in a single episode relies on semi-supervised prediction mechanisms and a novel form of  external memory, inspired by the dual-coding theory of knowledge representation . With these components, an  agent can exhibit both slow word learning and fast-mapping. Moreover, the agent exhibits an emergent propensity to integrate both fast-mapped and slowly acquired word meanings in a single episode, successfully executing instructions such as ``put the dax in the box"" that depend on both slow-learned  and fast-mapped  word meanings.   %An embodied learning system that executed fast-mapping with the same flexibility as the best large-scale text-based language models could lead to similarly improved human-agent interaction between users and game-based agents, virtual-reality avatars or robotic assistants.     Via controlled generalization experiments, we find that the agent is reasonably robust to a degree of variation in the number of objects involved in a given fast-mapping task at test time. The agent also exhibits above-chance success when presented with the name for a particular object in the ShapeNet taxonomy  and then instructed  to interact with a different exemplar from the same object class, and this propensity can be further enhanced by specific meta-training. We find that both the number of unique objects observed by the agent during training and the temporal aspect of its perceptual experience of those objects contribute critically to its ability to generalize, particularly its ability to execute fast-mapping with entirely novel objects. Finally, we show that a dual-coding memory schema can provide a more effective basis to derive a signal for intrinsic motivation than a more conventional  memory.   %Equipped with this intrinsic curiosity, an agent can resolve long episodes requiring fast-binding when there are no intermediate environment rewards to stimulate the requisite information discovery.        \paragraph{Limitations.} One limitation of our work is the time and cost required to produce our final models. Notably, fine-tuning our 6.7B model with RL required approximately 320 GPU-days.   This has an adverse effect on the environment as has been previously noted in .  Our data collection procedure is also expensive compared to prior work ---    the training set costing \textasciitilde \\mathrm{exp} \approx 1.6\mathcal{N})\gamma = 1\lambda = 0.95\pm\pm\pm\pm\pmr\beta\log - \frac{n - 1}{n}T=0$, further indicating that ROUGE correlates poorly with human preferences.  For supervised models, lowering temperature has a larger impact than increasing model size.  Interestingly, at higher temperatures, our feedback models actually outperform supervised counterparts .  On CNN/DM, ROUGE agrees with our human evaluations that our human feedback models transfer better than our supervised models.  However, unsurprisingly, supervised CNN/DM models still achieve much higher ROUGE.  In Table, we show the ROUGE results on CNN/DM for our 6.7B supervised baseline and various models from the literature. We find that our model achieves ROUGE scores less than T5 , but slightly greater than the CNN-2sent-hieco-RBM model from , which was SOTA for abstractive summarization on CNN/DM in mid-2019 according to the NLP-progress leaderboard.        In Table, we show the bigram overlap statistics for our models on the TL;DR and CNN/DM datasets as a proxy for how much the summaries copy frmo the post. As in Section, we compute the longest common subsequence of bigrams with the original Reddit post or news article, and dividing by the number of bigrams in the summary. We find that models evaluated on CNN/DM  generally copy more than models evaluated on TL;DR. Further, our supervised and human feedback models copy less than our pretrained models.                                      \caption{Qualitative examples showing the change in reward of the reward model on human-generated edits to TL;DR summaries that make the summaries better. Examples are randomly selected from the set where the edit distance was less than 5 and the magnitude of change in reward was greater than 0.5. Text in strike-through was removed from the original summary in the edit, and text in bold was added. The reward model is sensitive to small but semantically meaningful changes in the summary, although it makes errors on occasion. }              We are interested in understanding the relationship between different metrics for evaluating summaries. To do this, we compute agreement between various metrics, including automatic metrics and humans, for different subsets of the data for which we have human evaluations. To remove policy quality as a confounding variable, all of the summary comparisons are generated by the same policy at the same temperature value. In Table, we use samples from our 1.3B supervised model at T=0.7 on TL;DR; Table has comparisons from our 6.7B supervised model at T=0.7 on TL;DR; Table has comparisons from our 6.7B human feedback model at T=0.7 on TL;DR; and Table has comparisons from our 6.7B supervised baseline trained on CNN/DM.    Our 6.7B reward model generally agrees with labelers as much as other labelers, although an ensemble of labelers does better.  On the other hand, ROUGE generally has poor agreement, as does log probability under the supervised baselines, with simple heuristics like copying  and length often performing comparably.     python reflection/x/jeffwu/merge_agreement_matrix.py cnndm --latex | pbcopy      \section{Samples}     Here we provide non-cherry-picked samples and human evaluations for various models. In Tables- we show samples on the TL;DR dataset, and in Tables- we show samples on the CNN/DM dataset . See  \href{https://openaipublic.blob.core.windows.net/summarize-from-feedback/website/index.html}{our website} for more uncurated policy samples.                 \caption{An example of a difficult comparison task on the TL;DR dataset. Summary A makes it sound like the author was watching basketball on TV and kicked his PC out of anger, whereas Summary B sounds like the game just froze up, rather than the author being responsible for the GPU being dead.  }               We show examples of samples from a policy overoptimized to rm3. The summaries, while clearly long, low quality, and full of idiosyncrasies, do still reflect the rough gist of the post.     
"," Recent work has shown that large text-based neural language models acquire a surprising propensity for one-shot learning. Here, we show that an agent situated in a simulated 3D world, and endowed with a novel dual-coding external memory, can exhibit similar one-shot word learning when trained with conventional RL algorithms. After a single introduction to a novel object via visual perception and language , the agent can manipulate the object as instructed , combining short-term, within-episode knowledge of the nonsense word with long-term lexical and motor knowledge. We find that, under certain training conditions and with a particular memory writing mechanism, the agent's one-shot word-object binding generalizes to novel exemplars within the same ShapeNet category, and is effective in settings with unfamiliar numbers of objects. We further show how dual-coding memory can be exploited as a signal for intrinsic motivation, stimulating the agent to seek names for objects that may be useful later. Together, the results demonstrate that deep neural networks can exploit meta-learning, episodic memory and an explicitly multi-modal environment to account for fast-mapping, a fundamental pillar of human cognitive development and a potentially transformative capacity for artificial agents.",36
"   Emphasis selection is an emerging research problem  in the natural language processing domain, which involves automatic identification of words or phrases from a short text that would serve as good candidates for visual emphasis. This research is most relevant to visual media such as flyers, posters, ads, and motivational messages where certain words or phrases can be visually emphasized with the use of different color, font, or other typographic features. This type of emphasis can help with expressing an intent, providing more clarity, or drawing attention towards specific information in the text. Automatic emphasis selection is therefore useful in graphic design and presentation applications to assist users with appropriate choice of text layout.   Prior works in speech processing  have modeled word-level emphasis using acoustic and prosodic features. Understanding emphasis in speech is critical to many downstream applications such as text-to-speech synthesis , speech-to-speech translation , and computer assisted pronunciation training . In computational linguistics, emphasis selection is very closely related to the problem of keyphrase extraction . Keyphrases typically refer nouns and noun-phrases that capture the most salient topics in long documents such as scientific articles , news articles , web pages , etc. In contrast, emphasis selection deals with very short texts , and also emphasis could be applied to words belonging to various parts of speech.  The goal of SemEval 2020 - Task 10 is to design methods for automatic emphasis selection in short texts. To this end, the organizers  provided a dataset consisting of over 3,000  sentences annotated for token-level emphasis by multiple annotators. The authors employed the standard I-O tagging schema, which is widely used in annotation of token-level tags. We approached emphasis selection as a sequence labeling task solved using a Bidirectional Long Short-term Memory  model, where the individual tokens are represented using various contextual embedding models. We also employ label distribution learning   approach, which elegantly accounts for disagreements between the annotators.     In this paper, we have proposed a novel context-guided capsule network  for MMT. As a significant extension of the conventional capsule network,  DCCN utilizes the timestep-specific source-side context vector to dynamically guide the extraction of visual features at different timesteps, where the semantic interactions between modalities can be fully exploited for MMT via context-guided dynamic routing mechanism. Moreover, we employ DCCN to extract visual features in two complementary granularities: global visual features and regional visual features, respectively.   In English-to-German MMT task,   our model finally achieves +XXX improvement on BLEU, +XXX on METEOR and -XXX on TER. Experimental results on English-to-German and English-to-French MMT tasks strongly demonstrate the effectiveness of our model.  In the future,  we plan to apply DCCN to other multimodal tasks such as visual question answering and multimodal text summarization.   
"," This paper presents our submission to the SemEval 2020 - Task 10 on emphasis selection in written text. We approach this emphasis selection problem as a sequence labeling task where we represent the underlying text with various contextual embedding models. We also employ label distribution learning to account for annotator disagreements. We experiment with the choice of model architectures, trainability of layers, and different contextual embeddings. Our best performing architecture is an ensemble of different models, which achieved an overall matching score of 0.783, placing us 15th out of 31 participating teams. Lastly, we analyze the results in terms of parts of speech tags, sentence lengths, and word ordering. \blfootnote{*Authors contributed equally.}",37
"  The COVID-19 pandemic urged various science disciplines to do their best so as to contribute to understanding and relieving its impact. Thus, scholars and practitioners working on information sciences have been dedicating significant effort to help. Collecting and analyzing data published on social media platforms have become the focus in this respect. We joined the community that aims at organizing data collected from social media , as informative and uninformative. The WNUT-2020 Task 2 considers tweets about recovered, suspected, confirmed and death cases as well as location or travel history of the cases as informative. All other tweets are considered to be uninformative. The organizers did not share an annotation manual nor was a baseline system made available, presumably to prevent use of any other manually annotated data and to encourage broad participation respectively.\footnote{\url{http://noisy-text.github.io/2020/covid19tweet-task.html}, accessed on September 4, 2020.}  The effort was managed in terms of a shared task, in which the organizers share a dataset that consists of annotated tweets and conduct the evaluation of the submissions. The task requires the participating teams to develop short-text classification systems that facilitate the training and development data to generalize to the test set they release. Although the gold labels of the training and development data were available to the participants, neither the gold labels of the test data nor the annotation guidelines for any part of the data were shared with the participants. Moreover, the test instances were unknown to the participating teams. They were hidden in a larger dataset. Each team was allowed to submit only two outputs of the systems they developed for classifying tweets on the Codalab page of the task.\footnote{\url{https://competitions.codalab.org/competitions/25845}, accessed on September 4, 2020.} The highest score in terms of F1 positive class of each team was used to rank them in the leaderboard.  Integrating automatically created machine learning based  models with manually formulated rules to tackle a text classification task promises the best of both worlds. We pursued this goal by integrating the output of two deep learning models and a rule-based system under the team name COVCOR20. Although the integration slightly improves the total performance on the training and development sets in a cross-validation setting, the overall performance on the test data turned out to be slightly worse than our best ML system. Our best submission was ranked 22nd among 55 teams. The integration of our systems would be ranked 27th if its score were used as the final score for our team.  The deep learning models and the rule-based system are introduced in Sections and respectively. Next, the Section describes how we integrate the output of these systems. Then Section provide the results and their discussion. Finally, we conclude this report and share our future plans continuing in this line of research in Section.    We undertook a comprehensive concept identification and network analysis for COVID-19. We demonstrated the use of a novel concept recognition and relationship discovery engine that crafts some of the latest advances in natural language processing into a state-of-the-art solution for biomedical entity recognition and relationship discovery problem. Several new drugs were uncovered through the studies and many different treatment modalities were brought to the surface. We envision these solutions to have a wide ranging impact through the length and breadth of drug discovery process spanning all therapeutic areas.     
"," In the scope of WNUT-2020 Task 2, we developed various text classification systems, using deep learning models and one using linguistically informed rules. While both of the deep learning systems outperformed the system using the linguistically informed rules, we found that through the integration of  the three systems a better performance could be achieved than the standalone performance of each approach in a cross-validation setting. However, on the test data the performance of the integration was slightly lower than our best performing deep learning model. These results hardly indicate any progress in line of integrating machine learning and expert rules driven systems. We expect that the release of the annotation manuals and gold labels of the test data after this workshop will shed light on these perplexing results.",38
"      The phenomenon of combining two or more languages in the same message is known as code-switching or code-mixing . Code-switching is an indicator of bilingual competence  , and it is also motivated by social and cultural factors such as social status, race, age, etc. . %   Instead of consider it as an indicator of lack of competence , there are cultural and social factors which motivate its study . Although this phenomenon has been studied extensively in linguistics , it is still challenging for machines to process mixed natural languages. Code-switching is notoriously present on social media posts and chats such as Twitter, Facebook or WhatsApp;  consequently making it more difficult to process the sentiment expressed in such contents. %Multilingual people, who are non-native English speakers, tend to code-mix using English-based phonetic typing and the insertion of anglicisms in their main language.  %In addition to mixing languages at the sentence level, it is fairly common to find the code-mixing behavior at the word level.  %This linguistic phenomenon cannot be tackled with conventional NLP systems, which are based on monolingual resources to handle the combination of multiple languages.   %Statistics show that half of the messages on Twitter are in a language other than English. This evidence suggests that other languages, including multilingualism and code-mixing, need to be considered by the NLP community. % \hl{Statistics show how used is code switching on social media}   In this work, we present a Convolutional Neural Network  system to predict the sentiment of a given code-mixed tweet. The sentiment labels are either positive, negative, or neutral, and the languages involved are English and Spanish. Our best model utilizes only Spanish word embeddings from tweets  and does not require manual feature engineering.  %  Before classification, English texts were normalized to anonymize some entities, label stylistic patterns, and transform words to tackle some typical issues of the texts on Twitter.  %  We highlight the contributions of this work as follows:  %    %This paper is structured into six different sections. Section 2 contains the dataset description. As for section 3, contains the literature review that presents the existing related work on code-mixing. Section 4 depicts our methodology. Section 5 is devoted to the presentation and discussion of our experimental results. Finally, our recommendations for future research opportunities along with the conclusion are reported in section 6.   % ======================== Article section        \section{Conclusion and future work}     NO: hyphens are only used if in state of the art is used as a premodifying adjective   We have presented our effort in the scope of a shared task that aims at pushing the state of the art for classifying short-texts , as informative or uninformative.   We could extend the training set with cluster mining using Relevancer, use the rule-based system to extend the training set, or use the rule-based system to generate fine-grained data that can be used in a multi-task setting.    \section*{Acknowledgements} The authors from Ko鑾 University are funded by the European Research Council  Starting Grant 714868 awarded to Dr. Erdem Y鏋歳鐪塳 for his project Emerging Welfare.          
"," %   Code-switching is a phenomenon in which two or more languages are used in the same message. Nowadays, it is quite common to find messages with languages mixed in social media. This phenomenon presents a challenge for sentiment analysis. % forcing the models to use a mix of language resources. In this paper, we use a standard convolutional neural network model to predict the sentiment of tweets in a blend of Spanish and English languages. Our simple approach achieved a F1-score of $0.71$ on test set on the competition. We analyze our best model capabilities and perform error analysis to expose important difficulties for classifying sentiment in a code-switching setting.",39
"  .     %      % % final paper: en-us version      %        % space normally used by the marker      This work is licensed under a Creative Commons       Attribution 4.0 International License.      License details:      \url{http://creativecommons.org/licenses/by/4.0/}. }   Emphasis selection for written text in visual media is proposed by  and . The purpose of this shared task is to design automatic methods for emphasis selection, i.e. choosing candidates for emphasis in short written text, to enable automated design assistance in authoring. For example,  mentions that such a technique can be applied to some graphic design applications such as Adobe Spark to perform automatic text layout using templates that include images and text with different fonts and colors. The major challenge is that given only thousands of annotated short text data without any context about the text or visual background images, we are asked to learn the author- or domain-specific emphatic about the short text. Besides, these short text data are annotated by crowd-sourcing workers. And we find that different annotators have different standards, which increases the difficulty of this task.   To identify the most important words, we model the task as a sequential labeling problem. Our base models leverage different unsupervised language model such as ERNIE 2.0 , XLM-ROBERTA , ROBERTA  and ALBERT . These large unsupervised models are pre-trained on a large amount of unannotated data and carry valuable lexical, syntactic, and semantic information in training corpora. Our approach is as follows: firstly, the word-level output representations for the sentence are computed by pre-trained models and then fed into a designed downstream neural network for word selections; secondly, we finetune the downstream networks together with the pre-trained models on the annotated training data; thirdly, we investigate several different objective functions to learn our model; and finally, we apply feature engineering and several data augmentation strategies for further improvement.   The rest of the paper is organized as follows. In Section , we will briefly overview some related works to our system. Section  shows the details of our approach. Our experiments will be shown in Section , and Section  concludes.     Code-switching is an interesting problem holding an important presence in social media, which combined with informal writing style increases the challenges for social media processing such as sentiment analysis.  We experimented with the Sentimix Spanglish dataset using CNN model and only Spanish embeddings. We achieve a precsion, recall, and F1 score of 0.80, 0.64, and 0.71 respectively.    reporting good enough results for the competition .  Our analyses suggest that a deep learning model can be easily biased by the presence of cue words such as vulgar expressions for sentiment analysis. We found that this occurs mostly when the cue word is in English. This observation requires a deeper analysis.    \hl{the hard general ization contrast even more in a code-switching scenario}.  We also highlight the need to address complex language usage such as informality and sarcasm.       as well as dealing with messages involving extralinguistic information which usually needs world knowledge understanding for being processed.  Furthermore, we also pointed out that subjectivity in the annotation of sentiment labels is a problem that deserves to be addressed.  We plan to test contextual multilingual embeddings  and leverage the language tags and other non-linguistic constructs such as hashtags and emojis.            ======================== Article section   Do not include this section when submitting your paper for review.   
","   This paper describes the system designed by ERNIE Team which achieved the first place in SemEval-2020 Task 10: Emphasis Selection For Written Text in Visual Media. Given a sentence, we are asked to find out the most important words as the suggestion for automated design. We leverage the unsupervised pre-training model and finetune these models on our task. After our investigation, we found that the following models achieved an excellent performance in this task: ERNIE 2.0, XLM-ROBERTA, ROBERTA and ALBERT. We combine a pointwise regression loss and a pairwise ranking loss which is more close to the final $Match_{m}$ metric to finetune our models. And we also find that additional feature engineering and data augmentation can help improve the performance. Our best model achieves the highest score of 0.823 and ranks first for all kinds of metrics.",40
"  The 2020 edition of Workshop on Noisy User-generated Text  hosted a shared task on `Identification of Informative COVID-19 English Tweets'. The task involves automatically identifying whether an English Tweet related to the novel coronavirus  is `informative' or not. For a tweet to be considered informative in this context, it should provide information about recovered, suspected, confirmed, and death cases as well as location or travel history of the cases. The goal for developing such an automated system is to help track the development of the COVID-19 outbreak and to provide users the information related to the virus, e.g. any new suspicious/confirmed cases near/in the users' regions.  Aligned with the goals of this shared task, our paper details the use of state-of-the-art natural language processing techniques for this task. %to identify informative tweets that are related to COVID-19.  We experiment with a variety of methods, ranging from feature-based classifiers to leveraging recent advances in pre-trained neural architectures . To further improve performance, we incorporate unlabelled tweets released on COVID-19 via masked language modelling and pseudo-labelling techniques. Our best performing model is an ensemble that uses Logistic Regression to combine the output probabilities of several base classifiers . We further analyze the impact of pre-processing and semi-supervision through ablation studies. Through our qualitative adversarial analysis, we show how the predictions of BERT model are sensitive towards specific tokens such as `confirmed case' or even locations and numerals, which also guides our data pre-processing steps.     In this paper, we present our system that ranks first in SemEval-2020 Task 10. Our solution contains several strategies and we provide detailed experiments to analyze which of them are effective. Our experiments show that models empowered by pre-trained language models are most effective, especially for ERNIE 2.0. Besides, lexical features, pairwise loss, and data augmentation can also bring improvement for some of our models.     include your own bib file like this: 
"," We describe our system for WNUT-$2020$ shared task on the identification of informative COVID-19 English tweets. Our system is an ensemble of various machine learning methods, leveraging both traditional feature-based classifiers as well as recent advances in pre-trained language models that help in capturing the syntactic, semantic, and contextual features from the tweets. We further employ pseudo-labelling to incorporate the unlabelled Twitter data released on the pandemic. Our best performing model achieves an F1-score of $0.9179$ on the provided validation set and $0.8805$ on the blind test-set.",41
" Text classification is an important problem in natural language processing . The task is to assign a document to one or more predefined categories. It has a wide range of applications such as sentiment analysis~, topic categorization~, and email filtering~. Early machine learning approaches for text classification were based on the extraction of bag-of-words features followed by a supervised classifier such as na\""ive Bayes~ or a linear SVM~. Later, better word representations were introduced, such as latent semantic analysis~, skipgram~, and fastText~, which improved classification accuracy. Recently, recurrent and convolutional neural network~ models were introduced to utilize the word order and grammatical structure. Many complex variations of these models have been proposed to improve the text classification accuracy, e.g. training one-hot CNN  or one-hot bidirectional LSTM  network with dynamic max-pooling .  Current state-of-the-art approaches for text classification involve using pretrained LSTMs  or complex computationally intensive models . DL15 argued that randomly initialized LSTMs are difficult to optimize and can lead to worse performance than linear models. Therefore, to improve the performance, they proposed pretraining the LSTM with either a language model or a sequence auto-encoder. However, pretraining or using complicated models can be very time consuming, which is a major disadvantage and may not be always feasible. In this paper, we consider a BiLSTM classifier model similar to the one proposed by DL15 for text classification. For this simple BiLSTM model with pretrained embeddings, we propose a training strategy that can achieve accuracy competitive with the previous purely supervised models, but without the extra pretraining step. We also perform ablation studies to understand aspects of the proposed training strategy that result in an improvement.  Pretraining approaches often use extra unlabeled data in addition to the labeled data.  We explore the applicability of such semi-supervised learning  in our training framework, where there is no prior pretraining step. In this regard, we propose a mixed objective function for SSL that can utilize both labeled and unlabeled data to obtain further improvement in classification. To summarize, our contributions are as follows:      In this paper, we describe our system to identify informative COVID-19 English tweets. We find that an ensemble model which uses a logistic regression to combine the predictions of a variety of feature-based to neural methods achieves the best performance on the shared task. Our analysis shows that incorporating unlabelled tweets results in consistent performance gains. We show how the trained model can be sensitive to specific tokens in the tweets, and hence, advice for exercising caution while deploying machine learning models for downstream monitoring applications.          
"," \begin{quote}     In this paper, we study bidirectional LSTM network for the task of text classification using both supervised and semi-supervised approaches. Several prior works have suggested that either complex pretraining schemes using unsupervised methods such as language modeling or complicated models are necessary to achieve a high classification accuracy. However, we develop a training strategy that allows even a simple BiLSTM model, when trained with cross-entropy loss, to achieve competitive results compared with more complex approaches. Furthermore, in addition to cross-entropy loss, by using a combination of entropy minimization, adversarial, and virtual adversarial losses for both labeled and unlabeled data, we report state-of-the-art results for text classification task on several benchmark datasets. In particular, on the ACL-IMDB sentiment analysis and AG-News topic classification datasets, our method outperforms current approaches by a substantial margin. We also show the generality of the mixed objective function by improving the performance on relation extraction task.\footnote{\mycodeurl} \end{quote}",42
"  Coreference resolution aims at identifying all the expressions that refer to the same entity in a text.  It helps to derive the correct interpretation of a text by binding antecedents  with their pronouns together and recognizing the syntactic relationship among them. The coreference resolution is considered as a critical preprocessing step for various high-level natural language processing  tasks including document summarization, question answering, and information extraction .   Existing coreference resolution approaches can be divided into two major categories: mention-pair models  and entity-mention models . One of the main shortcomings of the mention-pair model is making each coreference decision without entity-level information. Moreover, the lack of information about the preceding clusters may result in contradictory links. The entity-mention model tries to make use of the non-local information by encouraging the sharing of features across all mentions that point to the same real-world entity. However, the coreferent mentions usually spread far apart in a text, which makes it extremely difficult to define effective global features.    Previous studies either count on the long-term memory  or their variants to implicitly capture the global features   or seek to incorporate the features of the clusters already formed to determine whether a mention is coreferent with a preceding cluster . The former might miss out some important features for specific pairwise predictions without the help of the explicit entity-level features, while the latter may suffer from error propagation as false clusters are used to create entity-level features when making future predictions.  Taking the text of ``On November 3, 1992, Clinton was elected the 42nd president of the United States, and the following year Hillary Clinton became the first lady. In 2013, he won the Presidential Medal of Freedom."" as an example, we assume that three mentions ``Clinton"", ``Hillary Clinton"", and ``he"" have been well identified. The traditional mention-pair model is very likely to group these three mentions into a cluster as shown in Figure  since ``Clinton"" and ``Hillary Clinton"" share the same surname, and ``he'' agrees with ``Clinton"" both in gender and number.  To make use of information about the clusters already formed, recent studies try to better represent the current mention by incorporating the features derived from the preceding cluster it will most probably join .  However, those methods only allow such information to be shared in a forward fashion, i.e., from antecedent expressions to postcedent ones, and are prone to reaching the results as shown in Figure  and .  The reason is that once ``Hillary Clinton'' is merged with ``Clinton'' to form a cluster, the pronoun ``he'' either joins the formed cluster or begins a new one by itself.  Even though these errors might be recovered by using a proper decoding algorithm at test time, such as the maximum spanning tree algorithm, similar errors cannot be completely eliminated.  If such information can be shared iteratively in both forward and backward ways, the disagreement in gender between ``Hillary Clinton'' and ``he'' will be detected when the representation of ``Clinton'' is updated by its two possible co-references, which helps to find the correct result as Figure .  Recently, graph neural network  has gained increasing popularity due to its ability in modeling the dependencies between nodes in a graph . For the coreference resolution, mentions are linked to each other via the edges modeling how likely two linked mentions refer to the same entity. The features between nodes  can be shared in each direction with message passing or neighborhood aggregation in an iterative way. We found the entity-centric features can be well captured by GNN, achieving close to state-of-the-art performance.  To avoid contradictory links in mention clustering results, we propose to use a variant of the maximum spanning tree algorithm, second-order decoding algorithm instead of the traditional greedy search algorithm  and the beam search algorithm .  We factorize the score of a tree into the sum of its arc-pair scores.  A pair of arcs link three different mentions, and the connected mentions can be viewed as a small cluster.  Our global inference algorithm up to second-order features helps to define powerful entity-level features between clusters of mentions by aggregating the scores of those small clusters.   Traditional coreference resolution methods usually include three successive steps: mention detection, candidate pair generation, and mention clustering .  However, recent studies  show that joint solutions usually lead to improved performance over pipelined systems by avoiding error propagation. We follow the line of these research and formulate coreference resolution in a joint manner.  Our contributions are summarized as follows:  graph neural networks are introduced to perform coreference resolution, which aims to better leverage the entity-centric information by encouraging the sharing of features across all mentions that refer to the same entity;   a global inference algorithm up to second-order features is presented to optimally cluster mentions into consistent groups;   we show our GNN-based method combing with the second-order decoding algorithm achieved close to state-of-the-art performance on the CoNLL-2012 coreference resolution benchmark.       We show that a simple BiLSTM model using maximum likelihood training can result in a competitive performance on text classification tasks without the need for an additional pretraining step. Also, in addition to maximum likelihood, using a combination of entropy minimization, adversarial, and virtual adversarial training, we report state-of-the-art results on several text classification datasets. This mixed objective function also generalizes well to other tasks such as relation extraction where it outperforms current best models.  \small  
"," One of the major challenges in coreference resolution is how to make use of entity-level features defined over clusters of mentions rather than mention pairs. However, coreferent mentions usually spread far apart in an entire text, which makes it extremely difficult to incorporate entity-level features. We propose a graph neural network-based coreference resolution method that can capture the entity-centric information by encouraging the sharing of features across all mentions that probably refer to the same real-world entity. Mentions are linked to each other via the edges modeling how likely two linked mentions point to the same entity.  Modeling by such graphs, the features between mentions can be shared by message passing operations in an entity-centric manner. A global inference algorithm up to second-order features is also presented to optimally cluster mentions into consistent groups. Experimental results show our graph neural network-based method combing with the second-order decoding algorithm  achieved close to state-of-the-art performance on the English CoNLL-2012 Shared Task dataset.",43
" Encoding linguistic units such as words, phrases or sentences into low-dimensional vectors has been the core and preliminary task for deep learning of natural language. The current language representation learning is usually done in different individual levels, typically, word or sentence. The former includes pioneering works such as word2vec, GloVe and fastText , and the latter includes the very recent so-called contextualized representations such as ELMo, GPT, BERT, XLNet and ELECTRA . Nevertheless, few works were done to uniformly learning and representing linguistic units in different hierarchies in the same vector space. Actually, nearly all existing work still focus on individual granular language unit for representation learning .  However, universal representation among different levels of linguistic units may offer a great convenience when it is needed to handle free text in language hierarchy in a unified way. As well known that, embedding representation for a certain linguistic unit  enables linguistics-meaningful arithmetic calculation among different vectors, also known as word analogy. For example, vector  - vector  + vector  results in vector . Thus universal representation may generalize such good analogy features or meaningful arithmetic operation onto free text with all language levels involved together. For example, Eat an onion : Vegetable :: Eat a pear : Fruit.   In this paper, we explore the regularities of representations including words, phrases and sentences in the same vector space. To this end, we introduce universal analogy tasks derived from Google's word analogy dataset. In addition, we train a Transformer-based model and compare it with currently popular representation methods. Experimental results demonstrate that well-trained Transformer-based models are able to map sequences of variable lengths into a shared vector space where similar sequences are close to each other. Meanwhile, addition and subtraction of embeddings reflect semantic and syntactic connections between sequences. In addition, we explore the applicability of this characteristic in retrieval-based chatbots by evaluation on an insurance FAQ task, where the universal representation models significantly outperform TF-IDF and BM25.      We proposed a coreference resolution system based on graph neural networks and enhanced with the second-order decoding algorithm. Modeling the mentions and their relationships by the multiple-layer graph neural networks makes it possible to aggregate the features of the mentions pointing to the same entity in an iterative way, while the global inference algorithm up to second-order features helps to produce optimal and consistent clustering results. Experiments on the English CoNLL-2012 shared task dataset demonstrated that our model achieved close to state-of-the-art performance in the coreference resolution task.      
"," Despite the well-developed cut-edge representation learning for language, most language representation models usually focus on specific level of linguistic unit, which cause great inconvenience when being confronted with handling multiple layers of linguistic objects in a unified way. Thus this work introduces and explores the universal representation learning, i.e.,  embeddings of different levels of linguistic unit in a uniform vector space through a task-independent evaluation. We present our approach of constructing analogy datasets in terms of words, phrases and sentences and experiment with multiple representation models to examine geometric properties of the learned vector space. Then we empirically verify that well pre-trained Transformer models incorporated with appropriate training settings may effectively yield universal representation. Especially, our implementation of fine-tuning ALBERT on NLI and PPDB datasets achieves the highest accuracy on analogy tasks in different language levels. Further experiments on the insurance FAQ task show effectiveness of universal representation models in real-world applications.",44
"   The ability to learn tasks continuously during a lifetime and with limited supervision is a hallmark of human intelligence. This is enabled by efficient transfer of knowledge from past experience. On the contrary, when current deep learning methods are subjected to learning new tasks in a sequential manner, they suffer from catastrophic forgetting , where previous information is lost due to the shift in data distribution.  Non-stationarity is inevitable in the real world where data is continuously evolving. Thus, we need to design more robust machine learning mechanisms to deal with catastrophic interference.   Lifelong learning, also known as continual learning , aims at developing models that can continuously learn from a stream of tasks in sequence without forgetting existing knowledge but rather building on the information acquired by previously learned tasks in order to learn new tasks . One conceptualization of this is to accelerate learning by positive transfer between tasks while minimizing interference with respect to network updates . Many approaches to continual learning employ manually-designed techniques such as regularization  or gradient alignment  to mitigate catastrophic forgetting, which have been shown effective in computer vision and reinforcement learning tasks.   A recent trend in continual learning, as well as machine learning in general, is to directly learn generalizable solutions via meta-learning . Meta-learning  aims to learn new tasks quickly using a limited number of examples by training on many related tasks. In continual learning, meta-learning has been applied with the objective of learning new tasks continually with a relatively small number of examples per task   or in a traditional continual learning setup by interleaving with several past examples from a memory component, i.e. experience replay  . While a high rate of experience replay  usually mitigates catastrophic forgetting, it comes closer to a multi-task learning than a lifelong learning setup and is computationally expensive when learning on a data stream in real-life applications.  In natural language processing , continual learning still remains relatively unexplored . Despite the success of large pre-trained language models such as BERT , they still require considerable amounts of in-domain examples for training on new tasks and are prone to catastrophic forgetting . Existing continual learning approaches to language processing tasks include purely replay-based methods , a meta-learning based method  as well as a generative replay-based method . However, these approaches suffer from several important limitations: they require task identifiers, a high rate of replay and multiple epochs of training, which deviates from a realistic lifelong learning scenario; or tend to have an expensive inference step .   In this paper, we propose a novel approach to lifelong learning on language processing tasks using meta-learning and experience replay that is sparse in time and size. We consider the realistic setting where only one pass over the training set is possible and no task identifiers are available. We extend two algorithms, namely online meta-learning   and a neuromodulatory meta-learning algorithm   to the domain of NLP and augment them with an episodic memory module for experience replay. While their original objective is to continually learn a new sequence of tasks during testing time, we enhance them for the conventional continual learning setup where evaluation is on previously seen tasks, thus directly addressing the problem of catastrophic forgetting. Furthermore, by realizing experience replay as a query set, we directly optimize to prevent forgetting. We show that combining a strong language model such as BERT along with meta-learning and sparse replay produces state-of-the-art performance on lifelong text classification and relation extraction benchmarks when compared against current methods under the same realistic setting. To the best of our knowledge, ours is the first meta-learning approach to lifelong learning of language tasks that incorporates sparse replay. Through further experiments, we demonstrate that our approach is considerably more efficient than previous work in terms of computational complexity as well as memory usage. To facilitate further research in the field, we make our code publicly available.    This work concentrates on the less concentrated language representation, seeking to learn a uniform vector form across different linguistic unit hierarchies. Far apart from learning either word only or sentence only representation, we find that training Transformer models on a large-scale corpus effectively learns a universal representation from words, phrases to sentences. We especially provide universal analogy datasets  \footnote{Our annotated datasets will be publicly released after the anonymous reviewing period.}  and an insurance FAQ dataset to evaluate models from different perspectives. The well-trained universal representation model holds the promise for demonstrating accurate vector arithmetic with regard to words, phrases and sentences and in applications such as FAQ retrieval tasks.   
"," Lifelong learning requires models that can continuously learn from sequential streams of data without suffering catastrophic forgetting due to shifts in data distributions. Deep learning models have thrived in the non-sequential learning paradigm; however, when used to learn a sequence of tasks, they fail to retain past knowledge and learn incrementally. We propose a novel approach to lifelong learning of language tasks based on meta-learning with sparse experience replay that directly optimizes to prevent forgetting. We show that under the realistic setting of performing a single pass on a stream of tasks and without any task identifiers, our method obtains state-of-the-art results on lifelong text classification and relation extraction. We analyze the effectiveness of our approach and further demonstrate its low computational and space complexity.",45
"  Humans possess the ability to encode and express a wide range of intricate verbal and non-verbal cues based on goal and context. This has evolved into a complementary ability to detect nuanced cues in everyday communication.  This ability is a result of top-down processing  where based on context and learning humans are able to encode and decode person to person information flow efficiently. Context is typically set by what is being communicated and how through multi-modal cues.  Inspired by this, several studies have shown that multi-modal input to the systems can improve accuracy on  tasks involving human communication, such as speech recognition , emotion recognition  and speaker recognition .  Recently, use of generalized feature representations have become prevalent in the computer vision and natural language research. Computer vision tasks like object detection and semantic segmentation show improved accuracy when the features from the images are extracted using models trained on large amounts of data like ImageNet .  In the natural learning literature, generalized embeddings like GloVe and word2vec have demonstrated state of the art performance in several tasks like word similarity, word analogy and named entity recognition.  For speech applications like automatic speech recognition , speaker recognition and paralinguistics it is still traditional to use hand-crafted features like MFCCs, LFBEs or features from toolkits like openSMILE .  However, it has also been demonstrated that features learned directly from audio can improve performance when the amount of training data is large enough .    The research in the various domains has demonstrated that  transfer learning with models trained on large datasets can improve accuracy on subsequent tasks. This is especially important when the size of the labeled datasets is not large. There are a variety of multi-modal tasks like emotion recognition which still do not have large amounts of publicly available datasets.  Motivated by this, we propose a model to learn  embeddings that combine the features from audio, video, and text modalities to improve the performance on downstream tasks. The main contribution of this paper is to understand if we can leverage large datasets to build these representations that can outperform the models built for specific tasks where the datasets are limited. For our work, we use emotion recognition as the downstream task to evaluate the embeddings. In practical applications, it is possible that all modalities are not available to the machine learning system for inference. For example, for any applications that use video from web-based applications, any disturbance in the communication network can lead to missing audio or visual input. This leads to the second objective of our study; to perform ablation studies to understand the impact of the missing modality, and understand how to compensate for it.  This paper is organized as follows; in Section , we discuss prior work in multi-modal tasks and embedding generation techniques.  Our proposed technique for embedding extraction is presented in Section . In  we discuss the training setup and data. Finally, we present our results in Section  and conclude in Section .    We showed that pre-trained transformer-based language models, meta-learning and sparse experience replay produce a synergy that improves lifelong learning on language tasks. This is an important step in moving away from manually-designed solutions into simpler, more generalizable methods to ultimately achieve human-like learning. Meta-learning could further be exploited for the combined setting of few-shot and lifelong learning. It might also be promising in  learning distinct NLP tasks in a curriculum learning fashion.         
","     General embeddings like word2vec, GloVe and ELMo have shown a lot of success in natural language tasks. The embeddings are typically extracted from models that are built on general tasks such as skip-gram models and natural language generation. In this paper, we extend the work from natural language understanding to multi-modal architectures that use audio, visual and textual information for machine learning tasks. The embeddings in our network are extracted using the encoder of a  transformer model trained using multi-task training. We use person identification and automatic speech recognition as the tasks in our embedding generation framework. We tune and evaluate the embeddings on the downstream task of emotion recognition and demonstrate that on the CMU-MOSEI dataset, the embeddings can be used to improve over previous state of the art results.",46
"  %============================================================================   Natural language understanding often requires the ability to comprehend and reason with expressions involving numbers. This has produced a recent rise in interest to build applications to automatically solve math word problems~. These math problems consist of a textual description comprising numbers with a question that will guide the reasoning process to get the numerical solution .  This is a complex task because of      The research community has focused in solving mainly two types of mathematical word problems: arithmetic word problems    and algebraic word problems . Arithmetic word problems  can be solved using basic mathematical operations  and  involve a single unknown variable. Algebraic word problems, on the other hand,  involve more complex operators such as square root, exponential and logarithm with multiple unknown variables.  In this work, we focus on solving arithmetic word problems such as the one illustrated in \figref{fig:example}. This figure illustrates .   The main idea of this paper is to explore the use of tree-based Recursive Neural Networks  to encode and score the expression tree .  This contrasts with predominantly sequential neural representations  that encode the problem statement from left to right or vice versa. By using Tree-RNN architectures, we can naturally embed the equation inside a tree structure such that the link structure directly reflects the various mathematical operations between operands selected from the sequential textual input. We hypothesize that this structured approach can efficiently capture the semantic representations of the candidate equations to solve more complex arithmetic problems involving multiple and/or non-commutative operators. To test our results, we use the recently introduced SingleEQ dataset . It contains a collection of 508 arithmetic word problems with varying degrees of complexity. This allows us to track the performance of the evaluated systems on subsets that require different reasoning capabilities. More concretely, we subdivide the initial dataset into different subsets of varying reasoning complexity  or non-commutative  operations), to investigate whether   the performance of the proposed architecture remains consistent across problems of increasing complexity.    \Figref{fig:conceptualview} provides a high-level conceptual view of the interconnection between the main components of our proposed system. The processing flow consists of two main steps. In the first step, we use the candidate generator to generate a list of potential candidate equations for solving a particular arithmetic word problem. To achieve this, we employ the Integer Linear Programming  constraint optimization component proposed by \mbox{} . In the second step, the candidate equations are ranked by the candidate ranker, and the equation with the highest score is chosen as the solution to the processed arithmetic word problem .  In this paper, we focus on this second step by exploring the impact of structural Tree-RNN-based and sequential Long Short Term Memory-based  candidate equation encoding methods. More specifically, we define two Tree-RNN models inspired by the work of  on \TreeLSTM{} models: . In the rest of the manuscript we refer to the general tree-structured architecture of these models as \TreeLSTM{}. The main difference between the two is that, while in \TLSTM{} the child node representations  are summed up, in \NTLSTM{} they are concatenated. Unlike the representation used in , where the input is given by the word embeddings, our Tree-LSTM models also take as input the operation embeddings  that represent each of the arithmetic operators . This allows our architecture to distinguish between different operators that are contained in a particular expression tree. We show that \NTLSTM{} is more suitable to deal with equations that involve non-commutative operators because this architecture is able to capture the order of the operands. We also compare our \TreeLSTM{} models with a sequential LSTM model which we call \BLSTM{}.  All the models  take as input the contextualized representation of the numbers in text produced by a bidirectional \LSTM{} layer  . After conducting a thorough multi-fold experimentation phase involving multiple random weight re-initializations in order to ensure the validity of our results, we will show that the main added value of our \TreeLSTM{}-based models compared to state-of-the-art methods lays in an increased performance for  more complex arithmetic word problems.  More concretely,  our contribution is three-fold:   %----------------------------------------------------------------------------   We have proposed a simple generative noise model for the generation of adversarial examples for training data augmentation of NMT systems.  Our results demonstrate that NMT systems that are trained using adversarial examples are more resilient to noisy input data. We show that while for the baseline NMT systems, noisy inputs cause a substantial drop in the translation quality , for the systems that are trained using adversarial examples translation quality changes comparatively little . In terms of translation robustness, systems trained on adversarial examples on average yield 50\  consistency improvement when compared to baselines trained on clean data. Methods proposed here will be useful for achieving NMT robustness to orthographic and interpunctual variation in input data. This will be especially beneficial in use cases where NMT systems are used to translate texts of informal origins, such as chat conversations, social media posts and web pages with comment sections.  
","   Solving arithmetic word problems is a cornerstone task in assessing language understanding and reasoning capabilities in NLP systems. Recent works    use automatic extraction and ranking of candidate solution equations providing the answer to arithmetic word problems. In this work, we explore novel approaches to score such candidate solution equations using tree-structured   recursive neural network  configurations.    The advantage of this Tree-RNN approach over using more established sequential representations, is that it can naturally capture the structure of the equations. Our proposed method consists of transforming the mathematical expression of the equation into an expression tree. Further, we encode this tree into a Tree-RNN by using different \TreeLSTM{} architectures.      Experimental results show that our proposed method     \begin{enumerate*}[]     \item  improves overall performance with more than 3\% accuracy points compared to previous state-of-the-art, and with over 15\% points on a subset of problems that require more complex reasoning, and \item outperforms sequential LSTMs by 4\% accuracy points on such more complex problems.  \end{enumerate*}",47
"  Semantic role labeling , namely semantic parsing, is a shallow semantic parsing task that aims to recognize the predicate-argument structure of each predicate in a sentence, such as who did what to whom, where and when, etc. Specifically, SRL seeks to identify arguments and label their semantic roles given a predicate. SRL is an important method for obtaining semantic information that is beneficial to a wide range of natural language processing  tasks, including machine translation, question answering, and discourse relation sense classification and relation extraction.  SRL can be split into four subtasks: predicate detection, predicate disambiguation, argument identification, and argument classification.  For argument annotation, there are two formulizations .  One is based on constituents , while the other is based on dependencies. The other, proposed by the CoNLL-2008 shared task, is also called semantic dependency parsing and annotates the heads of arguments rather than phrasal arguments. Figure  shows example annotations.    In prior SRL work, considerable attention has been paid to feature engineering, which struggles to capture sufficient discriminative information compared to neural network models, which are capable of extracting features automatically. In particular, syntactic information, including syntactic tree features, has been known to be extremely beneficial to SRL since the large scale of empirical verification of~\citet{punyakanok-etal-2008-importance}. Despite their success, their work suffered from erroneous syntactic input, leading to an unsatisfactory performance.  To alleviate the above issues, \citet{marcheggiani-etal-2017-simple,he-etal-2017-deep} proposed a simple but effective neural model for SRL without syntactic input. Their work suggested that neural SRL does not have to rely on syntactic features, contradicting the belief that syntax is a necessary prerequisite for SRL, which was believed as early as~\citet{gildea-palmer-2002-necessity}. This dramatic contradiction motivated us to make a thorough exploration on syntactic contribution to SRL.  Both span and dependency are effective formal representations for semantics, though it has been unknown which form, span or dependency, would be better for the convenience and effectiveness of semantic machine learning and later applications for a long time. This topic has been roughly discussed in , who both concluded that the  dependency SRL system at then clearly outperformed the span-based  system through gold syntactic structure transformation; however, due to the different requirements of downstream task applications, span and dependency both remain focuses of research. Additionally, the two forms of SRL may benefit from each other joint rather than separated development.  We, therefore, revisit the syntax roles under a more solid empirical basis and explore the syntax roles for the two styles with syntax information in equal quality, respectively.  Recent works on syntax contributions have been limited to individual models and the ways in which syntax has been utilized. The conclusions drawn for syntax roles therefore have some limitations. In order to reduce these limitations, we explored three typical and strong baseline models and two categories of syntactic utilization methods. In addition, pre-trained language models, such as ELMo  and BERT , that build contextualized representations, continue to provide gains on NLP benchmarks, and \citet{hewitt-manning-2019-structural} showed that structure of syntax information emerges in the deep models' word representation spaces. Whether neural SRL models can further benefit from explicit syntax information in addition to this implicit syntax information, however, is another issue we consider.  %This paper will focus on semantic dependency parsing and formulate SRL as one or two sequence tagging tasks with predicate-specific encoding. With the help of the proposed -order argument pruning algorithm over syntactic tree, our model obtains state-of-the-art scores on the CoNLL benchmarks for both English and Chinese.  Besides, most of SRL literature is dedicated to impressive performance gains on English, while other multiple languages receive relatively little attention. Although human languages have some basic commonalities in syntactic structure and even different levels of grammar, their differences are also very obvious. The study of syntactic roles needs to be examined in the context of multiple languages for verifying its effectiveness and applicability.  In order to quantitatively evaluate the contribution of syntax to SRL, we adopt the ratios between labeled F score for semantic dependencies  and the labeled attachment score  for syntactic dependencies, F score for syntactic constituents. This ration was first introduced by CoNLL-2008  Shared Task as an evaluation metric. Considering that various syntactic parsers contribute different syntactic inputs with varying levels of quality, the ratio provides a fairer comparison between syntactically-driven SRL systems, which our empirical study surveys.      ============================================================================   In this work we addressed the reasoning component involved in solving arithmetic word problems. We proposed a recursive tree architecture to encode the underlying equations for solving arithmetic word problems. More concretely, we proposed to use two different \TreeLSTM{} architectures for the task of scoring candidate equations. We performed an extensive experimental study on the SingleEQ dataset and demonstrated consistent effectiveness  of our models compared to current state-of-the-art.   We observed that, while very strong on simple instances involving single operations, the current feature-based state-of-the-art model exhibits a significant gap in performance for mathematical problems whose solution comprises non-commutative and/or multiple operations.  This reveals the weakness of this method to capture the intricate nature of reasoning necessary to solve more complex arithmetic problems. Furthermore, our experiments show that, while a traditional sequential approach based on recurrent encoding implemented using \biLSTMs{} over the equation proves to be a robust baseline, it is outperformed by our recursive \TreeLSTM{} architecture to encode the candidate solution equation on more complicated problems that require multiple operations to be solved.  This difference in performance becomes more significant as we introduce additional noise in our set of candidates by adding incorrect equations that contain non-commutative operations.    ============================================================================ 
"," Semantic role labeling  is dedicated to recognizing the semantic predicate-argument structure of a sentence.  Previous studies in terms of traditional models have shown syntactic information can make remarkable contributions to SRL performance; however, the necessity of syntactic information was challenged by a few recent neural SRL studies that demonstrate impressive performance without syntactic backbones and suggest that syntax information becomes much less important for neural semantic role labeling, especially when paired with recent deep neural network and large-scale pre-trained language models. Despite this notion, the neural SRL field still lacks a systematic and full investigation on the relevance of syntactic information in SRL, for both dependency and both monolingual and multilingual settings.  This paper intends to quantify the importance of syntactic information for neural SRL in the deep learning framework. We introduce three typical SRL frameworks , sequence-based, tree-based, and graph-based, which are accompanied by two categories of exploiting syntactic information: syntax pruning-based and syntax feature-based. Experiments are conducted on the CoNLL-2005, 2009, and 2012 benchmarks for all languages available, and results show that neural SRL models can still benefit from syntactic information under certain conditions. Furthermore, we show the quantitative significance of syntax to neural SRL models together with a thorough empirical survey using existing models.",48
"   Building a dialogue system that can converse with people naturally and meaningfully is one of the most challenging problems towards high-level artificial intelligence, and has been drawing increasing interests from both academia and industry area. Most existing dialogue systems are either generation-based or retrieval-based. Given the dialogue context, generation-based approaches synthesize a response word by word with a conditional language model, while retrieval-based methods select a proper response from a candidate pool. In this paper, we focus on retrieval-based approaches that are superior in providing informative responses and have been widely applied in several famous commercial products such as XiaoIce from Microsoft and AliMe Assist from Alibaba.  We consider the response selection task in multi-turn dialogues, where the retrieval model ought to select a most proper response by measuring the matching degree between a multi-turn dialogue context and a number of response candidates. Earlier studies concatenate the context to a single utterance and calculate the matching score with the utterance-level representations. Later, most response selection models  perform context-response matching within the representation-matching-aggregation paradigm, where each turn of utterance is represented individually and sequential information is aggregated among a sequence of utterance-response matching features. To further improve the performance of response selection, some recent approaches consider multiple granularities  of representations for matching or propose more complicated interaction mechanisms between the context and the response.    Recently, a wide range of studies have shown that pre-trained language models , such as BERT, XLNET and RoBERTa, on the large corpus can learn universal language representations, which are helpful for various downstream natural language processing tasks and can get rid of training a new model from scratch. To adapt pre-trained models for multi-turn response selection, \citet{whang2020domain} and \citet{gu2020speaker} make the first attempt to  utilize BERT to learn a matching model, where context and the candidate response are first concatenated and then fed into the PLMs for calculating the final matching score.  These pre-trained language models can well capture the interaction information among inter-utterance and intra-utterance through multiple transformer layers. Although PLM-based response selection models demonstrate superior performance due to its strong representation ability, it is still challenging to effectively learn task-related knowledge during the training process, especially when the size of training corpora is limited. Naturally, these studies typically  learn the response selection model with only the context-response matching task %learn the matching model with the single response prediction task,  and overlook many potential training signals  contained in dialogue data. %come from rich characteristics of dialogue text. Such training signals might  be  beneficial  for  context  understanding  and  produce better  features  for  response  prediction.  Besides, the response retrieved by existing dialogue systems supervised by the conventional way still faces some critical challenges, including  incoherence  and  inconsistency.     On account of the above issues, in this paper, instead of configuring complex context-response matching models, we propose learning the context-response matching model with auxiliary self-supervised tasks designed for dialogue data based on pre-trained language models . Specifically, we introduce four self-supervised tasks  including  next session prediction, utterance restoration, incoherence  detection and consistency  discrimination, and  jointly  train  the  PLM-based  response  selection  model with  these  auxiliary  tasks  in  a  multi-task  manner.  On the one hand, these auxiliary tasks help improve the capability of the response selection model to understand the dialogue context and measure the semantic relevance, consistency or coherent between the context and the response candidates. On the other hand, they can guide the matching model to effectively learn task-related knowledge with a fixed amount of train corpora and produce better features for response prediction.   We conduct experiments on two benchmark data sets for multi-turn response selection: the Ubuntu Dialog Corpus and the E-commerce Dialogue Corpus. Evaluation results show that our proposed approach is significantly better than all state-of-the-art models on both datasets. Compared with the previous state-of-the-art methods, our model achieves 2.9\% absolute improvement in terms of  for the Ubuntu dataset and 4.8\% absolute improvement for the E-commerce dataset. Furthermore, we applied our proposed self-supervised learning schema to some non-PLM-based response selection models, e.g., dual LSTM and ESIM. Experimental results indicate that our learning schema can also bring consistent and significant improvement to the performance of the existing matching models. Surprisingly, with self-supervised learning, a simple ESIM even performs better than BERT on the ubuntu dataset, demonstrating that our approach is beneficial for various matching architectures. % We will publish source code later.  In summary, our contributions are three-fold:      We perform four generative tests to asses learning of reduplication in deep convolutional networks:  a test of proportion of outputs when latent codes are manipulated to marginal values,  a test of interpolating latent variables,  a test  of reduplication on unobserved data in the ciwGAN architecture, and  a replication test  of reduplication on unobserved data in the bare WaveGAN architecture. All four tests suggest that deep convolutional networks can learn a simple identity-based pattern in speech called reduplication, i.e.~a process that copies some phonological material to express new meaning.    The ciwGAN network learns to encode a meaningful representation --- presence of reduplication into its latent codes. There is a near one-to-one correspondence between the two latent codes  and  and reduplication. By interpolating latent codes, we cause the bare form to gradually turn into a reduplicated form with no other major changes in the output in the majority of cases. These results are close to what would be considered appearance of symbolic computation or algebraic rules. Additional evidence that an approximation of symbolic computation emerges comes from the bare GAN replication experiment: there is a substantial drop in regression estimates after the first one or two latent variables with highest regression estimates, suggesting that even without the requirement to produce informative data, the network ``discretizes'' the continuous and highly variable phonetic feature --- presence of reduplication --- and uses a small subset of the latent space to represent this phonetic/phonological property.   Encoding an identity-based pattern as a meaningful representation in the latent space emerges  in a completely unsupervised manner in the ciwGAN architecture --- only from the requirement that the Generator output informative data.  Reduplicated and unreduplicated forms are never paired in the training data. The network is fed bare and reduplicated forms randomly. This unsupervised training approximates conditions in language acquisition: the human language learner needs to represent reduplication and to pair bare and reduplicated forms from raw  unlabeled acoustic data . The ciwGAN learns to group  reduplicated and unreduplicated forms and assign a unique representation to the process of reduplication. In fact,  the one-hot vector  that the Generator learns to associate with reduplication in training can be modeled as a representation of the unique meaning/function that reduplication adds, in line with an approach to represent unique semantics with one-hot vectors   .   The dependencies that deep neural networks can and cannot learn has been an ongoing line of inquiry. The results of the computational experiments presented in this paper suggest that the Generator network learns to extend the learned identity-based patterns to novel unobserved data.  While the network was not trained on reduplicated items that start with an [s], we were able to elicit reduplication in the output following a technique proposed in  . First, we identify variables that correspond to some phonetic/phonological representation such as presence of [s], based on , which proposes that setting single variables well above training range can reveal the underlying value for each latent variable and forces the desired property in the output. We can thus force both [s] and reduplication in the output simultaneously. For example, the network outputs [\textipa{s@siju}] if we force both reduplication and [s] in the output;  however, it never sees [\textipa{s@siju}] in the training data --- only  [\textipa{siju}] and other reduplicated forms, none of which included an [s]. We also excluded reduplicated and unreduplicated items that contain sequences that are acoustically similar to [s]. This suggests that the network extends reduplication to novel forms even in absence of acoustically similar reduplication patterns.   Thus, these experiments again confirm that the network uses individual latent variables to represent linguistically meaningful representations . Setting these individual variables to values well above the training interval reveals their underlying values. By manipulating these individual variables, we can explore how the representations are learned as well as how interactions between different variables work . The results of this study make apparent that the deep convolutional network is not only capable of encoding different phonetic properties in individual latent variables, but also processes as abstract as copying or reduplication.   One of the advantages of probing learning in deep convolutional neural networks on speech data trained with GANs is that the innovative outputs violate training data in structured and highly informative ways. The innovative output with reduplication of [s]-initial forms such as [\textipa{s@siju}] can be directly paralleled to acoustic outputs read by L1 speaker of American English  that were absent from the training data. Acoustic analysis shows a high degree of similarity between the generated reduplicated forms and human recordings, meaning that the network learns to output novel data that are linguistically interpretable and resemble human speech processes even though they are absent from the training data. Thus, the results of the experiments have implications for cognitive models of speech acquisition. It appears that one of the processes that has long been held as a hallmark of symbolic computation in language, reduplication, can emerge in deep convolutional network without language-specific components in the model even when they are trained on raw acoustic inputs.   The present paper tests a simple partial reduplicative pattern where only CV is copied and appears before the base item. This is perhaps computationally the simplest reduplicative pattern. The world's languages feature a large number of other reduplicative patterns in which only a C, CVC, or other types of phonological content is copied. Additionally, reduplication can precede or follow the base or can be inserted inside the base item.  This paper is thus also an appeal to use these well-understood identity-based patterns in speech with various degrees of complexity to  further test which patterns deep convolutional networks can and cannot learn and how self-organization of meaningful representations and discretization of a continuous space emerges in deep convolutional  networks.   \subsubsection*{Acknowledgements} This research was funded by a grant to new faculty at the University of Washington. I would like to thank  Ella Deaton for reading the training data.      \subsubsection*{Declaration of interests}  The author declares no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.  \iffalse      \fi  \clearpage             { }  \clearpage      \section{Training data}  } \caption{All items in which C is a voiceless or voiced stop used in training data. All items feature two unique repetitions and were read by an L1 American English speaker. The items are in transcription that was presented to the reader. }     \caption{All items in which C is a [m], [n], or [v] used in training data. All items feature two unique repetitions and were read by an L1 American English speaker. The items are in transcription that was presented to the reader. }      \caption{All items in which C is a [s] with corresponding number of unique repetitions in the training data per item. These items were never reduplicated in the training data. All items were read by an L1 American English speaker. The items are in transcription that was presented to the reader. }      
"," Building an intelligent dialogue system with the ability to select a proper response according to a multi-turn context is a great challenging task. Existing studies focus on building a context-response matching model with various neural architectures or PLMs and typically learning with a single response prediction task. These approaches overlook many potential training signals contained in dialogue data, which might be beneficial for context understanding and produce better features for response prediction.  Besides, the response retrieved from existing dialogue systems supervised by the conventional way still faces some critical challenges, including incoherence and inconsistency. To address these issues, in this paper, we propose learning a context-response matching model with auxiliary self-supervised tasks designed for the dialogue data based on pre-trained language models. Specifically, we introduce four self-supervised tasks including next session prediction, utterance restoration, incoherence detection and consistency discrimination, and jointly train the PLM-based response selection model with these auxiliary tasks in a multi-task manner.   By this means, the auxiliary tasks can guide the learning of the matching model to achieve a better local optimum and select a more proper response. Experiment results on two benchmarks indicate that the proposed auxiliary self-supervised tasks bring significant improvement for multi-turn response selection in retrieval-based dialogues, and our model achieves new state-of-the-art results on both datasets.",49
" 	 	Named Entity Recognition  is the process of identification of named entities  in natural language text. The present paper concentrates on three low resource languages : Bhojpuri, Maithili and Magahi , which belong to the Indo-Aryan language family. This work may be seen as the first attempt to develop an NER tool for Bhojpuri, Maithili and Magahi. There is no previous work on NER for these languages as far as we know. The main aim of the present paper is to start with insights from the NER systems that are developed for Indian Languages with more resources and based on that we try to develop an NER System for BMM. 	 	The NER module can be an important component  in  Natural  Language  Processing and Information Extraction systems.  It is an essential task for computational purposes like Machine Translation , developing search engines, automatic indexing, document classification  and  text  summarization, questiona answering etc., because it is not possible to build end-to-end Deep Learning systems for these languages due to the lack of data. It  will also  be helpful  in  many  cross-linguistic  applications  as  it is relevant for other Indian Languages, particularly LRLs. The present study mainly focuses on Named Entities  for BMM with machine translation as the goal. 	 	\subsection{Named Entity Recognition}  	The concept of Named Entity was introduced in the Sixth Message of Understanding Conference . It was often seen as part of an Information Extraction system, which refers to the automatic extraction of structured information such as entities, relationships between entities and attributes describing entities from unstructured sources. The role of NER system is to locate and classify words in a text into predefined categories such as the names of persons, organizations, locations, expressions of times, quantities etc. The NEs could be identified in two conventional ways, before the recent success of machine learning and then Deep Learning based techniques: 	 	 	 	It is a challenging task to implement NER for Indian languages due to the absence of capitalization in their writing systems. On the other hand, these systems are phonetically organized and designed, which makes it easily possible to use phonetic features for NER for Indian languages. Preparing a gazetteer閳ユ獨 list for all nouns is impossible because there can be a vast number of unknown named entities in the world in terms of a corpus versus a language. Here, one important point to be noted is that not much work has been reported for NER for Low Resource languages due to insufficient lexical resources and also due to morphological richness. There have been efforts on major Indian languages, i.e., Hindi, Tamil, Telugu, Urdu, Punjabi, but no efforts on Low Resource Indian languages such as BMM. 	 	\subsection{Bhojpuri, Maithili, Magahi : An Introduction} 	 	Bhojpuri is often considered a major `sub-language' of Hindi. It is not only a language which is spoken in various states of India but in other countries as well, viz. Nepal, Mauritius, Fiji, Surinam etc. The writing system of Bhojpuri was earlier Kaithi script but now Devanagari script is used more to write Bhojpuri. According to 2011 census~, there are 5,05,79,447 Bhojpuri speakers. 	 	Maithili belongs to the Indo-Aryan language family, while Bhojpuri and Magahi are considered `sub-languages'  of Hindi and are mainly spoken in Eastern Uttar Pradesh, Bihar and Jharkhand states of India. Maithili is included in the 22 `scheduled' languages of the Republic of India . Maithili was added in the Constitution of India in 2003 by the 92nd Constitutional Amendment Act. Maithili, a sister language of Hindi, is spoken in India, particularly in Bihar, Jharkhand, Uttar Pradesh etc. as well as in Nepal. It is the only language in the Bihari sub-family that is included in the eighth schedule of the Indian constitution. There are 1,35,83,464 Maithili speakers . It is also one of the 122 recognised languages of Nepal. In 2007, Maithili was included in the interim Constitution of Nepal and in March 2018, it received the second official language status in the Jharkhand state of India. It too was earlier considered a sub-language or a dialect. 	 	Magahi or Magadhi, also considered a major sub-language of Hindi, is chiefly spoken in some districts of Bihar, Jharkhand, and also in the Maldah district of West Bengal. Magahi was also written in the Kaithi script in earlier days, but at present it is usually written in the Devanagari script. There are 1,27,06,825 Magahi speakers . 	 	Earlier work on machine translation  has reported that proper handling of named tokens can improve the translation quality and performance. These named tokens would have been translated during source to target translation without an NER module, but with an NER module they can instead be simply transliterated. The current BMM machine translation systems for which we plan to use our NER module, is based on a transfer-based approach to machine translation. Even though the MT systems are based on a transfer approach, the NER module  can be based on machine learning or Deep Learning, not a rule-based approach. Due to this, we have annotated some corpus and developed an NER system for these three languages and have reported the lower and a higher baseline results. The former is based on CRF and the latter on a combination of Long Short Term Memory , Convolutional Neural Networ  and Conditional Randon Fields , called LSTM-CNNs-CRF. 	 	\subsection{Contributions} 	As there is no prior work on the NER problem for Bhojpuri, Maithili and Magahi, the contributions in this paper are as follows: 	 	 	 	 	  In this paper, we propose learning a context-response matching model with four auxiliary self-supervised tasks designed for the dialogue data. Jointly trained with these auxiliary tasks, the matching model can effectively learn task-related knowledge contained in dialogue data, achieve a better local optimum and produce better features for response selection. Experiment results on two benchmarks indicate that the proposed auxiliary self-supervised tasks bring significant improvement for multi-turn response selection in retrieval-based dialogues, and our PLM-based model achieves new state-of-the-art results on both datasets.     In the unusual situation where you want a paper to appear in the   references without citing it in the main text, use \nocite \nocite{langley00}  
"," 			In Natural Language Processing  pipelines, Named Entity Recognition  is one of the preliminary problems, which marks proper nouns and other named entities such as Location, Person, Organization, Disease etc. Such entities, without a NER module, adversely affect the performance of a machine translation system. NER helps in overcoming this problem by recognising and handling such entities separately, although it can be useful in Information Extraction systems also. Bhojpuri, Maithili and Magahi are low resource languages, usually known as Purvanchal languages. This paper focuses on the development of a NER benchmark dataset for the Machine Translation systems developed to translate from these languages to Hindi by annotating parts of their available corpora. Bhojpuri, Maithili and Magahi corpora of sizes 228373, 157468 and 56190 tokens, respectively, were annotated using 22 entity labels. The annotation considers coarse-grained annotation labels followed by the tagset used in one of the Hindi NER datasets. We also report a Deep Learning based baseline that uses an LSTM-CNNs-CRF model. The lower baseline F$_1$-scores from the NER tool obtained by using Conditional Random Fields models are 96.73 for Bhojpuri, 93.33 for Maithili and 95.04 for Magahi. The Deep Learning-based technique  achieved 96.25 for Bhojpuri, 93.33 for Maithili and 95.44 for Magahi.",50
"  As a fundamental task in speech and language processing, Automatic Speech Recognition  aims to generate transcripts from human speech. Recently, the successful application of deep neural networks has pushed the accuracy of end-to-end ASR models to a new level, but brings significant challenges for building large-scale, robust ASR systems, especially for industrial applications. Major bottlenecks are twofold: i) abundant labeled training data for learning large, accurate ASR models; and ii) an efficient distributed, computing framework for model training and serving at scale.  In this demo, we present EasyASR, a distributed machine learning platform to address both challenges. EasyASR is built upon the Machine Learning Platform for AI  of Alibaba Cloud~\footnote{https://www.alibabacloud.com/product/machine-learning/}, which provides an ultra-scale, deep learning framework on distributed GPU clusters. Our platform supports the complete process of training, evaluating and serving ASR models. Additionally, it is integrated with the functionalities i) to extract high-quality audio aligned with transcripts from massive video data and ii) to expand existing ASR training sets with various augmentation policies. We have designed easy-to-use PAI components that enable users to build or run ASR models within only a few lines of command, which  hides complicated techniques from starters. We also provide add-on configurations with the PAI commands to allow advanced users to customize network architectures for their own models. On EasyASR, we achieve state-of-the-art performance for Mandarin speech recognition over multiple public datasets. %In the following, we describe EasyASR in detail.   %    	Bhojpuri, Maithili and Magahi are Purvanchal languages which are often considered  dialects of Hindi, even though they are widely spoken in parts of India. Bhojpuri is spoken even outside India. Partly due to their dialectal nature, they show more linguistic variations such as nominal case inflection, emphatic expressions. Like other computational resources, there is a lack of any NER system for these languages. We describe a first attempt at this. This attempt includes the creation of a dataset as well as reporting the results for two baseline systems, one that uses CRF and the other that uses an LSTM-CNNs-CRF model. These NER systems are planned to be used in machine translation system for Bhojpuri, Maithili and Magahi to Hindi. The NER dataset, prepared by native speaker linguists, consists of 228373, 157468 and 56190 tokens, out of which 12351, 19809 and 7152 are NE閳ユ獨. The tagset used is a union of ENAMEX, TIMEX and NUMEX tagsets, having a total of 22 labels. The results obtained  are 70.56\  for 61.41\  for Bhojpuri with CRF and LSTM-CNNs-CRF, respectively. The results for Maithili are 73.19\  and 71.38\  and for Magahi, they are 84.18\  and 86.39\  for the two models. Even though the total data size is more for Bhojpuri, the scores are lower as the number of NEs in the dataset of this languages is relatively much less than for the other languages. In other words, the results are consistent with the number of NEs in the datasets, rather than with the total size of the dataset in number of tokens. 	 	 	
"," We present EasyASR, a distributed machine learning platform for training and serving large-scale Automatic Speech Recognition  models, as well as collecting and processing audio data at scale. Our platform is built upon the Machine Learning Platform for AI of Alibaba Cloud. Its main functionality is to support efficient learning and inference for end-to-end ASR models on distributed GPU clusters. It allows users to learn ASR models with either pre-defined or user-customized network architectures via simple user interface. On EasyASR, we have produced state-of-the-art results over several public datasets for Mandarin speech recognition.",51
"  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  Most neural machine translation systems are autoregressive, hence decoding latency grows linearly with respect to the length of the target sentence. For faster generation, several work proposed non-autoregressive models with sub-linear decoding latency given sufficient parallel computation~.   As it is challenging to precisely model the dependencies among the tokens without autoregression, many existing non-autoregressive models first generate an initial translation which is then iteratively refined to yield better output~.  While various training objectives are used to admit refinement , the generation process of these models is similar in that the refinement process happens in the discrete space of sentences.  Meanwhile, another line of work proposed to use continuous latent variables for non-autoregressive translation, such that the distribution of the target sentences can be factorized over time given the latent variables~.  Unlike the models discussed above, finding the most likely target sentence under these models requires searching over continuous latent variables. To this end, \citet{shu20latent} proposed an EM-like inference procedure that optimizes over a hybrid space consisting of both continuous and discrete variables. By introducing a deterministic delta posterior, it maximizes a proxy lowerbound by alternating between matching the delta posterior to the original approximate posterior , and finding a target sentence that maximizes the proxy lowerbound .  In this work, we propose an iterative inference procedure for latent variable non-autoregressive models that purely operates in the continuous space.} Given a latent variable model, we train an inference network to estimate the gradient of the marginal log probability of the target sentence, using only the latent variable as input. At inference time, we find the target sentence that approximately maximizes the log probability by  initializing the latent variable e.g. as the mean of the prior, and  following the gradients estimated by the inference network.  We compare the proposed approach with the EM-like inference~ on three machine translation datasets: {\wmtende}, {\wmtroen} and {\iwsltdeen}. The advantages of our approach are twofold: %We observe two advantages of our approach:  each refinement step is twice as fast, as it avoids discrete search over a large vocabulary, and   it is more effective, giving higher marginal probabilities and BLEU scores with the same number of refinement steps. Our procedure results in significantly faster inference, for instance giving  speedup over the autoregressive baseline on {\wmtende} at the expense of  BLEU score.  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    We have shown that it is possible to achieve few-shot performance similar to GPT-3 on SuperGLUE with LMs that have three orders of magnitude fewer parameters. This is achieved using \pet{}, a method that reformulates tasks as cloze questions and trains an ensemble of models for different reformulations. We have proposed a simple yet effective modification to \pet{} that enables us to use it for tasks that require predicting multiple tokens. In extensive experiments, we have identified several factors responsible for the strong performance of \pet{} combined with pretrained ALBERT: the possibility to concurrently use multiple patterns for transforming examples into cloze questions, the ability to compensate for patterns that are difficult to understand, the usage of labeled data to perform parameter updates    as opposed to using them for priming , and the underlying LM itself. To enable comparisons with our work, we make our dataset of few-shot training examples publicly available.    For future work, it would be interesting to see whether further improvements are possible by using \pet{} in a multi-task setting.       
"," We propose an efficient inference procedure for non-autoregressive machine translation that iteratively refines translation purely in the continuous space. Given a continuous latent variable model for machine translation, we train an inference network to approximate the gradient of the marginal log probability of the target sentence, using only the latent variable as input. This allows us to use gradient-based optimization to find the target sentence at inference time that approximately maximizes its marginal probability. As each refinement step only involves computation in the latent space of low dimensionality , we avoid computational overhead incurred by existing non-autoregressive inference procedures that often refine in token space. We compare our approach to a recently proposed EM-like inference procedure that optimizes in a hybrid space, consisting of both discrete and continuous variables. We evaluate our approach on {\wmtende}, {\wmtroen} and {\iwsltdeen}, and observe two advantages over the EM-like inference:  it is computationally efficient, i.e. each refinement step is twice as fast, and  it is more effective, resulting in higher marginal probabilities and BLEU scores with the same number of refinement steps. On {\wmtende}, for instance, our approach is able to decode $6.2$ times faster than the autoregressive model with minimal degradation to translation quality .",52
"  Deep learning methods have revolutionized the NLP field in the past ten years. Although LSTM networks  have been around for over two decades, the NLP community only learned how to train and use them effectively in the past ten years. \citet{DBLP:journals/corr/ChoMGBSB14} introduced a new sequence-to-sequence method, boosting the field of neural machine translation significantly . The same year \citet{bahdanau2014neural} presented the attention mechanism aimed at focusing on specific words within the prefix, in order to make the most accurate prediction of the next word while mapping one sequence to another. During the same period new text representation methods were adapted, complementing the following representation methods: bag-of-words , tf-idf, and one-hot vectors with dense representations, such as the very prominent word2vec  and Glove  embeddings, which served as the go-to methods in many works .  \citet{devlin2018bert} introduced a pre-trained transformer  based on the attention mechanism without any recurrent connections. BERT provided another advancement in the field of pre-trained text representations, showing enhanced performance on various NLP tasks .   Many research directions were shaped by  pre-trained word embeddings and representations with several software toolkits available for training deep neural networks. While the Keras  toolkit was widely used for text classification  with padding, the DyNet  and PyTorch  toolkits excelled at tasks in which a dynamic computation graph of the recurrent networks was exploited to achieve better predictive performance with sentences of varying length .  An important advancement in the dense representation area occurred with the introduction of TensorFlow  Hub in 2018. According to Google.                                                                                         We propose an efficient inference procedure for non-autoregressive machine translation that refines translations purely in the continuous space. Given a latent variable model for machine translation, we train an inference network to approximate the gradient of the marginal log probability with respect to the target sentence, using only the latent variable. This allows us to use gradient based optimization to find a target sentence at inference time that approximately maximizes the marginal log probability. As we avoid discrete search over a large vocabulary, our inference procedure is more efficient than previous inference procedures that refine in the token space.  We compare our approach with a recently proposed delta inference procedure that optimizes jointly in discrete and continuous space on three machine translation datasets: {\wmtende}, {\wmtroen} and {\iwsltdeen}. With the same underlying latent variable model, the proposed inference procedure using a learned score function has following advantages:  it is twice as fast as delta inference, and  it is able to find target sentences resulting in higher marginal probabilities and BLEU scores.  While we showed that iterative inference with a learned score function is effective for spherical Gaussian priors, more work is required to investigate if such an approach will also be successful for more sophisticated priors, such as Gaussian mixtures or normalizing flows. This will be particularly interesting, as recent study showed latent variable models with a flexible prior give high test log-likelihoods, but suffer from poor generation quality as inference is challenging~.  
"," One of the challenges in  the NLP field is training  large  classification  models, a task that is both difficult and tedious. It is even harder when GPU hardware is unavailable. The increased availability of pre-trained and off-the-shelf word embeddings, models, and modules aim at easing the process of training large models and achieving a competitive performance.   We explore the use of off-the-shelf BERT models and share the results of our experiments and compare their results to those of LSTM networks and more simple baselines. We show that the complexity and computational cost of BERT is not a guarantee for enhanced predictive performance in the classification tasks at hand.",53
" Autoregressive models are ubiquitous in natural language processing.  Due to the sequential nature of text generation, they are often the tool of choice for tackling sequence-to-sequence problems such as translation , summarization , and dialogue .  Furthermore, they form the backbone of several successful generative pre-training architectures .  Two recent trends have made autoregressive models cumbersome to deploy in real-world, natural language generation  applications.  First, state-of-the-art models have grown larger and larger, amounting to hundreds of millions and even billions of parameters .  The increase in size and depth dramatically slows down inference speed.  Second, the architecture of choice for autoregressive models seems to have shifted from the recurrent neural network   to the Transformer .  Though the Transformer's self-attention mechanism improves performance, it also increases the computational complexity of the step-by-step generation algorithms that are used at test time.  Thus, both of these trends have contributed to significantly increasing inference time costs, especially on CPUs and low-resource devices, hindering their use in production systems.  % The increasing memory and inference time costs of these enormous models make them cumbersome to deploy in real-world settings.  Inference on a CPU can already be quite slow, much less a smartphone device.  Thus, there exists a need to scale down these large autoregressive models for practical purposes.  Knowledge distillation   is one popular method for model compression.  It transfers the information learned by a large, pretrained teacher to a smaller, untrained  student.  In comparison to other methods such as weight pruning and quantization, KD allows the compressed model's architecture to significantly differ from that of the original teacher.  This feature enables models trained with KD to achieve high performance while meeting particular inference requirements .  Sequence-level knowledge distillation , proposed by \citet{kim2016sequence}, is the dominant technique for autoregressive KD in the current NLG literature, especially for machine translation .  This method trains a student model using a modified dataset generated by the teacher model and the standard negative log-likelihood objective.  While SeqKD is simple and efficient, we argue that it does not take advantage of the teacher's full potential.    %This method is a two-step procedure that 1) generates full sequences using the teacher model to produce a modified dataset and 2) trains the student model on the modified dataset with standard negative log-likelihood  training.  While seqKD is conceptually simple and efficient to implement, we argue that reducing the teacher's impact to a static dataset does not take advantage of its full potential.  % Autoregressive models are often trained in a way that is different from how they are used at inference time.  During training, the true sequence is available, so the model learns to predict one-step-ahead given the ground-truth context.  However, at inference time, the model must generate the entire sequence from scratch by repeatedly using its own outputs as context for subsequent steps.  This training-inference inconsistency leads to the exposure bias problem, which may be manifested as a decrease in sequence quality as the number of generation steps increases.  The seqKD algorithm is simply NLL training with a modified dataset, so it also experiences this issue.   Training the student model with a static dataset leads to the exposure bias problem. During training, the student model learns to predict the next token given previous tokens provided by the data. However, at inference time, the student generates the entire sequence from scratch by repeatedly using its own outputs as context for subsequent steps.  This training-inference inconsistency causes a decrease in generation quality.  Alternatively, we propose that the student can leverage the teacher in a dynamic fashion during the learning process.  % Our main contributions are the following:  We recast distillation for autoregressive models as an imitation learning problem, drawing parallels between SeqKD and behavioral cloning.   From this perspective, we design a new compression algorithm aimed at addressing exposure bias for autoregressive models called imitation-based knowledge distillation .   We conduct several experiments in translation and summarization, demonstrating that ImitKD is especially suitable for compressing deep Transformers that achieve high performance into shallow RNNs that generate much faster at inference time.  %The key insight of ImitKD is to treat the teacher model as an oracle that corrects the student閳ユ獨 generations at every step.  Thus, the student explicitly learns how to generate during training.  Our method consistently outperforms other popular distillation algorithms, such as SeqKD.  It yields student models that beat models trained without a teacher by 1.4 to 4.8 points on the Bleu and Rouge metrics.     We devise a new compression algorithm for autoregressive models called imitation-based knowledge distillation .  It is inspired by an imitation learning  perspective on the autoregressive distillation problem.  Our algorithm trains a student model within an IL framework by treating the teacher as an oracle, and allows the student to explore its own generation during training.  The teacher corrects the student's generation at every time step, thereby guiding the student in learning how to generate. %   Experimental results in translation and summarization show that ImitKD is especially suitable for compressing deep Transformer models that achieve high performance into shallow RNNs that generate up to 14 times faster at inference time.  Our method consistently outperforms other distillation algorithms , and yields student models that beat models trained without a teacher by 1.4 to 4.8 points on generation metrics such as BLEU and ROUGE. %   We share the results of our experimentation with two different NLP tasks. In both cases we experimented with small proprietary datasets from domains that suffer from a serious lack of labeled data. In these experiments we used the very promising and prominent BERT method and off-the-shelf TensorFlow Hub modules with the aim of outperforming several baselines on the tasks of proper word choice and political perspective identification. We used both pre-trained off-the-shelf and fine-tuned proprietary models. We failed to outdo the earlier folklore baselines as well as an advanced LSTM-based baselines, with a straightforward and systematic way of applying BERT.  Over 30 years ago, \citet{brooks1987no} argued that the software development process is hard at its very essence. They could not envision an advanced programming language capable of solving the complexity of performing high-quality software development projects on time. Analogously, a more user-friendly framework for pre-trained models can't guarantee excellent predictive performance. Training high performing models is essentially difficult. It requires deep understanding of the task data processing expertise. Fine-tuning a pre-trained model might be a good starting point, but the developer will still be required to delve deeply into a model's details in order to excel at predictive performance.     Please add the following required packages to your document preamble:   \usepackage{multirow}      
"," The performance of autoregressive models on natural language generation tasks has dramatically improved due to the adoption of deep, self-attentive architectures.  However, these gains have come at the cost of hindering inference speed, making state-of-the-art models cumbersome to deploy in real-world, time-sensitive settings.  We develop a compression technique for autoregressive models that is driven by an imitation learning perspective on knowledge distillation.  The algorithm is designed to address the exposure bias problem.     On prototypical language generation tasks such as translation and summarization, our method consistently outperforms other distillation algorithms, such as sequence-level knowledge distillation.  Student models trained with our method attain 1.4 to 4.8 BLEU/ROUGE points higher than those trained from scratch, while increasing inference speed by up to 14 times in comparison to the teacher model.\footnote{Our code can be found at \url{https://github.com/asappresearch/imitkd}.}",54
"   Extracting event temporal relations from raw text data has attracted surging attention in the NLP research community in recent years as it is a fundamental task for commonsense reasoning and natural language understanding. It facilitates various downstream applications, such as forecasting social events and tracking patients' medical history. Figure shows an example of this task where an event extractor first needs to identify events  in the input and then a relation classifier predicts all pairwise relations among them, resulting in a temporal ordering as illustrated in the figure. For example, \event{say} is \temprel{before} \event{stop}; \event{buildup} \temprel{includes} \event{say}; the temporal ordering between \event{buildup} and \event{stop} cannot be decided from the context, so the relation should be \temprel{vague}.        In this work, we developed a new knowledge distillation technique inspired by imitation learning for compressing large and cumbersome autoregressive models into smaller and faster counterparts.  We demonstrated the empirical success of our method over popular baselines on several natural language generation tasks.  We are excited about several possible avenues for future work.  One branch of ideas involves incorporating more advanced IL algorithms beyond DAgger, such as LOLS , to further improve the distillation process.  Another possibility is to design imitation-based fine-tuning analogs to the SeqInter method.  Finally, although our experiments in this paper focused on sequence-to-sequence settings, we are interested in exploring the use of ImitKD for compressing large language models aimed at transfer learning.  
","  Extracting event temporal relations is a critical task for information extraction and plays an important role in natural language understanding. Prior systems leverage deep learning and pre-trained language models to improve the performance of the task. However, these systems often suffer from two shortcomings: 1) when performing maximum a posteriori  inference based on neural models, previous systems only used structured knowledge that is assumed to be absolutely correct, i.e., hard constraints; 2) biased predictions on dominant temporal relations when training with a limited amount of data. To address these issues, we propose a framework that enhances deep neural network with distributional constraints constructed by probabilistic domain knowledge. We solve the constrained inference problem via Lagrangian Relaxation and apply it to end-to-end event temporal relation extraction tasks. Experimental results show our framework is able to improve the baseline neural network models with strong statistical significance on two widely used datasets in news and clinical domains.",55
" Encoder-decoder architecture, which uses an encoder to create a representation of source sequence and a decoder to predict target sequence, have been established as state of the art approaches in neural machine translation   . Recurrent neural network based  model , convolutional neural network  model and self-attention network based  model  are representative encoder-decoder models, and most of NMT models are variants or combination of these three. NMT models based on encoder-decoder architecture are similar in  some aspects, such as stack of layers having the same structure.  Stack of layers increases the complexity of model to approximate nonlinear function. Viewing all layers as one function, every single layer captures different information from input. Looking into every single NMT model such as RNN-based model or SAN-based model, models always try to make representation of one word containing information of whole sentence in every layer. However, empirically, one layer alone cannot result in satisfactory result.   It is common to regard sentence in NMT model as a directed complete simple graph, which views words as nodes and relationships between words as edges. However, this perspective only focuses on relationship between words, while ignoring other information, such as relationship between phrases or relationship between different fragments of sentences. As a result, structure of simple graph cannot fully reflect all information.   To overcome the shortcomings of simple graph, we view sentence as a multigraph  in SAN-based model. In multigraph , multiple edges exist between two nodes. Edge connects not only nodes but also subgraphs of  which reflects relationship between different fragments of sentences more than relationship of word-pair. Encoding is also regarded as a process of generating a multigraph to approximate  infinitely. Compared with simple graph, multigraph can explain th essence of encoding more comprehensively, and explain relationship between words in a more general way.  One layer in NMT model can capture the incremental information automatically compared with its previous layer. Fusion of the previous and incremental information makes representation more rich and thus benefits translation. From the perspective of multigraph, incremental information can be described as a set of higher-order subgraphs generated by this layer. Even though the current NMT models can capture information of subgraphs of different orders, fusing them into a representation with a fixed weight makes the model difficulty to pay more attention on really salient part.   To solve this problem, we propose a graph-based SAN empowered Graph-Transformer by enhancing the ability of capturing subgraph information over the current NMT models. First of all, we generally define a full representation as the fusing result of all concerned subgraph representations. Then let the representation of one layer split into two parts, previous representation and incremental representation. The previous representation reflects full representation from previous layer, and the incremental representation reflects new information generated in this layer. Based on this, the encoding process is modified to adapt to such representation division. We split the original self-attention into three independent parts to generate incremental representation. Our method accommodates subgraphs of different orders into different parts of incremental representation, and reduces the information redundancy. To fuse the full representation, We consider three fusing strategies in terms of different weighting schemes so that let the model focus on important parts of representation.        In experiments on WMT14 English-to-German  and IWSLT14 German-to-English , results of experiments prove our model can improve performance of translation with a few parameters increasing. Our model achieves a performance outperforming the Transformer with an improvement of 1.1 BLEU points in En-De and 1.0 BLEU points in De-En.        In conclusion, we propose a general framework that augments deep neural networks with distributional constraints constructed using probabilistic domain knowledge. We apply it in the setting of end-to-end temporal relation extraction task with event-type and relation constraints and show that the MAP inference with distributional constraints can significantly improve the final results.  We plan to apply the proposed framework on various event reasoning tasks and construct novel distributional constraints that could leverage domain knowledge beyond corpus statistics, such as the larger unlabeled data and rich information contained in knowledge bases.  
"," Neural machine translation  usually works in a seq2seq learning way by viewing either source or target sentence as a linear sequence of words, which can be regarded as a special case of graph, taking words in the sequence as nodes and relationships between words as edges. In the light of the current NMT models more or less capture graph information among the sequence in a latent way, we present a graph-to-sequence model facilitating explicit graph information capturing. In detail, we propose a graph-based SAN-based NMT model called Graph-Transformer by capturing information of subgraphs of different orders in every layers. Subgraphs are put into different groups according to their orders, and every group of subgraphs respectively reflect different levels of dependency between words. For fusing subgraph representations, we empirically explore three methods which weight different groups of subgraphs of different orders. Results of experiments on WMT14 English-German and IWSLT14 German-English show that our method can effectively boost the Transformer with an improvement of 1.1 BLEU points on WMT14 English-German dataset and 1.0 BLEU points on IWSLT14 German-English dataset.",56
"   Open-domain human-machine dialogue systems, especially the generation-based genre, have attracted extensive attention recently.  Typically, following the neural encoder-decoder paradigm, contemporary dialogue generation models~, more often than not,  are trained with Maximum Likelihood Estimation  principle to mimic human context-response pairs in the training corpus.  While notable gains have been achieved under this learning framework, prior art~ suggests that naive MLE objective used for training neural dialogue generation models is not that effective enough and tends to result in issues like dull response generation.  By optimizing the likelihood of training dialogues, neural models are inclined to assign high probabilities to ``safe'' responses, due to the fact that vacuous responses like ``I don't know'' are of relatively high frequencies in conversational datasets~.     One promising training framework for neural dialogue generation is adversarial learning~, where a discriminator provides rewards for the generator by contrastively distinguishing dialogues as human-generated or machine-generated.   However, the learning ability of GANs in text is drastically limited due to training instability and model collapse~.  First, the discriminator is usually unlikely to be fooled very easily, and the generator can hardly learn from those ineffective rewards.  Second, the generator is sometimes encouraged to mimic the high-frequency generic responses in the training corpus, \checkhere{because in some cases, the discriminator fails to distinguish a good response from a bad one: it can easily recognize contentful but less-grammatical responses as machine-generated, yet treat those human-generated dull responses as the oracle.}    In this paper, we introduce contrastive learning~ into dialogue generation, where the model explicitly perceives the difference between the well-chosen positive and negative utterances.  From the perspective of contrastive learning, the discriminator in adversarial learning considers human-generated responses as positive utterances and synthetic ones as negative samples.  Instead, this work deems highly-matched context-response pairs as positive samples and mismatched training pairs as negative samples.  In particular, we utilize a pretrained baseline model as a reference.  During contrastive learning, for context  and its response , the target dialogue model is trained to give higher conditional probabilities  for the positive samples, and lower conditional probabilities for those negative samples, compared to the reference model.  This training paradigm encourages the model to pull the positive data points together and push apart the negative samples, as exemplified in Figure.  As a result, our proposed training scheme explicitly takes the semantic associations and differences among training examples into account for dialogue modeling.  Besides, by contrastively characterizing the distinctions relative to a strong reference, our method implicitly enhances the {distinctiveness} of the generated responses as well, and ensures that the overall performance of the target model is not inferior to the reference.    Contrastively learning from one pair of positive and negative samples is quite straightforward, however, multi-mapping relations prevail in human-human conversations, where there exist multiple appropriate responses for a given context, and a response sometimes fits well to several contexts, known as one-to-many and many-to-one relations.  Such complex multi-mapping relations are overlooked in previous learning framework, which hampers effective dialogue response learning.  Furthermore, if a potential highly-matched utterance pair is treated as the negative sample or an outlier is used as the positive sample, the model may be confused.   Therefore, in order to consider the multi-mapping phenomenon in human conversations and remedy the potential problematic false learning samples, and enhance the training stability, we augment contrastive learning with group-wise dual sampling, where groups of positive and negative instances are sampled regarding both the context and the response, respectively.  To further depict subtle differences between instances in the group, we adapt the instance importance with the matching scores, and optimize the \iffalse expected \fi weighted loss.     We show an illustration case to understand our learning framework in Figure.   Given a training context-response pair  and  and .   By this mean, the target model is actually induced to pull the positive sample pairs together and push the mismatched pairs apart, and thus learns from the distinctions between the positives and negatives.        The proposed group-wise contrastive learning framework is suited for training various neural dialogue generation models.  We conduct extensive studies on three large-scale conversation datasets using four popular dialogue models to assess the proposed approach.  The experimental results confirm the effectiveness of our learning framework with very favorable performance over the baseline training approaches.% % File emnlp2020.tex % %% Based on the style files for ACL 2020, which were %% Based on the style files for ACL 2018, NAACL 2018/19, which were %% Based on the style files for ACL-2015, with some improvements %%  taken from the NAACL-2016 style %% Based on the style files for ACL-2014, which were, in turn, %% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009, %% EACL-2009, IJCNLP-2008... %% Based on the style files for EACL 2006 by  %%e.agirre@ehu.es or Sergi.Balari@uab.es %% and that of ACL 08 by Joakim Nivre and Noah Smith  \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{emnlp2020-templates/emnlp2020} \usepackage{times} \usepackage{latexsym} \renewcommand{\UrlFont}{\ttfamily\small}  % This is not strictly necessary, and may be commented out, % but it will improve the layout of the manuscript, % and will typically save some space. \usepackage{microtype}  % --------- packages added by the authors ---------> % \usepackage{booktabs} % For formal tables \usepackage{amsmath}  \usepackage{amsfonts} \usepackage{bm} \usepackage{array} \usepackage{enumitem} % \usepackage{needspace} % \usepackage{adjustbox} \usepackage{tikz} \usepackage{pgfplots} \usepackage{multirow} % \usepackage{autobreak} \usepackage{makecell} \usepackage{xcolor} \usepackage{amssymb} % \usepackage{import} % \usepackage{subcaption} \usepackage{nicefrac}       % compact symbols for 1/2, etc. \usepackage{microtype}      % microtypography % \usepackage{tabularx} % \usepackage{dcolumn} \usepackage{url} % <--------- packages added by the authors --------- %   % --------- commands added by the author ----------> % %  \newcommand\setrow[1]{\gdef\rowmac{#1}#1\ignorespaces} \newcommand\clearrow{\global\let\rowmac\relax}  \clearrow \newcommand{\wideslash}{\text{ / }} \newcommand{\xxx}{\textcolor{red}{Placeholder}} % \newcommand{\alert}[1]{{\textcolor{red}{#1}}} \newcommand{\alert}[1]{{#1}} % \newcommand{\notice}[1]{\textcolor{red}{#1}} \newcommand{\notice}[1]{{#1}} % \newcommand{\checkhere}[1]{\textcolor{blue}{#1}} \newcommand{\checkhere}[1]{{#1}} \newcommand*{\rom}[1]{\romannumeral#1\relax} \newcommand{\centercell}[1]{\multicolumn{1}{c}{#1}}  % \DeclareUnicodeCharacter{001D}{\textcolor{red}{CHECK THIS UNICODE CHAR!!!}} % <--------- commands added by the author ---------- %  \aclfinalcopy % Uncomment this line for the final submission \def\aclpaperid{690} %  Enter the acl Paper ID here  %\setlength\titlebox{5cm} % You can expand the titlebox if you need extra space % to show all the authors. Please do not make the titlebox % smaller than 5cm ; we will check this % in the camera-ready version and ask you to change it back.  \newcommand\BibTeX{Bib\TeX}  \title{Group-wise Contrastive Learning for Neural Dialogue Generation}  % \author{First Author \\ %   Affiliation / Address line 1 \\ %   Affiliation / Address line 2 \\ %   Affiliation / Address line 3 \\ %    \\\And %   Second Author \\ %   Affiliation / Address line 1 \\ %   Affiliation / Address line 2 \\ %   Affiliation / Address line 3 \\ %    \\} \author{ Hengyi Cai\thanks{\ \ Work done at JD.com.}, Hongshen Chen\\ {\bf Yonghao Song, Zhuoye Ding, Yongjun Bao, Weipeng Yan, Xiaofang Zhao} \\ {Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China} \\ {University of Chinese Academy of Sciences, Beijing, China} \\ {JD.com, China} \\ {caihengyi@ict.ac.cn, ac@chenhongshen.com} \\ {\{songyonghao, zhaoxf\}@ict.ac.cn, \{dingzhuoye, baoyongjun, Paul.yan\}@jd.com} }  \date{}  % \hypersetup{draft}  %%%%% NEW MATH DEFINITIONS %%%%%  \usepackage{amsmath,amsfonts,bm}  % Mark sections of captions for referring to divisions of figures \newcommand{\figleft}{} \newcommand{\figcenter}{} \newcommand{\figright}{} \newcommand{\figtop}{} \newcommand{\figbottom}{} \newcommand{\captiona}{} \newcommand{\captionb}{} \newcommand{\captionc}{} \newcommand{\captiond}{}  % Highlight a newly defined term \newcommand{\newterm}[1]{{\bf #1}}   % Figure reference, lower-case. \def\figref#1{figure} % Figure reference, capital. For start of sentence \def\Figref#1{Figure} \def\twofigref#1#2{figures  and } \def\quadfigref#1#2#3#4{figures , ,  and } % Section reference, lower-case. \def\secref#1{section} % Section reference, capital. \def\Secref#1{Section} % Reference to two sections. \def\twosecrefs#1#2{sections  and } % Reference to three sections. \def\secrefs#1#2#3{sections ,  and } % Reference to an equation, lower-case. \def\eqref#1{equation} % Reference to an equation, upper case \def\Eqref#1{Equation} % A raw reference to an equation---avoid using if possible \def\plaineqref#1{} % Reference to a chapter, lower-case. \def\chapref#1{chapter} % Reference to an equation, upper case. \def\Chapref#1{Chapter} % Reference to a range of chapters \def\rangechapref#1#2{chapters--} % Reference to an algorithm, lower-case. \def\algref#1{algorithm} % Reference to an algorithm, upper case. \def\Algref#1{Algorithm} \def\twoalgref#1#2{algorithms  and } \def\Twoalgref#1#2{Algorithms  and } % Reference to a part, lower case \def\partref#1{part} % Reference to a part, upper case \def\Partref#1{Part} \def\twopartref#1#2{parts  and }  \def\ceil#1{\lceil #1 \rceil} \def\floor#1{\lfloor #1 \rfloor} \def\1{\bm{1}} \newcommand{\train}{\mathcal{D}} \newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}} \newcommand{\test}{\mathcal{D_{\mathrm{test}}}}  \def\eps{{\epsilon}}   % Random variables \def\reta{{\textnormal{}}} \def\ra{{\textnormal{a}}} \def\rb{{\textnormal{b}}} \def\rc{{\textnormal{c}}} \def\rd{{\textnormal{d}}} \def\re{{\textnormal{e}}} \def\rf{{\textnormal{f}}} \def\rg{{\textnormal{g}}} \def\rh{{\textnormal{h}}} \def\ri{{\textnormal{i}}} \def\rj{{\textnormal{j}}} \def\rk{{\textnormal{k}}} \def\rl{{\textnormal{l}}} % rm is already a command, just don't name any random variables m \def\rn{{\textnormal{n}}} \def\ro{{\textnormal{o}}} \def\rp{{\textnormal{p}}} \def\rq{{\textnormal{q}}} \def\rr{{\textnormal{r}}} \def\rs{{\textnormal{s}}} \def\rt{{\textnormal{t}}} \def\ru{{\textnormal{u}}} \def\rv{{\textnormal{v}}} \def\rw{{\textnormal{w}}} \def\rx{{\textnormal{x}}} \def\ry{{\textnormal{y}}} \def\rz{{\textnormal{z}}}  % Random vectors \def\rvepsilon{{\mathbf{\epsilon}}} \def\rvtheta{{\mathbf{\theta}}} \def\rva{{\mathbf{a}}} \def\rvb{{\mathbf{b}}} \def\rvc{{\mathbf{c}}} \def\rvd{{\mathbf{d}}} \def\rve{{\mathbf{e}}} \def\rvf{{\mathbf{f}}} \def\rvg{{\mathbf{g}}} \def\rvh{{\mathbf{h}}} \def\rvu{{\mathbf{i}}} \def\rvj{{\mathbf{j}}} \def\rvk{{\mathbf{k}}} \def\rvl{{\mathbf{l}}} \def\rvm{{\mathbf{m}}} \def\rvn{{\mathbf{n}}} \def\rvo{{\mathbf{o}}} \def\rvp{{\mathbf{p}}} \def\rvq{{\mathbf{q}}} \def\rvr{{\mathbf{r}}} \def\rvs{{\mathbf{s}}} \def\rvt{{\mathbf{t}}} \def\rvu{{\mathbf{u}}} \def\rvv{{\mathbf{v}}} \def\rvw{{\mathbf{w}}} \def\rvx{{\mathbf{x}}} \def\rvy{{\mathbf{y}}} \def\rvz{{\mathbf{z}}}  % Elements of random vectors \def\erva{{\textnormal{a}}} \def\ervb{{\textnormal{b}}} \def\ervc{{\textnormal{c}}} \def\ervd{{\textnormal{d}}} \def\erve{{\textnormal{e}}} \def\ervf{{\textnormal{f}}} \def\ervg{{\textnormal{g}}} \def\ervh{{\textnormal{h}}} \def\ervi{{\textnormal{i}}} \def\ervj{{\textnormal{j}}} \def\ervk{{\textnormal{k}}} \def\ervl{{\textnormal{l}}} \def\ervm{{\textnormal{m}}} \def\ervn{{\textnormal{n}}} \def\ervo{{\textnormal{o}}} \def\ervp{{\textnormal{p}}} \def\ervq{{\textnormal{q}}} \def\ervr{{\textnormal{r}}} \def\ervs{{\textnormal{s}}} \def\ervt{{\textnormal{t}}} \def\ervu{{\textnormal{u}}} \def\ervv{{\textnormal{v}}} \def\ervw{{\textnormal{w}}} \def\ervx{{\textnormal{x}}} \def\ervy{{\textnormal{y}}} \def\ervz{{\textnormal{z}}}  % Random matrices \def\rmA{{\mathbf{A}}} \def\rmB{{\mathbf{B}}} \def\rmC{{\mathbf{C}}} \def\rmD{{\mathbf{D}}} \def\rmE{{\mathbf{E}}} \def\rmF{{\mathbf{F}}} \def\rmG{{\mathbf{G}}} \def\rmH{{\mathbf{H}}} \def\rmI{{\mathbf{I}}} \def\rmJ{{\mathbf{J}}} \def\rmK{{\mathbf{K}}} \def\rmL{{\mathbf{L}}} \def\rmM{{\mathbf{M}}} \def\rmN{{\mathbf{N}}} \def\rmO{{\mathbf{O}}} \def\rmP{{\mathbf{P}}} \def\rmQ{{\mathbf{Q}}} \def\rmR{{\mathbf{R}}} \def\rmS{{\mathbf{S}}} \def\rmT{{\mathbf{T}}} \def\rmU{{\mathbf{U}}} \def\rmV{{\mathbf{V}}} \def\rmW{{\mathbf{W}}} \def\rmX{{\mathbf{X}}} \def\rmY{{\mathbf{Y}}} \def\rmZ{{\mathbf{Z}}}  % Elements of random matrices \def\ermA{{\textnormal{A}}} \def\ermB{{\textnormal{B}}} \def\ermC{{\textnormal{C}}} \def\ermD{{\textnormal{D}}} \def\ermE{{\textnormal{E}}} \def\ermF{{\textnormal{F}}} \def\ermG{{\textnormal{G}}} \def\ermH{{\textnormal{H}}} \def\ermI{{\textnormal{I}}} \def\ermJ{{\textnormal{J}}} \def\ermK{{\textnormal{K}}} \def\ermL{{\textnormal{L}}} \def\ermM{{\textnormal{M}}} \def\ermN{{\textnormal{N}}} \def\ermO{{\textnormal{O}}} \def\ermP{{\textnormal{P}}} \def\ermQ{{\textnormal{Q}}} \def\ermR{{\textnormal{R}}} \def\ermS{{\textnormal{S}}} \def\ermT{{\textnormal{T}}} \def\ermU{{\textnormal{U}}} \def\ermV{{\textnormal{V}}} \def\ermW{{\textnormal{W}}} \def\ermX{{\textnormal{X}}} \def\ermY{{\textnormal{Y}}} \def\ermZ{{\textnormal{Z}}}  % Vectors \def\vzero{{\bm{0}}} \def\vone{{\bm{1}}} \def\vmu{{\bm{\mu}}} \def\vtheta{{\bm{\theta}}} \def\va{{\bm{a}}} \def\vb{{\bm{b}}} \def\vc{{\bm{c}}} \def\vd{{\bm{d}}} \def\ve{{\bm{e}}} \def\vf{{\bm{f}}} \def\vg{{\bm{g}}} \def\vh{{\bm{h}}} \def\vi{{\bm{i}}} \def\vj{{\bm{j}}} \def\vk{{\bm{k}}} \def\vl{{\bm{l}}} \def\vm{{\bm{m}}} \def\vn{{\bm{n}}} \def\vo{{\bm{o}}} \def\vp{{\bm{p}}} \def\vq{{\bm{q}}} \def\vr{{\bm{r}}} \def\vs{{\bm{s}}} \def\vt{{\bm{t}}} \def\vu{{\bm{u}}} \def\vv{{\bm{v}}} \def\vw{{\bm{w}}} \def\vx{{\bm{x}}} \def\vy{{\bm{y}}} \def\vz{{\bm{z}}}  % Elements of vectors \def\evalpha{{\alpha}} \def\evbeta{{\beta}} \def\evepsilon{{\epsilon}} \def\evlambda{{\lambda}} \def\evomega{{\omega}} \def\evmu{{\mu}} \def\evpsi{{\psi}} \def\evsigma{{\sigma}} \def\evtheta{{\theta}} \def\eva{{a}} \def\evb{{b}} \def\evc{{c}} \def\evd{{d}} \def\eve{{e}} \def\evf{{f}} \def\evg{{g}} \def\evh{{h}} \def\evi{{i}} \def\evj{{j}} \def\evk{{k}} \def\evl{{l}} \def\evm{{m}} \def\evn{{n}} \def\evo{{o}} \def\evp{{p}} \def\evq{{q}} \def\evr{{r}} \def\evs{{s}} \def\evt{{t}} \def\evu{{u}} \def\evv{{v}} \def\evw{{w}} \def\evx{{x}} \def\evy{{y}} \def\evz{{z}}  % Matrix \def\mA{{\bm{A}}} \def\mB{{\bm{B}}} \def\mC{{\bm{C}}} \def\mD{{\bm{D}}} \def\mE{{\bm{E}}} \def\mF{{\bm{F}}} \def\mG{{\bm{G}}} \def\mH{{\bm{H}}} \def\mI{{\bm{I}}} \def\mJ{{\bm{J}}} \def\mK{{\bm{K}}} \def\mL{{\bm{L}}} \def\mM{{\bm{M}}} \def\mN{{\bm{N}}} \def\mO{{\bm{O}}} \def\mP{{\bm{P}}} \def\mQ{{\bm{Q}}} \def\mR{{\bm{R}}} \def\mS{{\bm{S}}} \def\mT{{\bm{T}}} \def\mU{{\bm{U}}} \def\mV{{\bm{V}}} \def\mW{{\bm{W}}} \def\mX{{\bm{X}}} \def\mY{{\bm{Y}}} \def\mZ{{\bm{Z}}} \def\mBeta{{\bm{\beta}}} \def\mPhi{{\bm{\Phi}}} \def\mLambda{{\bm{\Lambda}}} \def\mSigma{{\bm{\Sigma}}}  % Tensor \DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl} \SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n} \newcommand{\tens}[1]{\bm{\mathsfit{#1}}} \def\tA{{\tens{A}}} \def\tB{{\tens{B}}} \def\tC{{\tens{C}}} \def\tD{{\tens{D}}} \def\tE{{\tens{E}}} \def\tF{{\tens{F}}} \def\tG{{\tens{G}}} \def\tH{{\tens{H}}} \def\tI{{\tens{I}}} \def\tJ{{\tens{J}}} \def\tK{{\tens{K}}} \def\tL{{\tens{L}}} \def\tM{{\tens{M}}} \def\tN{{\tens{N}}} \def\tO{{\tens{O}}} \def\tP{{\tens{P}}} \def\tQ{{\tens{Q}}} \def\tR{{\tens{R}}} \def\tS{{\tens{S}}} \def\tT{{\tens{T}}} \def\tU{{\tens{U}}} \def\tV{{\tens{V}}} \def\tW{{\tens{W}}} \def\tX{{\tens{X}}} \def\tY{{\tens{Y}}} \def\tZ{{\tens{Z}}}   % Graph \def\gA{{\mathcal{A}}} \def\gB{{\mathcal{B}}} \def\gC{{\mathcal{C}}} \def\gD{{\mathcal{D}}} \def\gE{{\mathcal{E}}} \def\gF{{\mathcal{F}}} \def\gG{{\mathcal{G}}} \def\gH{{\mathcal{H}}} \def\gI{{\mathcal{I}}} \def\gJ{{\mathcal{J}}} \def\gK{{\mathcal{K}}} \def\gL{{\mathcal{L}}} \def\gM{{\mathcal{M}}} \def\gN{{\mathcal{N}}} \def\gO{{\mathcal{O}}} \def\gP{{\mathcal{P}}} \def\gQ{{\mathcal{Q}}} \def\gR{{\mathcal{R}}} \def\gS{{\mathcal{S}}} \def\gT{{\mathcal{T}}} \def\gU{{\mathcal{U}}} \def\gV{{\mathcal{V}}} \def\gW{{\mathcal{W}}} \def\gX{{\mathcal{X}}} \def\gY{{\mathcal{Y}}} \def\gZ{{\mathcal{Z}}}  % Sets \def\sA{{\mathbb{A}}} \def\sB{{\mathbb{B}}} \def\sC{{\mathbb{C}}} \def\sD{{\mathbb{D}}} % Don't use a set called E, because this would be the same as our symbol % for expectation. \def\sF{{\mathbb{F}}} \def\sG{{\mathbb{G}}} \def\sH{{\mathbb{H}}} \def\sI{{\mathbb{I}}} \def\sJ{{\mathbb{J}}} \def\sK{{\mathbb{K}}} \def\sL{{\mathbb{L}}} \def\sM{{\mathbb{M}}} \def\sN{{\mathbb{N}}} \def\sO{{\mathbb{O}}} \def\sP{{\mathbb{P}}} \def\sQ{{\mathbb{Q}}} \def\sR{{\mathbb{R}}} \def\sS{{\mathbb{S}}} \def\sT{{\mathbb{T}}} \def\sU{{\mathbb{U}}} \def\sV{{\mathbb{V}}} \def\sW{{\mathbb{W}}} \def\sX{{\mathbb{X}}} \def\sY{{\mathbb{Y}}} \def\sZ{{\mathbb{Z}}}  % Entries of a matrix \def\emLambda{{\Lambda}} \def\emA{{A}} \def\emB{{B}} \def\emC{{C}} \def\emD{{D}} \def\emE{{E}} \def\emF{{F}} \def\emG{{G}} \def\emH{{H}} \def\emI{{I}} \def\emJ{{J}} \def\emK{{K}} \def\emL{{L}} \def\emM{{M}} \def\emN{{N}} \def\emO{{O}} \def\emP{{P}} \def\emQ{{Q}} \def\emR{{R}} \def\emS{{S}} \def\emT{{T}} \def\emU{{U}} \def\emV{{V}} \def\emW{{W}} \def\emX{{X}} \def\emY{{Y}} \def\emZ{{Z}} \def\emSigma{{\Sigma}}  % entries of a tensor % Same font as tensor, without \bm wrapper \newcommand{\etens}[1]{\mathsfit{#1}} \def\etLambda{{\etens{\Lambda}}} \def\etA{{\etens{A}}} \def\etB{{\etens{B}}} \def\etC{{\etens{C}}} \def\etD{{\etens{D}}} \def\etE{{\etens{E}}} \def\etF{{\etens{F}}} \def\etG{{\etens{G}}} \def\etH{{\etens{H}}} \def\etI{{\etens{I}}} \def\etJ{{\etens{J}}} \def\etK{{\etens{K}}} \def\etL{{\etens{L}}} \def\etM{{\etens{M}}} \def\etN{{\etens{N}}} \def\etO{{\etens{O}}} \def\etP{{\etens{P}}} \def\etQ{{\etens{Q}}} \def\etR{{\etens{R}}} \def\etS{{\etens{S}}} \def\etT{{\etens{T}}} \def\etU{{\etens{U}}} \def\etV{{\etens{V}}} \def\etW{{\etens{W}}} \def\etX{{\etens{X}}} \def\etY{{\etens{Y}}} \def\etZ{{\etens{Z}}}  % The true underlying data generating distribution \newcommand{\pdata}{p_{\rm{data}}} % The empirical distribution defined by the training set \newcommand{\ptrain}{\hat{p}_{\rm{data}}} \newcommand{\Ptrain}{\hat{P}_{\rm{data}}} % The model distribution \newcommand{\pmodel}{p_{\rm{model}}} \newcommand{\Pmodel}{P_{\rm{model}}} \newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}} % Stochastic autoencoder distributions \newcommand{\pencode}{p_{\rm{encoder}}} \newcommand{\pdecode}{p_{\rm{decoder}}} \newcommand{\precons}{p_{\rm{reconstruct}}}  \newcommand{\laplace}{\mathrm{Laplace}} % Laplace distribution  \newcommand{\E}{\mathbb{E}} \newcommand{\Ls}{\mathcal{L}} \newcommand{\R}{\mathbb{R}} \newcommand{\emp}{\tilde{p}} \newcommand{\lr}{\alpha} \newcommand{\reg}{\lambda} \newcommand{\rect}{\mathrm{rectifier}} \newcommand{\softmax}{\mathrm{softmax}} \newcommand{\sigmoid}{\sigma} \newcommand{\softplus}{\zeta} \newcommand{\KL}{D_{\mathrm{KL}}} \newcommand{\Var}{\mathrm{Var}} \newcommand{\standarderror}{\mathrm{SE}} \newcommand{\Cov}{\mathrm{Cov}} % Wolfram Mathworld says  is for function spaces and  is for vectors % But then they seem to use  for vectors throughout the site, and so does % wikipedia. \newcommand{\normlzero}{L^0} \newcommand{\normlone}{L^1} \newcommand{\normltwo}{L^2} \newcommand{\normlp}{L^p} \newcommand{\normmax}{L^\infty}  \newcommand{\parents}{Pa} % See usage in notation.tex. Chosen to match Daphne's book.  \DeclareMathOperator*{\argmax}{arg\,max} \DeclareMathOperator*{\argmin}{arg\,min}  \DeclareMathOperator{\sign}{sign} \DeclareMathOperator{\Tr}{Tr} \let\ab\allowbreak       Instead of treating MT as seq2seq learning in the current NMT, this work presents the first graph-to-sequence NMT model, Graph-Transformer. Considering that graph other than sequence is a generalized structure formalism, modeling graph information inside model may facilitate NMT model to learn important subgraph information from source. As the multigraph defined over the sentence cannot be immediately by one part of the model such as just one layer, we assign every layer of the model to learn subgraphs with different orders, respectively. As our model implementation, we revise the SAN so that it may acquire such explicit subgraph information through our introduced incremental representation. Results of experiments show that our method can effectively boost the Transformer.        
"," \checkhere{ Neural dialogue response generation has gained much popularity in recent years.  Maximum Likelihood Estimation  objective is widely adopted in existing dialogue model learning. However, models trained with MLE objective function are plagued by the low-diversity issue when it comes to the open-domain conversational setting. Inspired by the observation that humans not only learn from the positive signals but also benefit from correcting behaviors of undesirable actions, in this work, we introduce contrastive learning into dialogue generation, where the model explicitly perceives the difference between the well-chosen positive and negative utterances. Specifically, we employ a pretrained baseline model as a reference. During contrastive learning, the target dialogue model is trained to give higher conditional probabilities for the positive samples, and lower conditional probabilities for those negative samples, compared to the reference model. To manage the multi-mapping relations prevalent in human conversation, we augment contrastive dialogue learning with group-wise dual sampling. Extensive experimental results show that the proposed group-wise contrastive learning framework is suited for training a wide range of neural dialogue generation models with very favorable performance over the baseline training approaches. }",57
" Spoken dialogue systems  connect users and computer applications through human-machine conversations.  The users can achieve their goals, such as finding a restaurant, by interacting with a task-oriented SDS over multiple dialogue rounds or turns.  Dialogue state tracking  is an important task in SDS and the key function  is to maintain the state of the system so as to track the progress of the dialogue.  In the context of this work, a state  is the user's intention or interest accumulated from the conversation history, and the user's intention or interest at each turn is referred to as turn-level state.  %The state and immediate state are usually expressed in terms of a set of slot-value pairs.  % For example, the state  contains two slot-value pairs, . In this example,  and  are slots, and ,  are values. This state expresses the system's belief that the user wants to find a cheap Italian restaurant.  %At each turn, the system generates an action, which is expressed to the user as sentences in natural language, and the user responds with some sentences, referred to as an utterance. The system then updates its state. The problem of dialogue state tracking  is to learn a predictor from a set of training dialogues, each specified as a sequences of  quadruples; the learned predictor needs to be able to predict the state of the current turn from the dialogue history.    %Various models have been developed for DST. Traditional works usually deal with the task through incorporating a Spoken Language Understanding  module. These works make limited progress and rely on hand-crafted features. The neural networks thus have been used for DST and achieve much success.  Many neural-network models have been successfully applied to DST. These models usually solve the DST problem by two approaches, the Implicit Tracking and the Explicit Tracking. As is shown in Figure , the Implicit Tracking models  employs recurrent networks to accumulate features extracted from historical system action and user utterance pairs. A classifier is then built upon these accumulated features for state prediction. Although the Implicit Tracking captures temporal feature dependencies in recurrent-network cells, the state dependencies are not explicitly modeled. Only considering temporal feature dependencies is insufficient for accurate state prediction. This fact has been confirmed via an ablation study in our experiment.  Unlike the Implicit Tracking, the Explicit Tracking approaches, such as NBT and GLAD,  model the state dependencies explicitly. From the model structure in Figure, the Explicit Tracking approaches first build a classifier to predict the turn-level state of each turn and then utilize a state aggregator for state aggregation.   %One branch of these models handle DST problem by building an immediate-state predictor and map the historical immediate states to the accumulative state. To distinguish this branch of models from another one that ignore the immediate state and directly model the state accumulation through Recurrent Neural Networks , we name the former indirect models and the latter direct models. Unlike indirect models, Direct models, including, don't explicitly model the dependencies between the immediate state and the accumulative state. Indirect models like NBT and GALD, build their immediate-state predictors using features extracted from the current turn's system action and user uttrance , and update the state by a deterministic rule or heuristics. They use the Convolutional Neural Networks  or attention-based RNNs for feature extraction and achieve remarkable improvements upon the previous models. Despite their success, there are two limitations in existing indirect models. Despite achieving remarkable improvements upon the previous models, current Explicit Tracking models can be further improved in two aspects. One is that the temporal feature dependencies should be considered in model design. The Explicit Tracking models only extract features from the current system action and user utterance pair. In practice, the slot-value pairs in different turns are highly dependent. For example, if a user specifies  appears in the future turn-level states.   	\end{center} 	:Feature Extractor, such as CNNs, RNNs. {\bf RC}:Recurrent Cell, such as LSTM, GRU. {\bf CL}:Classifier. {\bf SA}:State Aggregator. The dotted arrowed lines emphasize modeling temporal feature dependencies. The dashed arrowed lines emphasize modeling temporal state dependencies.} 	 \end{figure*}  The other is that the uncertainties in the state aggregation can be more expressively modeled. The state-aggregation approaches in current Explicit Tracking models are sub-optimal. The deterministic rule in GLAD will propagate errors to future turns and lead to incorrect state aggregation. The heuristic aggregation in NBT needs further estimate the best configuration of its coefficient . An approach that can both reduce the error propagation and require less parameter estimation is necessary for the state aggregation.  % The other is that the uncertainties in state aggregation can be more expressively modeled. The deterministic state aggregation rule used in GLAD is sub-optimal because the errors caused by the hard decision will propagate to future turns and lead to incorrect aggregation of the future states. The NBT is aware of this uncertainty and deal with it using simple rule-based aggregation. And the best configuration of its coefficient need to be estimated.  %In Figure, we see that both TEN and TEN-X model can correctly estimate the state at the first turn and the second turn. At the third turn, suppose that the predicted turn-label probabilities on the values are , the TEN-X model using the deterministic state updating rule , will output a wrong state value . On the contrary, the TEN model with uncertainty modeling can still obtain the true state value  with a higher confidence on . This example indicates the significance of uncertainty modeling in state estimation. Although turn labels and states are related through a deterministic mapping , models estimating the state with deterministic rules  are in fact sub-optimal. This is because the estimation of the current state has averaged over all uncertainties from estimation of the previous states and turn labels. Such an averaging effect is ignored when the deterministic rules are used for state updating. Models which attempt to update the states with heuristics or leave the state updating as a learning task  are also sub-optimal. Actually, due to the fact that the deterministic mapping already exists, any heuristics or learned function may under-perform this deterministic mapping. A proper solution should maintain the deterministic mapping and handle the uncertainties simultaneously. % This is because in a training dialogue, when the system estimates the current state, it arguably has accounted for both uncertainties in estimating the previous state and in estimating the current turn label. That is, the system predictive distribution of the current state result from having averaged over these uncertainties. Updating the state using deterministic rules essentially ignores such an averaging effect. % dependency need to be taken into account for turn label and state prediction. 2) inadequate consideration of the uncertainty in the state estimates. The prediction of current state should consider the uncertainty in estimating the previous state and the uncertainty in estimating the current turn label. 3) less expressive modelling of the known dialogue dynamics. The known dynamics between the turn labels and the states can model explicitly. A detailed discussion about the limitation of existing models is depicted in the ""Related Works"" Section. % %{\bf Less expressive modelling of the known dialogue dynamics.} Some other works, including, build their DST models with recurrent networks. They ignore the provided turn labels and directly use the states as training target. In these models, the temporal feature dependency is considered when predicting the states. They however, do not explicitly model the known dynamics between the turn labels and the states. Demanding additional capacity, these models may under-perform the models which use the turn labels as training target. The immediate state is an important source for estimating the accumulative state because the accumulative state changes only when the immediate state has changed.  In this study, we propose a novel Temporally Expressive Networks  to jointly model the temporal feature dependencies and temporal state dependencies ). Specifically, to improve the turn-level state prediction, we exploits hierarchical recurrent networks to capture temporal feature dependencies across dialogue turns. Furthermore, to reduce state aggregation errors, we introduce factor graphs to formulate the state dependencies, and employ belief propagation to handle the uncertainties in state aggregation. Evaluating on the DSTC2, WOZ and MultiWoZ datasets, TEN is shown to improve the accuracy of the turn-level state prediction and the state aggregation.  The TEN model establishes itself as a new state-of-the-art model on the DSTC2 dataset and a state-of-the-art comparable model on the WOZ dataset.  %The system will take an action and respond to users on the basis of the estimated state. % The State Updating task has not been fully studied among the three subtasks. Some works avoid Turn-level Prediction and directly update the dialogue state using Recurrent Neural Networks. It's natural to use RNN for state updating, but the supervision of the turn labels will not be considered. Some other works train their models on the turn labels, and update the dialogue states with rule, which performs compatible or better than the models updating states with RNN. The limitations of the updating rules used in recent works are:  The updating rule in GLAD makes hard decision on the state and ignores the rich probabilistic distribution information, thus the turn-level error may propagate cumulatively.   The updating rule in NBT  rely on carefully tuned hyperparameters and this simple rule has difficulty handling the complex nature of state updating.  The MDT proposes a RNN-based updating rule training using the outputs of the turn-level prediction model. However, the updating rule is trained independently with the turn-level prediction model. % In this work, we propose a novel state updating model with factor graphs, which we call Factor Graph Tracker . The FGT is implemented with the sum-product algorithm and can effectively reduce the cumulative error propagation. It is natural to use sum-product algorithm to summary the previous states and the turn-level goal for updating the current state. The FGT can easily been built upon the turn-level prediction model as a unified model; turn-level prediction and state updating can thus been jointly learned. The state tracking may benefit from this joint learning strategy.  % Another limitation of existing models is that the dependency between turn-level goals is ignored at the turn-level prediction stage. We argue that the dependency between turn-level goals should be considered. For example, the area slot is usually requested after the food slot been requested; and if a slot-value pair has already been imformed, it has lower probability been expressed by the user at current turn. Instead of directly building classifiers to predict turn-level goals, in this work, we use GRU as a turn-label-tracker to handle the dependency between turn-level goals and build classifiers upon the outputs of the turn-label-tracker. % The GLAD introduce attention machinisum and propose a Global-Locally Self-Attentive  encoder for feature extraction. Specifically, a global self attention model with bidirectional LSTM  is used to extract global features of the input and for each slot, there is a local BiLSTMATT extracting slot-specific features. We propose a slot attention encoder that simplify the GLSA encoder and significantly decreases the model parameters.      In this work, we propose a group-wise contrastive dialogue learning approach, that explicitly perceives the difference between the well-chosen positive and negative utterances, and manages the multi-mapping relations in human conversations simultaneously.  Given a training instance, the proposed learning framework first organizes a group of positive samples and negative samples regarding context-response matching degrees, and then trains the target dialogue model to give higher conditional probabilities for positive pairs and lower probabilities for the negatives. Extensive experimental results show that the proposed learning framework brings a solid favorable performance boost amongst various strong baseline approaches.  
"," Dialogue state tracking  is an important part of a spoken dialogue system. Existing DST models either ignore temporal feature dependencies across dialogue turns or fail to explicitly model temporal state dependencies in a dialogue. In this work, we propose Temporally Expressive Networks  to jointly model the two types of temporal dependencies in DST. The TEN model utilizes the power of recurrent networks and probabilistic graphical models. Evaluating on standard datasets, TEN is demonstrated to improve the accuracy of turn-level-state prediction and the state aggregation.   %The existing models usually solve DST problem by two approaches, Implicit Tracking and Explicit Tracking. The Implicit Tracking employs recurrent networks to model the temporal feature dependencies across dialogue turns, but fails to consider the temporal state dependencies. While Explicit Tracking models state dependencies explicitly, it ignores the feature dependencies.  %Dialogue state tracking  is an important part of a spoken dialogue system. Some of the prior arts for DST build an momentary-state predictor and map the historical immediate states to the accumulative state. These models are however insufficiently modelling the temporal dependencies across dialogue turns and the uncertainties in state updating. In this work, we introduce a probabilistic graphical model to formulate the dialogue process and propose Temporally Expressive Networks  that utilizes hierarchical recurrent networks and belief propagation to deal with these issues. Evaluating on standard datasets, the proposed model is demonstrated to be significantly effective in improving accuracy for immediate-state prediction and reducing errors in state updating.  % a GRU  encoder sharing parameters across all slots to capture global information. The slot attention is adopted for each slot to capture local information. To alleviate the error propagation caused by hard decision on the turn-level goals, we propose a neural-network-based DST model with factor graphs and introduce the sum-product algorithm to handle the problem. Experimental stdies demonstrate that the proposed approach significantly improves the current art in tracking the joint goals.",58
"  %%General subject \ac{NLG} is the process of generating coherent natural language text from non-linguistic data. Despite community agreement on the text and speech output of these systems, there is far less consensus on what the input should be. A large number of inputs have hence been employed for \ac{NLG} systems, including images , numeric data, and \ac{SW} data. Practical applications can be found in domains such as weather forecasts , feedback for car drivers , diet management . %%%specific problem subject  Presently, the generation of natural language from  %\ac{SW}, more precisely from  \ac{RDF} data has gained substantial attention. The RDF-to-text task has hence been proposed to investigate the quality of automatically generated texts from \ac{RDF} \acp{KG}.  %Moreover, \ac{RDF} has demonstrated a promising ability to support the creation of \ac{NLG} benchmarks.  With the emergence of neural methods, end-to-end data-to-text models have been introduced to learn input-output mappings directly. These approaches rely much less  %\todo{less is a comparative, ergo less than what?}  on explicit intermediate representations compared to rule-based approaches.   Although Neural \ac{NLG} models have been achieving very good results  %\todo{cite paper where this is shown} , English is the only language that has been widely targeted.   % \todo[inline]{why it is important to be able to generate different language text with the same model} % \todo[inline]{What is the motivation behind investigating generation for different language families?} In this work, we alleviate this language limitation by proposing a multilingual approach, named NABU. The motivation behind multilingual models lies in several directions, mainly in  transfer learning; when low-resource language pairs are trained together with high-resource languages, the translation quality improves;  zero-shot translation, where multilingual models are able to translate between language pairs from similar families that were never seen during training;  Easy deploy, a multilingual model achieving same performance on many languages in comparison to several separate language-specific models are much more desirable for companies in terms of deployment.  Our approach, NABU, is based on the fact that knowledge graphs are language-agnostic and hence can be used on the encoder side to generate multilingual text. NABU consists of an encoder-decoder architecture which incorporates structural information of RDF triples using an encoding mechanism inspired by \ac{GAT}. In contrast to recent related work, NABU relies on the use of a reification  %\todo{sure?}  strategy for modeling the graph structure of RDF input. The decoder part  %\todo{do you mean decoder?}  is based on the vanilla Transformer model along with an unsupervised tokenization model.  %which implements \ac{BPE} and unigram language model for handling  multilinguality. %\todo{Is the statement below really necessary in here?Would make sense to add that in the details of the approach.}  %Note that NABU follows the same strategy of recent literature on multilingual \ac{NMT} models in which a special token is used in the encoder to determine to what target language to translate.  %evaluation We evaluate NABU on the standard benchmarking WebNLG datasets in three settings: monolingual, bilingual and multilingual. For the monolingual setting, we compare NABU with state-of-the-art English approaches and also perform experiments on Russian and German. The goal of the bilingual setting is to analyze the performance of NABU for language families. To achieve this goal, we train and evaluate bilingual models using NABU on English-German and on English-Russian. In the multilingual setting, we compare NABU with a multilingual Transformer model on English, German and Russian. %%%results Our results show that NABU outperforms state-of-the-art approaches on English and achieves 66.21 BLEU. NABU also achieves consistent results across all languages on multilingual settings with 56.04 BLEU. In addition, NABU presents promising results on the bilingual models with 61.99 BLEU.  %\todo{numbers?}  Our findings suggest that NABU is able to generate multilingual text with similar quality to that generated by humans. %conclusion The main contributions of this paper can be summarized as follows:    The version of NABU used in this paper and also all experimental data are publicly available.~\footnote{https://github.com/dice-group/NABU}.    This paper studies the problem of state generation for multi-domain dialogues. Existing generation-based models fail to model the dialogue dependencies and ignore the slot-overlapping problem in MDST. To overcome the limitation of existing models, we present novel Parallel Interactive Networks  for more accurate and robust dialogue state generation. The design of the PIN model is inspired by the interactive nature of the dialogues and the overlapping slots in the ontology. The Interactive Encoder characterizes the cross-turn dependencies and the in-turn dependencies. The slot-overlapping problem is solved by introducing the slot-level context. Furthermore, a distributed copy mechanism is introduced to perform a selective copy from either the historical system utterances or the historical user utterances. Empirical studies on two benchmark datasets demonstrate the effectiveness of the PIN model.       File emnlp2020.tex      Based on the style files for ACL 2020, which were    Based on the style files for ACL 2018, NAACL 2018/19, which were    Based on the style files for ACL-2015, with some improvements     taken from the NAACL-2016 style    Based on the style files for ACL-2014, which were, in turn,    based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,    EACL-2009, IJCNLP-2008...    Based on the style files for EACL 2006 by    e.agirre@ehu.es or Sergi.Balari@uab.es    and that of ACL 08 by Joakim Nivre and Noah Smith  \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{emnlp2020} \usepackage{times} \usepackage{latexsym} \usepackage{amsmath} \usepackage{amssymb} \usepackage{float} \usepackage{booktabs} \usepackage{enumerate} \usepackage{tikz}  \usetikzlibrary{calc}  \DeclareMathOperator{\softmax}{softmax}  \include{tikzd} \renewcommand{\UrlFont}{\ttfamily\small}    This is not strictly necessary, and may be commented out,   but it will improve the layout of the manuscript,   and will typically save some space. \usepackage{microtype}  \aclfinalcopy   Uncomment this line for the final submission  \def\aclpaperid{***}    Enter the acl Paper ID here  \setlength\titlebox{7cm}   You can expand the titlebox if you need extra space   to show all the authors. Please do not make the titlebox   smaller than 5cm ; we will check this   in the camera-ready version and ask you to change it back.  \newcommand\BibTeX{B\TeX}  \title{Parallel Interactive Networks for Multi-Domain Dialogue State Generation} \author{   Junfan Chen \\   BDBC and SKLSDE\\   Beihang University, China \\   \texttt{chenjf@act.buaa.edu.cn} \\   \And   Richong Zhang\thanks{Corresponding author}\\   BDBC and SKLSDE\\   Beihang University, China \\   \texttt{zhangrc@act.buaa.edu.cn} \\   \AND   Yongyi Mao \\   School of EECS\\   University of Ottawa, Canada \\   \texttt{ymao@uottawa.ca} \\   \And    Jie Xu \\   School of Computing\\   University of Leeds, United Kingdom \\   \texttt{j.xu@leeds.ac.uk} \\ }    \date{} \begin{document} \maketitle        
"," The RDF-to-text task has recently gained substantial attention due to continuous growth of Linked Data. In contrast to traditional pipeline models, recent studies have focused on neural models, which are now able to convert a set of RDF triples into text in an end-to-end style with promising results. However, English is the only language widely targeted. We address this research gap by presenting NABU, a multilingual graph-based neural model that verbalizes RDF data to German, Russian, and English. NABU is based on an encoder-decoder architecture, uses an encoder inspired by Graph Attention Networks and a Transformer as decoder. Our approach relies on the fact that knowledge graphs are language-agnostic and they hence can be used to generate multilingual text. We evaluate NABU in monolingual and multilingual settings on standard benchmarking WebNLG datasets. Our results show that NABU outperforms state-of-the-art approaches on English with 66.21 BLEU, and achieves consistent results across all languages on the multilingual scenario with 56.04 BLEU. %Moreover, we trained bilingual models for analyzing the capability of NABU to model jointly distinct language families such as English-Russian.  %\todo{Which conclusion did you reach from this training?} \keywords{Knowledge Graphs  \and Natural Language Generation \and Semantic Web.}",59
"   We are digitally surrounded by computational Language Models  that guide us while writing to reduce the user effort, suggest different options for words/sentences to enhance our style, or fix our grammatical/correctness errors accurately . Many of the keys we press while writing on a keyboard act as part of the inputs to compose new datasets for those models that shape how we communicate with others. Nevertheless, does it happen in the same way when we write code?  Succinctly, yes. According to some recent surveys found in the literature  , the Natural Language Processing  subfield related to programming language includes examples of LMs used in several tasks and contexts. For example, the authors of  used different techniques such as graph-based statistical LMs, probabilistic LMs, or Deep Learning  LMs to suggest code to programmers similarly to auto-completer features in IDEs. LMs were used to generate automated source code based on sample code inputs or pseudo-code and evaluating how this generated code performs . Another exciting application of NLP into source code languages is the automatic translation between different languages. The work reported in  explores different supervised and unsupervised approaches to migrate code between different programming languages to improve interoperability or port codebases written in obsolete or deprecated languages . Another example found is the use of Bayesian networks, attention mechanisms, and pointer networks  to fill a given code portion with missings.  There is a more general understanding of the natural languages閳 different characteristics in the NLP broad field. Since there exist many research fields related to human languages, there is a richer background on existing language characteristics. For example, there is much knowledge on aspects like the minimal representation units of a word in a specific language, the most used words of a language, or if a word is a neologism or not. Programming languages share some syntax similarities with spoken languages. However, it does not have the same restrictions in the sense of common words or neologisms , or other syntax restrictions and features such as punctuation, format, or style. Every programming language has indeed reserved words and symbols to denote different actions, resources, or syntax. However, there is an essential part of the source code that is only limited by the programmer閳ユ獨 imagination, the conventions existing, or the guides for good practices. As  claims,     In that paper, Karampatsis and Sutton \citeyear{karampatsis2019maybe} present how segmenting words into subword units can improve source code modeling. Similarly, other researchers  dug in representing source code vocabulary with a similar emphasis on modeling words using sub-word units and envisioning their importance when using neural networks . Nevertheless, how that word segmentation affect the accuracy or the appropriateness of the code generated or auto-completed in some modern LM using deep learning approaches? That kind of question raises the main goal for this paper: discover what kinds of associations between different modern neural network architectures and tokenization models produce the best results when creating LMs to generate and auto-complete source code.  To pursue that goal, this research aims to conduct experiments combining different deep neural network  architectures with different tokenization and pre-trained models over an existing Python dataset. Using that experimentation, we want to investigate the combinations that improve code generation and auto-completion tasks  while checking the outcomes from those tasks using metrics like accuracy and human assessment.  The rest of the paper is as follows: Section 2 presents the different approaches followed during the research, the DNNs used, the software methods and data employed. Section 3 describes results achieved during the research according to different metrics and tests, while section 4 discusses these findings and the implications of the results as appropriate. Finally, Section 5 presents some conclusions.      \todo[inline]{BLEURT: Learning Robust Metrics for Text Generation] https://arxiv.org/abs/2004.04696)}   \todo[inline]{Say that we plan to investigate the generation from different graphs [Kaffee et al. : Mind the  Gap: Generation of Multilingual Wikipedia Summaries from Wikidata for ArticlePlaceholders]} We presented a multilingual RDF verbalizer which relies on graph attention \ac{NN} along with a reification strategy.   We carried out an extensive evaluation set for certifying the quality of our approach.  Our experiments suggest that our approach, named NABU, outperforms state-of-the-art approaches in English. Additionally, NABU presented consistent results across the languages used in our evaluation. NABU is language-agnostic, which means it can be ported easily to languages other than those considered in this paper.  Moreover, we reported the challenges for training bilingual models with languages of distinct families.  To the best of our knowledge, we are the first approach to exploit and achieve the multilinguality successfully in the RDF-to-text task. As future work, we aim to exploit other graph-based neural architecture and other reification approaches for improving NABU's performance. Additionally, we plan to investigate how to deal with the similarity of relations by combining language models and new evaluation metrics. Moreover, we plan to investigate our methodology in the context of low-resource scenarios as well as on different \acp{KG}.  
"," In recent years, the use of deep learning in language models gained much attention. Some research projects claim that they can generate text that can be interpreted as human-writing, enabling new possibilities in many application areas. Among the different areas related to language processing, one of the most notable in applying this type of modeling is programming languages. For years, the Machine Learning community has been researching this software engineering area, pursuing goals like applying different approaches to auto-complete, generate, fix, or evaluate code programmed by humans. Considering the increasing popularity of the Deep-Learning-enabled language models approach, we detected a lack of empirical papers that compare different deep learning architectures to create and use language models based on programming code. This paper compares different neural network architectures like AWD-LSTMs, AWD-QRNNs, and Transformer while using transfer learning and different tokenizations to see how they behave in building language models using a Python dataset for code generation and filling mask tasks. Considering the results, we discuss each approach闁炽儲鐛 different strengths and weaknesses and what gaps we find to evaluate the language models or apply them in a real programming context.",60
"    A dominant approach to text generation  is to use autoregressive models learned by maximum likelihood estimation  on supervised data. However, this approach introduces two well-known discrepancies between training and evaluation objectives that lead to undesired generations.  % First, the training loss is negative log-likelihood, whereas the evaluation is based on human judgment of the output quality.  Under model misspecification, MLE tends to over-generalize, assigning large probability mass to both high-quality and low-quality sequences . Therefore, in practice, we must carefully select the  decoding algorithms to produce high-quality outputs.  Second, during training, the autoregressive model conditions on the gold history/prefix; however, at inference time it conditions on model-generated history. This is known as the exposure bias problem . In the worst case, one incorrect prediction can produce a low-probability prefix under the gold data distribution, and errors compound in each of the following steps . In practice, prior work has observed problems such as repetition and hallucination partly due to exposure bias .   We aim to bridge the gap between training and evaluation in this paper. To match training and evaluation objectives, ideally we should maximize output quality given model-generated histories. This corresponds to the reinforcement learning  objective: maximizing the expected reward  over trajectories  induced by the policy .  However, optimizing this objective is notoriously difficult. Prior RL approaches mainly focus on fine-tuning a learned model to optimize sequence-level metrics such as BLEU~, but empirically it remains unclear if RL is beneficial to text generation . % Note that many challenges in RL arise from exploring an exponentially large space of sequences,  with sparse rewards only on those close to the reference. We thus propose to learn from only the reference sequences without interaction . Specifically, we use off-policy policy gradient with importance weighting , where training examples with higher probability under the model are weighted higher.  Further, our reward functions approximate human judgment of the output quality  by estimating how likely a human would have generated a sequence.  We call our algorithm \algoname .    Results on news summarization,  question generation,  and machine translation show that \algoname leads to better model performance than MLE and RL fine-tuning by both task metrics and human-rated quality.  Further, our analysis shows that \algoname learns high-precision models that are less sensitive to decoding algorithms. In addition, it alleviates exposure bias: the output quality does not degrade much as generation length increases.     Considering the results obtained, one could convincingly assert that the tokenization model used profoundly affects the results when generating automated source code. Although that may be accurate, we must discuss it carefully.     First, our overall results are consistent with the existing literature . Sub-word tokenization works better in the case of modeling source code, as \citeyear{karampatsis2019maybe} stated. Every result obtained is consistent in that sense. Even more, as \citeyear{karpathy2016} envision, char tokenization probably should the best option to try by default when dealing with LMs and source code. Furthermore, according to the results achieved, models such as GPT-2 -using a tokenization model based on BPE over raw bytes- can outperform LSTM/QRNN models like those we tested to grasp better the internals of a programming language. As showcased during the results, even if GPT-2 was not the best model in terms of accuracy, it gave better code outputs than the other ones selected for the comparison.  As future work, it would be great to check if the better textual output in the case of GPT-2 is because of a) it is a much bigger and better pre-trained model , b) it is related to dataset's size or quality, c) if it is related to both causes or, d) if it is related to other issues.  Continuing with the comments about the accuracy, one may note that the textual outputs generated by AWD-LSTM char, AWD-QRNN char, and GPT-2 could be polished to be more accurate. The final training loss is higher than the validation loss for the three selected DNN architectures, which can be a sign of underfitting. We find the same issue  for BERT and RoBERTa-based models. Whether the purpose of this paper is not to produce state-of-the-art results per se, we continued the training for over five more epochs to verify it. The improvement obtained from extending the training for the best approaches was residual in general, so we decided to report the results for 1+30 epochs in AWD-LSTMs and AWD-QRNNs, and 1+10 epochs for Transformer.    Regarding the pre-training and transfer learning, every pre-trained model  got better accuracy than its non-pre-trained counterparts except in word tokenization models. It seems to be strongly related to the statements we introduced at the beginning of this paper, citing  about the source code does not have the same restrictions in the sense of common words or neologisms. In this sense, the conclusion comes into our mind rapidly: if we consider source code words in 閳ユ辅ord閳 units, they probably will not fit in the fixed set of words used in a human language like English. So, the LM閳ユ獨 knowledge acquired during the pre-training is not entirely valid when we get out of that fixed set of words that compose a language. Most words in the programming language are neologisms for the LMs pre-trained in English, and thus, it needs to incorporate them and their relationships into the learned knowledge. For the sub-word units, the LM can be less sensible to the neologisms. Potentially, it could be more robust the more divided a word is since the set of bytes or chars is more straightforward than the chunks present in richer constructions or information units.  Going deeper into this research, concerning the pre-training effect over LMs modeling source code, it could be worth researching the relationship between the pre-training in different human-spoken languages and the LM ability to work with existing source code specific programming languages.    About the tests made generating source code or filling in the blanks using the trained LMs, we think that, in general, the textual results obtained are not so good, yet they are informative of how LMs are working and how they can be improved. One of the things that can explain these results is the dataset used. In this case, we used a public dataset that other researchers can use to make results and experiments comparable and replicable. In the literature, we do not find a standard dataset for these tasks against which we can compare easily. Other papers  use custom datasets, but we find a lack in the literature of well-recognized code datasets to use. Comparing with other recent papers in the NLP field used as the basis for this research , the dataset may be relatively small to train a big LM to accomplish appropriately challenging tasks like generating source code or auto-completing it. Future work may be testing these or new approaches in bigger datasets to train big LMs focused on modeling the Python language and checking whether the results are better. Recent examples of LMs -such as GPT-3 - claim to produce accurate textual outputs even in contexts in which they were not trained. Part of the explanation given for that ability is the use of gargantuan datasets combined with Transformer and other attention-based architectures. So, those approaches can also be relevant to other contexts like ours.  Another line for future research can be using datasets focused on specific libraries or Python aspects and verify if these approaches specialize positively for those contexts the DNN models used in this paper.  Related to evaluating the code generated or filled, we observed in the literature different approaches . In the context of LMs modeling source code, many papers and software libraries devoted to translating between programming languages typically evaluate text generation using methods and metrics like BLEU , or variants like SacreBLEU . Other papers like  rely on the accuracy to assess an LM閳ユ獨 performance based on deep learning. Some models can even solve different tasks that are part of existing benchmarks  or are evaluated, checking their perplexity . The current tendency in large models is to evaluate them using human intervention to evaluate the output閳ユ獨 quality . We assessed the models using accuracy during our experiments and evaluated the models閳 textual outputs based on our prior human knowledge. It would be interesting for the future to plan new evaluation processes involving larger cohorts of source code experts to evaluate the models such as  do. One of the potential new assessments can be usability tests conducted with programmers. They can compare the code they would write against the code proposed by any of the DNNs presented here and the result from other common code auto-completion tools included in integrated development environments. As we outlined in the results section, relying only on metrics like accuracy should not be enough. As in our case, accuracy and the other metrics can be a good indicator of the model閳ユ獨 performance, yet we need to verify LMs behavior and quality using complementary methods like specialized metrics or human evaluation. For tasks like auto-completion or source code generation, there are no existing specialized metrics , so one of the future research lines is improving the evaluation of LMs for source code. Based on some existing ideas in broad NLP, there are many opportunities to explore in that sense. From new test suites for language models used in source code contexts  to behavioral testing  or human-centric evaluation of the models  with particular emphasis on reproducible and unbiased assessments, or combinations of automatic testing and human-centric assessments.  \section{Conclusions}  This paper compares how different approaches to tokenization models, deep neural network architectures, pre-trained models, and transfer learning affect the results from language models used to generate source code or auto-complete software pieces. We studied different DNN architectures like AWD-LSTM, AWD-QRNN, and Transformer to seek which kind of them work better with different tokenization models . Also, we compared the pre-training effect on the results given by LMs after training them and fine-tuning them via transfer learning to work with other languages . As a result of this work, we find that in small LMs , the tokenization using char-sized chunks works better than using any other tokenization models. In larger models like the Transformer GPT-2, the accuracy was slightly worse than the other architectures. However, GPT-2 raised better results on the source code generation tests . For source code auto-completion, we tested some transformer models like BERT and RoBERTA. While their accuracy was above any other models, they did not perform very well when performing the tasks proposed in our tests. In general, we find that pre-trained models work better, even if they were not trained initially for a programming language like Python . Finally, related to evaluating tasks like automating source code generation and source code auto-completion, we raise concerns about the literature gaps and propose some research lines to work on in the future.   \section{ Acknowledgments} We thank the IBM Quantum team and the IBM Research ETX team for the insightful discussions about this research and the support received during the development of this research.     
","     Current approaches to text generation largely rely on autoregressive models and maximum likelihood estimation.     This paradigm leads to       diverse but low-quality samples due to mismatched learning objective and evaluation metric      and  exposure bias due to mismatched history distributions .      To alleviate these problems, we frame text generation as an offline reinforcement learning  problem with expert demonstrations ,     where the goal is to maximize quality given model-generated histories.      We propose \algoname :     an easy-to-optimize algorithm that learns from the demonstrations by importance weighting.      Intuitively, \algoname upweights confident tokens and downweights unconfident ones in the reference during training,      avoiding optimization issues faced by prior RL approaches that rely on online data collection.     According to both automatic and human evaluation,     models trained by \algoname outperform those trained by MLE and policy gradient      on summarization, question generation, and machine translation.      Further, our models are less sensitive to decoding algorithms     and alleviate exposure bias.",61
"  \let\thefootnote\relax\footnote{  Corresponding author.}  Recent years have witnessed significant improvements in vision and language communities, which have consequently led to substantial attention in vision-language multi-modality tasks such as visual grounding , image captioning , and visual question answering . Furthermore, as video becomes ubiquitous, as a daily source of information and communication, video-language tasks such as video captioning , video moment retrieval , and video question answering   are emerging as important topics. Among these topics, video QA is especially challenging, as it requires fine-grained understanding of both video and language. \sh{Figure  shows an example of multiple-choice video QA from the TVQA dataset. The multiple-choice video QA task requires the model to select the correct answer given a question, corresponding video frames, and subtitles.}        We provide an efficient algorithm that addresses the two train/test discrepancies in MLE training for text generation: likelihood as learning objective vs. quality as evaluation metric; gold history in training vs. model-generated history in inference. We have demonstrated that off-policy RL is a promising framework for text generation, with matched train/test objectives and optimization advantages like MLE. We believe more advanced off-policy learning techniques  can be easily integrated into text generation and further improve performance.   
"," Video Question Answering  requires fine-grained understanding of both video and language modalities to answer the given questions. In this paper, we propose novel training schemes for multiple-choice video question answering with a self-supervised pre-training stage and a supervised contrastive learning in the main stage as an auxiliary learning. In the self-supervised pre-training stage, we transform the original problem format of predicting the correct answer into the one that predicts the relevant question to provide a model with broader contextual inputs without any further dataset or annotation. For contrastive learning in the main stage, we add a masking noise to the input corresponding to the ground-truth answer, and consider the original input of the ground-truth answer as a positive sample, while treating the rest as negative samples. By mapping the positive sample closer to the masked input, we show that the model performance is improved. We further employ locally aligned attention to focus more effectively on the video frames that are particularly relevant to the given corresponding subtitle sentences. We evaluate our proposed model on highly competitive benchmark datasets related to multiple-choice video QA: TVQA, TVQA+, and DramaQA. Experimental results show that our model achieves state-of-the-art performance on all datasets. We also validate our approaches through further analyses.",62
" Neural machine translation  which typically follows the encoder-decoder framework, directly applies a single neural network to transform the source sentence into the target sentence. With tens of millions of trainable parameters in the NMT model, translation tasks are usually data-hungry, and many of them are low-resource or even zero-resource in terms of training data. Following the idea of unsupervised and self-supervised pre-training methods in the NLP area , some works are proposed to improve the NMT model with pre-training, by making full use of the widely available monolingual corpora . Typically, two different branches of pre-training approaches are proposed for NMT: model-fusion and parameter-initialization.  The model-fusion approaches seek to incorporate the sentence representation provided by the pre-trained model, such as BERT, into the NMT model .  These approaches are able to leverage the publicly available pre-trained checkpoints in the website but they need to change the NMT model to fuse the sentence embedding calculated by the pre-trained model. Large-scale parameters of the pre-trained model significantly increase the storage cost and inference time, which makes it hard for this branch of approaches to be directly used in production.  As opposed to model-fusion approaches, the parameter-initialization approaches aim to directly pre-train the whole or part of the NMT model with tailored objectives, and then initialize the NMT model with pre-trained parameters . These approaches are more production-ready since they keep the size and structure of the model same as standard NMT systems.  While achieving substantial improvements, these pre-training approaches have two main cons. Firstly, as pointed out by \citet{yang2019xlnet}, the artificial symbols like [mask] used by these approaches during pre-training are absent from real data at fine-tuning time, resulting in a pretrain-finetune discrepancy. Secondly, while each pre-training step only involves sentences from the same language, these approaches are unable to make use of the cross-lingual alignment information contained in the source and target monolingual corpus. We argue that, as a cross-lingual sequence generation task, NMT requires a tailored pre-training objective which is capable of making use of cross-lingual alignment signals explicitly, e.g., word-pair information extracted from the source and target monolingual corpus, to improve the performance.  To address the limitations mentioned above, we propose Code-Switching Pre-training  for NMT. We extract the word-pair alignment information from the source and target monolingual corpus automatically, and then apply the extracted alignment information to enhance the pre-training performance. The detailed training process of CSP can be presented in two steps:  1) perform lexicon induction to get translation lexicons by unsupervised word embedding mapping ; 2) randomly replace some words in the input sentence with their translation words in the extracted translation lexicons and train the NMT model to predict the replaced words. CSP adopts the encoder-decoder framework: its encoder takes the code-mixed sentence as input, and its decoder predicts the replaced fragments based on the context calculated by the encoder. By predicting the sentence fragment which is replaced on the encoder side, CSP is able to either attend to the remaining words in the source language or to the translation words of the replaced fragment in the target language. Therefore, CSP trains the NMT model to: 1) learn how to build the sentence representation for the input sentence as the traditional pre-training methods do; 2) learn how to perform cross-lingual translation with extracted word-pair alignment information. In summary, we mainly make the following contributions:   \footnotetext[1]{To be used in production easily, these models need to be distilled into a student model with the structure and size same as standard NMT systems.}   \sh{Video QA requires fine-grained understanding of both video and language modalities. To address this, we focus on the training procedure that could possibly take the most advantage out of the given data.} In this paper, we propose novel training schemes \sh{that} specialize in multiple-choice video QA. We first pre-train our model with a transformed problem format \sh{of predicting which questions are from which contexts} for a better weight initialization. \sh{We} then train \sh{our} model with the original QA problem format while being guided by contrastive representation learning. Our model achieves state-of-the-art performance on three highly challenging video QA datasets. We expect that our proposed method can be applied for various multiple-choice video QA tasks, bringing further performance improvement.  
","  This paper proposes a new pre-training method, called Code-Switching Pre-training  for Neural Machine Translation . Unlike traditional pre-training method which randomly masks some fragments of the input sentence,  the proposed CSP randomly replaces some words in the source sentence with their translation words in the target language. Specifically, we firstly perform lexicon induction with unsupervised word embedding mapping between the source and target languages, and then randomly replace some words in the input sentence with their translation words according to the extracted translation lexicons. CSP adopts the encoder-decoder framework: its encoder takes the code-mixed sentence as input, and its decoder predicts the replaced fragment of the input sentence. In this way, CSP is able to pre-train the NMT model by explicitly making the most of the cross-lingual alignment information extracted from the source and target monolingual corpus. Additionally,  we relieve the pretrain-finetune discrepancy caused by the artificial symbols like [mask].  To verify the effectiveness of the proposed method, we conduct extensive experiments on unsupervised and supervised NMT. Experimental results show that CSP achieves significant improvements over baselines without pre-training or with other pre-training methods.",63
" 	% \{-0.3em} 	% General introduction 	Belief tracking  is an important component in task-oriented dialog systems. The system tracks user goals through multiple dialog turns, i.e. infers structured belief states expressed in terms of slots and values , to query an external database . 	Different belief tracking models have been proposed in recent years, either trained independently  or within end-to-end  trainable dialog systems . 	 	% problem 	Existing belief trackers mainly depend on supervised learning with human annotations of belief states for every user utterance. However, collecting these turn-level annotations is labor-intensive and time-consuming, and often requires domain knowledge to identify slots correctly. Building E2E trainable dialog systems, called E2E dialog systems for short, even further magnifies the demand for increased amounts of labeled data .  	 	 	 	% idea 	Notably, there are often easily-available unlabeled dialog data such as between customers and trained human agents accumulated in real-world customer services. 	In this paper, we are interested in reducing the reliance on belief state annotations in building E2E task-oriented dialog systems, by leveraging unlabeled dialog data towards semi-supervised learning. 	Intuitively, the dialog data, even unlabeled, can be used to enhance the performance of belief tracking and thus benefit the whole dialog system, because there are cues from user inputs and system responses which reveal the belief states, as shown in Figure . 	 	%The underlying idea is very simple: as the system makes responses based on its belief of user goals, we should be able to use the system response to infer the corresponding belief state.  	%The correlation between belief states and system responses have also been reported in previous works , which shows that learning belief tracking and response generation together is beneficial to both tasks. % mutual information  	 	% proposed model 	Technically, we propose a latent variable model for task-oriented dialogs, called the LAtent BElief State  dialog model. 	The model generally consists of multiple  turns of user inputs  and system responses  which are observations, and belief states  which are latent variables. 	Basically, \modelname{} is a conditional generative model of belief states and system responses given user inputs, i.e. . 	Once built, the model can be used to infer belief states and generate responses. 	More importantly, such latent variable modeling enables us to develop semi-supervised learning on a mix of labeled and unlabeled data under the principled variational learning framework . 	In this manner, we hope that the LABES model can exploit the cues for belief tracking from user inputs and system responses. 	Furthermore, we develop \modelname{}-S2S, which is a specific model instantiation of \modelname{}, employing copy-augmented Seq2Seq  based conditional distributions in implementing .  	 	%To leverage this correlation, we propose the LAtent BElief State dialog model , a conditional generative model that models belief states and system responses jointly given the user inputs.  	%In particular, we represent the structured belief state as discrete latent variables, e.g. a sequence of words defined on the vocabulary space.  	 	%With the recent advances of neural variational inference  , effective methods are proposed to address structured latent representation learning , discrete latent variable modeling  and sequential inference . Inspired by these works, we propose a VI-based scheme to learn the latent belief states sequentially over multiple dialog turns, which is employed under unsupervised scenarios. Thus our model can conduct semi-supervised learning from both labeled and unlabeled dialog data. 	 	We show the advantage of our model compared to other E2E task-oriented dialog models, and demonstrate the effectiveness of our semi-supervised learning scheme on three benchmark task-oriented datasets: CamRest676 , In-Car  and MultiWOZ  across various scales and domains.  	In supervised experiments, \modelname{}-S2S obtains state-of-the-art results on CamRest676 and In-Car, and outperforms all the existing models which do not leverage large pretrained language models on MultiWOZ.  	In utilizing unlabeled dialog data, semi-supervised \modelname{}-S2S significantly outperforms both supervised-only and prior semi-supervised baselines.  	Remarkably, we can reduce the annotation requirements to 50\% without performance loss on MultiWOZ, which is equivalent to saving around 30,000 annotations.  	 	 	   In this paper, we discussed the importance of precisely identifying candidates in order to resolve toponyms to their real-world referents. In particular, we highlighted its necessity when working with noisy and non-standard texts . To foster further research on this intermediary step, we have introduced DeezyMatch, a flexible deep learning method for candidate selection through toponym matching. It is based on the state-of-the-art neural network architectures and has been tested in different evaluation settings, considering various challenging scenarios  and in comparison with a series of well established baselines. DeezyMatch, the evaluation framework presented in this paper, and all other resources employed are useful contributions to other researchers working at the intersection of geospatial information retrieval and digital humanities.       The acknowledgments section is defined using the ""acks"" environment    . This ensures the proper    identification of the section in the article metadata, and the    consistent spelling of the heading.           The next two lines define the bibliography style to be used, and    the bibliography file. 
"," 		%濞存粣绠戠槐閬嶆晬鐏炲墽澹岄柟璇″枟閸ㄦ粓鎯冮崚鐞籺ro闁挎稑濂旈幈銊╁绩鐟欏嫭鍠呴悷 		Structured belief states are crucial for user goal tracking and database query in task-oriented dialog systems. However, training belief trackers often requires expensive turn-level annotations of every user utterance. 		In this paper we aim at alleviating the reliance on belief state labels in building end-to-end dialog systems, by leveraging unlabeled dialog data towards semi-supervised learning. 		We propose a probabilistic dialog model, called the LAtent BElief State  model, where belief states are represented as discrete latent variables and jointly modeled with system responses given user inputs. 		Such latent variable modeling enables us to develop semi-supervised learning under the principled variational learning framework. 		Furthermore, we introduce LABES-S2S, which is a copy-augmented Seq2Seq model instantiation of LABES\footnote{Code available at https://github.com/thu-spmi/LABES}. 		In supervised experiments, LABES-S2S obtains strong results on three benchmark datasets of different scales. In utilizing unlabeled dialog data, semi-supervised LABES-S2S significantly outperforms both supervised-only and semi-supervised baselines. 		Remarkably, we can reduce the annotation demands to 50\% without performance loss on MultiWOZ.",64
"  Deep learning has achieved significant successes, but these successes heavily rely on massive annotated data. Few-Shot Learning  is one of the keys to breaking such shackle, and commits to learning new tasks with only a few examples  . FSL has made impressive progress in many areas, such as computer vision  . But the progress of FSL in natural language processing  is much slower.  One of the primary constraints is the lack of a unified benchmark for few-shot NLP, thus new methods cannot be easily compared and iteratively improved.  %Similar to computer vision,  Existing few-shot NLP researches mainly focus on simple N-classification problems, such as  text classification  and  entity relation classification .  However, on one hand, these works often report results on their own constructed few-shot data, which is pretty inefficient in results comparison and thus hinders cumulative progress. On the other hand, these simple N-classification problems cannot reflect the complexity of real-world NLP tasks.  NLP tasks often face the challenges of structure prediction problems, such as sequence labeling  and parsing . More importantly, different NLP tasks are often deeply related to each other, i.e. multi-task problems .  One typical scenario of complex NLP is the Dialogue Language Understanding problem, which includes two sub-tasks: Intent Detection  and Slot Tagging .  As a multi-task problem, these two sub-tasks are proved to strongly promote and depend on each other .  One of the main obstacles in constructing the NLP FSL benchmark comes from the special evaluation paradigm of FSL. Few-shot models are usually first pre-trained on data-rich domains  and then tested on unseen few-shot domains. %where pre-training and test tasks need to be related . Thus, FSL evaluations always need a lot of different domains to conquer the result-randomness from domain selection and limited learning shots.  But it is often hard to gather enough domains for NLP tasks.  To solve this, existing works  construct fake domains from a single dataset. They split all labels into training labels and testing labels.  Then, they construct fake pre-training and testing domains with training and testing labels respectively, so that testing labels are unseen during pre-training. Such simulation can yield plenty of related domains, but lacks reality and only works when the label set is large.  Actually, splitting labels is impractical for many real-world NLP problems.  For example of the Name Entity Recognition, the label sets are often too small to split .  In this paper, we present FewJoint, a novel FSL benchmark for joint multi-task learning, to promote FSL research of the NLP area.  To reflect the real word NLP complexities beyond simple N-classification, we adopt a sophisticated and important NLP problem for the benchmark: Task-oriented Dialogue Language Understanding.  Task-oriented Dialogue is a rising research area that develops dialogue systems to help users to achieve goals, such as booking tickets. Language Understanding is a fundamental module of Task-oriented Dialogue that extracts semantic frames from user utterances . It contains two sub-tasks: Intent Detection and Slot Tagging.  With the Slot Tagging task, our benchmark covers one of the most common structure prediction problems: sequence labeling. Besides, thanks to the natural dependency between Intent Detection and Slot Tagging, our benchmark can embody the multi-task challenge of NLP problems. %Fig  shows an example for few-shot joint language understanding.  To conquer randomness and make an adequate evaluation,  we include 59 different dialogue domains from real industrial API, which is a considerable domain amount compared to all existing few-shot and dialogue data. We also provide a Few-shot Learning platform to ease the experiment set up and comparison.   In summary, our contribution is three-fold:  We present a novel Few-shot learning benchmark with 59 real-world domains, which allows evaluating few-shot models without constructing fake domains.  We propose to reflect real-world NLP complexities by covering the structure prediction problems and multi-task learning problems.  We propose a Few-shot Learning platform to ease comparison and implement of few-shot methods.    	 	%	 \end{figure*}  %  	In this paper we are interested in reducing belief state annotation cost for building E2E task-oriented dialog systems. We propose a conditional generative model of dialogs - \modelname{}, where belief states are modeled as latent variables, and unlabeled dialog data can be effectively leveraged to improve belief tracking through semi-supervised variational learning.  	Furthermore, we develop LABES-S2S, which is a copy-augmented Seq2Seq model instantiation of LABES. 	We show the strong benchmark performance of \modelname{}-S2S and the effectiveness of our semi-supervised learning method on three benchmark datasets. In our experiments on MultiWOZ, we can save around 50\ , i.e. around 30,000 belief state annotations without performance loss.  	 	There are some interesting directions for future work. 	First, the \modelname{} model is general and can be enhanced by, e.g. incorporating large-scale pre-trained language models, allowing other options for the belief state decoder and the response decoder such as Transformer based. 	 Second, \modelname{} provides a principled framework to build E2E dialog systems with less reliance on annotations, which enable semi-supervised learning and, as we explain below, reinforcement learning as well.  	 as we do not fix the form of backbone model to implement the conditional probabilities in , we may simply substitute the copy-augmented Seq2Seq implementation by more sophisticated models such as GPT-2 and train via the same semi-supervised learning principles to achieve better performance.  	Second, we can analogously introduce dialog acts  as latent variables to define the joint distribution , which can be trained with semi-supervised learning and reinforcement learning as well. 	 	
"," Few-shot learning  is one of the key future steps in machine learning and has raised a lot of attention. However, in contrast to the rapid development in other domains, such as Computer Vision, the progress of FSL in Nature Language Processing  is much slower.  One of the key reasons for this is the lacking of public benchmarks.  NLP FSL researches always report new results on their own constructed few-shot datasets, which is pretty inefficient in results comparison and thus impedes cumulative progress. In this paper, we present FewJoint, a novel Few-Shot Learning benchmark for NLP.  Different from most NLP FSL research that only focus on simple N-classification problems, our benchmark introduces few-shot joint dialogue language understanding, which additionally covers the structure prediction and multi-task reliance problems.  This allows our benchmark to reflect the real-word NLP complexity beyond simple N-classification.  Our benchmark is used in the few-shot learning contest of SMP2020-ECDT task-1.\footnote{The Eighth China National Conference on Social Media Processing. Link: \url{https://smp2020.aconf.cn/smp.html}}  We also provide a compatible FSL platform to ease experiment set-up.\footnote{The dataset and platform is available at \url{https://github.com/AtmaHou/MetaDialog}}",65
"  Event coreference resolution aims to identify which event mentions in a document refer to the same event . For example, the two event mentions in Figure , departing and leave, refer to the same EndPosition event of Nokia's CEO.  Traditional event coreference resolution methods usually rely on a series of upstream components , such as entity recognition and event detection. Such a pipeline framework, unfortunately, often suffers from the error propagation problem. For instance, the best event detection system in KBP 2017 only achieved 56 F1 , and it will undoubtedly limit the performance of the follow-up event coreference task . Furthermore, most previous approaches use hand-crafted features , which heavily depend on other NLP components  and thus are hard to generalize to new languages/domains/datasets.    In this paper, we propose an End-to-End Event Coreference method --  neural network, which can predict event chains from a raw text in an end-to-end manner. For example, taking the raw text in Figure  as input,  will directly output two event coreference chains, \{departing, leave, goodbye\} and \{rejoin\}. By jointly modeling event detection and event coreference,  neural network does not require any prior components, and the representations/pieces of evidence between different tasks and different decisions can be shared and reinforced. Besides,  are learned in an end-to-end manner, which can inherently resolve the error propagation problem.  End-to-end event coreference, however, is challenging due to the mention diversity and the long-distance coreference. First, event mentions are highly diversified , which may be a variety of syntactic objects, including nouns, verbs, and even adjectives. For example, an EndPosition event can be triggered by departing, leave, goodbye and former. By contrast, mentions in entity coreference are mostly noun phrases . Second, coreferential event mentions commonly appear over long-distance sentences, therefore event coreference is intricately governed by long-distance, semantic-dependent decisions . For example, in Figure  the closest antecedent\footnote{In this paper, antecedents are coreferential mentions that appear earlier in the document.} of the mention goodbye -- leave, is far from it. To resolve the coreference between these two distant, diverse event mentions, a system can only rely on their semantic meanings, i.e., they both describe the same EndPosition event but from different perspectives. By contrast, most of entity mentions' closest antecedents are in the same or immediately preceding sentence , which can be resolved more easily using local and syntactic clues.  To resolve the mention diversity problem and the long-distance coreference problem, this paper further proposes a type-guided mechanism into our  neural network. This mechanism bridges distant, diverse event mentions by exploiting event type information in three folds: 1) type-informed antecedent network which enables  to capture more semantic information of event mentions by predicting coreferential scores and type scores simultaneously; 2) type-refined mention representation which enhances mention representation with type information, therefore even lexically dissimilar mentions can be bridged together, such as the two diverse EndPosition mentions goodbye and departing; 3) type-guided decoding algorithm which can exploit global type consistency for more accurate event chains.  The main contributions of this paper are:  1. We propose an end-to-end neural network for event coreference resolution 閳-  neural network.  can jointly model event detection and event coreference, and learn to automatically extract features from raw text. To the best of our knowledge, this is the first end-to-end neural event coreference model that can achieve state-of-the-art performance.  2. We design a type-guided mechanism for event coreference, which can effectively resolve the mention diversity problem and the long-distance coreference problem in event coreference resolution.  3. We conduct experiments on two standard datasets: KBP 2016 and KBP 2017, which show that  achieves new state-of-the-art performance. And additional ablation experiments verify the effectiveness of the proposed type-guided mechanism.     In this paper, we present a novel few-shot learning benchmark for NLP tasks, which is the first few-shot NLP benchmark for joint multi-task learning.  Compared to existing few-shot learning data, our benchmark reflects real-world NLP complexities better by covering the structure prediction problem and multi-task learning problem.  Also, our benchmark consists of 59 real dialogue domains. This allows to evaluate few-shot model without constructing fake domain like existing works.   
","   Traditional event coreference systems usually rely on pipeline framework and hand-crafted features, which often face error propagation problem and have poor generalization ability.   In this paper, we propose an End-to-End Event Coreference approach -- $\text{E}^{3}\text{C}$ neural network, which can jointly model event detection and event coreference resolution tasks, and learn to extract features from raw text automatically.   Furthermore, because event mentions are highly diversified and event coreference is intricately governed by long-distance, semantic-dependent decisions, a type-guided event coreference mechanism is further proposed in our $\text{E}^{3}\text{C}$ neural network.   Experiments show that our method achieves new state-of-the-art performance on two standard datasets.",66
" Sequence labeling assigns each token with a label in a sequence. Tasks such as Named Entity Recognition  , Part-Of-Speech  tagging  and chunking  can all be formulated as sequence labeling tasks. BiLSTM-CRF  is one of the most successful neural sequence labeling architectures. It feeds pretrained  word representations into a single layer bi-directional LSTM  encoder to extract contextual features and then feeds these features into a CRF  decoder layer to produce final predictions. The CRF layer is a linear-chain structure that models the relation between neighboring labels. In the traditional CRF approach, exact probabilistic inference algorithms such as the forward-backward and Viterbi algorithms are applied for training and prediction respectively.  %The Viterbi algorithm is applied to exactly find the best label sequence in inference and the forward-backward algorithm is applied to compute posterior marginal distributions exactly for each position in training.  In many sequence labeling tasks, the CRF layer leads to better results than the simpler method of predicting each label independently.  In practice, we sometimes require very fast sequence labelers for training  and prediction . The BiLSTM encoder and the CRF layer both contain sequential computation and require  time over  input words even when parallelized on GPU. A common practice to improve the speed of the encoder is to replace the BiLSTM with a CNN structure , distill larger encoders into smaller ones  or in other settings . The CRF layer, however, is more difficult to replace because of its superior accuracy compared with faster alternatives in many tasks. %More recently, \citet{cui-zhang-2019-hierarchically} proposed BiLSTM-LAN to replace the CRF layer, which has a lower time complexity, but the network introduces 3 additional LSTM layers that require sequential computations. The CRF layer is still necessary for better accuracy in many tasks, which limits the speed. %  showed such an algorithm can be unfolded as an RNN on grid-structure, we expand the work on the sequence structure and unfold the MFVI algorithm as an RNN as will  In order to achieve sublinear time complexity on the CRF layer, we must parallelize the CRF prediction over the tokens. In this paper, we apply Mean-Field Variational Inference  to approximately decode the linear-chain CRF. MFVI iteratively passes messages among neighboring labels to update their distributions locally. Unlike the exact probabilistic inference algorithms, MFVI can be parallelized over different positions in the sequence, achieving time complexity that is constant in  with full parallelization. %Similar to \citet{zheng2015conditional}, we show that such an algorithm can be unfolded as an RNN,  Previous work  showed that such an algorithm can be unfolded as an RNN for grid CRF structure. We expand on the work for the linear-chain CRF structure and unfold the algorithm as an RNN which can be connected with the encoder to form an end-to-end neural network that is amenable to parallelization for both training and prediction. We call the unfolded RNN an approximate inference network . In addition to linear-chain CRFs, we also apply AIN to factorized second-order CRF models, which consider relations between more neighboring labels. Our empirical results show that AIN significantly improves the speed and achieves competitive accuracy against the traditional CRF approach on 4 tasks with 15 datasets.        This paper proposes a state-of-the-art, end-to-end neural network for event coreference resolution --  neural network, which jointly models event detection and event coreference, and learns to extract features from the raw text directly. A type-guided mechanism is further proposed for resolving the mention diversity problem and the long-distance coreference problem, which: 1) informs coreference prediction with type scoring, 2) refines mention representation using type information, and 3) guides decoding under type consistency. Experiments show that our method achieves state-of-the-art performances on KBP 2016 and KBP 2017. For future work, we will focus on the bottleneck of event coreference, e.g., event detection and argument modeling.      
"," %with pretrained word embeddings and contextual feature extractors such as RNN or CNN  The linear-chain Conditional Random Field  model is one of the most widely-used neural sequence labeling approaches. Exact probabilistic inference algorithms such as the forward-backward and Viterbi algorithms are typically applied in training and prediction stages of the CRF model. However, these algorithms require sequential computation that makes parallelization impossible. In this paper, we propose to employ a parallelizable approximate variational inference algorithm for the CRF model. Based on this algorithm, we design an approximate inference network that can be connected with the encoder of the neural CRF model to form an end-to-end network, which is amenable to parallelization for faster training and prediction. The empirical results show that our proposed approaches achieve a 12.7-fold improvement in decoding speed with long sentences and a competitive accuracy compared with the traditional CRF approach.",67
"  Historically, metrics for evaluating the quality of machine translation  have relied on assessing the similarity between an MT-generated hypothesis and a human-generated reference translation in the target language.  Traditional metrics have focused on basic, lexical-level features such as counting the number of matching n-grams between the MT hypothesis and the reference translation. Metrics such as {\sc Bleu}  and {\sc Meteor}  remain popular as a means of evaluating MT systems due to their light-weight and fast computation.   Modern neural approaches to MT result in much higher quality of translation that often deviates from monotonic lexical transfer between languages.  %A single reference translation might not always be sufficient to accommodate the expressiveness of such translations.  For this reason, it has become increasingly evident that we can no longer rely on metrics such as {\sc Bleu} to provide an accurate estimate of the quality of MT .  While an increased research interest in neural methods for training MT models and systems has resulted in a recent, dramatic improvement in MT quality, MT evaluation has fallen behind. The MT research community still relies largely on outdated metrics and no new, widely-adopted standard has emerged.  In 2019, the WMT News Translation Shared Task received a total of 153 MT system submissions . The Metrics Shared Task of the same year saw only 24 submissions, almost half of which were entrants to the Quality Estimation Shared Task, adapted as metrics .   The findings of the above-mentioned task highlight two major challenges to MT evaluation which we seek to address herein . Namely, that current metrics struggle to accurately correlate with human judgement at segment level and fail to adequately differentiate the highest performing MT systems.  %The findings of the Metrics Shared Task highlight that segment-level evaluation and strong neural MT systems are major challenges, with none of the submitted metrics achieving satisfactory levels of correlation with human judgements .  In this paper, we present {\sc Comet}\footnote{Crosslingual  Optimized Metric for Evaluation of Translation.}, a PyTorch-based framework for training highly multilingual and adaptable MT evaluation models that can function as metrics. Our framework takes advantage of recent breakthroughs in cross-lingual language modeling  to generate prediction estimates of human judgments such as Direct Assessments  , Human-mediated Translation Edit Rate   and metrics compliant with the Multidimensional Quality Metric framework .   Inspired by recent work on Quality Estimation  that demonstrated that it is possible to achieve high levels of correlation with human judgements even without a reference translation  , we propose a novel approach for incorporating the source-language input into our MT evaluation models. Traditionally only QE models have made use of the source input, whereas MT evaluation metrics rely instead on the reference translation. As in , we show that using a multilingual embedding space allows us to leverage information from all three inputs and demonstrate the value added by the source as input to our MT evaluation models.  To illustrate the effectiveness and flexibility of the {\sc Comet} framework, we train three models that estimate different types of human judgements and show promising progress towards both better correlation at segment level and robustness to high-quality MT.   %The rest of the paper is organized as follows. Section  presents an overview of the related literature. Section  describes the corpora used. Section  describes the different model architectures and training regimes. Section  describes the conducted experiments and evaluation metrics. Section  reports the corresponding results achieved. Finally, Section  presents our most relevant conclusions, and pinpoints possible future directions.  We will release both the {\sc Comet} framework and the trained MT evaluation models described in this paper to the research community upon publication.      and Future Work [TODO]}  In this paper, we explore more comprehensive document-level neural machine translation. Assuming that document-level clues are indeed helpful for better translation, it is kept an open problem for finding a good way to effectively introduce such helpful clues into sentence-independent NMT. Taking document embedding as our default representation for document-level clues, we distinguish two types of document embeddings, the global and the local, which targetedly capture both the general information in the whole document scope and the specific detailed information in the surrounding text. For the concerned document-level NMT, we for the first time survey multiple ways for generating document embeddings and conduct extensive experiments. Taking a strong Transformer baseline, our experimental results show that our global and local document embeddings may effectively enhance the baseline systems, showing that more sufficient and richer document clues indeed greatly help standard sentence-independent NMT.    In our future work, we will apply the context attention to the decoder and investigate the effect with the different memory sizes.   TBD    \clearpage     
"," We present {\sc Comet}, a neural framework for training multilingual machine translation evaluation models which obtains new state-of-the-art levels of correlation with human judgements. Our framework leverages recent breakthroughs in cross-lingual pretrained language modeling resulting in highly multilingual and adaptable MT evaluation models that exploit information from both the source input and a target-language reference translation in order to more accurately predict MT quality. To showcase our framework, we train three models with different types of human judgements: Direct Assessments, Human-mediated Translation Edit Rate and Multidimensional Quality Metrics. Our models achieve new state-of-the-art performance on the WMT 2019 Metrics shared task and demonstrate robustness to high-performing systems. %Furthermore, they show promising results towards solving the current challenges of accurate segment-level evaluation and robustness to top performing systems.",68
"   Aspect detection, which is a vital component of aspect-based sentiment analysis , aims at identifying predefined aspect categories  discussed in segments  of online reviews. Table shows an example review about a television from several different aspects, such as Image, Sound, and Ease of Use. With a large number of reviews, automatic aspect detection allows people to efficiently retrieve review segments of aspects they are interested in. It also benefits many downstream tasks, such as review summarization  and recommendation justification .  }                \end{table}  There are several research directions for aspect detection. Supervised approaches  can leverage annotated labels of aspect categories but suffer from domain adaptation problems . Another research direction consists of unsupervised approaches and has gained a lot of attention in recent years. Early unsupervised systems are dominated by Latent Dirichlet Allocation  based topic models . However, several recent studies have revealed that LDA-based approaches do not perform well for aspect detection and the extracted aspects are of poor quality  . Compared to LDA-based approaches,  deep learning models, such as aspect-based autoencoder  , have shown excellent performance in extracting coherent aspects and identifying aspect categories for review segments. However, these models require some human effort to manually map model discovered aspects to aspects of interest, which may lead to inaccuracies in mapping especially when model discovered aspects are noisy. Another research direction is based on weakly supervised approaches that leverage a small number of aspect representative words  for the fine-grained aspect detection . Although these models outperform unsupervised approaches, they do make use of human annotated data to extract high-quality aspect seed words, which may limit their application. In addition, they are not able to automatically discover new aspects from review corpus.  We focus on the problem of unsupervised aspect detection  since massive amount of reviews are generated every day and many of them are for newer products. It is difficult for humans to efficiently capture new aspects and manually annotate segments for them at scale. Motivated by ABAE, we learn interpretable aspects by mapping aspect embeddings into word embedding space, so that aspects can be interpreted by the nearest words. To learn better representations for both aspects and review segments, we formulate UAD as a self-supervised  representation learning problem and solve it using a contrastive learning algorithm, which is inspired by the  success of self-supervised contrastive learning in visual representations . In addition to the learning algorithm, we also resolve two problems that deteriorate the performance of ABAE, including its self-attention mechanism for segment representations and aspect mapping strategy . Finally, we discover that the quality of aspect detection can be further improved by knowledge distillation . The contributions of this paper are summarized as follows:       % } %      %      % \end{table}    \def\year{2021}\relax %File: formatting-instructions-latex-2021.tex %release 2021.1 \documentclass[letterpaper]{article} % DO NOT CHANGE THIS \usepackage{aaai21}  % DO NOT CHANGE THIS \usepackage{times}  % DO NOT CHANGE THIS \usepackage{helvet} % DO NOT CHANGE THIS \usepackage{courier}  % DO NOT CHANGE THIS \usepackage[hyphens]{url}  % DO NOT CHANGE THIS \usepackage{graphicx} % DO NOT CHANGE THIS \urlstyle{rm} % DO NOT CHANGE THIS \def\UrlFont{\rm}  % DO NOT CHANGE THIS \usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \frenchspacing  % DO NOT CHANGE THIS \setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS \setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS  %new added start \usepackage{booktabs} \usepackage{footnote}  \usepackage{amsmath,amssymb,mathrsfs} \usepackage[ruled,linesnumbered]{algorithm2e}  \usepackage{epstopdf} \usepackage{multirow} \usepackage[skip=0pt]{subcaption} \usepackage{soul}  \usepackage{tabularx} \renewcommand\tabularxcolumn[1]{m{#1}}  \usepackage{enumitem}  \renewcommand\vec[1]{\overrightarrow{#1}} \newcommand\cev[1]{\overleftarrow{#1}} \newcommand{\etal}{et~al.}  \usepackage{microtype} \usepackage[switch]{lineno}  %new added end    %\nocopyright %PDF Info Is REQUIRED. % For /Author, add all authors within the parentheses, separated by commas. No accents or commands. % For /Title, add Title in Mixed Case. No accents or commands. Retain the parentheses. \pdfinfo{ /Title  /Author  /TemplateVersion  } %Leave this % /Title  % Put your actual complete title  within the parentheses in mixed case % Leave the space between \Title and the beginning parenthesis alone % /Author  % Put your actual complete list of authors  within the parentheses in mixed case. % Each author should be only by a comma. If the name contains accents, remove them. If there are any LaTeX commands, % remove them.  % DISALLOWED PACKAGES % \usepackage{authblk} -- This package is specifically forbidden % \usepackage{balance} -- This package is specifically forbidden % \usepackage{color  % \usepackage{CJK} -- This package is specifically forbidden % \usepackage{float} -- This package is specifically forbidden % \usepackage{flushend} -- This package is specifically forbidden % \usepackage{fontenc} -- This package is specifically forbidden % \usepackage{fullpage} -- This package is specifically forbidden % \usepackage{geometry} -- This package is specifically forbidden % \usepackage{grffile} -- This package is specifically forbidden % \usepackage{hyperref} -- This package is specifically forbidden % \usepackage{navigator} -- This package is specifically forbidden %  % \indentfirst} -- This package is specifically forbidden % \layout} -- This package is specifically forbidden % \multicol} -- This package is specifically forbidden % \nameref} -- This package is specifically forbidden % \usepackage{savetrees} -- This package is specifically forbidden % \usepackage{setspace} -- This package is specifically forbidden % \usepackage{stfloats} -- This package is specifically forbidden % \usepackage{tabu} -- This package is specifically forbidden % \usepackage{titlesec} -- This package is specifically forbidden % \usepackage{tocbibind} -- This package is specifically forbidden % \usepackage{ulem} -- This package is specifically forbidden % \usepackage{wrapfig} -- This package is specifically forbidden % DISALLOWED COMMANDS % \nocopyright -- Your paper will not be published if you use this command % \addtolength -- This command may not be used % \balance -- This command may not be used % \baselinestretch -- Your paper will not be published if you use this command % \clearpage -- No page breaks of any kind may be used for the final version of your paper % \columnsep -- This command may not be used % \newpage -- No page breaks of any kind may be used for the final version of your paper % \pagebreak -- No page breaks of any kind may be used for the final version of your paperr % \pagestyle -- This command may not be used % \tiny -- This is not an acceptable font size. % {0} %May be changed to 1 or 2 if section numbers are desired.  % The file aaai21.sty is the style file for AAAI Press % proceedings, working notes, and technical reports. %  % Title  % Your title must be in mixed case, not sentence case. % That means all verbs , % nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while % articles, conjunctions, and prepositions are lower case unless they % directly follow a colon or long dash  \title{A Simple and Effective Self-Supervised Contrastive Learning Framework\\ for Aspect Detection} \author{     %Authors     % All authors must be in the same font size and format.     Tian Shi\textsuperscript{\rm 1}, Liuqing Li\textsuperscript{\rm 2}, Ping Wang\textsuperscript{\rm 1}, Chandan K. Reddy\textsuperscript{\rm 1}\\ } \affiliations{     %Afiliations     \textsuperscript{\rm 1}Department of Computer Science, Virginia Tech\\     \textsuperscript{\rm 2}Verizon Media\\     tshi@vt.edu, liuqing.li@verizonmedia.com, ping@vt.edu,      reddy@cs.vt.edu     % See more examples next } \iffalse %Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it \title{My Publication Title --- Single Author} \author {     % Author     Author Name \\ }  \affiliations{     Affiliation \\     Affiliation Line 2 \\     name@example.com } \fi  \iffalse %Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it \title{My Publication Title --- Multiple Authors} \author {     % Authors          First Author Name,\textsuperscript{\rm 1}         Second Author Name, \textsuperscript{\rm 2}         Third Author Name \textsuperscript{\rm 1} \\ } \affiliations {     % Affiliations     \textsuperscript{\rm 1} Affiliation 1 \\     \textsuperscript{\rm 2} Affiliation 2 \\     firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com } \fi            In this paper we present {\sc Comet}, a novel neural framework for training MT evaluation models that can serve as automatic metrics and easily be adapted and optimized to different types of human judgements of MT quality.   To showcase the effectiveness of our framework, we sought to address the challenges reported in the 2019 WMT Metrics Shared Task . We trained three distinct models which achieve new state-of-the-art results for segment-level correlation with human judgments, and show promising ability to better differentiate high-performing systems.   One of the challenges of leveraging the power of pretrained models is the burdensome weight of parameters and inference time. A primary avenue for future work on {\sc Comet} will look at the impact of more compact solutions such as DistilBERT .  Additionally, whilst we outline the potential importance of the source text above, we note that our {\sc Comet-rank} model weighs source and reference differently during inference but equally in its training loss function. Future work will investigate the optimality of this formulation and further examine the interdependence of the different inputs.  \section*{Acknowledgments} We are grateful to Andr\'e Martins, Austin Matthews, Fabio Kepler, Daan Van Stigt, Miguel Vera, and the reviewers, for their valuable feedback and discussions. This work was supported in part by the P2020 Program through projects MAIA and Unbabel4EU, supervised by ANI under contract numbers 045909 and 042671, respectively.     \clearpage   \section{Appendices}  \begin{table*}[!ht] \centering   
"," Unsupervised aspect detection  aims at automatically extracting interpretable aspects and identifying aspect-specific segments  from online reviews. However, recent deep learning based topic models, specifically aspect-based autoencoder, suffer from several problems such as extracting noisy aspects and poorly mapping aspects discovered by models to the aspects of interest. To tackle these challenges, in this paper, we first propose a self-supervised contrastive learning framework and an attention-based model equipped with a novel smooth self-attention  module for the UAD task in order to learn better representations for aspects and review segments. Secondly, we introduce a high-resolution selective mapping  method to efficiently assign aspects discovered by the model to the aspects of interest. We also propose using a knowledge distillation technique to further improve the aspect detection performance. Our methods outperform several recent unsupervised and weakly supervised approaches on publicly available benchmark user review datasets. Aspect interpretation results show that extracted aspects are meaningful, have a good coverage, and can be easily mapped to aspects of interest. Ablation studies and attention weight visualization also demonstrate effectiveness of SSA and the knowledge distillation method.",69
"     There are several recent studies that aim to predict the aspect ratings using deep neural network based models with multi-task learning framework . In this setting, rating predictions for different aspects, which are typically highly correlated and can share the same review encoder, are treated as different tasks. However, these models rely on hand-crafted aspect keywords to aid in rating/sentiment predictions . Thus, their results, especially case studies of reviews, are biased towards pre-defined aspect keywords. In addition, these models only focus on improving the prediction accuracy, however, knowledge discovery  from review corpus still relies on unsupervised  and rule-based methods , which limits applications of current MARP models . In the past few years, model uncertainty of deep neural network classifiers has received increasing attention , because it can identify low-confidence regions of input space and give more reliable predictions. Uncertainty models have also been applied to deep neural networks for text classification . However, few existing uncertainty methods have been used to improve the overall prediction accuracy of multi-task learning models when crowd-sourcing annotation is involved in the MARP task. In this paper, we attempt to tackle the above mentioned issues. The primary contributions of this paper are as follows:     The rest of this paper is organized as follows: In Section , we introduce related work of MARP task and uncertainty estimation methods. In Section , we present details of our proposed FEDAR model, AKR method and LEAD uncertainty estimation approach. In Section , we introduce different MARP datasets, baseline methods and implementation details, as well as analyze experimental results. Our discussion concludes in Section.%% %% This is file `sample-sigconf.tex', %% generated with the docstrip utility. %% %% The original source files were: %% %% samples.dtx   %%  %% IMPORTANT NOTICE: %%  %% For the copyright see the source file. %%  %% Any modified versions of this file must be renamed %% with new filenames distinct from sample-sigconf.tex. %%  %% For distribution of the original source see the terms %% for copying and modification in the file samples.dtx. %%  %% This generated file may be distributed as long as the %% original source files, as listed above, are part of the %% same distribution.  %% %% The first command in your LaTeX source must be the \documentclass command. \documentclass[sigconf]{acmart}  \usepackage{amsmath,amssymb,multicol,mathrsfs} \usepackage[ruled,linesnumbered]{algorithm2e} \usepackage{graphicx} \usepackage{balance}  \usepackage{epstopdf} \usepackage{multirow} \usepackage{color,soul}  \usepackage{tabularx} \renewcommand\tabularxcolumn[1]{m{#1}}  \usepackage[normalem]{ulem} \usepackage{enumitem} \setlist{leftmargin=5.5mm}  \usepackage{flushend} \usepackage{tikz} \usepackage{pgf} \usepackage[eulergreek]{sansmath}  \usepackage{graphicx} \usepackage{subcaption}  \renewcommand\vec[1]{\overrightarrow{#1}} \newcommand\cev[1]{\overleftarrow{#1}} \newcommand{\etal}{et~al. }  \usepackage{url}  \newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}  %%%% As of March 2017, [siggraph] is no longer used. Please use sigconf  for SIGGRAPH conferences.  %%%% As of May 2020, [sigchi] and [sigchi-a] are no longer used. Please use sigconf  for SIGCHI conferences.  %%%% Proceedings format for SIGPLAN conferences  % \documentclass[sigplan, anonymous, review]{acmart}  %%%% Proceedings format for conferences using one-column small layout % \documentclass[acmsmall,review]{acmart}  %% %% \BibTeX command to typeset BibTeX logo in the docs \AtBeginDocument{%   \providecommand\BibTeX{{%     \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}  %% Rights management information.  This information is sent to you %% when you complete the rights form.  These commands have SAMPLE %% values in them; it is your responsibility as an author to replace %% the commands and values with those provided to you when you %% complete the rights form. \setcopyright{acmcopyright} \copyrightyear{2018} \acmYear{2018} \acmDOI{10.1145/1122445.1122456}  %% These commands are for a PROCEEDINGS abstract or paper. \acmConference[]{}{}{} \acmBooktitle{}   \acmPrice{15.00} \acmISBN{978-1-4503-XXXX-X/18/06}   %% %% Submission ID. %% Use this when submitting an article to a sponsored event. You'll %% receive a unique submission ID from the organizers %% of the event, and this ID should be used as the parameter to this command. %%\acmSubmissionID{123-A56-BU3}  %% %% The majority of ACM publications use numbered citations and %% references.  The command \citestyle{authoryear} switches to the %% ""author year"" style. %% %% If you are preparing content for an event %% sponsored by ACM SIGGRAPH, you must use the ""author year"" style of %% citations and references. %% Uncommenting %% the next command will enable that style. %%\citestyle{acmauthoryear}  %% %% end of the preamble, start of the body of the document source.   %% %% The code below is generated by the tool at http://dl.acm.org/ccs.cfm. %% Please copy and paste the code instead of the example below. %%   \ccsdesc[500]{Information systems~Sentiment analysis} \ccsdesc[500]{Information systems~Clustering and classification} \ccsdesc[300]{Information systems~Information extraction}  %% %% Keywords. The author should pick words that accurately describe %% the work being presented. Separate the keywords with commas. \keywords{Multi-task learning, model uncertainty, deep neural network, dropout, classification, online reviews}  %% A ""teaser"" image appears between the author and affiliation %% information and the body of the document, and typically spans the %% page. %   %% %% This command processes the author and affiliation and title %% information and builds the first part of the formatted document.         %% %% The acknowledgments section is defined using the ""acks"" environment %% . This ensures the proper %% identification of the section in the article metadata, and the %% consistent spelling of the heading. %   \newpage \balance  %% %% The next two lines define the bibliography style to be used, and %% the bibliography file. \bibliographystyle{ACM-Reference-Format} \bibliography{ref}  \end{document} \endinput %% %% End of file `sample-sigconf.tex'.      In this paper, we propose a self-supervised contrastive learning framework for aspect detection. Our model is equipped with two attention modules, which allows us to represent every segment with word embeddings and aspect embeddings, so that we can map aspect embeddings to the word embedding space through a contrastive learning mechanism. In the attention module over word embeddings, we introduce a SSA mechanism. Thus, our model can learn robust representations, since SSA encourages the model to capture phrases and multiple keywords in the segments. In addition, we propose a HRSMap method for aspect mapping, which dramatically increases the accuracy of segment aspect predictions for both ABAE and our model. Finally, we further improve the performance of aspect detection through knowledge distillation. BERT-based student models can benefit from pretrained encoders and overcome the disadvantages of data preprocessing for the teacher model. During training, we introduce entropy filters in the loss function to ensure student models focus on high confidence training samples. Our models have shown better performance compared to several recent unsupervised and weakly-supervised models on several publicly available review datasets across different domains. Aspect interpretation results show that extracted aspects are meaningful, have a good coverage, and can be easily mapped to gold-standard aspects. Ablation studies and visualization of attention weights further demonstrate the effectiveness of SSA and entropy filters. 
","  In recent years, several online platforms have seen a rapid increase in the number of review systems that request users to provide aspect-level feedback. Multi-Aspect Rating Prediction , where the goal is to predict the ratings from a review at an individual aspect level, has become a challenging and an imminent problem. To tackle this challenge, we propose a deliberate self-attention deep neural network model, named as FEDAR, for the MARP problem, which can achieve competitive performance while also being able to interpret the predictions made. As opposed to the previous studies, which make use of hand-crafted keywords to determine aspects in sentiment predictions, our model does not suffer from human bias issues since aspect keywords are automatically detected through a self-attention mechanism. FEDAR is equipped with a highway word embedding layer to transfer knowledge from pre-trained word embeddings, an RNN encoder layer with output features enriched by pooling and factorization techniques, and a deliberate self-attention layer. In addition, we also propose an Attention-driven Keywords Ranking  method, which can automatically extract aspect-level sentiment-related keywords from the review corpus based on the attention weights. Since crowdsourcing annotation can be an alternate way to recover missing ratings of reviews, we propose a LEcture-AuDience  strategy to estimate model uncertainty in the context of multi-task learning, so that valuable human resources can focus on the most uncertain predictions. Our extensive set of experiments on different DMSC datasets demonstrate the superiority of the proposed FEDAR and LEAD models. Visualization of aspect-level sentiment keywords demonstrate the interpretability of our model and effectiveness of our AKR method.",70
"  % However, the gap between machine translation systems and human translators needs to be manually closed by post-editing.  % The recent success of deep learning algorithms heavily relies on the increasing availability of crowdsourcing services for either data annotations or human evaluations, such as ImageNet dataset  or Amazon Mechanical Turk.  % Through the power of the crowd, the data requesters can expect to obtain large amounts of data at relatively low cost.  % However, there is a growing demand for quality data that requires more technical expertise.  % For example, the cornerstone of multilingual researches in natural language processing typically lies in a multilingual paralleled corpus.  % Post-editing crowdsourcing is an efficient way to produce high-quality translations.  % However, the de facto demanding of such human intelligence generally requires the crowdsourcing participants educated with certain ability of language translation, which consequently leads a substantial increase in both of the spent expense and the elapsed time.   The explosive advances in the sequence to sequence model  enable the deep learning based neural machine translation  to approximate and even achieve the human parity in some specific language pairs and scenarios.  Instead of translating from scratch by human translators, a new translation paradigm has emerged: computer assisted translation  system, which includes the machine translation and human post-editing.  The post-editing is the process whereby humans amend machine-generated translations to achieve an acceptable final product. %, which is not necessarily the same as the reference generated by another human translator.  Practically, the estimated average translation time can be reduced by 17.4\%  .  However, utilizing NMT poses two key challenges.  First, the neural machine translation quality still continues to vary a great deal across different domains or genres, more or less in proportion to the availability of paralleled training corpora.  % Many experiments show that large scale in-domain data can boost the performance of NMT .  Second, the zero tolerance policy is a common choice in the vast majority of important applications.  For example, when business legal documents are translated, even a single incorrect word could bring serious financial or property losses.  Therefore, the subsequent human post-editing is indispensable in situations like this.  Unfortunately, while NMT systems saves time by providing the preliminary translations, the time spent on error corrections by humans  remains substantial to the extent that it offsets the efficiency gained by the NMT systems.  In this paper, we explore automatic post-editing  in the deep learning framework.  Specifically, we adopt an imitation learning approach, where our model first screens the  translation candidates by quality prediction and then decides whether to post edit with the generation or the atomic operation method. % Figure demonstrates an example of our system with the atomic operation post-editing, where the quality estimation  step illustrates the errors found in the original machine translation and the APE step proceeds with the proposed corrections.  % The benefits of our crowdsourcing system are faster error detection by the automatic QE system and faster error correction by the automatic correction suggestion system.  % In our pilot system such as the one shown in Figure, we observe the improved human efficiency with the aid of the automatic systems especially when the systems produce top-quality error corrections, requiring no further actions from the human.  Starting with a wide range of features used in the CAT system, we carefully analyze the human post-editing results to narrow down our framework design into three key modules: quality estimation , generative post-editing and atomic operation post-editing.  These modules are tightly integrated into the transformer neural networks .   Our main innovation is a  % adaptive crowdsourcing system with two modular post-editing algorithms that can be either independently or conditionally used.  hierarchical model with two modular post-editing algorithms which are conditionally used based on a novel fine-grained quality estimation model. % In each iteration and f For each machine translation, our %the system model i) runs the QE model to predict the detailed token level errors, which will be further summarized as an overall quality score to decide whether the machine translation quality is high or not, and ii) conditional on the previous decision, employs the atomic operation post-editing algorithm on the high quality sentence or the generative model to rephrase the translation for the low one.   We examine our approach on the public English--German dataset from WMT 2017 APE shared task.  Our system outperforms the top ranked methods in both BLEU and TER metrics.  In addition, following a standard human evaluation process aimed at achieving impartiality with respect to the efficiency of CAT system, we ask several certified translators to edit the machine translation outputs with or without our APE assistance.  Evaluation results show that our system significantly improves translators' efficiency.       In this paper, we proposed a multi-task deep learning model, namely FEDAR, for the problem of multi-aspect review rating prediction. Different from previous studies, our model does not require hand-crafted aspect-specific keywords to guide the attention and boost model performance for the task of rating prediction. Instead, our model relies on  a highway word embedding layer to transfer knowledge from pre-trained word vectors on a large corpus,  a sequential encoder layer whose output features are enriched by pooling and feature factorization techniques, and  a deliberate self-attention layer which maintains the interpretability of our model. Experiments on various MARP datasets have demonstrated the superior performance of our model. In addition, we also developed an Attention-driven Keywords Ranking  method, which can automatically extract aspect and sentiment keywords from the review corpus based on attention weights. Aspect-level sentiment word-cloud visualization results have demonstrated the interpretability of our model and effectiveness of our AKR method. Finally, we also proposed a LEcture-AuDience  method to measure the uncertainty of deep neural networks, including our FEDAR model, in the context of multi-task learning. Our experimental results on multiple real-world datasets  demonstrate the effectiveness of the proposed work. 
"," % Text translation is a difficult and expensive task in crowdsourcing, since it requires the expertise of at least two languages.  With the advent of neural machine translation, there has been a marked shift towards leveraging and consuming the machine translation results.  However, the gap between machine translation systems and human translators needs to be manually closed by post-editing.  In this paper, we propose an end-to-end deep learning framework of %as a computer assisted crowdsourcing system for  the quality estimation and automatic post-editing of the machine translation output.  Our goal is to provide error correction suggestions and to further relieve the burden of human translators through an interpretable model.  To imitate the behavior of human translators, we design three efficient delegation modules -- quality estimation, generative post-editing, and atomic operation post-editing and construct a hierarchical model based on them.  %When the quality estimation model predicts the translation to be poor, the generative post-editing module is called to completely rephrase the translation.  % In contrast, the translation quality is high, the output only needs several atomic operations, such as deletion, insertion, or substitution.  We examine this approach with the English--German dataset from WMT 2017 APE shared task and our experimental results can achieve the state-of-the-art performance.  We also verify that the certified translators can significantly expedite their post-editing processing with our model in human evaluation.",71
"  Recent advances in deep learning have led to significant improvement of Neural Machine Translation  .  Particularly, the performance on the sentence-level translation of both low- and high- resource language pairs is dramatically improved .  However, when translating text with long-range dependencies, such as in conversations or documents, the original mode of translating one sentence at a time ignores the discourse phenomena , introducing undesirable behaviors such as inconsistent pronouns across different translated sentences.   Document-level NMT, as a more realistic translation task in these scenarios, has been systematically investigated in the machine translation community.  Most literatures focused on looking back a fixed number of previous source or target sentences as the document-level context .  Some latest works innovatively attempted to either get the most out of the entire document context or dynamically select the suitable context .  Because of the scarcity of document training data, the benefit gained from such an approach, as reflected in BLEU, is usually limited. We therefore elect to pay attention to the context in the previous  sentences only where  is a small number and usually does not cover the entire document.    Almost all of the latest studies chose the standard transformer model as their baseline which translates each sentence in the document with the model trained on the sentence-level data.   The cohesion and consistency are in general poor.   A more reasonable baseline is to train the transformer with the context prepended, and this modification could be simply implemented via data preprocessing.  \citet{bawden2018evaluating} conducted a detailed analysis of RNN-based NMT models on the topic of whether or not to include the extended context.  Consistency and precision is often viewed as a trade-off of each other. We conduct a detailed analysis of the effect of document context on consistency in transformer architecture accepting multi-sentence input.  When it comes to leveraging the contextual information, the common approach is to model the interaction between the sentence and its context with specially designed attention modules .  Such works tend to include more than one encoder or decoder, with a substantial number of parameters and additional computations.  In our work, we reduce the contextual and regular attention modules into one single encoder and decoder.  Our idea is motivated by the one transformer decoder with the two-stream self-attention .  % In particular, we maintain two different sets of hidden states and employ two different masking matrices to capture the long and short term dependencies.   The contributions of this paper are threefold:   i) we extensively research the performance of the standard transformer in the setting of multi-sentence input and output;  ii) we propose a simple but effective modification to adapting the transformer for document NMT with the aim of ameliorating the effect of error accumulation;  iii) our experiments demonstrate that even the simple baseline can achieve comparable results.        Our studies show that we can offer more efficient computer assisted translation crowdsourcing system to reduce time and cost of human labor.      An interesting point to mention is the difference between training and inference algorithms.      The latter exclusively enjoys the benefits of iterative update while the former does not.      So a natural question is that whether the iterative update of QE and atomic operation APE can be successfully plugged into the training process.      The short answer is yes.      Because the simplest way is to replace the current inner loop of the model specialization in Algorithm with a similar iterative update as used in inference, the rationales of them are both data augmentation.      Particularly, after the model parameters of the encoder-memory encoder are updated via the loss minimization, we can infer the current atomic operation APE  and assign it to the machine translation, {\itshape i.e.} substituting the new tuple  for  in Line 4 of Algorithm.      We implemented this idea but found the results became worse.      We hypothesize that it was probably because the original model specialization can bring more diversity of errors in the machine translation to the models for learning.      Therefore, a more theoretically reasonable modification is to combine the original model specialization and the iterative update together, which is not computationally feasible because the training cost can significantly increase by several folds.      It might be argued that our final hierarchical system, which automatically selects the suitable model for inference, is a special case of the conventional two-model ensemble, but it is not.   The standard ensemble method requires inference from all of the trained models, and then combines the predicted distribution of each token.   In contrast, our hierarchical model only need to infer on the selected model once.    If the for-loop exits early in Algorithm, only the generative model is applied.    If the iterative update is desired, atomic operation model runs for 5 iterations, which is usually faster than the generative model.    This difference between our hierarchical APE system and the standard ensemble of multiple single models makes our system faster.    But more than that, the motivation to propose the hierarchical model is to better model the editing behaviors of human translators.    The decision making process allows a discriminatory APE for the machine translation outputs that vary in qualities.  
"," Many document-level neural machine translation  systems have explored the utility of context-aware architecture, usually requiring an increasing number of parameters and computational complexity.  However, few attention is paid to the baseline model.  In this paper, we research extensively the pros and cons of the standard transformer in document-level translation, and find that the auto-regressive property can simultaneously bring both the advantage of the consistency and the disadvantage of error accumulation.  Therefore, we propose a surprisingly simple long-short term masking self-attention on top of the standard transformer to both effectively capture the long-range dependence and reduce the propagation of errors.  We examine our approach on the two publicly available document-level datasets.  We can achieve a strong result in BLEU and capture discourse phenomena.",72
"  Knowledge Distillation  is a popular model acceleration and compression approach . It assumes that a lightweight network  can learn to generalize in the same way as a large network . To this end, a simple method is to train the student network with predicted probabilities of the teacher network as its targets.  In KD, the student network is a ``copycat'' of the teacher network because the knowledge is learned from the teacher prediction. Rather, a more straightforward way is to transfer the knowledge in parameters between two networks, as the parameters are the sources of the predictions. Such an idea has been recently found to be effective in the pre-training  fine-tuning paradigm . For example, the parameters learned on large-scale unlabeled data can be used as a good start to train a complex network on the target task. However, parameter reuse is not applicable to model acceleration and compression because the teacher and student networks might be of different width and depth\footnote{In a multi-layer neural network, the number of neurons in a hidden layer is referred to as network width, and the number of stacked layers is referred to as network depth.}.  In this paper, we propose Weight Distillation  to transfer the parameters of the teacher network to the student network. We design a parameter generator to model the transformation from teacher network parameters to student network parameters, even if they have different sized weight matrices. After that, a fine-tuning process is performed to improve the quality of the transferred parameters. See \fig{fig:compare} for a comparison of KD and WD.  We test the WD method in a well-tuned Transformer-based machine translation system. The experiments are run on three machine translation tasks, including WMT16 English-Roman , NIST12 Chinese-English , and WMT14 English-German . With a similar speedup, the student network trained by WD is 0.511.82 BLEU higher than KD. With a similar BLEU performance, the student network trained by WD is 1.111.39 faster than KD. More interestingly, it is found that WD is very effective to improve the student network when its model size is close to the teacher network. On the WMT14 En-De data, our WD-based system establishes a new state-of-the-art  but is 1.88 faster than the big teacher network.              %% predictions           \node[teacher prob,minimum height=0.6cm,anchor=south]  at  {};           \node[teacher prob,minimum height=1cm,anchor=south east]  at  {};           \node[teacher prob,minimum height=0.8cm,anchor=south east]  at  {};           \node[teacher prob,minimum height=0.4cm,anchor=south west]  at  {};           \node[teacher prob,minimum height=0.2cm,anchor=south west]  at  {};                        % Student           \node[student weight,anchor=west]  at  {};           \node[font=\small,anchor=south,inner sep=0pt]  at  {};           \node[student weight,anchor=south]  at  {};                        %% predictions           \node[student prob,minimum height=0.4cm,anchor=south]  at  {};           \node[student prob,minimum height=0.8cm,anchor=south east]  at  {};           \node[student prob,minimum height=0.6cm,anchor=south east]  at  {};           \node[student prob,minimum height=0.1cm,anchor=south west]  at  {};           \node[student prob,minimum height=0.3cm,anchor=south west]  at  {};                        %% ground truth           \node[ground truth prob,minimum height=0.1cm,anchor=south]  at  {};           \node[ground truth prob,minimum height=1cm,anchor=south east]  at  {};           \node[ground truth prob,minimum height=0.1cm,anchor=south east]  at  {};           \node[ground truth prob,minimum height=0.1cm,anchor=south west]  at  {};           \node[ground truth prob,minimum height=0.1cm,anchor=south west]  at  {};                        % Connections           \draw[-latex',red]  .. controls + and + .. ;           \draw[-latex',red]  to ;            \draw[-latex,densely dashed]  to ;           \draw[-latex,densely dashed]  to ;           \draw[-latex,densely dashed]  to ;            \draw[-latex,densely dashed]  to ;           \draw[-latex,densely dashed]  to ;           \draw[-latex,densely dashed]  to ;       \end{tikzpicture}          }   \hfill   \subfigure[Weight Distillation]   {                 %% predictions         \node[teacher prob,minimum height=0.6cm,anchor=south]  at  {};         \node[teacher prob,minimum height=1cm,anchor=south east]  at  {};         \node[teacher prob,minimum height=0.8cm,anchor=south east]  at  {};         \node[teacher prob,minimum height=0.4cm,anchor=south west]  at  {};         \node[teacher prob,minimum height=0.2cm,anchor=south west]  at  {};                    % Student         \node[student weight,anchor=west]  at  {};         \node[font=\small,anchor=south,inner sep=0pt]  at  {};         \node[student weight,anchor=south]  at  {};                    %% predictions         \node[student prob,minimum height=0.1cm,anchor=south]  at  {};         \node[student prob,minimum height=0.8cm,anchor=south east]  at  {};         \node[student prob,minimum height=0.1cm,anchor=south east]  at  {};         \node[student prob,minimum height=0.3cm,anchor=south west]  at  {};         \node[student prob,minimum height=0.1cm,anchor=south west]  at  {};                    %% ground truth         \node[ground truth prob,minimum height=0.1cm,anchor=south]  at  {};         \node[ground truth prob,minimum height=1cm,anchor=south east]  at  {};         \node[ground truth prob,minimum height=0.1cm,anchor=south east]  at  {};         \node[ground truth prob,minimum height=0.1cm,anchor=south west]  at  {};         \node[ground truth prob,minimum height=0.1cm,anchor=south west]  at  {};                    % Parameter Generator         \coordinate  at ;         \node[pgnode]  at }]pgmid) {};         \node[pgnode]  at }]pgmid) {};         \node[pgnode]  at }]pgmid) {};         \node[pgnode]  at }]pgmid) {};          \draw[-latex,lyyblue]  to ;         \draw[-latex,lyyblue]  to ;         \draw[-latex,lyyblue]  to ;         \draw[-latex,lyyblue]  to ;                    % Connections         \draw[-latex',red]  .. controls + and + .. ;         \draw[-latex',red]  to ;          \draw[-latex',red]  .. controls + and + .. ;         \draw[-latex',red]  .. controls + and + .. ;         \draw[-latex',red]  .. controls + and + .. ;          \draw[-latex',red]  .. controls + and + .. ;         \draw[-latex',red]  .. controls + and + .. ;          \draw[-latex,densely dashed]  to ;         \draw[-latex,densely dashed]  to ;         \draw[-latex,densely dashed]  to ;          \draw[-latex,densely dashed]  to ;         \draw[-latex,densely dashed]  to ;         \draw[-latex,densely dashed]  to ;       \end{tikzpicture}          }   \hspace*{\fill}       \end{figure*}    We propose a multi-level contrastive learning paradigm to exploit the fine-grained response quality to calibrate the training of the response generation models. We design a Rank-aware Calibration  network to construct the contrastive optimization objectives. We further build a Knowledge Inference  component to capture the keyword knowledge from the reference during training and exploit such information to encourage the generation of informative words. We evaluate the proposed model on a carefully annotated short-text conversation dataset and the results suggest that our model can generate more relevant and diverse responses compared to the baseline models.   
","   Knowledge distillation has been proven to be effective in model acceleration and compression. It allows a small network to learn to generalize in the same way as a large network. Recent successes in pre-training suggest the effectiveness of transferring model parameters. Inspired by this, we investigate methods of model acceleration and compression in another line of research. We propose Weight Distillation to transfer the knowledge in the large network parameters through a parameter generator. Our experiments on WMT16 En-Ro, NIST12 Zh-En, and WMT14 En-De machine translation tasks show that weight distillation can train a small network that is 1.88$\sim$2.94$\times$ faster than the large network but with competitive performance. With the same sized small network, weight distillation can outperform knowledge distillation by 0.51$\sim$1.82 BLEU points.",73
" % ==============================================================================  The CLEVR dataset  is a modern 3D incarnation of historically significant shapes-based datasets like SHRDLU , used for demonstrating AI efficacy on language understanding . Although originally aimed at the visual question answering  problem , its versatility has seen its use in diverse ML domains, including extensions to physics simulation engines for language augmented hierarchical reinforcement learning  and causal reasoning .      Parallelly, research interest in geometric learning and GNN  based techniques have seen a dramatic surge in recent deep learning zeitgeist. In this focused paper, we present a library that allows easy integration and application of geometric representation learning on CLEVR dataset tasks - enabling the NLP research community to apply GNN based techniques to their research .  The library has three main  components:  1. Parser: allows extraction of graph structured relationships among objects of the environment -- both for textual questions, and semantic image scene graphs, 2. Embedder: allows generation of latent embeddings using any models or desired backend of choice , 3. Visualizer: provides tools for visualizing structural graphs and latent embeddings.   %   %Thus, with the release of this library, we hope to enable greater adoption of geometric learning in the NLP community, by lowering initial learning curve and/or rapid prototyping and integration of GNNs in NLP research domains like language grounded RL, visual reasoning, language compositionality  etc. .  % ==============================================================================    In this work, we propose weight distillation to transfer knowledge in parameters of the teacher network to the student network. It generates the student network from the teacher network via a parameter generator. Our experiments show that weight distillation consistently outperforms knowledge distillation by producing a faster and better student network on three machine translation tasks.   
"," The CLEVR dataset has been used extensively in language grounded visual reasoning in  Machine Learning  and Natural Language Processing  domains. We present a graph parser library for CLEVR, that provides functionalities for object-centric attributes and relationships extraction, and construction of structural graph representations for dual modalities. Structural order-invariant representations enable geometric learning and can aid in downstream tasks like language grounding to vision, robotics, compositionality, interpretability, and computational grammar construction. We provide three extensible main components -- parser, embedder, and visualizer that can be tailored to suit specific learning setups. We also provide out-of-the-box functionality for seamless integration with popular deep graph neural network  libraries. Additionally, we discuss downstream usage and applications of the library, and how it accelerates research for the NLP research community\footnote{Code is available at - \url{https://github.com/raeidsaqur/clevr-parser}}.",74
"  Deep neural networks  have been proved vulnerable to adversarial attacks, which maliciously craft adversarial examples to fool the victim model . For instance, highly poisonous phrases with minor modification can easily deceive Google's toxic comment detection system . With the broad use of DNN-based natural language processing  systems, such as spam filtering  and malware detection , there is growing concern about their security. As a result, research into textual adversarial attacking becomes increasingly important.  %by perturbing the original input In recent years plenty of adversarial attack models have been proposed .  Nevertheless, few of them work satisfactorily in real-world attack situations. Existing adversarial attack models can be roughly classified into four categories according to the accessibility to the victim model: gradient-based, score-based, decision-based and blind models. First, gradient-based models, also known as white-box models, require full knowledge of the victim model to perform gradient computation . % attack models work in the white-box setting only , where full knowledge of the victim model is required for gradient computation. Unfortunately, we hardly know the architecture of the victim model in real-world attack situations, let alone compute the gradients.  Second, blind models do not need to know anything about the victim model, but their attack performance is usually not good enough, precisely because of complete ignorance about the victim model.  Specifically, existing blind models either implement character-level random perturbations  or conduct sentence-level distracting  and paraphrasing . However, character-level attacks are easy to repulse , and sentence-level attacks cannot guarantee attack validity, i.e, keeping the ground-truth label of the adversarial example the same as original input. More importantly, the attack success rates of most blind models are unsatisfactory. % and adversarial example quality, including grammaticality and language naturality. %  % inclined to craft invalid adversarial examples, which have different ground-truth labels from original input, or   Finally, score- and decision-based attack models seem to be more suitable for real-world adversarial attack situations. They only need to know the output of the victim models -- the former requires prediction scores and the latter just needs the final prediction decision. % which is normally practicable in real-world adversarial attacking situations % Attack models between the above two kinds of models seem to more suitable for the real-world situation of adversarial attacking, where we are usually able to invoke the victim model and obtain its output.  Existing score- and decision-based attack models have achieved great attack performance , but they have a significant problem. To craft an adversarial example, these models have to iteratively make perturbations and query the victim model too many times, e.g., a very recent score-based model needs to query the victim model more than  times on average to generate an adversarial example . % They utilize the victim model output as guidance and iteratively conduct perturbations until finding an adversarial example . % PWWS濞屸剝婀乮teratively % Although achieving good attacking performance, these models usually need to invoke the victim model too many times, e.g., the attack model in \citet{zang2020word} needs to invoke the victim model more than  times on average when attack one instance. It is neither efficient nor practical to invoke the victim model so many times in real-world situations of adversarial attacking.  We argue that the low efficiency of existing score- and decision-based attack models results from that they have no learning ability and simply follow certain fixed optimization rules to attack, e.g., greedy algorithm , genetic algorithm  and particle swarm optimization .  % these model -> these score- and decision-based models? % For each instance, they start to attack from scratch. % And no lessons are learned from previous attacks. %For example, \citet{zang2020word} ?  To solve this problem, we propose to build an attack model possessing learning ability, which can learn lessons from attack history and store them in its parameters so as to improve attack efficiency. % learn the weak sides of data and the victim model% data? % from history so as to launch deadly attacks efficiently. Considering no labeled data are available in adversarial attacking, we design our model following the reinforcement learning paradigm. There are two main operations in our model, including identifying key words in the original sentences that crucially influence the decision of the victim model, and selecting appropriate substitutes to replace them. Our model is aimed at learning an optimal policy under which a series of substitution operations are iteratively conducted to generate adversarial examples.  % The prober is aimed at locating where is the most vulnerable in a sentence, i.e., which word in a sentence is easiest to attack. % The attacker is supposed to find the most fatal attack, i.e., which word should replace the most vulnerable word in the original input. %Our attack model is highly adaptable and can be combined with different word substitution methods.   In experiments, we evaluate our attack model on the benchmark datasets of three typical NLP tasks including sentiment analysis, text classification and natural language inference. The victim models are respective  state-of-the-art models of the datasets, namely ALBERT , XLNet  and RoBERTa , and two open APIs. Since our model can work in both score- and decision-based attack settings, we carry out experiments in the two settings. Experimental results show that our attack model consistently outperforms the baseline methods on all the datasets in terms of both attack success rate and attack efficiency. % within whatever the limit of the number of victim model query times.  We also find our model can bring more robustness improvement to the victim model by adversarial training. % conduct quantitative analyses to exhibit the learning ability of our model.  % 閸滃矁鐦濋弴鎸庡床閺傝纭堕惃鍕波閸氬牊褝绱 % score閸滃畳ecision based閻ㄥ嫭甯归崙鐚寸吹 % 娣囶喗鏁奸悳鍥ㄦЦ閸氾箒顩︽担婊璐熸稉娑擃亪鍣哥憰浣瑰瘹閺嶅浄绱垫稉宥勭稊娑撴椽鍣哥憰浣瑰瘹閺嶅洤鎯傞敍灞惧壈娑斿绗夐弰顖滃閸掝偅妲戠涵&閹存垳婊戦惃鍕侀崹瀣躬鐠囥儲瀵氶弽鍥︾瑐濞屸剝婀侀弰搴㈡▔娴兼ê濞嶉妴     In this work, we proposed to improve the aggressive language detection  by jointly performing text normalization , via a adversarial multi-task learning framework. The private encoders for ALD and TN focused on the task-specific feature retrieving, respectively, and the shared encoder learned the underlying common features over two tasks. During adversarial training, the task discriminator distinguished the separate learning of ALD or TN. Experimental results on four ALD datasets showed that our model outperformed all baselines by large margins under differing settings, demonstrating the necessity of joint learning the TN with ALD.   
"," Adversarial attacking aims to fool deep neural networks with adversarial examples. In the field of natural language processing, various textual adversarial attack models have been proposed, varying in the accessibility to the victim model. Among them, the attack models that only require the output of the victim model are more fit for real-world situations of adversarial attacking. However, to achieve high attack performance, these models usually need to query the victim model too many times, which is neither efficient nor viable in practice. To tackle this problem, we propose a reinforcement learning based attack model, which can learn from attack history and launch attacks more efficiently. In experiments, we evaluate our model by attacking several state-of-the-art models on the benchmark datasets of multiple tasks including sentiment analysis, text classification and natural language inference. Experimental results demonstrate that our model consistently achieves both better attack performance and higher efficiency than recently proposed baseline methods. We also find our attack model can bring more robustness improvement to the victim model by adversarial training. All the code and data of this paper will be made public.",75
"  In natural languages, lexical items can often be used in multiple word classes without overt changes in word form. For instance, the word buru in Mundari can be used as a noun to denote `mountain', or as a verb to denote `to heap up' . Known as word class flexibility, this phenomenon is considered one of the most challenging topics in linguistic typology . We present a computational methodology to quantify the regularity in word class flexibility across languages.   There is an extensive literature on how languages vary in word class flexibility, either directly  or through related notions such as word class conversion  . However, existing studies tend to rely on analyses of small sets of lexical items that may not be representative of word class flexibility in the broad lexicon. Critically lacking are systematic analyses of word class flexibility across many languages, and existing typological studies have only focused on qualitative comparisons of word class systems.   We take to our knowledge the first step towards computational quantification of word class flexibility in \NumLanguages languages, taken from the Universal Dependencies project . We focus on lexical items that can be used both as nouns and as verbs, i.e., noun-verb flexibility. This choice is motivated by the fact that the distinction between nouns and verbs is the most stable in word class systems across languages: if a language makes any distinction between word classes at all, it will likely be a distinction between nouns and verbs . However, our understanding of cross-linguistic regularity in noun-verb flexibility is impoverished.  We operationalize word class flexibility as a property of lemmas. We define a lemma as flexible if some of its occurrences are tagged as nouns and others as verbs. Flexible lemmas are sorted into noun dominant lemmas, which occur more frequently as nouns, and verb dominant lemmas that occur more frequently as verbs. Our methodology builds on contextualized word embedding models  to quantify semantic shift between grammatical classes of a lemma, within a single language. This methodology can also help quantify metrics of flexibility in the lexicon across  languages.  We use our methodology to address one of the most fundamental questions in the study of word class flexibility: should this phenomenon be analyzed as a directional word-formation process similar to derivation, or as a form of underspecification? Derived words are commonly argued to have a lower frequency of use and a narrower range in meaning compared to their base . If word class flexibility is a directional process, we should expect that flexible lemmas are subject to more semantic variation in their dominant word class than in their less frequent class. We also test the claim that noun-to-verb flexibility  involves  more  semantic shift  than  verb-to-noun flexibility.  While previous work has explored these questions, it remains challenging to quantify semantic shift and semantic variation, particularly across different languages.  We present a novel probing task that reveals the ability of deep contextualized models to capture semantic information across word classes. Our utilization of deep contextual models predicts human judgment on the spectrum of noun-verb flexible usages including homonymy , polysemy , and word class flexibility. We find that BERT outperforms ELMo and non-contextual word embeddings, and that the upper layers of BERT capture the most semantic information, which resonates with existing probing studies .     In this paper, we propose a reinforcement learning-based textual adversarial attack model aimed at real-world adversarial attack situations. It can work in both score- and decision-based attack settings and possesses learning ability so as to launch attacks more efficiently.  We also find that our model can bring more robustness improvement to the victim model by adversarial training as compared with existing baselines.  In the future, we will work towards further enhancing attack efficiency and improving attack performance in the situation of extremely limited victim model queries. In addition, we will explore how to make model more robust by adversarial training or other methods.    
"," Word class flexibility refers to the phenomenon whereby a single word form is used across different grammatical categories. Extensive work in linguistic typology has sought to characterize word class flexibility across languages, but quantifying this phenomenon accurately and at scale has been fraught with difficulties. We propose a principled methodology to explore regularity in word class flexibility. Our method builds on recent work in contextualized word embeddings to quantify semantic shift between word classes , and we apply this method to \NumLanguages languages\footnote{Code and data to reproduce the experimental findings are available at: \url{https://github.com/SPOClab-ca/word-class-flexibility}.}. We find that contextualized embeddings not only capture human judgment of  class variation within words in English, but also uncover shared tendencies in class flexibility across languages. Specifically, we find greater semantic variation when flexible lemmas are used in their dominant word class, supporting the view that word class flexibility is a directional process. Our work highlights the utility of deep contextualized models in linguistic typology.",76
"  Coreference resolution is the task of identifying mentions in a document that co-refer to the same entity. It is an important task facilitating many applications such as question answering and text summarization.  \citet{lee-etal-2017-end} proposed the first neural end-to-end architecture for coreference resolution. Most recent state-of-the-art systems use it as a backbone while utilizing better scoring functions, pruning procedures, or pre-trained token representations. Despite this usage, to our knowledge, no in-depth analysis has been done to better understand the inner workings of such an influential system. This understanding is important: for example, \citet{kummerfeld-klein-2013-error}'s analysis of the then-best classical coreference systems inspired many important follow-up works . However, it is unknown if observations on such classical feature-based and often highly pipelined systems extend to the current end-to-end models.  In this paper, we empirically analyze the best instantiation of this model family, SpanBERT + c2f-coref, by investigating the interaction between its two components: the mention detector and mention linker. Specifically, we study how the errors in each independently or jointly affect the final clustering.  Using the CoNLL-2012 and PreCo datasets, we highlight the low-precision, high-recall nature of the detector. While traditionally only recall is emphasized for the detector as a design decision , we show huge degradation from noisy mentions and that, perhaps surprisingly, increasing the number of candidates considered by the baseline linker only deteriorates the performance. While some classical coreference pipelines focused on detector precision, it is rarely emphasized for modern end-to-end systems. We hence stress the importance of a precision-recall balance for the detector and demonstrate how pruning hyperparameters, in addition to reducing computational complexity, help control this trade-off. However, we show the difficulty of obtaining a high-precision detector by demonstrating the importance of anaphoricity decisions and the inability of the detector to make such decisions. Finally, we highlight the high potential of the linker and that the remaining errors besides anaphoricity decisions mainly involve pronoun resolution. We hope these findings shed light on the internal mechanism of the mainstream coreference system and lay out an empirical foundation for future research.     We use contextual language models to examine shared tendencies in word class flexibility across languages. We find that the majority class often exhibits more semantic variation than the minority class, supporting the view that word class flexibility is a directional process. We also find that in English, noun-to-verb flexibility is associated with more semantic shift than verb-to-noun flexibility, but this is not the case for most languages.  Our probing task reveals that the upper layers of BERT contextual embeddings best reflect human judgment of semantic similarity. We obtain similar results in different datasets and language models in English that support the robustness of our method. This work demonstrates the utility of deep contextualized models in linguistic typology, especially for characterizing cross-linguistic semantic phenomena that are otherwise difficult to quantify.  
","  Coreference resolution is an important task for discourse-level natural language understanding. However, despite significant recent progress, the quality of current state-of-the-art systems still considerably trails behind human-level performance. Using the CoNLL-2012 and PreCo datasets, we dissect the best instantiation of the mainstream end-to-end coreference resolution model that underlies most current best-performing coreference systems, and empirically analyze the behavior of its two components: the mention detector and mention linker. While the detector traditionally focuses heavily on recall as a design decision, we demonstrate the importance of precision, calling for their balance. However, we point out the difficulty in building a precise detector due to its inability to make important anaphoricity decisions. We also highlight the enormous room for improving the linker and that the rest of its errors mainly involve pronoun resolution. We hope our findings will help future research in building coreference resolution systems.",77
"    Neural machine translation   enables end-to-end training of translation models and is known to give state-of-the-art results for a large variety of language pairs. NMT for high-resource language pairs is straightforward: choose an NMT architecture and implementation, and train a model on all existing data. In contrast, for low-resource language pairs, this does not work well due to the inability of neural networks to generalize from small amounts of data. One reason for this is the strong over-fitting potential of neural models .  There are several solutions that address this issue of which the two most effective ones are transfer learning and model regularization. Transfer learning can sometimes be considered as data regularization and comes in the form of monolingual or cross-lingual  transfer learning , pseudo-parallel data generation  , or multi-task learning . On the other hand, model regularization techniques place constraints on the learning of model parameters in order to aid the model to learn robust representations that positively impact model performance. Among existing model regularization methods, dropout  is most commonly used and is known to be effective regardless of the size of data. We thus focus on designing a technique that can complement dropout especially in an extremely low-resource situation.  The most common way to train NMT models is to minimize a softmax cross-entropy loss, i.e., cross-entropy between the softmax distribution and the smoothed label distribution typically represented with a one-hot vector. In other words, the NMT model is trained to produce a softmax distribution that is similar to the label. In high-resource settings, this may never happen due to the diversity of label sequences.  However, in low-resource settings, due to lack of the diversity, there is a high chance of this occurring and over-fitting is said to take place. We consider that a simple manipulation of the softmax distribution may help prevent it.  This paper presents our investigation into softmax tempering  during training NMT models in order to address the over-fitting issue. Softmax tempering is realized by simply dividing the pre-softmax logits with a positive real number greater than 1.0.  This leads to a smoother softmax probability distribution, which is then used to compute the cross-entropy loss. Softmax tempering has been devised and used regularly in knowledge distillation , albeit for different purposes. We regard softmax tempering as a means of deliberately making the softmax distribution noisy during training with the expectation that this will have a positive impact on the final translation quality.    We primarily evaluate the utility of softmax tempering on extremely low-resource settings involving English and 11 languages in the Asian Languages Treebank  . Our experiments reveal that softmax tempering with a reasonably high temperature improves the translation quality. Furthermore, it makes the greedy search performance of the models trained with softmax tempering comparable to or better than the performance of the beam search using the models that are trained without softmax tempering, enabling faster decoding.  We then expand the scope of our study to high-resource settings, taking the WMT 2019 English-to-German translation task, as well as multilingual settings using the ALT data. We also show that softmax tempering improves the performance of NMT models using recurrently stacked layers that heavily share parameters. Furthermore, we clarify the relationship between softmax tempering and dropout, i.e., the most widely used and effective regularization mechanism. Finally, we analyze the impact of softmax tempering  on the softmax distributions and on the gradient flows during training.     We analyzed the complex interaction between the mention detector and linker in the mainstream coarse-to-fine coreference system. Using oracle experiments, we showed that, while detector recall is important, higher non-singleton mention precision would lead to dramatically better linker performance, though achieving this is difficult. We also demonstrated that the oracle linker performance is near perfect and that the vast majority of remaining linker errors besides anaphoricity decisions are about pronoun resolution. We hope these discoveries will help future research in coreference systems.     \clearpage                            
"," Neural machine translation  models are typically trained using a softmax cross-entropy loss where the softmax distribution is compared against smoothed gold labels. In low-resource scenarios, NMT models tend to over-fit because the softmax distribution quickly approaches the gold label distribution. To address this issue, we propose to divide the logits by a temperature coefficient, prior to applying softmax, during training. In our experiments on 11 language pairs in the Asian Language Treebank dataset and the WMT 2019 English-to-German translation task, we observed significant improvements in translation quality by up to 3.9 BLEU points. Furthermore, softmax tempering makes the greedy search to be as good as beam search decoding in terms of translation quality, enabling 1.5 to 3.5 times speed-up. We also study the impact of softmax tempering on multilingual NMT and recurrently stacked NMT, both of which aim to reduce the NMT model size by parameter sharing thereby verifying the utility of temperature in developing compact NMT models. Finally, an analysis of softmax entropies and gradients reveal the impact of our method on the internal behavior of NMT models.",78
" Neural text generation is one of the extensively studied tasks of natural language processing , as it forms the basis for dialogue systems, machine translation, and text summarization. However, often monotonous or dull, texts generated from existing methods do not fully reflect the rich diversity and expression in human language. In particular, models tend to overproduce words frequently appearing in the data, while hardly utilizing informative words  . % along with fast-evolving model architectures and pre-training techniques. \dkp{} % \st{However, existing methods in neural text generation stop short of resolving the problem of degeneration in which machine-generated texts are either monotonous or repeating the same words and phrases, often failing to complete a proper sentence.} Even pre-training techniques on large corpora fail to resolve the issue.  %\dkpc{Current logic: three causes, and we choose to solve the last  Better logic: one cause - drawback, second cause - drawback, the third cause - directly addressing the model, thus optimal!}  Possible causes for text degeneration have been illuminated, such as a defect specific to model architectures or the discrepancy between training data and a true distribution. Recently, the emphasis has been placed on investigating the flaws in the maximum likelihood objective. Concretely, the likelihood training pays little attention to the top ranks in terms of the target token probabilities, or maximizing likelihood itself does not adequately reflect human language processing. Therefore, with the maximum likelihood-based training, models learn to produce tokens frequently appearing in the data more often.   We argue, however, that the primary reason behind the sub-optimal performance of the likelihood objective is essentially the imbalanced token distribution inherent in natural language. Natural language is extremely skewed in distribution, where the top hundred most frequently-used  words occupy nearly half of the total corpus following the Zipf's law. Training a classifier with the inherently imbalanced data on the maximum likelihood estimation  leads to biased classification boundaries in favor of majority classes. In other words, models play a difficult role in learning with the imbalanced label  distribution. % \st{Our analysis  comparing the word frequencies between the corpus and texts generated from an MLE model reveals that the model uses top-100 words 40\% more often than the original data.} %   Although the above might be contributing factors, we found that word distribution itself provides clues to the text degeneration.   %We set our work in line with the last category. However, unlike the previous approaches, we claim that data distribution can provide clues as to why text degenerates.  %Prior studies report a number of main causes that for text degeneration. First, it is attributed to the Attention mechanisms, where \dkp{bulabula}. Another reason lies in the training of the machine over a fixed corpora of which the distribution does not agree with the real-world language distribution. Lastly, maximum-likelihood objective, by which the machine is trained with, has been questioned. Following the maximum-likelihood, little attention is made to the top ranks of the next \dkpc{next of what?} token probabilities. \dkpc{this should be explained crystal clear, since this phenomenon is directly related to our model}. and that it differs from human behavior.    %   We hypothesize that text generation can be enriched by balancing out the training data distribution. To this end, we introduce F-Softmax , Section), which factorizes the probability distribution of the target token into a product of two conditional probabilities of  frequency class, and  token from the target frequency class. It ensures training over balanced data, since the frequency classes are designed to have the distribution close to uniformity, and token distributions within a class are confined to  subsets of vocabularies grouped with similar frequencies. To this end, all unique tokens are assigned to a frequency class prior to the training, by our novel mean efficiency maximization , Section). MefMax evaluates and maximizes the class-labeling performance with the normalized entropy , having the probability distributions to be learned as uniform as possible.  % Athe probability distributions to be learned by the model are as uniform as possible, without introducing any hyperparameter. % \st{which assigns all tokens, in an order of decreasing frequency, to a unique frequency class given the condition that all classes share the same frequency mass. In this way, both prediction pipelines for frequency classes and tokens, respectively, are performed based on well-defined data with the near-uniform class distribution.}           % We propose a factorized softmax that achieves this by introducing the concept of classes and decomposing the output probabilities using the classes. It computes the probability distributions of tokens in a factorized manner; probability distribution of the class and conditional probability distribution of the next token given the class. The probability of the next token is computed within a subset of the vocabulary, rather than full vocabulary. Well structured subsets of vocabulary allows model to benefit from the balanced output distributions. We assign each token to a unique class utilizing our proposed mean efficiency maximization algorithm so that each data distribution to be trained has a distribution that is as uniform as possible.  We conduct extensive performance evaluations on seven relevant metrics that quantify the diversity and quality of generated texts. In terms of the diversity of generated texts, our approach significantly outperforms not only the MLE baseline but also other diversity-promoting alternatives . We also achieve state-of-the-art results on most of the quality performances.     In this paper, we explored the utility of softmax tempering for training NMT models. Our experiments in low-resource and high-resource settings revealed that not only does softmax tempering lead to an improvement in the decoding quality but also bridges the gap between greedy and beam search performance. Consequently, we can use greedy search while achieving better translation quality than non-tempered models leading to 1.5 to 3.5 times faster decoding. We also explored the compatibility of softmax tempering with multilingualism and extreme parameter sharing, and explicitly investigated the complementarity of softmax tempering and dropout, where we show that softmax tempering can be an alternative to dropout in high-resource settings, while it is complementary to dropout in low-resource settings. Our analysis of the softmax entropies and gradients during training confirms that tempering gives precise softmaxes while enabling the model to learn with strong gradient signals even during late training stages.  In the future, we will explore the effectiveness of softmax tempering in other natural language processing tasks.  
"," %Despite recent advances in neural text generation, encoding the rich diversity in human language remains elusive. We argue that the sub-optimal text generation is largely attributable to the imbalanced token distribution, which particularly misdirects the learning model when trained with the maximum-likelihood objective. As a simple yet effective remedy, we propose F$^2$-Softmax to enable a balanced training over the tokens with skewed frequency distribution. \dkp{By decomposing the softmax function, F$^2$-Softmax confines probability distribution to subsets of vocabularies which are more uniformly distributed. The subsets are further optimized by our novel mean efficiency maximization , without introducing any hyperparameter.} Significant performance gains across generation quality metrics suggest that our methods achieve human-like diversity in text generation.  Despite recent advances in neural text generation, encoding the rich diversity in human language remains elusive. We argue that the sub-optimal text generation is mainly attributable to the imbalanced token distribution, which particularly misdirects the learning model when trained with the maximum-likelihood objective. As a simple yet effective remedy, we propose two novel methods, F$^2$-Softmax and MefMax, for a balanced training even with the skewed frequency distribution. MefMax assigns tokens uniquely to frequency classes, trying to group tokens with similar frequencies and equalize frequency mass between the classes. F$^2$-Softmax then decomposes a probability distribution of the target token into a product of two conditional probabilities of  frequency class, and  token from the target frequency class. Models learn more uniform probability distributions because they are confined to subsets of vocabularies.  Significant performance gains on seven relevant metrics suggest the supremacy of our approach in improving not only the diversity but also the quality of generated texts.  % Despite recent advances in neural text generation, encoding the rich diversity in human language remains elusive. We argue that the sub-optimal text generation is mainly attributable to the imbalanced token distribution, which particularly misdirects the learning model when trained with the maximum-likelihood objective. As a simple yet effective remedy, we propose F$^2$-Softmax for a balanced training even with the skewed frequency distribution. F$^2$-Softmax decomposes a probability distribution of the target token into a product of two conditional probabilities of  frequency class  token from the target frequency class. Models learn more uniform probability distributions because they are confined to subsets of vocabularies. The subsets are further optimized by our novel mean efficiency maximization . It maximizes the . Significant performance gains across generation quality metrics suggest that our method achieves human-like diversity in text generation, without compromising the quality of generated texts. Significant performance gains on seven relevant metrics suggest the supremacy of our approach improves both diversity and quality in text generation.",79
"  Natural language understanding  is a key component of conversational dialogue systems, converting user's utterances into the corresponding semantic representations for certain narrow domain . As a core task in NLU, slot tagging is usually formulated as a sequence labeling problem.  Recently, motivated by commercial applications like Amazon Alexa, Apple Siri, Google Assistant, and Microsoft Cortana, great interest has been attached to rapid domain transfer and adaptation with only a few samples. Few-shot learning approaches become appealing in this scenario , where a general model is learned from existing domains and transferred to new domains rapidly with merely few examples .  The similarity-based few-shot learning methods have been widely analyzed on classification problems, which classify an item according to its similarity with the representation of each class. These methods learn a domain-general encoder to extract feature vectors for items in existing domains, and utilize the same encoder to obtain the representation of each new class from very few labeled samples . This  scenario has been successfully adopted in the slot tagging task by considering both the word-label similarity and temporal dependency of target labels. Nonetheless, it is still a challenge to devise appropriate word-label similarity metrics for generalization capability.  In this work, a vector projection network is proposed for the few-shot slot tagging task in NLU. To eliminate the impact of unrelated label vectors but with large norm, we exploit projections of contextual word embeddings on each normalized label vector as the word-label similarity. Moreover, the half norm of each label vector is utilized as a threshold, which can help reduce false positive errors.   %It first normalizes the vector representation of each label as a unit vector, and then exploits projections of contextual word embeddings on these unit label vectors as the word-label similarities.  One-shot and five-shot experiments on slot tagging and named entity recognition  tasks show that our method can outperform various few-shot learning baselines, enhance existing advanced methods like TapNet and prototypical network, and achieve state-of-the-art performances.  Our contributions are summarized as follows:     In this paper, we propose a unified multi-task learning approach that exploits the capabilities of adversarial learning approach for relation extraction from biomedical domain. We first experimented on three benchmark biomedical relation extraction tasks, i.e., protein-protein interaction, drug-drug interaction, and clinical relation extraction. For that, we utilized four popular datasets: AIMed, BioInfer, SemEval 2013 DDI shared task dataset and i2b2-2010 clinical relation dataset. We demonstrated that our model shows superior performance compared to state-of-the-art models for all the tasks. \\ Although our model has shown significant improvements over state-of-the-art methods on all the tasks, it was observed that our supervised model does not generalize well for the class label with the small instances. In future, we would like to develop a zero-shot learning method that could assist the model in the huge class imbalance issue.   {\bf Acknowledgement}:  Dr. Sriparna Saha gratefully acknowledges the Young Faculty Research Fellowship  Award, supported by Visvesvaraya Ph.D. Scheme for Electronics and IT, Ministry of Electronics and Information Technology , Government of India, being implemented by Digital India Corporation  for carrying out this research.    if have a single appendix:  [Proof of the Zonklar Equations]   or      for no appendix heading   do not use 
","  Few-shot slot tagging becomes appealing for rapid domain transfer and adaptation, motivated by the tremendous development of conversational dialogue systems. In this paper, we propose a vector projection network for few-shot slot tagging, which exploits projections of contextual word embeddings on each target label vector as word-label similarities. Essentially, this approach is equivalent to a normalized linear model with an adaptive bias. The contrastive experiment demonstrates that our proposed vector projection based similarity metric can significantly surpass other variants. Specifically, in the five-shot setting on benchmarks SNIPS and NER, our method outperforms the strongest few-shot learning baseline by $6.30$ and $13.79$ points on F$_1$ score, respectively. Our code will be released at \url{https://github.com/sz128/few_shot_slot_tagging_and_NER}.",80
" %   Over the last decade an increasing number of people access news online, and use social networking platforms to engage, consume and propagate this content in their social circles. Social networks provide easy means to distribute news and commentary, resulting in a sharp increase in the number of media outlets, representing a wide range of perspectives and ideologies. However, despite this diversity, content is often shared only among people that hold similar beliefs and ideologies, resulting in highly segregated information communities, often referred to as ``echo chambers''.  % To date, most works studying this phenomenon have either focused on the linguistic aspects of biased and polarized content, or on the social aspects connecting users to content providers and the way documents spread. Our main observation in this paper is that modeling both these aspects is needed in order to understand and analyze information communities. %focused on analyzing the interactions between news sources and users in social networks % Our goal in this paper is to formalize the connections between the perspectives expressed in the text, the users who share them, their social interactions and the information communities emerging from these connections. We suggest a novel, minimally supervised, approach for embedding information communities, which allows us to map the news media landscape on politically divisive issues, and capture the ideological biases and perspectives expressed in news content. We analyze the differences between communities based on their position on a continuous conservative-liberal ideological spectrum, and observe the differences in perspectives expressed in documents shared in these communities in three issues--  immigration, gun-control and abortion.   % %Identifying the perspective difference and making it explicit can help strengthen trust in the newly-formed information landscape and ensure that all perspectives are represented. It can also help lay the foundation for the automatic detection of false content and rumors and help identify information echo-chambers in which only a single perspective is highlighted. %ribeiro2018media    \subsection{Issue-Framing and Political Perspective}  To help clarify our objectives, consider two articles on the highly polarized immigration issue. \\ % Example 1: Different Perspectives on Immigration  %Difference in frame usage by party. Topic: Immigration, Frame used: Economic % colback=blue!5!white,colframe=blue!75!black         \end{tcbraster}   The two articles capture opposite political perspectives, liberal  and conservative . They do not directly contradict each other, rather they focus the discussion on different aspects helping them argue their case. The first emphasizing the contribution of immigrants to the community through tax revenue, and the second emphasizing implication on wages for U.S. workers. This process is known as framing.  % Our goal is to both capture the political perspective associated with articles, and explain that perspective by identifying the framing dimensions in the text, which are associated with that perspective and support it. Previous work by~\citet{boydstun2014tracking} studied policy issue framing on news media and suggested 15 broad frames to analyze how issues are framed, which include Economic, Morality and Security, among others. These framing dimensions can help capture ideological splits. For example, by framing the immigration issue using the morality frame or using the security frame, the reader is primed to accept the liberal or conservative perspectives, respectively. However, as shown in Example 1, in some cases this analysis is too coarse grained, as both articles frame the issue using the economic frame, suggesting that a finer grained analysis is needed to capture the differences in perspective. To help resolve this issue, we suggest a data-driven refinement to these frames, described in section, by identifying repeating expressions used in the context of the different frames, and grouping them to form sub-frames, which can separate between different usages of the frame to express different political perspectives . %  Our goal is to capture the ideological perspective associated with documents, identify how issues are framed to support these perspectives, and represent the political meaning of these frames on an ideological spectrum.     \subsection{Embedding Information Communities}  %Identifying political perspectives is typically framed as a text-categorization The analysis discussed above is typically framed as text classification, e.g., biased language analysis, political ideology identification or framing analysis. Given the highly dynamic nature of political events and the strategies used to discuss them, these methods would require continuous adaptation. %  Instead, we take a different approach driven by the principal of social homophily, referring to the tendency of individuals to form social ties with others who share their views. This phenomenon was previously used to help overcome language variation issues. In our settings, we follow the observation that the political perspectives and attitudes expressed in the text will be reflected in the behavior of users engaging with it. We identify similar patterns and exploit distant supervision to construct information communities consisting of documents and users,  holding similar views and focusing on similar aspects of the issues. Figure describes an example for the immigration issue.   We define the communities over an information graph, modeling the interaction between news document nodes, users who share them on Twitter, and political influencers, such as politicians, followed-by the sharing users. % %Given a graph connecting Twitter users nodes, via activity-links to news article nodes  , and  via social-links  to politically affiliated users ,  Our algorithm groups users and news-article nodes together into communities, associates political meaning with these communities by observing the social links to politicians, and identifies repeating themes and perspectives by observing how the topic is framed in the news articles associated with each community. %TODO: explain - the embedding space, allowing them to share representation, creates a common language for evaluating the relationship between these elements, connecting frames with political labels, documents .  A community defines a probability distribution, over these elements, to belong to the same cluster. The assignments are overlapping.  The community is represented using its centroid, allowing us to create an embedding for the community, that can be evaluated in the embedding space - by observing its similarity with other elements, such as labels, and perspectives, which  explain that community.  %  % To accomplish that, we define a latent space for embedding users, documents, political influencers, frames and ideology-labels. Intuitively, the embedding space is shaped both by the textual content of documents, the engagement patterns of users with these documents and their social ties to politicians.  We take a community embedding approach, and define communities as a multivariate Gaussian distribution over that latent space. We suggest an EM-style learning approach, augmenting the graph embedding objective, based on first-order graph relations, with a global-view derived from the inferred community assignments.  Unlike related work analyzing community behavior and conflicts, we do not analyze observed community structures, but rather our goal is to construct these communities, as a way to characterize how different issues are discussed and align social information with the text. Recent work by ~\citet{li2019encoding} exploits social supervision for detecting political bias in documents. We take a broader view in this work, and aim to characterize the discussion, rather than individual articles.   %TODO - what are our experiments designed todo?  One practical thing is to evaluate document classification, and show that adding communities can help.  More broadly -   sanity check for the communities.  communities properties. We conduct extensive experiments to evaluate the inferred community structures, over three politically divisive issues, namely, immigration, abortion and gun-control. We show that our approach can be used to detect the political ideology of documents, even when little social information is available, as well as characterize cohesive information communities, focusing on different aspects of these issues.   %   % TODO : discuss disconnected docs  % todo: discuss ""beyond binary labels""   % todo : discuss the no-supervision settings - similar to topic models etc.    %Eval:  %Extenral Indicators of sanity - % frame/subframe label correlation+visualization %indicator correlation. % classifier results - subframes are good features, comparable to BERT.    %Internal Sanity check - % took top-K articles for each SF, and evaluated  that they correspond to the definition . % TODO: add example for a couple of paragraphs. %  Sample 10 from each side, for each topic = 60 documents. Compare two lists of SF predicted from the text - GLDA vs. embedding    %Applying SF for analyzing data - %event based table    In this paper, we propose a vector projection network for the few-shot slot tagging task, which can be interpreted as a normalized linear model with an adaptive bias. Experimental results demonstrate that our method can significantly outperform the strongest few-shot learning baseline on SNIPS and NER datasets in both 1-shot and 5-shot settings. Furthermore, our proposed vector projection based similarity metric can remarkably surpass others variants.   For future work, we would like to add a learnable scale factor for bias in Eqn. .       
"," In this paper we suggest a minimally-supervised approach for identifying nuanced frames in news article coverage of politically divisive topics. We suggest to break the broad policy frames suggested by, \citeyear{boydstun2014tracking} into fine-grained subframes which can capture differences in political ideology in a better way. We evaluate the suggested subframes and their embedding, learned using minimal supervision, over three topics, namely, immigration, gun-control and abortion. We demonstrate the ability of the subframes to capture ideological differences and analyze political discourse in news media.  % a method for characterizing the perspectives on news media on several politically divisive issues, such as immigration, gun-control and abortion.",81
"   Two widely-known formalisms are commonly used to represent the syntactic structure of sentences in human languages: constituent and dependency representations.  Constituent trees, which are commonly used in tasks where span information is crucial, describe the syntax of a sentence in terms of constituents  and their hierarchical order. We can find two kinds of constituent trees: continuous and discontinuous  and , respectively). The latter extend the former by allowing  %the representation of  crossing branches and constituents with gaps in the middle. These are necessary for describing some wh-movement, long-distance extractions, dislocations, cross-serial dependencies and other linguistic phenomena common in free word order languages such as German .  On the other hand, a dependency tree straightforwardly connects each word of a sentence as a dependent of another, which is considered its head word. This structure composed of binary syntactic dependencies is known for representing information closer to semantic relations and can be classified as projective or non-projective  and , respectively). %, being the  Non-projective dependency trees  %are a more complex structure that allows to allow crossing dependencies, and can model the same linguistic phenomena described by discontinuous constituent trees.  Since the information described in a  %regular  constituent tree cannot be fully represented in a  %regular  dependency tree and vice versa ,  %typically there are parsers that are typically parsers are exclusively trained to produce either dependency or constituent structures and, in some cases,  %they are  restricted to the less complex continuous/projective representations. %, supporting just one out of the four syntactic structures described before.   \carlos{There are a few exceptions, i.e., approaches trained to generate both constituents and dependencies. For instance, the chart parser of \citet{zhou-zhao-2019-head} generates continuous and projective structures with a single  model, and the sequence labeling parser of \citet{strzyz19} combines continuous constituents with non-projective dependency structures. In both cases, which are discussed in more detail in Section,  representations are shown to benefit each other in terms of accuracy.}  \carlos{However, to our knowledge, no such joint training approaches have been defined that support both non-projective dependency trees and discontinuous constituents; and the most accurate and least computationally complex models for these formalisms are single-representation approaches: graph-based  and transition-based  models for non-projective dependencies,  and transition-based parsers  for discontinuous phrase-structure trees.}  \carlos{In order to fill this gap,} we propose a novel multitask transition-based parser that can efficiently generate unrestricted constituent and dependency structures \carlos{} from a single trained model. We design an encoder-decoder neural architecture that is jointly trained across the syntactic information represented in the two formalisms by following a multitask learning strategy . Inspired by  , we model constituent trees as augmented dependency structures  and use two separate task-specific decoders to produce both regular and augmented dependency trees. Each decoder relies on Pointer Networks  and a biaffine classifier  to incrementally generate labelled dependencies from left to right, as proposed by \citet{L2RPointer}. Finally, the decoding runtime $) and the required memory space of our multi-representational approach remains the same as the single-task dependency parser by \citet{L2RPointer}, since a single model is trained and the multitask learning strategy has no impact on decoding time, allowing both decoders to be run in parallel.    We test our multi-representational neural model\footnote{Source code available at \url{https://github.com/danifg/MultiPointer}.} on the continuous English and Chinese Penn Treebanks  and on the discontinuous NEGRA  and TIGER  datasets. In all benchmarks, our approach outperforms single-task parsers , which proves that learning across regular dependency trees and constituent information  leads to gains in accuracy in both tasks, obtaining competitive results in all cases and surpassing the current state of the art %by a wide margin  in several datasets.     \deproot{2}{} \depedge[edge unit distance=4ex]{2}{1}{ROOT+S\#2} \depedge{2}{3}{VP\#1} \depedge[edge unit distance=3ex]{2}{4}{VP\#1} \depedge[edge unit distance=3ex]{2}{5}{ROOT+S\#2} \end{dependency} %   \deproot[edge unit distance=2ex]{4}{} \depedge[edge unit distance=5ex]{4}{1}{nsubj} \depedge[edge unit distance=4ex]{4}{2}{cop} \depedge{4}{3}{advmod} \depedge[edge unit distance=4ex]{4}{5}{punct} \end{dependency}\\ % {\tiny a) Continuous constituent tree.}   {\tiny b) Projective augmented dependency tree.}  {\tiny c) Projective dependency tree.}\\  %%%%%%%%%%%%%%%%%%%%%%%%% \includegraphics[width=0.3\textwidth]{treedisc.png}  %  \deproot[edge unit distance=4ex]{2}{} \depedge[edge unit distance=2ex]{4}{1}{NP\#2} \depedge{4}{3}{NP\#1} \depedge[edge unit distance=4.5ex]{2}{4}{S\#1} \depedge[edge unit distance=4ex]{2}{5}{VROOT\#2} \end{dependency} %   \deproot[edge unit distance=2.5ex]{2}{} \depedge[edge unit distance=2ex]{4}{1}{APP} \depedge{4}{3}{DET} \depedge[edge unit distance=4.5ex]{2}{4}{SUBJ} \depedge[edge unit distance=4ex]{2}{5}{punct} \end{dependency}\\ % {\tiny d) Discontinuous constituent tree.}   {\tiny e) Non-projective augmented dependency tree.}  {\tiny f) Non-projective dependency tree.}    \end{figure*}     In this paper, we empirically validate the inequality of attention heads in Transformer and come up with an assumption of imbalanced training. Correspondingly, we propose a specific method in two ways to resolve the issue. Experiments show the improvements on multiple language pairs. And detailed analysis shows the alleviation of the problem and the effectiveness of our techniques.   
"," We propose a transition-based approach that, by training a single model, can efficiently parse any input sentence with both constituent and dependency trees, supporting both continuous/projective and discontinuous/non-projective syntactic structures. To that end, we develop a Pointer Network architecture with two separate task-specific decoders and a common encoder, and follow a multitask learning strategy to jointly train them. The resulting quadratic system, not only becomes the first parser that can jointly produce both unrestricted constituent  and dependency   trees from a single model, but also proves that both syntactic formalisms can benefit from each other during training, achieving state-of-the-art accuracies in several widely-used benchmarks such as the continuous English and Chinese Penn Treebanks, as well as the discontinuous German NEGRA and TIGER datasets.",82
"   %GOAL: introducing rule based% %Traditional solutions for task-oriented dialogue systems decompose the task of building a complete task-oriented dialogue system into several sequential steps, including \ac{LU}, \ac{DM} and \ac{NLG}~ . In this paper we focus on the dialogue policy that is a key component in dialogue management; it decides what actions the system should take at each time step according to the context and user feedback.  The aim of dialogue policies in \ac{TDS} is to select appropriate actions at each time step according to the current context of the conversation and user feedback~. In early work, dialogue policies were manually designed as a set of rules that map the dialogue context to a corresponding system action~. %That is only feasible when domain is not complex. %, an approach that suffers from limited task scalability and from an inability of easily being updated as user behavior changes.  %When the task domain is not complex and the possible conversation scenarios can be predefined explicitly, the dialogue policy can be represented as a set of rules that map the dialogue context to a corresponding system action .  The ability of rule-based solutions is limited by the domain complexity and task scalability. Moreover, the design and maintenance of these rules require a lot of effort and domain knowledge.   %GOAL: introducing supervised learning and its disadvantages% Due to recent advantages in deep learning and the availability of labeled conversational datasets, supervised learning can be employed for dialogue policy training to overcome the disadvantages of rule-based systems. %Dialogue context-action pairs are fed to the model to infer the underlying relation between dialogue context and corresponding dialogue actions with supervised learning methods.  \todo{It looks obvious what is the task from he first sentence the paragraph} The downside of the supervised learning approach is that the dialogues observed in the datasets are unlikely to represent all possible conversation scenarios; in some extreme cases, the required conversational dataset cannot be collected or acquiring it might cost-prohibitive.   %GOAL: introducing RL and its disadvantages% The success of \ac{RL} in other areas holds promises for dialogue \ac{PL}~. Using \ac{RL} techniques, we can train dialogue policies and optimize automatically, from scratch and utilizing interactions with users~.  % Handcrafting complex rules is not essential anymore and the expense and pressure of maintaining the policy over time can be alleviated.  In \ac{RL}-based solutions, the dialogue system takes actions that are controlled by the dialogue policy, and user feedback , which is provided when the dialogue is finished, is utilized to adjust the initial policy~.  %These methods assume that the system has access to a reward signal at the end of each dialogue. In practice, reward signals are not always available and may be inconsistent~.  As it is not practical to ask for explicit user feedback for each dialogue during policy training, different strategies have been proposed to design a rule-based user simulator along with a reward function that can approximate the real reward function which exists only in each user's mind.  Designing an appropriate user simulator and accurate reward function requires strong domain knowledge.  This process has the same disadvantages as rule-based dialog systems~.  The difference is that rule-based approaches to system design meet this problem at the dialogue agent side while rule-based user simulators need to solve it at the environment side.    %To train a dialogue agent with reinforcement learning, we have to handcraft a rule-based user simulator and it will suffer the same problem with rule-based dialogue agent when the task in becoming complex.  %The only difference is that one approach meets this problem at the dialogue agent side  while another one has to solve it at the environment side .  %%GOAL: Describing the bottleneck% If the task is simple and easy to solve, why not just build a rule-based system rather than a user-simulator that is then used with \ac{RL} techniques to train the dialogue system, where more uncontrollable factors are involved?  And if the task domain is complex and hard to solve, is it easier to design and maintain a complicated rule-based user simulator than to build a rule-based dialogue agent? % Training a model-based user simulator~ with real human dialogue dataset is an alternative solution but it is still data-hungry.  %Besides, there is no guarantee that human-designed and model-based simulator can cover all possible dialogue scenarios.  % With respect to the comparison between reinforcement learning and supervised learning, s Supervised learning methods do not suffer from these issues but require labeled conversational data; in some exceptional cases, if the data cannot be collected for privacy reasons, \ac{RL} is the solution. However, collecting labeled data is feasible for many applications~. % Therefore in this work seek to answer the following research question: Are we really making progress in c{TDSs focusing purely on advancing \ac{RL}-based methods?}   To address this question, we introduce three dialogue \ac{PL} methods which do not require a user simulator. The proposed methods can achieve comparable or even higher performance compared to \ac{SOTA} \ac{RL} methods.  The first method utilizes an action decoder to predict dialogue combinations.  %The sequential decision setup can make use of dependency information between different atomic dialogue actions in the same response.  The second method regards the dialogue \ac{PL} task as a multi-label classification problem.  Unlike previous work, we assign a dense layer to each action label in the action space. % This change provides the dialogue agent with more stable and higher performance.  Based on the second method, we propose an adversarial learning method for dialogue \ac{PL} without utilizing \ac{RL}.  To backpropagate the loss from the reward model to the policy model, we utilize the Gumbel-Softmax to connect the policy model and the reward model in our third method.  % We compare our methods with \ac{RL} and adversarial \ac{RL} based dialogue training solutions to show how we can achieve comparable performance without a utilizing costly user simulator.  To summarize, our contributions are:      We propose a novel encoder-decoder neural architecture based on Pointer Networks that, after being jointly trained on regular and constituent-based dependency trees, can syntactically parse a sentence to   two of the most extended formalisms.  both constituent and dependency trees. Apart from just requiring to train a single model, our approach can produce not only the simplest continuous/projective trees, but also discontinuous/non-projective structures in just  runtime. We test our parser on the main dependency and constituent benchmarks, obtaining competitive results in all cases and reporting state-of-the-art accuracies in several datasets.  As future work, we plan to perform auxiliary-task learning and train a separate model for each task, testing different weights for the loss computation. This will lose the advantage of training a single model to undertake both tasks, but will certainly lead to further improvements in accuracy.    
"," %\todo[maybe a more interesting title? like ``rethinking supervised learning and reinforcement learning in dialogue policy learning""] Dialogue policy learning for \ac{TDSs} has enjoyed great progress recently mostly through employing \ac{RL} methods. However, these approaches have become very sophisticated. It is time to re-evaluate it. Are we really making progress developing dialogue agents only based on \ac{RL}? We demonstrate how ~traditional supervised learning together with ~a simulator-free adversarial learning method can be used to achieve performance comparable to \ac{SOTA} \ac{RL}-based methods.  First, we introduce a simple dialogue action decoder to predict the appropriate actions. Then, the traditional multi-label classification solution for dialogue policy learning is extended by adding dense layers to improve the dialogue agent performance. Finally, we employ the Gumbel-Softmax estimator to alternatively train the dialogue agent and the dialogue reward model without using \ac{RL}.  Based on our extensive experimentation, we can conclude the proposed methods can achieve more stable and higher performance with fewer efforts, such as the domain knowledge required to design a user simulator and the intractable parameter tuning in reinforcement learning. Our main goal is not to beat \ac{RL} with supervised learning, but to demonstrate the value of rethinking the role of \ac{RL} and supervised learning in optimizing \ac{TDSs}.",83
"  Despite many recent advances in Natural Language Generation, successful creative narrative composition remains elusive.  Current neural approaches are plagued by difficulty in mastering structure, will veer between topics, and lack long-range cohesion. They successfully imitate the fluency and style of human writing, but on closer inspection sentences do not fit together to form a whole, and the reader is left with the impression that the generation has no content. % \np{I think abi see had some good work to cite.}  This lack of structure also degrades the relevance of generations conditioned on a prompt or other source text - a strong language model will repeat key phrases from a given prompt but will not remain on topic. These issues are illustrated in the Naive Generated Story in Table , where many of the sentences individually are fine, but do not fit together as one story, and do not all relate to the prompt.   We hypothesise that this problem can be addressed with a focus on deeper latent narrative structures. In Aristotle's Poetics, one of the most enduring treatises on the craft of writing good stories, the philosopher lays out the elements of story in order of importance. They are:   An amateur masters skills later in the list, but mastery of event choice and event arrangement is what distinguishes a good writer . Next is character, then relevance, and only finally do style and diction matter.  %A good writer must begin with events, and only once these are solidified should they transform the events into surface forms - names, details, natural language.   This philosophical framework fits remarkably well into the traditional Natural Language Generation Pipeline approach that emphasizes Content Planning .  The pipeline divides generation into three steps: Content Planning, Microplanning and Surface Realization, where at each step input is modified and refined, getting closer to the final textual output. %Abstract concepts get grounded, synonyms are chosen and the actual wording is selected, in order to convey the semantic information present in the input.  Incorporating a plot in order to generate stories can then be viewed as a proxy for  Content Planning/MicroPlanning before a language model makes use of it to convert it to a readable and grammatically correct natural language output .  Inspired by both the Aristotelian and Content Planning Frameworks, we develop a novel system for story generation. We focus on developing a system that can learn to expertly select events, characters, and relevant content, and write good plot structures. After the work on the plot is complete, a large language model can then do what it does best and fill in the descriptions, details, and local specifics of each story.   For plot generation, we employ a few event-choice and event-arrangement rescoring models which assist in building the arc and cohesion of the plot, a character rescoring model that helps select which characters appear where, and a relevance model that is responsible for keeping the plot structure and the story on topic. As both improving plot-generation via rescoring and using an Aristotelian framework for neural generation are novel concepts, there is no previous work on how to implement them in practice.  % \np{may contribution list 1) propose to leverage the principled Aristotelian framework for content planning. 2) propose and implementation of the framework using a revise-based approach with several rescoring models. 3) strong experimental results. } we  propose to leverage the principled Aristotelian framework for content planning, 2) we propose an implementation of the framework using a revision-based approach via several rescoring models 3) we show strong experimental results against 4 baselines.  % Our contributions are: 1) We build a system of rescoring models to enforce Aristotelian principles during the content planning process, 2) We experiment with various different architectures for each rescoring model, and ways to create training examples to encode each Aristotelian concept, and 3) We evaluate our best system against two state-of-the-art story generation systems on our dataset, as well as two ablated versions of itself, and find that our system has improved relevance and overall quality.    %- neither how best to train models that learn to select the correct events, nor to arrange them in the right order. There is similarly no work on how best to teach a model to incorporate character. \\    In this work, we proposed two supervised learning approaches and one adversarial learning method to train the dialogue policy for \acp{TDS} without building user simulators. The proposed methods can achieve state-of-the-art performance suggested by existing approaches based on \acf{RL} and adversarial learning. However, we have demonstrated that our methods require fewer training efforts, namely the domain knowledge needed to design a user simulator and the intractable parameter tuning for \ac{RL} or adversarial learning. Our findings have questioned if the full potential of supervised learning for dialogue \acf{PL} has been exerted and if \ac{RL} methods have been used in the appropriate \ac{TDS} scenarios.   \clearpage  
"," Long-form narrative text generated from large language models manages a fluent impersonation of human writing, but only at the local sentence level, and lacks structure or global cohesion. We posit that many of the problems of story generation can be addressed via high-quality content planning, and present a system that focuses on how to learn good plot structures to guide story generation. We utilize a plot-generation language model along with an ensemble of rescoring models that each implement an aspect of good story-writing as detailed in Aristotle's Poetics. We find that stories written with our more principled plot-structure are both more relevant to a given prompt and higher quality than baselines that do not content plan, or that plan in an unprincipled way.\footnote{Code at \url{https://github.com/PlusLabNLP/story-gen-BART}} %may need to talk about using the plot scaffolding to write stories later more directly - just trying to keep the focus on storyline % also could add a focus on ""long form text"" to differentiate from dialogue systems etc",84
"   % What is neural keyphrase generation in general Keyphrases are phrases that summarize and highlight important information in a piece of text. Keyphrase generation  is the task of automatically predicting such keyphrases given the source text. The task can be  easily misunderstood and trivialized as yet another natural language generation task like summarization and translation, failing to recognize one key aspect that distinguishes KPG: the multiplicity of generation targets; for each input sequence, a KPG system is expected to output multiple keyphrases, each a mini-sequence of multiple word tokens.    % Typically, one source text is associated with multiple keyphrases, % which may either be present in  or absent from the source text. % This property of the task, along with the others, pushes the community to investigate leveraging deep neural networks to handle this task.  % There are quite a few work on KPGen task, people mainly use two popular frameworks: one2one and one2seq % However, in previous literature, the comparison between the two frameworks, the effects of architectural and hyper-parameter choice remain unclear.  % Keyphrase generation is essentially a natural language generation  task. Despite this unique nature, KPG has been essentially ``brute-forced'' into the sequence-to-sequence   framework in the existing literature .%,sun2019divgraphpointer,ye2018kp_semi}.  % Seq2Seq models are encoder-decoder neural networks, where an encoder reads through the source text to form a hidden representation, and a decoder then generates a target sequence  word by word conditioned on the source text representation passed by the encoder. The community has approached the unique challenges with much ingenuity in problem formulation, model design, and evaluation. For example, multiple target phrases have been reformulated by either splitting into one phrase per data point or joining into a single sequence with delimiters , both allowing straightforward applications of existing neural techniques such as Seq2Seq. In accordance with the tremendous success and demonstrated effectiveness of neural approaches, steady progress has been made in the past few years --- at least empirically --- across various domains, including sub-areas where it was previously shown to be rather difficult .  Meanwhile, with the myriad of KPG's unique challenges comes an ever-growing collection of studies that, albeit novel and practical, may quickly proliferate and overwhelm. We are therefore motivated to present this study as --- to the best of our knowledge --- the first systematic investigation on such challenges as well as the effect of interplay among their solutions. We hope this study can serve as a practical guide to help researchers to gain a more holistic view on the task, and to profit from the empirical results of our investigations on a variety of topics in KPG including model design, evaluation, and hyper-parameter selection. %data processing,   % Based on their training paradigms, most keyphrase generation models introduced in prior works fall into two categories, namely \onetoone and \onetoseq . % Models have achieved improved performance on texts of various types, including scientific publications , news articles , and forum postings .  % However, we are unaware of any existing systematic and comprehensive empirical analysis on neural keyphrase generation, particularly on examining effects of the fundamental factors shared in various model designs.      % In this empirical study, we do exhaustive experiments and provide comprehensive analysis. % To facilitate future research in the community and clarifying,  % In this work, we present a comprehensive empirical study of neural keyphrase generation with extensive experiments, aiming to characterize key factors in keyphrase generation models, quantitatively analyze their impacts on model performance, and compare a wide range of baseline variants.  % We hope this study serves as a practical guide to help researchers on architecture, methods, and hyper-parameter selection. % We also hope to provide new insights to the community. % Based on extensive experiments, we provide comprehensive analyses on a number of factors that affect the training and generalization performance of keyphrase generation models. % Thus our contributions are: The rest of the paper is organized as follows. We first enumerate specific challenges in KPG due to the multiplicity of its target, and describe general setups for the experiments. We subsequently present experimental results and discussions to answer three main questions:\\ 1. How well do KPG models generalize to various testing distributions?\\ 2. Does the order of target keyphrases matter while training \onetoseq ?\\ 3. Are larger training data helpful? How to better make use of them?  %      We have shown that Content Planning via an interim plot structure representation can be combined with the use of rescoring models to inject Aristotelian story-writing principles into the plot. We found that this results in stories that are both more relevant and higher quality than stories that are generated directly from prompts or that use plots without Aristotelian rescoring. Our findings also suggest future work on additional ways to incorporate story principles into plot generation. Although our Aristotelian plots improved over the naive plot, there remains gaps in quality between generated and gold plot structures. There is also further work to be done in investigating what models are best able to incorporate plots, which would enable plot improvements to be even more effective.  
"," Recent years have seen a flourishing of neural keyphrase generation  works, including the release of several large-scale datasets and a host of new models to tackle them. Model performance on KPG tasks has increased significantly with evolving deep learning research. % \todo{Among the growing number of neural models competing on this track, we observe that most of them fall into two categories --- \onetoone and \onetoseq --- based on their training paradigms.} % However, there lacks a comprehensive comparison among different model designs, and an investigation on related factors  that may affect a keyphrase generation system's performance. However, there lacks a comprehensive comparison among different model designs, and a thorough investigation on related factors that may affect a KPG system's generalization performance. In this empirical study, we aim to fill this gap by providing extensive experimental results and analyzing the most crucial factors impacting the generalizability of KPG models. We hope this study can help clarify some of the uncertainties surrounding the KPG task and facilitate future research on this topic.",85
" 	 	 	Causal explanation detection  aims to detect whether there is a causal explanation in a given message . Linguistically, there are coherence relations in messages which explain how the meaning of different textual units can combine to jointly build a discourse meaning for the larger unit. The explanation is an important relation of coherence which refers to the textual unit  in a message that expresses explanatory coherent semantics . As shown in Figure , M1 can be divided into three discourses, and D2 is the explanation that expresses the reason why it is advantageous for the equipment to operate at these temperatures. CED is important for tasks that require an understanding of textual expression . For example, for question answering, the answers of questions are most likely to be in a group of sentences that contains causal explanations . Furthermore, the summarization of event descriptions can be improved by selecting causally motivated sentences . Therefore, CED is a problem worthy of further study. 	 	 	 	 	The existing methods mostly regard this task as a classification problem . At present, there are mainly two kinds of methods, feature-based methods and neural-based methods, for similar semantic understanding tasks in discourse granularity, such as opinion sentiment classification and discourse parsing . The feature-based methods can extract the feature of the relation between discourses. However, these methods do not deal well with the implicit instances which lack explicit features. For CED, as shown in Figure , D2 lacks explicit features such as because of, due to, or the features of tenses, which are not friendly for feature-based methods. The methods based on neural network are mainly Tree-LSTM model  and hierarchical Bi-LSTM model . The Tree-LSTM models learn the relations between words to capture the semantics of discourses more accurately but lack further understanding of the semantics between discourses. The hierarchical Bi-LSTM models can employ sequence structure to implicitly learn the relations between words and discourses. However, previous work shows that compared with Tree-LSTM, Bi-LSTM lacks a direct understanding of the dependency relations between words. Therefore, the method of implicit learning of inter-word relations is not prominent in the tasks related to understanding the semantic relations of messages . Therefore, how to directly learn the relations between words effectively and consider discourse-level correlation to further filter the key information is a valuable point worth studying. 	 	Further analysis, why do the relations between words imply the semantics of the message and its discourses? From the view of computational semantics, the meaning of a text is not only the meaning of words but also the relation, order, and aggregation of the words. In other simple words is that the meaning of a text is partially based on its syntactic structure . In detail, in CED, the core and subsidiary words of discourses contain their basic semantics. For example, as D1 shown in Figure , according to the word order in syntactic structure, we can capture the ability of temperature is advantageous. We can understand the basic semantic of D1 which expresses some kind of ability is advantageous via root words advantageous and its affiliated words. Additionally, why the correlation and key information at the discourse level are so important to capture the causal explanatory semantics of the message? Through observation, the different discourse has a different status for the explanatory semantics of a message. For example, in M1, combined with D1, D2 expresses the explanatory semantics of why the ability to work at these temperatures is advantageous, while D3 expresses the semantic of transition. In detail, D1 and D2 are the keys to the explanatory semantics of M1, and if not treated D1, D2, and D3 differently, the transitional semantic of D3 can affect the understanding of the explanatory semantic of M1. Therefore, how to make better use of the information of keywords in the syntactic structure and pay more attention to the discourses that are key to explanatory semantics is a problem to be solved. 	 	To this end, we propose a Pyramid Salient-Aware Networks  which utilizes keywords on the syntactic structure of each discourse and focuses on the key discourses that are critical to explanatory semantics to detect causal explanation of messages. First, what are the keywords in a syntactic structure? From the perspective of syntactic dependency, the root word is the central element that dominates other words, while it is not be dominated by any of the other words, all of which are subordinate to the root word . From that, the root and subsidiary words in the dependency structure are the keywords at the syntax level of each discourse. Specifically, we sample 100 positive sentences from training data to illuminate whether the keywords obtained through the syntactic dependency contain the causal explanatory semantics. And we find that the causal explanatory semantics of more than 80\% sentences be captured by keywords in dependency structure\footnote{Five Ph.D. students majoring in NLP judge whether sentences could be identified as which containing causal explanatory semantics by the root word and its surrounding words in syntactic dependency, and the agreement consistency is 0.8}. Therefore, we extract the root word and its surrounding words on the syntactic dependency of each discourse as its keywords.  	 	Next, we need to consider how to make better use of the information of keywords contained in the syntactic structure. To pay more attention to keywords, the common way is using attention mechanisms to increase the attention weight of them. However, this implicitly learned attention is not very interpretable. Inspired by previous researches , we propose a bottom graph-based word-level salient network which merges the syntactic dependency to capture the salient semantics of discourses contained in their keywords. Finally, how to consider the correlation at the discourse level and pay more attention to the discourses that are key to the explanatory semantics? Inspired by previous work , we propose a top attention-based discourse-level salient network to focus on the key discourses in terms of explanatory semantics. 	 	In summary, the contributions of this paper are as follows:  	 	 	   In this paper we described the development of a novel, holistic methodology for measuring hate speech in a scalable, debiased, explainable manner. Based on prior literature, we theorized eight qualitative levels on a scale ranging from genocidal hate speech to counterspeech and collected empirical observations as examples of each level . We developed a labeling instrument to record ordinal ratings on 10 components of hate speech through a reviewing process. We collected online comments from three major social media platforms  and sampled them in such a way as to focus our labeling on comments more likely to be hate speech or counterspeech, but maintaining generalizability by ensuring that all collected comments had a positive probability of selection in our sampling procedure. We created a crowdsourcing-based labeling procedure to allocate comments to reviewers and yield a network linking all reviewers to each other through overlapping comment reviews, facilitating the estimation of the survey interpretation bias of each reviewer . We fit the faceted Rasch partial credit model to create a sample-invariant scale for hate speech that placed comments, survey instrument items, and raters on the same continuous metric, and adjusted the estimated comment hate speech score for the estimated survey interpretation bias of the raters who happened to rate that comment. The statistical diagnostics from the Rasch model allowed us to evaluate the quality of each reviewer and remove crowdsource workers with low-quality responses. Finally, we applied supervised, multitask, Transformer-based deep learning with rater bias as an auxiliary input  , followed by an IRT nonlinear post-processsing transformation with plausible value sampling, to learn an estimator that maps raw text to the hate speech score in a robust, explainable manner. That deep learning model was encouraged to gain a more general understanding of language through training on data from three separate social media platforms.  Separately, each of these steps represents a novel contribution to the hate speech literature. In combination, we believe our methodology proposes a paradigm shift in the understanding and measurement of hate speech, and in supervised learning of human-labeled data more broadly. We hope that our work will encourage other researchers to adopt Constructing Measures-style theoretical development \& measurement in the study of complex social phenomena, including a transition from dichotomous or ordinal outcomes to continuous, linear scales estimated via Rasch-based item response modeling, corrected for survey interpretation bias of reviewers, and integrated into explainable multitask deep learning architectures. For future updates on our project, data, and models, please visit \href{https://hatespeech.berkeley.edu/}{hatespeech.berkeley.edu}.   
"," 		Causal explanation analysis  can assist us to understand the reasons behind daily events, which has been found very helpful for understanding the coherence of messages. In this paper, we focus on Causal Explanation Detection, an important subtask of causal explanation analysis, which determines whether a causal explanation exists in one message. We design a Pyramid Salient-Aware Network  to detect causal explanations on messages. PSAN can assist in causal explanation detection via capturing the salient semantics of discourses contained in their keywords with a bottom graph-based word-level salient network. Furthermore, PSAN can modify the dominance of discourses via a top attention-based discourse-level salient network to enhance explanatory semantics of messages. The experiments on the commonly used dataset of CEA shows that the PSAN outperforms the state-of-the-art method by 1.8\% F1 value on the Causal Explanation Detection task.",86
"     Event coreference resolution  is a task about determining which event mentions in a document refer to the same real-world event. Event coreference resolution is an important part of NLP systems such as summarization, text-level event extraction, question answering and so on. Besides, compared to considerable research of entity coreference resolution, there is less attention on event coreference resolution. Therefore, event coreference resolution is still a challenging task and the performance should be improved.           Event mentions that refer to the same event can occur both within a document  and across multiple documents . We focus on WD event coreference in this paper because WD event coreference is the basic work of CD event coreference.     The main task of WD event coreference is judging whether a pair of events are coreferential or not.     Figure shows two coreferential event pairs from two documents. The first event pair in D1 is about shooting event and the second event pair in D2 is about fire event.      In order to judge the coreference of a event pair, most approaches for solving event coreference resolution relied on various linguistic properties especially event argument, which contains {spatio-temporal} information of events. For instances, in Figure, the words with red front are events. And the words with blue, green and orange front are participant, time, location of the events respectively.            Although event arguments contain useful information for event coreference resolution, there are two problems for using event arguments information in event coreference resolution. Firstly, it's difficult to extract event arguments accurately due to the diversity of the expression of event arguments. The performance of event argument extraction is only 55.7 in ACE corpus. For instance, in D1, the arguments about shooting event in the two sentences are the same but are expressed differently. In details, in D1, the participant, time, location of shooting event are worker/2 women, 8:30 p.m. and kraft in S1, but the women, Friday evening and building in S2 respectively. Secondly, not every event mention contains all arguments of one event that may make model confused about the coreference of two events in a event pair. For instance, in D2, the Wasilla Bible Church that the location of fire event is in S1 but not in S2. Besides, in D2, devoid of event arguments, burned event and fire event are coreferential in context.      As aforementioned, the arguments of events are difficult to extract. It is also difficult to use arguments to solve all the problems of event coreference resolution even if they are extracted. Thus, the context about event mentions is more important and effective for event coreference resolution. In order to use context information efficiently, we propose a multi-loss neural network model  which doesn't need any argument information to accomplish within-document event coreference resolution task. We propose two sub-models which use context information to detect the coreference of two events in a event pair and train them jointly. One is a classifier which  predicts whether the two events in one pair are coreferential, and another is a scorer which calculates similarity scores between them to assist infer coreference.  	     The final stage about event coreference resolution is event clustering. After all event pairs are predicted and scored, we filter event pairs according to the results of classifier and scorer. Then, we use a dynamic connectivity algorithm to construct a graph for event clustering. Each node in graph is a event mention and each edge between two nodes represent whether the two event are coreferential or not. Finally, all events connected in one graph are considered to be in one event cluster. 	     We evaluate our model on ECB+ corpus and use B, CEAF, MUC and CoNLL  as measures. The experimental results show that our model achieve a significant improvement compared to the state-of-the-art methods which use event argument features.         	In this paper, we devise a pyramid salient-aware network  to detect causal explanations in messages. PSAN can effectively learn the key relation between words at the word level and further filter out the key information at the discourse level in terms of explanatory semantics. Specifically, we propose a bottom word-level salient-aware module to capture the salient semantics of discourses contained in their keywords based on a the syntactic-centric graph. We also propose a top discourse-level salient-aware module to modify the dominance of different discourses in terms of global explanatory semantic constraint via an attention mechanism. Experimental results on the open-accessed commonly used datasets show that our model achieves the best performance. 	 	
","Event coreference resolution is an important task in Natural Language Processing  and nearly all the existing approaches to this task  rely on event argument information. However, these methods tend to suffer from error propagation from the stage of event argument extraction. Besides, not every event mention contains all arguments of an event and argument information may confuse the model that events have arguments to detect event coreference in real text. Furthermore, the context information of an event is useful to infer coreference between events. Thus, in order to reduce the errors propagated from event argument extraction and use context information effectively, we propose a multi-loss neural network model which does not need any argument information to do the within-document event coreference resolution task and achieve a significant performance than the state-of-the-art methods.",87
" A task-oriented spoken dialogue system usually consists of three modules: input,output and control, shown in Fig.. The input module which consists of automatic speech recognition  and spoken language understanding  extracts semantic-level user dialogue actions from user speech signal. The control module  has two missions. One is to maintain dialogue state, an encoding of the machine's understanding about the conversation. Once the information from the input module is received, the dialogue state is updated by dialogue state tracking . The other is to choose a semantic-level machine dialogue action to response the user, which is called dialogue decision policy.    The output consists of natural language generation  and text-to-speech  synthesis, which convert dialogue action to audio. Dialogue management is an important part of a dialogue system. Nevertheless, there are inevitable ASR and SLU errors which make it hard to track true dialogue state and make decision. In recent statistical dialogue system, the distribution of dialogue state, i.e. belief state, is tracked. A well-founded theory for belief tracking and decision making is offered by partially observable Markov Decision Process  framework.  Previous DST algorithms can be divided into three families: hand-crafted rules, generative models, and discriminative models. Recently, since the Dialog State Tracking Challenges  have provided labelled dialog state tracking data and a common evaluation framework and test-bed, a variety of machine learning methods for DST have been proposed. These methods rely strictly on set of labelled off-line data. Since the labelled data are off-line, the learning process of these supervised learning methods is independent on the dialogue policy module. The key issues of these supervised learning methods are poor generalization and over-tuning. Due to the lack of labels, these approaches can not be easily used for on-line update of DST.   This work marks first step towards employing the deep reinforcement learning  method into dialogue state tracking  module. The performance of the DST module is optimized during the conversation between the user and the dialogue system. We call the DRL-based DST module as the tracking agent. In order to bound the search space of the tracking agent, we propose a companion teaching framework . Furthermore, under this framework, we can train tracking agent and dialogue policy agent jointly with respective deep reinforcement learning  algorithms in order to make these two agents adaptive to each other. % And there are two main types of DST systems in the current dialogue system. One is the semantic-based dialogue state tracking system, and the other is the text-based dialogue state tracking system that implicitly or explicitly removes spoken language understanding  module. In this paper, we explain the proposed tracking agent framework based on the semantic-based dialogue state tracking  system.  The paper has two main contributions:   The rest of the paper is organized as follows. Section  gives an overview of related work. In Section , the framework of on-line DST are presented. The implementation detail is represented in Section . In Section , the joint training process is introduced. Section  presents experiments conducted to evaluate the proposed framework, followed by the conclusion in Section .        We present a multi-layer feed-forward neural network for event mention extraction and a multi-loss neural network model for within-document event coreference resolution respectively. We do not use any information about event argument in our system. Additionally, we test our system in ECB+ corpus and achieve a significant improvement than the state-of-the-art methods.      Due to the incomplete annotation and the propagation of errors about event mentions and arguments extraction in pipeline systems, we will try to design a joint model to accomplish the event extraction, argument extraction, event coreference resolution tasks jointly in the future.                                                                               Acknowledgements. 閿熸枻鎷疯阿                                                                 \Acknowledgements{This work is supported by the Natural Science Foundation of China . This work was also supported by Alibaba Group through Alibaba Innovative Research  Program and Huawei Tech. Ltm through Huawei Innovation Research Program.).}                                                                               Supplements. 閿熸枻鎷烽敓鏂ゆ嫹閿熸枻鎷烽敓, 閿熻鎲嬫嫹閫                                                                  \Supplements{Appendix A.}                                                                          Reference section. 閿熻娇鍖℃嫹閿熸枻鎷烽敓鏂ゆ嫹         citation in the content using ""some words"".         ~ is needed to make the reference number is on the same line with the word before it.                                                                                                                                                       Appendix sections. 閿熸枻鎷峰綍閿熼摪鏂ゆ嫹, 閿熻鎲嬫嫹閫                                                                  \begin{appendix}      
"," Dialogue state tracking  is a crucial module in dialogue management. It is usually cast as a supervised training problem, which is not convenient for on-line optimization. In this paper, a novel companion teaching based deep reinforcement learning  framework for on-line DST optimization is proposed. To the best of our knowledge, this is the first effort to optimize the DST module within DRL framework for on-line task-oriented spoken dialogue systems. In addition, dialogue policy can be further jointly updated. Experiments show that on-line DST optimization can effectively improve the dialogue manager performance while keeping the flexibility of using predefined policy. Joint training of both DST and policy can further improve the performance.",88
"   {T}{he} task-oriented spoken dialogue system  aims to assist a human user in accomplishing a specific task . The dialogue management is a core part of SDS. There are two main missions in dialogue management: dialogue belief state tracking  and dialogue decision-making . In this work, we only focus on devising a policy that chooses which dialogue action to respond to the user.   The sequential system decision-making process can be abstracted into a partially observable Markov decision process . Under this framework, reinforcement learning approaches can be used for automated policy optimization.   In the past few years, there are many deep reinforcement learning  algorithms閿 which use neural networks  as function approximators, investigated for dialogue policy .  Most of these approaches focus on dialogue policy optimization in a single dialogue task. However, in real-life scenarios, a dialogue agent can be asked by many users for different dialogue tasks, e.g., Apple Siri can support many dialogue tasks .  In the multi-task setup, the traditional DRL-based approaches have to train an individual policy for each dialogue task.  It means that each dialogue policy has its independent model parameters, whose scale will increase proportionally with the number of the tasks. One solution is to train a generic policy for all dialogue tasks . However, there are two obstacles to do this with traditional DRL-based approaches.   In this paper, we propose  the Structured Actor-Critic  Reinforcement Learning for Universal Dialogue Management   to address the above two problems. It can use data collected from different dialogue tasks to train a generic policy. To tackle the scalability problem, we utilize the recently proposed structured dialogue policy , where the dialogue policy is represented by a graph neural network . With the scalability of the GNN , a single set of parameters can be used for different dialogue tasks. That makes it possible to train a generic policy among multiple dialogue tasks. To tackle the efficiency problem, we deploy an advanced off-policy actor-critic algorithm, which combines decoupled acting and learning with a novel off-policy correction method called V-trace. Combining the improved optimization algorithm with the structured dialogue policy, we can make the generic policy learning process more stable and efficient than the original GNN-based dialogue policy .  We evaluate the performance of STRAC on PyDial benchmark, which includes six environments and three dialogue domains. Results show that our unified dialogue agent STRAC gets the best performance on most of the 18 tasks of the benchmark.     This paper provides a DRL-based companion teaching framework to optimize the DST module of the dialogue system. Under this framework, the tracker can be learned during the conversations between the user and the SDS rather than produced by the off-line methods. We can also choose to jointly train dialogue policy agent and the tracking agent under this framework. The experiments showed that the proposed companion teaching framework for the on-line DST system achieved promising performances in DSTC2 and DSTC3.     
"," Traditional dialogue policy needs to be trained independently for each dialogue task. In this work, we aim to solve a collection of independent dialogue tasks using a unified dialogue agent. The unified policy is parallelly trained using the conversation data from all of the distributed dialogue tasks. However, there are two key challenges: the design of a unified dialogue model to adapt to different dialogue tasks;  finding a robust reinforcement learning method to keep the efficiency and the stability of the training process. Here we propose a novel structured actor-critic approach to implement structured deep reinforcement learning , which not only can learn parallelly from data of different dialogue tasks\footnote{In the experimental setup of this work, each dialogue task has only one dialogue domain.} but also achieves stable and sample-efficient learning. We demonstrate the effectiveness of the proposed approach on 18 tasks of PyDial benchmark. The results show that our method is able to achieve state-of-the-art performance.",89
"  %When building a dialogue system, complex tasks that require more information exchange are often more challenging. One example is to handle the restaurant reservation consultation in multiple areas during a single conversation. Specifically, this type of task that needs to complete some subtasks  in order to finish the conversation is called the composite task.  Composite tasks are different from multi-domain dialogue tasks. The latter is often mentioned in papers that focusing on transfer learning. In most case, multi-domain dialogue tasks involve only one domain in a single dialogue, and the performance of this one domain model is tested on different domains in order to highlight its transferability. On the contrary, composite dialogue tasks may involve multiple domains in a single dialogue, and the agent must complete all subtasks  in order to get positive feedback.  Consider the process of completing a composite task . An agent first chooses a subtask , then make a sequence of decisions to gather related information  until all information required by users are provided and these subtasks are completed, and then choose the next subtask  to complete. The state-action space will increase with the number of subtasks. Thus, dialogue policy learning for the composite task needs more exploration, and it needs to take more dialogue turn between agent and user to complete a composite task. The sparse reward problem is further magnified.   Solving composite tasks using the same method as the one solving single domain tasks may hit obstacles. The complexity of the composite task makes it hard for an agent to learn an acceptable strategy. While hierarchical deep reinforcement learning  shows its promising power, by introducing the framework of options over Markov Decision Process , the original task can be decomposed into two parts: deciding which subtask to solve and how to solve one subtask, thus simplifying the problem.  However, in previous works, multi-layer perceptrons  are often used in DQN to estimate the Q-value. MLPs use the concatenation of the flatten dialogue state as its inputs. In this way, it cannot capture the structural information of the semantic slots in that state easily, which results in low sampling efficiency. In our work, we propose ComNet, which makes use of the Graph Neural Network  to better leverage the graph structure in the observations  and being coherent with the HDRL method.  Our main contributions are three-fold: 1. We propose a new framework ComNet combining HDRL and GNN to solve the composite tasks while achieving sample efficiency. 2. We test ComNet based on PyDial  benchmark and show that our result over-performed the vanilla HDRL systems and is more robust to noise in the environment. 3. We test the transferability of our framework and prove that under our framework, an efficient and accurate transfer is possible.     This paper proposed a scalable distributed dialogue policy STRAC to train a generic dialogue policy on all available data collected from different dialogue tasks. STRAC increased scalability, stability and efficiency of the NN-based policy through combining structured dialogue policy and effective off-policy actor-critic algorithm. Compared with the traditional approaches, STRAC-M can be trained parallel on multiple tasks and gets the better performance, especially in the data-limited situation. Compared with another GNN-based policy optimization approach FM-GNN, the training process of STRAC is more stable and efficient. The final gains are more considerable in more complex environments. Compared with recent proposed generic policy DQNDIP-M, STRAC-M not only can be trained using the data from all the available dialogue tasks but also can model the relations among all the sub-agents. In future work, we will test STRAC with real users instead of the agenda-based user simulator.                 if have a single appendix:  [Proof of the Zonklar Equations]   or      for no appendix heading   do not use 
"," Dialogue policy training for composite tasks, such as restaurant reservation in multiple places, is a practically important and challenging problem. Recently, hierarchical deep reinforcement learning  methods have achieved good performance in composite tasks. However, in vanilla HDRL, both top-level and low-level policies are all represented by multi-layer perceptrons  which take the concatenation of all observations from the environment as the input for predicting actions. Thus, traditional HDRL approach often suffers from low sampling efficiency and poor transferability. In this paper, we address these problems by utilizing the flexibility of graph neural networks . A novel ComNet is proposed to model the structure of a hierarchical agent. The performance of ComNet is tested on composited tasks of the PyDial benchmark. Experiments show that ComNet outperforms vanilla HDRL systems with performance close to the upper bound. It not only achieves sample efficiency but also is more robust to noise while maintaining the transferability to other composite tasks.",90
"  Relation extraction  aims to identify the semantic relations between named entities in text. While previous work  focuses on extracting relations within a sentence, a.k.a.~sentence-level RE, recent studies  have escalated it to the document level, since a large amount of relations between entities usually span across multiple sentences in the real world. According to an analysis on Wikipedia corpus , at least 40.7\% of relations can only be extracted on the document level.  Compared with sentence-level RE, document-level RE requires more complex reasoning, such as logical reasoning, coreference reasoning and common-sense reasoning. A document often contains many entities, and some entities have multiple mentions under the same phrase of alias. To identify the relations between entities appearing in different sentences, document-level RE models must be capable of modeling the complex interactions between multiple entities and synthesizing the context information of multiple mentions.   Figure shows an example of document-level RE. Assume that one wants to extract the relation between ``Surfers Riverwalk"" in S11 and ``Queensland"" in S1. One has to find that ``Surfers Riverwalk"" contains ``Pacific Fair"" , and  ``Pacific Fair""  is located in ``Queensland"" . This chain of interactions helps infer the inter-sentential relation ``located in"" between ``Surfers Riverwalk"" and ``Queensland"".    %====================   In this paper, we propose ComNet, which is a structured hierarchical dialogue policy represented by two graph neural networks . By replacing MLPs in the traditional HDRL methods, ComNet makes better use of the structural information of dialogue state by separately feeding observations  and the top-level decision into slot-dependent, slot-independent and subtask nodes and exchange message between these nodes. We evaluate our framework on modified PyDial benchmark and show high efficiency, robustness and transferability in all settings.    
"," Relation extraction  aims to identify the semantic relations between named entities in text. Recent years have witnessed it raised to the document level, which requires complex reasoning with entities and mentions throughout an entire document. In this paper, we propose a novel model to document-level RE, by encoding the document information in terms of entity global and local representations as well as context relation representations. Entity global representations model the semantic information of all entities in the document, entity local representations aggregate the contextual information of multiple mentions of specific entities, and context relation representations encode the topic information of other relations. Experimental results demonstrate that our model achieves superior performance on two public datasets for document-level RE. It is particularly effective in extracting relations between entities of long distance and having multiple mentions.",91
"  Dialogue state tracker is a core part of the task-oriented dialogue system, which records the dialogue state. The dialogue state consists of a set of domain-slot-value triples, where the specific value represents the user goal, e.g., . The dialogue system responds to the user just based on the dialogue state. Thus, in order to make the dialogue process natural and fluent, it is essential to extract the dialogue state from the dialogue context accurately. However, the paucity of annotated data is the main challenge in this field. In this work, we solve a key problem that how to learn from the unlabeled data in DST task. We design a dual learning framework for DST task, where the dialogue state tracker is the primal agent and the dual agent is the utterance generator. Within the dual learning framework, these two primal-dual agents help to update each other through external reward signals and reconstruction errors by using unlabeled data. It only needs a few of labeled dialogue data to warm up these two primal-dual agents.  However, there are two main challenges when combining dual learning framework with previous dialogue state tracking  methods:  How to represent dialogue state under dual learning framework? Dual learning method is first proposed in the neural machine translation  task. The outputs of the primal-dual agents in NMT task are both sequential natural languages. However, in DST task, the output of the dialogue state tracker consists of isolated domain-slot-value triples. The traditional DST task is formulated as a classification problem with the given ontology, where all the possible values of the corresponding slot are listed. Under this problem definition, the previous classification methods just choose the right value for each slot. The recent innovated tracker TRADE directly generates the values slot by slot using copy mechanism from dialogue context. However, these tracker methods get slot values independently. During the dual learning loop, it is hard to get reward signal from these independent slot values. The reward signal from dual utterance generator is also hard to allocate to these isolated value generation processes. Since the relations of the predicted values are not modeled and they are assumed to be independent with each other, it would face serious reward sparse problem. In this work, we reformulate the dialogue state tracking task as a sequential generation task. The whole dialogue state is represented by a sequence with structured information. For example, the state  can be represented as ``\textless\textgreater  \textless\textgreater  \textless\textgreater   \textless\textgreater  \textless\textgreater  \textless\textgreater  \textless\textgreater''.    Is it reasonable that generating the whole dialogue context from dialogue state? The intuitive dual task of the state tracker is dialogue context generation. However, in MultiWOZ 2.1 dataset, the dialogue context has more than 10 turns on average and the average length of each sentence is over 10 tokens. It is very difficult in generating accurately a dialogue context with a dialogue state. Because the dialogue context is too long, it is hard to guarantee that the generated dialogue context contains the same semantics with the given state. In this work, we simplify the dual task into a user utterance generation task which ignores the specific values of the given state. The input of the dual task is composed of two parts , and its output is the delexicalized user utterance. The delexicalized script is copied from the released code \footnote{https://github.com/ConvLab/ConvLab}. The system utterance and user utterance can be lexicalized respectively according to the given turn state. We get a new pseudo-labeled dialogue turn. In order to produce multi-turn pseudo-labeled data, we sample a labeled dialogue data and combine it with the pseudo-labeled dialogue turn, where the dialogue turn directly adds to the end of the sampled dialogue context and the turn state covers into the label of the sampled state. Finally, we get a new dialogue context and pseudo label of the state, as the intuitive dual-task does.  The main contributions of this paper are summarized as follows:       In this paper, we proposed GLRE, a global-to-local neural network for document-level RE. Entity global representations model the semantic information of an entire document with R-GCN, and entity local representations aggregate the contextual information of mentions selectively using multi-head attention. Moreover, context relation representations encode the topic information of other relations using self-attention. Our experiments demonstrated the superiority of GLRE over many comparative models, especially the big leads in extracting relations between entities of long distance and with multiple mentions. In future work, we plan to integrate knowledge graphs and explore other document graph modeling ways  to improve the performance.\\  Acknowledgments. This work is supported partially by the National Key R\&D Program of China , the National Natural Science Foundation of China , and the Water Resource Science \& Technology Project of Jiangsu Province .     The next two lines define the bibliography style to be used, and the bibliography file.         
"," In task-oriented multi-turn dialogue systems, dialogue state refers to a compact representation of the user goal in the context of dialogue history. Dialogue state tracking  is to estimate the dialogue state at each turn. Due to the dependency on complicated dialogue history contexts, DST data annotation is more expensive than single-sentence language understanding, which makes the task more challenging. In this work, we formulate DST as a sequence generation problem and propose a novel dual-learning framework to make full use of unlabeled data. In the dual-learning framework, there are two agents: the primal tracker agent  and the dual utterance generator agent . Compared with traditional supervised learning framework, dual learning can iteratively update both agents through the reconstruction error and reward signal respectively without labeled data. Reward sparsity problem is hard to solve in previous DST methods. In this work, the reformulation of DST as a sequence generation model effectively alleviates this problem. We call this primal tracker agent dual-DST. Experimental results on MultiWOZ2.1 dataset show that the proposed dual-DST works very well, especially when labelled data is limited. It achieves comparable performance to the system where labeled data is fully used.",92
"  % P1 intro {T}{ask-oriented} dialog system aims for users to achieve goals such as finding attractions or booking restaurants. Developing such a system typically requires the following dialog components to construct a pipeline as illustrated in \fig : natural language understanding  to extract user's intents and slot-values , dialog state tracking  to update belief states , querying database, dialog policy  to decide the system's next action , and natural language generation  to generate system responses . Although recent advances in neural approaches in the natural language domain have greatly improved the performance of individual dialog components, errors in each component are accumulated in the pipelined system, resulting in degradation of overall performance. Therefore, designing an effective architecture and optimizing the entire dialog system in an end-to-end fashion are still challenging.  % P2 % e2e Recently, several end-to-end  neural dialog systems have proposed . % Modularized % seq2seq Sequence-to-sequence approaches directly generate system responses given user utterance inputs, but they have limitations that querying the external database is unavailable , and system actions are not interpretable . % RL in e2e Moreover, a few previous researchers have investigated dialog policy optimization by reinforcement learning in end-to-end neural task-oriented dialog systems .  % GPT-2 Meanwhile, recent approaches that transfer general linguistic knowledge from large pre-trained language model, GPT-2 , to goal-oriented dialog have shown remarkable improvements . They employed the GPT-2 backbone as it is, and fine-tuned the model to auto-regressively generate dialog states, system actions, and responses in a sequence. Although leveraging the rich knowledge allows the models to generate more natural and appropriate responses, reinforcement learning on transformer-based architectures has been reported as unstable , and learning dialog policy on those models has not been explored yet.  % P4 our approaches    In this paper, we present an end-to-end trainable neural dialog system with reinforcement learning for multi-domain task-completion tasks, SUMBT+LaRL, which consists of two components:  an extended version of SUMBT for a word-level dialog state tracker and  LaRL for a word-level policy model.  In addition to SUMBT that updates belief states employing the slot-utterance matching mechanism, SUMBT+ predicts domains and user-intents from the user utterance.  Then given the predictions by SUMBT+, the LaRL models a categorical latent system action spaces and generates system responses. In our training framework, we emphasize the importance of separately pre-train SUMBT+ and LaRL and fine-tune the entire model in an end-to-end fashion. Then, the trained dialog policy is further optimized by off-line reinforcement learning using REINFORCE algorithm to succeed dialog tasks. During reinforcement training, the policy gradients at latent actions decouple the discourse-level decision making and language generation by the decoder, enabling stable and effective reinforcement learning. We further propose new success  criteria in which the system has to respond to more requestable slots and calculate the match performance using the belief state estimated by SUMBT+.  We demonstrated the efficacy of the proposed system on MultiWOZ2.0, implementing on ConvLab platform for user simulator-based evaluations. Our extensive experimental results on both corpus and simulator-based evaluation shows the effectiveness of the proposed pretraining and end-to-end fine-tuning framework as well as reinforcement learning on the latent action space. From the results and qualitative analysis of simulated dialog examples, we also present the discrepancy problem of corpus and automatic evaluations, the limitations of off-line reinforcement learning for dialog systems, and the needs of advanced reward design and success criteria. Our model achieved the new state-of-the-art success rate in the end-to-end corpus-based evaluation on the MultiWOZ2.0, as well as outperformed the challenge winner of the 8th dialog system technology challenge  challenge in the simulator-based evaluation.  % P5 contribution summary In summary, the main contributions of this paper are three-fold:    % section intro   \sect 2 briefly reviews end-to-end multi-domain task-completion dialog systems and the DSTC8 Challenge. \sect 3 explains the detailed architecture of the proposed SUMBT+LaRL and training procedures. Related work is described in \sect 4 and experimental results are presented in \sect 5.  %\newpage %\clearpage   In this work, we first reformulate the dialogue state tracking task as a sequence generation task. Then we adopt a coarse-to-fine decoding method to directly generate the structured state sequence. The proposed coarse-to-fine tracker achieves the best performance among BERT-free methods. The main contribution of this work lies on building a dual learning framework for multi-domain DST task. The experimental results indicate that our proposed dual learning method can efficiently improve the pretrained tracker with unlabeled data. In future work, we will further improve the state tracking model and dual utterance generation model using pretrained models, e.g. BERT.             ijcai20.tex  \typeout{IJCAI--PRICAI--20 Instructions for Authors}    These are the instructions for authors for IJCAI-20.  \documentclass{article} \pdfpagewidth=8.5in \pdfpageheight=11in   The file ijcai20.sty is NOT the same than previous years' \usepackage{ijcai20}    Use the postscript times font! \usepackage{times} \usepackage{soul} \usepackage{url}   \usepackage[hidelinks]{hyperref} \usepackage[utf8]{inputenc} \usepackage[small]{caption} \usepackage{graphicx} \usepackage{amsmath} \usepackage{amsthm} \usepackage{booktabs} \usepackage{algorithm} \usepackage{algorithmic} \urlstyle{same} \usepackage[bookmarks=false]{hyperref}    the following package is optional:  \usepackage{latexsym}     See https://www.overleaf.com/learn/latex/theorems_and_proofs   for a nice explanation of how to define new theorems, but keep   in mind that the amsthm package is already included in this   template and that you must *not* alter the styling. \newtheorem{example}{Example} \newtheorem{theorem}{Theorem}    Following comment is from ijcai97-submit.tex:   The preparation of these files was supported by Schlumberger Palo Alto   Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.   Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.   Patel-Schneider, of AT\&T Bell Laboratories collaborated on their   preparation.    These instructions can be modified and used in other conferences as long   as credit to the authors and supporting agencies is retained, this notice   is not changed, and further modification or reuse is not restricted.   Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as   contacts for providing assistance without their prior permission.    To use for other conferences, change references to files and the   conference appropriate and use other authors, contacts, publishers, and   organizations.   Also change the deadline and address for returning papers and the length and   page charge instructions.   Put where the files are available in the appropriate places.  \title{IJCAI--PRICAI--20 Formatting Instructions}    Single author syntax \author{     Christian Bessiere     \affiliations     CNRS, University of Montpellier, France     \emails     pcchair@ijcai20.org }    Multiple author syntax    Check the ijcai20-multiauthor.tex file for detailed instructions \iffalse \author{ First Author \and Second Author\and Third Author\And Fourth Author \affiliations First Affiliation\\ Second Affiliation\\ Third Affiliation\\ Fourth Affiliation \emails \{first, second\}@example.com, third@other.example.com, fourth@example.com } \fi    
"," The recent advent of neural approaches for developing each dialog component in task-oriented dialog systems has remarkably improved, yet optimizing the overall system performance remains a challenge. In this paper, we propose an end-to-end trainable neural dialog system with reinforcement learning, named SUMBT+LaRL. The SUMBT+ estimates user-acts as well as dialog belief states, and the LaRL models latent system action spaces and generates responses given the estimated contexts. We experimentally demonstrate that the training framework in which the SUMBT+ and LaRL are separately pretrained and then the entire system is fine-tuned significantly increases dialog success rates. We propose new success criteria for reinforcement learning to the end-to-end dialog system as well as provide experimental analysis on a different result aspect depending on the success criteria and evaluation methods. Consequently, our model achieved the new state-of-the-art success rate of 85.4\% on corpus-based evaluation, and a comparable success rate of 81.40\% on simulator-based evaluation provided by the DSTC8 challenge.  %The recent advent of neural approaches for developing each dialog component in task-oriented dialog systems has remarkably improved, yet optimizing the overall system performance remains a challenge. In this paper, we propose an end-to-end trainable neural dialog system with reinforcement learning, named SUMBT+LaRL. The SUMBT+ estimates user-acts as well as dialog belief states, and the LaRL models latent system action spaces and generates responses given the estimated contexts. We experimentally demonstrate that the training framework in which the SUMBT+ and LaRL are separately pretrained and then the entire system is fine-tuned significantly increases dialog success rates. We propose new success criteria for reinforcement learning to the end-to-end dialog system as well as provide experimental analysis on a different result aspect depending on the success criteria and evaluation methods. Consequently, our model achieved the new state-of-the-art success rate of 85.4% on corpus-based evaluation, and a comparable success rate of 81.40% on simulator-based evaluation provided by the DSTC8 challenge.",93
"   The massive rise in user-generated web content, alongside with the freedom of speech in social media and anonymity of the users has brought about an increase in online offensive content and anti-social behavior. The consequences of such behavior on genuine users of the social media have become a serious concern for researchers in Natural Language Processing and related fields in recent years.  The shared task number 6 at SemEval 2019, OffensEval , proposes to model the task of offensive language identification hierarchically, which means identifying the offensive content, whether it is targeted, and if so, the target of the offense. In OffensEval, offensive language is defined as ``any form of non-acceptable language  or a targeted offense, which can be veiled or direct'' which includes ``insults, threats, and posts containing profane language or swear words'' .  We have participated in the first two subtasks  of OffensEval with the proposed approach of a deep model consisting of a Recurrent Neural Network  for word-level and Convolutional Neural Network  for character-level processing. Character-level processing is beneficial, as offensive comments are likely to follow unorthodox writing styles, contain obfuscated words, or have irregular word separation which leads to tokenization issues . We also experimented with two other methods, a Support Vector Machine  with TFIDF and count features and another SVM with BERT  -encoded sentences as input, both with lower performances comparing with the deep model.  After overviewing the related work in section , we discuss the methodology and the data in details in section , and the results in section . In section , we analyze the results and conclude the paper in section .     In this paper, we propose an end-to-end trainable task-oriented dialog system with reinforcement learning that consists of SUMBT+ and LaRL. The SUMBT+ estimates user-acts as well as dialog belief states, and the LaRL models latent system action spaces and generates responses given the estimated contexts. We experimentally demonstrated that the training framework in which the SUMBT+ and LaRL are pretrained, then the entire system is fine-tuned significantly increases dialog success rates. Besides, the end-to-end fine-tuning showed that the supervisions from the next system response also encourages to improve dialog state tracking, achieving the performance comparable to the state-of-the-art joint accuracy. We further trained the model with REINFORCE using the reward levels and success criteria we designed. Using the estimated belief states to assess the reward level 1 attained the best success rates in the end-to-end corpus evaluation, whereas the oracle belief states and reward level 2 achieved the highest in the automatic evaluations. The experiment results and the qualitative analysis of simulated dialog examples present the discrepancy problem of corpus and automatic evaluations, the limitations of off-line reinforcement learning for dialog policy, and the needs of advanced reward design and success criteria. Our model achieved the new state-of-the-art success rate of 85.4\  in end-to-end corpus-based evaluation on MultiWOZ corpus, as well as outperformed the challenge winner of the DSTC8 Track 1 challenge by showing 81.4\   in the simulator-based evaluation.    if have a single appendix:  [Proof of the Zonklar Equations]   or      for no appendix heading   do not use 
"," This paper presents the models submitted by Ghmerti team for subtasks A and B of the OffensEval shared task at SemEval 2019. OffensEval addresses the problem of identifying and categorizing offensive language in social media in three subtasks; whether or not a content is offensive , whether it is targeted  towards an individual, a group, or other entities . The proposed approach includes character-level Convolutional Neural Network, word-level Recurrent Neural Network, and some preprocessing. The performance achieved by the proposed model for subtask A is 77.93\% macro-averaged F\textsubscript{1}-score.",94
"  A wide range of Natural Language Processing  tasks, such as Machine Translation , speech recognition, information retrieval, data mining, and creating text resources for low-resource languages benefit from the upstream task of language identification. The Cuneiform Language Identification  task in VarDial 2019  tries to address the problem of identifying languages and dialects of the texts written in cuneiform symbols.   Identifying languages and dialects of the cuneiform texts is a difficult task, since such languages lack resources and also there is the problem of tokenization. Although there are some work addressing the problem of tokenization in some of these languages or dialects, there is not any universal method or tool available for tokenization of cuneiform texts, as such a task depends on the rules of that language, simply because cuneiform writing system is a syllabic as well as a logographic one.  As a result, all the endeavors in this paper are based on character-level features. This work investigates different machine learning methods which are proven to be effective in text classification and compares them by their obtained F\textsubscript{1}-score, accuracy, and training time.  In this paper, we first review the literature of language identification and the work on languages written using cuneiform writing system in , introduce the models used to tackle the problem of identifying such languages and dialects in , describe the training data in , and discuss the results in .  % You can begin with a brief description of the task and an overview of your approach.   % We would like to ensure that future readers of your paper can find the relevant task description, data and results. So, we ask that you cite the shared task report paper  in your introduction.      In this paper, we introduced Ghmerti team's approach to the problems of `offensive language identification' and `automatic categorization of offense type' in shared task 6 of SemEval 2019, OffensEval. In subtask A, the neural network-based model outperformed the other methods, including an SVM with word TFIDF and character count features and another SVM with BERT-encoded tweets as input. Furthermore, analysis of the results indicates that sarcastic language, inability to discern the emotions such as anger, and ethnic and racial slurs constitute a considerable portion of the errors. Such deficiencies demand larger training corpora and variety of other features, such as information on sarcasm, emotion, personality, etc.    
"," Identification of the languages written using cuneiform symbols is a difficult task due to the lack of resources and the problem of tokenization. The Cuneiform Language Identification task in VarDial 2019 addresses the problem of identifying seven languages and dialects written in cuneiform; Sumerian and six dialects of Akkadian language: Old Babylonian, Middle Babylonian Peripheral, Standard Babylonian, Neo-Babylonian, Late Babylonian, and Neo-Assyrian. This paper describes the approaches taken by  \tt{SharifCL} \normalfont team to this problem in VarDial 2019. The best result belongs to an ensemble of Support Vector Machines and a naive Bayes classifier, both working on character-level features, with macro-averaged F\textsubscript{1}-score of 72.10\%.",95
"    In recent years, there has been a growing interest in hierarchical multi-label classification  which can be applied in a wide range of applications such as International Patent Classification , product annotation  and advertising recommendation . In the common flat classification problem, each input sample is only associated with a single label from a set of disjoint labels. However, in HMC problem, the labels are organized in the form of a tree or a Directed Acyclic Graph  and each input sample is usually associated with multiple labels, which made it more challenging.  The most straight-forward approach in dealing with HMC problem is to convert it to a flat multi-label classification problem by simply ignoring the relevance between labels . The main disadvantage in doing so is the loss of the useful hierarchical information. Alternatively, the local approach  is designed to perform multi-label classification, where the classifications are carried out at each level of the label hierarchy . The overall classification results are then generated based on these local predictions. While hierarchical information can be better utilized in local approaches,  misclassifications are easily propagated to the next levels . Global approaches are proposed to learn a single global model for all labels to reduce the model size and consider the entire label hierarchy at once . These global classifiers are typically built on flat classifiers with modifications made to integrate the hierarchical information of labels  into the model. Recently, more algorithms which combine the local and global approaches are proposed .  All algorithms introduced above only focus on the design of hierarchical classifier while ignoring the hierarchical features which may be extracted and they are important in HMC as well. \citet{HARNN'2019} and \citet{rojas2020efficient} consider hierarchical feature extraction in their work. However, the extraction process is designed and fulfilled by applying the typical attention mechanism over the whole text. Since in HMC problem the text may be associated with multiple labels at each hierarchy level, the features extracted from typical attention may be diluted.  We believe it is reasonable to hypothesize that a label-based attention, where information extraction is performed based on different labels at different hierarchical levels, would allow the model to be more interpretable and have an overall better performance in accuracy. Given the above motivations, we propose LA-HCN --- a HMTC model with a label-based attention to facilitate label-based hierarchical feature extraction, where we introduce the concept and mechanism of component which is an intermediate representation that helps bridge the latent association between the words and the labels for label-based attention.    \paragraph{Contribution} Main contributions of this work:     In this paper, we investigated different machine learning methods, such as SVM and neural networks, and compared their performance in the task of language and dialect identification of cuneiform texts. The best performance was achieved by a combination of SVM and naive Bayes, using only character-level features. It was shown that characters are enough to obtain at least 72.10\  F\textsubscript{1}-score. However, the best model was not able to achieve a good result classifying some of the dialects which indicates a need for other kinds of features, such as word-level ones, and/or embedded or transferred knowledge of these languages and dialects to be used in training the deep models.    Here you conclude your paper. The readers are interested not only in your system performance but also in what could be learned with your submission.\\    You can also include ideas for future work.   
"," Hierarchical multi-label text classification  has been gaining popularity in recent years thanks to its applicability to a plethora of real-world applications. The existing HMTC algorithms largely focus on the design of classifiers, such as the local, global, or a combination of them. However, very few studies have focused on hierarchical feature extraction and explore the association between the hierarchical labels and the text. In this paper, we propose a Label-based Attention for Hierarchical Mutlti-label Text Classification Neural Network  , where the novel label-based attention module is designed to hierarchically extract important information from the text based on the labels from different hierarchy levels. Besides, hierarchical information is shared across levels while preserving the hierarchical label-based information. Separate local and global document embeddings are obtained and used to facilitate the respective local and global classifications. In our experiments, LA-HCN outperforms other state-of-the-art neural network-based HMTC algorithms on four public HMTC datasets. The ablation study also demonstrates the effectiveness of the proposed label-based attention module as well as the novel local and global embeddings and classifications. By visualizing the learned attention , we find that LA-HCN is able to extract meaningful information corresponding to the different labels which provides explainability that may be helpful for the human analyst.",96
"  Multi-task learning is the problem of minimizing the average error across  tasks, as measured on held-out samples, and motivated by the observation that sometimes learning a single model with partially shared parameters performs better than  single-task models. In the learning-to-learn setting, we worry about our error on a task . Both of these settings apply to randomly initialized base learners, as well as architectures pre-trained on yet another task. In learning-to-learn, the new task  is assumed to come from an ambiguity set defined by the  tasks.  Unsurprisingly, most approaches to multi-task learning minimize the average loss across the training samples available for these tasks. This does not always lead to the best solution, however, since the relations between loss and error may differ across tasks. Several off- and online methods for normalizing these relations have been proposed , but even with this, minimizing average loss across tasks has two disadvantages:  Performance on outlier tasks may be very poor ; and  in the learning-to-learn setting, minimizing average loss is only optimal if the task selection is unbiased .   Minimizing the worst-case loss across tasks instead of the average loss, in theory solves these two problems, which is why this approach is popular in algorithmic fairness  and domain adaptation under covariate shift assumptions . In some multi-task settings, it is possible to directly modify the loss that is minimized in multi-task learning , but this is for example not possible in the common approach to multi-task learning where each batch is sampled from one of  tasks at random . We present a more general approach to multi-task learning with worst-case-aware loss minimization, instead relying on automated curriculum learning .   \paragraph{Contributions} We present an automated curriculum learning approach to robust multi-task transfer learning. Our approach is general and parameterizes a family of worst-case-aware objectives, with minimax and loss-proportional minimization at the two extremes. In a series of experiments on the GLUE multi-task benchmark , we show that several of these objectives lead to better performance on the benchmark itself, but more importantly, also lead to much better  generalization to other out-of-domain data sets. %Finally, we show that the shared models learned using worst-case-aware curriculum learning also perform better in learning-to-learn settings.       We proposed LA-HCN, a novel algorithm for HMTC, where label-based attention are learned for the text at different hierarchical levels. Furthermore, both local and global text embeddings are generated for local and global classification respectively. At different levels, meaningful attention can be learned based on different labels. Comprehensive experiments demonstrate the effectiveness of LA-HCN, which outperforms other neural network-based state-of-the-art HMTC algorithms across four benchmark datasets of different properties. Moreover, the visualization of the learned label-based attentions reveals its interpretability. However, the practical meaning of learned components is not well explored so far and may be considered in our future work, where the explicit label structure may also be taken into consideration in the design of the components.   
"," Multi-task transfer learning based on pre-trained language encoders achieves state-of-the-art performance across a range of tasks. Standard approaches implicitly assume the tasks, for which we have training data, are equally representative of the tasks we are interested in, an assumption which is often hard to justify. This paper presents a more agnostic approach to multi-task transfer learning, %, relying on $\alpha$-ball  which uses automated curriculum learning to minimize a new family of worst-case-aware losses across tasks. Not only do these losses lead to better performance on outlier tasks; they also lead to better performance in zero-shot and few-shot transfer settings.",97
" Building robust task-oriented dialogue systems is challenging due to complex system design and limited availability of human-annotated data. A dialogue agent is expected to learn dialogue reasoning, decision making, and language generation, which require a large amount of training data.  However, collecting and annotating data for training a dialogue system is time-intensive and not transferable among domains. One possible workaround is to leverage the pre-trained language model to reduce human supervision.   Recent progress in pre-training language models has been shown to be promising in alleviating the data scarcity problem.  Such models are typically pre-trained on large-scale plain text with self-supervised objectives, e.g., language modeling and language denoising. Fine tuning pre-trained language models improves a wide range of natural language processing applications, notably machine translation, and personalized dialogue response generation. However, adapting pre-trained language models to task-oriented dialogue systems is not trivial.   Current state-of-the-art  approaches in task-oriented dialogue rely on several tasks-specific modules, such as State Operation Predictor for dialogue state tracking, and CopyNet for end-to-end dialogue task completion.   Such modules are usually absent in the pre-training stage. Therefore, tasks-specific architecture modifications are required in order to adapt pre-trained language models to different dialogue tasks.    In this work, we aim to simplify the process of transferring the prior knowledge of pre-trained language models for improving task-oriented dialogue systems.  We propose Minimalist Transfer Learning , a simple yet effective transfer learning framework that allows to plug-and-play pre-trained sequence-to-sequence  models and jointly learn dialogue state tracking  and dialogue response generation. Unlike previous approaches, which use a copy mechanism to ``carryover'' the previous dialogue states and generate new dialogue states, we introduce Levenshtein belief spans  which models the difference between old states and new states. In practice, MinTL first decodes the  for updating the previous dialogue state; then, the updated state is used to search the external knowledge base; and finally, a response decoder decodes response by conditioning on the dialogue context and knowledge base match result.   MinTL is easy to set up by using different pre-trained seq2seq backbones.  We conduct extensive experiments on both DST and end-to-end dialogue response generation tasks with two pre-trained seq2seq models, such as  T5 and BART. The experimental result on a large-scale task-oriented dialogue benchmark MultiWOZ suggests that our proposed method significantly improves SOTA performance in both the full data and simulated low resource setting. Our contributions are summarized as follows:            We presented \texttt{N-LTP}, a Python natural language processing toolkit for Chinese. To the best of our knowledge, this is the first neural Chinese toolkit that supports all Chinese fundamental NLP tasks. \texttt{N-LTP} is evaluated on five fundamental Chinese NLP tasks and obtains the state-of-the-art performance. We hope \texttt{N-LTP} can facilitate Chinese NLP research and applications. In the future, we will keep extending \texttt{N-LTP} by adding new state-of-the-art models going forward.  \nocite{*}  
"," In this paper, we propose Minimalist Transfer Learning  to simplify the system design process of task-oriented dialogue systems and alleviate the over-dependency on annotated data. MinTL is a simple yet effective transfer learning framework, which allows us to plug-and-play pre-trained seq2seq models, and jointly learn dialogue state tracking and dialogue response generation.  Unlike previous approaches, which use a copy mechanism to ``carryover'' the old dialogue states to the new one, we introduce Levenshtein belief spans , that allows efficient dialogue state tracking with a minimal generation length. We instantiate our learning framework with two pre-trained backbones: T5 and BART, and evaluate them on MultiWOZ. Extensive experiments demonstrate that: 1) our systems establish new state-of-the-art results on end-to-end response generation, 2) MinTL-based systems are more robust than baseline methods in the low resource setting, and they achieve competitive results with only 20\% training data, and 3) $Lev$ greatly improves the inference efficiency\footnote{Code available in \url{https://github.com/zlinao/MinTL}}.",98
"   Recent advancements in the area of generative modeling have helped increase the fluency of generative models. However, several issues persist: coherence of output and the semblance of mere repetition/hallucination of tokens from the training data .  One reason could be that the generation task is typically construed as an end-to-end system. This is in contrast to traditional approaches, which incorporate a sequence of steps in the NLG system, including content determination, sentence planning, and surface realization . A review of literature from psycholinguistics and cognitive science also provides strong empirical evidence that the human language production process is not a monolith .       Prior approaches have indeed incorporated content planning into the NLG system, for example data-to-text generation problems  as well as classic works that include planning, based on speech acts  .  Our work closely follows these prior approaches, with one crucial difference: our planners are not based on dialogue acts or speech acts.   Consider the example in Fig.. An input utterance by Person B, a statement , followed by a question , can be effectively responded to using plans, learned and generated, prior to the realization phase. The realization output can then include the mention of provides relief, consistent with the generated plan .   Dialogue acts  , by their nature, encompass a wide variety of realized output, and hence cannot sufficiently constrain the language model during the generation process. Research has addressed this issue by adapting existing taxonomies  towards their own goals . We instead use an adapted and extended form of lexical-conceptual structures  to help constrain the realization output more effectively .  Our work makes the following contributions: \\ %  \end{inparaenum}      In this paper, we proposed MinTL, a simple and general transfer learning framework that effectively leverages pre-trained language models to jointly learn DST and dialogue response generation. The  is proposed for reducing the DST complexity and improving inference efficiency. In addition, two pre-trained Seq2Seq language models: T5 and BART are incorporated in our framework. Experimental results on MultiWOZ shows that, by using MinTL, our systems not only achieve new SOTA result on both dialogue state tracking and end-to-end response generation but also improves the inference efficiency. In future work, we plan to explore task-oriented dialogues domain-adaptive pre-training methods to enhance our language model backbones, and extend the framework for mixed chit-chat and task-oriented dialogue agents.   
"," Achieving true human-like ability to conduct a conversation remains an elusive goal for open-ended dialogue systems. We posit this is because extant approaches towards natural language generation  are typically construed as end-to-end architectures that do not adequately model human generation processes.    To investigate, we decouple generation into two separate phases: planning and realization. In the planning phase, we train two planners to generate plans for response utterances. The realization phase uses response plans to produce an appropriate response. Through rigorous evaluations, both automated and human, we demonstrate that decoupling the process into planning and realization performs better than an end-to-end approach.",99
"   A metaphor is a figurative form of expression that compares a word or a phrase to an object or an action to which it is not literally applicable but helps explain an idea or suggest a likeness or analogy between them. Metaphors have been used extensively in all types of literature and writings, especially in poetry and songs to communicate complex feelings, emotions, and visuals present in the text to readers effectively. Metaphors are ubiquitous in natural language and help in structuring our understanding of the world even without our conscious realization of its presence. Given the prevalence and significance of metaphorical language, effective detection of metaphors plays an essential role in many natural language processing applications, for example, language understanding, information extraction, sentiment analysis, etc.  However, automated detection of metaphorical phrases is a difficult problem primarily due to three reasons. First, there is a subjective component involved: the metaphoricity of expression may vary across humans. Second, metaphors can be domain and context dependent. And third, there is a lack of annotated data, which is required to train supervised machine learning algorithms to facilitate automated detection accurately.   Most of the previous approaches for detection of metaphorical phrases, have either relied on manual and lexical detection which requires heavily handcrafted features built from linguistic resources, that are costly to obtain and greatly limits their applicability or have used supervised machine learning based algorithms with limited forms of linguistic context, for example using only the subject verb objects triplets . Although these techniques automate the detection of metaphorical phrases, however, the prediction accuracies are not as good as the prediction accuracies of these techniques in other text classification tasks.  Inspired by recent works in the field of NLP and transfer learning, in this paper, we present an end-to-end method composed of deep contextualized word embeddings, bidirectional LSTMs and multi-head attention mechanism to address some of the limitations aforementioned. Our method is notable in the sense that unlike many existing approaches, it requires only the raw text sequences as input and does not depend on any complex or fine-tuned feature pipelines.    We address the task of natural language generation in open-ended dialogue systems. We test our hypothesis that decoupling the generation process into planning and realization can achieve better performance than an end-to-end approach.  In the planning phase, we explore three methods to generate response plans, including a Symbolic Planner and two learned planners, the Context Attention and Pseudo Self Attention models. Through linguist expert evaluation, we are able to determine the efficacy of the response plans towards realization. In the realization phase, we use the Pseudo Self Attention model to make use of the learned response plans to generate responses.  	extbf{Our key finding through two separate human crowdsourced studies is that decoupling realization, and planning phases outperforms an end-to-end No Planner system across three metrics .}  In this work, we have taken an initial step towards the goal of replicating human language generation processes. Thorough and rigorous evaluations are required to fully support our claims, e.g., by including additional metrics and more diverse corpora. In this work, we limit the types to  GIVE, GAIN, LOSE, and PERFORM. However, we do not restrict the ask action and target at all. Also, since our symbolic planner can be used to obtain silver standard training data, straightforward changes like adding additional lexicons would enable us to generalize to other corpora as well as include additional ask types in our pipeline. Another natural extension would be to explore training the planning and realization phases together in a hierarchical process . This would, in principle, further validate the efficacy of our approach.   
"," %% Text of abstract Metaphors are ubiquitous in natural language, and their detection plays an essential role in many natural language processing tasks, such as language understanding, sentiment analysis, etc. Most existing approaches for metaphor detection rely on complex, hand-crafted and fine-tuned feature pipelines, which greatly limit their applicability. In this work, we present an end-to-end method composed of deep contextualized word embeddings, bidirectional LSTMs and multi-head attention mechanism to address the task of automatic metaphor detection. Our method, unlike many other existing approaches, requires only the raw text sequences as input features to detect the metaphoricity of a phrase. We compare the performance of our method against the existing baselines on two benchmark datasets, TroFi, and MOH-X respectively. Experimental evaluations confirm the effectiveness of our approach.",100
"  For text editing, the sequence-to-sequence  framework has been applied to text simplification , punctuation restoration , grammatical error correction , machine translation post-editing , and etc. We observe that current inference methods can be roughly grouped into two categories: End-to-end   and Tagging . For models from both categories, the encoders extract and encode information from the source text sequence. Yet, the goal of the decoders is different for End2end and Tagging. Upon receiving the encoder's hidden states that comprise the source text information, the decoder of End2end directly decodes the hidden states and generates the completely edited target text sequence. But, the decoder of Tagging produces a sequence of editing operations, such as deletion and insertion, that is later applied to the source text to yield the edited text via a realization step . The mechanisms of End2end and Tagging are illustrated in Figure .         In this work, we presented an end-to-end method composed of deep contextualized word embeddings, bidirectional LSTMs, and multi-head attention mechanism to address the task of automatic metaphor detection and classification. Our method requires only the raw text sequences as input and does not depend on any complex or fine-tuned feature pipelines. Our method established new state-of-the-art on both the datasets for metaphor detection.     The Appendices part is started with the command ;    appendix sections are then done as normal sections         
","  In neural text editing, prevalent sequence-to-sequence based approaches directly map the unedited text either to the edited text or the editing operations, in which the performance is degraded by the limited source text encoding and long, varying decoding steps. To address this problem, we propose a new inference method, Recurrence, that iteratively performs editing actions, significantly narrowing the problem space. In each iteration, encoding the partially edited text, Recurrence decodes the latent representation, generates an action of short, fixed-length, and applies the action to complete a single edit. For a comprehensive comparison, we introduce three types of text editing tasks: Arithmetic Operators Restoration , Arithmetic Equation Simplification , Arithmetic Equation Correction . Extensive experiments on these tasks with varying difficulties demonstrate that Recurrence achieves improvements over conventional inference methods.",101
" There is a broad consensus among grammar formalisms that the composition of form and meaning in natural language is a resource-sensitive process, with the words making up a phrase contributing exactly once to the resulting whole. The sentence ``the Mad Hatter offered'' is ill-formed because of a lack of grammatical material, ``offer'' being a ditransitive verb; ``the Cheshire Cat grinned Alice a cup of tea'' on the other hand is ill-formed because of an excess of material, which the intransitive verb ``grin'' cannot accommodate.  Given the resource-sensitive nature of language, it comes as no surprise that Linear Logic ,  in particular its intuitionistic version ILL, plays a central role in current logic-based grammar formalisms. Abstract Categorial Grammars and Lambda Grammars use ILL ``as-is'' to characterize an abstract level of grammatical structure from which surface form and semantic interpretation are obtained by means of compositional translations. Modern typelogical grammars in the tradition of the Lambek Calculus, e.g.~Multimodal TLG, Displacement Calculus, Hybrid TLG, refine the type language to account for syntactic aspects  of word order and constituency; ILL here is the target logic for semantic interpretation, reached by a homomorphism relating types and derivations of the syntactic calculus to their semantic counterparts.  A common feature of the aforementioned formalisms is their adoption of the parsing-as-deduction method: determining whether a phrase is syntactically well-formed is seen as the outcome of a process of logical deduction. This logical deduction automatically gives rise to a program for meaning composition, thanks to the remarkable correspondence between logical proof and computation known as the Curry-Howard isomorphism, a natural manifestation of the syntax-semantics interface. The Curry-Howard -terms associated with derivations are neutral with respect to the particular semantic theory one wants to adopt, accommodating both the truth-conditional view of formal semantics and the vector-based distributional view, among others.  Despite their formal appeal, grammars based on variants of linear logic have fallen out of favour within the NLP community, owing to a scarcity of large-scale datasets, but also due to difficulties in aligning them with the established high-performance neural toolkit. Seeking to bridge the gap between formal theory and applied practice, we focus on the proof nets of linear logic, a lean graphical calculus that does away with the bureaucratic symbol-manipulation overhead characteristic of conventional prooftheoretic presentations . Integrating proof nets with recent advances in neural processing, we propose a novel approach to linear logic proof search that eliminates issues commonly associated with higher-order types and hypothetical reasoning, while greatly reducing the computational costs of structure manipulation, backtracking and iterative processing that burden standard parsing techniques .  Our proposed methodology relies on two key components. The first is an encoder/decoder-based supertagger that converts raw text sentences into linear logic judgements by dynamically constructing contextual type assignments, one primitive symbol at a time. The second is a bi-modal encoder that contextualizes the generated judgement in conjunction with the input sentence. The contextualized representations are fed into a Sinkhorn layer, tasked with finding the valid permutation that brings primitive symbol occurrences into alignment. The architecture induced is trained on labeled data, and assumes the role of a formally grounded yet highly accurate parser, which transforms raw text sentences into linear logic proofs and computational terms of the simply typed linear -calculus, further decorated with dependency annotations that allow reconstruction of the underlying dependency graph .     We propose a recurrent inference method, Recurrence, that edits a given text sequence iteratively such that in each iteration the programmer determines a single step of editing action and the interpreter executes the action. Our method outperforms the other two inference methods, End2end and Tagging, in three arithmetic equation editing tasks we introduced. For future work, we plan to apply Recurrence to open-domain natural language data and investigate on how to relax its need for intermediate editing steps as extra supervision signals. We also wish to experiment with applying pointer attention  to replace the position component in actions.   
"," Linear logic and the linear $\lambda$-calculus have a long standing tradition in the study of natural language form and meaning. Among the proof calculi of linear logic, proof nets are of particular interest, offering an attractive geometric representation of derivations that is unburdened by the bureaucratic complications of conventional prooftheoretic formats. Building on recent advances in set-theoretic learning, we propose a neural variant of proof nets based on Sinkhorn networks, which allows us to translate parsing as the problem of extracting syntactic primitives and permuting them into alignment. Our methodology induces a batch-efficient, end-to-end differentiable architecture that actualizes a formally grounded yet highly efficient neuro-symbolic parser. We test our approach on {\AE}thel, a dataset of type-logical derivations for written Dutch, where it manages to correctly transcribe raw text sentences into proofs and terms of the linear $\lambda$-calculus with an accuracy of as high as $70\%$.",102
"  Autoregressive language models are functions that estimate a probability distribution over the next word in a sequence from past words, . This requires capturing statistical dependencies between words over short timescales, where syntactic information likely dominates , as well as long timescales, where semantic and narrative information likely dominate . Because this probability distribution grows exponentially with sequence length, some approaches simplify the problem by ignoring long-range dependencies. Classical -gram models, for example, assume word  is independent of all but the last  words, with typical  . Hidden Markov models  assume that the influence of previous words decays exponentially with distance from the current word .  In contrast, neural network language models such as recurrent  and transformer networks  include longer-range interactions, but simplify the problem by working in lower-dimensional representational spaces. Attention-based networks combine position and content-based information in a small number of attention heads to flexibly capture different types of dependencies within a sequence . Gated recurrent neural networks  compress information about past words into a fixed-length state vector . The influence each word has on this state vector tends to decay exponentially over time. However, each element of the state vector can have a different exponential time constant, or ``timescale'' , enabling gated RNNs like the long short-term memory  network to flexibly learn many different types of temporal relationships . Stacked LSTM networks reduce to a single layer , showing that network depth has an insignificant influence on how the LSTM captures temporal relationships. %Yet in both types of networks this flexibility comes at a cost, since the models must learn the shape of these dependencies from the data. %\ahcomment{rewrote this again substantially. think it's quite a bit better now?} Yet in all these networks the shape of the temporal dependencies must be learned directly from the data. This seems particularly problematic for very long-range dependencies, which are only sparsely informative .  This raises two related questions: what should the temporal dependencies in a language model look like? And how can that information be incorporated into a neural network language model?  To answer the first question, we look to empirical and theoretical work that has explored the dependency statistics of natural language. \citet{tegmark} quantified temporal dependencies in English and French language corpora by measuring the mutual information between tokens as a function of the distance between them. They observed that mutual information decays as a power law, i.e.\  for constant . This behavior is common to hierarchically structured natural languages  as well as sequences generated from probabilistic context-free grammars  . %While the precise shape of this dependency function may vary between languages and corpora, we shall take as a given that its mathematical form follows a power law.  Now to the second question: if temporal dependencies in natural language follow a power law, how can this information be incorporated into neural network language models? To our knowledge, little work has explored how to control the temporal dependencies learned in attention-based models. However, many approaches have been proposed for controlling gated RNNs, including updating different groups of units at different intervals , gating units across layers , and explicitly controlling the input and forget gates that determine how information is stored and removed from memory . Yet none of these proposals incorporate a specific shape of temporal dependencies based on the known statistics of natural language.  %\vvcomment{Rewrote that last sentence -- claiming that it's unclear how to relate them to this theoretical stuff seems a bit odd since we directly control the input/forget gates to relate them to the theory :D} \ahcomment{LOVE IT}%Yet it is unclear how to relate these largely practical modifications to theoretical properties of how these models capture temporal dependencies.  %\ahcomment{SHOULD WE SAY SOMETHING ABOUT TRANSFORMERS HERE? I'D LIKE TO, BUT I'M NOT EXACTLY SURE WHAT!} %\vvcomment{I'm tempted to claim at the top of the paragraph  that nobody's really thought through how to measure, let alone control, how transformers are encoding temporal dependencies between words. So they are not a good candidate for incorporating this information because we need a way to measure how a specific, controllable mechanism or group of mechanismin the model encode temporal dependencies between words. Then we can say that some thought has been put into this for RNNs...etc.}  %\ahcomment{good suggestion!}  In this work, we build on the framework of \citet{chrono} to develop a theory for how the memory mechanism in LSTM language models can capture temporal dependencies that follow a power law. This relies on defining the timescale of an individual LSTM unit based on how the unit retains and forgets information. We show that this theory predicts the distribution of unit timescales for LSTM %We show that this theory predicts specific characteristics--the distribution of timescales across LSTM units--of  models trained on both natural English  and formal languages . Further, we show that forcing models to follow this theoretical distribution improves language modeling performance. These results highlight the importance of combining theoretical modeling with an understanding of how language models capture temporal dependencies over multiple scales. %dependencies over multiple timescales.   %Effective language models should capture the statistical properties of natural language, including information that varies at multiple timescales. For example, syntactic effects evolve at the timescale of words, whereas semantics, emotions, and narratives can evolve at much longer timescales of tens to hundreds or thousands of words. The importance of long timescale information is evident in results showing that neural networks have outperformed classical n-gram models on many language modeling benchmarks . This difference is attributed to these networks' ability to capture long timescale dependencies that that are impossible for n-gram models. Yet it is difficult to interpret how neural language models represent information at different timescales, and unclear how these timescale representations should be controlled to yield better or more interpretable models.  %One popular architecture for neural language models is recurrent neural networks, in particular Long Short-Term Memory  . Efforts to interpret the representations learned by LSTMs using probing tasks have shown that LSTM language models are capable of learning both short timescale information about word order ~, and long timescale semantic information~. Other methods have attempted to interpret the timescale of LSTM representations using predictive models of brain responses to natural language~. Yet the question of how and where information about different timescales is maintained in LSTM representations still does not have a satisfying answer.  %One alternative to interpreting representations in existing models is to construct language models in which different layers or groups of units are explicitly constrained to operate at different timescales. Several approaches have been proposed for building such explicitly multi-timescale models, including updating different groups of units at different intervals , gating units across layers , and including explicit control of the input and forget gates that determine how information is stored and removed from memory . These approaches ease interpretation by controlling the timescales represented by different units. Yet this raises a new concern: unlike standard LSTMs, explicitly multi-timescale models are unable to flexibly learn the statistics of natural language. This can decrease the performance of these models  and diminish their utility. Thus, when constructing explicitly multi-timescale language models it is important to consider which timescales are present in natural language.  %\citet{tegmark} quantified the distribution of timescales in natural language by measuring the mutual information between tokens as a function of the distance between them. They observed that mutual information decays as a power law, which is common to many hierarchical structures . It would be desirable for a language model to retain temporal information that mimics these statistics. However, it is not clear how to attain power law using LSTMs, which are fundamentally designed to decay information exponentially across time .  %In this work, we present a method to control the timescales of information represented by each unit of an LSTM language model, resulting in interpretable multi-timescale representations. Building on the theoretical grounding of \citet{chrono}, we quantify the timescale represented in each unit using forget gate activations. We use this framework to analyze an existing LSTM language model  and show how different layers of the model retain information across time. Next, we use this framework to construct explicitly multi-timescale language models where the timescale of each LSTM unit is controlled by setting the forget and input gate biases. To determine the distribution of timescales within this model we used a prior that mimics the power law statistical properties of natural language  through a combination of exponential timescales. Finally, we show that this prior creates interpretable representations in which long and short timescale information is selectively routed into different parts of the network.      We have introduced neural proof nets, a data-driven perspective on the proof nets of ILL, and successfully employed them on the demanding task of transcribing raw text to proofs and computational terms of the linear -calculus. The terms construed constitute type-safe abstract program skeletons that are free to interpret within arbitrary domains, fulfilling the role of a practical intermediary between text and meaning. Used as-is, they can find direct application in logic-driven models of natural language inference.  Our architecture marks a departure from other parsing approaches, owing to the novel use of the Sinkhorn operator, which renders it both fully parallel and backtrack-free, but also logically grounded. It is general enough to apply to a variety of grammar formalisms inheriting from linear logic; if augmented with Gumbel sampling, it can further a provide a probabilistic means to account for derivational ambiguity. Viewed as a means of exposing deep tecto-grammatic structure, it paves the way for graph-theoretic approaches at syntax-aware sentential meaning representations.  
","  Language models must capture statistical dependencies between words at timescales ranging from very short to very long. %, but how much information is needed for each timescale? Earlier work has demonstrated that dependencies in natural language tend to decay with distance between words according to a power law. However, it is unclear how this knowledge can be used for analyzing or designing neural network language models. %However, it is unclear how power law decay of information should manifest in neural network language models. In this work, we derived a theory for how the memory gating mechanism in long short-term memory  language models can capture power law decay. We found that unit timescales within an LSTM, which are determined by the forget gate bias, should follow an Inverse Gamma distribution. Experiments then showed that LSTM language models trained on natural English text learn to approximate this theoretical distribution. Further, we found that explicitly imposing the theoretical distribution upon the model during training yielded better language model perplexity overall, with particular improvements for predicting low-frequency  words. Moreover, the explicit multi-timescale model selectively routes information about different types of words through units with different timescales, potentially improving model interpretability. These results demonstrate the importance of careful, theoretically-motivated analysis of memory and timescale in language models.   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % EMNLP version %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %Although neural language models are effective at capturing statistics of natural language, their representations are challenging to interpret. In particular, it is unclear how these models retain information over multiple timescales.  %In this work, we construct explicitly multi-timescale language models by manipulating the input and forget gate biases in a long short-term memory  network. %%In this work, we quantify and control the timescale of each unit in a LSTM language model via the the input and forget gate biases.  %The distribution of timescales is selected to approximate power law statistics of natural language through a combination of exponentially decaying memory cells. %%We then design a prior based on statistical properties of natural language and construct a multi-timescale LSTM language model.  %We then empirically analyze the timescale of information routed through each part of the model using word ablation experiments and forget gate visualizations. %%Next, we propose word ablation experiments and forget gate visualizations to interpret the timescale of information routing through the different parts of a model.  %These experiments show that the multi-timescale model successfully learns representations at the desired timescales, and that the distribution includes longer timescales than a standard LSTM.  %%Moreover, it outperforms the standard model on the language modeling task on the Penn Treebank and WikiText-2 datasets, especially on rare words. \ahcomment{change last sentence to point about interpretability} %Further, information about high-, mid-, and low-frequency words is routed preferentially through units with the appropriate timescales. %Thus we show how to construct language models with interpretable representations of different information timescales.  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %Shivangi's version %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Language models should ideally capture the statistical properties of natural language varying over multiple timescales. However, representations within language models  are challenging to interpret. Hence, it is unclear how different layers of an LSTM LM retain information over different timescales.  % % In this paper, we propose a mechanism to interpret and control the timescale of information routing through an LSTM unit. We observed that a standard LSTM LM favors representations of short timescale information . We then introduce a prior based on the statistical properties of language to control the distribution of the timescales across LSTM units to achieve an effective multi-timescale language model. In addition to this, we present a word ablation experiment and forget gate visualization to interpret the timescale of information routing through the different parts of the model. % % The proposed model learns representations of both short as well as long-timescale information. It also achieves better prediction performance than a standard LSTM LM on Penn Treebank and WikiText-2 datasets, especially on rare words.",103
"          The advancement in the field of Computer Vision ~ and Natural Language Processing ~ over the last decade, has introduced several interesting machine learning techniques. %problems more convenient.          The problems such as object detection~, segmentation~, and  image classification~ in CV, and machine translation~, question answering~, biomedical and clinical text mining~ , speech recognition~ in NLP, are being solved much more efficiently than ever before. This has facilitated the researchers to indulge into solving interdisciplinary problems that demand knowledge of both the fields.                   Visual Question Answering ~ has emerged as one such problem. In VQA, the task is poised as questions being asked with respect to an image, where the machine needs to learn and generate answers of such questions based on the learned features of the input image. In contrast to the typical CV tasks which largely focus on %have singular and          solving problems such as %restricted problems ~ and Inception-Resnet-v2~, respectively. We fuse the representations together and pass it to the specific answer prediction model at the leaf node. For the task of question classification in the root node, we propose a question segregation technique. We use Support Vector Machine ~ as the classifier with hand-engineered and word frequency-based features for QS. We use the machine learning technique for QS, as the rule-based strategy suffers from the problem of defining too many rules that may not extend to other datasets~. The following examples from RAdiology Data ~ show the difficulty of the rule-based approach in the medical domain.                                                      Careful analysis of the question reveals that the first example expects a descriptive type answer that is to list out the facts that indicate kidney hemorrhage , while the second example expects to confirm the presence/absence of spleen . The presence of such anomalies in the question acts as a hindrance in the formation of robust rules for the classification of questions into their correct type.                  We perform all our experiments in the RAD and  ImageCLEF2018 VQA-Med 2018  datasets, as they perfectly capture the problem statement that we intend to solve. Detailed discussion on the dataset can be found in Section. Experimental evaluation demonstrates promising results, showing the effectiveness of our proposed approach. %'s efficiency.          Additionally, error analysis of the system's outputs %error analysis          shows the future direction in this research area by addressing different kinds of errors.          The organization of this paper is as follows. We first discuss the related work in VQA. Then we present the details of the methodologies that we implemented to solve our specific problem. In particular, we explain our proposed HQS-VQA models in detail. Basically, we discussed the technique used for the question segregation module and the VQA components used to generate the query-specific answers. Details of experiments along with the evaluation results and necessary analysis are reported. %We then perform the experiments and show the results with qualitative and quantitative analysis.          Finally, we conclude and provide the future directions of our work.       \subsection{Motivation}          The motivation behind our work are stemmed from the following facts: %of the medical visual question answering are listed as follows:                                           \end{adjustwidth}         \end{table} \item         We identify this need, and propose a  SVM-based question segregation technique to segregate the questions. We then use this information to propose a hierarchical deep multi-modal network to generate the answers.   \end{itemize}     \subsection{Contributions}                                  In this paper we developed a theory for how LSTM language models can capture power law temporal dependencies. We showed that this theory predicts the distribution of timescales in LSTM language models trained on both natural and formal languages. We also found that explicit multi-timescale models that are forced to follow this theoretical distribution give better performance, particularly over very long timescales. Finally, we show evidence that information dependent on different timescales is routed through specific units, demonstrating that the unit timescales are highly interpretable. This enhanced interpretability makes it possible to use LSTM activations to predict brain data, as in , and estimate processing timescales for different brain regions . These results highlight the importance of theoretical modeling and understanding of how language models capture dependencies over multiple timescales.  \subsubsection*{Acknowledgments} We would like to thank Shailee Jain for valuable feedback on the manuscript and useful discussions, and the anonymous reviewers for their insights and suggestions. Funding support for this work came from the Burroughs Wellcome Fund Career Award at the Scientific Interface , Intel Research Award, and Alfred P. Sloan Foundation Research Fellowship.      anthology    \clearpage       anthology       
","        {        Visual Question Answering in Medical domain  plays an important role in providing medical assistance to the end-users. These users are expected to raise either a straightforward question with a Yes/No answer or a challenging question that requires a detailed and descriptive answer. The existing techniques in VQA-Med fail to distinguish between the different question types sometimes complicates the simpler problems, or over-simplifies the complicated ones. It is certainly true that for different question types, several distinct systems can lead to confusion and discomfort for the end-users. To address this issue, we propose a hierarchical deep multi-modal network that analyzes and classifies end-user questions/queries and then incorporates a query-specific approach for answer prediction. We refer our proposed approach as Hierarchical Question Segregation based Visual Question Answering, in short HQS-VQA.      %   We first use the Support Vector Machine  with the hand-engineered features to classify the questions into yes/no and descriptive types.    % Then, based on the question types, we employ different strategies to provide the answer. The Yes/No type questions are treated as a binary classification problem. We generate the answer from a fixed vocabulary for the descriptive type question.     Our contributions are three-fold, viz. firstly, we propose a question segregation  technique for VQA-Med; secondly, we integrate the QS model to the hierarchical deep multi-modal neural network to generate proper answers to the queries related to medical images; and thirdly, we study the impact of QS in Medical-VQA by comparing the performance of the proposed model with QS and a model without QS. We evaluate the performance of our proposed model on two benchmark datasets, viz. RAD and CLEF18. Experimental results show that our proposed HQS-VQA technique outperforms the baseline models with significant margins. We also conduct a detailed quantitative and qualitative analysis of the obtained results and discover potential causes of errors and their solutions.         }",104
"  The following instructions are directed to authors of papers submitted to EMNLP 2020 or accepted for publication in its proceedings. All authors are required to adhere to these specifications. Authors are required to provide a Portable Document Format  version of their papers. The proceedings are designed for printing on A4 paper.              In this paper, we propose a hierarchical multi-modal approach to tackle the VQA problem in the medical domain. In particular, we use a question segregation module at the top level of our hierarchy to divide the input questions into two different types , followed by individual and independent models at the leaf level, each dedicated to the type of question segregated at the previous level. Our proposed approach can be applied to any related problem where such segregation is possible but it does require non-trivial changes in the architecture.  We use SVM for QS but based on the requirements more rigorous QS techniques can be implemented.          To evaluate the usefulness of our proposed model, we conduct experiments on two different datasets, RAD and CLEF18. We also perform experiments on the combined data of the above two datasets to show the generalisability of our approach. Models, when trained with the proposed hierarchy with QS, scored better, outperforming all the stated baseline models. It suggests that questions with different types learn better in isolation having their individual learning paths. Experimental results indicate the effectiveness of our work, depicting its value for the VQA in the medical domain. We also find out that even simple versions of our model are competitive.          Further analysis of the obtained results reveals that the evaluation metric needs improvement to evaluate VQA in the medical domain. For future work, we plan to investigate a better evaluation strategy for evaluating the task apart from devising a detailed scheme for QS. We also plan to introduce better individual models to handle each of the leaf node tasks. 
"," This document contains the instructions for preparing a manuscript for the proceedings of EMNLP 2020. The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like. These instructions should be used for both papers submitted for review and for final versions of accepted papers. Authors are asked to conform to all the directions reported in this document.",105
"  The rapid development of science and technology in the world has created a vast amount of data. In particular, the growth of social networks continuously creates a huge amount of comments and posts which are valuable sources to exploit and analyze in the digital era. Text classification is a prerequisite for such works as analyzing user opinion in the network environment, filtering and removing malicious information, and detecting criminal risk. With great potential, text classification has attracted much attention from experts in the natural language processing community worldwide. In English, we easily search for a range of text classification publications in many fields. However, relatively few researches have been done on Vietnamese text. Most published articles focus on binary classification. However, a large amount of information today requires analysis in many more aspects . The lack of knowledge and techniques for the Vietnamese language makes us decide to conduct this research to classify multi-class text for Vietnamese social media datasets. These datasets are provided from the VLSP share-task and publications on text classification. In particular, there are various social media textual datasets such as UIT-VSMEC for emotion recognition  and UIT-VSFC for students' feedback classification  and HSD-VLSP for hate speech detection . These are the datasets with multi-label and imbalance between the labels that have been published recently. They are suitable for the requirements that we would like to study.  The emergence of deep neural networks  and word embeddings have made text classification more efficient. Pre-trained word embeddings accurately capture semantics to assist deep learning models improve the efficiency of classification. In this study, we implement deep learning models such as CNN , LSTM  and their variants to solve classification problems. Besides, we implement the BERT model , which is a state-of-the-art model in many natural language processing tasks in recent years. BERT is trained through the transformer閳ユ獨 two-dimensional context . BERT is in contrast to previous deep learning models that looked at a text sequence from left to right or combined left-to-right and right-to-left training. To improve the word representation, we create a normalized words dictionary, which helps recognize words included in pre-trained embedding but is not represented due to misspellings.  As a result, CNN model combined with fastText's pre-trained embedding , has been remarkably performance on Vietnamese social media datasets. Our study also proves the efficiency of BERT on Vietnamese students' feedback dataset. Besides, we combine single models to increase the efficiency of the classification. As a result, our ensemble model accomplishes higher results than the single model. Compared to previous studies done on the datasets, our models achieve better results.      In this work, we focus on the problem of mitigating gender bias in neural dialogue models. We propose an adversarial training framework Debiased-Chat to reduce the bias of a dialogue model during the training process. With the help of a disentanglement model, we design an adversarial learning framework that trains dialogue models to cleverly include unbiased gender features and exclude biased gender features in responses. Experiments on two human conversation datasets demonstrate that our model successfully mitigates gender bias in dialogue models and outperforms baselines by producing more engaging, diverse, and gender-specific responses. In the future, we will investigate debiasing retrieval-based dialogue models and more complicated pipeline-based dialogue systems.    File emnlp2020.tex      Based on the style files for ACL 2020, which were    Based on the style files for ACL 2018, NAACL 2018/19, which were    Based on the style files for ACL-2015, with some improvements     taken from the NAACL-2016 style    Based on the style files for ACL-2014, which were, in turn,    based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,    EACL-2009, IJCNLP-2008...    Based on the style files for EACL 2006 by    e.agirre@ehu.es or Sergi.Balari@uab.es    and that of ACL 08 by Joakim Nivre and Noah Smith  \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{emnlp2020} \usepackage{times} \usepackage{latexsym} \renewcommand{\UrlFont}{\ttfamily\small}    This is not strictly necessary, and may be commented out,   but it will improve the layout of the manuscript,   and will typically save some space. \usepackage{microtype}   \aclfinalcopy   Uncomment this line for the final submission  \def\aclpaperid{***}    Enter the acl Paper ID here   \setlength\titlebox{5cm}   You can expand the titlebox if you need extra space   to show all the authors. Please do not make the titlebox   smaller than 5cm ; we will check this   in the camera-ready version and ask you to change it back.  \newcommand\BibTeX{B\TeX}  \title{Instructions for EMNLP 2020 Proceedings}  \author{First Author \\   Affiliation / Address line 1 \\   Affiliation / Address line 2 \\   Affiliation / Address line 3 \\   \texttt{email@domain} \\\And   Second Author \\   Affiliation / Address line 1 \\   Affiliation / Address line 2 \\   Affiliation / Address line 3 \\   \texttt{email@domain} \\}  \date{}    
"," Text classification is a popular topic of natural language processing, which has currently attracted numerous research efforts worldwide. The significant increase of data in social media requires the vast attention of researchers to analyze such data. There are various studies in this field in many languages but limited to the Vietnamese language. Therefore, this study aims to classify Vietnamese texts on social media from three different Vietnamese benchmark datasets. Advanced deep learning models are used and optimized in this study, including CNN, LSTM, and their variants. We also implement the BERT, which has never been applied to the datasets. Our experiments find a suitable model for classification tasks on each specific dataset. To take advantage of single models, we propose an ensemble model, combining the highest-performance models. Our single models reach positive results on each dataset. Moreover, our ensemble model achieves the best performance on all three datasets. We reach 86.96\% of F1-score for the HSD-VLSP dataset, 65.79\% of F1-score for the UIT-VSMEC dataset, 92.79\% and 89.70\% for sentiments and topics on the UIT-VSFC dataset, respectively. Therefore, our models achieve better performances as compared to previous studies on these datasets.",106
" In recent years, Transformers  have defined state-of-the-art performance on a variety of NLP tasks, including machine translation  and language modeling. While large Transformer models can learn uniquely rich representations, they are also highly overparameterized . Several studies have therefore attempted to prune Transformers during or after training while retaining as much performance as possible . Some methods have been fairly successful, achieving compression ratios up to 10 depending on the downstream task.  Looking beyond task performance, however, it remains unclear how widely-used pruning methods affect a model's learned representations. For example, a pruned Transformer may translate text at the same BLEU, but does pruning affect the model in ways unaccounted for by this metric?  Motivated by this question, we apply recent analysis techniques to study the representations of increasingly sparse Transformers trained on MT. We perform magnitude pruning in an iterative, lottery-ticket fashion to identify Transformers at competitive sparsities with no drop in task performance . We examine the internal structures of our models as sparsity increases, specifically addressing the following questions:    Using iterative magnitude pruning , we train an En-De Transformer that retains 99.4\% of BLEU at 66.4\% sparsity. During IMP, we obtain eight Transformer models at varying levels of sparsity, along with the original unpruned model. We probe these models' representations for learned linguistic knowledge on eighteen auxiliary syntactic and semantic tasks . We then perform an unsupervised comparison of the representations and attention distributions between dense and sparse models, adopting metrics posed in \citet{wu_similarity_2020}. Our key conclusions are as follows:     We introduce energy-based re-ranking  to improve the performance of autoregressive neural machine translation. Still, the performance gap between the output of EBR and oracle re-ranker is significant. This gap indicates that the Joint-EBM model introduced in this paper cannot perfectly distinguish the samples of target sentences for each source sentence. Exploring different energy models for Joint-EBM is the target of our future work to reduce this gap.      proreweighted NMT  which augments autoregressive NMT  with energy-based models. We introduced a training algorithm for the energy-based model for translation tasks and experimentally show the effectiveness of ERNMT in single-source and multi-source translation tasks. Specifically, we showed that multi-source ERNMT consistently improves the performanc of the BaseNMT: .   \clearpage 
"," Recent work on the lottery ticket hypothesis has produced highly sparse Transformers for NMT while maintaining BLEU. However, it is unclear how such pruning techniques affect a model's learned representations. By probing Transformers with more and more low-magnitude weights pruned away, we find that complex semantic information is first to be degraded. Analysis of internal activations reveals that higher layers diverge most over the course of pruning, gradually becoming less complex than their dense counterparts. Meanwhile, early layers of sparse models begin to perform more encoding. Attention mechanisms remain remarkably consistent as sparsity increases.",107
" ACM's consolidated article template, introduced in 2017, provides a consistent \LaTeX\ style for use across ACM publications, and incorporates accessibility and metadata-extraction functionality necessary for future Digital Library endeavors. Numerous ACM and SIG-specific \LaTeX\ templates have been examined, and their unique features incorporated into this single new template.  If you are new to publishing with ACM, this document is a valuable guide to the process of preparing your work for publication. If you have published with ACM before, this document provides insight and instruction into more recent changes to the article template.  The ``\verb|acmart|'' document class can be used to prepare articles for any ACM publication --- conference or journal, and for any stage of publication, from review to final ``camera-ready'' copy, to the author's own version, with {\itshape very} few changes to the source.     A consistent theme in our analysis is the behavioral shift of early layers , which occurs gradually as sparsity increases. Our probing results find that lower layers of sparse models more directly encode POS and syntax information compared to dense models, even though performance of the final encoder representations is similar . Moreover, our similarity analyses conclude that early layer encoder hidden representations  and attention distributions  trend closer towards their respective final representations in sparse models. Information-theoretically, sparse layers have less maximum capacity for encoding, so each individual layer must shoulder more load for the final representations to remain predictively salient. Conversely, an overparameterized dense model can compensate for weak lower layer representations with its upper layers. Indeed, upper FC layers are pruned more than lower FC layers , reflecting the shift in modeling power away from higher layers.  We also observe a gradual loss of information stored in model representations as weights are pruned, especially in later layers. Individual neurons diverge from their dense counterparts , causing a drop in overall representational complexity in the encoder and decoder. Correspondingly, sparse models perform worse at higher-order semantic tasks that are less relevant to BLEU . The reduced overall complexity of sparse representations may partially explain why final layers are observed to be closer to early layers .  Finally, we find that sparse models' attention distributions remain largely similar to their values in the dense model. This ability to reduce weights in attention modules while maintaining nearly identical representations affirms other lines of work . Of the three attention types, encoder-decoder is pruned least , varies most across sparsities, and exhibits most within-model, inter-layer heterogeneity . These results corroborate existing evidence of its unique importance . Meanwhile, decoder self-attention is extremely homogenous across layers and sparsities, perhaps because encoder-decoder attention is more relevant to creating rich representations.  \paragraph{Limitations.} Our work focuses on pruned Transformers for which BLEU remains similar to the original model. However, BLEU is an imperfect measure of translation quality , and it is possible that our pruned models actually perform worse on the task at lower sparsities than suggested by BLEU. Still, we think our work is relevant given that sparse models are typically only held to the standard of matching unpruned task performance.  Next, we emphasize that our work focuses solely on magnitude pruning, which may not be representative of how other pruning methods impact Transformers. We chose this style of pruning primarily because it allows for higher overall sparsity without drop in performance . Further, while it might be expected  that pruning entire neurons or attention heads would substantially change e.g.~the distributions of the model's outputs, we found less existing work specifically measuring the effects of magnitude pruning. This dearth of analysis seemed particularly egregious given recent growth in work on unstructured sparsity .  Finally, a note on probing classifiers: as has been widely discussed by the community , probes measure correlation between model outputs and auxilliary information. Differences in probe performance do not necessarily imply anything about what information actually uses during its forward pass. Especially since we find some evidence suggesting that sparse models may be encoding information across layers, it is possible that their differing structure may explain worse probe performance, as opposed to fundamentally weaker linguistic feature extraction. We hope future work supplements our results by analyzing a model's encoded knowledge in other ways.  \section{Conclusions}  We evaluate how unstructured pruning affects the behavior of Transformers while task performance is maintained. We use probing classifiers to demonstrate that pruning degrades semantic knowledge before affecting BLEU, and that early layers of sparse models better encode low-level linguistic information. Unsupervised similarity analysis reveals that pruning induces representational changes in the encoder and decoder, particularly in higher layers, and that early sparse representations are more similar to their final representations. Meanwhile, attention distributions remain remarkably similar, even at high sparsities.  \section*{Acknowledgements}  We thank Yonatan Belinkov and Jonathan Frankle for their advice during the initial stages of the project. We thank Nelson F. Liu for providing access to preprocessed probing datasets.     \clearpage    \renewcommand\thefigure{\thesection\arabic{figure}} \setcounter{figure}{0}  \renewcommand\thetable{\thesection\arabic{table}} \setcounter{table}{0}  \section{Appendix}    For initial experiments, we trained a linear probe mapping our 1024-dimension token representations to the number of output classes . For subsequent MLP probing, we use an MLP with one 1024-neuron hidden layer with ReLU activation. All weights are trained using Adam with learning rate  for at most 50 epochs with 3 epochs of early stopping patience.   For more complete task descriptions, please refer to \citet{liu_linguistic_2019}. Of the eighteen tasks, five are pairwise, i.e. they involve predicting a property about a pair of tokens. These tasks are syntactic arc prediction, syntactic arc classification, semantic arc prediction, semantic arc classification, and coreference resolution . For these prediction tasks involving pairs of tokens, we input the two token embeddings  and  in addition to their elementwise product  .   Because our model uses Moses tokenization and byte-pair encoding, the source tokens in our preprocessed probing datasets are further split into subtokens by our model. We aggregate subtoken representations by averaging representations. Finally, we noticed that tasks with smaller train/test sets displayed some run-to-run variability, so for these tasks , we report averaged metrics across five replicate runs with different random seeds .  } &   \multicolumn{1}{c}{} &   \multicolumn{1}{c}{} &   \multicolumn{1}{c}{} &   \multicolumn{1}{c}{} \\ \midrule LTH0 & 0.000 & 0.000 & 27.77 & 27.77 \\ LTH1 & 0.168 & 0.200 & 28.04 & 27.59 \\ LTH2 & 0.302 & 0.360 & 28.00 & 27.81 \\  LTH3 & 0.410 & 0.488 & 27.70 & 27.46 \\ LTH4 & 0.496 & 0.590 & 27.93 & 27.24 \\ LTH5 & 0.565 & 0.672 & 27.80 & 26.90 \\ LTH6 & 0.620 & 0.738 & 27.76 & 26.51 \\ LTH7 & 0.664 & 0.790 & 27.61 & 26.14 \\  LTH8 & 0.669 & 0.832 & 27.19 & 25.82 \\ LTH9 & 0.727 & 0.865 & 27.16 & 25.33 \\ \bottomrule                                 
"," With the ever-increasing growth of online recruitment data, job-resume matching has become an important task to automatically match jobs with suitable resumes. This task is typically casted as a supervised text matching problem. Supervised learning is powerful when the labeled data is sufficient. However, on online recruitment platforms, job-resume interaction data is sparse and noisy, which affects the performance of job-resume match algorithms.  \ignore{This task is typically casted as a supervised text matching problem.While supervised learning is powerful when the labeled data is sufficient and clean, the job-resume interaction in practice is usually sparse and noisy, which brings difficulties to effective text representation learning.}  To alleviate these problems, in this paper, we propose a novel multi-view co-teaching network from sparse interaction data for job-resume matching.  Our network consists of two major components, namely text-based matching model and relation-based matching model.  The two parts capture semantic compatibility in two different views, and complement each other.  In order to address the challenges from sparse and noisy data, we design two specific  strategies  to combine the two components. First, two components share the learned parameters or representations, so that the original representations of each component can be enhanced. More importantly, we adopt a co-teaching mechanism to reduce the influence of noise in training data. The core idea is to let the two components help each other by selecting more reliable training instances. The two strategies focus on representation enhancement and data enhancement, respectively.  Compared with pure text-based matching models, the proposed approach is able to learn better data representations from limited or even sparse interaction data, which is more resistible to noise in training data.  Experiment results have demonstrated that our model is able to outperform state-of-the-art methods for job-resume matching.  %In such a way, compared with pure text-based match models, the proposed approach is able to learn better representations from limited or even sparse interaction data, and is more resistible to noise in training data.",108
"  In rule-based machine translation , a linguist formalises linguistic knowledge into lexicons and grammar rules, which is used by the system to analyse sentences in the source language and translate them. While this approach does not require any parallel corpora for training and grants control over the translations created by the system, the process of encoding linguistic knowledge requires a great amount of expert time. Notable examples of RBMT systems are the original, rule-based Systran , Lucy LT  and the Apertium platform .  Instead, corpus-based machine translation  systems learn to translate from examples, usually in the form of sentence-level aligned corpora. On the one hand, this approach is generally computationally more expensive and offers limited control over the generated translations. Furthermore, it is not feasible for language pairs that have limited to no available parallel resources. On the other hand, if parallel resources are available, it boasts a much higher coverage of the targeted language pair. Examples of corpus-based MT paradigms are phrase-based statistical machine translation   and neural machine translation  .  In this work, we focused on leveraging RBMT knowledge for improving the performance of NMT systems in an under-resourced scenario. Namely, we used the information provided by Lucy LT, an RBMT system where the linguistic knowledge is formalised by human linguists as computational grammars, monolingual and bilingual lexicons. Grammars are collections of transformations to annotated trees. Monolingual lexicons are collections of lexical entries, where each lexical entry is a set of feature-value pairs containing morphological, syntactic and semantic information. Bilingual lexicon entries include source-target lexical correspondences and, optionally, contextual conditions and actions. The Lucy LT system divides the translation process into three sequential phases: analysis, transfer, and generation. During the analysis phase, the source sentence is morphologically analysed using a lexicon that identifies each surface form and all its plausible morphological readings. Next, the Lucy LT chart parser together with an analysis grammar consisting of augmented syntactic rules extracts the underlying syntax tree structure and annotates it. The transfer and generation grammars are then applied in succession on that tree, which undergoes multiple annotations and transformations that add information about the equivalences in the target language and adapt the source language structures to the appropriate ones in the target language. Finally, the terminal nodes of the generation tree are assembled into the translated sentence. We focused on the analysis phase, with a special interest for two of the features used: the morphological category  and the inflexion class  or classes of the lexical entries.   %%% NE/TERM Additionally, we focused on two language phenomena that are easily addressable when using RBMT but present a challenge when using corpus-based MT: named entities and terminological expressions.  A named entity  is a word or a sequence of words that unequivocally refer to a real-world object, such as proper nouns, toponyms, numbers or dates. In the context of MT, NEs present different challenges. For example, if an English sentence starts with the word Smith, we do not know a priori if we are dealing with the name of a profession, that will have to be translated, or a proper noun that may have to be left untranslated, or maybe transliterated to a different script. A second issue may arise when using subword units: while word-level models may accidentally preserve an out-of-vocabulary NE, the subword level model will generate a  translation for it. NEs are one of the main out-of-vocabulary word classes, which often cause translation problems that seriously affect the meaning of the sentence .  Similarly, a terminological expression can consist of a single word or a sequence of words that may have a different meaning depending on the context or domain they appear. Hence, the translation for the term might be different depending on the context or domain. Moreover, different contexts and domains may impose additional restrictions on the language used, such as different modes or the use of active or passive voice, and the presence of particular terminology may suggest that a translation is not acceptable even if the meaning of the source sentence is preserved. Accurate terminology translation is crucial to produce adequate translations .  In this work we extend and further analyse the injection of morphological information technique that we proposed in a previous word  and we propose an approach to NEs and terminology that does not rely on any particular technology and can be applied to any MT approach using any kind of resource to detect and translate the NEs and terminological expressions.  To test our proposed approach, we focused on English-Spanish , English-Basque, English-Irish and English-Simplified Chinese language pairs in an under-resourced scenario, using corpora with around one million parallel entries per language pair and domain. Additional test sets that contain several examples of terms, NEs and rich morphology have also been selected and used to further explore the performance of the proposed approaches. Results suggest that, while obtaining results that are not statistically significantly different than the baseline in several scenarios, the proposed approaches show appropriate behaviours such as keeping the passive voice characteristic of some domains.   %Results suggested that adding morphological information to the source language is as effective as using subword units in this particular setting.      This paper presented a multi-view co-teaching network that is able to learn from sparse, noisy interaction data for job-resume matching.  We considered two views for developing the matching algorithm, namely text- and relation-based models.  Furthermore, the two models were integrated into a unified approach that was able to combine their merits for this task. We designed two strategies for model integration, namely representation enhancement and data enhancement.  Representation enhancement referred to the sharing of the learned parameters or representations across the two models; data enhancement referred to the process of filtering or re-weighting training instances according to their quality, which was implemented by the co-teaching algorithms. Extensive experiments showed that the proposed approach is able to achieve a better matching performance from  sparse and noisy interaction data by comparing with several competitive baselines.     In this paper, we only focus on the macro interaction behaviors, \ie the acceptation of interview or rejection. While, it is intuitive that other kinds of micro interactive actions should be also useful to the matching task, such as click or dwell time. We will investigate into this topic and develop a more comprehensive interaction model. Besides, we will also consider applying our approach to more categories and study the domain adaptation problem across different categories. 
"," Rule-based machine translation is a machine translation paradigm where linguistic knowledge is encoded by an expert in the form of rules that translate text from source to target language. While this approach grants extensive control over the output of the system, the cost of formalising the needed linguistic knowledge is much higher than training a corpus-based system, where a machine learning approach is used to automatically learn to translate from examples. In this paper, we describe different approaches to leverage the information contained in rule-based machine translation systems to improve a corpus-based one, namely, a neural machine translation model, with a focus on a low-resource scenario. Three different kinds of information were used: morphological information, named entities and terminology. In addition to evaluating the general performance of the system, we systematically analysed the performance of the proposed approaches when dealing with the targeted phenomena. Our results suggest that the proposed models have limited ability to learn from external information, and most approaches do not significantly alter the results of the automatic evaluation, but our preliminary qualitative evaluation shows that in certain cases the hypothesis generated by our system exhibit favourable behaviour such as keeping the use of passive voice. %Our results suggest that adding morphological information to the source language is as effective as using subword units in this particular setting.",109
" % no  Spoken Language Understanding  technology plays a crucial part in goal-oriented dialogue systems. It typically involves intent detection  and slot filling  tasks. As the names imply, intent detection aims to identify users閳 intents, while slot filling focuses on capturing semantic constituents from user utterances  . As shown in Fig., given a user query 閳ユイook a restaurant on next fall for 5閳ユ, which is sampled from the SNIPS dataset , intent BookRestaurant is assigned to the whole sentence, and each token in the sentence corresponds to one specific slot type. Due to the process interdependence between SLU and subsequent dialogue components, such as the dialogue manager and the natural language generator, performance on these two tasks, i.e., ID and SF, determines the upper limit for the utility of such dialogue system .      Intuitively, intent detection and slot filling are associated with each other  , which can be observed in Fig.. For instance, when the intent of an utterance is 	extit{PlayMusic, the slots of the utterance are more likely to be artist rather than cuisine, and vice versa  % .  . As the accumulation of annotated queries, the co-occurrence characteristic between slot tags and intent labels can become more prominent and perceptible, providing hints about the mutual dependence of ID and SF. Hence, it is promising to achieve a complementary effect by modeling the two tasks in a joint fashion and sharing knowledge between them. %  proposed using CNN based triangular CRF for joint intent detection and slot filling.  % Some works  simply rely on the shared parameters to model this co-occurrence characteristic in an implicit way.  Some works  proposed to model intent-slot relation by sharing parameters, outperforming previous separated models by a large margin. % With the rise of RNN-based methods and attention mechanisms, the practice of working the relationship between intents and slots into joint models is likely to get more sophisticated. More recently, gate mechanism and attention mechanism were also introduced to the RNN-based models   , which provides a new perspective for joint ID and SF modeling.  %  proposed using a slot-gated mechanism to enhance slot filling performance with intent information. To take one step further,  proposed a Stack-Propagation Framework to incorporate token-level intent information to better guide the slot prediction process. This stacking neural network model could provide better interpretability than the slot-gated mechanism.  However, these methods still suffer from various limitations.  For one thing, local context information is not fully exploited in their models, ignoring the intuition that local context is a useful architectural inductive prior for SF. For another thing, most methods fail to take full advantage of the supervised signals due to their implicit or unidirectional modeling style of the intent-slot relations.  Those limitations will hinder the further improvement of SLU systems, especially the overall accuracy, which highly depends on the joint performance of ID and SF.    In this work, we propose a novel Parallel Interactive Network  to address above issues. For the first issue, a Gaussian self-attentive encoder is introduced to better capture local structure and contextual information at each token, which incorporates valuable inductive prior knowledge for SF. For the second issue, we design a Intent2Slot module and a Slot2Intent module  to model the bidirectional information flow between SF and ID. Specifically, inspired by the Dual Process Theory  in neurocognitive science, we divide the information processing in these modules into two stages: the implicit interaction stage and the explicit interaction stage. These two stages correspond to two different processing styles in which the human brain operates: implicit , unconscious learning and explicit , conscious learning. In the implicit interaction stage, the relationships between intents and slots are implicitly captured in the parameters of the shared encoder, which is then utilized by the intuitive decoders to obtain token-level intent distribution and slot label distribution. In the explicit interaction stage, those distribution information obtained in former stage is explicitly utilized by rational decoders to reduce the solution space. Finally, a cooperation mechanism, which comprehensively considers information from above two stages, is performed to reduce the prediction bias and thereby improve the precision and accuracy of model predictions.  To verify the effectiveness of our proposed method, we conduct experiments on two real-world datasets, i.e., ATIS  and SNIPS , which are popularly used as benchmarks in recent works. Empirical results show that our method achieves competent performance on intent error rate, slot F1-score, and sentence-level semantic frame accuracy compared with other baselines. % 閹存垿妫潻妯瑰▏閻⑩暈ert娴ｆ粈璐熸０鍕唲缂佸啯膩閸ㄥ绱濇潻娑楃濮濄儲褰侀崡鍥︾啊濡崇烽惃鍕冮悳鑸 In addition, Bidirectional Encoder Representation from Transformer   is explored to further improve the performance of our model.  In summary, the key contributions are as follows:     In this work, we explored the use of rule-based machine translation  knowledge to improve the performance of neural machine translation  models in an under-resourced scenario, showing that the models had limited ability to learn from the external information.   adding morphological information to the source language is as effective as using subword units in this particular setting.   We also found that RBMT translations were often adequate but both BLEU and TER poorly reflected this, often scoring worse than incorrect NMT-generated translations.  We also tested different approaches to inject named entities  and terminological expressions contained in the RBMT model to NMT. The approaches treat the NMT model as a black box, that is, in such a way that there is no need to know or modify the inner workings of the system, thus being applicable to any model, implementation and architecture. Only the approaches injecting terminology in word-based models improved the baseline, albeit not statistically significantly. In some scenarios, the use of some approaches led to translations that, while not having a significantly different automatic evaluation score, appear to be closer to the style of the targeted text; namely, in the case of terminology translation, some strategies managed to retain the passive voice of the corpus.    One of the paths of our future work will further focus on a more sophisticated extraction of RBMT knowledge. Namely, we plan to use the transfer rules to improve the performance of the NMT model. One of the paths of our future work will further focus on the extraction of RBMT knowledge and the inclusion of transfer rules to improve the performance of the NMT model. The model that was trained following the structure with the parse tree was not able to properly deal with the information, and generally performed worse than the rest; integrating this information differently might produce better results.   Use a second encoder with the RBMT output as input.  A second path is using approaches that modify the architecture of the neural network. For example, using multiple encoders to take both the source sentence and the output of the RBMT system. This approach has been used to improve the performance of NMT. As previously mentioned, corpus-based MT gives limited control over the output to the user, especially when dealing with homographs and terminology; instead, RBMT gives total control. Combining the source sentence with the RBMT output that contains the user-selected translations might lead to improvements in domain-specific or low resource scenarios.    A second improvement path would be using multiple encoders. This approach has been used to improve the performance NMT, but, in our scenario, one of the inputs would be the output of the RBMT system. As previously mentioned, corpus-based machine translation gives limited control over the output to the user, specially when dealing with homographs and terminology; instead, RBMT gives total control. Combining the source sentence with the RBMT output that contains the user-selected translations might lead to improvements in domain-specific or low resource scenarios.   Use of other sources of information . Finally, we also plan to leverage information contained in other freely available RBMT systems, such as Apertium, that contains features similar to the ones used in this work.   While Apertium is a shallow-transfer system,>Apertium is now deep transfer  meaning that there is less syntactic information, features similar to the ones used in this work are available in Apertium.                     
"," % 闂侇厾顢婃担鍝ョ憥濞ｅ浂鍠楅弫濂告偋 Spoken Language Understanding  is an essential part of the spoken dialogue system, which typically consists of intent detection  and slot filling  tasks. Recently, recurrent neural networks  based methods achieved the state-of-the-art for SLU. It is noted that, in the existing RNN-based approaches, ID and SF tasks are often jointly modeled to utilize the correlation information between them. However, we noted that, so far, the efforts to obtain better performance by supporting bidirectional and explicit information exchange between ID and SF are not well studied. % However, we note that, so far, the explicit and bidirectional information flow for ID and SF tasks has not been explored to improve the performance of SLU.  % In addition, the utilization of the local context information will enhance the performance of SF.  In addition, few studies attempt to capture the local context information to enhance the performance of SF. Motivated by these findings, in this paper, Parallel Interactive Network  is proposed to model the mutual guidance between ID and SF. Specifically, given an utterance, a Gaussian self-attentive encoder is introduced to generate the context-aware feature embedding of the utterance which is able to capture local context information. Taking the feature embedding of the utterance, Slot2Intent module and Intent2Slot module are developed to capture the bidirectional information flow for ID and SF tasks. Finally, a cooperation mechanism is constructed to fuse the information obtained from Slot2Intent and Intent2Slot modules to further reduce the prediction bias. The experiments on two benchmark datasets, i.e., SNIPS and ATIS, demonstrate the effectiveness of our approach, which achieves a competitive result with state-of-the-art models. More encouragingly, by using the feature embedding of the utterance generated by the pre-trained language model BERT, our method achieves the state-of-the-art among all comparison approaches. % 闁告鍠撴晶 % Spoken Language Understanding  is an essential part of the spoken dialogue system, which typically consists of intent detection  and slot filling  tasks. Recurrent neural networks  based methods have achieved the state-of-the-art in SLU field. It is noted that, in those approaches, ID and SF are often jointly modeled due to the correlation between them.  % However, most existing joint models fall short of supporting bidirectional and explicit information exchange between ID and SF, which hinders the overall improvement of SLU systems.  % In addition, few studies have taken into account the explicit attention on local context, which is a useful structural inductive prior for SF task. Motivated by these findings, in this paper, Parallel Interactive Network  is proposed to model the mutual guidance between ID and SF. Specifically, given an utterance, we introduce a gaussian self-attentive encoder to extract context-aware features aiming at enhancing local structure information. Then these features are simultaneously fed to the Slot2Intent module and Intent2Slot module to build two-stage interactions where the semantic knowledge is both implicitly and explicitly shared between ID and SF tasks. Finally, a cooperation mechanism is proposed to fuse the information obtained from the two-stage interaction and further reduce the prediction bias. % The experiments on two benchmark datasets, i.e., SNIPS and ATIS, demonstrate the effectiveness of our approach, which achieves a competitive result with state-of-the-art models. % More encouragingly, by incorporating our approach to the pre-trained language model BERT, we outperform all comparison approaches and establish the new state-of-the-art performances in terms of slot F1-score and overall accuracy.",110
" Task-oriented dialogue systems are designed to help users achieve predefined goals, such as booking restaurants or movie recommendations via natural language interactions. These systems are deeply connected with external Knowledge Bases  since the system responses are guided by the output from the KB and the dialogue history.   The current state-of-the-arts are end-to-end pipelined systems that rely on Dialogue State Tracking  and Speech Act  annotations. Aside from the annotation cost, which is knowingly high, these pipelined systems must predict a valid DST for querying the KB, execute the query, generate a response template, and finally fulfill it with the retrieved information. The resulting systems are usually overly complicated, and they require multiple steps, including a direct interaction with the KB.   On the other end of the spectrum, there are end-to-end trainable models that use both the KB and the dialogue history as input, and they directly generate system responses. Most of the implementations use either the Gold KB as input or an intermediate API call to retrieve part of the KB . These systems require at least the DST annotation for generating the API calls or to select the gold KB. Moreover, even with the most advanced transformer architecture, end-to-end models struggle when the input becomes too large. For example, in MWOZ, there are 22K entities just for one of the domains. Interested readers can refer to Appendix C for an overview of different task-oriented methodologies.  On the other hand, \citet{petroni2019language} discovered a simple yet effective way to query factual knowledge from BERT. Later on, \citet{roberts2020much} fine-tuned a pre-trained language model, T5, on just question-answers pairs, without letting the model access any external context or knowledge. These results suggest that the actual knowledge is stored in the model parameters. However, in task-oriented dialogue systems, KB entities do not appear in news articles or Wikipedia, e.g., hotel addresses or postcodes, and thus the aforementioned methods cannot be straightforwardly applied, especially when the KB dynamically changes .  In this paper, we propose a method to store the KB directly into the model parameters using a novel Knowledge Embedded  approach. The resulting model does not use any DST or template responses, nor a KB as input at the inference time, and it can be used in dynamically changing KBs via fine-tuning. The KE approach consists of a newly defined user goal query that generates equivalents KE dialogues from the KB  using minimal annotation effort. Figure shows a high level overview of our approach. To verify the effectiveness of our proposed methodology, we extensively experiment, using both automatic and human metrics, in five task-oriented datasets with small, medium, and large KBs. Our experiments show that end-to-end models can effectively embed knowledge bases in their parameters and achieve competitive performance in all five datasets.  % Additionally, we show that end-to-end models can perform as well as pipelined modularized systems that uses both DST and S-ACT.     In this paper, we propose a novel Parallel Interactive Network  for jointly modeling intent detection and slot filling. In our model, a Gaussian self-attentive encoder is first introduced to better capture the local context information of utterance, then two modules are introduced to model the mutual guidance between ID and SF. Finally, a cooperation mechanism is proposed to further improve the performance and robustness of our proposed PIN. Experiment results on two benchmark datasets show that the proposed PIN achieves competent performance compared with other baselines, demonstrating the effectiveness of our proposed PIN. In addition, by incorporating the pre-trained language model BERT, our method achieves the state-of-the-art among all comparison approaches.  For our future work, we will extend our model to handle cold start problem where few data samples are provided for training process.       conference papers do not normally have an appendix     use section* for acknowledgment 
"," %Task-Oriented Dialogue Systems are either modularized with separate dialog %state tracking  and management steps, or end-to-end trainable. In either case, %, and they can be very large. Task-oriented dialogue systems are either modularized with separate dialogue state tracking  and management steps or end-to-end trainable. In either case, the knowledge base  plays an essential role in fulfilling user requests. Modularized systems rely on DST to interact with the KB, which is expensive in terms of annotation and inference time. End-to-end systems use the KB directly as input, but they cannot scale when the KB is larger than a few hundred entries. In this paper, we propose a method to embed the KB, of any size, directly into the model parameters. The resulting model does not require any DST or template responses, nor the KB as input, and it can dynamically update its KB via fine-tuning. We evaluate our solution in five task-oriented dialogue datasets with small, medium, and large KB size. Our experiments show that end-to-end models can effectively embed knowledge bases in their parameters and achieve competitive performance in all evaluated datasets\footnote{Code available in \url{https://github.com/HLTCHKUST/ke-dialogue}}. % The resulting model do not access any external resource during the user interaction, and do not require any KB as input. % to learn to embed structured knowledge of any size directly with model parameters. % % We propose to fine-tune large pre-trained models for task-oriented dialog system with our approach to learning task-specific structured knowledge.   %This has the advantage of  as part of the input nor as an external source during the user interaction.",111
" Open domain question answering~ involves finding answers to questions from an open corpus. The task has led to a growing interest in scalable end-to-end retrieval systems for question answering. Recent neural retrieval models have shown rapid improvements, surpassing traditional information retrieval~ methods such as BM25.   When QA is formulated as a reading comprehension task, cross-attention models like BERT have achieved better-than-human performance on benchmarks such as the Stanford Question Answering Dataset . Cross-attention models are especially well suited for problems involving comparisons between paired textual inputs, as they provide early fusion of fine-grained information within the pair. This encourages careful comparison and integration of details across and within the two texts.   However, early fusion across questions and answers is a poor fit for retrieval, since it prevents pre-computation of the answer representations. Rather, neural retrieval models independently compute embeddings for questions and answers typically using dual encoders for fast scalable search. Using dual encoders results in late fusion within a shared embedding space.  For machine reading, early fusion using cross-attention introduces an inductive bias to compare fine grained text spans within questions and answers. This inductive bias is missing from the single dot-product based scoring operation of dual encoder retrieval models. Without an equivalent inductive bias, late fusion is expected to require additional training data to learn the necessary representations for fine grained comparisons.  To support learning improved representations for retrieval, we explore a supervised data augmentation approach leveraging a complex classification model with cross-attention between question-answer pairs.  Given gold question passage pairs, we first train a cross-attention classification model as the supervisor. Then any collection of questions can be used to mine potential question passage pairs under the supervision of the cross-attention model. The retrieval model training benefits from additional training pairs annotated with the graded predictions from the cross-attention model augmenting, the existing gold data.   Experiments are reported on MultiReQA-SQuAD and MultiReQA-NQ, with retrieval models establishing significant improvements on Precision at   and Mean Reciprocal Rank  metrics.     In this paper, we propose to learn the KB directly into the model parameters using a novel Knowledge Embedded approach, that is fundamentally different from giving the KB as input or using the DST for querying the KB. We demonstrate that our approach is scalable to different KB sizes and it can be used with dynamically changing KBs via fine-tuning. Automatic and human evaluations confirm that models with embedded KBs achieve competitive performance in all evaluated datasets. Finally we show, for the first time, that end-to-end models can perform as well as pipelined modularized systems in the MWoZ single domain dataset.   
"," Neural models that independently project questions and answers into a shared embedding space allow for efficient continuous space retrieval from large corpora. Independently computing embeddings for questions and answers results in late fusion of information related to matching questions to their answers. While critical for efficient retrieval, late fusion underperforms models that make use of early fusion . We present a supervised data mining method using an accurate early fusion model to improve the training of an efficient late fusion retrieval model. We first train an accurate classification model with cross-attention between questions and answers. The accurate cross-attention model is then used to annotate additional passages in order to generate weighted training examples for a neural retrieval model. The resulting retrieval model with additional data significantly outperforms retrieval models directly trained with gold annotations on Precision at $N$  and Mean Reciprocal Rank .",112
" Topic models, such as Latent Dirichlet Allocation  , aim to discover underlying topics and semantic structures from text collections. Due to its interpretability and effectiveness, LDA has been extended to many Natural Language Processing  tasks . Most of these models employ mean-field variational inference or collapsed Gibbs sampling  for model inference as a result of their intractable posteriors. However, such inference algorithms are model specific and require dedicated derivations.  To address such limitation, neural topic models with black-box inference have been explored, with more flexible training schemes. Inspired by variational autoencoder  , \citet{miao2016nvdm} proposed Neural Variational Document Model which interprets the latent code in VAE as topics. Following this way, \citet{srivastava2017prodlda} adopted the logistic normal prior rather than Gaussian to mimic the simplex properties of topic distribution. Logistic normal is a Laplace approximation to the Dirichlet distribution . However, logistic normal can not exhibit multiple peaks at the vertices of the simplex as the Dirichlet distribution. Therefore, it is less capable of capturing the multi-modality which is crucial for topic modeling .  To overcome such limitation, \citet{wang2019atm} proposed Adversarial-neural Topic Model , a topic model based on Generative Adversarial Networks   and sampling topics directly from the Dirichlet distribution to impose a Dirichlet prior. ATM employs a generator transforming randomly sampled topic distributions to word distributions, and an adversarially trained discriminator estimating the probability that a word distribution came from the training data rather than the generator. Although ATM was shown to be effective in discovering coherent topics, it can not be used to induce the topic distribution given a document due to the absence of a topic inference module. Such limitation hinders its application to downstream tasks, such as text classification. Moreover, ATM fails to deal with document labels which can help extract more coherent topics. For example, a document labeled as `sports' more likely belongs to topics such as `basketball' or `football' rather than `economics' or `politics'.  To address such limitations of ATM, we propose a novel neural topic modeling approach, named Topic Modeling with Cycle-consistent Adversarial Training . In ToMCAT, topic modeling is cast into the transformation between topic distributions and word distributions. Specifically, the transformation from topic distributions to word distributions is used to interpret topics, and the reverse transformation is used to infer underlying topics for a given document. Under such formulation, ToMCAT employs a generator to transform topic distributions randomly sampled from the Dirichlet prior into the corresponding word distributions, and an encoder to reversely transform documents represented as word distributions into their topic distributions. To encourage the generator/encoder to produce more realistic target samples, discriminators for word/topic distributions are introduced to enable adversarial training. Additional cycle-consistency constraints are utilized to align the learning of the encoder and the generator to prevent them from contradicting each other. Furthermore, for documents with labels, we propose sToMCAT that introduces an extra classifier to regularize the topic modeling process.  The main contributions of the paper are:     In this paper, we propose a novel approach for making use of an early fusion classification model to improve late fusion retrieval models. The early fusion model is used to supervised data mining that augments the training data for the later model. The proposed approach mines 53\ ~ and 12\ ~ more examples for MultiRQA-NQ and MultiRQA-SQuAD, respectively. The resulting retrieval models improve +8.6\  and +1.0\  on P@1 on NQ and SQuAD, respectively. The current pipeline assumes there exists annotated in-domain question answer pairs to train the cross-attention model. With a strong general purpose cross-attention model, our supervised data mining method could be modified to train in-domain retrieval models without gold question answer pairs.  We leave this direction to the future work.  
","   Advances on deep generative models have attracted significant research interest in neural topic modeling.   The recently proposed Adversarial-neural Topic Model models topics with   an adversarially trained generator network   and employs Dirichlet prior to capture the semantic patterns in latent topics.   It is effective in discovering coherent topics but unable to infer topic distributions for given documents   or utilize available document labels.   To overcome such limitations, we propose Topic Modeling with Cycle-consistent Adversarial Training    and its supervised version sToMCAT.   ToMCAT employs a generator network to interpret topics and an encoder network to infer document topics.   Adversarial training and cycle-consistent constraints are used to   encourage the generator and the encoder to produce realistic samples that coordinate with each other.   sToMCAT extends ToMCAT by incorporating document labels   into the topic modeling process to help discover more coherent topics.   The effectiveness of the proposed models is evaluated on unsupervised/supervised topic modeling and   text classification.   The experimental results show that our models can produce both coherent and informative topics,   outperforming a number of competitive baselines.",113
"  Probabilistic topic models  are tools for discovering main themes from large corpora. The popular Latent Dirichlet Allocation   and its variants  are effective in extracting coherent topics in an interpretable manner, but usually at the cost of designing sophisticated and model-specific learning algorithm. Recently, neural topic modeling that utilizes neural-network-based black-box inference has been the main research direction in this field. Notably, NVDM  employs variational autoencoder   to model topic inference and document generation. Specifically, NVDM consists of an encoder inferring topics from documents and a decoder generating documents from topics, where the latent topics are constrained by a Gaussian prior. \citet{srivastava2017prodlda} argued that Dirichlet distribution is a more appropriate prior for topic modeling than Gaussian in NVDM and proposed ProdLDA that approximates the Dirichlet prior with logistic normal. There are also attempts that directly enforced a Dirichlet prior on the document topics. W-LDA  models topics in the Wasserstein autoencoders  framework and achieves distribution matching by minimizing their Maximum Mean Discrepancy  , while adversarial topic model  directly generates documents from the Dirichlet prior and such a process is adversarially trained with a discriminator under the framework of Generative Adversarial Network  .  Recently, due to the effectiveness of Graph Neural Networks   in embedding graph structures, there is a surge of interests of applying GNN to natural language processing tasks . For example, GraphBTM  is a neural topic model that incorporates the graph representation of a document to capture biterm co-occurrences in the document. To construct the graph, a sliding window over the document is employed and all word pairs in the window are connected.  A limitation of GraphBTM is that only word relationships are considered while ignoring document relationships. Since a topic is possessed by a subset of documents in the corpus, we believe that the topical neighborhood of a document, i.e., documents with similar topics, would help determine the topics of a document. To this end, we propose Graph Topic Model , a neural topic model that a corpus is represented as a document relationship graph where documents and words in the corpus are nodes and they are connected based on document-word co-occurrences. In GTM, the topical representation of a document node is aggregated from its multi-hop neighborhood, including both document and word nodes, using Graph Convolutional Network  . As GCN is able to capture high-order neighborhood relationships, GTM is essentially capable of modeling both word-word and doc-doc relationships. In specific, the relationships between relevant documents are established by their shared words, which is desirable for topic modeling as documents belonging to one topic typically have similar word distributions.  The main contributions of the paper are:     We have presented ToMCAT, a neural topic model with adversarial and cycle-consistent objectives, and its supervised extension, sToMCAT. ToMCAT employs a generator to capture semantic patterns in topics and an encoder to encode documents into their corresponding topics. sToMCAT further incorporates document labels into topic modeling. The effectiveness of ToMCAT and sToMCAT is verified by experiments on topic modeling and text classification. In the future, we plan to extend our model to cope with external word or document semantics. It would also be interesting to explore alternative architectures other than CycleGAN under our formulation of topic modeling.  
","   Graph Neural Networks    that capture the relationships between graph nodes via message passing   have been a hot research direction   in the natural language processing community.   In this paper, we propose Graph Topic Model , a GNN based neural topic model   that represents a corpus as a document relationship graph.   Documents and words in the corpus become nodes in the graph and   are connected based on document-word co-occurrences.   By introducing the graph structure,   the relationships between documents are established through their shared words   and thus the topical representation of a document is enriched by   aggregating information from its neighboring nodes using graph convolution.   Extensive experiments on three datasets were conducted   and the results demonstrate the effectiveness of the proposed approach.",114
" % {\color{red}jiaqi: outlines}  % \ys{Need to put more Covid information here. Logic is that we need to do so for covid 19 rather than we have the information and then we can do so. }   In this work, we report the system architecture and results of the team TEST\_POSITIVE in the competition of W-NUT 2020 sharred Task-3: extracting COVID-19 event from Twitter.   Since February 2020, the pandemic COVID-19 has been spreading all over the world, posing a significant threat to mankind in every aspect. The information sharing about a pandemic has been critical in stopping virus spreading. With the recent advance of social networks and machine learning, we are able to automatically detect potential events of COVID cases, and identify key information to prepare ahead.  % \kenneth{I would probably make it explicit that ``this paper reports the system architecture and results of the team ABC in XYZ competition at IMWUT 2020''.}  % Users share a wide range of information on social networks. Large platforms, such as Twitter and Facebook, provide sufficient user-generated content for natural language processing applications. For example, massive tweet data posted by users have nourished a variety of applications, e.g. sentiment analysis ~, disaster monitoring ~, event extraction ~ and etc.  We are interested in COVID-19 related event extraction from tweets. With the prevalence of coronavirus, Twitter has been a valuable source of news and information. Twitter users share COVID-19 related topics about personal narratives and news on social media . The information could be helpful for doctors, epidemiologists, and policymakers in controlling the pandemic. However, manual extracting useful information from tremendous amount of tweets is impossible. Hence, we aim to develop a system to automatically extract structured knowledge from Twitter.  % \ys{According to Chieh-Yang, using global model solved the issue of limited annotation, while using the various types of tasks to use all event data to do the training.} Extracting COVID-19 related events from Twitter is non-trivial due to the following challenges: \\  How to deal with limited annotations in heterogeneous events and subtasks?. The creation of the annotated data relies completely on human labors, and thus only a limited amount of data can be obtained in each event categories. There are a variety types of events and subtasks. % Due to the sparsity of the positive samples,  % \cc{why it is due to the sparsity of positve samples} the annotation cannot scale up properly and thus only a limited amount of data can be obtained. % The training dataset relies on manual annotation. Hence, we can only obtain a limited number of training data.  Many existing works solve these low resource problem by different approaches, inlcuding crowdsourcing , unsupervised training , or multi-task learning . Here we adopt multi-task training paradigm to benefit from the inter-event and intra-event  information sharing. In this way, \ours learns a shared embedding network globally from all events data. In this way, we implicitly augment the dataset by global training and fine-tuning the language model.    % because our events and subtasks share similarities % to make use of the fundamental relations across different subtasks and events in learning a global embedding network. %  Heterogeneous types of events and subtasks.  How to make type-aware predictions? Existing work  did not encode the information of different subtask types into the model, while it could be useful in suggesting the candidate slot entity type. In order to make type-aware predictions, we propose a NER-based post-processing procedure in the end of \ours pipeline. We use NER to automatically tag the candidate slots and remove the candidate whose entity type does not match the corresponding subtask type. For example, as shown in Figure, in subtask ``Who'', ``my wife's grandmother'' is a valid candidate slot, while ``old persons home'', tagged as location entity, would be replaced with ``Not Specified'' during the post-processing.   % UK閳 will not be a valid slot for the subtask 閳ユ辅ho閳,as 閳ユ辅ho閳 would require a human-related descrip-tion but 閳ユ矾K閳 is tagged as location-related entityby NER. %   %   % and trains   % tackles each event separately and trains multiple models for different events.   % \cy{Didn't see the reason for this to become a challenge.}  % To tackle the aforementioned challenges, we propose \underline{Jo}int \underline{E}vent Mu\underline{l}ti-task Learn\underline{in}g  model.  % Built upon a joint event multi-task learning framework, \ours benefits from the training data across all the event types.  % In this way, we implicitly augment the dataset by global training and fine-tuning the embedding parameters.  % Furthermore, we design a type-aware post-processing step to automatically remove the predictions whose entities do not match the corresponding subtask types by leveraging the named entity recognition  .  % For example, ``UK'' will not be a valid slot for the subtask ``who'', as ``who'' would require a human-related description but ``UK'' is tagged as location-related entity by NER. % \kenneth{This example is quite confusing. Need to make this more clear.} % For example, if a predicted slot for subtask ``who'' is tagged with a location related entity, we invalidate the prediction by ``Not Specified''.  %  In summary, \ours is enabled by the following technical contributions:\\ %     %    % covid-19 wide spreading  % To automatically extract structured knowledge on events % related to COVID-19 from Twitter is useful for epidemiologists, journalist or policymakers.    % Challenges:  Noisy text in Twitter;  Limited training data;   % In this work, we propose a joint event multi-task learning model for noisy text slot filling tasks with limited training data.  % Our Contributions: %    % s   We have introduced Graph Topic Model, a neural topic model that incorporates corpus-level neighboring context using graph convolutions to enrich document representations and facilitate the topic inference. Both quantitative and qualitative results are presented in the experiments to demonstrate the effectiveness of the proposed approach. In the future, we would like to extend GTM to corpora with explicit doc-doc interactions, e.g., scientific documents with citations or social media posts with user relationships. Replacing GCN in GTM with more advanced graph neural networks is another promising research direction.   
","  The competition of extracting COVID-19 events from Twitter is to develop systems that can automatically extract related events from tweets. The built system should identify different pre-defined slots for each event, in order to answer important questions . To tackle these challenges, we propose the \underline{Jo}int \underline{E}vent Mu\underline{l}ti-task Learn\underline{in}g  model. Through a unified global learning framework, we make use of all the training data across different events to learn and fine-tune the language model.  Moreover, we implement a type-aware post-processing procedure using named entity recognition  to further filter the predictions. \ours outperforms the BERT baseline by $17.2\%$ in micro F1.\footnote{\url{https://github.com/Chacha-Chen/JOELIN}}    % Extracting structured knowledge from Twitter is non-trivial because:  Limited annotated data: structured knowledge needs to be annotated manually;   Various types of tasks: there are different types of slot filling tasks for different events and subtasks.   % To tackle these challenges, we propose \underline{Jo}int \underline{E}vent Mu\underline{l}ti-task Learn\underline{in}g  model. Through a unified global learning framework, we make use of all the training data across different events to learn and fine-tune the language embedding parameters.  Moreover, we implement a type-aware post-processing procedure using NER-based techniques to further filter the predictions.\footnote{\url{https://github.com/Chacha-Chen/JOELIN}} % \kenneth{ I would give one or two examples about the event types-- what is an ``event relevant to COVID-19''? It's unclear in the abstract alone.  I would probably just say the performance numbers in the abstract. What is the performance of the proposed method?} % \jq{Thanks! Kenneth}",115
"  In the era of digitization, most businesses are turning towards leveraging artificial intelligence  techniques to exploit the information contained in business documents. Traditional information extraction  approaches utilize Natural Language Processing  methods to process the information from documents expressed in the form of natural language text . However, documents contain rich multi-modal information that includes both text and the document layout. The document layout organises the textual information into different formats such as sections, paragraphs, tables, multi-column etc. utilising different font-types/colors/positions/sizes/styles. Further, important visual cues are also indicated through figures/charts/logos etc. and the overall document page appearance. In general, information in a document spans over multiple pages which gives rise to a variety of complex document layouts that can be observed in scientific articles, invoices, receipts, emails, contracts, presentations, blogs, etc. Analyzing and understanding these documents is a challenging endeavor and requires a multi-disciplinary perspective combining NLP, computer vision , and knowledge-representation to learn a generic document representation suitable for different downstream applications .  Recent approaches towards document analysis have explored frameworks that utilize information from document text, document layout and document image in different capacities  for specific document tasks.  have proposed joint training of document text and structure for the task of IE from form-like documents, while  combine text and image information for the task of semantic segmentation of documents. Their proposed frameworks optimize the network performance with respect to downstream task which are not suitable for other tasks. To address this limitation,  proposed a pre-training technique based on the BERT transformer architecture , to combine text and layout information from scanned documents. They showcase applicability of their pre-trained network on different downstream tasks further utilizing the image information during fine-tuning for each task. Although  presents a pre-trained framework to learn document representation, there are two limitations to their approach -  the framework only allows for single page documents and  proposed pre-training tasks cannot utilize image information for learning document representation. In the real-world scenario, multi-page documents are common with different pages potentially containing different information across text, layout, and image dimensions. Also, the page image captures the overall layout beyond the appearance of text tokens in the document. Thus, for serving different documents tasks, a unified pre-training framework that learns a generic document representation from all three modalities and works on multi-page documents is necessary.     In this paper, we propose such a generic document representation learning framework that takes as input the document text, layout, and image information applicable to different document tasks. Specifically, we encode the multi-modal document information as -  text and position embeddings similar to BERT   text token 2D position embeddings to capture the layout,  text token image embeddings to capture their appearance, and  document page image and position embeddings to learn the document representation capable of handling multi-page documents. In order to handle large token sequences courtesy of multi-page documents, we utilize the Longformer model proposed by  as the backbone of our framework which introduces an attention mechanism that scales linearly with the sequence length. Following the work of , we utilize the Masked Visual Language Modelling  task and a document classification task that enforces the joint pre-training of all the input embeddings. To further ensure the network learns from the image embeddings, we introduce two additional self-supervised pre-training tasks in our framework -  document topic modeling  and  document shuffle prediction . Similar to the work of , we mine the latent topics from the document text and train our framework to predict the topic distribution using only the document page image embeddings for the task of DTM. On the other hand, DSP involves shuffling the page image order while keeping the other embeddings intact for randomly sampled documents during training to identify if the document is tampered with. While DSP task enforces the joint pre-training of the image embeddings with the text and layout embeddings, DTM task helps to learn richer page image embeddings. As explored by different approaches in prior art , we employ a multi-task learning framework to simultaneously train multiple objectives of the different pre-training tasks to learn shared representations across the text, layout, and image modalities of the documents. We train our network on the publicly available ArXiv dataset  which contains millions of research articles spanning a variety of STEM domains such as mathematics, physics, computer science, etc.  Fig.  signifies the applicability of our pre-trained embeddings for different document tasks. We evaluate the performance of our framework on the following tasks and datasets -  Form Understanding and IE from scanned forms    Document Classification    Table Token Classification  and  Document Retrieval . We conduct an exhaustive set of experiments to analyze the performance of our pre-trained embeddings against state-of-the-art  baselines and ablations of our framework. We're able to beat the SOTA baselines trained on comparable dataset size and network parameters for most of these tasks. In summary, the main contributions of this work are:  % We're able to beat the SOTA performance for certain tasks and achieve comparable performance in other cases utilizing only the pre-trained embeddings for fine-tuning on each task. In summary, the main contributions of this work are     In this work, we build \ours upon a joint event multi-task learning framework. We use NER-based post-processing to generate type-aware predictions. The results show \ours significantly boosts the performance of extracting COVID-19 events from noisy tweets over BERT and CT-BERT baselines. In the future, we would like to extend \ours to open domain event extraction tasks, which is more challenging and requires a more general pipeline.    \kenneth{Say one or two sentence about future work. What's next?}      \clearpage          
"," In this paper, we propose a multi-task learning-based framework that utilizes a combination of self-supervised and supervised pre-training tasks to learn a generic document representation. We design the network architecture and the pre-training tasks to incorporate the multi-modal document information across text, layout, and image dimensions and allow the network to work with multi-page documents. We showcase the applicability of our pre-training framework on a variety of different real-world document tasks such as document classification, document information extraction, and document retrieval. We conduct exhaustive experiments to compare performance against different ablations of our framework and state-of-the-art baselines. We discuss the current limitations and next steps for our work and make the code available to promote future research in this direction.   % In this paper, we propose a multi-task learning-based framework that utilizes a combination of self-supervised and supervised pre-training tasks to learn a generic document representation. We design the network architecture and the pre-training tasks to incorporate the multi-modal document information across text, structure, and image dimensions and allow the network to work with multi-page documents. We showcase the applicability of our pre-training framework on a variety of different real-world document tasks such as document classification, document information extraction, document table structure detection, and document retrieval. We conduct exhaustive experiments to compare performance against different ablations of our framework and SOTA baselines.  % To the best of our knowledge, this is the first approach in which multiple pages \& token-level visual information is encoded along with text and layout during pre-training.  % Our model outperforms existing SOTA baselines pre-trained on comparable dataset sizes across various downstream tasks. We discuss the current limitations and next steps for our work and make the code available to promote future research in this direction.",116
"  Discourse coherence has been the subject of much research in Computational Linguistics thanks to its widespread applications . Most current methods can be described as either stemming from explicit representations based on the Centering Theory , or deep learning approaches that learn without the use of hand-crafted linguistic features.  Our work explores a third research avenue based on the Rhetorical Structure Theory  . We hypothesize that texts of low/high coherence tend to adhere to different discourse structures. Thus, we pose that using even silver-standard RST features should help in separating coherent texts from incoherent ones. This stems from the definition of the coherence itself - as the writer of a document needs to follow specific rules for building a clear narrative or argument structure in which the role of each constituent of the document should be appropriate with respect to its local and global context, and even existing discourse parsers should be able to predict a plausible structure that is consistent across all coherent documents. However, if a parser has difficulty interpreting a given document, it will be more likely to produce unrealistic trees with improbable patterns of discourse relations between constituents. This idea was first explored by \citeauthor{feng-etal-2014-impact} \shortcite{feng-etal-2014-impact}, who followed an approach similar to \citeauthor{Barzilay-Entity-Grid} \shortcite{Barzilay-Entity-Grid} by estimating entity transition likelihoods, but instead using discourse relations  that entities participate in as opposed to their grammatical roles. Their method achieved significant improvements in performance even when using silver-standard discourse trees, showing potential in the use of parsed RST features for classifying textual coherence.       Our work, however, is the first to develop and test a neural approach to leveraging RST discourse representations in coherence evaluation. Furthermore, \citet{feng-etal-2014-impact} only tested their proposal on the sentence permutation task, which involves ranking a sentence-permuted text against the original. As noted by \citet{lai-grammerly}, this is not an accurate proxy for realistic coherence evaluation. We evaluate our method on their more realistic Grammarly Corpus Of Discourse Coherence , where the model needs to classify a naturally produced text into one of three levels of coherence. Our contributions involve:  RST-Recursive, an RST-based neural tree-recursive method for coherence evaluation that achieves 2\% below the state of the art performance on the GCDC while having 62\% fewer parameters.  When ensembled with the current state of the art, namely Parseq , we achieve a notable improvement over the plain ParSeq model.  We demonstrate the usefulness of silver-standard RST features in coherence classification, and establish our results as a lower-bound for performance improvements to be gained using RST features.    We present a multi-modal pre-training framework that utilizes multi-task learning to learn a generic document representation. Our framework encodes the visual, layout and textual information and supports real-world multi-page documents. Our network is pre-trained on the publically available Arxiv dataset utilizing self-supervised tasks that promote learning multi-modal shared representations. We fine-tune our pre-trained network to showcase state-of-the-art performance on different document tasks such as document classification, information extraction and document retrieval. In future, we will investigate pre-training on large datasets such as PublayNet  to analyze the performance gain for different tasks and further explore new architecture designs that will enable document image tasks such as object detection/segmentation using our framework.     We present a multi-modal neural network architecture that utilizes multi-task learning to learn a generic document representation. Our proposed architecture can encode multiple pages while encoding the visual, layout and textual components ubiquitous in real-world PDF documents. We further finetune our architecture across various downstream tasks, and compare our results with existing baselines. Our model significantly outperforms existing baselines in FUNSD, while attains comparable scores in RVL-CDIP, even when pretrained on a much smaller dataset compared to LayoutLM. We also demonstrate that our model is capable table token detection and document retrieval tasks. Novel to our approach, our architecture can utilize visual, layout \& textual components during pretraining and hence can generalize better even when pretrained on a smaller dataset. We also introduce two novel pretraining tasks that helps to learn richer visual representations and enforces joint representation learning for both visual and language modalities. Hence, our model pretrained on all the four pretraining tasks acheives the highest performance across all downstream tasks. We also conduct an ablation to demonstrate the efficacy of the two proposed tasks.     In future research, we will investigate pretraining our architecture on a larger subset of the Arxiv dataset and use the larger PublayNet dataset .   Add more future work \section{Ethical Impact}  The framework proposed in this paper for learning a generic document representation enables a system to read, understand and interpret digital documents. Such a framework is applicable in a variety of enterprise settings. Typical enterprise applications depend on experts to put in hours of work in collecting, filtering, reading, searching and analysing business documents to mine useful insights for business. Common examples include government officers validating user submitted documents for passport application, loan officers analysing user business documents to ascertain income status of the owner, corporate lawyers analysing contracts to identify loopholes etc. For all of these different scenarios, the upside to using our proposed framework is huge since it dramatically reduces the manual effort for all these different experts in conducting their routine tasks. For e.g., our framework fine-tuned on a dataset of passport applications is capable of analysing and extracting all the submitted fields by the applicant in their application. A system based on our framework deployed with the concerned government agency would assist its officials to quickly go through all the fields and approve/reject the application. Additionally, the officials do not need to acquire any specialised skills or undergo training to understand how the system works. On the other hand, it is difficult to come up with a scenario where our proposed framework can be ill-used without malicious intent. Users can potentially utilize our framework to mine personal information of applicants/employees from enterprise documents. For e.g., a corporate human resources  officer could keep a database of all applicants by mining their personal information from submitted resumes by using our framework that is fine-tuned on a dataset of resumes. Hence, in our opinion, the proposed framework enables decision making for different users by providing document insights which can be used to have both a positive or negative impact. \section{Introduction}  In the era of digitization, most businesses are turning towards leveraging artificial intelligence  techniques to exploit the information contained in business documents. Traditional information extraction  approaches utilize Natural Language Processing  methods to process the information from documents expressed in the form of natural language text . However, documents contain rich multi-modal information that includes both text and the document layout. The document layout organises the textual information into different formats such as sections, paragraphs, tables, multi-column etc. utilising different font-types/colors/positions/sizes/styles. Further, important visual cues are also indicated through figures/charts/logos etc. and the overall document page appearance. In general, information in a document spans over multiple pages which gives rise to a variety of complex document layouts that can be observed in scientific articles, invoices, receipts, emails, contracts, presentations, blogs, etc. Analyzing and understanding these documents is a challenging endeavor and requires a multi-disciplinary perspective combining NLP, computer vision , and knowledge-representation to learn a generic document representation suitable for different downstream applications .  Recent approaches towards document analysis have explored frameworks that utilize information from document text, document layout and document image in different capacities  for specific document tasks.  have proposed joint training of document text and structure for the task of IE from form-like documents, while  combine text and image information for the task of semantic segmentation of documents. Their proposed frameworks optimize the network performance with respect to downstream task which are not suitable for other tasks. To address this limitation,  proposed a pre-training technique based on the BERT transformer architecture , to combine text and layout information from scanned documents. They showcase applicability of their pre-trained network on different downstream tasks further utilizing the image information during fine-tuning for each task. Although  presents a pre-trained framework to learn document representation, there are two limitations to their approach -  the framework only allows for single page documents and  proposed pre-training tasks cannot utilize image information for learning document representation. In the real-world scenario, multi-page documents are common with different pages potentially containing different information across text, layout, and image dimensions. Also, the page image captures the overall layout beyond the appearance of text tokens in the document. Thus, for serving different documents tasks, a unified pre-training framework that learns a generic document representation from all three modalities and works on multi-page documents is necessary.     In this paper, we propose such a generic document representation learning framework that takes as input the document text, layout, and image information applicable to different document tasks. Specifically, we encode the multi-modal document information as -  text and position embeddings similar to BERT   text token 2D position embeddings to capture the layout,  text token image embeddings to capture their appearance, and  document page image and position embeddings to learn the document representation capable of handling multi-page documents. In order to handle large token sequences courtesy of multi-page documents, we utilize the Longformer model proposed by  as the backbone of our framework which introduces an attention mechanism that scales linearly with the sequence length. Following the work of , we utilize the Masked Visual Language Modelling  task and a document classification task that enforces the joint pre-training of all the input embeddings. To further ensure the network learns from the image embeddings, we introduce two additional self-supervised pre-training tasks in our framework -  document topic modeling  and  document shuffle prediction . Similar to the work of , we mine the latent topics from the document text and train our framework to predict the topic distribution using only the document page image embeddings for the task of DTM. On the other hand, DSP involves shuffling the page image order while keeping the other embeddings intact for randomly sampled documents during training to identify if the document is tampered with. While DSP task enforces the joint pre-training of the image embeddings with the text and layout embeddings, DTM task helps to learn richer page image embeddings. As explored by different approaches in prior art , we employ a multi-task learning framework to simultaneously train multiple objectives of the different pre-training tasks to learn shared representations across the text, layout, and image modalities of the documents. We train our network on the publicly available ArXiv dataset  which contains millions of research articles spanning a variety of STEM domains such as mathematics, physics, computer science, etc.  Fig.  signifies the applicability of our pre-trained embeddings for different document tasks. We evaluate the performance of our framework on the following tasks and datasets -  Form Understanding and IE from scanned forms    Document Classification    Table Token Classification  and  Document Retrieval . We conduct an exhaustive set of experiments to analyze the performance of our pre-trained embeddings against state-of-the-art  baselines and ablations of our framework. We're able to beat the SOTA baselines trained on comparable dataset size and network parameters for most of these tasks. In summary, the main contributions of this work are:    We're able to beat the SOTA performance for certain tasks and achieve comparable performance in other cases utilizing only the pre-trained embeddings for fine-tuning on each task. In summary, the main contributions of this work are   \section{Introduction}  In the era of digitization, most businesses are turning towards leveraging artificial intelligence  techniques to exploit the information contained in business documents. Traditional information extraction  approaches utilize Natural Language Processing  methods to process the information from documents expressed in the form of natural language text . However, documents contain rich multi-modal information that includes both text and the document structure. The document structure organises the textual information into different formats such as sections, paragraphs, tables, multi-column etc. utilising different font-types/colors/positions/sizes/styles. Further, important visual cues are also indicated through figures/charts/logos, etc. In general, information in the documents spans over multiple pages and the different document structures give rise to a variety of complex document layouts which can be observed in scientific articles, invoices, receipts, emails, contracts, presentations, blogs, etc. Analyzing and understanding these documents is a challenging endeavor and requires a multi-disciplinary perspective combining NLP, computer vision , and knowledge-representation to learn a generic document representation suitable for different downstream applications .  Although traditional approaches to document processing involve analysing the textual information  for document classification, summarisation etc., recent approaches have explored frameworks that utilize information from text, document structure and document image in different capacities  for specific downstream tasks.  has proposed joint training of document text and structure for the task of IE from form-like documents, while  combine text and image information for the task of semantic segmentation of documents. These approaches propose a framework with the objective of optimizing the network performance w.r.t. the downstream task and do not learn a generic document representation applicable to different downstream tasks. To address these limitations,  proposed a pre-training technique based on the BERT transformer architecture , to combine text and structure information from scanned documents. They incorporate modifications to the BERT pre-training tasks to make it suitable for training on documents and further showcase applicability on different downstream tasks utilizing the image information during fine-tuning for each task. Although  presents a pre-trained framework to learn document representation, there are two limitations to their approach -  the framework only allows for single page documents and  proposed pre-training tasks cannot utilize image information for learning document representation. In the real-world scenario, multi-page documents are common with different pages potentially containing different information across text, structure, and image dimensions. Also, the page image contains important visual cues about different document elements such as tables/figures/charts, etc. and the overall layout beyond the appearance of text tokens in the document. Thus, for serving different documents tasks, a unified pre-training framework that learns a generic document representation from all three modalities and works on multi-page documents is necessary.     In this paper, we propose such a generic document representation learning framework that takes as input the document text, structure, and image information applicable to different document tasks. Specifically, we encode the multi-modal document information as -  text and position embeddings similar to BERT   text token 2D position embeddings to capture the structure,  text token image embeddings to capture their appearance, and  document page image and position embeddings to learn the document representation capable of handling multi-page documents. In order to handle large token sequences courtesy of multi-page documents, we utilize the Longformer model proposed by  as the backbone of our framework which introduces an attention mechanism that scales linearly with the sequence length. Following the work of , we utilize the Masked Visual Language Modelling  task that enforces joint pre-training of the text, structure, and page embeddings and a document classification task that enforces the joint pre-training of all the input embeddings. To further ensure the network learns from the overall page image embeddings, we introduce two additional self-supervised pre-training tasks in our framework -  topic modeling  and  document shuffle prediction . Similar to the work of , we mine the latent topics from the document text and train our framework to predict the topic distribution using only the document page image embeddings for the task of DTM. On the other hand, DSP involves shuffling the page image order while keeping the other embeddings intact for randomly sampled documents during training to identify if the document is tampered with. Both of these tasks enforce the joint pre-training of the page image embeddings with the text and structure embeddings. As explored by different approaches in prior art , we employ a multi-task learning framework to simultaneously train multiple objectives of the different pre-training tasks to learn shared representations across the text, structure, and image modalities of the documents. We train our network on the publicly available ArXiv dataset  which contains millions of research articles spanning a variety of STEM domains such as mathematics, physics, computer science, etc.  Fig.  signifies the applicability of our pre-trained embeddings for different document tasks. We evaluate the performance of our framework on the following tasks and datasets -  Form Understanding and IE from scanned forms    Document Classification    Table Token Classification  and  Document Retrieval . We conduct an exhaustive set of experiments to analyze the performance of our pre-trained embeddings against state-of-the-art  baselines and ablations of our framework. We're able to beat the SOTA baselines trained on comparable dataset size and network parameters for most of these tasks. In summary, the main contributions of this work are:    We're able to beat the SOTA performance for certain tasks and achieve comparable performance in other cases utilizing only the pre-trained embeddings for fine-tuning on each task. In summary, the main contributions of this work are   \def\year{2021}\relax  File: formatting-instructions-latex-2021.tex  release 2021.1 \documentclass[letterpaper]{article}   DO NOT CHANGE THIS  \usepackage[switch]{lineno}  \usepackage{aaai21}    DO NOT CHANGE THIS \usepackage{times}    DO NOT CHANGE THIS \usepackage{helvet}   DO NOT CHANGE THIS \usepackage{courier}    DO NOT CHANGE THIS \usepackage[hyphens]{url}    DO NOT CHANGE THIS \usepackage{graphicx}   DO NOT CHANGE THIS \usepackage{fixltx2e} \urlstyle{rm}   DO NOT CHANGE THIS \def\UrlFont{\rm}    DO NOT CHANGE THIS \usepackage{natbib}    DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \usepackage{caption}   DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \frenchspacing    DO NOT CHANGE THIS \setlength{\pdfpagewidth}{8.5in}    DO NOT CHANGE THIS \setlength{\pdfpageheight}{11in}    DO NOT CHANGE THIS  \nocopyright   PDF Info Is REQUIRED.   For /Author, add all authors within the parentheses, separated by commas. No accents or commands.   For /Title, add Title in Mixed Case. No accents or commands. Retain the parentheses. \pdfinfo{ /Title   /Author  /TemplateVersion  }  Leave this   /Title    Put your actual complete title  within the parentheses in mixed case   Leave the space between \Title and the beginning parenthesis alone   /Author    Put your actual complete list of authors  within the parentheses in mixed case.   Each author should be only by a comma. If the name contains accents, remove them. If there are any LaTeX commands,   remove them. \usepackage{amsfonts} \copyrighttext{}   DISALLOWED PACKAGES   \usepackage{authblk} -- This package is specifically forbidden   \usepackage{balance} -- This package is specifically forbidden   \usepackage{color    \usepackage{CJK} -- This package is specifically forbidden   \usepackage{float} -- This package is specifically forbidden   \usepackage{flushend} -- This package is specifically forbidden   \usepackage{fontenc} -- This package is specifically forbidden   \usepackage{fullpage} -- This package is specifically forbidden   \usepackage{geometry} -- This package is specifically forbidden   \usepackage{grffile} -- This package is specifically forbidden   \usepackage{hyperref} -- This package is specifically forbidden   \usepackage{navigator} -- This package is specifically forbidden      \indentfirst} -- This package is specifically forbidden   \layout} -- This package is specifically forbidden   \multicol} -- This package is specifically forbidden   \nameref} -- This package is specifically forbidden   \usepackage{savetrees} -- This package is specifically forbidden   \usepackage{setspace} -- This package is specifically forbidden   \usepackage{stfloats} -- This package is specifically forbidden   \usepackage{tabu} -- This package is specifically forbidden   \usepackage{titlesec} -- This package is specifically forbidden   \usepackage{tocbibind} -- This package is specifically forbidden   \usepackage{ulem} -- This package is specifically forbidden   \usepackage{wrapfig} -- This package is specifically forbidden   DISALLOWED COMMANDS   \nocopyright -- Your paper will not be published if you use this command   \addtolength -- This command may not be used   \balance -- This command may not be used   \baselinestretch -- Your paper will not be published if you use this command   \clearpage -- No page breaks of any kind may be used for the final version of your paper   \columnsep -- This command may not be used    -- No page breaks of any kind may be used for the final version of your paper   \pagebreak -- No page breaks of any kind may be used for the final version of your paperr   \pagestyle -- This command may not be used   \tiny -- This is not an acceptable font size.    \usepackage{multirow}  \usepackage[switch]{lineno}  \setcounter{secnumdepth}{2}  May be changed to 1 or 2 if section numbers are desired.    The file aaai21.sty is the style file for AAAI Press   proceedings, working notes, and technical reports.      Title    Your title must be in mixed case, not sentence case.   That means all verbs ,   nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while   articles, conjunctions, and prepositions are lower case unless they   directly follow a colon or long dash    \title{Towards a Multi-modal, Multi-task Learning based Pre-training Framework for Document Representation Learning}   \author {         Author       Anonymous authors \\   }   \iffalse  Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it       \iffalse  Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it \title{Towards a Multi-modal, Multi-task Learning based Pre-training Framework for Document Representation Learning} \author {       Authors         Subhojeet Pramanik\thanks{Equal Contribution}\textsuperscript{\rm 1},         Shashank Mujumdar\textsuperscript{*\rm 2},         Hima Patel\textsuperscript{\rm 2}\\ } \affiliations{         \textsuperscript{1}IBM Cloud, India \\         \textsuperscript{2}IBM Research, India\\         \{subhojeet,shamujum,himapatel\}@in.ibm.com         }   \fi            
"," This paper evaluates the utility of Rhetorical Structure Theory  trees and relations in discourse coherence evaluation. We show that incorporating silver-standard RST features can increase accuracy when classifying coherence. We demonstrate this through our tree-recursive neural model, namely RST-Recursive, which takes advantage of the text's RST features produced by a state of the art RST parser. We evaluate our approach on the Grammarly Corpus for Discourse Coherence  and show that when ensembled with the current state of the art, we can achieve the new state of the art accuracy on this benchmark. Furthermore, when deployed alone, RST-Recursive achieves competitive accuracy while having 62\% fewer parameters.  %This paper explores the impact of silver-standard Rhetorical Structure Theory  trees and relations on discourse coherence evaluation. We show that incorporating discourse features benefits the previous state of the art model and also propose three models based on Recursive Neural Networks. We evaluate our models on the Grammarly Corpus for Discourse Coherence , showing promising results with one model achieving new state of the art performance on discourse classification, and another nearing previous state of the art accuracy. In addition, we provide valuable insights with respect to the application and behaviour of RST relations and trees in discourse analysis, and motivate future work in this area.",117
"    Medical code assignment categorizes clinical documents with sets of codes to facilitate hospital management and improve health record searching~.  These clinical texts comprise physiological signals, laboratory tests, and physician notes, where the International Classification of Diseases  coding system is widely used for annotation. Most hospitals rely on manual coding by human coders to assign standard diagnosis codes to the discharge summaries for billing purposes. However, this work is and error-prone~.  Incorrect coding can cause billing mistakes and mislead other general practitioners when patients are readmitted. Intelligent automated coding systems could act as a recommendation system to help coders to allocate correct medical codes to clinical notes.   Automatic medical code assignment has been intensively researched during the past decades~. Recent advances in natural language processing  with deep learning techniques have inspired many methods for automatic medical code assignment~.  \citet{zhang2019learning} incorporated structured knowledge into medical text representations by preserving translational property of concept embeddings. However, several challenges remain in medical text understanding. Diagnosis notes contain complex diagnosis information, which includes a large number of professional medical vocabulary and noisy information such as non-standard synonyms and misspellings.  Free text clinical notes are lengthy documents, usually from hundreds to thousands of tokens.  Thus, medical text understanding requires effective feature representation learning and complex cognitive process to enable multiple diagnosis code assignment.   Previous neural methods for medical text encoding generally fall into two categories.  Medical text modeling is commonly regarded as a synonym of recurrent neural networks  that capture the sequential dependency. Such works include AttentiveLSTM~, Bi-GRU~ and HA-GRU~.  The other category uses convolutional neural networks  such as  CAML~ and MultiResCNN~.  These methods only capture locality but have achieved the optimal predictive performance on medical code assignment.    Inspired by the generic temporal convolutional network  architecture~, we consider medical text modeling with causal constraints, where the encoding of the current token only depends on previous tokens, using the dilated convolutional network. We combine it with the label attention network for fine-grained information aggregation.   \paragraph{Distinction of Our Model} The MultiResNet is currently the state-of-the-art model. It applies multi-channel CNN with different filters to learn features and further concatenates these features to produce a final prediction.  In contrast, our model extends the TCN to sequence modeling that uses a single filter and the dilation operation to control the receptive field. In addition, instead of weight tying used in the TCN, we customize it with label attention pooling to extract relevant rich features.   \paragraph{Our Contributions} We contribute to the literature in three ways.  We consider medical text modeling from the perspective of imposing the sequential causal constraint in medical code assignment using dilated convolutions, which effectively captures long sequential dependencies and learns contextual representations in the long clinical notes.   We propose a dilated convolutional attention network , coupling residual dilated convolution, and label attention network for more effective and efficient medical text modeling.    Experiments in real-world medical data show improvement over the state of the art. Compared with multi-channel CNN and RNN models, our model also offers a smaller computational cost.          In this paper, we explore the usefulness of silver-standard parsed RST features in neural coherence classification. We propose two new methods, RST-Recursive and Ensemble. The former achieves reasonably good performance, only 2\  short of state of the art, while more robust with 62\  fewer parameters. The latter demonstrates the added advantage of RST features in improving classification accuracy of the existing state of the art methods by setting new state of the art performance with a modest but promising margin. This signifies that the document's rhetorical structure is an important aspect of its perceived clarity. Naturally, this improvement in performance is bounded by the quality of parsed RST features and could increase as better discourse parsers are developed.   In the future, exploring other RST-based architectures for coherence classification, as well as better RST ensemble schemes and improving RST parsing can be avenues of potentially fruitful research. Additional research on multipronged approaches that draw from Centering Theory, RST and deep learning all together can also be of value.                               
"," Medical code assignment, which predicts medical codes from clinical texts, is a fundamental task of intelligent medical information systems. The emergence of deep models in natural language processing has boosted the development of automatic assignment methods.  However, recent advanced neural architectures with flat convolutions or multi-channel feature concatenation ignore the sequential causal constraint within a text sequence and may not learn meaningful clinical text representations, especially for lengthy clinical notes with long-term sequential dependency. This paper proposes a Dilated Convolutional Attention Network , integrating dilated convolutions, residual connections, and label attention, for medical code assignment. It adopts dilated convolutions to capture complex medical patterns with a receptive field which increases exponentially with dilation size. Experiments on a real-world clinical dataset empirically show that our model improves the state of the art.",118
"  The Transformer translation model , which has outperformed previous RNN/CNN based sequence-to-sequence models, is based on multi-head attention networks. The multi-head attention mechanism, which computes several scaled dot-product attention in parallel, can be more efficiently parallelized at sequence level than RNNs , while addressing the drawback of CNNs  which can only model contexts inside a fixed window.  Even though the advantages in parallelization of the multi-head attention mechanism, recent studies  suggest that the computation the scaled dot-product attention is not sufficiently efficient, especially when handling very long sequences, due to the quadratic increasing size of the attention matrix.  In this paper, we study to accelerate the inference of the scaled dot-product attention in another perspective. Specifically, we propose to learn a hard retrieval attention which only attends to one position in the sequence rather than all tokens to simplify the computation of the scaled dot-product attention. Since the hard attention mechanism only attends to one token, the matrix multiplication between attention probabilities and the value sequence in the standard scaled dot-product attention can be achieved by a simple and efficient retrieval operation.  Our contributions are as follows:       Recent years extensively studies the automatic medical code assignment. Neural clinical text encoding models use CNNs to extract local features and RNNs to preserve sequential dependency. This paper combines both by using dilated convolution. The dilated convolutional attention network  consists of dilated convolution layers, residual connections, and the label attention layer. The DCAN model obeys the causal constraint of sequence encoding and learns rich representations to capture label-aware importance. Through experiments on the MIMIC-III dataset, our model shows better predictive performance than the state-of-the-art methods.   
"," The Transformer translation model that based on the multi-head attention mechanism can be parallelized easily and lead to competitive performance in machine translation. The multi-head attention network performs the scaled dot-product attention function in parallel, empowering the model by jointly attending to information from different representation subspaces at different positions. Though its advantages in parallelization, many previous works suggest the computation of the attention mechanism is not sufficiently efficient, especially when processing long sequences, and propose approaches to improve its efficiency with long sentences. In this paper, we accelerate the inference of the scaled dot-product attention in another perspective. Specifically, instead of squeezing the sequence to attend, we simplify the computation of the scaled dot-product attention by learning a hard retrieval attention which only attends to one token in the sentence rather than all tokens. Since the hard attention mechanism only attends to one position, the matrix multiplication between attention probabilities and the value sequence in the standard scaled dot-product attention can be replaced by a simple and efficient retrieval operation. As a result, our hard retrieval attention mechanism can empirically accelerate the scaled dot-product attention for both long and short sequences by $66.5\%$, while performing competitively in a wide range of machine translation tasks when using for cross attention networks.",119
" Neural Machine Translation  has opened up new opportunities in transfer learning from high-resource to low-resource language pairs . While transfer learning has shown great promise, the transfer between languages with different scripts brings additional challenges. For a successful transfer of the embedding layer, both the parent and the child model should use the same or a partially overlapping vocabulary . It is common to merge the two vocabularies by aligning identical subwords and randomly assigning the remaining subwords from the child vocabulary to positions in the parent vocabulary .   This works well for transfer between languages that use the same script, but if the child language is written in an unseen script, most vocabulary positions are replaced by random subwords. This significantly reduces the transfer from the embedding layer. \citet{gheini2019universal} argue that romanization can improve transfer to languages with unseen scripts. However, romanization can also introduce information loss that might hurt translation quality. In our work, we study the usefulness of romanization for transfer from many-to-many multilingual MT models to low-resource languages with different scripts. Our contributions are the following:        We propose to accelerate the inference of the scaled dot-product attention by learning a hard retrieval attention which only attends to one token in the sentence rather than all tokens. With the one-on-one hard attention matrix, the matrix multiplication between attention probabilities and the value sequence in the standard scaled dot-product attention can be replaced by a simple and efficient retrieval operation.  Our hard retrieval attention mechanism can accelerate both long and short sequences and is  times fast as the scaled dot-product attention. In our experiments on a wide range of machine translation tasks, we demonstrate that using the hard retrieval attention for cross attention networks can lead to competitive performance.  
"," Transfer learning is a popular strategy to improve the quality of low-resource machine translation. For an optimal transfer of the embedding layer, the child and parent model should share a substantial part of the vocabulary.   This is not the case when transferring to languages with a different script. We explore the benefit of romanization in this scenario. Our results show that romanization entails information loss and is thus not always superior to simpler vocabulary transfer methods, but can improve the transfer between related languages with different scripts. We compare two romanization tools and find that they exhibit different degrees of information loss, which affects translation quality. Finally, we extend romanization to the target side, showing that this can be a successful strategy when coupled with a simple deromanization model.",120
" Machine learning  models used in practice today are predominantly supervised models and rely on large datasets labeled for training. However, the cost of collecting and maintaining labeled training data remains a bottleneck for training high-capacity supervised models. Data programming aims to address the difficulty of collecting labeled data by using a programmatic approach to weak supervision by heuristics, where domain experts are expected to provide data programs  incorporating their domain knowledge. Prior work on data programming focuses on modeling and aggregating labeling functions written manually or generated automatically to denoise labeling functions.  % However, little is known about user experience  % in writing labeling functions and how to improve it.   Writing data programs can be, however, challenging and time consuming.  Most domain experts or lay users have no or little programming literacy, and even for those who are proficient programmers, it is often difficult to convert domain knowledge to a set of rules by writing programs.       %  By extending data programming with programming by example, we bridge the gap between scalable training data generation and domain experts. To address these challenges, we introduce data programming by demonstration ,  a new framework that aims to make creating labeling functions  easier by learning them from users' interactive visual demonstrations. DPBD moves the burden of writing labeling functions to an intelligent synthesizer while enabling users to steer the synthesis process at multiple semantic levels, from providing rationales relevant for their labeling choices to interactively filtering the proposed functions. DPBD draws from two lines of prior research; programming by demonstration  or example , e.g.,, which aims to make programming easier by synthesizing them based on user interactions or input and output examples, and  interactive learning from user-provided features or rationales .    We operationalize our framework with \system, an interactive system that enables more accessible data programming to create labeled training datasets for document classification. \system automatically generates  document level labeling rules from  span-level annotations and their relations on specific examples provided by users. Through a user study conducted with  10 data scientists, we evaluate  \system alongside manual data programming using Snorkel. We measure the predictive performances of models created by participants for two  common labeling tasks, sentiment classification and spam detection. We also elicit ratings and qualitative feedback from participants on multiple measures, including  ease of use, ease of learning, expressivity, and overall satisfaction.  We find \system facilitates more accessible creation of labeling functions without a loss in the quality of learned labeling  models.   Tagging or token level classification in text documents is another widely used task that can benefit from DPBD. Here we also briefly discuss our work in progress on \tagruler, a DPBD system that learns token labeling functions through user interaction to create training datasets for tagging models.   % Tagging or span-level classification in text documents is another widely used task that can benefit from DPBD. Here we also briefly discuss our work in progress on \tagruler, a DPBD system that enables the interactive generation of token labeling functions in order to create labeled training data for tagging models.       % On the other hand, \tagruler synthesizes token classification  rules based users.   In summary, we contribute  DPBD, a general data independent framework for learning labeling rules by interactive demonstration;  \system, an interactive system operationalizing our framework for document classification tasks; and  a comparative user study conducted with data scientists in performing real world tasks to evaluate \system and conventional data programming. We have made our research artifacts, including the \system code and demo, publicly available~.   %  along with the materials and anonymized results of the user study %  \documentclass[sigconf]{acmart} \usepackage[moderate]{savetrees} \usepackage{booktabs} % For formal tables \usepackage{listings} \usepackage{latexsym} \usepackage[sets]{cryptocode} \usepackage{amsmath} \usepackage{amssymb} \usepackage{graphicx} \usepackage{setspace} \usepackage{fullpage} \usepackage{xspace} \usepackage{xcolor} \usepackage{caption} \usepackage{subfigure} \usepackage{courier} \usepackage{enumitem} \usepackage[font=normal,skip=2pt]{caption} \usepackage{times} \usepackage{microtype} \usepackage{balance} % to better equalize the last page \usepackage{xcolor} \usepackage[hang,flushmargin]{footmisc} \setlength{\textfloatsep}{8pt plus 2pt minus 2.0pt} \setlength{\intextsep}{3.0pt plus 1.0pt minus 1.0pt}  % \textfloatsep: 20.0pt plus 2.0pt minus 4.0pt; % \floatsep: 12.0pt plus 2.0pt minus 2.0pt; % \intextsep: 12.0pt plus 2.0pt minus 2.0pt.  \renewcommand{\UrlFont}{\ttfamily\small} \renewcommand % where to search for the images % Copyright \setcopyright{none} \acmConference[]{}{}  %% %% Submission ID. %% Use this when submitting an article to a sponsored event. You'll %% receive a unique submission ID from the organizers %% of the event, and this ID should be used as the parameter to this command. %%\acmSubmissionID{123-A56-BU3}  %% %% The majority of ACM publications use numbered citations and %% references.  The command \citestyle{authoryear} switches to the %% ""author year"" style. %% %% If you are preparing content for an event %% sponsored by ACM SIGGRAPH, you must use the ""author year"" style of %% citations and references. %% Uncommenting %% the next command will enable that style. %%\citestyle{acmauthoryear}  %% %% end of the preamble, start of the body of the document source. %Conference  %\acmYear{1997} %\copyrightyear{2016}   %\acmArticle{4} %\acmPrice{15.00}  %% These commands are optional %%\acmBooktitle{Transactions of the ACM Woodstock conference} %\editor{Jennifer B. Sartor} %\editor{Theo D'Hondt} %\editor{Wolfgang De Meuter} \definecolor{tomato}{rgb}{1,0.2,0} \definecolor{turqoise}{rgb}{0.03, 0.91, 0.87} \definecolor{grey}{rgb}{0.4,0.4,0.4} \newif\ifnotes \notestrue \DeclareRobustCommand{\cagatay}[1]{\ifnotes{\small[\textcolor{grey}{\c{C}a\u{g}atay:}\textcolor{tomato}{#1}]}\fi} \DeclareRobustCommand{\sara}[1]{\ifnotes{\small[\textcolor{grey}{Sara:}\textcolor{turqoise}{#1}]}\fi} \DeclareRobustCommand{\subhead}[1]{#1} \DeclareRobustCommand{\system}{\mbox{\sc Ruler}\xspace} \DeclareRobustCommand{\ruler}{\mbox{\sc Ruler}\xspace} \DeclareRobustCommand{\tagruler}{\mbox{\sc TagRuler}\xspace}  \DeclareRobustCommand{\snorkel}{\mbox{\sc Snorkel}\xspace} \DeclareRobustCommand{\babblelabble}{\mbox{\sc BabbleLabble}\xspace} \DeclareRobustCommand{\thenum}{ten\xspace} \newcommand{\eat}[1]{} \newcommand{\example}[1]{{\underline{Example:} #1\qed}} \newcommand{\stitle}[1]{\smallskip {#1}} \newcommand{\sstitle}[1]{\smallskip {\underline{#1}}} \DeclareRobustCommand{\subhead}[1]{#1}  \newcommand{\squishlist}{      }      \renewcommand{\shortauthors}{} \settopmatter{printacmref=false,printfolios=true,printccs=false}       We analyzed the value of romanization for transferring multilingual models to low-resource languages with different scripts. While we cannot recommend romanization as the default strategy for multilingual models and transfer learning across scripts because of the information loss inherent to it, we find that it benefits transfer between related languages that use different scripts. The \texttt{uconv} romanization tool outperforms \texttt{uroman} because it preserves more information encoded in the original script and consequently causes less information loss. Furthermore, we demonstrated that romanization can also be successful on the target side if followed by an additional, learned deromanization step. We hope that our results provide valuable insights for future work in transfer learning and practical applications for low-resource languages with unseen scripts.  
"," % problem & importance   Data programming is a programmatic weak supervision approach to efficiently curate large-scale labeled training data. Writing data programs  requires, however, both programming literacy and domain expertise. Many subject matter experts have neither programming proficiency nor time to effectively write data programs. Furthermore, regardless of one's expertise in coding or machine learning, transferring domain expertise into labeling functions by enumerating rules and thresholds is not only time consuming but also inherently difficult.  % proposed solution  Here we propose a new framework, data programming by demonstration , to generate labeling rules using interactive demonstrations of users. DPBD aims to relieve the burden of writing labeling functions from users, enabling them to focus on higher-level semantics such as identifying relevant signals for labeling tasks.  We operationalize our framework with \system, an interactive system that synthesizes labeling rules for document classification by using span-level annotations of users on document examples.  % evidence that it works  We compare \system with conventional data programming  through a user study conducted with 10 data scientists creating labeling functions for sentiment and spam classification tasks.  We find that \system is easier to use and learn  and offers higher overall satisfaction, while providing discriminative model performances comparable to ones achieved by conventional data programming.",121
"      Deep neural networks are typically trained on a large amount of a single task data through a time-consuming optimization phase. This assumes that the distribution over data points is fixed. However, such neural models do not scale to complex, realistic environments and are prone to distributional shifts and adversarial data points. Online learning on the other hand does not make any distributional assumption and naturally involves an adversarial scenario. However, due to the larger number of training parameters and non-convex optimization landscape, the deep neural networks are hard to train in online settings.     % where the data points are made available over time in an streaming fashion.                \vskip -0.45in     \end{wrapfigure}          Meta-learning  has emerged as a promising technique for fast training of deep neural networks by acquiring and transferring knowledge across different tasks through a learned learning algorithm. This work proposes a meta-learning approach to learn sequential adaptation algorithms for deep neural networks. We introduce a sparse variant of Meta Networks to perform an online and continual fast adaptation of deep neural networks over a data stream with non-stationary distribution.           In Sparse Meta Networks , fast-weights are generated sparsely at each step by a meta-learner and accumulated across multiple steps. When the sparse fast-weights are accumulated in this way, across different tasks, they all together act as an mixture of multiple experts in a single Sparse-MetaNet model. Such sparsely generated recurrent fast-weights are not only computationally efficient; and thus can be applied with large scale deep neural networks, but also crucial to maintain a far past memory over the streaming data.           To demonstrate the effectiveness of our approach, we introduce a new vision based benchmark called Online Cifar. In the Online Cifar setup, Sparse-MetaNet shows a better flexibility and a less catastrophic interference, and achieves the best classification accuracy compared with gradient based baselines. We also evaluate Sparse-MetaNet on Wisconsin Card Sorting Test , a simple online reinforcement learning problem adapted from the human cognitive test and large scale language modelling benchmarks. When used along with Transformer-XL for adaptive language modelling, our Sparse-MetaNet achieves 1.00 bpc on enwik8 and 22.67 perplexity on WikiText-103 datasets, improving upon the original Transformer-XL result of 1.06 bpc and 24.0 perplexity, respectively.                 \vskip -0.45in     \end{wrapfigure}        Accessibility is a key to wider adoption of any technology and machine learning is no exception. Here  we introduced  data programming by demonstration , a general human-in-the-loop framework that aims to ease writing labeling functions, improving the accessibility and efficiency of data programming.  We then presented \system, a DPBD system, for easily generating labeling functions to create training datasets for document-level classification tasks. \system converts user rationales interactively expressed as span-level annotations and relations among them to labeling rules using the DPBD framework. We also reported our progress in developing \tagruler, a second DPBD system focusing on labeling functions for tagging.   Through a user study with 10 data scientists performing real world labeling tasks for classification, we evaluated \system together with conventional data programming and found that \system enables more accessible data programming without loss in the performance of labeling models created. We believe DPBD systems will be useful for data scientists as well as subject matter experts. We release \system as open source software to support future applications and extended research.   \system prioritizes accessibility over expressivity. Is this trade-off inevitable? The expressivity of \system can be enhanced by extended semantic and syntactic analysis of the document  context of user demonstrations. Enabling manual revision of synthesized labeling functions at multiple levels of abstraction can be also useful. In this context, further improving the expressivity of \system through use cases without diminishing its accessibility is an important area of future research. Deriving additional insights into how users  with limited or no  programming proficiency  would use \system is another area of future work, and open sourcing \system is a step forward in this direction. Future research also includes developing fast search and ranking algorithms and experimenting with different active learning strategies to effectively search and navigate the vast joint space of labeling functions and data examples.     In this paper we presented \system, a data programming by demonstration  system for easily generating labeling functions to create training datasets for document-level classification tasks. \system converts user rationales interactively expressed as span-level annotations and relations to  labeling rules using the DPBD framework.  DPDB is a general  human-in-the-loop framework that aims to ease writing labeling functions, improving the accessibility and efficiency of data programming.  Through a user study with 10 data scientists performing real world labeling tasks for classification, we evaluated \system together with conventional data programming and found that \system enables more accessible data programming without loss in the performance of labeling models created. Results of our study  also suggested that, even for  skilled programmers, the majority of functions they write can be captured more easily through visual interactions using our system. We release \system as an open source software to support future applications and extended research.  \section{Evaluation} We evaluate \system alongside manual data programming using Snorkel. Our goal is to better understand the trade-offs afforded by each method. To this end, we conducted a user study with data scientists and measured  their task performance accuracy in completing two labeling tasks. In addition to task performance, we also analyzed the accessibility and  expressivity of both methods using the qualitative feedback elicited from participants.   Note that \system can be used by programmers and non-programmer domain experts alike, but a fair comparison with Snorkel requires proficiency in conventional programming.   \subhead{Participants}  We recruited 10 participants with Python programming experience through our professional network. All participants had significant programming experience . Their experience with Python programming ranged from  to  years with an average of  years .    \subhead{Experimental Design}  We carried out the study using  a within-subjects experiment design, where all participants performed tasks using both conditions .  The sole independent variable controlled was the method of creating labeling functions. We counterbalanced the order in which the tools were used, as well as which classification task we performed with which tool.   \subhead{Tasks and Procedure} We asked participants to write  labeling functions for two prevalent labeling tasks: spam detection and sentiment classification.  They performed these two tasks on  YouTube Comments and Amazon Reviews, respectively. Participants received 15 mins of instruction on how to use each tool, using a topic classification task  over a newsgroup dataset as an example. We asked participants to write as many functions as they considered necessary for the goal of the task.  There were given 30 mins to complete each task and we recorded the labeling functions they created and these functions' individual and aggregate performances.  After completing both tasks, participants also filled out an exit survey, providing their qualitative feedback.  For the manual programming condition, we provided a Jupyter notebook interface based on the Snorkel tutorial. The notebook had a section for writing functions, a section with diverse analysis tools, and a section to train a logistic regression model on the labels generated.    \section{Evaluation}   We evaluate \system alongside manual data programming using Snorkel.   Our goal is to better understand the trade-offs afforded by each method. To this end, we conducted a user study with 10 data scientists and measured  their task performance accuracy in completing two labeling tasks. In addition to task performance, we also analyzed the accessibility and  expressivity of both methods using the qualitative feedback elicited from participants.     \subhead{Participants}  We recruited participants with Python programming experience through our professional network . Note that \system can be used by programmers and non-programmer domain experts alike, but a fair comparison with Snorkel requires proficiency in conventional programming.  All participants had significant programming experience . Their experience with Python programming ranged from  to  years with an average of  years .      \subhead{Experimental Design}  We carried out the study using  a within-subjects experiment design, where all participants performed tasks using both conditions .  The sole independent variable controlled was the method of creating labeling functions. We counterbalanced the order in which the tools were used, as well as which classification task we performed with which tool.     \subhead{Tasks and Procedure} We asked participants to write  labeling functions for two prevalent labeling tasks: spam detection and sentiment classification.  They performed these two tasks on  YouTube Comments and Amazon Reviews, respectively. Participants received 15 mins of instruction on how to use each tool, using a topic classification task  over a newsgroup dataset as an example. We asked participants to write as many functions as they considered necessary for the goal of the task.  There were given 30 mins to complete each task and we recorded the labeling functions they created and these functions' individual and aggregate performances.  After completing both tasks, participants also filled out an exit survey, providing their qualitative feedback.    For the manual programming condition, we iteratively developed a Jupyter notebook interface based on the Snorkel tutorial. We provided a section for writing functions, a section with diverse analysis tools, and a section to train a logistic regression model on the labels they had generated.     .      \section{Evaluation}   We evaluate our framework against a baseline of manual programming of labeling functions . Our primary goal is to better understand the trade offs afforded by each method based on the quantitative performance and the qualitative feedback by participants. To this end, we conducted a user study with \thenum participants and measured their task performance accuracy in two labeling tasks on two different corpora, YouTube Comments and Amazon Reviews. In addition to task performance, we also analyzed the accessibility, expressivity, and interpretability of both methods using the qualitative feedback elicited from participants and our observations gathered during the study sessions.     \subhead{Experimental Design} We wanted to be sure that each user had an opportunity to try both tools so that they could fairly compare the two, while still minimizing knowledge transfer between tasks. We also wanted to evaluate these methods on different types of tasks.  To achieve this, we divided the participant pool into two random groups each with five participants in each. We then randomly assigned task/tool pairings to each group.  To avoid ordering effects, we counterbalanced the presentation of tasks within each group.     The sole independent variable we controlled was the method of creating labeling function,  which had two conditions; \snorkel, and \system. Note that these two tools  correspond to two different forms of creating labeling functions, manual , and using visual interactive demonstration, respectively.      Babble Labble mention   In a pilot version of the study we also tested Babble Labble, a system for generation labeling functions from natural language explanations. In general our participants performed worse and found the system less expressive, which is why we have omitted it from this study. Our takeaway is that Babble may be useful for collecting functions at scale from, for example, crowdsource workers, but is less suited for an individual machine learning engineer or domain expert.     \subhead{Participants}  For a fair comparison, we wanted to make sure participants were skilled programmers, as well as familiar with training machine learning models and able to interpret statistics like precision and recall. Because of the difficulty of recruiting subjects with this skill set, we recruited participants who are employees or interns from our lab.  None of the participants were involved in this work.    Although we believe Ruler can be used by programmers and non-programmer domain experts alike, because the purpose of this study was to compare Ruler to existing methods, we only recruited programmers skilled at Python.     Participants had either ``research scientist'' or  ``software engineer''  as a job title. Five of them held PhDs and one held BS, all in computer science.     \todo{Mention titles, prev experience of participants}    All participants had significant programming experience . Their experience with Python programming ranged from  to  years with an average of  years .  Only two participants had used data programming in the past, but all had experience training supervised models and collecting training data.    \subhead{Tasks and Data} We asked participants to write  labeling functions for two prevalent labeling tasks, spam detection and sentiment classification.  They performed these two tasks on  YouTube Comments and Amazon Reviews, respectively. We asked participants to write as many functions as they considered necessary for the goal of the task.  They were given 30 mins to complete each task. Participants were also tutored for 15 mins on writing labeling functions using a topic  classification  task on a newsgroup dataset.     \subhead{Procedure}  Before the experiment began, users were asked to complete a questionnaire that elicited information on their educational background and programming and model development experiences. This way we could ensure that our treatment groups were reasonably balanced across several dimensions.     Each user was scheduled to complete two sessions, never on the same day  and not more than 3 days apart. These sessions were conducted over zoom and began with a 15 minute tutorial to learn how to use the tool by practicing on the newsgroup dataset.   Next, the user was given 30 minutes to complete their assigned task. They were allowed to ask questions and access the internet as desired.   Before each tutorial and task, the user was given as much time as they wanted to read a task description consisting of a short paragraph describing the task and 5 examples from each class.     We cannot expect a 30 minute experiment to be a realistic representation of what generating training data labels is like, but it is likely a good approximation of what the first 30 minutes of generating training data is like. Given constrained resources, we consider this the best method of evaluation.    Throughout each task, we recorded the labeling functions created by participants and these functions' individual and aggregate performances on each task. At the end of the session, participants completed an exit survey to provide their qualitative feedback. After the second such session, the user was asked to complete a final survey comparing the two tools.    For instance,  if spam detection was assigned to be the first task to be completed for a user, and Snorkel the first tool, then in the first session the participant would complete a Snorkel tutorial, then the spam detection task using Snorkel and a survey. On a later day, they would complete a Ruler tutorial, followed by the sentiment analysis task using Ruler, then a survey about Ruler, and a survey comparing the two tools.      \cagatay{If space permits, consider adding a figure illustrating the experiment flow.}  \sara{consider adding figure showing users' experience}\section{DPBD Framework} \stitle{Problem Statement} Given a dataset  of data records and a set of labels ,  we aim to develop a framework that enables human labelers to interactively assign a label from  for each data record efficiently sampled from   , while demonstrating their rationales for label assignments through visual interaction. Given a triplet  of a data record, a visual interaction from the labeler, and the label assigned,  we want this framework to effectively synthesize and propose labeling rules  for the labeler to choose from.  Finally, we want the framework to optimally aggregate all the chosen rules  in order to create a labeled training set from   with probabilistic labels in order to subsequently train discriminative models on it.  \stitle{Framework Overview} The data programming by demonstration  framework   has two input sources: the human labeler, and the data that is to be labeled. The labeler is the subject matter expert who has sufficient domain understanding to extract useful signals from data. Given a dataset, our framework enables the labeler to label each record with a categorical label, while providing their labeling rationales by interactively marking relevant parts of the record and specifying semantics and relationships among them. The output is a labeling model, which is trained to automatically produce labels for the large set of unlabeled data. The DPBD framework has four main components, labeling interface,  synthesizer, modeler, and active sampler.    The labeler interacts with data via the labeling interface. The labeling interface    records the labeler's interaction and compiles the interaction into a labeling rule. The    synthesizer synthesizes labeling rules and translates those chosen by the labeler into   program functions. Third, the selected functions are passed to the modeler, which    builds a labeling model by optimally aggregating the generated functions. Until a certain    stopping criterion is met  or the labeler decides to exit,   the active sampler selects the next data record to present the labeler.     In the rest of this section, we describe the details of each component.   The labeling interface is the workplace where the labeler encodes domain knowledge into labeling rules. It provides a way to express noisy explanations for labeling decisions using a visual interaction language,  which allows the user to express domain knowledge without having to formalize their ideas into computer programs or natural language explanations. This allows for more focus on patterns in the data while abstracting away any implementation concerns.  \stitle{Generalized Labeling Model} Inspired by the entity-relationship model in database modeling, the generalized labeling model  models the data records with concepts and relationships.  The GLM views the data record as a series of tokens, where a token is a continuous subset of a record with no semantics attached.  For example, in text data, a token can be any span  of the data record; in an image data record, it would be a 2D region, rectangular or free form; and in an audio data record, it would be a 1D window of the data record .  A concept is a group of tokens that the labeler believes share common semantics. For instance, over text data, the labeler might define a concept of positive adjectives consisting of a set of tokens, each of which can imply a positive review.  When labeling audio data, the labeler might create a concept to aggregate all clips that express excitement, or of a specific speaker.  This abstraction allows the user to teach the GLM which generalizations are relevant to the task. A relationship represents a binary correlation between token-token, token-concept, or concept-concept. Some examples are membership , co-existence , and positional .     \stitle{Mapping GLM Elements to Operations} Given the GLM specification described above, our framework also defines the operations that can be applied on GLM elements. Table lists the GLM elements and the corresponding operations. The implementation of both the labeling interface and the operations described in Table would vary across data types and token definitions. To add expressivity, the GLM may also perform transformations over the set of tokens, as we describe in the next section.   \stitle{Compiling Operations into Labeling Rules} Once the labeler finishes annotating an example using the provided operations, and selects a label, the tokens are extracted from the annotation and used  as the initial set of conditions from which to build rules. The synthesizer combines these conditions into labeling rules by selecting subsets of the conditions to be combined with different conjunctive formulas, according to the relationships the user has annotated. The synthesizer extends the initial set of labeling rules and presents the extended labeling rules for the labeler to select from, choosing desired ones based on  domain knowledge.  A labeling rule serves as an intermediate language, interpretable by both the labeler and the synthesizer. In our framework, we adopt the notation of domain relational calculus to represent these rules, which can be expressed as:  . The variable \texttt{tokens} is a sequence of tokens with existential quantification, and  \texttt{conditions} is a conjunctive formula over boolean predicates that is tested over \texttt{tokens} on a data record.   The predicates are first-order expressions, and each can be expressed as a tuple .  is an optional transformation function on a token identifier, a process of mapping the raw token to more generalized forms. Some example transformations are word lemmatization in text labeling, speech-to-text detection in audio labeling, or object recognition in image labeling.    is a token, while  is can be either token, literal or a set. If  denotes a token, the transformation function  may also apply to .   is an operator whose type depends on the type of .  If  is a token or literal,   detects a positional or an equality relationship. Otherwise, if  is a set,  is one of the set operators  . Since the \texttt{conditions} is in the conjunctive form, the order of labeler's interactions does not matter.  \example{ Consider the following review for the binary sentiment classification  task:  \texttt{This book was so great! I loved and read it so many times that I will soon have to buy a new copy.}   If the labeler thinks this data record has a positive sentiment, she can express her decision rationale using GLM. First, she may select two tokens that are related to the sentiment: \texttt{book} and \texttt{great}. Assume there are two concepts the labeler previously created:  \texttt{itembook, electronics}; and  \texttt{padjwonderful}. The labeler realizes the token \texttt{great} can be generalized by the \texttt{padj} concept, which means that the labeling rule will still be valid if this token is replaced by any tokens in the concept, so she adds this token to the concept.  Finally, the labeler creates a positional relationship from \texttt{book} to token \texttt{great} to indicate that they appear in the same sentence, before completing the labeling process. These operations compile into the labeling rule . }  This rule is sent to the synthesizer for expansion and program synthesis.   Given the compiled labeling rule from the labeling interface, the synthesizer extends one single labeling rule from labeler's interaction to a set of more general labeling rules; and translates those labeling rules into computer programs. It is straightforward to translate the rules into executable computer programs , so in this section, we focus on how to synthesize the extended labeling rules.  Given the labeling rule compiled from a labeler's interaction, the synthesizer generates more labeling rules while optimizing two competing goals: maximizing generalization, so that more  data can be accurately labeled; and maximizing the coverage of the labeler's interaction, simply because labeler's interaction is the most valuable signal for labeling based on the domain knowledge. Of course, the larger the set of annotations in an interaction, the larger the set of labeling functions that can be synthesized. To keep rule selection as easy as possible for the user, in this case we prioritize rules that cover more of the interaction, assuming that there is little redundancy.  in the labeler's interaction.  We achieve generalization of the given rules using the following heuristics:  substituting tokens with concepts;  replacing general coexistence relationships with position-specific ones; and  applying the available transformations over the tokens .    Since the labeling rule in GLM has conjunctive conditions, Algorithm  generalizes each predicate in the conditions.    Inside, Line to Line substitute token with concept.   Line can be implemented explicitly by matching token to concept set, as well as sophisticated data-dependent processing via transformation .   For example, in our system for text labeling , in addition to matching values with labeler defined concepts, we also apply named-entity recognition  where the named-entities are implicit concepts that a token can be a member of.    Line to Line replace the positional with co-occurrence relationship by removing the condition that specifies the positional context.   The conditions for extended labeling rules is a conjunctive combination of single predicates, one from each extended condition set .   In addition, for special cases of binary labeling, the algorithm also considers the rule which flips over the label by adding negation to the conditions .     Once the extended rules are generated, the rules are ranked by their generalization score---a measurement of how applicable a certain rule is. We define a data-independent generalization score for a labeling rule  as: .     Intuitively,  is calculated by counting how many different data instances that  can be used.  It prefers labeling rules using large sets to match tokens in the data record.  \example{ Continuing with our Amazon review example, the synthesizer can derive the following labeling rules from  using these heuristics:   Labeling rule~ is generated using heuristics  and .  Labeling rule~ and~ are synthesized by using heuristics  and , respectively. Note that labeling rule~ is more general than~ and~ because all data records that can be labeled by~ and~ will be labeled the same way using labeling rule~.  Labeling rules~ are due to flipping over the binary label with heuristics .  }   Once the extended labeling rules are generated, the labeler can help confirm the validity in order to achieve faster convergence. The top-k candidates ranked by the generalization score are displayed in the labeling interface for the labeler to accept or reject.   The modeler component trains a model that can be used to automatically annotate unlabeled datasets. Naively aggregating the labeling functions  can be either inaccurate , or does not scale with a large set of unlabeled data. Instead, the modeler encapsulates the ideas from traditional data programming to first build a generative model to denoise labeling functions, and then train a discriminative model to leverage other features beyond what are expressed by the labeling functions.   To improve the model quality at faster rates, our framework uses an active sampler to choose the next data record for labeling.  The active sampler can be plugged in with any custom active learning policy.  By default, it selects the data record  with the highest entropy :   where  is the probability that example  belongs to class , as predicted by the trained label model.     \section{DPBD Framework}   \stitle{Problem Statement}   Given a dataset  of data records and a set of labels ,  we aim to develop a framework that enables human labelers to interactively assign a label from  for each data record efficiently sampled from   , while demonstrating their rationales for label assignments through visual interaction. Given a triplet  of a data record, a visual interaction from the labeler, and the label assigned,  we want this framework to effectively synthesize and propose labeling rules  for the labeler to choose from.    Finally, we want the framework to optimally aggregate all the chosen rules  in order to create a labeled training set from   with probabilistic labels in order to subsequently train discriminative models on it.    \stitle{Framework Overview}   The data programming by demonstration  framework   has two input sources: the human labeler, and the data that is to be labeled. The labeler is the subject matter expert who has sufficient domain understanding to extract useful signals from data. Given a dataset, our framework enables the labeler to label each record with a categorical label, while providing their labeling rationales by interactively marking relevant parts of the record and specifying semantics and relationships among them.   The output is a labeling model, which is trained to automatically produce labels for the large set of unlabeled data.      Inherited from the traditional data programming~, our framework also assumes that a set of labeled data is available for tuning model hyperparameters.   The DPBD framework has four main components. The labeler interacts with data via the labeling interface. The labeling interface records the labeler's interaction and compiles the interaction into a labeling rule.   The synthesizer synthesizes labeling rules and translates those chosen by the labeler into program functions. Third, the selected functions are passed to the modeler, which builds a labeling model by optimally aggregating the generated functions. Until a certain stopping criterion is met  or the labeler decides to exit, the active sampler selects the next data record to present the labeler.       In the rest of this section, we describe the details of each component.       The labeling interface is the workplace where the labeler encodes domain knowledge into labeling rules. It provides a way to express noisy explanations for labeling decisions using a visual interaction language,  which allows the user to express domain knowledge without having to formalize their ideas into computer programs or natural language explanations. This allows for more focus on patterns in the data while abstracting away any implementation concerns.       Inspired by the entity-relationship model in database modeling, the generalized labeling model  models the data records with concepts and relationships.  The GLM views the data record as a series of tokens,   where a token is a continuous subset of a record with no semantics attached.    For example, in text data, a token can be any span  of the data record; in an image data record, it would be a 2D region, rectangular or free form; and in an audio data record, it would be a 1D window of the data record .      A concept is a group of tokens that the labeler believes share common semantics. For instance, over text data, the labeler might define a concept of positive adjectives consisting of a set of tokens, each of which can imply a positive review.    When labeling audio data, the labeler might create a concept to aggregate all clips that express excitement, or of a specific speaker.  This abstraction allows the user to teach the GLM which generalizations are relevant to the task.    A relationship represents a binary correlation between token-token, token-concept, or concept-concept. Some examples are membership , co-existence , and positional .           \subhead{Mapping GLM Elements to Operations}   Given the GLM specification described above, our framework also defines the operations that can be applied on GLM elements. Table lists the GLM elements and the corresponding operations. The implementation of both the labeling interface and the operations described in Table would vary across data types and token definitions. To add expressivity, the GLM may also perform transformations over the set of tokens, as we describe in the next section.     \subhead{Compiling Operations into Labeling Rules}   Once the labeler finishes annotating an example using the provided operations, and selects a label, the tokens are extracted from the annotation and used    as the initial set of conditions from which to build rules.   The synthesizer combines these conditions into labeling rules by selecting subsets of the conditions to be combined with different conjunctive formulas, according to the relationships the user has annotated.   The synthesizer extends the initial set of labeling rules and presents the extended labeling rules for the labeler to select from, choosing desired ones based on  domain knowledge.    A labeling rule serves as an intermediate language, interpretable by both the labeler and the synthesizer. In our framework, we adapt the notation of domain relational calculus to represent these rules, which can be expressed as:    .   The variable \texttt{tokens} is a sequence of tokens with existential quantification, and    \texttt{conditions} is a conjunctive formula over boolean predicates that is tested over \texttt{tokens} on a data record.     The predicates are first-order expressions, and each can be expressed as a tuple .  is an optional transformation function on a token identifier, a process of mapping the raw token to more generalized forms. Some example transformations are word lemmatization for text labeling, speech-to-text detection in audio labeling, or object recognition in image labeling.      is a token, while  is can be either token, literal or a set.   If  denotes a token, the transformation function  may also apply to .     is an operator whose type depends of the type of .  If  is a token or literal,   detects a positional or an equality relationship. Otherwise, if  is a set,  is one of the set operators  . Since the \texttt{conditions} is in the conjunctive form, the order of labeler's interactions does not matter.    \example{   Consider the binary sentiment classification  task on Amazon review data. Observe the following review:    \texttt{This book was so great! I loved and read it so many times that I will soon have to buy a new copy.}     If the labeler thinks this data record has a positive sentiment, she can express her decision rationale using GLM.   First, she may select two tokens that are related to the sentiment: \texttt{book} and \texttt{great}. Assume there are two concepts the labeler previously created:  \texttt{itembook, electronics}; and    \texttt{padjwonderful}. The labeler realizes the token \texttt{great} can be generalized by the \texttt{padj} concept, which means that the labeling rule will still be valid if this token is replaced by any tokens in the concept, so she adds this token to the concept.    Finally, the labeler creates a positional relationship from \texttt{book} to token \texttt{great} to indicate that they appear in the same sentence, before completing the labeling process.   These operations compile into the labeling rule   .   }    This rule is sent to the synthesizer for expansion and program synthesis.        Given the compiled labeling rule from the labeling interface, the synthesizer extends one single labeling rule from labeler's interaction to a set of more general labeling rules; and translates those labeling rules into computer programs.   It is straightforward to translate the rules into executable computer programs , so in this section, we focus on how to synthesize the extended labeling rules.    Given the labeling rule compiled from a labeler's interaction, the synthesizer generates more labeling rules while optimizing two competing goals: maximizing generalization, so that more  data can be accurately labeled; and maximizing the coverage of the labeler's interaction, simply because labeler's interaction is the most valuable signal for labeling based on the domain knowledge.   Of course, the larger the set of annotations in an interaction, the larger the set of labeling functions that can be synthesized. To keep rule selection as easy as possible for the user, in this case we prioritize rules that cover more of the interaction, assuming that there is little redundancy.  in the labeler's interaction.    We achieve generalization of the given rules using the following heuristics:    substituting tokens with concepts;  replacing general co-existence relationships with position-specific ones; and  applying the available transformations over the tokens .      Since the labeling rule in GLM has conjunctive conditions, Algorithm  generalizes each predicate in the conditions.      Inside, Line to Line substitute token with concept.     Line can be implemented explicitly by matching token to concept set, as well as sophisticated data-dependent processing via transformation .     For example, in our system for text labeling , in addition to matching values with labeler defined concepts, we also apply named-entity recognition  where the named-entities are implicit concepts that a token can be a member of.      Line to Line replace the positional with co-occurrence relationship by removing the condition that specifies the positional context.     The conditions for extended labeling rules is a conjunctive combination of single predicates, one from each extended condition set .     In addition, for special case of binary labeling, the algorithm also considers the rule which flips over the label by adding negation to the conditions .         Once the extended rules are generated, the rules are ranked by their generalization score---a measurement of how applicable a certain rule is.   We define a data-independent generalization score for a labeling rule  as: .         Intuitively,  is calculated by counting how many different data instances that  can be used.    It prefers labeling rules using large sets to match tokens in the data record.    \example{   Continuing with our Amazon review example, the synthesizer can derive the following labeling rules from  using these heuristics:       Labeling rule~ is generated using heuristics  and .  Labeling rule~ and~ are synthesized by using heuristics  and , respectively.   Note that labeling rule~ is more general than~ and~ because all data records that can be labeled by~ and~ will be labeled the same way using labeling rule~.    Labeling rules~ are due to flipping over the binary label with heuristics .    }     Once the extended labeling rules are generated, the labeler can help confirm the validity in order to achieve faster convergence.   The top-k candidates ranked by the generalization score are displayed in the labeling interface for the labeler to accept or reject.       The modeler component trains a model that can be used to automatically annotate unlabeled datasets.   Naively aggregating the labeling functions  can be either inaccurate , or does not scale with large set of unlabeled data.    This is simply because labeling functions are noisy: they may overlap, conflict and even depends with each other, and can only provide limited signals in weak supervision.   Instead, the modeler encapsulates the ideas from traditional data programming to first build a generative model to denoise labeling functions, and then train a discriminative model to leverage other features beyond what are expressed by the labeling functions.       To improve the model quality at faster rates, our framework uses an active sampler to choose the next data record for labeling.    The active sampler can plug in any custom active learning policy.  By default, it selects the data record  with the highest    entropy :   where  is the probability that example  belongs to class , as predicted by the trained label model. \section{Introduction} Machine learning  models used in practice today are predominantly supervised models and rely on large datasets labeled for training. However, the cost of collecting and maintaining labeled training data remains a bottleneck for training high-capacity supervised models. Data programming aims to address the difficulty of collecting labeled data by using a programmatic approach to weak supervision by heuristics, where domain experts are expected to provide data programs  incorporating their domain knowledge. Prior work on data programming focuses on modeling and aggregating labeling functions written manually or generated automatically to denoise labeling functions.    However, little is known about user experience    in writing labeling functions and how to improve it.   Writing data programs can be, however, challenging and time consuming.  Most domain experts or lay users have no or little programming literacy, and even for those who are proficient programmers, it is often difficult to convert domain knowledge to a set of rules by writing programs.          By extending data programming with programming by example, we bridge the gap between scalable training data generation and domain experts. To address these challenges, we introduce data programming by demonstration ,  a new framework that aims to make creating labeling functions  easier by learning them from users' interactive visual demonstrations. DPBD moves the burden of writing labeling functions to an intelligent synthesizer while enabling users to steer the synthesis process at multiple semantic levels, from providing rationales relevant for their labeling choices to interactively filtering the proposed functions. DPBD draws from two lines of prior research; programming by demonstration  or example , e.g.,, which aims to make programming easier by synthesizing them based on user interactions or input and output examples, and  interactive learning from user-provided features or rationales .    We operationalize our framework with \system, an interactive system that enables more accessible data programming to create labeled training datasets for document classification. \system automatically generates  document level labeling rules from  span-level annotations and their relations on specific examples provided by users. Through a user study conducted with  10 data scientists, we evaluate  \system alongside manual data programming using Snorkel. We measure the predictive performances of models created by participants for two  common labeling tasks, sentiment classification and spam detection. We also elicit ratings and qualitative feedback from participants on multiple measures, including  ease of use, ease of learning, expressivity, and overall satisfaction.  We find \system facilitates more accessible creation of labeling functions without a loss in the quality of learned labeling  models.   Tagging or token level classification in text documents is another widely used task that can benefit from DPBD. Here we also briefly discuss our work in progress on \tagruler, a DPBD system that learns token labeling functions through user interaction to create training datasets for tagging models.     Tagging or span-level classification in text documents is another widely used task that can benefit from DPBD. Here we also briefly discuss our work in progress on \tagruler, a DPBD system that enables the interactive generation of token labeling functions in order to create labeled training data for tagging models.         On the other hand, \tagruler synthesizes token classification  rules based users.   In summary, we contribute  DPBD, a general data independent framework for learning labeling rules by interactive demonstration;  \system, an interactive system operationalizing our framework for document classification tasks; and  a comparative user study conducted with data scientists in performing real world tasks to evaluate \system and conventional data programming. We have made our research artifacts, including the \system code and demo, publicly available~   where to search for the images   Copyright \setcopyright{none} \acmConference[]{}{}        Submission ID.    Use this when submitting an article to a sponsored event. You'll    receive a unique submission ID from the organizers    of the event, and this ID should be used as the parameter to this command.   \acmSubmissionID{123-A56-BU3}        The majority of ACM publications use numbered citations and    references.  The command \citestyle{authoryear} switches to the    ""author year"" style.       If you are preparing content for an event    sponsored by ACM SIGGRAPH, you must use the ""author year"" style of    citations and references.    Uncommenting    the next command will enable that style.   \citestyle{acmauthoryear}        end of the preamble, start of the body of the document source.  Conference   \acmYear{1997}  \copyrightyear{2016}    \acmArticle{4}  \acmPrice{15.00}     These commands are optional   \acmBooktitle{Transactions of the ACM Woodstock conference}  \editor{Jennifer B. Sartor}  \editor{Theo D'Hondt}  \editor{Wolfgang De Meuter} \definecolor{tomato}{rgb}{1,0.2,0} \definecolor{turqoise}{rgb}{0.03, 0.91, 0.87} \definecolor{grey}{rgb}{0.4,0.4,0.4} \newif\ifnotes \notestrue \DeclareRobustCommand{\cagatay}[1]{\ifnotes{\small[{\c{C}a\u{g}atay:}{#1}]}\fi} \DeclareRobustCommand{\sara}[1]{\ifnotes{\small[{Sara:}{#1}]}\fi} \DeclareRobustCommand{\subhead}[1]{#1} \DeclareRobustCommand{\system}{\mbox{\sc Ruler}\xspace} \DeclareRobustCommand{\ruler}{\mbox{\sc Ruler}\xspace} \DeclareRobustCommand{\tagruler}{\mbox{\sc TagRuler}\xspace}  \DeclareRobustCommand{\snorkel}{\mbox{\sc Snorkel}\xspace} \DeclareRobustCommand{\babblelabble}{\mbox{\sc BabbleLabble}\xspace} \DeclareRobustCommand{\thenum}{ten\xspace} \newcommand{\eat}[1]{} \newcommand{\example}[1]{{\underline{Example:} #1\qed}} \newcommand{\stitle}[1]{\smallskip {#1}} \newcommand{\sstitle}[1]{\smallskip {\underline{#1}}} \DeclareRobustCommand{\subhead}[1]{#1}  \newcommand{\squishlist}{      }      \renewcommand{\shortauthors}{} \settopmatter{printacmref=false,printfolios=true,printccs=false}  \begin{document}  \title[]{Data Programming by Demonstration:\\A Framework for Interactively Learning Labeling Functions}  \author{Sara Evensen} \affiliation{    \institution{Megagon Labs} }   \email{} \author{Chang Ge} \authornote{Work done during internship at Megagon Labs.} \affiliation{    \institution{University of Waterloo} }   \email{} \author{Dongjin Choi} \authornotemark[1] \affiliation{   \institution{Georgia Tech} }   \email{} \author{\c{C}a\u{g}atay Demiralp} \affiliation{   \institution{Megagon Labs} }   \email{}    \renewcommand{\shortauthors}{B. Trovato et al.}    \renewcommand{\shortauthors}{Evensen et al.}      \keywords{}  \maketitle  \pagestyle{plain}                    
","     Training a deep neural network requires a large amount of single-task data and involves a long time-consuming optimization phase. This is not scalable to complex, realistic environments with new unexpected changes.      Humans can perform fast incremental learning on the fly and memory systems in the brain play a critical role.     We introduce Sparse Meta Networks -- a meta-learning approach to learn online sequential adaptation algorithms for deep neural networks, by using deep neural networks.      We augment a deep neural network with a layer-specific fast-weight memory. The fast-weights are generated sparsely at each time step and accumulated incrementally through time providing a useful inductive bias for online continual adaptation. We demonstrate strong performance on a variety of sequential adaptation scenarios, from a simple online reinforcement learning to a large scale adaptive language modelling.",122
"  The advent of open-source software and question and answering websites contributed for improving the way developers produce code. Nowadays, code search permeates the development activities. Developers can spend 15\% of their time searching online for how a piece of code works, how to fix a bug, and how to use an API . According to \citet{sadowski-how-developers-search-for-code-case-study:2015}, at Google, developers search for code 12 times a day, clicking on 2 to 3 results in average per search session.    Most developers use general-purpose search engines  to look for code , which uses page rank and other indexes tactics that are not optimized for searching code. Then, general-purpose search engines do not adequately find code snippets unless they have accompanying descriptions. According to \citet{masudur-developers-use-google-code-retrieval:2018}, developers spend more time, visit more pages, and change queries more often when they are doing code-related searches. In particular, newcomers to a project can greatly benefit from semantic search since they face a variety of entrance barriers .   GitHub, a popular source code hosting platform, has attempted to build a semantic code search. They extracted millions of lines of code from its repositories and matched each code snippet to a docstring. The final results were not satisfactory as the tool could find a relevant code snippet only if the user provided a query that matched the docstring description . According to \citet{cambronero-deep-code-search-2019}, users' intents were better matched to questions collected from question-answering sites related to programming, e.g., Stack Overflow. Those sites allow users to ask a question and approve the best answer for it. Other users vote for the most helpful answer and mark the wrong or not helpful ones. Those collective actions curate and organize information.  Initial code search studies were based on deductive-logic rules and manually extracted features . The recent success of artificial neural networks has shifted recent works to a machine learning-based approach. \citet{cambronero-deep-code-search-2019} coined a name, neural code search, i.e., code search based on neural networks.  Recent works applied neural networks to summarize and retrieve code snippets. \citet{cambronero-deep-code-search-2019} proposed a neural network with attention mechanism and \citet{Gu-deep-code-search:2018} presented a recurrent neural network. Our novel approach is based on Convolutional Neural Networks . For the best of our knowledge, CNNs have not yet been used to search for code, but have achieved good results in selecting answers . CNNs prioritize local interactions  and its translation invariant, which are important traits for our task.   In our study, we answer the following research questions:       The only universal learning algorithm that we are aware of is how humans learn. Human learning is robust and flexible -- it relies on causality, has an ability of fast and sequential adaptation and balances memory encoding and active forgetting, across a large number of familiar and unfamiliar scenarios. Meta-learning offers a promising computational paradigm to learn such a universal learning algorithm in a data-driven way.  In this work, we proposed a meta-learning approach to learn a sequential adaptation algorithm for arbitrary deep neural network architectures. Our approach performs sequential adaptation with a bounded compute and memory across changing environment and tasks. The proposed Online Cifar setup can serve as a useful benchmark for studying flexible models and algorithms that go beyond the fixed distribution regime.   In the current state of the Sparse-MetaNet method, a sparsity mask is sampled from a fixed distribution. A future work should explore learning-based approaches for a conditional mask distribution, so that a Sparse-MetaNet model can selectively encode a fast-weight memory from past gradients. The current work has a limited focus on the catastrophic interference issue in neural networks. A future work can extend the Sparse-MetaNet approach for mitigating this issue.  
"," Software developers routinely search for code using general-purpose search engines. However, these search engines cannot find code semantically unless it has an accompanying description. We propose a technique for semantic code search: A Convolutional Neural Network approach to code retrieval . Our technique aims to find the code snippet that most closely matches the developer's intent, expressed in natural language. We evaluated our approach's efficacy on a dataset composed of questions and code snippets collected from Stack Overflow. Our preliminary results showed that our technique, which prioritizes local interactions , improved the state-of-the-art  by 5\% on average, retrieving the most relevant code snippets in the top 3  positions by almost 80\% of the time. Therefore, our technique is promising and can improve the efficacy of semantic code retrieval.",123
" In recent years, deep learning methods have become the standard for solving information retrieval tasks. These methods can effectively map words and phrases to vector representations. These representations can facilitate better matching between phrases that have similar meanings. Phrases closer in meaning will be represented closer to each other in a vector space. In information retrieval, many ways to develop relevance scores have been used, such as counting word overlap between query and document. Recently, more complex machine learning models use human-verified datasets to train models to assign similarity scores used for rankings. Applying deep learning to Natural Language Processing problems has given rise to new approaches that can better represent a sentence閳ユ獨 meaning using neural networks. For instance, Long Short Term Memory models with an attention mechanism allow for word relationships to be constructed between different sentences and thus for words to be better placed in context, rather than just by examining the words closest to them. A breakthrough development in Natural Language Processing, the BERT architecture, extracts word and consequently sentence representations by masking words throughout a sentence and predicting the omitted words, using self-attention to encode the entire sentence at once. Within the BERT framework, the model can also be trained to predict the next sentence out of a few choices, given an input sentence. \\  Even with these advances, deep learning methods still struggle with some inherent difficulties in IR tasks. These challenges result from discrepancies in query and document vocabulary, limited size of data used for training, and weaknesses in a given human-generated query. In an effort to mitigate these effects, our team閳ユ獨 approach was inspired by an existing method, doc2query, which for a given input document uses a transformer model architecture to predict plausible queries leading to that document. Although it was shown that the expanded documents indeed allowed improved retrieval performance by a downstream ranking model, this approach requires that all documents in the collection of interest are first ``pre-indexed'' by feeding them as input to the transformer model, which is not practical. Instead, we propose a query2query method that takes a given query as input and generates several queries similar in meaning. The hope is to create a more powerful query by augmenting the generated queries and the given query into a single representation, which is used to match a desired passage. To complete our architecture, we then feed the expanded queries to a pre-trained BERT model which can predict similarity scores between queries and documents and produce a final ranking. The goal of our approach is to reduce surface form 閳ユ笜oise閳 within a certain query by generating other queries that ask for the same information, but in different ways. By having different representations of the 閳ユ笩ame閳 query, we hope to create more holistic queries and as a result obtain an end-to-end method which can generalize better and potentially reduce the problems which modern IR faces.       Our model, CoNCRA, achieved an MRR score 5\  higher on average than Unif, a state-of-the-art technique. We could rank the most relevant code snippet among the first 3  positions in 78\  of cases. Our technique achieved a TOP-1 accuracy of 60\ , while the other techniques achieved 50\ .   The results seem promising, and we plan further investigation to check if our model is invariant to other datasets. We will also investigate transfer learning, e.g., checking if a model trained on a Stack Overflow dataset  can find relevant code snippets in a GitHub corpus . Our approach is based on an NLP technique proposed by \citet{feng-2015}, and future work may use transformers and autoencoders, as those techniques showed good results in many NLP tasks.  
"," This paper describes Brown University's submission to the TREC 2019 Deep Learning track. We followed a 2-phase method for producing a ranking of passages for a given input query: In the the first phase, the user's query is expanded by appending 3 queries generated by a transformer model which was trained to rephrase an input query into semantically similar queries. The expanded query can exhibit greater similarity in surface form and vocabulary overlap with the passages of interest and can therefore serve as enriched input to any downstream information retrieval method. In the second phase, we use a BERT-based model pre-trained for language modeling but fine-tuned for query - document relevance prediction to compute relevance scores for a set of 1000 candidate passages per query and subsequently obtain a ranking of passages by sorting them based on the predicted relevance scores.  According to the results published in the official Overview of the TREC Deep Learning Track 2019, our team ranked 3rd in the passage retrieval task , and 2nd when considering only re-ranking submissions.",124
" % Background Collecting a sufficient amount of electronic health records is a challenging task with various factors . Due to this problem, researchers in the medical field are often provided with only a small amount of data given. Owing to the fact that deep learning techniques perform better on large amounts of data, a number of studies using machine learning techniques have been conducted to solve specific medical problems, regarding a limited number of data . Dementia is also one of many medical symptoms facing this situation.  % Alzheimer's Dementia Dementia, a syndrome in which there is deterioration in cognitive function beyond what might be expected from normal ageing, is mostly affected by Alzheimer閳ユ獨 Disease . % Although studies with Dementia also faces the problem with lacking dataset,  There were previous researches with various approaches to recognize Alzheimer's Dementia , which has shown excellent performance. % However, the dataset used in these works were more adequete with quantity than the one used in this paper. However, datasets used in these works were sufficient with quantity than the one used in this paper.  % The ADReSS challenge The ADReSS challenge  at INTERSPEECH 2020 hosts two tasks: Alzheimer閳ユ獨 Dementia  classification and Mini Mental Status Examination  regression, while providing a refined dataset. The dataset is equally balanced of AD and non-AD participants with the metadata of age and gender. % Each data is a conversation between a participant and an investigator composed of acoustic and textual information. % Each data is a conversation between a participant and an investigator where a participant spontaneously describes the picture given by an investigator. % Each data is a conversation where a participant spontaneously describes the picture given by an investigator with acoustic and textual modality. Each data is a conversation in which participants, in both audio and text modalities, spontaneously describes the picture given by the investigator. % proposing work Participants of the challenge are suggested to solve hosted tasks using only the given data, where the numbers of train and test data are 108 and 48, respectively.  For recognizing AD with small amounts of data, we determined it would be beneficial to use both acoustic and textual features. % why? % we thought it would be best to use as many information as possible for recognizing AD 闉氭帾鐓遍瀬婵庢簜鎼 姘氭棄闈栨棶? Furthermore, we leverage models pre-trained on large scale datasets as feature extractor to get better representation. To this end, this paper focus on exploiting various multi-modal features, and design suitable network architecture. % 闇嬨倢妫 闆﹥妲 闆尗姣勯湆 鑷ф粚娈 鑷у嫴鐏ラ爟姗佺煀 闈广倠鐛忛爟姗佽荡 We compare 3 and 4 different acoustic and textual features, respectively, and use the hand-crafted  feature and part-of-speech  tagging as additional inputs. The usage of POS and HC is influenced by previous research, which has approved that using these features gained from transcript can improve the performance . The proposed network is a modified version of Convolutional Recurrent Neural Network ; capable of computing conversations with variable lengths, and implemented with methods to fit with a small amount of data. Also, the model is able to compute using the acoustic feature only, without any metadata, which can be efficient considering the real-world situation. Our experimental results show using features of the pre-trained network leads to performance gain than that of raw, and regression results imply the potential of network classifying classes of cognitive impairment based on MMSE score.      This report describes Brown University's entry to the TREC 2019 Deep Learning Track, in which we produced the final ranking of a set of 1000 candidate passages for given queries. Our method aims at enriching the meaning and surface form of a query by expanding it with similar queries, in the hopes that during the subsequent ranking process, the expanded query would provide extra semantic information or vocabulary overlap that would facilitate the retrieval of more relevant documents. \\  We found this retrieval method to be promising in terms of retrieval results, albeit with significant margins for future improvement. A natural focus point of future work is improving the semantic similarity between generated queries and the original query. In this work, we simply use the top 3 output beams in terms of estimated log-likelihood. However, different metrics could be used to re-order and prioritize a larger number of generated outputs. In addition, further investigation can be carried out in terms of various ways of synthesizing the query information or condensing the documents' representation.  
"," % The ADReSS Challenge at INTERSPEECH 2020 regards to discern patients suspicious of Alzheimer闁炽儲鐛 Dementia by providing acoustic and textual data. Since the given training dataset only comprised of 108 conversations, leveraging pre-trained models is effective than fitting from scratch. Therefore, this paper aims to recognize Alzheimer闁炽儲鐛 Dementia by exploiting various multi-modal features from pre-trained networks. With the given dataset of conversational form, we modify a Convolutional Recurrent Neural Network based structure to compute input modalities. Our model performs classification and regression tasks simultaneously and is capable of computing conversations with variable lengths. For the classification task, the best test accuracy using only acoustic input is 72.92\%, while using both modality results in 81.25\%. For the regression task, we achieved an RMSE score of 3.7749 . Additionally, our 5-fold cross-validation result for the regression task shows the possibility of classifying 4 classes of cognitive impairment, categorized by the MMSE score, with an accuracy of 78.70\%.   %We use 5-fold cross-validation for measuring model performance. For the classification task, the best F1 score using only acoustic input is 86.28\%, while using both modality results in 94.54\%. For the regression task, the best RMSE score is 3.3493.   Collecting and accessing a large amount of medical data is very time-consuming and laborious, not only because it is difficult to find specific patients but also because it is required to resolve the confidentiality of a patient's medical records. On the other hand, there are deep learning models, trained on easily collectible, large scale datasets such as Youtube or Wikipedia, offering useful representations. It could therefore be very advantageous to utilize the features from these pre-trained networks for handling a small amount of data at hand. In this work, we exploit various multi-modal features extracted from pre-trained networks to recognize Alzheimer's Dementia using a neural network, with a small dataset provided by the ADReSS Challenge at INTERSPEECH 2020. The challenge regards to discern patients suspicious of Alzheimer闁炽儲鐛 Dementia by providing acoustic and textual data. % With the given dataset, we assess features extracted from the pre-trained networks using a neural network. With the multi-modal features, we modify a Convolutional Recurrent Neural Network based structure to perform classification and regression tasks simultaneously and is capable of computing conversations with variable lengths. % Our model performs classification and regression tasks simultaneously and is capable of computing conversations with variable lengths. % For the classification task, the best test accuracy using only acoustic input is 72.92\%, while using both modality results in 81.25\%. For the regression task, we achieved an RMSE score of 3.7749 . Additionally, our 5-fold cross-validation result for the regression task shows the possibility of classifying 4 classes of cognitive impairment, categorized by the MMSE score, with an accuracy of 78.70\%. Our test results surpass baseline's accuracy by 18.75\%, and our validation result for the regression task shows the possibility of classifying 4 classes of cognitive impairment with an accuracy of 78.70\%.",125
"   Transformer  is one of the state-of-the-art approaches for Neural Machine Translation , and hence, being widely accepted. For example, in WMT19 machine translation tasks, it is reported that 80\% of submitted systems have adopted the Transformer architecture . Note that high translation quality of Transformer models entails a large number of parameters. Moreover, the Transformer model is inherently much slower than conventional machine translation approaches  mainly due to the auto-regressive inference scheme  incrementally generating each token. As a result, deploying the Transformer model to mobile devices with limited resources involves numerous practical implementation issues.  To address such implementation challenges with little degradation in translation quality, we study a low-bit quantization strategy for Transformer to accomplish high-performance on-device NMT. We note that most previous studies to compress Transformer models utilize uniform quantization . While uniform quantization may be effective for memory footprint savings, it would face various issues to improve inference time and to maintain reasonable BLEU score. For example, even integer arithmetic units for inference operations present limited speed up  and resulting BLEU score of quantized Transformer can be substantially degraded with low-bit quantization such as INT4 .  While determining the number of quantization bits for Transformer, it is crucial to consider that each component of Transformer may exhibit varied sensitivity of quantization error toward degradation in translation quality . Accordingly, a mixed precision quantization can be suggested as an effort to assign different numbers of quantization bits depending on how each component after quantization is sensitive to the loss function. In addition, as we illustrate later, even assigning different quantization bits for each row of an embedding block can further reduce the overall number of quantization bits of the entire Transformer model. Our proposed quantization strategy, thus, provides a finer-grained mixed precision approach compared to previous methods, such as  that consider layer-wise or matrix-wise mixed precision.  % One important aspect is that each block in Transformer contributes to the inference computation and the translation accuracy differently. Transformer consists of three major blocks: embedding, encoder, and decoder. The embedding block has a huge number of parameters due to its dependence on the vocabulary size, easily in scale of tens of thousands. On the contrary, the matrices in encoder and decoder are relatively small since they are independent of the vocabulary size.  As a result, embedding block causes a major memory and latency consumption. Since the decoding steps are not parallelizable at inference time, it also contributes largely to the inference computation.  % In consideration of these, we propose a mixed precision quantization strategy for Transformer quantization with efficient inference computation and reasonable accuracy loss. Accommodating distinguished implementation properties  of each component in Transformer, we propose the following methodologies to decide precision of a block: 1) in the case of embedding block, statistical importance of each word is taken into account and 2) for encoder and decoder blocks, sensitivity of each quantized sub-layer is considered. The main contributions of this paper are as follows:         For the classification task, the best test accuracy using only acoustic input is 72.92\ , while using both modality results in 81.25\ . For the regression task, we achieved an RMSE score of 3.7749 . Additionally, our 5-fold cross-validation result for the regression task shows the possibility of classifying 4 classes of cognitive impairment, categorized by the MMSE score, with an accuracy of 78.70\ .  This paper demonstrates extracted features from pre-trained networks are satisfactory for handling small amounts of data, to recognize Alzheimer's Dementia. The proposed model can compute variable lengths of dialogue and also introduce productive methods to fit the network with a little amount of data. Furthermore, our model does not require any metadata and also can perform well without transcript, which may be practical in real-world situations. Our test result outperforms baseline's with both tasks, and our regression results imply the potential of network classifying classes of cognitive impairment based on the MMSE score.    validation 闆碱煃纭犻瀽鎰冲妧 unimodal鎼 鑷 modality闉 闆介爟 鐡寸摚鑷ｆ post 鐡撮灊鏇ф殔 鐡寸摚鑷, audio闉愭劤鍔闆 姣电儎绋婄摽 text闉愭劤鍔闆 闊规顒呯, 鏀 姘氭﹤瀵戦灇 鐡村眾姣庤嚙 闉涘牗妫冮浖. 闉氭帾銈 鐡跨娊鐗戦爠鍫ㄦ綁 闇 bimodal network鑷 闇 modality姣 merge 闋冩﹤鈹愰澒 闉庡牗顣伴灇 鏀垫數鍕虫綁 姘氬姙鐏涢爟姗冾潊 闉庡﹫纰 闇呮﹤鐗 闋冩瑬濮烽爟姗冩３ 闈瑰姜濮 闉濋爟姗佺殰 闉涘牗妫冮浖銈婄 鏂兼棈娴爟 闈 闉涘牕濮呴浛, 闉氭帾銈 姘氣晥顫呴爟姗傚 姘囶煄宓 鐢戭剣鈥滄 future work闉欒導顢 姝嗗嫶鏋嗛爟 闈 闉涘牗娼 鐡村喒婢婇浖. 闇涚紕纰 闉濅緟鏌庢挨 闈 闉涘牗娼 闇    VGGish & Transformer-XL   VGGish wrong - 18   Transformer-XL wrong - 5    bimodial wrong - 9     future work to improve multi-modal network   Some modifications in the model architecture can be done to merge different modalities with beneficial effects on each other as future work. There were validation samples with no overlapping error results of the unimodal network of each modality, where the bimodal network using the same modality features above was able to reach the accurate answer for these typical samples. Yet, some samples that the unimodal networks could deduce correctly were wrong by the bimodal network. Accordingly, mechanisms effectively fusioning divergent features can be applied in expectation of performance gain  .    For future work, some modifications in the model architecture can be done to merge different modalities with mechanisms effectively fusioning divergent features can be applied in expectation of performance gain  .  For future work, with the expectation of performance gain, mechanisms effectively fusioning different modality features   can be applied in the model architecture.        Acknowledgements 
","  The deployment of widely used Transformer architecture is challenging because of heavy computation load and memory overhead during inference, especially when the target device is limited in computational resources such as mobile or edge devices. Quantization is an effective technique to address such challenges. Our analysis shows that for a given number of quantization bits, each block of Transformer contributes to translation quality and inference computations in different manners. Moreover, even inside an embedding block, each word presents vastly different contributions. Correspondingly, we propose a mixed precision quantization strategy to represent Transformer weights by an extremely low number of bits . For example, for each word in an embedding block, we assign different quantization bits based on statistical property. Our quantized Transformer model achieves 11.8$\times$ smaller model size than the baseline model, with less than -0.5 BLEU. We achieve 8.3$\times$ reduction in run-time memory footprints and 3.5$\times$ speed up  such that our proposed compression strategy enables efficient implementation for on-device NMT.",126
" The rapid progression of generative models in both computer vision  and natural language processing  has led to the increasing likelihood of realistic-looking news articles generated by Artificial Intelligence . The malicious use of such technology could present a major societal problem. \citet{zellers2019defending} report that humans are easily deceived by its AI-generated propaganda. By manipulating such technology, adversaries would be able to disseminate large amounts of online disinformation rapidly. While it is promising that the pretrained generative models themselves are our best defense , it is often challenging to be aware of the models utilized by adversaries beforehand. More importantly, it ignores the fact that news articles are often accompanied by images with captions .   %We argue that such visual context provides vital clues for discriminating against machine-generated articles.    In this paper, we present the first line of defence against neural fake news with images and captions. To the best of our knowledge, we are the first to address this challenging and realistic problem. Premised on the assumption that the adversarial text generator is unknown beforehand, we propose to evaluate articles based on the semantic consistency between the linguistic and visual components. While state-of-the-art approaches in bidirectional image-sentence retrieval  have leveraged visual-semantic consistency to great success on standard datasets such as MSCOCO  and Flickr30K , we show in Appendix they are not able to reason effectively about objects in an image and named entities present in the caption or article body. This is due to discrepancies in the distribution of these datasets, as captions in the standard datasets usually contain general terms including woman or dog as opposed to named entities such as Mrs Betram and a Golden Retriever, which are commonly contained in news article captions. Moreover, images are often not directly related to the articles they are associated with. For example, in Figure , the article contains mentions of the British Prime Minister. Yet, it only contains an image of the United Kingdom flag.   To circumvent this problem, we present DIDAN, a simple yet surprisingly effective approach which exploits possible semantic inconsistencies between the text and image/captions to detect machine-generated articles. For example, notice that the article and caption in Fig. actually mention different Prime Ministers. Besides evaluating the semantic relevance of images and captions to the article, DIDAN also exploits the co-occurrences of named entities in the article and captions to determine the authenticity score. The authenticity score can be thought of as the probability that an article is human-generated. We adopt a learning paradigm commonly used in image-sentence retrieval where models are trained to reason about dissimilarities between images and non-matching captions. In this instance, negative samples constitute articles and non-corresponding image-caption pairs. Not only is this a reasonable approach when the adversarial generative model is unknown, we show empirically that it is crucial to detecting machine-generated articles with high confidence even with access to machine-generated samples during training. More importantly, this means that DIDAN is easily trained on the abundance of online news articles without additional costly annotations.  To study this threat, we construct the NeuralNews dataset which contains both human and machine-generated articles. These articles contain a title, the main body as well as images and captions. The human-generated articles are sourced from the GoodNews  dataset. Using the same titles and main article bodies as context, we use GROVER  to generate articles. Instead of using GAN-generated images which are easy to detect even without exposure to them during training time , we consider the much harder setting where the articles are completed with the original images. We include both real and generated captions which are generated with the SOTA entity-aware image captioning model . We present results and findings from a series of empirical as well as user study experiments. In the user study experiments, we use 4 types of articles including real and generated news to determine what humans are most susceptible to. The insights derived from these findings help identify the possible weaknesses that adversaries can exploit to produce neural fake news and serve as a valuable reference for defending against this threat. Last but not least, our experimental results provide a competitive baseline for future research in this area.  In summary,  our contributions are multi-fold:        In this work, we analyze each block and sub-layer of the Transformer and propose an extremely low-bit quantization strategy for Transformer architecture. Our 2.6-bit quantized Transformer model achieves 11.8 model compression ratio with reasonable -0.5 BLEU. We also achieve the compression ratio of 8.3 in memory footprints and 3.5 speed up on a mobile device .       \clearpage   
"," Large-scale dissemination of disinformation online intended to mislead or deceive the general population is a major societal problem. Rapid progression in image, video, and natural language generative models has only exacerbated this situation and intensified our need for an effective defense mechanism. While existing approaches have been proposed to defend against neural fake news, they are generally constrained to the very limited setting where articles only have text and metadata such as the title and authors. In this paper, we introduce the more realistic and challenging task of defending against machine-generated news that also includes images and captions. To identify the possible weaknesses that adversaries can exploit, we create a NeuralNews dataset composed of 4 different types of generated articles as well as conduct a series of human user study experiments based on this dataset. In addition to the valuable insights gleaned from our user study experiments, we provide a relatively effective approach based on detecting visual-semantic inconsistencies, which will serve as an effective first line of defense and a useful reference for future work in defending against machine-generated disinformation.",127
" As neural networks are being adopted to solve real-world problems, while some parts of the network may be easy to develop, other unknown aspects such as hyperparameters, have no clear method of derivation. Ongoing research focuses on developing new network architectures and training methods. When developing neural networks, the question at hand is how to set the hyperparameter values to maximize results and set the training configuration. For network architecture design, important hyperparameters include the type of network, the number of layers, the number of units per layer, and unit type. For training configurations, important hyperparameters include learning algorithm, learning rate, and dropout ratio. All these hyperparameters interact with each other and affect the performance of neural networks. This interaction between hyperparameters can be referred to as epistasis. Thus they need to be tuned simultaneously to get optimum results.\\  The motivation behind this research is to replace tedious manual tuning of hyperparameters with an automatic method performed by computers. Current methods of optimization are limited to trivial methods like Grid search. Grid search is a simple method for hyperparameter optimization. However, as the number of hyperparameters increases, Grid search becomes time consuming and computationally taxing. This is because the number of lattice points increases in an exponential way with an increase in the number of hyperparameters . For example, if there are ten hyperparameters to be tuned and we only try five values for each parameter, and this alone requires more than 9 Million evaluations: . For this reason, the grid search is not feasible for certain applications. To solve this, we look to a GA for a higher-performing and less computationally taxing solution. The use of a GA for neural network hyperparameter optimization has been explored previously in . \\   We present an empirical study of GAs for neural network models in machine translation of natural language specifically Japanese to English. We describe the experiment setup in Section 2, our GA method in Section 3,  and results in Section 4. The preliminary findings suggest that a simple GA encoding has the potential to find optimum network architectures compared to a random search baseline.    In this paper, we define a new task, full-line code completion, and studied the performance of neural language models on this task. Apart from token-based and BPE-based approaches, which have already been evaluated on token-level code completion tasks, we additional conduct experiments with ASDL syntax-based models. Our experiments show that Transformer language model on token sequences currently performs best on our datasets.  In the future, we plan to further improve the effectiveness of language models on full-line code completion by training on more data and using models with larger parameter size. Meanwhile, we aim to utilize more powerful software analyzing tools to further narrow down the output space of our model, e.g., adding restrictions on variable names and API usage. Furthermore, we would like to improve our neural model to incorporate syntax structures like parent-child links in ASTs and incorporate BPE or copy mechanism to tackle the out-of-vocabulary problem.  \bigskip  
","  With neural networks having demonstrated their versatility and benefits, the need for their optimal performance is as prevalent as ever. A defining characteristic, hyperparameters, can greatly affect its performance. Thus engineers go through a process, tuning, to identify and implement optimal hyperparameters. That being said, excess amounts of manual effort are required for tuning network architectures, training configurations, and preprocessing settings such as Byte Pair Encoding . In this study, we propose an automatic tuning method modeled after Darwin's Survival of the Fittest Theory via a Genetic Algorithm . Research results show that the proposed method, a GA, outperforms a random selection of hyperparameters.",128
"  In the past few decades, knowledge graph construction and applications have been rapidly developed and achieved significant outcomes.  For better relevancy in web search, Google has been leveraging knowledge graph that represents real-world entities and their relationships to one another since 2012. %, there are also a large amount of publicly available knowledge graphs, such as freebase, Dbpedia, YAGO that have been constructed and used to many real-world intelligent applications. To identify those entities from text, named entity recognition  techniques have been extensively studied and applied in many areas  including e-commerce search . Such NER systems usually work with a well defined ontology to classify tokens in a sequence of words . A comprehensive and domain-specific PT ontology is beneficial to product search and discovery in an e-commerce platform . At The Home Depot , PT ontology has been used tremendously by the online search to improve query understanding and product retrieval. For example, Figure  shows a snippet of our PT ontology that consists of known PT classes. The PTs in the ontology serve as the entity reference for the NER task  as well as the classes for SKU-PT mapping  on the catalog side that facilitates the retrieval of relevant products.  %. Kutiyanawala et al. also proposed an product ontology framework created specially for e-commerce search and retrieval .  %comprehensive and domain-specific Ontology is required in order to better understand customers閳 intent and account for the expanding catalog. The Ontology enrichment has been proved effective to boost search relevancy. For example, given the customer query ""shower curtain hook"", the system would also return some ""shower curtain"" products since it failed to infer the proper product type due to the lack of knowledge. By introducing a new product type ""shower curtain hook"", the system is able to remove the noise and provide more relevant results. %  % \end{equation*}  %     \[ %   z = \overbrace[1pt][5pt]{ge}^{brand}\ \overbrace{7.3\:cu\:ft}^{dim} \quad\overbrace{dryer}^{product}\quad\overbrace{gas}^{attribute} %   \] %In the domain of e-commerce, a strong and well-structured knowledge graph also plays pivotal roles for both business to business  communications and customer search and navigation experience.   %A structured and standardized product ontology which define product description, catalog formats and business documents support electric data exchange between vendors and buyers.  %The Home Depot  is a world leading home improvement retailer for customers and business. Orange Graph  is the repository and access point for THD domain-specific knowledge, which includes rich product information, project information and their relationships. By adopting well-structured knowledge graph, a high-level of search quality, project-based buying features, marketing and customer services can be offered at THD e-commerce and enterprise systems.  % } %  %  % \end{table} Discovering valid PTs is a key task to build or expand a PT ontology with a fundamental challenge regarding the definition of a PT. % given it's a concept instead of fact. A PT can be defined from the demand side as atomic keywords/phrase that describes what customers look for  or from the supply side as a semantic tag/label that uniquely identifies a product. Within THD, we also have practical guidelines to distinguish between valid and invalid PTs like  %Product type  is an essential component of a PT ontology.  %it is widely used in e-commerce domain to group the similar products together. For instance, consider Appliances category, our goal is to discover distinct types of refrigerators which in this case it could be: ""Side By Side"", ""French Door"", etc.  %Although there are different definitions for a valid PT, In this paper, we define a valid PT as a leaf-level description of an entity.   no common attributes like color, brand, material, style etc in PTs  and  it requires significant differences in the form, functionality or usage location to make a new PT comparing to existing ones . %Another determiner for whether adding a token to a product type makes it a new product type  is if the addition of the new token changes the form, function or usage location. In our example, cordless doesn't change it for drill, while utility does for sink.   Obviously, neither the definition is definite nor the guidelines are exhaustive enough and there are always complicated cases and exceptions in which human judgement based on knowledge in merchandising, customer preference or just common sense is required. %without involving human knowledge which is usually expensive in term of time and monetary cost. %automatically determine if a candidate .  %Although aforementioned definition would generally help to distinguish between valid and invalid PTs, there are several challenges in this task  %as depicted in Table.  %First and foremost, it is crucial to determine a right level of granularity for discovered PTs. Very generic PTs are generally ambiguous as they could be attributable to a broad set of products with different use cases. For example, PT chairs can be ambiguous as it can comprise outdoor chairs, office chairs, dining chairs and each of these chairs types has a different usage location. %Specifically, domain experts have great advantage in  For example, a generic PT range can be broken down into more granular ones by fuel type like gas range, electric range or by other attribute like induction range, convention range. The word ""wood"" is material in wood rolling pin while is about usage in wood glue.   % Moreover, it is often subjective to determine in what level of granularity PT discovery should be stopped and based on what criteria a generic PT should be broken down into more granular PTs. For instance, given a generic PT ranges we can break it down by fuel type  or features . In this example, we can consider one of them as the PT and the other one as an attribute; alternatively they can be combined and construct a more granular PT.  % Another challenge is to automatically identify if a token in a PT is an attribute or not. As an example, consider wood rolling pin and wood glue; token wood in the latter change the use case of the glue, while in the former is a material.     However, leveraging human knowledge in large scale problems is usually timely and expensive.  To reduce such cost, this paper proposes  %The main contribution of this paper is as follows: proposing  an active learning framework that minimizes human effort in PT discovery by 1) identifying high quality candidates using phrase mining and user behavior. 2) limiting number of PT candidates for human validation.  %%%%%%%    This work introduces an advanced GA for hyperparameter optimization and applies it to machine translation optimization. We demonstrate that optimization of hyperparameters via a GA can outperform a random selection of hyperparameters. Specifically, outperform is defined by the ability of the algorithm to arrive at the goal with less individuals added. Finally, we propose future research directions which are expected to provide additional gains in the efficacy of GAs.  
"," Entity-based semantic search has been widely adopted in modern search engines to improve search accuracy by understanding users' intent. %behind the search terms.  %In e-commerce domain, product type  is a central concept in intent understanding as well as catalog organization. %indicating customers' intent in their search queries.  %be identified from customers' queries for understanding  In e-commerce, an accurate and complete product type  ontology is essential for recognizing product entities in queries and retrieving relevant products from catalog.  However, finding product types  to construct such an ontology is usually expensive due to the considerable amount of human efforts it may involve.  In this work, we propose an active learning framework that efficiently utilizes domain experts' knowledge for PT discovery.  We also show the quality and coverage of the resulting PTs in the experiment results.",129
" Distributional word representations trained on large-scale corpora are widely used in modern natural language processing  systems, which aims to describe the meaning of words and sentences with vectorized representations . Recent studies  addressed the state-of-the-art word embedding performance on various NLP tasks, where start to focus on how to evaluate the performance between different word embeddings accurately. However, \citet{Tsvetkov15} and \citet{Chiu16} have demonstrated that even for the same word embedding, most of the existing evaluation methods do not provide the constantly correlative results between intrinsic evaluation and extrinsic evaluation. Therefore, evaluating the performance of word embeddings with a unified metric is challenging in NLP tasks.  \citet{Hollenstein19} proposed a new evaluation framework called CogniVal, which applied traditional neural networks for regression and considered both intrinsic and extrinsic measurements based on collected human natural language processing-related cognitive data sources across three modalities: electroencephalography , functional magnetic resonance imaging , and eye-tracking. CogniVal is potentially identified as a pioneer of multi-modal cognitive word embedding evaluation framework, which conducts vectorized word embeddings evaluation by predicting how much they reflect the semantic representations against cognitive data sources that recorded when human processing natural language.   However, CogniVal framework ignored to measure some characteristics of human physiological signals. Specifically, all three modalities  of cognitive data used in their experiment featuring with non-stationary and non-linear motions . Inspired by \citet{Zekri08,Bodyanskiy13}, we assume that neural networks and fuzzy systems as computational intelligence methods are suitable tools for modelling expert knowledge and dealing with uncertain non-linear processes or non-stationary time series in a dynamic system, because approximate reasoning characteristics of fuzzy systems could present a practical model to handle uncertainty and disturbances in real data for complex hybrid non-linear or non-stationary problems . For this reason, we proposed a fuzzy-based neural network  framework for evaluating word embeddings with cognitive datasets, name CogniFNN, which expects to enhance the quality of evaluating the performance of word embeddings with cognitive data sources , and achieve a higher ratio of significant results with random word embeddings as well.   \paragraph{Contributions} The main contributions of our study are shown as follows:        In this work, we propose an active learning framework for product type discovery that leverage domain expertise in an efficient way.  The effectiveness of the framework is demonstrated by the quality and coverage of the resulting product types in the experiments as well as the positive business impact.  Experiment results also show that training data denoising is significantly beneficial to method performance. There are two kinds of future work including: 1) Feature engineering of PT classifier by exploiting more textual and/or image data 2) Design a denoise procedure and add it as an additional component into the framework.       
"," Word embeddings can reflect the semantic representations, and the embedding qualities can be comprehensively evaluated with human natural reading-related cognitive data sources. In this paper, we proposed the CogniFNN framework, which is the first attempt at using fuzzy neural networks to extract non-linear and non-stationary characteristics for evaluations of English word embeddings against the corresponding cognitive datasets. In our experiment, we used 15 human cognitive datasets across three modalities: EEG, fMRI, and eye-tracking, and selected the mean square error and multiple hypotheses testing as metrics to evaluate our proposed CogniFNN framework. Compared to the recent pioneer framework, our proposed CogniFNN showed smaller prediction errors of both context-independent  and context-sensitive  word embeddings, and achieved higher significant ratios with randomly generated word embeddings. Our findings suggested that the CogniFNN framework could provide a more accurate and comprehensive evaluation of cognitive word embeddings. It will potentially be beneficial to the further word embeddings evaluation on extrinsic natural language processing tasks.",130
" 	 	 	Reinforcement Learning~ methods are increasingly being used for solving sequential decision-making problems from natural language inputs, like text-based games chat-bots and personal conversation assistants. In this work, we focus on Text-Based Games~, which require solving goals like ``Obtain coin from the kitchen'', based on a natural language description of the agent's observation of the environment. To interact with the environment, the agent issues text-based action commands~ upon which it receives a reward signal used for training the RL agent. 	 	 	 	 	 	 	 	% generalization problem 	Traditional text-based RL methods focus on the problems of partial observability and large action spaces. However, the topic of generalization to unseen TBGs is less explored in the literature.  We show that previous RL methods for TBGs often show poor generalization to unseen test games. We hypothesize that such overfitting is caused due to the presence of irrelevant tokens in the observation text, which might lead to action memorization. 	% ~(eg. every time agent.  	To alleviate this problem, we propose CREST, which first trains an overfitted base model on the original observation text in training games using Q-learning. Subsequently, we apply observation pruning such that, for each episode of the training games, we remove the observation tokens that are not semantically related to the base policy's action tokens. Finally, we re-train a bootstrapped policy on the pruned observation text using Q-learning that improves generalization by removing irrelevant tokens. Figure shows an illustrative example of our method. Experimental results on TextWorld games show that our proposed method generalizes to unseen games using almost x-x fewer training games compared to SOTA methods; and features significantly faster learning. 	 	 	 	 	  In this paper, we proposed a CogniFNN framework using fuzzy-based neural networks to explore the non-linear and non-stationary characteristics of physiological signals for improving the evaluation performance of word embeddings against cognitive datasets which recorded when subjects were understanding natural language . Our findings showed that CogniFNN achieved smaller prediction errors and higher significant ratios on both context-independent  and context-sensitive  word embeddings against 15 cognitive data sources across EEG, fMRI and eye-tracking. Our contributions could be a useful evaluation strategy which is beneficial to the exhaustive investigation on word embedding evaluations with corresponding cognitive features.         
"," 		We show that Reinforcement Learning~ methods for solving Text-Based Games~ often fail to generalize on unseen games, especially in small data regimes. To address this issue, we propose Context Relevant Episodic State Truncation~ for irrelevant token removal in observation text for improved generalization. Our method first trains a base model using Q-learning, which typically overfits the training games. The base model's action token distribution is used to perform observation pruning that removes irrelevant tokens. A second bootstrapped model is then retrained on the pruned observation text. Our bootstrapped agent shows improved generalization in solving unseen TextWorld games, using $10$x-$20$x fewer training games compared to previous state-of-the-art~ methods despite requiring less number of training episodes.",131
" As a key step in constructing a knowledge graph, relation extraction is a task to extract the relation between the entities expressed in a sentence.  Previous work has largely focused on intra-sentence binary relation extraction, where the goal is to extract the relation between an entity pair in the sentence.   However, some relations require more than two entities and may span multiple sentences, which is defined as n-ary cross-sentence relation extraction. As the example shown in Table, the relation ``educate'' includes four entities, the person's ""name``, ""academic degree``, ""academic major`` and ""school``. In addition, this relation spans in four sentences in the example. Some prior works have applied a supervised learning approach to tackle this task, but they require large-scale labeled training data.  \end{table}  To obtain large-scale annotated data, some work assumes that if the consecutive sentences  contain the entities that have a relation in a knowledge base, these sentences as a whole describe that relation.  This assumption is referred to as distant supervision in the n-ary cross-sentence relation extraction task.  Even though methods based on distant supervision can quickly annotate sentences, they still have two main limitations: 1) they suffer from a noisy labeling problem;  2) the strong distant supervision assumption does not consider the non-consecutive sentences, which reduces the generalizability of the trained model. As the example shown in Table, the sentences at the 18th and 20th positions describe the fact but are not labeled using distant supervision because they are not consecutive. The first sentence is incorrectly labeled and is a noisy labeled data, which describes Alan Turing's work instead of his education.  To address the first limitation, we propose to train a sentence distribution estimator , which is a two-level agent reinforcement learning model. This provides a well-trained model that can select the high-quality labeled sentence groups and alleviate the impact of noisy data. There are previous works on applying reinforcement learning  to remove binary intra-sentence noisy data and achieve state-of-the-art  performance. When applying RL for n-ary cross-sentence relation extraction, a key challenge is that the RL model should not only learn sentence features, but also know the context and relation between each sentence. In this paper, the process of selecting sentences is not only influenced by the feature of the sentence itself, but also by the indicators we defined , which measure the semantic relationship between sentences. Moreover, whether a sentence is selected in a state or not is going to affect the decision of the next state. This state transition property provides the ability to choose the best combination of sentences in each sentence group.  To address the second limitation,  we relax the strong distant supervision assumption that lies at the heart of prior work by replacing it with a weaker distant supervision assumption. The assumption is that the sentence that has at least one main entity or two supplementary entities is annotated with the relation of these entities. We follow the Wikidata Knowledge Base scheme, where the main entity is the ``value'' of each fact and the supplementary entity is the ``qualifer'' of each fact. This assumption introduces some non-consecutive sentences and we propose a novel universal relation extractor to encode both consecutive and non-consecutive sentence groups. This relation extractor has a self-attention and soft attention mechanism layer, which compares the similarity between the word-level features and the relation query vectors. The relation extractor also encodes each sentence via a Piece-wise Convolution Neural Network  layer. The PCNN output is used to learn how the information transforms through sentences via a non-linear transformation layer.    	 	 	We present a method for improving generalization in TBGs using irrelevant token removal from observation texts. Our bootstrapped model trained on the salient observation tokens obtains generalization performance similar to SOTA methods, with x-x fewer training games, due to better generalization; and shows accelerated convergence.  	In this paper, we have restricted our analysis to TBGs that feature similar domain distributions in training and test games. In the future, we wish to handle the topic of generalization in the presence of domain differences such as novel objects, and goal statements in test games that were not seen in training. 	  	 	 	 	 	 	 	 	 	 	
"," The models of n-ary cross sentence relation extraction based on distant supervision assume that consecutive sentences mentioning $n$ entities describe the relation of these $n$ entities. However, on one hand, this assumption introduces noisy labeled data and harms the models' performance. On the other hand, some non-consecutive sentences also describe one relation and these sentences cannot be labeled under this assumption. In this paper, we relax this strong assumption by a weaker distant supervision assumption to address the second issue and propose a novel sentence distribution estimator model to address the first problem. This estimator selects correctly labeled sentences to alleviate the effect of noisy data is a two-level agent reinforcement learning model. In addition, a novel universal relation extractor with a hybrid approach of attention mechanism and PCNN is proposed such that it can be deployed in any tasks, including consecutive and non-consecutive sentences. Experiments demonstrate that the proposed model can reduce the impact of noisy data and achieve better performance on general n-ary cross sentence relation extraction task compared to baseline models.",132
" Healthcare information systems store huge volumes of electronic health records  that contain detailed visit information about patients over a period of time. The data is structured in three levels from top to bottom: the patient journey, the individual visit and the medical code. Fig. provides a typical example of this structure. An anonymous patient visits his/her doctor, a pathology lab and is admitted to the hospital on different days. The procedures and diagnoses performed at each of these visits are recorded as industry-standard medical codes. Each medical code, i.e. International Classification of Diseases  and Current Procedure Terminology , at the lowest level, records an independent observation while the set of codes at a higher level can depict the medical conditions of a patient at a given time point. At the top level, all occurrences of medical events at different time-stamps are chained together as a patient journey, which offers more informative details. Predicting sequential medical outcomes based on a patient's journey, such as hospital re-admissions and diagnoses, is a core research task that significantly benefits for healthcare management by hospitals and governments. For example, re-admission statistics could be used to measure the quality of care; Diagnoses can be used to understand more fully a patient's problems and relevant medical research. However, researchers have encountered many challenges in their attempts to represent patient journeys and predict medical outcomes from EHR data with the characteristics of temporality, high-dimensionality and irregularity.   Recurrent neural networks  have been widely used to analyze sequential data, unsurprisingly including medical events modelling for clinical prediction. For example, Choi et al. proposed a multi-level representation learning, which integrates visits and medical concepts based on visit sequences and the co-occurrence of medical concepts. They indirectly exploited an RNN to embed the visit sequences into a patient representation for downstream prediction tasks. Some other research works directly employed RNNs to model time-ordered patient visits for predicting diagnoses.  However, when the length of the patient visit sequence grows, such RNN-based models are restricted by the less expressive power of RNNs, such as vanishing gradient and forgetfulness.  However, such RNN-based models are constrained by forgetfulness, i.e., their predictive power drops significantly when the sequence of patient visits grows too long.  To memorize historical records, LSTM and GRU have been developed to utilize memory and gate mechanism for mitigating these issues.  To go further, Song et al. proposed to utilise attention mechanism in a deep framework to model sequential medical events.  It is worth noting that sequences of medical events are often found to be lengthy, especially when a patient suffers from chronic disease. Hence, due to the restricted ability of RNNs for long-term dependency modeling , the traditional RNNs, even with memory cells and gates, usually underperform in the cases of a long sequence of medical events. In light of this, a neural model that can overcome the performance bottleneck of RNN-based models is particularly desirable for medical predictions based on longitudinal EHR data.   %%%%%%%%  WHAT THE RELATION BETWEEN SHEN2018DISAN AND THIS ONE?? in a Directional self-attention networks can alleviate long sequence problems to improve the accuracy of predictions, as these models can be trained on all available input information - past and future.. CAN WE COME TO THE CONCLUSION: ONE OF CONTRIBUTION IS WE HAVE FULLY CONSIDERED ALL MEDICAL EVENTS COMPARING TO OTHER WORKS THAT CAN ONLY PARTIALLY CONSIDER.  % Recently, attention mechanism has been integrated into RNNs to model sequential EHRs data, which achieves good prediction accuracy. Although the attention-based RNNs relatively improves the prediction performance, the limitations of RNNs weaken the advantage of attention mechanism. In natural language processing , a sole attention mechanism has been used to construct a sequence to sequence model that achieves a state-of-the-art quality score on the neural machine translation  task. The attention mechanism has more flexibility in sequence length than RNN, and is more task/data-driven when modeling dependencies. Unlike sequential models, its computation can be easily and significantly accelerated by existing distributed/parallel computing schemes. However, to the best of our knowledge, a neural net entirely based on attention has not been designed for patient journey in EHRs data.  Most recently, attention mechanisms have sprung to the fore as effective integrations with RNNs for modeling sequential EHR data. So far, these approaches have shown satisfactory prediction accuracy, but some argue that the power of attention in an RNN is limited by weaknesses in the RNN itself . In particular, Vaswani et al. used a sole attention mechanism, i.e., multi-head attention and self-attention, to construct a sequence-to-sequence model for neural machine translation tasks and achieved a state-of-the-art quality score. And according to  Shen et al., self-attention mechanism allows for more flexibility in sequence lengths than RNNs and is more task/data-driven when modeling contextual dependencies. Unlike recurrent models, attention procedure is easy to compute and the computation can also be significantly accelerated with distributed/parallel computing schemes.  For example, Song et al. proposed to employ 1D CNN  to model local context and use attention mechanism  to capture long-term dependency for sequential medical events.  However, when applied to EHR data instead of regular sequential data , the current attention models cannot appropriately deal with some aspects of EHR data, such as arbitrary time-stamps and hierarchical data format.  Hence, to the best of our knowledge, a neural network-based entirely on attention has never been designed for analytics with EHR data.   To bridge the gap in this literature and address some of the open issues listed above, we propose a novel attention mechanism called Masked Encoder  for temporal context fusion. It uses self-attention to capture contextual information and temporal dependencies between a patient's visits.  Then, we propose an end-to-end neural network, called Bidirectional temporal encoder Network , to predict medical outcomes by leveraging a learned representation of the patient journey,  where the representation is generated solely by the proposed attention mechanism, MasEnc. BiteNet constructs a multi-level self-attention network to represent visits and patient journeys simultaneously, using attention pooling and stacked MasEnc layers. It is worth noting that, compared to the existed RNN-based methods, BiteNet can yield better prediction performance for long sequences of medical records.   Experiments conducted on two supervised prediction and two unsupervised clustering tasks with real-world EHR datasets demonstrate that the proposed BiteNet model is superior to prior state-of-the-art baseline methods.   To summarize, our main contributions are:   % The remainders of this paper are organized as follows. Section reviews related studies. In Section, we briefly discuss some preliminary, and details about our model are presented in Section. In Section, we demonstrate the experimental results conducted on real-world datasets. Lastly, we conclude our study in Section.%and outline our future work  %   We proposed  a sentence distribution estimator to alleviate the impact of noisy distant supervision labeled data for n-ary cross-sentence relation extraction;   a weaker distant supervision assumption, which considers non-consecutive sentences; and  a universal relation extractor, which is a hybrid model of attention mechanism and non-linear transformation layer that encodes both non-consecutive and consecutive sentence groups. The experiments showed that the proposed model reduces the impact of noisy data and achieves significantly better performance for n-ary cross sentence relation extraction compared to SotA models.  
"," Electronic health records  are longitudinal records of a patient's interactions with healthcare systems. A patient's EHR data is organized as a three-level hierarchy from top to bottom: patient journey - all the experiences of diagnoses and treatments over a period of time; individual visit - a set of medical codes in a particular visit; and medical code - a specific record in the form of medical codes. As EHRs begin to amass in millions, the potential benefits, which these data might hold for medical research and medical outcome prediction, are staggering - including, for example, predicting future admissions to hospitals, diagnosing illnesses or determining the efficacy of medical treatments. Each of these analytics tasks requires a domain knowledge extraction method to transform the hierarchical patient journey into a vector representation for further prediction procedure. The representations should embed a sequence of visits and a set of medical codes with a specific timestamp, which are crucial to any downstream prediction tasks. Hence, expressively powerful representations are appealing to boost learning performance. To this end, we propose a novel self-attention mechanism that captures the contextual dependency and temporal relationships within a patient's healthcare journey. An end-to-end bidirectional temporal encoder network  then learns representations of the patient's journeys, based solely on the proposed attention mechanism. We have evaluated the effectiveness of our methods on two supervised prediction and two unsupervised clustering tasks with a real-world EHR dataset. The empirical results demonstrate the proposed BiteNet model produces higher-quality representations than state-of-the-art baseline methods.",133
" The International Classification of Diseases  establishes a standardized fine-grained classification system for a broad range of diseases, disorders, injuries, symptoms, and other related health conditions . It is primarily intended for use by healthcare workers, policymakers, insurers and national health program managers. The United States incurs administrative costs in billions of dollars annually arising from a complex billing infrastructure . Specifically, the ICD code assignment is typically a manual process, consuming on average between 25 to 43 minutes per patient depending on the ICD version . It is also prone to errors resulting from inexperienced coders, variation between coders, incorrect grouping of codes or mistakes in the patient discharge summaries. These errors are very costly with one report estimating that preventable errors in ICD coding have cost Medicare system 31.6 billion in FY2018 .\\\\ Recent work  has tried to automate the task of ICD code assignment using deep learning.  Typically framed as a multilabel classification problem, researchers have trained Convolutional Neural Networks , Recurrent Neural Networks , and Transformer models to predict ICD-9 codes from patient discharge summaries.  These models have outperformed rule-based approaches and those utilizing conventional algorithms such as Logistic Regression, Support Vector Machines, Random Forests etc., achieving competitive micro F1-scores in the range 42\% - 68\%. Amongst these models, those based on CNNs have achieved the best performance.   Neural network models have revolutionized the field of NLP and SOTA models for various NLP tasks involve deep neural network models such as BERT, Bidirectional RNN or CNN-based methods. Recent works  have shown a particular vulnerability of such deep models to adversarial examples that are often produced by adding small and imperceptible perturbations to the input data. The state of the art models of NLP are no exceptions to such perturbations.  provides a review of different adversarial attacks and defense strategies in the NLP literature. Based on granularity of the perturbation, adversarial attack strategies in NLP can be classified into three types - character-level attacks, word-level attacks and sentence-level attacks. In a character-level attack strategy, the model induces noise at the character level. Character-level noise can be induced due to naturally occurring reasons such as typos and misspellings or due to intentional modification by a malicious third-party.  are some of the existing character-level attack strategies in NLP. To accurately model the naturally occurring typos,  restrict the typos distribution based on the character constraints found in a standard English keyboard. We follow this strategy in our work. Furthermore, we assume a white-box setting where the adversary has access to gradients of the loss function wrt to the model inputs. To our knowledge, this is the first work to investigate the effects of adversarial samples in clinical NLP domain.      In this paper, we proposed a novel prediction model called BiteNet. The model framework comprises a MasEnc module that captures the contextual information and the temporal relationships between the visits in a patient's healthcare journey and attention pooling that construct the hierarchical structure of three-levelled EHR data. The output is a representation of a patient journey that, once learned by the model, can be used to predict medical outcomes with an end-to-end sole self-attention network. We evaluated BiteNet's performance of the model against several baseline methods with supervised and unsupervised tasks, and conducted an ablation study to examine the contributions of each component. The results show that BiteNet produces more accurate predictions than baseline methods.  
","   Manual annotation of ICD-9 codes is a time consuming and error-prone process. Deep learning based systems tackling the problem of automated ICD-9 coding have achieved competitive performance. Given the increased proliferation of electronic medical records, such automated systems are expected to eventually replace human coders. In this work, we investigate how a simple typo-based adversarial attack strategy can impact the performance of state-of-the-art models for the task of predicting the top 50 most frequent ICD-9 codes from discharge summaries. Preliminary results indicate that a malicious adversary, using gradient information, can craft specific perturbations, that appear as regular human typos, for less than $3\%$ of words in the discharge summary to significantly affect the performance of the baseline model.",134
"   Systematic Generalization has been characterized as the capacity to understand and produce a potentially infinite number of novel combinations from known components . For example, in Figure, a model could be exposed to a set of facts , but not to all the possible facts that can be inferred by combination of the known components . More recent work has examined systematic generalization in terms of the ability of ``a model to manipulate concepts in new combinations after being trained on all concepts, but only on a limited set of their combinations'' . This view of systematic generalization shifts emphasis from reasoning to learning. %If a model is able to perfectly accomplish a task by leveraging existing facts to infer new ones, we deem the model is generalizing systematically. Here we examine systematic generalization through measuring the ability of a model to reason about new inference step combinations despite being trained on a limited subset of them. %, and conditioning upon a small subset of active relationships at inference time.   Recent developments in natural language processing  have shown that Transformer  Language Models  are able to capture linguistic knowledge , and yield state-of-the-art performance for many NLP tasks , including but not limited to answering reading comprehension questions  and generating factual knowledge  with little to no task supervision. These models are optimized on large corpora to predict the next words or a set of masked words in a sentence. While yielding impressive results, it is not clear if TLMs rely on many superficial patterns in the data or if they actually learn re-usable skills, enabling them to generalize to new tasks by leveraging the compositionality of those skills . Training on massive data can give certain advantages with respect to understanding the meanings of words, but we conjecture that such data gives models less experience with reasoning over inference chains.    In our work, we study the less understood issues related to how well TLMs are able to perform long chains of reasoning. In particular, we use TLMs for the task of theorem proving, where facts and proofs are specified in natural language. Using theorem proving, we test if TLMs can generate interpretable proofs with logically consistent language modeling as their main objective. % In this setting, language models have various attractive properties: they require no logical rule engineering while still being interpretable, do not need human annotations, and are easy to extend to more data. % Language models have many advantages over theorem provers: they require no rule engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. In particular, we study their behavior as logical reasoners on text by analyzing the generated proofs and the final answer. This setup allows us to evaluate the reasoning and generalization capabilities of TLMs. Recent work such as  suggest that language models can be treated as knowledge bases. This directly motivates us to investigate if language models can also learn certain reasoning strategies. Studying these abilities can give us insights to facilitate the use of such models as dynamic knowledge bases that could infer new knowledge even if it is not seen during pre-training.  For natural language theorem proving, we use the question answering CLUTRR benchmark suite  to perform controlled studies. This dataset is of interest because:  the compositional nature of tasks involved make it well suited for evaluating systematic generalization, and  each question--answer pair is accompanied by a proof that can be used to explain how to arrive at the answer. %Our goal is not to obtain state-of-the-art results on this dataset, rather, We use this dataset as a medium to understand the reasoning capacity of TLMs.  Our experiments reveal the following:   To the best of our knowledge, we are the first to use a language modeling objective to do interpretable theorem proving with a Transformer. We hope that this work can shed some light on the reasoning capacity of TLMs and inspire future research to design models with greater reasoning capacity.     This work is a first step at exploring the robustness of NLP models used for automatic ICD-9 code classification. Clinical documents are different from regular documents as they are typically generated in a fast-paced environment with higher than average typos and non-standard acronyms. As a result, clinical NLP models are more susceptible to adversarial samples compared to a regular NLP model trained on a standard English dataset. A key extension of the work would be to consider a dictionary learnt from clinical documents and biomedical literature as a defense against these character-level perturbations. Although this might mitigate the decrease in performance, it wouldn't completely solve it. A more rigorous way to deal with this would be to account for this in the tokenization strategy. It is easy to push a word out of vocabulary when using tokenization strategies like word2vec and GloVe. Other strategies that model words unseen in training dataset such as word-piece and byte-pair encoding will also break when typos are introduced because these models learn sub words from a standard dictionary. Therefore, any defense must account for these typos in the fundamental tokenization strategy. An interesting direction would be to learn a word similarity metric and map an unknown word to a closer word in the vocabulary given the input word and the context in which it appears. Building a robust tokenization strategy would be the first step towards a robust NLP model against character-level adversarial attacks.     \medskip  \small    
"," We are interested in understanding how well Transformer language models  can perform reasoning tasks when trained on knowledge encoded in the form of natural language. We investigate their systematic generalization abilities on a logical reasoning task in natural language, which involves reasoning over relationships between entities grounded in first-order logical proofs. Specifically, we perform soft theorem-proving by leveraging TLMs to generate natural language proofs. We test the generated proofs for logical consistency, along with the accuracy of the final inference. We observe length-generalization issues when evaluated on longer-than-trained sequences. However, we observe TLMs improve their generalization performance after being exposed to longer, exhaustive proofs. In addition, we discover that TLMs are able to generalize better using backward-chaining proofs compared to their forward-chaining counterparts, while they find it easier to generate forward chaining proofs. We observe that models that are not trained to generate proofs are better at generalizing to problems based on longer proofs. This suggests that Transformers have efficient internal reasoning strategies that are harder to interpret. These results highlight the systematic generalization behavior of TLMs in the context of logical reasoning, and we believe this work motivates deeper inspection of their underlying reasoning strategies.",135
" Singing voice synthesis  aims to synthesize high-quality and expressive singing voices based on musical score information, and attracts a lot of attention in both industry and academia ~. Singing voice synthesis shares similar pipeline with text to speech synthesis, and has achieved rapid progress~ with the techniques developed in text to speech synthesis~.   Most previous works on SVS~ adopt the same sampling rate  as used in text to speech, where the frequency bands or sampling data points are not enough to convey expression and emotion as in high-fidelity singing voices. However, simply increasing the sampling rate will cause several challenges in singing modeling. First, the audio with higher sampling rate contains wider and higher frequency bands\footnote{According to Nyquist-Shannon sampling theorem~, a sampling rate  can cover the frequency band up to . Therefore, the frequency band for the audio with 48kHz sampling rate spans from 024kHz while 012kHz for 24kHz sampling rate. The additional high frequency band 1224kHz increases the difficulty of modeling since high-frequency signals are more complicated and less predictive.}, which throws challenges when predicting these frequency spectrums in acoustic model. Second, the audio with higher sampling rate contains longer waveform points and much fine-grained fluctuations in a fixed period of time\footnote{For example, a 1 second audio waveform contains 48,000 sampling points when sampling rate is 48kHz.}, which also increases the difficulty of vocoder modeling in time domain. As a consequence, even if some previous works~ adopt higher sampling rate , they either leverage coarse-grained MFCC~ as acoustic features in slow autoregressive neural vocoder~, or use non-neural vocoder such as Griffin-Lim~ and WORLD~ to generate waveform, which do not fully exploit the potential of high sampling rate and thus cannot yield good voice quality.  In this paper, we develop HiFiSinger, an SVS system towards high-fidelity singing voices. HiFiSinger adopts FastSpeech~ as the acoustic model and Parallel WaveGAN~ as the vocoder since they are popular in speech synthesis~ to ensure fast training and inference speed and also high quality. %. Instead of using Griffin-Lim, WORLD or autoregressive neural model such as WaveRNN and WaveNet as the vocoder, HiFiSinger leverages  To address the challenges of high sampling rate in singing modeling , we design multi-scale adversarial training on both acoustic model and vocoder, and introduce several additional systematic designs and findings that are crucial to improve singing modeling:   We conduct experiments on our internal singing voice synthesis datasets that contain 11 hours high-fidelity singing recordings with 48kHz sampling rate. Experiment results demonstrate the advantages of our developed HiFiSinger over previous singing voice synthesis system. Further ablation studies verify the effectiveness of each design in HiFiSinger to generate high-fidelity voices.       ========================================================   we are interested in understanding the current limitations of Transformers  In this work, we carefully crafted a series of experiments to understand the systematic generalization capacity of Transformer language models in a symbolic reasoning question answering dataset.  While being powerful language modelers, we believe that if Transformers are to be part of our future personal assistants, they should be able to capture logical statements expressed in natural language and to extrapolate them to unseen proofs. TLMs are state of the art models for a wide variety of natural language processing tasks. Given their widespread use, it is important to understand the limits of their ability to reason on knowledge expressed in natural language and to extrapolate learned inference procedures to unseen problem instances. Our explorations reveal multiple insights. Firstly, TLMs suffer from length-generalization issues in generating proofs. Secondly, TLMs get better at reasoning when trained with longer, exhaustive proofs.  TLMs also generalize better by leveraging backward-chaining proofs than the forward-chaining proofs.  of these properties of Transformers provides a first important evaluation in this setting.   and has led us to insights allowing us to dramatically increase their ability to systematically generalize through a simple named entity transformation. In addition, the fact that backward-chaining proof models perform better than forward-chaining ones makes us believe that backward-chaining strategies are easier to use albeit being harder to generate. Moreover, we find that no-proof models perform better than those trained to produce proofs. We conjecture that benefiting from naturally stated logical proof statements requires more complex internal representations.   At the same time, we believe that in some cases, people would prefer an interpretable system at the cost of slightly lower accuracy.   We will explore both of these directions in future research projects. Recent work on developing position-agnostic attention mechanisms for Transformers  can be useful as a future direction to develop generalizable models. Furthermore, our results motivates the use of neuro-symbolic methods such as Neural Theorem Provers  as an alternative avenue to achieving systems that systematically generalize on logical and compositional reasoning tasks. Combining these approaches with large pre-trained language models is left as future research. We hope that this work will inspire research on the systematic generalization capacity of language models and motivate further study and the creation of neural models with greater reasoning capacity.   rather than with greater number of parameters and training data.   shed some light on their symbolic reasoning capacity of Transformers and inspire future research directions   
"," High-fidelity singing voices usually require higher sampling rate  with large range of frequency to convey expression and emotion. However, higher sampling rate causes the wider frequency band and longer waveform sequences and throws challenges for singing modeling in both frequency and time domains in singing voice synthesis . Conventional SVS systems that adopt moderate sampling rate  cannot well address the above challenges. In this paper, we develop HiFiSinger, an SVS system towards high-fidelity singing voice using 48kHz sampling rate. HiFiSinger consists of a FastSpeech based neural acoustic model and a Parallel WaveGAN based neural vocoder to ensure fast training and inference and also high voice quality. To tackle the difficulty of singing modeling caused by high sampling rate , we introduce multi-scale adversarial training in both the acoustic model and vocoder to improve singing modeling. Specifically, 1) To handle the larger range of frequencies caused by higher sampling rate , we propose a novel sub-frequency GAN  on mel-spectrogram generation, which splits the full 80-dimensional mel-frequency into multiple sub-bands  and models each sub-band with a separate discriminator. 2) To model longer waveform sequences caused by higher sampling rate, we propose a multi-length GAN  for waveform generation to model different lengths of waveform sequences with separate discriminators. 3) We also introduce several additional designs and findings in HiFiSinger that are crucial for high-fidelity voices, such as adding F0  and V/UV  as acoustic features, choosing an appropriate window/hop size for mel-spectrogram, and increasing the receptive field in vocoder for long vowel modeling in singing voices. Experiment results show that HiFiSinger synthesizes high-fidelity singing voices with much higher quality: 0.32/0.44 MOS gain over 48kHz/24kHz baseline and 0.83 MOS gain over previous SVS systems. Audio samples are available at \url{https://speechresearch.github.io/hifisinger/}.",136
" Deep speech representation learning has been the subject of a large number of past works. Many techniques have been developed and employed for extracting representations from speech for related tasks such as speaker recognition  and speech emotion recognition  using deep learning. A significant number of these deep learning models have been based on Convolutional Neural Networks  for SR  and SER . The most common approach to training CNN models for speech-related tasks is to use time-frequency inputs such as spectrograms derived from raw audio signals. Given sufficient data, such deep learning models enable the extraction of better speech representations compared to other methods such as i-Vectors .   Attention mechanisms have been shown to have a positive impact on extracting effective deep representations from input data, for instance speech signals. Considerable improvements in accuracy of emotion recognition models  and speaker recognition models  are some of the examples that demonstrate the potential benefits of using attention mechanisms for representation learning.   Attention models uphold a memory-query paradigm, where the memory is a set of information items such as CNN embeddings of a region of the spectral representation in speech-related tasks , or a part of the utterance embedded by a recurrent cell in a recurrent neural network  . The query is derived from a hidden state of the model from either the same modality or a different one . The majority of attention models used in speech-related tasks, use features extracted from utterances using a deep neural network as the information items or memory, and the last hidden layer of the model as the query . The general purpose of an attention model in generating deep representations of speech signals is to focus on each information item individually.   The information items considered in an attention model define the granularity of what the model can focus on. The spectral representation of an utterance enables deep learning models to consider fine-grained features such as frequency bins in very short time-frames. However, typical attention models used on audio signals utilize an embedding obtained from a CNN model as the memory and the final embedding of the model as query. Using embeddings obtained from CNNs, limits the granularity of the attention models to large regions of the spectral representation. On the other hand, improving the granularity of CNN embeddings of an utterance leads to very large attention models which are harder to train and prone to over-fitting. While there have been a number of studies investigating various attention models using CNN embeddings utterances , very limited number of studies aim to use more fine-grained attention models on spectral representation of the utterance.   In this paper, we address the challenge of improving granularity of attention models by introducing a fine-grained attention mechanism for audio signals. This mechanism enables deep learning models to focus on individual frequency bins of a spectrogram without the drawbacks of having very complex models that typically involve large number of parameters. The aim of this model is to attend to each frequency bin in the spectrogram representation in order to boost the contribution of most salient bins. This mechanism also helps reduce the importance of bins with no useful information leading to more accurate representations, which can also lead to more robustness with respect to existing noise in the input audio. The performance of the proposed attention mechanism has been tested using a select set of most prominent CNN architectures on two tasks of SR and SER. The experimental results show that deploying the fine-grained frequency attention mechanism improves the performance of all the benchmark networks substantially while being less impacted by added noise.   Our contributions in this paper are as follows:   The rest of this paper is organized as follows. First, we discuss the related work in the area of speech representation learning followed by particular approaches that have used attention mechanisms for this purpose. Next, we present the proposed attention mechanism. In the following section, we discuss the experiments along with implementation details. Next, we provide the results of our work. And finally, we summarize and conclude the paper.      In this paper, we have developed HiFiSinger, an SVS system to synthesize high-fidelity singing voice. To address the challenges caused by high sampling rate, we designed a SF-GAN on acoustic model to better model the wider frequency band, a ML-GAN on vocoder to better model longer waveform sequences, and introduced several systematic designs and findings that are important to improve singing modeling. Experiment results show that HFiSinger synthesizes singing voices with much higher quality than previous systems. For future work, we will continue to close the quality gap between the synthesized voices and recordings, and also apply our fidelity solution in HiFiSinger to text to speech synthesis.         
"," Deep learning techniques have considerably improved speech processing in recent years. Speech representations extracted by deep learning models are being used in a wide range of tasks such as speech recognition, speaker recognition, and speech emotion recognition. Attention models play an important role in improving deep learning models. However current attention mechanisms are unable to attend to fine-grained information items. In this paper we propose the novel Fine-grained Early Frequency Attention  for speech signals. This model is capable of focusing on information items as small as frequency bins. We evaluate the proposed model on two popular tasks of speaker recognition and speech emotion recognition. Two widely used public datasets, VoxCeleb and IEMOCAP, are used for our experiments. The model is implemented on top of several prominent deep models as backbone networks to evaluate its impact on performance compared to the original networks and other related work. Our experiments show that by adding FEFA to different CNN architectures, performance is consistently improved by substantial margins, even setting a new state-of-the-art for the speaker recognition task. We also tested our model against different levels of added noise showing improvements in robustness and less sensitivity compared to the backbone networks.",137
" Text summarization aims to produce condensed summaries covering salient and non-redundant information in the source documents. Recent studies on single-document summarization  benefit from the advances in neural sequence learning  as well as pre-trained language models  and make great progress.  However, in multi-document summarization  tasks, neural models are still facing challenges and often underperform classical statistical methods built upon handcrafted features.    We observe two major challenges when adapting advanced neural SDS methods to MDS:   Large search space.  MDS aims at producing summaries from multiple source documents, which exceeds the capacity of neural SDS models  and sets learning obstacles for adequate representations, especially considering that MDS labeled data is more limited. For example, there are 287K training samples  on the CNN/Daily Mail SDS dataset and only 30 on the DUC 2003 MDS dataset .  High redundancy. In MDS, the same statement or even sentence can spread across different documents. Although SDS models adopt attention mechanisms as implicit measures to reduce redundancy, they fail to handle the much higher redundancy of MDS effectively .       There have been attempts to solve the aforementioned challenges in MDS. Regarding the large search space, prior studies  perform sentence filtering using a sentence ranker and only take top-ranked  sentences. However, such a hard cutoff of the search space makes these approaches insufficient in the exploration of the  labeled data and limited by the ranker since most sentences are discarded,\footnote{ is set to 7 in~\citet{lebanoff-etal-2018-adapting} and 15 in~\citet{zhang-etal-2018-adapting}. One document set in DUC 2004, for example, averages 265.4 sentences.} albeit the discarded sentences are important and could have been favored. As a result, although these studies perform better than directly applying their base SDS models  to MDS,  they do not outperform state-of-the-art MDS methods.  Regarding the high redundancy,  various redundancy measures have been proposed, including heuristic post-processing such as counting new bi-grams  and cosine similarity, or dynamic scoring that compares each source sentence with the current summary like Maximal Marginal Relevance .   Nevertheless, these methods still use lexical features without semantic representation learning. One extension of these studies uses capsule networks to improve redundancy measures. However, its capsule networks are pre-trained on SDS and fixed as feature inputs of classical methods  without end-to-end representation learning.  In this paper, we present a deep RL framework, MMR-guided Reinforcement Learning  for MDS, which unifies advances in SDS and one classical MDS approach, MMR through end-to-end learning. \ours addresses the MDS challenges as follows:  \ours overcomes the large search space through soft attention. Compared to hard cutoff, our soft attention favors top-ranked candidates of the sentence ranker . However, it does not discard low-ranked ones, as the ranker is imperfect, and those sentences ranked low may also contribute to a high-quality summary. Soft attention restrains the search space while allowing more exploration of the limited labeled data, leading to better representation learning. Specifically, \ours infuses the entire prediction of MMR into  its neural module by attending  to important sentences and downplaying the rest instead of completely discarding them.  \ours resolves the high redundancy of MDS in a unified way: the explicit redundancy measure in MMR is incorporated into the neural representation of the current state, and the two modules are coordinated by RL reward optimization, which encourages non-redundant summaries.  We conduct extensive experiments and ablation studies to examine the effectiveness of \ours. Experimental results show that \ours achieves state-of-the-art performance on the DUC 2004 and TAC 2011 datasets . A comparison between various combination mechanisms demonstrates the benefits of soft attention in the large search space of MDS . In addition, ablation and manual studies confirm that \ours is superior to applying either RL or MMR to MDS alone, and MMR guidance is effective for redundancy avoidance .  \start{Contributions}  We present an RL-based MDS framework that combines the advances of classical MDS and neural SDS methods via end-to-end learning.   We show that our proposed soft attention is better than the hard cutoff of previous methods for learning adequate neural representations. Also, infusing the neural representation of the current summary with explicit MMR measures significantly reduces summary redundancy.  We demonstrate that \ours achieves new state-of-the-art results on benchmark MDS datasets.          \section{Conclusions}              
"," While neural sequence learning methods have made significant progress in single-document summarization , they produce unsatisfactory results on multi-document summarization . We observe two major challenges when adapting SDS advances to MDS:  MDS involves larger search space and yet more limited training data, setting obstacles for neural methods to learn adequate representations;  MDS needs to resolve higher information redundancy among the source documents, which SDS methods are less effective to handle. To close the gap, we present \ours, Maximal Margin Relevance-guided Reinforcement Learning for MDS, which unifies advanced neural SDS methods and statistical measures used in classical MDS.  \ours casts MMR guidance on fewer promising candidates, which restrains the search space and thus leads to better representation learning. Additionally, the explicit redundancy measure in MMR helps the neural representation of the summary to better capture redundancy. Extensive experiments demonstrate that \ours achieves state-of-the-art performance on benchmark MDS datasets. In particular, we show the benefits of incorporating MMR into end-to-end learning when adapting SDS to MDS in terms of both learning effectiveness and efficiency.\footnote{Code can be found at \url{https://github.com/morningmoni/RL-MMR}.}",138
" Natural language generators  for task-oriented dialogue take meaning representations  as inputs, i.e. a set of dialogue acts with attributes and their values, and output natural language utterances realizing the MR.  Current NLGs are trained end-to-end with a corpus of MR/utterance pairs where the MRs cover a specific set of dialogue acts and domain attributes. Creation of such datasets is labor intensive and time consuming. However, when building an NLG for a new domain ontology, it should be possible to re-use data built on existing domain ontologies.  If this were possible, it would speed up development of new dialogue systems significantly.   \end{footnotesize}   blue} and NYC is in {\color{darkred}red}. Some attributes are shared    between both sources: here the unique dialogue acts and attributes    for each source are underlined in E1 and E2.  E3 illustrates an MR    from the target test set that we dub COM. All the MRs in COM combine dialogue acts    and attributes from E2E and NYC. There is no training data     corresponding to E3.     %: the goal of the task is to re-use    %the existing training data from E2E and NYC %and train an NLG that    %can generalize to unseen combinations such %as shown in E3.      The MRs    illustrate how some attribute values, e.g. {\sc restaurant name,      point-of-interest}, are delexicalized to improve generalization.}  \end{figure*}  Here we experiment with one version of this task by building a new domain ontology based on {\bf combining} two existing ontologies, and utilizing their training data.  Each dataset is based on a different domain ontology in the restaurant domain, with novel attributes and dialogue acts not seen in the other dataset, e.g. only one has attributes representing family friendly and rating information, and only one has attributes for decor and service.  Our aim is an NLG engine that can realize utterances for the extended {\bf   combined} ontology not seen in the training data, e.g. for MRs that specify values for family friendly, rating, decor and   service.  Figure illustrates this task. Example E1 is from a training set referred to as NYC, from previous work on controllable sentence planning in NLG , while E2 is from the E2E NLG shared task . As we describe in detail in Section, E1 and E2 are based on two distinct ontologies.  Example E3  %in Figure  illustrates the task addressed in this paper: we create a test set of novel MRs for the combined ontology, and train a model to generate high quality outputs where individual sentences realize attributes from both ontologies.  To our knowledge, this is a completely novel task.  While it is common practice in NLG to construct test sets of MRs that realize attribute combinations not seen in training, initial experiments showed that this task is surprisingly adversarial.  However, methods for supporting this type of generalization and extension to new cases would be of great benefit to  task-oriented dialogue systems, where it is  common to start with a restricted set of attributes and then enlarge the domain ontology over time. New attributes are constantly being added to databases of restaurants, hotels and other entities to support better recommendations and better search.  Our experiments test whether existing data that only covers a subset of attributes can be used to produce an NLG for the enlarged ontology.   We describe below how we create a test set --- that we call {\sc com} --- of combined MRs to test different methods for creating such an NLG.  A baseline sequence-to-sequence NLG model has a slot error rate  of .45 and only produces semantically perfect outputs 3.5\% of the time. To improve performance, we experiment with three different ways of conditioning the model by incorporating side constraints that encode the source of the attributes in the MR . %,  i.e.,whether they are from E2E or NYC or both.  However, this only   increases the proportion of semantically perfect model outputs from   3.5\% to 5.5\% .  We then propose and motivate a novel self-training method that greatly improves performance by learning from the model mistakes. An error analysis shows that the models {\bf do} produce many {\bf combined} outputs, but with errorful semantics. We develop a rule-based text-to-meaning semantic extractor that automatically creates novel correct MR/text training instances from errorful model outputs, and use these in self-training experiments, thus learning from our mistakes . We validate the text-to-meaning extractor with a human evaluation.  We find that a model trained with this process produces SERs of only .03, and semantically perfect outputs 81\% of the time .  A human evaluation shows that these outputs are also natural, coherent and grammatical. Our contributions are:    We start in Section by defining the task in more detail, describe our models and metrics in Section, and results in Section.  We discuss related work throughout the paper where it is most relevant and in the conclusion in Section.    We present a reinforcement learning framework for MDS that unifies neural SDS advances and Maximal Marginal Relevance  through end-to-end learning. The proposed framework leverages the benefits of both neural sequence learning and statistical measures, bridging the gap between SDS and MDS. We conduct extensive experiments on benchmark MDS datasets and demonstrate the superior performance of the proposed framework, especially in handling the large search space and high redundancy of MDS. In the future, we will investigate the feasibility of incorporating classical MDS guidance to abstractive models with large-scale pre-training  and more challenging settings where each document set may contain hundreds or even thousands of documents.  
"," Natural language generators  for task-oriented dialogue typically take a meaning representation  as input, and are trained end-to-end with a corpus of MR/utterance pairs, where the MRs cover a specific set of dialogue acts and domain attributes. Creation of such datasets is labor intensive and time consuming. Therefore, dialogue systems for new domain ontologies would benefit from using data for pre-existing ontologies.   Here we explore, for the first time, whether  it  is possible to train  an NLG for a new {\bf larger} ontology using  existing training sets for the restaurant domain, where each set is based on a {\bf different} ontology. We create a new, larger {\bf combined}  ontology,  and then  train an NLG  to produce utterances covering it. For example, if one dataset has  attributes for family friendly and   rating information, and the other has attributes for decor and service, our aim is an NLG for the combined ontology that can produce utterances that realize values for family friendly, rating, decor and   service.   Initial experiments with a baseline neural sequence-to-sequence model show that this task is surprisingly  challenging. %, and that in many cases the models do not produce combine attributes from the two original ontologies, and when they do the semantics are highly errorful. We then develop a  novel {\bf self-training} method that identifies  model outputs, automatically  constructs a corrected MR input to form a new  training pair, and then repeatedly adds these new instances back into the training data. %that combine attributes from both sources %and then automatically construct an MR that matches the string that %was actually generated .   %We repeatedly construct and add these %new instances back into training, resulting in a self-trained %model that produces semantically perfect outputs 83\% of the time. %We repeatedly construct and add these %new instances back into training, resulting  We then test the resulting model on a new test set. The result is a self-trained model whose performance is an absolute 75.4\% improvement over the baseline model.  %can produce semantically perfect outputs 83\% of the time. %improves the proportion of semantically perfect outputs for the new combined ontology  from 5.5\% to 83\%.  We also report a human qualitative evaluation of the final  model showing that it achieves high naturalness, semantic coherence and grammaticality.",139
" In recent years, neural LMs  have shown profound abilities to generate texts that could be almost indistinguishable from human writings . Neural LMs could be used to generate concise summaries , coherent stories , and complete documents given prompts . It is natural to question their source and extent of rhetorical knowledge: What makes neural LMs articulate, and how?  While some recent works query the linguistic knowledge , this open question remain unanswered. We hypothesize that contextualized neural LMs encode rhetorical knowledge in their intermediate representations, and would like to quantify the extent they encode rhetorical knowledge.  To verify our hypothesis, we hand-craft a set of 24 rhetorical features including those used to examine rhetorical capacities of students , and evaluate how well neural LMs encode these rhetorical features in the representations while encoding texts.  Recent work has started to evaluate encoded features from hidden representations. Among them, probing  has been a popular choice. Previous work probed morphological , agreement , and syntactic features . Probing involves optimizing a simple projection model from representations to features. The loss of this optimization measures the difficulty to decode features from the representations.   In this work, we use a probe containing self attention mechanism. We first project the variable-length embeddings to a fixed-length latent representation per document. Then, we apply a simple diagnostic classifier to detect rhetorical features from this latent representation. This design of probe reduces the total number of parameters, and enable us to better understand each model's ability to encode rhetorical knowledge. We find that:   These observations allow us to investigate the mechanisms of neural LMs to better understand the degree to which they encode linguistic knowledge. We demonstrate how discourse-level features can be queried and analyzed from neural LMs. All of our code and parsed tree data will be available at github.       \nocite{KedzieMcKeown19,shah2018bootstrapping} \nocite{budzianowski2018multiwoz,eric2019multiwoz,gavsic2015policy,hakkani2016multi,Cervoneetal19,shah2018bootstrapping,ultes2017pydial,chen2017deep}  This paper presents the first experiments on training an NLG for an extended domain ontology by re-using existing within-domain training data.  We show that we can combine two training datasets for the restaurant domain, that have different ontologies,  relying on distinct sets of dialogue acts and attributes, and generate output that combines attributes from both sources, by applying a combination of neural supervision and a novel self-training method.  While it is common practice to construct test sets with unseen attribute combinations, we know of no prior work based on constructing a new combined ontology. Our experiments show that the task is surprisingly adversarial, consistent with recent work suggesting that neural models often fail to generalize .  Work on  domain transfer shares similar goals to the experiments presented here  , but these methods do not produce NLG outputs that integrate attributes from two different sources into the same sentence. Our final results show that the ability of our self-training method to automatically construct new training instances  results in high quality natural, coherent and grammatical outputs with high semantic accuracy.    In future, we hope to generalize our novel self-training method to build an NLG that can combine two distinct domains, e.g.  hotels or movies combined with restaurants in multi-domain dialogue . Ideally systems that cover multiple domains should be able to produce utterances that seamlessly integrate both domains, if data exists for each domain independently.  However, there may be additional  challenges in such combinations. Our results require the initial neural models to generate {\bf some} combined outputs. It is not clear whether there are some aspects of our experimental setup that facilitate this, e.g. it may require  some attributes to be shared across the two initial ontologies, or  some shared vocabulary. Thus it is possible that initial models for two more distinct domains may not produce any combined outputs, and it may be necessary to seed the self-training experiments with a small number of combined training instances. We leave these issues to future work.      In future work we plan to investigate the use of our novel    self-training method for building an NLG by combining two distinct domains such    as hotel and restaurant information, where training data exists for    hotels alone and restaurants alone, e.g. to generate The Ritz is      a great place to stay because its rooms are lovely and its      restaurant serves excellent nouvelle cuisine, an utterance that    combines attributes from both domains.    This may be     {\color{red} say what assumptions we make as per the one review and our rebuttal,    say that method relies on that at least SOME output make the combination. worst    case is that you'd have to collect a small amount. May also be other training methods    can try to force more combinations.} In    We also plan to investigate whether stylistic attributes from  one source can be injected into utterances from another  source.      
"," Recently, neural language models  have demonstrated impressive abilities in generating high-quality discourse. While many recent papers have analyzed the syntactic aspects encoded in LMs, to date, there has been no analysis of the inter-sentential, rhetorical knowledge.  In this paper, we propose a method that quantitatively evaluates the rhetorical  capacities of neural LMs. We examine the capacities of neural LMs understanding the rhetoric of discourse by evaluating their abilities to encode a set of linguistic features derived from Rhetorical Structure Theory . Our experiments show that BERT-based LMs outperform other Transformer LMs, revealing the richer discourse knowledge in their intermediate layer representations. In addition, GPT-2 and XLNet apparently encode less rhetorical knowledge, and we suggest an explanation drawing from linguistic philosophy. Our method presents an avenue towards quantifying the rhetorical capacities of neural LMs.",140
"  Our WeChat AI team participates in the WMT 2020 shared news translation  task on ChineseEnglish. In this year閳ユ獨 translation task, we mainly focus on exploiting several effective model architectures, better data augmentation, training and model ensemble strategies.  For model architectures, we mainly exploit two different architectures in our approaches, namely Transformers and RNMT. For Transformers, we implement the Deeper transformer with Pre-Norm, the Wider Transformer with larger filter-size and the average attention based transformer. For the RNMT, we use the deep transition based DTMT model. We finally ensemble four kinds of models in our system.  For synthetic data generation, we explore various methods for out-of-domain and in-domain data generation. For out-of-domain data generation, we explore the back-translation method to leverage the target side monolingual data and the knowledge distillation method to leverage source side of golden parallel data. For in-domain data generation, we employ iterative in-domain knowledge transfer to leverage the source side monolingual data and golden parallel data.  Furthermore, data augmentation methods, including noisy fake data and sampling, are used for training more robust NMT models. %We also apply these techniques on the corresponding side of golden parallel data.  For training strategies, we mainly focus on the parallel scheduled sampling, the target denoising and minimum risk training algorithm for in-domain finetuning.  We also exploit a self-bleu  based model ensemble approach to enhance our system. As a result, our constrained ChineseEnglish system achieves the highest case-sensitive BLEU score among all submitted systems.  In the remainder of this paper, we start with an overview of model architectures in Section.  Section describes the details of our systems and training strategies.  Then Section shows the experimental settings and results.  Finally, we conclude our work in Section.    In this paper, we propose a method to quantitatively analyze the amount of rhetorical information encoded in neural language models. We compute features based on Rhetorical Structure Theory  and probe the RST features from contextualized representations of neural LMs. Among six popular neural LMs, we find that contextualization helps to generally improve the rhetorical capacities of LMs, while individual models may vary in quality. In general, LMs attending to contexts from both directions  encode rhetorical knowledge in a more stable manner than those using uni-directional contexts  or permuted contexts .  Our method presents an avenue towards quantitatively describing rhetorical capacities of neural language models based on unlabeled, target-domain corpus. This method may be used for selecting suitable LMs in tasks including rhetorical acts classifications, discourse modeling, and response generation.  
"," We participate in the WMT 2020 shared news translation task on Chinese$\to$English. Our system is based on the Transformer with effective variants and the DTMT architecture. In our experiments, we employ data selection, several synthetic data generation approaches ,  advanced finetuning approaches and self-bleu based model ensemble. Our constrained Chinese$\to$English system achieves 36.9 case-sensitive BLEU score, which is the highest among all submissions.",141
"  Social media has become an essential element of our society by which people communicate and exchange information on a daily basis. The strong influence of social media on internet users has been of great benefit to many individuals, businesses, and organizations. Many companies and organizations nowadays use social media to reach customers, promote products, and ensure customer satisfaction. Despite the benefits associated with the widespread use of social media, they remain vulnerable to ill-intentioned activities, as the openness, anonymity, and informal structure of these platforms have contributed to the spread of harmful and violent content. \par  Although social media service providers have policies to control these ill-intentioned behaviors, these rules are rarely followed by users. Social media providers also allow their users to report any inappropriate content, but unreported content may not be discovered due to the huge volume of data on these platforms. Some countries have restricted the use of social media, and others have taken legal action regarding violent or harmful content that might target particular individuals or communities. However, these violations might end up unpunished due to the anonymous nature of these platforms, allowing ill-intentioned users to fearlessly share harmful content by using nicknames or fake identities. One of the most-shared harmful content on social media is hate content, which might take different forms such as text, photos, and/or video. Hate speech is any expression that encourages, promotes, or justifies violence, hatred, or discrimination against a person or group of individuals based on characteristics such as color, gender, race, sexual orientation, nationality, religion, or other attributes. Online hate speech is rapidly increasing over the entire world, as nearly \% of the world閳ユ獨 population  communicates on social media. Studies have shown that nearly \% of Americans have experienced online hate and harassment. This result is \% higher than the results of a comparable questionnaire conducted in  . For younger people, the results show that \% of teenagers frequently encounter hate speech on social media.  \par   One of the most dangerous and influential forms of online hate speech is led and spread by supporters of extreme ideologies who target other racial groups or minorities. White supremacists are one of the ideological groups who believe that people of the white race are superior and should be dominant over people of other races; this is also referred to as white nationalism in more radical ideologies. White supremacists claim that they are undermined by dark skin people, Jews, and multicultural Muslims, and they want to restore white people閳ユ獨 power, violently if necessary. They have also claimed responsibility for many violent incidents that happened in the s, including bank robberies, bombings, and murders. The white supremacist ideology has been adopted by both right-wing and left-wing extremists who combine white supremacy with political movements. \par   White supremacist hate speech has become a significant threat to the community, either by influencing young people with hateful ideas or by creating movements to implement their goals in the real world. A study has also suggested links between hate speech and hate crimes against others . Several recent brutal attacks have also been committed by supporters of radical white supremacists who were very active members on social media. The mass shootings in New Zealand, Texas, and Norway were committed by white supremacists who had shared their opinions and ideologies on social media. The attacker of two mosques in Christchurch, New Zealand, was a 28 year old man who identified himself as a white nationalist hero, and posted a manifesto that discussed his intent to kill people as a way to reinforce the sovereignty of white extremists. From a psychological point of view, any violent attack must be preceded by warning behaviors, which includes any behavior that shows before a violent attack that is associated with it, and can in certain situations predict it. Warning behaviors can be either real-world markers  or linguistic markers or signs  which can happen in real life and/or online.  \par   Automatic detection of white supremacist content on social media can be used to predict hate crimes and violent events. Perpetrators can be caught before attacks happen by examining online posts that give strong indications of an intent to make an attack. Predicting violent attacks based on monitoring online behavior would be helpful in crime prevention, and detecting hateful speech on social media will also help to reduce hatred and incivility among social media users, especially younger generations. \par  Studies have investigated the detection of different kinds of hate speech such as detecting cyberbullying , offensive language  , or targeted hate speech in general by distinguishing between types of hate speech and neutral expressions. Others have dealt with the problem by detecting a specific types of hate speech, such as anti-religion, jihadist, sexist, and racist. However, less attention has been given to detecting white supremacism in particular, with limited studies.   \par  White supremacist extremists tend to use rhetoric   in their language. They also use specific vocabulary, abbreviations, and coded words to express their beliefs and intent to promote hatred or encourage violence to avoid being detected by traditional detection methods. They mostly use hate speech against other races and religions, or claim that other races are undermining them. Figure shows an example of a white supremacist tweet.  \par  \subsection{Research goal and contributions}  In this paper, we aim to detect white supremacist tweets based on textual features by using deep learning techniques. We collected about  tweets from white supremacist accounts and hashtags to extract word embeddings, and then we labeled about  subsets of the data corpus to build a white supremacist dataset. We applied two approaches: the first uses domain-specific word embedding learned from the corpus and then classifies  tweets using a Bidirectional LSTM-based deep model. This approach is evaluated on multiple dataset and achieved different results depending on the datasets that ranged from a \% to a \% F1-score. The second approach uses a pre-trained language model that is fine-tune on the white supremacist dataset using Neural Network dense layer. The BERT language model F1-scores ranged from \% to \%. Thus, the research contribution can be summarized as follow:   \par  The rest of the paper proceeds with the Background Section , which provides information on the methodology used, related studies in the Literature Review section , a detailed description of methods in the Methodology section , details of the used datasets in the Dataset section , specifications of the methodologies and the results of each approach in the Experiments and Results section , observations and analysis of the performance of each approach in the Discussion section , and finally, the Conclusion and Future Work section .        In this paper, we introduce the system WeChat submitted for the WMT 2020 shared task on ChineseEnglish news translation. Our system is based on the Transformer with different variants and the DTMT architecture. Data selection, several effective synthetic data generation approaches , advanced finetuning approaches  and self-bleu based model ensemble are employed and proven effective in our experiments. Our constrained ChineseEnglish system achieved 36.9 case-sensitive BLEU score which is the highest among all submissions.   
","  White supremacists embrace a radical ideology that considers white people superior to people of other races. The critical influence of these groups is no longer limited to social media; they also have a significant effect on society in many ways by promoting racial hatred and violence. White supremacist hate speech is one of the most recently observed harmful content on social media. Traditional channels of reporting hate speech have proved inadequate due to the tremendous explosion of information, and therefore, it is necessary to find an automatic way to detect such speech in a timely manner. This research investigates the viability of automatically detecting white supremacist hate speech on Twitter by using deep learning and natural language processing techniques. Through our experiments, we used two approaches, the first approach is by using domain-specific embeddings which are extracted from white supremacist corpus in order to catch the meaning of this white supremacist slang with bidirectional Long Short-Term Memory  deep learning model, this approach reached a 0.74890 F1-score. The second approach is by using the one of the most recent language model which is BERT, BERT model provides the state of the art of most NLP tasks. It reached to a 0.79605 F1-score. Both approaches are tested on a balanced dataset given that our experiments were based on textual data only. The dataset was combined from dataset created from Twitter and a Stormfront dataset compiled from that white supremacist forum.",142
"   Graph Neural Networks  have in recent years been shown to provide a scalable and highly performant means of incorporating linguistic information and other structural biases into NLP models. They have been applied to various kinds of representations  and shown effective on a range of tasks, including relation extraction~, question answering~, syntactic and semantic parsing tasks~, summarization ~, machine translation~ and abusive language detection in social networks~.     While GNNs often yield strong performance, % such models are % complex, and it can be difficult to understand the `reasoning' behind their predictions. For NLP practitioners, it is highly desirable to know which linguistic information a given model encodes and how that encoding happens~. The difficulty in interpreting GNNs represents a barrier to such analysis. %  Furthermore,  this opaqueness decreases user trust% , impedes the discovery of harmful biases, and complicates error analysis% ~,   an issue for GNNs where seemingly small implementation differences can make or break models~.  In this work, we focus on post-hoc analysis of GNNs and formulate some desiderata for an interpretation method:      A simple way to perform interpretation is to use  erasure search~, an approach wherein attribution happens by searching for a maximal subset of features which can be entirely removed without affecting model predictions. % The removal guarantees that all information about the discarded features is ignored by the model. This  contrasts with approaches which use heuristics to define feature importance, for example attention-based methods~ or back-propagation techniques~. They do not guarantee that the model ignores low-scoring features, attracting criticism in recent years . % The trust in erasure search is reflected in the literature through other methods % motivated as approximations of erasure~, or through new attribution techniques % evaluated using erasure search as ground truth~.  Applied to GNNs, erasure search would involve a search for the largest subgraph which can be completely discarded. Besides faithfulness considerations and conceptual simplicity, discrete attributions would also simplify the comparison of relevance between paths; this is in contrast to continuous attribution to edges, where it is not straightforward to extract and visualize important paths. Furthermore, in contrast to techniques based on artificial gradients~, erasure search would provide implementation invariance~. This is important in NLP, as models commonly use highly parametrized decoders on top of GNNs, e.g.~\citet{koncel-kedziorski-etal-2019-text}.   While arguably satisfying criteria  and  in our desiderata, erasure search unfortunately fails on tractability. In practical scenarios, it is infeasible, and even approximations, which remove one feature at a time~ and underestimate their contribution due to saturation~,  remain prohibitively expensive.   Our GraphMask aims at meeting the above desiderata by achieving the same benefits as erasure search in a scalable manner. That is, our method makes easily interpretable hard choices on whether to retain or discard edges such that discarded edges have no relevance to model predictions, while remaining tractable and model-agnostic~. GraphMask  can be understood as a differentiable form of subset erasure, where, instead of finding an optimal subset to erase for every given example, we learn an erasure function which predicts for every edge  at every layer  whether that connection should be retained. Given an example graph , our method returns for each layer  a subgraph  such that we can faithfully claim that no edges outside  influence the predictions of the model. To enable gradient-based optimization for our erasure function, we rely on sparse stochastic gates~.  In erasure search, optimization happens individually for each example. This can result in a form of overfitting where even non-superfluous edges are aggressively pruned, because a similar prediction could be made using an alternative smaller subgraph; we refer to this problem as hindsight bias. % Because our model relies on a parametrized erasure function rather than an individual per-edge choice, we can address this issue by amortizing parameter learning over a training dataset through a process similar to the readout bottleneck introduced in~\citet{schulz2020restricting}. As we demonstrate in Section, this strategy avoids hindsight bias.  \paragraph{Contributions} Our contributions are as follows:       The first approach of domain-specific experiments in  , the results show that domain-specific embedding with Bidirectional LSTM model outperforms the results of  who used randomly initialized word embedding with LSTM. Their accuracy was \ , while our accuracy is \ . Although our model exceeds their accuracy, but we expected much higher accuracy than only 2 points, which means that random initialization does not perform very badly. It is important to mention that white supremacist corpus for the pretrained word embedding was about 1 million tweets, increasing the corpus size would provide better performance, but we were limited by Twitter閳ユ獨 policies. This experiment shows that the Bidirectional LSTM based deep model gave good performance for the white supremacy detection, which contradicts, who said that LSTM did not give a good performance because the length of tweets was limited to 180 characters; however, now it is 280 characters. \par From the feature perspective comparison, Table shows how WSW2V performs in comparison with other domain-agnostic models using the same classifier and datasets; the WSW2V outperforms other models on both the Stormfront and Balanced datasets, but GloVe Twitter outperforms WSW2V, and this is because the big size difference of the data trained on, i.e,  for  GloVe Twitter and  for WSW2V. From the classifier perspective comparison, the Bidirectional LSTM-based deep model outperforms LR on two datasets , but LR outperforms the Bidirectional LSTM-based deep model on the Twitter dataset.  \par The second experiment involved using the BERT model on the dataset to assess its performance on the white supremacist hate speech classification task. As shown in Table, BERT outperforms all the distributional-based embeddings  with the Bidirectional LSTM-based deep model in Table. This means that the BERT model gives a closer meaningful vector of the words due to its training strategy  and the large corpus trained on. The BERT language model combines the advantages of domain-agnostic and domain-specific embeddings in its training strategy, it is petrained on a large corpus and add extra layer for training your specific task.  \par Finally, narcissists often use first-person singular pronouns and profane and aggressive language in their social media communications ,  while individuals with an argumentative personality often comment on other people閳ユ獨 posts or frequently post on similar topics to prove their point. White supremacists usually associate themselves with radical groups by either identifying themselves as a member in their profiles or by encouraging or promoting their ideological perspectives. This study focuses on tweets or textual features to detect white supremacy, and not account for profile features. Thus, we only focus on tweet features that help to identify white supremacists閳 characteristics. Further account analysis will be included in future work. 	  \section {Conclusion and Future work}    From the experiments, we have shown that a combination of word embedding, and deep learning perform well for the problem of white supremacist hate speech. Some of the datasets are imbalanced to simulate real-world data, and others are balanced to assess the model閳ユ獨 performance under an ideal situation. The BERT model has also proved that it provides the state of art for this problem. For future work, the corpus size will be maximized in order to generate more meaningful embeddings, and experiments will be done on multiclass problems instead of binary class problems and by combining Google Word2Vec and domain-specific Word2Vec.  \section {Acknowledgement} I would like to thank all the researchers who have made their resources available to the research community.    
"," Graph neural networks  have become a popular approach to integrating structural inductive biases into NLP models. However, there has been little work on interpreting them, and specifically on understanding which parts of the graphs  contribute to a prediction. In this work, we introduce a post-hoc method for interpreting the predictions of GNNs which identifies unnecessary edges. % Given a trained GNN model, we learn a simple classifier that, for every edge in every layer, predicts if that edge can be dropped. We demonstrate that such a classifier can be trained in a fully differentiable fashion, employing stochastic gates and encouraging sparsity through the expected  $L_0$ norm. We use our technique as an attribution method to analyze GNN models for two tasks -- question answering and semantic role labeling -- providing insights into the information flow in these models. We show that we can drop a large proportion of edges without deteriorating the performance of the model, while we can analyse the remaining edges for interpreting model predictions.",143
"  Modern methods of natural language processing  are based on complex neural network architectures, where language units are represented in a metric space . Such a phenomenon allows us to express linguistic features  mathematically.   The method of obtaining such representation and their interpretations were described in multiple overview works. Almeida and Xex\'eo surveyed different types of static word embeddings , and Liu et al.  focused on contextual representations found in the most recent neural models. Belinkov and Glass  surveyed the strategies of interpreting latent representation. Best to our knowledge, we are the first to focus on the syntactic and morphological abilities of the word representations. We also cover the latest approaches, which go beyond the interpretation of latent vectors and analyze the attentions present in state-of-the-art Transformer models. %analyzed matrix representation of the neural networks. %.    %\tltodo{Maybe use ToC as instroduction to section and remove them from here} %The survey is organized in the following way: %In Section, we introduce several types of NLP models that are going to be analyzed. Section shortly describes the metrics used to evaluate syntactic information captured by the models. The observations and results for static and contextual word embeddings are presented in Section. The observations on attention matrices for different Transformer architectures are described in Section. We summarize our findings in Section. %for attention matrices in Transformer models. %We conclude the survey by mentioning supervised approaches to enhance syntactic signal.   %   In this paper, we propose LUKE, new pretrained contextualized representations of words and entities based on the transformer. LUKE outputs the contextualized representations of words and entities using an improved transformer architecture with using a novel entity-aware self-attention mechanism. The experimental results prove its effectiveness on various entity-related tasks. Future work involves applying LUKE to domain-specific tasks, such as those in biomedical and legal domains.       
","  Neural networks trained on natural language processing tasks capture syntax even though it is not provided as a supervision signal. %The syntax is captured by the natural language processing models even when not provided as a supervision signal. This %This phenomenon  indicates that syntactic analysis is essential to the understating of language in artificial intelligence systems. % This overview paper covers approaches of evaluating the amount of syntactic information included in the representations of words for different neural network architectures. %This overview paper covers approaches to evaluating of syntactic information in the representation of words in neural networks. We compare the spectrum of model architectures and the training data. We mainly summarize research on English monolingual data on language modeling tasks and multilingual data for neural machine translation systems and multilingual language models.   %Particularly we consider corpora in one language, mainly English used for training Language Models, and multilingual data for Machine Translation Systems and Multilingual Language Models. We describe which pre-trained models and representations of language are best suited for transfer to syntactic tasks.  % We hope that our comparison will help in finding pretrained model for transfer   % The survey covers the research on producing representation of language and evaluation of captured syntactic information. I focus on the works that do not use syntactic supervision during training of the representation, and are obtained on large mono or multilingual corpora.  % The aim of this work is to examine to what extent syntactic features can be extracted from plain text and how it can be compared to expert annotations.",144
" Texts represent the main source of knowledge for our society. However, they can be written in various manners, thus creating a barrier between the readers and the ideas they intend to convey. Therefore, document comprehension is the main challenge users have to overcome, by understanding the meaning behind troublesome words and becoming familiar with them. Complex Word Identification  is a task that intends to identify hard-to-understand tokens, highlighting them for further clarification and assisting users to grasping the contents of the document.  Motivation. Each culture includes exclusive ideas, available only for the ones who can pass the obstacle of language. However, properly understanding language can prove to be a difficult task. By identifying complex words, users can make consistent steps towards adapting to the culture and accessing the knowledge it has to offer. As an example, entries like ""mayoritariamente""  or ""gobernatura""  in the Spanish environment can create understanding problems for non-native Spanish speakers, thus requiring users to familiarize themselves with these particular terms.  Challenges. The identification task becomes increasingly more difficult, as proper complex word identification is not guaranteed. For example, if we use human identification techniques, language learners may consider a new word to be complex, while others might not share the same opinion by relying on their prior knowledge in that language. Therefore, universal annotation techniques are required, such that a ground truth can be established and the same set of words is considered complex in any context.  Proposed Approach. We consider state-of-the-art solutions, namely multilingual Transformer-based approaches, to address the CWI challenge. First, we apply a zero-shot learning approach. This was performed by training Recurrent Neural Networks  and Transformer-based models on a source language corpus, followed by validating and testing on a corpus from a target language, different from the source language.  A second experiment consists of a one-shot learning approach that considers training on each of the three languages , but only keeping one entry from the target language, and validating and testing on English, German, Spanish, and French, respectively.   In addition, we performed few-shot learning experiments by validating and testing on a language, and training on the others, but with the addition of a small number of training entries from the target language. The model learns sample structures from the language and, in general, performs better when applied on multiple entries. Furthermore, this training process can help the model adapt to situations in which the number of training inputs is scarce. The dataset provided by the CWI Shared Task 2018  was used to perform all experiments.  This paper is structured as follows. The second section describes related work and its impact on the CWI task. The third section describes the corpus and outlines our method based on multilingual embeddings and Transformer-based models, together with the corresponding experimental setup. The fourth section details the results, alongside a discussion and an error analysis. The fifth section concludes the paper and outlines the main ideas, together with potential extensions.        Main observations:   1. The unsupervised neural networks capture syntax.   2. Contextual embeddings are more suited for probing for syntactic features than static word embedding.   3. Static word embeddings perform better on task that does not require contextual information, such as syntactic analogies retrival   4. An easy pre-training task, such as auto-encoding, requires syntactic information to lesser extent, therefore it is worse captured by the word embeddings.   5. Embeddings obtained from language models and machine translation system give similar results when probed for part of speech when trained on the corpora of the same size. However, the performance rises with the amount of data and typically language models can be trained with larger corpora, and therfore yield better results in transfer learning to syntactic probing.   6. Some attention matrices in Transformer architecture are aligned with dependency relations.   7. Usually the middle layer of Language Models are more syntactic.   8. In Machine Translation the top layers of the encoder are more syntactic. This may be because of the fact that the model's output is not predicted directly from their output and latent representation is more syntactic.     Word Embeddings and Neural Networks trained on large corpora capture syntactic information.    This phenomena  In this overview, we survey that syntactic structures are latently learned by the neural models for natural language processing tasks.  naturally underlay the natural language and is reflected by unsupervised models. We have compared multiple approaches of others and described the features that affect the ability to capture the syntax. The following aspects tend to improve the performance on syntactic tasks such as POS tagging:  Our meta-analysis of latent states showed that the most syntactic representation could be found in the middle layers of the model. They tend to capture more complex relations than initial layers, and the representations are less dependent on the pretraining objectives than in the top layers.    In this work We have shown to what extent systems trained for a non-syntactic task can learn grammatical structures. The question we leave for further research is whether providing explicit syntactic information to the model can improve its performance on other NLP tasks. ?   
"," Complex Word Identification  is a task centered on detecting hard-to-understand words, or groups of words, in texts from different areas of expertise. The purpose of CWI is to highlight problematic structures that non-native speakers would usually find difficult to understand. Our approach uses zero-shot, one-shot, and few-shot learning techniques, alongside state-of-the-art solutions for Natural Language Processing  tasks . Our aim is to provide evidence that the proposed models can learn the characteristics of complex words in a multilingual environment by relying on the CWI shared task 2018 dataset available for four different languages . Our approach surpasses state-of-the-art cross-lingual results in terms of macro F1-score on English , German , and Spanish  languages, for the zero-shot learning scenario. At the same time, our model also outperforms the state-of-the-art monolingual result for German .",145
" Aspect based sentiment analysis   is a fine-grained sentiment analysis task. ABSA contains several subtasks, four of which are aspect category detection  detecting aspect categories mentioned in sentences, aspect category sentiment analysis  predicting the sentiments of the detected aspect categories, aspect term extraction  identifying aspect terms presenting in sentences and aspect term sentiment analysis  classifying the sentiments toward the identified aspect terms. While aspect categories mentioned in a sentence are from a few predefined categories and may not occur in the sentence, aspect terms  explicitly appear in sentences. Fig.  shows an example. ACD detects the two aspect categories food and service and ACSA predicts the positive and negative sentiments toward them. ATE identifies the two aspect terms ``taste'' and ``service'' and ATSA classifies the positive and negative sentiments toward them. In this paper, we concentrate on the ACSA task. The ACD task as a auxiliary is used to find aspect category-related nodes from sentence constituency parse trees for the ACSA task.    Since a sentence usually discusses one or more aspect categories and expresses different sentiments toward them, various attention-based methods have been developed to allocate appropriate sentiment words for given aspect categories. Wang et al.  were the first to explore attention mechanism on the ACSA task and proposed an attention based LSTM . For a given sentence and an aspect category mentioned in the sentence, AT-LSTM first models the sentence via a LSTM model,  then combines the hidden states from the LSTM with the representation of the aspect category to generate aspect category-specific word representations, finally applies an attention mechanism over the word representations to find the aspect category-related sentiment words, that are used to predict the sentiment of the aspect category. The constrained attention networks   handles multiple aspect categories of a sentence simultaneously and introduces orthogonal and sparse regularizations to constrain the attention weight allocation. The aspect-level sentiment capsules model  performs ACD and ACSA simultaneously, which also uses an attention mechanism to find aspect category related sentiment words and achieves state-of-the-art performances on the ACSA task.  However, these models directly use the given aspect category to find the aspect category-related sentiment words, which may cause mismatching between the sentiment words and the aspect categories when an unrelated sentiment word is semantically meaningful for the given aspect category. For the example in Fig., ``Great'' and ``bad'' can be used interchangeably. It is hard for attention-based methods to distinguish which word is associated with aspect category food or service among ``good'' and ``bad''. To solve the problem, The HiErarchical ATtention network  first finds the aspect terms indicating the given aspect cagegory, then finds the aspect category-related sentiment words  depending on the position information and semantics of the aspect terms. Although HEAT obtains good results, to train HEAT, we additionally need to annotate the aspect terms indicating the given aspect category, which can be time-consuming and expensive.  To mitigate the mismatch problem, we propose a Sentence Constituent-Aware Network  for aspect-category sentiment analysis which does not require any additional annotation. SCAN contains two graph attention networks   and an interactive loss function. Given a sentence, we first use the Berkeley Neural Parser  to generate the constituency parse tree. The two GATs generate representations of the nodes in the sentence constituency parse tree for the ACD task and the ACSA task, respectively. The GAT for ACD mainly attends to the words indicating aspect categories, while the GAT for ACSA mainly attends to sentiment words. For a given aspect category, the interactive loss function helps the ACD task to find the nodes that can predict the aspect category but can閳ユ獩 predict other aspect categories. The sentiment words in the nodes then are used to predict the sentiment polarity of the aspect category by the ACSA task. Fig.  shows the constituency parse tree of the sentence ``Greate taste bad service.''. For the aspect category food, SCAN first finds the yellow nodes ``Greate taste'' and ``taste'', then predict the sentiment of food based on the sentiment word ``Great'' in the node ``Great taste''. SCAN excludes the blue node ``Great taste bad service.'' for food, because it can predict not only food but also service.  The main contributions of our work can be summarized as follows:      Complex Word Indentification is a challenging task, even when using state-of-the-art Transformer-based solutions. In this work, we introduce an approach that improves the previous results on the cross-lingual and monolingual CWI shared task 2018 by using multilingual and language-specific Transformer models, multilingual word embeddings , and different fine-tuning techniques. Fine-tuning a model on data from two different languages creates the opportunity of grasping features that empower it to better recognize complex words in certain contexts, even in a different language. In addition, zero-shot, one-shot, and few-shot learning strategies provide good results, surpassing strong baselines  and proposing an alternative to help non-native speakers to properly understand the difficult aspects of a certain language.  For future work, we intend to improve our results on the monolingual tasks by integrating additional models, such as XLNet  and techniques like adversarial training and multi-task learning. Furthermore, we intend to experiment with other pretraining techniques specific to Transformer models, such that the results for French can benefit from cross-lingual transfer learning.  
"," Aspect category sentiment analysis  aims to predict the sentiment polarities of the aspect categories discussed in sentences. Since a sentence usually discusses one or more aspect categories and expresses different sentiments toward them, various attention-based methods have been developed to allocate the appropriate sentiment words for the given aspect category and obtain promising results. However, most of these methods directly use the given aspect category to find the aspect category-related sentiment words, which may cause mismatching between the sentiment words and the aspect categories when an unrelated sentiment word is semantically meaningful for the given aspect category. To mitigate this problem, we propose a Sentence Constituent-Aware Network  for aspect-category sentiment analysis. SCAN contains two graph attention modules and an interactive loss function. The graph attention modules generate representations of the nodes in sentence constituency parse trees for the aspect category detection  task and the ACSA task, respectively. ACD aims to detect aspect categories discussed in sentences and is a auxiliary task. For a given aspect category, the interactive loss function helps the ACD task to find the nodes which can predict the aspect category but can闁炽儲鐛 predict other aspect categories. The sentiment words in the nodes then are used to predict the sentiment polarity of the aspect category by the ACSA task. The experimental results on five public datasets demonstrate the effectiveness of SCAN. \footnote{Data and code can be found at https://github.com/l294265421/SCAN}  \keywords{Aspect Category Sentiment Analysis  \and Aspect Based Sentiment Analysis \and Graph Attention Network.}",146
"  With the rapid development of e-commerce, online reviews written by  users  have become increasingly important for reflecting real customer experiences. To ease the process of review writing, the task of personalized review generation~ has been proposed to automatically produce review text conditioned on necessary context data, \eg users, items, and ratings.  As a mainstream solution, RNN-based models  have been widely applied to the PRG task. Standard RNN models mainly model sequential dependency among tokens,  which cannot effectively generate high-quality review text. Many efforts have been devoted to improving this kind of architecture for the PRG task, including context utilization,  long text generation, and  writing style enrichment. These studies have improved the performance of the PRG task to some extent. However, two major issues still remain to be solved. First, the generated text is likely  to be uninformative, lacking factual description on product information. Although several studies try to incorporate structural or semantic features ,  they mainly extract such features from the review text.   Using review data alone, it is difficult to fully capture diverse and comprehensive facts from unstructured text. Second, most of these studies focus on word-level generation, which makes it difficult to directly model  user preference at a higher level. For example, given a product, a user may focus on the price, while another user may emphasize the look.  To address these issues, we propose to improve the PRG task with external knowledge graph . By associating online items with KG entities, we are able to obtain rich attribute or feature information for items, which is potentially useful for the PRG task. Although the idea is intuitive, it is not easy to fully utilize the knowledge information for generating review text in our task. KG typically organizes facts as triples, describing the relation between two involved entities. It may not be suitable to simply integrate KG information to enhance text representations or capture user preference due to varying intrinsic characteristics of different data signals.  In order to bridge the semantic gap, we augment the original KG with user and word nodes, and construct a heterogeneous knowledge graph  by adding user-item links and entity-word links. User-item links are formed according to user-item interactions, and entity-word links are formed according to their co-occurrence in review sentences. We seek to learn a unified semantic space that is able to encode different kinds of nodes. Figure presents an illustrative example for the HKG. Given such a graph, we focus on two kinds of useful information for the PRG task. First, the associated facts regarding to an item  can be incorporated to enrich the review content. Second, considering users as target nodes, we can utilize this graph to infer users' preference  on some specific relation or aspect . The two kinds of information reflect word- and aspect-level enrichment, respectively. To utilize the semantics at the two levels, we decompose  the review generation process into two stages, namely aspect sequence generation and sentence generation.  We aim to inject multi-granularity KG information in different generation stages for improving the PRG task.     To this end, in this paper, we propose a KG-enhanced personalized review generation model based on capsule graph neural networks~. Compared with most of existing GNN-based methods representing graphs as individual scalar features, Caps-GNN can extract underlying characteristics of graphs as capsules at the graph level through the dynamic routing mechanism and each capsule reflects the graph properties in different aspects. Based on the constructed HKG, we utilize Caps-GNN to extract graph properties in different aspects as graph capsules, which may be helpful to infer aspect- and word-level user preference. For aspect sequence generation, we propose a novel adaptive learning algorithm that is able to capture personalized user preference at the aspect level, called aspect capsules, from the graph capsules.  We associate an aspect capsule with a unique aspect from unsupervised topic models.   Furthermore, for the generation of sentences, we utilize the learned aspect capsules to capture personalized user preference at the word level. Specially, we design a graph-based copy mechanism to generate related entities or words by copying them from the HKG, which can enrich the review contents.  In this way, KG information has been effectively utilized  at both aspect and word levels in our model.   %To our knowledge, we are the first to utilize knowledge graph to generate personalized review text, which is able to capture both aspect- and word-level KG semantics for learning user preference.  To our knowledge, we are the first to utilize KG to capture both aspect- and word-level user preference for generating personalized review text. For evaluation, we constructed three review datasets by associating items with KG entities. Extensive experiments  demonstrate the effectiveness of KG information and our model. %%Our code and dataset will be released after the review period.         In this paper, We propose a Sentence Constituent-Aware Network  for aspect-category sentiment analysis. The two graph attention modules and the interactive loss function in SCAN form a complete solution to alleviate the mismatch problem. The experimental results on five public datasets demonstrate the effectiveness of SCAN. Future work could consider making the representations of the leaf nodes richer by using syntactic information from the dependency tree of the sentence and modelling the inter-aspect category dependencies.     ---- Bibliography ----     BibTeX users should specify bibliography style 'splncs04'.   References will then be sorted and formatted in the correct style.   
"," Personalized review generation  aims to automatically produce review text reflecting user preference, which is a challenging natural language generation task. Most of previous studies do not explicitly model  factual description of products, tending to generate uninformative content. Moreover, they mainly focus on word-level generation, but cannot accurately reflect more abstractive  user preference in multiple aspects.  To address the above issues, we propose a novel knowledge-enhanced PRG model  based on capsule graph neural network~. We first  construct a heterogeneous knowledge graph  for utilizing rich item attributes. We adopt  Caps-GNN to learn graph capsules for encoding underlying characteristics from the HKG. Our generation process contains two major steps, namely aspect sequence generation and sentence generation. First, based on graph capsules, we adaptively learn aspect capsules for inferring the aspect sequence.   Then, conditioned on the inferred aspect label, we design a graph-based copy mechanism to generate sentences by incorporating related entities or words from HKG. To our knowledge, we are the first to utilize knowledge graph for the PRG task. The incorporated KG information is able to enhance user preference at both aspect and word levels. Extensive experiments on three real-world datasets have demonstrated the effectiveness of our model on the PRG task.",147
" As mentioned in Chapter , models trained simply to obtain a high accuracy on held-out sets can often learn to rely on shallow input statistics, resulting in brittle models. % susceptible to adversarial attacks. For example, \citet{lime} present a document classifier that distinguishes between Christianity and Atheism with a test accuracy of . However, on close inspection, the model spuriously separates classes based on words contained in the headers, such as ``Posting'', ``Host'', and ``Re''.  Spurious correlations in both training and test sets allow for such undesired models to obtain high accuracies. Much more complex hidden correlations may be present in any arbitrarily large and human-annotated dataset . Such correlations may be difficult to spot, and even when one identifies them, it is an open question how to mitigate them .   In this chapter, I investigate a direction that has the potential to both steer neural models away from relying on spurious correlations and provide explanations for the predictions of these models. This direction is that of enhancing neural models with the capability to learn from natural language explanations during training time and to generate such explanations at test time. For humans, it has been shown that explanations play a key role in structuring conceptual representations for categorisation and generalisation . Humans also benefit tremendously from reading explanations before acting in an environment for the first time . Thus, explanations may also be used to set a model in a better initial position to further learn the correct functionality. Meanwhile, at test time, generating correct argumentation in addition to obtaining a high accuracy has the potential to endow a model with a higher level of transparency and trust.     %In this work, we introduce a new dataset and models for exploiting and generating explanations for the task of recognizing textual entailment.  Incorporating external knowledge into a neural model was shown to result in more robust models . % show that models achieving high accuracies on SNLI, such as , show dramatically reduced performance on this simpler dataset, while the model of \citet{kim} is more robust due to incorporating external knowledge.  Free-form natural language explanations are a form of external knowledge that has the following advantages over formal language. First, it is easy for humans to provide free-form language, eliminating the additional effort of learning to produce formal language, thus making it simpler to collect such datasets. Secondly, natural language explanations might potentially be mined from existing large-scale free-form text. Finally, natural language is readily comprehensible to an end-user who needs to assert the reliability of a model.  %Thirdly, the formal languages chosen by researchers may differ from work to work and therefore models constructed over one formal language might not be trivially transferred to another. Meanwhile free-form explanations are generic and applicable to diverse areas of research, such as natural language processing, computer vision, or policy learning.   Despite the potential for natural language explanations to improve both learning and transparency, there is a scarcity of such datasets in the community, as discussed in Section .  To address this deficiency, I collected a large corpus of K human-annotated explanations for the SNLI dataset~. I chose SNLI because it constitutes an influential corpus for natural language understanding that requires deep assimilation of fine-grained nuances of commonsense knowledge. %A plethora of models have been developed on this dataset, including previous state-of-the-art in universal sentence representations , which demonstrates the power of this task and dataset. I call this explanation-augmented dataset e-SNLI, which I release publicly\footnote{The dataset can be found at \url{https://github.com/OanaMariaCamburu/e-SNLI}.} to advance research in the direction of training with and generation of free-form natural language explanations.    %To demonstrate the efficacy of the e-SNLI dataset,  %I show that it is much more difficult for neural models to produce correct natural language explanations based on spurious correlations than it is to produce correct labels. Further, I develop models that predict a label and generate an explanation for their prediction. I also investigate how the presence of natural language explanations at training time can guide neural models into learning better universal sentence representations  and into having better capabilities to solve out-of-domain instances.  Secondly, I show that it is much more difficult for a neural model to produce correct natural language explanations based on spurious correlations than it is for it to produce correct labels based on such correlations.   Thirdly, I develop models that predict a label and generate an explanation for their prediction, and I investigate the correctness of the generated explanations.   Finally, I investigate whether training a neural model with natural language explanations can result in better universal sentence representations produced by this model and in better performance on out-of-domain datasets.   \paragraph{Remark.} In this chapter, I use the concept of correct explanation to refer to the correct argumentation for the ground-truth label on an instance.  This should not be confused with the concept of faithful explanation, which refers to the accuracy with which an explanation describes the decision-making process of a model, as described in Section .  The capability of a neural model to generate correct explanations is an important aspect of the development of such models.  For example, correct argumentation may sometimes be needed in practice, alongside the correct final answer. Hence, in this chapter, I inspect the correctness of the explanations generated by the introduced neural models. In the next chapter, I will take a step towards verifying the faithfulness of these explanations.% is given in Chapter .     In this paper, we propose a structured meta-learning algorithm for open domain dialogue generation on infrequent sentence functions. To tackle the low-resource issue, our proposed model, based on the recently proposed model-agnostic meta-learning, can find both transferable internal representations and sensible parameters which can produce large improvement under a few adaptation steps. Moreover, we further explore the structure across fine-grained sentence functions and such that the model can balance knowledge generalization and knowledge customization. Extensive experiments show that our structured meta-learning  algorithm outperforms existing approaches under the low-resource setting.   
","  Deep neural networks are becoming more and more popular due to their revolutionary success in diverse areas, such as computer vision, natural language processing, and speech recognition. However, the decision-making processes of these models are generally not interpretable to users. In various domains, such as healthcare, finance, or law, it is critical to know the reasons behind a decision made by an artificial intelligence system. Therefore, several directions for explaining neural models have recently been explored.   In this thesis, I investigate two major directions for explaining deep neural networks. The first direction consists of feature-based post-hoc explanatory methods, that is, methods that aim to explain an already trained and fixed model , and that provide explanations in terms of input features, such as tokens for text and superpixels for images . The second direction consists of self-explanatory neural models that generate natural language explanations, that is, models that have a built-in module that generates explanations for the predictions of the model. The contributions in these directions are as follows.   % In this thesis, I investigate the topic of explaining deep neural networks. This topic is crucial nowadays as neural model are becoming more and more employed in real-world applications due to their high performance in diverse areas, such as computer vision, natural language processing, and speech recognition. However, the decision-making processes learned by these models are not generally human-interpretable. In various real-world applications, such as healthcare, finance, or criminal justice, it is critical to know the reasons behind a decision made by an artificial intelligence system. Therefore, several directions for explaining neural models have recently been explored.   % a series of methods have recently been developed to provide explanations for the predictions of neural models. This thesis brings contributions to two major directions for explaining deep neural networks: feature-based post-hoc explanatory methods and self-explanatory neural models that generate natural language explanations for their predictions. The contributions are as follows.   %However, it is still an open question how to verify whether the explanations provided by these methods are faithfully describing the decision-making processes of the models that they aim to explain. Secondly, it is also an open question whether neural networks can learn from human-provided natural language explanations for the ground-truth labels at training time, as well as support their predictions with natural language explanations at test time, just like humans do.    First, I reveal certain difficulties of explaining even trivial models using only input features. I show that, despite the apparent implicit assumption that explanatory methods should look for one specific ground-truth feature-based explanation, there is often more than one such explanation for a prediction. I also show that two prevalent classes of explanatory methods target different types of ground-truth explanations without explicitly mentioning it. Moreover, I show that, sometimes, neither of these explanations is enough to provide a complete view of a decision-making process on an instance. %These findings can have an important impact on how users choose explanatory methods to best suit their needs.    Second, I introduce a framework for automatically verifying the faithfulness with which feature-based post-hoc explanatory methods describe the decision-making processes of the models that they aim to explain. This framework relies on the use of a particular type of model that is expected to provide insight into its decision-making process. I analyse potential limitations of this approach and introduce ways to alleviate them.  % The introduced verification framework is generic and can be instantiated on different tasks and domains to provide off-the-shelf sanity tests that can be used to test feature-based post-hoc explanatory methods. I instantiate this framework on a task of sentiment analysis and provide sanity tests\footnote{The sanity tests are available at \\ \url{https://github.com/OanaMariaCamburu/CanITrustTheExplainer}.} %to test any feature-based post-hoc explanatory method. Furthermore,  on which I present the performances of three popular explanatory methods. %The results show that these methods may provide unfaithful explanations.  %I also discuss ways in which the current limitations of the framework can further be addressed to lead to more robust and flexible verifications.    %In the process of developing this framework, I uncover several ways in which a particular type of model that is expected to provide insight into its decision-making process can provide misleading such insight. I also introduce checks that can be done to account for this misleading insight in order to use this type of model in the proposed framework.  % %%%%%%%% BEFORE %%%%%%%%%%The framework is generic and can be instantiated on different tasks and domains. I instantiate it on a task of sentiment analysis and provide sanity tests that can be used off-the-shelf\footnote{The tests are available at \url{https://github.com/OanaMariaCamburu/CanITrustTheExplainer}.} to test any feature-based post-hoc explanatory method. Furthermore, I present preliminary results of three explanatory methods on these tests, which raise awareness of the unfaithful explanations that these methods may provide. %I discuss ways in which the limitations of this verification framework can further be addressed and open the path towards more robust and flexible verification frameworks that can be adapted to users' needs.  %%%% this framework relies on the use of a particular type of model that is expected to provide insight into its decision-making process. I analyse the potential limitations of this approach and introduce ways to overcome them. By constructions   %In addition, as a step towards addressing the question of verifying if explanatory methods faithfully describe the decision-making processes learned by the models they aim to explain, I investigate a particular type of self-explanatory neural model and I show three ways in which this type of model can provide misleading explanations. % on its decision-making process.    %Secondly, I present a novel verification framework that can generate a multitude of sanity tests for explanatory methods. I instantiate this framework on the task of sentiment analysis and provide three sanity tests, which can be used off-the-shelf.\footnote{The tests are available at \url{https://github.com/OanaMariaCamburu/CanITrustTheExplainer}.} I present the results of three explanatory methods on these tests. I discuss ways in which the limitations of this verification framework can further be addressed and open the path towards more robust and flexible verification frameworks that can be adapted to users' needs.  % improve their behaviour and performance %exhibit improved behaviour  % if they are additionally given natural language explanations for the ground-truth label at training time  Third, to explore the direction of self-explanatory neural models that generate natural language explanations for their predictions, I collected a large dataset of $\sim\!\!570$K human-written natural language explanations on top of the influential Stanford Natural Language Inference  dataset. I call this explanation-augmented dataset e-SNLI.\footnote{The dataset is publicly available at \url{https://github.com/OanaMariaCamburu/e-SNLI}.} %, which I release publicly\footnote{The dataset is available at \url{https://github.com/OanaMariaCamburu/e-SNLI}.} %to advance research in the direction of training with and generation of natural language explanations.  % Further, I provide empirical evidence that models generating correct explanations are more reliable than models that just predict the correct labels.  % I also train different neural models that generate natural language explanations at test time, and I measure the success of these models to generate correct explanations. I also investigate whether the presence of natural language explanations at training time can lead a model to produce better universal sentence representations and to perform better on out-of-domain datasets. I do a series of experiments that investigate both the capabilities of neural models to generate correct natural language explanations at test time, and the benefits of providing natural language explanations at training time.  Fourth, I show that current self-explanatory models that generate natural language explanations for their own predictions may generate inconsistent explanations, such as ``There is a dog in the image.'' and ``There is no dog in the [same] image.''. Inconsistent explanations reveal either that the explanations are not faithfully describing the decision-making process of the model or that the model learned a flawed decision-making process.  I introduce a simple yet effective adversarial framework for sanity checking models against the generation of inconsistent natural language explanations. Moreover, as part of the framework, I address the problem of adversarial attacks with exact target sequences, a scenario that was not previously addressed in sequence-to-sequence attacks, and which can be useful for other tasks in natural language processing. I apply the framework on a state of the art neural model on e-SNLI and show that this model can generate a significant number of inconsistencies.  This work paves the way for obtaining more robust neural models accompanied by faithful explanations for their predictions.  %My hope is that in the future feature-based post-hoc explanatory methods will be superseded  by robust and accurate neural models that faithfully explain themselves to their human users in natural language.",148
"  We use a sequence of vectors to represent a sentence, where each vector consists of  a semantic-role  tag, a part-of-speech  tag, and other syntactic and semantic tags,  and we refer to such a sequence as a \textsl{meta sequence}.  We present an application using meta-sequence learning to generate, on a given article,  adequate QAPs to form multiple-choice questions.  In particular, we develop a scheme called MetaQA to learn meta sequences  of declarative sentences and the corresponding interrogative sentences from a training dataset. % consisting of such sentences. Combining and removing redundant meta sequences yields a set called MSDIP  , with each element being a pair of an MD and corresponding MI, where MD and MI stand for, respectively, a meta sequence for a declarative sentence and for an interrogative sentence. A trained MetaQA model generates QAPs for a given declarative sentence  as follows: Generate a meta sequence for , find a best-matched MD from MSDIP, generates meta sequences for interrogative sentences according to the corresponding MIs and the meta sequence of , identifies the meta-sequence answer to each MI, and coverts them back to text to form a QAP.    \begin{comment}    Our work put forwards an opinion triplet extraction perspective for aspect-based sentiment analysis. Existing works that are applicable to opinion triplet extraction have been shown insufficient, owing to the use of unified aspect-sentiment tagging scheme and ignorance of the interaction between elements in the triplet. Thus, we propose a multi-task learning framework to address the limitations by highlighting the uses of joint training, decoupled aspect and sentiment prediction, and regularization among correlated tasks during learning. Experimental results verify the effectiveness of our framework in comparison with a wide range of strong baselines. Comparison results with different variants of the proposed framework signify the necessity of the core components in the framework.  Based on the observations from a case study and error analysis, we plan to carry out further research in the following aspects:  more robust taggers for aspect and opinion extraction,  more flexible evaluation metric for triplet extraction, and  more mighty triplet interaction mechanism .     File emnlp2020.tex      Based on the style files for ACL 2020, which were    Based on the style files for ACL 2018, NAACL 2018/19, which were    Based on the style files for ACL-2015, with some improvements     taken from the NAACL-2016 style    Based on the style files for ACL-2014, which were, in turn,    based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,    EACL-2009, IJCNLP-2008...    Based on the style files for EACL 2006 by    e.agirre@ehu.es or Sergi.Balari@uab.es    and that of ACL 08 by Joakim Nivre and Noah Smith  \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{emnlp2020} \usepackage{times} \usepackage{latexsym} \renewcommand{\UrlFont}{\ttfamily\small} \usepackage{booktabs} \usepackage{color} \usepackage{tikz-dependency} \usepackage{amsfonts} \usepackage{amsmath} \usepackage{multirow} \usepackage{makecell} \usepackage{pifont} \newcommand{\cmark}{\ding{51}} \newcommand{\xmark}{\ding{55}} \usepackage[noend]{algpseudocode} \usepackage{algorithmicx,algorithm}    This is not strictly necessary, and may be commented out,   but it will improve the layout of the manuscript,   and will typically save some space. \usepackage{microtype}  \aclfinalcopy   Uncomment this line for the final submission \def\aclpaperid{704}    Enter the acl Paper ID here   \setlength\titlebox{5cm}   You can expand the titlebox if you need extra space   to show all the authors. Please do not make the titlebox   smaller than 5cm ; we will check this   in the camera-ready version and ask you to change it back.  \newcommand\BibTeX{B\TeX}  \title{A Multi-task Learning Framework for Opinion Triplet Extraction}  \author{Chen Zhang\textsuperscript{1}, Qiuchi Li\textsuperscript{2}, Dawei Song\textsuperscript{1}\Thanks{ Dawei Song is the corresponding author.}, Benyou Wang\textsuperscript{2} \\   \textsuperscript{1} Beijing Institute of Technology, Beijing, China. \\   \textsuperscript{2} University of Padova, Padova, Italy. \\    \texttt{\{czhang,dwsong\}@bit.edu.cn}, \texttt{\{qiuchili,wang\}@dei.unipd.it} \\}  \date{}           
"," %Creating multiple-choice questions to assess reading comprehension of a given article %involves generating question-answer pairs  on the main points of the document. We present a meta-sequence representation of sentences and demonstrate how to use meta-sequence learning to generate adequate question-answer pairs  over a given article. %learning scheme to generate adequate QAPs  %via meta-sequence representations of sentences.   %without handcrafted features.  A meta sequence is a sequence of vectors of semantic and syntactic tags. %In particular, %we devise a scheme called MetaQA to %learn meta sequences from training data to form  %pairs of a meta sequence for a declarative sentence   %and a corresponding  interrogative sentences . % indexed for fast retrieval,  On a given declarative sentence, a trained model  converts it to a meta sequence,  finds a matched meta sequence in its learned database,  and   uses the corresponding meta sequence for interrogative sentence to generate QAPs. %We implement MetaQA for the English language using  %semantic-role labeling,  %part-of-speech tagging, and  named-entity recognition, We show that, trained on a small dataset,  our method generates efficiently, on the official SAT practice reading tests, a large number of syntactically and semantically correct QAPs with high accuracy.",149
"  The desire for human-like interfaces to technical systems, as evidenced by growing use of intelligent assistants, belies the need for conversational AI systems that can accomplish a wide range of tasks, such as booking restaurants, trains, and flights, IT help desk and accessing financial accounts and transaction records. The wide range of tasks have necessitated the need for a flexible and scalable dialogue system that can support a variety of use cases with minimal development and maintenance effort. Existing dialogue systems are broken into two major categories,  open-domain dialogue systems, which focus on non-task related conversations, and task-oriented dialogue systems, which focus on user task completion. A typical open-domain system uses an end-to-end neural architecture often trained with input and output utterances from human-to-human conversations . While open-domain systems are optimized for engaging in human-like conversation, they lack any inherent ability to interface with any other systems on behalf of their conversation partner. Whereas, a typical task-oriented dialogue system seeks to understand human intents and execute them. This is done by adopting a modularized pipeline architecture with three modules that are sequentially connected as shown in Fig. . A natural language understanding  module that recognizes user intents and extract useful entity information . The dialogue management  module contains two submodules, the dialogue state tracker  and the dialogue action policy  modules. The DST module tracks the mapping of entities to slots that are relevant or required for completing user tasks . The POL module decides which actions to execute via the API. Finally, the natural language generation  module generates the user response based on the user aspects of the system actions . In some cases, multiple modules are combined together, e.g. systems with a composite NLU and DST module , and systems with a composite POL and NLG module that maps previous utterances and dialogue states to the system response .  Despite research advances in modular neural approaches, they are hardly used in practice. Industrial dialogue systems, though modularized, still use expensive expert driven rule-based heuristics implemented with several lines of codes and hand-crafted templates, and therefore difficult to scale as the number of use cases grows. More recently, there has been a renewed effort to apply a single end-to-end neural architecture  to model task-oriented dialogue with the use of autoregressive transformer architecture . This has led to the reformulation of dialogue system design as a text generation or sequence modeling task. While some of these efforts have obtained state-of-the-art performance on publicly available task-oriented dialogue datasets, there is still room for improvement, especially in the areas of generality and practicality. First, their problem formulation fails to reconcile open-domain and task-oriented dialogue in the same model architecture. Also, in many cases, they do not address the complexity of the action policy especially towards the back-end API system. Finally, they don't fully incorporate the control, verification and explanation capabilities that make modularized approaches attractive.  To resolve these shortcomings, we propose DLGNet-Task, an end-to-end neural network that simultaneously handles both open-domain and task-oriented dialogue, in such a way that the model outputs are controllable, verifiable, and explainable at the module level. This system is compatible with both data driven and expert driven rule-based approaches.   That is, our approach is simultaneously modular and end-to-end, and can be a drop-in replacement for traditional modular task-oriented dialogue  systems. To the best of our knowledge, this is the most expressive approach to date in achieving this objective. In summary, we are able to model the individual behavior of NLU, DM and NLG components with a single neural network model trained end-to-end. Still, the model is flexible enough to allow individual modules to be separately trained and validated in line with the traditional TOD system.  % Validation at module level can provide information about where additional training is needed. It could also help in balancing the contribution of each module if the model is finetuned with module-level objectives.  % The DLGNet-Task model is based on the autoregressive transformer architecture similar to DLGNet  and GPT-2/3  models. To evaluate the performance of DLGNet-Task, we trained the model with just the system-level training objective on a modified MultiWoz2.1 dataset. The dataset modification is done mainly to support DLGNet-Task design framework . Based on the widely used TOD metrics, such as inform rate, success rate, and BLEU score , our experiments show that DLGNet-Task produces a comparable performance to the state-of-the-art approaches on the MultiWoz2.1 dataset.  % in addition to the controllable, verifiable, and explainable model's intermediate outputs.       In this paper, we presented a technique for optimal synthesis from multimodal specifications. On a benchmark of complex regex synthesis problems, we showed that this approach is substantially more accurate than past models, and our synthesis algorithm finds the model-optimal program more frequently compared to beam search. While we have evaluated this method in the context of regular expressions, our technique is also applicable for other synthesis tasks.     
"," Task oriented dialogue  requires the complex interleaving of a number of individually controllable components with strong guarantees for explainability and verifiability. This has made it difficult to adopt the multi-turn multi-domain dialogue generation capabilities of streamlined end-to-end open-domain dialogue systems. In this paper, we present a new framework, DLGNet-Task, a unified task-oriented dialogue system which employs autoregressive transformer networks such as DLGNet and GPT-2/3 to complete user tasks in multi-turn multi-domain conversations. Our framework enjoys the controllable, verifiable, and explainable outputs of modular approaches, and the low development, deployment and maintenance cost of end-to-end systems. Treating open-domain system components as additional TOD system modules allows DLGNet-Task to learn the joint distribution of the inputs and outputs of all the functional blocks of existing modular approaches such as, natural language understanding , state tracking, action policy, as well as natural language generation . Rather than training the modules individually, as is common in real-world systems, we trained them jointly  with appropriate module separations. When evaluated on the MultiWOZ2.1 dataset, DLGNet-Task shows comparable performance to the existing state-of-the-art approaches. Furthermore, using DLGNet-Task in conversational AI systems reduces the level of effort required for developing, deploying, and maintaining intelligent assistants at scale.  % significant improvement over existing approaches, and achieves state-of-the-art performance at both the module and system levels.",150
"   Knowledge graphs  represent knowledge of the world as relationships between entities, i.e., triples with the form  . Such knowledge resource provides clean and structured evidence for many downstream applications such as question answering. KGs are usually constructed by human experts, which is time-consuming and leads to highly incomplete graphs . Therefore automatic KG completion  is proposed to infer a missing link of relationship  between a head entity  and a tail entity .    Existing KG completion work mainly makes use of two types of information: 1) co-occurrence of entities and relations and 2) deducible reasoning paths of tuples. KG embeddings encode entities and relations, the first type of information, together into continuous vector space with low-rank tensor approximations~.  Ours approach utilizes the second type of information, reasoning path of tuples that can be deduced to the target tuple~. Here a reasoning path starts with the head entity  and ends with the tail entity \e{t}: \e{h \overset{r_1}{\rightarrow} e_1  \overset{r_k}{\rightarrow} e_k \overset{r_N}{\rightarrow} t}, where \e{r_1 \wedge ... \wedge r_N} forms a relation chain that infers the existence of . Therefore these methods are also referred as multi-hop reasoning over KGs, which learns a multi-hop chain as a rule to deduce the target . An example of such a chain is given in Figurea to infer whether an athlete plays in an location. Multi-hop reasoning approaches can usually utilize richer evidence and self-justifiable in terms of  reasoning path rules used in the predictions, making the prediction of missing relations more interpretable.   Despite  advantages and  success of the multi-hop reasoning approach , a target relationship may not be perfectly inferred from a single relation chain. There could exist multiple weak relation chains that correlate with the target relation. Figure gives examples of such cases.  These multiple chains could be leveraged in following ways:  the reasoning process naturally relies on the logic conjunction of multiple chains ;  more commonly, there are instances for which none of the chains is accurate, but aggregating multiple pieces of evidence improves the confidence , as also observed in the case-based study works. Inspired by these observations, we propose the concept of  multi-chain multi-hop rule set.  Here, instead of treating each single multi-hop chain as a rule, we learn rules consisting of a small set of multi-hop chains. Therefore the inference of target relationships becomes a joint scoring of such  a set of chains. {We  treat each set of chains as one rule and, since different query pairs can follow different rules, together we have  a set of rules to reason each relation.}  Learning the generalized multi-hop rule set is a combinatorial search problem.  We address this challenge with a game-theoretic approach inspired by. Our approach consists of two steps:  selecting a generalized multi-hop rule set by employing a Multi-Layer Perceptron  over the candidate chains;   reasoning with the generalized rule set, which uses another MLP to model the conditional probability of the target relationship given the selected relation chains. The nonlinearity of MLP as reasoner provides the potential to model the logic conjunction among the selected chains in the rule set.  We demonstrate the advantage of our method on KG completion tasks in FB15K-237 and NELL-995. Our method outperforms existing single-chain approaches, showing that our defined generalized rules are necessary for many reasoning tasks.     In this paper, we have proposed DLGNet-Task, an end-to-end neural network framework for modeling multi-turn multi-domain task-oriented dialogue. The DLGNet-Task model learns the joint distribution of the nodes  of a dialogue flow graph capable of representing both task-oriented and open-domain dialogue systems. For TOD specific applications, DLGNet-Task is also capable of learning the action policy towards the back-end API. Experimental results show that DLGNet-Task gives comparable performance with existing approaches with practical focus. The results also showed that performance of DLGNet is hampered by the errors in the original MultiWoz dataset as well as the noise introduced during the data processing.    While DLGNet-task framework is capable to learning a controllable, verifiable and explainable end-to-end model.  This also shows need for consistent TOD datasets with properly defined dialogue flow graph. We hope to explore this direction as part of our future work both in terms of dataset generation and data processing pipeline. We also hope to improve DLGNet-Task model performance with adversarial and reinforcement learning.        \clearpage   \break        \iffalse \iftrue \setcounter{table}{0} \renewcommand{\thetable}{A\arabic{table}}      
"," Multi-hop reasoning approaches over knowledge graphs infer a missing relationship between entities with a multi-hop rule, which corresponds to a chain of relationships. We extend existing works to consider a generalized form of multi-hop rules, where each rule is a set of relation chains.  To learn such generalized rules efficiently, we propose a two-step approach that first selects a small set of relation chains as a rule and then evaluates the confidence of the target relationship by jointly scoring the selected chains. A game-theoretical framework is proposed to this end to simultaneously optimize the rule selection and prediction steps. Empirical results show that our multi-chain multi-hop  rules result in superior results compared to the standard single-chain approaches, justifying both our formulation  of  generalized rules  and the effectiveness of the proposed learning framework.",151
"  Generating text that conforms to syntactic or semantic constraints benefits many NLP applications. To name a few, when paired data are limited, \citet{yang-etal-2019-low} build templates from large-scale unpaired data to aid the training of the dialog generation model; \citet{Niu2017ASO} and \citet{liu-etal-2019-rhetorically} apply style constraints to adjust the formality or rhetoric of the utterances; \citet{iyyer2018adversarial} and \citet{li-etal-2019-Insufficient} augment dataset using controlled generation to improve the model performance.  We study the problem of syntactically controlled text generation, which aims to generate target text with pre-defined syntactic guidance. Most recent studies on this topic  use sentences as exemplars to specify syntactic guidance. However, the guidance specified by a sentence can be vague, because its syntactic and semantic factors are tangled. Different from them, we use constituency parse trees as explicit syntactic constraints. As providing full-fledged parse trees of the target text is impractical, we require only a template parse tree that sketches a few top levels of a full tree . Figure shows our pipeline.    \citet{iyyer2018adversarial} adopt the same setting as ours. Their proposed SCPN model uses two LSTM  encoders to respectively encode source text and parse tree, and connects them to one decoder with additional attention  and pointer  structures. Nonetheless, recurrent encoders not only suffer from information loss by compressing a whole sequence into one vector but also are incapable of properly modeling the tree structure of constituency parse as well. Consequently, their network tends to ``translate'' the parse tree, instead of learning the real syntactic structures from it. % \zc{this sentence is still unclear.}  We propose a Transformer-based syntax-guided text generation method, named \ours. It first expands a template constituency parse tree to a full-fledged parse tree tailored for the input source text, and then uses the full tree to guide text generation. To capture the tree structure of the syntax, we apply a path attention mechanism  to our text generation model. It forces one node to attend to only other nodes located in its path  instead of all the nodes in the tree. Such a mechanism limits the information flow among the nodes in the constituency tree that do not have the direct ancestor-descendant relationship, forcing the parent nodes to carry more information than their children. In cooperation with path attention, we linearize the constituency trees to a more compact node-level format . Moreover, to address the challenge of properly integrating the semantic and syntactic information, we design a multi-encoder attention mechanism . It enables the Transformer decoder to accept outputs from multiple encoders simultaneously.  We evaluated our model on the controlled paraphrasing task. The experiment results show that \ours outperforms the state-of-the-art SCPN method by  in syntactic quality and  in semantic quality. % \zc{ use absolute improvements instead of relative ones} Human evaluations prove our method generates  semantically and syntactically superior sentences, with  semantic and  syntactic score improvements. % \zc{also give concrete numbers here, how much improvements?} Further, we find that the multi-encoder attention mechanism enhances the Transformer's ability to deal with multiple inputs, and the path attention mechanism significantly contributes to the model's semantic performance .   Our contributions include: 1) a multi-encoder attention mechanism that allows a Transformer decoder to attend to multiple encoders; 2) a path attention mechanism designed to better incorporate tree-structured syntax guidance with a special tree linearization format; and 3) a syntax-guided text generation method \ours that achieves new state-of-the-art semantic and syntactic performance.   We propose a new approach of multi-chain multi-hop rule learning for knowledge graph completion tasks. First, we formalize the concept of multi-hop rule sets with multiple relation chains from knowledge graphs. Second, we propose a game-theoretical learning approach to efficiently select predictive relation chains for a query relation. Our formulation and learning method demonstrate advantages on two benchmark datasets over existing single-chain based approaches. For future work, we plan to investigate rules beyond chains, as well as integrate KG embeddings into our framework.   
","   We study the problem of using  constituency parse trees as syntactic guidance for controlled text generation. Existing approaches to this problem use recurrent structures, which not only suffer from the long-term dependency problem but also falls short in modeling the tree structure of the syntactic guidance. We propose to leverage the parallelism of Transformer to better incorporate parse trees. Our method first expands a partial template constituency parse tree to a full-fledged parse tree tailored for the input source text, and then uses the expanded tree to guide text generation. The effectiveness of our model in this process hinges upon two new attention mechanisms: 1) a path attention mechanism that forces one node to attend to only other nodes located in its path in the syntax tree to better incorporate syntax guidance; 2) a multi-encoder attention mechanism that allows the decoder to dynamically attend to information from multiple encoders. Our experiments in the controlled paraphrasing task show that our method outperforms SOTA models both semantically and syntactically, improving the best baseline's BLEU score from $11.83$ to $26.27$.",152
" Recently, there has been great success in automatic text summarization and generation. To better compare and improve the performance of models, evaluation for such systems has been a problem of interest. The selection of evaluation metrics will greatly affect the assessed quality of a generated summary and thus affect the evaluation of summarization models.   The most ideal metric is definitely human judgement, which is often treated as the gold standard. But human evaluation is time-consuming and labor-intensive, an automatic evaluation metric that cannot only save human resources but also simulate the ability of human judgement is of crucial importance.   Most of the existing automatic evaluation methods assess a summary by comparing it with reference texts written by humans. Some of them are model-free and simply use hand-crafted matching functions to calculate the similarity between the candidate summary and the reference  . These methods consider both the reference and the candidate as a sequence of tokens or n-gram blocks. For instance, as the de facto standard evaluation metric, ROUGE  calculates the n-gram overlap between the machine-generated summaries and reference summaries. Although these methods have the advantage of interpretability and efficiency, they are found to correlate poorly with human evaluation.   To reduce the requirement of exact word matching, some recent work tried to match the reference and the candidate summary in the embedding space of words or sentences . For instance, BERTScore  uses contextual word embeddings generated by BERT and performs a greedy matching to obtain the maximum cosine similarity between two texts. %\citeauthor{clarketal2019sentence}  designed a metric that combines sentence-level embeddings with the word mover閳ユ獨 distance   to calculate the distance of moving the candidate sequence into the reference and transforms the distance into a similarity score, while MoverScore  combines n-gram embeddings with WMD.   These methods are proved to correlate better with human judgement than ROUGE on many datasets, which demonstrates the effectiveness of using contextual embeddings.   }  , all the three dimensions focus on evaluating the linguistic quality of summaries.}  \end{table*}  However, the aforementioned methods all have some intrinsic drawbacks: these methods always need at least one human-generated reference to assess a candidate summary. References written by humans are costly to obtain. In addition, most of them only consider the semantic similarities with references, i.e. semantic qualities of the summaries, which ignores the linguistic qualities and other important aspects. In this paper, we propose a new unsupervised contrastive learning framework for automatically evaluating the summary qualities without comparing with reference summaries or training with human ratings. Specifically, we design an evaluator to consider both linguistic and semantic aspects of a summary. Then for each of the aspect we create a set of negative samples by perturbing the training samples. We compare the scores of original training samples and the negative samples to obtain the contrastive loss function and learn the evaluator. The experiments on Newsroom and CNN/Daily Mail demonstrate that our new evaluation method has much higher correlation with human judgement.  We summarize our contributions as follows:       We have proposed a novel syntactically guided text generation method \ours.~ \newcommand{\x}{\bm{x}}   \newcommand{\y}{\mathbf{y}} \newcommand{\y}{\bm{y}} \newcommand{\s}{\bm{s}} \newcommand{\bt}{\bm{t}} \newcommand{\z}{\bm{z}} \newcommand{\Z}{\mathcal{Z}} \newcommand{\R}{\mathbb{R}} \newcommand{\prob}{\mathbb{P}} \newcommand{\D}{\mathcal{D}} \newcommand{\E}{\mathbb{E}} \newcommand{\N}{\mathcal{N}} \newcommand{\h}{\mathbf{h}} \newcommand{\Qp}{Q_\phi} \newcommand{\Pt}{P_\theta} \newcommand{\bmu}{\bm{\mu}} \newcommand{\ba}{\bm{\alpha}} \newcommand{\V}{\mathcal{V}}  \newcommand{\tsrc}{\bm{s}_{\rm src}} \newcommand{\ttgt}{\bm{s}_{\rm tgt}} \newcommand{\spred}{\hat{\bm{x}}_{\rm tgt}} \newcommand{\stgt}{\bm{x}_{\rm tgt}} \newcommand{\stmpl}{\bm{x}_{\rm tmpl}} \newcommand{\ssrc}{\bm{x}_{\rm src}} \newcommand{\hsrc}{\bm{h}_{\rm src}} \newcommand{\htmpl}{\bm{h}_{\rm tmpl}} \newcommand{\hscr}[1]{\h^{}} \newcommand{\uscr}[2]{#1^{}}  \newcommand{\ours}{{GuiG}\xspace} \newcommand{\synexpan}{{\ours.SE}\xspace} \newcommand{\guigen}{{\ours.TG}\xspace}  \newcommand{\zc}[1]{{[#1]}}   \aclfinalcopy   Uncomment this line for the final submission   \def\aclpaperid{***}    Enter the acl Paper ID here    \setlength\titlebox{5cm}   You can expand the titlebox if you need extra space   to show all the authors. Please do not make the titlebox   smaller than 5cm ; we will check this   in the camera-ready version and ask you to change it back.  \newcommand\BibTeX{B\TeX}  \title{Transformer-Based Neural Text Generation with Syntactic Guidance}  \author{Yinghao Li \\   Georgia Institute of Technology \\   \texttt{yinghaoli@gatech.edu} \\\And   Rui Feng \\   Georgia Institute of Technology \\   \texttt{rfeng@gatech.edu} \\\AND   Isaac Rehg \\   Georgia Institute of Technology \\   \texttt{isaacrehg@gatech.edu} \\\And   Chao Zhang \\   Georgia Institute of Technology \\   \texttt{chaozhang@gatech.edu} \\}  \date{}  \begin{document} \maketitle                 
"," Evaluation of a document summarization system has been a critical factor to impact the success of the summarization task. Previous approaches, such as ROUGE, mainly consider the informativeness of the assessed summary and require human-generated references for each test summary. In this work, we propose to evaluate the summary qualities without reference summaries by unsupervised contrastive learning. Specifically, we design a new metric which covers both linguistic qualities and semantic informativeness based on BERT. To learn the metric, for each summary, we construct different types of negative samples with respect to different aspects of the summary qualities, and train our model with a ranking loss. Experiments on Newsroom and CNN/Daily Mail demonstrate that our new evaluation method outperforms other metrics even without reference summaries. Furthermore, we show that our method is general and transferable across datasets.",153
" Part-of-speech  tags and dependency parsing have formed a long-standing union in NLP. But equally long-standing has been the question of its efficacy. % of this union. %POS tags as features for parsers.  \carlos{Prior to the prevalence of deep learning in NLP, they were shown to be useful for syntactic disambiguation in certain contexts} %Certainly in the nigh-on forgotten pre-deep learning era of NLP, it seemed as if they were useful for syntactic disambiguation in certain contexts  . However, for neural network implementations, especially those which utilise character embeddings, POS tags have been shown to be much less useful .   Others have found that POS tags can still have a positive impact when using character representations given that the accuracy of the predicted POS tags used is sufficiently high . \citet{smith2018investigation} undertook a systematic study of the impact of features for Universal Dependency  parsing and found that using universal POS  tags does still offer a marginal improvement for their transition-based neural parser. The use of fine-grained POS tags still seems to garner noticeable improvements %even for challenging multi-lingual settings  .   %By far and away the most common use of  Latterly, POS tags have been commonly utilised implicitly for neural network parsers in multi-learning frameworks where they can be leveraged without the cost of error-propagation . Beyond multi-learning systems, \citet{strzyz2019viable} introduced dependency parsing as sequence labelling by encoding dependencies using relative positions of UPOS tags, thus explicitly requiring them at runtime. %So even if coarse POS tags, universal or otherwise, prove to be superfluous for graph- or transition-based neural parsers as direct features, there are still many uses for them.% in dependency parsing.   We follow the work of \citet{smith2018investigation} and evaluate the interplay of word embeddings, character embeddings, and POS tags as features for two modern parsers, one a graph-based parser, Biaffine, and the other a transition-based parser, UUParser . Similar to \citet{zhang2020pos}, we focus on the contribution of POS tags but evaluate UPOS tags.  \paragraph{Contribution} We analyse the effect UPOS accuracy has on two dependency parser systems for a number of UD treebanks. Our results suggest that in order to leverage UPOS tags as explicit features for these neural parsers, a prohibitively high tagging accuracy is needed, and that gold tag annotation seems to possess some exceptionality. We also investigate what aspects of predicted UPOS tags have the most impact on parsing accuracy.     In this paper, we propose a new evaluation method in the field of text summarization. We found that the quality of a summary can be evaluated in two separate dimensions: semantic quality and linguistic quality. Since human-authored references used in most of the existing metrics are costly, we investigate automatic evaluation metrics in an unsupervised reference-free setting. Leveraging powerful representations of BERT, our methods achieve the highest performance on two datasets.  Although our experiments are only on single-document summarization datasets, our method can also be also extended to evaluation of multi-document summarization with slight changes, especially in the part of semantic quality evaluation.    
"," We present an analysis %contributing to the discussion  on the effect UPOS accuracy has on parsing performance. Results suggest that leveraging UPOS tags as features for neural parsers requires a prohibitively high tagging accuracy and that the use of gold tags offers a non-linear increase in performance, suggesting some sort of exceptionality. We also investigate what aspects of predicted UPOS tags impact parsing accuracy the most, highlighting some potentially meaningful linguistic facets of the problem.",154
"  Conversational Machine Reading  is challenging because the rule text may not contain the literal answer, but provide a procedure to derive it through interactions . In this case, the machine needs to read the rule text, interpret the user scenario, clarify the unknown user's background by asking questions, and derive the final answer. Taking Figure  as an example, to answer the user whether he is suitable for the loan program, the machine needs to interpret the rule text to know what are the requirements, understand he meets ``American small business'' from the user scenario, ask follow-up clarification questions about ``for-profit business'' and ``not get financing from other resources'', and finally it concludes the answer ``Yes'' to the user's initial question.    Existing approaches  decompose this problem into two sub-tasks.  Given the rule text, user question, user scenario, and dialog history , the first sub-task is to make a decision among ``Yes'', ``No'', ``Inquire'' and ``Irrelevant''. The ``Yes/No'' directly answers the user question and ``Irrelevant'' means the user question is unanswerable by the rule text. If the user-provided information  are not enough to determine his fulfillment or eligibility, an ``Inquire'' decision is made and the second sub-task is activated. The second sub-task is to capture the underspecified condition from the rule text and generate a follow-up question to clarify it. \citet{zhong-zettlemoyer-2019-e3} adopt BERT  to reason out the decision, and propose an entailment-driven extracting and editing framework to extract a span from the rule text and edit it into the follow-up question.  The current \sota model EMT  uses a Recurrent Entity Network  with explicit memory to track the fulfillment of rules at each dialog turn for decision making and question generation.   In this problem, document interpretation requires identification of conditions and determination of logical structures because rules can appear in the format of bullet points, in-line conditions, conjunctions, disjunctions, etc. Hence, correctly interpreting rules is the first step towards decision making. Another challenge is dialog understanding. The model needs to evaluate the user's fulfillment over the conditions, and jointly consider the fulfillment states and the logical structure of rules for decision making. For example, disjunctions and conjunctions of conditions have completely different requirements over the user's fulfillment states. However, existing methods have not considered condition-level understanding and reasoning.   In this work, we propose \modelnameshortnsp: \modelnamecap. To better understand the logical structure of a rule text and to extract conditions from it, we first segment the rule text into clause-like elementary discourse units  using a pre-trained discourse segmentation model. Each EDU is treated as a condition of the rule text, and our model estimates its entailment confidence scores over three states: Entailment, Contradiction or Neutral by reading the user scenario description and existing dialog. Then we map the scores to an entailment vector for each condition, and reason out the decision based on the entailment vectors and the logical structure of rules. Compared to previous methods that do little entailment reasoning  or use it as multi-task learning , \modelnameshort is the first method to explicitly build the dependency between entailment states and decisions at each dialog turn.   \modelnameshort achieves new \sota results on the blind, held out test set of ShARC. In particular, \modelnameshort outperforms the previous best model EMT  by 3.8\% in micro-averaged decision accuracy and 3.5\% in macro-averaged decision accuracy. Specifically, \modelnameshort performs well on simple in-line conditions and conjunctions of rules while still needing improvements on understanding disjunctions. Finally, we conduct comprehensive analyses to unveil the limitation of \modelnameshort and current challenges for the ShARC benchmark. We find one of the biggest bottlenecks is the user scenario interpretation, in which various types of reasoning are required. % Code and models will be released to facilitate research along this line.     We have evaluated the impact POS tag accuracy has on parsing performance for leading graph- and transition-based parsers across a diverse range of UD treebanks, highlighting the stark difference between using predicted POS tags  and gold POS tags at runtime. We observed a non-linear increase in performance when using gold tags, suggesting they are somehow exceptional\carlos{, i.e., precisely the tag patterns that not even the most accurate taggers can correctly predict  seem to be the most important for parsing}. \carlostwo{This could be due to the parsers implicitly learning POS tag information, in such a way that the taggers learn nothing new to contribute or not enough to avoid a loss in performance due to the errors disrupting what the parsers have learnt.}  at runtime and using gold POS tags with a non-linear increase in performance when using gold tags suggesting gold tagged annotation are somehow exceptional.   This was further corroborated by our experiment using treebanks for which we could obtain very high scoring taggers.  Our analysis also shows that practitioners should evaluate the efficacy of using predicted tags for a given system or language.   rather than assuming they won't have a negative impact.   Beyond the global conclusions drawn from our analysis,  We have also analysed what aspects of erroneous tagging predictions have the greatest impact and correlation to parsing performance. We observed some global trends, \carlos{like the importance of \texttt{CCONJ},} but also language-specific issues which highlight the need to evaluate the usefulness of POS tags per language. The results also suggest that using a subset of POS tags might be effective.  and potentially even per treebank.    
","  Document interpretation and dialog understanding are the two major challenges for conversational machine reading. In this work, we propose \modelnameshortnsp, a discourse-aware entailment reasoning network to strengthen the connection and enhance the understanding for both document and dialog. Specifically, we split the document into clause-like elementary discourse units  using a pre-trained discourse segmentation model, and we train our model in a weakly-supervised manner to predict whether each EDU is entailed by the user feedback in a conversation. Based on the learned EDU and entailment representations, we either reply to the user our final decision ``yes/no/irrelevant"" of the initial question, or generate a follow-up question to inquiry more information. Our experiments on the ShARC benchmark  show that \modelnameshort achieves \sota results of 78.3\% macro-averaged accuracy on decision making and 64.0 BLEU1 on follow-up question generation. Code and models are released at \url{https://github.com/Yifan-Gao/Discern}.",155
"   .     %      % % final paper: en-us version      %     %   % space normally used by the marker     % This work is licensed under a Creative Commons      % Attribution 4.0 International License.     % License details:     % \url{http://creativecommons.org/licenses/by/4.0/}. }  Neural Language Models  have become a central component in NLP systems over the last few years, showing outstanding performance and improving the state-of-the-art on many tasks . However, the introduction of such systems has come at the cost of interpretability %and explainability and, consequently, at the cost of obtaining meaningful explanations when automated decisions take place. % and, specifically, of understanding how linguistic predictors - that were common as features in earlier systems - are encoded in such models.  Recent work has begun to study these models in order to understand whether they encode %are able to learn  linguistic phenomena even without being explicitly designed %forse meglio trained?  to learn such properties . Much of this work focused on the analysis and interpretation of attention mechanisms  and on the definition of probing models trained to predict simple linguistic properties from unsupervised representations.   Probing models trained  on different contextual representations provided evidences that such models are able to capture a wide range of linguistic phenomena  and even to organize this information in a hierarchical manner . However, the way in which this knowledge affects the decisions they make when solving specific downstream tasks has been less studied.  In this paper, we extended prior work by studying the linguistic properties encoded by one of the most prominent NLM, BERT , and how these properties affect its predictions when solving a specific downstream task. %,  using a suite of more than 80 probing tasks.  % qui vedere se tenere 'several' perch鑼 abbiamo 10 task di classificazione o dire che 鐚 uno solo diviso in 10 ""sotto-task"". We defined three research questions aimed at understanding:  what kind of linguistic properties are already encoded in a pre-trained version of BERT and where across its 12 layers;  how the knowledge of these properties is modified after a fine-tuning process;  whether this implicit knowledge %of these properties  affects the ability of the model to solve a specific downstream task, i.e. Native Language Identification . %With this aim, we firstly perform a very large suite of probing tasks using %on %DOMI: SPOSTIAMO QUESTA PARTE %To answer the first two questions, we firstly perform a very large suite of probing tasks using %on %the sentence representations extracted from the internal layers of BERT. Each of these tasks makes explicit a particular property of the sentence, from very shallow features  to more complex aspects of morpho--syntactic and syntactic structure , thus making them as particularly suitable to assess the implicit linguistic knowledge encoded in a NLM at a deep level of granularity. %with respect to a wide spectrum of phenomena overing lexical, morpho-syntactic and syntactic structure.  To tackle the first two questions, we adopted an approach inspired to the `linguistic profiling' methodology put forth by , which assumes that wide counts of linguistic features automatically extracted from parsed corpora allow modeling a specific language variety and detecting how it changes with respect to other varieties, e.g. complex vs simple language, female vs male--authored texts, texts written in the same L2 language by authors with different L1 languages.  Particularly relevant for our study, is that multi-level linguistic features have been shown to have a highly predictive role in tracking the evolution of learners' linguistic competence across time and developmental levels, both in first and second language acquisition scenarios .  %when leveraged by traditional learning models on a variety of text classification problems, all of which can be successfully tackled using formal, rather than content based aspects of a text: from the assessment of sentence complexity and text readability , to the identification of personal and sociodemographics traits of an author, such as his/her native language, gender, age etc.  and to the prediction of the evolution of learners' linguistic competence across time . %From this perspective, our approach can be considered as a particular implementation of the `linguistic profiling' methodology put forth by , which assumes that wide counts of linguistic features automatically extracted from parsed corpora allow modeling a specific language variety and detecting in what way it changes with respect to other varieties, e.g. complex vs simple language, female vs male--authored texts, texts written in the same L2 language by authors with different L1 languages. Given the strong informative power of these features to encode a variety of language phenomena across stages of acquisition, we assume that they can be also helpful to dig into the issues of interpretability of NLMs. In particular, we would like to investigate whether features successfully exploited to model the evolution of language competence can be similarly helpful in profiling how the implicit linguistic knowledge of a NLM changes across layers and before and after tuning on a specific downstream task. We chose the NLI task, i.e. the task of automatically classifying the L1 of a writer based on his/her language production in a learned language .  %Secondly, we investigate the type and degree of variations of linguistic information before and after fine-tuning the pre-trained model on 10 distinct  datasets used to solve Native Language Identification , i.e. the task of automatically classifying the L1 of a writer based on his/her language production in a learned language .   As shown by , linguistic features play a very important role when NLI is tackled as a sentence--classification task rather than as a traditional document--classification task.  %NLI can be addressed by exploiting only linguistic features extracted at sentence--level reaching comparable performance to those obtained by state--of--the--art models based on word embeddings .  This is the reason why we considered the sentence-level NLI classification as a task particularly suitable for probing the NLM linguistic knowledge. %perch鑼 鐚 un task che per essere risolto 鐚 necessario che il modello codifichi un'ampia gamma di informazioni linguistiche e anche perch鑼 鐚 un task basato sull'info estratta dalla sentence -come dimostrato da Cimino et al  nonostante lo stato dell'arte 鐚 stato definito soltanto usando word embeddings  %vecchia versione: a fine-tuning process based on a Native Language Identification  downstream task.  %vecchia versione: -base and 10 fine-tuned models obtained training BERT on as many Native Language Identification  tasks.  Finally, we investigated whether and which linguistic information encoded by BERT is involved in discriminating the sentences correctly or incorrectly classified by the fine-tuned models. To this end, we tried to understand if the linguistic knowledge that the model has of a sentence affects the ability to solve a specific downstream task involving that sentence.   %vecchia versione: Adopting a suite of more than 80 probing tasks, we firstly perform % We perform our experiments using a suite of more than 80 probing tasks, each of which corresponds to a specific/distinct sentence-level feature. We find that / We show that  %The remainder of the paper is organized as follows. We start by presenting some related works which are more closely related to our study  and in Section  we highlight the main novelties of our approach. We then describe in more details the data , the probing tasks  and the models  we used. Experiments and results are described in Section ,  and . To conclude, in Section  we summarize the main findings of the study.  \paragraph{Contributions} In this paper:  we carried out an in-depth linguistic profiling of BERT's internal representations %deep analysis of the implicit linguistic knowledge stored in BERT's internal representations and how it changes across layers using a wide suite of sentence-level probing tasks, corresponding to a wide spectrum of linguistic phenomena at different level of complexity; % we verify the implicit linguistic knowledge stored in BERT's internal representations using a suite of more than 80 probing tasks corresponding to a wide range of linguistic phenomena at different level of complexity;   we showed that contextualized representations tend to lose their precision in encoding a wide range of linguistic properties %general-purpose linguistic properties  after a fine-tuning process; % RIVEDERE 'GENERAL-PURPOSE' COME TERMINE PER DESCRIVERE LE NOSTRE FEATURES  we showed that the linguistic knowledge stored in the contextualized representations of BERT positively affects its ability to solve NLI downstream tasks: the more BERT stores information about these features% in its embeddings/internal representations , the higher will be its capacity of predicting the correct label.     In this paper, we present \modelnameshortnsp, a system that does discourse-aware entailment reasoning for conversational machine reading. \modelnameshort explicitly builds the connection between entailment states of conditions and the final decisions. Results on the ShARC benchmark shows that \modelnameshort outperforms existing methods by a large margin.  We also conduct comprehensive analyses to unveil the limitations of \modelnameshort and challenges for ShARC. In future, we plan to explore how to incorporate discourse parsing into the current decision making model for end-to-end learning. One possibility would be to frame them as multi-task learning with a common  encoder.  Another direction is leveraging current methods in question generation  to improve the follow-up question generation sub-task since \modelnameshort\ is on par with the previous best model EMT.  
"," In this paper we investigate the linguistic knowledge learned by a Neural Language Model  before and after a fine-tuning process and how this knowledge affects its predictions during several classification problems. We use a wide set of probing tasks, each of which corresponds to a distinct sentence-level feature extracted from different levels of linguistic annotation. We show that BERT is able to encode a wide range of linguistic characteristics, but it tends to lose this information when trained on specific downstream tasks. We also find that BERT's capacity to encode different kind of linguistic properties has a positive influence on its predictions: the more it stores readable linguistic information of a sentence, the higher will be its capacity of predicting the expected label assigned to that sentence.",156
"   Recent emergent-communication studies, renewed by the astonishing success of neural networks, are often motivated by a desire to develop neural network agents eventually able to verbally interact with humans . To facilitate such interaction, neural networks' emergent language should possess many natural-language-like properties. However, it has been shown that, even if these emergent languages lead to successful communication, they often do not bear core properties of natural language .  In this work, we focus on one basic property of natural language that resides on the tendency to use messages that are close to the informational optimum. This is illustrated in the Zipf's law of Abbreviation , an empirical law that states that in natural language, the more frequent a word is, the shorter it tends to be . Crucially, ZLA is considered to be an efficient property of our language .  Besides the obvious fact that an efficient code would be easier to process for us, it is also argued to be a core property of natural language, likely to be correlated with other fundamental aspects of human communication, such as regularity and compositionality . Encouraging it might hence lead to emergent languages that are also more likely to develop these other desirable properties.   Despite the importance of such property,  \citet{chaabouni:etal:2019} showed that standard neural network agents, when trained to play a simple signaling game , develop an inefficient code, which even displays an anti-ZLA pattern. That is, counterintuitively, more frequent inputs are coded with longer messages than less frequent ones. This inefficiency was related to  neural networks' ``innate preference'' for long messages. In this work, we aim at understanding which constraints need to be introduced on neural network agents in order to overcome  their innate preferences and communicate efficiently, showing a proper ZLA pattern.  To this end, we %follow \citet{chaabouni:etal:2019} and use a reconstruction game where we have two neural network agents: speaker and listener. For each input, the speaker outputs a sequence of symbols  sent to the listener. The latter needs then to predict the speaker's input based on the given message. Also, similarly to the previous work, inputs are drawn from a power-law distribution.   We first describe the experimental and optimization framework . In particular, we introduce a new communication system called `LazImpa', comprising two different constraints  Laziness on the speaker side and  Impatience on the listener side. The former constraint is inspired by the least-effort principle which is attested to be a ubiquitous pressure in human communication .   However, if such a constraint is applied too early, the system does not learn an efficient system. We show that incrementally penalizing long messages in the cost function enables an early exploration of the message space  and prevents converging to an inefficient local minimum.   The other constraint, on the listener side, relies on the prediction mechanism, argued to be important in language comprehension \citep[e.g.,][]{federmeier2007, altmann2009}, and is achieved by allowing the listener to reconstruct the intended input as soon as possible. We also provide a two-level analytical method: first, metrics quantifying the efficiency of a code; second, a new protocol to measure its informativeness . Applying these metrics, we demonstrate that, contrary to the standard speaker/listener agents, our new communication system `LazImpa' leads to the emergence of an efficient code. The latter follows a ZLA-like distribution, close to natural languages . Besides the plausibility of the introduced constraints, our new communication system is, first, task- and architecture-agnostic , and second allows stable optimization of the speaker/listener. We also show how both listener and speaker constraints are fundamental to the emergence of a ZLA-like distribution, as efficient as natural language .     In this paper we studied what kind of linguistic properties are stored in the internal representations learned by BERT before and after a fine-tuning process and how this implicit knowledge correlates with the model predictions when it is trained on a specific downstream task. Using a suite of 68 probing tasks, we showed that the pre-trained version of BERT encodes a wide range of linguistic phenomena across its 12 layers, but the order in which probing features are stored in the internal representations does not necessarily reflect the traditional division with respect to the linguistic annotation levels. We also found that BERT tends to lose its precision in encoding our set of probing features after the fine-tuning process, probably because it is storing more task--related information for solving NLI.  QUI NON SERVE : Interestingly, we noticed that features encoding verbal tense knowledge are the ones that decreases significantly for all the fine-tuned models.  We thus think that further work needs to be done to investigate what kind of discriminant linguistic properties properties emerge after a fine-tuning process.  This is particularly evident for the models fine-tuned on the classification of language pairs belonging to the same family .   Se possibile Scrivere meglio: Finally, we showed that the implicit linguistic knowledge encoded by BERT positively affects   is strongly correlated with its ability to solve the tested downstream tasks.  In particular, we first showed that, regardless of the layer and model taken into account, most of the probing features are involved in discriminating the sentences correctly or incorrectly classified by the fine-tuned models. Second, we noticed that for such features the probing model performance show an improvement when BERT correctly predicts the L1 of a native speaker, and this is especially true for the pre--trained model. This suggests that its capacity to encode linguistic information has an influence on its predictions.   decisions.   In future work, we would like to extend our approach to other NLMs, such as ELMo  or XLNet , and to investigate how the linguistic information implicitly encoded in such models affects different downstream tasks.   The demonstrated influence of linguistic competence of NLM on classification tasks would allow us to develop NLMs able to maximize    In future work, we plan to study how the linguistic information encoded in a NLM arise during training, performing the probing tasks on several sentence representations extracted in the pre-training phase. The aim of this investigation is studying new strategies to maximize the linguistic competence of a NLM, for example adding during the pre-training process specific linguistic tasks.   Moreover, it would be interesting to study how the linguistic information encoded in a NLM arise and evolve as these models are trained, performing the probing tasks on several sentence representations extracted during the pre-training process.  DA FELICE: se riusciamo aggiungere anche: Un ulteriore campo di indagine sar鑴 quello di generare NLM massimizzando la loro competenza linguistica ad esempio adding at the pre-training process specific linguistic tasks.    include your own bib file like this: 
"," Previous work has shown that artificial neural agents naturally develop surprisingly non-efficient codes.  This is illustrated by the fact that in a referential game involving a speaker and a listener neural networks optimizing accurate transmission over a discrete channel, the emergent messages fail to achieve an optimal length. Furthermore, frequent messages tend to be longer than infrequent ones, a pattern contrary to the Zipf Law of Abbreviation  observed in all natural languages. Here, we show that near-optimal and ZLA-compatible messages can emerge, but only if both the speaker and the listener are modified. We hence introduce a new communication system, ``LazImpa'', where the speaker is made increasingly lazy, i.e.,~avoids long messages, and the listener impatient, i.e.,~seeks to guess the intended content as soon as possible.",157
" % 1 - What problem are you solving? Entity typing classifies textual mentions of entities, according to their semantic class, within a set of labels  organized in an inventory. %Multi-label text classification is the task of assigning to a sample all the relevant labels from a label  inventory . The task has progressed from recognizing a few coarse classes , to extremely large inventories, with hundreds  or thousands of labels . Therefore, exploiting inter-label correlations has become critical to improve performance.   % 2 - Why is it an interesting/important problem? % es interesante porque son buenos para modelar redes y estructuras jer璋﹔quicas. % Problema: su adopcion en nlp ha sido baja dado que no hay una forma muy intuitiva de modelar texto en ellos. Distintos papers muestran como agregar un peque甯給 cambio pero no una aplicacion real y completa Large inventories tend to exhibit a hierarchical structure, either by an explicit tree-like arrangement of the labels , or implicitly through the label distribution in the dataset . %A natural solution for dealing with large inventories is to organize them in hierarchy ranging from general, coarse labels near the top, to more specific, fine classes at the bottom. Prior work has integrated only explicit hierarchical information by formulating a hierarchy-aware loss  or by representing instances and labels in a joint Euclidean embedding space .  However, the resulting space is hard to interpret, and these methods fail to capture implicit relations in the label inventory. Hyperbolic space is naturally equipped for embedding symbolic data with hierarchical structures . Intuitively, that is because the amount of space grows exponentially as points move away from the origin. This mirrors the exponential growth of the number of nodes in trees with increasing distance from the root  . %Its tree-like properties make it efficient to learn hierarchical representations with low distortion .     % Embeddings  that  are  close  to  the  origin  of  the  disk  will have a relatively small distance to all other points, rep-resenting the root of the hierarchy.  On the other hand,embeddings that are close to the boundary of the disk will have a relatively large distance to all other points and are well suited to represent leaf nodes   % 3 - How are you going to solve it? In this work, we propose a fully hyperbolic neural model for fine-grained entity typing. Noticing a perfect match between hierarchical label inventories in the linguistic task and the benefits of hyperbolic spaces, we endow a classification model with a suitable geometry to capture this fundamental property of the data distribution. By virtue of the hyperbolic representations, the proposed approach automatically infers the latent hierarchy arising from the class distribution and achieves a meaningful and interpretable organization of the label space. This arrangement captures implicit hyponymic relations  in the inventory and enables the model to excel at fine-grained classification. To the best of our knowledge, this work is the first to apply hyperbolic geometry from beginning to end to perform multi-label classification on real NLP datasets.  %NICE PHRASE FROM GULCEHRE: The focus of this work is to endow neural network representations with suitable geometry to capture fundamental properties of data... given the perfect fit between the label distribution in the linguistic task of entity typing and the mathematical properties of hyperbolic spaces.   % esto deberia ser ""hay componentes ya hechos"". Y lo conecto al toque con el parrafo sig.  Recent work has proposed hyperbolic neural components, such as word embeddings , recurrent neural networks  and attention layers . %Advantages of hyperbolic representations are well-established for discrete data such as networks  and graphs . In the realm of Natural Language Processing  components that exploit hyperbolic geometry have been developed as well, such as word embeddings , recurrent neural networks  and attention layers . %or classifiers  Me encanta este paper pero no hace NLP :. We address these issues. Our model encodes textual inputs, applies a novel attention mechanism, and performs multi-class multi-label classification, executing all operations in the Poincar\'e model of hyperbolic space . %By employing the leveraging the geometric properties of hyperbolic space through    %The lack of systems that utilize hyperbolic space from beginning to end is due to three main difficulties: %First, there are different analytic models of hyperbolic space, and not all previous work operates in the same one, which hinders their combination.  %Second, it is not clear how to integrate these components into conventional Euclidean neural models since a mapping of the data from one space onto the other is required. Third, optimization of hyperbolic models is non-trivial.   %We bridge the gaps among previous work by developing the missing connections and adapting different components to employ the Poincar\'e model of hyperbolic space in all layers of the network.  % We bridge the gaps among previous work by developing the missing connections and adapting different components, in order to accomplish a full hyperbolic neural network. This is, a network that extracts features from text, applies attention layers and performs \todo{I am the only one doing this}{multi-class classification}, executing all operations in hyperbolic geometry.   % able to perform multi-label multi-class classification with text as input    %The model is proposed in a generic manner such that it can be applied to classify sequential data . Since hyperbolic geometry is naturally equipped to model hierarchical structures, we hypothesize that the model will excel at tasks that profit from the incorporation of hierarchical information. % \todo{awful}{systems} that operate under this metric space result in superior performance when incorporating hierarchical information.   %We evaluate our model on the task of fine-grained entity type classification , which we consider a suitable testbed due to its connection with textual inputs and hierarchical type inventories.  % Introduce main results % HNN's phrase: ""On a series of experiments and datasets we showcase the effectiveness of our hyperbolic neural network layers compared to their ""classic"" Euclidean variants on"" % \todo[inline]{Forwarding a bit of the results is a good idea . %\todo[inline]{Cambiar esta frase a la idea de que ""imponer the right metric es como imponer the right bias""}  %We impose an inductive bias on the model by means of the geometry of its internal representation. This allows us to operate on very low-dimensional spaces thus substantially reducing the parameter cost. Instead of relying on large pre-trained models, we impose a suitable inductive bias by choosing an adequate metric space to embed the data, which does not introduce extra burden on the parameter footprint. %Phrase from xiong2019inductiveBias: ""Instead of using an explicit graphical model, we enforce a relational bias on model parameters, which does not introduce extra burden on label decoding."" % Misma idea pero yo meto el bias en la representacion, lo cual no introduce un costo adicional y permite operar con MUCHOS menos par璋﹎etros.   %Our components are developed in a modular way which allows them to be seamlessly integrated into NLP architectures.    %\todo{Remove!}{While there now exist several hyperbolic components, a practitioner faced with these options has a simple question: How to integrate them with conventional layers? In this work, we answer this question.}  By means of the exponential and logarithmic maps  we are able to mix hyperbolic and Euclidean components into one model, aiming to exploit their strengths at different levels of the representation. We perform a thorough ablation that allows us to understand the impact of each hyperbolic component in the final performance of the system , and showcases its ease of integration with Euclidean layers.  %In summary, we make the following contributions: %%%%% %      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    We demonstrated that a standard communication system, where standard Speaker and Listener LSTMs are trained to solve a simple reconstruction game, leads to long messages, close to the maximal threshold. Surprisingly, if these messages are long, LSTM agents rely only on a small number of informative message symbols, located at the end. We then introduce LazImpa, a constrained system that consists of Lazy Speaker and Impatient Listener. On the one hand, Lazy Speaker is obtained by introducing a cost on messages length once the communication is successful. We found that early exploration of potentially long messages is crucial for successful convergence . On the other hand, Impatient Listener aims to succeed at the game as soon as possible, by predicting Speaker's input at each message's symbol.   We show that both constraints are necessary for the emergence of a ZLA-like protocol, as efficient as natural languages. Specifically, Lazy Speaker alone would fail to shorten the messages. We connect this to the importance of the Impatience mechanism to locate useful information at the beginning of the messages. If the function of this mechanism is subject to a standing debate \cite[e.g.,][]{jackendoff2007,anderson2013}, many prior works had pointed to its necessity to human language understanding \citep[e.g.,][]{friston:2010,clark:2013}. We augment this line of works and suggest that impatience could be at play in the emergence of ZLA-obeying languages. However, if impatience leads to ZLA, it is not sufficient for human-level efficiency. In other words, efficiency needs constraints both on Speaker and Listener sides.   Our work highlights the importance of introducing the right pressures in the communication system. Indeed, to construct automated agents that would eventually interact with humans, we need to introduce task-agnostic constraints, allowing the emergence of more human-like communication. Moreover, while being general, LazImpa provides a more stable optimization compared to the unconstrained system. Finally, this study opens several lines of research. One would be to investigate further the gap from optimality. Indeed, while LazImpa emergent languages show human-level efficiency, they do not reach optimal coding. Specifically, emergent languages still have non-informative symbols at the end of the messages. If these additional non-useful symbols drift the protocol from optimality, we encounter similar trend in human  and animal communication  . We leave the understanding of the role of these non-informative symbols and how we can reach optimal coding for future works. A second line of research would be to apply this system to other games or NLP problems and study how it affects other properties of the language such as regularity or compositionality.   
"," Label inventories for fine-grained entity typing have grown in size and complexity. Nonetheless, they exhibit a hierarchical structure. Hyperbolic spaces offer a mathematically appealing approach for learning hierarchical representations of symbolic data. However, it is not clear how to integrate hyperbolic components into downstream tasks. This is the first work that proposes a fully hyperbolic model for multi-class multi-label classification, which performs all operations in hyperbolic space. We evaluate the proposed model on two challenging datasets and compare to different baselines that operate under Euclidean assumptions.  Our hyperbolic model infers the latent hierarchy from the class distribution, captures implicit hyponymic relations in the inventory, and shows performance on par with state-of-the-art methods on fine-grained classification with remarkable reduction of the parameter size. A thorough analysis sheds light on the impact of each component in the final prediction and showcases its ease of integration with Euclidean layers. \footnote{Code available at:\\ \url{https://github.com/nlpAThits/hyfi}}",158
"  Entity Recognition  involves detection  and classification of entities mentioned in unstructured text into pre-defined categories. It is one of the foundational sub-task of several Information Extraction   and Natural Language Processing  pipelines. Hence, errors introduced during the extraction of entities can propagate further and degrade the performance of the complete IE or NLP pipeline. In the domains of experimental biology, the growing complexity of experiments has resulted in a need to automate wet laboratory procedures. Such an automation will be useful in avoiding human errors introduced in the wet lab protocols and thereby will enhance the reproducibility of experimental biological research.   To achieve this reproducibility, some of the previous research works have focussed on defining machine-readable formats for writing wet lab protocols . However, the vast majority of today閳ユ獨 protocols are written in natural language with jargon and colloquial language constructs that emerge as a byproduct of ad-hoc protocol documentation. This motivates the need for machine reading systems that can interpret the meaning of these natural language instructions, to enhance reproducibility via semantic protocols  and enable robotic automation  by mapping natural language instructions to executable actions. In order to enable research on interpreting natural language instructions, with practical applications in biology and life sciences, an annotated database  of wet lab protocols was introduced.   The first step in interpreting natural language lab protocols is to extract entities, followed by identification of relations between them. To address the research focussing on entity recognition over Wet Lab Protocols a shared task  was introduced at EMNLP WNUT-2020 Workshop. The task was based on the annotated database  of wet lab protocols. We tackle this task in two phases. In the first phase, we experiment with various contextualised word embeddings  and a BiLSTM-CRF model to arrive at the best-performing architecture. In the second phase, we create an ensemble composed of eleven BiLSTM-CRF models. The individual models are trained on random train-validation splits of the complete dataset. Here, we also experiment with different output merging schemes, including Majority Voting and SLE.  The rest of the paper is structured as follows: Section 2 states the task definition. Section 3 describes the specifics of our methodology. Section 4 explains the experimental setup and the results, and Section 5 concludes the paper.       1) X  is an important problem    2) The core challenges are this and that.    3) Previous work on X has addressed these with Y, but the problems with this are Z.    4) In this work we do W .    5) This has the following appealing properties and our experiments show this and that.  Incorporating hierarchical information from the label inventory into neural models has become critical to improve performance. Hyperbolic spaces are an exciting approach since they are naturally equipped to model hierarchical structures. However, previous work integrated  isolated components into neural systems.  In this work we propose a fully hyperbolic model and showcase its effectiveness on challenging datasets.  Our hyperbolic model automatically infers the latent hierarchy from the class distribution, captures implicit hyponymic relations in the inventory and achieves a performance comparable to state-of-the-art systems on very fine-grained labels with a remarkable reduction of the parameter size.  This emphasizes the importance of choosing a metric space suitable to the data distribution as an effective inductive bias to capture fundamental properties, such as hierarchical structure.  Moreover, we illustrate ways to integrate different components with Euclidean layers, showing their strengths and drawbacks. An interesting future direction is to employ hyperbolic representations in combination with contextualized word embeddings. We release our implementation with the aim to ease the adoption of hyperbolic components into neural models, yielding lightweight and efficient systems.   Add future work! En Gulcehre citan un paper y dicen ""future work seria hacer lo mismo que CITE, pero co hyperbolic whatever.   Para mi future work podr閾哸 ser explorar variations de HyperbolicMLR para paliar algunas de las desventajas de Softmax .  De Gulcehre: ""Similarly as a future work, an interesting potential future direction is to use hyperbolic..."", or say clearly that I do not use contextualized word embeddings and future work: explore hyperbolic representation in combination with contextualized word embeddings   
"," In this paper, we describe the approach that we employed to address the task of Entity Recognition over Wet Lab Protocols - a shared task in EMNLP WNUT-2020 Workshop. Our approach is composed of two phases. In the first phase, we experiment with various contextualised word embeddings  and a BiLSTM-CRF model to arrive at the best-performing architecture. In the second phase, we create an ensemble composed of eleven BiLSTM-CRF models. The individual models are trained on random train-validation splits of the complete dataset. Here, we also experiment with different output merging schemes, including Majority Voting and Structured Learning Ensembling . Our final submission achieved a micro F1-score of 0.8175 and 0.7757 for the partial and exact match of the entity spans, respectively. We were ranked first and second, in terms of partial and exact match, respectively.",159
"  We make many decisions as we interact with the world. When we are rewarded , we learn to modify not only the proximal cause of the stimulus but the chain of decisions leading up to it, to encourage  future similar results. This process naturally is the paradigm of Reinforcement Learning . Policy-based learning seeks to find good estimates for , a function that returns the expected cumulative reward  if action  is chosen at state . A desirable property of methodologies to learn  is their ability to generalize such that an appropriate action can be taken when encountering a previously unseen state.   Recent advances have shown strong evidence of generalization in spatiotemporal modalities such as robotic manipulation , video games , and autonomous navigation . However, in the modality of language, there is less work applying generalization approaches to decision making.  Useful applications of sequential decision making language models are personal assistants that proactively anticipate client needs; anti-phishing mediation agents that waste a would-be thief's time with relevant but non-helpful responses; and investigative journalist assistants that determine what to read, whom to contact, and what questions to ask to create a revelatory news report.  Neural reinforcement learning  training approaches, such as those used to play action video games , have potential applicability in language-based decision making due to their ability to learn to navigate adversarial or exploratory scenarios. Naturally, the generalization and background knowledge capability afforded by large contextualized language models such as \bert  may be applicable as well. A useful virtual world proxy in which to explore these approaches' applicability is that of text adventure game playing. In a text adventure game, a player is immersed in an environment by reading textual descriptions of a scene and issuing natural language commands to navigate inside the scene. The player discovers and interacts with entities and accomplishes goals, while receiving explicit rewards for doing so.   Learning to play text games is a useful pursuit because it is a convenient proxy for the real world cases cited above. Unlike these, plentiful data for numerous games exist, an endless supply of games can be constructed, and text games have built-in reward functions,  making them suitable for RL. This class of problems is also useful because it is challenging: after exposure to a family of games that explore the same topic and have similar gameplay , human players perform nearly perfectly on additional games, but computer models struggle.   Why is this? Humans quickly understand the situation they are placed in and can make rational decisions based on trial-and-error and life experience, which we can call commonsense knowledge. Knowing a priori that, e.g.,  a  door should be  or that it is helpful to  in a  allows  players to learn  faster. Even though these games have the complexity of finite-state machines, computer models cannot learn to play them well. The problem appears to be due to a lack of generalization caused by a lack of commonsense. To a computer model, considering whether to  using a  is no more ludicrous than considering whether to  using a  . Both actions can be discouraged by negative reinforcement, but a human only needs to learn not to do the latter.   Furthermore, a computer player learning that one can  with a  may not generalize that one can  the same way, but a human surely will.  There is existing work in learning to play text games with RL   but the standard pattern of incorporating large language models such as \bert  has not yet been seen in current literature. It turns out that this integration is not trivial. Most models that use \bert and its ilk predominantly apply their results to supervised learning tasks that have training data with ground truth  or at least, in the case of generation-based tasks like dialogue and translation, a corpus of desirable output to mimic . For tasks suited to RL such as the exploration of and interaction with a world, there is no true target or even, initially, a corpus, and thus learning can only proceed iteratively via, e.g., exploration-exploitation , which requires millions of training iterations to converge . Integrating this process with the additional overhead of fine-tuning a large model like \bert leads to an impractical slowdown: for the experiments considered in this work, the baseline models that use \cnn require a little more than three weeks to train on an Nvidia P100 GPU-equipped machine. Using the same models on the same tasks run for the same number of iterations on the same hardware while fine-tuning a 12-layer \bert model would take more than two years.      In this work, we compare different previously used representation models for deep RL through an imitation learning method that first trains a light-weight teacher using exploration-exploitation, and then uses that trained model to train a more heavy-weight student model. This dramatically decreases the amount of training time needed to learn.  Moreover, we devise a means of casting an RL problem into a supervised learning paradigm, allowing better exploitation of large contextualized language models. In so doing, we show that agents can benefit from both the imitation learning and the reformulation, converging faster than other models, and exceeding teacher performance by 7\% and 24\% on both in- and out-of-domain problems, despite the limited search space.  The novel contributions of this work are:                 File main.tex      Based on the style files for ACL 2020, which were    Based on the style files for ACL 2018, NAACL 2018/19, which were    Based on the style files for ACL-2015, with some improvements     taken from the NAACL-2016 style    Based on the style files for ACL-2014, which were, in turn,    based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,    EACL-2009, IJCNLP-2008...    Based on the style files for EACL 2006 by    e.agirre@ehu.es or Sergi.Balari@uab.es    and that of ACL 08 by Joakim Nivre and Noah Smith  \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{emnlp2020} \usepackage{times} \usepackage{latexsym}  \renewcommand{\UrlFont}{\ttfamily\small}    This is not strictly necessary, and may be commented out,   but it will improve the layout of the manuscript,   and will typically save some space. \usepackage{microtype} \usepackage[utf8]{inputenc} \usepackage{dirtytalk} \usepackage{natbib} \usepackage{amsmath} \usepackage{amsfonts} \usepackage{bm} \usepackage{adjustbox} \renewcommand{\UrlFont}{\ttfamily\small}  \usepackage{xcolor} \usepackage{xspace} \usepackage{comment} \usepackage{graphicx} \usepackage{url} \usepackage{array} \usepackage{multirow} \usepackage{booktabs} \usepackage{caption} \usepackage{subcaption} \usepackage{etoolbox}   \AtBeginEnvironment{quote}{\singlespacing \small}   \aclfinalcopy   Uncomment this line for the final submission  \def\aclpaperid{***}    Enter the acl Paper ID here   \setlength\titlebox{5cm}   You can expand the titlebox if you need extra space   to show all the authors. Please do not make the titlebox   smaller than 5cm ; we will check this   in the camera-ready version and ask you to change it back.  \newcommand{\joy}[1]{{\color{blue}{\bf #1 -joy}}} \newcommand{\cy}[1]{{\color{orange}{\bf #1 -cy}}} \newcommand{\lwku}[1]{{\small\color{red}{\bf\xspace#1 -ku}}}  \newcommand{\kenneth}[1]{{\color{blue}{\bf #1 -Kenneth}}}  \newcommand{\fitb}{context modeling \xspace} \newcommand{\ent}{entailment modeling \xspace}  \newcommand{\entshort}{EMLA\xspace} \newcommand{\fitbshort}{CMLA\xspace}  \newcommand\BibTeX{B\TeX}  \title{Assessing the Helpfulness of Learning Materials \\with Inference-Based Learner-Like Agent}  \author{Yun-Hsuan Jen, Chieh-Yang Huang, Mei-Hua Chen, \\ Ting-Hao  Huang, and Lun-Wei Ku \\   Academia Sinica, Taipei, Taiwan. \\ \texttt{yhjen2@gmail.com}, \texttt{lwku@iis.sinica.edu.tw}\\   Pennsylvania State University, University Park, PA, USA. \\ \texttt{\{chiehyang,txh710\}@psu.edu}\\   Tunghai University, Taichung, Taiwan. \texttt{mhchen@thu.edu.tw} }  \date{}     
"," We consider problems of making sequences of decisions to accomplish tasks,  interacting via the medium of language. These problems are often tackled with reinforcement learning approaches. We find that these models do not generalize well when applied to novel task domains. However, the large amount of computation necessary to adequately train and explore the search space of sequential decision making, under a reinforcement learning paradigm, precludes the inclusion of large contextualized language models, which might otherwise enable the desired generalization ability. We introduce a teacher-student imitation learning methodology and a means of converting a reinforcement learning model into a natural language understanding model. Together, these methodologies enable the introduction of contextualized language models into the sequential decision making problem space. We show that models can learn faster and generalize more, leveraging both the imitation learning and the reformulation. Our models exceed teacher performance on various held-out decision problems, by up to 7\% on in-domain problems and 24\% on out-of-domain problems.",160
"  %   Reinforcement learning has shown great success in environments with large state spaces. Using neural networks to capture state representations has allowed end-to-end training of agents on domains like Atari  and Go . It is natural to emulate this success in text domains, especially given that the state space in language-based tasks is combinatorially large. A sentence of length  with allowed vocabulary  has  possible states, and tabular methods like learning  will fail unless coupled with powerful function approximators like neural networks.\\  While the current state of RL has multiple challenges, sparse rewards are one that leads to slow, and sometimes no convergence. Consider an agent learning in an environment with a large state space, with only a few states leading to a reward . An agent starting on the far left must take a large number of actions before encountering a reward. In turn, this sparse feedback results in a very noisy gradient for training the neural network. In an extreme scenario, as in Figure , an agent might have to take an exponential number of actions to reach a single leaf that has a reward.      Some early work, such as reward shaping , attempted to solve the sparse reward problem by introducing dense rewards based on heuristics, e.g., how close the agent is to the goal. However, these require complex design choices that might result in unexpected behavior from the agents.\\  Sparse rewards are common because they are the most straightforward way to specify how a task needs to be solved. If a robot is expected to pour water from a jug into a glass, the simplest way is to give a reward of  if it fills the glass, and  otherwise. This type of reward design is common in text-based games, in which the agent is rewarded upon reaching the goal state, and task-oriented dialogue, in which the agent is rewarded based on the successful completion of the task.\\  For this study, we examine text-based games and find that providing dense rewards with the help of sentiment analysis improves performance under some conditions.     We provide a recipe for integrating large contextualized language models and deep reinforcement learning, applying to sequential decision making and a demonstration on the proxy task of text games, showing dramatic improvements over the standard practice, particularly in out-of-domain held-out tests. We expect to apply this approach to various challenging real-world sequential decision scenarios, such as goal-directed dialogue and active information-gathering.  
"," While reinforcement learning  has been successful in natural language processing  domains such as dialogue generation and text-based games, it typically faces the problem of sparse rewards that leads to slow or no convergence. Traditional methods that use text descriptions to extract only a state representation ignore the feedback inherently present in them. In text-based games, for example, descriptions like ``Good Job! You ate the food'' indicate progress, and descriptions like ``You entered a new room'' indicate exploration. Positive and negative cues like these can be converted to rewards through sentiment analysis. This technique converts the sparse reward problem into a dense one, which is easier to solve. Furthermore, this can enable reinforcement learning without rewards, in which the agent learns entirely from these intrinsic sentiment rewards. This framework is similar to intrinsic motivation, where the environment does not necessarily provide the rewards, but the agent analyzes and realizes them by itself. We find that providing dense rewards in text-based games using sentiment analysis improves performance under some conditions.",161
"  Natural language data is rich in structure, but most of the structure is not visible at the surface.  Machine learning models tackling high-level language tasks would benefit from uncovering underlying structures such as trees, sequence tags, or segmentations.  Traditionally, practitioners turn to pipeline approaches where an external, pretrained model is used to predict, \eg, syntactic structure.  The benefit of this approach is that the predicted tree is readily available for inspection, but the downside is that the errors  can easily propagate throughout the pipeline and require further attention . In contrast, deep neural architectures tend to eschew such preprocessing, and instead learn soft hidden representations, not easily amenable to visualization and analysis.  The best of both worlds would be to model structure as a latent variable, combining the transparency of the pipeline approach with the end-to-end unsupervised representation learning that makes deep models appealing. Moreover, large-capacity model tend to rediscover structure from scratch , so structured latent variables may reduce the required capacity.  Learning with discrete, combinatorial latent variables is, however, challenging, due to the intersection of large cardinality and null gradient issues. For example, when learning a latent dependency tree, the latent parser must choose among an exponentially large set of possible trees; what's more, the parser may only learn from gradient information from the downstream task. If the highest-scoring tree is selected using an argmax operation, the gradients will be zero, preventing learning.  One strategy for dealing with the null gradient issue is to use a surrogate gradient, explicitly overriding the zero gradient from the chain rule, as if a different computation had been performed. The most commonly known example is the straight-through estimator \citep[STE;][]{bengio2013estimating}, which pretends that the argmax node was instead an identity operator. Such methods lead to a fundamental mismatch between the objective and the learning algorithm. The effect of this mismatch  is still insufficiently understood, and the design of successful new variants is therefore challenging. For example, the recently-proposed SPIGOT method  found it beneficial to use a projection as part of the surrogate gradient.  In this paper, we study surrogate gradient methods for deterministic learning with discrete structured latent variables. Our contributions are:    While the discrete methods do not outperform the relaxed alternatives using the same building \linebreak blocks, we hope that our interpretation and insights would trigger future latent structure research.  The code for the paper is available on \url{https://github.com/deep-spin/understanding-spigot}.         We find that adding auxiliary rewards using sentiment analysis can help improve RL agents' performance in text domains. Our methods take a step in the direction of creating agents that infers rewards by themselves. We expect that these improvements are applicable to similar text-based domains, such as task-oriented dialogue. Given the rapid improvements in NLP methods, we believe that better pre-training and sentiment analysis models will translate to better RL agents in the future.  
"," Latent structure models are a powerful tool for modeling language data: they can mitigate the error propagation and annotation bottleneck in pipeline systems, while simultaneously uncovering linguistic insights about the data. One challenge with end-to-end training of these models is the argmax operation, which has null gradient. In this paper, we focus on surrogate gradients, a popular strategy to deal with this problem. We explore latent structure learning through the angle of pulling back the downstream learning objective. In this paradigm, we discover a principled motivation for both the straight-through estimator  as well as the recently-proposed SPIGOT---a variant of STE for structured models. Our perspective leads to new algorithms in the same family. We empirically compare the known and the novel pulled-back estimators against the popular alternatives, yielding new insight for practitioners and revealing intriguing failure cases.",162
"   %% Paragraph 1:  %% * introduce the constructions of interest  %% * give broad impression of the subtlety of grammatical phenomena, %% * emphasize the verb bias problem, since this is one of our unique contributions When we use language, we are often faced with a choice between several possible ways of expressing the same message. For example, in English, to express an event of intended or actual transfer between two animate entities, one option is the double-object  construction, in which two noun phrases follow the verb.  Alternatively, the same content can be expressed using the prepositional dative  construction.  \ex.  \a. Ava gave him something. \hfill DO \b. Ava gave something to him. \hfill PO  Speakers' preferences for one or the other construction depend on multiple factors, including the length and definiteness of the arguments  . % could also cite: Davidse 1996; Givo 铏俷 1984a; Polinsky 1996; Ransom 1979; Snyder 2003; Thompson 1990, 1995;  One particularly subtle factor is the lexical verb bias. While some verbs readily occur in either construction, others have strong preferences for one over the other :  \ex.  \a. ?Ava said him something. \hfill DO \b. Ava said something to him. \hfill PO  %% Paragraph 2:  %% * transition to motivation for why this problem is interesting for NLP %% * briefly mention major previous work on this problem and its gaps   Decades of work in linguistics and psychology has investigated how humans learn these distinctions . Yet, as deep neural networks have achieved state-of-the-art performance across many tasks in natural language processing, little is known about the extent to which they have acquired similarly fine-grained preferences. Although neural language models robustly capture certain types of grammatical constraints, e.g., subject-verb agreement and long distance dependencies , they continue to struggle with other aspects of syntax, including argument structure \cite[e.g.][]{warstadt2019neural}. Verb biases provide a particularly interesting testbed.  Successfully predicting these psycholinguistic phenomena requires the integration of specific lexical information with representations of higher-level grammatical structures, with implications for understanding differential performance between models on other tasks.    %% Paragraph 3: our contribution In the current work, we take an analytic and comparative approach. First, we introduce the DAIS  dataset, containing 50K human preference judgments for 5K sentence pairs, using 200 unique verbs. These empirical judgments indicate that verb bias preferences are highly gradient in practice , rather than belonging to binary ``alternating'' and ``non-alternating'' classes, as commonly assumed. Second, we evaluate the predictions of a variety of neural models, including both recurrent architectures and transformers, and analyze their internal states to understand what drives differences in performance.  \change{Finally, we evaluate our models on natural production data from the Switchboard corpus, finding that transformers achieve similar classification accuracy as prior work using hand-annotated features \cite[;][]{bresnan2007predicting}.}       In this work, we provide a novel motivation for straight-through estimator  and SPIGOT, based on pulling back the downstream loss. We derive promising new algorithms, and novel insight into existing ones. Unstructured controlled experiments suggest that our new algorithms, which use the cross-entropy loss instead of the perceptron loss, can be more stable than SPIGOT while accurately disentangling the latent variable. Differentiable relaxation models  are the easiest to optimize to high downstream accuracy, but they fail to correctly identify the latent clusters. On structured NLP experiments, relaxations  tend to overall perform better and be more stable than straight-through variants in terms of classification accuracy. However, the lack of gold-truth latent structures makes it impossible to assess recovery performance. We hope that our insights, including some of our negative results,  may encourage future research on learning with latent structures.   
"," Languages typically provide more than one grammatical construction to express certain types of messages. A speaker's choice of construction is known to depend on multiple factors, including the choice of main verb -- a phenomenon known as verb bias. Here we introduce DAIS, a large benchmark dataset containing 50K human judgments for 5K distinct sentence pairs in the English dative alternation. This dataset includes 200 unique verbs and systematically varies the definiteness and length of arguments.  We use this dataset, as well as an existing corpus of naturally occurring data, to evaluate how well recent neural language models capture human preferences. Results show that larger models perform better than smaller models, and transformer architectures  tend to out-perform recurrent architectures  even under comparable parameter and training settings.  Additional analyses of internal feature representations suggest that transformers may better integrate specific lexical information with grammatical constructions.",163
"     The core idea behind the predominant pretrain and fine-tune paradigm for transfer learning in NLP is that general language knowledge, gleaned from large quantities of data using unsupervised objectives, can serve as a foundation for more specialized endeavors. Current practice involves taking the full model that has amassed such general knowledge and fine-tuning it with a second objective appropriate to the new task \citep[see][for an overview]{raffelExploringLimitsTransfer2019}. Using these methods, pre-trained transformer-based language models \citep[e.g., BERT, ][]{devlin-etal-2019-bert} have been employed to great effect on a wide variety of NLP problems, thanks, in part, to a fine-grained ability to capture aspects of linguistic context .      However, this paradigm introduces a subtle but insidious limitation that becomes evident when the downstream application is a topic model. A topic model may be cast as a  autoencoder , and we could fine-tune a pretrained transformer with an identical document reconstruction objective. But in replacing the original topic model, we lose the property that makes it desirable: its interpretability. The transformer gains its contextual power from its ability to exploit a huge number of parameters, while the interpretability of a topic model comes from a dramatic dimensionality reduction.      We combine the advantages of these two approaches---the rich contextual language knowledge in pretrained transformers and the intelligibility of topic models---using knowledge distillation . In the original formulation, knowledge distillation involves training a parameter-rich teacher classifier on large swaths of data, then using its high-quality probability estimates over outputs to guide a smaller student model. Since the information contained in these estimates is useful---a picture of an ox will yield higher label probabilities for buffalo than apricot---the student needs less data to train and can generalize better.  We show how this principle can apply equally well to improve unsupervised topic modeling, which to our knowledge has not previously been attempted.  While distillation usually involves two models of the same type, it can also apply to models of differing architectures. Our method is conceptually quite straightforward: we fine-tune a pretrained transformer  on a document reconstruction objective, where it acts in the capacity of an autoencoder. When a document is passed through this BERT autoencoder, it generates a distribution over words that includes unobserved but related terms. We then incorporate this distilled document representation into the loss function for topic model estimation.    To connect this method to the more standard supervised knowledge distillation, observe that the unsupervised ``task'' for both an autoencoder and a topic model is the reconstruction of the original document, i.e. prediction of a distribution over the vocabulary. The BERT autoencoder, as ``teacher'', provides a dense prediction that is richly informed by training on a large corpus. The topic model, as ``student'', is generating its own prediction of that distribution. We use the former to guide the latter, essentially as if predicting word distributions were a multi-class labeling problem. \newcommand{\reffig}[1]{\hl{[FIG: #1]}} \newcommand{\reftable}[1]{\hl{[TABLE: #1]}} \newcommand{\refsec}[1]{\hl{[SECTION: #1]}} \newcommand{\ho}[1]{\textcolor{blue}{}} \newcommand{\pg}[1]{\textcolor{red}{}} \newcommand{\psrcomment}[1]{}  \newcommand{\ignore}[1]{} \newcommand{\ourmodel}{BAT }   \newcommand{\e}[2]{\mathbb{E}_{#1}\left[ #2 \right] } \newcommand{\B}{B} \DeclareMathOperator*{\argmin}{arg\,min}  \aclfinalcopy %   \newcommand\BibTeX{Bib\TeX}  \title{Improving Neural Topic Models using Knowledge Distillation}  \author{Alexander Hoyle\thanks{\, Equal contribution.} \\   Computer Science \\   University of Maryland \\   College Park, MD \\    \\\And   Pranav Goel\footnotemark[1] \\   Computer Science \\   University of Maryland \\   College Park, MD \\    \\\And   Philip Resnik \\   Linguistics / UMIACS \\   University of Maryland \\   College Park, MD \\    \\}  \date{}  \begin{document}                         \bibliography{anthology,refs,zotero} \bibliographystyle{acl_natbib}  \clearpage \appendix    In natural languages, speakers routinely select one alternative over others to express their intended message.   These choices are sensitive to many interacting factors, including the choice of the main verb and the length and definiteness of arguments.  Our new dataset, DAIS, not only offers a higher-resolution window into the richness of human preferences, it also provides a newly powerful benchmark for evaluating and understanding the corresponding sensitivity of language models. We found that transformer architectures corresponded especially well with human verb bias judgments.  Further work is needed to more precisely determine the source of the architectural differences we observed. One possibility is that the transformer's self-attention mechanism and layer-wise organization improves its ability to represent lexically-specific structures.  However, it is also possible that differences are attributable to training data. Another line of future research is to compare the incremental predictions of neural models to finer-grained eye-tracking evidence during sentence processing of double-object sentences \cite[e.g.][]{filik2004processing}. As neural language models become more complex, subtler phenomena like verb bias may yield new insights into how lexical and grammatical representations are jointly learned and successfully integrated for language understanding.   
","     Topic models are often used to identify human-interpretable topics to help make sense of large document collections. We use knowledge distillation to combine the best attributes of probabilistic topic models and pretrained transformers. Our modular method can be straightforwardly applied with any neural topic model to improve topic quality, which we demonstrate using two models having disparate architectures, obtaining state-of-the-art topic coherence. We show that our adaptable framework not only improves performance in the aggregate over all estimated topics, as is commonly reported, but also in head-to-head comparisons of aligned topics.",164
"      Interactive systems capable of understanding natural language and responding in the form of natural language text have high potentials in various applications.  In pursuit of building and evaluating such systems, we study learning agents for Interactive Fiction  games. IF games are world-simulating software in which players use text commands to control the protagonist and influence the world, as illustrated in Figure. IF gameplay agents need to simultaneously understand the game's information from a text display  and generate natural language command  via a text input interface.  Without providing an explicit game strategy, the agents need to identify behaviors that maximize objective-encoded cumulative rewards.    IF games composed of human-written texts  create superb new opportunities for studying and evaluating natural language understanding  techniques due to their unique characteristics.   Game designers elaborately craft on the literariness of the narrative texts to attract players when creating IF games. The resulted texts in IF games are more linguistically diverse and sophisticated than the template-generated ones in synthetic text games.  The language contexts of IF games are more versatile because various designers contribute to enormous domains and genres, such as adventure, fantasy, horror, and sci-fi.  The text commands to control characters are less restricted, having sizes over six orders of magnitude larger than previous text games.  The recently introduced Jericho benchmark provides a collection of such IF games.   The complexity of IF games demands more sophisticated NLU techniques than those used in synthetic text games. Moreover, the task of designing IF game-play agents, intersecting NLU and reinforcement learning , poses several unique challenges on the NLU techniques. The first challenge is the difficulty of exploration in 	extbf{the huge natural language action space}. To make RL agents learn efficiently %via trial-and-error  without prohibitive exhaustive trials, the action estimation must generalize learned knowledge from tried actions to others.  To this end, previous approaches, starting with a single embedding vector of the observation, either predict the elements of actions independently; or embed each valid action as another vector and predict action value based on the vector-space similarities. These methods do not consider the compositionality or role-differences of the action elements, or the interactions among them and the observation. Therefore, their modeling of the action values is less accurate and less data-efficient.   The second challenge is 	extbf{partial observability}.  At each game-playing step, the agent receives a textual observation describing the locations, objects, and characters of the game world.  But the latest observation is often not a sufficient summary of the interaction history and may not provide enough information to determine the long-term effects of actions.  Previous approaches address this problem by building a representation over past observations . These methods treat the historical observations equally and summarize the information into a single vector without focusing on important contexts related to the action prediction for the current observation. Therefore, their usages of history also bring noise, and the improvement is not always significant.  We propose a novel formulation of IF game playing as Multi-Passage Reading Comprehension  and harness MPRC techniques to solve the huge action space and partial observability challenges. The graphical illustration is shown in Figure.  First, the action value prediction  is essentially generating and scoring a compositional action structure by finding supporting evidence from the observation. We base on the fact that each action is an instantiation of a template, i.e., a verb phrase with a few placeholders of object arguments it takes~. Then the action generation process can be viewed as extracting objects for a template's placeholders from the textual observation, based on the interaction between the template verb phrase and the relevant context of the objects in the observation. Our approach addresses the structured prediction and interaction problems with the idea of context-question attention mechanism in RC models.  Specifically, we treat the observation as a passage and each template verb phrase as a question.  The filling of object placeholders in the template thus becomes an extractive QA problem that selects objects from the observation given the template. Simultaneously each action  gets its evaluation value predicted by the RC model. Our formulation and approach better capture the fine-grained interactions between observation texts and structural actions, in contrast to previous approaches that represent the observation as a single vector and ignore the fine-grained dependency among action elements.  Second, alleviating partial observability is essentially enhancing the current observation with potentially relevant history and predicting actions over the enhanced observation. Our approach retrieves potentially relevant historical observations with an object-centric approach  , so that the retrieved ones are more likely to be connected to the current observation as they describe at least one shared interactable object. Our attention mechanisms are then applied across the retrieved multiple observation texts to focus on informative contexts for action value prediction.   We evaluated our approach on the suite of Jericho IF games, compared to all previous approaches. Our approaches achieved or outperformed the state-of-the-art performance on 25 out of 33 games, trained with less than one-tenth of game interaction data used by prior art.  We also provided ablation studies on our models and retrieval strategies.     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    To our knowledge, we are the first to distill a ``black-box'' neural network teacher to guide a probabilistic graphical model. We do this in order to combine the expressivity of probabilistic topic models with the precision of pretrained transformers. Our modular method sits atop any neural topic model  to improve topic quality, which we demonstrate using two NTMs of highly disparate architectures , obtaining state-of-the-art topic coherence across three datasets from different domains. Our adaptable framework does not just produce improvements in the aggregate : its effect can be interpreted more specifically as identifying the same space of topics generated by an existing model and, in most cases, improving the coherence of individual topics, thus highlighting the modular value of our approach.  In future work, we also hope to explore the effects of the pretraining corpus  and teachers  on the generated topics. Another intriguing direction is exploring the connection between our methods and neural network interpretability. The use of knowledge distillation to facilitate interpretability has also been previously explored, for example, in  to learn interpretable decision trees from neural networks. In our work, as the weight on the BERT autoencoder logits  goes to one, the topic model begins to describe less the corpus and more the teacher. We believe mining this connection can open up further research avenues; for instance, by investigating the differences in such teacher-topics conditioned on the pre-training corpus. Finally, although we are motivated primarily by the widespread use of topic models for identifying interpretable topics \cite[][Ch. 3]{boyd2017applications},  we plan to explore the ideas presented here further in the context of downstream applications like document classification.  \looseness=-1
"," Interactive Fiction  games with real human-written natural language texts provide a new natural evaluation for language understanding techniques.  In contrast to previous text games with mostly synthetic texts, IF games pose language understanding challenges on the human-written textual descriptions of diverse and sophisticated game worlds and language generation challenges on the action command generation from less restricted combinatorial space. We take a novel perspective of IF game solving and re-formulate it as Multi-Passage Reading Comprehension  tasks. Our approaches utilize the context-query attention mechanisms and the structured prediction in MPRC to efficiently generate and evaluate action outputs and apply an object-centric historical observation retrieval strategy to mitigate the partial observability of the textual observations.  Extensive experiments on the recent IF benchmark  demonstrate clear advantages of our approaches achieving high winning rates and low data requirements compared to all previous approaches.\footnote{Source code is available at: \url{https://github.com/XiaoxiaoGuo/rcdqn}. }",165
"   Recent advances in self-supervised pre-training have resulted in impressive downstream performance on several NLP tasks. However, this has led to the development of enormous models, which often require days of training on non-commodity hardware . Furthermore, studies have shown that it is quite challenging to successfully train these large Transformer models, requiring complicated learning schemes and extensive hyperparameter tuning.  Despite these expensive training regimes, recent studies have found that once trained, these bi-directional language models exhibit simple patterns of self-attention without much linguistic backing. For example, 40\% of heads in a pre-trained BERT model simply pay attention to delimiters added by the tokenizer . Since these attention patterns are independent of linguistic phenomena, a natural question arises: can Transformer models be guided towards such attention patterns without requiring extensive training?    In this paper, we propose an attention guidance  mechanism for self-attention modules in Transformer architectures to enable faster, more efficient, and robust self-supervised learning. Our approach is simple and agnostic to the training objective. Specifically, we introduce an auxiliary loss function to guide the self-attention heads in each layer towards a set of pre-determined patterns . These patterns encourage the formation of both  global  and local  structures in the model.   Through several experiments, we show that our approach enables training large Transformer models considerably faster 閳 for example, we can train a 16-layer RoBERTa model with SOTA performance on a low-resource domain in just two days using four GPUs, while excluding our loss leads to slow or no convergence. Our method also achieves competitive performance with BERT on three English natural language understanding tasks, and outperforms the baseline masked language modeling  models on eleven out of twelve settings considered.  Further, we also show that our initialization is agnostic to the training objective by demonstrating gains on the replaced token detection objective proposed by ELECTRA and on machine translation with Transformers. Finally, we provide an analysis of the attention heads learned using our method. Surprisingly, contrary to recent studies, we find that it is possible to train models that perform well on language modeling without learning a single attention head that models coreferences. % . For example, our model fails the co-reference test in  while still performing well on language modeling and downstream tasks.  To summarize, our main contributions are:   We formulate the general IF game playing as MPRC tasks, enabling an MPRC-style solution to efficiently address the key IF game challenges on the huge combinatorial action space and the partial observability in a unified framework.  Our approaches achieved significant improvement over the previous state-of-the-art on both game scores and training data efficiency. Our formulation also bridges broader NLU/RC techniques to address other critical challenges in IF games for future work, e.g., common-sense reasoning, novelty-driven exploration, and multi-hop inference.    
"," % Despite being successful in downstream language understanding tasks, modern language models contain millions of parameters and require multiple days of training on specialized hardware such as TPUs. Training such models on commodity hardware  often means slow convergence, making it practically intractable for many researchers.  In this paper, we propose a simple and effective technique to allow for efficient self-supervised learning with bi-directional Transformers. Our approach is motivated by recent studies demonstrating that self-attention patterns in trained models contain a majority of non-linguistic regularities. We propose a computationally efficient auxiliary loss function to guide attention heads to conform to such patterns. Our method is agnostic to the actual pre-training objective and results in faster convergence of models as well as better performance on downstream tasks compared to the baselines, achieving state of the art results in low-resource settings. Surprisingly, we also find that linguistic properties of attention heads are not necessarily correlated with language modeling performance.\footnote{Code: \href{https://github.com/ameet-1997/AttentionGuidance}{https://github.com/ameet-1997/AttentionGuidance}}",166
" %  % Transformer models  have outperformed previously used RNN based models and traditional statistical MT techniques.  This improvement, though, comes at the cost of higher computation complexity. The decoder computation is sequential and becomes the bottleneck due to the autoregressive nature, large depth and self-attention structure.   % Another recent trend has been making the models larger and ensembling multiple models to achieve the best possible translation quality . Leading solutions on common benchmark  usually use an ensemble of Transformer big models, which combined can have more than 1 billion parameters.   % In this paper, we focus on developing architectures which are faster during inference and have less number of parameters, without sacrificing translation quality.  % Recent work \citet{ludicrously:kim2019} proposed methods to replace self-attention in the decoder with simpler simple recurrent units  and used knowledge distillation to simplify training for the final architecture. \citet{deepencoder} also proposed to make the decoder lightweight by training a deep-encoder, shallow decoder architecture. Another line of effort to make NMT architectures more efficient is pruning different components of the model. \citet{prune_voita-etal-2019-analyzing} and \citet{prune_michel:NIPS2019_9551} show that most of the attention heads in the network learn redundant information and can be pruned away.  % All of the above works use the vanilla Transformer architecture as their baseline, so it is not clear if these approaches can give complimentary results when combined together. In this work, we explore and benchmark combining all of the above techniques, with the goal of maximizing inference speed without hurting in translation quality. % %We adapt the same approach and  extend it with the following ideas. First, we optimized the SSRU to make it more efficient. Second, we removed the feed-forward network in the decoder completely. Then, we kept only 1 layer in the decoder and used very deep encoder. Last we pruned all the redundant heads in the deep encoder.  % After carefully stacking the approaches, our proposed architecture is able to achieve a significant speed improvement of 84\% on GPU and 102\% on CPU architectures without any degradation of translation quality in terms of BLEU.  % %%%%%%%% original Related Work %%%%%%%%% %     In this section, we investigate two questions: 1) why We project token-level representations obtained from the BERT embedders onto a 2-dimensional space using t-SNE. \autoref{fig:tsne} presents the visualization results on the CoNLL and WNUT test sets .  beyond optimal visual effect)  Fine-tuning BERT on OntoNotes clearly improves the task-awareness with respect to both CoNLL and WNUT datasets, as instances of the same class are much closer compared to those obtained from the non-fine-tuned BERT model. The separation of different entity classes is more evident on CoNLL due to the greater tag set overlap with OntoNotes.   Instances labeled with \nertag{O} are spread across the space, regardless of fine-tuning.   This explains the effectiveness of \sysname. First, fine-tuning BERT in a conventional NER setting is able to learn a good entity specific metric space. Second, the nearest neighbor classifier that emphasizes more on local distance is more appropriate for assigning \nertag{O} to an instance.    , \nertag{c-work}, and \nertag{corp.} correspond \nertag{MEDICAL-RECORD}, \nertag{location}, \nertag{creative-work}, and \nertag{corporation} respectively.}    \paragraph{Per-class performance analysis} We attempt to shed some light on the second question by analyzing outputs from the best five-shot \sysname~systems on the domain transfer task. The per-class F1 scores are shown in, where we exclude I2B2 classes with less than 200 instances in the test set. \sysname~achieves reasonable performance on less ambiguous entity classes such as \nertag{DATE}, \nertag{CITE}, \nertag{person}, and \nertag{location}. However, it struggles to distinguish between highly ambiguous classes. For example, \nertag{AGE}, \nertag{MEDICAL-RECORD}, \nertag{PHONE}, and \nertag{IDNUM} are all numbers. It is still challenging for our system to differentiate different numerical types without any domain specific knowledge. Similarly, \sysname~often predicts a \nertag{PATIENT} entity as \nertag{DOCTOR} and it nearly always assigns the \nertag{corporation} label to entities of \nertag{group}. We believe that domain specific cues like `Dr.' and `MD.' can be useful in resolving these ambiguities and enable few-shot NER systems to generalize better.  beyond the few support examples.    We focus on the typical errors made on the I2B2 and WNUT test sets, as the system performance on CoNLL is very solid. \section{Experiments}   In this section, we compare \sysname~against existing methods on two few-shot NER scenarios: tag set extension and domain transfer. We adopt several benchmark NER corpora in different domains for the few-shot experiments. \let\argmin\relax \let\argmax\relax \DeclareMathOperator*{\argmin}{arg\,min} \DeclareMathOperator*{\argmax}{arg\,max} \newcommand{\example}[1]{`#1'} \newcommand{\nertag}[1]{\texttt{#1}} \newcommand{\sysname}{}  \newcommand{\arzoo}[1]{[{Arzoo: {#1}}]}    --------------------------------------------  \aclfinalcopy   Uncomment this line for the final submission \def\aclpaperid{2799}    Enter the acl Paper ID here  \setlength\titlebox{5cm}      Expanding the titlebox \title{Simple and Effective Few-Shot Named Entity Recognition\\ with Structured Nearest Neighbor Learning}  \author{Yi Yang \\ 	ASAPP Inc.\\ 	New York, NY 10007\\ 	yyang@asapp.com \\\And  	Arzoo Katiyar \thanks{ \hspace{0.15cm}Work done at ASAPP Inc.} \\ 	Pennsylvania State University \\ 	University Park, PA 16802\\ 	arzoo@psu.edu     }                             \date{}      ***********************************************************   Introduction     ***********************************************************   Problem     ***********************************************************   Model     ***********************************************************   Experiment     ***********************************************************   Discussion     ***********************************************************   Related Work     ***********************************************************   Conclusion and Future Work     ***********************************************************   Acknowledgments     ***********************************************************       ***********************************************************   Appendix   
"," Large Transformer models have achieved state-of-the-art results in neural machine translation and have become standard in the field. In this work, we look for the optimal combination of known techniques to optimize inference speed without sacrificing translation quality. We conduct an empirical study that stacks various approaches and demonstrates that combination of replacing decoder self-attention with simplified recurrent units, adopting a deep encoder and a shallow decoder architecture and multi-head attention pruning can achieve up to $109$\% and $84$\% speedup on CPU and GPU respectively and reduce the number of parameters by $25$\% while maintaining the same translation quality in terms of BLEU. %State-of-the-art neural machine translation has become compute and parameter intensive in the last several years, which puts significant pressure on the latency and hardware resources during inference. In this paper, we change the standard Transformer architecture to reduce the number of parameters and increase inference speed without sacrificing translation quality. We demonstrate that combination of replacing decoder self-attention with the simpler simple recurrent units, adopting a deep encoder and shallow decoder architecture, and multi-head attention pruning, we can achieve up to 102\% speedup and reduce the number of parameters by 13\% while maintaining the same translation quality in terms of BLEU.",167
" Intent Detection  is a crucial task in natural language understanding, whose objective is to extract underlying intents behind the given utterances. The extracted intents could provide further contexts for further downstream Natural Language Processing tasks such as dialogue state tracking or question answering. Unlike traditional text classification, ID is challenging for two main reasons  Utterances are usually short and diversely expressed,  Emerging intents occur continuously, especially across different domains .  Despite recent advances, state-of-the-art ID methods  require a large amount of annotated data to achieve competitive performance. This requirement inhibits models' capability in generalizing to newly emerging intents with no or limited annotations during inference. Re-training or fine-tuning large models on few samples of emerging classes could easily lead to overfitting problems.      Motivated by human capability in correctly categorizing new classes with only a few examples , few-shot learning  paradigms are adopted to tackle the scarcity problems of emerging classes. FSL methods take advantage of a small set of labeled examples  to learn how to discriminate unlabeled samples  between classes, even those not seen during training.  Recent works in FSL  focus on learning the matching information between the labeled samples  and the unlabeled samples  to provide additional contextual information for instance-level representations, leading to effective prototype representation. However, these methods only extract similarity based on fine-grained word semantics, failing to capture the diverse expressions of users' utterances. This problem could further lead to overfitting either to seen intents or novel intents, especially in the challenging Generalized Few-shot Intent Detection  setting  where both seen and novel intents are existent in a joint label space during inference. Instead, matching support and query samples on coarser-grained semantic components could provide additional informative contexts beyond word levels. For instance, two utterances ""i need to get a table at a pub with southeastern cuisine"" and ``book a spot for six friends"" share a similar intent label ``Book Restaurant"". While word-level semantics might find similar action words as ``get"" and ``book"", these words do not necessarily contribute to the correct intent findings. Instead, coarser-grained semantics such as ``get a table"" and ``book a spot"" could provide further hints to identify ``Book Restaurant"" intent.      As semantic components  could be effectively extracted from multi-head self-attention, matching these SC between support and query can enhance both query and support representations, leading to improvements in generalization from seen training classes to unseen testing classes. To further enhance the dynamics of extracted SC across various domains and diversely expressed utterances, we introduce additional head regularizations. In addition, to overcome the insufficiency of a single similarity measure for matching sentences with diverse semantics, a more comprehensive matching method is further explored.      Our main contribution is summarized as follows:       In this paper we explored the combination of techniques aimed at improving inference speed which lead to the discovery of a very efficient architecture. The best architecture has a deep -layer encoder, and a shallow decoder with only one single lightweight recurrent unit layer and one encoder-decoder attention mechanism. \  of the encoder heads were pruned giving rise to a model with \  fewer parameters than the baseline Transformer. In terms of inference speed, the proposed architecture is \  faster on a GPU, and \  faster on a CPU.   In the future, we plan to investigate pruning the feed-forward network in the encoder, and explore application of the lottery ticket hypothesis.        In this paper,     we have investigated various approaches of simplifying Transformer model to speed up the inference and successfully combine multiple techniques. To be more specific,    we achieve the very efficient inference architecture, which consists of only one lightweight recurrent unit layer and one encoder-decoder attention mechanism in the decoder. With the head pruning method, only 18\  of attention heads are required in the deep encoder and shallow decoder architecture. This model has 13\  fewer parameters, and during the inference stage, it is 84\  and 102\  faster than baseline on GPU and CPU, respectively.    In the future, we plan to prune the feed-forward network in the encoder and explore the combination with the lottery ticket hypothesis.      In the future, we plan to investigate more different approaches and build a mroe efficient inference architecture for machine translation.     we plan to prune the feed-forward neurons and apply the unstructured pruning techniques to remove weights in the whole model.  
"," Few-shot Intent Detection is challenging due to the scarcity of available annotated utterances. Although recent works demonstrate that multi-level matching plays an important role in transferring learned knowledge from seen training classes to novel testing classes, they rely on a static similarity measure and overly fine-grained matching components. These limitations inhibit generalizing capability towards Generalized Few-shot Learning settings where both seen and novel classes are co-existent. In this paper, we propose a novel Semantic Matching and Aggregation Network where semantic components are distilled from utterances via multi-head self-attention with additional dynamic regularization constraints. These semantic components capture high-level information, resulting in more effective matching between instances. Our multi-perspective matching method provides a comprehensive matching measure to enhance representations of both labeled and unlabeled instances. We also propose a more challenging evaluation setting that considers classification on the joint all-class label space. Extensive experimental results demonstrate the effectiveness of our method. Our code and data are publicly available \footnote{\url{https://github.com/nhhoang96/Semantic\_Matching}} .",168
"  Neural machine translation  is a data-hungry approach, which requires a large amount of data to train a well-performing NMT model. However, the complex patterns and potential noises in the large-scale data make training NMT models difficult.  To relieve this problem, several approaches have been proposed to better exploit the training data, such as curriculum learning, data diversification, and data denoising.  In this paper, we explore an interesting alternative which is to reactivate the inactive examples in the  training data for NMT models. By definition, inactive examples are the training examples that only marginally contribute to or even inversely harm the performance of NMT models.  Concretely, we use sentence-level output probability assigned by a trained NMT model to measure the activeness level of training examples, and regard the examples with the least probabilities as inactive examples . Experimental results show that removing 10\% most inactive examples can marginally improve translation performance. In addition, we observe a high overlapping ratio  of the most inactive and active examples across random seeds, model capacity, and model architectures . These results provide empirical support for our hypothesis of the existence of inactive examples in large-scale datasets, which is invariant to specific NMT models and depends on the data distribution itself.  We further propose data rejuvenation to rejuvenate the inactive examples to improve the performance of NMT models.  Specifically, we train an NMT model on the active examples as the rejuvenation model to re-label the inactive examples, resulting in the rejuvenated examples~. The final NMT model is trained on the combination of the active examples and rejuvenated examples. Experimental results show that the data rejuvenation approach consistently and significantly improves performance on SOTA NMT models  on the benchmark WMT14 English-German and English-French datasets~. Encouragingly, our approach is also complementary to existing data manipulation methods , and combining them can further improve performance.      Finally, we conduct extensive analyses to better understand the inactive examples and the proposed data rejuvenation approach. Quantitative analyses reveal that the inactive examples are more difficult to learn than active ones, and rejuvenation can reduce the learning difficulty~. The rejuvenated examples stabilize and accelerate the training process of NMT models~, resulting in final models with better generalization capability~.  Our contributions of this work are as follows:        In this work, we propose a multi-task learning framework that jointly trains the model with the translation task on bitext data, the masked language modeling task on the source-side monolingual data and the denoising auto-encoding task on the target-side monolingual data. We explore data and noising scheduling approaches and demonstrate their efficacy for the proposed approach. We show that the proposed MTL approach can effectively improve the performance of MNMT on both high-resource and low-resource languages with large margin, and can also significantly improve the translation quality for zero-shot language pairs without bitext training data. We showed that the proposed approach is more effective than pre-training followed by finetuning for NMT. Furthermore, we showed the effectiveness of multitask learning for cross-lingual downstream tasks outperforming  SOTA larger models trained on single task.  For future work, we are interested in investigating the proposed approach in a scaled setting with more languages and a larger amount of monolingual data. Scheduling the different tasks and different types of data would be an interesting problem. Furthermore, we would also like to explore the most sample efficient strategy to add a new language to a trained MNMT system.  
"," Large-scale training datasets lie at the core of the recent success of neural machine translation  models. However, the complex patterns and potential noises in the large-scale data make training NMT models difficult. In this work, we explore to identify the inactive training examples which contribute less to the model performance, and show that the existence of inactive examples depends on the data distribution. We further introduce data rejuvenation to improve the training of NMT models on large-scale datasets by exploiting inactive examples. The proposed framework consists of three phases.  First, we train an identification model on the original training data, and use it to distinguish inactive examples and active examples by their sentence-level output probabilities. Then, we train a rejuvenation model on the active examples, which is used to re-label the inactive examples with forward-translation. Finally, the rejuvenated examples and the active examples are combined to train the final NMT model. Experimental results on WMT14 English-German and English-French datasets show that the proposed data rejuvenation consistently and significantly improves performance for several strong NMT models. Extensive analyses reveal that our approach stabilizes and accelerates the training process of NMT models, resulting in final models with better generalization capability.}  %In this work, we propose to improve the training of NMT models on large-scale datasets by exploiting inactive training examples, which contribute less to the model performance. Specifically, the proposed framework consists of three phases. First, we identify the inactive examples with their sentence-level prediction confidence assigned by an identification model trained on the original training data. Then, we train a rejuvenation model on the active examples, which is used to re-label the inactive examples with forward-translation. Finally, the rejuvenated examples and the active examples are combined to train the final NMT model. Experimental results on WMT14 English-German and English-French datasets show that the proposed data rejuvenation consistently and significantly improves performance for several strong NMT models. Extensive analyses reveal that our approach stabilizes and accelerates the training process of NMT models, resulting in final models with better generalization capability.",169
"  The following instructions are directed to authors of papers submitted to EMNLP 2020 or accepted for publication in its proceedings. All authors are required to adhere to these specifications. Authors are required to provide a Portable Document Format  version of their papers. The proceedings are designed for printing on A4 paper.      In this study, we propose data rejuvenation to exploit the inactive training examples for neural machine translation on large-scale datasets. The proposed data rejuvenation scheme is a general framework where one can freely define, for instance, the identification and rejuvenation models. Experimental results on different model architectures and language pairs demonstrate the effectiveness and universality of the data rejuvenation approach.  Future directions include exploring advanced identification and rejuvenation models that can better reflect the learning abilities of NMT models, as well as validating on other NLP tasks such as dialogue and summarization.    
"," This document contains the instructions for preparing a manuscript for the proceedings of EMNLP 2020. The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like. These instructions should be used for both papers submitted for review and for final versions of accepted papers. Authors are asked to conform to all the directions reported in this document.",170
" Modern neural machine translation~ models employ sufficient capacity to fit the massive data well by utilizing a large number of parameters, and suffer from the widely recognized issue, namely, over-parameterization. For example,  showed that over 40\% of the parameters in an RNN-based NMT model can be pruned with negligible performance loss. However, the low utilization efficiency of parameters results in a waste of computational resources , as well as renders the model stuck in a local optimum.   In response to the over-parameterization issue, network pruning has been widely investigated for both computer vision   and natural language processing  tasks . Recent work has proven that such spare parameters can be reused to maximize the utilization of models in CV tasks such as image classification. The leverage of parameter rejuvenation in sequence-to-sequence learning, however, has received relatively little attention from the research community. In this paper, we empirically study the efficiency issue for NMT models.  Specifically, we first investigate the effects of weight pruning on advanced Transformer models, showing that 20\% parameters can be directly pruned, and by continuously training the sparse networks, we can prune 50\% with no performance loss. Starting from this observation, we then exploit whether these redundant parameters are able to be re-utilized for improving the performance of NMT models. Experiments are systematically conducted on different datasets  and NMT architectures . Results demonstrate that the rejuvenation approach can significantly and consistently improve the translation quality by up to +0.8 BLEU points. Further analyses reveal that the rejuvenated parameters are reallocated to enhance the ability to model the source-side low-level information, lacking of which leads to a number of problems in NMT models.  \paragraph{Contributions} Our key contributions are:      We introduce GraphGlove~--- graph word embeddings, where each word is a node in a weighted graph and the distance between words is the shortest path distance between the corresponding nodes. The graph is learned end-to-end in an unsupervised manner. We show that GraphGlove substantially outperforms both Euclidean and Poincar\'e GloVe on word similarity and word analogy tasks. Our analysis reveals that the structure of the learned graphs is hierarchical and similar to that of WordNet; the geometry is highly non-trivial and contains subgraphs with different local topology.   Possible directions for future work include using GraphGlove for unsupervised hypernymy detection, analyzing undesirable word associations, comparing learned graph topologies for different languages, and downstream applications such as sequence classification. Also, given the recent success of models such as ELMo and BERT, it would be interesting to explore extensions of GraphGlove to the class of contextualized embeddings.  
"," Modern neural machine translation  models employ a large number of parameters, which leads to serious over-parameterization and typically causes the underutilization of computational resources. In response to this problem, we empirically investigate whether the redundant parameters can be reused to achieve better performance. Experiments and analyses are systematically conducted on different datasets and NMT architectures. We show that: 1) the pruned parameters can be rejuvenated to improve the baseline model by up to +0.8 BLEU points; 2) the rejuvenated parameters are reallocated to enhance the ability of modeling low-level lexical information.",171
"  Sentiment analysis  has attracted increasing attention recently. Aspect-based sentiment analysis   is a fine-grained sentiment analysis task and includes many subtasks, two of which are aspect category detection  that detects the aspect categories mentioned in a sentence and aspect-category sentiment analysis  that predicts the sentiment polarities with respect to the detected aspect categories. Figure shows an example. ACD detects the two aspect categories, ambience and food, and ACSA predicts the negative and positive sentiment toward them respectively. In this work, we focus on ACSA, while ACD as an auxiliary task is used to find the words indicating the aspect categories in sentences for ACSA.    Since a sentence usually contains one or more aspect categories, previous studies have developed various methods for generating aspect category-specific sentence representations to detect the sentiment toward a particular aspect category in a sentence. To name a few, attention-based models  allocate the appropriate sentiment words for the given aspect category. \citet{xue2018aspect} proposed to generate aspect category-specific representations based on convolutional neural networks and gating mechanisms. Since aspect-related information may already be discarded and aspect-irrelevant information may be retained in an aspect independent encoder, some existing methods  utilized the given aspect to guide the sentence encoding from scratch. Recently, BERT based models  have obtained promising performance on the ACSA task. However, these models ignored that the sentiment of an aspect category mentioned in a sentence is an aggregation of the sentiments of the words indicating the aspect category. It leads to suboptimal performance of these models. For the example in Figure, both ``drinks'' and ``food'' indicate the aspect category food. The sentiment about food is a combination of the sentiments of ``drinks'' and ``food''. Note that, words indicating aspect categories not only contain aspect terms explicitly indicating an aspect category but also contain other words implicitly indicating an aspect category . In Figure, while ``drinks'' and ``food'' are aspect terms explicitly indicating the aspect category food, ``large'' and ``noisy'' are not aspect terms implicitly indicating the aspect category ambience.  In this paper, we propose a Multi-Instance Multi-label Learning Network for Aspect-Category sentiment analysis . AC-MIMLLN explicitly models the fact that the sentiment of an aspect category mentioned in a sentence is an aggregation of the sentiments of the words indicating the aspect category. Specifically, AC-MIMLLN treats sentences as bags, words as instances, and the words indicating an aspect category as the key instances  of the aspect category. Given a bag and the aspect categories mentioned in the bag, AC-MIMLLN first predicts the instance sentiments, then finds the key instances for the aspect categories, finally aggregates the sentiments of the key instances to get the bag-level sentiments of the aspect categories.  Our main contributions can be summarized as follows:     In this paper, we prove that existing NMT systems are over-parameterized and propose to improve the utilization efficiency of parameters in NMT models by introducing a rejuvenation approach. Empirical results on a variety of language pairs and architectures demonstrate the effectiveness and universality of the presented method. We also analyze the gains from perspectives of learning dynamics and linguistic probing, which give insightful research directions for future work.   Future directions include continuing the exploration of this research topic for large sequence-to-sequence pre-training models  and multi-domain translation models . We will employ recent analysis methods to better understand the behaviors of rejuvenated models.     \clearpage  
"," 	Aspect-category sentiment analysis  aims to predict sentiment polarities of sentences with respect to given aspect categories. To detect the sentiment toward a particular aspect category in a sentence, most previous methods first generate an aspect category-specific sentence representation for the aspect category, then predict the sentiment polarity based on the representation. These methods ignore the fact that the sentiment of an aspect category mentioned in a sentence is an aggregation of the sentiments of the words indicating the aspect category in the sentence, which leads to suboptimal performance. In this paper, we propose a Multi-Instance Multi-Label Learning Network for Aspect-Category sentiment analysis , which treats sentences as bags, words as instances, and the words indicating an aspect category as the key instances of the aspect category. Given a sentence and the aspect categories mentioned in the sentence, AC-MIMLLN first predicts the sentiments of the instances, then finds the key instances for the aspect categories, finally obtains the sentiments of the sentence toward the aspect categories by aggregating the key instance sentiments. Experimental results on three public datasets demonstrate the effectiveness of AC-MIMLLN \footnote{Data and code are available at https://github.com/l294265421/AC-MIMLLN}.",172
" The recent success of the language model pre-training approaches~, which train language models on diverse text corpora with self-supervised or multi-task learning, have brought up huge performance improvements on several natural language understanding  tasks~. The key to this success is their ability to learn generalizable text embeddings that achieve near optimal performance on diverse tasks with only a few additional steps of fine-tuning on each downstream task.    Most of the existing works on language model aim to obtain a universal language model that can address nearly the entire set of available natural language tasks on heterogeneous domains. Although this train-once and use-anywhere approach has been shown to be helpful for various natural language tasks~, there have been considerable needs on adapting the learned language models to domain-specific corpora . Such domains may contain new entities that are not included in the common text corpora, and may contain only a small amount of labeled data as obtaining annotation on them may require expert knowledge.  Some recent works~ suggest to further pre-train the language model with self-supervised tasks on the domain-specific text corpus for adaptation, and show that it yields improved performance on tasks from the target domain.  Masked Language Models  objective in BERT~ has shown to be effective for the language model to learn the knowledge of the language in a bi-directional manner~. In general, masks in MLMs are sampled at random~, which seems reasonable for learning a generic language model pre-trained from scratch, since it needs to learn about as many words in the vocabulary as possible in diverse contexts.  However, in the case of further pre-training of the already pre-trained language model, such a conventional selection method may lead a domain adaptation in an inefficient way, since not all words will be equally important for the target task. Repeatedly learning for uninformative instances thus will be wasteful. Instead, as done with instance selection, it will be more effective if the masks focus on the most important words for the target domain, and for the specific NLU task at hands. How can we then obtain such a masking strategy to train the MLMs?   Several works~ propose rule-based masking strategies which work better than random masking ~ when applied to language model pre-training from scratch. Based on those works, we assume that adaptation of the pre-trained language model can be improved via a learned masking policy which selects the words to mask. Yet, existing models are inevitably suboptimal since they do not consider the target domain and the task. To overcome this limitation, in this work, we propose to adaptively generate mask by learning the optimal masking policy for the given task, for the task-adaptive pre-training~ of the language model.  As described in Figure , we want to further pre-train the language model on a specific task with a task-dependent masking policy, such that it directs the solution to the set of parameters that can better adapt to the target domain, while task-agnostic random policy leads the model to an arbitrary solution.  To tackle this problem, we pose the given learning problem as a meta-learning problem where we learn the task-adaptive mask-generating policy, such that the model learned with the masking strategy obtains high accuracy on the target task.  We refer to this meta-learner as the Neural Mask Generator . Specifically, we formulate mask learning as a bi-level problem where we pre-train and fine-tune a target language model in the inner loop, and learn the NMG at the outer loop, and solve it using renforcement learning. We validate our method on diverse NLU tasks, including question answering and text classification. The results show that the models trained using our NMG outperforms the models pre-trained using rule-based masking strategies, as well as finds a proper adaptive masking strategy for each domain and task.  Our contribution is threefold:     In this paper, we propose a Multi-Instance Multi-Label Learning Network for Aspect-Category sentiment analysis . AC-MIMLLN predicts the sentiment of an aspect category mentioned in a sentence by aggregating the sentiments of the words indicating the aspect category in the sentence. Experimental results demonstrate the effectiveness of AC-MIMLLN. Since AC-MIMLLN finds the key instances for the given aspect category and predicts the sentiments of the key instances, it is more interpretable. In some sentences, phrases or clauses rather than words indicate the given aspect category, future work could consider multi-grained instances, including  words, phrases and clauses. Since directly finding the key instances for some aspect categories is ineffective, we will try to first recognize all opinion snippets in a sentence, then assign these snippets to the aspect categories mentioned in the sentence.   
"," We propose a method to automatically generate a domain- and task-adaptive maskings of the given text for self-supervised pre-training, such that we can effectively adapt the language model to a particular target task . Specifically, we present a novel reinforcement learning-based framework which learns the masking policy, such that using the generated masks for further pre-training of the target language model helps improve task performance on unseen texts. We use off-policy actor-critic with entropy regularization and experience replay for reinforcement learning, and propose a Transformer-based policy network that can consider the relative importance of words in a given text. We validate our Neural Mask Generator  on several question answering and text classification datasets using BERT and DistilBERT as the language models, on which it outperforms rule-based masking strategies, by automatically learning optimal adaptive maskings. \footnote{Code is available at \url{github.com/Nardien/NMG}.}",173
"   Sentiment analysis has become an increasingly popular natural language  processing  task in academia and industry.  It provides real-time  feedback on consumer experience and their needs, which helps  producers to offer better services.  To deal with the presence of  multiple categories in one document,  ACSA tasks, including aspect-category  sentiment analysis  and targeted aspect-category sentiment analysis , were introduced.   The main purpose for ACSA task  is to identify sentiment polarity  of an input sentence upon specific predefined categories . For  example, as shown in Table , giving an input sentence ``Food is  always fresh and hot-ready to eat, but it is too expensive."" and predefined categories \{food, service, price,  ambience and anecdotes/miscellaneous\},  the sentiment of category food is positive, the polarity  regarding to category price is negative, while is none for others.  In this task, the models should  capture both explicit expressions and implicit expressions. For example, the phrase ``too expensive"" indicates the  negative polarity  in the price category, without a direct indication of ``price"".    In order to  deal with ACSA with both multiple categories and multiple targets, TACSA task was introduced  to analyze sentiment polarity on a set of predefined target-category pairs. An example is shown in Table , given targets ``restaurant-1"" and ``restaurant-2"", in the case ``I like  restaurant-1 because it's cheap, but restaurant-2 is too  expansive"", the category price for target ``restaurant-1"" is positive, but is  negative for target ``restaurant-2"", while is none for other target-category pairs. A mathematical definition for ACSA is given  as follows: giving a  sentence  as input, a predefined set of targets  and a predefined set of  aspect categories , a model predicts the sentiment polarity  for  each target-category pair . For ACSA  task, there is only one target  in all  categories. In this paper, in order to simplify the expression in TACSA, we use predefined categories, which is short for predefined target-category pairs.   	} 	 \end{table*}  Multi-task learning, with shared encoders but individual decoders for each category, is an approach to analyze all the categories in one sample simultaneously for ACSA . Compared with single-task ways , multi-task approaches utilize category-specific knowledge in training signals from each task and get better performance. However, current multi-task models still suffer from a lack of  features such as category name . Models with category name features encoded in the model may further improve the performance.  On the other hand, the predefined categories in ACSA task make the application  in new categories inflexible, as for ACSA applications, the number of categories maybe  varied over time.  For example, fuel consumption, price level, engine power, space and so  on are source categories to be analyzed in the gasoline automotive domain. For  electromotive domain, source categories in the automotive domain will still be used, while new target category such as battery duration should also be analyzed.  Incremental learning is a way to solve this problem. Therefore, it is necessary to propose an  incremental learning task and an incremental learning model concerned with new  category for ACSA tasks.  Unfortunately, in the current multi-task learning ACSA models, the encoder is shared but the decoders for each category are individual. This parameter sharing mechanism results in only the shared encoder  and target-category-related decoders are finetuned during the finetuning process, while the decoder of source categories remains unchanged. The finetuned encoder and original decoder of source categories may cause catastrophic forgetting problem in the origin  categories. For real applications, high accuracy is excepted in source  categories and target  categories.  Based on the previous researches that decoders between different tasks are usually modeled by mean regularization   , an idea comes up to further make the decoders the same by sharing the decoders in all categories to decrease the catastrophic forgetting problem. But here raises another question, how to identify each category in the encoder and decoder shared network? In our approach, we  solve the category discrimination problem by the input category name feature.   In this paper,  we proposed a multi-task category name embedding network  .  The multi-task learning  framework makes full use of training signals from all categories. To make it feasible for incremental learning, both encoder and decoders for each category are shared. The category names were applied as another input feature for task discrimination. We also present a new task for ACSA incremental learning. In particular,  our contribution is three-folded:    We proposed a multi-task CNE-net framework with both encoder and decoder shared to weaken catastrophic forgetting problem in multi-task learning ACSA model.     We achieved  state-of-the-art on the two ACSA datasets, SemEval14-Task4  and Sentihood.   We proposed a new task for incremental learning in ACSA. By sharing both encoder layers and decoder layers of all the tasks, we   achieved better results compared with other baselines both in source  categories and in the target category.     We proposed a novel framework which automatically generates an adaptive masking for masked language models based on the given context, for language model adaptation to low-resource domains. To this end, we proposed the Neural Mask Generator , which is trained with reinforcement learning to mask out words that are helpful for domain adaptation. We performed an empirical study of various rule-based masking strategies on multiple datasets for question answering and text classification tasks, which shows that the optimal masking strategy depends on both the language model and the domain. We then validated NMG against rule-based masking strategies, and the results show that it either outperforms, or obtains comparable performance to the best heuristic. Further qualitative analysis suggests that such good performance comes from its ability to adaptively mask meaningful words for the given task.  
"," ACSA tasks, including aspect-category sentiment analysis  and  targeted  aspect-category sentiment analysis , aims at identifying sentiment  polarity on predefined categories. Incremental learning on new categories is necessary for ACSA real applications. Though current multi-task learning models achieve good performance in ACSA tasks, they suffer from catastrophic forgetting problems in ACSA incremental learning tasks. In this paper, to make multi-task learning feasible for incremental learning, we proposed Category Name  Embedding network  . We set both encoder and decoder shared among all categories to weaken the catastrophic forgetting problem. Besides the origin input sentence, we applied another input feature, i.e., category name, for task discrimination.  Our model achieved state-of-the-art  on two ACSA benchmark datasets. Furthermore, we proposed  a dataset for ACSA incremental learning and achieved the best performance compared with other strong baselines.",174
"   Conditional random fields  have been shown to perform well in various sequence labeling tasks. Recent work uses rich neural network architectures to define the ``unary'' potentials, i.e., terms that only consider a single position's label at a time~. However, ``binary'' potentials, which consider pairs of adjacent labels, are usually quite simple and may consist solely of a parameter or parameter vector for each unique label transition. Models with unary and binary potentials are generally referred to as ``first order'' models.   A major challenge with CRFs is the complexity of training and inference, which are quadratic in the number of output labels for first order models and grow exponentially when higher order dependencies are considered. This explains why the most common type of CRF used in practice is a first order model, also referred to as a ``linear chain'' CRF.   One promising alternative to CRFs is structured prediction energy networks , which use deep neural networks to parameterize arbitrary potential functions for structured prediction. While SPENs also pose challenges for learning and inference, \citet{tu-18} proposed a way to train SPENs jointly with ``inference networks'', neural networks trained to approximate structured  inference.   In this paper, we leverage the frameworks of SPENs and inference networks to explore high-order energy functions for sequence labeling. Naively instantiating high-order energy terms can lead to a very large number of parameters to learn, so we instead develop concise neural parameterizations for high-order terms. In particular, we draw from vectorized Kronecker products, convolutional networks, recurrent networks, and self-attention.  We also consider ``skip-chain'' connections~ with various skip distances and ways of reducing their total parameter count for increased learnability.   Our experimental results on four sequence labeling tasks show that a range of high-order energy functions can yield performance improvements. While the optimal energy function varies by task, we find strong performance from skip-chain terms with short skip distances, convolutional networks with filters that consider label trigrams, and recurrent networks and self-attention networks that consider large subsequences of labels.     We also demonstrate that modeling high-order dependencies can lead to significant performance improvements in the setting of noisy training and test sets.  Visualizations of the high-order energies show various methods capture intuitive structured dependencies among output labels.   Throughout, we use inference networks that share the same architecture as unstructured classifiers for sequence labeling, so test time inference speeds are unchanged between local models and our method.  Enlarging the inference network architecture by adding one layer leads consistently to better results, rivaling or improving over a BiLSTM-CRF baseline,  suggesting that training efficient inference networks with high-order energy terms can make up for errors arising from approximate inference. While we focus on sequence labeling in this paper, our results show the potential of developing high-order structured models for other NLP tasks in the future.      In this paper, in order to make multi-task learning feasible for incremental learning,  we proposed CNE-net with different attention mechanisms. The category  name features and the multi-task learning structure help the model  achieve state-of-the-art on ACSA and TACSA tasks. Furthermore,  the shared encoder and decoder layers weaken catastrophic forgetting in the incremental learning task.  We proposed a task for ACSA incremental learning and achieved the best  performance with CNE-net compared with other strong baselines.  Further research may be concerned with zero-shot learning on new categories.   
"," Many tasks in natural language processing involve predicting structured outputs, e.g., sequence labeling, semantic role labeling, parsing, and machine translation. Researchers are increasingly applying deep representation learning to these problems, but the structured component of these approaches is usually quite simplistic. In this work, we propose several high-order energy terms to capture complex dependencies among labels in sequence labeling, including several that consider the entire label sequence. We use neural parameterizations for these energy terms, drawing from convolutional, recurrent, and self-attention networks. We use the framework of learning energy-based inference networks for dealing with the difficulties of training and inference with such models. We empirically demonstrate that this approach achieves substantial improvement using a variety of high-order energy terms on four sequence labeling tasks, while having the same decoding speed as simple, local classifiers.  We also find high-order energies to help in noisy data conditions.\footnote{Code  is available at \url{https://github.com/tyliupku/Arbitrary-Order-Infnet}}",175
" Long document coreference resolution poses runtime and memory challenges. Current best models % for coreference resolution have large memory requirements and quadratic runtime in the document length~, making them impractical for long documents. %  Recent work revisiting the entity-mention paradigm~, which seeks to maintain explicit representations only of entities, rather than all their constituent mentions, has shown practical benefits for memory while being competitive with state-of-the-art models~. In particular, unlike other approaches to coreference resolution which maintain representations of both mentions and their corresponding entity clusters~ , the entity-mention paradigm stores representations only of the entity clusters, which are updated incrementally as coreference predictions are made. While such an approach requires less memory than those that additionally store mention representations, the number of entities can be impractically large when processing long documents, making the storing of all entity representations problematic.  Is it necessary to maintain an unbounded number of mentions or entities?  Psycholinguistic evidence suggests it is not, as human language processing is incremental  and has limited working memory~. In practice, we find that most entities have a small spread , and thus do not need to be kept persistently in memory. This observation suggests that tracking a limited, small number of entities at any time can resolve the computational %  issues, albeit at a potential accuracy tradeoff.  Previous work on bounded memory models for coreference resolution has shown potential, but has been tested only on short documents  % . % Moreover, this previous work makes token-level predictions while standard coreference datasets have span-level annotations.  % We propose a bounded memory model that performs quasi-online coreference resolution,      We explore arbitrary-order models with different neural parameterizations on sequence labeling tasks via energy-based inference networks. This approach achieve substantial improvement using high-order energy terms, especially in noisy data conditions, while having same decoding speed as simple local classifiers.     File emnlp2020.tex      Based on the style files for ACL 2020, which were    Based on the style files for ACL 2018, NAACL 2018/19, which were    Based on the style files for ACL-2015, with some improvements     taken from the NAACL-2016 style    Based on the style files for ACL-2014, which were, in turn,    based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,    EACL-2009, IJCNLP-2008...    Based on the style files for EACL 2006 by    e.agirre@ehu.es or Sergi.Balari@uab.es    and that of ACL 08 by Joakim Nivre and Noah Smith   \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{emnlp2020} \usepackage{times} \usepackage{latexsym} \renewcommand{\UrlFont}{\ttfamily\small}      This is not strictly necessary, and may be commented out,   but it will improve the layout of the manuscript,   and will typically save some space. \usepackage{microtype}  \usepackage{graphicx} \usepackage{xcolor}  \usepackage{color} \usepackage{multirow} \newcommand{\vect}[1]{\mbox{\boldmath }} \newcommand{\theHalgorithm}{\arabic{algorithm}} \DeclareMathOperator*{\LM}{TLM} \DeclareMathOperator*{\BLSTM}{BiLSTM} \DeclareMathOperator*{\g}{G} \DeclareMathOperator*{\d0}{D} \DeclareMathOperator*{\PT}{\#paras_T} \DeclareMathOperator*{\PI}{\#paras_I} \DeclareMathOperator*{\attention}{attention}  \usepackage{amssymb} \usepackage{graphicx} \usepackage{subcaption}  \usepackage{ctable}  \newcommand{\lmreg}{E^{\LM}}  \DeclareMathOperator*{\TLM}{TLM} \newcommand{\encseq}{\enc_{\mathrm{NN}}} \DeclareMathOperator*{\LSTM}{LSTM} \newcommand{\Expect}{{\rm I\kern-.3em E}}  \DeclareMathOperator*{\LayerNorm}{LayerNorm} \DeclareMathOperator*{\MLP}{MLP}   \DeclareMathOperator*{\product}{KP} \DeclareMathOperator*{\product}{VKP}   \newcommand{\x}{\boldsymbol{x}} \newcommand{\y}{\boldsymbol{y}} \newcommand{\xspace}{\mathcal{X}} \newcommand{\yspace}{\mathcal{Y}} \newcommand{\relyspace}{\mathcal{Y}_{R}} \newcommand{\cost}{\bigtriangleup} \newcommand{\infnet}{\mathbf{A}_{\Psi}} \newcommand{\canet}{\mathbf{F}_{\Phi}} \newcommand{\mlocal}{\mathit{loc}} \newcommand{\mlabel}{\mathit{lab}}  \newcommand{\R}{\mathbb{R}} \newcommand{\ltok}{\ell_{\mathrm{token}}} \newcommand{\pvect}{\mathbf{v}}   \newenvironment{itemizesquish}{}       This is not strictly necessary, and may be commented out,   but it will improve the layout of the manuscript,   and will typically save some space. \usepackage{microtype}  \hyphenation{Gimpel} \hyphenation{Unk-Test} \hyphenation{Unk-Train} \aclfinalcopy   Uncomment this line for the final submission  \def\aclpaperid{***}    Enter the acl Paper ID here   \setlength\titlebox{5cm}   You can expand the titlebox if you need extra space   to show all the authors. Please do not make the titlebox   smaller than 5cm ; we will check this   in the camera-ready version and ask you to change it back.  \newcommand\BibTeX{B\TeX}   \title{An Exploration of Arbitrary-Order Sequence Labeling\\ via Energy-Based Inference Networks}  \author{Lifu Tu \Thanks{ Equal contribution.} \ \ \ \ \ \   Tianyu Liu  \newcommand{\new}{\marginpar{NEW}}                     
"," Long document coreference resolution remains a challenging task	 due to the large memory and runtime requirements of current models. Recent work doing incremental coreference resolution using just the global representation of entities shows practical benefits but requires keeping all entities in memory, which can be impractical for long documents. % We argue that keeping all entities in memory is unnecessary, and we propose a memory-augmented neural network that tracks only a small bounded number of entities at a time, thus guaranteeing a linear runtime in length of document. We show that  the model remains competitive with models with high memory and computational requirements on OntoNotes and LitBank, and  the model learns an efficient memory management strategy easily outperforming a rule-based strategy.",176
" Since the early days of NLP, conversational agents have been designed to interact with humans through language to solve diverse tasks, e.g., remote instructions or booking assistants . In this goal-oriented dialogue setting, the conversational agents are often designed to compose with predefined language utterances. Even if such approaches are efficient, they also tend to narrow down the agent's language diversity.  To remove this restriction, recent work has been exploring interactive word-based training. In this setting, the agents are generally trained through a two-stage process: Firstly, the agent is pretrained on a human-labeled corpus through supervised learning to generate grammatically reasonable sentences. Secondly, the agent is finetuned to maximize the task-completion score by interacting with a user. Due to sample-complexity and reproducibility issues, the user is generally replaced by a game simulator that may evolve with the conversational agent. Unfortunately, this pairing may lead to the language drift phenomenon, where the conversational agents gradually co-adapt, and drift away from the pretrained natural language. The model thus becomes unfit to interact with humans.  While domain-specific methods exist to counter language drift, a simple task-agnostic method consists of combining interactive and supervised training losses on a pretraining corpus, which was later formalized as Supervised SelfPlay  .   Inspired by language evolution and cultural transmission, recent work proposes Seeded Iterated Learning  as another task-agnostic method to counter language drift. SIL modifies the training dynamics by iteratively refining a pretrained student agent by imitating interactive agents, as illustrated in Figure. At each iteration, a teacher agent is created by duplicating the student agent, which is then finetuned towards task completion. A new dataset is then generated by greedily sampling the teacher, and those samples are used to refine the student through supervised learning. The authors empirically show that this iterated learning procedure induces an inductive learning bias that successfully maintains the language grounding while improving task-completion.       \vskip -1em \end{figure*}  As a first contribution, we further examine the performance of these two methods in the setting of a translation game.  We show that S2P is unable to maintain a high grounding score and experiences a late-stage collapse, while SIL has a higher negative likelihood when evaluated on human corpus.  We propose to combine SIL with S2P by applying an S2P loss in the interactive stage of SIL. We show that the resulting Supervised Seeded Iterated Learning  algorithm manages to get the best of both algorithms in the translation game. Finally, we observe that the late-stage collapse of S2P is correlated with conflicting gradients before showing that \algo empirically reduces this gradient discrepancy.         We propose a memory model which tracks a small, bounded number of entities. The proposed model guarantees a linear runtime in document length, and in practice significantly reduces peak memory usage during training. Empirical results on LitBank and OntoNotes show that the model is competitive with an unbounded memory version and outperforms a strong rule-based baseline. In particular, we report state of the art results on LitBank. In future work we plan to apply our model to longer, book length documents, and plan to add more structure to the memory.   
"," Language drift has been one of the major obstacles to train language models through interaction. When word-based conversational agents are trained towards completing a task, they tend to invent their language rather than leveraging natural language. In recent literature, two general methods partially counter this phenomenon: Supervised Selfplay  and Seeded Iterated Learning .  While S2P jointly trains interactive and supervised losses to counter the drift, SIL changes the training dynamics to prevent language drift from occurring. In this paper, we first highlight their respective weaknesses, i.e., late-stage training collapses and higher negative likelihood when evaluated on human corpus. Given these observations, we introduce \longalgo~ to combine both methods to minimize their respective weaknesses.  We then show the effectiveness of \algo in the language-drift translation game.",177
"  Event argument extraction  aims to identify the entities that serve as arguments of an event and to classify the specific roles they play. As in Fig., ``two soldiers'' and ``yesterday'' are arguments, where the event triggers are ``attacked''   and ``injured'' . For the trigger ``attacked'', ``two soldiers'' plays the argument role Target while ``yesterday'' plays the argument role Attack\_Time. For the event trigger ``injured'', ``two soldiers'' and ``yesterday'' play the role Victim and INJURY\_Time, respectively. There has been significant work on event extraction  , but the EAE task remains a challenge and has become the bottleneck for improving the overall performance of EE.\footnote{EAE has similarities with semantic role labeling. Event triggers are comparable to predicates in SRL and the roles in most SRL datasets have a standard convention of interpreting who did what to whom. EAE has a custom taxonomy of roles by domain. We also use inspiration from the SRL body of work .}     Supervised data for EAE is expensive and hence scarce. One possible solution is to use other available resources like unlabeled data. For that,  We use  BERT as our model encoder which leverages a much larger unannotated corpus where semantic information is captured. Unlike%previous studies ~ who added a final/prediction layer to BERT for argument extraction, we use BERT as token embedder and build a sequence of EAE task-specific components .  We use  in-domain data to adapt the BERT model parameters in a subsequent pretraining step as in . This makes the encoder domain-aware.  We perform self-training to construct auto-labeled data .  A crucial aspect for EAE is to integrate event trigger information into the learned representations. This is important because arguments are dependent on triggers, i.e., the same argument span plays completely different roles toward different triggers. An example is shown in Fig., where ``two soldiers'' plays the role Target for the event ATTACK and the role Victim for INJURY. Different from existing work that relies on regular sequence encoders, we design a novel trigger-aware encoder which simultaneously learns four different types of trigger-informed sequence representations. %for candidate arguments.   Capturing the long-range dependency is another important factor, e.g., the connection between an event trigger and a distant argument. Syntactic information could be useful in this case, as it could help bridge the gap from a word to another distant but highly related word. We modify a Transformer  by explicitly incorporating syntax via an attention layer driven by the dependency parse of the sequence. % .  %Since arguments of an event are entities, entity mentions are very effective hints.  We design our role-specific argument decoder to seamlessly accommodate both settings . We also tackle the role overlap problem  using a set of classifiers or taggers in our decoder.   Our model achieves the new state-of-the-art on ACE2005 Events data.% for EAE.  % % Motivation 1: data scarcity. Proposed and used solutions:  pretrained model BERT  External embedding   Self-training   BERT MLM  MLM encoder and decoder joint pre-training.  Teacher-Student    %   We present the first systematic study of negative interference  in multilingual models and shed light on its causes. We further propose a method and show it can improve cross-lingual transferability  by mitigating negative interference.  While prior efforts focus on improving sharing and cross-lingual alignment,  we provide new insights and a different perspective  on unsharing and resolving language conflicts.   
"," Event argument extraction  aims to identify the arguments of an event and classify the roles that those arguments play. Despite great efforts made in prior work, there remain many challenges:  Data scarcity.  Capturing the long-range dependency, specifically, the connection between an event trigger and a distant event argument.  Integrating event trigger information into candidate argument representation. For , we explore using unlabeled data in different ways. For , we propose to use a syntax-attending Transformer that can utilize dependency parses to guide the attention mechanism. For , we propose a trigger-aware sequence encoder with several types of trigger-dependent sequence representations. We also support argument extraction either from text annotated with gold entities or from plain text. Experiments on the English ACE2005 benchmark show that our approach achieves a new state-of-the-art.",178
" In most current NLP tasks, fixed-length vector representations of words, word embeddings, are used to represent some form of the meaning of the word. In the case of humans, however, oftentimes we will use a sequence of words known as a definition ---a statement of the meaning for a term--- to express meanings of terms . It is with this in mind that the question of ``Can machines define?'' is aimed to be answered with the task of definition modeling .  Definition modeling can be framed as a task of conditional generation, in which the definition  of the word or phrase is generated given a conditioning variable  such as a word's associated word embedding or other representations of context. Current approaches for this task  are mainly encoder-decoder based, in which one encodes a contextual representation for a word/phrase  using a variety of features such as context or character composition, and uses the contextual representation to generate the definition .   % here discuss issues of these approaches including Despite the relative success of existing approaches for definition modelling, their discriminative nature ---where distributional-derived information is at one end of the model and lexical information is at the other--- limits their power as the underlying semantic representations of the distributional and lexical information are learned in an implicit rather than direct way. For example, although \citet{ishiwatari-etal-2019-learning} successfully showed that both local and global contexts are useful to disambiguate meanings of phrases in certain cases, their approach heavily relies on an attention mechanism to identify semantic alignments between the input phrase and the output definition, which may introduce noise and ultimately be insufficient to capture the entire meaning of each phrase-definition pair.  % latent definition space with  To tackle this issue, we propose to explicitly model the underlying semantics of  phrase-definition pairs by introducing a continuous latent variable  over a definition space, which is used in conjunction with  to guide the generation of definition . The introduction of this latent representation enables us to treat it as a global defining signal during the generation process, complementing existing alignment mechanisms such as the attention.   % We specifically incorporate the latent variable directly into the decoder cell, showing that the addition of the latent variable in this way leads to increased performance on our task.   Although the latent definition variable enables us to explicitly model underlying semantics of context-definition pairs, the incorporation of it into the task renders the posterior intractable. In this paper we recur to variational inference to estimate this intractable posterior, effectively making our model a Conditional Variational Autoencoder and evolving the generation process from  to .  %to serve as a global decoding signal allows for the decoder to rely on both the attention, but if the attention is misleading you can rely on the latent variable % and this issue of misleading attentions is exacerbated in noisy datasets, so we can see improvements there as well when the generator learns misleading attention representations.    % EDISON % enables us not only to generate definitions of previously unknown words or phrases, by menas of an example , but also to obtain semantically meaningful vectors of new words by means of providing their definition alongside with an example of their usage. Effectively, our mode is able to mapping both inputs  to the same smooth space/manifold?.  We also note that existing approaches for definition modelling heavily rely on word embeddings, which due to their fixed nature can only capture so much of the semantics, being known to offer limited capabilities when dealing with polysemy. Considering the success of pretrained deep contextualized word representations which by specifically addressing these limitations have been shown to improve performance on a variety of downstream NLP tasks , in this paper we propose a mechanism to integrate deep contextualized word representations in the definition modelling task. Specifically, we successfully leverage BERT  as our contextual encoder and our definition encoder to produce representations for  and  respectively.   %While the inclusion of deep contextual word representations is important to our approach, our resuts show that it is not essential . %As a result, our model is able to  allowing for  a more meaningful continuous latent space, and  . [2-3 more sentences]  Finally, we develop two new datasets for this task, one derived from the Cambridge Dictionary , and the other derived from Le Petit Robert. In summary, our contributions are:  Datasets and pre-trained models will be publicly released to the greater NLP community to help facilitate further advances on this task upon acceptance of this paper.   We present a new model which provides the best results in the EAE task. The model can generate trigger-aware argument representations, incorporate syntactic information , and handle the role overlapping problem with role-specific argument decoder. We also experiment with some methods to address the data scarcity issue. Experimental results show the effectiveness of our proposed approaches.    Experimental results demonstrate the effectiveness of our approach.   We also addressd the learning gap/discrepancy between pre-trained and newly-trained components.  
","     %Definition modeling, the task of generating word/phrase definitions, is the task that aims to answer ``Can machines define?'' In this paper, we aim to tackle this problem by introducing a continuous latent variable to explicitly model the underlying relationship between a phrase used within a context and its definition. Additionally, we release 2 new datasets, Cambridge and the first non-English dataset Robert. On most datasets, our Variational Contextual Definition Modeler  achieves a new state-of-the-art, outperforming existing systems as well as a new BERT-based baseline. In this paper we tackle the task of definition modeling, where the goal is to learn to generate definitions of words and phrases. Existing approaches for this task are discriminative, combining distributional and lexical semantics in an implicit rather than direct way. To tackle this issue we propose a generative model for the task, introducing a continuous latent variable to explicitly model the underlying relationship between a phrase used within a context and its definition. We rely on variational inference for estimation and leverage contextualized word embeddings for improved performance. Our approach is evaluated on four existing challenging benchmarks with the addition of two new datasets, Cambridge and the first non-English corpus Robert, which we release to complement our empirical study. Our Variational Contextual Definition Modeler  achieves state-of-the-art performance in terms of automatic and human evaluation metrics, demonstrating the effectiveness of our approach.\footnote{We release the code at: \url{https://github.com/machelreid/vcdm}}",179
"  Topic segmentation is a fundamental NLP task that has received considerable attention in recent years .  It can reveal important aspects of a document semantic structure by splitting the document into topical-coherent textual units. Taking the Wikipedia article in Table as an example, without the section marks, a reliable topic segmenter should be able to detect the correct boundaries within the text and chunk this article into the topical-coherent units ,  and . The results of topic segmentation can further benefit other key downstream NLP tasks such as document summarization , question answering , machine reading  and dialogue modeling .   }  A Wikipedia sample article about City Marcus covering three topics: ,  and } \end{table}  A wide variety of techniques have been proposed for topic segmentation. Early unsupervised models exploit word statistic overlaps , Bayesian contexts  or   %the  semantic relatedness graphs  to measure the lexical or semantic cohesion between the sentences or paragraphs and infer the segment boundaries from them. More recently, several works have framed topic segmentation as neural supervised learning, because of the remarkable success achieved by such models in most NLP tasks .  %While one line of research forms topic segmentation as a sequence labeling problem and builds neural models to predict segment boundaries directly ;  %another line of works first trains neural models for other tasks , and then uses these models' outputs to predict boundaries .  Despite %the  minor architectural differences, most of these neural solutions adopt Recurrent Neural Network  and its variants  as their main framework.  On the one hand, RNNs are appropriate because topic segmentation can be modelled as a sequence labeling task where each sentence is either the end of a segment or not. On the other hand, this choice makes these neural models limited in how to model the context. Because some sophisticated RNNs  are able to preserve long-distance information , which can largely help language models. But for topic segmentation, it is critical to supervise the model to focus more on the local context.    %In fact, RNNs are superior on many NLP tasks due to their capability of preserving long-distance information . %However, for topic segmentation, it is also critical to supervise the model to learn the right information from the local context.   As illustrated in Table, the prediction of the segment boundary between  and  hardly depends on the content in . Bringing in excessive long-distance signals may cause unnecessary noise and %further  hurt %model's  performance. Moreover, text coherence has strong relation with topic segmentation .  For instance, in Table, sentence pairs from the same segment  %should be  are more coherent %to put together than sentence pairs across segments .  Arguably, with a proper way of modeling the coherence between adjacent sentences, a topic segmenter can be further enhanced.   %\textcolor{red}{We hypothesize that topic segment prediction should rely on local contextual information in a way that cannot be effectively captured by RNNs.} %\textcolor{red}{In essence, RNNs are able to model long and short-distance dependencies only implicitly.}  %However, with restricted self-attention, our model can pay attention to the local context from the neighboring sentences in a more explicitly constrained way . %In essence, local contextual information is critical in predicting topical boundaries, but simple Recurrent Neural Network  and its variants are arguably not sufficiently powerful to represent the necessary information.  %However, both approaches still face the challenge of insufficient context modeling. Topic segment boundary prediction usually heavily relies on local contextual information. Hence, how to effectively select local contexts and model the relations between contexts becomes important. Neural models like RNN and its variants can represent the state of each timestep by memorizing or forgetting the information from its previous and later contexts. But how these learned contextual information contribute to model's decision is not straightforward and sufficiently transparent.  In this paper, we propose to enhance a state-of-the-art  topic segmenter  based on hierarchical attention BiLSTM network to better model the local context of a sentence in two complementary ways. First, we add a coherence-related auxiliary task to make our model learn more informative hidden states for all the sentences in a document.  %More specifically, we refine the objective of our model to encourage that the coherence of the sentences from different segments is smaller than the coherence of the sentences from the same segment.  More specifically, we refine the objective of our model to encourage smaller coherence for the sentences from different segments and larger coherence for the sentences from the same segment.  Secondly, we enhance context modeling by utilizing restricted self-attention , which enables our model to pay attention to the local context and make better use of the information from the closer neighbors of each sentence .  Our empirical results show  that our proposed context modeling strategy significantly improves the performance of the SOTA neural segmenter on three datasets,  that the enhanced segmenter is more robust in domain transfer setting when applied to four challenging real-world test sets, sampled differently from the training data,  that our context modeling strategy is also effective for the segmenters trained on other challenging languages , rather than just English.     In this paper we have introduced a generative model that directly combines distributional and lexical semantics via a continuous latent variable for the task of definition modeling. Empirical results on multiple corpora, including two new datasets released, show that our model is able to outperform previous work by a consistent margin, also successfully being able to leveraging contextualized word representations. For future work we are interested in exploring how definition modeling could be adapted to a multilingual or cross-lingual setting.     where the goal is to learn to generate definitions of words and phrases. Existing approaches for this task are discriminative, To tackle this issue we propose a generative model for the task, introducing a continuous latent variable to explicitly model the underlying relationship between a phrase used within a context and its definition. We rely on variational inference for estimation and leverage contextualized word embeddings for improved performance. Our approach is evaluated on four existing challenging benchmarks with the addition of two new datasets,  and the first non-English corpus , which we release to complement our empirical study. Our Variational Contextual Definition Modeler  achieves state-of-the-art performance in terms automatic and human evaluation metrics, demonstrating the effectiveness of our approach.     Conclude something here.  
","      Topic segmentation is critical %, the process of splitting a document into topic-coherent pieces,      %plays a vital role      in key NLP tasks and recent works favor highly effective neural supervised  approaches.     %Due to the high effectiveness of neural models, more recent works have favored framing topic segmentation as a neural-based supervised learning problem.     However, current neural solutions are arguably limited in how they model context.     %topic segmenters proposed so far are still limited by the insufficient context modeling.      In this paper, we enhance a segmenter based on a hierarchical attention BiLSTM network to better model context, by adding a coherence-related auxiliary task and restricted self-attention. Our optimized segmenter\footnote{Our code will be publicly available at \url{www.cs.ubc.ca/cs-research/lci/research-groups/natural-language-processing/}} outperforms SOTA approaches when trained and tested on three datasets. We also the robustness of our proposed model in domain transfer setting by training a model on a large-scale dataset and testing it on four challenging real-world benchmarks. Furthermore, we apply our proposed strategy to two other languages , and show its effectiveness in multilingual scenarios.",180
" Natural Language Understanding  evaluation plays a key role in benchmarking progress in natural language processing  research. With the recent advance in language representative learning, results on previous benchmarks have rapidly saturated. This leads to an explosion of difficult, diverse proposals of tasks/datasets for NLU evaluation, including Natural Language Inference , Grounded Commonsense Inference, Commonsense QA, Social Interactions Reasoning, Abductive Commonsense Reasoning , etc.   One common practice followed by most of these recent works is to simplify the evaluation of various reasoning abilities as a classification task. This is analogous to asking objective questions to a human in educational testing. This simplification not only facilitates the data annotation but also gives interpretable evaluation results, based on which behaviors of the models are studied and then weaknesses are diagnosed.   Despite the straightforwardness of this formalization, one assumption behind most prior benchmark data sourcing is that there exists a single prescriptive ground truth label for each example. The assumption might be true in human educational settings where prescriptivism is preferred over descriptivism because the goal is to test humans with well-defined knowledge or norms. However, it is not true for many NLP tasks due to their pragmatic nature where the meaning of the same sentence might differ depending on the context or background knowledge.   Specifically for the NLI task, \citet{manning2006local} advocate that annotation tasks should be ``natural'' for untrained annotators, and the role of NLP should be to model the inferences that humans make in practical settings. Previous work that uses a graded labeling schema on NLI, showed that there are inherent disagreements in inference tasks. All these discussions challenge the commonly used majority ``gold-label'' practice in most prior data collections and evaluations.  Intuitively, such disagreements among humans should be allowed because different annotators might have different subjective views of the world and might think differently when they encounter the same reasoning task. Thus, from a descriptive perspective, evaluating the capacity of NLP models in predicting not only individual human opinions or the majority human opinion, but also the overall distribution over human judgments provides a more representative comparison between model capabilities and `collective' human intelligence.  Therefore, we collect ChaosNLI, a large set of Collective HumAn OpinionS for examples in several existing  NLI datasets, and comprehensively examine the factor of human agreement  on the state-of-the-art model performances. Specifically, our contributions are:  The ChaosNLI dataset and experimental scripts are available at \url{https://github.com/easonnie/ChaosNLI}       This work aims to establish a better way to represent the language modality in text-based ZSL for image classification. Our approach only relies on semantic information about visual features, and not on the visual features themselves. Specifically, our two orthogonal text-processing methods, employing textual similarity and visually-relevant summaries, lead to significant improvements across models, splits, and datasets, and illustrate that adequate text-processing is essential in text-based ZSL tasks.  We   conjecture that text-processing methods will be essential in a range of vision and language-based tasks, and hope this work will assist future research in better representing the language modality in various multi-modal tasks.    First, unsupervised clustering algorithms are used to construct textual similarity vectors between seen and unseen image-text pairs.   Second, visually relevant summaries  from texts. Each sentence from the image description is assigned a VRS-score, which determines the sentence's level of groundedness in images.   
"," Despite the subjective nature of many NLP tasks, most NLU evaluations have focused on using the majority label with presumably high agreement as the ground truth. Less attention has been paid to the distribution of human opinions. We collect ChaosNLI, a dataset with a total of 464,500 annotations to study Collective HumAn OpinionS in oft-used NLI evaluation sets. This dataset is created by collecting 100 annotations per example for 3,113 examples in SNLI and MNLI and 1,532 examples in \abdnli. Analysis reveals that:  high human disagreement exists in a noticeable amount of examples in these datasets;  the state-of-the-art models lack the ability to recover the distribution over human labels;   models achieve near-perfect accuracy on the subset of data with a high level of human agreement, whereas they can barely beat a random guess on the data with low levels of human agreement, which compose most of the common errors made by state-of-the-art models on the evaluation sets. This questions the validity of improving model performance on old metrics for the low-agreement part of evaluation datasets. Hence, we argue for a detailed examination of human agreement in future data collection efforts, and evaluating model outputs against the distribution over collective human opinions.\footnote{The ChaosNLI dataset and experimental scripts are available at \url{https://github.com/easonnie/ChaosNLI}}",181
" Understanding and reasoning over natural language plays a significant role in artificial intelligence tasks such as Machine Reading Comprehension  and Question Answering . Several QA tasks have been proposed in recent years to evaluate the language understanding capabilities of machines . These tasks are single-hop QA tasks and consider answering a question given only one single paragraph. % The drawback of single-hop QA tasks is the lack of evaluating deep reasoning capability.  % We observe that many existing neural models achieve promising performance without reasoning.  Many existing neural models rely on learning context and type-matching heuristics. Those rarely build reasoning modules but achieve promising performance on single-hop QA tasks. The main reason is that these single-hop QA tasks are lacking a realistic evaluation of reasoning capabilities because they do not require complex reasoning.   Recently multi-hop QA tasks, such as HotpotQA  and WikiHop, have been proposed to assess multi-hop reasoning ability. HotpotQA task provides annotations to evaluate document level question answering and finding supporting facts. Providing supervision for supporting facts improves explainabilty of the predicted answer because they clarify the cross paragraph reasoning path.   Due to the requirement of multi-hop reasoning over multiple documents with strong distraction, multi-hop QA tasks are challenging.  Figure shows an example of HotpotQA. Given a question and 10 paragraphs, only paragraph  and paragraph  are relevant. The second sentence in paragraph  and the first sentence in paragraph  are the supporting facts. The answer is ``Geelong Football Club''.   Primary studies in HotpotQA task prefer to use a reading comprehension neural model. First, they use a neural retriever model to find the relevant paragraphs to the question. After that, a neural reader model is applied to the selected paragraphs for answer prediction. Although these approaches obtain promising results, the performance of evaluating multi-hop reasoning capability is unsatisfactory.   To solve the multi-hop reasoning problem, some models tried to construct an entity graph using Spacy or Stanford CoreNLP and then applied a graph model to infer the entity path from question to the answer. However, these models ignore the importance of the semantic structure of the sentences and the edge information and entity types in the entity graph. To take the in-depth semantic roles and semantic edges between words into account here we use semantic role labeling  graph as the backbone of a graph convolutional network. Semantic role labeling provides the semantic structure of the sentence in terms of argument-predicate relationships.  % such as ``who did what to whom.'' The argument-predicate relationship graph can significantly improve the multi-hop reasoning results. Our experiments show that SRL is effective in finding the cross paragraph reasoning path and answering the question.  Our proposed semantic role labeling graph reasoning network  jointly learns to find cross paragraph reasoning paths and answers questions on multi-hop QA. In SRLGRN model, firstly, we train a paragraph selection module to retrieve gold documents and minimize distractor. Second, we build a heterogeneous document-level graph that contains sentences as nodes ,  % and the sentence nodes include  and SRL sub-graphs including semantic role labeling arguments as nodes and predicates as edges. Third, we train a graph encoder to obtain the graph node representations that incorporate the argument types and the semantics of the predicate edges in the learned representations. Finally, we jointly train a multi-hop supporting fact prediction module that finds the cross paragraph reasoning path, and answer prediction module that obtains the final answer. Notice that both supporting fact prediction and answer prediction are based on contextual semantics graph representations as well as token-level BERT pre-trained representations. The contributions of this work are as follows:   {\bf 1)} We propose the SRLGRN framework that considers the semantic structure of the sentences in building a reasoning graph network. Not only the semantics roles of nodes but also the semantics of edges are exploited in the model.  {\bf 2)} We evaluate and analyse the reasoning capabilities of the semantic role labeling graph compared to usual entity graphs. %We analyze the multi-hop reasoning capacity on HotpotQA task.  The fine-grained semantics of SRL graph help in both finding the answer and the explainability of the reasoning path.  {\bf 3)} Our proposed model obtains competitive results on both HotpotQA  and the SQuAD benchmarks.    In this paper, we presented our approach on detecting and categorizing offensive language in social media. We proposed a multi-lingual learning method to detect offensive language and a knowledge distillation method to categorize offensive language. We will further our exploration of multilingual offensive language identification in future, e.g. validating the zero-shot performance of our model in more languages.       include your own bib file like this: 
"," This work deals with the challenge of learning and reasoning over multi-hop question answering . We propose a graph reasoning network based on the semantic structure of the sentences to learn cross paragraph reasoning paths and find the supporting facts and the answer jointly. The proposed graph is a heterogeneous document-level graph that contains nodes of type sentence , and semantic role labeling sub-graphs per sentence that contain arguments as nodes and predicates as edges. Incorporating the argument types, the argument phrases, and the semantics of the edges originated from SRL predicates into the graph encoder helps in finding and also the explainability of the reasoning paths. Our proposed approach shows competitive performance on the HotpotQA distractor setting benchmark compared to the recent state-of-the-art models.",182
"   The organizers of the 2020 VarDial Evaluation Campaign  proposed a shared task targeted towards the geolocation of short texts, e.g.~tweets, namely the Social Media Variety Geolocation  task. Typically formulated as a double regression problem, the task is about predicting the location, expressed in latitude and longitude, from where the text received as input was posted on a certain social media platform. Twitter and Jodel are the platforms used for data collection, divided by the language area in three subtasks, namely:   In this paper, we focus only on the second subtask, SMG-CH, proposing a variety of handcrafted and deep learning models, as well as an ensemble model that combines all our previous models through meta-learning. Our first model is a Support Vector Regression  classifier  based on string kernels, which are known to perform well in other dialect identification tasks . Our second model is a character-level convolutional neural network  , which is also known to provide good results in dialect identification . Due to the high popularity and the outstanding results of Bidirectional Encoder Representations from Transformers   in solving mainstream NLP tasks, we decided to try out a Long Short-Term Memory  network  based on German BERT embeddings as our third model. Lastly, we combine our three models into an ensemble that employs Extreme Gradient Boosting   as meta-learner. We conducted experiments on the development set provided by the organizers, in order to decide which models to choose for our three submissions for the SMG-CH subtask. Our results indicate that the ensemble model attains the best results. Perhaps surprisingly, our shallow approach based on string kernels outperforms both deep learning models. Our observations are consistent across the development and the test sets provided by the organizers.  % We experimented with a few Machine Learning algorithms for the second subtask, namely CH,  % Geolocation can be framed as a double regression task, but more sophisticated model architectures have been proposed .  % Jodel is a mobile chat application that lets people anonymously talk to other users within a 10km-radius around them.   % All three subtasks will use the same data format and evaluation methodology, and participants are encouraged to submit their systems for all subtasks.  The rest of this paper is organized as follows. We present related work on dialect identification and geolocation of short texts in Section. Our approaches are described in more detail in Section. We present the experiments and empirical results in Section. Finally, our conclusions are drawn in Section.    We proposed a novel semantic role labeling graph reasoning network  to deal with multi-hop QA.    The model jointly trains to detect the supporting facts and to find the final answer. The backbone graph of our proposed graph convolutional network  is created based on the semantic structure of the sentences. In creating the  edges and nodes of the graph, we exploit a semantic role labeling sub-graph for each sentence and connect the candidate supporting facts. The cross paragraph argument-predicate structure of the sentences expressed in the graph provides an explicit representation of the reasoning path and helps in both finding and explaining the multiple hops of reasoning that lead to the final answer.   We analyze the multi-hop reasoning ability of our model.  SRLGRN exceeds most of the SOTA results on the HotpotQA benchmark. Moreover, we evaluate the model  on other reading comprehension benchmarks. Our approach achieves competitive performance on SQuAD v and v.  
"," In this work, we introduce the methods proposed by the UnibucKernel team in solving the Social Media Variety Geolocation task featured in the 2020 VarDial Evaluation Campaign. We address only the second subtask, which targets a data set composed of nearly 30 thousand Swiss German Jodels. The dialect identification task is about accurately predicting the latitude and longitude of test samples. We frame the task as a double regression problem, employing a variety of machine learning approaches to predict both latitude and longitude. From simple models for regression, such as Support Vector Regression, to deep neural networks, such as Long Short-Term Memory networks and character-level convolutional neural networks, and, finally, to ensemble models based on meta-learners, such as XGBoost, our interest is focused on approaching the problem from a few different perspectives, in an attempt to minimize the prediction error. With the same goal in mind, we also considered many types of features, from high-level features, such as BERT embeddings, to low-level features, such as characters n-grams, which are known to provide good results in dialect identification. Our empirical results indicate that the handcrafted model based on string kernels outperforms the deep learning approaches. Nevertheless, our best performance is given by the ensemble model that combines both handcrafted and deep learning models.",183
"  Comparing and contrasting the meaning of text conveyed in different languages is a fundamental nlp task. It can be used to curate clean parallel corpora for downstream tasks such as machine translation~, cross-lingual transfer learning, or semantic modeling~, and it is also useful to directly analyze multilingual corpora. For instance, detecting the commonalities and divergences between sentences drawn from English and French Wikipedia articles about the same topic would help analyze language bias~, or mitigate differences in coverage and usage across languages~. This requires not only detecting coarse content mismatches, but also fine-grained differences in sentences that overlap in content.  Consider the following English and French sentences, sampled from the WikiMatrix parallel corpus. While they share important content, highlighted words convey meaning missing from the other language:     We show that explicitly considering diverse types of semantic divergences in bilingual text benefits both the annotation and prediction of cross-lingual semantic divergences. We create and release the Rationalized English-French Semantic Divergences corpus , based on a novel divergence annotation protocol that exploits rationales to improve annotator agreement. We introduce \modelname, a  bert-based model that detects fine-grained semantic divergences without supervision by learning to rank synthetic divergences of varying granularity. Experiments on \dataset show that our model distinguishes semantically equivalent from divergent examples much better than a strong sentence similarity baseline and that unsupervised token-level divergence tagging offers promise to refine distinctions among divergent instances. We make our code and data publicly available.\footnote{Implementations of \modelname can be found at: \url{https://github.com/Elbria/xling-SemDiv}; the \dataset dataset is hosted at:   \url{https://github.com/Elbria/xling-SemDiv/tree/master/REFreSD}.}           In the current work, we tackled the SMG-CH shared subtask of the 2020 VarDial Evaluation Campaign. We addressed this challenge from a shallow perspective, with handcrafted models such as a -SVR based on string kernels, as well as from a deep learning perspective, with neural models such as an LSTM based on BERT embeddings and a character-level CNN, respectively. Additionally, we combined the proposed models into an ensemble, employing the XGBoost meta-learner. We obtained our best results with the XGBoost ensemble, which benefits from complementary information from the handcrafted and deep models. We therefore brought one more proof regarding the effectiveness of ensemble learning in general, and of XGBoost, in particular. Another important conclusion is that our shallow model based on string kernels outperforms the two deep neural networks. We consider this as yet another indicator of the high discriminative power that string kernels can bring to a fairly standard learning model, i.e.~the -SVR.   In future work, we aim to explore ways to improve our performance with respect to the metrics proposed by the shared task organizers. Currently, it seems that training the models to simply minimize the MSE or the MAE values is not effective, as our best model was significantly outperformed by the model proposed by the shared task organizers themselves.  
","  Detecting fine-grained differences in content conveyed in different languages matters for cross-lingual nlp and multilingual corpora analysis, but it is a challenging machine learning problem since annotation is expensive and hard to scale.~This work improves the prediction and annotation of fine-grained semantic divergences.~We introduce a training strategy for multilingual bert models by learning to rank synthetic divergent examples of varying granularity.~We evaluate our models on the~Rationalized~English-French~Semantic~Divergences, a new dataset released with this work, consisting of English-French sentence-pairs annotated with semantic divergence classes and token-level rationales.~Learning to rank helps detect fine-grained sentence-level divergences more accurately than a strong sentence-level similarity model, while token-level predictions have the potential of further distinguishing between coarse and fine-grained divergences.",184
"    A renewed emphasis must be placed on sentence fusion in the context of neural abstractive summarization. A majority of the systems are trained end-to-end, where an abstractive summarizer is rewarded for generating summaries that contain the same words as human abstracts, measured by automatic metrics such as ROUGE. A summarizer, however, is not rewarded for correctly fusing sentences. In fact, when examined more closely, only few sentences in system abstracts are generated by fusion. For instance, 6\% of summary sentences generated by Pointer-Gen are through fusion, whereas human abstracts contain 32\% fusion sentences. Moreover, sentences generated by fusion are prone to errors. They can be ungrammatical, nonsensical, or otherwise ill-formed. There is thus an urgent need to develop neural abstractive summarizers to fuse sentences properly.       The importance of sentence fusion has long been recognized by the community before the era of neural text summarization. The pioneering work of Barzilay et al.~\shortcite{barzilay-etal-1999-information} introduces an information fusion algorithm that combines similar elements across related text to generate a succinct summary. Later work, such as, builds a dependency or word graph by combining syntactic trees of similar sentences, then employs integer linear programming to decode a summary sentence from the graph.  Most of these studies have assumed a set of similar sentences as input, where fusion is necessary to reduce repetition. Nonetheless, humans do not limit themselves to combine similar sentences. In this paper, we pay particular attention to fuse disparate sentences that contain fundamentally different content but remain related to make fusion sensible. In Figure, we provide an example of a sentence fusion instance.   We address the challenge of fusing disparate sentences by enhancing the Transformer architecture with points of correspondence between sentences, which are devices that tie two sentences together into a coherent text. The task of sentence fusion involves choosing content from each sentence and weaving the content pieces together into an output sentence that is linguistically plausible and semantically truthful to the original input. It is distinct from~\citet{geva-etal-2019-discofuse} that connect two sentences with discourse markers. Our contributions are as follows.          We present a cascade approach to neural abstractive summarization that separates content selection from surface realization. Importantly, our approach makes use of text highlights as intermediate representation; they are derived from one or two sentences using a coarse-to-fine content selection strategy, then passed to a neural text generator to compose a summary sentence. A successful cascade approach is expected to accurately select sentences and highlight an appropriate amount of text, both can be customized for domain-specific tasks.   
","  The ability to fuse sentences is highly attractive for summarization systems because it is an essential step to produce succinct abstracts. However, to date, summarizers can fail on fusing sentences. They tend to produce few summary sentences by fusion or generate incorrect fusions that lead the summary to fail to retain the original meaning.  In this paper, we explore the ability of Transformers to fuse sentences and propose novel algorithms to enhance their ability to perform sentence fusion by leveraging the knowledge of points of correspondence between sentences. Through extensive experiments, we investigate the effects of different design choices on Transformer's performance. Our findings highlight the importance of modeling points of correspondence between sentences for effective sentence fusion.",185
"   The recent advances in neural machine translation   have provided the research community and the commercial landscape with effective translation models that can at times achieve near-human performance. However, this usually holds at phrase or sentence level. When using these models in larger units of text, such as paragraphs or documents, the quality of the translation may drop considerably in terms of discourse attributes such as lexical and stylistic consistency.  In fact, document-level translation is still a very open and challenging problem. The sentences that make up a document are not unrelated pieces of text that can be predicted independently; rather, a set of sequences linked together by complex underlying linguistics aspects, also known as the discourse . The discourse of a document includes several properties such as grammatical cohesion , lexical cohesion , document coherence  and the use of discourse connectives . Ensuring that the translation retain such linguistic properties is expected to significantly improve its overall readability and flow.  However, due to the limitations of current decoder technology, NMT models are still bound to translate at sentence level. In order to capture the discourse properties of the source document in the translation, researchers have attempted to incorporate more contextual information from surrounding sentences. Most document-level NMT approaches augment the model with multiple encoders, extra attention layers and memory caches to encode the surrounding sentences, and leave the model to implicitly learn the discourse attributes by simply minimizing a conventional NLL objective. The hope is that the model will spontaneously identify and retain the discourse patterns within the source document. Conversely, very little work has attempted to model the discourse attributes explicitly. Even the evaluation metrics typically used in translation such as BLEU  are not designed to assess the discourse quality of the translated documents.  For these reasons, in this paper we propose training an NMT model by directly targeting two specific discourse metrics: lexical cohesion  and coherence . LC is a measure of the frequency of semantically-similar words co-occurring in a document  . For example, car, vehicle, engine or wheels are all semantically-related terms. There is significant empirical evidence that ensuring lexical cohesion in a text eases its understanding . At its turn, COH measures how well adjacent sentences in a text are linked to each other. In the following example from Hobbs \shortcite{hobbs1979coherence}:       the two sentences make little `sense' one after another. An incoherent text, even if grammatically and syntactically perfect, is anecdotally very difficult to understand and therefore coherence should be actively pursued. Relevant to translation, Vasconcellos \shortcite{vasconcellos1989cohesion} has found that a high percentage of the human post-editing changes over machine-generated translations involves the improvement of cohesion and coherence.  Several LC and COH metrics that well correlate with the human judgement have been proposed in the literature. However, like BLEU and most other evaluation metrics, they are discrete, non-differentiable functions of the model's parameters. Hereafter, we propose to overcome this limitation by using the well-established policy gradient approach from reinforcement learning  which allows using any evaluation metric as a reward without having to differentiate it. By combining different types of rewards, the model can be trained to simultaneously achieve more lexically-cohesive and more coherent document translations, while at the same time retaining faithfulness to the reference translation. %the information contained in the source document.  %The rest of the paper is organized as follows. Section  discusses related work. Section  describes the baseline NMT architectures used for the experiments. Section  presents the proposed training approach and the discourse rewards used with it. Section  presents the experiments and, finally, Section  concludes the paper.       We address the challenge of information fusion in the context of neural abstractive summarization by making crucial use of points of correspondence between sentences. We enrich Transformers with PoC information and report model performance on a new test bed for information fusion. Our findings suggest that modeling points of correspondence is crucial for effective sentence fusion, and sentence fusion remains a challenging direction of research. Future work may explore the use of points of correspondence and sentence fusion in the standard setting of document summarization. Performing sentence fusion accurately and succinctly is especially important for summarizing long documents and book chapters. These domains may contain more entities and events to potentially confuse a summarizer, making our method of explicitly marking these entities beneficial.   
","   Document-level machine translation focuses on the translation of entire documents from a source to a target language. It is widely regarded as a challenging task since the translation of the individual sentences in the document needs to retain aspects of the discourse at document level. However, document-level translation models are usually not trained to explicitly ensure discourse quality. Therefore, in this paper we propose a training approach that explicitly optimizes two established discourse metrics, lexical cohesion  and coherence , by using a reinforcement learning objective. Experiments over four different language pairs and three translation domains have shown that our training approach has been able to achieve more cohesive and coherent document translations than other competitive approaches, yet without compromising the faithfulness to the reference translation. In the case of the Zh-En language pair, our method has achieved an improvement of $2.46$ percentage points  in LC and $1.17$ pp in COH over the runner-up, while at the same time improving $0.63$ pp in BLEU score and $0.47$ pp in $\mathrm{F}_{\mathrm{BERT}}$.      %In fact, in some cases our training approach has even improved translation accuracy metrics such as BLEU and the recently proposed $F_{\text{BERT}}$.",186
" In recent years, neural models have led to state-of-the-art results in machine translation  . Many of these systems can broadly be characterized as following a multi-layer encoder-decoder neural network design: both the encoder and decoder learn representations of word sequences by a stack of layers , building on an interesting line of work in improving such models. The simplest of these increases the model capacity by widening the network, whereas more recent work shows benefits from stacking more layers on the encoder side. For example, for the popular Transformer model , deep systems have shown promising BLEU improvements by either easing the information flow through the network  or constraining the gradient norm across layers . An improved system can even learn a 35-layer encoder, which is  deeper than that of vanilla Transformer .  Although these methods have enabled training deep neural MT  models, questions remain as to the nature of the problem. The main question here is: why and how deep networks help in NMT. Note that previous work evaluates these systems in a black-box manner . It is thus natural to study how much a deep NMT system is able to learn that is different from the shallow counterpart. Beyond this, training an extremely deep model is expensive although a narrow-and-deep network can speed up training . For example, it takes us  longer time to train the model when we deepen the network from 6 layers to 48 layers. This might prevent us from exploiting deeper models in large-scale systems.  In this paper, we explore why deep architectures work to render learning NMT models more effectively. By investigating the change of the hidden states in different layers, we find that new representations are learned by continually stacking layers on top of the base model. More stacked layers lead to a stronger model of representing the sentence. This particularly makes sense in the deep NMT scenario because it has been proven that deep models can benefit from an enriched representation .  In addition, the finding here inspires us to develop a simple yet efficient method to train a deep NMT encoder: we train model parameters from shallow to deep, rather than training the entire model from scratch. To stabilize training, we design a sparse linear combination method of connecting lower-level layers to the top. It makes efficient pass of information through the deep network but does not require large memory footprint as in dense networks. We experiment with the method in a state-of-the-art deep Transformer system. Our encoder consists of 48-54 layers, which is almost the deepest Transformer model used in NMT. On WMT En-De and En-Fr tasks, it yields a  speedup of training, matching the state-of-the-art on the WMT'16 En-De task.      In this paper, we have presented a novel training method for document-level NMT models that uses discourse rewards to encourage the models to generate more lexically cohesive and coherent translations at document level. As training objective we have used a reinforcement learning-style function, named Risk, that permits using discrete, non-differentiable terms in the objective. Our results on four different language pairs and three translation domains have shown that our models have achieved a consistent improvement in discourse metrics such as LC and COH, while retaining comparable values of accuracy metrics such as BLEU and . In fact, on certain datasets, the models have even improved on those metrics. While the approach has proved effective in most cases, the best combination of discourse rewards, accuracy rewards and NLL has had to be selected by validation for each dataset. In the near future we plan to investigate how to automate this selection, and also explore the applicability of the proposed approach to other natural language generation tasks.  
","    Deep encoders have been proven to be effective in improving neural machine translation  systems, but training an extremely deep encoder is time consuming. Moreover, why deep models help NMT is an open question. In this paper, we investigate the behavior of a well-tuned deep Transformer system. We find that stacking layers is helpful in improving the representation ability of NMT models and adjacent layers perform similarly. This inspires us to develop a shallow-to-deep training method that learns deep models by stacking shallow models. In this way, we successfully train a Transformer system with a 54-layer encoder. Experimental results on WMT'16 English-German and WMT'14 English-French translation tasks show that it is $1.4$ $\times$ faster than training from scratch, and achieves a BLEU score of $30.33$ and $43.29$ on two tasks. The code is publicly available at \href{https://github.com/libeineu/SDT-Training/}{https://github.com/libeineu/SDT-Training}.",187
"   Task-oriented dialogue systems complete tasks for users, such as making a hotel reservation or finding train routes, in a multi-turn conversation . The generated system utterances should not only be naturally sound, but more importantly be informative, i.e., to proceed the dialogue towards task completion. To fulfill this requirement, conditioned response generation is widely adopted based on system actions .  The response generation process is decoupled into two consecutive steps, where an action is first selected and then an utterance is generated conditioned on this action. One can optimize each step towards its goal, i.e., informative and naturally sound, without impinging the other . However, such approaches rely on action annotations , which require domain knowledge and extensive efforts to obtain.     %  \end{threeparttable} \end{table}    To deal with the absence of action annotations, latent action learning has been introduced .  System utterances are represented as low-dimensional latent variables by an auto-encoding task , and utterances with the same representations are considered to convey similar meanings.  Such action representations might be prone to over-dependence on the training data, which restricts the model generalization capability, especially when multiple domains are considered. % This is because the implicit nature of latent variables makes it unable to enforce the desired properties of the latent space, i.e., to capture the intentions of system utterances, without explicit supervision .  This is because, without explicit supervision, the desired property of capturing the intentions of system utterances in the latent space cannot be enforced , which in turn is due to the implicit nature of latent variables. For example, variational auto-encoder , which is often used for latent action learning, tends to produce a balanced distribution over the latent variables , while the true distribution of system actions is highly imbalanced . The resulting misaligned action representations would confuse the model of both steps and degenerate the sample efficiency in training.      % This is because without explicit supervision the desired property of capturing the intentions of system utterances in the latent space cannot be enforced , which in turn is due to the implicit nature of latent variables.   To address the above issues, we propose to learn natural language actions that represent system utterances as a span of words, which explicitly reveal the underlying intentions. % benefits of natural language actions Natural language provides unique compositional structure while retaining the representation flexibility. These properties promote model generalization and thus make natural language a 閾夸骏xible representation for capturing characteristics with minimal assumptions . % the main rationale to obtain such actions % In our scenarios, we aim to use language as the interface by  Motivated by these advantages, we learn natural language actions by identifying salient words of system utterances.  Salient refers to indicative for a prediction task  that takes as input the original utterance. % for the characteristics of utterances. The main rationale is that the principal information that the task concerns can be preserved by just the salient words. For example, the sentiment of sentence ``The movie starts out as competent but turn bland'' can be revealed by the word ``bland'' when it is identified salient by considering the complete context.   In our scenarios, we consider measuring word saliency in terms of state transitions. This is because state transitions reflect how the intentions of a system utterance influence the dialogue progress, and action representations that capture such influences can well reveal the intentions . By considering salient words for state tracking tasks as actions, we obtain action representations that enjoy the merits of natural language and indeed capture the characteristics of interest, i.e., intentions of system utterances. % explainable     % technical contributions Obtaining salient words by applying existing saliency identification approaches  is, however, unable to produce unified action representations. Specifically, system utterances with the same intention might not share similar wordings, and existing attribution approaches can only identify salient words within utterances. We tackle this challenge by proposing a memory-augmented saliency approach that identifies salient words from a broader vocabulary. The vocabulary consists of all the words that could compose natural language actions,~\footnote{We consider content words from state annotations and task descriptions, which will be specified in Sec. } and each word is stored as a slot in the memory component.  By incorporating the memory component into a dialogue state tracking model, we use each system utterance as a query to perform memory retrieval, and the retrieval results are considered as salient words. The retrieval results might contain words that are redundant since we do not have direct supervision for the retrieval operations. For example, the resulting salient words might be ``but turn bland'' in the example shown earlier, which include unnecessary words and may lead to degenerated action results.  To obtain compact action representations, we propose an auxiliary task based on pseudo parallel corpus, i.e., dialogue context and state annotation pairs.  We observe that dialogue states serve as good examples of how compact representation should be. Therefore, we use the encoded dialogue context as query and ask the memory component to reconstruct its text-based dialogue states. In this way, the obtained concise actions generalize better and can be easily interpreted.     Our contributions are summarized as follows:           We have investigated the behaviour of the well-trained deep Transformer models and found that stacking more layers could improve the representation ability of NMT systems. Higher layers share more global information over different positions and adjacent layers behave similarly. Also, we have developed a shallow-to-deep training strategy and employ sparse connections across blocks to ease the optimization. With the help of learning rate restart and appropriate initialization we successfully train a 48-layer RPR model by progressive stacking and achieve a  speedup on both WMT'16 English-German and WMT'14 English-French tasks. Furthermore, our -RPR-24L  achieves a BLEU score of  on WMT'16 English-German task, and speeds up the training by .  
","   Response generation for task-oriented dialogues implicitly optimizes two objectives at the same time: task completion and language quality. Conditioned response generation serves as an effective approach to separately and better optimize these two objectives.  Such an approach relies on system action annotations which are expensive to obtain. To alleviate the need of action annotations, latent action learning is introduced to map each utterance to a latent representation. However, this approach is prone to over-dependence on the training data, and the generalization capability is thus restricted.   To address this issue, we propose to learn natural language actions that represent utterances as a span of words.  This explicit action representation promotes generalization via the compositional structure of language. It also enables an explainable generation process. Our proposed unsupervised approach learns a memory component to summarize system utterances into a short span of words. To further promote a compact action representation, we propose an auxiliary task that restores state annotations as the summarized dialogue context using the memory component. Our proposed approach outperforms latent action baselines on MultiWOZ, a benchmark multi-domain dataset.",188
"      Consider helping a friend prepare dinner in an unfamiliar house: when your friend asks you to clean and slice an apple for an appetizer, how would you approach the task? Intuitively, one could reason abstractly:  find an apple  wash the apple in the sink  put the clean apple on the cutting board  find a knife  use the knife to slice the apple  put the slices in a bowl. Even in an unfamiliar setting, abstract reasoning can help accomplish the goal by leveraging semantic priors. Priors like locations of objects --~apples are commonly found in the kitchen along with implements for cleaning and slicing, object affordances --~a sink is useful for washing an apple unlike a refrigerator, pre-conditions --~better to wash an apple before slicing it, rather than the converse. We hypothesize that, learning to solve tasks using abstract language,  unconstrained by the particulars of the physical world, enables agents to complete embodied tasks in novel environments by leveraging the kinds of semantic priors that are exposed by abstraction and interaction.      To test this hypothesis, we have created the novel \env framework, the first interactive, parallel environment that aligns text descriptions and commands with physically embodied robotic simulation. We build \env by extending two prior works: \tw~ - an engine for interactive text-based games, and \alfred~ - a large scale dataset for vision-language instruction following in embodied environments.  \env provides two views of the same underlying world and two modes by which to interact with it: \tw, an abstract, text-based environment, generates textual observations of the world and responds to high-level text actions;  \alfred, the embodied simulator, renders the world in high-dimensional images and responds to low-level physical actions as from a robot .\footnote{Note: Throughout this work, for clarity of exposition, we use \alfred{} to refer to both tasks and the grounded simulation environment, but rendering and physics are provided by \thor{}~.} Unlike prior work on instruction following , which typically uses a static corpus of cross-modal expert demonstrations, we argue that aligned parallel environments like \env offer a distinct advantage: they allow agents to explore, interact, and learn in the abstract environment of language before encountering the complexities of the embodied environment.  While fields such as robotic control use % simulators like MuJoCo~ to provide infinite data through interaction, there has been no analogous mechanism  -- short of hiring a human around the clock --  for providing linguistic feedback and annotations to an embodied agent.  \tw{} addresses this discrepancy by providing programmatic and aligned linguistic signals during agent exploration. This facilitates the first work, to our knowledge, in which an embodied agent learns the meaning of complex multi-step policies, expressed in language, directly through interaction.    Empowered by the \env framework, we introduce \model , an agent that first learns to perform abstract tasks in \tw using Imitation Learning  and then transfers the learned policies to embodied tasks in \alfred.  When operating in the embodied world, \model leverages the abstract understanding gained from \tw to generate text-based actions; these serve as high-level subgoals that facilitate physical action generation by a low-level controller. Broadly, we find that \model is capable of generalizing in a zero-shot manner from \tw to unseen embodied tasks and settings. Our results show that training first in the abstract text-based environment is not only  faster, but also yields better performance than training from scratch in the embodied world. These results lend credibility to the hypothesis that solving abstract language-based tasks can help build priors that enable agents to generalize to unfamiliar embodied environments.   Our contributions are as follows:\\[-15pt]               We propose explicit action learning to achieve generalizable and interpretable dialogue generation.  Our proposed model MASP learns unified and compact action representations.     We propose a memory component that summarizes system utterances into natural language actions, i.e., spans of words from a unified vocabulary.  We further introduce an auxiliary task to encourage natural language actions to only preserve task-relevant information. Experimental results confirm that MASP achieves better performance compared with the state-of-the-art in different settings, especially when supervision is limited.  We plan to consider structural action representation learning that could convey more information as future work.  
","  Given a simple request like Put a washed apple in the kitchen fridge, humans can reason in purely abstract terms by imagining action sequences and scoring their likelihood of success, prototypicality, and efficiency, all without moving a muscle.  Once we see the kitchen in question, we can update our abstract plans to fit the scene. Embodied agents require the same abilities, but existing work does not yet provide the infrastructure necessary for both reasoning abstractly and executing concretely.  We address this limitation by introducing \env{}, a simulator that enables agents to learn abstract, text-based policies in \tw and then execute goals from the ALFRED benchmark in a rich visual environment. \env{} enables the creation of a new \model agent whose abstract knowledge, learned in \tw, corresponds directly to concrete, visually grounded actions. In turn, as we demonstrate empirically, this fosters better agent generalization than training only in the visually grounded environment. \model's simple, modular design factors the problem to allow researchers to focus on models for improving every piece of the pipeline .",189
"  Annual Reports may extend up to 250 pages long as stated above, which contains different sections General Corporate Information, financial and operating cost, CEOs message, Narrative texts, accounting policies, Financial statement including balance sheet and summary of financial data documents. In the Financial narrative summarisation task, only the narrative section is summarised, which is not explicitly marked in the dataset, making it challenging and interesting.  In recent years, previous manual small-scale research in the Accounting and Finance literature has been scaled up with the aid of NLP and ML methods, for example, to examine approaches to retrieving structured content from financial reports, and to study the causes and consequences of corporate disclosure and financial reporting outcomes . \par Companies produce glossy brochures of annual reports with a much looser structure, and this makes automatic summarisation of narratives in UK annual reports a challenging task . Hence we summarize the narrative section of annual reports, particular narrative sentences that are spread loosely across the document need to be first identified and summarise those sentences. The summarisation limit is set to 1000 words, where the actual length of the report may go up to 250 pages long. Hence to summarize these long annual reports using a combination of extractive and abstractive summarisation.\par The text summary method can be classified into two paradigms: extractive and abstractive. The extractive summarisation method extracts the meaningful sentences or a section of text from the original text and combines them  to form a summary . Whereas abstractive summarisation generates words and sentences that are similar in meaning to the given text to form a summary that may not be in actual text . When summarizing long documents such as in our case up to 250 pages long, extractive summarisation may not produce a coherent and readable summary, and abstractive summarisation cannot cover complete information using encoder-decoder architecture. One problem is that typical seq2seq frameworks often generate unnatural summaries consisting of repeated words or phrases . Hence, we come up with a combination of extractive and abstractive summarisation to first select important narrative sentences and concisely convey them. \par Pointer Networks  is used in various combinatorial optimization problems, such as Travelling Salesman Problem , Convex hull optimization. We used pointer networks in our task of financial narrative summarization to extract relevant narrative sentences in a particular order to have a logical flow in summary. These extracted sentences are paraphrased to summarise these sentences in an abstractive way using the T-5 sequence-to-sequence model. We train the complete model by optimizing the ROUGE-LCS evaluation metric through a reinforcement learning objective.   % % The following footnote without marker is nebe fireded for the camera-ready % version of the paper. % Comment out the instructions  and uncomment the 8 lines % under ""final paper"" for your variant of English. %  .     %      % % final paper: en-us version             % space normally used by the marker     This work is licensed under a Creative Commons      Attribution 4.0 International License.     License details:     \url{http://creativecommons.org/licenses/by/4.0/}. }    We introduced \env, the first interactive text environment with aligned embodied worlds. \env allows agents to explore, interact, and learn abstract polices in a textual environment. Pre-training our novel \model agent in \tw, we show zero-shot  generalization to embodied tasks in the \alfred dataset. The results indicate that reasoning in textual space allows for better generalization to unseen tasks and also faster training, compared to other modalities like vision.   \model is designed with modular components which can be upgraded in future work. Examples include the template-based state-estimator and the A* navigator which could be replaced with learned modules, enabling end-to-end training of the full pipeline. Another avenue of future work is to learn ``textual dynamics models'' through environment interactions, akin to vision-based world models~. Such models would facilitate construction of text-engines for new domains, without requiring access to symbolic state descriptions like PDDL. Overall, we are excited by the challenges posed by aligned text and embodied environments for better cross-modal learning.    
","   Companies provide annual reports to their shareholders at the end of the financial year that describes their operations and financial conditions. The average length of these reports is 80, and it may extend up to 250 pages long. In this paper, we propose our methodology PoinT-5  algorithms) that we used in the Financial Narrative Summarisation  2020 task. The proposed method uses Pointer networks to extract important narrative sentences from the report, and then T-5 is used to paraphrase extracted sentences into a concise yet informative sentence. We evaluate our method using $\operatorname{ROUGE}$-N , L,and SU4. The proposed method achieves the highest precision scores in all the metrics and highest F1 scores in $\operatorname{ROUGE}$ 1,and LCS and only solution to cross MUSE solution baseline in $\operatorname{ROUGE}$-LCS metrics.",190
"   Neural Architecture Search  methods aim to automatically discover neural architectures that perform well on a given task and dataset. These methods search over a space of possible model architectures, looking for ones that perform well on the task and will generalize to unseen data. There has been substantial prior work on how to define the architecture search space, search over that space, and estimate model performance .    Recent works, however, cast doubt on the quality and performance of NAS-optimized architectures , showing that current methods fail to find the best performing architectures for a given task and perform similarly to random architecture search.  In this work, we explore applications of a SOTA NAS algorithm, ENAS , to two sentence-pair tasks, paraphrase detection  and semantic textual similarity . We conduct a large set of experiments testing the effectiveness of ENAS-optimized RNN architectures across multiple models , embeddings  and datasets . We are the first, to our knowledge, to apply ENAS to PD and STS, to explore applications across multiple embeddings and traditionally LSTM-based NLP models, and to conduct extensive SOTA HPT across multiple ENAS-RNN architecture candidates.   Our experiments suggest that baseline LSTM models, with appropriate hyperparameter tuning , can sometimes match or exceed the performance of models with ENAS-RNNs. We also observe that random architectures sampled from the ENAS search space offer a strong baseline, and can sometimes outperform ENAS-RNNs. Given these observations, we recommend that researchers  conduct extensive HPT  across various candidate architectures for the fairest comparisons;  compare the performances of ENAS-RNNs against both standard architectures like LSTMs and RNN cells randomly sampled from the ENAS search space;  examine the computational  requirements of ENAS methods alongside the gains observed.     In this work we present our solution on Financial Narrative Summarisation dataset using PoinT-5 method explained in . It is combination of both extractive and abstractive methods using Pointer Network and T-5. With these methods we are able to achieve highest precision score in every evaluation metric and achieve highest F-1 scores in ROUGE-LCS and ROUGE-1.\par In our future work we would like to address several limitation of our method such as factual correctness in summaries which is very important in financial domain as done in  in summarizing radiology reports. To improve precision of our generated summaries under 1000 words we would formulate a penalty if system generates more than 1000 words during training of RL algorithm rather than restricting algorithm to fixed number of sentences.     include your own bib file like this: 
","  Neural Architecture Search  methods, which automatically learn entire neural model or individual neural cell architectures, have recently achieved competitive or state-of-the-art  performance on variety of natural language processing and computer vision tasks, including language modeling, natural language inference, and image classification. In this work, we explore the applicability of a SOTA NAS algorithm, Efficient Neural Architecture Search  \cite{Pham2018EfficientNA} to two sentence pair tasks, paraphrase detection and semantic textual similarity. We use ENAS to perform a micro-level search and learn a task-optimized RNN cell architecture as a drop-in replacement for an LSTM. We explore the effectiveness of ENAS through experiments on three datasets , with two different models , and two sets of embeddings . In contrast to prior work applying ENAS to NLP tasks, our results are mixed -- we find that ENAS architectures sometimes, but not always, outperform LSTMs and perform similarly to random architecture search.",191
" Constituency parsing is a well-studied problem in natural language processing, but most state-of-the-art parsers have only been tested on written text, e.g.\ the standard Penn Treebank Wall Street Journal  dataset .  These recent neural parsers are commonly formulated as encoder-decoder systems, where the encoder learns the input sentence representation and the decoder learns to predict a parse tree. While input is often represented by word-level features, representation for the output trees varies:  as a sequence of parse symbols , a set of spans ,  syntactic distances , or per-word structure-rich labels . A key characteristic in many of these neural parsers is the recurrent network structure, particularly Long Short-Term Memory networks ; however, Kitaev and Klein  have shown that a non-recurrent encoder such as the Transformer network introduced in  is also capable of encoding timing information through self-attention mechanisms, achieving state-of-the-art parse results on the Treebank WSJ dataset.  Further, these parsers  %seem to mainly  benefit from contextualized information learned from larger external text data, such as ELMo  and BERT .  It is not clear that these advances will transfer to speech data, particularly for the different styles of speech. Even when perfect transcripts are available, speech poses many challenges to parsers learned from written text due to the lack of punctuation and case, and the presence of disfluencies.  On the other hand, speech signals carry rich information beyond words via variations in timing, intonation, and loudness, i.e. in prosody. Linguistic studies have shown that prosodic cues align with constituent structure , signal disfluencies by marking the interruption point , and help listeners resolve syntactic ambiguities . Empirical evidence, however, has been mixed regarding the utility of prosody for constituency parsing. Most gains have been observed when sentence boundaries are unknown , or with annotated prosodic labels . Most related to our current work, Tran et al.\  recently showed the benefit of using prosody in parsing within a sequence-to-sequence framework, proposing a convolutional neural network  as a mechanism to combine discrete word-level features with frame-level acoustic-prosodic features.  In this study, we extend the work in  and  to explore the utility of recent neural advances on spontaneous speech data, and compare the utility of prosody in read vs.\ spontaneous speech. Specifically, the goal of the current study is to answer the following questions:    % TT: may cut this if space is lacking. But I didn't want to end the intro with questions without saying anything further %The rest of this paper is organized as follows: Section  describes the models used in this work; Section  reviews the datasets and metrics in constituency parsing; Section  presents our experiments, results, and analyses; and Section  summarizes the findings.  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Moved data table here since it was oddly arranged %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  \end{table*}\documentclass[a4paper]{article}  \usepackage{INTERSPEECH2019} \usepackage{url} \usepackage{multirow} \usepackage{xcolor} \usepackage{subcaption,enumitem} \usepackage{booktabs} \usepackage{comment}  \newcommand{\ttcomment}[1]{\textcolor{red}{\bf \small [#1 --TT]}} \newcommand{\jycomment}[1]{\textcolor{blue}{\bf \small [#1 --JY]}} \newcommand{\ylcomment}[1]{\textcolor{cyan}{\bf \small [#1 --YL]}} \newcommand{\mocomment}[1]{\textcolor{green}{\bf \small [#1 --MO]}}  \title{On the Role of Style in Parsing Speech with Neural Models} \name{Trang Tran, Jiahong Yuan, Yang Liu, Mari Ostendorf} %The maximum number of authors in the author list is twenty. If the number of contributing authors is more than twenty, they should be listed in a footnote or in acknowledgement section, as appropriate. \address{   Electrical \& Computer Engineering, University of Washington\\   LAIX Inc.} \email{\{ttmt001,ostendor\}@uw.edu, \{jiahong.yuan,yang.liu\}@liulishuo.com}   Index Terms: constituency parsing, prosody, spontaneous speech, contextualized embeddings %Index Terms: constituency parsing, prosody, spontaneous speech, read speech, switchboard, ELMo, BERT, contextualized embeddings %\ttcomment{take out some of these?}             \bibliographystyle{IEEEtran}  \bibliography{interspeech19}  \end{document}     Unlike prior work applying ENAS to NLP, we find that ENAS-RNNs only outperform LSTMs and random search on some dataset, embedding, model) configurations. Our findings parallel recent work  which question the effectiveness of current NAS methods and their superiority to random architecture search and SOTA HPT methods.  Given our mixed results, we recommend researchers:  extensively tune hyperparameters for standard  and randomly sampled architectures to create strong baselines;  benchmark ENAS performance across multiple simple and complex model architectures ;  present computational requirements alongside gains observed with ENAS methods.       
"," The differences in written text and conversational speech are substantial; previous parsers trained on treebanked text have given very poor results on spontaneous speech. For spoken language, the mismatch in style also extends to prosodic cues, though it is less well understood.  This paper re-examines the use of written text in parsing speech in the context of recent advances in neural language processing. We show that neural approaches facilitate using written text to improve  parsing of spontaneous speech, and that prosody further improves over this state-of-the-art result. Further, we find an asymmetric degradation from read vs.\ spontaneous mismatch, with spontaneous speech more generally useful for training parsers.  %  Prosodic information in the speech signal has been shown to correlate with syntactic structure of a sentence; however, the impact of prosody on parsing has been mixed. Recent results show a benefit for conversational speech, particularly in utterances with disfluencies, but there is little recent work on other speaking styles. In this work, we extend recent advances in constituency parsing of spontaneous speech, integrating acoustic-prosodic cues and achieving SOTA results on the Switchboard dataset. We then explore the performance of the parser on mismatched training/testing scenarios. Specifically, we show that training on spontaneous speech results in a small degradation when testing on read speech, while fine-tuning with WSJ read speech substantially degrades the performance on spontaneous speech.",192
" The recent progress in machine translation models has led researchers to question the use of n-gram overlap metrics such as BLEU, which focus solely on surface-level aspects of the generated text, and thus may correlate poorly with human evaluation. This has led to a surge of interest for more flexible metrics that use machine learning to capture semantic-level information. Popular examples of such metrics include YiSi-1, ESIM, BERTscore, the Sentence Mover's Similarity, and \BLEURT{}.  These metrics utilize contextual embeddings from large models such as BERT which have been shown to capture linguistic information beyond surface-level aspects.   The WMT Metrics 2020 Shared Task is the reference benchmark for evaluating these metrics in the context of machine translation. It tests the evaluation of systems that are to-English  and to other languages , which requires a multilingual approach. An additional challenge for learned metrics is that human ratings are not available for all language pairs, and therefore, the models must use unlabeled data and perform zero-shot generalization.   We describe several learned metrics based on \BLEURT{}~, originally developed for English data. We first extend \BLEURT{} to the multilingual setup, and show that our approach achieves competitive results on the WMT Metrics 2019 Shared Task.\footnote{We use the following languages for fine-tuning and/or testing: Chinese, Czech, German, English, Estonian, Finnish, French, Gujarati, Kazakh, Lithuanian, Russian, and Turkish. In addition, we also pre-train on Inuktitut, Japanese, Khmer, Pastho, Polish, Romanian, and Tamil.} We also present several simple BERT-based baselines, which we submit for analysis. Finally, we focus on English to German and enhance \BLEURT{}'s performance by combining its predictions with those of YiSi as well as by using alternative  references.      We show that neural architectures, in particular contextualized embeddings pretrained on large written text , improve constituency parsing on conversational speech transcripts. The use of prosody results in further improvements overall, especially in longer sentences and in reducing attachment errors. Assessing the utility of prosody in different speaking styles, we found that parsers trained with spontaneous prosody are consistently useful, improving over their text-only counterparts when testing on both conversational and read  speech. Fine-tuning such parsers on read speech improves results when testing on the same read style, but degrades significantly on spontaneous speech. This suggests that conversational speech data is more useful for general parser training. 
"," The quality of machine translation systems has dramatically improved over the last decade, and as a result, evaluation has become an increasingly challenging problem. This paper describes our contribution to the WMT 2020 Metrics Shared Task, the main benchmark for automatic evaluation of translation. We make several submissions based on \BLEURT{}, a previously published metric which uses transfer learning. We extend the metric beyond English and evaluate it on 14 language pairs for which fine-tuning data is available, as well as 4 ``zero-shot'' language pairs, for which we have no labelled examples. Additionally, we focus on English to German and demonstrate how to combine \BLEURT{}'s predictions with those of YiSi and use alternative reference translations to enhance the performance. Empirical results show that the models achieve competitive results on the WMT Metrics 2019 Shared Task, indicating their promise for the 2020 edition.",193
" 	 	Although neural machine translation  has achieved great progress in recent years , when fed an entire document, standard NMT systems translate sentences in isolation without considering the cross-sentence dependencies. Consequently, document-level neural machine translation  methods are proposed to utilize source-side or target-side inter-sentence contextual information to improve translation quality over sentences in a document . 	 	More recently, researchers of DocNMT mainly focus on exploring various attention-based networks to leverage the cross-sentence context efficiently, and evaluate the special discourse phenomena . However, there is still an issue that has received less attention: which context sentences should be used when translating a source sentence? 	 	 			 			 		\end{center} 	\end{table} 	 	 	We conduct an experiment to verify an intuition: the translation of different source sentences requires different context. As shown in Table , we train two DocNMT models and test them using various context settings\footnote{We apply a typical DocNMT method  to train models on ZhEn TED, and select 1,000 sentences to test. The BLEU of sentence-level baseline is 20.06.}. During the test, we obtain dynamic context sentences that achieve the best BLEU scores by traversing all the context combinations for each source sentence. Compared with the fixed size context , dynamic context  can significantly improve translation quality. Although row 2 uses more context, redundant information may hurt the results. Experiments indicate that only the limited context sentences are really useful, and they change with source sentences. 	 	Majority of existing DocNMT models set the context size or scope to be fixed. They utilize all of the 	previous  context sentences , or the full context in the entire document . As a result, the inadequacy or redundancy of contextual information is almost inevitable. From this viewpoint, \citet{maruf2019selective} propose a selective attention approach that uses the sparsemax function  instead of the softmax to normalize the attention weights. The sparsemax assigns the low probability in softmax to zero so that the model can focus on the sentences with high probability. However, the learning of attention weights lacks guidance, and they cannot handle the situation where the source sentences achieve the best translation results without relying on any context, which happens in about 39.4\% of sentences in the experiment. 	 	To address the problem, we propose an effective approach to select contextual sentences {\bf dynamically} for each source sentence in the document-level translation. Specifically, we propose a Context Scorer to score each candidate context sentence according to the currently translated source sentence. Then, we utilize two selection strategies to select useful context sentences for the translation module. The size of selected context is variable for different sentences. A core challenge of our approach is that the selection process is non-differentiable. Therefore, we leverage the reinforcement learning  method to train the selection and DocNMT modules together. We design a novel reward to encourage the model to be aware of different context sentences and select more appropriate context to improve translation quality. 	 	In this paper, we make the following contributions: 	 	 	    We provide empirical evidence on the ability of self-attention  networks to learn generalized  languages. We compare the performance of two SA networks, SA and SA, which differ only in the inclusion of a starting symbol in their vocabulary.  We demonstrate that a simple addition of the starting symbol helps SA generalize to sequences that are longer and have higher depths.  The competitive performance of SA  against LSTMs might seem surprising, considering that the recognition of  languages is an inherently hierarchical task. From our experiments, we conclude that recognizing Dyck languages is not tied to recursion, but rather learning the right representations to look up the head token. Further, we find that the representations learned by SA are highly interpretable and the network performs computations similar to a stack automaton. Our results suggest formal languages could be an interesting avenue to explore the interplay between performance and interpretability for SA. Comparisons between SA and LSTM reveal interesting contrast between the two architectures which calls for further investigation. Recent work  shows how to express the Transformer as an RNN through linearization of the attention mechanism, which could lay grounds for more theoretical analysis of these neural architectures           \setcounter{section}{0} \import{}{supp_arxiv}     
"," 		Document-level neural machine translation has yielded attractive improvements. However, majority of existing methods roughly use all context sentences in a fixed scope. They neglect the fact that different source sentences need different sizes of context. To address this problem, we propose an effective approach to select dynamic context so that the document-level translation model can utilize the more useful selected context sentences to produce better translations. Specifically, we introduce a selection module that is independent of the translation module to score each candidate context sentence. Then, we propose two strategies to explicitly select a variable number of context sentences and feed them into the translation module. We train the two modules end-to-end via reinforcement learning. A novel reward is proposed to encourage the selection and utilization of dynamic context sentences. Experiments demonstrate that our approach can select adaptive context sentences for different source sentences, and significantly improves the performance of document-level translation methods.",194
"  \vsec Automatic text summarization\footnote{We refer to abstractive summarization in this paper.} is an attractive technique for helping humans to grasp the content of documents effortlessly. While supervised neural methods have shown good performances, the unsupervised approach is starting to attract interest due to its advantage of not requiring costly parallel corpora. However, the empirical performance of unsupervised methods is currently behind that of state-of-the-art supervised models. Unsupervised text summarization is still developing and is now at the stage where various solutions should be actively explored.     One previous unsupervised approach extends neural encoder-decoder modeling to the zero paired data scenario, where a model is trained with a paradigm called compression-reconstruction  learning. The mechanism is similar to that of the back-translation: the model consists of a compressor  and a reconstructor, and they are co-trained so that the reconstructor can recover the original sentence from the summary generated by the compressor~. Experimental results showed that such an unsupervised encoder-decoder-based summarizer is able to learn the mapping from a sentence to a summary without paired data. % Also, \citealp{zhou-rush-2019-simple} proposes a more straightforward method that mimics the reconstruction part by means of contextual similarity between an original input sentence and a top of a generating summary. % However, the performance of any unsupervised methods is still deficient compared to the latest supervised models.   Reinforcement learning  is also a potential solution for the no paired data situation. In related fields, for example, there are unsupervised methods for text simplification and text compression with policy-gradient learning. Recent RL techniques take a value-based approach  such as DQN or the combination of policy and value-based approaches such as Asynchronous Advantage Actor-Critic. A critical requirement to leverage a value-based method is a value function that represents the goodness of an action on a given state. We can naturally define the value function by utilizing the CR-learning paradigm, and it makes the latest value-based approaches available for unsupervised text summarization. % , and they require to define value-function. % We can leverage the values-based approach  % A crucial requirement for RL is a value function that represents a goodness of action on a given state. % We can satisfy the requirement by leveraging the definition in CR learning paradigm. % One concern is, however, that RL with large action space   generally has difficulty in the training. % In addition, the latest techniques to improve RL are from a value-based approach  such as DQN or the combination of policy-based and value-based approaches such as Asynchronous Advantage Actor-Critic.   In this paper, we propose a new method based on Q-learning and an edit-based summarization~. The edit-based summarization generates a summary by operating an edit action  for each word in the input sentence. Our method implements the editing process with two modules: 1) an {\bf E}ditorial {\bf A}gent that predicts edit actions, and 2) a {\bf L}anguage {\bf M}model  converter that deterministically decodes a sentence on the basis of action signals, which we call \ealm. The CR learning is defined on the Q-learning framework to train the agent to predict edit actions that instruct the LM converter to produce a good summary. Although a vast action space causing sparsity in reward, such as the word generation of an encoder-decoder model, is generally difficult to be learned in RL, our method mitigates this issue thanks to its fewer edit actions and the deterministic decoding of a language model. Moreover, the formulation by Q-learning enables us to incorporate the latest techniques in RL.  The main contribution of this paper is that we provide a new solution in the form of an unsupervised edit-based summarization leveraging Q-learning and a language model. Experimental results show that our method achieved a competitive performance with encoder-decoder-based methods even with truly no paired data , and qualitative analysis brings insights as to what current unsupervised models are missing. Also, the problem formulation on Q-learning enables us to import the latest techniques in RL, which leads to potential improvements in future research.  % 2) We propose the first Q-learning-based method that uses a pre-trained language model. % , which mitigates the issues prevalent among the previous methods. % Empirically, our method shows a competitive performance in the news corpus benchmarks with truly no paired data . % Also, our method requires no parallel data even for validation; therefore, it can be instantly applicable to any situation if there is a language model.  % Our proposed approach brings new insights to the growing field of unsupervised text summarization, and will pave the way to future development.  % This paper is organized as follows: Section defines the problem statement of unsupervised text summarization with the \algoname\ paradigm. % After reviewing the previous methods in Section, we introduce our approach in Section . % Then, we report experimental results in Section . % Discussing insights from the experiment in Section , we conclude the contribution of this paper for future unsupervised text summarization in Section .    % Text Summarization is a task to transform an input sentence into an informative summary . % Although supervised summarization models like encoder-decoder have shown success for these years , it still has an issue to demand us to create massive parallel data. % The question ``how we can model the transformation only from the input sentences?"" attracts research interests, and known as unsupervised text summarization .  % In unsupervised text summarization, only the input sentences are available for training a model. % Instead, it holds a hypothesis: a summary should contain information about its input sentence to some extent that we can guess the original contents. % And, lgoname is an approach to leverage this hypothesis .  % In \algoname, we prepare two modules, the one for compression that produces the summary  from the input sentence, and the other one for reconstruction that re-produces the input sentence from the generated summary. % These two modules are optimized based on the hypothesis, more specifically, minimizing the difference between the input sentence and the reconstructed sentence while the compressed sentence  is satisfying essential properties such as shortness or readability . % In previous studies, they use generative models such as encoder-decoder for compression and reconstruction, and directly train them to output desired sentences . % We illustrate the flow in the left-hand side of Figure .  % Our proposed method is also on top of the same paradigm but uses different modules, {\bf Q-learning agent} and {\bf fixed-language model} .\footnote{A pretrained language model that is not fine-tuned, i.e., fixed, during training.} % As illustrated in the right-hand side of Figure , the agent determines action, whether to remove, keep, or replace each word in the input sentence. % Receiving the action signals, the fixed-LM deterministically produces compressed and reconstructed sentences. % In short, we train the agent to properly control the fixed-LM so that we obtain desired sentences as the results of compression and reconstruction.  % The primary contribution of this paper is to provide a new option leveraging Q-learning with a language model to the growing field of unsupervised text summarization. % Introducing Q-learning, we open the problem to sophisticated techniques on value-based Reinforcement Learning  algorithms , which is not covered only with policy-based RL algorithms employed so far.\footnote{RL algorithms are classified into value-based  and policy-based . To the best of our knowledge, most of the text summarization methods with RL, both in supervised and unsupervised settings, leverages policy-based RL algorithms . Combining such a previous policy-based and our value-based methods for sentence compression will lead to the applicability of more advanced RL algorithms such as Actor-Critic  and Asynchronous Advantage Actor-Critic .} % Also, proposing an approach to fixedly utilize the pre-trained language model, we benefit from its powerful performance capturing sentence semantics along with mitigating issues generative models inherently hold such as complexity in co-training of multiple generators or repetition in decoding. % Experimentally, our approach shows promising results; it achieves competitive performance in standard datasets and outperforms the previous generator models in out-of-domain circumstances. % This paper brings novel insights for unsupervised text summarization and contributes to be flourishing in the future.  % This paper is organized as follows: Section defines the problem statement of unsupervised text summarization with the \algoname\ paradigm. % After reviewing the previous methods in Section, we introduce our approach in Section . % Then, we report experimental results in Section . % Discussing insights from the experiment in Section , we conclude the contribution of this paper for future unsupervised text summarization in Section .  \vsecu   	 	We propose a dynamic selection method to choose variable sizes of context sentences for document-level translation. The candidate context sentences are scored and selected by two proposed strategies. We train the whole model via reinforcement learning, and design a novel reward to encourage the selection of useful context sentences. When applied to existing DocNMT models, our approach can improve translation quality significantly. In the future, we will select context sentences in larger candidate space, and explore more effective ways to extend our approach to select target-side context sentences. 	 	
"," % Unsupervised methods for abstractive text summarization are attractive because they do not require parallel corpora. % However, their performance is still somehow lacking, therefore research on promising solutions is ongoing. % In this paper, we propose a new approach based on Q-learning with an edit-based summarization. % Our method combines two key modules to form an {\bf E}ditorial {\bf A}gent and {\bf L}anguage {\bf M}odel converter~. % The agent predicts edit actions, and then the LM converter deterministically generates a summary on the basis of the action signals. % Q-learning is leveraged to train the agent to output proper edit actions. % Experimental results show that \ealm~has a competitive performance compared with the previous encoder-decoder-based methods, even with truly zero paired data .  % Defining the task as Q-learning enables us not only to develop a competitive method but also to make the latest techniques in reinforcement learning available for unsupervised summarization. % We also conduct qualitative analysis and provide insights on future work for the current unsupervised summarizers.\footnote{Our codes are available at \url{https://github.com/kohilin/ealm}} Unsupervised methods are promising for abstractive textsummarization in that the parallel corpora is not required.  However, their performance is still far from being satisfied, therefore research on promising solutions is on-going.   In this paper, we propose a new approach based on Q-learning with an edit-based summarization.  The method combines two key modules to form an Editorial Agent and Language Model converter .  The agent predicts edit actions , and then the LM converter deterministically generates a summary on the basis of the action signals.  Q-learning is leveraged to train the agent to produce proper edit actions.  Experimental results show that \ealm~delivered competitive performance compared with the previous encoder-decoder-based methods, even with truly zero paired data . Defining the task as Q-learning enables us not only to develop a competitive method but also to make the latest techniques in reinforcement learning available for unsupervised summarization. We also conduct qualitative analysis, providing insights into future study on unsupervised summarizers.\footnote{Our codes are available at \url{https://github.com/kohilin/ealm}}",195
" Neural machine translation  systems are data driven models, which highly depend on the training corpus.  NMT models have a tendency towards over-fitting to frequent observations  while neglecting those low-frequency observations.  Unfortunately, there exists a token imbalance phenomenon in natural languages as different tokens appear with different frequencies, which roughly obey the Zipf's Law.  Table shows that there is a serious imbalance between high-frequency tokens and low-frequency tokens.  NMT models rarely have the opportunity to learn and generate those ground-truth low-frequency tokens in the training process. %It is harder for the NMT model to generate ground-truth low-frequency tokens even in the training process.  %Compared to the reference, the NMT model tends to generate more high-frequency tokens and less low-frequency tokens, which hurts the translation quality.  Some work tries to improve the rare word translation by maintaining phrase tables or back-off vocabulary or adding extra components, which bring in extra training complexity and computing expense.  Some NMT techniques which are based on smaller translation granularity can alleviate this issue, such as hybrid word-character-based model, BPE-based model and word-piece-based model. %For example, the sub-word model adapted byte pair encoding  technique to the task of word segmentation.  These effective work alleviate the token imbalance phenomenon to a certain extent and become the de-facto standard in most NMT models.  Although sub-word based NMT models have achieved significant improvements, they still face the token-level frequency imbalance phenomenon, as Table shows.  %It is obvious that there are always low-frequency tokens no matter what the number of merge operations of BPE is. %As shown in Table, the rare word 'slower' is split into two tokens as 'slow' and 'er', there still exist obvious token-level imbalance between 'slow' and other tokens.   \iffalse            \end{table} \fi    \iffalse  \fi   \iffalse            \end{table} \fi Furthermore, current NMT models generally assign equal training weights to target tokens without considering their frequencies.  It is very likely for NMT models to ignore the loss produced by the low-frequency tokens because of their small proportion in the training sets. The parameters related to them can not be adequately trained, which will, in turn, make NMT models tend to prioritize output fluency over translation adequacy, and ignore the generation of low-frequency tokens during decoding, which is illustrated in Table. It shows that the vanilla NMT model tends to generate more high-frequency tokens and less low-frequency tokens. %This will, in turn, make the model %tend to generate too many high-frequency tokens and too less low-frequency tokens during decoding. However, low-frequency tokens may carry critical semantic information which may affect translation quality once they are neglected.   %It is very likely for NMT models to ignore the loss produced by rare words so that the patterns learned by the encoder, decoder, or attention modules from them can't be adequately updated. What's more, NMT models tend to prioritize output fluency over translation adequacy and ignore the translation of rare words during generation.  %In our experiments, we observed that vanilla NMT models usually produce more frequent words and less rare words than real references. Therefore, some techniques should be adopted to improve the translation of rare words. %distribution.   %It is obvious that there are always rare tokens no matter what the number of merge operations of BPE is and the problem of token distribution imbalance still exists.  %One of the advantages of this technique is that it reduces the number of rare words by splitting them into more frequent subword tokens , which in fact  %relieve the imbalance of word   %The strength is that NMT models can make use of large amounts of parallel training sentences and learn the knowledge and features embodied in the training data. However, one of the weaknesses is that NMT models have a tendency towards over-fitting to frequent observations , but neglecting those rare cases which are not frequently observed. Unfortunately, there is a natural word distribution imbalance in the corpus. According to the Zipf's Law, the frequency of any word is inversely proportional to its ranking in the frequency table, which indicates that the occurrences of some words are far more than others naturally.     %For word-level NMT models, NMT has its limitation in handling a larger vocabulary because of the training complexity and computing expense.   % %In their work, they first represent each word as a sequence of characters and then iteratively combine the most frequent pair as a new symbol. %which achieved better accuracy for the translation of rare words %, we seek to further alleviate the token imbalance problem based on the above analysis. For this purpose,  To address the above issue, we proposed token-level adaptive training objectives based on target token frequencies.  We aimed that those meaningful but relatively low-frequency tokens could be assigned with larger loss weights during training so that the model will learn more about them. %In our objectives, those relatively low-frequency but valuable tokens will be assigned with larger loss weights during training to encourage the model to learn more about them. To explore suitable adaptive objectives for NMT, we first applied existing adaptive objectives from other tasks to NMT and analyzed their performance. We found that though they could bring modest improvement on the translation of low-frequency tokens, they did much damage to the translation of high-frequency tokens, which led to an obvious degradation on the overall performance. This implies that the objective should ensure the training of high-frequency tokens first. %training of high-frequency tokens should be ensured first. %We should ensure the training of high-frequency tokens and enlarge the weights of low-frequency tokens at the same time. %We firstly tried the focal loss, which was proposed for solving the token imbalance problem in the CV task, and analyzed the performance.  Then, based on our observations, we proposed two heuristic criteria for designing the token-level adaptive objectives based on the target token frequencies. Last, we presented two specific forms for different application scenarios according to the criteria. Our method yields consistent improvements in translation quality on ZH-EN, EN-RO, and EN-DE translation tasks, especially on sentences that contain more low-frequency tokens where we can get 1.68, 1.02, and 0.52 BLEU increases compared with baseline, respectively. Further analyses show that our method can also improve the lexical diversity of translation. %We carried out experiments on ZHEN, ENRO, and ENDE translation tasks to validate our methods. The experimental results show that our methods achieve significant improvement in translation quality, especially in sentences that contain more low-frequency tokens.  %Besides, the token distribution of our translations becomes closer to references for test sets.  %Besides, our method also improves the diversity of the translations.   Our contributions can be summarized as follows:   %More specifically, NMT models are first trained with equal weights and then fine-tuned with well-defined weights introduced by the scoring functions. In this way, it won't hurt the translation of frequent tokens, but also can improve the translation of rare tokens to a certain degree. To the best of our knowledge, this is the first work trying to concern about the training weights at the token level to solve the distribution imbalance problem in NMT. The experiments on multiple translation tasks show that our method can improve the overall translation performance without almost any additional computing or storage expense. And the analysis experiments indicate that our method can improve the rare tokens translation significantly and the tokens distribution of our translation are much closer to the references than the baseline translations.     \vsec We brought the Q-learning framework into unsupervised text summarization and proposed a new method \ealm~that is an edit-based unsupervised summarizer leveraging a Q-learning agent and a language model. The experments showed that \ealm~performed competitively with the previous encoder-decoder-based methods. However, in qualitative analysis, we found that the quality of the generated summaries of any unsupervised model was not sufficient, and there are individual limitations for each model. These issue must be overcome as the step forward to generating practically available summaries without paired data. In particular for \ealm, there is room for improvement by importing the latest techniques in RL. Our work paves the way for further research on bridging Q-learning and unsupervised text summarization.                                   
"," There exists a token imbalance phenomenon in natural language as different tokens appear with different frequencies, which leads to different learning difficulties for tokens in Neural Machine Translation .  The vanilla NMT model usually adopts trivial equal-weighted objectives for target tokens with different frequencies and tends to generate more high-frequency tokens and less low-frequency tokens compared with the golden token distribution. %%% However, low-frequency tokens may carry critical semantic information that will affect the translation quality once they are neglected.   In this paper, we explored target token-level adaptive objectives based on token frequencies to assign appropriate weights for each target token during training.  We aimed that those meaningful but relatively low-frequency words could be assigned with larger weights in objectives to encourage the model to pay more attention to these tokens. %More specifically, those relatively low-frequency but valuable target tokens will be assigned with larger weights in objectives to encourage the model to pay more attention to these tokens. %%% %We conducted experiments  Our method yields consistent improvements in translation quality on ZH-EN, EN-RO, and EN-DE translation tasks, especially on sentences that contain more low-frequency tokens where we can get 1.68, 1.02, and 0.52 BLEU increases compared with baseline, respectively. Further analyses show that our method can also improve the lexical diversity of translation. %Experiments on multiple translation tasks show that our methods can achieve significant improvement in translation quality, especially on sentences that contain more low-frequency tokens.  %Besides, our method also improves translation diversity. %Besides, the token distribution of our translations becomes closer to the reference of test sets.  %.  %Rare words translation has always been one of the key challenges to Neural Machine Translation .",196
"   Graph structures play a pivotal role in NLP because they are able to capture particularly rich structural information. For example, Figure shows a directed, labeled Abstract Meaning Representation  graph, where each node denotes a semantic concept and each edge denotes a relation between such concepts. Within the realm of work on AMR, we focus in this paper on the problem of AMR-to-text generation, i.e. transducing AMR graphs into text that conveys the information in the AMR structure. A key challenge in this task is to efficiently learn useful representations of the AMR graphs. Early efforts  neglect a significant part of the structural information in the input graph by linearizing it. Recently, Graph Neural Networks  have been explored to better encode structural information for this task .   % \tzy{papers before 2018??? Gated Graph Neural networks??? Do not miss an important paper.}     One type of such GNNs is Graph Convolutional Networks .  GCNs follow a local information aggregation scheme, iteratively updating the representations of nodes based on their immediate  neighbors.  Intuitively, stacking more convolutional layers in GCNs helps capture more complex interactions .  However, prior efforts  have shown that the locality property of existing GCNs precludes efficient non-local information propagation. \citet{AbuElHaija2019MixHopHG} further proved that vanilla GCNs are unable to capture feature differences among neighbors from different orders no matter how many layers are stacked. Therefore, Self-Attention Networks  have been explored as an alternative to capture global dependencies. As shown in Figure , SANs associate each node with other nodes such that we model interactions between any two nodes in the graph. Still, this approach ignores the structure of the original graph. \citet{Zhu2019ModelingGS} and \citet{Cai2019GraphTF} propose structured SANs that incorporate additional neural components to encode the structural information of the input graph.   Convolutional operations, however, are more computationally efficient than self-attention operations because the computation of attention weights scales quadratically while convolutions scale linearly with respect to the input length . Therefore, it is worthwhile to explore the possibility of models based on graph convolutions. One potential approach that has been considered is to incorporate information from higher order neighbors, which helps to facilitate non-local information aggregation for node classification . However, simple concatenation of different order representations may not be able to model complex interactions in semantics for text generation .    We propose to better integrate high-order information, by introducing a novel dynamic fusion mechanism and propose the Lightweight, Dynamic Graph Convolutional Networks . As shown in Figure  , nodes in the LDGCN model are able to integrate information from first to third-order neighbors. With the help of the dynamic mechanism, LDGCNs can effectively synthesize information from different orders to model complex interactions in the AMR graph for text generation. Also, LDGCNs require no additional computational overhead, in contrast to vanilla GCN models. We further develop two novel weight sharing strategies based on the group graph convolutions and weight tied convolutions. These strategies allow the LDGCN model to reduce memory usage and model complexity.  Experiments on AMR-to-text generation show that LDGCNs outperform best reported GCNs and SANs trained on LDC2015E86 and LDC2017T10 with significantly fewer parameters. On the large-scale semi-supervised setting, our model is also consistently better than others, showing the effectiveness of the model on a large training set. We release our code and pretrained models at \url{https://github.com/yanzhang92/LDGCNs}.\footnote{Our implementation is based on  MXNET  and the Sockeye toolkit .}     In this work, we focus on the token imbalance problem of NMT. We show that the output of vanilla NMT contains more high-frequency tokens and has lower lexical diversity.  the vanilla NMT model tends to generate more high-frequency words than the true distribution due to.  there is a token imbalance phenomenon in the natural language and the vanilla NMT model tends to generate more high-frequency words than the true distribution.  and less low-frequency words    This output bias will affect the translation quality since the low-frequency tokens may carry critical semantic information.  To alleviate this problem, we investigated existing adaptive objectives for other tasks and then proposed two heuristic criteria based on the observations. Next, we gave two simple but effective forms based on the criteria, which can assign appropriate training weights to target tokens.  we propose token-level adaptive objectives based on token frequencies, aiming to assign appropriate training weights to target tokens. To achieve this, we propose three heuristic criteria and then put forward two simple but effective forms based on the criteria.  The final results show that our methods can achieve significant improvement in performance, especially on sentences that contain more low-frequency tokens. Further analyses show that our method can also improve the lexical diversity.   
"," 	 	% Camera-Ready 	AMR-to-text generation is used to transduce Abstract Meaning Representation structures  into text. A key challenge in this task is to efficiently learn effective graph representations. Previously, Graph Convolution Networks  were used to encode input AMRs, however, vanilla GCNs are not able to capture non-local information and additionally, they follow a local  information aggregation scheme. To account for these issues, larger and deeper GCN models are required to capture more complex interactions. In this paper, we introduce a dynamic fusion mechanism, proposing Lightweight Dynamic Graph Convolutional Networks  that capture richer non-local interactions by synthesizing higher order information from the input graphs. We further develop two novel parameter saving strategies based on the group graph convolutions and weight tied convolutions to reduce memory usage and model complexity. With the help of these strategies, we are able to train a model with fewer parameters while maintaining the model capacity. Experiments demonstrate that LDGCNs outperform state-of-the-art models on two benchmark datasets for AMR-to-text generation with significantly fewer parameters.",197
" Neural machine translation  has achieved promising results with the use of various optimization tricks.  In spite of that, these techniques lead to increased training time and massive hyper-parameters, making the development of a well-performed system expensive.  As an alternative mitigation, curriculum learning~\citep[CL,][]{elman1993learning,bengio2009curriculum} has shown its effectiveness on speeding up the convergence and stabilizing the NMT model training.  CL teaches NMT model from easy examples to complex ones rather than equally considering all samples, where the keys lie in the definition of ``difficulty'' and the strategy of curricula design. Existing studies artificially determine data difficulty according to prior linguistic knowledge such as sentence length  and word rarity , and manually tune the learning schedule.  However, neither there exists a clear distinction between easy and hard examples, nor these human intuitions exactly conform to effective model training.  Instead, we resolve this problem by introducing self-paced learning, where the emphasis of learning can be dynamically determined by model itself rather than human intuitions. Specifically, our model measures the level of confidence on each training example, where an easy sample is actually the one of high confidence by the current trained model. Then, the confidence score is served as a factor to weight the loss of its corresponding example. In this way, the training process can be dynamically guided by model itself, refraining from human predefined patterns.   We evaluate our proposed method on IWSLT15 EnVi, WMT14 EnDe, as well as WMT17 ZhEn translation tasks. Experimental results reveal that our approach consistently yields better translation quality and faster convergence speed than Transformer baseline and recent models that exploit CL. Quantitative analyses further confirm that the intuitive curriculum schedule for a human does not fully cope with that for model learning.    In this paper, we presented the Multichannel Generative Language Model .  MGLM is a generative joint distribution model that marginalizes over all possible factorizations within and across channels. MGLM endows flexible inference, including unconditional, conditional, and partially observed generation.  We experimented with those inference modes using the Multi30K dataset containing English, French, Czech, and German. We provide qualitative samples sampled unconditionally from the generative joint distribution. We also quantitatively analyze the quality-diversity trade-offs and find MGLM outperform traditional bilingual discriminative models.  Our work focused on a specific instantiation of channels as languages.  However, MGLM is not limited to only languages and can generalize to other notions of channels.  In future work, we will consider other textual channels, such as paraphrases, premises and hypotheses, questions and answers, and multimodal channels, such as images. Another direction can investigate scaling MGLM to dozens/hundreds of channels. Fully generative models still often lag behind purely discriminative counterparts in performance, but we hope our work motivates future research on building generative joint distribution models of the world.     \color{black}                  File emnlp2020.tex      Based on the style files for ACL 2020, which were    Based on the style files for ACL 2018, NAACL 2018/19, which were    Based on the style files for ACL-2015, with some improvements     taken from the NAACL-2016 style    Based on the style files for ACL-2014, which were, in turn,    based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,    EACL-2009, IJCNLP-2008...    Based on the style files for EACL 2006 by    e.agirre@ehu.es or Sergi.Balari@uab.es    and that of ACL 08 by Joakim Nivre and Noah Smith  \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{emnlp2020} \usepackage{times} \usepackage{latexsym} \renewcommand{\UrlFont}hchan@cs.toronto.edu    This is not strictly necessary, and may be commented out,   but it will improve the layout of the manuscript,   and will typically save some space. \usepackage{microtype}  \usepackage{times} \usepackage{latexsym} \usepackage{url} \usepackage{times} \usepackage{latexsym} \usepackage{amsmath} \usepackage{amssymb} \usepackage{amsfonts} \usepackage{booktabs} \usepackage{enumitem} \usepackage{graphicx} \usepackage{hyperref} \usepackage{url} \usepackage{tikz} \usepackage{xcolor} \usepackage{pifont} \usepackage{placeins}   \usepackage[english, german, czech, french]{babel} \usepackage[utf8x]{inputenc} \usepackage{todonotes} \usepackage{wrapfig} \usepackage{natbib} \usepackage{subcaption} \usepackage{lipsum}   for dummy text only \usepackage{dblfloatfix}      To enable figures at the bottom of page \usepackage{float}   \setlength\titlebox{5cm}   You can expand the titlebox if you need extra space   to show all the authors. Please do not make the titlebox   smaller than 5cm ; we will check this   in the camera-ready version and ask you to change it back.  \newcommand\BibTeX{B\TeX} \newcommand{\blk}[1]{{#1}} \newcommand{\blu}[1]{{#1}} \newcommand{\ul}[1]{\underline{#1}} \newcommand{\gray}[1]{{\color{gray}#1}} \newcommand{\black}[1]{{\color{black}#1}} \newcommand{\xv}{\mathbf{x}} \newcommand{\yv}{\mathbf{y}} \newcommand{\wv}{\mathbf{w}} \newcommand{\ourmodel}{Multichannel Generative Language Model}  \newcommand{\ourtask}{multichannel generative language modeling} \newcommand{\modelabbv}{MGLM}   ULM MCM \DeclareMathOperator*{\argmax}{argmax}    Optional math commands from https://github.com/goodfeli/dlbook_notation.   \aclfinalcopy   Uncomment this line for the final submission \def\aclpaperid{3148}    Enter the acl Paper ID here   \setlength\titlebox{5cm}   You can expand the titlebox if you need extra space   to show all the authors. Please do not make the titlebox   smaller than 5cm ; we will check this   in the camera-ready version and ask you to change it back.    \newcommand\BibTeX{B\TeX}  \title{Multichannel Generative Language Model: \\ Learning All Possible Factorizations Within and Across Channels}  \author{Harris Chan\thanks{\;Work done during an internship at Google Brain.} \\   Vector Institute \\   University of Toronto \\   kiros@google.com \\\AND   Jamie Kiros \\   Google Research, Brain Team \\   williamchan@google.com \\\And   William Chan \\   Google Research, Brain Team \\   {\tt williamchan@google.com}} \date{}  \begin{document} \maketitle    
"," Recent studies have proven that the training of neural machine translation  can be facilitated by mimicking the learning process of humans. Nevertheless, achievements of such kind of curriculum learning rely on the quality of artificial schedule drawn up with the hand-crafted features, e.g. sentence length or word rarity. We ameliorate this procedure with a more flexible manner by proposing self-paced learning, where NMT model is allowed to 1) automatically quantify the learning confidence over training examples; and 2) flexibly govern its learning via regulating the loss in each iteration step.  Experimental results over multiple translation tasks demonstrate that the proposed model yields better performance than strong baselines and those models trained with human-designed curricula on both translation quality and convergence speed.\footnote{Our codes:  \href{https://github.com/NLP2CT/SPL_for_NMT}{https://github.com/NLP2CT/SPL\_for\_NMT}.}",198
" In recent years, cyberbullying has become one of the most pressing online risks among youth and raised serious concerns in society. Cyberbullying is commonly defined as the electronic transmission of insulting or embarrassing comments, photos or videos, as illustrated in Figure~ . Harmful bullying behavior can include posting rumors, threats, pejorative labels, and sexual remarks. Research from the American Psychological Association and the White House has revealed more than  of young people in the US indicate that they have been bullied on social media platforms~. Such a growing prevalence of cyberbullying on social media has detrimental societal effects, such as victims may experience lower self-esteem, increased suicidal ideation, and a variety of negative emotional responses~. Therefore, it has become critically important to be able to detect and prevent cyberbullying on social media. Research in computer science aimed at identifying, predicting, and ultimately preventing cyberbullying through better understanding the nature and key characteristics of online cyberbullying.     In the literature, existing efforts toward automatically detecting cyberbullying have primarily focused on textual analysis of user comments, including keywords~ and sentiments analysis ~. These studies attempt to build a generic binary classifier by taking high-dimensional text features as the input and make predictions accordingly. Despite their satisfactory detection performance in practice, these models largely overlooked temporal information of cyberbullying behaviors. They also ignore user interactions in social networks. Furthermore, the majority of these methods focus on detecting cyberbullying sessions effectively but cannot explain ``why'' a media session was detected as cyberbullying. Given a sequence of comments with user attributes, we think sequential learning can allow us to better exploit and model the evolution and correlations among individual comments. Besides, graph-based learning can enable us to represent and learn how users interact with each other in a session.   This work aims to detect cyberbullying by jointly exploring explainable information from user comments on social media. To this end, we build an explainable cyberbullying detection framework, \underline{HE}terogeneous \underline{N}eural \underline{I}nteraction \underline{N}etworks , through a coherent process. HENIN consists of three main components that learn various interactions among heterogeneous information displayed in social media sessions. A comment encoder is created to learn the representations of user comments through a hierarchical self-attention neural network so that the semantic and syntactic cues on cyberbullying can be captured. We create a post-comment co-attention mechanism to learn the interactions between a posted text and its comments. Moreover, two graph convolutional networks are leveraged to learn the latent representations depicting how sessions interact with one another in terms of users, and how posts are correlated with each other in terms of words.  Specifically, we address several challenges in this work:  how to perform explainable cyberbullying detection that can boost detection performance,  how to highlight explainable comments without the ground truth,  how to model the correlation between posted text and user comments, and  how to model the interactions between sessions in terms of users, and the interactions between textual posts in terms of words. Our solutions to these challenges result in a novel framework HENIN.   Our contributions are summarized as follows. %     In this paper, we propose a novel self-paced learning model for NMT in which the learning schedule is determined by model itself rather than being intuitively predefined by humans. Experimental results on three translation tasks verify the universal effectiveness of our approach. Quantitative analyses confirm that exploiting self-paced strategy presents a more flexible way to facilitate the model convergence than its CL counterparts. It is interesting to combine with other techniques to further improve NMT. Besides, as this idea is not limited to machine translation, it is also interesting to validate our model in other NLP tasks, such as low-resource NMT model training and neural architecture search.  
"," In the computational detection of cyberbullying, existing work largely focused on building generic classifiers that rely exclusively on text analysis of social media sessions. Despite their empirical success, we argue that a critical missing piece is the model explainability, i.e., why a particular piece of media session is detected as cyberbullying. In this paper, therefore, we propose a novel deep model, HEterogeneous Neural Interaction Networks , for explainable cyberbullying detection. HENIN contains the following components: a comment encoder, a post-comment co-attention sub-network, and session-session and post-post interaction extractors. Extensive experiments conducted on real datasets exhibit not only the promising performance of HENIN, but also highlight evidential comments so that one can understand why a media session is identified as cyberbullying.",199
"  \zc{ Title: need to be more concrete, something like ""Denoising Multi-Source Weak Supervision for Neural Text Classification"" will probably be better  Introduction:  Paragraph 1: many NLP tasks can be formulated as text classification  dnns are successful  but they require labeled data, which are expensive to obtain  recently, pre-trained language models can alleviate this problem, but still suffers degraded performance when labeled data is limited. \wendi{BERT still need labeled data}  Paragraph 2: weak supervision is promising, but also challenging to apply because weak labels are inaccurate and incomplete.  Paragraph 3: we study using multiple weak supervision sources to learn text classifiers; the intuition is multiple weak supervision sources can provide complementary information to eliminate noise; and combined with unlabeled data, they can address label incompleteness as well. \wendi{key: complementary information; bootstrapping on D_U}  Paragraph 4: there are a large body of works on weakly-supervised learning, most are dealing with only single-source weak supervision  they may suffer from the unreliability of single sources and error propagation; \wendi{sensitive to single source} several works deal with multiple sources, but they XXX , need to make sure we cite and discuss them).  Paragraph 5: introduce our method, the key idea, the uniqueness compared with existing methods. I feel the current method description is a bit plain, need to distill the main ideas. I think the main ideas are: - source reliability estimation and neural classification benefit each other  the co-training framework  \wendi{regularization} - conditional source reliability - self-training to leverage unmatched samples to obtain more labeled instances. - maybe also mention we rely on pre-trained language models to get good representations, which helps denoising  \wendi{high level: denoise, and how to enhance}  Other Sections: Section 2: make it at most half a page Section 3: 2.5 pages Section 4: 3 pages others: 1 page  Something we had better show in the experiments: - multi-source weak supervision can be powerful   for this, we already have a lot of results - majority voting does not work - our method works better than existing weak supervision methods  - what happens if we use some subsets of the multiple weak supervision sources - are there any interpretations about the source reliability we learned - how the different designs in our method work  - would labeled data help further }  Text classification, relation extraction, question answering are the fundamental natural language tasks with numerous applications such as document classification or knowledge extraction.  \zc{ Many NLP tasks can be formulated as text classification   problems, such as sentiment analysis, topic classification, relation   extraction, and XXX .} Recently, deep neural nets  have demonstrated superior performance for this problem \zc{briefly mention earlier dnns , to the recent trend of BERT-based ones}, largely due to their capabilities of automatically learning distributed features and fitting complex functions based on large-scale training data.   However, in many real world scenarios, large-scale labeled data are unavailable and manually annotating data at a large scale is prohibitively expensive. \zc{merge paragraph 1 and 2}  To address the label scarcity bottleneck, we study the problem of  using heuristic rules to train neural text classifiers.  While domain experts \zc{not   necessarily domain experts, can be also KBs.} often cannot afford to annotate millions of documents carefully, they can easily provide a set of heuristic rules as weak supervision signals.  Using such rules can automatically induce labeled data for model training , but meanwhile it introduces two major challenges: label noise and low label coverage. %The first challenge is label noise.   The label noise issue arises because heuristic rules are often too simple to capture the rich contexts and complex patterns for text classification. For instance, while a rule `expensive \ negative' for restaurant ranking is correct for most times, but sometimes it wrong because the delicious food deserves the high price. Seed rules have limited coverage because real-life text corpora often have long-tail distributions, many heuristic rules are defined over the most frequent keywords, so the instances containing only long-tail keywords cannot be covered by any given rules. \zc{can merge the previous paragraph and shorten it.}  There have been studies  that attempt to use weak supervision for deep text classification. Unfortunately, their performance is limited by the above two challenges. Ratner \etal  proposed a data programming method, which uses heuristic rules as labeling functions and then trains discriminative models using the automatically created labeled data. However, the training data annotated by data programming come from instances that can be directly matched by the rules, making the model have limited performance on the unmatched data.  Meng \etal  proposed a deep self-training method, which uses weak supervision to learn an initial model and then updates the model by using the model's own confident predictions. However, the self-training procedure can overfit the label noise and suffer from the error propagation.  \sep Our contributions. We propose a new method that uses weak supervision to train deep text classifiers in a label-efficient way, while addressing the label noise and label coverage issues. We assume multiple weak supervision sources  provide complementary sets of heuristic rules. \zc{the previous two sentences can be merged.} Our idea is that the complementary information in the multiple sources can not only reduce label noise, but also effectively bootstrap on unlabeled data to improve label coverage, making it possible to learn an accurate deep text classifier with weak supervision.   Motivated by the above, we propose a model with two carefully designed components. The first component is a rule-based classifier \zc{ rule reliability estimators} using the conditional soft attention mechanism. Given weak labels from annotators and document representations, we learn reliability scores for labeling sources, which emphasize the weak annotators' opinions that are most informative for our particular corpus. We then use the reliability scores to aggregate our disparate weak labels into a denoised pseudo label. \zc{need to highlight that our rule reliability is conditional on input text features}  The second component is a neural classifier that learns labels and distributed feature representations for all samples, matched and unmatched. This neural classifier is supervised by both the denoised labels and its own confident predictions on the unmatched data, enabling it to solve the rule coverage problem while simultaneously enhancing the rule denoiser via patterns present in the unmatched data.  The two components are integrated into a end-to-end training framework.  \zc{maybe we should also say we use pre-trained BERT as our feature extractor:   its representation power can help our denoiser work better.}  We evaluate our model on four text classification tasks, including sentiment analysis, topic classification, spam classification, and information extraction. The results on five benchmarks show that:  the soft-attention module can indeed effectively denoise the noisy training data induced from weak supervision sources, achieving \textasciitilde{}\% accuracy for denoising; and  the co-training design can improve prediction accuracy for unmatched samples, achieving at least \% accuracy increase on them. In terms of the overall performance, our model consistently outperforms state-of-the-art weakly supervised methods , semi-supervised methods , and fine-tuning methods   by 9.2\% on average. Further, we show that the denoised labels can be fed into fully supervised models and fine-tune the models to improve their performance.   % Our contributions are summarized as follows: %      %  =============================================== % Chao: I outline a structure for the intro, fill and extend these paragraphs!  % % Paragraph 1: Text classification is one of the most fundamental problems in text mining, information retrieval, and natural language processing. While deep neural nets % % have achieved dominant performance for text classification, they are highly label-hungry, often requiring hundreds of thousands of labeled samples to achieve strong performance.  This has become a key bottleneck of applying deep % % text classifiers to many real-life applications, where large-scale labeled data are too expensive to obtain.  % % Paragraph 2: An overview of existing methods for handling label sparsity. Including:  % % self-training methods, % % fine-tuning methods,  % % weakly supervised methods. Think hard about their drawbacks.  % % Paragraph 3: An overview of our model: we propose a deep neural text classifier, which is learned not from excessive labeled data, but only unlabeled data plus a set of easy-to-provide heuristic rules.  % % Paragraph 4: Two challenges of learning from rules: Learning the model from heuristic rules is difficult, because the rules can only induce noisy training data and can have limited coverage.  % % Paragraph 5: How we address the two challenges: % % First, it has a label denoising module, which estimates source reliability and denoises rule-induced supervision with a soft attention mechanism. Second, it has a self-learning module for improving the label coverage issue, which iteratively predicts soft labels for unmatched samples by aggregating the denoised multi-source classifiers. The two modules are integrated into a neural co-training model, which can be learned in an end-to-end manner.  % % Paragraph 6: The results we obtain on real data  % % A bullet list summarizing our contributions:  Cyberbullying detection on social media attracts growing attention in recent years. It is also crucial to understand why a media session is detected as cyberbullying. Thus we study the novel problem of explainable cyberbullying detection that aims at improving detection performance and highlighting explainable comments. We propose a novel deep learning-based model, HEterogeneous Neural Interaction Networks , to learn various feature representations from comment encodings, post-comment co-attention, and graph-based interactions between sessions and posts. Experimental results exhibit both promising performance and evidential explanation of HENIN. We also find that the learning of graph-based session-session and post-post interactions contributes most to the performance. Such results can encourage future studies to develop advanced graph neural networks in better representing the interactions between heterogeneous information. In addition, it is worthwhile to further model information propagation and temporal correlation of comments in the future.   
"," % While deep neural nets have achieved superior performance for % text classification, they highly rely on large-scale labeled data. Obtaining large-scale labeled data, however, is prohibitively % expensive in many applications.  We study the problem of learning neural text classifiers without using any labeled data, but only easy-to-provide rules as multiple weak supervision sources. This problem is challenging because rule-induced weak labels are often noisy and incomplete. To address these two challenges, we design a label denoiser, which estimates the source reliability using a conditional soft attention mechanism and then reduces label noise by aggregating rule-annotated weak labels. The denoised pseudo labels then supervise a neural classifier to predicts soft labels for unmatched samples, which address the rule coverage issue. % To address these challenges, we % propose an end-to-end model with two key components \zc{this sentence is not %   informative enough, need to deliver the key idea of our method in one sentence % here, and then use the remaining sentences to elaborate our idea.}. The first component is a % rule denoiser, which estimates conditional source reliability using a soft % attention mechanism and reduces label noise by aggregating rule-annotated weak % labels. The second is a neural classifier that predicts soft labels for % unmatchable samples to address the rule coverage issue. %The two components are integrated into a co-training framework, which can be trained end-to-end to mutually enhance each other. We evaluate our model on five benchmarks for sentiment, topic, and relation classifications. The results show that our model outperforms state-of-the-art weakly-supervised and semi-supervised methods consistently, and achieves comparable performance with fully-supervised methods even without any labeled data. Our code can be found at \url{https://github.com/weakrules/Denoise-multi-weak-sources}.",200
"  Systematic reviews are part of the field of evidence-based analysis, and are a methodology for conducting literature surveys, where the focus is on comprehensively summarising and synthesising existing research for the purpose of answering research questions . The aim of this process is to be very broad coverage to avoid unknown bias creeping into results via the alternative of cherry-picking scientific results . %As many relevant documents as possible should be included, and the process should also be thoroughly documented to aid replicability.  Conducting systematic reviews requires trained researchers with domain knowledge. The stages of the process are time-consuming, but vary in how much physical and mental labour they require . As a result, systematic reviews suffer from three primary challenges :  So though systematic reviews have been shown to be very effective and less prone to human biases , these issues often prove prohibitive. \\  However, these challenges are well suited to Machine Learning solutions, and there has recently been an increase in interest in applying NLP to this process . In this paper, we investigate the feasibility of implementing the multi-stage human process of a systematic review as a Machine Learning pipeline. We construct a systematic review pipeline which aims to assist researchers and organisations focusing on livestock health in various African countries who previously performed reviews manually . The pipeline begins with scraping for articles, then classifies them into whether or not to include in the review, then identifies data to extract and outputs a spreadsheet. We discuss the technical options we evaluated at each steps. Pipeline components are evaluated with intrinsic metrics as well as more pragmatic, extrinsic, considerations such as time and effort saved.  While previous work exists surveying the applicability of various Machine Learning methods and toolkits to the systematic review process  and a few apply them, there are no extant studies that implement a full system and analyse the trade-offs between different methods of training data creation, different annotation schemas, human expert hours needed to build a system, and final accuracy. We experiment with all of these factors, as well as with a few different architectures, with the aim of informing the planning and implementation of systematic review automation more broadly.    To further this goal, we particularly experiment with low resource scenarios and with generalisability. We investigate different thresholds for training data for the document classifier and different annotation schemas for the data extraction. We additionally test the ability of the system to generalise to documents from new countries.   % also talk about not needing deep learning resources  Key research questions are as follows: \paragraph{Extraction} Which techniques are best for identifying and extracting the desired information? \paragraph{Data Requirements} How much labelled training data is needed? Can existing resources be leveraged? \paragraph{Re-usability} How generalisable is a pipeline to new diseases and countries? \paragraph{Performance} What is the trade-off between pipeline accuracy and human time savings? \paragraph{Architecture \& Pre-training} How important is model architecture as applied to extraction tasks? How important is embedding pre-training, and how important is pre-training on scientific literature vs. general content ?\\  We find that surprisingly little training data  are necessary to get an accurate document classifier, and that it generalises well to unseen African countries , which enables systematic reviews to be expanded to new areas with essentially constant time. In our text extraction experiments, we find that both sentence and phrase level extraction models can each play a role in such a pipeline,  %given their complementary strengths and weaknesses on this kind of data,  but that phrase extraction, which has not previously been done for this task, performed better than expected both with baseline CNN models  and with BERT-based Transformers , with Transformers based on scientific pre-training  performing best. We demonstrate how the creation of labelled training data can be sped up through annotation tools, and that consideration should be given to the balance of training examples present within this data, since doing so may require less data overall while still maintaining good performance. Furthermore, besides automatic information extraction, much labour in constructing systematic reviews can be saved through simply automating the process of searching and downloading documents.   We empirically demonstrate that most of the three month pipeline of a systematic review can be automated to require very little human intervention, with acceptable accuracy of results. We release our code, annotation schema, and labelled data to assist in the expansion of systematic reviews via automation.  While we demonstrate this system on one domain, the framework is domain independent and could be applied to other kinds of systematic reviews. New training data and annotation schemes would be necessary to switch to medical or other domains, but our findings on time saving processes for annotation  would apply, and confidence thresholds that we implement are adjustable to customise to different levels of accuracy to human time trade-offs that are appropriate to different fields. Our exploration into necessary amounts of training data for accuracy and generalisability are broadly applicable.           \item Compositionality provides an explanation for why LSTMs learn long-range connections slowly and how LSTMs take advantage of linguistic structure.       \item Long-range connections build on predictable short range connections during training.       \item Familiar patterns attract new significance by encouraging interdependence, even at the cost of more general predictors.       \item Syntactically associated words have higher interdependence in English.  Using our proposed tool of Decompositional Interdependence, we illustrate how information exchanged between words aligns roughly with syntactic structure, indicating LSTMs compose meaning bottom-up. Synthetic experiments then illustrate that a memorized span intervening between a long distance dependency promotes early learning of the dependency rule, but fails to generalize to new domains, implying that these memorized spans are used as scaffolding in a bottom-up learning process.   This combination of behaviors is similar to a syntactic language model, suggesting that the LSTM's demonstrated inductive bias towards hierarchical structures is implicitly aligned with our understanding of language and emerges from its natural learning process.  
"," Systematic reviews, which entail the extraction of data from large numbers of scientific documents, are an ideal avenue for the application of machine learning. They are vital to many fields of science and philanthropy, but are very time-consuming and require experts. Yet the three main stages of a systematic review are easily done automatically: searching for documents can be done via APIs and scrapers, selection of relevant documents can be done via binary classification, and extraction of data can be done via sequence-labelling classification. Despite the promise of automation for this field, little research exists that examines the various ways to automate each of these tasks. We construct a pipeline that automates each of these aspects, and experiment with many human-time vs. system quality trade-offs. We test the ability of classifiers to work well on small amounts of data and to generalise to data from countries not represented in the training data. We test different types of data extraction with varying difficulty in annotation, and five different neural architectures to do the extraction. We find that we can get surprising accuracy and generalisability of the whole pipeline system with only 2 weeks of human-expert annotation, which is only 15\% of the time it takes to do the whole review manually and can be repeated and extended to new data with no additional effort.\footnote{\hspace{0.1cm}Code and links to models available at \url{https://github.com/seraphinatarrant/systematic_reviews}}",201
"   Although recent neural models of language have made advances in learning syntactic behavior, research continues to suggest that inductive bias plays a key role in data efficiency and human-like syntactic generalization . Based on the long-held observation that language exhibits hierarchical structure, previous work has proposed coupling recurrent neural networks  with differentiable stack data structures  to give them some of the computational power of pushdown automata , the class of automata that recognize context-free languages . However, previously proposed differentiable stack data structures only model deterministic stacks, which store only one version of the stack contents at a time, theoretically limiting the power of these stack RNNs to the deterministic~CFLs.  A sentence's syntactic structure often cannot be fully resolved until its conclusion , requiring a human listener to track multiple possibilities while hearing the sentence. Past work in psycholinguistics has suggested that models that keep multiple candidate parses in memory at once can explain human reading times better than models which assume harsher computational constraints. This ability also plays an important role in calculating expectations that facilitate more efficient language processing . Current neural language models do not track multiple parses, if they learn syntax generalizations at all .  We propose a new differentiable stack data structure that explicitly models a nondeterministic PDA, adapting an algorithm by \citet{lang:1974} and reformulating it in terms of tensor operations. The algorithm is able to represent an exponential number of stack configurations at once using cubic time and quadratic space complexity. As with existing stack RNN architectures, we combine this data structure with an RNN controller, and we call the resulting model a \ourmodel{} .  We predict that nondeterminism can help language processing in two ways. First, it will improve trainability, since all possible sequences of stack operations contribute to the objective function, not just the sequence used by the current model. Second, it will improve expressivity, as it is able to model concurrent parses in ways that a deterministic stack cannot. We demonstrate these claims by comparing the \om{} to deterministic stack RNNs on formal language modeling tasks of varying complexity. To show that nondeterminism aids training, we show that the \om{} achieves lower cross-entropy, in fewer parameter updates, on some deterministic CFLs. To show that nondeterminism improves expressivity, we show that the \om{} achieves lower cross-entropy on nondeterministic CFLs, including the ``hardest context-free language"" , a language which is at least as difficult to parse as any other CFL and inherently requires nondeterminism. Our code is available at \url{https://github.com/bdusell/nondeterministic-stack-rnn}.    We investigated the application of automation to all stages of the systematic review pipeline for our veterinary research case study. We found that with two weeks  of human expert annotation we can automate a systematic review that previously took 3 months, and still maintain high levels of accuracy. Our classification system generalises well, enabling it to be applied to new countries for additional systematic reviews with no additional human annotation cost. Sentence-based and phase-based data extraction both perform well, and the creation of phrase-based training data can still fit within a small amount of human annotation hours and avoids the need for extensive post-processing. Fine-tuned BERT-based Transformers perform best at data extraction, with BERT pre-trained on scientific data giving the largest boost in performance, though a baseline CNN still performs surprisingly well. In future work, we plan to test generalisability cross-lingually, expand the generalisability tests to extraction as well as classification, and study the performance improvements of continuous training of classifiers on human corrections of low-confidence output. 
"," We present a differentiable stack data structure that simultaneously and tractably encodes an exponential number of stack configurations, based on Lang闁炽儲鐛 algorithm for simulating nondeterministic pushdown automata. We call the combination of this data structure with a recurrent neural network  controller a \ourmodel. We compare our model against existing stack RNNs on various formal languages, demonstrating that our model converges more reliably to algorithmic behavior on deterministic tasks, and achieves lower cross-entropy on inherently nondeterministic tasks.",202
"   Cryptography has been used since antiquity to encode important secrets.  There are many unsolved ciphers of historical interest, residing in national libraries, private archives, and recent corpora collection projects .  Solving classical ciphers with automatic methods is a needed step in analyzing these materials.  In this work, we are concerned with automatic algorithms for solving a historically-common type of book code, in which word tokens are systematically replaced with numerical codes. Encoding and decoding are done with reference to a dictionary possessed by both sender and recipient.  While this type of code is common, automatic decipherment algorithms do not yet exist.  The contributions of our work are:       We implement and evaluate techniques to pronounce Chinese text in Mandarin, without the use of a pronunciation dictionary or parallel resource.  The EM method achieves a test-set accuracy of 71\ , while the vector-based method achieves 81\ .  By combining the two methods, we obtain 89\  accuracy, which significantly exceeds that of prior work.  We also demonstrate that current methods for unsupervised matching of vector spaces are sensitive to the structure of the spaces.  In the presence of one-to-many mappings between pinyin and characters,  the mapping accuracy is severely downgraded, leaving open an opportunity to design more robust unsupervised vector mapping systems.   
"," We solve difficult word-based substitution codes by constructing a decoding lattice and searching that lattice with a neural language model.  We apply our method to a set of enciphered letters exchanged between US Army General James Wilkinson and agents of the Spanish Crown in the late 1700s and early 1800s, obtained from the US Library of Congress.  We are able to decipher 75.1\% of the cipher-word tokens correctly.",203
"   Neural network language models , pretrained on vast amounts of raw text, have become  the dominant input to downstream tasks . Commonly, these tasks involve aspects of language  comprehension . One explicit example is coreference resolution, wherein anaphora  are linked to antecedents  requiring knowledge of syntax, semantics,  and world-knowledge to match human-like comprehension.   Recent work has suggested that LMs acquire abstract, often human-like, knowledge of syntax  \cite[e.g.,][]{gulordavaetal18, futrelletal2018, huetal2020-systematic}. Additionally, knowledge of grammatical and referential aspects linking a pronoun to its antecedent noun   have been demonstrated for both  transformer and long short-term memory architectures . Humans are able  to modulate both referential and syntactic comprehension  given abstract linguistic knowledge . Contrary to humans, we find that discourse structure  only influences LM behavior  for reference, not syntax, despite model representations that encode the necessary discourse information.  The particular discourse structure we examined is governed by implicit causality  verbs . Such verbs influence pronoun comprehension:  \ex.      \a. Sally frightened Mary because she was so terrifying.      \b. Sally feared Mary because she was so terrifying.   In , she agrees in gender with both Sally and Mary, so  both are possible antecedents. However, English speakers overwhelmingly  interpret she as referring to Sally in  and Mary  in , despite the semantic overlap between the verbs. Verbs that  have a subject preference  are called subject-biased IC verbs, and verbs with a object preference  are called object-biased IC verbs.   In addition to pronoun resolution, IC verbs also interact with relative clause  attachment:   \ex.      \a.  John babysits the children of the musician who...         \a.  ...lives in La Jolla.         \b.  ...are students at a private school.         \z.     \b.  John detests the children of the musician who...         \a.  ...lives in La Jolla.         \b.  ...are arrogant and rude.          \z.     \z.     \citep[from][]{rohdeetal2011}  In ,  and  are sentence fragments with possible  continuations modifying the musician in  and  and  continuations modifying the children in  and . We might expect  human continuation preferences to be the same in  and . However, the use  of an object-biased IC verb  in  increases the proportion of continuations given by human participants  that refer to the children . Without  an object-biased IC verb the majority of continuations refer to the more recent noun  .  Effects  of IC have received renewed interest in the field of psycholinguistics in recent years \cite[e.g.,][]{kehler2008coherence, ferstl2011implicit, hartshorne2013verb, hartshorne2014, williams_IC_2020}. Current accounts of IC claim that the phenomenon is inherently a linguistic process, which  does not rely on additional pragmatic inferences by comprehenders \cite[e.g.,][]{rohdeetal2011, hartshorne2013verb}. Thus, IC is argued to be contained within the linguistic signal, analogous to  evidence of syntactic agreement and verb argument structure within corpora. We  hypothesize that if these claims are correct, then current LMs will be able to  condition reference and syntactic attachment by  IC verbs with just language data .   We tested this hypothesis using unidirectional transformer and long short-term memory network \citep[LSTM;][]{hochreiterschmidhuber97} language models. We find that LSTM  LMs fail to acquire a subject/object-biased IC distinction that influences reference or RC attachment.   In contrast, transformers learned a representational  distinction between subject-biased and object-biased IC verbs that interacts  with both reference and RC attachment,  but the distinction only influenced model output for reference. The apparent failure of model  syntactic behavior to exhibit an IC  contrast that is present in model representations raises questions  about the broader capacity of LMs to display  human-like linguistic knowledge.     In this work, we show that it is possible to decipher a book-based cipher, using a known-plaintext attack and a neural English language model. We apply our method to letters written to and from US General James Wilkinson, and we recover 75.1\  of the word tokens correctly.    We believe word-based neural language models are a  powerful tool for decrypting classical codes and ciphers.  Because they have much lower perplexities than widely-used n-gram models, they can distinguish between candidate plaintexts that resemble English at a distance, versus candidate plaintexts that are grammatical, sensible, and relevant to the historical context.  
","  Language models  trained on large quantities of text have been claimed to acquire abstract linguistic representations. Our work tests the robustness of these abstractions by focusing on the ability of LMs to learn interactions between different linguistic representations. In particular, we utilized stimuli from psycholinguistic studies showing that humans can condition reference  and syntactic processing on the same discourse structure . We compared both transformer and long short-term memory LMs to find that, contrary to humans, implicit causality only influences LM behavior for reference, not syntax, despite model representations that encode the necessary discourse information. Our results further suggest that LM behavior can contradict not only learned representations of discourse but also syntactic agreement, pointing to shortcomings of standard language modeling.",204
" Word ordering often determines the meaning of a sentence; therefore how to utilize the position information of a word sequence has been an important topic in NLP and widely investigated recently. A common approach for modeling word ordering is to use recurrent neural networks , such as long short-term memory   or gated  recurrent unit  , which use a hidden state to represent the information of an ordered sequence and update model weights by backpropagation through time  ; thus the ordering information can be modeled by this structure.  However, RNN and BPTT are very inefficient in modern GPU computation due to the difficulty of parallelization with the time dependency. To solve this problem, recent work, such as convolutional seq2seq  and Transformers  which apply convolutional neural network   and self-attention respectively, succeed to eliminate the time dependency to take the computational advantage of GPU.  Instead of storing the information of ordered sequences, these models utilize the position information by using a feature-level positional encoding. For example, convolutional seq2seq proposed learnable position embeddings to represent the positions in a sequence.  Recently, various pre-trained Transformer language models keep breaking state-of-the-art results in numerous NLP tasks.  There are many different ways to pre-train a Transformer language model. For example, using an encoder, decoder, or the whole part of the Transformer, adapting the self-attention masks, or training with different objectives .  However, in terms of positional encoding, most work only used a learned position embedding which is originally proposed in convolutional seq2seq  without any analysis, even different objectives may learn completely different position information.  Motivated by the above observations, our goal is to investigate what position information the pre-trained Transformers could learn under different settings. We conduct a deep analysis of the learned position embeddings among three iconic pre-trained Transformer language models: BERT , RoBERTa  and GPT-2 . To examine the performance of different NLP types, we conduct the experiments on text classification, language modeling, and machine translation, and empirically analyze and explain the meaning and influence of position embeddings from different aspects.  The contributions of this paper are 3-fold:      The present study examined the extent to which  discourse structure, determined by implicit causality verbs,  could be acquired by  transformer and LSTM language models . Specifically, we evaluated, via comparison to human experiments, whether IC verb biases could influence reference and syntactic attachment in LMs. Analyses were conducted at two levels of granularity: model  behavior  and model representation . Given  the claims in recent literature that implicit causality arises without extra pragmatic inference on the part  of human comprehenders, we hypothesized that LMs  would be able to acquire such contrasts .   We found that LSTM LMs were unable to demonstrate  knowledge of IC either in influencing reference or syntax.  However, a  transformer  trained on the exact  same data as the LSTM LMs was able to partially represent an IC distinction, but model output was only influenced by IC bias when resolving reference, not syntactic attachment. In evaluating a transformer model trained on  vastly more data , we found a more robust, human-like sensitivity to IC bias when  resolving reference: subject-biased IC verbs  increased model preference for subject pronouns and object-biased IC verbs increased model preferences for object pronouns. However, the same mismatch as TransformerXL between model representation and model behavior  arose in processing syntactic attachment.   In contrast to our results,  \citet{davis-van-schijndel-2020b} showed syntactic predictions for LSTM LMs are influenced by some aspects of discourse structure. A simple explanation for these conflicting results may  be that the LMs we examined here are unable to learn the syntactic operation of attachment, and thus no influence of discourse can  surface. The erasure  of number agreement in the final layers of the transformer LMs  provides  compelling evidence towards this conclusion.\footnote{Further cross-linguistic evidence bearing on the inability of LSTM LMs, specifically, to learn relative clause attachment is given in \citet{davis-van-schijndel-2020-recurrent}.}   From a theoretical perspective, the present study provides additional support for the centering of  implicit causality within the linguistic signal proper.  That is, IC bias is learnable, to some degree,  without pragmatic inference as hypothesized in Section  \cite[see also][]{hartshorne2014}.  The mismatches  in syntactic representations and behavior suggest, however, that models ignore the abstract categories that are learned,  contrary to human findings \cite[cf.][]{rohdeetal2011}.   We believe a solution may lie in changing model  training objectives .  Psycholinguistic studies focusing on the interaction  of discourse and syntax have suggested that  coherence relations may be the unit of linguistic  prediction, in contrast to the next-word prediction  used in most language modeling work \cite[see][]{rohdeetal2011}. We leave to  future work an  investigation of this suggestion as well as  teasing apart the exact role that training data and  model architecture play in the interaction  between types of linguistic representation.    \section*{Acknowledgments} Thank you to members of the C.Psyd lab at Cornell, who gave feedback on an earlier form of this work. We would also like to thank the three anonymous reviewers for their comments and suggestions.       \section{Stereotypically gendered nouns used in referential experiments}                          
"," In recent years, pre-trained Transformers have dominated the majority of NLP benchmark tasks.  Many variants of pre-trained Transformers have kept breaking out, and most focus on designing different pre-training objectives or variants of self-attention.  Embedding the position information in the self-attention mechanism is also an indispensable factor in Transformers however is often discussed at will.  Therefore, this paper carries out an empirical study on position embeddings of mainstream pre-trained Transformers, which mainly focuses on two questions: 1) Do position embeddings really learn the meaning of positions? 2) How do these different learned position embeddings affect Transformers for NLP tasks?  This paper focuses on providing a new insight of pre-trained position embeddings through feature-level analysis and empirical experiments on most of iconic NLP tasks. It is believed that our experimental results can guide the future work to choose the suitable positional encoding function for specific tasks given the application property.\footnote{The source code is available at: \url{https://github.com/MiuLab/PE-Study}} %to make our study more convincing.",205
"  Autoregressive sequence to sequence  models such as Transformers  are trained to maximize the log-likelihood of the target sequence, conditioned on the input sequence. Furthermore, approximate inference  is typically done using the beam search algorithm , which allows for a controlled exploration of the exponential search space. However, seq2seq models  suffer from a discrepancy between token level classification during learning and sequence level inference during search. This discrepancy also manifests itself in the form of the curse of sentence length i.e. the models' proclivity to generate shorter sentences during inference, which has received considerable attention in the literature .  In this work, we focus on how to better model long-tailed phenomena, i.e. predicting the long-tail of low-frequency words/tokens , in seq2seq models, on the task of Neural Machine Translation . Essentially, there are two mechanisms by which tokens with low frequency receive lower probabilities during prediction: firstly, the norms of the embeddings of low frequency tokens are smaller, which means that during the dot-product based softmax operation to generate a probability distribution over the vocabulary, they receive less probability. This has been well known in Image Classification  and Neural Language Models . Since NMT shares the same dot-product softmax operation, we observe that the same phenomenon holds true for NMT as well. For example, we observe a Spearman閳ユ獨 Rank Correlation of 0.43 between the norms of the token embeddings and their frequency, when a standard transformer model is trained on the IWSLT-14 De-En dataset . Secondly, for transformer based NMT, the embeddings for low frequency tokens lie in a different subregion of space than semantically similar high frequency tokens, due to the different rates of updates , thereby, making rare words token embeddings ineffective. Since these token embeddings have to match to the context vector for getting next-token probabilities, the dot-product similarity score is lower for low frequency tokens, even when they are semantically similar to the high frequency tokens.   Further, better modeling long-tailed phenomena has significant implications for several text generation tasks, as well as for compositional generalization . To this end, we primarily ask and seek answers to the following two fundamental questions in the context of NMT: By exploring these questions, we arrive at the conclusion that the widely used cross-entropy  loss limits NMT models' expressivity during inference and propose a new loss function to better incorporate the inductive biases of beam search.    This paper investigates the implicit meaning of pre-trained Transformer position embeddings. Transformer encoders learn the local position information that can only be effective in masked language modeling. On the other hand, the Transformer decoders for autoregressive language modeling actually learn about absolute positions.  The empirical experiments on the pre-trained position embeddings validate our hypothesis. We also show that different NLP tasks with different model architectures and different training objectives may utilize the position information in different ways. As a result, it is believed that this study will benefit future work about choosing suitable positional encoding functions or designing other modeling methods for position information in the target NLP tasks based on their properties.  
"," State-of-the-art Neural Machine Translation  models struggle with generating low-frequency tokens, tackling which remains a major challenge. The analysis of long-tailed phenomena in the context of structured prediction tasks is further hindered by the added complexities of search during inference. In this work, we quantitatively characterize such long-tailed phenomena at two levels of abstraction, namely, token classification and sequence generation. We propose a new loss function, the Anti-Focal loss, to better adapt model training to the structural dependencies of conditional text generation by incorporating the inductive biases of beam search in the training process. We show the efficacy of the proposed technique on a number of Machine Translation  datasets, demonstrating that it leads to significant gains over cross-entropy across different language pairs, especially on the generation of low-frequency words. We have released the code to reproduce our results.\blfootnote{The first author is now a researcher at Microsoft, USA.}\footnote{\url{https://github.com/vyraun/long-tailed}} %",206
" Grammar induction is the task of learning the grammar of a target corpus without exposure to the parsing ground truth or any expert-labeled tree structures . Recently emerging latent tree learning models provide a new approach to this problem . They learn syntactic parsing under only indirect supervision from their main training tasks such as language modelling and natural language inference.  In this study, we analyze ON-LSTM , a new latent tree learning model that set the state of the art on unsupervised constituency parsing on WSJ test  when it was published at ICLR 2019. The model is trained on language modelling and can generate binary constituency parsing trees of input sentences like the one in Figure .     As far as we know, though there is an excellent theoretical analysis paper  of the ON-LSTM model that focuses on the model's architecture and its parsing algorithm, there is no systematic analysis of the parses the model generates. There are no in-depth investigations of  whether the model's parsing behavior is consistent among different restarts or  how the parses it produces are different from PTB gold standards. Answering these questions is crucial for a better understanding of the capability of the model and may bring insights into how to build more advanced latent tree learning models in the future.  Therefore, we replicate the model with 5 random restarts and look into the parses it generates. We find that  ON-LSTM has fairly consistent parsing behaviors across different restarts, achieving a self F1 of 65.7 on WSJ test.  The model struggles to correctly parse the internal structures of complex noun phrases.  The model has a consistent tendency to overestimate the height of the split points right before verbs or auxiliary verbs, leading to a major difference between its parses and the Penn Treebank gold-standard parses. We speculate that both problems can be explained by the training task, unidirectional language modelling, and thus we hypothesize that training a bidirectional model on a more syntax-related task like acceptability judgement might be a good choice for future latent tree learning models.       In this work, we characterized the long-tailed phenomena in NMT and demonstrated that NMT models aren't able to effectively generate low-frequency tokens in the output. We proposed a new loss function, the Anti-Focal loss, to incorporate the inductive biases of beam search into the NMT training process. We conducted comprehensive evaluations on 9 language pairs with different amounts of training data from the IWSLT and TED corpora. Our proposed technique leads to gains across a range of metrics, improving long-tailed NMT at both the token as well as at the sequence level. In future, we wish to explore its connections to entropy regularization and model calibration and whether we can fully encode the inductive biases of label smoothing in the loss function itself.  
"," Recent latent tree learning models can learn constituency parsing without any exposure to human-annotated tree structures. One such model is ON-LSTM \citep{ONLSTMShen}, which is trained on language modelling and has near-state-of-the-art performance on unsupervised parsing. In order to better understand the  performance and consistency of the model as well as how the parses it generates are different from gold-standard PTB parses, we replicate the model with different restarts and examine their parses. We find that  the model has reasonably consistent parsing behaviors across different restarts,  the model struggles with the internal structures of complex noun phrases,  the model has a tendency to overestimate the height of the split points right before verbs. We speculate that both problems could potentially be solved by adopting a different training task other than unidirectional language modelling.",207
" Deep learning has become the dominant approach to address most Natural Language Processing  tasks, including text classification. With sufficient and high-quality training data, deep learning models can perform incredibly well . However, in real-world cases, such ideal datasets are scarce. Often times, the available datasets are small,  full of regular but irrelevant words, and contain unintended biases . These can lead to suboptimal models with undesirable properties. For example, the models may have biases against some sub-populations or may not work effectively in the wild as they overfit the imperfect training data.  To improve the models, previous work has looked into different techniques beyond standard model fitting. If the weaknesses of the training datasets or the models are anticipated, strategies can be tailored to mitigate such weaknesses. For example, augmenting the training data with gender-swapped input texts helps reduce gender bias in the models . Adversarial training can prevent the models from exploiting irrelevant and/or protected features . With a limited number of training examples, using human rationales or prior knowledge together with training labels can help the models perform better .  Nonetheless, there are side-effects of sub-optimal datasets that cannot be predicted and are only found after training thanks to post-hoc error analysis. To rectify such problems, there have been attempts to enable humans to fix the trained models  . Since the models are usually too complex to understand, manually modifying the model parameters is not possible. Existing techniques, therefore, allow humans to provide feedback on individual predictions instead. Then, additional training examples are created based on the feedback to retrain the models.  However, such local improvements for individual predictions could add up to inferior overall performance . Furthermore, these existing techniques allow us to rectify only errors related to examples at hand but provide no way to fix problems kept hidden in the model parameters.   In this paper, we propose a framework which allows humans to debug and improve deep text classifiers by disabling hidden features which are irrelevant to the classification task. We name this framework FIND . FIND exploits an explanation method, namely layer-wise relevance propagation  , to understand the behavior of a classifier when it predicts each training instance. Then it aggregates all the information using word clouds to create a global visual picture of the model. This enables humans to comprehend the features automatically learned by the deep classifier and then decide to disable some features that could undermine the prediction accuracy during testing. The main differences between our work and existing work are:   first, FIND leverages human feedback on the model components, not the individual predictions, to perform debugging;   second, FIND targets deep text classifiers which are more convoluted than traditional classifiers used in existing work .   We conducted three human experiments  to demonstrate the usefulness of FIND.  For all the experiments, we used as classifiers convolutional neural networks  ,  which are a popular, well-performing architecture for many text classification tasks including the tasks we experimented with . The overall results show that FIND with human-in-the-loop can improve the text classifiers and mitigate the said problems in the datasets.  After the experiments, we discuss the generalization of the proposed framework to other tasks and models. Overall, the {\bf main contributions} of this paper are:   The rest of this paper is organized as follows.  Section  explains related work about analyzing, explaining, and human-debugging text classifiers.  Section  proposes FIND, our debugging framework.  Section  explains the experimental setup followed by the three human experiments in Section  to . Finally, Section  discusses generalization of the framework and concludes the paper. Code and datasets of this paper are available at \url{https://github.com/plkumjorn/FIND}.    In summary, the model shows basic self-consistency on the task of constituency parsing, and it is consistently able to correctly identify certain constituents . All these results show that the unique design of the model brings us closer to developing consistently powerful unsupervised parsing models. However, the experiments show that it  struggles with the internal structures of complex NPs, and  often overestimates the height of the split points right before verbs. Based on our analysis, we hypothesize that both of the failures can be at least partially attributed to the use of unidirectional language modelling as the training task.   There are two potential problems with this training task. First, the motivation of language modelling generally does not perfectly match the target task constituency parsing, since cross-constituent hints are sometimes helpful, as revealed by . Second, it is very hard for a unidirectional model to correctly identify some high-level constituents, as revealed by . Therefore, we believe a promising research direction is to build latent tree learning models based on bidirectional model architectures like transformer  and the task of acceptability judgement with a dataset like CoLA , which is a more syntax-related sentence-level task that requires the model to predict whether an input sentence is grammatically acceptable. Another option to consider is masked language modelling because it is also a bidirectional task and is much easier to scale up compared to acceptability judgement since it is a self-supervised task.    
"," Since obtaining a perfect training dataset  is hardly possible, many real-world text classifiers are trained on the available, yet imperfect, datasets.  These classifiers are thus likely to have undesirable properties. For instance, they may have biases against some sub-populations or may not work effectively in the wild due to overfitting.  In this paper, we propose FIND -- a framework which enables humans to debug deep learning text classifiers by disabling irrelevant hidden features. Experiments show that by using FIND, humans can improve CNN text classifiers which were trained under different types of imperfect datasets .",208
" % Neural dependency parsers  predicts the relations and interactions between words equipped with nerual networks.  Graph-based dependency parsing is a popular approach to dependency parsing that scores parse components of a sentence and then finds the highest scoring tree through inference. First-order graph-based dependency parsing takes individual dependency edges as the components of a parse tree, while higher-order dependency parsing considers more complex components consisting of multiple edges. There exist both exact inference algorithms  and approximate inference algorithms  to find the best parse tree. %Neural network based dependency parsers become popular due to its high efficiency and accuracy. Transition-based dependency parsing  builds the dependency trees by making a series of decisions on a sequence of words, and graph-based dependency parser  first encodes all words in a sentence using bi-directional LSTM and score components in parse tree and find the highest scoring tree through inference. Recent work focused on neural network based graph dependency parsers . \citet{dozat2016deep} proposed a first-order graph-based neural dependency parsing approach with a simple head-selection training objective. It uses a biaffine function to score dependency edges and has high efficiency and good performance. Subsequent work introduced second-order inference into their parser. \citet{ji-etal-2019-graph} proposed a graph neural network that captures second-order information in token representations, which are then used for first-order parsing. Very recently, \citet{zhang2020efficient} proposed an efficient second-order tree CRF model for dependency parsing and achieved state-of-the-art performance. %Higher-order dependency parsing takes more complex higher-order components like siblings and grandparents into consideration in decoding phase  and uses algorithms like dynamic programming for exact inference. Such kind of higher-order components increases the global information in inference and results in improvements in parsing accuracy, but they also make inference slower and more complicated. Recent work on graph-based higher-order dependency parsing and semantic dependency parsing  focused on approximate inference on the graph,  , which is much faster and with minor performance reduction compared to the exact inference algorithm.   % \citet{falenska-kuhn-2019-non} also showed that adding second-order inference to BiLSTM-based parser leads to very small improvements. \citet{wang-etal-2019-second} proposed a second-order approach to semantic dependency parsing  , which does not have the tree constraint in syntactic dependency parsing. They employed an end-to-end neural network derived from message-passing algorithms for approximate second-order parsing and achieved state-of-the-art accuracies in SDP.  In this paper, we first show how a previously proposed second-order semantic dependency parser  can be applied to syntactic dependency parsing with simple modifications. The parser is an end-to-end neural network derived from message passing inference on a conditional random field that encodes the second-order parsing problem. We then propose an alternative conditional random field that incorporates the head-selection constraint of syntactic dependency parsing, and derive a novel second-order dependency parser. We empirically compare the two second-order approaches and the first-order baselines on English Penn Tree Bank 3.0 , Chinese Penn Tree Bank 5.1  and datasets of 12 languages in Universal Dependencies . We show that our approaches achieve state-of-the-art performance on both PTB and CTB and our approaches are significantly faster than recently proposed second-order parsers.   We also make two interesting observations from our empirical study. First, it is a common belief that contextual word embeddings such as ELMo  and BERT  already conveys sufficient high-order information that renders high-order parsing less useful, but we find that second-order decoding is still helpful even with strong contextual embeddings like BERT. Second, while \citet{zhang-etal-2019-empirical} previously found that incoperating the head-selection constraint is helpful in first-order parsing, we find that with a better loss function design and hyper-parameter tuning both first- and second-order parsers without the head-selection constraint can match the accuracy of parsers with the head-selection constraint and can even outperform the latter when using BERT embedding.  Our approaches are closely related to the work of \citet{gormley-etal-2015-approximation}, which proposed a non-neural second-order parser based on Loopy Belief Propagation . Our work differs from theirs in that: 1) we use Mean Field Variational Inference  instead of LBP, which \citet{wang-etal-2019-second} found is faster and equally accurate in practice; 2) we add the head-selection constraint and do not include the global tree constraint that is shown to produce only slight improvement  but would complicate our neural network design and implementation; 3) we employ modern neural encoders and achieve much better parsing accuracy. Our approaches are also closely related to the very recent work of \citet{turbo2020}. The main difference is that we use MFVI while they use the dual decomposition algorithm   for approximate inference.  % In recent work on semantic dependency parsing  , \citet{wang-etal-2019-second} proposed a second-order parser following the first-order parser of \citet{dozat-manning-2018-simpler}. % %encodes the first-order score following \citet{dozat-manning-2018-simpler} with biaffine functions and the second-order score by trilinear functions.  % They used Mean Field Variational Inference  or Loopy Belief Propagation  algorithm to pass messages on a Conditional Random Field  and trained in an end-to-end manner. The approach on SDP sees the existence of every single edge as a binary classification problem and it can also be applied in the tree-based dependency parsing. \citet{zhang-etal-2019-empirical} compared different structured outputs in dependency parsing and they showed that in first-order dependency parsing, the head constraint of \citet{dozat2016deep} is stronger than the binary classification structure of \citet{dozat-manning-2018-simpler} in dependency parsing.  % In this paper, we adopt the message passing method of MFVI on dependency parsing and we additionally add a Local head constraint in second-order inference procedure, which views the problem as a head-selection classification problem. We investigate the advantage of the Single and Local structured output for second-order parsers and show that the second-order parsers achieve state-of-the-art performance on both PTB and CTB. Both the second-order parsers with Local or Single structured outputs can outperform the first-order parser of \citet{dozat2016deep} and have an improvement with BERT embeddings. Compared with the approach of \citet{ji-etal-2019-graph} that decodes second-order information through passing token features on a graph neural network, the second-order parsers with message passing are more interpretive as we follow most of previous higher-order approaches  that assigns scores for each components. \citet{gormley-etal-2015-approximation} proposed a second-order parser with Single structured output with tree constraint on dependency parsing using LBP. Compared with their approach, we consider the Local head constraint. We use the MFVI algorithm which is faster in practice, and we don't need the time-consuming Inside-Outside algorithm to keep the tree structure in training. Furthermore, we don't compare a structured output with the tree constraint in the second-order parser because in the empirical investigation of \citet{zhang-etal-2019-empirical}, the tree constraint only gives modest improvement compared with the first-order Local approach. We believe the advantage of the tree constraint will be further diminished as the second-order parser considers more tree components. %          In this paper, we propose a novel two-stage pipeline approach Loire to learn commonsense from images. In the first stage, a text representation model ViBERT is trained in the bi-modal sequence-to-sequence approach for scene layout generation on COCO. Therefore, visual commonsense knowledge like spatial relations will be encoded in ViBERT by the supervision of caption and image layout. After that, ViBERT is concatenated with a pre-trained language model to perform a knowledge-augmented reasoning process. Experimental results show that Loire outperforms the current state-of-the-art language models BERT and RoBERTa on two NLP commonsense reasoning tasks, i.e.~commonsense question answering data CommonsenseQA and pronoun resolution data WinoGrande. The ablation and case study further show that the improvements are truly owing to the learned visual commonsense knowledge, and how this knowledge helps the NLP reasoning process.  The current approach is a preliminary study on the proposed direction of using images to automatically learn commonsense knowledge to facilitate the NLP reasoning tasks, which could be modified from the following aspects to further improve the empirical performances. Firstly, larger bi-modal data could be employed to learn more commonsense required in the reasoning task. Secondly, other bi-modal methods instead of training ViBERT by the supervision of scene layout generation may be investigated. Thirdly, how to design intrinsic evaluation to help to understand what is learned by Lorie is still challenging and will be considered in the future.   
"," In this paper, we propose second-order graph-based neural dependency parsing using message passing and end-to-end neural networks. We empirically show that our approaches match the accuracy of very recent state-of-the-art second-order graph-based neural dependency parsers and have significantly faster speed in both training and testing. We also empirically show the advantage of second-order parsing over first-order parsing and observe that the usefulness of the head-selection structured constraint vanishes when using BERT embedding. %We adapt a previous approach that predicts dependency edges independently and we also propose a new approach that incorporates the head-selection structural constraint.",209
"  Our SJTU-NICT team participated in the WMT20 shared task, including supervised track, unsupervised, and low-resource track. During the participation, we placed our attention on Polish   English  and English   Chinese  on the supervised track, while on the unsupervised and low-resource track, the German   Upper Sorbian  both directions are focused.  Our  baseline system in supervised track is based on the Transformer big architecture proposed by \citet{vaswani2017attention}, in which its open-source implementation version Fairseq  is adopted. In the unsupervised and low-resource track, we draw on the successful experience of the XLM framework , and used the two-stage training mode of masked language modeling  pre-training + back-translation  finetune to obtain a very strong baseline performance. Marian  toolkit is utilized for training the decoder in reranking using machine translation targets instead of common GPT-style language modeling targets.  In order to better play the role of WMT evaluation in polishing the methods proposed or improved by our team , we divided the three language pairs we participated in into three categories:   %  In the supervised PLEN translation direction, we based on the XLM framework to pre-train a Polish language model using common crawl and news crawl monolingual data, and proposed the XLM enhanced NMT model inspired from the idea of incorporating BERT into NMT . Besides, we trained a bidirectional translation model of EN-PL based on the parallel corpus and further finetuned it to the PLEN direction.  In the supervised ENZH translation with document information, we propose a document enhanced NMT model based on Longformer . The training of our proposed document enhanced NMT model is split into three stages.  In the first stage, we pre-train the Longformer document encoder with MLM target on the document text in Wikipedia dumps, UN News, and News Commentary monolingual corpus. A conventional Transformer-big NMT model is trained in the second stage. In the final stage, the Longformer encoder and conventional Transformer big NMT model are used to initialize the full document-enhanced NMT model parameters, in which the Longformer encoder is adopted to extract representations for the document of an input sequence, and then the document representations are fused with each layer of the encoder and decoder of the NMT model through attention mechanisms.   In the unsupervised machine translation track on DE-HSB, we experimented with the reference language based UNMT   framework we proposed recently. Under this framework, we choose English as the reference language, and use the Europarl parallel corpus of EN-DE to enhance the unsupervised machine translation between DE and HSB. Specifically, we adopted reference language translation , reference language back-translation , and cross-lingual back-translation  three training targets with the help of the cross-lingual agreement provided by the EN-DE parallel corpus to enhance the unsupervised translation performance.  Due to the introduction of more explicit supervision signals brought by parallel corpus in the low-resource machine translation track on DE-HSB, we discarded the use of the weaker agreement provided by the reference language,  conducted joint training on the unsupervised back-translation and the supervised translation directly, and introduced BT-BLEU based collaborative filtering technology for further self-training. In addition, inspired by our previous work , we also use MLM and translation language modeling  to continue pre-training the model while machine translation training.  In addition, in all basic NMT models, we empower the training process with our proposed data-dependent gaussian prior objective  , so that the model can maintain the diversity of the output. When the main model training is finished, the TF-IDF algorithm is employed to filter the training set according to the input of the test set, a training subset whose domain is more similar to the test set is obtained, and then used to finetune the model for reducing the performance degradation caused by domain inconsistency. For the final submission, an ensemble of several different trained models outputs the -best predictions, and used the decoder trained with Marian toolkit to performs reranking to get the final system output.    We propose second-order graph-based dependency parsing based on message passing and end-to-end neural networks. We modify a previous approach that predicts dependency edges independently and also design a new approach that incorporates the head-selection structured constraint. Our experiments show that our second-order approaches have better overall performance than the first-order baselines; they achieve competitive accuracy with very recent start-of-the-art second-order graph-based parsers and are significantly faster. Our empirical comparisons also show that second-order decoders still outperform first-order decoders even with BERT embeddings, and that the usefulness of the head-selection constraint is limited, especially when using BERT embeddings. Our code is publicly avilable at .  
","  In this paper, we introduced our joint team SJTU-NICT 's participation in the WMT 2020 machine translation shared task. In this shared task, we participated in four translation directions of three language pairs: English-Chinese, English-Polish on supervised machine translation track, German-Upper Sorbian on low-resource and unsupervised machine translation tracks. Based on different conditions of language pairs, we have experimented with diverse neural machine translation  techniques: document-enhanced NMT, XLM pre-trained language model enhanced NMT, bidirectional translation as a pre-training, reference language based UNMT,  data-dependent gaussian prior objective, and BT-BLEU collaborative filtering self-training. We also used the TF-IDF algorithm to filter the training set to obtain a domain more similar set with the test set for finetuning. In our submissions, the primary systems won the first place on English to Chinese, Polish to English, and German to Upper Sorbian translation directions.",210
"     Neural summarizers have achieved impressive performance when evaluated by ROUGE ~ on in-domain setting, and the recent success of pre-trained models drives the state-of-the-art results on benchmarks to a new level ~. However, the superior performance is not a guarantee of a perfect system since exsiting models tend to show defects when evaluated from other aspects. For example, \citet{zhang-etal-2018-abstractiveness} observes that many abstractive systems tend to be near-extractive in practice. \citet{cao2018faithful,wang2020asking,kryscinski2019evaluating,maynez2020faithfulness,durmus2020feqa} reveal that most generated summaries are factually incorrect. These non-mainstream evaluation methods make it easier to identify the model's weaknesses.  Orthogonal to above two evaluation aspects, we aim to diagnose the limitation of existing systems under cross-dataset evaluation, in which a summarization system trained on  one corpus would be evaluated on a range of out-of-dataset corpora. Instead of evaluating the quality of summarizers solely based on one dataset or multiple datasets individually, cross-dataset evaluation enables us to evaluate model performance from a  different angle. For example, Fig. shows the ranking of  summarization systems studied in this paper under different  evaluation metrics, in which the ranking list `` in-dataset R2'' is obtained by traditional ranking criteria while other two are based on our designed cross-dataset measures. Intuitively, we observe that 1) there are different definitions of a ``good'' system in various evaluation aspects; 2) abstractive and extractive systems exhibit diverse behaviors when evaluated under the cross-dataset setting.    The above example recaps the general motivation of this work, encouraging us to rethink the generalization ability of current top-scoring summarization systems from the perspective of cross-dataset evaluation. Specifically, we ask two questions as follows:   Q1: {How do different neural architectures of summarizers influence the cross-dataset generalization performances?} When designing summarization systems, a plethora of neural components can be adopted ~. For example, will copy  and coverage   mechanisms improve the cross-dataset generalization ability of summarizers? Is there a risk that BERT-based summarizers will perform worse when adapted to new areas compared with the ones without BERT? So far, the generalization ability of current summarization systems when transferring to new datasets still remains unclear, which poses a significant challenge to design a reliable system in realistic scenarios. Thus, in this work, we take a closer look at the effect of model architectures on cross-dataset generalization setting.    Q2: {Do different generation ways  of summarizers influence the cross-dataset generalization ability?} Extractive and abstractive models, as two typical ways to summarize texts, usually follow diverse learning frameworks and favor different datasets.  It would be absorbing to know their discrepancy from the perspective of cross-dataset generalization.      To answer the questions above, we have conducted a comprehensive experimental analysis, which involves eleven summarization systems , five benchmark datasets from different domains, and two evaluation aspects. Tab. illustrates the overall analysis framework. We explore the effect of different architectures and generation ways on model generalization ability in order to answer Q1 and Q2. Semantic equivalency  and factuality are adopted to characterize the different aspects of cross-dataset generalization ability. Additionally, we strengthen our analysis by presenting two views of evaluation: holistic and fine-grained views .   }%        % \end{table}%  Our contributions can be summarized as: 1) Cross-dataset evaluation is orthogonal to other evaluation aspects , which can be used to re-evaluate current summarization systems, accelerating the creation of more robust summarization systems. 2) We have design two measures Stiffness and Stableness, which could help us to characterize generalization ability in different views, encouraging us to diagnose the weaknesses of state-of-the-art systems.  3) We conduct dataset bias-aided analysis  and suggest that a better understanding of datasets will be helpful for us to interpret systems'  behaviours.        This paper describes SJTU-NICT's submission to the WMT20 news translation task. For three typical scenarios, we adopt different strategies. In this work, we not only study the pre-trained language model to enhance MT, but also consider the impact of document information on translation. We considered both the way of converting document alignment into sentence alignment and the use of BERT's NSP to recover the structure of documents. In addition, transfer learning from supervision is taken into account in unsupervised translation, and various means are used to enhance low-resource translation. Our systems performed strongly among all the constrained submissions: we ranked 1st in PLEN, ENZH, and DEHSB respectively, and stayed Top-3 for the HSBDE.  
"," Neural network-based models augmented with unsupervised pre-trained knowledge have achieved impressive performance on text summarization. However, most existing evaluation methods are limited to an in-domain setting, where summarizers are trained and evaluated on the same dataset. We argue that this approach can narrow our understanding of the generalization ability for different summarization systems. In this paper, we perform an in-depth analysis of characteristics of different datasets and investigate the performance of different summarization models under a cross-dataset setting, in which a summarizer trained on one corpus will be evaluated on a range of out-of-domain corpora. A comprehensive study of 11 representative summarization systems on 5 datasets from different domains reveals the effect of model architectures and generation ways  on model generalization ability. Further, experimental results shed light on the limitations of existing summarizers. Brief introduction and supplementary code can be found in \url{https://github.com/zide05/CDEvalSumm}.",211
"    As robots are deployed in collaborative applications like healthcare and household assistance , there is a growing need for reliable human-robot communication. One such communication modality that is both user-friendly and versatile is natural language; to this end, we focus on robust natural language interfaces  that can map utterances to executable behavior .  Most existing work on NLIs  falls into a static train-then-deploy paradigm: models are first trained on large datasets of  pairs and then deployed, with the hope they will reliably generalize to new utterances. Yet, what happens when such models make mistakes or are faced with types of utterances unseen at training --- for example, providing a household robot with a novel utterance like ``wash the coffee mug?'' Such static systems will fail with no way to recover, burdening the user to find alternate utterances to accomplish the task . Instead, we argue that NLIs need to be dynamic and adaptive, learning interactively from user feedback to index and perform more complicated behaviors.   In this work, we explore building NLIs for simulated robotics that learn from real humans. Inspired by \citet{wang2017naturalizing}, we leverage the idea of learning from decomposition to learn new abstractions. Just like how a human interactively teaches a new task to a friend by breaking it down, users interactively teach our system by simplifying utterances that the system cannot understand  into lower-level utterances that it can .  To map language to executable behavior, \citet{wang2017naturalizing} and \citet{thomason2019improving} built adaptive NLIs that leverage grammar-based parsers that allow reliable one-shot generalization but lack lexical flexibility. For example, a grammar-based system that understands how to ``wash the coffee mug'' may not generalize to ``clean the mug.'' Meanwhile, recent semantic parsers are based primarily on neural sequence-to-sequence models . While these models excel from a lexical flexibility perspective, they lack the ability to perform reliable one-shot generalization: it is difficult to train them to generalize from individual examples .    In this paper we propose a new interactive NLI that is lexically flexible and can reliably and efficiently perform one-shot generalization. We introduce a novel exemplar-based neural network semantic parser that first abstracts away entities , allowing for generalization to previously taught utterances with novel object combinations. Our parser then retrieves the corresponding ``lifted'' utterance and respective program  from the training examples based on a learned metric , giving us the lexical flexibility of sequence-to-sequence models.  We demonstrate the efficacy of our learning from decomposition framework through a set of human-in-the-loop experiments where crowdworkers use our NLI to solve a suite of simulated robotics tasks in household environments. Crucially, after completing a task, we update the semantic parser so that users can immediately reuse what they taught. We show that over time, users are able to complete complex tasks  more efficiently with our exemplar-based method compared to a neural sequence-to-sequence baseline. However, for more straightforward tasks that can be completed in fewer steps, we see similar performance to the baseline. We end with an error analysis and discussion of user trust and incentives in the context of building interactive semantic parsing systems, paving the way for future work that better realizes the potential of the interactive paradigm.    By performing a comprehensive evaluation on eleven summarization systems and five mainstream datasets, we summarize our observations below:  1) Abstractive summarizers are extremely brittle compared with extractive approaches, and the maximum gap between them reaches 37 in terms of the measure stableness  defined in this paper.  2) BART  is superior over other abstractive models and even comparable with extractive models in terms of stiffness . On the other hand, it is robust when transferring between datasets as it possesses high stableness . 3) BERT  performs excellently in terms of stiffness, while still lacks stableness when transferred to \texttt{Bigpatent B} from other datasets.   4) The robustness of models can be improved through either equipped the model with ability to copy span from source document  or make use of well trained sequence to sequence pre-trained model . 5) Simply adding BERT on encoder could improve the stiffness  of model but will cause larger cross-dataset and in-dataset performance gap, a better way should be found to merge BERT into abstractive model, or a better training strategy should be applied to offset the negative influence it brings. 6) Existing factuality checker  is limited in predictive power of positive samples  . 7) Out-of-domain systems can even surpass in-domain systems in terms of factuality.      
","  Our goal is to create an interactive natural language interface that efficiently and reliably learns from users to complete tasks in simulated robotics settings. We introduce a neural semantic parsing system that learns new high-level abstractions through decomposition: users interactively teach the system by breaking down high-level utterances describing novel behavior into low-level steps that it can understand. Unfortunately, existing methods either rely on grammars which parse sentences with limited flexibility, or neural sequence-to-sequence models that do not learn efficiently or reliably from individual examples. Our approach bridges this gap, demonstrating the flexibility of modern neural systems, as well as the one-shot reliable generalization of grammar-based methods. Our crowdsourced interactive experiments suggest that over time, users complete complex tasks more efficiently while using our system by leveraging what they just taught. At the same time, getting users to trust the system enough to be incentivized to teach high-level utterances is still an ongoing challenge. We end with a discussion of some of the obstacles we need to overcome to fully realize the potential of the interactive paradigm.",212
"  % ============== version 5.0 ================= Intent detection, a fundamental component of task-oriented dialogue system , is increasingly raising attention as a Multi-Label Classification  problem , since a single utterance often carries multiple user intents .  In real-world scenarios, intent detection often suffers from lack of training data, because dialogue tasks/domains change rapidly and new domains usually contain only a few data examples.  Recent success of Few-Shot Learning  presents a promising solution for such data scarcity challenges.  It provides a more human-like learning paradigm that generalizes from only a few learning examples  by exploiting prior experience. % from old domains.   %For multi-label intent detection, state-of-the-art works adopt ``one-vs-rest'' strategy to convert the multi-class classification into binary-class classifications .  State-of-the-art works for multi-label intent detection focus on threshold-based strategy, where a common practice is estimating label-instance relevance scores and picking the intent labels with score higher than a threshold value .  Usually, the coordination and respective quality of the two modules, i.e. thresholding and relevance scoring, are crucial to the performance of MLC models.  However, in few-shot scenarios, such multi-label setting poses unique challenges for both threshold estimation and label-instance relevance scoring.  For thresholding, previous works explore to tune a fixed threshold  or to learn thresholds from data . But, these thresholds work well only when learning examples are sufficient.  In few-shot scenarios, it is pretty hard to determine appropriate thresholds with only a few examples. %In few-shot scenarios, it is pretty hard to determine appropriate thresholds  %with only a few examples. %without overfitting to the limited examples. % to the limited examples. %For few-shot scenarios, it is pretty hard to determine appropriate thresholds with only a few examples. Besides, it is also difficult to directly transfer the pre-learned thresholds due to the domain differences, such as differences in label number per instance, score density and scale.    Estimation of the label-instance relevance scores is also challenging. %It is also challenging to compute the label-instance relevance scores.  Few-shot learning has achieved impressive progress with similarity-based methods  , where the relevance scores can be modeled as label-instance similarities.  And the label representations can be obtained from corresponding support examples.  Unfortunately, despite huge success in previous single-label tasks, these similarity-based methods become impractical for multi-label problems.  When instances have multiple labels, representations of different labels may be obtained from the same support examples and become confused with each other. For the example in Fig , intents of query\_time and query\_loc share the same support example  and thus have the same label representation,  %Such confused label representations  which makes it impossible to predict correct labels with similarity scores.  %In such situations, vanilla similarities will assign query x equal score to query\_time and query\_loc  In this paper, we study the few-shot learning problem of multi-label intent detection and propose a novel framework to tackle the challenges from both thresholding and label-instance relevance scoring.  To solve the thresholding difficulties of prior-knowledge transferring and domain adaption with limited examples, we propose a Meta Calibrated Threshold  mechanism that first learns universal thresholding experience on data-rich domains, then adapts the thresholds to certain few-shot domains with a Kernel Regression based calibration.  Such combination of universal training and domain-specific calibration allows to estimate threshold using both prior domain experience and new domain knowledge.  %Here, as a non-parametric learning method, Kernel Regression allows to alleviate overfitting by calibrating the thresholds without finetuning.  To tackle the challenge of confused label representation in relevance scoring, we propose the Anchored Label Representation  to obtain well-separated label representations. Inspired by the idea of embedding label name as anchor points to refine representation space , ALR uses the embeddings of label names as additional anchors and represents each label with both support examples and corresponding anchors.  Different from the previous single-label intent detection that uses label embedding as additional features , our label embeddings here have unique effects of separating different labels in metric space.  Finally, to encourage better coordination between thresholding and label-instance relevance scoring, we introduce the Logit-adapting mechanism to MCT that automatically adapts thresholds to different score densities.   Experiments on two datasets show that our methods significantly outperform strong baselines.  Our contributions are summarized as follows:   We explore the few-shot multi-label problem in intent detection of task-oriented dialogue, which is also an early attempt for the few-shot multi-label classification.   We propose a Meta Calibrated Threshold mechanism with Kernel Regression and Logits Adapting that estimates threshold using both prior domain experience and new domain knowledge.  We introduce the Anchored Label Representation to obtain well-separated label representation for better label-instance relevance scoring.    %% ============== version 4.0 ================= %Intent detection, a fundamental component of task-oriented dialogue system , is increasingly raising attention as a Multi-Label Classification  problem , since a single utterance often carries multiple user intents .  %In real-world scenarios, intent detection often suffers from lack of training data, because dialogue tasks/domains change rapidly and new domains usually contain only a few data examples.  %Recent success of Few-Shot Learning  presents a promising solution for such data scarcity challenges.  %It provides a more human-like learning paradigm that generalizes from only a few learning examples  by exploiting prior experience. %% from old domains.  % %%For multi-label intent detection, state-of-the-art works adopt ``one-vs-rest'' strategy to convert the multi-class classification into binary-class classifications .  %State-of-the-art works for multi-label intent detection focus on threshold-based strategy, where a common practice is estimating label-instance relevance scores and picking the intent labels with score higher than a threshold value .  %Usually, the coordination and respective quality of the two modules, i.e. thresholding and relevance scoring, are crucial to the performance of MLC models.  %However, in few-shot scenarios, such multi-label setting poses unique challenges for both threshold estimation and label-instance relevance scoring. % %For thresholding, previous works explore to tune a fixed threshold  or to learn thresholds from data . %But, these thresholds work well only when learning examples are sufficient.  %In few-shot scenarios, it is pretty hard to determine appropriate thresholds without overfitting. %% to the limited examples. %%For few-shot scenarios, it is pretty hard to determine appropriate thresholds with only a few examples. %Besides, it is also difficult to directly transfer the pre-learned thresholds due to the domain differences, such as differences in label number per instance, score density and scale. % % % %It is also challenging to compute the label-instance relevance scores.  %Few-shot learning has achieved impressive progress with similarity-based methods  , where the relevance scores can be modeled as label-instance similarities.  %And the label representations can be obtained from corresponding support examples.  %Unfortunately, despite huge success in previous single-label tasks, these similarity-based methods become impractical for multi-label problems.  %When instances have multiple labels, representations of different labels may be obtained from the same support examples and become confused with each other. %For the example in Fig , intents of query\_time and query\_loc share the same support example  and thus have the same label representation,  %%Such confused label representations  %which makes it impossible to predict correct labels with similarity scores.  %%In such situations, vanilla similarities will assign query x equal score to query\_time and query\_loc % %In this paper, we study the few-shot learning problem of multi-label intent detection and propose a novel framework to tackle the challenges from both thresholding and label-instance relevance scoring. % %To solve the thresholding difficulties of prior-knowledge transferring and overfitting, we propose a Meta Calibrated Threshold  mechanism that first learns universal thresholding experience on data-rich domains, then adapts the thresholds to certain few-shot domains with a Kernel Regression based calibration.  %Here, as a non-parametric learning method, Kernel Regression allows to avoid overfitting by calibrating the thresholds without finetuning. % %To tackle the challenge of confused label representation in relevance scoring, we propose the Anchored Label Representation  to obtain well-separated label representations. %Inspired by the idea of embedding label name as anchor points to refine representation space , ALR uses the embeddings of label names as additional anchors and represents each label with both support examples and corresponding anchors.  %Different from the previous single-label intent detection that uses label embedding as additional features , our label embeddings here have unique effects of separating different labels in metric space. % %Finally, to encourage better coordination between thresholding and label-instance relevance scoring, we introduce the logit-adapting mechanism to MCT that automatically adapts thresholds to different score densities.  % %Experiments on two datasets show that our methods significantly outperform strong baselines.  %Our contributions are summarized as follows:  % We explore the few-shot multi-label problem in intent detection of task-oriented dialogue, which is also an early attempt for the few-shot multi-label classification.  % We propose a Meta Calibrated Threshold mechanism with Kernel Regression and Logits Adapting that estimates threshold using both prior domain experience and new domain knowledge. % We introduce the Anchored Label Representation to obtain well-separated label representation for better label-instance relevance scoring.    %% ============== version 3.0 EMNLP version ================= % %Intent detection  is a fundamental component for task-oriented dialogue system . %In real-word scenarios, intent detection often suffers from rapid changing of domains, because the new domains are usually lacking in data and may contain only a few data examples.  %Few-Shot Learning  is a promising solution to this problem.  %It provides a more human-like learning paradigm that generalizes from only a few learning examples  by exploiting prior experience from old domains.  % %In addition to data scarcity problem, intent detection also faces the problem of multi-label prediction. %As shown in Fig , a single utterance may carry multiple user intents.  %For this consideration, intent detection needs to be formulated as a Multi-Label Classification  problem , where a common practice is estimating label-instance relevance scores and picking the labels with score higher than a threshold value . % %Usually, the threshold is crucial to the performance of MLC models. %For multi-label intent detection, previous works explore to tune a fixed threshold  or to learn thresholds from data .  %However, these thresholds work well only when learning examples are sufficient.  %For few-shot scenarios, it is pretty hard to determine appropriate thresholds with only a few examples. %Also, it is difficult to directly transfer the threshold learned in data-rich domains due to the domain differences, such as differences in label number per instance, score density and scale. % % % %It is also challenging to compute the label-instance relevance scores for few-shot MLC.  %Previous few-shot research mainly focuses on single label classification and has achieved impressive progress with similarity-based methods  .  %Generally, these methods first obtain per class representations from a few examples , and then classify an  instance according to its similarity with the representation of each class. %However, such similarity scores rely on well-separated class  representations, which poses unique challenges in multi-label settings. %When instances have multiple labels, representations of different labels may be obtained from same support examples and become confused with each other. %For the example in Fig , intents of query\_time and query\_loc share the same support example  and thus have the same label representation.  % %In this paper, we study the few-shot learning problem of multi-label intent detection . %As mentioned above, it is difficult to estimate and transfer thresholds for few-shot MLC. %To solve this, we first learn universal thresholding experience on data-rich domains, and exploit the experience to estimate appropriate thresholds for unseen few-shot domains. %Specifically, we propose Meta Calibrated Threshold , which first learns a domain-general meta threshold, and then learns to calibrate it to fit specific domains with Kernel-Regression.  %To further encourage threshold generalization, we introduce the logit-adapting mechanism that automatically adapts meta thresholds to different score densities.  % %For computing label-instance score of few-shot MLC, we propose the Anchored Label Representation  to obtain well-separated label representations. %Inspired by the idea of embedding label name as anchor points to refine representation space , ALR uses the embeddings of label names as additional anchors and represent each label with both support examples and corresponding anchors.  % %Experiments on two datasets show that our methods significantly outperform strong baselines.  %Our contributions are summarized as follows:  % We explore the few-shot multi-label problem in intent detection of task-oriented dialogue,  %which is also an early attempt for few-shot multi-label classification.  % We propose a Meta Calibrated Threshold mechanism that estimate threshold using both prior domain experience and new domain knowledge. % We introduce the Anchored Label Representation to obtain well-separated label representation for better label-instance relevance score calculation.      We employed a copy mechanism to address the lexical cohesion problem in document-level NMT.  Our model computes a copy probability and weights of words to copy referring to preceding source sentences and their translation outputs.  Experiments on Japanese to English translation indicated that our model is effective to improve lexical cohesion, compared to strong context-aware NMT models.  As future work, we intend to evaluate the effectiveness of our model on various language pairs and domains, such as English-French and English-Russian; news and novels.  Also, we will improve the weighting method to copy words to avoid copying inappropriate words.     
"," % ========== Version 6.0 ============= In this paper, we study the few-shot multi-label classification for user intent detection.  For multi-label intent detection, state-of-the-art work estimates label-instance relevance scores and uses a threshold to select multiple associated intent labels.  To determine appropriate thresholds with only a few examples, we first learn universal thresholding experience on data-rich domains, and then adapt the thresholds to certain few-shot domains with a calibration based on non-parametric learning. %on metric learning. %, that does not require fine tuning to avoid overfitting. %Kernel Regression here allows to avoid overfitting by calibrating threshold without finetuning. For better calculation of label-instance relevance score, we introduce label name embedding as anchor points in representation space, which refines representations of different classes to be well-separated from each other. Experiments on two datasets show that the proposed model significantly outperforms strong baselines in both one-shot and five-shot settings.\footnote{Data and code are available at \url{https://github.com/AtmaHou/FewShotMultiLabel}}   %% ========== Version 5.0 ============= %In this paper, we study the few-shot multi-label classification for user intent detection.  %For multi-label intent detection, state-of-the-art work estimates label-instance relevance scores and uses a threshold to select multiple associated intent labels.  %To determine appropriate thresholds with only a few examples, we first learn universal thresholding experience on data-rich domains, and then adapt the thresholds to certain few-shot domains with a calibration based on Kernel Regression, that does not require fine tuning to avoid overfitting. %%Kernel Regression here allows to avoid overfitting by calibrating threshold without finetuning. %For better calculation of label-instance relevance score, we introduce label name embedding as anchor points in representation space, which refines representations of different classes to be well-separated from each other. %Experiments on two datasets show that our model significantly outperforms strong baselines in both one-shot and five-shot settings.\footnote{Data and code are available at \url{https://anonymous.com}}  %% ========== Version 5.0 ============= %In this paper, we study the few-shot multi-label classification for user intent detection.  %For multi-intent detection, state-of-the-art work estimates label-instance relevance scores and uses a threshold to select multiple associated intent labels.  %To determine appropriate thresholds with only a few examples, we first learn universal thresholding experience on data-rich domains, and then adapt the thresholds to certain few-shot domains with a Kernel Regression based calibration.  %Kernel Regression here allows to avoid overfitting by calibrating threshold without finetuning. %For better calculation of label-instance relevance score, we introduce label name embedding as anchor points in representation space, which refine representations of different classes to be well-separated from each other. %Experiments on two datasets show that our model significantly outperforms strong baselines in both one-shot and five-shot settings.\footnote{Code is available at \url{https://anonymous.com}}  %% ========= version 4.0 EMNLP version ========= %In this paper, we study the few-shot multi-label classification for user intent detection.  %Multi-label classification usually estimates label-instance relevance scores and uses a threshold to select multiple associated labels.  %To determine appropriate thresholds with only a few examples, we first learn universal thresholding experience on data-rich domains, and then calibrate the learned universal thresholds to fit certain few-shot domains. %For better calculation of label-instance relevance score, we introduce label name embedding as anchor points in representation space, which refine representations of different classes to be well-separated from each other. %Experiments on both open and in-house datasets show that our model significantly outperforms strong baselines in both one-shot and five-shot settings.\footnote{Code is available at: \url{https://anonymous.com}}",213
"  % % The following footnote without marker is needed for the camera-ready % version of the paper. % Comment out the instructions  and uncomment the 8 lines % under ""final paper"" for your variant of English. %  .          % % final paper: en-us version      %     %   % space normally used by the marker     % This work is licensed under a Creative Commons      % Attribution 4.0 International License.     % License details:     % \url{http://creativecommons.org/licenses/by/4.0/}. }  Translation into languages with grammatical gender involves correctly inferring the grammatical gender of all entities in a sentence. In some languages this grammatical gender is dependent on the social gender of human referents. For example, in the Spanish translation of the sentence `This is the doctor',  `the doctor' would be either  `el m鑼卍ico', masculine, or `la m鑼卍ica', feminine. Since the noun refers to a person the grammatical gender inflection should be correct for a given referent.   In practice many NMT models struggle at generating such inflections correctly , often instead defaulting to gender-based social stereotypes  or masculine language . For example, an NMT model might always translate `This is the doctor' into a sentence with a masculine inflected noun: `Este es el m鑼卍ico'.     Such behaviour can be viewed as translations  exhibiting gender bias. By `bias' we follow the definition from  of behaviour which `systematically and unfairly  discriminate[s]  against certain individuals or groups of individuals in favor of others.' Specifically, translation performance favors referents fitting into groups corresponding to social stereotypes, such as male doctors.   Such systems propagate the representational harm of erasure to referents -- for example, a non-male doctor would be incorrectly gendered by the above example translation. Systems may also cause allocational harms if the incorrect translations are used as inputs to other systems . System users also experience representational harms via the reinforcement of stereotypes associating occupations with a particular gender . Even if they are not the referent, the user may not wish for their words to be translated in such a way that they  appear to endorse social stereotypes. Users will also experience a lower quality of service in receiving grammatically incorrect translations.   A common approach to this broad problem in NMT is the use of gender features, implicit or explicit. The gender of one or more words in a test sentence  is determined from external context  or by reliance on `gender signals' from words in the source sentence such as gendered pronouns. That information can then be used when translating. Such approaches combine two distinct tasks: identifying the gender inflection feature, and then applying it to translate words in the source sentence. These feature-based approaches make the unstated assumption that if we could correctly identify that, e.g., the doctor in the above example should be female, we could inflect entities in the sentence correctly, reducing the effect of gender bias.   Our contribution is an exploration of this assumption. We propose a scheme for incorporating an explicit gender inflection tag into NMT, particularly for translating coreference sentences where the reference gender label is known. Experimenting with translation from English to Spanish and English to German, we find that simple existing approaches overgeneralize from a gender signal, incorrectly using the same inflection for every entity in the sentence. We show that a tagged-coreference adaptation approach is effective for combatting this behaviour.  Although we only work with English source sentences to extend prior work, we note that our approach can be extended to source languages without inherent gender signals like gendered pronouns, unlike approaches that rely on those signals.  Intuitively, if gender tagging does not perform well when it can use the label determined by human coreference resolution, it will be even less useful when a gender label must be automatically inferred.  Conversely, gender tagging that is effective in this scenario may be beneficial when the user can specify the gendered language to use for the referent, such as Google Translate's translation inflection selection , or for translations where the grammatical gender to use for  all human referents is known.  We also find that our approach works well  with RoBERTa-based gender tagging for English test sentences.    Existing work in NMT gender bias has focused on the translation of sentences based on binary gender signals, such as exclusively male or female personal pronouns. This excludes and erases those who do not use binary gendered language, including but not limited to non-binary individuals . As part of this work we therefore explore applying tagging to indicate gender-neutral referents, and produce a WinoMT set to assess translation of coreference sentences with gender-neutral entities.       \subsection{Related work} Variations on a gender tag or signal for machine translation have been proposed in several forms.  incorporate a `speaker gender' tag into training data, allowing gender to be conveyed at the sentence level. However, this does not allow more fine-grained control, for example if there is more than one referent in a sentence. Similar approaches from   and   infer and use gender information from discourse context.  also incorporate a single explicit gender feature for each sentence at inference.    integrate coreference links into machine translation reranking to improve pronoun translation with cross-sentence context.  propose NMT gender bias reduction by `mixing signals' with the addition of pro-stereotypical adjectives. Also related to our work is the very recent approach of , who train their NMT models from scratch with all source language words annotated with target language grammatical gender.  In  we treat gender bias as a domain adaptation problem by adapting to a small set of synthetic sentences with equal numbers of entities using masculine and feminine inflections. We also interpret this as a gender `tagging' approach, since the gendered terms in the synthetic dataset give a strong signal to the model. In this work we extend the synthetic datasets from this work to explore this effect further.  Other approaches to reducing gender bias effects involve adjusting the word embeddings either directly  or by training with counterfactual data augmentation  . We view these approaches as orthogonal to our proposed scheme: they have similar goals but do not directly control inference-time gender inflection at the word or sentence level.      In this paper, we explore the few-shot learning problem of multi-label intent detection.  To estimate a reasonable threshold with only a few support examples,  we propose the Meta Calibrated Threshold that adaptively combines prior experience and domain-specific knowledge.  To obtain label-instance relevance score under few-shot setting,  we introduce a metric learning based method with Anchored Label Representation. It provides well-separated label representations for label-instance similarity calculation.  Experiment results validate that both the Meta Calibrated Threshold and Anchored Label Representation can improve the few-shot multi-label intent detection.      
"," Neural Machine Translation  has been shown to struggle with grammatical gender that is dependent on the gender of human referents, which can cause gender bias effects. Many existing approaches to this problem seek to control gender inflection in the target language by explicitly or implicitly adding a gender feature to the source sentence, usually at the sentence level.    In this paper we propose schemes for incorporating explicit word-level gender inflection tags into NMT. We explore the potential of this gender-inflection controlled translation when the gender feature can be determined from a human reference, or when a test sentence can be automatically gender-tagged, assessing on English-to-Spanish and English-to-German translation.  We find that simple existing approaches can over-generalize a gender-feature to multiple entities in a sentence, and suggest effective alternatives in the form of tagged coreference adaptation data. We also propose an extension to assess translations of gender-neutral entities from English given a corresponding linguistic convention, such as a non-binary inflection, in the target language.",214
"    Self-supervised pretraining through language modeling on massive datasets has revolutionized NLP. One reason this method works is that pretraining shapes a model's hypothesis space, giving it inductive biases that help it learn linguistic tasks . Numerous probing studies have provided support for this idea by showing that language models learn representations that encode linguistic features .   However, feature learning is just the first step to acquiring helpful inductive biases. Models must also be able to learn which features matter. The NLU datasets these models are often fine-tuned on are ambiguous and contain artifacts, and often support multiple possible generalizations. Neural networks are not mind readers: Models that have been shown to represent linguistic features sometimes fail to use them during fine-tuning on NLU tasks, instead adopting shallow surface generalizations . To this end, recent work in probing pretrained models advocates for shifting the focus of study away from whether they represent linguistic features and in favor of whether they learn useful representations of those features .  % }           \end{table*}  We investigate how RoBERTa  acquires language-specific inductive biases during self-supervised pretraining. We track separately how RoBERTa's representation of linguistic features and its preferences for linguistic generalizations over surface generalizations change as the amount of pretraining data increases. We pretrain RoBERTa from scratch on datasets ranging from 1M to 1B words and evaluate these models alongside RoBERTa in a series of experiments to probe the inductive biases of a pretrained model at the time of fine-tuning on a downstream task.   We probe these models in three kinds of experiments: First, we conduct control experiments where we fine-tune models on unambiguous binary classification tasks to test whether they learn to represent simple linguistic and surface features. Second, we conduct ambiguous experiments following the poverty of the stimulus design , as illustrated in Figure . In these experiments, we fine-tune a pretrained model on an ambiguous binary classification task in which the training set is consistent with both a linguistic generalization and a surface one. We then test the classifier on disambiguating data to reveal which generalization the model adopted, and by extension its preference among the two features. Third, we conduct inoculation experiments \citep[following][]{liu2019inoculation} to test how hard it is to sway a model with a surface bias to adopt a linguistic generalization. We do this by introducing small amounts of disambiguating data into an otherwise ambiguous training set. We automatically generate data for all these tasks, and call the resulting dataset \dataset\ , pronounced ``messages''.   The results show that RoBERTa acquires a stronger linguistic bias as pretraining increases. RoBERTa has the strongest linguistic bias, and requires little to no inoculating data to reliably make the linguistic generalization. In general, models with more pretraining data can generally be induced to adopt linguistic generalizations with less inoculating data. We also find a large gap between the amount of pretraining data that RoBERTa needs to learn the linguistic features necessary to generalize out-of-domain and the amount it needs to learns that it should prefer those features when generalizing. The control experiments on unambiguous data reveal that models with little pretraining do actually represent the linguistic features, but nonetheless show a strong surface bias. In other words, the main contribution of pretraining to linguistic bias learning is devoted not to extracting features, but to learning which features matter.   We conclude that helpful inductive biases can be learned through pretraining, but current models require abundant data to do so. The implications of this conclusion point in two directions: First, we can probably continue to pretrain on increasingly massive training sets to improve on the generalization and few-shot learning abilities of models like T5  and GPT-3 . Second, since models learn useful features early, there is hope that future advances could accelerate by reducing the amount of data needed to learn which features matter. To aid in this effort, we release the MSGS dataset, our pretrained RoBERTas, and all our code: \href{https://github.com/nyu-mll/msgs}{\url{https://github.com/nyu-mll/msgs}}.    Tagging words with target language gender inflection is a powerful way to improve accuracy of translated inflections. This could be applied in cases where the correct grammatical gender to use for a given referent is known, or as monolingual coreference resolution tools improve sufficiently to be used for automatic tagging.  It also has potential application to new inflections defined for gender-neutral language.   However, there is a risk that gender features will be used in an over-general way. Providing a strong gender signal for one entity has the potential to harm users and referents by erasing other entities in the same sentence, unless a model is specifically trained to translate sentences with multiple entities. In particular we find that our V3 system, which is trained on multiple-entity translation examples, allows good performance while minimizing peripheral effects.   We conclude by emphasising that work on gender coreference in translation requires care to ensure that the effects of interventions are as intended, as well as testing scenarios that capture the full complexity of the problem, if the work is to have an impact on gender bias.   
","   One reason pretraining on self-supervised linguistic tasks is effective is that it teaches models features that are helpful for language understanding. However, we want pretrained models to learn not only to represent linguistic features, but also to use those features preferentially during fine-turning. With this goal in mind, we introduce a new English-language diagnostic set called MSGS , which consists of 20 ambiguous binary classification tasks that we use to test whether a pretrained model prefers linguistic or surface generalizations during fine-tuning. We pretrain RoBERTa models from scratch on quantities of data ranging from 1M to 1B words and compare their performance on \dataset\ to the publicly available RoBERTa$\subtxt{BASE}$. We find that models can learn to represent linguistic features with little pretraining data, but require far more data to learn to prefer linguistic generalizations over surface ones. Eventually, with about 30B words of pretraining data, RoBERTa$\subtxt{BASE}$ does demonstrate a linguistic bias with some regularity. We conclude that while self-supervised pretraining is an effective way to learn helpful inductive biases, there is likely room to improve the rate at which models learn which features matter.",215
" .     %      % % final paper: en-us version      %     %   % space normally used by the marker     % This work is licensed under a Creative Commons      % Attribution 4.0 International License.     % License details:     % \url{http://creativecommons.org/licenses/by/4.0/}. }  \reza{ Neural models have been revolutionising machine translation , and have achieved state-of-the-art for many high-resource language pairs . However, the scarcity of bilingual parallel corpora is still a major challenge for training high-quality NMT models  % especially for a broad range of languages for which the available translation training resources are too small to be used with existing NMT systems  . % Transfer learning by fine-tuning, from a model trained for a high-resource language-pair, % \wray{Wray: Having trouble with this:  isn't ""high-resource language-pair"" mean both source and target are high resource so how does this relate to what we do?} is a standard approach to tackle the scarcity of the data in the target low-resource language-pair . % However, this is a one-to-one approach, which is not able to exploit models trained for multiple high-resource language-pairs for the target language-pair of interest.  % Furthermore, models transferred from different high-resource language-pairs may have complementary syntactic and/or semantic strengths, hence using a single model may be sub-optimal.  }   %Transfer learning is one of the widely used solutions for addressing the data scarcity problem in low-resource scenarios .  % However, applying the original transfer learning to LR models is neither able to make full use of highly related multiple high-resource languages nor to receive different parameters from all effective high-resource NMT models simultaneously.  %However, transfer learning from high-resource to low-resource NMT models is generally a one-to-many approach which is not able to exploit multiple high-resource languages and high-resource NMT models' parameters simultaneously. Contrariwise,   \reza{ Another appealing approach is multilingual NMT, whereby a single NMT model is trained  by combining data from multiple high-resource and low-resource language-pairs . % %is an appealing approach for low-resource languages by utilizing the training examples of multiple languages .  %In practice, for training a multilingual NMT, a multilingual vocabulary set from all language pairs are used for training a single NMT model among all languages that enable sharing resources between high-resource and low-resource languages. % and improves the regularization of the model by avoiding over-fitting to the limited data of the low-resource languages.  However, the performance of a multilingual NMT model is highly dependent on the types of languages used to train the model.  Indeed, if languages are from very distant language families, they lead to negative transfer, causing low translation quality in the multilingual system compared to the counterparts trained on the individual language-pairs  .  % To address this problem,  has proposed a knowledge distillation approach to effectively train a multilingual model,  % by selectively distilling the knowledge from individual teacher models to the multilingual student model. However, still all the language pairs are trained in a single model with a blind contribution during training. %during the training process when the accuracy of the individual models surpasses the multilingual one.  % by distilling knowledge from individual NMT models. To avoid distilling knowledge from the not effective teachers, they selectively apply distillation during the training process when the accuracy of the individual models surpasses the multilingual one.  }  \reza{ In this paper, we propose a many-to-one transfer learning approach which can effectively transfer models from multiple high-resource language-pairs to a target low-resource language-pair of interest.  % As the fine-tuned models from different high-resource language pairs can have complementary syntactic and/or semantic strengths in the target language-pair, our idea is to distill their knowledge into a single student model to make the best use of these teacher models.  % We further propose an effective adaptive knowledge distillation  approach to dynamically adjust the contribution of the teacher models during the distillation process, enabling making the best use of teachers in the ensemble.  % Each teacher model provides dense supervision to the student via dark knowledge  using a mechanism similar to label smoothing , where the amount of smoothing is regulated by the teacher.  % In our AKD approach, the label smoothing coming from different teachers is  combined and regulated, based on the loss incurred by the teacher models during the distillation process.   % %\wray{Wray:  This next sentence could be deleted if you need space.} %Although we focus on the application of this method for NMT, it can be applied more generally to other NLP tasks suffering from the scarcity of training data, e.g. summarisation {CITE}  and question answering \todo{CITE}. } %Experimental results on various teacher-student language pairs show up to 0.9 BLEU score improvement compare to the strong baselines. Experiments on transferring from a collection of six language pairs from IWSLT to five low-resource language-pairs from TED Talks demonstrate the effectiveness of our approach, achieving up to +0.9 BLEU score improvements compared to strong baselines.  %\todo{talk more about the experiments?}  %In this paper, we introduce a new distil-based approach to make full use of all high-resource languages % and NMT models simultaneously and effectively. To do so, we firstly apply transfer learning from high-resource to low-resource languages to generate strong teachers. Then, we adaptively distil knowledge from multiple teachers based on their effectiveness  %to improve the accuracy of low-resource NMT model.  % What distinguishes our approach from the previous distil-based method  is choosing the best teachers statistically rather than deterministically. Our approach weights teachers based on the context of each mini-batch and the ability of each teacher to improve the prediction of student for that specific mini-batch during training. % Our experiments show that the proposed approach outperforms the vanilla transformer, original transfer learning, multilingual NMT, and selective knowledge distillation for translation of five low-resource languages to English.  %Our main contributions are as follows: %    a) We      % propose a new approach to  %    transfer knowledge from high-resource to low-resource language pairs which only assumes the availability of translation models in high-resource and the bilingual data for low-resource languages which leads to best usage of computational resources via exploiting the computational work already done on the high-resource side.     % , which is particularly interesting when there is limitation in the available computational resources. %    b) We      % propose a new method to %    dynamically distil knowledge from existing teacher models to a student model. What distinguishes our approach from the previous distillation-based methods  is choosing the best teachers statistically based on the data and knowledge gap of the student model, rather than deterministically as done in the previous work . %    c) Experimental results on various teacher-student language pairs show up to 0.9 BLEU score improvement compare to the strong baselines.  %   In this paper, we propose the task of Video-based Multimodal Summarization with Multimodal Output  which chooses a proper video cover and generates an appropriate textual summary for a video-attached article. We propose a model named Dual-Interaction-based Multimodal Summarizer  including a local conditional self-attention mechanism and a global-attention mechanism to jointly model and summarize multimodal input. Our model achieves state-of-the-art results in terms of autometrics and outperforms human evaluations by a large margin. In near future, we aim to incorporate the video script information in the multimodal summarization process.  
"," \reza{ Scarcity of parallel sentence-pairs poses a significant hurdle for training high-quality Neural Machine Translation  models in bilingually low-resource scenarios.  % A standard approach is transfer learning, which involves taking a model trained on a high-resource language-pair and fine-tuning it on the data of the low-resource MT condition of interest.  % However, it is not clear generally which high-resource language-pair offers the best transfer learning for the target MT setting. Furthermore, different transferred models may have complementary semantic and/or syntactic strengths, hence using only one model may be sub-optimal.      % In this paper, we tackle this problem using knowledge distillation, where we propose to distill the knowledge of ensemble of teacher models to a single student model.  % As the quality of these teacher models varies, we propose an effective adaptive knowledge distillation approach to dynamically adjust the contribution of the teacher models during the distillation process.  % Experiments on transferring from a collection of six language pairs from IWSLT to five low-resource language-pairs from TED Talks demonstrate the effectiveness of our approach, achieving up to +0.9 BLEU score improvement compared to strong baselines.  } %In this paper, we propose a two-phase method  to tackle this challenge. The first phase involves transfer learning, where models trained on high-resource languages-pairs are fine-tuned on the data of the low-resource MT condition of interest.  % %The second phase involves disstilling the knowledge from this collection of teachers to a single student model.  % %As the quality of these teacher models vary, we propose an adaptive knowledge distillation approach to adaptively adjust the contribution of the teacher models during the training process of the student.  % %NMT models, where a pretrained modeld on high-resource data is fine tuned on .  The transferred models are treated as teachers which produce soft targets for each low-resource language. In the second phase, we adaptively distil knowledge from all teachers based on their capability to improve the accuracy of the low-resource NMT model . By optimizing the student to fit the teachers' distribution over smoothed labels, we expect the student闁炽儲鐛 generalisation affected by teachers' probability calibration. Moreover, we propose to control the teachers' contributions when computing the soft targets for knowledge distillation, such that better teachers contribute more. This contribution is adaptively changing based on how good a teacher captures the context of an incoming mini-batches during training. Experiments on IWSLT and TED dataset demonstrate the effectiveness of our model which outperforms strong baselines on the translation of five low-resource languages to English.",216
"  Natural language processing for deception detection focus on preprocessing text into computational data with required features for the propose. As deception detection is about understanding the meaning of the text or how the text is viewed by people, the sequence of the text is always considered as one of primary source of context. For example, N-gram, the representative method of natural language processing, contains the data of a word and its subsequent word and its statistical probabilities. The attribute subsequent contains the continuous context of the text, or the linguist  will describes as linearity. In contrast, feature extractions without considering this language's linearity seems to be nonsense. However, if the data that been processed out of those non-linear feature extractions shows notable accuracy of detecting deceptions, it is possible to suggest that some of those preprocessing methods could be used as one of possible natural language processing for certain situations. \  In this paper, we discuss the effectiveness of APV, a simple natural language processing method using alphabet frequency, in the context of application on fake news detection. By using deep learning algorithm and fake news dataset in Kaggle, our findings suggest that simple deep learning algorithms using APV as pre-processing method could show prominent accuracy on predicting deception of the text. \  In section 2, we investigate conventional natural language processing that is used for machine learning and deep learning algorithms. In section 3, we define APV and its mathematical structure. We will also discuss the hypothesis that might improve feature extraction of APV.  In section 4, basic experiment protocol will be set including the structure of deep learning algorithms and performance metrics that will be used in the experiment. In section 5, we present the result of the algorithms performance. Finally, in section 6, we conclude the study.    In this paper, we present an adaptive knowledge distillation approach to improve NMT for low-resource languages. We address the inefficiency of the original transfer learning and multilingual learning by making wiser use of all high-resource languages and models in an effective collaborative learning manner. Our approach shows its effectiveness in translation of low-resource languages especially when there are complementary knowledge in multiple high-resource languages from the same linguistic family and it is not explicitly clear which language has more impact in every mini-batch of low-resource training data. Experiments on the translation of five extremely low-resource languages to English show improvements compared to the strong baselines.  
","     Feature extraction is an important process of machine learning and deep learning, as the process make algorithms function more efficiently, and also accurate. In natural language processing used in deception detection such as fake news detection, several ways of feature extraction in statistical aspect had been introduced . In this research, it will be shown that by using  deep learning algorithms and alphabet frequencies of the original text of a news without any information about the sequence of the alphabet can actually be used to classify fake news and trustworthy ones in high accuracy . As this pre-processing method makes the data notably compact but also include the feature that is needed for the classifier, it seems that alphabet frequencies contains some useful features for understanding complex context or meaning of the original text.\\\\  keywords: {[FEATURE EXTRACTION], [DEEP LEARNING]}  % Received, Accepted 闂嗩喚濞嬮～锟犳禃 闂夋稑瀚靛 闂夋稑鎳為悧鎾荤垷濮楀喚娼 濮ｉ潧鐗楅崝顖炵亙.",217
"  Sentence matching is a fundamental technology in natural language processing. Over the past few years, deep learning as a data-driven technique has yielded state-of-the-art results on sentence matching . However, this data-driven technique typically requires large amounts of manual annotation and brings much cost. If large labeled data can't be obtained, the advantages of deep learning will significantly diminish.  To alleviate this problem, active learning is proposed to achieve better performance with fewer labeled training instances . Instead of randomly selecting instances, active learning can measure the whole candidate instances according to some criteria, and then select more efficient instances for annotation . However, previous active learning approaches in natural language processing mainly depend on the entropy-based uncertainty criterion , and ignore the characteristics of natural language. To be more specific, if we ignore the linguistic similarity, we may select redundant instances and waste many annotation resources. Thus, how to devise linguistic criteria to measure candidate instances is an important challenge.  Recently, pre-trained language models  have been shown to be powerful for learning language representation. Accordingly, pre-trained language models may provide a reliable way to help capture language characteristics. In this paper, we devise linguistic criteria from a pre-trained language model to capture language characteristics, and then utilize these extra linguistic criteria  to enhance active learning. It is shown in Figure . Experiments on both English and Chinese sentence matching datasets demonstrate the pre-trained language model can enhance active learning.      As the current natural language processing suggests, it is ideal for the natural language to be considered by their strict and linear order. However, in this paper, we suggest that even if the natural sequence of the data are excluded from the feature extraction of a text, it is possible to use those data to classify the text with high accuracy. And we consider this accuracy is a fair trade-off between accuracy and pre-processing effort, as APV shrinks the data to approximately   in its size but still obtained 92\  of the accuracy the deep learning algorithm that is been reported has .  It is not sure whether or not APV is capable of summarizing the text, however it seems possible to use APV in supervised learning regarding natural language. We are planning to use the proposed method to classify more than 2 classes, and also hopefully find mathematical explanations why this method works and how to improve the feature extraction more than the results listed in this paper.  
"," Active learning is able to significantly reduce the annotation cost for data-driven techniques. However, previous active learning approaches for natural language processing mainly depend on the entropy-based uncertainty criterion, and ignore the characteristics of natural language. In this paper, we propose a pre-trained language model based active learning approach for sentence matching. Differing from previous active learning, it can provide linguistic criteria to measure instances and help select more efficient instances for annotation. Experiments demonstrate our approach can achieve greater accuracy with fewer labeled training instances.",218
"   %text matching閺堝绶㈡径姝瀍ep learning閺傝纭堕敍灞炬櫏閺嬫粈绗夐柨娆欑礉娴ｅ棙妲搁崣顖澬掗柌濠傛▕閿涘奔绗栭柅鐔峰娑撳秹鐝  The neural networks represent two sentences individually to a dense vector in the same embedding space, and then define different functions to calculate the matching degree of the two-sentence vectors. However, they are getting extremely time-consuming as the networks are becoming more sophisticated and introducing more parameters. Even worse, it is still a black box for researchers and practitioners, and in urgent need of interpretability. We can't figure out what's the specific meaning of the representation obtained from neural networks, which is unaccountable or challenging to comprehend and will lead to an untrusty and irresponsible result.   %閹存垳婊戠亸杈ㄥ厒閹靛彞绔存稉顏勫嫉韫囶偄寮垫總鍊熜掗柌濠忕礉娴犲簼浜掗崜宥囨畱deep learning鐠囦焦妲戞禍鍡楊劅閺傚洦婀伴惃鍕秵缂佺銆冪粈鐑樻Ц闂堢姾姘ㄩ惃鍕剁礉閹垫禒顧砮tric learn閸掓艾銈界亸杈ㄦЦ鏉╂瑦鐗遍敍灞界穿閸忣櫝etric learning閿涘奔绗栭敍鍫滀簰瀵伴弰顖涘簼绠為悽鈺〆tric learning閿  To tackle these, we aim to find a fast and interpretable approach for sentence matching. There are several studies focused on learning low-dimensional representations of the data, which called metric learning and even some of them combine it with some similarity metrics for ranking tasks .  Moreover, some researchers apply metric learning principles to design the loss function in information retrieval and question-answering tasks. But for the deep metric learning that they utilized, the neural network part still demands a lot of time. It hardly runs on a memory-limited device, together with high energy consumption.  %閹存垳婊戝銉ょ稊閺勵垰婀猼ext matching娑撳﹥褰佹稉娑擃亜鎻╅柅鐔烘畱閺傝纭堕妴鍌樺倶鍌涘娴狀櫑pply閵嗗倶鍌  It is considering the unexplainable implications brought from neural networks, such as fairness or transparency, and the challenge of time-consuming. In this paper, we apply metric learning approaches to address the problems mentioned above. Because metric learning has an advantage in time and memory usage on large-scale and high-dimensional datasets compared with methods above. Here, metric learning finds a representation of the data that preserves these constraints that are placed by human-provided labels. Building on its success in learning ``label constraint preserving'' representations, or low-distortion embeddings, we explore two \textsf{F}ast, \textsf{I}nterpretable, and \textsf{L}ow-rank \textsf{M}etric learning approaches, what we called \textsf{FILM}.   %閻鍩岄弫鍫熺亯metric learning閼宠棄鐤勯悳鎵娴艰偐娈戠紒鎾寸亯閿涘奔绗栬箛顐︾喍绗栭崣顖澬掗柌濠冄嶇窗缁炬寧褏娈   Notably, we explore \textsf{FILM} methods on text matching tasks, which is also known as the semantic equivalence problem in the IR community~. To be more specific, one based on an interpretable low-rank manifold optimization method. To solve this optimization problem,  we apply the Cayley transformation method with the Barzilai-Borwein step size. After being trained for this task, both are added to the kNN index for prediction for efficient retrieval. The input question is encoded and used as a query to the index, returning the top k most similar questions. We test our approaches on data from the Quora Challenge and SemEval-2017 Semantic Textual Similarity  Task, which provide pairwise sentence similarity labels.   %\footnote{}   %Our motivation is to investigate whether \textsf{FILM} approaches can perform as well as, if not better than, some ``black box'' approaches that are so popular these days.    The rest of this paper is organized as follows. In Section , we provide a quick overview of metric learning. In Section  we present the interpretable \textsf{FILM} method. In Section , we summarize the Quora dataset and task, explain how \textsf{FILM} is applied to the task, and summarize our deep neural network approach. In Section  we report some results.  \end{comment}     In this paper, we combine active learning with a pre-trained language model. We devise extra linguistic criteria from a pre-trained language model, which can capture language characteristics and enhance active learning. Experiments show that our proposed active learning approach obtains better performance.  
"," Detection of semantic similarity plays a vital role in sentence matching. It requires to learn discriminative representations of natural language. Recently, owing to more and more sophisticated model architecture, impressive progress has been made, along with a time-consuming training process and not-interpretable inference. % In sentence matching and semantic analysis, detecting semantic similarity is a challenge that requires learning discriminative representations of natural language. Recent advances in the deep neural network enable us to learn semantic representation, but are getting time-consuming and fail in interpretation. To alleviate this problem, we explore a metric learning approach, named \textsf{FILM}  to efficiently find a high discriminative projection of the high-dimensional data. We construct this metric learning problem as a manifold optimization problem, and solve it with the Cayley transformation method with Barzilai-Borwein step size. % To alleviate this problem, in this paper we construct sentence matching as a manifold optimization problem that learns a distance function between sentences. % % and obtain the semantic representation by learning a similarity or distance function. % We explore a metric learning approach, named \textsf{FILM}  to efficiently find a high discriminative projection of the high-dimensional data. % that still preserves high discriminative power. % To this end, our manifold optimization method is solved by the Cayley transformation method with Barzilai-Borwein step size.  In experiments, we apply \textsf{FILM} with triplet loss minimization objective to the Quora Challenge and Semantic Textual Similarity  Task. The results demonstrate that the \textsf{FILM} method achieves a superior performance as well as the fastest computation speed, which is consistent with our theoretical analysis of time complexity.",219
" %A common situation for language learners is to encounter unrecognized words. %In this case, looking up the dictionary may be the preferred solution for many people. %However, the capacity of dictionaries is limited, and they may not contain new words or new meanings of words. %What's more, not all language pairs have dictionaries, especially those with low resources. %Therefore, it may be a good idea to directly generate definitions for words.  The definition modeling task proposed by \citet{Noraset2017DefinitionML} is to generate a dictionary definition of a specific word. This task can prove useful for language learners, such as provide reading help by giving definitions for words in the text. However, definition modeling can only work for a specific language, which puts high demands on users because it requires them to read definitions written in this language. Besides, many low-resource languages lack large-scale dictionary data, making it difficult to train definition generation models for these languages. %This task can prove useful for language learners, such as provide reading help by giving definitions for words in the text. %However, definition modeling can only work for a specific language, which puts high demands on users because it requires them to read definitions written in this language.  Therefore, we emphasize the necessity of generating definitions cross-lingually, which can generate definitions for various language inputs, as illustrated in figure . Since English is widely used around the world, and English dictionary resources are relatively easy to obtain, we choose to generate definitions in English. In this way, a cross-lingual model trained on English can be directly applied to other languages.  The challenging issue is how to effectively transfer the knowledge of definition generation learned in English to other languages. To solve this problem, we propose to employ cross-lingual pretrained language models  as encoders. These models have shown to be able to encode sequences of various languages, which enables the ability of cross-lingual transfer . %In this work, we emphasize the necessity of generating definitions cross-lingually, which requires the model to generate definitions with just one language for words in various languages as illustrated in figure . %Considering English is widely used around the world, and English dictionary resources are relatively easy to obtain, we choose to use English to generate definitions for other languages in this work.  %Recently, cross-lingual pretrained language models  have shown to be capable of encoding sequences of different languages into the same vector space, which enables the ability of cross-lingual transfer. %Therefore, we propose to employ them as encoders for cross-lingual definition generation. %After training and fine-tuning the model on English dataset, we directly apply the obtained model to generate definitions for other languages.    To verify our proposed method, we build an English dataset for model training and a Chinese dataset for zero-shot cross-lingual evaluation. %We collected English words, example sentences and definitions in the OALD as the English dataset, and collected Chinese words, example sentences and English definitions in the Chinese WordNet   as the Chinese dataset. Experiments and manual analyses on the constructed datasets show that our proposed models have good cross-lingual transfer ability. Compared with the reference definitions in the CWN dataset, although the generated definitions are still insufficient on the accuracy, their fluency is already good enough.  Furthermore, considering the generated definitions are provided for language learners, and many of them are non-English native speakers, we argue that the difficulty of definitions should be under control. We control the lexical complexity of generated definitions by limiting definitions in the training set to the Oxford 3000 vocabulary, which is a list of important and useful words that are carefully selected by language experts and experienced teachers . %These words have been used to write definitions in the Oxford Advanced Learner's Dictionary  , in order to make them easy to understand. %We compute the Type/Token Ratio  as a measure of lexical complexity. %The TTR of generated definitions  is much lower than that of reference definitions , which indicates a lower lexical complexity. We compute four different metrics to measure the lexical complexity. Definitions generated by our models outperform the reference definitions on all four metrics by a large margin. The result shows that our method can generate simpler definitions, which is suitable for language learners.     We investigated text matching, a core task in information retrieval and semantic analysis. We introduced the notation and definition of metric learning, and how it can be applied to text matching. Then, we explored \textsf{FILM} , which aim to reduces the time cost and memory usage, also save energy consumption. In order to solve this task efficiently, \textsf{FILM} combined with a fast approximate k nearest neighbour search index. Compare to neural models, our method also has advantage in time and memory usage on large-scale and high-dimensional datasets.   
"," Generating dictionary definitions automatically can prove useful for language learners. However, it's still a challenging task of cross-lingual definition generation. In this work, we propose to generate definitions in English for words in various languages. To achieve this, we present a simple yet effective approach based on publicly available pretrained language models. In this approach, models can be directly applied to other languages after trained on the English dataset. We demonstrate the effectiveness of this approach on zero-shot definition generation. Experiments and manual analyses on newly constructed datasets show that our models have a strong cross-lingual transfer ability and can generate fluent English definitions for Chinese words. We further measure the lexical complexity of generated and reference definitions. The results show that the generated definitions are much simpler, which is more suitable for language learners. %We further conduct a manual analysis of the generated Chinese definitions and find that although these definitions are insufficient on the accuracy, they are already good enough on fluency and lexical complexity.",220
"  The CoNLL 2020 MRP Shared Task  combines five frameworks for graph-based meaning representation: EDS, PTG, UCCA, AMR and DRG. It further includes evaluations in English, Czech, German and Chinese. While EDS, UCCA and AMR participated in the 2019 MRP shared task , which focused only on English, PTG and DRG are newly-added frameworks to the MRP uniform format.  For this shared task, we extended TUPA , which was adapted as the baseline system in the 2019 MRP shared task , to support the two new frameworks and the different languages. In order to add this support, only minimal changes were needed, demonstrating TUPA's strength in parsing a wide array of representations.  TUPA is a general transition-based parser for directed acyclic graphs , originally designed for parsing UCCA . It was previously used as the baseline system in SemEval 2019 Task 1 , and generalized to support other frameworks .  We also experimented with the HIT-SCIR parser . This was the parser with the highest average score across frameworks in the 2019 MRP shared task, and has also since been applied to other frameworks  .   	\end{adjustbox} 	 \end{figure*}       In this work, we employ pretrained language models, namely mBERT and XLM for cross-lingual definition generation. In addition, we propose to use the Oxford 3000 vocabulary to limit the lexical complexity of generated definitions. We build the OALD dataset for monolingual training and the CWN dataset for cross-lingual evaluation. Experiments indicate the strong cross-lingual transfer ability of our proposed method. Furthermore, results on lexical complexity shows that definitions generated using our method is simpler than the reference, which is suitable for language learners.  Experiments conducted on these datasets show the effectiveness of our proposed method.  Furthermore, manual analysis performed on the CWN test set shows that although the generated definitions are insufficient on the accuracy, they are already good enough on fluency and lexical complexity.  \clearpage     \clearpage   	\caption{Generated samples} 	    	\caption{Hyperparameters used in Experiments} 	   
","   This paper describes the HUJI-KU system submission to the shared task   on Cross-Framework Meaning Representation Parsing  at the 2020   Conference for Computational Language Learning ,   employing TUPA and the HIT-SCIR parser, which were, respectively,   the baseline system and winning system in the 2019 MRP shared task.   Both are transition-based parsers using BERT contextualized embeddings.   We generalized TUPA to support the newly-added MRP frameworks and languages,   and experimented with multitask learning with the HIT-SCIR parser.   We reached 4th place in both the cross-framework and cross-lingual tracks.",221
"  \renewcommand{\thefootnote}{}   Recurrent Neural Network language models  have been shown to learn many aspects of natural language syntax including a number of long-distance dependencies and representations of incremental syntactic state . However, previous studies have not investigated the relationship between a token's frequency in the training corpus and syntactic properties models learn about it. In this work, we assess neural models' ability to make robust syntactic generalizations about a token's nominal number or verbal argument structure based on minimal exposure with the token during training. Because of the Zipfian distribution of words in a corpus, the vast majority of word types will be seen only a handful of times during training . Therefore, the few-shot learning capabilities of neural LMs are critical to their robustness as an NLP system and as a cognitive model.  However, human learning goes beyond simply learning syntactic properties in particular constructions. People apply the same properties across different constructions, meaning that their representations of the syntactic features of a word are in some sense invariant to the grammatical context of that word. For example, speakers and listeners are sensitive to a verb's argument structure relationships and can easily recognize that a verb which cannot take a direct object in active, declarative sentences cannot be passivized  The relationship between an active sentence and a passive sentence has been termed a transformation in the linguistic literature . Many semantic-syntactic rules that govern word co-occurrence in one form, such as a verb's argument structure relationships, hold uniformly across transformations. It remains an open question whether models learn grammatical rules invariant to their surface realization, a property we call syntactic invariance.  We combine assessment of few-shot learning and syntactic invariance for two grammatical features of English: whether a noun is singular or plural  and whether a verb is transitive or intransitive . We assess whether a model is able to make different predictions based on number or argument structure in a simple active voice base context. We then assess whether models are able to make similar distinctions in a transformed context---passive voice for verbs and polar questions for nouns. In the transformed contexts, we test models with tokens that occur only in the base context during training.  For models to succeed in the transformed contexts they must represent syntactic features in a way that is invariant to the specific realization of those features in terms of word co-occurrences in different constructions. For each grammatical feature, we introduce a suite of novel targeted test sentences, similar to those presented in \citet{marvin2018targeted}.  We find that all neural models tested are able to induce the proper syntactic generalizations in the base and transformed contexts after just two or three exposures, whereas a baseline -gram model fails to learn the relevant generalizations. For all constructions tested our two neural models enhanced with explicit structural supervision outperform the purely sequence model. Assessing invariance properties, we find that neural models demonstrate proper behavior in transformed contexts, even for tokens seen only in base contexts during training. This behavior indicates that models are able to deploy generalizations learned in one syntactic context into different syntactic environments, a key component of human linguistic capabilities that has been so far untested in the neural setting.  \subsection{Related Work}  Bayesian models of word learning have shown successes in acquiring proper syntactic generalizations from minimal exposure , however it is not clear how well neural network models would exhibit these rapid generalizations. Comparing between neural network architectures, recent work has shown that models enhanced with explicit structural supervision during training produce more humanlike syntactic generalizations , but it remains untested whether such supervision helps learn properties of tokens that occur rarely during training.  Previous studies have found that Artificial Neural Networks  are capable of learning some argument structure paradigms and make correct predictions across multiple frames , however these capabilities remain untested for incremental language models. Much has been written about the ability of ANNs to learn number agreement , including their ability to maintain the dependency across different types of intervening material  and with coordinated noun phrases . \citet{hu2020systematic} find that model architecture, rather than training data size, may contribute most to performance on number agreement and related tasks. Focusing on RNN models, \citet{lakretz2019emergence} find evidence that number agreement is tracked by specific ``number"" units that work in concert with units that carry more general syntactic information like tree depth. \citet{jumelet2019analysing} argue that when learning dependencies RNNs acquire a default form , and predicting a non-default form requires explicit contrary evidence. Our results support their hypothesis. Models are more accurate with singular nouns and transitive verbs seen only a few times in training, behavior that indicates these forms are expected when evidence is sparse.    We have presented TUPA-MRP and a modified HIT-SCIR parser, which constitute the HUJI-KU submission in the CoNLL 2020 shared task on Cross-Framework Meaning Representation. TUPA is a general transition-based DAG parser with a uniform transition system, which is easily adaptable for multiple frameworks. We used it for parsing in both the cross-framework and the cross-lingual tracks, adapting it for the newly introduced frameworks, PTG and DRG.  HIT-SCIR is a transition-based parser with framework-specific transition systems, which we adapted for this year's shared task and used for English EDS and UCCA parsing in the cross-framework track. The HIT-SCIR parser was additionally used in experimenting on multitask learning, with negative results for that approach.  Future work will tackle the MRP task with more modern transition-based-like parser architectures, such as pointer networks , which have so far only been applied to bilexical framworks, i.e., flavor-0 SDP .   
"," Humans can learn structural properties about a word from minimal experience, and deploy their learned syntactic representations uniformly in different grammatical contexts. We assess the ability of modern neural language models to reproduce this behavior in English and evaluate the effect of structural supervision on learning outcomes. First, we assess few-shot learning capabilities by developing controlled experiments that probe models' syntactic nominal number and verbal argument structure generalizations for tokens seen as few as two times during training. Second, we assess invariance properties of learned representation: the ability of a model to transfer syntactic generalizations from a base context  to a transformed context . We test four models trained on the same dataset: an $n$-gram baseline, an LSTM, and two LSTM-variants trained with explicit structural supervision \citep{dyer2016rnng, charniak2016parsing}. We find that in most cases, the neural models are able to induce the proper syntactic generalizations after minimal exposure, often from just two examples during training, and that the two structurally supervised models generalize more accurately than the LSTM model. All neural models are able to leverage information learned in base contexts to drive expectations in transformed contexts, indicating that they have learned some invariance properties of syntax.\blfootnote{Miguel conducted this work while at IBM Research}",222
"  Despite \bert{'s}  popularity and  effectiveness, little is known about its inner workings. Several attempts have been made to demystify certain aspects of \bert , often leading to contradicting conclusions. For instance, \citet{clark-etal-2019-bert} argue that attention measures the importance of a particular word when computing the next level representation for this word. However, \citet{kovaleva-etal-2019-revealing} showed that most attention heads contain trivial linguistic information and follow a vertical pattern , which could be related to under-utilization or over-parameterization issues. Other studies attempted to link specific \bert heads with linguistically interpretable functions ,  agreeing that no single head densely encodes enough relevant information but instead different linguistic features are learnt by different attention heads. We hypothesize that the aforementioned largely contributes to the lack of attention-based explainability of \bert. Another open topic is how the knowledge is distributed across \bert layers. Most studies agree that syntactic knowledge is gathered in the middle layers , while the final layers are more task-specific. Most importantly, it seems that any semantic knowledge is spread across the model, explaining why non-trivial tasks are better solved at the higher layers .  Driven by the above discussion, we propose a novel fine-tuning approach where different parts of \bert are guided to directly solve increasingly challenging classification tasks following an underlying label hierarchy. Specifically, we focus on Large Scale Multilabel Text Classification  where documents are assigned with one or more labels from a large predefined set. The labels are organized in a hierarchy from general to specific concepts. Our approach attempts to tie specific \bert layers with specific hierarchy levels. In effect, each of these layers is responsible for predicting the labels of the corresponding level. We experiment with two \lmtc datasets  and several variations of structured \bert training. Our contributions are:  We propose a novel structured approach to fine-tune \bert where specific layers are tied to specific hierarchy levels;  We show that structured training yields better results than the baseline across all levels of the hierarchy, while also leading to better parameter utilization.         In this paper, we have tested the few-shot learning capabilities of neural language models, as well as whether these models can learn grammatical representations that are invariant to syntactic transformation. First, we addressed neural models' ability to learn nominal number, introducing a novel testing paradigm that leveraged polar questions to assess subject/verb number agreement learning in syntactically transformed settings. Second, we turned to neural models' ability to represent verbal argument structure, developing two novel suites of tests that assessed preference for themes---either realized as direct objects or passive subjects---in both active contexts and passive contexts. In each experiment we assessed the effect of syntactic supervision on learning outcomes by comparing two supervised models to one purely sequence model.  A summary of our results can be seen in Table, with few-shot learning outcomes in colored cells on the left, and the effect of structural supervision on the right. The results from experiments that assess syntactic invariance are on the bottom, below the line break. This table makes it clear that all neural models are capable of making syntactic generalizations about a token from minimal exposure during training. Although model accuracy is reduced for tests that assess syntactic invariance, all neural models show at least a moderate ability to generalize across syntactic transformations. Furthermore, Table shows that syntactic invariance is enhanced in structurally supervised models. Interestingly, both ActionLSTM and RNNG have access to syntactic information, but the comparison in Table indicates that RNNG can leverage that information more effectively to produce syntactic invariance. Therefore we suggest that RNNG's improved performance does not come from the mere presence of syntactic information in the training and test data, but rather from the fact that it uses syntactic information to structure its computation in a non-sequential way.   Models performed better on singular nouns and transitive verbs, especially when the token occurred minimally during training. This behavioral pattern is consistent with the hypothesis outlined by \citet{jumelet2019analysing}, who suggest that models acquire default syntactic categories, and require supporting evidence before they make non-default predictions.  Because these experiments require careful and robust syntactic analysis of the training data, we evaluated models trained on a relatively small, human-annotated corpus. While the small training data poses some limitations when interpreting the results, it makes them more relevant to low-resource NLP applications and suggests that using structurally supervised models can lead to better generalization in a sparse data environment. While sub-word tokenization schemes such as Byte-Pair Encoding  have helped reduce the number of individual lexical items that need to learned, they do not completely eliminate the long tail of sub-word units. Thus, robust few-shot generalization is still an important problem in these environments. It may be that larger amounts of training data support even better few-shot learning and syntactic invariance outcomes. Scaling these carefully-controlled methods to the larger data setting will be an important next step. However, even with the relatively small models tested here, the results support a growing body of evidence that incremental statistical models of language are able to induce many key features of human linguistic competence.   \section*{Acknowledgements}  The authors thank the anonymous reviewers for their feedback. This work was supported by the MIT-IBM Watson AI Lab.       \section{Effect of Exposure on Model Accuracy}  In this section we report the result for statistical tests assessing the effect of a token's frequency in training on model accuracy for that token. We derive significance from a general linear model with \# of exposures as a sole predictor, with random by-item intercepts ))})  \paragraph{Nominal Number} For the base context, in the no modifier condition we find a positive effect of increased exposure for all models . For the PP modifier test we find an effect of exposure for the ActionLSTM and the RNNG , and a negative, but insignificant effect for the -gram and the LSTM. For the RC Modifier experiment we find an effect of increased exposure for all three neural models , but no effect for the -gram. For the inverted contexts: in the no modifier tests we find no effect of increased exposure, except for the LSTM, where the effect is negative . For the modifier tests, we find a significant effect for the ActionLSTM and the RNNG .  \paragraph{Argument Structure} For the base context : In the infinitival tests, we find a significant effect of exposure on accuracy for the ActionLSTM and the RNNG  and a negative effect for the -gram model . In the past-tense, we find no significant effect for the RNNG or the ActionLSTM, and a negative effect for the -gram and LSTM models . In the transformed contexts , for the no-modifier tests we find a significant effect of exposure for all models . For the short-modifier tests we find an effect for the ActionLSTM  and the RNNG . And in the long-modifier test we find a marginally significant effect for the three neural models .  \section{Learning Outcomes by Grammatical Condition}       In this section, for each test reported in the paper, we break down model performance by grammatical category, either singular vs plural nouns  or transitive vs. intransitive verbs . Charts follow the same presentational paradigm: -axis shows accuracy and -axis the number of times each word appears during training, on a log-10 scale. Smooth lines are results of logistic regression model fits on the raw data, with shaded regions indicating standard error. Dark blue lines show model performance averaged between the two conditions .   The data presented here are consistent with the hypothesis from . When models receive scant evidence of a token's syntactic properties in training, they assume that it belongs to a ``base"" category, which is singular for nouns and transitive for verbs. Thus, models are more accurate for singular nouns and transitive verbs seen rarely in training. As the model receives more evidence that a token is not in the base category, its predictions flip. Hence, gains in overall-accuracy tend to come from models learning the proper agreement for non-base tokens . Generally, these effects are stronger for nominal number learning, and stronger for structurally supervised models than for the LSTM, which is consistent with the findings presented in the main body of the text.     The nominal number breakdown for base contexts can be seen in Figure , with accuracy scores for singular nouns  in red and plural nouns \texttt{NNS}) in teal. Over all, models tended to show higher accuracy scores for singular nouns, which indicates the presence of a singular bias. Interestingly, the ActionLSTM and the RNNG are capable of overcoming the singular bias when presented with sufficient data, however the LSTM remains equally biased for tokens seen 2 and 100 times in training.        The nominal number breakdown for transformed can be seen in Figure . The empirical picture is more complicated here, however if anything models show higher performance for plural nouns. This behavior suggests that is sets up weaker expectations for singular nouns than are does for plural nouns. Such a pattern is consistent with the hypothesis that models learn the singular as a base form, in which case it would set up weaker expectations for singular nouns. These results compliment those from \citet{an2019representation} , who also test in inverted settings and find that models tend not to be surprised at coordinated NPs following a singular verb, as in the ungrammatical sentence *What is the pig and the cat eating?     The breakdown for argument structure learning base contexts can be seen in Figure , with accuracy scores for intransitive verbs in red and transitive verbs in teal. Here, we see a strong transitive bias for the two structurally supervised models, with no obvious bias for the LSTM and an intransitive bias for the -gram.      The breakdown for argument structure learning in the transformed contexts can be seen in Figure  with transformation tests on the top and invariance tests on the bottom. In this case, where performance is different between the two conditions models display higher accuracy scores for transitive verbs.  
","     Although \bert is widely used by the \nlp community, little is known about its inner workings. Several attempts have been made to shed light on certain aspects of \bert, often with contradicting conclusions. A much raised concern focuses on \bert's over-parameterization and under-utilization issues. To this end, we propose o novel approach to fine-tune \bert in a structured manner. Specifically, we focus on Large Scale Multilabel Text Classification  where documents are assigned with one or more labels from a large predefined set of hierarchically organized labels. Our approach guides specific \bert layers to predict labels from specific hierarchy levels. Experimenting with two \lmtc datasets we show that this structured fine-tuning approach not only yields better classification results but also leads to better parameter utilization.",223
"  Deep neural network-based  models have demonstrated remarkable performance on a multitude of text-to-text \cite[inter alia]{bahdanau-attention,bert-to-bert,narayan-etal-2018-dont,rush-etal-2015-neural} as well as data-to-text generation tasks \cite[inter alia]{wiseman-etal-2017-challenges,puduppully-etal-2019-data}.  % To reach high performance, DNN models require a large training corpus which is normally not readily available. Indeed, it is rare to have a sufficiently large human-curated corpus of parallel data , and researchers have come up with heuristic rules to mine input-output pairs on a large scale .  No matter how powerful, DNN models are known to be sensitive to data artifacts  and pick on the noise in the training data.    While hallucinations have not been defined formally, the term is standardly used to refer to the generated content which is either unfaithful to the input, or nonsensical . In our work we are concerned with the former hallucination kind which is primarily caused by imperfect quality of the training data. %  If the data are noisy, how can one reduce the chances of hallucinating? % One may try to improve the quality of a dataset and clean it from phrases for which a clear support in the input is missing, or augment the input with information found only in the output. The former path is risky as it easily results in ungrammatical targets. The latter approach of enforcing a stronger alignment between inputs and outputs has been tried previously but it assumes a moderate amount of noise in the data .  % Alternatively, one can leave the data as is and try to put more pressure on the decoder to pay attention to the input at every generation step . This requires significant modifications to the model and may make it harder for the decoder to generate fluent and diverse text as found in the targets.   In contrast to the described approaches, our proposal is to train the model on the data as is without modifying the decoding  architecture but instead introduce a handle on the input side to control the degree of hallucination . With this ""hallucination knob"" one can minimize  the amount of unsupported information in the output during generation . The hallucination or noise degree of every training instance is estimated separately and converted into a categorical value which becomes part of the input, like in a controlled generation setting . We introduce a simple technique to measure the amount of noise in every training example which is based on the intuition that whenever a language model  has a smaller loss than a conditional generator during forced-path decoding, it is a good signal that the next token cannot be explained by the input. % .  We consider a particularly noisy dataset, WikiBio , which has been found to have extra information in 62\% of the references  and where 1:1 correspondence between the input and the output never holds \citet{perez-beltrachini-gardent-2017-analysing}. Our models demonstrate superior performance to the model of  which reports SoTA BLEU results on WikiBio.  % In sum, our contributions are  a novel idea of controlling hallucinations which requires no modification to the model,  a data- and task-independent technique of implementing this idea and  three-way evaluation with human raters which confirms that faithfulness does not need to be traded for coverage.       In this work, we present novel techniques that enable successful offline reinforcement learning on any base language model from real human conversations. This allows the dialog systems practitioner to train models that learn language structure from vast, readily-available corpora, then fine-tune for specific desirable behaviors post-hoc through RL rewards.   We observe that the new offline RL method successfully optimizes both generated bot rewards and elicited human responses. We show that it presents a better option than using regularization in training a specific bot behavior. Further, RL currently remains the only option for maximizing user feedback over the course of a conversation.   Compared to prior work in offline RL, the novel WOP offline RL algorithm achieves higher performance in traditional RL tasks, elicits more positive feedback in conversations with novel humans at test time, and earns overall higher human ratings.  A limitation of our study is that the question of what to optimize with RL to improve overall qualitative ratings remains open.  We have shown that manual ratings are too sparse to optimize effectively, and instead suggest using implicit rewards. However, our reward set proved insufficient to achieve higher human quality ratings, at least with the limited offline training data we were able to collect. It is unlikely the rewards proposed here fully cover what it means to have a high quality open-ended conversation. Future work should investigate more rewards for training an open-domain dialog model such as long term conversation rewards that may need to be computed over many conversation turns.   Our work computes conversational rewards based on dialog data and annotations from online task workers in the United States. Considering the broader impacts of our work, a representative and diverse set of conversations and annotations should be collected before real world systems are trained and deployed using our algorithms.   We have shown that the proposed techniques can be useful for shaping dialog model behavior towards a desired objective. For many practical applications, we may have specific requirements for the language generated by a model---for example, that it is appropriate, positive, and polite---even if this leads to a lower perception of conversation quality for some users. We have shown that the Way Off-Policy algorithm provides a more effective way to teach a language model specific behaviors from offline data than previously proposed RL or regularization techniques.  \section*{Acknowledgments} We would like to thank Scott Fujimoto for insightful email correspondence on this topic, approval of the DBCQ algorithm, and suggestion to apply model averaging. We would like to thank Sudha Rao and Yonatan Bisk for helpful guidance and feedback in the re-framing and re-writting process of this work. We also thank Max Kleiman-Weiner, Ardavan Saeedi, Sebastian Zepf, Sara Taylor, Oliver Saunders Wilder, Kyle Kastner, Marissa Zhang, and Kristy Johnson for their helpful discussions about this project, and many others for helping test-drive our bots.  We thank the MIT Quest for Intelligence, and MIT Stephen A. Schwarzman College of Computing, and the Machine Learning Across Disciplines Challenge for providing computing resources, and MIT Media Lab Consortium for the support of this research. This work has been partially supported by RTI2018-095232-B-C22 grant from the Spanish Ministry of Science.      \section{Reproducibility}   \subsubsection*{Baseline Models}  The underlying architecture of the baseline language models employed for this work is a Variational Hierarchical Recurrent Encoder Decoder  . We also conduct a second set of experiments on an enhanced version of this model with additional knowledge distillation to improve the model's ability to track the sentiment and semantics of the conversation, as proposed by \citet{ghandeharioun2019approximating}. The language models were originally trained on two datasets: movie dialogs  and a dataset scraped from  .  The underlying parameters of the VHRED model were as follows: Context RNN hidden size , decoder hidden size , encoder hidden size ,  embedding size , gradient clip , dropout . The maximum conversation length was fixed at 5 utterances , and the maximum sentence length was 30 tokens. The VHRED model has  million parameters.   We also added layers to the Context RNN and regularized it to be able to predict the semantic content of the input utterance using a form of knowledge distillation  from a state-of-the-art sentence-embedding model . There were 2 additional feedforward semantic prediction prediction layers of size 128, which used ReLu activation. The VHRED model with sentiment and infersent regularization has  million parameters.   Each RL model was trained on a NVIDIA GeForce GTX 1080 GPU.    \subsubsection*{RL Models} The RL models, the main focus of our work, were trained using human conversation data collected via the online interactive platform  and batch size was fixed at 32. Each model was trained for  epochs. The RL models were initialized with the weights of the best model trained on the Reddit dataset. Early stopping was used to determine the number of training iterations of the best checkpoint. For each bot, 3 different stopping epochs were tested and the best was selected. The checkpoint was selected using manual tuning based on interactive chat with the chatbots. For the best performing bots, KL-Control  and KL-Control , the 1600 and 1800 epoch checkpoints were selected respectively.   The reward weights were also tuned to determine which weighting of rewards produced the desired bot behavior. We tried uniform weights  and slightly increased weights for repetition rewards and human bot interaction rewards. The best weights were found to be assigning  to repetition and human bot interaction rewards and  to all other rewards. Reward weights were also determined using manual tuning and conversational interaction. The same reward weights were shared between all RL models we trained. Only 3 sets of weights were tried in the reward weights hyperparameter optimization process.   All other hyperparameters were shared between RL models, and were as follows: discount , weight placed on RL reward vs. KL-divergence term , number of Monte Carlo samples of the Target -network , target network update rate , learning rate . We used a smooth  loss function to approximate the -values, and clipped gradients at a value of . The RL models have a total of  parameters .   } \\ \hline VHRED-EI Baseline   & 3.11  .41         & 4.34  .44         & 4.66 .49  & 3.02  .47          & 3.45  .47          & 18.59 1.76          & 0.19          & -0.05\\ \hline DBCQ                & 1.64  .48         & 1.87  .34         & 3.13 .58  & 1.84  .34          & 2.09  .38          & 10.58 1.55          & -0.23         & -0.02 \\ Batch              & 1.87  .30         & 2.36 .42          & 2.20 .41           & 1.91 .32           & 2.58 .47           & 11.91 1.58          & -0.16         & 0.00 \\ Batch  + MC        & 1.85  .39         & 2.46 .44          & 2.46 .52           & 1.98 .39           & 2.34 .49           & 11.07 1.82          & -0.07         & 0.03  \\ KL-control         & 2.38 .39 & 3.24 .47          & 3.42 .54           & 2.38 .45  & 2.56 .43           & 13.98 1.81          & 0.02          & 0.01  \\ KL-control    & 2.33 .41            & 3.73 .53  & 2.82 .50            & 2.31 .44  & 3.47 .50  & 14.67 1.82 & 0.13 & 0.03 \\ \hline  }      } & Quality & Fluent & Diverse & Related & Empathy & Total  & Votes &   \\ \hline Conv. len.      & 2.20 .40             & 3.61 .53           & 3.02 .52            & 2.25 .46            & 2.48 .45            & 13.57 1.84          & -0.04          & -0.01  \\ Infersent Coher.   & 1.93 .34          & 3.50 .45           & 2.37 .45            & 2.11 .45            & 2.52 .48            & 12.43 1.75          & -0.02          & -0.01  \\ User laughter   & 1.96 .38             & 3.56 .48           & 2.33 .51            & 1.93 .42            & 3.20 .55            & 12.98 1.60          & -0.15          & -0.01 \\ User Word Len  & 2.11 .32              & 3.96 .44           & 3.04 .45            & 2.04 .35            & 2.55 .46            & 13.70 1.44          & 0.06           & 0.04  \\ Manual votes    & 2.14 .38             & 3.47 .45           & 2.91 .47            & 2.07 .39            & 2.42 .46            & 13.00 1.65          & -0.03          & 0.01 \\ Sent. trans.    & 2.02 .31             & 3.71 .49           & 2.98 .50            & 2.04 .42            & 2.84 .48            & 13.60 1.63          & 0.03           & 0.01  \\ Bot Question        & 2.29 .37         & 4.31 .50  & 3.31 .52   & 2.20 .40            & 2.60 .41            & 14.71 1.63          & 0.06           & 0.04  \\ User Sentiment       & 2.47 .32   & 4.05 .45           & 3.23 .46            & 2.42 .39            & 3.23 .55   & 15.40 1.49 & 0.09  & 0.04  \\ \hline }        Each RL model was trained on a NVIDIA GeForce GTX 1080 GPU. Training models for 2000 epochs took approximately 30 minutes for each model. The runtime for training the VHRED baseline models is around 6 hours. The speediness of training the RL models illustrates the scalability of RL training in improving dialog models for specific features.    We use interactive human evaluation through an online chat interface. Human participants are recruited using Amazon Mechanical Turk and rate either 7 or 8 bots each. Participants were instructed to continue the conversation through at least 6 human responses. After the conversation, participants are asked to rate each bot in terms of Quality, Fluency, Diversity, Contingency, and Empathy on a 7-point Likert scale. A detailed example of the chat and interaction platform can be found in Section . Since our models are evaluated using interactive chat, we also validate our models through interactive chat and rate the models while tuning hyperparameters. The authors interacted with and rated bots during to validate bots.    \section{Offline-RL with VHRED with Emotion and Infersent Regularization} We also conducted experiments using each offline RL algorithm with a Sentiment and Infersent regularized VHRED Model. As described in Section , by adding about 20 million extra parameters to the VHRED model in order to better achieve semantic coherence and sentiment contingency, the VHRED-EI  model is a better performing baseline in terms of human ratings .   We conducted the same human experiments where we recruited participants from Amazon Mechanical Turk to chat with and rate each dialog model. We found similar results as presented in our main paper. While our KL-control models achieved higher qualitative ratings than the other offline RL algorithms, none of the RL models received higher qualitative ratings than the VHRED-EI Model . We also replicated training the KL-Control  model on single rewards and found that training on User Sentiment elicited the highest human qualitative ratings . This consistent with our results on the VHRED model.                       \section{Traditional RL experiments}  To demonstrate the effectiveness of these techniques, we tested them on traditional RL tasks using the OpenAI gym , focusing on the CartPole-v0 and Acrobot-v1 experiments. We first train an online -learning Behavior policy, and store all  experience samples into a replay buffer. We use this buffer to train a prior model of  using a Variational Auto-encoder. The VAE was trained to reconstruct the next state given the current state, , using a mean-squared error loss.  The next action was predicted from the latent embedding , meaning the model learned three functions: , , and . For Cartpole, both the encoder and decoder were made up of two linear layers with 750 neurons each. The latent dimension of the VAE was size 256. For Acrobot, the encoder and decoder had only one layer of size 256 each, and the latent dimension was 64.   This VAE is used as a part of both the DBCQ and WOP algorithms. We can also use it for imitation learning, by sampling actions directly from  to obtain Behavioral Cloning . We benchmark all of these techniques against vanilla -learning on the batch data . All -networks shared the same underlying architecture: three fully-connected layers of size [256, 128, 64], with ReLU activation between. All models were trained with the Adam optimizer .   For each experiment, we ran 50 trials of each model with a different random seed each time. The Behavior policy was trained for a total of 20,000 steps in the environment, so in the Full buffer condition offline agents saw 20,000 experience samples. The Behavior policy typically converged before 10,000 steps, so in the Expert demonstrator condition the offline agents received the last 10,000 experience samples from the trained agent. In the Concurrent condition, offline agents saw a moving window of 1000 samples, since the online learner only used the most recent 1000 samples in the buffer for learning. The learning rate was .001, , and  decayed linearly from 1.0 to .01 over 2000 steps.  The KL-constraint was computed as , where  and . DBCQ sampled  actions before selecting the best action based on the maximum -value; note that in this environment there are only 2 actions. For Cartpole we used the -learning loss, and for Acrobot we used the traditional -learning loss.  We experiment with four different conditions which vary the quality of the Behavior policy and the replay buffer data: a) Full buffer: all experience samples experienced during online training are used for offline learning; b) Concurrent: the offline learning algorithms see a sliding window of experience samples in the same order that the online learner experienced them; c) Expert demonstrator: the buffer only contains experience generated by a fully trained online learner; and d) Noisy demonstrator: the online learner has a high probability of acting randomly  and is thus a bad model of the optimal policy.   Figure  shows the results. Across conditions, we see that WOP is able to outperform Batch , imitation learning , DBCQ, and the original behavior policy. As expected, Imitation learning  underperforms other techniques when the batch contains noisy or inexpert experience samples. However, when the batch contains only expert trajectories, Batch  fails to learn, because the batch does not cover the full state-action space well, increasing extrapolation error. DBCQ matches or outperforms BC and Batch  in all scenarios. However, because DBCQ acts by sampling from  as learned by the BC model, its performance suffers when the batch data is noisy or imperfect. In contrast, WOP is able to learn to trade-off staying close to the prior and obtaining higher reward, and consistently outperforms all other algorithms in this environment.    \section{Additional results}    Figure  shows the KL-divergence between RL policies and the prior language model throughout offline RL training. Without KL-regularization, the baseline RL models diverge quickly and continuously from the prior, losing information about realistic sequences. This figure also helps explain the poor performance of DBCQ in Table . The underlying -network in DBCQ does not directly integrate the prior. As -learning causes the model to diverge from the prior, the -estimates of language generated according to the prior become unrealistic, and selects unrealistic actions. This results in highly `diverse'  generated utterances. Note that since we operate in discrete action space, we could not include the perturbation model originally proposed by , which may be critical to achieving good performance with BCQ.  \section{Implicit Rewards Details} The total reward used to train the bots is a combination of the rewards described in Table . These rewards were selected based on the average z-score of rewards for utterances that were upvoted and downvoted. Figure  shows all the user rewards and that User Laughter and User Sentiment reward scores correlate with upvotes and downvotes. Figure  shows all the bot rewards with Bot Sentiment, Bot Laughter, Bot Convo. Repetition, and Bot Utterance Repetition as rewards that correlate with manual votes. Figure  shows the bot-user combined rewards, and that Word Similarity and USE Similarity are the rewards that correlate with manual up and downvotes.                    Based on prior work , we use the number of turns in the conversation as an indicator of the quality of the bot's performance. To distribute this reward over every utterance in the conversation, we take the total conversation length , and compute the discounted reward for utterance  as  . We also reward each utterance with the number of words and characters in the user's response, which we refer to as User Ans. Word Len and User Ans. Char Len.  We also examine how long bot responses are with the Bot Response Length reward.    Laughter has been shown to be very important to human affiliation  and solidarity . Therefore, we detect the number of occurrences of strings indicating laughter  in the user's response, and use this as a reward. Interestingly, we find that bots trained to maximize user laughter learn to be extremely supportive and cheerful compared to other bots .   Language style matching has been shown to be a strong predictor of relationship initiation and stability . While it would be ideal if our chatbots could intelligently adapt their conversation style to a new user, in reality most baseline dialog models struggle to maintain topic coherence, even over a few utterances . Therefore we reward semantic similarity between the user's input and the bot's response, to encourage the bot to stay on topic and produce reasonable answers. The Infersent Cornell Coherence and Infersent Reddit Coherence rewards are computed using a sentence embedding model trained on the Reddit and Cornell corpora respectively . We use the Universal Sentence Encoder  to compute the USE Similarity reward. We also directly compute word overlap as a reward as Word Similarity.    Asking questions is an important listening skill, and is linked to conversation management, attentiveness, and responsiveness . Therefore, we give the bot a reward of 0.5 if the utterance contains a question word , and an additional 0.5 if it contains a question mark. We refer to this reward as Bot Question.     After training the bots on these rewards, we noticed a shift in the distribution of their language towards more polite, cheerful, and supportive speech. Therefore, we designed post-hoc metrics to measure these qualities, which are based on counting whether a subset of phrases is present in an utterance.  Compliment phrases: you are beautiful, you are so beautiful, you're beautiful, you're beautiful,                    you are the best, you're the best, i like you, you're a good,                    you re a good, i love the way you  Politeness phrases: if I may; may I; please; thanks; no worries; if you don't mind; have a great day; I'm sorry.  Supportive phrases: you're right; you are right; you're not alone; you are not alone; congrats; that's a good idea; that is a good idea; you'll be fine; you will be fine; you'll be okay; you will be okay; it will get better; sorry you're going through; sorry you are going through; if it makes you feel better; if it makes you feel any better; keep your head up; keep it up; I'm in a similar situation; I am in a similar situation; you'll get it; you will get it; happy for you; I'm in the same boat; I am in the same boat; if you feel like you need to vent.               Cheerful phrases: nice to hear; happy; excited; really nice; glad; the best; great; good time; looking forward; beautiful.   We also want to discourage our bot from malicious or offensive language. \citet{saleh2019hierarchical} incorporate a Toxicity Classifier trained with data from the Toxic Comment Classification Challenge\footnote{} as a reward in the training hierarchical RL dialog models. We compute Toxicity reward scores using this classifier as Bot Toxicity .    Specificity within a conversation is valuable in avoid exchanging vacuous phrases back and forth. However building a chit-chat bot without a knowledge graph back-end limits the level of substance that can be incorporated into a conversation. We use the approach from  of computing normalize IDF to create more specificity in the conversation. We compute NIDF on both user  and bot  text.    While minimizing repetition is a common implicit goal of dialog systems, we will explicitly optimize for reducing repetition through repetition rewards. We compute utterance repetition by the number of non-unique words in each utterance as Bot Utterance Repetition Reward. We compute conversation repetition by the number of non-unique words in each conversation as Bot Convo. Repetition Reward. These rewards are negated since we want a higher reward score for less repetition. We also remove stop words in the computation of non-unique words.  \section{Interactive bot platform details}  To collect data from humans interacting with our bots, we built a platform for hosting deep neural network dialog models online on GPU for fast, real-time inference. Figure  shows an example of the interface, in which users are able to rate the bots after talking to them for at least three turns.     Note that during the chat, annotators can optionally click the up and down arrows beside each chatbot response to give feedback on the specific utterance. Once 6 or more turns of the conversation has taken place, participants may click ``Close Chat and Rate"" to get to the rating screen.   We train our RL models based on chat data collected on this platform. Currently, the conversations contain Personally Identifiable Information such as user name, age, location, etc. We obtained for IRB approval for this study and cannot release the conversations at this time in their current form.       The server was hosted on a Google Cloud Platform virtual instance with 64GB of RAM and a NVIDIA Tesla P100 graphics card. The backend was a Django program being served by NGINX and uWSGI. For simplicity, we opted to have the Django process import the chatbots into the same Python process as Django, rather than have the two connect to each other via other means such as sockets. This configuration decreased development time and increased reliability, but it would need to be revisited if the server needed to scale several orders of magnitude past what was required for this study. The current configuration was still able to support hundreds of simultaneous users and host more than 30 bots concurrently.  The chatbots were kept in a separate project from the Django project and maintained separately from the server code. Each chatbot extended an abstract class that defined key methods for the Django program to use, and was registered to a globally accessible dictionary via a decorator. The Django project was provided the path to the Chatbots project in its PYTHONPATH, so it could import the dictionary in which all the chatbot objects had been registered and use that to dynamically determine which chatbots were available and to access them in its views.  It is important to note that the chatbots used PyCUDA, and PyCUDA does not work in a multiprocessing environment. Because of this, uWSGI needed to be configured to only have one python process and to disable any attempt at multiprocessing. Furthermore, the chatbots required substantial startup times, so all chatbots are kept in memory at all times in the Django process. In order to keep all the chatbots in memory concurrently, we needed a very high amount of RAM on our server and opted for a 64GB virtual instance, and a GPU with 16GB RAM. This combination of CUDA to run the chatbots on the GPU with a high amount of RAM to keep all bots in memory at the same time resulted in incredibly fast server response times, with effectively no increase in response time when using the bots in requests compared to requests that did not.  For further information and instructions on server configuration, please read the server documentation available at . We hope that this platform will allow others to host their own bots and evaluate them in an interactive setting.   
"," Neural text generation  demonstrates remarkable performance when training data is abundant which for many applications is not the case.  To collect a large corpus of parallel data, heuristic rules are often used but they inevitably let noise into the data, such as phrases in the output which cannot be explained by the input.  Consequently, models pick up on the noise and may hallucinate--generate fluent but unsupported text.  Our contribution is a simple but powerful technique to treat such hallucinations as a controllable aspect of the generated text, without dismissing any input and without modifying the model architecture. On the WikiBio corpus \cite{lebret-etal-2016-neural}, a particularly noisy dataset, we demonstrate the efficacy of the technique both in an automatic and in a human evaluation.",224
"   %   %Added value of \atomicTT{}: 1) diversity in terms of vocab, style, concepts, 2) higher quality   %\ronan{Cite publications that used ATOMIC in a downstream application}  Commonsense understanding % knowledge modeling and reasoning remain long-standing challenges in general artificial intelligence.  % However, in the subfield of natural language processing, the last few years have brought tremendous progress in AI applications.  However, large-scale language models have brought tremendous progress in the sub-field of natural language processing.  Such large-scale language models   trained on extreme-scale data have been shown to effectively adapt to diverse downstream tasks, achieving significant performance gains across natural language benchmarks .  %%%%%%%OLD %%%%%% Despite these successes, these models have been shown to learn brittle representations, often from only simple surface word associations , which routinely lead them to make nonsensical predictions detached from common sense . Interestingly, as these models have grown larger , their benchmark performance has continued to improve  despite limited conceptual improvements,  %leading many researchers to conjecture as to  leaving open questions regarding  the source of these remarkable generalization properties.   Recent work has hypothesized that many of these performance gains could be a result of language models being able to memorize facts in their parameters during training  that can be leveraged at evaluation time. As a result, a new paradigm of language models as knowledge bases has emerged . In this setting, language models are prompted with natural language prefixes or questions, and they express knowledge through language generation. The initial success of this paradigm for representing commonsense knowledge  %, combined with limited examples of LMs being successfully integrated with structured commonsense knowledge resources for downstream application,  has led to the optimistic claim that language models comprehensively encode commonsense knowledge, and remove the need for structured knowledge resources. %\antoine{run-on sentence, need to shorten}  We take a more skeptical view of this capacity of language models -- Does scaling up language models actually endow them with commonsense knowledge? While language models can successfully express certain types of knowledge, their best results are observed in narrowly specific conditions -- we show  that they perform better when evaluated on knowledge bases that prioritize ontological relations and whose examples resemble language-like assertions .\footnote{An observation supported by \citet{brown2020language}'s \gpttt{} model, whose best few-shot performance on commonsense knowledge benchmarks comes on the PhysicalIQA  and HellaSwag  datasets.} Consequently, the types of knowledge that can be directly accessed through the language model's interface remains limited.  %Consequently, while these methods are encouraging, they also demonstrate that the limited interface of language models precludes them from expressing the diversity of commonsense knowledge that must be accessible for robust commonsense reasoning.  %\chandra{i am not sure the last line in the paragraph flows logically from the rest of the paragraph. maybe i am missing something?}  However, prior work has also shown that training language models on knowledge graph tuples leads them to learn to express their implicit knowledge directly , allowing them to provide commonsense knowledge on-demand. These adapted knowledge models have exhibited promising results on commonsense benchmarks compared with methods that require linking entities to knowledge graphs . Inspired by these successes, we propose a dual use for commonsense knowledge bases going forward: as static graphs that can be linked to for discrete knowledge access, and as resources for adapting language models to hypothesize commonsense knowledge about un-annotated entities and events.   %%%%%%% OLD %%%%%%%% As a result, recent work has investigated augmenting language models with retrieval mechanisms that query commonsense knowledge graphs  for related facts to the entities mentioned in text. The idea behind these approaches is that access to these facts and the potential to compose them with learned reasoning functions would allow models to more robustly leverage commonsense knowledge to make predictions. Despite the premise of these approaches, they are unfortunately limited by the coverage of the resources used to provide commonsense knowledge facts , motivating the need for new, high coverage resources in the short-term.   % Option 1 % With this second purpose in mind, we shift the design goals of commonsense knowledge resources toward prioritizing pieces of knowledge that are not readily accessible in pretrained language models.  % Option 2 With this second purpose in mind, we propose evaluating commonsense knowledge resources based on the complementary information they can bring to pretrained language models. We construct \atomicTT{}, a new, high-quality knowledge graph with M commonsense knowledge tuples across  commonsense relations. We compare \atomicTT{} with respect to its coverage and accuracy in competition with other highly used CSKGs, such as \conceptnet~. Our results show that \atomicTT{} is able to cover more correct facts about more diverse types of commonsense knowledge than any existing, publicly-available commonsense knowledge resource. However, our results also indicate that there remains a large amount of exclusivity between these KGs, highlighting the challenge of creating resources that cover the scale and diversity of general commonsense knowledge.   %%%%%%% OLD %%%%%%Meanwhile, a new paradigm has emerged that proposes that large-scale language models implicitly learn to represent large amounts of factual and commonsense knowledge . While these methods are promising, they also show that the limited interface of language models precludes them from producing commonsense knowledge robustly. However, using knowledge graph tuples as additional training signal allows these model to be better adapted to representing knowledge . Furthermore, the use of these knowledge models to provide commonsense knowledge on-demand has shown promising results over static knowledge graphs . Consequently, in this work, we propose evaluating commonsense knowledge resources on a new, second purpose: whether they can be used to repurpose language models for commonsense modeling.   Furthermore, we formalize the \comet framework of \citet{Bosselut2019COMETCT} across different seed language models and training knowledge graphs, and evaluate the commonsense knowledge hypothesized by these adapted knowledge models. %Our results indicate that this purpose is a promising evaluation for commonsense resources, as \comet models can successfully hypothesize plausible knowledge for new, unseen entities.  Our empirical study yields two promising conclusions. First, it confirms that KG-adapted language models learn to express knowledge more precisely than naive language models trained only on language. And second, we show that \atomicTT{} as a transfer resource leads to \comet models that achieve the largest increase over their seed language model  for the commonsense knowledge types it covers, validating the importance of constructing knowledge resources with examples of knowledge not readily found in language models. %allows language models to learn representations of commonsense knowledge types that are less covered in naive language models. % Furthermore, a comparison of these \comet models across different commonsense knowledge graphs shows that \atomicTT{} as a transfer resource allows language models to learn richer commonsense knowledge representation than training with other resources.   %   Key Contributions:  In summary, we make three key contributions in this paper. We present \atomicTT{}---a new commonsense knowledge graph covering social, physical, and eventive aspects of everyday inferential knowledge . Next, we compare \atomicTT{} with other prominent CSKBs head-to-head and show that our new symbolic knowledge graph is more accurate than any current CSKB  . Finally, we show that our new neural knowledge model \comet{}-\atomicTT{} successfully transfers \atomicTT{}'s declarative knowledge to beat \gpttt{}, the largest pre-trained language model, in spite of using ~400x fewer parameters  . This demonstrates the utility and importance of high-quality symbolic knowledge provided by \atomicTT{} to generalize on commonsense information that LMs cannot expressively capture on their own .  % * Our new symbolic knowledge graph ATOMICTT is superior in accuracy and coverage to the currently existing large-scale knowledge graphs .  % * our neural knowledge model COMET-ATOMICTT successfully transfers the ATOMICTT's declarative knowledge to beat even the most impressively large pretrained model, GPT-3 . This demonstrates LMs, no matter its size, can benefit from the symbolic knowledge provided by high quality KB like ATOMICTT.      Comparing the two methods of estimating the amount of hallucinations in a target, for applications where the input and the output use the same vocabulary with a comparable term distribution the overlap method may be better as it has a clear foundation.    The LM-based method that we proposed has an important advantage that it makes no assumptions about the data. In our WikiBio experiment it also produced better results in the human evaluation, presumably because it allowed for paraphrasing and straightforward inferences. For example, the target ozren nedoklan was a yugoslav footballer and manager. has a high  score because the source table has no occupation field and does not mention yugoslav. The  score of that example is zero because footballer and manager can be inferred from the names of the clubs and the manageryears fields in the source.  \paragraph{Possible extensions} It should be emphasized that alternative methods of detecting noise can be explored and may perform better in the controlled-hallucination framework. For example, it is possible to measuring target-source similarity in an embedded space or use word alignment tools to find unsupported information.   While here we have focused on eliminating hallucinations, one can think of applications where one is interested in generating adversarial sentences which sound fluent but are guaranteed to include unsupported information. Figure  shows how the amount of hallucinations in the output increases following the value of the hallucination knob.  \paragraph{Why is BLUE so different?} It is striking that while all the models tested outperform \citet{liu-2018-structure-aware} in terms of PARENT and human evaluation scores, none could approach its BLEU performance. We do not have an explanation of why this is so but note that our results are in line with the review by \citet{reiter-2018-structured} who concludes that BLEU is an inappropriate metric for generation tasks other than MT.   \paragraph{Can we measure length instead of noise?} One may wonder whether an even simpler approach of controlling for length would deliver a similar reduction in hallucinations. Indeed, hallucinations and length are expected to correlate, and shorter length should result in fewer hallucinations. However, as pointed out in Sec.\ , drastically reducing hallucinations may be possible without any control mechanism and can be achieved, at least on WikiBio, with templates. The main challenge lies in doing so without a big drop in informativeness, that is, in coverage of input fields. Comparing the outputs of  with those of , and both with those of \citet{tian-sticking}, we note that the ranking in terms of average sentence length  coincides with the ranking in terms of coverage : 17.2, 17.8, 18.7. While  may associate the special hal\_0 token with the shortest 20\  of the training data, for  this token is apparently associated with a different selection of 20\  of the data points.   \section{Conclusions}  We presented a simple but powerful idea of controlling hallucinations which are caused by the noise in the training data and proposed two ways of detecting such noise.    We demonstrated that it is possible to reduce the amount of hallucinations at no coverage cost by informing the model about how noisy every source-target example is and without changing the model architecture. Importantly, this was done without making any assumptions about the data.   In an evaluation with humans we showed that the faithfulness of generated sentences can be significantly improved at no loss in fluency or coverage. The results we reported on the noisy WikiBio dataset improve upon the prior work.     
"," % Check out this new knowledge graph! % Storyline: % \begin{enumerate} % \item We introduce \atomicTT. % \item We provide the first side-by-side comparison of commonsense knowledge bases and comprehensive ways to capture precision and coverage. % \item We show how commonsense KGs provide a clear vehicle to access knowledge in LMs.  ).  % \end{enumerate}  Recent years have brought about a renewed interest in commonsense representation and reasoning in the field of natural language understanding. The development of new commonsense knowledge graphs  has been central to these advances as their diverse facts can be used and referenced by machine learning models for tackling new and challenging tasks. At the same time, there remain questions about the quality and coverage of these resources due to the massive scale required to comprehensively encompass general commonsense knowledge.  In this work, we posit that manually constructed CSKGs will never achieve the coverage necessary to be applicable in all situations encountered by NLP agents. Therefore, we propose a new evaluation framework for testing the utility of KGs based on how effectively implicit knowledge representations can be learned from them.   With this new goal, we propose \atomicTT{}, a new CSKG of general-purpose commonsense knowledge containing knowledge that is not readily available in pretrained language models. We evaluate its properties in comparison with other leading CSKGs, performing the first large-scale pairwise study of commonsense knowledge resources. Next, we show that \atomicTT{} is better suited for training knowledge models that can generate accurate, representative knowledge for new, unseen entities and events. Finally, through human evaluation, we show that the few-shot performance of GPT-3 , while impressive, remains $\sim$12 absolute points lower than a BART-based knowledge model trained on \atomicTT{} despite using  over 430x fewer parameters.  % useful they are for training knowledge models that can generate relevant representative knowledge for new, unseen entities.  % In this work, we propose \atomicTT{}, a new knowledge graph of general-purpose commonsense knowledge facts. To evaluate its utility in comparison to existing resources, we perform the first large-scale pairwise study of commonsense knowledge graphs on coverage and precision. Finally, we posit that a new use for commonsense knowledge graphs is their ability to allow large-scale language models to learn to represent knowledge implicitly. We propose a new evaluation for testing knowledge graphs on how useful they are for training knowledge models that can generate relevant representative knowledge for new, unseen entities.",225
"   Despite its successes, neural machine translation  still has unresolved problems. Among them is the problem of rare words, which are paradoxically very common because of Zipf's Law. In part, this is a problem intrinsic to data-driven machine translation because the system will inevitably encounter words not seen in the training data. In part, however, NMT systems seem particularly challenged by rare words, compared with older statistical models.   One reason is that NMT systems have a fixed-size vocabulary, typically 10k--100k words; words outside this vocabulary are represented using a special symbol like \unk{}. Byte pair encoding  breaks rare words into smaller, more frequent subwords, at least allowing NMT to see them instead of \unk{} . But this by no means solves the problem; even with subwords, NMT seems to have difficulty learning translations of very rare words, possibly an instance of catastrophic forgetting .  Humans deal with rare words by looking them up in a dictionary, and the idea of using dictionaries to assist machine translation is extremely old. From a statistical perspective, dictionaries are a useful complement to running text because the uniform distribution of dictionary headwords can smooth out the long-tailed distribution of running text. In pre-neural statistical machine translation systems, the typical way to incorporate bilingual dictionaries is simply to include them as parallel sentences in the training data. But , this does not work well for NMT systems.  We are aware of only a few previous attempts to find better ways to incorporate bilingual dictionaries in NMT. Some methods use dictionaries to synthesize new training examples . \citet{arthur-etal-2016-incorporating} extend the model to encourage it to generate translations from the  dictionary. \citet{post+vilar:naacl2018} constrain the decoder to generate translations from the dictionary. What these approaches have in common is that they all treat dictionary definitions as target-language text, when, in fact, they often have properties very different from ordinary text. For example, CEDICT defines \zh{濮濄倛鍤  as ``'' which cannot be used as a translation. In the case of a monolingual source-language dictionary, the definitions are, of course, not written in the target language at all.  In this paper, we present an extension of the Transformer  that ``attaches'' the dictionary definitions of rare words to their occurrences in source sentences. We introduce new position encodings to represent the nonlinear structure of a source sentence with its attachments. Then the unmodified translation model can learn how to make use of this attached information. We show that this additional information yields improvements in translation accuracy of up to 3.1 BLEU. Because our method does not force dictionary definitions to be treated as target-language text, it is generalizable to other kinds of information, such as monolingual source-language dictionaries, which yield smaller improvements, but still as much as 0.7 BLEU.  }}      \centering          \scalebox{0.8}{%     \textrm{WE}[f]f\textrm{PE}[p]p\textrm{DPE}[q]q$ within a dictionary definition. The rare word \zh{濮濈粯鎹  is replaced with \unk{} and defined as the Dead Sea. The words of the definition are encoded with both the position of the defined word  and their positions within the definition.}      \end{figure*}      \paragraph{Do pretrained language models already encode commonsense knowledge?} Our conclusions on this subject are mixed and hinge on the ambiguous meaning of what it means to encode knowledge. Despite the conclusions of prior work , our results in Table are clear that language models fail to express large varieties of knowledge when prompted for it in a zero-shot manner. When converted to \comet models by training on a knowledge graph, their performance at hypothesizing knowledge tuples skyrockets -- 47.9\  absolute difference between \cometbart{} and \gptxl{} on \atomicTT.   However, the evaluation tuples are adversarially selected to not include head entities that were in the training set. The model must generalize its learned representations of relations to entities it has not observed these relationships for  at any point  during fine-tuning, meaning the representation of these entities is solely formulated from learning language. As a result, language models may still encode this knowledge in their parameters, even if they are not capable of expressing it directly. With this framing in mind, the COMET training paradigm proposed by \citet{Bosselut2019COMETCT} can perhaps be viewed less as a means of learning knowledge from KGs, and more as a method of learning an interface for language models to hypothesize encoded knowledge through language generation. We look forward to future work in this space that attempts to disentangle these two ideas.    What considerations should be made when designing commonsense knowledge resources?  Commonsense knowledge graphs are uniquitous tools for natural language processing agents that must perform commonsense reasoning.  Based on our results in Section, we outline desiderata for the design and development of future commonsense knowledge graphs. Because certain types of knowledge are already encoded and expressible by pretrained language models, CSKG designers should focus on collecting examples and categories of knowledge that are less likely to be known by language models. For example, of the 378 test tuples evaluated by the \gptxl{} zero-shot model that contained the \HinderedBy{} relation, only 1.3\  were deemed plausible by human raters -- jumping to 85\  plausibility for \cometbart{} -- pointing to an advantage in constructing \atomicTT{} with this relationship in mind .  Second, commonsense knowledge resources should be designed with the goal of accuracy and relationship coverage. Because language models exhibit powerful adaptation , they can generalize many commonsense relationships as long they have examples on which to train. Consequently, we should construct commonsense resources that encapsulate larger numbers of relations so the knowledge in pretrained language models can be grounded to a variety of relationships. However, language models also benefit from learning from precise examples. Being able to train on a large collection of examples from \transomcs  did not allow \comet models to generalize to unseen entities as these examples were not of sufficient quality . Resources should be carefully validated for the quality of their facts, an example set by \citet{speer2017conceptnet} and \citet{sap2018atomic}.   \section{Conclusion}  In this work, we formalize a use for commonsense knowledge graphs as transfer learning tools for pretrained language models. With this new purpose, we hypothesize that commonsense knowledge graphs should be designed to contain knowledge that is not already expressible by language models without difficulty . Consequently, we propose \atomicTT, a novel commonsense knowledge graph containing tuples whose relations are specifically selected to be challenging for pretrained language models to express. Our empirical studies demonstrate that \atomicTT contains high-accuracy knowledge tuples across multiple novel relations not found in existing CSKGs or expressible by LMs. Furthermore, we show that \atomicTT can be effectively used as a training set for adapting language models as knowledge models to generate high quality tuples on-demand.    \clearpage     
"," Despite advances in neural machine translation  quality, rare words continue to be problematic. For humans, the solution to the rare-word problem has long been dictionaries, but dictionaries cannot be straightforwardly incorporated into NMT. In this paper, we describe a new method for ``attaching'' dictionary definitions to rare words so that the network can learn the best way to use them. We demonstrate improvements of up to 3.1 BLEU using bilingual dictionaries and up to 0.7 BLEU using monolingual source-language dictionaries.",226
"   % % The following footnote without marker is needed for the camera-ready % version of the paper. % Comment out the instructions  and uncomment the 8 lines % under ""final paper"" for your variant of English. % %  % . %     %  %     % % final paper: en-us version  %     % %     %   % space normally used by the marker %     % This work is licensed under a Creative Commons  %     % Attribution 4.0 International License. %     % License details: %     % \url{http://creativecommons.org/licenses/by/4.0/}. % }   % 1. 鐟欙綁鍣 CCG閿涘奔浜掗崣 CCG 閻ㄥ嫰鍣哥憰浣 % 2. CCG parsing 閻ㄥ嫰鍣搁悙鐟版躬娴 supertagging閵嗗倿娓剁憰浣割嚠 contextual information 閺堝鐦潏鍐ㄣ偨閻 encode 閻ㄥ嫭鏌熷▔鏇樺倸澧犳禍铏规畱閺傝纭堕敍灞间簰閸欏﹤鐪梽鎰剁礄閸欘亪鍣伴悽 powerful encoder閿涘本鐥呴張澶嬪赴濮瑰倿顤傛径 contextual feature 閻ㄥ嫪缍旈悽銊ф畱閻梻鈹掗敍 % 3. n-gram 閺勵垯绔存稉顏呮箒閺佸牏娈 contextual feature閿涘苯褰查懗钘夘嚠 supertagging 閺堝鏁ら敍鍫熷絹娓氭稑褰查懗鐣屾畱鐠囧秳绗岀拠宥勭闂 combination 閻ㄥ嫭娈粈鐚寸礆 % 4. 閹存垳婊戦惃 model   % 鐟欙綁鍣 CCG閿涘矁鐦濆Ч鍥瘱閻ｈ揪绱檚upertag閿涘婀伴煬顐㈠瘶閸氼偂绨℃稉鏉跨槣閻ㄥ嫬褰炲▔鏇炴嫲鐠囶厺绠熼惃鍕繆閹 Combinatory categorial grammar  is a lexicalized grammatical formalism, where the lexical categories  of the words in a sentence provide informative syntactic and semantic knowledge for text understanding. % 閹垫禒 ccg閿涘瞼澹掗崚顐ｆЦ supertagging 瀵板牊婀侀悽 Therefore, CCG parse often provides useful information for many downstream natural language processing  tasks such as logical reasoning  and semantic parsing . To perform CCG parsing in different languages, % 閸 ccg parsing 閸掑棔琚卞銉ｄ靠upertagging 鏉╂瑤绔村銉︽付闁插秷顩 most studies conducted a supertagging-parsing pipline , in which their main focus is the first step, and they generated the CCG parse trees directly from supertags with a few rules afterwards. % which is known as ``almost parsing''   % with essential CCG information for a sentence and one can generate its parse directly from supertags with a few rules. % supertagging 闂囩憰 contextual information %  Building an accurate supertagger in a sequence labeling process requires a good modeling of contextual information. %  Recent neural approaches to supertagging mainly focused on leveraging powerful encoders with recurrent models , with limited attention paid to modeling extra contextual features such as word pairs with strong relations. % Graph convolutional networks  is demonstrated to be an effective approach to model such contextual information between words in many NLP tasks ; thus we want to determine whether this approach can  also help CCG supertagging.  However, we cannot directly apply conventional GCN models to CCG supertagging because in most of the previous studies the GCN models are built over the edges in the dependency tree of an input sentence. As high-quality dependency parsers are not always available, we do not want our CCG supertaggers to rely on the existence of dependency parsers.  %  Thus, we need another way to extract useful word pairs to build GCN models. For that, we propose to obtain word pairs from frequent chunks  in the corpus, because those chunks are easy to identify with co-occurrence counts. %  %  %  % Such features, which may come from n-grams or dependency parsing results, are demonstrated to be helpful for many NLP tasks , and they are expected to enhance CCG supertagging as well. % Among all such features, the ones from n-grams are more attractive since n-grams are easy to obtain and also provide word relation cues, while dependency parsing results are exactly the goal of CCG and thus conflicts with the problem setting. % % As for the model to encode such features, graph convolutional networks  is one of the promising choices although it is often built over the dependency or semantic parse of the input text. %However, GCN suffers from the limitation of obtaining such parsing results, which is exactly the goal of CCG and thus conflicts with the problem setting. % %So that one and they are expected to enhance CCG supertagging. %especially the n-gram ones because they are easy to obtain and can provide cues for word-word combination if they are appropriately modeled. % %\textcolor{blue}{ %To leverage such contextual features, graph convolutional networks  is one of the privileging approaches to do so, where the graph is often built over the dependency or semantic parsing results of the input text. %However, GCN suffers from the limitation of obtaining such parsing results, which is exactly the goal of CCG and thus conflicts with the problem setting. %} % \textcolor{red}{ % Consider that graph convolutional networks , which is an effective solution to learn contextual information and is demonstrated to be useful in many other NLP tasks , can be potentially useful for CCG supertagging.} % , such as semantic role labeling , sentiment classification , and question answering . %input words based on the results of dependency or semantic parsing of the input texts, which may not be an appropriate way to construct graph for CCG, %since the task itself is about parsing. % \textcolor{blue}{ % Therefore, an appropriate way to construct the graph is required for CCG and n-grams could potentially be helpful since they carry contextual information and provide a group of words in which  % its containing words  % they may have strong relationship with respect to word-word combination if the n-grams are appropriately selected. % % } % Previous studies using GCN often build the graph over the dependency or semantic parsing results of the input text, suffering from the limitation of obtaining such parsing results, which is exactly the goal of CCG thus conflicts with the problem setting. % To appropriately learn from n-grams, one requires the GCN to be able to distinguish different word pairs because such information in n-grams are not explicitly structured as that in dependency parses. %In addition, Because existing GCN models are limited in treating all word pairs equally, %while identifying and learning from essential units are important for syntactic tasks, we propose an adaptation of conventional GCN for CCG supertagging. %especially when the graph are not constructed on dependencies. %  % Inspired by that n-grams can carry contextual information and provide a span in which its containing words may have strong relationships if the n-grams are appropriately selected, we build the graph upon well selected n-grams. % , especially the ones containing words with strong relationships between each other,  % % n-gram 閺勵垯绔存稉顏堝櫢鐟曚胶娈 contexutal feature % Consider that n-grams are conventionally used as a simple yet effective method to represent contextual features in many NLP tasks %in which powerful encoders are used  % , % 閸ョ姵顒濋敍瀹-gram 鐎 supertagging 娑旂喐婀侀悽顭掔礉鐏忋倕鍙鹃弰顖炲亝娴滄稖鍏樻径鐔虹矋閹存劗鐓拠顓犳畱 n-gram閿涘矁鍏樻径鐔稿絹娓氭稑鍙ф禍搴ょ槤娑撳氦鐦濇稊瀣？缂佸嫬鎮庨崗宕囬兇閻ㄥ嫪淇婇幁顖ょ礉閺堝濮禍 supertagging % they are also expected to serve as effective contextual features for CCG supertagging, where they, \textcolor{blue}{especially the ones containing words with strong relationships between each other,} % that are valid phrases,  % should provide plausible cues on potential combinations among words. % 閻掓儼宀嬬礉婵″倷缍嶉張澶嬫櫏閸︽澘鍩勯悽銊ㄧ箹娴 n-gram 娓氭繃妫弰顖欑娑擃亝瀵幋姗堢礉閸ョ姳璐熼柇锝勭昂娑撳秹鍣哥憰浣烘畱 n-gram 閸欘垯浜掔拠顖氼嚤 supertagger %\textcolor{blue}{ % However, it is not trivial to appropriately learn from n-grams for syntactic tasks, % where one needs to identify informative n-grams out of all possible combinations of words for the task. %since the unimportant ones carrying misleading cues for the combination may hurt the performance of a supertagger. %}   %       % 閹垫禒銉ь儑娑撳顔岄柌宀勬桨鐏忚精顩﹂崨鐓庣安鏉╂瑩鍣烽惃鍕敶鐎圭櫢绱濈悰銊с仛閸戠儤娼甸幋鎴滄粦閺冦垼鍏橀悽鈺猤ram閿涘苯寮甸懗鐣屾暏GCN缂佹獢gram瀵ょ儤膩 % 閹存垳婊戦幓鎰毉 channeled attention 閺 model 鏉╂瑤绨 n-gram %To address these problems, In this paper, we propose attentive GCN  for CCG supertagging, where its input graph is built based on chunks  extracted with unsupervised methods. % In this paper, we propose attentive GCN  for CCG supertagging, where its input graph is built upon word groups suggested by high confident n-grams extracted from unsupervised methods. % , where the graph is constructed on word groups. %which follows the sequence labeling paradigm. % 鐠囷妇绮忔禒瀣矝婵″倷缍嶅銉ょ稊閿涘矂顩婚崗鍫濐嚠 n-gram 閸掑棛绮 % Inspired by that n-grams can carry contextual information and provide a span in which its containing words may have strong relationships if the n-grams are appropriately selected, we build the graph upon the n-grams in the sentence, where an edge will be added to a pair of words if they are in the same n-gram. In detail, two types of edges in the graph are introduced to model word relations within and across chunks %for the word groups to model the word-word relation within and cross the groups. % we build the graph over the words upon the n-grams in the input sentence, where an edge will be added to a pair of words if they are in a span suggested by the same n-gram. % % For edges within a group, feed-forward attention is applied  and an attention mechanism is applied to GCN to weight those edges. %and discriminately learn from them through the edges. %In addition, for each word, a attention mechanism is used % to weight the contextual information carried by all its associated words  according to their contribution to the tagging process. %  In doing so, different contextual information are discriminatively learned to facilitate CCG supertagging without requiring any external resources. % , with the \textcolor{blue}{within and cross chunk relations} % local and global word relations  % weighted on our in-chunk and cross-chunk edges, respectively. %Moreover, the way of building the graph requires no external resources  %suggested by high confident n-grams is learned by A-GCN through the in-group edges; and long distance relations among groups are also leveraged by cross-group edges. %Therefore, a hierarchical structure of word relations are built  %Besides, our approach proposes a novel self-supervised method to build the graph for GCN, where no extra parsing results  are required as extra input. % , but also our attentive GCN is able to discriminately learn from the contextual information carried by different words.} % In the proposed attention, n-grams associated to each word in the input texts are firstly categorized into different groups according to their length,  % 閻掕泛鎮楀В蹇庨嚋 n-gram 閺夈儱濮為弶 % and then fed into a specific channel of attentions according to their groups, so that the n-grams are weighted separately in each group according to their contributions to the supertagging process. % 婵傝棄顦╅敍宀顑囨稉閺勵垰灏崚顐＄啊闁插秷顩﹂惃鍕嫲娑撳秹鍣哥憰浣烘畱 n-gram閿涙稓顑囨禍灞炬Ц閼宠棄顧勬禒搴ㄥ亝娴滄盯鍣哥憰浣烘畱闂 n-gram 娑擃厼顒熼崚鐗堟纯鏉╂粏绐涚粋鑽ゆ畱 context information % In doing so, not only important n-grams are distinguished, but also can our approach discriminatively learn from n-grams in different length, where the infrequent and long n-grams carrying important long range contextual information are appropriately modeled without being influenced by the frequent short ones. %  % 鐎圭偤鐛欑拠浣规閺堝鏅 The validity of our approach is demonstrated by experimental results on the CCGbank , where state-of-the-art performance is obtained for both tagging and parsing.       In this paper, we presented a simple yet effective way to incorporate dictionaries into a Transformer NMT system, by attaching definitions to source sentences to form a nonlinear structure that the Transformer can learn how to use. We showed that our method can beat baselines significantly, by up to 3.1 BLEU. We also analyzed our system's outputs and found that our model is learning to select and adapt parts of the definition, which it does not learn to do when the dictionary is simply appended to the training data. We also found that our method has some potential to work with monolingual dictionaries.  
","  % supertagging 閻庣敻娑氳壘 CCG parsing 闂傚牏鍋涢悥鍫曟煂瀹ュ牜娲 Supertagging is conventionally regarded as an important task for combinatory categorial grammar  parsing, where effective modeling of contextual information is highly important to this task. % 闂傚嫨鍊撶花鈩冩媴鐠恒劍鏆忛柡鍥ㄦ綑瀹搁亶鎯 encoder闁挎稑鏈惁顔戒繆 biLSTM闁挎稑鑻晶鐘崇閸濆嫷鍤犲ù supertagging 閺夆晜鐟ら柌 task 闁告垹濮崇粻顔尖柦閿涘嫭鏆忛柛鎺楊暒缁牊绋婇崼婵嗙劶闁 context feature闁挎稑鑻畵 n-gram However, existing studies have made limited efforts to leverage contextual features except for applying powerful encoders . % 闁哄牜鍓氶弸鍐晬鐏炴儳鐏夊ù鐙鍓氳ぐ渚宕 channeled n-gram attention 闁哄鍎遍ˇ鈺呮偠閸℃氨绠瑰☉鎿冧邯濡埖锛 In this paper, we propose attentive graph convolutional networks to enhance neural CCG supertagging through a novel solution of leveraging contextual information. %  Specifically, we build the graph from chunks  extracted from a lexicon and apply attention over the graph, so that different  % word relations  word pairs from the contexts within and across chunks are weighted in the model and facilitate the supertagging accordingly. % 閻庡湱鍋ら悰娆戠磼閹惧浜悶娑栧妽濡叉垿鏁嶇仦鎯х亯濞寸媭鍓涘▓鎴﹀棘鐟欏嫮銆婇柡鍕靛灡濠渚寮崼銏＄暠 The experiments performed on the CCGbank demonstrate that our approach outperforms all previous studies % , as well as strong baselines from existing toolkits,  in terms of both supertagging and parsing. %  Further analyses illustrate the effectiveness of each component in our approach to discriminatively learn from word pairs to enhance CCG supertagging.\footnote{Our code and models for CCG supertagging are released at \url{https://github.com/cuhksz-nlp/NeST-CCG}.}",227
" Pre-trained Transformers  have lead to state-of-the-art results on a wide range of NLP tasks, for example, named entity recognition, relation extraction and question answering, often approaching human inter-rater agreement .  These models have also been demonstrated to learn effective cross-lingual representations, even without access to parallel text or bilingual lexicons .  Multilingual pre-trained Transformers, such as mBERT and XLM-RoBERTa , support surprisingly effective zero-shot cross-lingual transfer, where training and development data are only assumed in a high resource source language , and performance is evaluated on another target language. 	 Because no target language annotations are assumed in this setting, source language data is typically used to select among models that are fine-tuned with different hyperparameters and random seeds.  However, recent work has shown that English dev accuracy does not always correlate well with target language performance .  In this paper, we propose an alternative strategy for model selection in a zero-shot setting.  Our approach, dubbed Learned Model Selection , learns a function that scores the compatibility between a fine-tuned multilingual transformer, and a target language. The compatibility score is calculated based on features of the multilingual model's learned representations and the target language.  A model's features are based on its own internal representations; this is done by aggregating representations over an unlabeled target language text corpus.  These model-specific features capture information about how the cross-lingual representations transfer to the target language after fine-tuning on source language data.  In addition to model-specific representations, we also make use of learned language embeddings from the lang2vec package , which have been shown to encode typological information, for example, whether a language has prepositions or postpositions.  To measure compatibility between a multilingual model's fine-tuned representations and a target language, the model- and language- specific representations are combined in a bilinear layer.  Parameters of the scoring function are optimized to minimize a pairwise ranking loss on a set of held-out models, where the gold ranking is calculated using standard performance metrics, such as accuracy or F, on a set of pivot languages .  LMS does not rely on any annotated data in the target language for meta-learning or hyperparameter tuning, yet it is effective in learning to predict whether a multilingual model's representations are a good match for a specific target language.    In experiments on five well-studied NLP tasks , we find LMS consistently selects models with better target-language performance than those chosen using English dev data.  Appendix  demonstrates that our framework supports multi-task learning, which can be helpful in settings where some target-language annotations are available, but not for the desired task.  Finally, we show that LMS generalizes to both mBERT and XLM-RoBERTa in Appendix .             In this paper, we propose A-GCN for CCG supertagging, with its graph built from chunks extracted from a lexicon.    We use two types of edges for the graph, namely, in-chunk and cross-chunk edges for word pairs within and across chunks, respectively, and propose an attention mechanism   where an attention mechanism is used to enhance the model.     Specifically,  we construct the graph based on word groups suggested by high confident n-grams where in-group and cross-group edges are used and A-GCN is able to learn from the word groups through those edges.   an attention mechanism is proposed  to distinguish the important word pairs according to their contribution to CCG supertagging.   婵傝棄顦╅敍宀顑囨稉閺勵垰灏崚顐＄啊闁插秷顩﹂惃鍕嫲娑撳秹鍣哥憰浣烘畱 n-gram閿涙稓顑囨禍灞炬Ц閼宠棄顧勬禒搴ㄥ亝娴滄盯鍣哥憰浣烘畱闂 n-gram 娑擃厼顒熼崚鐗堟纯鏉╂粏绐涚粋鑽ゆ畱 context information   Therefore, not only the important n-grams are distinguished, but also can our approach discriminatively learn from n-grams in different length, especially the long and infrequent ones that carry important long distance contextual information and could be influenced by the majority voting effect.   Therefore, context features are appropriately modeled and the GCN can discriminatively learn from them.     The effectiveness of our approach to CCG supertagging as well as to parsing is demonstrated by the experimental results and the ablation study on the English CCGbank, where state-of-the-art performance is obtained. Experimental results and the ablation study on the English CCGbank demonstrate the effectiveness of our approach to CCG supertagging, where state-of-the-art performance is obtained on both CCG supertagging and parsing.   Further analysis is performed to investigate using different types of edges, which reveals their quality and confirms the necessity of introducing attention to GCN for CCG supertagging.  For future studies,  we plan to explore other approaches to building the graph as well as performing end-to-end   analyze the effect of them on  CCG supertagging and parsing.  
"," Transformers that are pre-trained on multilingual text corpora, such as, mBERT and XLM-RoBERTa, have achieved impressive cross-lingual transfer learning results.  In the zero-shot cross-lingual transfer setting, only English training data is assumed, and the fine-tuned model is evaluated on another target language.  No target-language validation data is assumed in this setting, however substantial variance has been observed in target language performance between different fine-tuning runs.  Prior work has relied on English validation/development data to select among models that are fine-tuned with different learning rates, number of steps and other hyperparameters, often resulting in suboptimal choices.  To address this challenge, we propose a meta-learning approach to model selection that uses the fine-tuned model's own internal representations to predict its cross-lingual capabilities.  In extensive experiments we find that our approach consistently selects better models than English validation data across five languages and five well-studied NLP tasks, achieving results that are comparable to small amounts of target language development data.\footnote{We will make our code and data available on publication.}  %We further demonstrate that our method can benefit from pooling data across tasks when auxiliary annotations are available in the target language.",228
" %   Summarization is the process of identifying the most important information pieces in a document. For humans, this process is heavily guided by background knowledge, which encompasses preconceptions about the task and priors about what kind of information is important .    %  %   % Understanding background knowledge would yield insights about what, on average, humans consider as known, interesting and important.  % Furthermore, accurate models of human background knowledge would be greatly valuable to improve the selection methods of information selection systems.  %  Despite its fundamental role, background knowledge has received little attention from the summarization community. Existing approaches largely focus on the relevance aspect, which enforces similarity between the generated summaries and the source documents . % , without consideration for background knowledge.   In previous work, background knowledge has usually been modeled by simple aggregation of large background corpora. % A prominent example is \cpt{TFIDF} , a practical solution to the problem of identifying content words based on document frequencies within background corpora. For instance, using \cpt{TFIDF} , one may operationalize background knowledge as the set of words with a large document frequency in background corpora.  %While this approach was useful for the stopword problem significant to the development of summarization systems, it is cannot easily be extended to model background knowledge.  However, the assumption that frequently discussed topics reflect what is, on average, known does not necessarily hold. For example, common-sense information is often not even discussed . Also, information present in background texts has already gone through the importance filter of humans, e.g., writers and publishers. In general, a particular difficulty preventing the development of proper background knowledge models is its latent nature. We can only hope to infer it from proxy signals. Besides, there is, at present, no principled way to compare and evaluate background knowledge models.   %  In this work, we put the background knowledge in the foreground and propose to infer it from summarization data. Indeed, choices made by human summarizers and human annotators provide implicit information about their background knowledge. We build upon a recent theoretical model of information selection , which postulates that information selected in the summary results from 3 desiderata: low redundancy , high relevance , and high informativeness . The tension between these 3 elements is encoded in a summary scoring function  that explicitly depends on the background knowledge . % that explicitly depends on the background knowledge .  As illustrated by \Figref{fig:overall}, the latent  can then be inferred from the residual differences in information selection that are not explained by relevance and redundancy. For example, the black information unit in \Figref{fig:overall} is not selected in the summary despite being very prominent in the source document. Intuitively, this is explained if this unit is already known by the receiver.  % and the human summarizer regarded it as not important. To leverage this implicit signal, we view  as a latent parameter learned to best fit the observed summarization data.  %  \xhdr{Contributions} We develop algorithms for inferring  in two settings:  when only pairs of documents and reference summaries pairs are observed  and  when pairs of document and summaries are enriched with human judgments . % The framework also provides an evaluation methodology for , by measuring how well the resulting  correlates with human judgments.  In \Secref{sec:comparison} we evaluate our inferred s with respect to how well the induced scoring function  correlates with human judgments. Our proposed algorithms significantly surpass previous baselines by large margins.   In \Secref{sec:geometry}, we give a geometrical perpespective on the framework and show that a clear geometrical structure emerges from real summarization data.  % The framework is simple, constrained and interpretable but this does not hinder its ability to fit the data. In fact, our proposed algorithms significantly and largely surpass previous baselines in terms of correlation with human judgments.   % The framework is general and inferring human prior on information importance can be of broad use. We explore several applications and briefly discuss potential for future work. The ability to infer interpretable importance priors in a data-driven way has many applications, some of which we explore in \Secref{sec:applications}.  % We explore some of them and later discuss possibilities for future work. \Secref{sec:qualitative_analysis} qualitatively reveals which topics emerge as known and unkown in the fitted priors. % First, it is possible to investigate qualitatively the fitted priors to understand which topics emerge as known and unkown.  % We do so both at the word level and at the topic-model level.  Moreover, we can infer  based on different subsets of the data. By training on the data of one annotator, we get a prior specific to this annotator. Similarly, one can find domain-specific 's by training on different datasets. This is explored in \Secref{sec:annotator_specific}, where we analyze  annotators and  different summarization datasets, yielding interesting insights, e.g., averaging several, potentially biased, annotator-specific or domain-specific 's results in systematic generalization gains. % Adding the inferred 's to summarization systems can produce improvements in the quality of extracted summaries .   Finally, we discuss future work and potential applications beyond summarization in \Secref{sec:ccl}. Our code is available at \url{https://github.com/epfl-dlab/KLearn}     %that averaging various annotator specific 's gives large generalization improvements over single annotators and compared to previous baselines. Furthermore, the average of all annotators performs almost as good as the optimal . Similarly, averaging many domain-specific 's gives significant improvements over baselines in TAC datasets.  %Finally, a more qualitative analysis of the best 's reveals that they capture stopwords and some properties of IDFs even without being exposed to any background corpora.       %Background knowledge is important in summarization and often left out.  %When not left out, it requires design choices and collection of large background corpora.  %Previous work has defined simple models of summarization which involves background knowledge from first principles  %We show that such formulation allows us to infer background knowledge simply from observing human preferences.   %In fact, a probabilistic model is developed that can infer background knowledge only from pairs of document summaries.     In this paper, we presented a meta-learning approach to model selection for zero-shot cross-lingual transfer.  We showed that our approach improves over the standard practice of model selection using source language development data.  Experiments on five well-studied NLP tasks show that by inspecting internal representations, our method consistently selects better models. LMS also achieves comparable results to the slower and more expensive alternative of annotating small amounts of target-language development data.       \subsubsection*{Acknowledgments}    We thank Wei Xu for helpful feedback.    Use unnumbered third level headings for the acknowledgments. All   acknowledgments, including those to funding agencies, go at the end of the paper.        
"," The goal of text summarization is to compress documents to the relevant information while excluding background information already known to the receiver. So far, summarization researchers have given considerably more attention to relevance than to background knowledge. In contrast, this work puts background knowledge in the foreground. Building on the realization that the choices made by human summarizers and annotators contain implicit information about their background knowledge, we develop and compare techniques for inferring background knowledge from summarization data. Based on this framework, we define summary scoring functions that explicitly model background knowledge, and show that these scoring functions fit human judgments significantly better than baselines. We illustrate some of the many potential applications of our framework. First, we provide insights into human information importance priors. Second, we demonstrate that averaging the background knowledge of multiple, potentially biased annotators or corpora greatly improves summary\hyp scoring performance. Finally, we discuss potential applications of our framework beyond summarization. % Finally, we apply our models in a simple yet effective summarization system.",229
"  . }  Definition Extraction refers to the task in Natural Language Processing  of detecting and extracting a term and its definition in different types of text. A common use of automatic definition extraction is to help building dictionaries , but it can be employed for many other applications. For example, ontology building can benefit from methods that extract definitions , whilst the fields of definition extraction and information extraction can employ similar methodologies. It is therefore normal that there is growing interest in the task of definition extraction.  This paper describes our system that participated in two of the three subtasks of Task 6 at SemEval 2020 , a shared task focused on definition extraction from a specialised corpus. Our method employs state-of-the-art neural architectures in combination with automatic methods which extend and clean the provided dataset.  %Task 6 at SemEval 2020  is a shared task for definition extraction from a specialised corpus, tailoured specifically to the needs of definition extraction. This paper describes the RGCL team system that works on all three subtasks of the shared task. We employ state-of-the-art neural architectures and combine them with simple automatic methods to extend and clean the provided dataset where appropriate.  The remaining parts of this paper are structured as follows. First, we present related work in the area of definition extraction and the related field of relation extraction . The three subtasks and the dataset provided by the task organisers are described in Section . Next, we describe our system , followed by the results of the evaluation  and a final conclusion .      We focus on the often-ignored background knowledge for summarization and infer it from implicit signals from human summarizers and annotators. We introduced and evaluated different approaches, observing strong abilities to fit the data.   We also provide geometrical insights for the framework and the inferred background knowledge.  The newly-gained ability to infer interpretable priors on importance in a data-driven way has many potential applications. For example, we can describe which topics should be extracted more frequently by systems to improve their agreement with humans. Using pretrained priors also helps systems to reduce overfitting on the frequency signal within source documents as illustrated by initial results in \Appref{sec:summarization}.   An important application made possible by this framework is to infer  on any meaningful subset of the data. In particular, we learned annotator-specific 's, which yielded interesting insights: some annotators exhibit large differences from the others, and averaging several, potentially biased 's results in generalization improvements. We also inferred 's from different summarization datasets and also found increased performance on the news domain when averaging 's from diverse domains.  For future work, different choices of semantic units can be explored, e.g., learning  directly in the embedding space. Also, we fixed  to get comparable results across methods, but including them as learnable parameters could provide further performance boosts. Investigating how to infuse the fitted priors into summarization systems is another promising direction.   More generally, inferring  from a common-sense task like summarization can provide insights about general human importance priors. Inferring such priors has applications beyond summarization, as the framework can model any information selection task.   Finally, inferring unobserved importance priors is a general problem with applications beyond summarization. The proposed framework can benefit any information selection task.    and the method proposed here can bene information selection task.    Put the focus on the background knowledge   Data-driven way to infer it from implicit signal in summarization data   Proposed several approaches that work with different kind of data    They work well    The general framework for inferring priors has several potential applications.   Some of which we investigated in this work. For example, we found some which topics should be extracted more/less by summarization systems to improve their agreement with human judgments. Also, the use such priors can help systems to not overfit on the frequency signal in original documents     An interesting application is to aggregate on different subsets of data. In particular, we obtained annotator specific and domain specific priors and could compare quantitatively annotators and domains. Interestingly, we find consistent improvements resulting from averaging several, potentially biased, priors.    The framework also has application beyond summarization has the methodology can be easily extended to general information selection tasks .    Within summarization, one can also explore the use of different semantic units, in particular learning  directly in semantic sapce of embeddings could be interesting.   Also, we fix here the parameters  and  to 1, learning this parameters alongside  would give better ability to fit the data. Finally, investigating how to infuse the fitted priors into summarization systems is promising direction for improviment systems.      In this work, we leveraged summarization data to infer background knowledge. We inferred annotator and domain-specific priors and found large benefits resulting from averaging different background knowledge.     For future work, such human priors can be used to improve summarization systems but also automatic evaluation metrics. Another promising direction could study different semantic unit representations, e.g., distributional representations.     In general, a better understanding of human priors and background knowledge can benefit a wide range of applications like information retrieval or dialog systems.                                                                                  Introduction                                                                                    Include this file in all LaTeX papers that you write at dlab by adding a line   """" right after the ""\documentclass"" command.                                                                                    Some standard packages                                                                                  \usepackage[utf8]{inputenc} \usepackage[T1]{fontenc} \usepackage{hyphenat} \usepackage{xspace} \usepackage{amsmath} \usepackage{amsfonts} \usepackage{hyperref} \usepackage{url} \usepackage{booktabs} \usepackage{multirow}  \usepackage{subfig} \usepackage{makecell} \usepackage{caption} \usepackage{minibox} \usepackage{bbm} \usepackage{graphicx} \usepackage{balance} \usepackage{mathtools} \usepackage{color} \usepackage{marvosym} \usepackage{ifthen} \usepackage{textcomp} \usepackage{enumitem} \usepackage{verbatim} \usepackage{algorithm} \usepackage{algorithmic} \usepackage{numprint} \usepackage{balance}  \usepackage{amsthm} \theoremstyle{plain} \newtheorem{theorem}{Theorem} \newtheorem{definition}[theorem]{Definition} \newtheorem{lemma}[theorem]{Lemma} \newtheorem{proposition}[theorem]{Proposition} \newtheorem{example}[theorem]{Example}                                                                                    How to include TODOs and notes                                                                                    Adapted from the widely circulating chato-notes.sty -- thanks, ChaTo!  \newcommand{\chatoDisplayMode}[1]{#1}    If you quickly want to hide all notes, e.g., to check how long your paper   would be without them, add the following line to your preamble or uncomment   it here.   \renewcommand{\chatoDisplayMode}[1]{}    Usage:   \todo[Your name]{What needs to be done}   \note[Your name]{A note to include in a box}   \inote{An inline note}   \citemissing{}   \definecolor{MyRed}{rgb}{0.6,0.0,0.0}  \definecolor{MyBlack}{rgb}{0.1,0.1,0.1}  \newcommand{\inred}[1]{{\color{MyRed}\sf}} \newcommand{\frameit}[2]{      }\\   }    }  \newcommand{\note}[2][]{\chatoDisplayMode{\def\@tmpsig{#1}\frameit{{\Pointinghand} Note}{#2\ifx \@tmpsig \@empty \else \mbox{ --\em #1}\fi}}} \newcommand{\todo}[2][]{\chatoDisplayMode{\def\@tmpsig{#1}\frameit{{\Writinghand} To-do}{#2\ifx \@tmpsig \@empty \else \mbox{ --\em #1}\fi}}} \newcommand{\inote}[1]{\chatoDisplayMode{\inred{{{\Pointinghand} }} {\sf #1} \inred{}}} \newcommand{\citemissing}[0]{\chatoDisplayMode{\inred{[citation]}}}                                                                                    How to make your edits conspicuous                                                                                    In the final stages of editing, it is often useful to mark edits in color, so   everyone can easily see what was changed. To do so, define a command that has   the same name as you and use your favorite color. \newcommand{\bob}[1]{{#1}} \newcommand{\yourname}[1]{{#1}}                                                                                    Latin abbreviations                                                                                    Don't use plain text for Latin abbreviations such as ""e.g."", ""i.e."", etc.   Use these macros instead. Advantage: you can consistently change their style,   e.g., if you want to typeset them in italics at some point.    Latin abbreviations in normal font. \newcommand{\abbrevStyle}[1]{#1}   Latin abbreviations in italics.   \newcommand{\abbrevStyle}[1]{#1}  \newcommand{\ie}{\abbrevStyle{i.e.}\xspace} \newcommand{\eg}{\abbrevStyle{e.g.}\xspace} \newcommand{\cf}{\abbrevStyle{cf.}\xspace} \newcommand{\etal}{\abbrevStyle{et al.}\xspace} \newcommand{\vs}{\abbrevStyle{vs.}\xspace} \newcommand{\etc}{\abbrevStyle{etc.}\xspace} \newcommand{\viz}{\abbrevStyle{viz.}\xspace}                                                                                    Referring to sections, figures, tables, etc.                                                                                    To refer to sections, figures, tables, etc., use the following macros.   Don't type ""Section~1"", ""Fig.~1"", etc., manually. This way, you can easily   and consistently switch between styles, e.g., if you want to use ""Sec.""   instead of ""Section"" at some point.  \newcommand{\Secref}[1]{Sec.} \newcommand{\Eqnref}[1]{Eq.} \newcommand{\Dashsecref}[2]{Sec.--} \newcommand{\Dblsecref}[2]{Sec. and } \newcommand{\Tabref}[1]{Table} \newcommand{\Figref}[1]{Fig.} \newcommand{\Dashfigref}[2]{Fig.--} \newcommand{\Appref}[1]{Appendix} \newcommand{\Thmref}[1]{Thm.} \newcommand{\Lemmaref}[1]{Lemma} \newcommand{\Defref}[1]{Def.}                                                                                    Paragraph headings                                                                                    Academic text is often much more legible if you give important paragraphs a   concise name that describes what the paragraph is about. Use the \xhdr   command for this. \newcommand{\xhdr}[1]{{{\bf #1.}}}    Same as \xhdr, but without a period after the heading. Use this version if   the heading is directly integrated into the first sentence of the paragraph;   e.g., ""\xhdrNoPeriod{Results} are shown in \Figref{fig}."" \newcommand{\xhdrNoPeriod}[1]{{{\bf #1}}}                                                                                    More compact lists                                                                                    In some styles, list items are widely spaced. To condense them and save some   space, you may use this command. \newcommand{\denselist}{ \itemsep -2pt\topsep-10pt\partopsep-10pt }    Same, but with slightly different spacing. \newcommand{\denselistRefs}{ \itemsep -2pt\topsep-5pt\partopsep-7pt }                                                                                    Miscellaneous useful macros                                                                                    Some bibliography styles make it hard to typeset references like   ""Einstein et al. "". This command provides a convenient way to do so. \newcommand{\textcite}[1]{\citeauthor{#1} \shortcite{#1}}    When you frequently refer to Wikipedia articles, Wikidata entities, etc., it   may be useful to typeset those in a particular font. Use the \cpt  command for this purpose. \newcommand{\cpt}[1]{}}    To exclude a large portion of text from the PDF, wrap it in \hide. \newcommand{\hide}[1]{}    Wrap matrix variables in \mtx. Don't make them bold etc. manually. By using   a macro, you can consistently change the rendering style at any point. \newcommand{\mtx}[1]{\mathbf{#1}}    Transpose of a matrix, e.g., . \newcommand{\trans}{^\top}    \argmin and \argmax. \DeclareMathOperator*{\argmax}{arg\,max} \DeclareMathOperator*{\argmin}{arg\,min}                                                                                    Hyphenation                                                                                    Some words are ill-hyphenated by default. Here you can define the correct   hyphenation once, and it is then used consistently.  \hyphenation{ Wi-ki-pe-dia Wi-ki-me-dia Wi-ki-da-ta De-ter-mine Page-Rank web-page web-pages da-ta-set }                                                                                    Avoid widows!                                                                                    The term ""widow"" refers to the first line of a paragraph if it is the last   line on a page, or to the last line of a paragraph if it is the first line on   a page. Widows are considered a cardinal typesetting sin, so avoid them at   all cost, via the following commands.  \widowpenalty=10000 \clubpenalty=10000                                                                                    Enable section numbering in the AAAI style                                                                                     In the AAAI style, this enables section numbering. \setcounter{secnumdepth}{2}                                                                                    Listing authors in a space-economic way in the ACM style                                                                                    By default, using ""\documentclass[sigconf]{acmart}"" will list authors in rows   of 2, which can take up a lot of space. To get more authors in one row, use   something like this:   \author{     \authorbox{Author 1}{Affiliation 1}{Email 1}     \authorbox{Author 2}{Affiliation 2}{Email 2}     ...   }    If you use \authorbox, you will also have to suppress the standard reference   block, by pasting the following row somewhere before ""     BEFORE BOB'S EDITS:   Despite being an essential aspect of any information selection process, background knowledge has received little attention from the summarization field.      In contrast, this work puts the focus on this neglected component. We emphasize that choices made by human summarizers and annotators contain implicit information about their priors. Thus, we develop and compare several approaches leveraging these signals.    This produces data-driven and interpretable information importance priors that fit human judgment data significantly better than baselines.   We then illustrate some of the many potential applications. First, we investigate which topics received low or high weight in the inferred priors. By using different aggregation of data, we obtain annotator\hyp specific and domain\hyp specific priors. A simple analysis yields interesting insights, e.g., averaging many, potentially biased, priors systematically and greatly improves performance. Finally, the resulting priors can be used to guide summarization systems.              
","   This paper presents the RGCL team submission to SemEval 2020 Task 6: DeftEval, subtasks 1 and 2. The system classifies definitions at the sentence and token levels. It utilises state-of-the-art neural network architectures, which have some task-specific adaptations, including an automatically extended training set. Overall, the approach achieves acceptable evaluation scores, while maintaining flexibility in architecture selection.",230
" Event extraction is a process to extract the named entities, event triggers and their relationships from real-world corpora. The named entities refer to those texts about predefined classes  and event triggers are words that express the types of events in texts . In literature, named entities and triggers are connected and named entities with corresponding roles are called arguments for a given trigger of a specific event.  %Named entities refer to the text mentions with predefined classes such as person names, company names and locations, etc. An event trigger is a word that mostly expresses the event types  in text. Named entities link to triggers by different roles, and named entities with corresponding roles are called arguments for a given trigger  of a specific event.  Currently, most existing works divide the event extraction into two independent sub-tasks: named entity recognition and trigger labeling. These two sub-tasks are always formulated as multi-class classification problems, and many works apply the sequence-to-sequence based labeling method which aims to translate a sentence into sequential tags. From our investigation, one problem of these sequence-to-sequence methods is that they ignore the orders of output tags, and therefore, it is difficult to precisely annotate different parts of an entity. To address this issue, some methods propose to incorporate the conditional random field  module to be aware of order-constraints for the annotated tags.  Since entities and triggers are naturally connected around events, recent works try to extract them jointly from corpora. Early methods apply pipeline frameworks with predefined lexical features which lack generality to different applications. Recent works leverage the structural dependency between entities and triggers to further improve the performances of both the entity and trigger identification sub-tasks.  %The prevalent methods can be divided into two categories: a) a parallel framework to obtain entities and triggers simultaneously and b) a pipeline framework to get triggers at first and then perform sub-tasks to extract entities. Takanobu et al.  propose a hierarchical reinforcement learning model to extract triggers first and then evoke a sub-process to get the related entities by referring to the obtained triggers in the same sentences. Nguyen et al.  design an attention mechanism to augment the accuracy for trigger extraction in multilingual environments. Fu el al.  employ graph convolutional network  to capture the local contextual information in sentences and use a two-stage method to extract entities and triggers from text together.   % The main challenges to improve the performance of jointly extract entities and triggers are two-fold: Although existing works have achieved comparable performance on jointly extracting entities and triggers, these approaches still suffer the major limitation of losing co-occurrence relationships between entities and triggers. Many existing methods determine the trigger and entities separately and then match the entities with triggers. % In this way, the co-occurrence relationships between entities and triggers are ignored, therefore, those methods might require more pre-trained features or prior data in order to achieve better performance. In this way, the co-occurrence relationships between entities and triggers are ignored, although pre-trained features or prior data are introduced to achieve better performance. It is also challenging to capture effective co-occurrence relationships between the entities and their triggers. We observed from the experiments that most of the entities and triggers are co-occurred sparsely  throughout a corpus. This issue exacerbates the problem of losing co-occurrence relationships mentioned before.   %However, most existing methods suffer performance degradation when extracting entities and triggers jointly. The reason is that most of the entities and triggers are sparsely  co-occurred throughout a corpus and the previous approaches do not well handle this sparse co-occurred relationship. %In addition, it is challenging to establish an effective interaction mechanism between the sub-tasks for joint-event-extraction, because traditional joint learning may lead to an error-propagation issue that lowers the accuracy of joint tasks.       %% label for entire figure \end{figure*}  To address the aforementioned challenge, the core insight of this paper is that in the joint-event-extraction task, the ground-truth annotations for triggers could be leveraged to supervise the extraction of the entities, and vice versa. Based on this insight, this paper proposes a novel method to extract structural information from corpora by utilizing the co-occurrence relationships between triggers and entities. Furthermore, in order to fully address the aforementioned sparsely co-occurrence relationships, we model the entity-trigger co-occurrence pairs as a heterogeneous information network  and supervise the trigger extraction by inferring the entity distribution with given triggers based on the indirect co-occurrence relationships collected along the meta-paths from a heterogeneous information network .  Figure illustrates the process of our proposed method to collect indirect co-occurrence relationships between entities and triggers. Figure is a sub-graph of the ``entity-trigger'' HIN for the ACE 2005 corpus. Figure compares the entity distributions inferred from given triggers based on the direct adjacency matrix and that inferred from the meta-path adjacency matrix. From this figure, we observe that a trigger does not necessarily connect to all entities directly and the direct-adjacency-based distribution is more concentrated on a few entities, while the meta-path-based distribution is spread over a larger number of entities. This shows that a model could collect indirect co-occurrence patterns between entities and triggers based on the meta-path adjacency matrix of an ``entity-trigger'' HIN. Moreover, the obtained indirect patterns could be applied to improve the performance to extract both entities and triggers.  Based on the aforementioned example and analysis, we propose a neural network to extract event entities and triggers. Our model is built on the top of sequence-to-sequence labeling framework and its inner parameters are supervised by both the ground-truth annotations of sentences and ``entity-trigger'' co-occurrence relationships. Furthermore, to fully address the indirect ``entity-trigger'' co-occurrence relationships, we propose the \underline{C}ross-\underline{S}upervised \underline{M}echanism  based on the HIN. The CSM alternatively supervises the entity and trigger extraction with the indirect co-occurrence patterns mined from a corpus. CSM builds a bridge for triggers or entities by collecting their latent co-occurrence patterns along meta-paths of the corresponding heterogeneous information network for a corpus. Then the obtained patterns are applied to boost the performances of entity and triggers extractions alternatively. We define this process as a ``cross-supervise'' mechanism. The experimental results show that our method achieves higher precisions and recalls than several state-of-the-art methods.  In summary, the main contributions of this paper are as follows:   The remainder of this paper is organized as follows. In Section, we first introduce some preliminary knowledge about event extraction and HIN, and also formulate the problem. Section presents our proposed model in detail. Section verifies the effectiveness of our model and compares it with state-of-the-art methods on real-world datasets. Finally, we conclude this paper in Section.     We have presented the system the RGCL team has prepared for the SemEval-2020 Task 12. The design of the system allows for easy switching of different architectures to accommodate the needs of the task at hand. For this task, we have shown the Transformer architecture using XLNet is the most successful when working with limited resources. It has also been shown that data augmentation techniques we experimented, while not detrimental to overall performance, do not necessarily improve performance. In a shared task setting, the effect of the extended data from Wikipedia was not useful, however, for a wider approach with higher recall, this could be more helpful.  We also tried to participate in the final subtask, Relation Classification. However, due to time constraints, we were not able to achieve a valid submission for the this subtask. We approached it as a sequence pair classification task and employed a Siamese Neural Network which was shown to perform well in sequence pair classification tasks . The architecture we employed is similar to the architecture presented in . When two sequences have a relation, we extracted the sequences and provided them as the input for the Siamese transformer architecture. Then we used the objective function suggested as classification objective function in  and optimised the cross-entropy loss. Due to the complexity of this task, we managed to run only a baseline of the proposed architecture which achieved very low evaluation scores on the development data. Therefore, we did not have a submission for this task and do not present any results here. In future, we hope to carry out further experiments with Siamese transformer architectures for relation classification tasks.  Going forth, we also wish to use this system for further tasks across further languages. While we may not achieve the best performance, the system utilises realistic system resources and is therefore very versatile. This is particularly with regard to the first subtask, where the difference to the best team is around 0.09, whereas for subtask two the best team is 0.36 ahead of us, indicating that our system is not competitive. It is possible to extend these experiments to a different domain easily using a pretrained transformer model in that domain given that a corpus similar to deft corpus is available in that domain. For an example, our system should be easily adoptable to biology domain using the BioBERT pretrained transformer model  and a deft corpus like corpus on biology domain.     include your own bib file like this: 
"," Joint-event-extraction, which extracts structural information  from unstructured real-world corpora, has attracted more and more research attention in natural language processing. Most existing works do not fully address the sparse co-occurrence relationships between entities and triggers, which loses this important information and thus deteriorates the extraction performance. To mitigate this issue, we first define the joint-event-extraction as a sequence-to-sequence labeling task with a tag set composed of tags of triggers and entities. Then, to incorporate the missing information in the aforementioned co-occurrence relationships, we propose a \underline{C}ross-\underline{S}upervised \underline{M}echanism  to alternately supervise the extraction of either triggers or entities based on the type distribution of each other. Moreover, since the connected entities and triggers naturally form a heterogeneous information network , we leverage the latent pattern along meta-paths for a given corpus to further improve the performance of our proposed method. To verify the effectiveness of our proposed method, we conduct extensive experiments on four real-world datasets as well as compare our method with state-of-the-art methods. Empirical results and analysis show that our approach outperforms the state-of-the-art methods in both entity and trigger extraction.",231
"  Recently, pre-trained self-supervised models such as BERT have attracted an increasing amount of attention in natural language processing and vision-language processing.  Benefiting from common knowledge contained in massive unlabeled data, the pretraining-finetuning framework has become a representative paradigm for advancing various language-related downstream tasks.   Most endeavors on pre-trained representation models rely on elaborately designed self-supervised tasks, which typically corrupt the given sequence with certain types of noise , and then train the model to recover the original sequence.  As a consequence, the learned representations tend to be covariant with the input noise of pre-training in this paradigm.  However, when transferred to downstream tasks, the pre-trained model is responsible for encoding the original sequence without noise, and is expected to obtain noise invariant representations.  Such pretrain-finetune discrepancy not only impedes fast fine-tuning, but also may result in suboptimal sequence representations, thus affecting the performance in downstream tasks.   %%%%%%%%%%%% %  % 	\vskip -0.1in % \end{table} %%%%%%%%%%%%  %%%%%%%%%%%% %  %%%%%%%%%%%%  To remedy this, we present ContrAstive Pre-Training  to learn noise invariant  sequence representations. %, inspired by the Noise Contrastive Estimation. The core idea of CAPT is to enhance the consistency between semantic representations of the original sequence and that of corresponding corrupted version  via unsupervised instance-wise training signals. %can be fully utilized via elaborately designed semantic contrastive loss. %As shown in Figure, our approach  In more detail, it strives to pull the representation of the corrupted sequence towards that of the original instance in the semantic space, while pushing it away from representations of other instances. % Such training objectives are formulated as a multi-class classification task, which aims at classifying the original sequence to the class of its corrupted version and vice versa, while classifying different instances into different classes. % For implementation feasibility, two effective model extension are proposed to further enhance the capability of the model to extract noise-concentrated and instance-diffused features. Moreover, in order to enable the model to learn from more ``difficult'' and ``diverse'' instances, two effective methods are proposed to further enhance the capability of the model to extract noise-concentrated and instance-diffused features. With such training objective, the pre-trained model is encouraged to learn noise invariant representations, thereby alleviating the pretrain-finetune discrepancy to some extent.  As an additional benefit, CAPT also assists the pre-trained model to more effectively capture the global semantics of the input.  Most prior work only focuses on token-level pre-training tasks , which lacks the modeling of global semantics of the input.  Some other efforts alleviate this problem by introducing sentence-level pre-training tasks  that rely on the relative position of segments in the document. However, the semantic connection between these segments tends to be excessively loose, which may result in confusing gradient signals.  By contrast, our CAPT offers incentives for representations of inputs sharing the same semantics  to be similar, while the representations of inputs expressing different semantics  are penalized to be distinguished from each other. Such more reasonable sentence-level supervision enables our approach to look beyond the local structures of input sequences and become more aware of the global semantics. %With such more reasonable sentence-level supervision, our approach achieves better modeling of global semantics of the input.   We perform the evaluation on a comprehensive suite of benchmark, covering 8 natural language understanding and 3 cross-modal tasks.  Extensive empirical evidence demonstrates that our approach can achieve consistent improvements over the baselines in both language and vision-language domains. To be more specific, our CAPT raises the performance of RoBERTa from 88.9\% to 89.5\% on the GLUE dev set, and also surpasses LXMERT by 0.5\%, 0.6\% and 0.8\% on VQA, GQA and , respectively.       In this paper, we have proposed a novel cross-supervised mechanism which allows models to extract entities and triggers jointly. Our mechanism alternately supervises the extraction process for either the triggers or the entities, based on the information in the type distribution of each other. In this way, we incorporate the co-occurrence relationships between entities and triggers into the joint-event-extraction process of our model. Moreover, to further address the problem caused by the sparse co-occurrence relationships, our method also resorts to the heterogeneous information network technology to collect indirect co-occurrence relationships. The empirical results show that our method improves the extraction performances for entities and triggers simultaneously. This verifies that the incorporated co-occurrence relationships are useful for the joint-event-extraction task and our method is more effective than existing methods in utilizing training samples. Our future works include:  investigating the impact of length of sampled meta-paths, as in this paper we have limited the meta-path into a fixed length;  connecting the extracted entities and triggers from a corpus to facilitate the automatic knowledge graph construction.  
"," Pre-trained self-supervised models such as BERT have achieved striking success in learning sequence representations, especially for natural language processing. These models typically corrupt the given sequences with certain types of noise, such as masking, shuffling, or substitution, and then try to recover the original input. However, such pre-training approaches are prone to learning representations that are covariant with the noise, leading to the discrepancy between the pre-training and fine-tuning stage. To remedy this, we present ContrAstive Pre-Training  to learn noise invariant sequence representations. The proposed CAPT encourages the consistency between representations of the original sequence and its corrupted version via unsupervised instance-wise training signals. In this way, it not only alleviates the pretrain-finetune discrepancy induced by the noise of pre-training, but also aids the pre-trained model in better capturing global semantics of the input via more effective sentence-level supervision. Different from most prior work that focuses on a particular modality, comprehensive empirical evidence on 11 natural language understanding and cross-modal tasks illustrates that CAPT is applicable for both language and vision-language tasks, and obtains surprisingly consistent improvement, including 0.6\% absolute gain on GLUE benchmarks and 0.8\% absolute increment on $\text{NLVR}^2$.",232
" \subsection{Natural Language Processing} Ang Natural Language Processing  ay isang subfield ng linguistics, computer science, at artificial intelligence na nauukol sa pag proseso at pag-unawa ng natural na wika . Ang ilan sa mga aplikasyon ng NLP ay ang email spam filters , pag-unawa ng nais sabihin tulad ng mga smart assistants , pagsasalin ng isang wika sa iba pang wika , mag predict ng susunod na salita base sa mga naunang salita , at marami pang iba. Dahil sa kaunlaran sa kasaganahan sa datos at pagiging accessible ng malakas na compute power, nabuhay muli ang machine learning approach. Sa maikling salita, ang machine learning approach ay gumagamit ng malaking datos na ginagamit ng isang computer algorithm upang matutunan ang mga patterns ng datos na ito. Dahil dito, naging epektibo siyang approach sa mga komplikadong problema dahil hindi na kailangan direktang i-program ang mga rules para malutas ang isang problema.  \subsection{Transfer Learning} Notorious ang machine learning approach sa pangangailangan nito ng sobrang laking datos para mapakinabangan. Ang Transfer Learning  ay isang area ng research na concerned sa problemang ito . Sa maikling salita, ang TL ay ang pag retain o pagpapanatili ng mga natutunan ng isang model sa isang gawain at paggamit o ""transfer"" ng mga natutunan nito sa iba pero may kaugnayan na gawain. Halimbawa, ang mga natutunan ng isang model sa pag detect ng muka ng tao ay maaring gamitin bilang tuntungan para sa pag-aaral ng model na matutunan kung ang muka ng tao ay galit, masaya, at iba pang facial expressions .     This work presents contrastive pre-training for learning denoised sequence representations in a self-supervised manner. By enhancing the consistency between representations of the original sequence and the corresponding corrupted version, the pre-trained model is encouraged to learn noise invariant sequence representations.  On this account, the proposed approach not only alleviates the pretrain-finetune discrepancy induced by the noise of pre-training, but also better captures the global semantics of the input via more effective sentence-level supervision. Extensive experiments demonstrate the effectiveness and versatility of our approach, which can achieve consistent improvements over baselines in both language and vision-language domains.  
"," Ang mga low-resource languages tulad ng Filipino ay gipit sa accessible na datos kaya't mahirap gumawa ng mga applications sa wikang ito. Ang mga Transfer Learning  techniques ay malaking tulong para sa low-resource setting o mga pagkakataong gipit sa datos. Sa mga nagdaang taon, nanaig ang mga transformer-based TL techniques pagdating sa low-resource tasks ngunit ito ay mataas na compute and memory requirements kaya nangangailangan ng mas mura pero epektibong alternatibo. Ang papel na ito ay may tatlong kontribusyon. Una, maglabas ng pre-trained AWD-LSTM language model sa wikang Filipino upang maging tuntungan sa pagbuo ng mga NLP applications sa wikang Filipino. Pangalawa, mag benchmark ng AWD-LSTM sa Hate Speech classification task at ipakita na kayang nitong makipagsabayan sa mga transformer-based models. Pangatlo, suriin ang performance ng AWD-LSTM sa low-resource setting gamit ang degradation test at ikumpara ito sa mga transformer-based models.",233
"  \iffalse \dr{%If we want to reposition it as in the abstract, we should start by considering the event in Fig. 1:  Natural language text is typically written to tell the reader about events. But events are not expressed as single predicate mentions, but rather as structures over multiple such predicates and their arguments. Consider the description the impact of the Typhoon in Fig..... It is mentioned that the typhoon killed people , flights canceled and affected many people. It is also clear that there is temporal order among some of the predicates, and recognizing this is important to understanding the composite event. Then you can continue saying that this is our goal.}  \fi  % typically, a single predicate mention  does not constitute what we typically think about as events; we typically think of an event as something that consists of multiple such primitive structures %{\fontsize{10.5}{11} \selectfont Text}           %\fontsize{11pt}{13pt}\selectfont Human languages evolve to communicate about %always involve the description of  real-world events. Therefore, understanding events plays a critical role in natural language understanding . A key challenge to this mission lies in the fact that events are not just simple, standalone predicates. Rather, they are often described at different granularities and may form complex structures. %topologies. Consider the example in Figure, where the description of a storm  involves more fine-grained event mentions about people killed , flights canceled  and passengers affected . Some of those mentions also follow strict temporal order . Our goal is to induce such an event complex that recognizes %organizes  the membership of multi-granular events described in the text, as well as their temporal order. This is not only at the core of text understanding, but is also beneficial to various applications such as question answering , narrative prediction , timeline construction  and summarization . %\dr{The choice of references is good but revealing; I suggest to replace the summarization with a ``classical"" summarization paper .  %such as question answering , narrative prediction , coreference resolution , and summarization . Since events are not standalone objects, understanding event essentially involves comprehending their relations, %cite{wities-etal-2017-consolidated, wadden-etal-2019-entity}, relations , as well as their internal structures and processes .  inasmuch as they necessarily provide actionable knowledge to support question answering , narrative prediction , timeline construction  and summarization .      \muhao{TODO: forming what we call a ``event complex''} Human languages always involve the description of real-world events. Therefore, understanding events plays a critical role in natural language understanding , and supports tasks such as question answering , narrative prediction , timeline construction  and summarization . Typically, events are not just standalone predicate mentions, but rather as structures over multiple such predicates. Consider the example in Figure.  The description to the impact of the storm  also involves mentions about killed people , canceled flights  and affected passengers . Some of mentions thereof also follow temporal order. To support the comprehension of complex events, it is important to recognize the multifaceted relations for the predicate mentions in the text. \fi        % second paragraph \iffalse Recently, much research effort has been put into extracting specific aspects of relations for events. \citet{ning-etal-2018-improving} studied event temporal relation  extraction with a statistical common sense resource \citet{ning-etal-2019-improved} and \citet{han-etal-2019-joint} adopted data-driven methods for TempRel extraction; parent-child relations among events are studied in \citealp[]{liu-etal-2018-graph} and \citealp[]{aldawsari-finlayson-2019-detecting}. Though some of the previous work has ensured consistency via adding constraints in the inference phase, essentially they are not improving local predictions and the inconsistent results from the models might not be corrected in the inference stage. Besides, most of the approaches suffered from limited learning resources and the tasks are studied separately. \fi  Recently, significant %much research effort has been devoted to several event-event relation extraction tasks, such as event temporal relation  extraction  and subevent relation extraction . Addressing such challenging tasks requires a model to recognize the inherent connection between event  %\dr{should it be predicate mentions, to ease the ambiguity?}  mentions as well as their contexts in the documents. Accordingly, a few previous methods apply statistical learning methods to characterize the grounded events in the documents . Such methods often require designing various features to characterize the structural, discourse and narrative aspects of the events, which are costly to produce and are often specific to a certain task or dataset. More recent works attempted to use data-driven methods based on neural relation extraction models  which refrain from feature engineering and offer competent performances.     \iffalse \dr{The next two paragraphs can be shortened, but they are the right paragrpahs to include here.} While data-driven methods provide a general and tractable way to capture specific event-event relations, it still remains challenging for those methods to precisely infer the correct relations. One challenge is that almost every task for event-event relation extraction comes with limited available annotated resources. Specifically, most tasks annotate no more than a hundred articles . Even the largest one in the literature, i.e., MATRES  for TempRel extraction, contains annotation for merely 275 articles. The lack of supervision hinders feature learning of events as well as inference of the relations, %Therefore, effectively tackling these tasks inevitably calls  therefore calling upon plausible auxiliary supervision from resources that are external to each of the tasks.    On the other hand, the event-event relations are often constrained by  %\drc{logical \dr{}change everywhere} %logic %\muhao{done.} properties, such as transitivity of TempRels Before and After , as well as that of %the relation between parent and child events subevent relations . In favor of such constraints, literature has employed global inference in the inference phase to comply with the logical properties particularly for TempRels . However, there lacks an effective way to ensure the global logical consistency in the training phase, which is key to making a data-driven machine learning model consistent on the beliefs of training data for various relation types . Moreover, the logical constraints may apply to different categories of %event-event  relations, and form complex conjunctive rules.  Consider the example in Figure : given that e2:died is Before e3:canceled and e3:canceled is a parent event of e4:affecting, the learning process should enforce e2:died Before e4:affecting. %\todo{Add an example of a conjunctive rule containing temporal and subevent relations.} Accordingly, ensuring the logical constraints across task-specific relations is another challenge being overlooked by the literature, the resolve of which provides a natural way to bridge the learning processes on multiple tasks. %\magenta{HW:TCR?} \fi  While data-driven methods provide a general and tractable way for event-event relation extraction, their performance is restricted by the limited annotated resources available. For example, the largest temporal relation extraction dataset MATRES only has 275 articles, which is far from enough for training a well-performing supervised model. The observation that relations and, in particular, event-event relations should be constrained by their logical properties , led to employing global inference to comply with transitivity and symmetry consistency, specifically on TempRel . However, in an event complex, the logical constraints may globally apply to different task-specific relations, and form more complex conjunctive constraints.  Consider the example in Figure : given that e2:died is Before e3:canceled and e3:canceled is a Parent event of e4:affecting, the learning process should enforce e2:died Before e4:affecting by considering the conjunctive constraints on both TempRel and subevent relations. While previous works focus on preserving logical consistency through  inference or structured learning , there was no %lacks an  effective way to endow neural models with the sense of global logical consistency during training.  %\dr{Notice that the previous statement was not correct; I change to limit it to neural models, since structure learning did it} %ensure the global logical consistency in the training phase.  This is key to bridging %bridge  the learning processes of %on both TempRel and subevent relations, which is a research focus of this paper.  %Event-relation extraction is a non-trivial task because of the following challenges: %1) Almost every event relation extraction task comes with limited learning resources with annotations. %2) Event relations are often volatile given different scenarios, and the determination of parent-child relation is especially difficult since there are less explicit lexical expressions compared with the cases for time and causation. %3) Event relations are often endowed with logical properties: % some temporal relations and parent-child relations comply with transitivity; % logical consistency should also be ensured across different categories of event relations.  The first contribution of this work is proposing %to propose  a joint constrained learning model for multifaceted event-event relation extraction.  The joint constrained learning framework seeks to regularize the model towards consistency with the logical constraints across both temporal and subevent relations, for which three types of consistency requirements are considered: annotation consistency, symmetry consistency and conjunction consistency. Such consistency requirements comprehensively define the interdependencies among those relations, essentially unifying the ordered nature of time and the topological nature of multi-granular subevents based on a set of declarative logic rules. Motivated by the logic-driven framework proposed by \citet{li-etal-2019-logic}, the declarative logical constraints are converted into differentiable functions that can be incorporated into the learning objective for relation extraction tasks.  Enforcing logical constraints across temporal and subevent relations is also a natural way to combine %two event-event relation extraction tasks with a shared learning objective. the supervision signals coming from two different datasets, one for each of the  relation extraction tasks with a shared learning objective. %\dr{You said what is the first contribution, but not the second; do you want now to claim this as the second contribution? Note that I modified to emphasize the two datasets} %Besides, the consistency of the final prediction is further enforced by global inference via an ILP solver.  Despite the scarce annotation for both tasks, the proposed method surpasses the SOTA TempRel extraction method on MATRES by relatively 3.27\% in ; %\dr{I don't understand -- is it relative or F1? Also, Tab. 2 shows 2.5\%}  it also offers promising performance on the HiEve dataset for subevent relation extraction, relatively surpassing previous methods by at least 3.12\% in .  %\dr{which table is this from?} %by 3.12\% and 21.4\%. %We further provide ablation studies to show the importance of each component of our framework. %This fact is further illustrated by ablation studies.   From the NLU perspective, %the acquired knowledge of our method is able to simultaneously models the internal membership structure of a complex event, as well as the temporal relations among both simple and complex events. the second contribution of this work lies in providing a general method for inducing an event complex that comprehensively represents the relational structure of several related event %\drc{predicate} % mentions. %in two directions.  This is supported by the memberships vertically identified between multi-granular events, as well as the horizontal temporal reasoning within the event complex. As far as we know, this is %essentially different from all %many  previous works that only formulated relations along a single axis. Our model further demonstrates the potent capability of inducing event complexes  %with promising performance  when evaluated  %based  on the RED dataset .       In this paper we explore the problem of seed-guided topical taxonomy construction. Our proposed framework \corel completes the taxonomy structure by a relation transferring module and enriches the semantics of concept nodes by a concept learning module. The relation transferring module learns the user-interested relation preserved in seed parent-child pairs, then transfers it along multiple paths to expand the taxonomy in width and depth. The concept learning module finds discriminative topical clusters for each concept in the process of jointly embedding concepts and words. Extensive experiments show that both modules work effectively in generating a high-quality topical taxonomy based on user-given seeds.  For future work, it is interesting to study how we can generate multi-faceted taxonomy automatically, so that each concept node is described by terms from different aspects . Though these terms can be captured by our concept learning module, how to recognize them and organize them into meaningful clusters remains challenging and worth exploring.\clearpage  \onecolumn 
","     %\dr{I think that the current version  is too detailed and does not position the work at all, it just says what is being done. Here is a suggestion:}    Understanding natural language involves recognizing how multiple event mentions structurally and temporally interact with each other.     In this process, one can induce event complexes that organize multi-granular events with temporal order and membership relations interweaving among them.    Due to the lack of jointly labeled data for these relational phenomena and the restriction on the structures they articulate, we propose a joint constrained learning framework for modeling event-event relations.    Specifically, the framework enforces logical constraints within and across multiple temporal and subevent relations     %of events     by converting these constraints into differentiable learning objectives. We show that our joint constrained learning approach effectively compensates for the lack of jointly labeled data, and outperforms SOTA methods on benchmarks for both temporal relation extraction and event hierarchy construction, replacing a commonly used but more expensive global inference process.    We also present a promising case study showing the effectiveness of our approach in inducing event complexes on an external corpus.\footnote{Our code is publicly available at \url{https://cogcomp.seas.upenn.edu/page/publication_view/914}.} %\dr{Doesn't this contradict the statement above regarding the lack of joint data? Do we need to address it somehow}    %\dr{do we need the next clause? really, you show that you don't need it, but it reads like you just don't use it. If you really want to keep it, maybe better to say ""replacing a commonly used, more expensive, global inference process""} even without global inference that is widely used in previous methods.     \iffalse     \drc{Understanding events described in natural language text requires a reader to identify how they interact, structurally and temporally, to form an event complex.      Nevertheless, most of the work in NLP has focused on predicate mentions and not on the event complex they form together.      In this paper we study the induction of larger event units from text -- identifying a set of predicate mentions that together -- via temporal, co-reference, and subevent relations, form event complexes.     The scarcity of jointly labeled data for these relational phenomena presents a significant technical challenge. However, these phenomena interact with each other, thus restricting the structures they articulate. To make this explicit, we propose a joint learning framework that enforces logical constraints among the relations to be identified, by converting these into differentiable learning objectives.      We show that not only does our joint training approach address the lack of jointly labeled data, but it also outperforms SOTA results on both the temporal benchmark data set and the event hierarchy benchmark data set. %We also present a promising case study on RED, a small-scale dataset with fully annotated relations.     }     \fi     \ignore{     We study within-document temporal and hierarchical relations of events using a joint constrained learning framework.      %We first obtain the event representation  via an encoder, and then jointly train a multi-layer perceptron to predict confidence scores for temporal and hierarchical relations before we make structured prediction via integer linear programming .      The framework first incorporates a contextualized encoder to characterize the events in the document, and then predicts the confidence scores for temporal and hierarchical relations among them.     In the training phase, our framework learns to enforce logic consistency among various types of event relations in both categories,     by converting declarative rules into differentiable learning objective functions. %Furthermore, the consistency of final prediction is enforced by global inference .      %The inference phase performs structured prediction based on integer linear programming  to respect the corresponding logic constraints of relations.     %We utilize the benchmark dataset for the extraction task of each category of relations for training and evaluation. %By experimental results, we prove the feasibility of joint constrained learning of different tasks using datasets that have partial annotations for each task, %avoiding the labor for creating another dataset that has full annotation.     The experimental results show that the proposed framework outperforms the state-of-the-art method on the benchmark dataset, MATRES, of event temporal relation extraction task by 2.8\%; and it improves over the model of training jointly without constraints by 5\% F1-score on HiEve dataset, a benchmark for event hierarchy construction.     Therefore, the joint constrained learning effectively bridges the tasks with limited annotated learning resources, and promisingly leverages domain rules to support the precise learning and inference of various event relations.     }",234
"  Word embeddings which can capture semantic similarities have been extensively explored in a wide spectrum of Natural Language Processing  applications in recent years.  Word2Vec , FastText , and Glove  are some examples. Even though distributional word embeddings produce high quality representations, representing longer pieces of text such as sentences and paragraphs is still an open research problem. A sentence embedding is a contextual representation of a sentence which is often created by transformation of word embeddings through a composition function. There has been a large body of work in the literature which propose different approaches to represent sentences from word embeddings. SkipThought , InferSent , and Universal Sentence Encoder  are well-known examples.  % Other proposed methods for learning sentence representations include, but are not limited to .  There has been a growing interest in understanding what linguistic knowledge is encoded in deep contextual representation of language. For this purpose, several probing tasks are proposed to understand what these representations are capturing . One of the interesting findings is that despite the existence of explicit syntactic annotations, these learned deep representations encode syntax to some extent . Hewitt et. al. provide an evidence that the entire syntax tree is embedded implicitly in deep model's vector geometry. Kuncoro et. al.  show that LSTMs trained on language modeling objectives capture syntax-sensitive dependencies. Even though deep contextual language models implicitly capture syntactic information of sentences, explicit modeling of syntactic structure of sentences has been shown to further improve the results in different NLP tasks including neural language modeling \cite {shen2017neural, havrylov2019cooperative}, machine comprehension , summarization , text generation , machine translation , authorship attribution , etc. Furthermore, Kuncoro et. al. provide evidence that models which have explicit syntactic information result in better performance . Of particular interest, one of the areas where syntactic structure of sentences plays an important role is style-based text classification tasks, including authorship attribution. The syntactic structure of sentences captures the syntactic patterns of sentences adopted by a specific author and reveal how the author structures the sentences in a document.   Inspired by the above observations, our initial work demonstrates that explicit syntactic information of sentences improves the performance of a recurrent neural network classifier in the domain of authorship attribution . We continue this work in this paper by investigating if structural representation of sentences can be learned explicitly. In other words, similar to pre-trained word embeddings which mainly capture semantics, can we have pre-trained embeddings which mainly capture syntactic information of words. Such pre-trained word embeddings can be used in conjunction with semantics embeddings in different domains including authorship attribution. For this purpose, we propose a self-supervised framework using a Siamese  network  to explicitly learn the structural representation of sentences. The Siamese network is comprised of two identical components; a lexical sub-network and a syntactic sub-network; which take the sequence of words in the sentence and its corresponding linearized syntax parse tree as the inputs, respectively. This model is trained based on a contrastive loss objective where each pair of vectors  is close to each other in the embedding space if they belong to an identical sentence , and are far from each other if they belong to two different sentences .    As a result, each word in the sentence is embedded into a vector representation which mainly carries structural information. Due to the -to- mapping of word types to structural labels, the word representation is deduced into structural representations. In other words, semantically different words  are mapped to similar structural labels ; hence, semantically different words may have similar structural representations. These pre-trained structural word representations can be used as complimentary information to their pre-trained semantic embeddings . We use probing tasks proposed by Conneau et al.  to investigate the linguistic features learned by such a training.  The results indicate that structural embeddings show competitive results compared to the semantic embeddings, and concatenation of structural embeddings with semantic embeddings achieves further improvement.  Finally, we investigate the efficiency of the learned structural embeddings of words for the domain of authorship attribution across four datasets. Our experimental results demonstrate classification improvements when structural embeddings are concatenated with the pre-trained word embeddings.  The remainder of this paper is organized as follows: we elaborate our proposed self-supervised framework in Section .  The details of the datasets and experimental configuration are provided and the experimental results reported in Section ; We review the related work in Section . Finally, we conclude this paper in Section .        Event-event relation extraction is a challenging task which is beneficial to understanding event complex composed of multi-granular events with temporal orders. Despite the existence of previous attempts for addressing TempRel and subevent relation extraction, this is the first work  We propose a joint constrained learning framework for extracting event complexes from documents.  that combines the two tasks and addresses them by constrained learning with shared objectives.  The proposed framework bridges TempRel and subevent relation extraction tasks with a comprehensive set of logical constraints, which are enforced during learning by  converting them into differentiable objective functions.  On two benchmark datasets, the proposed method outperforms SOTA statistical learning methods and data-driven methods for each task, without using data that is jointly annotated with the two classes of relations. It also presents promising event complex extraction results on RED that is external to training.  Thus, our work shows that the global consistency of the event complex significantly helps understanding both temporal order and event membership. For future work, we plan to extend the framework towards an end-to-end system with event extraction. We also seek to extend the conjunctive constraints along with event argument relations.  , demonstating the effectiveness of joint constrained learning framework from both machine-learning and NLU view .    
","   Syntactic structure of sentences in a document substantially informs about its authorial writing style. Sentence representation learning has been widely explored in recent years and it has been shown that it improves the generalization of different downstream tasks across many domains. Even though utilizing probing methods in several studies suggests that these learned contextual representations implicitly encode some amount of syntax, explicit syntactic information further improves the performance of deep neural models in the domain of authorship attribution. These observations have motivated us to investigate the explicit representation learning of syntactic structure of sentences.  In this paper, we propose a self-supervised framework for learning structural representations of sentences. The self-supervised network contains two components; a lexical sub-network and a syntactic sub-network which take the sequence of words and their corresponding structural labels as the input, respectively. Due to the $n$-to-$1$ mapping of words to their structural labels, each word will be embedded into a vector representation which mainly carries structural information. We evaluate the learned structural representations of sentences using different probing tasks, and subsequently utilize them in the authorship attribution task. Our experimental results indicate that the structural embeddings significantly improve the classification tasks when concatenated with the existing pre-trained word embeddings.",235
"    Since the end of the twentieth century and the spread of mobile communication technologies in the Arab world, youth, in particular, have developed a new chat alphabet to communicate more efficiently in informal Arabic. Because most media and applications initially did not enable chatting in Arabic, these Arab speakers resorted to what is now commonly known as ""Arabizi"". In, Arabizi was defined as the newly-emerged Arabic variant written using the Arabic numeral system and Roman script characters. With the widespread use of social media worldwide in more recent years, Arabizi emerged as an established Arabic writing system for mobile communication and social media in the Arab world.   Compared to the increasing studies of sentiment analysis in Indo-European languages, similar research for Arabic dialects is still very limited.\ This is mainly attributed to the lack of the needed good quality Modern Standard Arabic  publicly-available sentiment analysis resources in general, and more specifically dialectical Arabic publicly-available resources.\ Building such resources involves several difficulties in terms of data collection and annotation, especially for underrepresented Arabic dialects such as the Tunisian dialect. Nevertheless, existing Tunisian annotated datasets focused on code-switching datasets written using the Arabic or the Romanized Alphabet. The studies on these datasets applied off-the-shelf models that have been built for MSA on a dataset of Tunisian Arabic. An intuitive solution is to translate Tunisian Romanized Alphabet into Arabic Script. This approach suffers from the need for a parallel Tunisian-Arabic text corpus, the low average precision performances achieved and the irregularity of the words written.  Using a model trained on Modern Standard Arabic sentiment analysis data and then applying the same model on dialectal sentiment analysis data, does not produce good performances as shown in. This suggests that MSA models cannot be effective when applied to dialectical Arabic. There is, thus, a growing need for the creation of computational resources, not only for MSA but also for dialectical Arabic. The same situation holds when one tries to use computational resources used for a specific dialect of Arabic with another one.  To the best of our knowledge, this is the first study on sentiment analysis TUNIZI Romanized Alphabet. \ This could be deduced in the next sections where we will present TUNIZI and the state-of-the-art of Tunisian sentiment analysis followed by our proposed approach, results and discussion before conclusion and future work.      In this paper, we have proposed a self-supervised framework for learning structural representation of sentences for the domain of authorship attribution. The result of training this self-supervised framework is pre-trained structural embeddings which capture information regarding the syntactic structure of sentences. Subsequently, these structural embeddings can be concatenated to the existing pre-trained word embeddings and create a style-aware embedding which carries both semantic and syntactic information and it is well-suited for the domain of authorship attribution. Moreover, structural embeddings eliminate the necessity of syntactic parsing for training syntactic neural networks; therefore, training a neural model using pre-trained structural embeddings is computationally more efficient. According to our experimental results on four benchmark datasets in authorship attribution, using structural embedding improves the performances of the proposed neural model.             The next two lines define the bibliography style to be used, and    the bibliography file. 
"," Tunisians on social media tend to express themselves in their local dialect using Latin script . This raises an additional challenge to the process of exploring and recognizing online opinions. To date, very little work has addressed TUNIZI sentiment analysis due to scarce resources for training an automated system. In this paper, we focus on the Tunisian dialect sentiment analysis used on social media. Most of the previous work used machine learning techniques combined with handcrafted features. More recently, Deep Neural Networks were widely used for this task, especially for the English language. In this paper, we explore the importance of various unsupervised word representations  and we investigate the use of Convolutional Neural Networks and Bidirectional Long Short-Term Memory. Without using any kind of handcrafted features, our experimental results on two publicly available datasets showed  comparable performances to other languages.    \keywords{Tunisian Dialect  \and TUNIZI \and Sentiment Analysis \and Deep Learning \and Neural networks \and Natural language analysis.}",236
"   In recent years, neural networks have shown impressive performance gains on long-standing AI problems, such as natural language understanding, speech recognition, and computer vision.  Based on these successes, researchers have considered the application of neural nets to data management problems, including learning indices, query optimization and entity matching.  In applying neural nets to data management, research has so far assumed that the data was modeled by a database schema.    The success of neural networks in processing unstructured data such as natural language and images   raises the question of whether their use can be extended to a point where we can relax the fundamental assumption of database management, which is that the data we process is represented as fields of a pre-defined schema.  What if, instead, data and queries can be represented as short natural language sentences, and queries can be answered from these sentences?  This paper presents a first step in answering that question.  We describe \systemname, a database system in which updates and queries are given in natural language. The query processor of a \ndb\ builds on the primitives that are offered by the state of the art Natural Language Processing~ techniques.  Figure shows example facts and queries that \ndb\ can answer. %\ms{In Figure 1, queries 4&5 are not really joins, they just need language understanding/paraphrasing}  Realizing the vision of \systemname\ will offer several benefits that database systems have struggled to support for decades.  The first, and most important benefit is that a \ndb, by definition, has no pre-defined schema. Therefore, the scope of the database does not need to be defined in advance and any data that becomes relevant as the application is used can be stored and queried. The second benefit is that updates and queries can be posed in a variety of natural language forms, as is convenient to any user.  In contrast, a traditional database query needs to be based on the database schema.  A third benefit comes from the fact that the \ndb\  is based on a pre-trained language model that already contains a lot of knowledge.   For example, the fact that London is in the UK is already encoded in the language model. Hence, a query asking who lives in the UK can retrieve people who are known to live in London without having to explicitly specify an additional join. Furthermore, using the same paradigm, we can endow the \ndb\  with more domain knowledge by extending the pre-training corpus to that domain.   By nature, a \ndb\ is not meant to provide the same correctness guarantees of a traditional database system, i.e., that the answers returned for a query satisfy the precise binary semantics of the query language.  Hence, \ndb s should not be considered as an alternative to traditional databases in applications where such guarantees are required.    Given its benefits, \neuraldatabases\ are well suited for emerging applications where the schema of the data cannot be determined in advance and data can be stated in a wide range of linguistic patterns.  A family of such applications arise in the area of storing knowledge for personal assistants that currently available for home use and in the future will accompany Augmented Reality glasses. In these applications, users store data about their habits and experiences, their friends and their preferences, and designing a schema for such an application is impractical.  Another class of applications is the modeling and querying of political claims .  Here too, claims can be about a huge variety of topics and expressed in many ways.   Our first contribution is to show that state of the art transformer models can be adapted to answer simple natural language queries. Specifically, the models can process facts that are relevant to a query independent of their specific linguistic form, and combine multiple facts to yield correct answers, effectively performing a join. However, we identify two major limitations of these models:  they do not perform well on aggregation queries , and  since the input size to the transformer is bounded and the complexity of the transformer is quadratic in the size of its input, they only work on a relatively small collection of facts.  Our second contribution is to  propose an architecture for neural databases that uses the power of transformers at its core, but puts in place several other components in order to address the scalability and aggregation issues. Our architecture runs multiple instances of a Neural SPJ operator in parallel. The results of the operator are either the answer to the query or the input to an aggregation operator, which is done in a traditional fashion. Underlying this architecture is a novel algorithm for generating the small sets of database sentences that are fed to each Neural SPJ operator.  Finally, we describe an experimental study that validates the different components of \systemname s, namely the ability of the Neural SPJ to answer queries or create results for a subsequent aggregation operator even with minimal supervision, and our ability to produce support sets that are fed into each of the Neural SPJ operators. Putting all the components together, our   final result shows that we can accurately answer queries over thousands of sentences with very high accuracy. To run the experiments we had to create an experimental dataset with training data for \ndb s, which we make available for future research.    % and capable of generating intermediate results and  accurately predicting the aggregation operation to execute over these intermediate results.        In this work, we have tackled the Tunisian Romanized alphabet sentiment analysis task. We have experimented two different word-level representations  and two deep neural networks , without the use of any pre-processing step. Results showed that CNN trained with M-BERT achieved the best results compared to the word2vec, frWac and Bi-LSTM. This model could improve the performance over the baselines. Experiments and promising results achieved on the TUNIZI and TSAC-TUNIZI datasets helped us to better understand the nature of the Tunisian dialect and its specificities. This will help the Tunisian NLP community in further research activities not limited to the sentiment analysis task, but also in more complex NLP tasks.  A natural future step would involve releasing TunaBERT, a Tunisian version of the Bi-directional Encoders for Transformers  that should be learned on a very large and heterogeneous Tunisia dataset. The Tunisian language model can be applied to complex NLP tasks . To demonstrate the value of building a dedicated version of BERT for Tunisian, we also plan to compare TunaBERT to the multilingual cased version of BERT.   
"," \jt{TODO Before final submission remove page numbers} In recent years, neural networks have shown impressive performance gains on long-standing AI problems, and in particular, answering queries from natural language text. These advances raise the question of whether they can be extended to a point where we can relax the fundamental assumption of database management, namely, that our data is represented as fields of a pre-defined schema.   This paper presents a first step in answering that question.  We describe \ndb, a database system with no pre-defined schema, in which updates and queries are given in natural language. We develop query processing techniques that build on the  primitives offered by the state of the art Natural Language Processing methods.   We begin by demonstrating that at the core, recent NLP transformers, powered by pre-trained language models, can answer select-project-join queries if they are given the exact set of relevant facts. However, they cannot scale to non-trivial databases and cannot perform aggregation queries. Based on these findings, we describe a \ndb\ architecture that runs multiple Neural SPJ operators in parallel, each with a set of database sentences that can produce one of the answers to the query. The result of these operators is fed to an aggregation operator if needed. We describe an algorithm that learns how to create the appropriate sets of facts to be fed into each of the Neural SPJ operators. Importantly, this algorithm can be trained by the Neural SPJ operator itself. We experimentally validate the accuracy of \systemname\ and its components, showing that we can answer queries over thousands of sentences with very high accuracy.",237
" %  Enabling chatbots to indulge in engaging conversations requires massive datasets of human-human conversations . Training such dialog agents requires substantial time and effort expended in the collection of adequate number of high quality conversation samples.  \citet{hancock2019learning} alleviate this problem by introducing a self-feeding chatbot which can directly learn from user interactions. This chatbot requests users to provide natural language feedback when the users are dissatisfied with its response.  \citet{hancock2019learning} treat this feedback as a gold response to the wrong turn and use it as an additional training sample to improve the chatbot.    Although natural language feedback is cheap to collect from a chatbot's end-users, most often, feedback cannot be used directly as a training sample since feedback is usually not the answer itself, but simply contains hints to the answer. \Cref{tab:response_samples} shows some feedback text samples. Naive modification of feedback using heuristics like regular expressions would lead to generic responses that are ineffective in improving the dialog ability of chatbots . Additionally, writing an exhaustive set of regular expression rules is time consuming and requires extensive analysis of the data.  Annotating data to convert feedback text to natural response is also expensive and defeats the purpose of learning from feedback text.      \end{table} In this work, we propose a generative adversarial setup for converting such noisy feedback instances into natural, human-like responses that provide better training signals for the dialog agents. \Cref{fig:interface} gives a bird's-eye view of our problem. We frame this problem as a variant of text style transfer where the generator is tasked with making the feedback resemble the optimal response to the user's previous utterance and the discriminator is a classifier that distinguishes whether a given response is feedback or natural.   Our main contributions are the following: %      Medical code assignment from clinical notes is a fundamental task for healthcare information systems and diagnosis decision support.  This paper proposes a novel framework with gated convolutional neural networks and note-code message passing mechanism for automated medical code assignment. Our solution can learn meaningful features from lengthy clinical documents and effectively control the deep propagation of information flow.  Moreover, the message passing mechanism can enhance the ICD code space's semantics and model the note-code interaction to improve medical code prediction. Experiments show the effectiveness of our proposed method.   
","  The ubiquitous nature of chatbots and their interaction with users generate an enormous amount of data. Can we improve chatbots using this data? A self-feeding chatbot improves itself by asking natural language feedback when a user is dissatisfied with its response and uses this feedback as an additional training sample. However, user feedback in most cases contains extraneous sequences hindering their usefulness as a training sample. In this work, we propose a generative adversarial model that converts noisy feedback into a plausible natural response in a conversation. The generator's goal is to convert the feedback into a response that answers the user's previous utterance and to fool the discriminator which distinguishes feedback from  natural responses. We show that augmenting original training data with these modified feedback responses improves the original chatbot performance from 69.94\% to 75.96\% in ranking correct responses on the \personachat dataset, a large improvement given that the original model is already trained on 131k samples.\footnote{Our code is released at \url{https://github.com/ekunnii/adversarial-feedback-chatbot/}}",238
"  Text Generation is the task of producing written or spoken narrative from structured or unstructured data. The overarching goal is the seamless human-machine communication by presenting a wealth of data in a way we can comprehend. With respect to the modeling approaches, there are three main paradigms in generating text based on the schema of input and output:  Text-to-Text  Data-to-Text  None-to-Text. Table  presents the categorization of different tasks based on this paradigm. These several tasks deserve undivided attention and accordingly they have been heavily dissected, studied and surveyed in the recent past. For instance, independent and exclusive surveys are periodically conducted on summarization , knowledge to text generation {DBLP:conf/inlg/GardentSNP17, DBLP:conf/naacl/Koncel-Kedziorski19}, machine translation , dialog response generation , storytelling, narrative generation , image captioning  etc., to dig deeper into task specific approaches that are foundational as well as in the bleeding edge of research. While these are extremely necessary, often the focus on techniques that are beneficial to other tightly coupled tasks are overlooked. The goal of this survey is to focus on these key components that are task agnostic to improve the ensemble of tasks in neural text generation. %The rest of the survey is organized as follows: Section  describes the modeling approaches in text generation including the learning paradigms, pre-training and decoding strategies. This is followed by Section  describing the key challenges and solutions to the text generation such as fluency, length, content selection, speed etc.,. Section  describes evaluation and finally Section  presents the conclusions and the prospective future directions.   }   \end{table}     %https://www.sciencedirect.com/science/article/pii/S1319157820303360    There have been several studies conducted on surveying text generation. \citet{DBLP:journals/cai/PereraN17} present a detailed overview of information theory based approaches. \citet{iqbal2020survey} primarily focus on core modeling approaches, especially VAEs  and GANs . \citet{DBLP:journals/jair/GattK18} elaborated on tasks such as captioning, style trasfer etc., with a primary focus on data-to-text tasks. Controllability aspect is explored by \citet{prabhumoye2020exploring}. The workclosest to this is by \citet{DBLP:journals/corr/abs-1803-07133} who perform an empirical study on the core more modeling approaches only. In contrast to these, this paper focuses on task agnostic components and factors capable of pushing the ensemble of tasks forward. Figure  presents the various components and factors that are important to study in neural text generation which are elaborated in this paper. %Text generation is an overarching set of tasks where these underlying factors that cut across tasks are very critical in pushing the field forward and this paper is dedicated to be a one stop destination to learn these several fundamental factors.    In this work, we show that while chatbots can be improved using natural language feedback, converting feedback to natural responses that fit in the conversation outperform the naive usage of feedback.  We presented \feedresp, a generative adversarial model, that converts feedback to natural responses without requiring manually annotated parallel data. Our results show that \feedresp results in a 6~point improvement for the \polyencoder chatbot, an already powerful dialog ranking agent.  This is a strong result as HITS@1/20 is a tough metric to improve upon .  Our work joins the class of models that use natural language feedback to improve different tasks, e.g., image captioning , classification . While these methods use feedback for reward shaping or feature extraction, we use feedback to produce correct response using adversarial learning. We pose this problem as a style transfer problem inspired from the style transfer literature .  While these focus on studying the stylistic attributes of sentences, e.g, sentiment, we explore this problem in the context of improving chatbots.  
","   Neural text generation metamorphosed into several critical natural language applications ranging from text completion to free form narrative generation. Generating natural language has fundamentally been a human attribute and the advent of ubiquitous NLP applications and virtual agents marks the need to impart this skill to machines. There has been a colossal research effort in various frontiers of neural text generation including machine translation, summarization, image captioning, storytelling etc., We believe that this is an excellent juncture to retrospect on the directions of the field. Specifically, this paper surveys the fundamental factors and components relaying task agnostic impacts across various generation tasks such as storytelling, summarization, translation etc., In specific, we present an abstraction of the imperative techniques with respect to learning paradigms, pretraining, modeling approaches, decoding and the key challenges. Thereby, we hope to deliver a one-stop destination for researchers in the field to facilitate a perspective on where to situate their work and how it impacts other closely related tasks. %scope it : current neural techniques %for single and multi-sentence",239
"  The following instructions are directed to authors of papers submitted to EACL 2021 or accepted for publication in its proceedings. All authors are required to adhere to these specifications. Authors are required to provide a Portable Document Format  version of their papers. The proceedings are designed for printing on A4 paper.      The past decade witnessed text generation dribbling from niche scenarios into several mainstream NLP applications. This urges the need for a snapshot to retrospect the progress of varied text generation tasks in unison. This paper is written with the goal of presenting a one-stop destination for task agnostic components and factors in text generation for researchers foraging to situate their work and guage their impact in this vast field. Moving forward, we envision that there are some of the crucial directions to focus for impactful innovation in text generation. These include  generation in real time  non-autoregressive decoding  consistency with situated contexts in real and virtual environments and games  consistency with personality with opinions especially for virtual agents  conditioning on multiple modalities together with text and data  investigation is still ongoing on finding better metrics to evaluate NLG with better correlated human judgements   creative text generation. We believe this is the right time to extend advancements in any particular task to other tightly coupled tasks to revamp improvements in text generation as a holistic task.  
"," This document contains the instructions for preparing a manuscript for the proceedings of EACL 2021. The document itself conforms to its own specifications, and is therefore an example of what your manuscript should look like. These instructions should be used for both papers submitted for review and for final versions of accepted papers. Authors are asked to conform to all the directions reported in this document.",240
" Cross-lingual abstractive summarization is the task to generate a summary of a given document in a different target language. This task provides the overview of an article in a foreign language and thus helps readers understand a text written in an unfamiliar language quickly.   Early work on cross-lingual abstractive summarization adopted the pipeline approach: either translation of the given document into the target language followed by summarization of the translated document or summarization of the given document followed by translation of the summary into the target language. On the other hand, recent studies have applied a neural encoder-decoder model, which is widely used for natural language generation tasks including machine translation and monolingual abstractive summarization, to generate a summary in the target language from the given document directly. %Such direct generation approaches prevent the error propagation problems in pipeline methods. Such direct generation approaches prevent the error propagation in pipeline methods.  Training neural encoder-decoder models requires numerous sentence pairs. In fact,  provided 3.8M sentence-summary pairs to train their neural encoder-decoder model for English abstractive summarization, and the following studies used the same training data. However, constructing a large-scale cross-lingual abstractive summarization dataset is much more difficult than collecting monolingual summarization datasets because we require sentence-summary pairs in different languages. To address this issue, recent studies applied a machine translation model to monolingual sentence-summary pairs. They used the constructed pseudo dataset to train their neural encoder-decoder models.    Meanwhile, the possibility whether existing genuine parallel corpora such as translation pairs and monolingual abstractive summarization datasets can be utilized needs to be explored. In machine translation,  indicated that using translation pairs in multiple languages improved the performance of a neural machine translation model. Similarly, we consider that such existing genuine parallel corpora have a positive influence on the cross-lingual abstractive summarization task since the task is a combination of machine translation and summarization.   In this study, we propose a multi-task learning framework, Transum, which includes machine translation, monolingual abstractive summarization, and cross-lingual abstractive summarization, for neural encoder-decoder models. The proposed method controls the target task with a special token which is inspired by Google's multilingual neural machine translation system. For example, we attach the special token  to the beginning of the source-side input sentence in translation.   The proposed Transum is quite simple because it does not require any additional architecture in contrast to  but effective in cross-lingual abstractive summarization. Experimental results show that Transum improves the performance of cross-lingual abstractive summarization and outperforms previous methods in Chinese-English and Arabic-English summarization. In addition, Transum significantly improves machine translation performance compared to that obtained using only a genuine parallel corpus for machine translation.   Furthermore, we construct a new test set to simulate more realistic situations: cross-lingual summarization with several length constraints. In a summarization process, it is important to generate a summary of a desired length. However, existing test sets for cross-lingual abstractive summarization cannot evaluate whether each model controls output lengths because the test sets do not contain summaries with multiple lengths. Thus, we translate an existing monolingual abstractive summarization that contains summaries with multiple lengths to construct the new test set.    The contributions of this study are as follows:     Our results suggest that GPT-2 generally outputs better narratives than the most recent non-GPT-based neural model. Additionally, we find that larger models are better. While GPT-2 Large may be infeasible for very long sequence generation, it is possible to use GPT-2 Medium for all narrative lengths generated here. Once GPT-3  is released for public use, it is very likely that this model will outperform GPT-2 based on these trends. We encourage future work to investigate similar hyperparameters to see whether the trends observed here are stable across model sizes.  We recommend keeping the  hyperparameter within the range  to . This aligns with the findings of \citet{ippolito2020}, who suggest that  values well below  are needed to generate text that more closely approximates human text.    Diverse decoding increased narrative quality on all metrics at small . This could be used to qualitatively induce more intense and vivid stories with higher  values, though this finding should be seen as preliminary and tested in other domains. Using higher values of  also seemed to induce more vivid stories, but with less consistent fluency and coherence; thus, the diverse decoding objective could be a promising way to increase narrative interestingness without significantly decreasing performance on any particular metric.  While relatively low dist- may correlate with consistently poor quality stories and relatively high dist- may correlate with more variable-quality stories, we find that this metric did not correlate well with any of our metrics in general . Sent-BERT did not correlate with any of our metrics of narrative quality. Thus, we do not recommend optimizing over either of these automatic quantities.  Surprisingly, we do not find a strong diversity-quality trade-off in narrative generation, perhaps due to the more creative and long-form nature of this task. Indeed, diversity and quality do not correlate well in general: diverse decoding and higher  values often coincide with better performance on all human metrics in this domain up to a point. This could be due to the more creative and long-form nature of narrative generation compared to tasks such as chatbot response generation. We thus encourage future work to investigate other methods of inducing more diverse output, as certain methods can increase human perceptions of narrative quality.  Our findings aim to inform future efforts in the narrative generation domain by establishing future baselines given our recommended hyperparameters, and by facilitating further investigation of decoding objectives for better narrative generation. Additionally, we hope that this investigation highlights issues to be addressed in future work when evaluating narratives automatically, since no metrics aside from perplexity seem to correlate well with human judgments of quality.     \clearpage    
"," We present a multi-task learning framework for cross-lingual abstractive summarization to augment training data. Recent studies constructed pseudo cross-lingual abstractive summarization data to train their neural encoder-decoders. Meanwhile, we introduce existing genuine data such as translation pairs and monolingual abstractive summarization data into training. Our proposed method, Transum, attaches a special token to the beginning of the input sentence to indicate the target task. The special token enables us to incorporate the genuine data into the training data easily. The experimental results show that Transum achieves better performance than the model trained with only pseudo cross-lingual summarization data. In addition, we achieve the top ROUGE score on Chinese-English and Arabic-English abstractive summarization. Moreover, Transum also has a positive effect on machine translation. Experimental results indicate that Transum improves the performance from the strong baseline, Transformer, in Chinese-English, Arabic-English, and English-Japanese translation datasets.",241
" Table-to-text generation is an important task for text generation from structured data. It aims at automatically producing descriptive natural language text that covers the salient information in table to help people to get the salient information of the tables. Practical applications can be found in domains such as weather forecasts, biography generation, NBA news generation, etc.  Over the pass several years, neural text generation methods have made significant progress on this task. \citeauthor{lebret-etal-2016-neural,wiseman-etal-2017-challenges,bao2018table} model it as a machine translation task and view the input table a record sequence. To generate text that contains more salient and well-organized facts,  \citeauthor{sha2018order,puduppully-etal-2019-data,moryossef-etal-2019-step,trisedya2020sentence,ijcai2020-522} explicitly model content selection and planning. %Some works also introduce extra knowledge  or pre-executed symbolic operations on table  to improve the result. To learning better representation for tables,  \citeauthor{liu2018table,bao2018table,nema-etal-2018-generating,jain-etal-2018-mixed,gong-etal-2019-table} explicitly model the structure of table from multiple levels or different dimensions. In addition, \citeauthor{liu2019hierarchical} propose three auxiliary supervision tasks to capture accurate semantic representation of the table.    However, some issues have been overlooked. First, many tables ) contain a large number of numerical records. For instance,  of records and almost  of column types are numeric in ROTOWIR , a benchmark of NBA basketball games. Current methods treat these records as words in natural language text and ignore the characteristics of the number itself which play an important role in table representation, such as size attribute. In addition, there are noises in human-written summaries in dataset. These noises include redundant information and records that do not exist in the input tables ). These noises may cause incorrect alignments between input tables and target text or wrong supervision signals. And they can affect the performance of models based on content selection and planning or auxiliary supervision. %In addition, when human are writing a summary to describe the given table, they may consider the most salient records. For example, when describing the table in Figure  , they may pay more attention to K. Leonard, because he is the top scorer.   To solve above problems, we explore the use of the information contained in the tables and introduce two self-supervised tasks to learn better representation for tables. We argue that the better representation of tables can help the model to capture and organize the important facts, even without explicitly modeling content selection and planning. Specially, we improve ~\citeauthor{gong-etal-2019-table}'s method and employ a hierarchical table encoder to model the table structure from record level and row level. The record-level encoder utilizes two cascaded self-attention models to encode the table from column and row dimension, respectively. And then, we introduce a row-level fusion gate to obtain the row-level representation for each row. To learn a number-aware record representation, we introduce a Number Ordering  task. This task utilizes a pointer network to generate a descending record sequence for each column in table, according to their content. Figure   shows a number ordering example for column PTS. To the best of our knowledge, this is the first work on neural table-to-text generation via focusing on learning representation for number in table. Another self-supervised task, Significance Ordering , is further proposed to learn a significance-aware representation for the record. The significance denotes the relative relation between records in same row. This is inspired by the intuition that when humans describe the performance of a player, they tend to focus on his more salient records. For example, in Figure , K. Thompson's scores  is more likely to be described than his other's records. The SO task executes a descending sort operation on each row according to the significance scores of records. We use the position index of record  to measure its importance and the smaller the significance score, the more important the record is. The position index of record is obtained by the results of Number Ordering. For example, in Figure  , K. Thompson scores  points which are the largest in PTS, so the significance score of this record is 1. The proposed two tasks are trained together with the table2text generation model and they share the same encoder parameters. Obviously, the two proposed tasks are self-supervised and the training labels are easily obtained from the input tables. Therefore, the errors caused by noises in training set are avoided. %For record in same row, it includes another size information:significance. It denotes the relative relation between records in same row. To learn a significance-aware representation for table, we propose a Significance Ordering task which executes a ascending sort operation on each row according to the significance of records. We use the position index of record  to measure its importance and the smaller the significance score, the more important the record is. The position index of record is obtained by the results of Number Ordering. For example, in Figure  , K. Leonard score 45 points which are the largest in PTS, so the significance score of this record is 1). Obviously, the two proposed tasks are self-supervised and the training labels are easily obtained from the input tables. Therefore, the errors caused by noise in training set are avoided.   We conducted experiments on ROTOWIRE to verify the effectiveness of the proposed approach. The experimental results demonstrate that, even without explicitly modeling content selection or introducing extra knowledge, our method can help to generate text that contains more salient and well-organized facts. And we achieve the state-of-the-art performance on automatic metrics. %Content Selection , Content Ordering  and BLEU.     This paper presents a multi-task learning framework for cross-lingual abstractive summarization to augment training data. The proposed method, Transum, attaches the special token to the beginning of the input sentence to indicate the target task. The special token enables us to use genuine translation pairs and the monolingual abstractive summarization dataset in addition to the pseudo cross-lingual abstractive summarization data for training. The experimental results show that Transum achieved better performance than the pipeline approach and model trained with pseudo data only. We achieved the top ROUGE scores in Chinese-English and Arabic-English abstractive summarization. Moreover, Transum also improved the performance of machine translation and outperformed the previous top score in the JIJI English-Japanese translation.         
"," Table-to-text generation aims at automatically generating natural text to help people to conveniently obtain the important information in tables. Although neural models for table-to-text have achieved remarkable progress, some problems still overlooked. The first is that the values recorded in many tables are mostly numbers in practice. The existing approaches do not do special treatment for these, and still regard these as words in natural language text.  Secondly, the target texts in training dataset may contain redundant information or facts do not exist in the input tables. These may give wrong supervision signals to some methods based on content selection and planning and auxiliary supervision. To solve these problems, we propose two self-supervised tasks, Number Ordering and Significance Ordering,  to help to learn better table representation. The former works on the column dimension to help to incorporate the size property of numbers into table representation. The latter acts on row dimension and help to learn a significance-aware table representation. We test our methods on the widely used dataset ROTOWIRE which consists of NBA game statistic and related news. The experimental results demonstrate that the model trained together with these two self-supervised tasks can generate text that contains more salient and well-organized facts, even without modeling context selection and planning. And we achieve the state-of-the-art performance on automatic metrics. % Content Selection , Content Ordering  and BLEU.",242
" In healthcare, real-world data  refers to patient data routinely collected during clinic visits, hospitalization, as well as patient-reported results. In recent years, RWD's volume has become enormous, and invaluable insights and real-world evidence can be generated from these datasets using the latest data processing and analytical techniques. However, RWD's quality remains one of the main challenges that prevent novel machine learning methods from being readily adopted in healthcare.  Therefore, creating data quality tools is of great importance in health care and health data sciences.  Erroneous data in healthcare systems could jeopardize a patient's clinical outcomes and affect the care provider's ability to optimize its performance.     Common data quality issues include missing critical information about medical history, wrong coding of a condition, and inconsistency in documentation across different care sites. Manual review by domain experts is the gold standard for achieving the highest data quality but is unattainable in regular care practices. Recent developments in the field of Natural Language Processing  has attracted great interest in the healthcare community since algorithms for identifying variables of interest and classification algorithm for diseases  have been recently developed .  In this paper, we presented a novel model for the extraction of queries  in a corpus of dialogue between data entry clinicians and expert reviewers in a multi-site dialysis environment.   %The work's ultimate goal is to identify the data elements that caused most uncertainty or errors during the documentation process.  The main contributions of this work are:  Finally, in addition to evaluating our model's performance in a medical context, we also experimented in section  with a general-domain dataset  to show our model's generalizability.  The rest of the paper is organized as follows. Related work is presented in section . The different question detection methods that will be examined,   are described in section . Section  details the characteristics of the proposed multi-channel CNN model. Finally, the results of the experiments are reported in section  and a conclusion and a plan for future work are given in section .    In this work, we first point out the shortcomings of MLE based training for keyphrase generation. We specifically address the lack of output diversity issue via the use of unlikelihood training objective. We adopt a target level unlikelihood loss and propose a novel copy token unlikelihood loss, the combination of which provides large diversity gains. In addition, a -step ahead MLE and UL objective is incorporated into the training. Through extensive experiments on datasets from three different domains, we demonstrate the effectiveness of our model for diverse keyphrase generation. For future work, we plan to explore directions that would enable us to simultaneously optimize for quality and diversity metrics.  
"," In most clinical practice settings, there is no rigorous reviewing of the clinical documentation, resulting in inaccurate information captured in the patient medical records. The gold standard in clinical data capturing is achieved via ``expert-review"", where clinicians can have a dialogue with a domain expert  and ask them questions about data entry rules. Automatically identifying ``real questions"" in these dialogues could uncover ambiguities or common problems in data capturing in a given clinical setting.  In this study, we proposed a novel multi-channel deep convolutional neural network architecture, namely Quest-CNN, for the purpose of separating real questions that expect  an answer  about an issue from sentences that are not questions, as well as from questions referring to an issue mentioned in a nearby sentence , which we will refer as ``c-questions"". We conducted a comprehensive performance comparison analysis of the proposed multi-channel deep convolutional neural network against other deep  neural networks. Furthermore, we evaluated the performance of traditional rule-based and learning-based methods for detecting question sentences. The proposed Quest-CNN achieved the best F1 score both on a dataset of data entry-review dialogue in a dialysis care setting, and on a general domain dataset.",243
"  Semantic parsing is the task of mapping a natural language query into a formal language, that is extensively used in goal-oriented dialogue systems. For a given query, such model should identify the requested action  and the associated values specifying parameters of the action . For example, if the query is Call Mary the action is call and the value of slot contact is Mary.  The number of different intents and slots in publicly available datasets  can be close to a hundred and it may be the orders of magnitude larger in real-world systems. Such a big number of classes usually causes a long tail in the class frequency distribution . These tail classes can be significantly improved with small quantities of additional labeled data.    However, training a neural semantic parsing model from scratch can take hours even on a relatively small public dataset . The real-world datasets can contain millions of examples  which can change the time scale to weeks. % Need to describe the problem and motivation to production settings more.  In this work, we propose to fine-tune a model that has already been trained on the old dataset  instead of training a new model to significantly speed up the incorporation of a new portion of data. We call this setting Incremental training, as the new portions of data can be added incrementally.  We focus on semantic parsing % and seq2seq networks for our case studies for the following reasons. Semantic parsing is a more complex NLP task compared to classification or NER and we hope that the lessons learned here would be more widely applicable. Task-oriented semantic parsing tend to have a large output vocabulary that can be frequently updated, and thus, benefit most from the Incremental setting. % We choose seq2seq networks for this work due to two reasons: first, seq2seq networks are very % general and can be easily adapted to simpler tasks like NER; % second, seq2seq models perform really well on popular natural language understanding datasets like TOP and SNIPS.  % Exploring this space of possible solutions, we compare the effectiveness of these approaches with each other and come up with a set of guidelines that are useful for incremental training tasks as well.  % To emulate the ""data-patch"" scenario, we split these datasets by focusing on a few classes. We show that naive fine-tuning leads to catastrophic forgetting and come up with approaches to remedy this. We observe that it is possible to fine-tune models to new classes in a few minutes compared to hours when retraining from scratch. We also compare the effect of pre-trained representations like BERT on fine-tuning. Using these observations we come up with fine-tuning guidelines in scenarios where the label space does not change. We verify that our approaches work on 2 popular semantic parsing datasets: TOP and SNIPS under different data splits.  The main contributions of this work are:    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Related work %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%     In this paper, we have provided an analysis of the performance of existing methods for question extraction with real-world misclassification examples that showed the weak point of each method. Furthermore, we have proposed a novel approach for the automatic identification of real questions   and c-questions. We have also shown empirically that the proposed architecture of unifying syntactic, semantic and statistical features achieved a state-of-the-art F1 score for this particular task. Finally, we have presented the relevance of exploiting domain knowledge in the overall performance of a model.  We are in the process of obtaining access to datasets from different application contexts in order to examine the generalizability of our model. As for future work, we plan to extend our work by calculating the similarity of questions in order to create groups of questions that represent the most impactful ``problems'' of a given application environment. Finally, we plan to compare our model with recent  language   representation  models like the BERT model  in  both for the task of question identification and for the task of creating the above mentioned ``problem'' groups.      
"," A semantic parsing model is crucial to natural language processing applications such as goal-oriented dialogue systems. Such models can have hundreds of classes with a highly non-uniform distribution. In this work, we show how to efficiently  improve model performance given a new portion of labeled data for a specific low-resource class or a set of classes. We demonstrate that a simple approach with a specific fine-tuning procedure for the old model can reduce the computational costs by ~90\% compared to the training of a new model. The resulting performance is on-par with a model trained from scratch on a full dataset. We showcase the efficacy of our approach on two popular semantic parsing datasets, Facebook TOP, and SNIPS.",244
"  Recent progress in abstractive summarization has been fueled by the advent of large-scale Transformers pre-trained on autoregressive language modeling objectives . Despite their strong performance on automatic metrics like ROUGE , abstractive models are not as straightforward and interpretable as their extractive counterparts. Free-form generation in these models also leads to serious downstream errors, such as factual inconsistencies with the input document . Although the interpretability of NLU models has been extensively studied , summarization models specifically have not received similar attention, with analysis efforts often focused on datasets and evaluation .  %Generic explanation methods for language models  or neural machine translation models  are not entirely applicable, as summarization models typically have different interactions with the input document.  In this work, we focus on interpreting and understanding abstractive summarization models through the lens of decoder uncertainty, or the entropy of decisions during generation. While uncertainty in generation has been studied from the perspective of data , sampling , and training  , it is underutilized as a technique for analysis and inspection of generation systems. We study two prominent summarization models, PEGASUS  and BART , fine-tuned on two English summarization datasets, CNN/Daily Mail  and XSum , to understand model behavior in each setting. %We analyze the model using both blackbox and whitebox perspectives.  First, by comparing -grams between the input document and generated summaries, we establish two coarse types for decoded tokens, copy and generate . We find that the entropy of the generation decision correlates with whether the model is copying or generating, as well as where in the sentence the token is. This paints a picture of certain contexts being more restrictive from the standpoint of generation, particularly early in sentences where a model has not ``decided'' what to copy yet, and illustrates the interaction of content selection and lexical choice. %Furthermore, it illustrates the interaction of content selection and lexical choice: new bigrams are higher entropy, but beginnings of sentences are also high entropy, indicating that the model has some uncertainty about what sentence to discuss, even if it is going to copy. Second, we extend this analysis by looking at how uncertainty relates to the syntax of the generated sentence: whether uncertainty connects to syntactic notions of surprisal  and how the entropy varies across certain syntactic productions. % Finally, we derive a way to quantify decoder attention by aggregating self-attention heads, and investigating the correspondence between the prediction entropy and the fraction of the decoded tokens in the aggregated attention.\todo{change this sent to refer to entropy more} Finally, we derive a way to quantify decoder attention by aggregating distinct self-attention heads, revealing the correlation between the attention entropy and prediction entropy, and investigating the correspondence between the prediction entropy and the fraction of the past and future decoded tokens. % highly attentive positions and decoded or not-yet-decoded tokens with respect to specific Transformer layers in the decoder.  Taking this analysis together, we find that the abstractiveness of reference summaries fundamentally changes model behavior: the extractive nature of CNN/DM makes most of its decisions low entropy and copy-oriented while the model maintains higher uncertainty on XSum, yielding more abstractive summaries. More broadly, we show that uncertainty is a simple but effective tool to characterize decoder behavior in text generation. %  By analyzing decoder self-attention layers, we find that when the attention only focuses on a few tokens, the prediction entropy will be fairly low and the focused tokens are very likely to be predicted.       In this work, we consider a practical side of CL that has been previously overlooked by NLP researchers - the ability to quickly update an existing model with new data. Nowadays, with the performance of models scaling superlinearly with their size, training time becomes a more challenging issue every year. We anticipate that in the near future of billion-parameter-sized models, incremental and continual learning settings can not only lead to a significant advantage in terms of resource efficiency but also become a necessity.  Our experimental results show that a simple incremental setup can reduce computational costs up to 90\ . It is both beneficial in terms of increasing the speed of the development cycle and in terms of the environmental impact that is becoming more and more significant in the field .  We also want to notice some of the negative results we discovered. Training only the top layer  is a surprisingly bad way to include more data. Possibly, because some of the feature-engineering should happen in the lower layers of the model. Also, even though the model quickly fits the fine-tuning data, increasing regularization does not seem to improve the final performance. And finally, a na\""{\i}ve combination of successful methods such as dynamic sampling, freezing, and move norm does not seem to help either.    This paper evaluates simple and efficient methods for Incremental training, The Continual Learning community has made incredible progress using   more sophisticated methods such as EWC  and LAMOL . Many of these approaches are applicable in a real-world scenario and should be tested in practical applications. In our future work, we want to consider such models and evaluate them in terms of both performance  and computational costs. Another important direction is to study how the model changes after multiple iterative updates.                                             References                                               TODO: REMOVE THIS BEFORE THE FINAL VERSION!!!     \section{Hyperparameters and training setup}   Table  contains hyperparameters used for pretraining. We used the Noam schedule  for the learning rate. Note that it involves  learning rate scaling.   For fine-tuning, the same parameters were used unless otherwise stated in the experiment description. The only exception to this rule is the batch size that we set to 128 during all fine-tuning experiments. Model, optimizer, and learning rate scheduler states were restored from the checkpoint with the best EM.         
"," % An advantage of seq2seq abstractive summarization models is that they generate text in a free-form manner, but this inherent flexibility makes it difficult to interpret and understand model behavior. In this work, we adopt a data-driven methodology to unpack decoder behavior in both a blackbox and whitebox way. We fine-tune and analyze a GPT-2 \cite{radford-2019-gpt2} model on two benchmark datasets featuring different levels of abstraction. Our experiments yield three key results. First, by analyzing the entropy of model predictions and its corresponding test-time behavior, we find a strong correlation between low entropy and where the model copies document spans rather than generating novel text. Second, this entropy analysis can allow us to understand what sentence positions and even what syntactic configurations are associated with copying existing content. Finally, by analyzing decoder self-attention patterns, we can trace this copying behavior to a particular pattern of attending to immediate decoder context and finding the next token to generate in the source document. An advantage of seq2seq abstractive summarization models is that they generate text in a free-form manner, but this flexibility makes it difficult to interpret model behavior.  In this work, we analyze summarization decoders in both blackbox and whitebox ways by studying on the entropy, or uncertainty, of the model's token-level predictions. For two strong pre-trained models, PEGASUS \cite{pegasus} and BART \cite{lewis-2019-bart} on two summarization datasets, we find a strong correlation between low prediction entropy and where the model copies tokens rather than generating novel text. The decoder's uncertainty also connects to factors like sentence position and syntactic distance between adjacent pairs of tokens, giving a sense of what factors make a context particularly selective for the model's next output token. Finally, we study the relationship of decoder uncertainty and attention behavior to understand how attention gives rise to these observed effects in the model. We show that uncertainty is a useful perspective for analyzing summarization and text generation models more broadly.\footnote{Code is available at \url{https://github.com/jiacheng-xu/text-sum-uncertainty}} % can trace this copying behavior to a particular pattern of attending to immediate decoder context and finding the next token to generate in the source document.",245
"  Neural attention mechanisms have been widely applied in  computer vision and have been shown to enable neural networks to only focus on those aspects of their input that are important for a given task. While neural networks are able to learn meaningful attention mechanisms using only supervision received for the target task, the addition of human gaze information has been shown to be beneficial in many cases. An especially interesting way of leveraging gaze information was demonstrated by works incorporating human gaze into neural attention mechanisms, for example for image and video captioning or visual question answering.  While attention is at least as important for reading text as it is for viewing images, integration of human gaze into neural attention mechanisms for natural language processing  tasks remains under-explored. A major obstacle to studying such integration is data scarcity: Existing corpora of human gaze during reading consist of too few samples to provide effective supervision for modern data-intensive architectures and human gaze data is only available for a small number of NLP tasks. For paraphrase generation and sentence compression, which play an important role for tasks such as reading comprehension systems, no human gaze data is available.  We address this data scarcity in two novel ways: First, to overcome the low number of human gaze samples for reading, we propose a novel hybrid text saliency model  in which we combine a cognitive model of reading behavior with human gaze supervision in a single machine learning framework. More specifically, we use the E-Z Reader model of attention allocation during reading to obtain a large number of synthetic training examples. We use these examples to pre-train a BiLSTM network with a Transformer whose weights we subsequently refine by training on only a small amount of human gaze data. We demonstrate that our model yields predictions that are well-correlated with human gaze on out-of-domain data. Second, we propose a novel joint modeling approach of attention and comprehension that allows human gaze predictions to be flexibly adapted to different NLP tasks by integrating TSM predictions into an attention layer. By jointly training the TSM with a task-specific network, the saliency predictions are adapted to this upstream task without the need for explicit supervision using real gaze data. Using this approach, we outperform the state of the art in paraphrase generation on the Quora Question Pairs corpus by more than 10\% in BLEU-4 and achieve state of the art performance on the Google Sentence Compression corpus. As such, our work demonstrates the significant potential of combining cognitive and data-driven models and establishes a general principle for flexible gaze integration into NLP that has the potential to also benefit tasks beyond paraphrase generation and sentence compression.     This work analyzes pre-trained summarization models via uncertainty, or the entropy of decoding decisions. We pursue several lines of inquiry: uncertainty can help us understand copying document spans vs.~generating novel text, the behavior of models in different syntactic environments, and coarse properties of the model's attention distribution. All of these give insight into what conditions most heavily restrict the model's generation: generating an observed bigram , low syntactic distance, and attention which can easily identify decoder context in the source document. We believe this approach can power future analyses of pre-trained text generation systems.  
"," A lack of corpora has so far limited advances in integrating human gaze data as a supervisory signal in neural attention mechanisms for natural language processing . We propose a novel hybrid text saliency model  that, for the first time, combines a cognitive model of reading with explicit human gaze supervision in a single machine learning framework. On four different corpora we demonstrate that our hybrid TSM duration predictions are highly correlated with human gaze ground truth. We further propose a novel joint modeling approach to integrate TSM predictions into the attention layer of a network designed for a specific upstream NLP task without the need for any task-specific human gaze data. We demonstrate that our joint model outperforms the state of the art in paraphrase generation on the Quora Question Pairs corpus by more than 10\% in BLEU-4 and achieves state of the art performance for sentence compression on the challenging Google Sentence Compression corpus. As such, our work introduces a practical approach for bridging between data-driven and cognitive models and demonstrates a new way to integrate human gaze-guided neural attention into NLP tasks.",246
" %\hh{check the fuzziness: pre-trained or pretrained and decide which one to use .} Modern techniques for text summarization generally can be categorized as either extractive methods, which identify the most suitable %\pfliu{How about ``which identify the most suitable semantic units ''}  words or sentences from the input document and concatenate them to form a summary, or abstractive methods, which generate summaries freely and are able to produce novel words and sentences. Compared with extractive algorithms, abstractive algorithms are more flexible, making them more likely to produce fluent and coherent summaries. %\pfliu{better if adding some references here}  %and the generation process is more human-like \gn{Re ``more human-like''. First, I'm not sure if this is actually true: humans copy-paste text as well. Second, it doesn't seem really important here. Maybe you could just expand on the ``more flexible'' part and mention the practical advantages of this.}. However, the unconstrained nature of abstractive summarization can also result in problems. First, it can result in unfaithful summaries, containing factual errors as well as hallucinated content. Second, it can be difficult to control the content of summaries; it is hard to pick in advance which aspects of the original content an abstractive system may touch upon. %\pfliu{I'm thinking about if it's suitable to place the following paragraph here .  Will it be better if we exchange it with ``There have been some ...'' this paragraph and make corresponding modification.} To address the issues, we propose methods for guided neural abstractive summarization: methods that provide various types of guidance signals that 1) constrain the summary so that the output content will deviate less from the source document; 2) allow for controllability through provision of user-specified inputs.             % Table generated by Excel2LaTeX from sheet 'Sheet1' \iffalse %   %      \end{table*}%  \fi      \iffalse  %   '' and ``{cover.}'' represent the copy and coverage mechanism respectively. Guidance represents different guided information while Guiding Method denotes how to introduce the guided information. ``ourGuidance'' contains sentences, relations keywords and retrieved summaries. ``Marker Embedding'' suggests that the guided information is introduced by embedding it as a feature vector.}% \gn{add  for completeness. Make sure it's in chronological order. I don't think BART needs to be included, but you might also include other methods that provide guidance on, for example, the style of the output .}} %\zj{Is there any particular reason to make ``copy'' and ``cover.'' italic?}.}   % \end{table*}%  \fi  %      %'' and ``{cover.}'' represent the copy and coverage mechanism respectively. Guidance represents different guided information while Guiding Method denotes how to introduce the guided information. ``ourGuidance'' contains sentences, relations keywords and retrieved summaries. ``Marker Embedding'' suggests that the guided information is introduced by embedding it as a feature vector.}% \gn{add  for completeness. Make sure it's in chronological order. I don't think BART needs to be included, but you might also include other methods that provide guidance on, for example, the style of the output .}} %\zj{Is there any particular reason to make ``copy'' and ``cover.'' italic?}.}   % \end{table*}%  %\gn{The term ``hybrid summarization models'' is sudden, and it doesn't follow clearly from the last sentence in the previous paragraph. I think the point of this paragraph is ``we are not the first to propose guided neural summarization models, but previous methods were limited to only a particular type of guidance''. If so, then you can say the ``we are not the first'' part at the beginning of this paragraph, and the ``limited'' part at the final part of the paragraph.} There have been some previous methods for guiding neural abstractive summarization models. For example,~\citet{kikuchi-etal-2016-controlling} specify the length of abstractive summaries,~\citet{li2018guiding} provide models with keywords to prevent the model from missing key information, and ~\citet{cao2018retrieve} propose models that retrieve and reference relevant summaries from the training set. %, and~\citet{gehrmann2018bottom} propose to train a model to identify salient words and encourage the final model to faithfully copy them from the source. While these methods have demonstrated improvements in summarization quality and controllability, each focuses on one particular type of guidance -- it remains unclear which is better and whether they are complementary to each other. %In addition, most of the previous work whether they are compatible with pre-trained language models such as BERT. %Previously, in order to address the issues of abstractive summarization models, researchers have proposed hybrid summarization models that combine the merits of extractive and abstractive methods. %\gn{In the following three sentences, it is not explicitly stated or clear how these methods address the issues of abstractive summarization models.} %For example,~\citet{gu2016incorporating} propose methods to copy words from the source document.~\citet{gehrmann2018bottom} utilize bottom-up attention to constrain the decoder to attend to salient parts of the inputs. %Similarly, %While these approaches can achieve good performance in terms of ROUGE, we cannot guarantee the models learn to identify the salient segments correctly or control the summaries due to the lack of explicit supervision signals  %\gn{can your model guarantee this? if you're putting it as a downside here it seems that it should be something that does not apply to your model.} \zd{I think our model does not try to learn to identify the salient part. Instead, we explicitly provide the salient part to the model so that the model learns to rely on this input.} \gn{But the extractive summarization model may fail at test time, right?} \zd{right, but i think that's the problem of extractive summarization, and the goal of our model is to learn to depend on the input, no matter whether the input signal is correct or not. } \gn{See my comment below. I think that there's a problem of a disconnect between how you're presenting the method , and what we're actually doing in experiments. It'd be best if you can write the story in the way that encompasses the things in experiments . Could you think of a way to reframe the intro a little bit in this direction? I think one thing you can definitely say about your method is that it can use a wide variety of different types of guidance, including that from automatic up-stream systems, or perhaps user-specified keywords etc. You are using a method to encourage the model to pay close attention to this guidance . This is very empirically effective. I'll take a look once you've thought about this a bit and modified the intro accordingly. Additionally, you might want to add a sentence to the end of the first paragraph describing what you attempt to achieve in this paper before jumping into the previous work. This will help make the contrasts more clear in this paragraph.} \zd{Thanks a lot! I'll think more about this and change the paper accordingly!}. %To improve the controllability of summarization models, previous works have attempted to provide models with keywords or length information, but the choices of guidance are limited and thus the controllability of the output summaries is hindered \gn{Again, here it's not super-clear how or why your proposed method is better in these aspects}.   %\gn{I think this is OK, but could really benefit from a figure at the top-right of page 1 demonstrating the behavior.} %To obtain abstractive summarization models with good performance as well as flexible controllability, In this paper, we propose a general and extensible guided summarization framework that can take different kinds of external guidance as input. %\gn{Maybe one more sentence on how the framework works.} Like most recent summarization models, our model is based on neural encoder-decoders, instantiated with contextualized pretrained language models, including BERT and BART. With this as strong starting point, we make modifications allowing the model to attend to both the source documents and the guidance signals when generating outputs. %\gn{A little more concreteness here could help, even just saying ``attends to sequences representing both the source document and the guidance signal''.} %\gn{I would put the next two sentences in the method description above, before we discuss the specific types of guidance we provide.} As shown in Figure, we can provide automatically extracted or user-specified guidance to the model during test time to constrain the model output. At training time, to encourage the model to pay close attention to the guidance, %\pfliu{Since oracle-based training method is a  contribution of this work, it would be better if we can express this more explicitly. For example: ``we propose to use ...instead of ..''} we propose to use an oracle to select informative guidance signals -- a simple modification that nonetheless proved essential in effective learning of our guided summarization models.  %\gn{How is this different than ? This sentence seems to say the same thing as the second-to-last sentence of the previous paragraph. I understand that ``extensible'' may be attempting to make a contrast, but it's not very clear.}. Using this framework, we investigate four types of guidance signals:  highlighted sentences in the source document,  keywords,  salient relational triples in the form of , and  retrieved summaries. %\zj{Just a minor point. Maybe better to make the orders here consistent with the experiment section .}   We evaluate our methods on 6 popular summarization benchmarks. Our best model, using highlighted sentences as guidance, can achieve state-of-the-art performance on 4 out of the 6 datasets, including 1.28/0.79/1.13 ROUGE-1/2/L improvements over previous state-of-the-art model on the widely-used CNN/DM dataset. In addition, we perform in-depth analyses of different guidance signals and demonstrate that they are complementary to each other in that we can aggregate their outputs together and obtain further improvements. An analysis of the results also reveals that our guided models can generate more faithful summaries and more novel words. Finally, we demonstrate that we can control the output by providing user-specified guidance signals, with different provided signals resulting in qualitatively different summaries.  %\pfliu{Do we need to highlight our contributions?} %We first evaluate our methods on the widely-used CNN/DailyMail benchmark and perform in-depth analysis of different guidance signals. Experimental results demonstrate that our best method can achieve 1.13 ROUGE-L improvements over the state-of-the-art model. We then pick the best guidance signal and evaluate our models on the other five popular summarization benchmarks. Extensive experiments demonstrate the effectiveness of our model on extractive datasets and analyses reveal that our methods can generate more novel words and more faithful summaries. In addition, we can control the output by providing user-specified guidance signals.      In this work we made two novel contributions towards improving natural language processing tasks using human gaze predictions as a supervisory signal. First, we introduced a novel hybrid text saliency model that, for the first time, integrates a cognitive reading model with a data-driven approach to address the scarcity of human gaze data on text. Second, we proposed a novel joint modeling approach that allows the TSM to be flexibly adapted to different NLP tasks without the need for task-specific ground truth human gaze data. We showed that both advances result in significant performance improvements over the state of the art in paraphrase generation as well as competitive performance for sentence compression but with a much less complex model than the state of the art. We further demonstrated that this approach is effective in yielding task-specific attention predictions. Taken together, our findings not only demonstrate the feasibility and significant potential of combining cognitive and data-driven models for NLP tasks -- and potentially beyond -- but also how saliency predictions can be effectively integrated into the attention layer of task-specific neural network architectures to improve performance.            
"," Neural abstractive summarization models are flexible and can produce coherent summaries, but they are sometimes unfaithful and can be difficult to control. While previous studies attempt to provide different types of guidance to control the output and increase faithfulness, it is not clear how these strategies compare and contrast to each other. In this paper, we propose a  general and extensible guided summarization framework  that can effectively take different kinds of external guidance as input, and we perform experiments across several different varieties. Experiments demonstrate that this model is effective, achieving state-of-the-art performance according to ROUGE on 4 popular summarization datasets when using highlighted sentences as guidance. In addition, we show that our guided model can generate more faithful summaries and demonstrate how different types of guidance generate qualitatively different summaries, lending a degree of controllability to the learned models.\footnote{Code is available at \url{https://github.com/neulab/guided_summarization}.}%, generating more novel words, and generating more faithful summaries on 4 popular summarization datasets \gn{``when using XXX as guidance''}. In addition, we demonstrate how different types of guidance generate qualitatively different summaries, lending a degree of controllability to the learned models.",247
" In recent years, abstractive summarization  has made impressive progress with the development of sequence-to-sequence  framework . This framework is composed by an encoder and a decoder. The encoder processes the source text and extracts the necessary information for the decoder, which then predicts each word in the summary. Thanks to their generative nature, abstractive summaries can include novel expressions never seen in the source text, but at the same time, abstractive summaries are more difficult to produce compared with extractive summaries  which formed by directly selecting a subset of the source text. It has been also found that seq2seq-based abstractive methods usually struggle to generate out-of-vocabulary  words or rare words, even if those words can be found in the source text. Copy mechanism  can alleviate this problem and meanwhile maintain the expressive power of the seq2seq framework. The idea is to allow the decoder not only to generate a summary from scratch but also copy words from the source text.  Though effective in English text summarization, the copy mechanism remains relatively undeveloped in the summarization of some East Asian languages e.g. Chinese. Generally speaking, abstractive methods for Chinese text summarization comes in two varieties, being word-based and character-based. Since there is no explicit delimiter in Chinese sentence to indicate word boundary, the first step of word-based methods  is to perform word segmentation . Actually, in order to avoid the segmentation error and to reduce the size of vocabulary, most of the existing methods are character-based . When trying to combine the character-based methods in Chinese with copy mechanism, the original ``word copy'' degrades to ``character copy'' which does not guarantee a multi-character word to be copied verbatim from the source text . Unfortunately, copying multi-character words is quite common in Chinese summarization tasks. Take the Large Scale Chinese Social Media Text Summarization Dataset   as an example, according to Table I, about 37\% of the words in the summaries are copied from the source texts and consist of multiple characters.    		} 	\end{center}  	   	 \end{table}  Selective read  was proposed to handle this problem. It calculates the weighted sum of encoder states corresponding to the last generated character and adds this result to the input of the next decoding step. Selective read can provide location information of the source text for the decoder and help it to perform the consecutive copy. A disadvantage of this approach, however, is that it increases reliance of present computation on partial results before the current step which makes the model more vulnerable to the errors accumulation and leads to exposure bias during inference.  Another way to make copied content consecutive is through directly copying text spans. Zhou et al.  implement span copy operation by equipping the decoder with a module that predicts the start and end positions of the span. Because a longer span can be decomposed to shorter ones, there are actually many different paths to generate the same summary during inference, but their model is optimized by only the longest common span at each time step during training, which exacerbates the discrepancy between two phases. In this work, we propose a novel lexicon-constrained copying network . The decoder of LCN can copy either a single character or a text span at a time, and we constrain the text span to match a potential multi-character word. Specifically, given a text and several off-the-shell word segmentators, if a text span is included in any segmentation result of the text, we consider it as a potential word. By doing so, the number of available spans is significantly reduced, making it is viable to marginalize over all possible paths during training. Furthermore, during inference, we aggregate all partial paths on the fly that producing the same output using a word-enhanced beam search algorithm, which encourages the model to copy multi-character words and facilitates the parallel computation.  To be in line with the aforementioned decoder, the encoder should be revised to learn the representations of not only characters but also multi-character words. In the context of neural machine translation, Su et al.  first organized characters and multi-character words in a directed graph named word-lattice. Following Xiao et al. , we adopt an encoder based on the Transformer  to take the word-lattice as input and allow each character and word to have its own hidden representation. By taking into account relative positional information when calculating self-attention, our encoder can capture both global and local dependencies among tokens, providing an informative representation of source text for the decoder to make copy decisions.   Although our model is character-based , it can directly utilize word-level prior knowledge, such as keywords. In our setting, keywords refer to words in the source text that have a high probability of inclusion in the summary. Inspired by Gehrmann et al. , we adopt a separate word selector based on the large pre-trained language model, e.g. BERT  to extract keywords. When the decoder intends to copy words from the source text, those selected keywords will be treated as candidates, and other words will be masked out.  Experimental results show that our model can achieve better performance when incorporating with the word selector.      We propose a general framework for guided neural summarization, using which we investigate four types of guidance signals and achieve state-of-the-art performance on various popular datasets. We demonstrate the complementarity of the four guidance signals, and find that our models can generate more novel words and more faithful summaries. We also show that we can control the output by providing user-specified guidance signals.  Given the generality of our framework, this opens the possibility for several future research directions including 1) developing strategies to ensemble models under different guidance signals; 2) incorporating sophisticated techniques such as copy or coverage over the source document, the guidance signal, or both; and 3) experimenting with other kinds of guidance signals such as salient elementary discourse units.  
"," Copy mechanism allows sequence-to-sequence models to choose words from the input and put them directly into the output, which is finding increasing use in abstractive summarization. However, since there is no explicit delimiter in Chinese sentences, most existing models for Chinese abstractive summarization can only perform character copy, resulting in inefficient. To solve this problem, we propose a lexicon-constrained copying network that models multi-granularity in both encoder and decoder. On the source side, words and characters are aggregated into the same input memory using a Transformer-based encoder. On the target side, the decoder can copy either a character or a multi-character word at each time step, and the decoding process is guided by a word-enhanced search algorithm which facilitates the parallel computation and encourages the model to copy more words. Moreover, we adopt a word selector to integrate keyword information. Experiments results on a Chinese social media dataset show that our model can work standalone or with the word selector. Both forms can outperform previous character-based models and achieve competitive performances.",248
"  Humans are not supervised by the natural language inference . Supervision is necessary for applications in human-defined domains. For example, humans need the supervision of what is a noun before they do POS tagging, or what is a tiger in Wordnet before they classify an image of tiger in ImageNet. However, for NLI, people are able to entail that \textcircled{a} A man plays a piano contradicts \textcircled{b} A man plays the clarinet for his family without any supervision from the NLI labels. In this paper, we define such inference as a more general process of establishing associations and inferences between texts, rather than strictly classifying whether two sentences entail or contradict each other. Inspired by this, we raise the core problem in this paper: Given a pair of natural language sentences, can machines entail their relationship without any supervision from inference labels?   In his highly acclaimed paper, neuroscientist Moshe Bar claims that ``predictions rely on the existing scripts in memory, which are the result of real as well as of previously imagined experiences''. The exemplar theory argues that humans use {\bf similarity} to recognize different objects and make decisions.   Analogy helps humans understand a novel object by linking it to a similar representation existing in memory. Such linking is facilitated by the object itself and its context. Context information has been widely applied in self-supervision learning . Adapting context to NLI is even more straightforward. A simple idea of {\bf constant conjunction} is that A causes B if they are constantly conjoined. Although constant conjunction contradicts ``correlation is not causation'', modern neuroscience has confirmed that humans use it for reasoning in their mental world. For example, they found an increase in synaptic efficacy arises from a presynaptic cell's repeated and persistent stimulation of a postsynaptic cell in Hebbian theory. As to the natural language, the object and its context can be naturally used to determine the inference. For example, \textcircled{a} contradicts \textcircled{b} because they cannot happen simultaneously in the same {\bf context}.  The context representation learned by SSL  has already achieved big success in NLP. From the perspective of context, these models learn the sentence level contextual information  and the word level contextual information .  Besides linguistic contexts, humans also link other modalities  to novel inputs. Even if the goal is to reason about plain texts, other modalities still help . For example, if only textual information is used, it is difficult to entail the contradiction between \textcircled{a} and \textcircled{b}. We need the commonsense that a man only has two arms, which cannot play the piano and clarinet simultaneously. This commonsense is hard to obtain from the text. However, if we link the sentences to their visual scenes, the contradiction is much clearer because the two scenes cannot happen in the same visual context. We think it is necessary to incorporate other modalities for the unsupervised natural language inference.  The idea of adapting multimodal in SSL is not new.  According to, we briefly divide previous multimodal SSL approaches into two categories based on their encoder infrastructures. As shown in Fig., the first category uses one joint encoder to represent the multimodal inputs. Obviously, if the downstream task is only for plain text, we cannot extract the representation of text separately from the joint encoder. So the first category is infeasible for the natural language inference. The second category first encodes the text and the image separately by two encoders. Then it represents the multimodal information via a joint encoder over the lower layer encoders. This is shown in Fig.. Although the textual representation can be extracted from the text encoder in the lower layer, such representation does not go through the joint learning module and contains little visual knowledge. In summary, the encoders in previous multimodal SSL approaches are coupled. If only textual inputs are given, they cannot effectively incorporate visual knowledge in their representations. Thus their help for entailing the contradiction between \textcircled{a} and \textcircled{b} is limited.    In order to benefit from multimodal data in plain text inference, we propose the \underline{M}ultimodal \underline{A}ligned \underline{C}ontrastive \underline{D}ecoupled learning  network. This is shown in Fig.. Its text encoder is decoupled, which only takes the plain text as inputs. Thus it can be directly adapted to downstream NLI tasks. Besides, we use multimodal contrastive loss between the text encoder and the image encoder, thereby forcing the text representation to align with the corresponding image. Therefore even if the text encoder in MACD only takes the plain text as input, it still represents visual knowledge. In the downstream plain text inference tasks, without taking images as input, the text encoder of MACD still implicitly incorporating the visual knowledge learned by the multimodal contrastive loss. Note that we do not need a decoupled image encoder in the SSL. So the image encoder in Fig. in MACD takes texts as inputs to provides a more precise image encoder. We will elaborate this in section.      In this paper, we propose a novel lexicon-constrained copying network for Chinese summarization. Querying the multigranularity representation learned by our encoder, our decoder can copy either a character or a multi-character word at each time step. Experiments on the LCSTS dataset show that our model is superior to the Transformer baselines and quite competitive with the latest models. With the help of keyword information provide by the word selector, it can even achieve state-of-the-art performance. In the future, we plan to apply our model to other tasks, such as comment  generation, and to other languages, such as English.                      \hfill mds   \hfill August 26, 2015       An example of a floating figure using the graphicx package.   Note that \label must occur AFTER  \caption.   For figures, \caption should occur after the \includegraphics.   Note that IEEEtran v1.7 and later has special internal code that   is designed to preserve the operation of \label within \caption   even when the captionsoff option is in effect. However, because   of issues like this, it may be the safest practice to put all your   \label just after \caption rather than within \caption{}.     Reminder: the ""draftcls"" or ""draftclsnofoot"", not ""draft"", class   option should be used if it is desired that the figures are to be   displayed while in draft mode.        Note that the IEEE typically puts floats only at the top, even when this   results in a large percentage of a column being occupied by floats.     An example of a double column floating figure using two subfigures.      The subfigure \label commands are set within each subfloat command,   and the \label for the overall figure must come after \caption.   \hfil is used as a separator to get equal spacing.   Watch out that the combined width of all the subfigures on a   line do not exceed the text width or a line break will occur.         Note that often IEEE papers with subfigures do not employ subfigure   captions , but instead will   reference/describe all of them , , etc., within the main caption.   Be aware that for subfig.sty to generate the , , etc., subfigure   labels, the optional argument to \subfloat must be present. If a   subcaption is not desired, just leave its contents blank,   e.g., \subfloat[].     An example of a floating table. Note that, for IEEE style tables, the   \caption command should come BEFORE the table and, given that table   captions serve much like titles, are usually capitalized except for words   such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to   and up, which are usually not capitalized unless they are the first or   last word of the caption. Table text will default to \footnotesize as   the IEEE normally uses this smaller font for tables.   The \label must come after \caption as always.           Note that the IEEE does not put floats in the very first column   - or typically anywhere on the first page for that matter. Also,   in-text middle  positioning is typically not used, but it   is allowed and encouraged for Computer Society conferences . Most IEEE journals/conferences use   top floats exclusively.   Note that, LaTeX2e, unlike IEEE journals/conferences, places   footnotes above bottom floats. This can be corrected via the   \fnbelowfloat command of the stfloats package.  
","   We propose to solve the natural language inference problem without any supervision from the inference labels via task-agnostic multimodal pretraining. Although recent studies of multimodal self-supervised learning also represent the linguistic and visual context, their encoders for different modalities are coupled. Thus they cannot incorporate visual information when encoding plain text alone. In this paper, we propose \underline{M}ultimodal \underline{A}ligned \underline{C}ontrastive \underline{D}ecoupled learning  network. MACD forces the decoupled text encoder to represent the visual information via contrastive learning. Therefore, it embeds visual knowledge even for plain text inference. We conducted comprehensive experiments over plain text inference datasets . The unsupervised MACD even outperforms the fully-supervised BiLSTM and BiLSTM+ELMO on STS-B.",249
"  %閺鍙ラ嚋閸ユ拝绱濋弰顖氱秼閸撳秶娈戞径姘侀崹瀣劥缂冨弶鍎忛崘纰夌礉鐠侇厾绮屾稉娑擃亜銇囧Ο鈥崇烽敍灞藉晙閽傛悂顩撮崚鐧楁稉顏勭毈濡崇烽敍灞剧槨娑擃亜鐨Ο鈥崇烽崘宥呭礋閻欘剟鍣洪崠...  閹存垳婊戦惃鍕煙濞夋洩绱濈拋顓犵矊娑撴稉顏勩亣濡崇烽敍瀹杋netune鏉╂瑤閲滄径褎膩閸ㄥ鎮撻弮鍫曞倸绨睳娑擃亙绗夐崥灞剧箒鎼达妇娈戠亸蹇斈侀崹瀣剁礉閸欘亪娓剁电绻栨稉娑擃亝膩閸ㄥ绻樼悰宀勫櫤閸...   As neural machine translation models become heavier and heavier , we have to resort to model compress techniques  to deploy  smaller models in devices with limited resources, such as mobile phones. However, a practical challenge is that the hardware conditions of different devices vary greatly. To ensure the same calculation latency, customizing distinct model sizes  for different devices is necessary, which leads to huge model training and maintenance costs . For example, we need to distill the pre-trained large model into N individual small models.  %Then some model post-processing steps, such as model pruning  and quantization , are also performed independently for each small model.  The situation becomes worse for the industry when considering more translation directions and more frequent model iterations.  An ideal solution is to train a single model that can run in different model sizes. Such attempts have been explored in SlimNet  and LayerDrop . SlimNet allows running in four width configurations by joint training of these width networks, while LayerDrop can decode with any depth configuration by applying Dropout  on layers during training.      In this work, we take a further step along the line of flexible depth network like LayerDrop.  As shown in Figure, we first demonstrate that when there is a large gap between the predefined layer dropout during training and the actual pruning ratio during inference, LayerDrop's performance is poor.  %We attribute it to huge sub-network training space and mismatch between random sampling training and deterministic inference.  To solve this problem, we propose to use multi-task learning to train a flexible depth model by treating each supported depth configuration as a task. We reduce the supported depth space for the aggressive model compression rate and propose an effective deterministic sub-network assignment method to eliminate the mismatch between training and inference in LayerDrop. %Specifically, we design two metrics to determine which sub-network assignment is good.  Experimental results on deep Transformer  show that our approach can simultaneously support decoding in 24 depth configurations and is superior to the individual training and LayerDrop.       In this paper, we study the multimodal self-supervised learning for unsupervised NLI.  The major flaw of previous multimodal SSL methods is that they use a joint encoder for representing the cross-modal correlations. This prevents us from integrating visual knowledge into the text encoder. We propose the multimodal aligned contrastive decoupled learning , which learns to represent visual knowledge while using only texts as inputs. In the experiments, our proposed approach steadily surpassed other methods by a large margin.     
"," The standard neural machine translation model can only decode with the same depth configuration as training. Restricted by this feature, we have to deploy models of various sizes to maintain the same translation latency, because the hardware conditions on different terminal devices  may vary greatly. Such individual training leads to increased model maintenance costs and slower model iterations, especially for the industry. In this work, we propose to use multi-task learning to train a flexible depth model that can adapt to different depth configurations during inference. Experimental results show that our approach can simultaneously support decoding in 24 depth configurations and is superior to the individual training and another flexible depth model training method闁炽儲鏌￠幙鐜測erDrop.",250
"   Targeted sentiment analysis  involves jointly predicting entities which are the targets of an opinion, as well as the polarity expressed towards them . The TSA task, which is part of the larger set of fine-grained sentiment analysis tasks, can enable companies to provide better recommendations , as well as give digital humanities scholars a quantitative approach to identifying how sentiment and emotions develop in literature .  Although there have been many improvements to modelling TSA since the original CRF models , such as utilising Recurrent Neural Networks  , and treating the task as span prediction rather than a sequence labelling task , most of these have concentrated on making the best use of data annotated specifically for the task.  However, annotation for fine-grained sentiment is more taxing and tends to have lower inter-annotator agreement than document or sentence classification tasks . This leads to a lack of available high-quality training data, even for highly resourced languages and prevents TSA models from learning the complex, compositional phenomena which are necessary to correctly predict targeted sentiment in an end-to-end fashion.   We believe this lack of data for fine-grained sentiment analysis leads to TSA models that cannot learn effectively complex compositional phenomena that exists in language, thus making TSA models fragile to highly compositional language. It has also been shown that incorporating compositional information from negation or speculation detection improves sentence-level sentiment classification . Other supervised tasks, such as semantic role labelling , or document level sentiment analysis  have shown promise for improving fine-grained sentiment analysis. Further transfer learning from a self-supervised language-modelling task, commonly referred to as contextualised word representations , has also shown to greatly benefit fine-grained sentiment analysis . Based on this, in this paper, we wish to explore two research questions:      To this end, we propose a multi-task learning  approach to incorporate sources of negation and speculation information into a neural targeted sentiment classifier. We additionally compare our approach with MTL models that use part-of-speech tagging, dependency relation prediction, and lexical analysis as auxiliary tasks, following previous work . Furthermore, in order to overcome the lack of evaluative resources to investigate the effects of negation and speculation, we annotate two new challenge datasets which contain difficult negated and speculative examples.     We find that the MTL models are more robust than the single task learning ,  performing competitively on the majority of the standard datasets while significantly outperforming the STL models on the negation challenge datasets, and on average better than STL models on the speculation challenge datasets. Moreover, we show that when transfer learning is applied, using CWR, to both MTL and STL models, MTL models are no longer significantly better, but are still better on average for the negation challenge dataset and one of the speculation challenge datasets. This result suggests that transfer learning does incorporate some compositional information that is required for negated and speculative samples. However all results on the challenge datasets are considerably lower than the standard dataset, showing that more work is needed to make these models more robust to compositional language.     The contributions of the paper are the following:       We demonstrated LayerDrop is not suitable for FDM training because of  the huge sub-network space in training and  the mismatch between training and inference. Then we proposed to use multi-task learning to mitigate it. Experimental results show that our approach can decode with up to 24 depth configurations and obtain comparable or better performance than individual training and LayerDrop. In the future, we plan to explore more effective FDM training methods, and combining flexible depth and width is also one of the attractive directions.   
","   The majority of work in targeted sentiment analysis has concentrated on finding better methods to improve the overall results. Within this paper we show that these models are not robust to linguistic phenomena, specifically negation and speculation. In this paper, we propose a multi-task learning method to incorporate information from syntactic and semantic auxiliary tasks, including negation and speculation scope detection, to create models that are more robust to these phenomena. Further we create two challenge datasets to evaluate model performance on negated and speculative samples. We find that multi-task models and transfer learning from a language model can improve performance on these challenge datasets. However the results indicate that there is still much room for improvement in making our models more robust to linguistic phenomena such as negation and speculation.",251
"  % making new tools useless if noone uses them efficiently The consensus that human activity caused the climate crisis  has led to the development of many tools and possible policy interventions, designed to minimize greenhouse gas emissions or mitigate negative impacts of climate change.  However, even the most promising tools to counter the climate crisis are futile, if they are not used. All important research efforts to mitigate the climate crisis are lost without an efficient international adaptation of tools and policies.  %promises of politicans don't lead to action  Strategies have to be adopted at a national level, following international cooperative guidelines such as the Sustainable Development Goals  or the Kyoto protocol . However, scientists, non-state actors\footnote{https://www.euronews.com/living/2018/12/21/ngos-sue-french-government-over-insufficient-climate-change-action}, and voters increasingly critique their government for insufficient action mitigating climate change . This suggests a gap between promises made by politicians and actual action taken: somewhere along the way ambitious promises for climate change mitigation have turned into careless discourse with insufficient measures taken.  %accountability shown to  prevent mismanagement Holding politicians accountable for their actions has been shown to be a major factor in preventing mismanagement, political corruption and misalignment of politician閳ユ獨 opinions and the public they are representing . %so we are working on improving the accountability to use existing tools Our work aims to provide the general public with a metric to assess if a candidate or a party is using their platform to discuss the topics related to climate change.   % the overall system In Section  we introduce a Multi-Source Topic Aggregation System  which increases transparency by providing an overview of topics discussed by politicians.  The large amount of publicly available documents are made transparent through the MuSTAS topic overview, which would otherwise be unattainable for the general public due to the amount of data. Through this transparency, decision-makers can be held accountable for their promises and claims by the general public, accelerating policies and the societal changes needed to mitigate and adapt to climate change.   %Using a the large amount of publicly available data are processed to asses how a politician uses their influence across channels and timelines.  % The research on multi-source LDA builds the scientific foundation In Section  we describe a novel multi-source hybrid latent Dirichlet allocation model which builds the scientific foundation for MuSTAS and forms the core of this research proposal. In Section  we outline how MuSTAS impacts climate change. % climate change impact  % Here be short paragraph about the structure of this proposal and the roles: MuSTAS is the larger scope, and topic modelling with multi-source hybrid LDA is the focus of research.  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    In this paper, we have compared the effects of MTL using various auxiliary tasks for TSA and have created a negation and speculation annotated challenge dataset\footnote{Dataset can be found at } for TSA in order to isolate the effects of MTL. We show that TSA methods are drastically affected by negation and speculation effects in the data. These speculation  effects can be  reduced by incorporating speculation  information into the model through MTL. The negation and speculation effects can also be reduced through transfer learning via CWR. Additionally, MTL of negation can still improve the CWR models themselves but not significantly. These findings answer the two original research questions. Whereby we have found that in general MTL using negation  as an auxiliary task does make TSA models more robust to negated  samples. Additionally that transfer learning must have to some extent learnt some compositional knowledge that is useful for classifying negated and speculative samples, leading to more robust TSA models. Lastly that using more general syntactic information as an auxiliary task within MTL creates models that are more robust to both negation and speculation. However the results presented here show how sensitive current models are to linguistic phenomena and suggest that there is still much room for improvement.     As the results from the standard datasets found using MTL does not always improve performance and results from \Fi on Laptop Table  showed that transfer learning can harm performance\footnote{Compare the performance of MTL  using GloVe  to when it uses CWR .}. Additionally the results from the challenge datasets showed that different auxiliary tasks improved the performance of different subtasks of TSA through the extraction and sentiment classification metrics. This may suggest that the target extraction and sentiment classification tasks should not be treated as a collapsed labelling task, as the sentiment and extraction tasks are not similar enough . Future work should consider using a pipeline approach, where each subtask is paired with the most beneficial auxiliary tasks, whereby this approach could lead to MTL and transfer learning better complimenting each other. Finally, we release the code\footnote{}, dataset, and trained models associated with this paper, hyperparameter search details with compute infrastructure , number of parameters and runtime details , and further detailed dev and test results , in line with the result checklist from .           
","     Decades of research on climate have provided a consensus that human activity has changed the climate and we are currently heading into a climate crisis.     Many tools and methods, some of which utilize machine learning, have been developed to monitor, evaluate, and predict the changing climate and its effects on societies.      However, the mere existence of tools and increased awareness have not led to swift action to reduce emissions and mitigate climate change.     Politicians and other policy makers lack the initiative to move from talking about the climate to concrete climate action. % in an appropriate schedule allowing for mitigation of the potentially catastrophic changes.      In this work, we contribute to the efforts of holding decision makers accountable by describing a system which digests politicians' speeches and statements into a topic summary.     We propose a multi-source hybrid latent Dirichlet allocation model which can process the large number of publicly available reports, social media posts, speeches, and other documents of Finnish politicians, providing transparency and accountability towards the general public.",252
"  In recent years, the effectiveness of utilizing image data in tandem with a text corpus to improve the quality of machine translation has been a source of extensive investigation. Several proposals have been made to incorporate visual data, such as using a doubly-attentive decoder for image and text data , initializing the encoder or decoder hidden state with image features , and using a deliberation network approach to refine translations using image data . However, a common difficulty is the lack of publicly available multimodal corpora, particularly for English-Japanese translation tasks. Currently, two of the only available English-Japanese multimodal datasets are the Japanese extension of the Pascal sentences  and Flickr30k Entities JP , which is a Japanese translation of the Flickr30k Entities dataset .    In order to contribute to the current list of English-Japanese multimodal corpora, we propose a new multimodal English-Japanese corpus with comparable sentences. Comparable sentences are sentences that contain bilingual terms and parallel phrases that describe a similar topic, but are not direct translations . This data is of particular interest due to its natural prevalence across various areas of media. For example, e-commerce sites in different countries may have product descriptions for similar products in different languages, or social media users may comment about images in several different languages.    In this study, we created a large comparable training corpus by compiling the existing image captions from the MS-COCO  and STAIR  captioning datasets.  %By compiling the existing image captions from the MS-COCO  and STAIR  captioning datasets, we were able to create a large comparable training corpus that did not require translation.  Furthermore, for validation and testing purposes, we translated a small subset of MS-COCO captions that contain ambiguous verbs. The advantage of comparable sentences in relation to their available quantity can be clearly seen in Table , with our proposed corpus containing almost twice as many sentence pairs as Flickr30k Entities JP, the current largest parallel multimodal English-Japanese corpus.  As a benchmark of current multimodal NMT models on our corpus, we performed an English-Japanese translation experiment using several baseline models, which confirmed that current NMT models are not well suited to a comparable translation task. %o evaluate our proposed corpus, we performed an English-Japanese translation experiment on several baseline models, which confirmed that current NMT models are not well suited to a comparable translation task. However, we believe that our corpus can be used to facilitate research into creating multimodal NMT models that can better utilize comparable sentences.  % % The following footnote without marker is needed for the camera-ready % version of the paper. % Comment out the instructions  and uncomment the 8 lines % under ""final paper"" for your variant of English. %  .     %     % % final paper: en-uk version      %     %   % space normally used by the marker     % This work is licensed under a Creative Commons      % Attribution 4.0 International Licence.     % Licence details:     % \url{http://creativecommons.org/licenses/by/4.0/}.     %      % % final paper: en-us version      %     %   % space normally used by the marker     % This work is licensed under a Creative Commons      % Attribution 4.0 International License.     % License details:     % \url{http://creativecommons.org/licenses/by/4.0/}. } \newcommand\T{\rule{0pt}{2.6ex}}   \newcommand\B{\rule[-1.5ex]{0pt}{0pt}} \newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash}m{#1}} \newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash}m{#1}} \newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash}m{#1}}        \end{table}     In this paper, we propose a multi-adversarial learning method for cross-lingual word embeddings. Our system learns different linear mappings for different source subspaces instead of just learning a single one for the whole source space. The results of our experiments on bilingual lexicon induction on both close languages and the difficult case of typologically-distant languages prove that learning cross-lingual word embeddings with multi-mapping improves the performance over single mapping.        
"," Multimodal neural machine translation  has become an increasingly important area of research over the years because additional modalities, such as image data, can provide more context to textual data. Furthermore, the viability of training multimodal NMT models without a large parallel corpus continues to be investigated due to low availability of parallel sentences with images, particularly for English-Japanese data. However, this void can be filled with comparable sentences that contain bilingual terms and parallel phrases, which are naturally created through media such as social network posts and e-commerce product descriptions. In this paper, we propose a new multimodal English-Japanese corpus with comparable sentences that are compiled from existing image captioning datasets. In addition, we supplement our comparable sentences with a smaller parallel corpus for validation and test purposes. To test the performance of this comparable sentence translation scenario, we train several baseline NMT models with our comparable corpus and evaluate their English-Japanese translation performance. Due to low translation scores in our baseline experiments, we believe that current multimodal NMT models are not designed to effectively utilize comparable sentence data. Despite this, we hope for our corpus to be used to further research into multimodal NMT with comparable sentences.",253
"  %\todo[inline]{Why predicting hate-speech is important in general?}  %\todo[inline]{why detecting hate-speech is important in Yahoo news and Yahoo finance?}   %  %What is the problem? %Why is it interesting and important? %Why is it hard?  %Why hasn't it been solved before?  %What are the key components of my approach and results? Also include any specific limitations.  %Hatespeech is speech that ``intended to insult, offend, or intimidate a person because of some trait "". The occurrence of hatespeech has been increasing. It has become easier than before to reach a large audience quickly via social media, causing an increase of the temptation for inappropriate behaviors such as hatespeech, and potential damage to social systems. In particular, hatespeech interferes with civil discourse and turns good people away. Furthermore, hatespeech in the virtual world can lead to physical violence against certain groups in the real world\footnote{https://www.nytimes.com/2018/10/31/opinion/caravan-hate-speech-bowers-sayoc.html}\footnote{https://www.washingtonpost.com/nation/2018/11/30/how-online-hate-speech-is-fueling-real-life-violence}, so it should not be ignored on the ground of freedom of speech.  To detect hatespeech, researchers developed human-crafted feature-based classifiers , and proposed deep neural network architectures . %Online service providers also strive to combat the hatespeech through ranking algorithms, filtering, and suspending or deactivating user accounts. \textcolor{red}{However, blah blah blah}. However, they might not explore all possible important features for hatespeech detection, ignored pre-trained language model understanding, or proposed uni-directional language models by reading from left to right or right to left.   %--> 2. Other deep model for hatespeech detection: either didn't understand fully hateful context , or  ignore pretrained language model understanding and/or uni-directionally understanding language models by reading from left to right or right to left .  Recently, the BERT  model  has achieved tremendous success in Natural Language Processing % . The key innovation of BERT is in applying the transformer to language modeling tasks. %It proposed to do language modeling through two tasks: predicting masked words and predicting the next sentence. A BERT model pre-trained on these language modeling tasks forms a good basis for further fine-tuning on supervised tasks such as machine translation and question answering, etc.  Recent work on hatespeech detection  has applied the BERT model and has shown its prominent results over previous hatespeech classifiers. However, we point out its two limitations in hatespeech detection domain. First, the previous studies  have shown that a hateful corpus owns distinguished linguistic/semantic characteristics compared to a non-hateful corpus. For instance, hatespeech sequences are often informal or even intentionally mis-spelled, so words in hateful sequences can sit in a long tail when ranking their uniqueness, and a comment can be hateful or non-hateful using the same words .  %For example, ``n1gger'' in the sentence ``i am not a `n1gger' as you have indicated'' is non-hateful, but ``n1gger'' in ``you all are such a n1gger!'' is hateful.  For example, ``dick'' in the sentence ``Nobody knew dick about what that meant'' is non-hateful, but ``d1ck'' in ``You are a weak small-d1cked keyboard warrior'' is hateful \footnote{It is important to note that this paper contains hate speech examples, which may be offensive to some readers. They do not represent the views of the authors. We tried to make a balance between showing less number of hate speech examples and illustrating the challenges in real-world applications.}.  Thus, to better understand hateful vocabularies and contexts, it is better to pre-train on a mixture of both hateful and non-hateful corpora. Doing so helps to overcome the limitation of using BERT models pre-trained on non-hateful corpora like English Wikipedia and BookCorpus. Second, even the smallest pre-trained BERT ``base'' model contains 110M parameters. It takes a lot of computational resources to pre-train, fine-tune, and serve.  %There have been recent efforts reducing  Some recent efforts aim to reduce  the complexity of BERT model with the knowledge distillation technique such as DistillBert  and TinyBert . In these methods, a pre-trained BERT-alike model is used as a teacher model, and a student  model  is trained to produce similar output to that of the teacher model. Unfortunately, while their complexity is reduced, the performance is also degraded in NLP tasks compared to BERT. Another direction is to use cross-layer parameter sharing, such as ALBERT . However, ALBERT's computational time is similar to BERT, since the number of layers remains the same as BERT; likewise, its inference is equally expensive.  Based on the above observation and analysis, we aim to investigate whether it is possible to achieve a better hatespeech prediction performance than state-of-the-art machine learning classifiers, including classifiers based on publicly available BERT model, while significantly reducing the number of parameters compared with the BERT model. By doing so, we believe that performing pre-training tasks from the ground up and on a hatespeech-related corpus would allow the model to understand hatespeech patterns better and enhance the predictive results. However, while language model pretraining tasks require a large scale corpus size, available hatespeech datasets are normally small: only 16K115K annotated comments . Thus, we introduce a large annotated hatespeech dataset with 1.4M comments extracted from Yahoo News and Yahoo Finance. To reduce the complexity, we reduce the number of layers and hidden size, and propose Quaternion-based Factorization mechanisms in BERT architecture. To further improve the model effectiveness and robustness, we introduce a multi-source ensemble-head fine-tuning architecture, as well as a target-based adversarial training.  %Internet platforms can  moderate user-generated content in the interest of the majority of their users, and the business needs. Through ranking algorithms, filtering, suspending or deactivating user accounts, many Internet companies strive to combat hatespeech. %Twitter, for example, has ""the twitter rules"", which states that ``Violence, harassment and other similar types of behavior discourage people from expressing themselves, and ultimately diminish the value of global public conversation."".  %To ensure that users have a positive experience on its properties, Verizon Media also has clear rules against hatespeech. %, which state that ``Don't use hatespeech. Hatespeech directly attacks a person or group on the basis of race, ethnicity, national origin, religion, disability, disease, age, sexual orientation, gender, or gender identity. As noted above, we're a diverse global community of many types of people, with different beliefs, opinions, sensitivities, and comfort levels. If you don't feel that you can abide by our Community Guidelines as outlined below, maybe participating in the Oath community isn't for you."" %At Verizon Media, the Standard Moderation Platform  runs a platform service to moderate text, URL, images and videos. The hatespeech classifiers in SMP are based on  a number of past research work, including.   % The purpose of the work described in this paper is to improve the performance of the current state of the art for hatespeech classifiers. In a previous study, % we used a pretrained BERT  model as a starting point for fine tuning. % %, we investigated a range of different machine learning models for text classification. % %We show that a combination of a linear model, and % We found that the BERT architecture gives better performance than most baseline models, including. %, as well as Google's Prospective API. In that study, a pretrained BERT model is used as a starting point for fine tuning.  %Recently, the BERT  model has become a state-of-the-art language model and has achieved tremendous success in Natural Language Processing . %\todo[inline]{talking about BERT and its success in variety of nlp tasks with some cited works} %BERT is a modified transformer network architecture. Traditionally, many language tasks such as translation or question answering, are handled using recurrent neural networks, combined with the attention mechanism. This %reflects the fact that we tend to read a sentence from left to right. However, human also read words within context of other words, %some of them could be quite far apart, %instead of only from left to right or right to left in a mechanical way. Furthermore, recurrent network has a memory problem and can not handle long text, due to problems with vanishing or exploding gradient. In addition, it is intrinsically sequential, making the training process slow. Transformer network was proposed to solve these problems. In its setup, each word in the input text has visibility of all other words, through the use of multi-headed attention.   %It has been used %in a variety of NLP tasks as well as in other area such as image processing.     %One of the motivation of this paper is to investigate whether it is possible to achieve performance similar to, or better than the publicly available BERT models, but with smaller models. In doing so, we want to realize considerable saving in training and serving time. Another motivation is to see if it is possible to improve the BERT model further, by introducing changes to the model architecture. The third motivation is the following. The pretrained BERT models are based on % BooksCorpus and English Wikipedia. They have very different characteristics from the dataset of interest to us, which consists of users-generated comments in Yahoo News and Yahoo Finance. Consequently we believe that retraining a language model from scratch % should give us a model that understands % the language of our dataset better.  %\todo[inline]{talking about the limitation of BERT, like it is to complicated and heavy or has too many parameters. Then question is to build a better model, but with less number of parameters?}  The major contributions of our work are: \squishlist % \squishend  % We organize the paper as followed. % We give related work in Section, and % define the problem we are solving formerly in Section. We present our approach in Section, and show experimental results in Section. We conclude our paper in Section with discussions and future work.  %   In this paper, we have proposed a new multimodal English-Japanese corpus with comparable sentences. Based on the baseline performance of this data, we believe that current multimodal NMT models are not well suited to this type of task, and further research is required in order to better leverage the comparable sentences and images together in order to improve translation performance. In the future, we hope to see our corpus used to encourage research into multimodal machine translation tasks with comparable sentences instead of parallel sentences.   
"," We present our {HABERTOR} model for detecting hatespeech in large scale user-generated content. Inspired by the recent success of the BERT model, we propose several modifications to BERT to enhance the performance on the downstream hatespeech classification task. {HABERTOR} inherits BERT's architecture, but is different in four aspects:  it generates its own vocabularies and is pre-trained from the scratch using the largest scale hatespeech dataset;  it consists of Quaternion-based factorized components, resulting in a much smaller number of parameters, faster training and inferencing, as well as less memory usage;  it uses our proposed multi-source ensemble heads with a pooling layer for separate input sources, to further enhance its effectiveness; and  it uses a regularized adversarial training with our proposed fine-grained and adaptive noise magnitude to enhance its robustness. Through experiments on the large-scale real-world hatespeech dataset with 1.4M annotated comments, we show that {HABERTOR} works better than 15 state-of-the-art hatespeech detection methods, including fine-tuning Language Models. In particular, comparing with BERT, our {HABERTOR} is 4$\sim$5 times faster in the training/inferencing phase, uses less than 1/3 of the memory, and has better performance, even though we pre-train it by using less than 1\% of the number of words. Our generalizability analysis shows that {HABERTOR} transfers well to other unseen hatespeech datasets and is a more efficient and effective alternative to BERT for the hatespeech classification.  %The code and the pretrained models are available at anonymized.",254
"   %------------------Previous version------------------ %Since UNMT in low-resource domains is not yet an actively explored field, one may naively approach this problem by training a model on multiple domains and expect it to generalize on the unseen, low-resource domains, e.g., training the model on news and sports domains and evaluating on the biomedical domain. %However, due to domain mismatch, studied on supervised NMT, the model can show inferior performance. %------------------------------------------------------- Unsupervised neural machine translation  leverages unpaired monolingual corpora for its training, without requiring an already labeled, parallel corpus. Recently, the state of the art in UNMT has achieved comparable performances against supervised machine translation approaches. However, in the case of the translation of domain-specific documents, the monolingual data themselves are scarce, and collecting them involves high cost, still suffering from low NMT performance. For instance, a model trained with monolingual data in such a low-resource domain, say, the medical domain, can experience degraded translation quality due to overfitting.  %------------------Previous version------------------ %Another reasonable approach is transfer learning, which has been frequently used for domain adaption in the literature of supervised NMT and often showed improvements in the target domain. The model is pretrained with multiple domains and then finetuned with the new domain. However, this approach may suffer from overfitting  and catastrophic forgetting when given a small number of training data and a large domain gap in a downstream task. %-------------------------------------------------- Yet, UNMT for low-resource domains is not an actively explored field. One naive approach is to train a model on high-resource domains  while hoping it to generalize on an unseen low-resource domain  as well. However, it has been shown from recent studies on supervised NMT that a nontrivial domain mismatch can significantly cause low translation accuracy.  Another reasonable approach is transfer learning, or in particular domain adaptation, which has shown  performance improvements in the literature of supervised NMT. In this approach, the model is first pretrained using existing domains and then finetuned using the data in a new domain. However, this approach may suffer from overfitting and catastrophic forgetting due to a small number of training data and a large domain gap.  As an effective method for handling a small number of training data, meta-learning has shown its superiority in various NLP tasks, such as dialog generation, translation, and natural language understanding. However, to the best of our knowledge, it was not applied to tackle the UNMT tasks with a small number of training data, i.e., low-resource UNMT.   In response, this paper extends meta-learning approach for low-resource UNMT, called \toolnameMeta. The objective of \toolnameMeta is to find the optimal initialization for model parameters that can quickly adapt to a new domain even with only a small amount of monolingual data. To be specific, assuming that data from multiple source domains are available, which makes meta-learning applicable, we first pretrain the UNMT model with source domains based on \toolnameMeta and then finetune the model  using a target domain.   Moreover, we propose an improved meta-learning approach called \ourtoolname for low-resource UNMT by explicitly promoting common knowledge across multiple domains as well as generalizable knowledge from a particular domain to another. In particular, our proposed approach prevents the model from overfitting due to a small amount of training data in a new domain.   In summary, our contributions include the following.    %\item \ourtoolname shows that it has domain-general knowledge and is faster in convergence than all the other methods. %\item We empirically demonstrate that our enhanced algorithm, \ourtoolname, consequently boosts up the performance of low-resource UNMT against other baseline models including \toolnameMeta.  %\item We extend the meta-learning algorithm by incorporating the domain mixing loss, and it outperforms all the other methods. % %We show zero-shot performance to evaluate generalization ability for \ourtoolname, where \ourtoolname outperforms other methods.  % To the best of our knowledge, our work is the first to apply a meta-learning approach to UNMT tasks. Our proposed algorithms can quickly adapt to in-domain with only a few iteration steps. Both \toolnameMeta and \ourtoolname consistently outperform the baseline models up to 3 BLEU scores. Especially, \ourtoolname achieves promising results among others including \toolnameMeta. Besides, we show zero-shot performance to evaluate generalization ability for \ourtoolname, where \ourtoolname outperforms other methods.  %--------------------------------- % 闋冩﹥顫呮 姘╁牗妫撮瀽鎰冲妧闆 闇冨嫴饪洪灇 闈镐緛纾ら瀽鍡㈡緤 鐡垮婀㈣嚙 闇呮﹤濮 general 闋 feature闇屻倢婢 闉涘牕瀚.  % Although each domain is very distance each others in domain adaptation, they share some linguistic features, such as the grammar and basic words.     % Azam: To alleviate the aforementioned challenge, % Azam: To overcome this issue, many %   % \item  % \item 闉栧崐螠闉 contribtuion bullet point鎼 summary : % \item 1. formulate new task  % \item 2. New frame work proposed % \item 3. evaluate various domain. show fast adaptation and quality. %On the other hand, since unsupervised machine translation has attained comparable performance against supervised machine translation, fully unsupervised domain adaptation, which uses only monolingual data for both in-domain and out-of-domain, is more suitable to handle data-scarce languages. %yet has a challenge for data-scarce domains. In other words, an unsupervised domain adaptation task can handle data-scarce languages; however, it cannot resolve a challenge for low-resource domains. % %such that it alleviates the aforementioned challenge, building a parallel corpus. %Therefore, a fully unsupervised domain adaptation task, consisted of unpaired language corpus for both in-domain and out-of-domain, is more realistic setting than a supervised domain adaptation task.%and substantial effort to collect domain specific data. %A meta-learning algorithm is superior for low-resource data. Unlike domain adaptation, a meta-learning algorithm does not require in-domain data to learn initial parameters. It only asks few training samples to meta-train  the model. Collaborating a meta-learning algorithm with unsupervised machine translation    %Since we leverage cross-lingual language model pretraining  which allows the model to learn cross-lingual representations, our gradient updates are divided into two objective functions, back-translation and language modeling. % Several approaches have been proposed to resolve the scarcity problem. For instance, a data mixing can be one approach that aggregates high-resource and low-resource data and train the model to adequately translate the low-resource target language   % To overcome the data scarcity problem, one simple approach is a data mixing that aggregates high-resource and low-resource data and train the model to adequately translate the low-resource target language. The other approach is a transfer learning that first pretrains on high-resource data and fine-tunes the low-resource data. Although these aforementioned approaches explicitly tackle the low-resource challenge, the scarcity problem still remains in NMT because building parallel corpus with specialized expertise is costly expensive.   % In this paper, we leverage recent success of unsupervised NMT  that uses only monolingual corpus. Inspired by , we propose new task called low-resource UNMT. To the best of our knowledge, this is a first attempt    % To overcome this issue, unsupervised learning in NMT has been proposed to resolve the parallel data scarcity problem. However, this approach has a constraint that abundant monolingual corpus should be always available.   % In reality, monolingual corpus can be also scarce if the domains or languages are often used. %鑶﹂浛 闉涙劤鍔爩 闉氭尗婀 闈广倠鐛  % Although various approaches have been proposed to address a low-resource challenge , none of the works consider a low-resource unsupervised task in NMT. To the best of our knowledge, this is first the attempt which explicitly tackles the low-resource UNMT task.  % In this paper,    % When we translate a word to the different language, the semantic meaning can be changed. For instance, the meaning of word ""CNN"" is different in the domain of deep learning and news     % To overcome this issue, the abundant parallel data are required which are not easy to obtain. Recently, unsupervised NMT  studies show reasonable performance comparison to supervised NMT.     % Data mixing with high-resource and low-resource is one approach to handle the following issue. The other approach is a transferring learning method that first trains on high-resource datasets and fine-tunes on a low-resource datatset. However, the problem can still remain if the parallel data is scarce in domains or languages. To overcome the parallel data scarcity problem    % To overcome this issue, unsupervised learning in NMT has been proposed to resolve the the problem of insufficient parallel data. However, this approach assumes that obtaining monolingual corpus is always easier than acquiring parallel corpus. Since the languages can vary by domains , either monolingual or parallel data can be scarce.  % utilize monolingual corpus which assume that monolingual corpus are always available. However,     % In NMT, the data scarcity problem can be divided into two different training data scenarios, insufficient training parallel data and training data itself . To overcome the scarce parallel data issue, recent studies proposed to utilize monolingual corpus.    % the parallel data is essential to train the NMT model    % several learning methods, such as unsupervised learning and transfer learning in NMT, are proposed to overcome the data scarcity problem. However, those works only consider in languages which still remains the problem in domains . Moreover, to the best of our knowledge, none of the works attempt to  %Learning is an inevitable phase when we adapt to a new task. However, various learning experiences can reduce the exertion of learning a new task.         %   %Domains can be  %To overcome this issue, one simple approach is a domain mixing that aggregates high-resource and low-resource domains and train the model to adequately translate the low-resource domain. The other approach is a transfer learning that first pretrains on high-resource domains and fine-tunes the low-resource domain.  %Despite the remarkable success on neural machine translation ~, the performance of NMT drops substantially against traditional statistical machine translation  when the training data is scarce  %To overcome the scarcity of training data in languages, variants of multilingual translation approaches have been proposed. These approaches basically exploit high-resource knowledge by aggregating both high-resource and low-resource data to train one single model. The other approach is utilizing transfer learning that the model first pretrains on high-resource data and later fine-tunes on low-resource data. The similar manner follows for the domains as well.  %Moreover, few-shot learning and meta-learning arise in machine learning where both attempt to handle the data scarcity problem. In NMT, ~\citet{gu2018meta} re-formulates the model-agnostic meta-learning  algorithm to resolve the low-resource challenge for NMT.  %Although aforementioned approaches tackle the low-resource challenge, the data scarcity problem can still remain because following approaches require parallel data, and building a low-resource language pair  with specialized expertise is costly expensive. Hence, the recent research suggests to rely only on monolingual corpus instead of using parallel corpus. The various unsupervised NMT ~ studies show the reasonable performance comparison to supervised NMT. % 闋冩﹥顫呮 monolingual corpus 姣靛牗鐖涢渻 闆垮姙婢婇煰 鐡寸粖鏅爢鍕冲剨闉 闉氭鏌庨洰鐘惧灛闉涘牗娼 -鏀磋兂鏌涢瀼鎸 鏀撮附寮版皡鏃嶆緫闉 闉濅緟娼夐澗姗冪抽浖..?  %sufficient in-domain data to train the model; however, in real-world, collecting domain specific data requires substantial effort. %building a low-resource language pair  with specialized expertise is costly expensive  % 鏂撴粔鑺 闇屻倢鏌 MT闉 姘氭粚鐖犻灇 闈奉剢鐎 姘╁牗妫撮澗姗冾槬鏃矅顫 闇冨嫴瀚 闋冩﹥姒鹃灇 . % Machine learning 闉愭劤鍔闉 Data scarcity 姘嶈兂鐗 闉濇粔璧 % Domain translation闉 闉 娆锋埄娈ч爟婊岊潊  % unsuperivsed machine translation % data mixing, transfer learning % knowledge gets partially vanished  % 闆垮姙婢婇煰 鐡寸粖鏅 % 闋冩悡鑸堕爟姗佽荡闉欏嫶鏆ｉ澒 transfer learning mixing data 鑷ф瑬娼 姘氣晣鐭 闈奉剣姣 % 闋冩﹥顫呮 parallel setting 闉愭劤鍔 闉濅緟姣勯爟 % parallel 闆垮姙婢婇煰鐡ｇ殰 闈炬﹥顫栭爟姗佽荡鑷 闋屾﹤鎽 % monolingual corpus姣 闈奉剣姣勯爟姗傚 UNMT work闇屻倢婢 闈告繉绠 % unsupervised 闈瑰姜濮ら灇 鏂撴粔鑺抽湆銈屾煄 姣靛韩婢 闆存帥鏅炴瓎 % 闋冩﹥顫呮 monolingual corpus 姣靛牗鐖涢渻 闆垮姙婢婇煰 鐡寸粖鏅爢鍕冲剨闉 闉氭鏌庨洰鐘惧灛闉涘牗娼 -鏀磋兂鏌涢瀼鎸 鏀撮附寮版皡鏃嶆緫闉 闉濅緟娼夐澗姗冪抽浖..? % 鏀撮附螠闋冩﹥妫 闉栧崐螠闆 low-resource UNMT姣 meta-learning algorithm闉欒導顢 闊块附濮 姘氣晥鏅ラ灇 闉濇粚瀚 % 鏃姙銆 meta-nmt 闆茶導顑撶摽鑼у 闆笺倠顩 闉氭尗婀㈤浕 闉栧崐螠鏃拌導濮 unsupervised闉 %  multi doamin 鑷ф洢鈥 %       Though as an important issue, long sequence translation used to be regarded as a hard problem that sequence-to-sequence methods in neural style can not handle. However, in this paper, we prove the feasibility of end to end training in this field. Firstly, the basic experiments show that direct document-level translation with a large scale dataset has comparable performance compared with merged sentences generated by sentence unit model. One step forward, with widely available large scale sentence-level parallel data and almost infinite document-level monolingual data that can be used in back-translation, the potential of document-level translation can be activated. In other words, we propose a training criteria in document translation which can break the length bottleneck of sentence-level translation model. The observation may shed important light on extremely long sentence generation and make us rethink the routine of the long sequence machine translation. Finally, our dataset proposed in this paper contributes greatly as a boost in this field.     In this paper, we review main challenges unsolved in document-level neural machine translation, including datasets, metrics, context usage, and restricted training. After pointing out the under-explored status of this field, we attempt to refine the groundwork. A package of datasets, along with a new training paradigm for DNMT is proposed to push the limitation in this field. We hope our work can advance the research works and inspire correlative long-range sequence generation.     In this paper, we review the recent studies of document-level NMT and find them sort of misguided. Most works focus on appending more model modules as model regularization, which turns out to be oversold. Instead, we suggest heading back to the original but concise way of Doc2Doc to deal with DNMT. With our multi-resolutional training strategy, Doc2Doc yields the best results and show significant superiority over Doc2Sent. We also make a further step to reveal that the bottleneck in this field lies in datasets and metrics. Correspondingly, we propose a package of datasets along with metrics to boost the development of DNMT. We hope the analytical review and contributive datasets can be thought-provoking and inspire more works.  In this paper, we propose the literal document-to-document  translation and successfully activate it with multi-resolutional training. Different from traditional methods of modifying the model architectures, our approach introduces no extra parameters. A comprehensive set of experiments on various metrics show the advantage of MR Doc2Doc. In addition, we contribute a new document-level dataset as well as three new metrics to the community. 
"," Unsupervised machine translation, which utilizes unpaired monolingual corpora as training data, has achieved comparable performance against supervised machine translation. However, it still suffers from data-scarce domains. To address this issue, this paper presents a meta-learning algorithm for unsupervised neural machine translation  that trains the model to adapt to another domain by utilizing only a small amount of training data. We assume that domain-general knowledge is a significant factor in handling data-scarce domains. Hence, we extend the meta-learning algorithm, which utilizes knowledge learned from high-resource domains to boost the performance of low-resource UNMT. Our model surpasses a transfer learning-based approach by up to 2-4 BLEU scores. Extensive experimental results show that our proposed algorithm is pertinent for fast adaptation and consistently outperforms other baseline models.",255
" Numerous entities are emerging everyday. The attributes of the entities are often noisy or incomplete, even missing.  In the field of electronic commerce, target attributes  of new products are often missing .  In medical analysis, attributes like transmission, genetics and origins of a novel virus are often unknown to people.  Even in DBpedia, a well-constructed and large-scale knowledge base extracted from Wikipedia, half of the entities contain less than 5 relationships .  %In KG construction area, KGs often suffer from incompleteness.  %For example, in DBpedia, a well-constructed and large-scale knowledge base extracted from Wikipedia, half of the entities contain less than 5 relationships . %Therefore,  A method that is capable of supplementing reliable attribute values for emerging entities can be highly useful in many applications.  %With the method to automatically extract attribute values for emerging entities, the eCommerce retailers are able to better serve the customers with updated information; the extracted medical attribute information of a novel virus can be organized to assist the understanding of the virus; the KG will be able to provide more complete information for users.      Although information extraction methods have been extensively studied, the task of open attribute value extraction remains challenging. First, the emerging entities may have new attribute values that are absent in the existing KG. Under such circumstances, the prediction methods under the closed-world assumption and the methods that cannot utilize external information are not well suited due to their limited recalls. Second,  while web corpus can be used as a good resource to provide relatively updated and relevant articles for large varieties of emerging entities, %that are relatively complete and updated in a timely manner,  %considering the large variety of the emerging entities, the web corpus, which is relatively complete and updated in a timely manner, is able to provide a rich collection of relevant articles.  %However,  the articles retrieved from web corpus can be noisy and/or irrelevant, which in turn leads to a limited precision.  Finally, even when articles are relevant, the extracted answers might still be inaccurate due to the error-prone information extraction model.    To effectively filter out noisy answers that are obtained either due to the irreverent articles or the errors incurred by the information extraction system, we  %need to answer  pose the following two questions: First, how many articles should we collect from the enormous web corpus? Second,  how to select the most reliable value out of the pool of all the possible answers extracted from the articles?  There is no common answer to the first question that works for all triplets because of the inconsistent degrees of difficulties in finding the correct attribute values. The decision of when to stop querying more external articles needs to be made after successive evaluations of the candidate answers. Thus the decision making process is inherently sequential. %Thus, it is inherently a sequential decision making problem.   Reinforcement learning  is a commonly adopted method to deal with sequential decision problems and has been widely studied in the field of robotic and game . But there are not many researches on open attribute value extraction with RL.  One existing literature of RL-based method for value extraction is proposed by .  In their work, a RL framework is designed to improve accuracy of event-related value extraction by acquiring and incorporating external evidences.  However, their approach requires a great amount of context information about the specific event of interest during the training process.  It is not trivial to extend their framework for open attribute value extraction, because we would need to collect context words and train a new model with annotated data for each emerging attribute. Therefore, their framework cannot be generalized to open attribute value extraction task when various entities and attributes are involved.  While using the context words to construct the states in RL is not suitable in our task,  our solution is to leverage the rich, well-organized information in KG, which is not only informative but also generalizable.  %The knowledge from KG  Such information can be leveraged in answer comparisons, which addresses our second question. For example, to fill the incomplete triplet  iPhone 11, display resolution, ?, from the KG we may find that the attribute values  ``display resolutions"" of an entity that is under category ``Phone"" is commonly expressed in the format of ``xxx by xxxx Pixels"", where x stands for some digit. The typical instances of the attribute values for entities under the same category provide valuable background information.   In this paper, we propose a knowledge-guided RL framework to perform open attribute value extraction.  The RL agent is trained to make good actions for answer selection and stopping time decision.  Our experiments show that the proposed framework significantly boosts the extraction performance.  To the best of our knowledge, we are the first to integrate KG in a RL framework to perform open attribute value extraction %use KG to guide the RL-based sequential decision for open attribute value extraction.  %The experiment results demonstrate that our approach improves the extraction performances substantially. In summary, our contribution are in three folds:       This paper proposed novel meta-learning approaches for low-resource UNMT. \toolnameMeta leverages multiple source domains to quickly and effectively adapt our model to the target domain. Moreover, we introduce an improved method called \ourtoolname, which enhances aggregate-domain and cross-domain generalization such that the model incorporates the knowledge learned across multiple domains. Eventually, the method prevents the model from overfitting due to a small amount of training data in a new domain, thereby leading to improved performance of low-resource UNMT. We empirically show that our proposed approaches consistently outperform the baseline models with a nontrivial margin.    In this paper, we propose novel meta-learning algorithms for low-resource UNMT. These algorithms leverages multiple source domains to learn common knowledge and then finetune the target domain. By comparing with various baseline models, we empirically show that our proposed algorithms significantly surpass others. Moreover, we introduce an enhanced algorithm, \ourtoolname, which utilizes aggregate-domain and cross-domain losses such that the model incorporates learned knowledge across multiple domains.     Owing to these losses, \ourtoolname quickly adapt a new domain in a few iterations, and further improve the performance in low-resource UNMT .    In experiment section, we demonstrate \ourtoolname quickly pretrain from source domains and finetunes a new domain in a few iteration.     Moreover, \ourtoolname shows superiority in a low resource doamain and   the importance of proposed loss and the effectiveness of proposed algorithms in varying size of a new domain. Moreover, \ourtoolname shows superiority in    Future work, we apply our extended algorithms to computer vision domain tasks, whic are suffer from the data scarcity problem.   In this paper, we propose a novel meta-learning algorithm for low-resource UNMT. The algorithm leverages multiple source domains to learn domain-general information and then finetune the target domain. Moreover, we introduce an enhanced algorithm, \ourtoolname, which utilizes aggregate-domain and cross-domain losses such that the model incorporates learned knowledge across multiple domains. Eventually, the algorithm prevents the model from being over-fitted due to a small amount of training data in a new domain and improves the performance of low-resource UNMT. We empirically show that our proposed algorithms effectively leverage domain-general knowledge and outperform baseline models with a considerable margin.     \begin{comment}      
"," Open attribute value extraction for emerging entities is an important but challenging task.  A lot of previous works formulate the problem as a question-answering  task.  While the collections of articles from web corpus provide updated information about the emerging entities, the retrieved texts can be noisy, irrelevant, thus leading to inaccurate answers. Effectively filtering out noisy articles as well as bad answers is the key to improving extraction accuracy. Knowledge graph , which contains rich, well organized information about entities, provides a good resource to address the challenge. In this work, we propose a knowledge-guided reinforcement learning  framework for open attribute value extraction.  Informed by relevant knowledge in KG, we trained a deep Q-network  to sequentially compare extracted answers to improve extraction accuracy. The proposed framework is applicable to different information extraction system. Our experimental results show that our method outperforms the baselines by 16.5 - 27.8\%.",256
"  % NMT is good but needs lots of parallel data + we should exploit mono data more Neural machine translation  using sequence to sequence architectures  has become the dominant approach to automatic machine translation. While being able to approach human-level performance , it still requires a huge amount of parallel data, otherwise it can easily overfit. Such data, however, might not always be available. At the same time, it is generally much easier to gather large amounts of monolingual data, and therefore, it is interesting to find ways of making use of such data. The simplest strategy is to use backtranslation , %but it can be rather costly since it requires training another model in the opposite translation direction and then creating the source-side synthetic sentences by translating the target-side monolingual corpus. but it can be rather costly since it requires training a model in the opposite translation direction and then translating the monolingual corpus.  % We introduce the compositionality  It was suggested by \citet{lake2017machines} that during the development of a general human-like AI system, one of the desired characteristics of such a system is the ability to learn in a continuous manner using previously learned tasks as building blocks for mastering new, more complex tasks. %by combining the knowledge learned from the previously learned simpler tasks. Until recently, continuous learning of neural networks was problematic, among others, due to the catastrophic forgetting . Several methods were proposed , however, %they mostly focused on preserving the knowledge of each task learned by the whole network. they mainly focus only on adapting the whole network  to new tasks while maintaining good performance on the previously learned tasks.  % Summary of our method using EWC %\XXX{toto mozna posunout za nasledujici odstavec + jak resime jejich nedostatky} In this work, we present an unsupervised pretraining method for NMT models using Elastic Weight Consolidation . First, we initialize both encoder and decoder with source and target language models respectively. Then, we fine-tune the NMT model using the parallel data. To prevent the encoder and decoder from forgetting the original language modeling  task, we regularize their weights individually using Elastic Weight Consolidation based on their importance to that task. Our hypothesis is the following: by forcing the network to remember the original LM tasks we can reduce overfitting of the NMT model on the limited parallel data. %\XXX{Ukazujeme, ze metoda funguje, je rychlejis + mame odvozeno, ze by mela fungovat i pro podsite} %\XXX{Zminit rovnou strucne prinosy?}  % Summary of the method we used as a comparison We also provide a comparison of our approach with the method proposed by \citet{ramachandran2017pretraining}. They also suggest initialization of the encoder and decoder with a language model. However, during the fine-tuning phase they use the original language modeling objectives as an additional training loss in place of model regularization. Their approach has two main drawbacks: first, during the fine-tuning phase, they still require the original monolingual data which might not be available anymore in a life-long learning scenario. Second, they need to compute both machine translation and language modeling losses which increases the number of operations performed during the update slowing down the fine-tuning process. Our proposed method addresses both problems: it requires only a small held-out set to estimate the EWC regularization term and converges 2-3 times faster than the previous method.\footnote{The speedup is with regard to the wall-clock time. In our experiments both EWC and the LM-objective methods require similar number of training examples to converge.}   %Intro to compositionality %Compositional learning + using previosly learned elementary knowledge to learn more complex model   %Avoiding catastrophic forgetting as key to continual learning and compositionality -> choice of EWC  %Benefits of compositionality in greater scope  + why NMT + LM pretrain? %It is a first step in our ongoing reseach  %The paper is structured as following...    Multi-hop QG task is more challenging and worthy of exploration compared to conventional single-hop QG. To address the additional challenges in multi-hop QG, we propose MulQG, which does multi-hop context encoding with Graph Convolutional Network and encoding fusion via a Gated Reasoning module. To the best of our knowledge, we are the first to tackle the challenge of multi-hop reasoning over paragraphs without any sentence-level information. The model performance on HotpotQA dataset demonstrates its effectiveness on aggregating scattered pieces of evidence across the paragraphs and fusing information effectively to generate multi-hop questions. The strong reasoning ability of the Multi-hop Encoder in the MulQA model can potentially be leveraged in complex generation tasks for the future work.    In addition, from the human evaluation, our proposed model is likely to generate more fluent complete questions and outperform the baseline by 20.8\  on the percentage of questions assessed as multi-hop type.       
","   This work presents our ongoing research of unsupervised pretraining in neural machine translation . In our method, we initialize the weights of the encoder and decoder with two language models that are trained with monolingual data and then fine-tune the model on parallel data using Elastic Weight Consolidation  to avoid forgetting of the original language modeling tasks.   We compare the regularization by EWC with the previous work that focuses on regularization by language modeling objectives.   %We compare the EWC regularization with the previous work that uses language modeling objectives from the original task for model regularization.      The positive result is that using EWC with the decoder achieves BLEU scores similar to the previous work. However,   the model converges 2-3 times faster and does not require the original unlabeled training data during the fine-tuning stage.      In contrast, the regularization using EWC is less effective if the original and new tasks are not closely related. We show that initializing the bidirectional NMT encoder with a left-to-right language model and forcing the model to remember the original left-to-right language modeling task limits the learning capacity of the encoder for the whole bidirectional context.      %%% POZNAMKY %%%   % Analyza Fisher Information   % - Self-attention projekce are more important than the Feedforward layers   % - Self-attention:   %     - output and value projections are more important at the higher layers   %     - key and query projections are more important at lower layers   % ...      % Previous work    % - requires orig. unlabeled data for MT training -> EWC can estimate Empirical Fisher on small  heldout data   % - is effective even when the orig. and new tasks differ   %  and then using this pretrained encoder in MT  -> EWC is bad at this      % Our work :   % - has nice mathematical definition    % - faster convergence in time    % - works only with decoder  -> little worse than LM obj.   % - method works when task are similar in nature    % - how deep should the unlabeled-data-pretrained enc-dec should be?   %       % why only left-context? previous work shows that with transformer, the drop in performance is not that big + it is much easier to implement       % Future work :   % - Investigate complementarity of EWC and LM obj.    % - Investigate the learning rate schemes    % - Investigate the method in the multimodal/multisource scenario   % - Investigate the method",257
"   Even though machine translation  has greatly improved with the emergence of neural machine translation   and more recently the Transformer architecture , there remain challenges which can not be solved by using sentence-level NMT systems. Among other issues, this includes the problem of inter-sentential anaphora resolution  or the consistent translation across a document , for which the system inevitably needs document-level context information.  In recent years, many works have focused on changing existing NMT architectures to incorporate context information in the translation process . However, often times results are reported only on very specific tasks , making it difficult to assess the potential of the different methods in a more general setting. This, together with the fact that big improvements are typically reported on low resource tasks, gives the impression that document-level NMT mostly improves due to regularization rather than from leveraging the additional context information. In this work we want to give a more complete overview of the current state of document-level NMT by comparing various approaches on a variety of different tasks including an application-oriented E-commerce setting. We discuss both, widely used performance metrics, as well as highly task-specific observations.  Another important aspect when talking about document-level NMT is the applicability in ``real life"" settings. There, when faced with a low resource data scenario, back-translation is an established way of greatly improving system performance . However, to the best of our knowledge, the effect of back-translation data obtained and used by context-aware models has never been explored before. The main contributions of this paper are summarized below:       We introduced our work in progress, and exploration of model regularization of NMT encoder and decoder parameters based on their importance for previously learned tasks and its application in the unsupervised pretraining scenario.  which can be used in the unsupervised pretraining scenarios based on their importance for language modeling tasks. We documented that our method slightly improves the NMT performance  when combined with a pretrained target language model. We achieve this improvement at a reduced training time.  while reducing the training time.   We also showed that the method is less effective if the original language modeling task used to pretrain the NMT encoder is too different from the task learned during the fine-tuning. We plan to further investigate whether we can gain improvements by using a different pretraining method for the encoder and how much this task mismatch relates to the learning capacity of the encoder.  
","  Context-aware neural machine translation  is a promising direction to improve the translation quality by making use of the additional context, e.g., document-level translation, or having meta-information. Although there exist various architectures and analyses, the effectiveness of different context-aware NMT models is not well explored yet. This paper analyzes the performance of document-level NMT models on four diverse domains with a varied amount of parallel document-level bilingual data. We conduct a comprehensive set of experiments to investigate the impact of document-level NMT.  We find that there is no single best approach to document-level NMT, but rather that different architectures come out on top on different tasks. Looking at task-specific problems, such as pronoun resolution or headline translation, we find improvements in the context-aware systems, even in cases where the corpus-level metrics like BLEU show no significant improvement. We also show that document-level back-translation significantly helps to compensate for the lack of document-level bi-texts.   \includecomment{ Context-aware neural machine translation  is a promising direction for improving the translation quality having more context, e.g., document-level translation, or having meta-information. The goal is to enhance the translation of discourse phenomena and polysemous words. This paper analyzes the performance of document-level NMT models with a varied amount of parallel document-level bilingual data. Including a diverse set of tasks, e.g., movie subtitles and e-commerce data, we conduct a comprehensive set of experiments to analyze and to learn the impact of document-level NMT. We show the document-level back-translation significantly helps to compensate for the lack of document-level bi-texts.  }",258
" Automatic summarization is a fundamental task in Natural Language Processing, which aims to condense the original input into a shorter version covering salient information and has been continuously studied for decades . Recently, online multi-speaker dialogue/meeting has become one of the most important ways for people to communicate with each other in their daily works. Especially due to the spread of  COVID-19 worldwide, people are more dependent on online communication. In this paper, we focus on dialogue summarization, which can help people quickly grasp the core content of the dialogue without reviewing the complex dialogue context.   Recent works that incorporate additional commonsense knowledge in the dialogue generation  and dialogue context representation learning  show that even though neural models have strong learning capabilities, explicit knowledge can still improve response generation quality.   It is because that a dialog system can understand conversations better and thus respond more properly if it can access and make full use of large-scale commonsense knowledge. However, current dialogue summarization systems  ignore the exploration of commonsense knowledge, which may limit the performance. In this work, we examine the benefit of incorporating commonsense knowledge in the dialogue summarization task and also address the question of how best to incorporate this information. Figure  shows a positive example to illustrate the effectiveness of commonsense knowledge in the dialogue summarization task.  Bob asks Tom for help because his car has broken down. On the one hand, by introducing commonsense knowledge according to the pick up and car broke down, we can know that Bob expects Tom to give him a lift. On the other hand, commonsense knowledge can serve as a bridge between non-adjacent utterances that can help the model better understanding the dialogue.  In this paper, we follow the previous setting  and also use ConceptNet  as a large-scale commonsense knowledge base, while the difference is that we regard knowledge and text as heterogeneous data in a real multi-speaker dialogue. We propose a model named Dialogue Heterogeneous Graph Network  for incorporating commonsense knowledge by constructing the graph including both utterance and knowledge nodes. Besides, our heterogeneous graph also contains speaker nodes at the same time, which has been proved to be a useful feature in dialogue modeling. In particular, we equip our heterogeneous graph network with two additional designed modules. One is called message fusion, which is specially designed for utterance nodes to better aggregate information from both speakers and knowledge. The other one is called node embedding, which can help utterance nodes to be aware of position information. Compared to homogeneous graph network in related works , we claim that the heterogeneous graph network can effectively fuse information and contain rich semantics in nodes and links, and thus more accurately encode the dialogue representation.   We conduct experiments on the SAMSum corpus , which is a large-scale chat summarization corpus. We analyze the effectiveness of integration of knowledge and heterogeneity modeling. The human evaluation also shows that our approach can generate more abstractive and correct summaries. To evaluate whether commonsense knowledge can help our model better generalize to the new domain, we also perform zero-shot setting experiments on the Argumentative Dialogue Summary Corpus , which is a debate summarization corpus. In the end, we give a brief summary of our contributions:  We are the first to incorporate commonsense knowledge into dialogue summarization task.  We propose a D-HGN model to encode the dialogue by viewing utterances, knowledge and speakers as heterogeneous data.  Our model can outperform various methods.     This paper proposes an adaptive attentional network for few-shot KG completion, termed as FAAN. Previous studies solve this problem by learning static representations of entities or references, ignoring their dynamic properties. FAAN proposes to encode entity pairs adaptively, and predict facts by adaptively matching references with queries. Experiments on two public datasets demonstrate that our model outperforms current state-of-art methods with different few-shot sizes. Our future work might consider other advanced methods to model few-shot relations, and exploiting more contextual information like textual description to enhance entity embeddings.   
"," Abstractive dialogue summarization is the task of capturing the highlights of a dialogue and rewriting them into a concise version. In this paper, we present a novel multi-speaker dialogue summarizer to demonstrate how large-scale commonsense knowledge can facilitate dialogue understanding and summary generation. In detail, we consider utterance and commonsense knowledge as two different types of data and design a Dialogue Heterogeneous Graph Network  for modeling both information. Meanwhile, we also add speakers as heterogeneous nodes to facilitate information flow. Experimental results on the SAMSum dataset show that our model can outperform various methods. We also conduct zero-shot setting experiments on the Argumentative Dialogue Summary Corpus, the results show that our model can better generalized to the new domain.",259
" %\yy{para 1: problem is important, para 2: temporal graph, existing systems, para 3: neural networks, para 4: why difficult: lack of training data, para 5: what do we do}  %\yy{this is a comment} %\yyc{before correction}{after correction}   %The flow of time is used to chain narratives, reason about causes and effects of events, form a deeper understanding of the past, and postulate the future. Temporal reasoning is crucial for analyzing the interactions among complex events and producing   coherent interpretations of text data . There is a rich body of research on the use of temporal information in a variety of important application domains, including topic detection and tracking, information extraction, parsing of clinical records , discourse analysis, and question answering. %\yy{Aman: Please update the cites based on some quick Google search on temporal reasoning/expressions in IE/TDT/medical .} %Motivated by its ubiquity in text understanding, we undertake the task of extracting temporal graphs from documents. %and a rich understanding of temporal aspects of a document helps humans in reading comprehension.   %Temporal reasoning also plays a critical role in downstream natural language processing  tasks like    Graphs are a natural choice for representing the temporal ordering among events, where the nodes are the individual events, and the edges capture temporal relationships such as ``before'', ``after'' or ``simultaneous''. Representative work on automated extraction of such graphs from textual documents includes the early work by~\citet{chambers2009unsupervised}, where the focus is on the construction of event chains from a collection of documents, and the more recent \caevo and \cct, which extract a graph for each input document instead.   These methods focus on rule-based and statistical sub-modules to extract verb-centered events and the temporal relations among them. %Specifically, given a document, our system extracts a temporal event graph, where the nodes of the graph are the events, and the edges capture the temporal order~ between them. %Classical temporal information extraction systems focus on one of the two broad themes of relation identification and temporal relation classification. %Relation identification is the task of identifying events that can be connected by a temporal relation. %The task of temporal relation involves identifying the temporal relationship that exists between the given two events. % For example, in the sentence I had a coffee while I was getting a haircut, the phrase while I was expresses the fact that the events of drinking a coffee and getting a haircut took place at the same time. %For example, given the sentence I had a coffee while I was getting a haircut, a relation identification system would identify events had a coffee and getting a haircut. %A temporal relation classification system would then determine that the events happened simultaneously. %Our goal is to create a system that can perform both these tasks together in an end-to-end fashion over multiple sentences.  %The idea of extracting temporal graphs from a given document is not new. %Tempeval-3 introduced a task specifically to this end. %The idea of extracting events and the temporal links between them as a graph was proposed in Tempeval-3. %However, the evaluation still relied on a set of pre-identified events from the TimeBank corpus, leading most of the teams to focus on relation classification. %Despite its importance, the task has received limited attention. %Representative temporal graph extraction systems like  \caevo and \cct break down the problem into sub-tasks, like event identification and relation extraction, and then employ rule-based and statistical systems to solve each sub-task. %Additionally, they use small amounts of hand-labeled corpora for their development, limiting their generalizability and scalability. As an emerging area of nlp, large scale pre-trained language models have made strides in addressing challenging tasks like commonsense knowledge graph completion and task-oriented dialog generation. %Besides relying on an intricate arrangement of sub-systems, they have some common shortcomings: i) They either admit a lot of noisy events  or ignore events from the secondary narrative , ii) generate one-word verbs as events, without adding any context, iii) have limited generalization capabilities by way of relying on rules or small training corpora. % These systems typically fine-tune large language models like gpt or \gptz on a corpus of task-specific dataset. These systems typically fine-tune large language models on a corpus of a task-specific dataset. %However, these advances have not benefited temporal graph extraction.  However, these techniques have not been investigated for temporal graph extraction.  This paper focuses on the problem of generation of an event-level temporal graph for each document, and we refer to this task as contextualized graph generation.   We address this open challenge by proposing a novel reformulation of the task as a sequence-to-sequence mapping problem, which enables us to leverage large pre-trained models for our task. Further, our proposed approach is completely end-to-end and eliminates the need for a pipeline of sub-systems commonly used by traditional methods. %This helps approach is end-to-end, it is not only easier to implement,  approach prevents error propagation across stages and minimizes the effort required for feature engineering.  We also address a related open challenge, which is a prerequisite to our main goal: the difficulty of obtaining a large quantity of training graphs with human-annotated events and temporal relations.   %We address this second challenge with an unsupervised approach, i.e., to  % To this end, we automatically produce a large collection of document-graph pairs by applying existing information extraction and \nlp tools to textual documents, followed by a few rule-based post-processing steps for pruning and noise reduction. Specifically, using \caevo and other tools, we generate a large collection of 89,000 document/graph pairs. To this end, we automatically produce a large collection of document-graph pairs by using \caevo, followed by a few rule-based post-processing steps for pruning and noise reduction.  %Specifically, using \caevo and other tools, we generate a large collection of 89,000 document/graph pairs. %. %which facilitates both large-scale fine-tuning as well as large-scale evaluation of our new approach in comparison with other competing methods.} %The primary block for this union remains the data-hungry nature of large language models; they typically require sizeable datasets for effective training, while popular temporal corpora usually only offer tens to hundreds of hand-labeled documents. %Given that large scale pre-trained language models  %Despite its importance, temporal graph extraction has not benefited from the recent advances in large scale pre-trained language models, which have been effective for  %The limitation does not lie in their representative capabilities.  %Rather, the lack of training data forms the  %The lack of training data forms the biggest bottleneck for this unification: large scale language models typically require large datasets for effective training. Simultaneously, popular temporal corpora usually have tens to hundreds of documents. % bridge this gap by generating a large corpus of 89k document-graph pairs for the task. %We achieve this by first using \caevo as a cheap supervision mechanism for creating a large corpus of dense temporal graphs. %Admittedly, the data generated by \caevo has considerable amounts of error and noise. %We alleviate these issues by injecting human knowledge in the \caevo generated data by applying several post-processing strategies. % Specifically, we remove noisy events and relations extracted with low confidence, and use event clusters to map each graph to its correct context. We then encode the graph in each training pair as a string in the graph representation format \dotlang, transforming the text-to-graph mapping into sequence-to-sequence mapping. %task. We fine-tune \gptz on this dataset of document-graph pairs, which yields large performance gains over strong baselines on system generated test set and outperforms \caevo on TimeBank-Dense on multiple metrics. Figure 1 shows an example of the input document and the generated graph by our system. %While automatic labeling cannot rival human-curation in quality, our strong experimental results show that the dataset prepared by our method provides a competitive signal to noise ratio at virtually zero cost.  %allowing strong learners to generalize on unseen data. %and use masked-language modeling with \gptz for estimating the conditional distribution of temporal graphs given a document. %Our experiments with \gptz show large gains over strong baselines on our dataset and outperforms \caevo on TimeBank-Dense on a range of metrics. %In the process, we answer several practical questions on selecting salient events, identifying the context for a temporal graph, graph representation, and evaluation. %The system trained on strong results on our data and outperforming \caevo on TimeBank-Dense on a range of metrics. %TODO we are the first to  %Qualitative analysis of nodes generated from our method shows that our approach can successfully use the large training corpus for learning generalized patterns of temporal relations, with error analysis on a held-out set revealing that \caevo fixes the labels for 10\% of the cases. % We use \caevo to label a large corpus of documents and apply novel pruning techniques on top of graphs generated by \caevo.  % These pruning techniques retain the high confidence annotations by \caevo while removing noisy events and relations. % Further, the context for each graph is automatically discovered using the notion of event communities, obviating the need for any hardcoded cutoffs typically adopted in temporal systems. In summary, our main contributions are: %\am{write about three contributions: i) annotation pipeline, ii) encoding to strings, thus allowing the use of gpt, iii) strong results on our data, very good result on \tbden, dramatic improvements over off-the-shelf \gptz}  % % File acl2020.tex % %% Based on the style files for ACL 2020, which were %% Based on the style files for ACL 2018, NAACL 2018/19, which were %% Based on the style files for ACL-2015, with some improvements %%  taken from the NAACL-2016 style %% Based on the style files for ACL-2014, which were, in turn, %% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009, %% EACL-2009, IJCNLP-2008... %% Based on the style files for EACL 2006 by  %%e.agirre@ehu.es or Sergi.Balari@uab.es %% and that of ACL 08 by Joakim Nivre and Noah Smith  \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{acl2020} \usepackage{times} \usepackage{latexsym} \renewcommand{\UrlFont}{\ttfamily\small} \usepackage{color} \usepackage{xspace} \usepackage{amsmath} \usepackage{amsfonts} \usepackage{multirow} \usepackage[multiple]{footmisc} \usepackage{array, booktabs, makecell} \usepackage{graphicx} \usepackage{colortbl} \usepackage{xcolor} \setlength{\textfloatsep}{0.1cm} % This is not strictly necessary, and may be commented out, % but it will improve the layout of the manuscript, % and will typically save some space. \usepackage{microtype}  %\aclfinalcopy % Uncomment this line for the final submission %\def\aclpaperid{***} %  Enter the acl Paper ID here  %\setlength\titlebox{5cm} % You can expand the titlebox if you need extra space % to show all the authors. Please do not make the titlebox % smaller than 5cm ; we will check this % in the camera-ready version and ask you to change it back.  \newcommand\BibTeX{Bib\TeX}  \title{Neural Language Modeling for Contextualized Temporal Graph Generation} \aclfinalcopy \author{Aman Madaan, Yiming Yang \\   Language Technologies Institute, Carnegie Mellon University \\   Pittsburgh, PA, USA \\    \\}  \date{}     In this paper, we improve abstractive dialogue summarization by incorporating commonsense knowledge. We first construct a heterogeneous dialogue graph by introducing knowledge from a large-scale commonsense knowledge base. Then we present a Dialogue Heterogeneous Graph Network  for this task by viewing utterances, knowledge and speakers in the graph as heterogeneous nodes. We additionally design two modules named message fusion and node embedding to facilitate information flow. Experiments on the SAMSum dataset show the effectiveness of our model that can outperform various methods. Zero-shot setting experiments on the Argumentative Dialogue Summary Corpus show that our model can better generalized to the new domain.   
"," This paper presents the first study on using large-scale pre-trained language models for automated generation of an event-level temporal graph for a document. Despite the huge success of neural pre-training methods in NLP tasks, its potential for temporal reasoning over event graphs has not been sufficiently explored. Part of the reason is the difficulty in obtaining large training corpora with human-annotated events and temporal links. We address this challenge by using existing IE/NLP tools to automatically generate a large quantity  of system-produced document-graph pairs, and propose a novel formulation of the contextualized graph generation problem as a sequence-to-sequence mapping task. These strategies enable us to leverage and fine-tune pre-trained language models on the system-induced training data for the graph generation task. Our experiments show that our approach is highly effective in generating structurally and semantically valid graphs. Further, evaluation on a challenging hand-labeled, out-domain corpus shows that our method outperforms the closest existing method by a large margin on several metrics.\footnote{Code and pre-trained models available at}",260
" Building dialog systems typically requires a large collection of conversation logs that a model can use as training data. Crowd-sourcing is a popular method for generating such data-sets and depending on the aspect of dialog modeling being studied, crowd-sourced workers may be asked to annotate existing chat logs for intents and dialog acts, create dialog summaries, converse with each other based on a script or converse to accomplish tasks or goals etc. For instance, to create datasets for task oriented dialogs, crowd-sourced workers may be provided with a goal  that describes the task that needs to be accomplished; workers then play the roles of a user and an agent to generate conversations . % that plays the role of user.   The user worker begins the conversation by stating their requirement and the agent worker provides information to the user by querying a knowledge base , if required. Together, the two workers interact with each other via natural language to generate conversations that can involve booking restaurant tables, making train reservations, calling a taxi etc. However, creating large crowd-sourced datasets can be time consuming and expensive.               Current methods for generating event-level temporal graphs have focused on the use of existing Information Extraction  trained on relatively small amounts of hand-labeled data.  Current methods for generating event-level temporal graphs are developed with relatively small amounts of hand-labeled data.   On the other hand, the possibility of using pre-trained neural sequence-to-sequence models for this task has not received sufficient attention, primarily due to the difficulty of obtaining large corpora of human-annotated graphs for temporal reasoning over events. On the other hand, the possibility of using pre-trained language models for this task has not received sufficient attention, primarily due to the difficulty of obtaining large corpora of human-annotated graphs for temporal reasoning over events.  The possibility of using pre-trained language models for generating event-level temporal graphs has not received sufficient attention.  This is primarily due to the difficulty in obtaining large corpora of human-annotated graphs for temporal reasoning over events. This paper addresses this open challenge by first developing a data generation pipeline that uses existing //clustering techniques for automated acquisition of a large corpus of document-graph pairs, and by proposing a new formulation of the graph generation task as a sequence-to-sequence mapping task, allowing us to leverage and fine-tune pre-trained language models for our goal.  \am{note for later: break into two sentences/points}   Our experiments strongly support the effectiveness of the proposed approach, which significantly outperforms strong baselines, which represents transitional IE approaches. Our experiments strongly support the effectiveness of the proposed approach, which significantly outperforms strong baselines, including traditional  techniques.  We experiment with \gptz and show that it achieves large gains over strong baselines on a system created test set and outperforms \caevo on several metrics for a hand-labeled, out-of-domain dataset. We plan to explore techniques for adapting large-scale language models on unseen domains and at multiple granularity levels in the future.  As an exciting extension of our work, we plan to measure the efficacy of the temporal graphs for downstream tasks like narrative extraction and generation of temporal graphs at different granularity levels. 
"," Popular task-oriented dialog data sets such as MultiWOZ \cite{Multiwoz} are created by providing crowd-sourced workers a goal instruction, expressed in natural language, that describes the task to be accomplished. Crowd-sourced workers play the role of a user and an agent to generate dialogs to accomplish tasks involving booking restaurant tables, making train reservations, calling a taxi etc. However, creating large crowd-sourced datasets can be time consuming and expensive. To reduce the cost associated with generating such dialog datasets, recent work has explored methods to automatically create larger datasets from small samples.  %Popular dialog data sets such as MultiWoz \cite{Multiwoz} are created by providing crowd-sourced workers a goal instruction, expressed in natural language, which described the task that needed to be accomplished. Crowd-sourced workers played the role of a user and an agent to generate dialogs that can involve booking restaurant tables, making train reservations, calling a taxi etc.  In this paper, we present a data creation strategy that uses the pre-trained language model, GPT2 \cite{GPT2}, to simulate the interaction between crowd-sourced workers by creating a user bot and an agent bot.  We train the simulators using a smaller percentage of actual crowd-generated conversations and their corresponding goal instructions. We demonstrate that by using the simulated data, we achieve significant improvements in both low-resource setting as well as in overall task performance. To the best of our knowledge we are the first to present a model %this is the first model proposed  for generating entire conversations by simulating the crowd-sourced data collection process. %To the best of our knowledge we are the first to use inter-bot conversation logs to improve the performance of task oriented dialog systems.",261
" Multilingual machine translation , which can serve multiple language pairs with a single model, has attracted much attention. In contrast to bilingual MT systems which can only serve one single language pair, multilingual models can serve  language pairs  .  The amount of available training data can differ a lot across language pairs and the majority of available MT training data is English-centric  which in practice means that most non-English language pairs do not see a single training example when training multilingual models .  As a consequence, the actual performance of language pairs that do not include English on the source or target side lags behind the ones with large amounts of training data. Further, when increasing the number of languages, it gets  impractical to gather training data for each language pair and  challenging to find the right mix during training. Which is why models tasked with direct translation between non-English pairs either resort to bridging  through a pivot language , or make use of synthetic parallel data   or study the problem under zero-shot settings .     In this study, we make use of the potential pre-existing multi-way property in the training corpora and generate as many direct training examples from pre-existing English-centric training data. If we can find training examples for each language pair in a multilingual mix, we call this model complete Multilingual Neural Machine Translation . cMNMT is then trained on all bilingual pairs between source and target languages by utilizing multi-way aligned training examples that consist of translations of the same sentence into multiple languages. We resurface multi-way aligned training examples by aligning training examples from different language pairs when either their source or target sides are identical .  To make use of this data, the model samples a source and target language from the set of multi-way aligned corpus during training, which allows the model to see language pairs where originally no training data existed . As our experiments support, this method enables us to get access to training data for all tested language pairs ). We will show that it is possible to generate a complete graph for at least a 6-language WMT setup. Some of the WMT training data is multi-way parallel by construction. Nevertheless, we show that we also find many training examples where the source and target origin from different sources. We further show on our 112 languages internal dataset, that we can find sufficient training data for over 12,000 language pairs by only providing 111 English-centric training corpora. This result indicates that it is possible to generate direct training data for many language pairs without the need for crawling new training examples. Our experiments suggest that before falling back to methods like zero-shot translation, you should investigate the structure of your pre-existing training data.  To address the problem of finding the right mix of examples from different language pairs during training, we further introduce a hierarchical sampling strategy that is language-specific . In addition to fixing some chronic issues of MNMT , the proposed sampling strategy efficiently ensures all source-target pairs are covered.  Experiments demonstrate that we can train a cMNMT model on a 30-language-pair WMT setup that outperforms bilingual and multilingual baselines as well as bridging on all non-English language pairs. We further show that the performance of the English language pairs stay stable and do not suffer from the changes in both the training data and the new training data sampling strategy. Furthermore, we share experiments at scale by demonstrating that we can train a cMNMT model that can serve  12,432 language pairs.  Our contribution is three-fold:      In this paper, we demonstrated a dialog generation framework that mimics the data creation process employed by crowd-sourced workers. We find that our method is able to generate meaningful conversations that aids the training of end-task dialog models in both, low resource and full data settings. The use of additional simulated data to train end-task dialog models result in a performance improvement of 18-25\  in low resource settings, and when combined with full training data, we find that the performance of a simple GPT2 based end-task model becomes comparable to current state-of-the-art models. The simulation-framework does not make strict assumptions about the domain or dataset and it would be interesting to explore its use in other dialogue tasks such as Persona-Chat  in future work.  which we wish to explore in our future work.  We include qualitiatve results demonstrating the se
"," Multilingual Neural Machine Translation  models are commonly trained on a joint set of bilingual corpora which is acutely English-centric . While direct data between two languages that are non-English is explicitly available at times, its use is not common. In this paper, we first take a step back and look at the commonly used bilingual corpora , and resurface the existence and importance of implicit structure that existed in it: multi-way alignment across examples . We set out to study the use of multi-way aligned examples to enrich the original English-centric parallel corpora. We reintroduce this direct parallel data from multi-way aligned corpora between all source and target languages. By doing so, the English-centric graph expands into a complete graph, every language pair being connected. We call MNMT with such connectivity pattern complete Multilingual Neural Machine Translation  and demonstrate its utility and efficacy with a series of experiments and analysis. In combination with a novel training data sampling strategy that is conditioned on the target language only, cMNMT yields competitive translation quality for all language pairs. We further study the size effect of multi-way aligned data, its transfer learning capabilities and how it eases adding a new language in MNMT. Finally, we stress test cMNMT at scale and demonstrate that we can train a cMNMT model with up to 111$*$112=12,432 language pairs that provides competitive translation quality for all language pairs.",262
"  Machine Translation  has shown impressive progress in recent years. Neural architectures have greatly contributed to this  improvement, especially for languages with abundant training data.  This progress creates novel challenges for the evaluation of machine translation,  both for human and automated evaluation  protocols.  Both types of evaluation play an important role in machine translation. While human evaluations provide a gold standard evaluation, they involve a fair amount of careful and hence expensive work by human assessors. Cost therefore limits the scale of their application. On the other hand, automated evaluations are much less expensive. They typically only involve human labor when collecting human reference translations and can hence be run at scale to compare a wide range of systems or validate design decisions. The value of automatic evaluations  therefore resides in their capacity to be used as a proxy for human evaluations for large scale comparisons and system development.  The recent progress in MT has raised concerns about whether automated evaluation methodologies reliably reflect human ratings in high accuracy ranges. In particular, it has been observed that the best systems according to humans might fare less well with automated metrics. Most metrics such as \BLEU and TER measure overlap between a system output and a human reference translation. More refined ways to compute such overlap have consequently been proposed.  Orthogonal to the work of building improved metrics,  hypothesized that human references are also an important factor in the reliability of automated evaluations. In particular, they observed that standard references exhibit simple, monotonic language due to human  `translationese` effects. These standard references might favor systems which excel at reproducing these effects, independent of the underlying translation quality. They showed that better correlation between human and automated evaluations could be obtained when replacing standard references with paraphrased references, even when still using surface overlap metrics such as BLEU~. The novel references, collected by asking linguists to paraphrase standard references, were shown to steer evaluation away from rewarding translation artifacts. This improves the assessment of alternative, but equally good translations.  Our work builds on the success of paraphrased translations for evaluating  existing systems, and asks if different design choices could have been made when designing a system with such an evaluation protocol in mind. This examination has several potential benefits: it can help identify choices which improve BLEU on standard references but have limited impact on final human evaluations; or those that result in better translations for the human reader, but worse in terms of standard reference BLEU. Conversely, it might turn out that paraphrased references are not robust enough to support system development due to the presence of `metric honeypots': settings that produce poor translations, but which are nevertheless assigned high BLEU scores.  To address these points, we revisit the major design choices of the best EnglishGerman system from WMT2019 step-by-step, and measure their impact on standard reference BLEU as well as on paraphrased BLEU. This allows us to measure the extent to which steps such as data cleaning, back-translation, fine-tuning, ensemble decoding and reranking benefit standard reference BLEU more than paraphrase BLEU. Revisiting these development choices with the two metrics results in two systems with quite different behaviors. We conduct a human evaluation for adequacy and fluency to assess the overall impact of designing a system using paraphrased BLEU.  Our main findings show that optimizing for paraphrased BLEU is advantageous for human evaluation when compared to an identical system optimized for standard BLEU. The system optimized for paraphrased BLEU significantly improves WMT newstest19 adequacy ratings  and fluency ratings  despite scoring 5 BLEU points lower on standard references.    In this work, we introduced complete Multilingual Neural Machine Translation  that exploits the multi-way alignment information in the underlying training data to improve translation quality for language pairs where training data is scared or not available. Standard MNMT models are trained on a joint set of different training corpora for a variety of language pairs. cMNMT combines the different corpora and constructs multi-way aligned training examples that consist of translations of the same sentence into multiple languages.   In combination with a novel temperature-based sampling approach that is conditioned on the target language only, we show that cMNMT is superior to the standard MNMT model and the even better-performing bridging approach.    Experimental results on a public WMT 30 language pairs dataset and an in-house 12,432 language pairs dataset demonstrated an average BLEU increase of more than 10 BLEU points for non-English language pairs. This approach leads to a single NMT model that can serve 12,432k language pairs with reasonable quality which also surpasses the translation quality of the bridging approach, which is nowadays used in most modern MT services.    
","  Automatic evaluation comparing candidate translations to human-generated paraphrases of reference translations has recently been proposed by \newcite{freitag2020bleu}. When used in place of original references, the paraphrased versions produce metric scores that correlate better with human judgment. This effect holds for a variety of different automatic metrics, and tends to favor natural formulations over more literal  ones. In this paper we compare the results of performing end-to-end system development using standard and paraphrased references. With state-of-the-art English-German NMT components, we show that tuning to paraphrased references produces a system that is significantly better according to human judgment, but 5 BLEU points worse when tested on standard references. Our work confirms the finding that paraphrased references yield metric scores that correlate better with human judgment, and demonstrates for the first time that using these scores for system development can lead to significant improvements.",263
"     % Demonstrating intelligent behavior in complex environments requires agents that can reason about entities and their relationships, and identify regularities in structured data which can help predict the properties-of and relationships-between entities.  % Understanding natural language in realistic settings requires models that can reason about the interactions between content and context, model the dependencies between different textual elements and leverage information about authors when interpreting their content.  For example, when analyzing interactions in a social network, leveraging information about users' social behavior can help identify similarities in the contents of posts they author. Dealing with this type of relational data requires making predictions over multiple, often inter-dependent, variables.    Understanding natural language interactions in realistic settings requires models that can deal with noisy textual inputs, reason about the dependencies between different textual elements and leverage the dependencies between textual content and the context from which it emerges. Work in linguistics and anthropology has defined context as a frame that surrounds a focal communicative event and provides resources for its interpretation . %\citealt{contextualization-92} introduced the term contextualization cues as signalling mechanisms in communication that add to the shared understanding between the participants, into relationships, the situation, and the environment of the conversation    %Say something about debate networks and add some references. As a motivating example, consider the interactions in the debate network  described in Fig.. Given a debate claim , and two consecutive posts debating it , we define a textual inference task, determining whether a pair of text elements hold the same stance in the debate }). This task is similar to other textual inference tasks which have been successfully approached using complex neural representations. In addition, we can leverage the dependencies between these decisions.  For example, assuming that one post agrees with the debate claim }}), and the other one does not }}), the disagreement between the two posts can be inferred:  {\small \PRED{\neg Agree\wedge Agree \rightarrow \neg Agree}}. Finally, we consider the social context of the text. The disagreement between the posts can reflect a difference in the perspectives their authors hold on the issue. While this information might not be directly observed, it can be inferred using the authors' social interactions and behavior. % Given the principle of social homophily, stating that people with strong social ties are likely to hold similar views and authors' perspectives can be captured by representing their social interactions. Exploiting this information requires models that can align the social representation with the linguistic one.  Motivated by these challenges, we introduce \DRAIL, a Deep Relational Learning framework, which uses a combined neuro-symbolic representation for modeling the interaction between multiple decisions in relational domains. Similar to other neuro-symbolic approaches our goal is to exploit the complementary strengths of the two modeling paradigms. Symbolic representations, used by logic-based systems and by probabilistic graphical models, are interpretable, and allow domain experts to directly inject knowledge and constrain the learning problem. Neural models capture dependencies using the network architecture and are better equipped to deal with noisy data, such as text. However, they are often difficult to interpret and constrain according to domain knowledge.   Our main design goal in \DRAIL is to provide a generalized tool, specifically designed for NLP tasks. Existing approaches designed for classic relational learning tasks, such as knowledge graph completion, are not equipped to deal with the complex linguistic input. While others are designed for very specific NLP settings such as word-based quantitative reasoning problems or aligning images with text. We discuss the differences between \DRAIL and these approaches in Section.  % While the examples in this paper focus on modelings various argumentation mining tasks and their social and political context, the same principles can be applied to wide array of NLP tasks with different contextualizing information, such as images that appear next to the text, or prosody when analyzing transcribed speech, to name a few examples. %TODO: explain why DRAIL is specifically useful for NLP compared to other languages. We don't do the same type of evaluation  as we are interested in working with raw entities.     %  Entities in \DRAIL are either human-interpretable discrete entities , which we refer to as symbols, or raw entities that have a complex internal structure which cannot be easily represented as a symbol . This view allows us to define two conceptual learning tasks: relations connecting raw and symbolic entities }}), and relations connecting raw inputs to each other, which define inference tasks }}).   % \DRAIL uses a declarative language for defining deep relational models. Similar to other declarative languages, it allows users to inject their knowledge by specifying dependencies between decisions using first-order logic rules, which are later compiled into a factor graph with neural potentials.   % In addition to probabilistic inference, \DRAIL also models dependencies using a distributed knowledge representation, denoted \relnets, which provides a shared representation space for entities and their relations, trained using a relational multi-task learning approach. This provides a mechanism for explaining symbols, and aligning representations from different modalities.  %Introduce the s-s, r-r, s-r, distinction as a way to support classification, textual inference, and probabilistic inference. Following our running example, ideological standpoints, such as \PRED{Liberal} or \PRED{Conservative}, are discrete entities embedded in the same space as textual entities and social entities. These entities are initially associated with users, however using \relnets this information will propagate to texts reflecting these ideologies, by exploiting the relations that bridge social and linguistic information . % In the resulting shared embedding space, we can explain these ideological standpoints in terms of users holding them, or texts that express them.%}).    %TODO: what are the research questions    %TODO - explain the difference in task from DRAIL's perspective - argument relations inside a single text, analyzing discussions - the simple case, discussed in the literature, where we predict a symbol , and the debate.org setup where we combine textual inference  with soclia linfo    To demonstrate \DRAIL's modeling approach, we introduce the task of open-domain stance prediction with social context, which combines social networks analysis and textual inference over complex opinionated texts, as shown in Fig. . %Unlike traditional stance prediction tasks, where the prediction problem is defined over a fixed set of issues  ~ , we go beyond coarse-grained definitions, and delve into the specific arguments and questions of each discussion, as shown in Fig. . We follow the intuition that debates are part of a broader online conversation, involving multiple people that contribute or express their support for the different views, and explicitly model these interactions.  % AugensteinD16-1084,P18-2123,C18-1316} %TODO: add some discussion about qualitative evaluation % We complement our evaluation of \DRAIL with two additional tasks, issue-specific stance prediction, where we identify the views expressed in debate forums with respect to a set of fixed issues, and argumentation mining, a document-level discourse analysis task.    %We demonstrate \DRAIL's modeling approach over three challenging problems. Argumentation mining, a document-level discourse analysis task. Debate stance prediction, identifying the views expressed-in, and interactions-between, debate forum posts. Finally, we introduce a new problem, open-domain stance prediction with social context, which combines social networks analysis and textual inference over complex opinionated texts.  In all three tasks we evaluate different modeling choices, obtaining competitive results.    %TODO: contributions %Our contributions are summarized as follows: % %    %Unrealted TODO: add a discussion about globally normalized RELNETs- the constraints and the multiple objectives shape them.  %homophily, %, This phenomenon was previously used to help overcome language variation issues   % political-social representations %network embedding:we learn a graph embedding, a different way to define social context %graphical models way    	In this paper, we present the Bi-directional Cognitive Thinking Network  which corresponding to the Bi-directional Cognitive Knowledge Framework  from the perspective of psychology. The BCTN answers the question with bi-directional knowledge by simulating the inertial thinking and reverse thinking. And we decouple these two parts of knowledge rather than couple them with the same module. 	  in a bi-directional way of thinking that stemmed from cognitive psychology.  	To determine the stimulus intensity of reverse thinking in memory, we consider the decoded tokens to calculate the score based on the gate mechanism. We show that the proposed BCTN is very effective, it has competitiveness with the previous methods in literature on DuReader with a single model. Our future work will consider to use different datasets and design various models to simulate the behavior of our brain to capture human-level language understanding and intelligence. Finally, we believe that our framework can generalize to other generative tasks, 	such as summarization and image caption. 	 	
"," Building models for realistic natural language tasks requires dealing with long texts and accounting for complicated structural dependencies. Neural-symbolic representations have emerged as a way to combine the reasoning capabilities of symbolic methods, with the expressiveness of neural networks. However, most of the existing frameworks for combining neural and symbolic representations have been designed for classic relational learning tasks that work over a universe of symbolic entities and relations. In this paper, we present \DRAIL, an open-source declarative framework for specifying deep relational models, designed to support a variety of NLP scenarios. Our framework supports easy integration with expressive language encoders, and provides an interface to study the interactions between representation, inference and learning.",264
"   End-to-end neural models have emerged in recent years as the dominant approach to a wide variety of sequence generation tasks in natural language processing, including speech recognition, machine translation, and dialog generation, among many others. While highly accurate, these models typically operate by outputting tokens from a predetermined symbolic vocabulary, and require integration into larger pipelines for use in user-facing applications such as voice assistants where neither the input nor output modality is text.  In the speech domain, neural methods have recently been successfully applied to end-to-end speech translation , in which the goal is to translate directly from speech in one language to speech in another language. We propose to study the analogous problem of in-image machine translation. Specifically, an image containing text in one language is to be transformed into an image containing the same text in another language, removing the dependency of any predetermined symbolic vocabulary or processing.  \paragraph{Why In-Image Neural Machine Translation ?} In-image neural machine translation is a compelling test-bed for both research and engineering communities for a variety of reasons. Although there are existing commercial products that address this problem such as image translation feature of Google Translate the underlying technical solutions are unknown. By leveraging large amounts of data and compute, end-to-end neural system could potentially improve overall quality of pipelined approaches for image translation. \iffalse First, existing commercial products that address this problem such as the image translation feature of Google Translate employ a traditional pipelined approach consisting of separate optical character recognition, translation, and image rendering steps.\todo{orhanf will check this with mobile team. Elman: commented out as suggested by mobile wordlens team. technical solution of wordlens is not publicly available hence this sentence is a bit speculative}  Combining all these components into a single end-to-end neural system could help reduce cascading errors and improve overall translation quality, leveraging large amounts of data and compute. \fi Second, and arguably more importantly, working directly with pixels has the potential to sidestep issues related to vocabularies, segmentation, and tokenization, allowing for the possibility of more universal approaches to neural machine translation, by unifying input and output spaces via pixels.  Text preprocessing and vocabulary construction has been an active research area leading to work on investigating neural machine translation systems operating on subword units , characters  and even bytes  and has been highlighted to be one of the major challenges when dealing with many languages simultaneously in multilingual machine translation , and cross-lingual natural language understanding . Pixels serve as a straightforward way to share vocabulary among all languages at the expense of being a significantly harder learning task for the underlying models.  In this work, we propose an end-to-end neural approach to in-image machine translation that combines elements from recent neural approaches to the relevant sub-tasks in an end-to-end differentiable manner. We provide the initial problem definition and demonstrate promising first qualitative results using only pixel-level supervision on the target side. We then analyze some of the errors made by our models, and in the process of doing so uncover a common deficiency that suggests a path forward for future work.    In this paper, we motivate the need for a declarative neural-symbolic approach that can be applied to NLP tasks involving long texts and contextualizing information. We introduce a general framework to support this, and demonstrate its flexibility by modeling problems with diverse relations and rich representations, and obtain models that are easy to interpret and expand.  Going forward, we would like to study distant supervision, and to support learning with latent predicates, to reason over relations and properties that are not directly observed.   The code, data and documentation for \DRAIL and the application examples in this paper will be released to the community, to help promote this modeling approach for other applications.   We discuss and evaluate different modeling choices for deep relational learning. We characterize the strengths and weaknesses of symbolic and neural approaches, and suggest a framework for combining them. We demonstrate our framework's flexibility by modeling problems with diverse relations and rich representations, allowing us to focus on the abstractions needed to understand the relevant dependencies in each task. \DRAIL is designed to streamline this process and help alleviate reproducibility challenges.     Going forward, we will continue to explore ways to leverage representation, inference and learning, to gain insights into the challenges and opportunities that these hybrid approaches present us.   
"," In this paper, we offer a preliminary investigation into the task of in-image machine translation: transforming an image containing text in one language into an image containing the same text in another language. We propose an end-to-end neural model for this task inspired by recent approaches to neural machine translation, and demonstrate promising initial results based purely on pixel-level supervision. We then offer a quantitative and qualitative evaluation of our system outputs and discuss some common failure modes. Finally, we conclude with directions for future work.",265
" Transformer based models  have been proven to be very effective in building the state-of-the-art Neural Machine Translation  systems via neural networks and attention mechanism . Following the standard Sequence-to-Sequence architecture, Transformer models consist of two essential components, namely the encoder and decoder, which rely on stacking several identical layers, i.e., multihead attentions and position-wise feed-forward network.   Multihead attentions and position-wise feed-forward network, together as a basic unit,  plays an essential role in the success of Transformer models.  Some researchers  propose to improve the model capacity by stacking this basic unit many times, i.e., deep Transformers, and achieve promising results. Nevertheless, as an orthogonal direction, investigation over multiple parallel units draws little attention.   Compared with single unit models, multiple parallel unit layout is more expressive to capture complex information flow  in two aspects. First, this multiple-unit layout boosts the model by its varied feature space composition and different attentions over inputs. With this diversity, multi-unit models advance in expressiveness.  Second, for the multi-unit setting, one unit could mitigate the deficiency of other units and compose a more expressive network, in a complementary way.  In this paper, we propose the Multi-Unit TransformErs , which aim to promote the expressiveness of transformer models by introducing diverse and complementary parallel units. Merely combining multiple identical units in parallel improves model capability and diversity by its varied feature compositions. Furthermore, inspired by the well-studied bagging  and gradient boosting algorithms  in the machine learning field, we design biased units with a sequential dependency to further boost model performance.  Specifically, with the help of a module named bias module, we apply different kinds of noises to form biased inputs for corresponding units. By doing so, we explicitly establish information gaps among units and guide them to learn from each other.  Moreover, to better leverage the power of complementariness, we introduce sequential ordering into the multi-unit setting, % by learning a permutaion matrix  to automatically shuffle the outputs of multiple units,  and force each unit to learn the residual of its preceding accumulation.  We evaluate our methods on three widely used Neural Machine Translation datasets, NIST Chinese-English,  WMT'14 English-German and WMT'18 Chinese-English. Experimental results show that our multi-unit model yields an improvement of +1.52, +1.90 and +1.10 BLEU points, over the baseline model  for three tasks with different sizes, respectively.  Our model even outperforms the Transformer-Big on the WMT'14 English-German by 0.7 BLEU points with only 54\% of parameters.  Moreover, as an interesting side effect, our model only introduces mild inference speed decrease  compared with the Transformer-Base model, and is faster than the Transformer-Big model. % which proves the practicability of our methods.   The contributions of this paper are threefold:      In this work\footnotemark\footnotetext{ .}, we explored different ways in which trained models can be applied to improve AMR parsing performance via self-learning. Despite the recent strong improvements in performance through novel architectures, we show that the proposed techniques improve performance further, achieving new state-of-the-art on AMR 1.0 and AMR 2.0 tasks without the need for extra human annotations.        uncomment to redo bbl    
","     Transformer models \cite{vaswani2017attention} achieve remarkable success in Neural Machine Translation.      Many efforts have been devoted to deepening the Transformer by stacking several units  in a cascade,      while the investigation over multiple parallel units draws little attention.     In this paper, we propose the Multi-Unit TransformErs , which aim to promote the expressiveness of the Transformer by introducing diverse and complementary units.     Specifically, we use several parallel units and show that modeling with multiple units improves model performance and introduces diversity.      Further, to better leverage the advantage of the multi-unit setting, we design biased module and sequential dependency that guide and encourage complementariness among different units.      % need more results and exciting data.     Experimental results on three machine translation tasks, the NIST Chinese-to-English, WMT'14 English-to-German and WMT'18 Chinese-to-English, show that the MUTE models significantly outperform the Transformer-Base, by up to +1.52, +1.90 and +1.10 BLEU points, with only a mild drop in inference speed .      In addition, our methods also surpass the Transformer-Big model, with only 54\% of its parameters. These results demonstrate the effectiveness of the MUTE, as well as its efficiency in both the inference process and parameter usage. \footnote{Code is available at \url{https://github.com/ElliottYan/Multi\_Unit\_Transformer}}",266
"  %  %     Prior work primarily focused on exploiting visual patterns using carefully crafted features . These rendering-based methods have two major drawbacks: 1) they are expensive since they require downloading all external files including CSS, javascript, and images to render the page to compute visual features; 2) they require carefully crafted heuristics around visual proximity  to work well with these expensive features. In this paper, we propose a novel two-stage neural architecture, named FreeDOM, that can be trained on a small number of seed websites and generalize well to unseen websites without requiring any hand-engineered visual features. %we want to employ neural networks for learning transferable visual features such that we can eliminate the need of rendering and human engagement in crafting textual patterns. %We propose a novel two-stage neural architecture that can directly learn from a few annotated websites just based on their raw HTML content and transfer the models for unseen websites without using any human labels . %We parse HTML documents as DOM Trees of the page and classifies it into one of the target fields. This node-level module combines neighboring character sequences, token sequences, as well as markup  to learn a combined representation for the node. We propose a combination of CNNs and LSTMs and show that it can effectively encode useful features in DOM nodes.  These node representations are encoded individually and inevitably lose some global information useful for an extraction task. In particular, only relying on local node features can cause failure when value nodes have no obvious patterns themselves or their local features are very similar to other non-value nodes. To mimic the signal that may be available through visual features used in rendering-based methods,  we use a relational neural network as our second module . This allows us to model the relationship between a pair of elements using both distance-based and semantic features. The rationale behind this is to learn more global representations of node pairs so that we can jointly predict node labels instead of relying only on local features.   Extensive experimental results on a large-scale public dataset, the Structured Web Data Extraction  corpus, show that our model consistently outperforms competitive baseline methods by a large margin.  The proposed FreeDOM is able to generalize to unseen sites after training on a small number of seed sites. In fact, we show that with training data from just three seed sites, our approach out-performs techniques that use explicit visual rendering features by 3.7 F1 points on average. To the best of our knowledge, our framework is among the first neural architectures that efficiently obtains high-quality representations of web documents for structured information extraction.   \eat{Our framework utilizes minimal human efforts in feature engineering and does not require any rendering results, thus making large-scale information extraction on web documents much easier and more effort-light. We believe the proposed model can be promising in other applications that require neural representations of web documents.}  %The node-level module itself can predict node labels for identifying values of interested fields, but the encoded local features cannot capture the long-range dependencies between values and thus degenerate in unlabeled target websites. %To address this problem, we further propose a relational neural network. %As the second-stage module, it explicitly models the relations between DOM nodes and effectively learns the page-level constraints for producing structured predictions. % it models the relational features reflected by each node pairs, and finally conducts structured data extraction as a structured prediction problem.  %Our contributions in this paper are three-fold: %%  %}   %Our contribution is that we propose a novel neural model, FreeDom, for structured data extraction over web documents while using less information  and no hand-crafted features. Extensive experiments on a large-scale public data set  show that the proposed FreeDom outperforms other strong baseline methods while only using raw features. %%ying{The last sentence looks not complete. \yuchen{Done.}} %\tata{Don't say 'less information' emphasize that not requiring visual rendering is cheaper and not requiring hand-crafted features means you can generalize to new tasks better. Need to make this claim more focused so the contributions are clear. We also need to spell out the two stages more clearly 'First stage does blah', 'Second stage does blah'} %\tata{Might be worth adding that entity resolution is not in scope for this work -- ie, we might extract duplicate entries across websites for the same car. There are many papers dealing with that and we're not focused on that in this paper.} %   In this paper, we propose Multi-Unit Transformers for NMT to improve the expressiveness by introducing diverse and complementary units.  In addition, we propose two novel techniques, namely bias module and sequential dependency to further improve the diversity and complementariness among units.    We show that merely integrate several identical units can improve model performance and diversity. Furthermore, we introduce Biased Multi-Unit and Sequentially Biased Multi-Unit towards explicit guidance of interaction between units.     We evaluate our methods on two widely used NMT datasets. Experimental results show that our methods can significantly outperform the baseline methods and achieve comparable / better performance compared with existing strong NMT systems. In the meantime, our methods use much fewer parameters and only introduce mild inference speed degradation, which proves the efficiency of our models.        \clearpage   
"," % tata: Jan 26 rewrite of Abstract.  Extracting structured data from HTML documents is a long-studied problem with a broad range of applications like augmenting knowledge bases, supporting faceted search, and providing domain-specific experiences for key verticals like shopping and movies. Previous approaches have either required a small number of examples for each target site or relied on carefully handcrafted heuristics built over visual renderings of websites. In this paper, we present a novel two-stage neural approach, named FreeDOM, which overcomes both these limitations.  The first stage learns a representation for each DOM node in the page by combining both the text and markup information. The second stage captures longer range distance  and semantic relatedness using a relational neural network. By combining these stages, FreeDOM is able to generalize to unseen sites after training on a small number of seed sites from that vertical without requiring expensive hand-crafted features over visual renderings of the page. Through experiments on a public dataset with 8 different verticals, we show that FreeDOM beats the previous state of the art by nearly 3.7 F1 points on average without requiring features over rendered pages or expensive hand-crafted features. % 3.7 is from Table 2 k=3 .  % tata: Previous version of abstract follows:  %",267
"    Data-to-Text aims at generating natural language descriptions from structured data ; fostered by recent advances on neural approaches  and  %for data-to-text have been made possible by  the emergence of large scale datasets made of  pairs . Figure illustrates an example from the WikiBIO dataset . These datasets are either hand-crafted via crowdworkers or automatically built by aligning sources found on the Internet. As such, %training examples are imperfect reference texts might include divergences of two types, limiting the ability of generation models to produce realistic descriptions. First, reference texts might contain information not grounded in the source data;  especially for automatically constructed datasets, where references were not written with the source-data description task in mind. For instance, the phrase ``who served as lieutenant [...]'' in  Figure has no basis in the associated infobox. Second, reference texts do not always cover the entirety of the table . In most settings, this second point is referred to as content selection and is inherent of most data-to-text tasks. % and is part of the normal subtask flow of data-to-text. %; see for example Figure and information about wars.  %However, some hand-crafted datasets are designed such that annotators have been asked to transcribe every fields, and systems are also expected to do the same. In this case, incomplete references can lead models to fail to learn to transcribe all information, and only partially cover data-sources at inference. However, some hand-crafted datasets are designed where annotators are asked to transcribe every fields, with models also expected to do the same. In this case, incomplete references  can lead to models failing to learn to transcribe all information, and only partially cover data-sources at inference.   Divergence in training examples leads to hallucinated/omitted content in model output; which is a well-known problem in neural approaches for text generation . This problem arises both from the training procedure , and from the testing protocols. Indeed, current standard metrics only measure similarity  to ground truth reference texts and do not fully capture relevance to the source data. %Indeed, most evaluation metrics  work on computing precision of n-grams contained in the generated sentence w.r.t to the ground truth description.  Thus, there is no distinction between a mismatch caused by a paraphrase, poor lexicalization of content, or made-up/incorrect statement, leading to imperfect model selection. While a number of work argue for the need for novel automatic evaluation method , to the best of our knowledge only \citet{wiseman2017} and \citet{dhingra2019} propose metrics based on both the reference and the source data. %Additionally, \citet{dhingra2019} show that their proposed metric PARENT correlates more strongly with human evaluation than any other metric, while being easier to use out of the box.  Recently, different regularization methods have also been proposed to mitigate the negative influence of divergences in reference texts. These approaches can be either at the dataset level , where authors propose techniques to clean/standardize instances; or at the training level , where authors propose novel neural modules designed to limit hallucinations/omissions. However, these approaches are severely limited: e.g., they require significant annotation labor, model-specific tricks and/or manual tuning.   Furthermore, virtually all proposed neural approaches still suffer from 1)~exposure bias and 2)~inconsistency between train/test measurement. Indeed, current neural models are trained via a mechanism called teacher forcing , where the decoder is fed the previous correct token, no matter its actual prediction~, in order to maximize the log-likelihood of the target sentence , but are evaluated through the previously discussed n-gram metrics~. See Section for a more detailed discussion about this subject.\\  %On one hand, not controllable approaches have been proposed: for example, \citet{Liu2019hier} train a hierarchical encoder-decoder on three auxiliary tasks  which are meant to guide the decoding process, in order to achieve descriptions with higher fidelity with respect to the conditioning input.  To the best of our knowledge, there have been few approaches  focused on the training procedure. %We cite , where \citet{liu2019} train a hierarchical encoder-decoder on three auxiliary tasks  which are meant to guide the decoding process. %, in order to achieve descriptions with higher fidelity with respect to the conditioning input. Closest to our work, \citet{Liu2019b} propose a novel neural module for constrained attention, along with a reinforcement learning  training procedure based on BLEU and TFIDF. In our work, to remedy the above shortcomings and building upon the work of \citet{Liu2019b}, we show that no novel neural module is necessary to handle hallucinations and omissions. We propose a model-agnostic RL framework, called PARENTing, where pretrained models are further trained with a self-critical policy gradient algorithm  to limit the impact of divergences in training examples on text generation. Specifically, we use the PARENT metric   which exhibits a strong correlation with human evaluation, while being easier to use out of the box. We provide extensive automatic evaluations on two data-to-text model families  on two widely used benchmarks , as well as a more focused human evaluation %to high-light differences in several training procedures  on WikiBIO.  We report new state of the art PARENT scores on both datasets while BLEU scores are on par with previous SOTA approaches, which shows that our framework efficiently reduces pathological behaviors while keeping generation fluent.       %To remedy those shortcomings, we propose a model-agnostic reinforcement learning framework, called PARENTing, where pretrained models are further trained with a self-critical policy gradient algorithm  to limit the impact of divergences in training examples on text generation. % inspired by recent advancements in other text generation fields.  %Specifically, %we fine-tune pretrained models with a self-critical policy gradient algorithm  based on  %we use the PARENT metric   which exhibits a strong correlation with human evaluation, while being easier to use out of the box. We provide extensive evaluations on two data-to-text model families  on two widely used benchmarks . We report new state of the art PARENT scores on both datasets while BLEU scores are on par with previous approaches, which shows that our framework efficiently reduces pathological behaviors while keeping generation fluent.     %In the following, we first review in Section data-to-text approaches as well as the recent attempts at controlling hallucinations/omissions.  We then introduce in Section our model-agnostic framework limiting hallucinations/omissions in the generation. The evaluation protocol is presented in Section, followed by the obtained results . Section concludes the paper and presents perspectives.  %In the following, we first present a state-of-the art of attempts to reduce hallucinations and to address the exposure bias and inconsistencies in between train/test measurement in data-to-text literature . revoir la structure We then describe in details the PARENT metric from \citet{dhingra2019} in Section and the our proposed RL training framework in Section. The evaluation protocol is presented in Section, followed by the results . Section concludes the paper and presents perspectives.      In this paper, we propose a neural architecture for extracting structured data from web documents. It uses training data from only a few seed sites but generalizes well to other unseen websites in the same vertical. We show that our approach, , beats the previous state-of-the-art performance on a large-scale public dataset consisting of 8 different verticals  by nearly 3.7 F1 points. In particular, it does so without using any expensive rendering-based visual features.  We also discovered that typical sequence labeling techniques from NLP do not work well for this task and presented hypotheses for why that is the case.  We believe that this work opens up multiple avenues for future research in web data extraction. What structured prediction techniques might work better at incorporating information from farther away and work well on large DOM trees with sparse labels?  An even more interesting question is if we can transfer information across verticals? That is, if we are able to do well on one vertical, can we leverage that information somehow to train a model for the next vertical? Will there be a large pre-trained neural encoding model for HTML documents, just like BERT for plain texts?  We believe our work can be also useful for future research that needs to learn a more site-general neural representations for semi-structured documents including web pages, pdf files and so on.         The next two lines define the bibliography style to be used, and    the bibliography file.   \clearpage   \clearpage     \endinput         End of file `sample-authordraft.tex'.  
","  %The effectiveness of language generation models conditioned by structured data is inherently due to the quality of reference texts and the training protocol. First, these reference texts often diverge from the information contained in the associated source data . Second,  In language generation models conditioned by structured data, the classical training  via maximum likelihood almost always leads  models to pick up on dataset divergence , and to incorporate them erroneously in their own generations at inference.  %In this work, we propose a model-agnostic reinforcement learning framework in order to reduce hallucinations and omissions. To do so, we rely on the recently introduced PARENT metric assessing the adequacy of a candidate generation with both the human reference and the source data.  In this work, we build ontop of previous Reinforcement Learning based approaches and show that a model-agnostic framework relying on the recently introduced PARENT metric is efficient at reducing both hallucinations and omissions. Evaluations on the widely used WikiBIO and WebNLG benchmarks demonstrate the effectiveness of this framework compared to state-of-the-art models.",268
" Relation classification  aims to identify the relation between two specified entities in a sentence.  Previous supervised approaches on this task heavily depend on human-annotated data, which limit their performance on classifying the relations with insufficient instances. Therefore, making the RC models capable of identifying relations with few training instances becomes a crucial challenge. Inspired by the success of few-shot learning methods in the computer vision community ,  first introduce the few-shot learning to RC task and propose the FewRel %   dataset. % dataset as the benchmark. Recently, many works focus on this task and achieve remarkable performance .  %distant supervision  is proposed to automatically construct training instances for RC. %However, in the dataset extracted by distant supervision, some long-tail relations only have few instances and suffer from data sparsity problem. %Inspired by the success of few-shot learning  methods in the computer vision community, e.g., Matching Network , Relation Network  and Memory-augmented network ,  first introduce FSL to RC to tackle the long tail problem. They use the Prototypical Network , which achieves the state-of-the-art performance on several FSL benchmarks. Recently, many works followed their framework have achieved remarkable performance on the Few-shot RC dataset FewRel . %The prototypical network learns the representation  for each relation based on sampled instances, and then classifies the queries into a set of pre-defined relations. %\CheckedBox   % Even though the existing works perform well, they all assume that there is only one relation in a sentence.   Previous few-shot relation classifiers perform well on sentences with only one relation of a single entity pair. However, in real natural language, a sentence usually jointly describes multiple relations of different entity pairs. Since these relations usually keep high co-occurrence in the same context, previous few-shot RC models struggle to distinguish them with few annotated instances. For example, Table shows three instances from the FewRel dataset, where each sentence describes multiple relations with corresponding keyphrases highlighted  as evidence. When specified two entities  in the sentence, there is a great opportunity for the instance to be incorrectly categorized as a {\color{red}{confusing relation}}  instead of the {\color{blue}{true relation}} . % % Specifically,  %is that different entity pairs are usually described  in an input sentence, in which the relation classification of these entity pairs often interferes with each other. %This results in that the entity pairs of these relations are often misclassified into confusing relations by models without the ability of explicitly decoupling easily-confused relations. %Table shows three instances from the FewRel dataset , each of which contains a sentence with two given entities  on the right side, and its positive  and confusing relations  on the left side.  %Previous few-shot methods tend to misclassify these sentences into the confusing relations. the first instance should be categorized as the true relation `parents-child' based on the given entity pair and natural language  expression `a daughter of'. However, since it also includes the NL expression `his wife',  %which describes the confusing relation `husband-wife', it is probably misclassified into this confusing relation `husband-wife'. In this paper, we name it as a relation confusion problem.   %===============================================================================================  % \verb|\checkmark|: \checkmark \par % \verb|\cmark|: \cmark \par % \verb|\xmark|: \xmark   	{blue}} and {\color{red}{red}} words respectively correspond to true and confusing relations.} 	 		 \end{table} %============================================================================================== To address the relation confusion problem, it is crucial for a model to %  effectively select the information with high relevance to the given entity pair and  be aware of which NL expressions cause confusion and learn to avoid mapping the instance into its easily-confused relation. % To address the relation confusion problem, it is crucial for a model to be aware of which NL expressions cause confusion and how to explicitly distinguish the easily-confused relations.  From these perspectives, we propose two assumptions.  Firstly, in a sentence, words that keep high relevance to the given entities are more important in expressing the true relation. Intuitively, the specified entity information is crucial to identify the true relations.  Secondly, explicitly learning of mapping an instance into its confusing relation with augmented data in turn boosts a few-shot RC model on identifying the true relation. % allowing the model to explicitly learn the confusing relations can help it to identify the true relations. %Intuitively, the specific entities information is helpful to identify the positive relation.  Based on these assumptions, we propose CTEG, a few-shot RC model with two novel mechanisms:  An Entity-Guided Attention  encoder, which leverages the syntactic relations and relative positions between each word and the specified entity pair to softly select important information of words expressing the true relation and filter out the information causing confusion.  A Confusion-Aware Training  method, which explicitly learns to distinguish relations by playing a pushing-away game between classifying a sentence into a true relation and its confusing relation. %has the ability of explicitly learning to distinguish easily-confused relations. In addition, inspired by the success of pre-trained language models, our approaches are based on BERT , which has been proved effective especially for few-shot learning tasks. %===========================================================================   % Specifically, when encoding a sentence by the attention mechanism, our EGA guides the calculation of the attention score through multiply it by an entity-aware gate. %we adopt the transformer incorporating with a self-attention mechanism to encoding an input instance,  Specifically, the backbone of the encoder of our model is a transformer equipped with the proposed EGA which guides the calculation of self-attention distributions by weighting the attention logits with entity-guided gates. % The gate is a matrix of relevance scores, which are used to measure the importance of each word according to its relevance to the entities. % The gates are used to measure the importance of each word according to its relevance to the entities. The gates are used to measure the relevance between each word and the given two entities. % Two types of position information of the words are used to calculate the scores. One of them is the relative position , which is the relative distance between a word and an entity in the sentence squence. Two types of information for each word are used to calculate its gate. % One of them is the relative position , which is the relative distance between a word and an entity in the sentence squence. One is the relative position  information, which is the relative distance between a word and an entity in the input sequence. The other is syntactic relation which is proposed in this paper, defined as the dependency relations between each word and the entities. % Besides, we further propose the syntax position, defined as the dependency relations between each word and the entities. Based on these information, the entity-guided gates in EGA are able to select those important words and control the contribution of each word in self-attention. % Based on these information, the entity-aware gate in EGA is able to select those important words and control the contribution of each word in the self-attention.    % For the proposed CAT, it allows the model to and asynchronously learn the confusing relations for each sentence. After each training step, the CAT first selects those misclassified sentences, and regards the relations they are misclassified into as the confusing relations. After that, The CAT uses these misclassified sentences and their confusing relations to conduct an additional training process, which aimes to learn the confusing relations explicitly.  We also propose CAT to explicitly force the model to asynchronously learn the classification from an instance to its true relation and its confusing relation. After each training step, the CAT first selects those misclassified sentences, and regards the relations they are misclassified into as the confusing relations. After that, The CAT uses these misclassified instances and their confusing relations as augmented data to conduct an additional training process, which aims to learn the mapping between these instances into the confusing relations.  % After that, The CAT uses these misclassified sentences and their confusing relations to  conduct an additional training process, which aims to learn the confusing relations explicitly.  Afterwards, the CAT adopts the KL divergence to teach the model to distinguish the difference between the true and confusing relations, which benefits the true relation classification from the confusing relation identification.  % Extensive experiments are conducted on the FewRel dataset, and the results show that our proposed model achieves comparable and even better results to strong baselines in terms of accuracy. % Furthermore, ablation test and case study verify the effectiveness of our proposed EGA and CAT, especially in addressing the relation confusion problem.  The contributions of this paper are summarized as follows:   We propose an Entity-Guided Attention encoder, which can select crucial words and filter out NL expressions causing confusion based on their relevance to the specified entities.    We propose a Confusion-Aware Training process to enhance the model with the ability of distinguishing true and confusing relations.   We conduct extensive experiments on few-shot RC dataset FewRel, ans the results show that our model achieves comparable and even much better results to strong baselines. Furthermore, ablation and case studies verify the effectiveness of the proposed EGA and CAT, especially in addressing the relation confusion problem.     In this work, we have proposed a model-agnostic reinforcement learning framework for data-to-text aimed at reducing hallucinations and improving recall/coverage of relevant information. We shaped the reward based on PARENT , which is a recently proposed metric with a high correlation with human judgement.  on a number of datasets.   This   training protocol allows for a more flexible training, where the model learns to depend less on the reference and more on the source data. Framework effectiveness is assessed via thorough experiments on two model family  and two benchmarks .   In particular, we showed that further training using the proposed framework led to models to learn non-trivial behavior, like shortening generation when the pretrained models would still output  content, or on the contrary adding relevant information from the table that were missed by the pretrained models. Furthermore, quantitative and qualitative evaluations show that our PARENTing framework   help models to reduce both hallucinated and omitted content. This approach  obtains better results than a dedicated attention module or a less source-relying reward.  .    However, this framework relies on the quality of the metric employed during training, and crafting an effective metric is still an open problem. In particular, the PARENT metric was designed specifically for datasets like WikiBIO and WebNLG,  in which values are linguistic sequences associated with a single entity and explicit semantic fields.     This  avoids possible confusion to which value is associated to which field.   However, such a metric is not reliable for more complex datasets \citet{wiseman2017,puduppully2019}. For instance, in RotoWire , tables report statistics of basketball games and regroup several entities of the same nature. In this setting, the sentence ``James Harden scored 20 points'' could achieve a high PARENT score if any player had scored  points in the game.  Therefore, the information-retrieval metrics introduced by \citet{wiseman2017} are still the only metric able to capture precision of generated texts. However, they are based on manually tuned pattern-matching and computed using an ensemble of six deep neural network: they are specific to RotoWire and are in practice not usable in a realistic training protocol.    For future work, we plan to  propose an evaluation metric more robust to dataset peculiarities with the final objective to evaluate our model-agnostic framework on  more complex and challenging datasets. Once such a metric devised, it would be interesting to apply the framework on more challenging settings which ask for more in-depth reasoning.  However, this approach relies on the metric employed and crafting an effective metric is still an open problem. In particular, PARENT is designed for single-entity datasets, like WikiBIO and WebNLG,  However, this framework relies on the quality of the metric employed during training, and crafting an effective metric is still an open problem. In particular, the PARENT metric was designed specifically for datasets relating a single entity and explicit semantic fields, like WikiBIO and WebNLG.    in which values are linguistic sequences associated with a single entity and explicit semantic fields.   This  avoids possible confusion to which value is associated to which field. which is not reliable for more complex datasets   reporting heterogeneous data and/or  containing multiple entities  , as seen in basketball games  . In this setting, the sentence ``James Harden scored 20 points.'' could achieve a high PARENT score if any player had scored  points in the game.  Therefore, the information-retrieval metrics introduced by \citet{wiseman2017} are still the only metric able to capture precision of generated texts. However, they are based on manually tuned pattern-matching and computed using an ensemble of six deep neural network: they are specific to RotoWire and are in practice not usable in a realistic training protocol.  An interesting future work would be the design of an evaluation metric more robust to dataset peculiarities.   with the final objective to evaluate our model-agnostic framework on  more complex and challenging datasets.   Once such a metric devised, it would be interesting to apply the framework on more challenging settings which ask for more in-depth reasoning.  
"," This paper aims to enhance the few-shot relation classification especially for sentences that jointly describe multiple relations. Due to the fact that some relations usually keep high co-occurrence in the same context, previous few-shot relation classifiers struggle to distinguish them with few annotated instances. To alleviate the above relation confusion problem, we propose CTEG, a model equipped with two mechanisms to learn to decouple these easily-confused relations. On the one hand, an Entity-Guided Attention  mechanism, which leverages the syntactic relations and relative positions between each word and the specified entity pair, is introduced to guide the attention to filter out information causing confusion. On the other hand, a Confusion-Aware Training  method is proposed to explicitly learn to distinguish relations by playing a pushing-away game between classifying a sentence into a true relation and its confusing relation. Extensive experiments are conducted on the FewRel dataset, and the results show that our proposed model achieves comparable and even much better results to strong baselines in terms of accuracy. Furthermore, the ablation test and case study verify the effectiveness of our proposed EGA and CAT, especially in addressing the relation confusion problem.",269
"    % The following footnote without marker is needed for the camera-ready % version of the paper. % Comment out the instructions  and uncomment the 8 lines % under ""final paper"" for your variant of English.  .          % final paper: en-us version           %   % space normally used by the marker     % This work is licensed under a Creative Commons      % Attribution 4.0 International License.     % License details:     % \url{http://creativecommons.org/licenses/by/4.0/}. }    Complaining is a basic speech act, usually triggered by a discrepancy between reality and expectations towards an entity or event. Social media has become a popular platform for expressing complaints online  where customers can directly address companies regarding issues with services and products. Complaint detection aims to identify a breach of expectations in a given text snippet. However, the use of implicit and ironic expressions and accompaniment of other speech acts such as suggestions, criticism, warnings and threats make it a challenging task. Identifying and classifying complaints automatically is important for:  improving customer service chatbots;   linguists to analyze complaint characteristics on large scale ; and  psychologists to understand the behavior of humans that express complaints.  Previous work has focused on binary classification between complaints and non-complaints in various domains. Furthermore, some studies have performed more fine-grained complaint classification. For instance, complaints directed to public authorities have been categorized based on their topics or the responsible departments. Other categorizations are based on possible hazards and risks as well as escalation likelihood. Most of these previous studies have used supervised machine learning models with features extracted from text  or task-specific neural models trained from scratch. Adapting state-of-the-art pre-trained neural language models based on transformer networks such as BERT and XLNet has yet to be explored.    In this paper, we focus on the binary classification of Twitter posts into complaints or not \shortcite{preotiuc2019automatically}. We adapt and evaluate a battery of pre-trained transformers which we subsequently combine with external linguistic information from topics and emotions.   \paragraph{Contributions}  New state-of-the-art results on complaint identification in Twitter, improving macro FI by 8.0\% over previous work by  Preotiuc-Pietro et al. \shortcite{preotiuc2019automatically};  A qualitative analysis of the limitations of transformers in predicting accurately whether a given text is a complaint or not.       We show how to use LRP to evaluate the relative contributions of source and target to NMT predictions. We illustrate the potential of this approach by analyzing changes in these contributions when conditioning on different types of prefixes , when varying training objectives or the amount of training data, and during the training process. Some of our findings are: ~models trained with more data rely on source information more and have more sharp token contributions; ~the training process is non-monotonic with several distinct stages. These stages agree with the ones found in previous work focused on validating the lottery ticket hypothesis, which suggests future investigation of this connection.  Additionally, we show that models suffering from exposure bias are more prone to over-relying on target history  than the ones where the exposure bias is mitigated. In future work, our methodology can be used to measure the effects of different and novel training regimes on the balance of source and target contributions.  
","    Complaining is a speech act extensively used by humans to communicate a negative inconsistency between reality and expectations. Previous work on automatically identifying complaints in social media has focused on using feature-based and task-specific neural network models. Adapting state-of-the-art pre-trained neural language models and their combinations with other linguistic information from topics or sentiment for complaint prediction has yet to be explored. In this paper, we evaluate a battery of neural models underpinned by transformer networks which we subsequently combine with linguistic information. Experiments on a publicly available data set of complaints demonstrate that our models outperform previous state-of-the-art methods by a large margin achieving a macro F1 up to 87.",270
" 	\com{ 		Remember to recheck: 		intro 		each section place is clear 		reiterate paragraph 		 		structure: 		taxonomy explained 		validations of our taxonomy+classification  		comparison to other taxonomies /classifications   		proof of usefulness 		various kinds of analysis this allows  		qualitative results and discussion 		related work 		conclusion 	} 	Taxonomies of grammatical errors are important for linguistic and computational analysis of learner language, as well as for Grammatical Error Correction  systems.\footnote{Code can be found \href{https://github.com/borgr/GEC_UD_divergences}{in github repo GEC\_UD\_divergences}. Matrices directly mentioned are included in the appendix.} 	Such taxonomies divide the complex space of errors into meaningful categories and enable characterizing their distribution in learner productions. This information can be beneficial for GEC: it can support the development of systems that focus on specific error types, serve as a form of inductive bias , and guide data augmentation and data filtering by controlling the distribution of error types. Error taxonomies can also improve the interpretability of system outputs for error analysis and learner feedback. 	 	%  	%  	% \end{small} 	% \end{table} 	 	 	 	 	 	A number of annotation efforts for learner language developed error taxonomies , and statistical classifiers into such taxonomies, notably ERRANT . Taking error types into consideration in learning has also been shown to improve GEC performance \citep[][{cf.  \S}]{kantor2019learning}. 	However, most existing taxonomies are fairly coarse-grained and language specific, and do not produce meaningful types for a large proportion of the errors. For example, 25\% of the errors in the standard NUCLE corpus  are mapped to the residual category OTHER . 	 	We propose \secl, a taxonomy of Syntactic Errors  and an automatic Classification. Inspired by a longstanding tradition in Machine Translation  which analyses divergences between source and translated texts based on syntactic structure , \secl\ is based on divergences between ungrammatical sentences and their corrections. 	We define SEs as errors whose correction involves changing morphological features, POS labels or the syntactic structure labels. \secl\ takes as input edits, i.e., grammatically incorrect text spans and their corrections, and compares their labels. For example, the error in Fig.  is an adjective replaced with an adverb  in POS terms, and an \ra in edge-label terms. Thus, SEs are defined by changes in form, rather than by the principles governing the choice of a correct form. 	 	\secl\ is the first taxonomy derived from a syntactic representation framework, and it uses the Universal Dependencies formalism \citep[UD;][]{nivre2016universal}.  	This approach provides three major advantages over prior learner error taxonomies. First, the \secl\ taxonomy is derived automatically from UD annotations, circumventing the need for constructing ad-hoc manually defined error categories. Second, using the UD formalism makes the method applicable across languages, allowing for consistent analyses and comparisons of learner errors across different languages within one unified framework. Third, \secl\ is compatible with standard representations and tools in NLP.  	 	Further, the UD based approach to error classification can yield finer distinctions compared to existing schemes. For example, it divides the commonly used class of adposition errors into errors in the use of prepositions as nominal modifiers , and the use of prepositions in prepositional objects or adjuncts .  	%prepositions involving verbal arguments  and errors involving spatial/temporal relations.\oa{how exactly? maybe we should say we distinguish between NP-internal PPs and clause-level PPs?} \lc{One would be obj something and the other will not . Isn't what is an object and subject a main thing syntax allows?, you can write another example. Note that the example should involve a type not usually split . }  	POS tags alone cannot distinguish them, but the UD trees expose this distinction straightforwardly. UD can also help classify agreement and case-assignment errors thanks to its morphological-feature layer containing information about case, number, gender, and other features relevant for inflection. 	 	 	We validate \secl's reliability by showing  SEs based on automatic parses are similar to ones based on manual parses.  ;  \secl\ types map well to NUCLE's manually curated taxonomy ;  \secl\ is complementary to the standard type classifier ERRANT: 60\% of the errors not classified by ERRANT are classified by \secl. 	 	We demonstrate \secl's unique features, notably cross-linguistic applicability, by analyzing SE distributions in available corpora for learner English  and learner Russian . 	 	Finally, we find in GEC systems  certain SEs are harder to correct  SEs are harder than non-SEs   the granular types can help devising rules to improve products . 	 	%\lc{yb, I gave it a try, is that better? Am I being too general?} 	 	%We validate the accuracy of relying on parsing technology  and compare \secl\ to manual  and automatic taxonomies , finding that \secl\ classifies 60\% of the errors not covered by by the leading error classifier for English ERRANT . We further examine its characteristics by using UD features and by applying it to Russian . All these findings suggest that \secl\ is a reliable, fine-grained annotation which is the only current taxonomy and classifier that is not language specific. To show its wide applicability, we use \secl\ to provide a detailed picture of the distribution of SEs in various learner English corpora . We proceed to use \secl\ to detect trends in error type distribution across learner levels . We conclude by analyzing system outputs .\yb{many people skip these paper summary paragraphs. I would instead have a list of contributions as bullet points .} 	 	 	%  	%While classifying grammatical error types . In this paper we focus on syntactic errors, i.e., errors that require changing the tree structure to fix, and  	 	 	 	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 	  In this paper, we have proposed Token Drop mechanism for neural machine translation task. Inspired by self-supervised learning, we introduced Replaced Token Detection and Dropped Token Prediction training objective. We found that NMT model trained with Token Drop gains larger generalization capacity and reduction in overfitting. Even without prior knowledge and additional parameters, our proposed approach reports convincing results on neural machine translation. In future work, we plan to investigate impact of dropping on different words, e.g. word importance and word type.   
"," 		We present a method for classifying syntactic errors in learner language, namely errors whose correction alters the morphosyntactic structure of a sentence. 		The methodology builds on the established Universal Dependencies syntactic representation scheme, and provides complementary information to other error-classification systems.  		Unlike existing error classification methods, our method is applicable across languages, which we showcase by producing a detailed picture of syntactic errors in learner English and learner Russian. We further demonstrate the utility of the methodology for analyzing the outputs of leading Grammatical Error Correction  systems.",271
"  % Second, is a NMT model's ability to handle streaming ASR output; an ASR system provides the best greedy recognition  from a live speech's segmented audio. % we don't really talk about that ^ %deleted simultaneous With the advance of Automatic Speech Recognition  and Neural Machine Translation  systems, speech translation has become increasingly feasible and has received considerable attention.  However, researchers have encountered many challenging problems within the standard cascaded framework where ASR system outputs are passed into NMT systems. First, since NMT models are often trained with clean, well-structured text, the disfluency of spoken utterances and the recognition errors from ASR systems are not modeled by the NMT systems.  Second, people speak differently than they write, which results in changes in both sentence structure and meaning.  Third, automatically predicting sentence boundaries is challenging.  Taken as a whole, poorly segmented sentences with incorrect word recognition leads to poor translations.  These problems pose unique challenges for ASR NMT robustness that are not readily addressed by current methods. %  %\subsection{Related Work} % Current approaches to robust NMT with noisy inputs typically focus on improving word transcription through data augmentation techniques. Such methods include disfluency removal where redundant and unnecessary words are removed before translating the transcript, domain adaptation where NMT models are augmented with in-domain training data, and synthetic noise, where random edits are made to training data.   %  % \footnotetext{When compared to Table , the sum of System/System with transcript and segmentation degradation surpasses the Gold/Gold evaluation by 0.57 BLEU points. This is because the modifications to the evaluation data are not directly additive, ie .}  % %\subsection{Contributions} % % Although data domain and segmentation issues are often tackled separately, we find their compounded effects, namely erroneous transcript sentence boundaries, are neglected and substantially detrimental to final translation quality.  % As such, our contributions are two fold, we analyze the impact of noisy ASR segmentations on translation and propose an easily adaptable and simple data augmentation strategy to increase NMT robustness. % this sentence can be optional In our experimentation, we found that ASR system punctuation is often imperfect. It may omit or insert sentence-final punctuation, resulting in sentences that are erroneously compounded or fragmented.  While this is corroborated by similar works, which note that degradation of translation is caused by poor system sentence boundary prediction, they do not specifically evaluate, quantify, and address this issue. % should we mention how much sentence boundaries degrade accuracy % Find an example? To tackle the sentence boundary problem, we propose a simple scheme to augment NMT training data, which yields +1 BLEU point on average. % Similar to , we first ascertain that a NMT model can implicitly learn target punctuation from unpunctuated source text, even with noisy imperfect sentence boundaries. % is this sentence above necessary?^ %We show that with a simple data augmentation scheme on both general and in-domain NMT training data, we can achieve an improvement of  and  BLEU for tst2015 and tst2018 respectively.  This procedure is agnostic to ASR systems and can be applied to any NMT model training easily.  %    In this research, we have shown that the use of stacking model using neural network and xgboost makes it able to get a high score on the Ukara 1.0 challenge dataset. We also propose to use SMOTE and TPE to handle some problems in automatic short answer scoring and also improve the model performance. The model we produced received a combined F1 score of 0.821, better than previously published methods. From the results we obtained, it can be seen that there is still a big difference between F1 Score in question A and question B. This could be due to the different characteristics of the questions. In future research, it can be explored to use different features or methods for each question. Furthermore, it can also be explored the use of multi-task learning methods that train the model for all questions at the same time.  
"," Neural Machine Translation  models have demonstrated strong state of the art performance on translation tasks where well-formed training and evaluation data are provided, but they remain sensitive to inputs that include errors of various types. Specifically, in the context of long-form speech translation systems, where the input transcripts come from Automatic Speech Recognition , the NMT models have to handle errors including phoneme substitutions, grammatical structure, and sentence boundaries, all of which pose challenges to NMT robustness.  %This paper makes two main contributions via an in-depth error analysis and a proposed solution.  Through in-depth error analysis, we show that sentence boundary segmentation has the largest impact on quality, and we develop a simple data augmentation strategy to improve segmentation robustness.",272
" Automatic summarization is the automated process of reducing the size of an input text while preserving its most relevant information content and its core semantics. Techniques for summarization are often characterized as being either: Extractive or Abstractive. Extractive methods construct summaries by combining the most salient passages  of a source text; a process similar to human's way of identifying the right information. One way to achieve extractive summarization is to define the problem as a sentence classification task, using some form of  representation of the sentences in a document . To avoid content overlap issues, previous work has used sentence reranking  or sentence ordering by extracting sentences recurrently . Abstractive methods generate summaries by generating new sentence constructs ``from scratch'', or from representation of document content, a process that is conceptually more similar to the notion of paraphrasing. Abstractive text summarization has attracted interest since it is capable of generating novel formulations of summaries using language generation models conditioned on the source text. Several attention-based Recurrent Neural Network  encoder-decoders have been introduced to tackle varying text generation issues of standalone abstractive sequence-to-sequence  models. Copy and pointer mechanisms , for example, have enabled decoders to better generate unseen words, out-of-vocabulary words and named entities.   Most recently, hybrid extractive and abstractive architectures have been proposed and have shown promising results in both quantitative performance measures and human evaluations. In such set-ups, the extractive model first selects salient sentences from a source article, and the abstractive model paraphrases the extracted sentences into a final summary. The majority of current state-of-the-art abstractive summarization models\footnote{Excluding summarization models using large scale pre-trained language models such as BERT } are based on the hybrid approach .  Nonetheless, hybrid models can be limited by three disadvantages. First, since ground-truth labels for extractive summarization are usually not provided, extractive labels must be generated by a potentially suboptimal algorithm . The performance of models trained with such labels is therefore bounded by the quality of the performance of the extractive heuristics. Second, since ground-truth binary labels for recurrently extracted sentences are typically teacher forced as in \citet{chen-bansal-2018-fast}, ``exposure bias''  may negatively affect content selection performance at inference. Finally, given that the hard extraction step is not differentiable, existing hybrid models typically require multi-step training   or reinforcement learning  to train the whole model.  In this paper, we introduce a novel abstractive summarization model that incorporates an intermediate extractive step but does not require labels for this type of extractive content selection, and it is fully end-to-end trainable. To achieve this, we propose a new memory augmented encoder-decoder  architecture  called Mem2Mem. Mem2Mem has 2 memorization modes:  absorb key information of the encoded source sequence via a compression mechanism, and  sequentially update the external memory during target summary generation. Without using extractive ground-truth labels, we find in our analysis that Mem2Mem's compression mechanism behaves as an implicit sentence extractor that stores sentence representations of the salient content. The choice of sentence representations is only guided by the memory regularization and conditional language modeling loss of the decoder, thus avoiding exposure bias from maximizing the likelihood of sequential binary extraction labels. Finally, the encoded memory is transferred to the decoder memory, which is iteratively refined during the decoding process. To our knowledge, Mem2MeM is the first abstractive summarization model that uses memory compression for sentence extraction and that directly employs the memorized representations during summary generation. We empirically demonstrate the merits of this approach by setting a new state-of-the-art on long text abstractive summarization tasks on the Pubmed, arXiv and Newsroom datasets . Our contributions are three fold:   % fig_architecture       We propose that sentence boundary errors are a neglected area of study for NMT robustness, especially in the context of speech translation.  We quantitatively demonstrate that poor sentence segmentation degrades performance almost twice as much as transcript level-errors.  To address this, we developed a simple method for data augmentation with immediate gains that can serve as a baseline for future work in segmentation NMT robustness.    Given the simplicity and ease of adaptation into existing systems, we hope to integrate our approach into production systems.  \vfill\pagebreak     References should be produced using the bibtex program from suitable   BiBTeX files . The IEEEbib.bst bibliography   style file from IEEE produces unsorted bibliography list.   ------------------------------------------------------------------------- 
"," We introduce Mem2Mem, a memory-to-memory mechanism for hierarchical recurrent neural network based encoder decoder architectures and we explore its use for abstractive document summarization. Mem2Mem transfers ``memories"" via readable/writable external memory modules that augment both the encoder and decoder. Our memory regularization compresses an encoded input article into a more compact set of sentence representations. Most importantly, the memory compression step performs implicit extraction without labels, sidestepping issues with suboptimal ground-truth data and exposure bias of hybrid extractive-abstractive summarization techniques. By allowing the decoder to read/write over the encoded input memory, the model learns to read salient information about the input article while keeping track of what has been generated.  Our Mem2Mem approach yields results that are competitive with state of the art transformer based summarization methods, but with 16 times fewer parameters. %On abstractive long text summarization, Mem2Mem surpasses, with full end-to-end training, the current state-of-the-art by 3.98 and 3.08 average ROUGE scores on the Pubmed and arXiv datasets while using $16$ times less parameters.  % Our code and trained models are available at \url{https://github.com/anonymously999/mem2mem}.",273
"  Attention-based encoder-decoder modeling is a natural and powerful paradigm for speech to text tasks, such as automatic speech recognition  and speech translation , and that has led to significant progress .  However, it relies on large amounts of supervised speech data, which is expensive to transcribe and translate.  In addition, the amount of speech transcripts and speech translation labels is dwarfed by the amount of text data available for language model  and machine translation  training. For example, the number of text tokens used for LM modeling is two orders of magnitude larger than the number of tokens from the corresponding speech corpus in the Librispeech data corpus, as shown in Table.    Attention-based encoder-decoder models are not designed to incorporate heterogeneous inputs and cannot benefit from large amounts of low cost text data directly in speech applications. As expected, performance gaps can still be observed between attention based encoder-decoder systems and conventional systems with multiple components.  %Short description about previous work In order to alleviate the data scarcity issue, different approaches have been studied, including acoustic and linguistic aspects.  %In this study, we focus on leveraging text data to improve linguistic modeling ability in speech to text systems.  LM is the most commonly used method to integrate linguistic information into ASR.  Prior work focuses on building LM with monolingual text data, and then integrate LM or transfer knowledge from it into the decoder.    generate synthetic data from text to augment speech training corpus. Another direction is to leverage text data directly during training through multitask learning.  use a common representation space to learn correspondences between different modalities for spoken language understanding.  propose multi-modal data augmentation to jointly train text and speech for ASR.  %is reminiscent of work done on multimodal learning or spoken language understanding  that also uses a common representation space to learn correspondences between different modalities.  are focused on ST tasks and trained with an ASR system together, where ASR is used as an auxiliary task. Hence, those methods cannot be applied back to ASR systems.  %What is proposed, describe the main idea %We follow the second direction and propose using auxiliary text tasks to enhance speech to text tasks. In this study, we focus on leveraging text data to improve linguistic modeling ability in speech to text tasks. We propose a general framework to leverage text data for ASR and ST tasks.  %Two encoders take text and speech as input respectively,  while the decoder is shared between tasks. During inference, only the speech encoder and decoder are used. A denoising autoencoder task  is introduced to be jointly trained with the ASR task with monolingual data, while a machine translation task is co-trained with  ST task  with  parallel  data. Text  input  is  represented  as  spoken form using phoneme sequence and it effectively reduces the difference between speech input and text input. We also carefully study different design choices for the joint training system, including strategies to share the text and speech encoders and comparing the joint training system with models initialized from pre-trained components.   Our experiments show the proposed joint training systems can effectively reduce word error rate  for the ASR task by 10\% to 15\% and improve BLEU score by 3.69.2 for ST tasks.  %Compared with previous methods, our method emphasizes reducing the difference between the two encoders and eases the knowledge transfer between the text to text and the speech to text tasks. %The method includes three parts: first, the representation difference from text and speech input is minimized through phoneme sequence representation and an additional speech end of sentence token. Second, a novel cross attentive loss is proposed to increase the similarity between sequences with different lengths. It acts as an auxiliary loss to regularize the outputs from two encoders. Third,  %masking is applied to input text tokens to simulate the adverse conditions in speech, such as noise and incomplete pronunciation. It also encourages the decoder to learn better language context representation to fill the gap due to masking.   %Instead of focusing on one particular task as in previous work, our method can be applied to both ASR and ST tasks. Experiments are conducted on two popular ASR and ST benchmark tasks. The results show the proposed method brings substantial gains over the baseline in both ASR and ST tasks.     This work proposes Mem2Mem, a novel MAED based mechanism for very long text abstractive summarization. Mem2Mem involves two memory types: A static encoder memory for compressing input texts and a dynamic decoder memory which refines the generation process. Memory transfer between them links two memories and maximizes the benefit of content extraction aimed for summarization. Different from existing hybrid extractive and abstractive approaches, Mem2Mem incorporates an extraction step without ground truth sentence labels and multi-step training. We demonstrate the effectiveness of Mem2Mem by showing promising results on the PubMed, arXiv, and Newsroom summarization datasets with an order of magnitude less parameters than competing transformer-based models. The Mem2Mem's memory compression can be generalized to other domains that require text generation guided by content selection. In future work, we will extend and validate the strength of our approach on a variety of language learning tasks.       
"," Attention-based sequence-to-sequence modeling provides a powerful and elegant solution for applications that need to map one sequence to a different sequence.  Its success heavily relies on the availability of large amounts of training data.  This presents a challenge for speech applications where labelled speech data is very expensive to obtain, such as automatic speech recognition  and speech translation .  In this study, we propose a general multi-task learning framework to leverage text data for ASR and ST tasks. Two auxiliary tasks, a denoising autoencoder task and machine translation task, are proposed to be co-trained with ASR and ST tasks respectively.  We demonstrate that representing text input as phoneme sequences can reduce the difference between speech and text inputs, and enhance the knowledge transfer from text corpora to the speech to text tasks.  Our experiments show that the proposed method achieves a relative 10$\sim$15\% word error rate reduction on the English Librispeech task compared with our baseline, and improves the speech translation quality on the MuST-C tasks by 3.6$\sim$9.2 BLEU.",274
" Motivated by the process of human inquiry and learning, the field of question generation  requires a model to generate natural language questions in context. QG has wide applicability in automated dialog systems, language assessment, data augmentation, and the development of annotated data sets for question answering  research.    Most prior research on QG has focused on generating relatively simple factoid-based questions, where answering the question simply requires extracting a span of text from a single reference document. However, motivated by the desire to build NLP systems that are capable of more sophisticated forms of reasoning and understanding, there is an increasing interest in developing systems for multi-hop question answering and generation , where answering the questions requires reasoning over the content in multiple text documents .  Unlike standard QG, generating multi-hop questions requires the model to understand the relationship between disjoint pieces of information in multiple context documents.  Compared to standard QG, multi-hop questions tend to be substantially longer, contain a higher density of named entities, and---perhaps most importantly---high-quality multi-hop questions involve complex chains of predicates connecting the mentioned entities   To address these challenges, existing research on multi-hop QG primarily relies on graph-to-sequence  methods. These approaches extract graph inputs by augmenting the original text with structural information  and then apply graph neural networks  to learn graph embeddings that are then fed to a sequence-based decoder.  However, the necessity of these complex G2S approaches---which require designing hand-crafted graph extractors---is not entirely clear, especially when standard transformer-based sequence-to-sequence  models already induce a strong relational inductive bias. Since transformers have the inherent ability to reason about the relationships between the entities in the text, one might imagine that these models alone would suffice for the relational reasoning requirements of multi-hop QG.   \xhdr{Present work} In this work, we show that, in fact, a standard transformer architecture is sufficient to outperform the prior state-of-the-art on multi-hop QG.  We also propose and analyze a graph-augmented transformer ---which integrates explicit graph structure information into the transformer model. GATE sets a new state-of-the-art and outperforms the best previous method by 5 BLEU points on the HotpotQA dataset. However, we show that the gains induced by the graph augmentations are relatively small compared to other improvements in our vanilla transformer architecture, such as an auxiliary contrastive objective and a data filtering approach, which improve our model by 7.9 BLEU points in ablation studies.  Overall, our results suggest diminishing returns from incorporating hand-crafted graph structures for multi-hop reasoning and provides a foundation for stronger multi-hop reasoning systems based on transformer architectures.    Our key contributions are summarized as follows:  We hope that our work provides a strong foundation for future research on multi-hop QG while guiding the field towards the most promising avenues for future model improvements.\documentclass[11pt,a4paper]{article}  \usepackage[hyperref]{emnlp2020}   \usepackage{times}     \usepackage{latexsym} \renewcommand{\UrlFont}sachande@mila.quebec, wuli@us.ibm.com  \usepackage{microtype}  \aclfinalcopy % Uncomment this line for the final submission  \usepackage[utf8]{inputenc} % allow utf-8 input \usepackage[T1]{fontenc}    % use 8-bit T1 fonts \usepackage{url}            % simple URL typesetting \usepackage{booktabs}       % professional-quality tables \usepackage{amsfonts}       % blackboard math symbols \usepackage{amsmath} \usepackage{nicefrac}       % compact symbols for 1/2, etc. \usepackage{graphicx} \usepackage{microtype}      % microtypography \usepackage{tabularx} \usepackage{xcolor} \usepackage{bbm} \usepackage{array} \usepackage{arydshln} \usepackage{amsfonts} \usepackage{amsmath} \DeclareMathOperator*{\argmax}{arg\,max} \DeclareMathOperator*{\argmin}{arg\,min} \usepackage{bbm} \usepackage{boldline} \usepackage{bigstrut} \usepackage{blindtext} \usepackage{booktabs, siunitx} \usepackage[labelfont=bf, format=plain, justification=justified, singlelinecheck=false]{caption} \usepackage{color} \usepackage{cprotect} \usepackage{ctable} \usepackage{dirtytalk} \usepackage{enumitem} \usepackage[export]{adjustbox} \usepackage{float} \usepackage{graphicx} \usepackage{hhline} \usepackage{latexsym} \usepackage{mathrsfs} \usepackage{microtype} \usepackage{moresize} \usepackage{multicol} \usepackage{multirow} \usepackage{nccmath} \usepackage{nicefrac} \usepackage{pifont} \usepackage{placeins}     \setlength\bigstrutjot{3pt} \usepackage{soul} \usepackage{subcaption} \usepackage{times} \usepackage[utf8]{inputenc} \usepackage{url} \usepackage{verbatim} \usepackage{wrapfig, lipsum} \usepackage{textcomp} \usepackage{enumitem}  %\hypersetup{draft}  \newcommand\sL{\ensuremath{\mathcal{L}}} \newcommand\sD{\ensuremath{\mathcal{D}}}  % colors \definecolor{lblue}{HTML}{A6CEE3} \definecolor{lgreen}{HTML}{B2DF8A} \definecolor{lred}{HTML}{FB9A99} \definecolor{lorange}{HTML}{FDBF6F} \definecolor{mblue}{HTML}{80B1D3} \definecolor{mgreen}{HTML}{B3DE69} \definecolor{mred}{HTML}{FB8072} \definecolor{morange}{HTML}{FDB462} \definecolor{blue}{HTML}{1F78B4} \definecolor{green}{HTML}{33A02C} \definecolor{red}{HTML}{E31A1C} \definecolor{orange}{HTML}{FF7F00} \definecolor{dblue}{HTML}{0050EF} \definecolor{dgreen}{HTML}{006D2C} \definecolor{dorange}{HTML}{EC7014} \newcommand{\blue}[1]{{\color{blue} #1}} \newcommand{\green}[1]{{\color{green} #1}} \newcommand{\red}[1]{{\color{red} #1}} \newcommand{\orange}[1]{{\color{orange} #1}} \newcommand{\dblue}[1]{{\color{dblue} #1}} \newcommand{\dgreen}[1]{{\color{dgreen} #1}} \newcommand{\dorange}[1]{{\color{dorange} #1}}  \newcommand{\cut}[1]{} \newcommand{\xhdr}[1]{{\bfseries #1}.}  \interfootnotelinepenalty=1000  \title{Stronger Transformers for Neural Multi-Hop Question Generation}  \author{Devendra Singh Sachan, Lingfei Wu, Mrinmaya Sachan, William Hamilton \\ Mila - Quebec AI Institute\\ School of Computer Science, McGill University\\ IBM Thomas J. Watson Research Center, Yorktown Heights\\ ETH Zurich\\ mrinmaya.sachan@inf.ethz.ch, wlh@cs.mcgill.ca\\ {\tt mrinmaya.sachan@inf.ethz.ch, wlh@cs.mcgill.ca} }   \date{}   % !TeX root = main.tex    In this study, we propose a general multi-task learning framework to leverage text data for ASR and ST tasks. The ASR task is co-trained with a denoising autoencoder task using monolingual text, while a MT task is jointly trained with the ST task with parallel data.  Text input is represented as phoneme sequences to reduce the difference between speech input and text input. We examined different factors that impact the performance of the jointly trained system. Our experimental results show substantial WER reduction is achieved on the  dataset and large BLEU score gain is obtained in the  datasets.  It proves the effectiveness of the proposed method.                           \vfill\pagebreak     References should be produced using the bibtex program from suitable   BiBTeX files . The IEEEbib.bst bibliography   style file from IEEE produces unsorted bibliography list.   ------------------------------------------------------------------------- 
"," Prior work on automated question generation has almost exclusively focused on generating simple questions whose answers can be extracted from a single document. However, there is an increasing interest in developing systems that are capable of more complex multi-hop question generation, where answering the questions requires reasoning over multiple documents. In this work, we introduce a series of strong transformer models for multi-hop question generation, including a graph-augmented transformer that leverages relations between entities in the text.  While prior work has emphasized the importance of graph-based models, we show that we can substantially outperform the state-of-the-art by {5 BLEU points}  using a standard transformer architecture. We further demonstrate that graph-based augmentations can provide complimentary improvements on top of this foundation. Interestingly, we find that several important factors---such as the inclusion of an auxiliary contrastive objective and data filtering could have larger impacts on performance.  We hope that our stronger baselines and analysis provide a constructive foundation for future work in this area.",275
"  Variational Autoencoders   allow to design complex generative models of data.  % since the inference process of VAE-based approaches has the advantage of being independent from the model architecture providing high flexibility in designing new neural components. In the wake of the renewed interest for VAEs, traditional probabilistic topic models  have been revised giving rise to several Neural Topic Model  variants, such as NVDM ,  ProdLDA , NTM-R , etc. % GSM , W-LDA  However, existing topic models when applied to user reviews may extract topics associated with writers' subjective opinions mixed with those related to factual descriptions such as plot summaries of movies and books . Although these approaches have achieved significant results via the neural inference process, surprisingly very little work has been done on how to disentangle the inferred topic representations.   % Despite the lack of general consensus about a formal definition of disentangled representations ,   Disentangled representations can be defined as representations where individual latent units are sensitive to variations of a single generative factor, while being relatively invariant to changes of other factors . Inducing such representations has been shown to be significantly beneficial for their generalization and interpretability .  For example, an image can be viewed as the results of several generative factors mutually interacting, as one or many sources of light, the material and reflective properties of various surfaces or the shape of the objects depicted . %  In the context of topic modeling, documents result from a generative process over mixtures of latent topics, and therefore, we propose to consider these latent topics as generative factors to be disentangled to improve their interpretability and discriminative power. Disentangled topics are topics invariant to the factors of variation of text, which for instance, in the context of book and movie reviews could be the author's opinion , the salient parts of a plot or other auxiliary information reported. An illustration of this is shown in Fig. in which opinion topics are separated from plot topics.  % where this leads to separating topics based on the ``factor of variation"" they are revealing. % For example, in generating a book review, the factors of variation involved could depend on the author's expertise in identifying the salient features of the book, %his knowledge of the book's genre, or  % his ability to summarize the plot and the feelings evoked by the book.  % % [Let's break in/the atom] % % Figure  reports a examples of polarity-disentangled topics generated from the IMDB movie reviews of ""The Hobbit"". The topics on the left and right summarize some of the positive and negative aspects described by users, while neutral topics in the middle report the main elements of the movie's plot.  % An effective approach for disentangling features in the latent space of VAEs is to adopt adversarial training . However, despite its successful applications in computer vision , the applications to text analysis has been rather limited so far , narrowed by the lack of proper tasks to evaluate the generated disentangled representations and the limited availability of suitable datasets.  % For example, in book or movie reviews, we want to disentangle topics which are related to opinions expressed in text and topics relating to book/movie plots. An illustration of this is shown in Figure in which opinion topics are separated from plot topics.   However, models relying solely on sentiment information are easily misled and not suitable to disentangle opinion from plots, since even plot descriptions frequently make large use of sentiment expressions . Consider for example the following sentence: ``The ring holds a dark power, and it soon begins to exert its evil influence on Bilbo"", an excerpt from a strong positive Amazon's review.  % This overcomes the difficulty of separating opinions from plot and auxiliary information yet containing polarised descriptions that easily mislead models merely relying on sentiment lexicon; analogously to the issue of mixed topics generated when traditional topic models are applied to review documents, as pointed out in \citet{Blei08}.  % Despite its successful employment in computer vision , the adversarial approach has had a rather limited application in text analysis so far , narrowed by the lack of proper tasks to evaluate the generated disentangled representations and the limited availability of suitable datasets.  Therefore, we propose to distinguish opinion-bearing topics from plot/neutral ones combining a neural topic model architecture with an adversarial training. In this study, we present the DIsentangled Adversarial TOpic Model \footnote{Source code and dataset omitted for the anonymous submission.}, aiming at disentangling information related to the target labels , from other distinct aspects yet possibly still polarised . We also introduce a new dataset, namely the MOBO dataset\footnotemark[\value{footnote}], made up of movie and book reviews, paired with their related plots. The reviews come from different publicly available datasets: IMDB , GoodReads  and Amazon reviews , %,  and encompass a wide spectrum of domains and styles. We conduct an extensive experimental assessment of our model. First, we assess the topic quality in terms of topic coherence and diversity and compare DIATOM with other supervised topic models on the sentiment classification task; then, we analyse the disentangling rate of topics to quantitatively assess the degree of separation between actual opinion and plot/neutral topics.    Our contributions are summarized below:    The rest of the paper is organized as follows. We review the related literature on sentiment-topic models, neural topic models and the studies on disentangled representations . Then, we present the details of our proposed DIATOM model , followed by the experimental setup  and results . Finally, we conclude with a summary of the results and suggestions for future works .     %%%%%%%%%%%%%%%%%%%%%%%%%%%    In this work, we propose a series of strong transformer models for multi-hop QG. To effectively encode the context documents and the answer, we introduce answer type embeddings and a new sublayer to incorporate the extracted entity-centric graph. We also propose an auxiliary contrastive objective to identify the supporting facts and a data filtering approach to balance the training-test distribution mismatch. Experiments on the HotpotQA dataset show that our models outperform the current best approaches by a substantial margin of 5 BLEU points. Our analysis further reveals that graph-based components may not be the most critical in improving the performance, but can render complementary strengths to the transformer.  !TeX root = main.tex  
"," The flexibility of the inference process in Variational Autoencoders  has recently led to revising traditional probabilistic topic models giving rise to Neural Topic Models . Although these approaches have achieved significant results, surprisingly very little work has been done on how to disentangle the latent topics. Existing topic models when applied to reviews may extract topics associated with writers' subjective opinions mixed with those related to factual descriptions such as plot summaries in movie and book reviews. It is thus desirable to automatically separate opinion topics from plot/neutral ones enabling a better interpretability. %Since in the topic modeling framework documents result from a generative process over mixtures of latent topics, we propose to interpret these latent topics as generative factors to be disentangled to improve their interpretability and discriminative power. In this paper, we propose a neural topic model combined with adversarial training to disentangle opinion topics from plot and neutral ones. We conduct an extensive experimental assessment introducing a new collection of movie and book reviews paired with their plots, namely MOBO dataset, showing an improved coherence and variety of topics, a consistent disentanglement rate, and sentiment classification performance superior to other supervised topic models.",276
" \subsection{Dialogue act recognition}  Mutual understanding in interactive situations, either when several people are engaged in a dialogue or when they are interacting with a modern computer system in natural language, may not be achieved without considering both the semantic information in the speakers utterances and the pragmatic interaction level, especially relative to dialogue acts. Dialogue Acts  represent the meaning of an utterance  in the context of a dialogue, or, in other words, the function of an utterance in the dialogue. For example, the function of a~question is to request some information, while an answer shall provide this information. Dialogue acts are thus commonly represented as phrase-level labels such as statements, yes-no questions, open questions, acknowledgements, and so on.  Automatic recognition of dialogue acts is a fundamental component of many human-machine interacting systems that support natural language inputs. For instance, dialogue acts are typically used as an input to the dialogue manager to help deciding on the next action of the system: giving information when the user is asking a question, but eventually keeping quiet when the user is just acknowledging, giving a comment, or even asking for delaying the interaction. In the latter case, a system reaction may be perceived as intrusive. Beyond human-machine interaction, this task is also important for applications that rely on the analysis of human-human interactions, either oral, e.g., in recordings of meetings, or % lada - added reference according to rev 1 written, e.g., through the reply and mention-at structures in Twitter conversations. It is also essential for a large range of other applications, for example talking head animation, machine translation, automatic speech recognition or topic tracking. The knowledge of the user dialogue act is useful to render facial expressions of an avatar that are relevant to the current state of the discourse. In the machine translation domain, recognizing dialogue acts may bring relevant cues to choose between alternative translations, as the adequate syntactic structure may depend on the user intention. Automatic recognition of dialogue acts may also be used to improve the word recognition accuracy of automatic speech recognition systems, where a different language model is applied during recognition depending on the dialogue act. %lada - added reference according to rev 1,   To conclude, dialogue act recognition is an important building block of many understanding and interacting systems. %pav --I've commented the rest of the sentence, because it was not clear for 2 reviewers ) -- and typically completes semantic role labelling and dialogue management.  \subsection {Motivation and objectives} Researches on dialogue act recognition have been carried out for a long time, as detailed in Section. The majority of these works exploit supervised learning with lexical, syntactic, prosodic and/or dialogue history features. However, few approaches consider semantic features, while they may bring additional information and prove useful to improve the accuracy of the dialogue act recognition system. For instance,  a~frequent cause of recognition errors are ``unknown'' words in the testing corpus that never occur in the training sentences. Replacing specific named entities in the text  by their category has been proposed in the literature as a remedy to this issue. We investigate a more general solution that exploits lexical similarity between word vectors. These word vectors may be computed in various ways, but they typically include mostly lexical semantic information about the word itself as well as some syntactic information, e.g., related to the relative position or degree of proximity of pairs of words within a sentence. This additional information may be used to improve dialogue act recognition, in particular when the training and test conditions differ, or when the size of the training corpus is relatively small.  %goal In this work, we propose a new Deep Neural Network  based on Long Short-Term Memory  for the task of dialogue act recognition, and we compare its performance to a standard Maximum Entropy model. Our first objective is to leverage the modelling capacity of such a DNN in order to achieve dialogue act recognition with only the raw observed word forms, i.e., without any additional expert-designed feature. This model is described in Section. The second objective is to further validate this model both on a standard English DA corpus, as well as on two other languages, without changing anything in the model, in order to assess the genericity and robustness of the approach. These experiments are summarized in Section. Finally, our third objective is to study the impact of word embeddings, which have been shown to provide extremely valuable information in numerous Natural Language Processing  tasks, but which have never been used so far~\footnote{To the best of our knowledge at the time of submission} for dialogue act recognition. This study is summarized in Section. %The following Section presents a review of related works of the domain.     We have described DIATOM, a new neural topic model to generate disentangled topics through the combination of VAE and adversarial learning.   We reported the results of our experimental study based on the novel  dataset highlighting the benefit of such an approach leading to topics with higher interpretability in terms of both topic coherence and topic uniqueness and more discriminative power reflected in better sentiment classification results compared to other supervised topic models.   We further discussed the model capability to consistently disentangle opinion-bearing topics from plot/neutral ones measuring the introduced disentangling rate.  Finally, we identified current limitations and viable solutions to be explored in the future.      
"," Dialogue act recognition is an important component of a large number of natural language processing pipelines. Many research works have been carried out in this area, but relatively few investigate deep neural networks and word embeddings. This is surprising, given that both of these techniques have proven exceptionally good in most other language-related domains. We propose in this work a new deep neural network that explores recurrent models to capture word sequences within sentences, and further study the impact of pretrained word embeddings. We validate this model on three languages: English, French and Czech. The performance of the proposed approach is consistent across these languages and it is comparable to the state-of-the-art results in English. More importantly, we confirm that deep neural networks indeed outperform a Maximum Entropy classifier, which was expected. However, and this is more surprising, we also found that standard word2vec embeddings do not seem to bring valuable information for this task and the proposed model, whatever the size of the training corpus is. We thus further analyse the resulting embeddings and conclude that a possible explanation may be related to the mismatch between the type of lexical-semantic information captured by the word2vec embeddings, and the kind of relations between words that is the most useful for the dialogue act recognition task.",277
"   As an important task in Natural Language Generation , dialogue generation empowers a wide spectrum of applications, such as chatbot and customer service automation. In the past few years, breakthroughs in dialogue generation technology focused on a series of sequence-to-sequence models .  More recently, external knowledge is employed to enhance model performance. % , for instance, propose Mem2Seq using structured knowledge in task-oriented dialogue generation.   can assist dialogue generation by using knowledge triples. Similarly,  explore document as knowledge discovery for dialogue generation, and  utilize unstructured knowledge to explore in the open-domain dialogue generation. However, unaffordable knowledge construction and defective domain adaptation restrict their utilization.   Copy-based generation models  have been widely adopted in content generation tasks and show better results compared to sequence-to-sequence models when faced with out-of-vocabulary problem. Thanks to their nature of leveraging vocabulary and context distributions for content copy, it enables to copy the aforementioned named entities  appeared in the above context) from the upper context to improve the specificity of the generated text.    In the task of dialogue generation, we can often observe the phrases/utterance patterns across different ""similar dialogue"" instances. For example, in customer service, the similar inquiries from the customers will get similar responses from the staff. It motivates us to build a model that can not only copy the content within the upper context of the target dialogue instance, but also learn the similar patterns across different similar cases of the target instance. Such external copy can be critical in some scenarios.  %Fi Judge's questions, in the target court debate case, can be copied from both internal and external sources, and this `cross-copy' can enhance the dialougue generation essentially.    Figure this paper, we are aware of the possibility of copying  from adjacent Unfortunately, these methods only enable internal copy, e.g., copy the content within the target dialogue instance. External copy, e.g., copy content across different dialougue instances, is incapable. However, as Figure. depicted,   %is another effective network structure. It solved the problem that the traditional sequence-to-sequence model cannot solve the problem that the vocabulary of the output sequence will change with the length of the input sequence. %Copynet proposed humans tend to repeat entity names or even long phrases in conversation.And then generate the entity that appeared in the previous article will be copied. %Recently, Pointer networks and Copynet's variants have played a very important role in NLG. Among them, Pointer-Generator Networks  was proposed. %In order to copy the key information from the context as well as cope with the Out-Of-Vocabulary problem. It relies on the vocabulary distribution and context distribution, the extended vocabulary is further obtained. % GLMP proposed a global memory encoder and a local memory decoder to share external knowledge by Pointer networks. %}As general domain network structure, the pointer network  and Copynet  shows fine effect in general text generation tasks. It not only can solves the problem of domain adaptability poor in dialog generation, does not introduce external knowledge, but also address Out-Of-Vocabulary  problem and enable content copy. % Pointer networks  and Copynet  provided effective approach to address Out-Of-Vocabulary  problem and enable content copy.  %The more recent effort, Pointer-Generator Networks  , inherited their advantages by leveraging vocabulary and context distributions for content copy.   As shown in Figure., we propose two different kinds of copy mechanisms in this study: vertical copy context-dependent information within the target dialogue instance, and horizontal copy logic-dependent content across different 'Similar Cases' . This framework is labeled as Cross-Copy Networks . As exemplar dialogue depicted, judges may repeat  words, phrases or utterances from historical dialogues when those SCs sharing similar content, e.g., `A sue B because of X and Y'.  %In this study, 'Similar Cases'  refers to a similar dialogue for each dialogue. When generating the next sentence based on the historical dialogue, we can refer to the similar dialogue of the dialogue to obtain it. In this paper, we propose a new network: Cross-Copy Networks, which can not only copy the previous entity, but also learn the logic of dialogue generation and copied specific words, phrases or utterance from similar cases to deal with out-of-vocabulary  words. % The CCN has two pointers, one can copy the specific entity or sentence from the context and another can copy the process discourse or a complete sentence from SC.  % As shown in Figure 1, there are two similar cases and a target case. Our copy methods are divided into two types, internal copy and external copy.  internal copy: we can directly copy some specific entities words that appear in the context as the words to be generated.  external copy: we can copy related sentences or phrases in similar cases as the directly generated sentences.   % As shown in Fig., There are three samples of CCN:  Selective copy: it can copy some specific words or phrases from SC as sentences to be generated, as sample 1.  Cross copy: it copy specific entities from the context, and then copy some process-frame nature sentences in SC, as sample 2.  Deep copy: it can copy some process discourse directly as a generated sentence, usually this sentence appears frequently in the full text, as sample 3.  In order to validate the proposed model, we employ two different dialogue datasets from two orthogonal domains - court debate and customer service. We apply proposed CCN to both datasets for dialogue generation. Experiments show that our model achieves the best results. To sum up, our contributions are as follows:  %    We propose in this work an LSTM-based deep neural network for dialogue act recognition. We show that this model performs as good as the state-of-the-art, even though it only uses the raw word forms as inputs, without any additional information, in particular neither part-of-speech tags nor information about the speaker. We have further applied exactly the same model with the same hyper-parameters on three different languages: English, French and Czech. The proposed model performs well on all three languages, suggesting that its performance generalizes nicely to various types of corpora and is not dependent on a specific tuning of the hyper-parameters to experimental conditions. This confirms the interesting modelling potential of deep recurrent networks for NLP in general, and supports the conclusions of recent works in the domain, which demonstrate the good performance of end-to-end training of deep neural networks for dialogue act recognition.  A more surprising conclusion of our work concerns the actual impact of pretrained word embeddings, which have been shown to be of great importance in several NLP tasks in the literature. We show in this work that standard pretrained embeddings do not help for the dialogue act recognition task in any of the three tested languages. We thus further study the embeddings that result from training the proposed model in an end-to-end manner, and show that they seem to differ from vanilla word2vec embeddings, which may explain why they do not perform as well as in other tasks. Of course, a single type of word embeddings has been tested in this work, word2vec, but some additional preliminary experiments suggest that LDA and COALS-based embeddings do not help either. More experiments with various embeddings should be made to confirm or infirm this conclusion, but it would be more convincing if they were realized with another deep network implementation and in more variable experimental conditions. To the best of our knowledge, this is the first work that exploits pretrained word embeddings for dialogue act recognition, and one of the rare published work that shows and analyzes some weakness of word2vec embeddings.  We further compare the proposed deep neural network with a standard Maximum Entropy classifier, and show that the DNN consistenly outperforms the Maximum Entropy classifier both in French and English. This is not the case in Czech, but it is likely due to the already high level of accuracy reached on this corpus, which leaves little to be gained by improving the model. A more interesting conclusion about this comparison between DNN and Maximum Entropy is that  pretrained word embeddings improve the Maximum Entropy model but not the DNN. This likely results from the limited modelling capacity of the Maximum Entropy model, which still benefits from the information brought by pretrained embeddings. But this information is not precise enough for the DNN, as shown in our qualitative analysis of word2vec.  
"," In the past few years, audiences from different fields witness the achievements of sequence-to-sequence models  to enhance dialogue content generation. While content fluency and accuracy often serve as the major indicators for model training, dialogue logics, carrying critical information for some particular domains, are often ignored. Take customer service and court debate dialogue as examples, compatible logics can be observed across different dialogue instances, and this information can provide vital evidence for utterance generation.  In this paper, we propose a novel network architecture - Cross Copy Networks  to explore the current dialog context and similar dialogue instances闁 logical structure simultaneously. Experiments with two tasks, court debate and customer service content generation, proved that the proposed algorithm is superior to existing state-of-art content generation models. % The traditional sequence-to-sequence model  has achieved good results in Natural Language Generation tasks. % For dialogue generation task in specific areas , some of the utterances by judge and customer service personnel to be saied usually contain specific logic and this utterances are highly similar. % Therefore, when generating the current utterance, we need to refer to not only the current context but also similar cases. % In this paper, we proposed a new neural network architecture named Cross Copy Networks , It locates entity in the context and the logical expression of similar cases by learning two conditional probability pointers. % We apply CCN to the legal dialogue data and customer service dialogue data for dialogue generation task. % Experiments show that our model achieves the best results.",278
"  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  A long-standing challenge in computer science is to develop algorithms that can interact with human users via dialog in natural language~.  Of particular interest is task-oriented dialog, wherein a user interacts with a system to achieve some goal .  The system should understand the user's requests and assist them by taking the appropriate actions . In recent years, supervised learning approaches to this problem have become particularly popular, because they can potentially learn complex patterns without relying on hand-crafted rules. While such data-driven methods already demonstrate impressive performance in open-domain dialog , task-oriented dialog models face the additional difficulty of transferring skills to tasks and domains that were not present in the training data.  To address this issue, we present the Schema-guided Dialog Dataset for Transfer Learning  dataset, a collection of realistic, task-oriented dialogs, that is especially designed to test and facilitate the transfer of learned patterns between tasks.  Unlike open-domain dialogs, task-oriented dialogs are accompanied by a set of steps that are necessary to complete the task.  These steps are typically known a priori and thus do not have to be learned from the data. In fact, for practical applications it is desirable that we could make modifications to this logic without having to discard large parts of the dataset. The ideal sequences of steps that a dialog would follow to complete the task can be arranged in a graph . Together with the utterances or actions that are associated with the nodes of this graph, we hence call this a task schema, or simply schema. Note, that what we call `schema' is similar to the `task specification' of , but distinct from the `schemas' that only define slots and intents of a task as used by \citet{rastogi2019towards}. %or \citet{kimEighthDialogSystem2019}.     In a typical supervised model that is trained to, say, predict the next system action for a task-oriented dialog, the schema of the training tasks is implicitly captured by the learned model parameters. This makes generalizing to a new task difficult, as the implicitly memorized schema will no longer be appropriate .  With \DATASETNAME\ we provide explicit schema representations for each task and thereby enable models to condition on the schema .  To collect \DATASETNAME\ we use a Wizard of Oz setup , where the system's role is played by a human `wizard'. Based on our pilot studies, we found that the quality of crowd-sourced dialogs depends strongly on   We refined our approach through extensive internal testing and four rounds of pilot studies.  % All code and instructions are available as open source at \anonymous{\DATASETURL}.   Our aim is to create an ecologically valid dataset  with the following four attributes, which we believe are crucial for a dataset to be of high quality: %     The progression of difficulty allows better assessment of dialog models and potential for transfer learning across levels of difficulty.     \item Consistency on the system side. % The behavior of a task-oriented dialog system should be largely deterministic and not subject to the whims or personality of the wizard. %     In particular, we encourage wizards to follow the given task schema as closely as possible.     \item Explicit knowledge base queries. %     A large part of developing a dialog system is the implementation of application programming interface  calls, such as knowledge base queries. %     In \DATASETNAME\ we represent our dialogs as a three-party interaction wherein the system acts as the intermediary between a user and a knowledge base . %     Thus, models have to learn when to query the knowledge base, what the query should be, and how to explain the returned knowledge base item to the user.  \end{enumerate} % With these properties, we create a is ecologically valid, as described by.  With this paper, we contribute   The code for the latter setup, all collected  data, and all modeling code is freely available under \anonymous{\DATASETURL}.      We have studied the feasibility of training a fully bilingual deep neural language model, i.e.\ a model that approaches or matches the performance of monolingual models at language-specific tasks. We trained a bilingual Finnish-English \bertbase{} model by expanding the vocabulary size to be the sum of the size of the two individual vocabularies, and compared the model performance to monolingual models. We found that, on a range of NLU tasks, the bilingual model performs comparably or nearly comparably with monolingual models. We conclude that, for the \bertbase{} architecture, it is possible to train a fully bilingual deep contextual model for two remotely related languages. We release the newly introduced \bbert{} model and all tools introduced to create the model under open licenses at .  
"," We present \DATASETNAME, a schema-guided task-oriented dialog dataset consisting of 127,833 utterances and knowledge base queries across 5,820 task-oriented dialogs in 13 domains that is especially designed to facilitate task and domain transfer learning in task-oriented dialog. Furthermore, we propose a scalable crowd-sourcing paradigm to collect arbitrarily large datasets of the same quality as \DATASETNAME. Moreover, we introduce novel schema-guided dialog models that use an explicit description of the task to generalize from known to unknown tasks.  We demonstrate the effectiveness of these models, particularly for zero-shot generalization across tasks and domains.",279
" % -------------------------------------------------------------- % % The following footnote without marker is needed for the camera-ready % version of the paper. % Comment out the instructions  and uncomment the 8 lines % under ""final paper"" for your variant of English. %  .     %      % final paper: en-us version          % space normally used by the marker      This work is licensed under a Creative Commons       Attribution 4.0 International License.      License details:      \url{http://creativecommons.org/licenses/by/4.0/}.       } The relationship between a group of human languages can be characterized across several dimensions of variation , including  the temporal dimension, wherein languages have diverged from a common historical ancestor as in the case of Romance languages;  the spatial dimension, wherein the speaker communities are geographically adjacent as in the case of the Indo-Aryan and Dravidian languages of India; and  the socio-political dimension, wherein languages have evolved under shared political and/or religious forces as in the case of Arabic and Swahili. Languages, or language varieties, can be related across all these dimensions, which often results in a dialect continuum. Speakers of languages that constitute a dialect continuum can usually communicate with each other efficiently using their own mother tongue. The degree of intercomprehensibility between speakers of different language varieties within a continuum is mainly determined by linguistic similarities. A notable case of this phenomenon is the mutual intelligibility among the Slavic languages, which we study in this paper.   One of the goals of linguistics is to study and categorize languages based on objective measures of linguistic distance. The degrees of similarity at different levels of the linguistic structural organization can be seen as preconditions for, as well as predictors of, successful oral intercomprehension.  For closely-related languages, similarities at the pre-lexical, that is the acoustic-phonetic and phonological, level have been found to be better predictors of cross-lingual speech intelligibility than lexical similarities . In a different, yet relevant research direction,  have investigated non-linguists' perception of language variation using data from the popular spoken language guessing game, the Great Language Game . By analyzing the confusion patterns of the GLG's human participants, the authors have shown that factors predicting players' confusion in the game correspond to objective measures of similarity established by linguists. For example, both phylogenetic relatedness and overlap in phoneme inventories have been identified as factors of perceptual confusability  of languages in GLG.   The development of automatic systems that determine the identity of the language in a speech segment has received attention in the speech recognition community . State-of-the-art approaches for automatic spoken language identification, henceforth LID, are based on multilayer deep neural networks . DNN-based LID systems are parametric models that learn a mapping from spectral acoustic features of  speech to high-level feature representations in geometric space where languages are linearly separable. These models have shown tremendous success not only in discriminating between distant languages but also closely-related language varieties . Nevertheless, none of the previous works in spoken language recognition has analyzed the emerging representations from neural LID models for related languages. Thus, it is still unknown whether the distances in these representation spaces correspond to objective measurements of linguistic similarity and/or to non-linguists' perception of language variation. In this paper, we aim to fill this gap and consider the family of Slavic languages as a case study. Our key contribution is two-fold:   In this paper, we attempt to bridge different lines of research that have so far remained unconnected. On the one hand, we employ neural architectures from the field of spoken language recognition and build a robust model to identify languages in contemporary acoustic realizations of Slavic speech. On the other hand, we analyze the emerging language representations using techniques established by previous research in multilingual natural language processing . We consequently shed light on the speech modality and show how  speech signals can complement research done in computational studies of linguistic typology and language variation.   %  to the best of our knowledge  % The recognition of spoken language   % LID in speech technology  % untranscribed speech   % NN has made possible for end-to-end systems to be developed, while traditional approaches feature many components   % closely-related languages have similar phonotactics, but differ in acoustic realizations of segments and suprasegmental features   % language identity and objective linguistic measures of similarity   % The GLG   % similarity of representation in deep neural networks    % --------------------------------------------------------------                                                                                                             With this work, we make multiple contributions to the field of task-oriented dialog research. First, we presented \DATASETNAME, a novel dialog dataset that we specifically designed to facilitate transfer learning experiments. Second, we introduced a new, scalable crowd sourcing paradigm to collect data of similar quality as \DATASETNAME. In future work, this setup could be used to expand on \DATASETNAME\ by collecting data for additional tasks, domains, or in languages other than English. Finally, we established baseline scores for next action prediction, response generation, and zero-shot transfer learning for the former two tasks. With this we demonstrated how task schemas can be used to improve transfer learning capabilities. We also outlined a variety of other experiments that \DATASETNAME\ would be suitable for, and we look forward to seeing these experiments, as well as improvements upon our baseline scores, implemented in future publications.  \clearpage    
"," Deep neural networks have been employed for various spoken language recognition tasks, including tasks that are multilingual by definition such as spoken language identification. In this paper, we present a neural model for Slavic language identification in speech signals and analyze its emergent representations to investigate whether they reflect objective measures of language relatedness and/or non-linguists' perception of language similarity. While our analysis shows that the language representation space indeed captures language relatedness to a great extent, we find perceptual confusability between languages in our study to be the best predictor of the language representation similarity.",280
" For a conversational AI or digital assistant system , Natural Language Understanding  is an established component that produces semantic interpretations of a user request, which typically involves analysis in terms of domain, intent, and slot . For instance, the request ``Play a song by Taylor Swift"" can be interpreted as falling within the scope of Music domain with Play Song intent and Taylor Swift identified for Artist slot.  Improving the accuracy of the NLU component is important for satisfactory end-to-end user experience. Without an accurate semantic understanding of the user request, a conversational AI system cannot fulfill the request with a satisfactory response or action. As one of the most upstream components in the runtime workflow , NLU's errors also have a wider blast radius that propagates to all subsequent downstream components, such as dialog management, routing logic to back-end applications, and language generation.  A straight-forward way to improve NLU is through human annotations. For example, we can mine the user requests that resulted in unsatisfactory user experience and make ground-truth annotations on those requests that produced incorrect NLU outputs, which can be used as additional supervision data for improving the models or rule engines within NLU. However, this approach is labor-intensive and expensive. It requires at least multiple tiers of annotations , and it is hard to consider all underlying contextual conditions. It is also limited by the existing annotation guidelines that may not accurately reflect user expectations. Due to these limitations, leveraging user feedback, both implicit and explicit, from real production systems is emerging as a new area of research.     In this paper, we propose a scalable and automatic approach for improving NLU by leveraging implicit user feedback, with an insight that user interaction data and dialog context have rich information embedded from which user satisfaction and intention can be inferred. For instance, while interacting with a conversational AI system, dissatisfied users might often choose to intervene by stopping the system response in the middle and rephrasing the previous request to make it clearer with less room for ambiguous interpretation .  Our work makes three main contributions. First, to our knowledge, this work is the first in the literature to introduce a scalable and automatic approach of leveraging domain-agnostic implicit user feedback that can continuously improve the NLU component of a large-scale conversational AI system in production. Second, we propose a general framework for curating supervision data for improving NLU from live traffic that can be leveraged for various subtasks within NLU - e.g., the supervision data can be applied to improve individual semantic interpretation models  or a ranking/classification model across all interpretations . Last, we show with an extensive set of experiments on live traffic the performance of the proposed framework and its impact on improving NLU in the production system across 10 widely used domains. \def\year{2021}\relax %File: formatting-instructions-latex-2021.tex %release 2021.1 \documentclass[letterpaper]{article} % DO NOT CHANGE THIS \usepackage{aaai21}  % DO NOT CHANGE THIS \usepackage{times}  % DO NOT CHANGE THIS \usepackage{helvet} % DO NOT CHANGE THIS \usepackage{courier}  % DO NOT CHANGE THIS \usepackage[hyphens]{url}  % DO NOT CHANGE THIS \usepackage{graphicx} % DO NOT CHANGE THIS \urlstyle{rm} % DO NOT CHANGE THIS \def\UrlFont{\rm}  % DO NOT CHANGE THIS \usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \frenchspacing  % DO NOT CHANGE THIS \setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS \setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS  \usepackage{amsfonts} \usepackage{amsmath} \usepackage{algorithm} \usepackage{xcolor} \usepackage[noend]{algpseudocode}  % \nocopyright %PDF Info Is REQUIRED. % For /Author, add all authors within the parentheses, separated by commas. No accents or commands. % For /Title, add Title in Mixed Case. No accents or commands. Retain the parentheses. % \pdfinfo{ % /Title  % /Author  % /TemplateVersion  %} %Leave this % /Title  % Put your actual complete title  within the parentheses in mixed case % Leave the space between \Title and the beginning parenthesis alone % /Author  % Put your actual complete list of authors  within the parentheses in mixed case. % Each author should be only by a comma. If the name contains accents, remove them. If there are any LaTeX commands, % remove them.  % DISALLOWED PACKAGES % \usepackage{authblk} -- This package is specifically forbidden % \usepackage{balance} -- This package is specifically forbidden % \usepackage{color  % \usepackage{CJK} -- This package is specifically forbidden % \usepackage{float} -- This package is specifically forbidden % \usepackage{flushend} -- This package is specifically forbidden % \usepackage{fontenc} -- This package is specifically forbidden % \usepackage{fullpage} -- This package is specifically forbidden % \usepackage{geometry} -- This package is specifically forbidden % \usepackage{grffile} -- This package is specifically forbidden % \usepackage{hyperref} -- This package is specifically forbidden % \usepackage{navigator} -- This package is specifically forbidden %  % \indentfirst} -- This package is specifically forbidden % \layout} -- This package is specifically forbidden % \multicol} -- This package is specifically forbidden % \nameref} -- This package is specifically forbidden % \usepackage{savetrees} -- This package is specifically forbidden % \usepackage{setspace} -- This package is specifically forbidden % \usepackage{stfloats} -- This package is specifically forbidden % \usepackage{tabu} -- This package is specifically forbidden % \usepackage{titlesec} -- This package is specifically forbidden % \usepackage{tocbibind} -- This package is specifically forbidden % \usepackage{ulem} -- This package is specifically forbidden % \usepackage{wrapfig} -- This package is specifically forbidden % DISALLOWED COMMANDS % \nocopyright -- Your paper will not be published if you use this command % \addtolength -- This command may not be used % \balance -- This command may not be used % \baselinestretch -- Your paper will not be published if you use this command % \clearpage -- No page breaks of any kind may be used for the final version of your paper % \columnsep -- This command may not be used % \newpage -- No page breaks of any kind may be used for the final version of your paper % \pagebreak -- No page breaks of any kind may be used for the final version of your paperr % \pagestyle -- This command may not be used % \tiny -- This is not an acceptable font size. % {2} %May be changed to 1 or 2 if section numbers are desired.  % The file aaai21.sty is the style file for AAAI Press % proceedings, working notes, and technical reports. %  % Title  % Your title must be in mixed case, not sentence case. % That means all verbs , % nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while % articles, conjunctions, and prepositions are lower case unless they % directly follow a colon or long dash  % \title{AAAI Press Formatting Instructions \\for Authors Using \LaTeX{} --- A Guide } % \author{  %     %Authors %     % All authors must be in the same font size and format. %     Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help from the AAAI Publications Committee.}\\ %     AAAI Style Contributions by Pater Patel Schneider, %     Sunil Issar,  \\ %     J. Scott Penberthy, %     George Ferguson, %     Hans Guesgen, %     Francisco Cruz, %     Marc Pujol-Gonzalez %     \\ % } % \affiliations{ %     %Afiliations  %     \textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\ %     %If you have multiple authors and multiple affiliations %     % use superscripts in text and roman font to identify them. %     %For example,  %     % Sunil Issar, \textsuperscript{\rm 2} %     % J. Scott Penberthy, \textsuperscript{\rm 3} %     % George Ferguson,\textsuperscript{\rm 4} %     % Hans Guesgen, \textsuperscript{\rm 5}. %     % Note that the comma should be placed BEFORE the superscript for optimum readability  %     2275 East Bayshore Road, Suite 160\\ %     Palo Alto, California 94303\\ %     % email address must be in roman text type, not monospace or sans serif %     publications21@aaai.org  %     % See more examples next % } %\iffalse % %Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it \title{A Scalable Framework for Learning From Implicit User Feedback to Improve Natural Language Understanding in Large-Scale Conversational AI Systems} \author {     Sunghyun Park\thanks{Equal contribution.}, Han Li\textsuperscript{\rm *}, Ameen Patel, Sidharth Mudgal, Sungjin Lee, Young-Bum Kim, Spyros Matsoukas, Ruhi Sarikaya \\ } \affiliations{     % Affiliations     Amazon Alexa AI \\     \{sunghyu, lahl, paameen, sidmsk, sungjinl, youngbum, matsouka, rsarikay\}@amazon.com } %\fi  \iffalse %Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it \title{My Publication Title --- Multiple Authors} \author {     Authors         First Author Name,\textsuperscript{\rm 1}         Second Author Name, \textsuperscript{\rm 2}         Third Author Name \textsuperscript{\rm 1} \\ } \affiliations {     % Affiliations     \textsuperscript{\rm 1} Affiliation 1 \\     \textsuperscript{\rm 2} Affiliation 2 \\     firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com } \fi   \newcommand{\red}[1]{{\color{red} #1}} \newcommand{\vecb}[1]{\mathbf{#1}}  \newtheorem{definition}{Definition}              \newpage \bibliography{citation} % \bibliographystyle{aaai21}  \end{document}   Insufficient labeled data limits the effectiveness of attention-based models for the ASC task. In this paper, we propose a novel attention transfer framework, in which two different attention transfer methods are designed to exploit attention knowledge from resource-rich document-level sentiment classification corpus to enhance the attention process of resource-poor aspect-level sentiment classification, finally achieving the goal of improving the performance of ASC. Experimental results indicate that our approaches outperform the state-of-the-art works. Further analysis validates the effectiveness and benefits of transferring the attention knowledge from DSC data for the ASC task.  
"," Natural Language Understanding  is an established component within a conversational AI or digital assistant system, and it is responsible for producing semantic understanding of a user request. We propose a scalable and automatic approach for improving NLU in a large-scale conversational AI system by leveraging implicit user feedback, with an insight that user interaction data and dialog context have rich information embedded from which user satisfaction and intention can be inferred. In particular, we propose a general domain-agnostic framework for curating new supervision data for improving NLU from live production traffic. With an extensive set of experiments, we show the results of applying the framework and improving NLU for a large-scale production system and show its impact across 10 domains.",281
"   Chinese Word Segmentation  is a fundamental task for Chinese natural language processing , which aims at identifying word boundaries in a sentence composed of continuous Chinese characters. It provides a basic component for other NLP tasks like named entity recognition, dependency parsing, and semantic role labeling, etc.  Generally, most previous studies model the CWS task as a character-based sequence labeling task . Recently, pre-trained models  such as BERT  have been introduced into CWS tasks, which could provide prior semantic knowledge and boost the performance of CWS systems.  directly fine-tunes BERT on several CWS benchmark datasets.  fine-tunes BERT in a multi-criteria learning framework, where each criterion shares a common BERT-based feature extraction layer and owns a private projection layer.  combines Chinese character glyph features with pre-trained BERT representations. %  builds a unified BERT-based model for multi-criteria CWS tasks and fine-tunes it on eight CWS criteria jointly.  proposes a neural CWS framework WMSeg, which utilizes memory networks to incorporate wordhood information into the pre-trained model ZEN.  PTMs have been proved quite effective by fine-tuning on downstream CWS tasks. However, PTMs used in previous works usually adopt language modeling as pre-training tasks. Thus, they usually lack task-specific prior knowledge for CWS and ignore the discrepancy between pre-training tasks and downstream CWS tasks.     \end{table}  To deal with aforementioned problems of PTMs, we consider introducing a CWS-specific pre-trained model based on existing CWS corpora, to leverage the prior segmentation knowledge. However, there are multiple inconsistent segmentation criteria for CWS, where each criterion represents a unique style of segmenting Chinese sentence into words, as shown in Table. Meanwhile, we can easily observe that different segmentation criteria could share a large proportion of word boundaries between them, such as the boundaries between word units ``閺夊骸顭'', ``鏉╂稑鍙'' and ``閸楀﹤鍠呯挧'', which are the same for all segmentation criteria. It shows that the common prior segmentation knowledge is shared by different criteria.  In this paper, we propose a CWS-specific pre-trained model MetaSeg. To leverage shared segmentation knowledge of different criteria, MetaSeg utilizes a unified architecture and introduces a multi-criteria pre-training task. Moreover, to alleviate the discrepancy between pre-trained models and downstream unseen criteria, meta learning algorithm is incorporated into the multi-criteria pre-training task of MetaSeg.  Experiments show that MetaSeg could outperform previous works significantly, and achieve new state-of-the-art results on twelve CWS datasets. Further experiments show that  MetaSeg has better generalization performance on downstream unseen CWS tasks in low-resource settings, and improve Out-Of-Vocabulary  recalls. To the best of our knowledge, MetaSeg is the first task-specific pre-trained model especially designed for CWS.     In this paper, we proposed a domain-agnostic and scalable framework for leveraging implicit user feedback, particularly user dissatisfaction and rephrase behavior, to automatically curate high-quality supervision data to continuously improve NLU in a large-scale conversational AI or digital assistant system. We showed with an extensive set of experiments on live traffic how the framework can be applied to improve NLU and analyzed its performance across 10 popular domains by traffic volume on a real production system. We further showed component-level analysis of our framework for more in-depth validation of its performance.
","     Recent researches show that pre-trained models  are beneficial to Chinese Word Segmentation .     However, PTMs used in previous works usually adopt language modeling as pre-training tasks, lacking task-specific prior segmentation knowledge and ignoring the discrepancy between pre-training tasks and downstream CWS tasks.     % However, existing approaches usually fine-tune general-purpose pre-trained models directly on separate downstream CWS corpora.     % These general-purpose pre-trained models usually adopt language modeling objectives, lack task-specific prior segmentation knowledge, and ignore the discrepancy between pre-training tasks and downstream CWS tasks.     In this paper, we propose a CWS-specific pre-trained model MetaSeg, which employs a unified architecture and incorporates meta learning algorithm into a multi-criteria pre-training task.     Empirical results show that MetaSeg could utilize common prior segmentation knowledge from different existing criteria and alleviate the discrepancy between pre-trained models and downstream CWS tasks.     Besides, MetaSeg can achieve new state-of-the-art performance on twelve widely-used CWS datasets and significantly improve model performance in low-resource settings.",282
"  Automatic question answering is a very active area of research within natural language processing. %Open-domain question answering looks for methods to re-utilize systems across multiple domains. One possible way to approach this task is to look for answers in the text passages of a collection of documents. Recent research has shown promising results on developing neural models for passage retrieval tasks, including Retrieval Question Answering, Open Domain Question Answering, and MS MARCO. The models in these systems are often trained using the dual encoder framework where questions and passages are encoded separately. Training an effective neural retrieval model usually requires a large amount of high-quality data. To alleviate the need of high-quality data, training can be approached in two-stages: pre-training on noise data and fine tuning on a smaller amount of high-quality data, also regarded as ``gold"" data. % One significant advantage of the dual encoder framework is that, once the question and passage embeddings are available, efficient nearest neighbour search can be used to retrieve the passages that contain the answers to the questions.    When used for question answering, one advantage of the dual encoder is that training in batches allows to use, for each question, the passages that answer all the other questions in the batch as negatives. Given that the training batches are randomly sampled from all the question-passage pairs, the negatives in the batch are random in nature. While effective in many retrieval tasks, random negatives have the limitation of not being targeted nor challenging enough to clearly separate the passage that answers a given question from any other passage. How to sample the negatives in a way that widens this separation and improves the contrast between the correct and incorrect passages remains an open question.  % A viable approach to negative sampling is to use ``hard"" negatives that are specific to each question and answer  pair. In this paper we systematically explore the use of ``hard'' negatives in the neural passage retrieval models that we train using a two-stage approach. Using hard negatives as part of the dual encoder framework has shown advantageous in different tasks . %Using hard negatives as part of the dual encoder framework has shown advantageous in cross-lingual tasks. %For example, \citet{guo-etal-2018-effective} show that training with hard negatives generated by retrieving ``coarse"" negatives with low-resolution model improves the quality of the translation pairs retrieved with a dual encoder model. %Similarly, \citet{dpr} showed improvement when using hard negatives retrieved with a BM25 model in the passage retrieval part of the Open Domain Question Answering task. %In contrast to previous works,  We explore different types of negatives, and experiment using them in both the pre-training and fine-tuning stages. The types of negatives we tried are:   We first use hard negatives on the data that we use to pre-train the models. We leverage the question generator model described in and generate new questions for each of the passages we use in the pre-training stage . %The new questions are paired with the original passages. %The augmented set of question-passage pairs is used to train the first stage of the neural retrieval model. % It has been shown as an effective approach to improve passage retrieval models. During pre-training we use negatives generated from strategy 4\footnote{Or strategy 1, if strategy 4 is not feasible} to improve the retrieval model, as the other strategies could introduce more false negatives into the data. %Our initial experiments showed that using retrieval models to find the hard negatives at this point, often generated very noisy question-passage pairs, especially because our pre-training data includes synthetic pairs. %As the generated question passage pairs sometimes are noise, retrieval-based approaches may create better question-passage pairs than the synthetic pairs. %We only apply a heuristic based context negatives on this pre-training task. Next, we continue with the fine tuning stage  using a small amount of gold training data. At this stage, we explore all four types of negative sampling. To the best of our knowledge, this is the first work that explores the effectiveness of hard negatives for passage retrieval in a systematic way, and integrates them in the retrieval models  pre-training stage. Our overall experimental architecture is outlined in Figure.  %For each question-passage pair in the training set, we collect negatives using the strategies listed above and augment them into the training.  We conduct experiments with this approach on two passage retrieval tasks: Open Domain QA  and SQuAD) and MS MARCO. %Open Domain QA Natural Questions~, Open Domain QA SQuAD, and MS MARCO. Our results show that all four kinds of hard negatives improve the dual encoder models significantly with consistent performance gains across both tasks. However, depending on the types of questions and their domain, one kind of hard negative may perform better than the others in a particular task. For example, context negatives work best in NQ and semantic retrieval-based negatives  work best in SQuAD. We further ensemble the models trained on different types of hard negatives. The final models achieve state-of-the-art performance on Open Domain QA task with an improvement over prior works of 0.8--2.9 points on accuracy rates.  %\hl{highlight numbers here}.  The main contribution of this paper are:      In this work, we pursued a new research problem of M\&A prediction. Our transformer-based classifier leveraged the regularization benefits of adversarial training to enhance model robustness. More importantly, we built upon previous techniques to quantify the importance of words and help guarantee the generation of plausible counterfactual explanations with a masked language model in financial text classification. The results demonstrate superior accuracy and explanatory performance compared to state-of-the-art techniques. An obvious extension would be to include canceled deals into the classifier, or to predict novel M\&A events based on market descriptions of companies . Moreover, additional financial events  is yet another related task to be considered for further research.   
"," %In this paper we explore the discriminate training for neural passage retrieval models with hard negatives. %Four different hard negative sampling strategies are experimented, including one BM25 based hard negative, two semantic based hard negatives, and one heuristic hard negative. %For training the model, we employ a two stage dual encoder model with pre-training using synthetic data followed by a fine-tuning using the gold training data. %Discriminate training is applied on both stages. %The trained models are evaluated on 3 passage retrieval tasks from Open Domain QA NQ, Open Domain QA SQuAD, and MS MARCO. %Results show that all of them can improve the naive dual encoder models significantly with consistent performance gain over all three tasks. %However, there is no single type of hard negative perform best on all tasks. %Further analysis show that the synthetic question pre-training with discriminate training is an effective approach to improve the passage retrieval performance. %The best trained models establish the new state-of-the-art on retrieval tasks of Open Domain QA NQ and SQuAD. %",283
" Neural machine translation  has been explored typically in sentence-level translation settings. Such sentence-level nmt models inevitably suffer from ambiguities when multiple  %% semantically-different translations are accepted  interpretations are possible to a source sentence.  To address this issue, context-aware nmt models have recently been presented %to address the issue  to incorporate document-level information in translation. Most of the existing context-aware nmt models are end-to-end models which take as input the current source sentence to be translated and the context sentences, and then output a translation. These models are trained on document-level parallel data, namely, sentence pairs with surrounding, usually preceding, sentences in the source and target language. However, in practical scenarios, document-level bilingual data is limited in most language pairs and domains, % posing a challenge to building context-aware nmt systems .  In this study, we propose a simple yet effective approach to context-aware nmt  % consisting of  using two primitive components, a sentence-level nmt model and a document-level language model . This approach allows us to independently train the two components on bilingual data and monolingual data, respectively, without resorting to expensive document-level bilingual data.  % and thereby no document-level bilingual data is needed. To give a probabilistic foundation to this combination of two independent models, we exploit % take advantage of  the probabilistic nature of nmt decoding. When generating a sequence, a left-to-right decoder outputs a categorical probability distribution over the vocabulary at every time step. % . The decoder assigns higher probability to the tokens that would be more suitable at that step. Therefore,  % we can assume that  when multiple valid translations are possible to the source sentence, % , which has ambiguities a sentence-level nmt is confused by,  the decoder just gives a higher  % sequence  probability to the translation that is plausible without considering contexts.  % than to wrong ones. Our idea is to adjust the probability distributions in a context-aware manner using a document-level lm of the target language which  % is capable of modeling  models inter-sentential dependencies in the target side document.  % Since a network structure of nmt models evolves very quickly, model-agnostic approach like ours is more preferable than model-tweaking approach .  We evaluate our methods on English to French, Russian and Japanese translations with OpenSubtitles2018 corpus in terms of the bleu scores and contrastive discourse test sets. Experimental results confirmed that our method achieved comparable performance with existing context-aware nmt models.  The contributions of this paper are as follows:     In this work, we presented a simple and unified representation learning framework, \modelname, for event and entity coreference. \modelname~learns a  mention-pair representation by forwarding concatenated sentences into RoBERTa, where sentences provide the context of mentions. This algorithm is applied to both event and entity coreference benchmarks and obtains state of the art performance. In addition, we augmented this pairwise representation with structured argument features to further improve its performance in event coreference.      
"," % There exist inevitable ambiguities in translating a single sentence, and we resort to context beyond the target sentence for resolving such ambiguities. Although many context-aware neural machine translation models have been proposed to incorporate contexts in translation,  most of those models are trained end-to-end on parallel documents aligned in sentence-level.  Because only a few domains  have such document-level parallel data, we cannot perform accurate context-aware translation in most domains. We therefore present a simple method to turn a sentence-level translation model into a context-aware model by incorporating a document-level language model into the decoder. Our context-aware decoder is built upon only a sentence-level parallel corpora and monolingual corpora; thus no document-level parallel data is needed. In a theoretical viewpoint, the core part of this work is the novel representation of contextual information using point-wise mutual information between context and the current sentence. We show the effectiveness of our approach in three language pairs, English to French, English to Russian, and Japanese to English, by evaluation in bleu and contrastive tests for context-aware translation.",284
" A keyphrase is a multi-word text representing highly abstractive information in a long document. Keyphrase extraction  is a task that aims to generate an appropriate keyphrase set for the given document, thus helping to identify salient contents and concepts from the document. Recently, the KE task has attracted much research interest since it serves as an important component of many downstream applications such as text summarization, document  classification, information retrieval and question generation.  Early KE systems commonly operate in an extractive manner, which usually consists of two steps: 1) selecting candidates from the source document using heuristic rules,  and 2) ranking the candidates list to determine which is correct. However, the two-step ranking approaches are usually based on feature engineering, which is labor-intensive. Motivated by the progress in sequence-to-sequence applications of neural networks, KE research's focus has gradually shifted to deep learning methods. \citet{DBLP:conf/acl/MengZHHBC17} first formulate KE as a sequence generation problem and introduce an attentive Seq2Seq framework to generate the keyphrase sequence conditioned on the input document. Compared with traditional methods, the Seq2Seq based method achieves superior performance.  Seq2Seq based KE is exposed to two major challenges: 1) Document-level representation learning. For any Seq2Seq generative framework, the latent hidden representation is a very important factor, and its quality will directly affect the decoder's performance. In KE task, the input is commonly a long document instead of a sentence, which poses a greater challenge to latent representation learning. 2) Modeling the compositionality of keyphrases set. The elements in the keyphrase set are dependent and correlated. That is, better modeling the inherent composition embodied in the keyphrase set during the learning process will effectively boost the diversity and quality of final results.   Recently, various approaches have been proposed to optimize the Seq2Seq generation framework in KE task. To learn a better latent representation, previous studies try to introduce different encoding structures  to address the two issues above simultaneously. We explore to incorporate the dependency tree for document representation learning in the encoder part. The syntactic dependency tree can help to locate key information in a document. In practice, the document graph  is constructed depending on the syntactic dependency tree, and then a convolution process will be operated over .  On the other hand, we rethink the implication of compositionality in the keyphrase set. In the training process of generative models, whether a candidate keyphrase should be generated not only hinges on the document itself, but also depends on the keyphrases that have already been generated. Therefore, a dynamic graph updating mechanism is introduced to explicitly modeling the inter-dependency among keyphrases. In our method, the graph structure in the encoder part will be dynamically updated according to the keyphrases generated in the decoder part. Concretely, after one keyphrase is decoded, its information will be transferred to modify the edge weights in the document graph through a score function, and the latent hidden representation will also be updated. In this approach, we could dynamically ensure the information exchange between encoder and decoder parts in both directions.   The contribution of this work is three-fold:  1) A novel generative framework, Div-DGCN, is proposed that leverages both the dynamic syntactic graph encoder and diversified inference process for KE. 2) A dynamic computation mechanism is adopted to model the compositionality in keyphrase set explicitly and then enhancing the information interchange between the encoder and decoder parts in the Seq2Seq architecture.  3) Extensive experiments conducted on five benchmarks show that our proposed method is effective against competitive baselines on several metrics.    We present an approach to context-aware  based on  between the context and the current sentence. We first provide the formulation of the objective, , and the computation process of the  using a sentence-level translation model and a document-level language model. We investigate two search methods, reranking and beam search, and evaluate the methods in English-French, English-Russian, and Japanese-English translation. We also provide some analysis and visualization to better understand the nature of  between the context and the current sentence.  We plan to design context-aware  using  for context-aware  models. We will extend our method to non-autoregressive . We will release all of the code to promote the reproducibility of our results.    
"," Keyphrase extraction  aims to summarize a set of phrases that accurately express a concept or a topic covered in a given document. Recently, Sequence-to-Sequence  based generative framework is widely used in KE task, and it has obtained competitive performance on various benchmarks. The main challenges of Seq2Seq methods lie in acquiring informative latent document representation and better modeling the compositionality of the target keyphrases set, which will directly affect the quality of generated keyphrases. In this paper, we propose to adopt the Dynamic Graph Convolutional Networks  to solve the above two problems simultaneously. Concretely, we explore to integrate dependency trees with GCN for latent representation learning. Moreover, the graph structure in our model is dynamically modified during the learning process according to the generated keyphrases. To this end, our approach is able to explicitly learn the relations within the keyphrases collection and guarantee the information interchange between encoder and decoder in both directions. Extensive experiments on various KE benchmark datasets demonstrate the effectiveness of our approach.",285
"  Sanskrit is one of the oldest of the Indo-Aryan languages. The oldest known Sanskrit texts are estimated to be dated around 1500 BCE. It is the one of the oldest surviving languages in the world. A large corpus of religious, philosophical, socio-political and scientific texts of multi cultural Indian Subcontinent are in Sanskrit. Sanskrit, in its multiple variants and dialects, was the Lingua Franca of ancient India . Therefore, Sanskrit texts are an important resource of knowledge about ancient India and its people. Earliest known Sanskrit documents are available in the form called Vedic Sanskrit. Rigveda, the oldest of the four Vedas, that are the principal religious texts of ancient India, is written in Vedic Sanskrit. In sometime around 5\textsuperscript{th} century BCE, a Sanskrit scholar named pARini wrote a treatise on Sanskrit grammar named azwADyAyI, in which pARini formalized rules on linguistics, syntax and grammar for Sanskrit. azwDyAyI is the oldest surviving text and the most comprehensive source of grammar on Sanskrit today. azwADyAyI literally means eight chapters and these eight chapters contain around 4000 sutras or rules in total. These rules completely define the Sanskrit language as it is known today. azwADyAyI is remarkable in its conciseness and contains highly systematic approach to grammar. Because of its well defined syntax and extensively well codified rules, many researchers have made attempts to codify the pARini閳ユ獨 sutras as computer programs to analyze Sanskrit texts.  \subsection{Introduction of Sandhi and Sandhi Split in Sanskrit}  Sandhi refers to a phonetic transformation at word boundaries, where two words are combined to form a new word. Sandhi literally means 'placing together'  is the principle of sounds coming together naturally according to certain rules codified by the grammarian pARini in his azwADyAyI. There are 3 different types of Sandhi as defined in azwADyAyI.  An example for each type Sandhi is shown below:  \end{quote}  Sandhi Split on the other hand, resolves Sanskrit compounds and 閳ユ笡honetically merged閳  words into its constituent morphemes. Sandhi Split comes with additional challenge of not only splitting of compound word correctly, but also predicting where to split. Since Sanskrit compound word can be split in multiple ways based on multiple split locations possible, split words may be syntactically correct but semantically may not be meaningful.  \end{quote}   \subsection{Existing Work on Sandhi} The current resources available for doing Sandhi in open domain are not very accurate. Three most popular publicly available set of Sandhi tools viz. JNU, UoH \& INRIA tools are mentioned in table .     \end{table*}   An analysis and description of these tools is present in the paper on Sandhikosh . The same paper introduced a dataset for Sandhi and Sandhi Split verification and compared the performance of the tools in table  on that dataset.  Neural networks have been used for Sandhi Split by many researchers, for example ,  and . The task of doing Sandhi has been mainly addressed as a rule based algorithm e.g. . There is no research on Sandhi using neural networks in public domain so far. This paper describes experiments with Sandhi operation using neural networks and compares results of suggested approach with the results achieved using existing Sandhi tools .  \subsection{Existing Work on Sandhi Split}  Many researchers like  and  have tried to codify pARini閳ユ獨 rules for achieving Sandhi Split along with a lexical resource.  proposed a statistical method based on Dirichlet process. Finite state methods have also been used . A graph query method has been proposed by .  Lately, Deep Learning based approaches are increasingly being tried for Sandhi Split.  used a one-layer bidirectional LSTM to two parallel character based representations of a string.  and  proposed deep learning models for Sandhi Split at sentence level.  uses a double decoder model for compound word split.  The method proposed in this paper describes an RNN based, two stage deep learning method for Sandhi Split of isolated compound words without using any lexical resource or sentence information.  In addition to above, there exist multiple Sandhi Splitters in the open domain. The prominent ones being JNU Sandhi Splitter  , UoH Sandhi Splitter  and INRIA Sanskrit reader companion. The paper  compares the performance of above 3 tools with their results. This was an attempt to create benchmark in the area of Sanskrit Computational Linguistics.     In this research work, we propose Pratyaya-Kosh, a benchmark corpus to help researchers new to Sanskrit in building AI based Morphological Analyzer for Sanskrit derivative nouns. Also we propose neural approach for learning derivative noun formation without use of any external resources such as language models, morphological or phonetic analyzers and still manage to outperform existing approaches. In future we intend to extend current work to verb derivative and indeclinable derivative using machine learning methods. Proposed models can be further refined by using additional training data. Benchmark corpus  will be made available on git hub.       
"," This paper describes neural network based approaches to the process of the formation and splitting of word-compounding, respectively known as the Sandhi  and Vichchhed, in Sanskrit language. Sandhi is an important idea essential to morphological analysis of Sanskrit texts. Sandhi leads to word transformations at word boundaries. The rules of Sandhi formation are well defined but complex, sometimes optional and in some cases, require knowledge about the nature of the words being compounded. Sandhi split or Vichchhed is an even more difficult task given its non uniqueness and context dependence. In this work, we propose the route of formulating the problem as a sequence to sequence prediction task, using modern deep learning techniques. Being the first fully data driven technique, we demonstrate that our model has an accuracy  better than the existing methods on multiple standard datasets, despite not using any additional lexical or morphological resources. The code is being made available at https://github.com/IITD-DataScience/Sandhi\_Prakarana",286
"   % Unsupervised representation learning allows models to learn high-level latent representations from unlabeled data.  % Models pretrained from unsupervised data can be fine-tuned with a small amount of labeled data. % % Deep probabilistic generative models presents a powerful approach to learn representations by modeling the data generation process.  % Variational AutoEncoders  are one of the popular approaches to representation learning by modeling the latent features in a unit Gaussian space. % Vector-Quantized VAE  is a method to learn discrete representations from data.  Speech waveforms are a complex, high-dimensional form of data influenced by a number of underlying factors, which can be broadly categorized into linguistic contents and speaking styles. % Learning disentangled latent representations from speech has a wide set of applications in generative tasks, including speech synthesis, data augmentation, voice transfer, and speech compression. Downstream tasks such as speech recognition  and speaker classification  can also benefit from such learned representations. % A pre-trained model can also be fine-tuned for classification tasks such as speech recognition and speaker classification. % \ngyuzh{what about rephrase it like: Downsteam tasks such as speech recognition  and speaker classification  can also benefit from such learned representations.}  Because of the cost, complexity, and privacy concerns around collecting labeled speech data, there has been a lot of interest in unsupervised representation learning for speech. Of particular interest is to learn representations for speech styles from unsupervised data due to the difficulty in describing prosody with human labels.  Some previous works aim to learn global representations from entire speech sequences. % Global style tokens learn a dictionary of embeddings from speech without prosody labels. % As another example, Hsu et al.  model disentangled speech styles with a hierarchy of variational autoencoder . % Hu et al.  proposed a content and style separation model by pre-training on a single-speaker dataset with text transcription and minimizing mutual information  between the content and style representation.  Other works try to learn fine-grain localized representations of speech. %  apply self-supervised learning to unlabeled speech data and extract localized latent representations that can be fine-tuned for speech recognition. % FHVAE learns a sequence of high-level features by applying VAE to every frame. %  leverages vector-quantized VAE  to learn a discrete sequence representation of speech.  We propose a framework to learn both global and localized representation of speech. In order to disentangle content and style representations, we apply  a local encoder with VQ layer to learn a discrete per-timestep representation of the speech that captures the linguistic contents and  a global VAE to extraction per-utterance representations to reflect the speech styles. We further disentangle the local and global representations with a mutual information loss. We evaluate the quality of linguistic and style representations by running speech and speaker recognition models on the reconstructed speech. We also show that the global representation captures the speaker information well enough that we can obtain a speaker classification model by training a linear projection layer on top of the global representation with only one example per speaker.     In this research work, we propose novel algorithms for Sandhi word formation and Sandhi Split that can be trained without use of any external resources such as language models, morphological or phonetic analyzers, and still manage to match or outperform existing approaches. Due to the simplicity of the models, these are computationally inexpensive to train and execute. In future we intend to extend current work to internal Sandhi and internal Sandhi-split using machine learning methods. Proposed models can be further refined by using additional training data as well as investigating techniques to reduce the errors in current training data.          The next two lines define the bibliography style to be used, and    the bibliography file. 
"," We present an approach for unsupervised learning of speech representation disentangling contents and styles. Our model consists of:  a local encoder that captures per-frame information;  a global encoder that captures per-utterance information; and  a conditional decoder that reconstructs speech given local and global latent variables. Our experiments show that  the local latent variables encode speech contents, as reconstructed speech can be recognized by ASR with low word error rates , even with a different global encoding;  the global latent variables encode speaker style, as reconstructed speech shares speaker identity with the source utterance of the global encoding. Additionally, we demonstrate an useful application from our pre-trained model, where we can train a speaker recognition model from the global latent variables and achieve high accuracy by fine-tuning with as few data as one label per speaker. % % \rpang{How about: Our deep generative model consists of:  a local encoder that captures per-frame information;  a global encoder that captures per-utterance information; and  a conditional decoder that reconstruct speech given local and global latent variables, potentially extracted from different utterances. Our experiments show that  the local latent variables encode speech contents, since reconstructed speech can be recognized by ASR with low word error rates , even with a different global encodings;  the global latent variables encode speaker style, as reconstructed speech shares speaker identity with the source utterance of the global encoding and a speaker recognition model can be trained from the global latent variables with as few as one supervised example per speaker.  % }",287
"  %Sentiment analysis  is one of the fundamental tasks in natural language processing that aims to find the attitude that the author expressed in his/her sentence. One of the important sub-tasks of SA is aspect based sentiment analysis in which the goal is to find the sentiment polarity toward a specific aspect mentioned in the sentence. Due to the importance of ABSA, several sub-tasks has been proposed and studied for this problem, including aspect category extraction, aspect term extraction, opinion word extraction and opinion summarization . Among these sub-tasks, Targeted Opinion Word Extraction  is an important sub-task that might provide useful information to explain the prediction of the sentiment polarity from an ABSA system. In particular, the goal of TOWE is to find the words that express the attitude of the author toward a specific target mentioned in that sentence. For instance, in the sentence ``The food is good, especially their more basic dishes, and the drinks are delicious"", the word ``good"" is the opinion word for the target ``food"" while delicious is the opinion word for the target word ``drinks"". Among different applications, TOWE can be used for target-oriented sentiment analysis  and pair-wise opinion summarization .  %Sentiment analysis  is one of the fundamental tasks in natural language processing that aims to find the attitude that the author expressed in his/her sentence. One of the important sub-tasks of SA is aspect based sentiment analysis in which the goal is to find the sentiment polarity toward a specific aspect mentioned in the sentence. Due to the importance of ABSA, several sub-tasks has been proposed and studied for this problem, including aspect category extraction, aspect term extraction, opinion word extraction and opinion summarization . Among these topics, Targeted Opinion Word Extraction  is an important task that might provide useful information to explain and/or improve the sentiment polarity prediction of the ABSA systems. In particular, given a target word  in the input sentence, the goal of TOWE is to find the words in the sentence  that help to express the attitude of the author toward the aspect represented by the target word. For instance, in the sentence ``The food is good, especially their more basic dishes, and the drinks are delicious"", ``good"" is the opinion word for the target word ``food"" while the opinion words for the target word ``drinks"" would involve ``delicious''. Among different applications, TOWE finds its application in target-oriented sentiment analysis  and pair-wise opinion summarization .   %Targeted Opinion Word Extraction  is an important task in aspect based sentiment analysis  of sentiment analysis . Given a target word  in the input sentence, the goal of TOWE is to find the words in the sentence  that help to express the attitude of the author toward the aspect represented by the target word. For instance, in the sentence ``The food is good, especially their more basic dishes, and the drinks are delicious"", ``good"" is the opinion word for the target word ``food"" while the opinion words for the target word ``drinks"" would involve ``delicious''. As the opinion words might provide useful information to explain and/or improve the sentiment prediction of the ABSA systems, TOWE can be applied in different problems, including target-oriented sentiment analysis  and pair-wise opinion summarization .  Targeted Opinion Word Extraction  is an important task in aspect based sentiment analysis  of sentiment analysis . Given a target word  in the input sentence, the goal of TOWE is to identify the words in the sentence  that help to express the attitude of the author toward the aspect represented by the target word. For instance, as a running example, in the sentence ``All warranties honored by XYZ  are disappointing."", ``disappointing"" is the opinion word for the target word ``warranties"" while the opinion words for the target word ``company"" would involve ``reputable''. Among others, TOWE finds its applications in target-oriented sentiment analysis  and opinion summarization .   %As the opinion words might provide useful information to explain and/or improve the sentiment prediction of the ABSA systems, TOWE can be applied in different problems, including target-oriented sentiment analysis  and pair-wise opinion summarization .  %A notable problem is that although the related tasks of TOWE has been extensively explored in the past, there have been only a few work to explicitly consider the TOWE problem in the literature . In particular, the most related task of TOWE is opinion word extraction  that aims to locate the terms used to express attitude explicitly in the sentence . A key difference between OWE and TOWE is that OWE does not require the opinion words to tie to any target words in the sentence  while the opinion words in TOWE should be explicitly paired with a given target word. Note that some previous works have also attempted to jointly predict the target and opinion words ; however, the target words are still not paired with their corresponding opinion words in these studies .    %Among the previous works for TOWE, t  The early approach for TOWE has involved the rule-based and lexicon-based methods  while the recent work has focused on deep learning models for this problem . One of the insights from the rule-based methods is that the syntactic structures  of the sentences can provide useful information to improve the performance for TOWE . However, these syntactic structures have not been exploited in the current deep learning models for TOWE . Consequently, in this work, we seek to fill in this gap by extracting useful knowledge from the syntactic structures to help the deep learning models learn better representations for TOWE. In particular, based on the dependency parsing trees, we envision two major syntactic information that can be complementarily beneficial for the deep learning models for TOWE, i.e., the syntax-based opinion possibility scores and syntactic word connections for representation learning. First, for the syntax-based possibility scores, our intuition is that the closer words to the target word in the dependency tree of the input sentence tend to have better chance for being the opinion words for the target in TOWE. For instance, in our running example, the opinion word ``disappointing"" is sequentially far from its target word ``warranties"". However, in the dependency tree shown in Figure , ``disappointing"" is directly connected to ``warranties"", promoting the distance between ``disappointing"" and ``warranties""  in the dependency tree as an useful feature for TOWE. Consequently, in this work, we propose to use the distances between the words and the target word in the dependency trees to obtain a score to represent how likely a word is an opinion word for TOWE . These possibility scores would then be introduced into the deep learning models to improve the representation learning for TOWE.  In order to achieve such possibility score incorporation, we propose to employ the representation vectors for the words in the deep learning models to compute a model-based possibility score for each word in the sentence. The model-based possibility scores also aim to quantify the likelihood of being an opinion word for each word in the sentence; however, they are based on the internal representation learning mechanism of the deep learning models for TOWE. To this end, we propose to inject the information from the syntax-based possibility scores into the models for TOWE by enforcing the similarity/consistency between the syntax-based and model-based possibility scores for the words in the sentence. The rationale is to leverage the possibility score consistency to guide the representation learning process of the deep learning models  to generate more effective representations for TOWE. In this work, we employ the Ordered-Neuron Long Short-Term Memory Networks   to obtain the model-based possibility scores for the words in the sentences for TOWE. ON-LSTM introduces two additional gates into the original Long Short-Term Memory Network  cells that facilitate the computation of the model-based possibility scores via the numbers of active neurons in the hidden vectors for each word.  %The second type of syntactic information employed for TOWE in this work considers the dependency connections between the words in the sentence.   %As the deep learning models need to compute a representation vector for each word to perform opinion word prediction in TOWE,   %While the possibility scores aim to improve the representation vectors for TOWE via the syntax-based possibility features, the second type of syntactic information in this work seeks to do so by leveraging the dependency connections between the words to infer the effective context words to be encoded in the representation vector for each word in the sentence. In particular, motivated by our running example, we argue that the effective context words for the representation vector for a current word in TOWE involve the neighboring words of the current word and the target word in the dependency tree. For instance, consider the running example with ``warranties"" as the target word and ``reputable"" as the word we need to compute the representation vector. One the one hand, it is important to include the information of the neighboring words of ``reputable""  in the representation so the models can know the context for the current word . On the other hand, the information about the target word  should also be encoded in the representation vector for ``reputable"" so the models can be aware of the context of the target word and make appropriate comparison in the representation to decide the label  for ``reputable"" in this case. Note that this syntactic connection mechanism allows the models to de-emphasize the context information of ``I'' in the representation for ``reputable"" to improve the representation quality. Consequently, in this work, we propose to formulate these intuitions into an importance score matrix whose cells quantify the contextual importance that a word would contribute to the representation vector of another word given a target word for TOWE. These importance scores will be conditioned on the distances between the target word and the other words in the dependency tree. Afterward, the score matrix will be consumed by a Graph Convolutional Neural Network  model  to produce the final representation vectors for opinion word prediction.  For the second type of syntactic information in this work, the main motivation is to further improve the representation vector computation for each word by leveraging the dependency connections between the words to infer the effective context words for each word in the sentence. In particular, motivated by our running example, we argue that the effective context words for the representation vector of a current word in TOWE involve the neighboring words of the current word and the target word in the dependency tree. For instance, consider the running example with ``warranties"" as the target word and ``reputable"" as the word we need to compute the representation vector. On the one hand, it is important to include the information of the neighboring words of ``reputable""  in the representation so the models can know the context for the current word . On the other hand, the information about the target word  should also be encoded in the representation vector for ``reputable"" so the models can be aware of the context of the target word and make appropriate comparison in the representation to decide the label  for ``reputable"" in this case. Note that this syntactic connection mechanism allows the models to de-emphasize the context information of ``I'' in the representation for ``reputable"" to improve the representation quality. Consequently, in this work, we propose to formulate these intuitions into an importance score matrix whose cells quantify the contextual importance that a word would contribute to the representation vector of another word, given a target word for TOWE. These importance scores will be conditioned on the distances between the target word and the other words in the dependency tree. Afterward, the score matrix will be consumed by a Graph Convolutional Neural Network  model  to produce the final representation vectors for opinion word prediction.  Finally, in order to further improve the induced representation vectors for TOWE, we introduce a novel inductive bias that seeks to explicitly distinguish the representation vectors of the target-oriented opinion words and those for the other words in the sentence. We conduct extensive experiments to demonstrate the benefits of the proposed model, leading to the state-of-the-art performance for TOWE in several benchmark datasets.  %Finally, in order to further improve the induced representation vectors for TOWE, we introduce a novel inductive bias that seeks to explicitly distinguish the representation vectors of the target-oriented opinion words  and those for the other opinion words  in the sentence . Extensive experiments are conducted to demonstrate the benefits of the proposed model, leading to the state-of-the-art performance for TOWE in several datasets.  %Finally, in order to further improve the induced representation vectors for TOWE, we introduce a novel inductive bias that seeks to explicitly distinguish the representation vectors of the target-related opinion words  and those for the other opinion words  in the sentence . As both target-related and non-target opinion words can be used to express the opinion of the author , we expect that the explicit representation distinction would help to better separate the two types of opinion words based on the target word, eventually improving the performance for TOWE in this work. We conduct extensive experiments to demonstrate the benefits of the proposed model, leading to the state-of-the-art performance for TOWE in several datasets.   %the close distance between ``disappointing"" and the target word will suggest the models to include the information of ``warranties"" into the representation vector for ``disappointing"" while the long distance between ``warranties"" and ``reputable"" can help to prevent/mitigate that for the representation vector of ``reputable"". The presence of the information from the target word in the representation vectors will help the models to successfully accept ``disappointing"" as an opinion word and reject ``reputable"" in this case.   %the close words to the target word would provide more effective information to induce the representation vectors for a word in the sentence in TOWE than the farther ones.   %we argue that the syntactic neighboring words in the dependency tree would provide effective information to induce the representation vector for a word in opinion word prediction. For instance, in the running example with the target word ``warranties"", the close distance between ``disappointing"" and the target word will suggest the models to include the information of ``warranties"" into the representation vector for ``disappointing"" while the long distance between ``warranties"" and ``reputable"" can help to prevent/mitigate that for the representation vector of ``reputable"". The presence of the information from the target word in the representation vectors will help the models to successfully accept ``disappointing"" as an opinion word and reject ``reputable"" in this case.  %employ the dependency connections between the words to infer the effective context words .    %employ the syntactic neighboring words to compute the representation vectors for a word in the sentence for TOWE.   %extends the popular Long Short-Term Memory Networks  by introducing two additional gates  in the hidden vector computation. These new gates controls how long each neuron in the hidden vectors should be activated across different time steps  in the sentence . Based on such controlled neurons, the model-based importance score for a word can be determined by the number of active neurons that the word possesses in the operation of ON-LSTM. To our knowledge, this is the first time ON-LSTM is applied for RE in the literature.  %How can we encode the syntax-based importance scores of the words into a deep model? In this paper, we propose to employ the syntax-based importance scores to retain or update the information encoded in the representations of each word. In particular, those words that are syntactically more important should retain more information in the computation graph of the deep model while the information about less important words should be discarded more frequently. In order to impose this information update policy in our model, we use the new proposed architecture Ordered-Neuron Long Short-Term Memory  . ON-LSTM is an extension of the well-known Long Short-Term Memory  with two additional gates . These new gates are employed to control the frequency of updating each neuron across different time steps  in the sentence. Concretely, the values of the master forget and input gates determine how much information in the hidden vector of the LSTM cell should be retained or updated based on the word at the current time step. Thereby, one can infer the importance scores inferred by the model  using the values of the master forget or input gates. So, based on this characteristics of ON-LSTM, to encode the syntax-based importance scores into our model, we propose to exploit the syntax-based importance scores to regulate model-based importance scores. Specifically, in training time, we encourage the model-based scores to be consistent with syntax-based importance scores.  %the two words ``disappointing"" and ``warranties"" are directly connected to each other.  %Early feature-based models  has shown that syntactical structure of the sentence is useful for TWOE. More specifically, the application of dependency tree for TOWE is two fold:  Pairwise Word Importance: Dependency tree is useful to infer the relative importance of a word toward another word  in the same sentence. This relative importance could be helpful for TOWE to attend to the important words for the target word. To infer pair-wise importance of two words using dependency tree, one can computes the distance between two words in the dependency tree. For instance, as a running example, in the sentence ``All warranties honored by HP  are disappointing"", the opinion word ``disappointing"" is sequentially far from its target word ``warranties"". However, in the dependency tree shown in Figure , the two words ``disappointing"" and ``warranties"" are directly connected to each other. The short distance between these two words could be helpful to infer the importance of the word ``disappointing"" for the target ``warranties"".  Word Connection: Dependency tree could provide better contextual information for each word via the connections of the word with its head and dependants, thus it helps to improve word representations. Thereby, dependency tree could benefit TOWE. For instance, in the running example, the head of ``reputable"" is ``company"" while the head of ``warranties"" is ``disappointing"". Therefore, it would be easier to infer that the opinion word ``disappointing"" is related to the target word ``warranties"" and ``reputable"" is irrelevant.   %Besides the difference between the rule-based and deep learning models for TOWE regarding the representation learning methods, the rule-based methods have exploited the syntactic structures  of the sentences to improve the performance for TOWE while  %In particular, the related tasks of TOWE involves target word extraction/aspect term exaction  , and opinion word extraction   . A key difference between OWE and TOWE is that the opinion words in OWE are general and do not need to tie to any target words in the sentence while TOWE explicitly   %Despite its potential benefits, TOWE has only been studied by a few works in the past, characterizing the early rule-based and lexicon-based approaches  and very recently deep learning models .   %In the literature, feature-based models and deep learning model has been proposed for both target word extraction  and opinion word extraction . While joint models predict both the opinion and the target words, they cannot pair up them, thus being unable to solve the task of TOWE. In the literature, only a few of works have studied the task of TOWE, including the early attempts with the rule-based and lexicon-based approaches  and the recent works with deep learning models for TOWE .       We present a framework to learn disentangled representations of speech with unlabeled data. The framework includes a local VQ encoder to extract a discrete sequence representation of the speech contents and a global VAE encoder to learn a continuous representation of speech styles. Our evaluation shows that the discrete sequence representation effectively captures the linguistic contents while the continuous global representation encapsulates the speaker style. Additionally, we also show the application from our pre-trained model, in which we successfully train a speaker recognition system with high accuracy  only with one sample per speaker.  \vfill\pagebreak    References should be produced using the bibtex program from suitable   BiBTeX files . The IEEEbib.bst bibliography   style file from IEEE produces unsorted bibliography list.   ------------------------------------------------------------------------- 
"," Targeted opinion word extraction  is a sub-task of aspect based sentiment analysis  which aims to find the opinion words for a given aspect-term in a sentence. Despite their success for TOWE, the current deep learning models fail to exploit the syntactic information of the sentences that have been proved to be useful for TOWE in the prior research. In this work, we propose to incorporate the syntactic structures of the sentences into the deep learning models for TOWE, leveraging the syntax-based opinion possibility scores and the syntactic connections between the words. We also introduce a novel regularization technique to improve the performance of the deep learning models based on the representation distinctions between the words in TOWE. The proposed model is extensively analyzed and achieves the state-of-the-art performance on four benchmark datasets.  %Deep learning models have been shown to achieve the state-of-the-art performance for TOWE in the recent studies.  %While previous feature-based models have shown syntactical structure  is useful for this task, recent deep neural nets ignore this information in their model. To address this limitation, in this paper, we propose a new approach which incorporates syntactical structure  into deep neural nets. More specifically, our model employs the dependency tree to capture the relative importance of the words to the aspect-term and to encode the connections between words. Our extensive experiments on four benchmark datasets prove the superiority of the proposed model, leading to new state-of-the-art results on all datasets. Moreover, detailed analysis shows the effectiveness of the components of the proposed model.",288
"  Aspect-based Sentiment Analysis  is a fine-grained version of sentiment analysis  that aims to find the sentiment polarity of the input sentences toward a given aspect. We focus on the term-based aspects for ABSA where the aspects correspond to some terms  in the input sentence. For instance, an ABSA system should be able to return the negative sentiment for input sentence ``The staff were very polite, but the quality of the food was terrible.'' assuming ``food'' as the aspect term.    %Aspect based sentiment analysis  is a fine-grained version of sentiment analysis . In ABSA, the goal is to find the sentiment polarity of the sentence toward a given aspect. In the literature, two versions of aspect have been proposed:  Aspect-category: Aspect categories are a set of pre-defined categories in which the given sentence contains opinion of the author toward one of them. Aspect categories may not explicitly appear in the sentence.  Aspect-term: Aspect term is a subsequent of the sentence in which the given sentence express sentiment toward it. For instance in the example The staff were very polite, but the quality of the food was terrible., the author has a positive sentiment toward aspect-category service and negative sentiment toward aspect-term food. In this paper, we introduce a novel model for sentiment analysis toward aspect-term.  %The early attempts for ABSA have performed feature engineering to produce useful features for the statistical models  for this problem . One limitation of these feature-based models is that they require significant human effort and linguistic background to design effective features. In order to overcome this limitation,  %The typical network architectures for ABSA in the literature involve convolutional neural networks  , recurrent neural networks  , memory networks , attention  and gating mechanisms .  %automatically induce effective features for ABSA and  Due to its important applications , ABSA has been studied extensively in the literature. In these studies, deep learning has been employed to produce the state-of-the-art performance for this problem . Recently, in order to further improve the performance, the syntactic dependency trees have been integrated into the deep learning models  for ABSA . Among others, dependency trees help to directly link the aspect term to the syntactically related words in the sentence, thus facilitating the graph convolutional neural networks   to enrich the representation vectors for the aspect terms.  %Although the graph-based models have achieved decent performance for ABSA, these models have   However, there are at least two major issues in these graph-based models that should be addressed to boost the performance. First, the representation vectors for the words in different layers of the current graph-based models for ABSA are not customized for the aspect terms. This might lead to suboptimal representation vectors where the irrelevant information for ABSA might be retained and affect the model's performance. Ideally, we expect that the representation vectors in the deep learning models for ABSA should mainly involve the related information for the aspect terms, the most important words in the sentences. Consequently, in this work, we propose to regulate the hidden vectors of the graph-based models for ABSA using the information from the aspect terms, thereby filtering the irrelevant information for the terms and customizing the representation vectors for ABSA. In particular, we compute a gate vector for each layer of the graph-based model for ABSA leveraging the representation vectors of the aspect terms. This layer-wise gate vector would be then applied over the hidden vectors of the current layer to produce customized hidden vectors for ABSA. In addition, we propose a novel mechanism to explicitly increase the contextual distinction among the gates to further improve the representation vectors.  %as the hidden vectors at different layers of the graph-based models tend to capture different levels of contextual information, the gate vectors for the different layers should also maintain some level of contextual distinction. To this end, we propose a novel mechanism to explicitly increase the contextual distinction among the gate vectors to further improve the quality of the representation vectors.  The second limitation of the current graph-based deep learning models is the failure to explicitly exploit the overall importance of the words in the sentences that can be estimated from the dependency trees for the ABSA problem. In particular, a motivation of the graph-based models for ABSA is that the neighbor words of the aspect terms in the dependency trees would be more important for the sentiment of the terms than the other words in the sentence. The current graph-based models would then just focus on those syntactic neighbor words to induce the representations for the aspect terms. However, based on this idea of important words, we can also assign a score for each word in the sentences that explicitly quantify its importance/contribution for the sentiment prediction of the aspect terms. In this work, we hypothesize that these overall importance scores from the dependency trees might also provide useful knowledge to improve the representation vectors of the graph-based models for ABSA. Consequently, we propose to inject the knowledge from these syntax-based importance scores into the graph-based models for ABSA via the consistency with the model-based importance scores. In particular, using the representation vectors from the graph-based models, we compute a second score for each word in the sentences to reflect the model's perspective on the importance of the word for the sentiment of the aspect terms. The syntax-based importance scores are then employed to supervise the model-based importance scores, serving as a method to introduce the syntactic information into the model. In order to compute the model-based importance scores, we exploit the intuition that a word would be more important for ABSA if it is more similar the overall representation vector to predict the sentiment for the sentence in the final step of the model. In the experiments, we demonstrate the effectiveness of the proposed model with the state-of-the-art performance on three benchmark datasets for ABSA. In summary, our contributions include:   %, we propose to obtain another important score for each word in the sentence based on the representation vectors from the models. These model-based importance scores are then   %In particular, for ABSA, some words might introduce more useful information to predict the sentiment of the aspect terms than the the other words in the sentence   %In particular, some words in a given sentence might involve more useful information for relation prediction in RE than the other words, and the dependency tree for this sentence can help to better identify those important words and assign higher importance scores for them . We expect that introducing such importance information for the words in the deep learning models might lead to improved performance for RE. Consequently, in this work, we propose to obtain an importance score for each word in the sentences from the dependency trees . These will serve as the general tree representation to incorporate the syntactic information into the deep learning models for RE.  %In particular, as the aspect terms are the most important words in the sentences for ABSA,     %Syntactical structure, e.g., dependency tree, could shorten the distance between syntactically related words thus improve the contextualized representation of the words. In order to incorporate the syntactical tree into the deep models, recent work mainly employs the graph convolutional network   to model the interaction between words based on the syntactic tree. In order to emphasize on the given aspect term, current models use the representation of the aspect term generated by GCN either directly for final classification or as a gate to filter out features of a sequential model. However, these methods cannot benefit from the information of the given aspect term to control the information flow in the graph based model. Moreover, it is expected that the words that are syntactically related to the given aspect term should convey more information about the sentiment toward it. Unfortunately, non of the existing work considers this relative importance in the final representation of the sentence. In order to address these issue, we propose a new graph based model which employs the semantic of the given aspect term to control interaction between nodes/words in the GCN model and to emphasize more on the syntactically important words in the final representation of the sentence.  %Due to the application of ABSA in other downstream applications, e.g., opinion mining, it has gained a lot of attention in natural language processing community and several methods have been proposed for this task. Early attempts employed feature engineering to extract useful features for statistical models like SVM . These methods require extensive human effort and strong linguistic knowledge. They also suffer from low generalization ability. Due to these limitations, neural networks and deep models have superseded feature based models and obtain promising results in ABSA . Early deep models for ABSA have exploited sequential models  , convolutional neural nets  or even memory networks . In order to improve the performance, attention  and gating mechanism  has also been widely adopted in deep models. Recently, it has been shown that syntactical information could also improve the performance of deep models . Syntactical structure, e.g., dependency tree, could shorten the distance between syntactically related words thus improve the contextualized representation of the words. In order to incorporate the syntactical tree into the deep models, recent work mainly employs the graph convolutional network   to model the interaction between words based on the syntactic tree. In order to emphasize on the given aspect term, current models use the representation of the aspect term generated by GCN either directly for final classification or as a gate to filter out features of a sequential model. However, these methods cannot benefit from the information of the given aspect term to control the information flow in the graph based model. Moreover, it is expected that the words that are syntactically related to the given aspect term should convey more information about the sentiment toward it. Unfortunately, non of the existing work considers this relative importance in the final representation of the sentence. In order to address these issue, we propose a new graph based model which employs the semantic of the given aspect term to control interaction between nodes/words in the GCN model and to emphasize more on the syntactically important words in the final representation of the sentence.   %In particular, in this paper, we propose a novel model which employs the representation of the given aspect term to compute a gate. This gate is applied over the output of one layer of GCN. By doing so, the information represented in the aspect term would erase non-relevant information in each node/word obtained by its interaction with its neighbors in one aggregation step in GCN. As different layers of GCN capture different substructure of the graph, e.g., 1-hop vicinity vs 2-hop vicinity, we propose to exploit different gates in different layers. To ensure the gates in different layers are not the same, we propose a novel method to encourage diversity among gates in different layers of the GCN. Moreover, in addition to exploiting the semantic of the aspect term to control interactions between nodes/words in the GCN, in this paper, we propose to encourage the model to emphasize on the words that are syntactically important to the aspect term. In particular, we use the distance between a word to the aspect term in the dependency tree as an indication of the syntactic importance of the word to the aspect term. This importance is employed as supervision signal to encourage the model to emphasize on the words that are syntactically important to the aspect term. This is obtained in the final layer of the model when the sentiment prediction is performed. More specifically, we first estimate the semantic importance of each word by employing the final representation of the word as the input to a classifier to predict the label distribution and then we compute the KL-Divergence between this label distribution predicted by the word representation and the label distribution predicted by the sentence representation. If the two label distribution are more similar, it shows that the word representation contains most of the information that the model consumes to perform the final classification. Finally, in order to ensure those words which are syntactically important to the aspect term are semantically important in the model too, we decrease the divergence between distribution of the syntactic score and semantic score for each word via KL-Divergence between these two distributions.  %Our extensive experiments on three benchmark datasets, empirically prove the effectiveness of the proposed model leading to new state-of-the-art results in all three benchmark datasets.      A novel method to regulate the GCN-based representation vectors of the words using the given aspect term for ABSA.   A novel method to encourage the consistency between the syntax-based and model-based importance scores of the words based on the given aspect term.   Extensive experiments on three benchmark datasets for ABSA, resulting in new state-of-the-art performance for all the datasets.      We propose a novel deep learning model for TOWE that seeks to incorporate the syntactic structures of the sentences into the model computation. Two types of syntactic information are introduced in this work, i.e., the syntax-based possibility scores for words  and the syntactic connections between the words . We also present a novel inductive bias to improve the model, leveraging the representation distinction between the words in TOWE. Comprehensive analysis is done to demonstrate the effectiveness of the proposed model over four datasets.   Our comprehensive analysis on the model architecture together with the extensive experiments on four benchmark datasets demonstrate the effectiveness of the proposed model.   More specifically, the syntactic structure is employed to infer the target-related importance of the words and it is incorporated into the model using the newly proposed architecture Ordered-Neuron LSTM . Moreover, we employed GCN to encode word connections in the dependency tree. To overcome the noisy or non-relevant connections in the dependency tree, we propose to learn a dense graph out of the dependency tree which is customized to the given target word. Finally, we introduce a syntax-based regularization to preserve target-related information in the model. Our comprehensive analysis on the model architecture together with the extensive experiments on four benchmark datasets show the effectiveness of the proposed model, establishing new the state-of-the-art results on all of datasets.    In this work, we study the target-oriented opinion word extraction problem , one of the sub-tasks of aspect-based sentiment analysis  . We propose a deep learning model to incorporate the syntactic structure into the model computations. More specifically, the syntactic structure is employed to infer the target-related importance of the words and it is incorporated into the model using the newly proposed architecture Ordered-Neuron LSTM . Moreover, we employed GCN to encode word connections in the dependency tree. To overcome the noisy or non-relevant connections in the dependency tree, we propose to learn a dense graph out of the dependency tree which is customized to the given target word. Finally, we introduce a syntax-based regularization to preserve target-related information in the model. Our comprehensive analysis on the model architecture together with the extensive experiments on four benchmark datasets show the effectiveness of the proposed model, establishing new the state-of-the-art results on all of datasets.  
"," Aspect-based Sentiment Analysis  seeks to predict the sentiment polarity of a sentence toward a specific aspect. Recently, it has been shown that dependency trees can be integrated into deep learning models to produce the state-of-the-art performance for ABSA. However, these models tend to compute the hidden/representation vectors without considering the aspect terms and fail to benefit from the overall contextual importance scores of the words that can be obtained from the dependency tree for ABSA. In this work, we propose a novel graph-based deep learning model to overcome these two issues of the prior work on ABSA. In our model, gate vectors are generated from the representation vectors of the aspect terms to customize the hidden vectors of the graph-based models toward the aspect terms. In addition, we propose a mechanism to obtain the importance scores for each word in the sentences based on the dependency trees that are then injected into the model to improve the representation vectors for ABSA. The proposed model achieves the state-of-the-art performance on three benchmark datasets.  %These models employ graph based neural nets to incorporate syntactical structure into the model. However, they ignore the aspect term information to control the interaction between words in the syntax tree which is modeled by graph neural net.  % Moreover, they neglect the consistency between the syntactic and semantic importance of the words toward the given aspect. %Moreover, the relative importance of the words to the given aspect term based on their syntactical role is neglected in the final representation produced by the existing syntax-aware models. To address these two issues, in this paper, we introduce a new syntax-aware model which incorporates gating mechanism to control information flow in the graph based model using the given aspect term. It also ensures the words that are syntactically important to the aspect term are more pronounced in the final representation of the sentence. Our extensive experiments on three benchmark datasets empirically prove the effectiveness of the proposed model leading to new state-of-the-art results on all three benchmark datasets.",289
" Entity normalization and variant generation are fundamental for a variety of other tasks such as semantic search and relation extraction . Given an entity name , the goal of entity normalization is to convert  to a canonical form , while the goal of entity variant generation is to convert  to a set of different textual representations that refer to the same entity as E .   \looseness=-1 Typically, entity normalization and variant generation are done by first performing entity linking , i.e., matching entity names appearing in some context  to named entities in curated knowledge bases , then use the canonical form or variations  residing in the KBs to complete the tasks. Unfortunately, in some scenarios, such as search , entity names are not surrounded by context.  Furthermore, for specialized domain-specific applications, there may not be a knowledge base to govern the names of the relevant entities. Thus, entity linking is not always applicable. In this paper,  we take the view  %the problem differently, in particular, we argue  that entity normalization and variant generation can be done without contextual information or  external KBs if we understand the internal structures of entity names.  % Fundamental to the success of entity linking is the availability of the contextual information  and ontological information .    %  and there are no external KBs that we can use as master datasets to match input entity names. \todo{One may argue that DBpedia and Wikipedia is a good proxy. It may be useful to talk about related work taking this view here.} % For example, when searching \example{General Electric Company}, we need to also consider variations like \example{GE Co.}, \example{G.E.}, \example{General Electric}, etc. without relying on any contextual information and external KBs.  % Performing entity normalization and variant generation in a contextless fashion is extremely challenging because we have only the surface forms of entity names.  % Several attempts have been made to parse the structured representation of entity names. As observed in , entity names often have  %structured representation  implicit structures  that can be exploited to solve entity normalization and variant generation. Table  shows how we can manipulate such structured representations of entity names to generate different variations without help from context or external knowledge.  % For example, if we know that \example{Michael} is \component{first} and \example{Jordan} is \component{last} in \example{Michael Jordan}, we can generate two variations:  \example{M. Jordan}  and  \example{Jordan, Michael} .     \end{table*}  Declarative frameworks are proposed in  to allow  %high-skill  developers to manually specify rules that parse  entity names into  %the  a structured representation. %of enity names. To avoid such low-level manual effort,  used fully supervised methods for identifying nested entities embedded in flat named entities. Unfortunately, labeled data are rarely available to leverage these methods in the real-world.  To mitigate the need for training data,  proposed an active learning %-based  system, LUSTRE, to semi-automatically learn rules for mapping entity names to their structured representations.  By  %making use of  using regex-based extractors and a list of comprehensive dictionaries that capture crucial domain vocabularies, LUSTRE can generate rules that achieve SoTA results. However, for more complex and realistic scenarios, dictionaries may not be available and regex-based extractors alone are not expressive enough. Moreover, as shown in Section, LUSTRE cannot handle long entities such as machine logs.  In this paper, we present a  %learning  framework that learns high-quality BERT-CRF models for parsing entity names into   structured representations  %of entity names  in low-resource settings, namely, when no labeled data is available. The proposed framework is essentially an active learning-based approach that learns from human interactions. We believe that comprehensible user interfaces are essential for active learning-based approaches, especially for labeling tasks that require non-trivial human labels . Therefore, we developed a system named PARTNER  that implements this framework. We designed the interface of PARTNER similar to that of LUSTRE, but we also made major modifications so that it is more user friendly.  Interested readers can find a video demo of PARTNER at \url{http://ibm.biz/PARTNER}. Our main contributions include: % \todo{Low-resource setting can mean different things. It would be helpful to clearly describe what you mean here.}  % { % \squishlist %     \item We developed a full-fledged system built upon an effective framework to learn high-quality BERT-CRF models for parsing structured representation of entity names without contextual information  . %     \item To minimize human effort, our framework combines active learning and weak supervision, which were usually applied in isolation.      %     \item Both the datasets and the system will be made publicly available.  % \squishend % }  { \squishlist     \item      %We propose      A hybrid framework combining active learning and weak supervision to effectively learn BERT-CRF-based models with low human effort.      \item      %We developed      A full-fledged system, with intuitive UI, that implements the framework.     \item Comprehensive experimental results showing that the framework learns high-quality models      from merely a dozen or so labeled examples.  \squishend }   \medskip Related work. Our problem is related to both flat and nested named entity recognition . However, as discussed in , NER focuses on identifying the outermost flat entities and completely ignores their internal structured representations.  identify nested entities within some context using fully supervised methods that require large amounts of labeled data, whereas our goal is to learn from very few labels  in a contextless fashion.  Active learning  and weak supervision have been widely adopted for solving many entity-centric problems, such as entity resolution , NER , and entity linking . While the power of the combination of the two techniques has been demonstrated in other domains , to the best of our knowledge, the two approaches are usually applied in isolation in prior entity-related work.  Recently, data programming approaches  use labeling functions/rules to generate weak labels to train machine learning models in low-resource scenarios. Data programming approaches like Snorkel usually assume that labeling functions are manually provided by users, indicating that their target users must have programming skills in order to provide such labeling functions. In contrast, our goal is to minimize both human effort  and lower human skills .   % Named entity recognition   % Our problem is similar to NER and its fine-grained version nested NER  with several key differences:  there is no labeled data available in our settings;  we focus on the scenarios where entity names is all we have . Recently,  proposed active learning based approaches for NER in low-resource settings. Following the same direction, we enhance active learning with weak supervision so as to further reduce the labeling efforts.    % Understanding entity names is an important task for many entity-centric tasks such as entity disambiguation and information retrieval. Computing the textual similarity of two entity names is one of the widely used methods to tell whether they are the same name or not . However, entity names can be highly ambiguous and text-based similarity functions are not robust enough to resolve complex cases . Consider the following date entities:  % \smallskip % { % {\small % \squishlist %     \item []  ``December first, nineteen nineteen"", %     \item []  ``December first, nineteen ninety"", %     \item []  ``1919-12-01"". % \squishend % } % } % \smallskip  %  Two different entities may be textually similar  and ), while the same entity may be textually dissimilar  and ).   % Entity names are not merely sequences of characters, they usually have internal semantic structures that are useful for understanding different name variations. For example, if we can identify that \example{December} is \component{Month}, \example{first} is \component{Day}, and \example{nineteen nineteen} is \component{Year}, we can transform these components separately  and assemble the transformed components according to some standardized format, such as \component{Year}-\component{Month}-\component{Day}, then we can translate  to .  % Currently, named entity recognition  and the subsequent entity disambiguation task are either treated separately , or treated as one joint task by looking into the unstructured text where the entities are extracted from and linking them to a reference knowledge base . However, in some tasks , entities are given without context . % Enriching entities with normalized form and variations obtained by manipulating their semantic structures can be helpful for these tasks.   % Several attempts have been made to understand entity name structures.  proposed declarative frameworks that allow high-skill developers to manually specify rules that translate entity names into semantic structures. To avoid this labor-intensive and clearly not scalable manual process,  proposed an active learning-based framework named LUSTRE that semi-automatically learns these parsing rules. However, the availability of a list of comprehensive, accurate, and complete dictionaries is crucial to the success of LUSTRE.   % \looseness=-1 Understanding entity name structures can be viewed as a sequence labeling problem. Recently, deep learning-based approaches have been shown to achieve state-of-the-art performance on sequence labeling problems . One of the foundations of these approaches is the use of pre-trained character or word embeddings that carry semantic information learned from large text corpus. However, these deep learning-based approaches are data hungry.         This work validates and supports the existing literature on curriculum learning. Our results confirm that curriculum learning methods for supervised learning can lead to faster convergence or better local minima, as measured by test set performance . We have shown that by replacing a heuristic for difficulty with a theoretically-based, learned difficulty value for training examples, static curriculum learning strategies can be improved. We have also proposed \modelabbr, the first curriculum learning method to dynamically probe a model during training to estimate model ability at a point in time. Knowing the model's ability allows for data to be selected for training that is appropriate for the model and is not rigidly tied to a heuristic schedule. \modelabbr~trains more effective models in most cases that we considered, particularly for randomly initialized LSTM models.  Based on our experiments, we report mixed results on our stated hypotheses. Replacing heuristics with learned difficulty values leads to improved performance when training models with curriculum learning, supporting H1. \modelabbr~does outperform other training setups when used to train LSTM models. Results are mixed when used to fine-tune the  model. Therefore H2 is partially supported. We see similarly mixed results when evaluating efficiency. With  fine-tuning, fully supervised fine-tuning is usually the most efficient, as the number of fine-tuning epochs needed is already very low. For LSTM, \modelabbr~is more efficient than the other curriculum learning strategies, and is the most efficient overall for two of the six tasks. H3 is partially supported by these results.   There are limitations to this work that can inform future work.  Strategies for learning difficulties from artificial crowds and identifying the necessary number of examples to estimate ability need more study to identify optimal strategies.  For example, recent work has shown that 85\  accuracy is an optimal learning rate to target .  \modelabbr~can be used to dynamically select data to maintain a learning rate of 85\ .    Even though it is dynamic, \modelabbr~employs a simple schedule: only include examples where . However, being able to estimate ability on the fly with \modelabbr~opens up an exciting new research direction: what is the best way to build a curriculum, knowing example difficulty and model ability ?   Our results also showed that there was no ``best'' heuristic for the competency-based baselines across data sets.   In four data sets , using learned difficulty from IRT outperformed using the sentence length difficulty heuristic, which is a new result.   A key contribution of DDaCLAE is that selecting a rate schedule and difficulty heuristic is no longer needed.     Gathering response patterns to estimate difficulty is expensive, but it is a one-time cost.   Learned difficulty estimates can be shared with the data set as features.   Identifying the best way to generate artificial response patterns, including parallelization, is an open question.  By releasing the learned difficulty values for the GLUE data sets we hope to encourage their use both for non-heuristic curriculum learning but also for future IRT evaluations.   It may be the case that only data with difficulty within a range of ability  is better, and the training set shifts as the model improves.  There are many directions to for future work, and this will be an exciting area of work moving forward.    Re-add the below for camera ready 
"," \looseness=-1  %Entity names usually have structured representation that is useful for many entity-related tasks such as entity normalization and variant generation. Learning the structured representation of entity names in low-resource settings without context and external knowledge bases is challenging. In this paper, we present a novel learning framework that combines active learning and weak supervision to solve this problem, and we experimentally show that our method can learn high-quality BERT-CRF models in low-resource settings. A video demo of a system that implements this framework is included in supplementary materials. Structured representations of entity names are useful for many entity-related tasks such as entity normalization and variant generation. Learning the implicit structured representations of entity names without context and external knowledge  is particularly challenging. In this paper, we present a novel learning framework that combines active learning and weak supervision to solve this problem. Our experimental evaluation show that this framework enables the learning of high-quality models from merely a dozen or so labeled examples.",290
"  Coreference resolution is the task of grouping mentions in a text that refer to the same real-world entity into clusters  . %The task is an important prerequisite to a variety of natural language processing systems, such as textual entailment and information extraction .  Coreference resolution is a difficult task  that %since it  requires reasoning, context understanding, and background knowledge of real-world entities,  and %Therefore, the task  has driven research in both natural language processing and machine learning, particularly since the release of the ontonotes multilingual corpus providing annotated coreference data for Arabic, Chinese and English and used for the 2011 and 2012 {\CONLL} shared tasks . Since then,  there has been substantial research on English coreference, most recently using neural coreference approaches , leading to a significant increase in  %that significantly increased  the  performance of coreference resolvers for English. % % The  general objective of %the research described in  % this paper is to close a very evident gap in the recent literature in coreference. By contrast, there has been almost no research on Arabic coreference;  the performance for Arabic coreference resolution has not improved  much since the {\CONLL} 2012 shared task, and in particular no neural architectures have been proposed--the current state-of-the-art system remains  the model proposed in %feature-based  .  In this paper we close this very obvious gap by proposing what to our knowledge is the first neural coreference resolver for Arabic.  One explanation for this lack of research might simply be the lack of  training data large enough for the task.  Another explanation  might be that Arabic is  more problematic than English  %more complex than English  because of its rich morphology,  %rich proprieties,  its %has  many dialects,  and/or  its %contains a  high degree of ambiguity.  We explore the first of these possibilities.  %Our proposal does address some of these aspects.  %one aspect of the problem. % Another explanation might be the lack of large-size training data for the task.  % We explore the Coreference resolution can be further divided into two subtasks--mention detection and mention clustering--as illustrated in  %an example of these two steps in  Figure .   % % Coreference resolution is a difficult task  % that %since it  % requires reasoning, context understanding, and background knowledge of real-world entities,  % and % %Therefore, the task  % has driven research in both natural language processing and machine learning, particularly since the release of the ontonotes multilingual corpus providing annotated coreference data for Arabic, Chinese and English . % %and various approaches have been applied.  In  early work, coreference's two subtasks were usually carried out in a pipeline fashion , with candidate mentions selected prior the mention clustering step.  Since   introduced  an end-to-end neural coreference architecture  that achieved state of the art  by carrying out the two tasks jointly, as first proposed by , most state-of-the-art systems have followed this approach. % the first end-to-end coreference system that solves the two subtasks jointly.  % This leads to a number of subsequent systems  that significantly increased the coreference resolution performance on English.  % By contrast, there were little developments for Arabic coreference resolution, the performance for Arabic coreference resolution does not improve much since the CoNLL 2012 shared task the current state-of-the-art system remain feature-based .  However, no end-to-end solution was attempted for Arabic. We intend to explore whether an end-to-end solution would be practicable with a corpus of more limited size.  % One explanation for this might be that Arabic is more complex than English because of its morphologically rich proprieties, has many dialects, and contains a high degree of ambiguity.  % Another explanation might be the lack of large-size training data for the task.   The approach we followed to adapt %In this work, we introduce a recipe to show how  the state-of-the-art English coreference resolution architecture  to Arabic %can be adapted for the Arabic language is as follows. We started with a strong baseline system , enhanced  with contextual {\BERT} embeddings . We then explored three methods for improving the model's performance for  Arabic.  %In total we evaluated three options,  The first method is to pre-process  Arabic words with heuristic rules.  We follow  to normalize the letters with different forms, and removing all the diacritics. This results in a substantial improvement of 7 percentage points over our baseline.  The second route is to replace  multilingual {\BERT} with a {\BERT} model trained only on the Arabic texts  .  Multilingual {\BERT} is trained with 100+ languages; as a result,  it is not optimized for any of them. %needs to balance the tread of between languages.  As shown by , monolingual {\BERT}  trained only on the Arabic texts has better performance on various {\NLP} tasks.   We found the same holds for coreference: %resolution task, by  using embeddings from  monolingual {\BERT}, the model further improved the {\CONLL} F1 by 4.8 percentage points. Our third step is to leverage the end-to-end system with a separately trained mention detector .  We show that a better mention detection performance can be achieved by using a separately trained mention detector.  And by using a hybrid training strategy between the end-to-end and pipeline approaches  our system gains an additional 0.8 percentage points.  Our final system achieved a {\CONLL} F1 score of 63.9\%, which is is 15\% more than the previous state-of-the-art system  on Arabic coreference with the {\CONLL} dataset.  Overall, we show that the state-of-the-art English coreference model can be adapted to Arabic coreference  leading to a substantial improvement in performance when compared to previous feature-based systems.     Building trust and confidence in agents with conversational interfaces requires smooth dialogue that avoids breakdown. Detecting dialogue breakdown, either before or while it happens, is an essential part in ensuring users have satisfactory  experiences with these agents. We investigate two semi-supervised learning methods to leverage unlabelled data to improve breakdown detection, including continued pre-training on the Reddit dataset and SSMBA data augmentation. We utilize these methods in our submission to the 5th Dialogue Breakdown Detection Challenge, beating other baselines and submissions by a large margin. In ablations on previous test sets, we show that the addition of our semi-supervised methods improves our baseline models by over 2\  accuracy and reduces JS divergence by over 0.003. These methods are simple and applicable to any dialogue task. In the future we will continue to investigate applying these methods for intent prediction, slot filling, state tracking and language generation.  
","  No neural coreference resolver for Arabic exists, in fact we are not aware of any learning-based coreference resolver for Arabic since \cite{anders:2014}.  In this paper, we introduce a coreference resolution system for Arabic based on Lee et al's end-to-end architecture combined with the Arabic version of {\BERT} and an external mention detector.  As far as we know, this is the first neural  coreference resolution system aimed specifically to Arabic, and it substantially outperforms the existing state-of-the-art on  OntoNotes 5.0 with a gain of 15.2 points {\CONLL} F1.   We also discuss the current limitations of the task for Arabic and possible approaches that can tackle these challenges.  %\footnote{Our code is available at \url{https://github.com/juntaoy/aracoref}.}  \blfootnote{     % % final paper: en-us version     \hspace{-0.65cm}  % space normally used by the marker     This work is licensed under a Creative Commons     Attribution 4.0 International License.     License details:     \url{http://creativecommons.org/licenses/by/4.0/}. } \let\thefootnote\relax\footnotetext{* Equal contribution. Listed by alphabetical order.}",291
" Deep architectures for emotion recognition from speech is a growing research field .  Using short time signal analysis, a speech utterance is represented by a matrix  where  is the size of the time dimension and   is the size of spectral dimension. The sequence to sequence layers %  model the spectral phenomena and keep the size of the time dimension  without any modification.  A sequence to vector layer is used to convert the sequence to a fixed dimension vector which can be fed to feed forward dense layers. The global average pooling, global max pooling and attention are common choices for this type of layer. %Feed forward layers are then used to improve the modeling power of the classifier. Fully-connected dense layers are then used to apply nonlinear compression of the input features for better representation which improves the modeling power of the classifier. A multiclass classifier is implemented using a softmax layer. Typically, the model is trained using the cross-entropy objective function.  Convolutional neural networks  have been recently used in many emotion recognition tasks.  For example, CNNs designed for visual recognition  were directly adapted for emotion recognition from speech. Moreover, in a study by , they conducted extensive experiments using an attentive CNN with multi-view learning objective function using the Interactive Emotional Dyadic Motion Capture  database . They concluded that for a CNN architecture, the particular choice of features is not as important as the model architecture, or the amount and kind of training data. %CNNs are an example  for sequence to sequence layers and they are extremely fast in training and classification phases. CNNs are excellent in feature extraction and very fast in training compared to standard sequence modeling.  Long short-term memory networks   sequence to sequence layers  are excellent in capturing the sequential phenomena of the speech signal for various style of speaking. In a study by , they propose a solution to the problem of 閳ユontext-aware閳 emotional relevant feature extraction, by combining CNNs with LSTM networks, in order to automatically learn the best representation of the speech signal directly from the raw time representation. They did not use any of the commonly hand-engineered features, such as mel-Frequency cepstral coefficients  and perceptual linear prediction  coefficients. Their end-to-end system was targeted to learn an intermediate representation of the raw input signal automatically that better suits the task at hand and hence leads to better performance.  Both CNN and  LSTM networks have shown significant improvements over fully-connected neural network across a wide variety of tasks.  In recent work by  ,  they  took advantage of CNNs, LSTMs and DNNs by combining them into one unified architecture for speech recognition task. CNNs are good at reducing frequency variations, LSTMs are good at temporal modeling, and finally DNNs map the features into a more separable space. Their CLDNN provided a 4-6\% relative improvement in WER. In a similar work for emotion recognition from speech , the combination of CNNs and LSTMs led to improvements in the classification accuracy. The last state of the LSTM was used for sequence to vector conversion.   Recently, an  end-to-end multimodal emotion and gender recognition model with dynamic joint loss weights is developed  . The proposed model does not need any pre-trained features from audio and visual data. In addition, the system is  trained using a multitask objective function and its weights are assigned using a dynamic approach.     In this paper, we build on these contributions to develop an emotion recognition system for Arabic data using the recently introduced KSU emotions corpus\footnote{https://catalog.ldc.upenn.edu/LDC97S45}. Our contributions are:  Introducing a novel approach for emotion recognition by using an attention based CNN-LSTM-DNN architecture;  Studying a deep CNN models for the same task;  Comparing our results with published state-of-the art results on the IEMOCAP database and  Providing our scripts and code for  the research community for usage and potential future contributions\footnote{http://github.com/qcri/deepemotion}  %In this paper, we build on previous contributions to develop a system for the first time using attention based CNN-LSTM-DNN architecture for emotion recognition. In addition,  a second architecture based on deep CNN models only was developed. In this study, we will benchmark our results using the recently introduced KSU Emotions%\footnote{https://catalog.ldc.upenn.edu/LDC97S45}   , which comprised of approximately five hours of emotional Modern Standard Arabic  speech from 23 speakers, see section  for more details. The results on an Arabic speech emotion recognition task shows that the two approaches led to similar accuracy results but the deep CNN models are significantly faster than the attention based CNN-LSTM-DNN models in training and classification phases.    The rest of the paper is organized as follows: In section 2, we describe the attention-based CNN-LSTM-DNN  and the proposed deep CNN architectures. Data is explained in section 3. Experimental setup is illustrated in section 4. This is followed by results in section 5. Finally section 6 concludes the paper and discusses future work.    %Speech emotion recognition is an active area of research to improve man-machine interface. The task aims to classify an utterance into discrete emotion labels . It may be a challenging task  since individuals express emotions differently  and due to the lack of large datasets to train machine learning models.  %Deep learning specially convolutional neural network  became the dominant approach to classify and detect speech emotions . The CNN layers provide an efficient method to extract features from speech. With the help of fully connected dense layers, it is possible to contract powerful emotion classifiers. Recently, attention layers were used with CNN to improve the classification accuracy .         In this paper, we modernize the Arabic coreference resolution task by adapting state-of-the-art English coreference system to the Arabic language. We start with a strong baseline system and introduce three methods  to effectively enhance the performance of the Arabic coreference resolution. Our final system enhanced by all three methods achieved a {\CONLL} F1 score of 63.9\  and improved the state-of-the-art result on Arabic coreference resolution task by more than 15 percentage points.      
"," Emotion recognition from speech signal based on deep learning is an active research area. Convolutional neural networks  may be the dominant method in this area. In this paper, we implement two neural architectures to address this problem.  The first architecture is an attention-based CNN-LSTM-DNN model. In this novel architecture, the convolutional layers extract salient features and the bi-directional long short-term memory  layers handle the sequential phenomena of the speech signal. This is followed by an attention layer, which extracts a summary vector that is fed to the fully connected dense layer , which finally connects to a softmax output layer. The second architecture is based on a deep CNN model. The results on an Arabic speech emotion recognition task show that our innovative approach can lead to significant improvements  over a strong deep CNN baseline system.  On the other hand, the deep CNN models are significantly faster than the attention based CNN-LSTM-DNN models in training and classification.% phases.  %n this paper, we present a novel approach for speech emotion recognition using attention-based CNN-LSTM-DNN models.  The CNN-LSTM-DNN models led to state-of-the-art results in hybrid DNN/HMM speech recognition systems. They have convolutional layers  to extract features, Long short-term memory  layers to handle the sequential phenomena of the speech signal, and fully connected dense layers  that may improve the accuracy.  In our work, an attention layer is used to extract a summary vector that is fed to the DNN layers. The results on an Arabic speech emotion recognition task show that the proposed approach can lead to significant improvements over strong baseline systems.",292
"  The following instructions are directed to authors of papers submitted to EMNLP 2020 or accepted for publication in its proceedings. All authors are required to adhere to these specifications. Authors are required to provide a Portable Document Format  version of their papers. The proceedings are designed for printing on A4 paper.      In this paper, we designed an end-to-end attention-based CNN-LSTM-DNN emotion classifier.   In our classifier, the convolutional layers  extract salient features, the bi-directional long short-term memory  layers handle the sequential phenomena of the speech signal. This is followed by an attention layer, which extracts a summary vector that is fed to the fully connected dense layer , which finally connects to a softmax layer. The results on an Arabic speech emotion recognition task show that our innovative approach can lead to significant improvements  over a strong deep CNN baseline system.  However, the deep CNN models are significantly faster than the attention-based CNN-LSTM-DNN models in training and classification phases.   Future work will focus on training an ensemble classifier and interpolating the predictions to improve the classification accuracy. We plan to use large Arabic emotion databases using our powerful attention-based CNN-LSTM-DNN models. In addition, joint estimation of the emotion, dialect, language, and accent using multitask learning will be investigated.   In addition, the  separate label per  frame  methods developed in will be compared with  the  single label per utterance methods commonly used in the field in a unified framework.     \pagebreak        
"," Text classification is a critical research topic with broad applications in natural language processing. Recently, graph neural networks  have received increasing attention in the research community and demonstrated their promising results on this canonical task. Despite the success, their performance could be largely jeopardized in practice since they are:  unable to capture high-order interaction between words;  inefficient to handle large datasets and new documents. To address those issues, in this paper, we propose a principled model -- hypergraph attention networks , which can obtain more expressive power with less computational consumption for text representation learning. Extensive experiments on various benchmark datasets demonstrate the efficacy of the proposed approach on the text classification task.",293
"   Publicly available biomedical articles keep increasing rapidly. Automated systems that utilize biomedical text mining methods are necessary to be able to handle this large amount of data with minimal manual effort. An important first step of any biomedical text mining method is the detection and classification of biomedical entities such as disease, drug or chemical mentions in biomedical articles. This task is referred to as biomedical named entity recognition .  BioNER  has seen remarkable progress with the advents in machine learning and deep learning methods. These methods require labeled datasets and benefit from increasing the amount of labeled examples. Artificial neural networks form the core of almost all state-of-the-art bioNER systems. The main drawback of these methods is that the networks must be trained from scratch for each dataset, separately. Even though recent progress in BioNER is promising, the overall performance is significantly lower than general domain NER. This is mainly due to the scarcity and sub-optimal utilization of the labeled datasets in the biomedical domain.  Transfer learning is a training paradigm that mitigates the above mentioned issues of current approaches. It attempts to utilize the information obtained from a source task to improve the performance on a target task. Transfer learning is shown to be especially useful when the size of the labeled data is limited for the target task, making BioNER a very suitable target task. Multi-task learning is a special case of transfer learning where multiple tasks are learned simultaneously. In this context, this corresponds to learning multiple biomedical named entity datasets using a single neural network.  Recently, the seminal work of Devlin et al., i.e. the BERT model, enabled progress in various NLP tasks, including NER. BERT uses self-supervised learning which relieves the need for having labeled examples to train the neural network. Lee et al. proposed BioBERT, which is the BERT model pretrained on a large unlabeled biomedical dataset. They finetuned the BioBERT model on labeled datasets using supervised learning and obtained improvements on several downstream biomedical NLP tasks. Yet, BioBERT has not been applied before in the context of multi-task learning, to the best of our knowledge. This motivated us to use BioBERT as the shared network across all biomedical datasets. We claim that sharing information across datasets help improve the overall performance as the representations obtained on one biomedical dataset is relevant to others, even though the annotated entities are different.  Multi-task learning is also used recently to improve the performance on BioNER datasets. Yet, the analysis of where the improvements come from is limited and the effect of transfer learning is unclear. Thus, there is a lack of theoretical understanding of when and why transfer learning and multi-task learning bring improvements.  In this study, we analyze the effect of multi-task learning for biomedical named entity recognition. To this end, we experimented on seven BioNER benchmark datasets and analyzed the effect of multi-task learning by using ten different measures. We evaluate the usefulness of these measures with three different metrics. Besides, we propose combining transfer learning and multi-task learning for BioNER which is not employed before to the best of our knowledge. The main contributions of this study are as follows:            This paper presents a comprehensive review of text style transfer with deep learning methods. We have surveyed recent research efforts in TST and developed schemes to categorize and distill the existing literature. This survey has covered the task formulation, evaluation metrics, and methods on parallel and non-parallel data. We also discussed several important topics on TST, its connection to other NLP tasks, and important future directions. This survey provide a reference for future researchers working on TST.  
"," Developing high-performing systems for detecting biomedical named entities has major implications. State-of-the-art deep-learning based solutions for entity recognition often require large annotated datasets, which is not available in the biomedical domain. Transfer learning and multi-task learning have been shown to improve performance for low-resource domains. However, the applications of these methods are relatively scarce in the biomedical domain, and a theoretical understanding of why these methods improve the performance is lacking. In this study, we performed an extensive analysis to understand the transferability between different biomedical entity datasets. We found useful measures to predict transferability between these datasets. Besides, we propose combining transfer learning and multi-task learning to improve the performance of biomedical named entity recognition systems, which is not applied before to the best of our knowledge.",294
" Aspect-based sentiment analysis  is a fine-grained sentiment analysis task, which analyzes the sentiment or opinions toward a given aspect in a sentence. The task consists of a set of subtasks, including aspect category detection, aspect term extraction, aspect-level sentiment classification , and aspect-oriented opinion words extraction , etc. Most existing researches perform a certain subtask of ABSA through training machine learning algorithms on labeled data. However, the public corpora of ABSA are all small-scale due to the expensive and labor-intensive manual annotation. Scarce training data limits the performance of data-driven approaches for ABSA. Therefore, an interesting and valuable research question is how to mine and exploit internal connections between ABSA subtasks to achieve the goal of facilitating them simultaneously. In this work, we focus on two subtasks ALSC and AOWE because they are highly mutually indicative. We first introduce them briefly before presenting our motivations.    Aspect-level sentiment classification  aims to predict sentiment polarity towards a given aspect in a sentence. As Figure shows, there are two aspects mentioned in the sentence ``waiters are unfriendly but the pasta is out of this world.'', namely ``waiters'' and ``pasta''. The sentiments expressed towards each aspect are negative and positive respectively. Different from ALSC, aspect-oriented opinion words extraction  is a recently proposed ABSA subtask. The objective of this task is to extract the corresponding opinion words towards a given aspect from the sentence. Opinion words refer to the word/phrase of a sentence used to express attitudes or opinions explicitly. In the example above, ``unfriendly'' is the opinion word towards the aspect ``waiters'', and ``out of this world'' is the opinion words towards the aspect ``pasta''.  It is a common sense that positive opinion words imply positive sentiment polarity, while negative opinion words correspond to negative sentiment polarity. Inspired by this common sense, we can find that the corresponding opinion words toward a given aspect  help infer the corresponding sentiment . Correspondingly, the sentiment determined in ALSC also can provide some clues to help extract polarity-related opinion words for the AOWE task. Therefore, the goals of AOWE and ALSC are mutually indicative and they can benefit each other.  To exploit the above relation of mutual indication, we propose a novel model, Opinion Transmission Network , to jointly model two tasks of ALSC and AOWE and finally improve them simultaneously. Overall, OTN contains two base modules, namely the attention-based ALSC module and the CNN-based AOWE module, and two tailor-made opinion transmission mechanisms, respectively from AOWE to ALSC and ALSC to AOWE. Specifically, we utilize the extracted results of AOWE as complementary opinions information and inject them into the ALSC module in the form of additional attention. To successfully transmit implicit opinions from ALSC to AOWE, we unearth that the features in attention layer of the ALSC module keep abundant useful aspect-related opinions, which can be utilized to facilitate AOWE. It is worth noting that our proposed model works without requiring simultaneous annotations of AOWE and ALSC on the same data, thus it can be applied in more practical scenarios.  The main contributions of this work can be summarized as follows:      In this work, we proposed combining transfer learning and multi-task learning for BioNER, which is not done before to the best of our knowledge. The proposed method achieved state-of-the-art results on several biomedical named entity datasets. The main purpose of this study was to analyze and understand under which conditions transferring information from an auxiliary dataset helps improve performance on a target dataset. To this end, we used various dataset measures and evaluated their ability to predict the MTL gains using three different evaluation metrics. The analysis showed that the dataset measures contain strong signals about the benefits of multi-task learning.  
"," Aspect-level sentiment classification  and aspect oriented opinion words extraction  are two highly relevant aspect-based sentiment analysis  subtasks. They respectively aim to detect the sentiment polarity and extract the corresponding opinion words toward a given aspect in a sentence. Previous works separate them and focus on one of them by training neural models on small-scale labeled data, while neglecting the connections between them. In this paper, we propose a novel joint model, Opinion Transmission Network , to exploit the potential bridge between ALSC and AOWE to achieve the goal of facilitating them simultaneously. Specifically, we design two tailor-made opinion transmission mechanisms to control opinion clues flow bidirectionally, respectively from ALSC to AOWE and AOWE to ALSC. Experiment results on two benchmark datasets show that our joint model outperforms strong baselines on the two tasks. Further analysis also validates the effectiveness of opinion transmission mechanisms.  \keywords{Aspect-level sentiment classification  \and Aspect-oriented opinion words extraction \and Opinion transmission network.}",295
" With the development of large-scale pre-trained Language Models  such as BERT , XLNet , and T5 , tremendous progress has been made in Question Answering . Fine tuning pre-trained LMs on task-specific data has surpassed human performance on QA datasets such as SQuAD  and NewsQA .  Nevertheless, most existing QA systems largely deal with factoid questions and assume a simplified setup such as multiple-choice questions, retrieving spans of text from given documents, and filling in the blanks. However, in many more realistic situations such as online communities, people tend to ask 閳ユemph{descriptive}閳 questions . Answering such questions requires the identification, linking, and integration of relevant information scattered over long-form multiple documents for the generation of free-form answers.  We are particularly interested in developing a QA system for questions from e-shopping communities using customer reviews. Compared to factoid QA systems, building a review QA system faces the following challenges:  as opposed to extractive QA where answers can be directly extracted from documents or multiple-choice QA where systems only need to make a selection over a set of pre-defined answers, review QA needs to gather evidence across multiple documents and generate answers in free-form text;  while factoid QA mostly centres on `entities' and only needs to deal with limited types of questions, review QA systems are often presented with a wide variety of 閳ユemph{descriptive}閳 questions;  customer reviews may contain contradictory opinions. Review QA systems need to automatically identify the most prominent opinion given a question for answer generation.    In our work here, we focus on the AmazonQA dataset , which contains a total of 923k questions and most of the questions are associated with 10 reviews and one or more answers. We propose a novel Cross-passage Hierarchical Memory Network named Chime to address the aforementioned challenges. Regular neural QA models search answers by interactively comparing the question and supporting text, which is in line with human cognition in solving factoid questions . While for opinion questions, the cognition process is deeper: reading larger scale and more complex texts, building cross-text comprehension, continually refine the opinions, and finally form  the answers . Therefore, Chime is designed to maintain hierarchical dual memories to closely simulates this cognition process. In this model, a context memory dynamically collect cross-passage evidences, an answer memory stores and continually refines answers generated as Chime reads supporting text in a sequential manner. Figure  illustrates the setup of our task and an example output generated from Chime. The top box shows a question extracted from our test set while the left panel and the right upper panel show the related 10 reviews and the paired 4 actual answers. We can observe that the question can be decomposed into complex sub-questions and both reviews and answers contain contradictory information. However, Chime can deal with such information effectively and generate appropriate answers as shown in the right-bottom box.  In summary, we have made the following contributions:     %%%%%%%%%%%%%%%% % Related Work % %%%%%%%%%%%%%%%%   In ABSA research, Aspect-level sentiment classification  and aspect-oriented opinion words extraction  are two highly relevant tasks. Previous works usually focus on one of the two tasks and neglect mutual indication between them. In this paper, we propose a novel joint model, Opinion Transmission Network , to exploit the potential connection between ALSC and AOWE to benefit them simultaneously. In OTN, two tailor-made opinion transmission mechanisms are designed to control opinion clues to flow respectively from ALSC to AOWE and AOWE to ALSC. Experiment results on two tasks validate the effectiveness of our method.   \subsubsection{Acknowledgements.} This work was supported by the NSFC  and National Key R\&D Program of China .      ---- Bibliography ----     BibTeX users should specify bibliography style 'splncs04'.   References will then be sorted and formatted in the correct style.   
","   We introduce Chime, a cross-passage hierarchical memory network for question answering  via text generation. It extends XLNet \cite{yang2019xlnet} introducing an auxiliary memory module consisting of two components: the context memory collecting cross-passage evidence, and the answer memory working as a buffer continually refining the generated answers. Empirically, we show the efficacy of the proposed architecture in the multi-passage generative QA, outperforming the state-of-the-art baselines with better syntactically well-formed answers and increased precision in addressing the questions of the AmazonQA review dataset. An additional qualitative analysis revealed the interpretability introduced by the memory module\blfootnote{This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: \url{http://creativecommons.org/licenses/by/4.0/}.}.",296
" . } The ability to understand  user's requests is essential to develop effective task-oriented dialogue systems.  For example, in the utterance ""I want to listen to Hey Jude by The Beatles"", a dialogue system should correctly identify that the user's intention is to give a command  to play a song, and that Hey Jude and The Beatles are, respectively, the song's title  and the artist name that the user would like to listen. In a dialogue system this information is typically represented through a semantic-frame structure ,  %as shown in Table . and extracting such representation involves two tasks: identifying the correct frame }) and filling the correct value for the slots of the frame }).   In recent years, neural-network based models have achieved the state of the art  for a wide range of natural language processing tasks, including SF and IC. Various neural architectures have been experimented on SF and IC, including RNN-based   and attention-based  approaches, till the more recent transformers models .  Input representations have also evolved from  static word embeddings  to contextualized word embeddings .  Such progress allows to better address dialogue phenomena involving SF and IC, including  context modeling, handling out-of-vocabulary words, long-distance dependency between words, and to better exploit the  synergy between SF and IC through joint models.  In addition to rapid progresses in the research community, the demand for commercial conversational AI is also growing fast, shown by a variety of available solutions, such as Microsoft LUIS, Google Dialogflow, RASA, and Amazon Alexa. These solutions also use various kinds of semantic frame representations as part of their framework.  Motivated by the rapid explosion of scientific progress, and by unprecedented market attention,  we think that a guided map of the approaches on SF and IC  can be useful for a large spectrum of researchers and practitioners interested in dialogue systems. The primary goal of the  survey is to give a broad overview of  recent neural models applied to SF and IC, and to compare their performance in the context of task-oriented dialogue systems.  We also highlight and discuss open issues that still need to be addressed in the future. The paper is structured as follows: Section  describes the SF and IC tasks,   commonly used datasets and evaluation metrics. Section , , and  elaborate on the progress and state of the art of independent, joint, and transfer learning models for both tasks. Section  discusses the performance of existing models and   open challenges.  % \footnote{https://www.luis.ai/home} % \footnote{https://dialogflow.com/} % \footnote{https://rasa.com/docs/rasa/} % \footnote{https://developer.amazon.com/en-US/docs/alexa/custom-skills/create-intents-utterances-and-slots.html}              \end{table*}  % \todo[inline]{Explain the structure of the paper}    In this paper, we have proposed , a cross-passage hierarchical memory network for multi-passage generative review QA. It is built on the XLNet generator  by adding a memory module consisting of a context and a answer memory which guarantees a more accurate refining process for cross-passage evidence collection and answer generation. The sequential process adopted in  makes it possible to elaborate longer text passages and some straightforward interpretability. We have assessed experimentally a significant quality improvement using different state-of-the-art metrics to measure the lexical and semantic coherence of the generated text. We plan to further extend  to model with multiple ground truth simultaneously and leverage the available product attributes.  
"," % pertama harus ngomongin perkembangan yang menarik di area dialgoue systems terus  % SLU itu penting % terus paper ini ngapain % harapannya apa dengan paper ini In recent years, fostered by deep learning technologies and by the high demand for conversational AI, various approaches have been proposed  that address the capacity to elicit and understand user闁炽儲鐛 needs in task-oriented dialogue systems. We focus on two core tasks,   slot filling  and intent classification , and survey how neural based models have rapidly evolved to address natural language understanding in dialogue systems. We introduce three neural architectures: independent models, which model SF and IC separately, joint models,  which exploit the mutual benefit of the two tasks simultaneously, and transfer learning models,  that scale the model to new domains.  We  discuss the current state of the research in SF and IC, and highlight challenges that still require attention.",297
"  %Conversational systems are usually built using manual rules, supervised machine learning or a combination of both. Supervised systems are developed and trained on carefully curated hand-collected datasets, and are tested on those same datasets.   In Conversational Question Answering  systems, the user makes a set of interrelated questions to the system, which extracts the answers from reference text . These systems are trained on datasets of human-human dialogues collected using Wizard-of-Oz techniques, where two crowdsourcers are paired at random to emulate the questioner and the answerer. Several projects have shown that it is possible to train effective systems using such datasets. For instance, QuAC includes question and answers about popular people in Wikipedia , and DoQA includes question-answer conversations on cooking, movies and travel FAQs . Building such datasets comes at a cost, which limits the widespread use of conversational systems built using supervised learning.   The fact that conversational systems interact naturally with users poses an exciting opportunity to improve them after deployment. Given enough training data, a company can deploy a basic conversational system, enough to be accepted and used by users. Once the system is deployed, the interaction with users and their feedback can be used to improve the system. %\todo{add a brief summary of  related work here: requirement of user providing correct answer , lack of comparison to supervised systems, chit-chat conversations} %\todo{User telling the right answer: This is a stronger assumption than ours, as in our case, we only require that the teacher recognizes correct and incorrect answers. }   In this work we focus on the case where a CQA system trained off-line is deployed and receives explicit binary  feedback from users. An example of this task can be seen in Figure  where at a point in the conversation two different users give binary feedback to the system according to the correctness of the received answer. Assuming a large number of interactions, we can safely ignore examples for which no feedback is received. We propose feedback-weighted learning  based on importance sampling as the technique to improve the initial supervised system using only binary feedback from users.    In our experiments user feedback is simulated, and the correct/incorrect feedback is extracted from the gold standard. That is, if the system output matches the gold standard output then it is deemed correct, otherwise it is taken to be incorrect.   In order to develop and test feedback-weighted learning we perform  initial experiments on  document classification. The results show that the model improved by the proposed algorithm performs comparably to the fully supervised model that is fine-tuned with true labels rather than binary feedback. Those experiments are also used to check the impact of hyperparameters like the weight of the feedback and the balance between exploitation and exploration, which shows that our method is not particularly sensitive to the values of those hyperparameters.   Regarding CQA, we use the best hyperparameters from the earlier experiment on document classification, and conduct experiments using several domains in CQA including datasets like QuAC and DoQA. Our method always improves over the initial supervised system. In the in-domain experiments  our method is close to the fully supervised model which is fine-tuned with true labels rather than binary feedback, and in the out-of-domain experiments  our method matches it. The out-of-domain results are particularly exciting, as they are related to the case where a CQA system trained off-line in one domain could be deployed in another domain, letting the users improve it via their partial feedback by interacting with the system. Our experiments reveal that the proposed approach is robust to the choice of the system architecture, as we experimented with both multi-layer perceptron and pre-trained transformer. %Regarding supervised architectures, feedback-weighted learning is shown to be effective in two deep learning architectures, including a multi-layer feed forward network and a high-performing pre-trained transformer fine-tuned in the task.   %Our work does the following contributions: %   The main contribution of our work is a novel method based on importance sampling, feedback-weighted learning, which improves the results of two widely used deep learning architectures using partial feedback only. Experimental results from document classification show that feedback-weighted learning improves over the initial supervised system, matching the performance of a fully supervised system which uses true labels. In-domain and out-of-domain CQA experiments show that the proposed method improves over the initial supervised system in all cases, matching a fully supervised system in out-of-domain experiments.  This work opens the prospect to exploit interactions with real users and improve conversational systems after deployment. All the code and dataset splits are made publicly available .         %\item Motivation: enpresak S0, deployment, nola hobetu S0 erabiltzaileei erantzun zuzenak eskatu gabe ? Aukeratzen dugu S0rako arkitektura neuronal superbisatu standard batzuk , eta hori hobetzen saiatzen gara.   %\item Google Award-etik recuperatu daiteke zerbait?   %  %Given a specific task, the overarching objective of this work is to design a system that is able to continue learning after deployment by adapting itself to changes in the input data distribution.   %Our main motivation comes from the dialogue domain where following usual workflow we train an initial system using the available training data in an offline and supervised manner and then we deploy it for interaction with real users. Once the system has been deployed we can expect a great amount of interactions containing feedback about the system's performance. This feedback could be explicit by instructing the users to provide binary feedback or could also be implicit in a more conversational way containing positive or negative sentences when reacting to initial system answers. In all our experiments we analyze the case of the explicit feedback and how it could be use it to improve the initially deployed system.        We have surveyed recent neural-based models applied to SF and IC in the context of task-oriented dialogue systems. We examined three approaches, i.e.  independent, joint, and transfer learning based models. Joint models  exploiting the relation between SF and IC simultaneously shown relatively better performance than independent models. Empirical results have shown that most joint  models nearly ""solve""  widely used datasets,  ATIS and SNIPS, given sufficient in-domain training data. Nevertheless, there are still several challenges related to SF and IC, especially  improving the scalability of the model to new domains and languages when limited labeled data are available.          
"," %Feedback weighted learning for ConvQA in LLL The interaction of conversational systems with users poses an exciting opportunity for improving them after deployment, but little evidence has been provided of its feasibility. In most applications, users are not able to provide the correct answer to the system, but they are able to provide binary  feedback. In this paper we propose feedback-weighted learning based on importance sampling to improve upon an initial supervised system using binary user feedback. We perform simulated experiments on document classification  and Conversational Question Answering datasets like QuAC and DoQA, where binary user feedback is derived from gold annotations. The results show that our method is able to improve over the initial supervised system, getting close to a fully-supervised system that has access to the same labeled examples in in-domain experiments , and even matching in out-of-domain experiments .  Our work opens the prospect to exploit interactions with real users and improve conversational systems after deployment.",298
"  .     %      % % final paper: en-us version      %        % space normally used by the marker      This work is licensed under a Creative Commons       Attribution 4.0 International License.      License details:      \url{http://creativecommons.org/licenses/by/4.0/}. }  %1Yang 閺堫剚顔屽楦款唴婵″倷绗呴幓蹇氬牚閿涙瓊MT閸欐牕绶辨禍鍝燨TA閻ㄥ嫬鐤勬灞炬櫏閺嬫粌鑻熷妤鍩屾禍鍡楃畭濞夋稓娈戞惔鏃傛暏閿涘牐顔戦弬鍥х穿閻㈩煉绱氶妴鍌滄暠娴滃孩婀佹径褔鍣洪惃鍕棘閺佸府绱濋幍娴狀檾MT闂囩憰浣搞亣闁插繒娈戠拋顓犵矊閺佺増宓侀弬鐟板讲閸忓懎鍨庨崣鎴炲皩鐎瑰啰娈戞导妯哄◢閵嗗倻鍔ч懓灞芥躬鐎圭偤妾惔鏃傛暏娑擃叏绱濋弫鐗堝祦瀵板娴兼艾鍨庣敮鍐х瑝閸у浄绱濋幋鏍懏绉归崣濠傚煂妫板棗鐓欓懛顏堝倸绨查惃鍕６妫版ǜ鍌氭躬鏉╂瑧顫掗幆鍛枌娑撳绱漀MT濡崇峰瀵版导姘朵粣韫囨ê鍑＄涳箑鍩岄惃鍕叀鐠囧棴绱濋懓灞藉箵閹风喎鎮庨弬鐗堝潑閸旂姷娈戦弫鐗堝祦閿涘瞼鍔ч懓灞炬付缂佸牆绶遍崚鎵畱濡崇风憰浣割槱閻炲棗宓堥弰顖氬弿閸掑棗绔烽惃鍕殶閹诡噯绱濇潻娆戭潚閻滄媽钖勭亸杈ㄦЦ鏉╃偟鐢荤涳缚绡勬稉顓犳畱閻忛箖姣﹂幀褔浠愯箛姗堢礄瀵洜鏁ら惄绋垮彠閺傚洨灏為敍澶堝倹寮挎潻鏉挎禈1閻ㄥ嫬鐤勬宀娲伴惃鍕簰閸欏﹦绮ㄧ拋鐑樻降妤犲矁鐦夐幋鎴滄粦娑撳﹪娼伴惃鍕鏉╁府绱欓崶鍓у娑撳秴顧勫〒鍛珰閿涘苯鎸ㄩ崗鑸垫Ц閺傚洤鐡ч敍宀鏃辨潪瀵告畱閳ユ窂LEU閳ユ粏顕柈鐣屾暏婢堆冨晸閿涘 Neural machine translation  models have achieved state-of-the-art results and have been widely used in many fields. Due to numerous parameters, NMT models can only play to their advantages based on large-scale training data. However, in practical applications, NMT models often need to perform translation for some specific domain with only a small quantity of in-domain data available.  In this situation, continual training, which is also referred to as fine-tuning, is often employed to improve the in-domain translation performance. In this method, the model is first trained with large-scale general-domain training data and then continually trained with the in-domain data. With this method, the in-domain performance can be improved greatly, but unfortunately, the general-domain performance decline significantly, since NMT models tend to overfit to frequent observations  in the in-domain data but forget previously learned knowledge. This phenomenon is called catastrophic forgetting. Figure shows the performance trends on the in-domain and general-domain. %As the size of the training corpus grows, the NMT model is trained in the manner of continual learning  from a stream of data.  %Unfortunately, there usually exists a distribution bias in large data set especially when the data is collected from different domains. In this situation, the NMT model has a tendency towards over-fitting to frequent observations  in the newly added data, but forgetting previously learned patterns from the old data, leading to poor performance in the old data.  In the example of domain adaptation shown in Figure, as the training goes, the performance surges for in-domain while slides fast for general-domain. This phenomenon is the catastrophic forgetting of neural network.  %when there are large amounts of parallel training sentences available. However, similar to many other successful neural network-based methods, it also has limited continual learning ability to learn from a stream of training data, which could have different distributions . It is because the NMT system suffers from catastrophic forgetting which refers to that model has a tendency towards over-fitting to frequent observations  in newly added training data, but forgetting previously learned features in the old data.   %Figure denotes this phenomenon in NMT.  %1Yang 娑撳娼版潻娆愵唽閸樼粯甯 %Improving the continual learning ability of the NMT system is of significant importance both in theory and practice. From the artificial intelligence perspective, it can be seen as another step towards the grand goal of creating a real intelligent translation system that can learn continuously new translation skills without forgetting old knowledge as a human does. From a practical perspective, it enables the model to update the model with only recent new data to improve the model's overall performance. We don't need to retrain the model from scratch which is very time-consuming. Moreover, considering that a well-trained model maybe is already deployed in an application, the original training data may not be available at that time. Therefore it is very necessary to improve the continual learning ability of the NMT system.      %1Yang 閺堫剚顔屽楦款唴婵″倹妲搁幓蹇氬牚閿涙氨浼ㄩ梾鐐囦粣韫囨ü绔撮惄瀛樻Ц缁佺偟绮＄純鎴犵捕鐠侇厾绮屾稉顓犳畱娑撴径褔姣︽０姗堢礉閾忕晫鍔ч惄顔煎瀹歌尙绮￠張澶夌娴滄稑浼愭担婊嗗毀閸旀稐绨憴锝呭枀鏉╂瑤閲滈梻顕顣介敍灞借嫙缂佹瑥鍤禍鍡曠娴滄稖顢戞稊瀣箒閺佸牏娈戠憴锝呭枀閺傝纭堕敍鍫濈穿閻€劎娴夐崗铏瀮閻氼噯绱氶敍灞肩稻閺勵垳娲伴崜宥呰嫙濞屸剝婀佸銉ょ稊閸樼粯甯扮槐銏犳躬閻忛箖姣﹂幀褔浠愯箛妯跨箖缁嬪鑵戦崘鍛村劥閺佺増宓侀惃鍕綁閸栨牗鍎忛崘纰夌礉鏉╂瑧顫掗幒銏㈠偍娴兼碍婀侀崝鈺绨幋鎴滄粦閻炲棜袙閻忛箖姣﹂幀褔浠愯箛妯哄絺閻㈢喓娈戦崢鐔锋礈楠炲爼鍣伴崣鏍祲鎼存梻娈戦幒顏呮煢閵  Many methods have been proposed to address the catastrophic forgetting problem under the scheme of fine-tuning.  ensembles the general-domain model and the fine-tuned model together so that the integrated model can consider both domains.   introduces domain-specific output layers for both of the domains and thus the domain-specific features of the two domains can be well preserved.  , , and  propose regularization-based methods that introduce an additional loss to the original objective to help the model trade off between the general-domain and in-domain. All these methods show their effectiveness and have mitigated the performance decline on general-domain, but we still don't know what happened inside the model during continual training and why these methods can alleviate the catastrophic forgetting problem. The study on these can help to understand the working mechanism of continual training and inspire more effective solutions to the problem in return.    %Catastrophic forgetting is a long-known problem in the training of neural networks. Some researchers have managed to alleviate this problem with different strategies, such as changing the model structure, adding an extra regularization term, employing complementary learning systems  theory-based strategies and so on. However, to the best of our knowledge, these methods mainly focus on how to solve the problem, not what causes the problem. %Understanding the cause of the problem will inspire effective solutions. %, there is still no work trying to figure out the inner reason for catastrophic phenomenon and no direct evidence to show the change of model parameters in NMT. We believe that the attempt to understand this phenomenon can help us adopt appropriate measures to solve this problem.  %it is still not clear what happens during the continual learning process and what causes catastrophic forgetting indeed.  %1Yang 閺堫剚顔岄崣顖欎簰鏉╂瑦鐗遍崘娆欑窗閸︺劍婀伴弬鍥风礉閹存垳婊戠亸婵婄槸閸︺劑顣崺鐔诲殰闁倸绨查惃鍕攱閺嬫湹绗呴崢缁樺赴缁鳖晼arameters閸滃瞼浼ㄩ梾鐐囦粣韫囨娈戦崗宕囬兇閿涘苯鑻熼崚鑽ゆ暰閸戠皢arameters閸︺劎浼ㄩ梾鐐囦粣韫囨ǹ绻冪粙瀣╄厬閻ㄥ嫬褰夐崠鏍Ъ閸旇￥鍌欒礋娴滃棜鎻崚鎷岀箹娑擃亞娲伴惃鍕剁礉閹存垳婊戦柅姘崇箖Absolute value閸滃瓗IM閺夈儴鐦庢导鏉垮棘閺佹澘婀Ο鈥崇风拋顓犵矊娑擃厾娈戦柌宥堫洣閹嶇礄閸欏倽鍐╂瀮閻氼噯绱氶敍灞借嫙闁俺绻冮崣鍌涙殶閹匡箓娅庨惃鍕煙濞夋洘娼甸幒銏㈠偍鏉╂瑤绨洪崡鏇熸殶鐎靛湱鐐曠拠鎴炑嗗厴閻ㄥ嫬濂栭崫宥冨倿姘崇箖鐎圭偤鐛欑紒鎾寸亯閿涘本鍨滄禒顒褰傞悳鏉款嚠娴滃酣姘辨暏妫板棗鐓欓柌宥堫洣閻ㄥ嫬寮弫鏉款嚠娴滃穼n-domain娴犲秶鍔у鍫ュ櫢鐟曚緤绱濋懓灞芥躬妫板棗鐓欓懛顏堝倸绨查惃鍕箖缁嬪鑵戞潻娆庣昂閸欏倹鏆熼惃鍕綁閸栨牕绶㈡径褋鍌氱唨娴滃氦绻栨禍娑樺絺閻滃府绱濈电懓绨叉禍搴ょ槑娴兼澘寮弫浼村櫢鐟曚焦褏娈戞稉銈囶潚閺傝纭堕敍灞惧灉娴狀剛娴夋惔鏃傛畱閹绘劕鍤稉銈囶潚閺傝纭堕弶銉﹀付閸掓儼绻栨禍娑㈠櫢鐟曚胶娈戦崣鍌涙殶閸︺劑顣崺鐔诲殰闁倸绨查惃鍕箖缁嬪鑵戞稉宥勭窗閸欐ê瀵叉潻鍥с亣閿涘矁宀娼冮柌宥勭艾鐠嬪啯鏆ｉ柇锝勭昂娑撳秹鍋呮稊鍫ュ櫢鐟曚胶娈戦崣鍌涙殶閵嗗倸鐤勬宀绮ㄩ弸婊嗐冮弰搴㈠灉娴狀剛娈戦弬瑙勭《閼宠棄婀穱婵婄槈in-domain閺佺増宓佹稉濠勬畱缂堟槒鐦ч幀褑鍏橀崣妯哄娑撳秵妲戦弰鍓ф畱閹懎鍠屾稉瀣亣楠炲懎瀹抽惃鍕絹妤傛﹢姘辨暏妫板棗鐓欓惃鍕倳鐠囨垶褑鍏橀妴  %Given this, we seek to understand the relationship between catastrophic forgetting phenomenon and model parameters under the task of domain adaptation. More specifically, we aim to figure out the trend of model parameters during catastrophic forgetting. To fulfill this goal, we propose two methods to evaluate the importance of the model parameters. The first is to use the absolute value of model parameters and the second is to use the empirical Fisher Information Matrix . To verify the effectiveness and correctness of the proposed methods, we then do parameter erasure experiments. According to the experimental results, we find that some parameters are important for both the general-domain and in-domain. Based on these findings, we try to alleviate catastrophic forgetting by designing learning strategies based on the importance of the parameters. We put more constrains on those important parameters to make them change more conservatively while encourage those less important parameters to change more aggressively during the continual learning process. The experiments on multiple translation tasks show that our methods can improve the translation quality on the new domain without degrading the performance on the old domain too much.  Given above, in this paper, we focus on the catastrophic forgetting phenomenon and investigate the roles of different model parts during continual training. To this end, we explore the model from the granularities of modules and parameters . In the module analyzing experiments, we operate the model in two different ways, by freezing one particular module or freezing the whole model except for this module. We find that different modules preserve knowledge for different domains. In the parameter analyzing experiments, we erase parameters according to their importance which is evaluated by the Taylor expansion-based method . According to the experimental results, we find that some parameters are important for both of the general-domain and in-domain and meanwhile they change greatly during domain adaptation which may result in catastrophic forgetting.  To ensure the validity and reliability of the findings, we conduct experiments over different language pairs and domains.   \iffalse Given this, we step into the catastrophic forgetting phenomenon by investigating the influence of different model parts from different granularities, depicting the different roles played by them during continual training. Inspired by the work of  and , we conducted two kinds of analyzing experiments. The first, focusing on the macro parts of the model, is the module analyzing experiment, where we freeze the target module of the model or freeze the whole model except for the target module during continual training to study the influence of each module on the translation performance. We found that some modules are of higher capacity to preserve the general-domain knowledge while some modules are more essential for adapting to the in-domain.  The second, focusing on the micro parts of the model is the parameter analyzing experiment based on the parameter importance, where the Taylor expansion-based method is adopted as the importance evaluation criterion.  According to the experimental results, we found that some parameters are important for both of the general-domain and in-domain and meanwhile they fluctuate greatly during domain adaptation which may result in performance slipping. To ensure the validity and reliability of our conclusions, we conducted our experiments across different language pairs and domains.  \fi  Our main contributions are summarized as follows:   \iffalse To answer these questions, we put forward two ways of evaluating the importance of the model parameters. The first is to use the absolute value of model parameters and a larger absolute value stands for they are more important for the model. Inspired by the work of, we use the diagonal of the Fisher information matrix  of the model parameters to evaluate the importance. To verify the effectiveness and correctness of the proposed methods, we then did parameter erasure experiments which is an effective analysis approach. The results show that some model parameters are more important than others and have much more impact on the final translation quality.  this phenomenon by analyzing the change of model parameters during the continual learning process. We focus on the domain adaptation task of NMT under the continual learning scenario which means first we make the model well-trained using large amounts of general-domain data, and then this model is further trained using limited amounts of in-domain data which is from another domain. It should be noted that no general-domain data is available during the further trained process which is a common practice of continual learning. We aim to investigate the following questions:    Based on our findings of parameter importance above, we then investigate their changes during the continual learning process. We find that the important parameters for the general-domain translation still play major roles for the in-domain translation by doing another parameter erasure experiments. What's more, the substantial decline of general-domain translation quality and the rise of in-domain translation quality is also due to the change of these parameters.   Finally, based on our findings, we propose some practical methods to overcome the catastrophic forgetting phenomenon by parameter regularization method and learning rate adjustment method based on their importance to the model. We change the important parameters slightly while changing the less important parameters more aggressively. The results show that our approach can alleviate catastrophic forgetting significantly.      Our work indicates that some parameters are more important than others and the change of these parameters can influence translation results a lot. Therefore, we can try to alleviate catastrophic forgetting by designing different learning strategies based on the importance of the parameters. As far as we know, this is the first work trying to analyze the catastrophic forgetting phenomenon in NMT. Moreover, the analyzing methods we put forward in this work are task-independent and can be applied to other neural network-based methods in other tasks. \fi \iffalse extra space to store all the old training data or even retrain from scratch with the and without storing old training data or even retraining with   This work focuses on the domain adaptation problem of NMT which is a special case of the continual learning scenario of the neural network. They share the same training task but the distribution of the training data is different.  Domain adaptation deals with the problem of improving the performance of a model trained on a general domain data over test instances from a new domain. In such a scenario, we usually have large amounts of general-domain training data and a welled trained model based on it. In contrast, we only have a limited number of in-domain training data which will lead the NMT system to overfit soon and perform poorly when only trained with these data. Some researchers solve this problem by combining the training data from the general-domain and in-domain together and train a new system from scratch. They usually make use of the domain information to improve the translating performance by adding domain labels to training data or using domain discriminator to find the domain invariant features. On the one hand, these methods are very time consuming and need extra space to store all the training data which is not efficient in real-life applications. On the other hand, due to the relatively small size of in-domain data, it will lead the model to overfit the general-domain data which has been observed in the results.   Fine-tuning is a fast and efficient method for continual learning of neural networks which has already been applied for NMT. NMT system is first trained on general-domain data and then further trained on in-domain data.   Domain adaptation is the most common application scenario of continual learning in NMT which has drawn much attention recently. Under this scenario, we   The translation quality drops quickly when the distribution of the training data changes. It suffers a catastrophic forgetting in the continual training process. \fi       We have presented a first empirical study of practical concerns of targeted attacks on black-box NMT system driven by parallel data poisoning. We evaluated scenarios of poisoning the from-scratch training, pre-training, and fine-tuning of NMT systems trained on parallel data. We show that with very small poisoning budgets , systems can be severely compromised, even when they are trained on tens of millions of clean samples. We hope to raise the awareness of the risk of training NMT systems with malicious inputs from untrusted sources. As our end goal is an effective defence, one of our next steps is to look into developing countermeasures to this attack, such as designing algorithms for more robust parallel data filtering, as well as for detecting and protecting the named entities under attack.    \paragraph{\bf Ethical Considerations} Our aim in this work is to identify and mitigate potential threats to NMT systems, by adopting established threat modelling for machine learning systems, to identify and prioritise need to devise effective defences and develop robust systems. Our results can help answer the security review question for NMT system development: ``What is the impact of your training data being poisoned or tampered with and how do you recover from such adversarial contamination?'' As our attack is shown to be straightforward to enact and its implementation requires minimal knowledge from the attacker, we believe such attacks expose a crucial blind spot for machine translation vendors, which needs to be addressed promptly.    
","  %Neural machine translation  always suffers catastrophic forgetting during the continual learning process which means the model tends to forget all its previously learned knowledge when further trained with new data with different distributions, like from different domains or languages. However, it is not clear what happens during this process and what causes this phenomenon. More specifically, it is not clear whether this is due to the overall change of the model or the impact of certain parameters. In this work, we focus on the domain adaptation task of NMT under the continual learning scenario. First, we put forward two ways for evaluating the importance of the parameters and show that the translation quality mainly dependents on the most important parameters of the model. Then we analyze the behavior of the parameters according to their importance for the model during the continual learning process and it shows that the important parameters for the general-domain translation still play major roles for the in-domain translation after the continual learning process. What's more, the catastrophic forgetting phenomenon, shown as the substantial decline of general-domain translation quality with the rise of in-domain translation quality,  is mainly due to the change of these important parameters.  Finally, we propose some practical methods to overcome the catastrophic forgetting by controlling the updates of parameters differently based on their importance.    Neural machine translation  models usually suffer from catastrophic forgetting during continual training where the models tend to gradually forget previously learned knowledge and swing to fit the newly added data which may have a different distribution, e.g. a different domain. Although many methods have been proposed to solve this problem, we cannot get to know what causes this phenomenon yet. Under the background of domain adaptation, we investigate the cause of catastrophic forgetting from the perspectives of modules and parameters . The investigation on the modules of the NMT model shows that some modules have tight relation with the general-domain knowledge while some other modules are more essential in the domain adaptation. And the investigation on the parameters shows that some parameters are important for both the general-domain and in-domain translation and the great change of them during continual training brings about the performance decline in general-domain. We conduct experiments across different language pairs and domains to ensure the validity and reliability of our findings.    %by tracing parameter variation in this progress and depict the influence of different model modules.  %and depict the relationship between them so that we can work out solutions to the catastrophic forgetting problem based on these findings.  %Under the background of domain adaptation for machine translation, we found that some parameters play an essential role in both general domain and in-domain translation and the change of them brings about the performance decline in general-domain. Based on these findings, we propose a solution to detect these important parameters and accordingly suppress their fluctuation during domain adaptation. Experimental results prove  %that our method can greatly improve the translation quality in in-domain and meanwhile minimize the negative influences on general-domain translation.",299
"  Recurrent neural network architectures have demonstrated remarkable success in natural language processing, achieving state of the art performance across an impressive range of tasks ranging from machine translation to semantic parsing to question answering . These tasks demand the use of a wide variety of computational processes and information sources , and are evaluated in coarse-grained quantitative ways. As a result, it is not an easy matter to  identify the specific strengths and weaknesses in a network's solution of a task.    In this paper, we take a different tack, exploring the degree to which neural networks successfully master one very specific aspect of linguistic knowledge: the interpretation of sentences containing reflexive anaphora.  We address this problem in the context of the task of semantic parsing, which we instantiate as mapping a sequence of words into a predicate calculus logical form representation of the sentence's meaning. \pex<ex:transform>     \a Mary runs       \a John sees Bob   \xe Even for simple sentences like those in~, which represent the smallest  representations of object reflexives in English, the network must learn lexical semantic  correspondences  and a mode of composition .   %Such simple disentangled representations of meaning are highly successful once all of the words are learned.  Of course, not all of natural language adheres to such simple formulas. Reflexives, words like herself and himself, do not have an interpretation that can be assigned independently of the meaning of the surrounding context. \pex<ex:transform-refl>     \a Mary sees herself      \a Alice sees herself  \xe In these sentences, the interpretation of the reflexive is not a constant that can be combined with the meaning of the surrounding elements. Rather, a reflexive object must be interpreted as identical to the meaning of verb's subject.  Of course, a network could learn a context-sensitive interpretation of a reflexive, so that for any sentence with \lex{Mary} as its subject, the reflexive is interpreted as , and with \lex{Alice} as its subject it is interpreted as .  However, such piecemeal learning of reflexive meaning will not support generalization to sentences involving a subject that has not been encountered as the antecedent of a reflexive during training, even if the interpretation of the  subject has occurred elsewhere. What is needed instead is an interpretation of the reflexive that is characterized not as a specific  output token, but rather as an abstract instruction to duplicate the interpretation of the subject. Such an abstraction requires more than the ``jigsaw puzzle"" approach to meaning that simpler sentences afford.   \citet{Marcus98} argues that this kind of abstraction, which he takes to require the use of  algebraic variables to assert identity, is beyond the capacity of recurrent neural networks.  \citeauthor{Marcus98}'s demonstration involves a simple recurrent network  language model that is trained to predict the next word over a corpus of sentences of the following form: \pex     \a A rose is a rose.     \a A mountain is a mountain. %    \a A car is a car \xe All sentences in this training set have identical subject and object nouns.  \citeauthor{Marcus98} shows, however, that the resulting trained network does not correctly predict the subject noun when tested with a novel preamble `\lex{A book is a }'. Though intriguing, this demonstration is not entirely convincing: since the noun occurring in the novel preamble, \lex{book} in our example, did not occur in the training data, there is no way that the network could possibly have known which  output should correspond to the reflexive for a sentence containing the novel  subject noun, even if the network did successfully encode an identity relation between subject and object.   \citet{frank2013} explore a related  task in the context of SRN interpretation of reflexives. In their experiments, SRNs were trained to map input words to corresponding semantic symbols that are output on the same time step in which a word is presented. For most words in the vocabulary, this is a simple task: the desired output is a constant function of the input .  For reflexives however, the target output depends on the subject that occurs earlier in the sentence. \citeauthor{frank2013}\ tested the network's ability to interpret a reflexive in sentences containing a subject that had not occurred as a reflexive's antecedent during training. However, unlike Marcus' task, this subject and its corresponding semantic symbol did occur in other  contexts in the training data, and therefore was in the realm of possible inputs and outputs for the network. Nonetheless, none of the SRNs that they trained succeeded at this task for even a single test example.   Since those experiments were conducted, substantial advances have been made on recurrent neural network architectures, some of which have been crucial in the success of practical NLP systems.   These innovations open up the possibility that modern network architectures may well be able to solve the variable identity problem necessary for mapping reflexive sentences to their logical form. In the experiments we describe below, we explore whether this is the case.        In this work, we focus on the catastrophic forgetting phenomenon of NMT and aim to find the inner reasons for this. Under the background of domain adaptation, we propose two analyzing methods from the perspectives of modules and parameters  and conduct experiments across different language pairs and domains. We find that some modules tend to maintain the general-domain knowledge while some modules tend to adapt to the in-domain; we also find that some parameters are more important for both the general-domain and in-domain translation and the change of them brings about the performance decline in general-domain. Based on our findings, we have proposed several ideas that may help improve the vanilla continual training method. We will prove the effectiveness of these ideas in future work.      The investigation on the different modules of the NMT model showed that some modules are of higher capacity to preserve the general-domain knowledge while some other modules are more essential for adapting to the in-domain; the investigation on the parameters showed that some parameters are important for both the general domain and in-domain translation and the change of them brings about the performance decline in general-domain.    We put forward two methods for evaluating the importance of parameters, and we find that some parameters play an essential role in both general-domain and in-domain. Then we find that the change of important parameters brings about the performance decline in general-domain through a series analyzing experiments.  Finally, based on our analysis, we propose an importance evaluation based method to alleviate catastrophic forgetting and the experimental results of different languages and domains prove the effectiveness of the method.    
"," Reflexive anaphora present a challenge for semantic interpretation: their meaning varies depending on context in a way that appears to require abstract variables. Past work has raised doubts about the ability of recurrent networks to meet this challenge. In this paper, we explore this question in the context of a fragment of English that incorporates the relevant sort of contextual variability. We consider sequence-to-sequence architectures with recurrent units and show that such networks are capable of learning semantic interpretations for reflexive anaphora which generalize to novel antecedents. We explore the effect of attention mechanisms and different recurrent unit types on the type of training data that is needed for success as measured in two ways: how much lexical support is needed  to induce an abstract reflexive meaning  and what contexts must a noun phrase occur in to support generalization of reflexive interpretation to this noun phrase?",300
"  Pre-trained contextualized language models such as BERT are state-of-the-art for a wide variety of natural language processing tasks. Similarly, in Information Retrieval , these models have brought about large improvements in the task of ad-hoc retrieval---ranking documents by their relevance to a textual query, where the models increasingly dominate the leaderboards of ad-hoc retrieval competitions.  Despite this success, little is understood about why pretrained language models are effective for ad-hoc ranking. What new aspects of the task do neural models solve that previous approaches do not?  Previous work has shown that traditional IR axioms, e.g. that increased term frequency should correspond to higher relevance, do not explain the behavior of recent neural models . Outside of IR, others have examined what characteristics contextualized language models learn in general , but it remains unclear if these qualities are valuable to the ad-hoc ranking task specifically. Thus, new approaches are necessary to characterize the models.  We propose a new framework aimed at Analyzing the Behavior of Neural IR ModeLs  based on three testing strategies: ``measure and match'', ``textual manipulation'', and ``dataset transfer''. The ``measure and match'' strategy, akin to the diagnostic tests proposed by~\citet{Rennings2019AnAA}, constructs test samples by controlling one measurement  and varying another  using samples from an existing IR collection. The ``textual manipulation'' strategy tests the effect that altering the document text has on ranking. The ``dataset transfer'' strategy constructs tests from non-IR datasets.  The new tests allow us to isolate model characteristics---such as sensitivity to word order, or preference for summarized rather than full documents---that are imperceptible using other approaches.  We also release an open-source implementation of our framework that makes it easy to define new diagnostics and to replicate the analysis on new models.  Using our new framework, we perform the first large-scale analysis of neural IR models. We compare today's leading ranking techniques, including those using BERT and T5, as well as methods focused on efficiency like DocT5Query and EPIC. We find evidence showing that neural models are able to make effective use of textual signals that are not reflected by classical term matching methods like BM25.  For example, when controlling for term frequency match, the neural models detect document relevance much more accurately than the BM25 baseline, and the effect is more pronounced in larger neural models.  Further, unlike prior approaches, rankers based on BERT and T5 are heavily influenced by word order: shuffling the words in a document consistently lowers the document's score relative to the unmodified version. We also find significant differences between different neural models: e.g., while most models treat queries navigationally , the BERT-based EPIC model and T5 do not exhibit such behaviors. Finally, these models can exhibit unexpected : adding additional relevant text to the end of a document frequently can reduce its ranking score, and adding non-relevant content can increase it---despite document length itself having a limited effect on the ranking scores. %  In summary, we present a new framework  for performing analysis of ad-hoc ranking models. We then demonstrate how the framework can provide insights into ranking model characteristics by providing the most comprehensive analysis of neural ranking models to date. Our released software framework facilitates conducting further analyses in future work.                     Because of their abstract meaning, reflexive anaphora present a distinctive challenge for semantic parsing that had been thought to be beyond the capabilities of recurrent networks. The experiments described here demonstrate that this was incorrect. Sequence-to-sequence networks with a range of recurrent unit types are in fact capable of learning an interpretation of reflexive pronouns that generalizes to novel antecedents. Our results also show  that such generalization is nonetheless contingent on the appearance of the held-out  antecedent in a variety of syntactic positions as well as the diversity of antecedents providing support for the reflexive generalization. Additionally successful generalization depends on the  network architecture in ways that we do not fully understand. It is at present unknown whether the demands that any of these architecture impose on the learning environment for successful learning of reflexives are consistent with what children experience, but this could be explored with both corpus and experimental work.  Future work will also be necessary to elucidate the nature of the networks' representations of reflexive interpretation and to understand how they support lexical generalization .    The question we have explored here is related to, but distinct from, the issue of systematicity , according to which pieces of representations learned in distinct contexts can freely recombine.  This issue has been addressed  using sequence-to-sequence architectures  in recent work with the synthetic SCAN robot command interpretation dataset  and on  language modeling , in both cases with limited success.  One aspect of the SCAN domain that is particularly relevant to reflexive interpretation is commands involving adverbial modifiers such as \lex{twice}.  Commands like \lex{jump twice} must be interpreted by duplicating the meaning of the verb, i.e., as , which is similar to what we require for the interpretation of the reflexive object, though in a way that does not require sensitivity to syntactic structure that we have not explored here. Recently, \citet{lake2019compositional}, \citet{li-etal-2019-compositional} and \citet{Gordon2020Permutation} have proposed novel architectures that increase systematic behavior, and we look forward to exploring the degree to which these impact performance on reflexive interpretation.   Our current work has focused  exclusively on recurrent networks, ranging from  SRNs to GRUs and LSTMs. Recent work by \citet{transformer} shows that Transformer networks  attain superior performance on a variety of sequence-to-sequence tasks while dispensing with recurrent units altogether. Examining both the performance and training characteristics of Transformers will allow us to compare the effects of attention and recurrence on the anaphora interpretation task. This is especially interesting given the impact that attention had on performance in our experiments.  Finally, while our current experiments are revealing about the capacity of recurrent networks to learn generalizations about context-sensitive interpretation, there are nonetheless limited in a number of respects because of simplifications in the English fragment we use to create our synthetic data. Reflexives famously impose a structural requirement on their antecedents . In the following example, the reflexive's antecedent must be  and cannot be . \ex The student near the teacher sees herself    \xe We do not know whether the architectures that have succeed on our experiments would do similarly well if the relevant generalization required reference to  structure. Past work has explored the sensitivity of recurrent networks to hierarchical structure, with mixed results . In ongoing work, we are exploring this question by studying  more complex synthetic domains both with the kind of recurrent sequence-to-sequence network used here as well networks that explicitly encode or decode sentences in a hierarchical manner.   A second simplification concerns the distribution of reflexives themselves. English reflexives can appear in a broader range of syntactic environments apart from transitive objects . It would be of considerable interest to explore the reflexive interpretation in a naturalistic setting that incorporate this broader set of distributions.   
"," Numerous studies have demonstrated the  effectiveness of pretrained contextualized language models such as BERT and T5 for ad-hoc search. However, it is not well-understood why these methods are so effective, what makes some variants more effective than others, and what pitfalls they may have.  We present a new comprehensive framework for Analyzing the Behavior of Neural IR ModeLs , which includes new types of diagnostic tests that allow us to probe several characteristics---such as sensitivity to word order---that are not addressed by previous techniques.  To demonstrate the value of the framework, we conduct an extensive empirical study that yields insights into the factors that contribute to the neural model's gains, and identify potential unintended biases the models exhibit.  We find evidence that recent neural ranking models have fundamentally different characteristics from prior ranking models. For instance, these models can be highly influenced by altered document word order, sentence order and inflectional endings. They can also exhibit unexpected behaviors when additional content is added to documents, or when documents are expressed with different levels of fluency or formality. We find that these differences can depend on the architecture and not just the underlying language model.\footnote{\url{https://github.com/allenai/abnriml}}",301
"  .     %     % % final paper: en-uk version      %     %   % space normally used by the marker     % This work is licensed under a Creative Commons      % Attribution 4.0 International Licence.     % Licence details:     % \url{http://creativecommons.org/licenses/by/4.0/}.     %      % % final paper: en-us version      %     %   % space normally used by the marker     % This work is licensed under a Creative Commons      % Attribution 4.0 International License.     % License details:     % \url{http://creativecommons.org/licenses/by/4.0/}. }  Commonsense is the knowledge shared by the majority of people in society and acquired naturally in everyday life. Commonsense reasoning is the process of logical inference by using commonsense information. Commonsense to answer the questions that is ``'' in Figure  is depicted as: ``'', ``'', and ``.'' An enormous amount of pre-defined commonsense knowledge is available and people can make inferences using this commonsense such as in the following example: ``''  ``''  ``''  ``'' This chain of commonsense reasoning is naturally deduced by humans without substantial difficulty. Whereas people acquire commonsense in their lives, machines cannot learn this knowledge without any assistance. A large amount of external knowledge and several reasoning steps are required for machines to learn commonsense. In recent years, various datasets  have been constructed to enable machines to reason commonsense.    is one of the most widely researched datasets and is presented in Figure  \subref{subfig:examplea}. The studies of commonsense reasoning based on this dataset can be categorized into two mainstream approaches. The first approach uses pre-trained language models with distributed representations, which exhibit high performances on most Natural Language Processing  tasks. However, despite their high performance, these models must be trained with an excessive number of parameters and cannot explain the process of commonsense reasoning. The second approach is reasoning with a commonsense knowledge graph. The generally used commonsense knowledge graph is ConceptNet 5.5 , which includes parsed representation from Open Mind Commonsense  and other different language sources such as WordNet  or DBPedia . In this approach, the subgraph of  ConceptNet corresponding to the questions are transformed into node embeddings by the graph encoder. The candidate with the highest attention score is selected as an answer that is computed between the node embeddings and the word vectors from the language models. To learn the commonsense knowledge that is not observed or understood by the language models, relations from ConceptNet serve as a critical role in this method. The performance is improved by utilizing the relations that are not represented in the text; however, the interpretation of the question is still not enough.   Unlike , the most commonly used method of solving this problem is Knowledge-Based Question-Answering   employing semantic representations. As this method infers the answer with the logical structure of the question using the knowledge base, the question-answering process can be explained in a logical form. In our work, Abstract Meaning Representation  , which is one of the logical structure, is used to understand the overall reasoning process, from the question to the answer.  AMR is a graph for meaning representation that symbolizes the meaning of sentences. AMR illustrates ``who is doing what to whom'' that is implied in a sentence with a graph.  The components of these graphs are not the words, but rather the concepts and their relations. Each concept denotes an event or an entity, and each relation represents the semantic role of the concepts.   In this paper, we enable the language models to exploit the AMR graph to understand the logical structure of sentences. However, it is difficult to infer commonsense information with only an AMR graph, owing to its deficiency of commonsense knowledge of the given sentence. For example, in Figure  \subref{subfig:exampleb}, the AMR graph indicates the path of the logical structure of the sentence ``'' ; in other words, these paths from the single AMR graph lack the proficient information to predict the right answer. Therefore, for commonsense reasoning, dynamic interactions between the AMR graph and ConceptNet are inevitable to reach the correct answer.   Thus, we propose a new compact AMR graph expanded with the ConceptNet's commonsense relations with pruning, and it is called ACP graph. The proposed method can interpret the path from the question to the answer by performing commonsense reasoning within the connected graph, such as ``'' .    The contributions of our study are as follows.      The remainder of this paper is organized as follows. In Section 2, we present the entire process of our method in detail. The experimental setup and results are explained in Section 3. A discussion of the proposed model is provided in Section 4, and Section 5 presents the conclusions. Appendix A provides related works including ConceptNet, previous works on commonsense reasoning, and AMR.        We presented a new framework  for analyzing ranking models based on three testing strategies: Measure and Match Tests , Textual Manipulation Tests , and Dataset Transfer Tests . By using these tests, we demonstrated that a variety of insights can be gained about the behaviors of recently-proposed ranking models, such as those based on BERT and T5. Our analysis is, to date, the most extensive analysis of the behaviors of neural ranking models, and sheds light on several unexpected model behaviors. For instance, adding non-relevant text can increase a document's ranking score, even though the models are largely not biased towards longer documents. We also see that the same base language model used with a different ranking architecture can yield different behaviors, such as higher sensitivity to shuffling a document's text. Meanwhile, different language models can be sensitive to different characteristics, such as the importance of prepositions.   \documentclass[11pt,a4paper]{article} \usepackage[table]{xcolor} \usepackage{times,latexsym} \usepackage{url} \usepackage[T1]{fontenc} \usepackage{amsfonts} \usepackage{amsmath} \usepackage{todonotes} \usepackage{booktabs} \usepackage{adjustbox} \usepackage{rotating} \usepackage{layouts} \usepackage{enumitem}  \usepackage{afterpage}  \usepackage{float}  \usepackage{lipsum}  \DeclareMathOperator{\sgn}{sgn}  \definecolor{pos}{RGB}{76,144,186} \definecolor{neg}{RGB}{222,102,62} \definecolor{art}{RGB}{200,200,200}  \setlist[itemize]{noitemsep, topsep=0pt}  \hyphenation{Conv-KNRM}   \usepackage[acceptedWithA]{tacl2018v2}     \usepackage{xspace,mfirstuc,tabulary} \newcommand{\dateOfLastUpdate}{Sept. 20, 2018} \newcommand{\styleFileVersion}{tacl2018v2}  \newcommand{\ex}[1]{{\sf #1}} \newcommand{\sys}{ABNIRML}  \newif\iftaclinstructions \taclinstructionsfalse   \iftaclinstructions \renewcommand{\confidential}{} \renewcommand{\anonsubtext}{} \newcommand{\instr} \fi  \iftaclpubformat   \newcommand{\taclpaper}{final version\xspace} \newcommand{\taclpapers}{final versions\xspace} \newcommand{\Taclpaper}{Final version\xspace} \newcommand{\Taclpapers}{Final versions\xspace} \newcommand{\TaclPapers}{Final Versions\xspace} \else \newcommand{\taclpaper}{submission\xspace} \newcommand{\taclpapers}{{\taclpaper}s\xspace} \newcommand{\Taclpaper}{Submission\xspace} \newcommand{\Taclpapers}{{\Taclpaper}s\xspace} \newcommand{\TaclPapers}{Submissions\xspace} \fi   \newcommand\ac[1]{{\color{brown}\{#1\}}} \newcommand\sergey[1]{{\color{blue}\{#1\}}} \newcommand\doug[1]{{\color{orange}\{#1\}}} \newcommand\sm[1]{{\color{purple}\{#1\}}}  \title{\sys: Analyzing the Behavior of Neural IR Models}   \author{ {\bf Sean MacAvaney}\thanks{\xspace \xspace Work done during internship at AI2} \qquad Sergey Feldman \qquad {\bf Nazli Goharian} \\ {\bf Doug Downey} \qquad {\bf Arman Cohan}   \\      IR Lab, Georegetown University, Washington, DC \\      Allen Institute for AI, Seattle, WA \\   {\tt\small \{sean,nazli\}@ir.cs.georgetown.edu} \\   {\tt\small \{sergey,dougd,armanc\}@allenai.org} }  \date{}          
"," \texttt{CommonsenseQA} is a task in which a correct answer is predicted through commonsense reasoning with pre-defined knowledge. Most previous works have aimed to improve the performance with distributed representation without considering the process of predicting the answer from the semantic representation of the question. To shed light upon the semantic interpretation of the question, we propose an AMR-ConceptNet-Pruned  graph. The ACP graph is pruned from a full integrated graph encompassing Abstract Meaning Representation  graph generated from input questions and an external commonsense knowledge graph, ConceptNet . Then the ACP graph is exploited to interpret the reasoning path as well as to predict the correct answer on the \texttt{CommonsenseQA} task. This paper presents the manner in which the commonsense reasoning process can be interpreted with the relations and concepts provided by the ACP graph. Moreover, ACP-based models are shown to outperform the baselines.",302
"  Part-Of-Speech  tagging is a crucial step for language understanding, both being used in automatic language understanding applications such as named entity recognition  and question answering , but also being used in manual language understanding by linguists who are attempting to answer linguistic questions or document less-resourced languages .   Much prior work  on developing high-quality POS taggers uses neural network methods which rely on the availability of large amounts of labelled data. However, such resources are not readily available for the majority of the world's 7000 languages .  Furthermore, manually annotating large amounts of text with trained experts is an expensive and time-consuming task, even more so when linguists/annotators might not be native speakers of the language.    Active Learning \cite[AL]{lewis1995evaluating,settles2009active} is a family of methods that aim to train effective models with less human effort and cost by selecting such a subset of data that maximizes the end model performance. While many methods have been proposed for AL in sequence labeling , through an empirical study across six typologically diverse languages we show that within the same task setup these methods perform inconsistently. Furthermore, even in an oracle scenario  %  where we have access to the true labels during data selection, existing methods are far from optimal.  We posit that the primary reason for this inconsistent performance is that while existing methods consider uncertainty in predictions, they do not consider the direction of the uncertainty with respect to the output labels. For instance, in Figure  we consider the German token ``die,'' which may be either a pronoun  or determiner . According to the initial model , ``die'' was labeled as PRO majority of the time, but a significant amount of probability mass was also assigned to other output tags  for many examples. Based on this, existing AL algorithms that select uncertain tokens will likely select ``die'' because it is frequent and its predictions are not certain, but they may select an instance of ``die'' with either a gold label of PRO or DET. Intuitively, because we would like to correct errors where tokens with true labels of DET are mis-labeled by the model as PRO, asking the human annotator to tag an instance with a true label of PRO, even if it is uncertain, is not likely to be of much benefit.  Inspired by this observation, we pose the problem of AL for part-of-speech tagging as selecting tokens which maximally reduce the confusion between the output tags. For instance, in the example we would attempt to pick a token-tag pair ``die/DET'' to reduce potential errors of the model over-predicting PRO despite its belief that DET is also a plausible option. We demonstrate the features of this model in an oracle setting where we know true model confusions , and also describe how we can approximate this strategy when we do not know the true confusions.  We evaluate our proposed AL method by running simulation experiments on six typologically diverse languages namely German, Swedish, Galician, North Sami, Persian, and Ukrainian, improving upon models seeded with cross-lingual transfer from related languages . In addition, we conduct human annotation experiments on Griko, an endangered language that truly lacks significant resources.   Our contributions are as follows:           % File tacl2018v2.tex % Sep 20, 2018  % The English content of this file was modified from various *ACL instructions % by Lillian Lee and Kristina Toutanova % % LaTeXery is mostly all adapted from acl2018.sty.  \documentclass[11pt,a4paper]{article} \usepackage{times,latexsym} \usepackage{url} \usepackage[T1]{fontenc} \usepackage{amsmath} \usepackage{amssymb} \usepackage{tabularx} \usepackage{mathtools} \usepackage{booktabs} \usepackage{url} \usepackage{longtable} \usepackage{tabu} \usepackage{multirow} \usepackage{amsfonts} \usepackage{tabu} \usepackage{algorithm} \usepackage{bbm} \usepackage{subfigure} \usepackage[noend]{algpseudocode} \usepackage[normalem]{ulem} \usepackage{enumitem} \makeatletter  \def\BState{\State\hskip-\ALG@thistlm} \usepackage{bbm} \usepackage{xcolor} \DeclareMathOperator*{\argmax}{arg\,max} \DeclareMathOperator*{\b-argmax}{ b\text{-}arg\,max} \DeclareMathOperator*{\argmin}{arg\,min}   %% Package options: %% Short version: ""hyperref"" and ""submission"" are the defaults. %% More verbose version: %% Most compact command to produce a submission version with hyperref enabled %%    \usepackage[]{tacl2018v2} %% Most compact command to produce a ""camera-ready"" version \usepackage[acceptedWithA]{tacl2018v2} %% Most compact command to produce a double-spaced copy-editor's version %\usepackage[acceptedWithA]{tacl2018v2} % %% If you need to disable hyperref in any of the above settings  in the TACL instructions), add "",nohyperref"" in the square %% brackets.  %\usepackage[nohyperref]{tacl2018v2}  %%%% Material in this block is specific to generating TACL instructions \usepackage{xspace,mfirstuc,tabulary} \newcommand{\dateOfLastUpdate}{Sept. 20, 2018} \newcommand{\styleFileVersion}{tacl2018v2}  \newcommand{\gn}[1]{\textcolor{magenta}{\small [#1 --GN]}} \newcommand{\an}[1]{\textcolor{blue}{\small [#1 --AA]}}   \newcommand{\ex}[1]{{\sf #1}}  \newif\iftaclinstructions \taclinstructionsfalse % AUTHORS: do NOT set this to true \iftaclinstructions \renewcommand{\confidential}{} \renewcommand{\anonsubtext}{} \newcommand{\instr} \fi  % \iftaclpubformat % this ""if"" is set by the choice of options \newcommand{\taclpaper}{final version\xspace} \newcommand{\taclpapers}{final versions\xspace} \newcommand{\Taclpaper}{Final version\xspace} \newcommand{\Taclpapers}{Final versions\xspace} \newcommand{\TaclPapers}{Final Versions\xspace} \else \newcommand{\taclpaper}{submission\xspace} \newcommand{\taclpapers}{{\taclpaper}s\xspace} \newcommand{\Taclpaper}{Submission\xspace} \newcommand{\Taclpapers}{{\Taclpaper}s\xspace} \newcommand{\TaclPapers}{Submissions\xspace} \fi  %%%% End TACL-instructions-specific macro block %%%%  \title{Reducing Confusion in Active Learning for Part-Of-Speech Tagging}  \author{Aditi Chaudhary\textsuperscript{1},      Antonios Anastasopoulos\textsuperscript{2,\Thanks{ Work done at Carnegie Mellon University.}},      Zaid Sheikh\textsuperscript{1}, Graham Neubig\textsuperscript{1} \\   \textsuperscript{1}Language Technologies Institute, Carnegie Mellon University\\   \textsuperscript{2}Department of Computer Science, George Mason University\\   { @cs.cmu.edu}}    { }  }    \date{}   %            In some cases of failure, our model exhibits two problems as follows:  As the concept node \texttt{illness} disappeared while generating the graph, our model may not have enough information for extracting the subgraph from ConceptNet.         The red edges in Figure  present the paths that have high attention weight for the question ``\texttt{What home entertainment equipment requires cable?}'' In Figure  \subref{subfig:case-heatmap}, the top four paths with high attention weights are described. As opposed to predicting the answers simply with the ConceptNet graph connected to the question, we allow our model to learn relevant paths inherent in the ACP graph. That is, our graph path learning module with ACP graph is capable of commonsense reasoning exploring the paths.     \section{Conclusions and Future Works} We introduce a new commonsense reasoning method, using the proposed ACP graph. This method outperformed the model that simply learns the ConceptNet graph. Furthermore, our method can explain the answer-inference process by interpreting the logical structure of the sentences within commonsense reasoning process. Models that applied our method exhibit higher performance compared to the  previous models. However, certain problems still remain. Though the relations \texttt{ARG0} and \texttt{ARG1} occupy most of the core roles in the AMR graph, it is still arguable that the other choice of relations may lead to better results. Therefore, we will show the experimental results according to the different pruning rules on the \texttt{CommonsenseQA} task in the future. Also, we plan to develop an end-to-end learning model that incorporates the AMR generation model and the question-answering model to reduce the error propagation from the AMR generation.  \section{Acknowledgement} This work was supported by Institute for Information \& communications Technology Planning \& Evaluation grant funded by the Korea government . Also, this research was supported by the MSIT, Korea, under the ITRC support program supervised by the IITP      \section*{Acknowledgements}    The acknowledgements should go immediately before the references.  Do   not number the acknowledgements section. Do not include this section   when submitting your paper for review.    include your own bib file like this:       ConceptNet. In ConceptNet , real-world assertions are represented as two nodes and directed edges, which denote certain concepts and their relations, respectively. The nodes represent words or phrases from natural language sentences. The edges represent the relations between nodes, and they contain lexical as well as commonsense relation information. As ConceptNet is created by collecting data from various types of knowledge bases, nodes of different types also exist. Each node represents a slightly different meaning considering its role in the sentence. For example, the word ``\texttt{person}'' can be found in the concept of ``\texttt{person/n},'' which is analyzed as a noun with a POS tagger, and with more detailed semantic information, it can be identified as ``\texttt{person/n/wn/body}.'' This information makes possible the detailed extraction of knowledge that considers the purpose of each sentence. Meanwhile, one or more edges may be defined between two nodes. For example, the edge between the nodes ``\texttt{person}'' and ``\texttt{eat}'' can be defined independently as ``\texttt{CapableOf}'' and ``\texttt{Desires}.'' Various concepts and their relations are defined as nodes and edges in ConceptNet, considering the ambiguity in the sentences.   Commonsense reasoning.  Commonsense reasoning is the process of logical inference by using commonsense information. In \texttt{CommonsenseQA}\footnote[1]{https://www.tau-nlp.org/csqa-leaderboard} task, the fine-tuning approach with pre-trained language representations makes use of external commonsense knowledge. There are two means of exploiting external knowledge. The first\footnote[7]{ttps://drive.google.com/file/d/1sGJBV38aG706EAR75F7LYwCqci9ocG9i/view,\\ https://gist.github.com/commonsensepretraining/507aefddcd00f891c83ebf6936df15e8} is the method that post-trained with some commonsense sentence corpus. It then performs fine-tuning with evidence derived from questions and answers. The second method  is to encode commonsense knowledge graphs and train with language models. The language models that have exhibited high performance in this method are BERT , RoBERTa , which use bidirectional transformer encoders. They also include XLNet , which is based on autoregressive language modeling, ALBERT , which adopts cross-layer parameter sharing and factorized embedding parameterization and ELECTRA  that is pre-trained with Replaced Token Detection  task.  AMR. AMR  represents the relations between concept nodes using the PropBank frameset and vocabularies from the sentences. The edges between two or more concept nodes or the argument nodes are relations. AMR represents semantic roles such as core and numbered roles, and uses more than 100 semantic relations, including negation, conjunction, command, and wikification. In PropBank , the semantic roles are labeled in the form of \texttt{ARG0}\texttt{4} and \texttt{ARGM}. In general, \texttt{ARG0} denotes the agent of the verb, \texttt{ARG1} is the patient, \texttt{ARG2} means the instrument, benefactive, or attribute, \texttt{ARG3} is interpreted as the starting point, benefactive, or attribute, and \texttt{ARG4} represents the ending point. The root node serves as the central point of the representation and is called frame node. Thereafter, other concept nodes are sequentially combined according to the semantic relations. AMR consists of concept nodes in a single graph that is traversable to all nodes, similar to a parse tree. However, unlike the parse tree, which represents the explicit structure of sentences, AMR aims to describe the conceptual and semantic structure. That is, if the semantic meanings of explicitly different sentences are the same, they can be represented by the same AMR graph. For example, the two sentences ``\texttt{The boy is a hard worker}'' and ``\texttt{The boy works hard}'' are represented by the same PENMAN graph, namely \texttt{ :manner )}. The data constructed to generate and evaluate these representations are AMR 2.0  and AMR 1.0 . The model with the highest performance on these data was presented by Zhang et al. \shortcite{zhang2019amr:2019}, using BERT. Various NLP fields have exploited AMR, such as sentence generation , summarization , question and answering , dialogue systems , paraphrase detection , and biomedical text mining .  
"," Active learning  uses a data selection algorithm to select useful training samples to minimize annotation cost. This is now an essential tool for building low-resource syntactic analyzers such as part-of-speech  taggers. Existing AL heuristics are generally designed on the principle of selecting uncertain yet representative training instances, where annotating these instances may reduce a large number of errors. However, in an empirical study across six typologically diverse languages , we found the surprising result that even in an oracle scenario where we know the true uncertainty of predictions, these current heuristics are far from optimal. Based on this analysis, we pose the problem of AL as selecting instances which maximally reduce the confusion between particular pairs of output tags. Extensive experimentation on the aforementioned languages shows that our proposed AL strategy outperforms other AL strategies by a significant margin.  We also present auxiliary results demonstrating the importance of proper calibration of models, which we ensure through cross-view training, and analysis demonstrating how our proposed strategy selects examples that more closely follow the oracle data distribution. The  code is publicly released here.\footnote{\url{https://github.com/Aditi138/CRAL}}",303
" With an increasing submission of academic papers in recent years, the task of making final decisions manually incurs significant overheads to the program chairs, it is desirable to automate the process.  In this study, we aim at utilizing document-level semantic analysis for paper review rating prediction and recommendation.  Given the reviews of each paper from several reviewers as input, our goal is to infer the final acceptance decision for that paper and the reviewers' evaluation with respect to a numeric rating .  Paper review rating prediction and recommendation is a practical and important task in AI applications which will help improve the efficiency of the paper review process. It is also intended to enhance the consistency of the assessment procedures and outcomes, and to diversify the paper review process by comparing human recommended rating with machine recommended rating.  In the literature, most of existing studies cast review rating prediction as a multi-class classification/regression task .  They build a predictor by using supervised machine learning models with review texts and corresponding ratings.  Due to the importance of features, most researches focus on extracting effective features such as context-level features  and user features  to boost prediction performance.  However, feature engineering is time-consuming and labor-intensive.   Recently, with the development of neural networks and its wide applications, various deep learning-based models have been proposed for automatically learning features from text data .  Existing deep learning models usually learn continuous representations of different grains  from text corpus .  Although deep learning models can automatically learn extensive feature representation, they cannot efficiently capture the hierarchical relationship inherent to the review data.  To address this problem,  studied a hierarchical architecture and implemented it in deep learning framework to learn a better document-level representation.  Also, with the success of attention mechanism in many tasks such as machine translation, question answering and so on ,   designed a directional self-attention network to gain context-aware embeddings for words and sentences.  Despite great progress made by these models, they do not focus on the task of paper review rating recommendation and are not effective enough to be directly used for this task because of the following reasons: First, the review data is hierarchical in nature.  There exists a three-level hierarchical structure in the review data: word level, intra-review level and inter-review level, while previous models only capture two-levels  of this hierarchy.  Second, paper reviews are usually much longer than other reviews , while most of these models are working on those shorter reviews stated above and they do not leverage the up to date representation techniques such as BERT  and SciBERT .   In this paper, we propose a novel neural network framework for paper review rating recommendation by taking word, intra-review and inter-review information into account.  Specifically, inspired by HAN  and DiSAN , we introduce a Hierarchical Bi-directional self-Attention Network  framework to effectively incorporate different levels of hierarchical information.  The proposed framework consists of three main modules in end-to-end relationship: sentence encoder, intra-review encoder and inter-review encoder, which can consider hierarchical structures of review data as comprehensive as possible. The outputs of inter-review encoder are leveraged as features to build the rating predictor without any feature engineering. We release the code and data collected by us to enable replication and application to new tasks, available at https://github.com/RingBDStack/HabNet.  The contributions of this work are as follows:      We have presented a novel active learning method for low-resource POS tagging which works by reducing confusion between output tags. Using simulation experiments across  six typologically diverse languages, we show that our confusion-reducing strategy achieves higher accuracy than existing methods. Further, we test our approach under a true setting of active learning where we ask linguists to document POS information for an endangered language, Griko. Despite being unfamiliar with the language, our proposed method achieves performance gains over the other methods in most iterations. For our next steps, we plan to explore the possibility of adapting our proposed method for complete morphological analysis, which poses an even harder challenge for AL data selection due to the complexity of the task. 
"," Review rating prediction of text reviews is a rapidly growing technology with a wide range of applications in natural language processing.  However, most existing methods either use hand-crafted features or learn features using deep learning with simple text corpus as input for review rating prediction, ignoring the hierarchies among data.  In this paper, we propose a Hierarchical bi-directional self-attention Network framework  for paper review rating prediction and recommendation, which can serve as an effective decision-making tool for the academic paper review process. Specifically, we leverage the hierarchical structure of the paper reviews with three levels of encoders: sentence encoder , intra-review encoder  and inter-review encoder .  Each encoder first derives contextual representation of each level, then generates a higher-level representation, and after the learning process, we are able to identify useful predictors to make the final acceptance decision, as well as to help discover the inconsistency between numerical review ratings and text sentiment conveyed by reviewers.  Furthermore, we introduce two new metrics to evaluate models in data imbalance situations.  Extensive experiments on a publicly available dataset  and our own collected dataset  demonstrate the superiority of the proposed approach compared with state-of-the-art methods.",304
"  % What is QG and Why it is important Question Generation  aims to endow machines with the ability to ask relevant and to-the-point questions about a document.  QG has important practical applications, such as  generating assessments for course materials in education, prompting user interaction in dialog systems, enabling machines to ask clarification questions such as FAQs, and automatically building large-scale QA datasets for the research community.   % How tranditional works do it? Recent QG approaches have used Seq2Seq models with attention, which feeds the input document into an encoder, and generates a question about the document through a decoder.  % Why it needs RL? The training objective is to maximize the log likelihood of the ground-truth question paired with each input document using teacher forcing. However, as the ground-truth questions are insufficient to account for the many equivalent ways of asking a question, this likelihood-based training suffers from the problem of exposure bias, i.e., the model does not learn how to distribute probability mass over sequences that are valid but different from the ground truth.  % How RL addresses the problem? %   To address this issue, previous QG works proposed to optimize the model directly on question-specific rewards via Reinforcement Learning .  This process decouples the training procedure from the ground truth data, so that the space of possible questions can be better explored. Moreover, it allows the training to target on specific properties we want the question to exhibit, such as relevant to a specific topic or answerable by the document.  % What is the problem for RL-based method? Although various rewards have been employed for QG --- such as BLEU, the answerability reward, and the word movers distance --- optimizing the reward scores does not always lead to higher question quality in practice, as observed by Hosking and Riedel~\shortcite{Hosking2019EvaluatingRF}. How to define robust and effective QG-specific rewards still requires further investigation.   % What we want to do? We aim to analyze the effectiveness of question-specific rewards in QG. Instead of using general natural language generation metrics such as BLEU, we target three QG-related metrics that are commonly cited in human evaluations of question quality:  Fluency indicates whether the question follows the grammar and accords with the correct logic;  Relevance indicates whether the question is relevant to the document; and  Answerability indicates whether the question is answerable given the document. We design a specific RL reward for each metric: a language model based reward for fluency, a discriminator-based reward for relevance, and a QA-based reward for answerability.  After optimizing each reward via RL, we conduct comprehensive analysis, including automatic and human evaluation, to arrive at the following conclusions:  both individual and joint optimization of these rewards can lead to performance gain in automated metrics, but this does not guarantee an improvement in the real question quality;  the reward for relevance substantially helps to improve the question quality, while the reward for answerability reduces the quality due to the bias brought by the QA model; and  a reward is more likely to improve the question quality if the reward score correlates well with human judgement.     In this paper, a scientific paper review dataset called OpenReview is collected from ICLR openreview website and released. We observe that there is a three-level hierarchical structure in this dataset  -- the information and relationships between reviews of one paper may affect the final decision, and so may relationships between words and sentences in each review. Based on these observations, a hierarchical bi-directional self-attention network  framework is proposed for paper review rating prediction and recommendation that can model the interactions among words, sentences, intra- and inter-reviews in an end-to-end manner. Moreover, considering the imbalanced distribution of different classes  in the review rating prediction task, we design two new metrics to better evaluate models.  It is seen that both experimental results of predicting final decisions for submitted papers and identifying ratings for reviews on two datasets  demonstrate our proposed framework has sufficient ability to capture the hierarchical structures of words, sentences and reviews in the datasets and outperforms other models. In the future, we plan to investigate multi-task learning for paper review rating recommendation.   
","     Recent question generation  approaches often utilize the sequence-to-sequence framework  to optimize the log likelihood of ground-truth questions using teacher forcing. However, this training objective is inconsistent with actual question quality, which is often reflected by certain global properties such as whether the question can be answered by the document. As such, we directly optimize for QG-specific objectives via reinforcement learning to improve question quality. We design three different rewards that target to improve the fluency, relevance, and answerability of generated questions. We conduct both automatic and human evaluations in addition to thorough analysis to explore the effect of each QG-specific reward.      We find that optimizing on question-specific rewards generally leads to better performance in automatic evaluation metrics. However, only the rewards  that correlate well with human judgement  lead to real improvement in question quality. Optimizing for the others, especially answerability, introduces incorrect bias to the model, resulting in poor question quality. Our code is publicly available at \href{https://github.com/YuxiXie/RL-for-Question-Generation}{https://github.com/YuxiXie/RL-for-Question-Generation}.",305
"  % In daily bases plethora of opinion data is published about different topics and in response to different stimuli using Social Media.  % Aiming to analyse and gain insights from opinions posted in social media, research in stance detection has become increasingly popular in recent years. Framed as a classification task, the stance detection consists in determining if a textual utterance expresses a supportive, opposing or neutral viewpoint with respect to a target or topic . Research in stance detection has largely been limited to analysis of single utterances in social media. Furthering this research, the SardiStance 2020 shared task  focuses on incorporating contextual knowledge around utterances, including metadata from author profiles and network interactions. The task included two subtasks, one solely focused on the textual content of social media posts for automatically determining their stance, whereas the other allowed incorporating additional features available through profiles and interactions. This paper describes and analyses our participation in the SardiStance 2020 shared task, which was held as part of the EVALITA  campaign and focused on detecting stance expressed in tweets associated with the Sardines movement. %  %   % For a network interaction graph, we generate user embeddings, using variations of graph neural network  embedding methods, and then concatenate author's vector with its corresponding utterance features for each stance. We also extract two types of text embedding representations for each utterance, embedding-based features, namely word embedding vectors and cosine similarity vectors, using different models including variations of CNN and bidirectional LSTM models. Further, the results of these two feature extraction methods are concatenated for the final classification step. We also consider the standard methods that extract frequency-based representations from author profiles and stance utterances including unigrams and Tfidf vectors. All these four features where combined and fed into the drop out and dense layers, to finally generate the final label using a softmax activation function. Though, we deactivate some of these four sources of features and alter the frequency-based vector by excluding some features, changing the embedding source and reducing the dimensionality for highly dimensional vectors  using PCA.}     In this paper we designed and developed a pipeline for representing the knowledge of scientific publication into a structured graph that we called scientific knowledge graph. We employed various state-of-the-art NLP tools and machine learning, and provided a workflow to merge their results. Moreover, we integrated the knowledge coming from many scientific publications into a single knowledge graph with the purpose to represent detailed knowledge of the scientific literature about the Semantic Web domain. The evaluation proved that this solution is able to automatically produce good quality scientific knowledge graphs and that the integration of different tools yields a better overall performance.     There are a number of limitations that need to be still addressed in future work. In the first instance, the current version does not take full advantage of the semantic characterization of the research entities to verify the resulting triples. For instance, it is currently possible for an entity of kind Material to include a entity of kind Task, which may be semantically incorrect. For this reason, we plan to develop a more robust semantic framework that could drive the extraction process and discard triples that do not follow specific constraints. For example, we could state that a material could include another material, but not a task or a method. These requirements could be enforced and verified with the use of specific semantic technologies for expressing constraints such as SHACL\footnote{https://www.w3.org/TR/shacl/}.  A second limitation is that the current prototype can only extract one relationship between two entities. This is not completely realistic since two entities can be linked by many kinds of relationships.  This could also lead to a higher number of relationships that could suggest different applications or uses of entities, increasing the probability of finding unconsidered issues and solutions within a research field. We intend to explore this possibility in future work. Additionally, we will thoroughly investigate the conjunction construct which might hide rich knowledge about the relationship that frequently occurs between two research entities .  We also plan to improve the knowledge graph by considering cross document relations  to further link our entities, in order to better support tools for scientific inquiry.  A third limitation regards our ability to recognize synonyms that are not defined in existent knowledge bases, such as CSO. For instance, the current version may still fail to recognize that two quite different strings  actually refer to the same entity.  We intend to address this issue by computing the semantic similarity between word and graph embeddings representing the entities in order to detect and merge synonyms more effectively.   A fourth limitation regards the scalability of our pipeline.  The current implementation presents a few bottlenecks that could make difficult to apply it on very large-scale datasets. First, the Extractor Framework requires a lot of hard disk space. This entails that data must be sampled to be processed. Second, the current pipeline only adopts the Stanford Core NLP server with just one thread, which requires a long time to mine textual resources sentence-by-sentence.  However, this is not a big issue since it would be possible to run the Stanford Core NLP server in multi-thread mode, speeding up the extraction process.    An important next step will also be  to perform an extrinsic evaluation of the proposed knowledge base within different tasks. In particular, we would like to assess how AI tasks such as those tackled by recommender systems or graph embeddings creation strategies can benefit from it.    
"," This paper presents our submission to the SardiStance 2020 shared task, describing the architecture used for Task A and Task B. While our submission for Task A did not exceed the baseline, retraining our model using all the training tweets, showed promising results leading to  using bidirectional LSTM with BERT multilingual embedding for Task A. For our submission for Task B, we ranked 6th . With further investigation, our best experimented settings increased performance from  to  with same architecture and parameter settings and after only incorporating social interaction features- highlighting the impact of social interaction on the model's performance.",306
"   State-of-the-art for most existing natural language processing  classification tasks is currently achieved by systems that are first pre-trained on auxiliary language modeling tasks and then fine-tuned on the task of interest with cross-entropy loss . Although commonly used, cross-entropy loss -- the KL-divergence between one-hot vectors of labels and the distribution of model's output logits -- has several shortcomings. Cross entropy loss leads to poor generalization performance due to poor margins , and it lacks robustness to noisy labels  or adversarial examples . Effective alternatives have been proposed to change the reference label distributions through label smoothing , Mixup , CutMix , knowledge distillation  or self-training~.  Additionally, it has been recently demonstrated in NLP that fine-tuning using cross entropy loss tends to be unstable , especially when supervised data is limited, a scenario in which pre-training is particularly helpful. To tackle the issue of unstable fine-tuning, recent work proposes local smoothness-inducing regularizers  and regularization methods inspired by the trust region theory  to prevent representation collapse that lead to poor generalization performance. Empirical analysis suggests that fine-tuning for longer, reinitializing top few layers~, and using debiased Adam optimizer during fine-tuning~ can make the fine-tuning procedure more stable.  We are inspired by the learning strategy that humans deploy when given a few examples -- try to find the commonalities between the examples of each class and contrast them with examples from other classes. We hypothesize that a similarity-based loss will be able to hone in on the important dimensions of the multidimensional hidden representations and lead to better few-shot learning results and be more stable while fine-tuning pre-trained models. We propose a novel objective for fine-tuning pre-trained language models that includes a supervised contrastive learning term that pushes examples from the same class close and examples of different classes further apart. The new term is similar to the contrastive objective used for self-supervised representation learning in various domains such as image, speech, and video domains. . In constrast to these methods, however, we use a contrastive objective for supervised learning of the final task, instead of contrasting different augmented views of examples.  Adding supervised contrastive learning  term to the fine-tuning objective improves performance on several natural language understanding tasks from the GLUE benchmark , including SST-2, CoLA, MRPC, RTE, and QNLI over the state-of-the-art models fine-tuned with cross entropy loss. The improvements are particularly strong in few-shot learning settings , and models trained with SCL are not only robust to the noise in the training data, but also have better generalization ability to related tasks with limited labeled data. Our approach does not require any specialized architectures , memory banks , data augmentation of any kind, or additional unsupervised data. To the best of our knowledge, our work is the first to successfully integrate a supervised contrastive learning objective for fine-tuning pre-trained language models.   % \ves{end of alternative}  % State-of-the-art models for most existing natural language processing  tasks are currently learned by fine-tuning pre-trained large language models  that have been shown to capture semantic, syntactic, and world knowledge.  Recent attempts at improving the pre-training stage over masked language modeling~ has led to improvements on natural language understanding tasks, but fine-tuning stage has stayed the same for all downstream NLP classification tasks: add a task-specific output layer to the pre-trained language model and continue training on the labeled task data using cross-entropy loss.  % Cross-entropy loss is the most widely adopted objective for supervised classification models, defined as the KL-divergence between one-hot vectors of labels and the distribution of model's output logits. Although commonly used by the state-of-the-art models across many fields including NLP, there has been several works demonstrating the shortcomings of the cross-entropy loss, showing that it leads to poor generalization performance due to poor margins , and lack of robustness to noisy labels  or adversarial examples . Among the alternative objective functions proposed, more effective approaches in practice have been the ones that change the reference label distributions such as label smoothing , Mixup , CutMix , knowledge distillation  or self-training~.  % Several recent studies show that the fine-tuning procedure is unstable , especially for the case where supervised data is limited, a scenario in which pre-training is particularly helpful. To tackle the issue of unstable fine-tuning, local smoothness-inducing regularizers  and regularization methods inspired by the trust region theory  have been proposed to prevent representation collapse that leads to poor generalization performance of task models. There has also been empirical analysis that suggests fine-tuning for longer, reinitializing top few layers~, and using debiased Adam optimizer during fine-tuning~ make the fine-tuning procedure more stable.   % On the other hand, contrastive learning methods have seen remarkable success for self-supervised representation learning on various downstream tasks, particularly in the image, speech, and video domains.   % These self-supervised contrastive learning methods primarily try to reduce the distance between representations of the positive pairs while increasing the distance between representations of the negative pairs. Positive pairs are constructed as the different augmented views of the same labeled example, and negative pairs are simply augmented views of all the other examples. Augmented views of the examples are often constructed with state-of-the-art data augmentation methods such as RandAugment  or AutoAugment  for the computer vision domain, and distance metric is often chosen as the inner product or the Euclidean distance between the representations of the pairs in a low-dimensional embedding space.    % Recently, \citet{Khosla2020SupervisedCL} extended contrastive learning to a fully supervised setting through using label information while constructing positive and negative pairs, showed improved performance over cross-entropy loss baseline on ImageNet image classification accuracy and robustness benchmarks, and demonstrated that supervised contrastive learning is less sensitive to hyperparameter changes. Similarly, \citet{Liu2020HybridDT} propose a hybrid discriminative-generative training of energy-based models, where they approximate the generative term with a contrastive objective and demonstrate improved image classification accuracy on CIFAR-10 and CIFAR-100, along with improved performance on robustness, out-of-distribution detection, and calibration.  % In this paper, we propose a supervised contrastive learning regularization for fine-tuning of large pre-trained language models that helps the model leverage label information more effectively across different labeled data regimes. Our approach does not require specialized architectures , memory banks , or very large batch sizes , but still outperforms the strong baseline of fine-tuning RoBERTa-Large on labeled task data with cross-entropy loss, unlike some previous works. To the best of our knowledge, our work is the first to successfully integrate a supervised contrastive learning objective for fine-tuning pre-trained language models. % while sho results on few-shot learning, robustness, and generalization ability.  % We summarize our key contributions in the following: %     In this work, we described a state-of-the-art stance detection system leveraging different features including author profiling, word meaning context and social interactions. Using different random runs, our best model achieved  leveraging deepwalk-based knowledge graphs embeddings, FastText and similarity feature vectors extracted by two multi-headed convolutional neural networks from auther's utterance. This motivates our future, aiming to reduce the model complexity and automate the feature selection process.   
"," State-of-the-art natural language understanding classification models follow two-stages: pre-training a large language model on an auxiliary task, and then fine-tuning the model on a task-specific labeled dataset using cross-entropy loss. Cross-entropy loss has several shortcomings that can lead to sub-optimal generalization and instability.  Driven by the intuition that good generalization requires capturing the similarity between examples in one class and contrasting them with examples in other classes, we propose a supervised contrastive learning  objective for the fine-tuning stage. Combined with cross-entropy, the SCL loss we propose obtains improvements over a strong RoBERTa-Large baseline on multiple datasets of the GLUE benchmark in both the high-data and low-data regimes, and it does not require any specialized architecture, data augmentation of any kind, memory banks, or additional unsupervised data. % In all of our experiments, we use a very competitive baseline of fine-tuning RoBERTa Large using cross entropy loss on the labeled task data.  %including SST-2, CoLA, MRPC, RTE and QNLI. %Our method outperforms the baseline on multiple datasets in the GLUE benchmark including SST-2, CoLA, MRPC, RTE and QNLI for the full dataset regime.  % We also show the effectiveness of our regularization for few-shot learning and demonstrate  % We also demonstrate the robustness of the learned representations by using noisy datasets, and show that the learned representations are more transferable to related tasks.  We also demonstrate that the new objective leads to models that are more robust to different levels of noise in the training data, and can generalize better to related tasks with limited labeled task data.",307
" With the rapid growth of textual documents on the internet, accessing information from the web has become a challenging issue . Often users want the summary of a topic from various sources to fulfill their information needs . The QF-MDS task deals with such problems where the goal is to summarize a set of documents to answer a given query.     In the QF-MDS task, the summaries generated by the summarizer can be either extractive or abstractive. An extractive summarizer extracts relevant text spans from the source document, whereas an abstractive summarizer generates a summary in natural language that may contain some words which did not appear in the source document . With the rising popularity of virtual assistants in recent years, there is a growing interest to integrate abstractive summarization capabilities in these systems for natural response generation .   One major challenge for the QF-MDS task is that the datasets  used for such tasks do not contain any labeled training data. Therefore, neural summarization models that leverage supervised training cannot be used in these datasets. Note that for other related tasks , how to reduce the demands for labeling the data and how to leverage unlabeled data were also identified as a major challenge. While using datasets similar to the target dataset as the training data for the QF-MDS task, we find that these datasets only contain multi-document gold summaries. However, the state-of-the-art transformer-based  summarization models  cannot be used in long documents due to computational complexities . To tackle these issues, we propose a novel weakly supervised approach by utilizing distant supervision to generate weak reference summary of each single-document from multi-document gold reference summaries. We train our model on each document with weak supervision and find that our proposed approach that generates abstractive summaries is very effective for the QF-MDS task. More concretely, we make the following contributions:         We propose a supervised contrastive learning objective for fine-tuning pre-trained language models and demonstrate improvements over a strong RoBERTa-Large baseline on multiple datasets of the GLUE benchmark in both high-data and low-data regimes. We also show that our proposed objective leads to models that are more robust to different levels of noise in the training data and can generalize better to related tasks with limited labeled task data. Currently, data augmentation methods in NLP and their effects on the downstream tasks are neither as effective nor as well understood as their counterparts in the computer vision domain. In future work, we plan to study principled and automated data augmentation techniques for NLP that would allow extending our supervised contrastive learning objective to both semi-supervised and self-supervised learning settings.            
"," In the Query Focused Multi-Document Summarization  task, a set of documents and a query are given where the goal is to generate a summary from these documents based on the given query. However, one major challenge for this task is the lack of availability of labeled training datasets. To overcome this issue, in this paper, we propose a novel weakly supervised learning approach via utilizing distant supervision. In particular, we use datasets similar to the target dataset as the training data where we leverage pre-trained sentence similarity models to generate the weak reference summary of each individual document in a document set from the multi-document gold reference summaries. Then, we iteratively train our summarization model on each single-document to alleviate the computational complexity issue that occurs while training neural summarization models in multiple documents  at once. Experimental results in Document Understanding Conferences\footnote{https://duc.nist.gov/}  datasets show that our proposed approach sets a new state-of-the-art result in terms of various evaluation metrics.",308
" One ultimate goal of language modelling is to construct a model like human, to grasp general, flexible and robust meaning in language. One reflection of obtaining such model is be able to master new tasks or domains on same task quickly. However, NLU models have been building from specific task on given data domain but fail when dealing with out-of-domain data or performing on a new task. To combat this issue, several research areas in transfer learning including domain adaptation, cross lingual learning, multi-task learning and sequential transfer learning have been developed to extend model handling on multiple tasks. However, transfer learning tends to favor high-resources tasks if not trained carefully, and it is also computationally expensive .  Meta learning algorithm tries to solve this problem by training model in a variety of tasks which equip the model the ability to adapt to new tasks with only a few samples.  In our case, we adopt the idea of model-agnostic meta learning  which is an optimization method of meta learning that directly optimized the model by constructing an useful initial representation that could be efficiently trained to perform well on various tasks . However, in an continual learning where data comes into the model sequentially, there is still a potential problem of catastrophic forgetting where a model trained with new tasks would start to perform worse on previous tasks. The two objectives of designing a continual learning architecture are to accelerate future learning where it exploits existing knowledge of a task quickly together with general knowledge from previous tasks to learn prediction on new samples and to avoid interference in previous tasks by updates from new tasks. .   % new In this paper, we utilize algorithm derived from Jave and White \shortcite{MLRCL:19} which applies Meta-Learning under continual learning. Our objective is to apply this framework in NLP field, specifically on NLU tasks. By taking advantage of this model-agnostic approach, Meta-Learning under continual learning should be applicable on any language model that is optimized by gradient-based methods. We compare our results with Duo et al \shortcite{dou:19} which applies meta-learning on Glue tasks, our MAML-Rep shows comparable results. We hope to bring new research direction in NLP fields focusing on such method. The implementation of our code can be found at \url{https://github.com/lexili24/NLUProject}.  % old % This paper aims to develop a framework that incorporate meta learning under the continual learning framework. Hypothetically, our approach is efficient in training by relying on low-resources on various tasks adapted from meta learning characteristics. By training a meta learner under continual learning framework, our model should have consistent results on various tasks with little catastrophic forgetting and learning general representation for all tasks. Finally, our approach is model agnostic, and could essentially apply on any existing language models as long as the model can be optimized by gradient descent. Moreover, our method can be put into the framework of some other continual learning techniques like GEM. The implementation of our code can be found at \url{https://github.com/lexili24/NLUProject}.        In this paper, we propose a novel weakly supervised approach for the Query Focused Multi-Document Abstractive Summarization task to  tackle the issue of no available labeled training data for such tasks. We also propose an iterative approach to address the computational problem that occurs while training neural models in long documents . Experimental results in three datasets show that our proposed approach sets a new state-of-the-art result in various evaluation metrics. In the future, we will apply our models on more tasks, such as information retrieval applications , sentiment analysis , learning from imbalanced or unlabeled datasets , and automatic chart question answering .   
"," Neural network has been recognized with its accomplishments on tackling various natural language understanding  tasks. Methods have been developed to train a robust model to handle multiple tasks to gain a general representation of text. In this paper, we implement the model-agnostic meta-learning  and Online aware Meta-learning  meta-objective under the continual framework for NLU tasks proposed by Javed and White\shortcite{MLRCL:19}. We validate our methods on selected SuperGLUE \shortcite{superglue:19}  and GLUE benchmark \shortcite{glue:19}.",309
"  	 	%  	% % final paper: en-us version  	% 	  % space normally used by the marker 	This work is licensed under a Creative Commons  	Attribution 4.0 International License. 	License details: 	\url{http://creativecommons.org/licenses/by/4.0/} }   Neural Machine Translation  adopts the encoder-decoder paradigm to model the entire translation process . Specifically, the encoder finds a multi-layer representation of the source sentence, and the decoder queries the topmost encoding representation to produce the target sentence through a cross-attention mechanism . However, such over-reliance on the topmost encoding layer is problematic in two aspects:  Prone to over-fitting, especially when the encoder is under-trained, such as in low-resource tasks ;  It cannot make full use of representations extracted from lower encoder layers, which are syntactically and semantically complementary to higher layers  .   Researchers have proposed many methods to make the model aware of various encoder layers besides the topmost to mitigate this issue. Almost all of them resort to the adjustment of network structure, which can be further divided into two categories. The first is to merge the feature representations extracted by distinct encoder layers before being fed to the decoder . The differences between them lie in the design of the merge function: through self-attention , recurrent neural network , or tree-like hierarchical merge . Moreover, the second makes each decoder layer explicitly align to a parallel encoder layer  or all encoder layers .  However, the above methods either complicate the original model  or limit the model's flexibility, such as requiring the number of the encoder layers to be the same as the decoder layers .   Instead, in this work, we propose layer-wise multi-view learning to address this problem from the perspective of model training, without changing the model structure. Our method's highlight is that only the training process is concerned, while the inference speed is guaranteed to be the same as that of the standard model. The core idea is that we regard the off-the-shelf output of each encoding layer as a view for the input sentence. Therefore, it is straightforward and cheap to construct multiple views during a standard layer-by-layer encoding process.  Further, in addition to the output of the topmost encoder layer used in standard models , we also incorporate an intermediate encoder layer as the auxiliary view. We feed the two views to a partially shared decoder for independent predictions. An additional regularization loss based on prediction consistency between views is used to encourage the auxiliary view to mimic the primary view. Thanks to the co-training on the two views, the gradients during back-propagation can simultaneously flow into the two views, which implicitly realizes the knowledge transfer.  Extensive experimental results on five translation tasks  show that our method can stably outperform multiple baseline models . In particular, we have achieved new state-of-the-art results of 10.8 BLEU on KoEn and 36.23 BLEU on IWSLT'14 DeEn. Further analysis shows that our method's success lies in the robustness to encoding representations and dark knowledge  provided by consistency regularization.  \iffalse Our contributions are threefold:  \fi     In this work, we are able to extend Meta-Learning under continual learning framework to learn a general presentation that is robust on a set of continual tasks with efficiency. We replicate \shortcite{MLRCL:19} method and and implement on NLU tasks. Results show that with less datapoints, we could derive a MAML like model that is robust on testing tasks, however extending it to continual setting during training phrase, the performance drastically worsen. Future direction would be extending this approach to other language models, as wells as experiment with a combination of high and low resources other than Glue and SuperGlue benchmark to evaluate model performance.       
","   Traditional neural machine translation is limited to the topmost encoder layer's context representation and cannot directly perceive the lower encoder layers. Existing solutions usually rely on the adjustment of network architecture, making the calculation more complicated or introducing additional structural restrictions. In this work, we propose layer-wise multi-view learning to solve this problem, circumventing the necessity to change the model structure.    We regard each encoder layer's off-the-shelf output, a by-product in layer-by-layer encoding, as the redundant view for the input sentence.   In this way, in addition to the topmost encoder layer , we also incorporate an intermediate encoder layer as the auxiliary view.    We feed the two views to a partially shared decoder to maintain independent prediction.     Consistency regularization based on KL divergence is used to encourage the two views to learn from each other.   Extensive experimental results on five translation tasks show that our approach yields stable improvements over multiple strong baselines. As another bonus, our method is agnostic to network architectures and can maintain the same inference speed as the original model.",310
" % . } % Emotion analysis is now an established research area which finds application in a variety of different fields, including social media analysis \cite[i.a.]{Purver2012,Wang2012b,Mohammad2017,Ying2019}, opinion mining \cite[i.a.]{Choi2006}, and computational literary studies \cite[i.a.]{Ovesdotter2005,Kimfanfic2019,Haider2020,Zehe2020}. The most prominent task in emotion analysis is emotion categorization, where text receives assignments from a predefined emotion inventory, such as the fundamental emotions of \fear, \anger, \joy, \anticipation, \trust, \surprise, \disgust, and \sadness which follow theories by  or . Other tasks include the recognition of affect values, namely valence or arousal  or analyses of event appraisal .  More recently, categorization  tasks have been complemented by more fine-grained analyses, namely emotion stimulus detection and role labeling, to detect which words denote the experiencer of an emotion, the emotion cue description, or the target of an emotion. These efforts lead to computational approaches of detecting stimulus clauses  and emotion role labeling and sequence labeling , with different advantages and disadvantages we discuss in .  Further, this work led to a rich set of corpora with annotations of different subsets of roles. An example of a sentence annotated with semantic role labels for emotion is ``\experiencer{John} \cue{hates} \target{cars} because they \stimulus{pollute the   environment}.'' A number of English-language resources are available:  manually construct a dataset following FrameNet's emotion predicate and annotate the stimulus as its core argument.   annotate Tweets for emotion cue phrases, emotion targets, and the emotion stimulus. In our previous work  we publish news headlines annotated with the roles of emotion experiencer, cue, target, and stimulus.  annotate sentence triples taken from literature for the same roles.  A popular benchmark for emotion stimulus detection is the Mandarin corpus by .  annotate English and Mandarin texts in a comparable way on the clause level .  In this paper, we utilize role annotations to understand their influence on emotion classification. We evaluate which of the roles' contents enable an emotion classifier to infer the emotions. It is reasonable to assume that the roles' content carries different kinds of information regarding the emotion: One particular experiencer present in a corpus might always feel the same emotion; hence, be prone to a bias the model could pick up on. The target or stimulus might be independent of the experiencer and be sufficient to infer the emotion.  The presence of a target might limit the set of emotions that can be triggered.  Finally, as some of the corpora contain cue annotations, we assume that these are the most helpful to decide on the expressed emotion, as they typically have explicit references towards concrete emotion names.     We studied to incorporate different encoder layers through multi-view learning in neural machine translation. In addition to the primary view from the topmost layer, the proposed model introduces an auxiliary view from an intermediate encoder layer and encourages the transfer of knowledge between the two views. Our method is agnostic to network architecture and can maintain the same inference speed as the original model. We tested our method on five translation tasks with multiple strong baselines: Transformer, deep Transformer, and DynamicConv. Experimental results show that our multi-view learning method can stably outperform the baseline models. Our models have achieved new state-of-the-art results in KoEn and IWSLT'14 DeEn tasks.   
","   Emotion recognition is predominantly formulated as text classification in   which textual units are assigned to an emotion from a predefined inventory   .   More recently, semantic role labeling approaches have been developed to   extract structures from the text to answer questions like: ``who is   described to feel the emotion?'' , ``what causes this   emotion?'' , and at   which entity is it directed?'' . Though it has been shown that   jointly modeling stimulus and emotion category   prediction is beneficial for both subtasks, it remains unclear which of   these semantic roles enables a classifier to infer the emotion. Is it the   experiencer, because the identity of a person is biased towards a   particular emotion ? Is it a particular target    or a stimulus ? We   answer these questions by training emotion classification models on five   available datasets annotated with at least one semantic role by masking the   fillers of these roles in the text in a controlled manner and find that   across multiple corpora, stimuli and targets carry emotion information,   while the experiencer might be considered a confounder.  Further, we   analyze if informing the model about the position of the role improves the   classification decision. Particularly on literature corpora we find that   the role information improves the emotion classification.",311
" In recent years, the best results for coreference resolution of English have been obtained with end-to-end neural models~. However for Dutch, the existing systems are still using either a  rule-based~ or a machine learning approach~. The rule-based system dutchcoref~ outperformed previous systems on two existing datasets and also presented a corpus and evaluation of literary novels .  In this paper we compare this rule-based system to an end-to-end neural coreference resolution system: e2e-Dutch. This system is a variant of \citet{lee2018higher} with BERT token representations. We evaluate and compare the performance of e2e-Dutch to dutchcoref on two different datasets:  the SoNaR-1 corpus , a genre-balanced corpus of 1 million words, and  the RiddleCoref corpus of contemporary novels . This provides insights into  the relative strengths of a neural system versus a rule-based system for Dutch coreference, and  the effect of domain differences .  The two datasets we consider vary greatly in terms of overall size and length of the individual documents; the training subset of RiddleCoref contains only 23 documents  compared to 581 documents for SoNaR-1. However, the average number of sentences per document is higher for RiddleCoref than for SoNaR-1 .  We also conduct an error analysis for both of the systems to examine the types of errors that the systems make.       Our experiments show that the importance of semantic roles for emotion classification differs between datasets and roles: The stimulus and cue are critical for classification, which correspond to the direct report of a feeling and the description that triggered an emotion. This result is shown in the drop in performance when removing these roles. This information is not redundantly available outside of these arguments.  It is particularly beneficial for the model's performance to have access to the position of cues and stimuli. This suggests that the classifier learns to tackle the problem differently when this information is available, especially so for ECA and ES -- the cases in which literature has been annotated and the instances are comparably long.  The bi-LSTM model indicates that the experiencer role is a confounder in GNE.  The performance can be increased when the model does not have access to its content. Similar results are observed for ET, in which the target role is a confounder. However, these results should be taken with a grain of salt given that they are not confirmed while switching to the transformer-based model. The differences in results between the bi-LSTM and the transformer also motivate further research, as they suggest that the contextualized representation might compensate for missing information, and is, therefore, more robust.  Finally, our results across both models and multiple datasets indicate that emotion classification approaches indeed benefit from semantic roles' information by adding the positional information. Similarly to targeted and aspect-based sentiment analysis, this motivates future work, in which emotion classification and role labeling should be modelled jointly. In this case, it can also be interesting to investigate what happens when the positional indicators are added to all roles jointly.  
","     We evaluate a rule-based \citep{lee2013deterministic}     and neural \citep{lee2018higher} coreference system on Dutch datasets of     two domains: literary novels and news/Wikipedia text.     The results provide insight into the relative strengths of data-driven and     knowledge-driven systems, as well as the influence of domain, document     length, and annotation schemes.     The neural system performs best on news/Wikipedia text,     while the rule-based system performs best on literature.     The neural system shows weaknesses with limited training data and long     documents, while the rule-based system is affected by annotation     differences. The code and models used in this paper are available at     \url{https://github.com/andreasvc/crac2020}",312
"  A relational triple consists of two entities connected by a semantic relation, which is in the form of . The extraction of relational triples from unstructured raw texts is a key technology for automatic knowledge graph construction, which has received growing interest in recent years.  There have been several studies addressing technical solutions for relational triple extraction. Early researches, such as \citet{zelenko2003kernel,chan2011exploiting}, employ a pipeline manner to extract both of entities and relations, where entities are recognized first and then the relation between the extracted entities is predicted. Such a pipeline approach ignores the relevance of entity identification and relation prediction  and tends to suffer from the error propagation problem.  %    To model cross-task dependencies explicitly and prevent error propagation in the pipeline approach, subsequent studies propose joint entity and relation extraction. These studies can be roughly categorized into three main paradigms. The first stream of work, such as \citet{miwa2016end,gupta2016table,zhang2017end}, treats joint entity and relation extraction task as an end-to-end table filling problem. Although these methods represent entities and relations with shared parameters in a single model, they extract the entities and relations separately and produce redundant information . The second stream of work, such as \citet{zheng2017joint,dai2019joint,wei-etal-2020-novel}, transforms joint entity and relation extraction into sequence labeling. To do this, human experts need to design a complex tagging schema. The last stream of work, including \citet{zeng2018extracting,zeng2019learning,nayak2019ptrnetdecoding,zeng2020copymtl}, is driven by the sequence-to-sequence  model  to generate relational triples directly, which is a flexible framework to handle overlapping triples and does not require the substantial effort of human experts.  We follow the seq2seq based models for joint entity and relation extraction. Despite the success of existing seq2seq based models, they are still limited by the autoregressive decoder and the cross-entropy loss. The reasons are as follows: the relational triples contained in a sentence have no intrinsic order in essence. However, in order to adapt the autoregressive decoder, whose output is a sequence,  the unordered target triples must be sorted in a certain order during the training phase. Meanwhile, cross-entropy is a permutation-sensitive loss function, where a penalty is incurred for every triple that is predicted out of the position. Consequently, current seq2seq base models not only need to learn how to generate triples, but also are required to consider the extraction order of multiple triples.   % consists of three parts  featured by transformers with non-autoregressive parallel decoding and the bipartite matching loss.  In detail, there are three parts in the proposed set prediction networks :  to avoid introducing the order of triplets  % restoring to the original form of this task without considering the order of multiple triples In this work, we formulate the joint entity and relation extraction task as a set prediction problem, avoiding considering the order of multiple triples. In order to solve the set prediction problem, we propose an end-to-end network featured by transformers with non-autoregressive parallel decoding and bipartite matching loss. In detail, there are three parts in the proposed set prediction networks : a sentence encoder, a set generator, and a set based loss function. First of all, we adopt the BERT model  as the encoder to represent the sentence. Then, since an autoregressive decoder must generate items one by one in order, such a decoder is not suitable for generating unordered sets. In contrast, we leverage the transformer-based non-autoregressive decoder  as the set generator, which can predict all triples at once and avoid sorting triples. Finally, in order to assign a predicted triple to a unique ground truth triple, we propose bipartite matching loss function inspired by the assigning problem in operation research . Compared with  cross-entropy loss  that highly penalizes small shifts in  triple order, the proposed loss function is invariant to any permutation of predictions; thus it is suitable for evaluating the difference between ground truth set and prediction set.  % To summarize, our contributions are as follows: In a nutshell, our main contributions are: % the main contributions of our work are as follows:   % the conjunction of the bipartite matching loss and transformers with %  parallel decoding  % Our work build on prior work in several domains:relation extraction, non-autoregressive model, andbipartite matching losses for set prediction. % Relation Extraction.   Non-autoregressive Model.     We found large gaps in performance for the two systems across the two domains, but this result is not conclusive due to several reasons, which are as follows.   1, 2 The neural system shows a weakness with the long documents in the novel corpus, but also needs more training data to reach its full potential.   3, 4 The rule-based system should be better adapted to the SoNaR-1 annotation scheme, but the neural system's capacity to adapt to arbitrary annotation conventions does not necessarily imply better linguistic performance.   5 To maximize the comparability and usefulness of the corpora, their annotations should be harmonized, which involves manual mention annotation. In future work we want to improve the neural system by using genre metadata and finetuning BERT, and the rule-based system should be extended to a hybrid system by adding supervised classifiers.    
"," The joint entity and relation extraction task aims to extract all relational triples from a sentence. In essence, the relational triples contained in a sentence are unordered. However, previous seq2seq based models require to convert the set of triples into a sequence in the training phase. To break this bottleneck, we treat joint entity and relation extraction as a direct set prediction problem, so that the extraction model can get rid of the burden of predicting the order of multiple triples. To solve this set prediction problem, we propose networks featured by transformers with non-autoregressive parallel decoding. Unlike autoregressive approaches that generate triples one by one in a certain order, the proposed networks directly output the final set of triples in one shot. Furthermore, we also design a set-based loss that forces unique predictions via bipartite matching. Compared with cross-entropy loss that highly penalizes small shifts in triple order, the proposed bipartite matching loss is invariant to any permutation of predictions; thus, it can provide the proposed networks with a more accurate training signal by ignoring triple order and focusing on relation types and entities. Experiments on two benchmark datasets show that our proposed model significantly outperforms current state-of-the-art methods. Training code and trained models will be available at \url{http://github.com/DianboWork/SPN4RE}.",313
" Zero-shot translation has first been introduced by \citet{firat-etal-2016-zero} and refers to the ability of a multilingual NMT model to translate between all its source and target languages, even those pairs for which no parallel data was seen in training. In the simplest setting, all parameters in the network are shared between the different languages and the translation is guided only by special tags to indicate the desired output language .  While this capability is attractive because it is an alternative to building  dedicated translation systems to serve  languages, performance on zero-shot pairs tends to lag behind pivot translation. Recent papers, such as \citet{Arivazhagan2019}, \citet{Gu2019} and \citet{Zhang2020}, have suggested training techniques to improve the generalization to unseen language pairs, but performance varies considerably across settings.  In this paper, we examine in detail the behavior of the multilingual model proposed by \citet{Johnson2017} on zero-shot translation directions. Our experiments show the following:     Overall, we observe improvements of 8.1 BLEU  on 6 zero-shot directions with simple changes to the multilingual training setup.    In this paper, we introduce set prediction networks for joint entity and relation extraction. Compared with previous seq2seq based models, We formulate the  joint entity and relation extraction task as a set prediction problem. In such a way, the extraction model will be relieved of predicting the extraction order of multiple triples. To solve the set prediction problem, We combine non-autoregressive parallel decoding with bipartite matching loss function. We conduct extensive experiments on two widely used datasets to validate the effectiveness of the proposed set prediction networks. Experimental results show that our proposed networks outperforms state-of-the-art baselines over different scenarios. This challenging task is far from being solved. We find that relation types exhibit an imbalanced or long-tailed distribution in NYT dataset and WebNLG dataset. Our future work will concentrate on how to combine cost-sensitive learning with the proposed set prediction networks.          
"," Zero-shot neural machine translation is an attractive goal because of the high cost of obtaining data and building translation systems for new translation directions. However, previous papers have reported mixed success in zero-shot translation. It is hard to predict in which settings it will be effective, and what limits performance compared to a fully supervised system. In this paper, we investigate zero-shot performance of a multilingual EN$\leftrightarrow$\{FR,CS,DE,FI\} system trained on WMT data. We find that zero-shot performance is highly unstable and can vary by more than 6 BLEU between training runs, making it difficult to reliably track improvements. We observe a bias towards copying the source in zero-shot translation, and investigate how the choice of subword segmentation affects this bias. We find that language-specific subword segmentation results in less subword copying at training time, and leads to better zero-shot performance compared to jointly trained segmentation. A recent trend in multilingual models is to not train on parallel data between all language pairs, but have a single bridge language, e.g.\ English. We find that this negatively affects zero-shot translation and leads to a failure mode where the model ignores the language tag and instead produces English output in zero-shot directions.  We show that this bias towards English can be effectively reduced with even a small amount of parallel data in some of the non-English pairs.",314
"  Entrainment is a well-known psycholinguistic phenomenon causing people to adapt to conversation partners so as to become more similar. It affects many linguistic features including phonetics , lexical choice , syntax , and prosody . Importantly, it correlates with interesting aspects of the conversation such as task success, liking, and even rapport with a robot .  The researchers cited above employed various means to measure entrainment, such as correlations, models of conditional probabilities, comparisons of distributions, and perceived similarity. Recently, \citet{Nasir2018} proposed the first neural entrainment measure. Our work builds on theirs by addressing a challenge critical to measuring entrainment: accounting for consistency.   Entrainment is defined as an active, though unconscious, adaptation of a speaker towards their partner. In practice, however, the static similarity or correlation between two speakers is often measured. Thus, even two speakers whose vocal characteristics were initially similar are perceived to have entrained, although no adaptation has taken place. Alternatively, when Speaker B entrains to Speaker A, both speakers are perceived to have entrained, without adaptation from Speaker A. We apply neural methods proposed by \citet{Pryzant2018} to explicitly deconfound consistency, the tendency to adhere to one's own vocal style, from entrainment, the tendency to adapt to one's partner. We argue that entrainment measures that do not control for consistency overestimate the degree of entrainment in a conversation.  Section  explains the data and features that we use to train our networks, which are described in Section . Section  introduces two experiments to validate our methods whose results are discussed, lastly, in Section .    We analyze the importance of shared subwords in multilingual models and find that language-specific BPE segmentation helps to reduce the amount of untranslated segments in zero-shot directions. Furthermore, we explore whether the tendency to produce the wrong output language can be attributed to using English as the only bridge language, and show that even with a small amount of additional training data in non-English language pairs, generalization to unseen translation directions improves as the model is less likely to produce output in the wrong language.  Compared to previous work, the methods we propose are easier to implement, since they only concern data collection and pre-processing, and result in higher gains for zero-shot directions. They are also compatible in principle with approaches that introduce new training objectives or model modifications, and we report best results when fine-tuning a multi-bridge model with back-translation for zero-resource translation directions.  For future work, we are interested in testing the effects of subword regularization  on zero-shot translation performance, and scaling multi-bridge setups to massively multilingual settings.  
","   Human interlocutors tend to engage in adaptive behavior known as entrainment to become more similar to each other. Isolating the effect of consistency, i.e., speakers adhering to their individual styles, is a critical part of the analysis of entrainment. We propose to treat speakers' initial vocal features as confounds for the prediction of subsequent outputs. Using two existing neural approaches to deconfounding, we define new measures of entrainment that control for consistency. These successfully discriminate real interactions from fake ones. Interestingly, our stricter methods correlate with social variables in opposite direction from previous measures that do not account for consistency. These results demonstrate the advantages of using neural networks to model entrainment, and raise questions regarding how to interpret prior associations of conversation quality with entrainment measures that do not account for consistency.",315
"  The proliferation of online hate speech has become prevalent in recent times. Numerous social media outlets and the computational social science community are looking at various automated techniques to detect and classify hate speech. However, most models, nascent in nature, have significant limitations due to the complexity of the problem. Primarily, the lack of a reliable baseline coupled with an evolving vocabulary of hateful content makes this a particularly challenging issue. For instance, many studies have classified this problem as a binary classification task, but this fails to address the subtleties of hate speech, such as direct  vs. indirect  hate speech. These binary classification models also fail to identify different types of hate speech like racism, sexism, antisemitism, etc. or their varying degrees. Another key obstacle that plagues these binary models is their inability to distinguish between general offensive language and hate speech. A third issue that arises in designing automated approaches is class imbalance---hate speech is usually a small percentage of the overall data---and the need to adequately upsample hate observations without model overfitting.  In our work, inspired by the recent successes in developing multi-class hate speech models that separate hate speech from offensive content, we propose DeL-haTE, an ensemble of tunable deep learning models that leverages CNN and GRU layers. The CNN layer extracts higher-order features from the word embedding matrix that then inform the GRU layer, which extracts informative features from the sequence of words. These features are utilized for automatic detection of hate speech on social media. Our novelty lies in using a tuning procedure to adapt the model to individual dataset characteristics.   %Issues particular to developing hate speech detection models %	- Class imbalance issue %		- Hate speech is a minute portion of the overall content on social media both generally and in published datasets %	- How to adequately upsample hate observations for training without leading to model overfitting? % %	- We, like others, utilize a downsampling approach during training to ensure a class-balanced dataset passes through the model at each epoch %	- We combine this with an early stopping procedure that utilizes a validation dataset and saves the model state at the epoch with minimal validation loss % %	- These procedures, and other factors, lead to variability in resultant models   %To maintain the necessity of downsampling during training while mitigating the problems of overfitting and variability, we develop an ensemble approach for hate speech classification, extending the CNN-RNN-FC model topology that has been shown to be successful for hate speech classification.   Our major contributions can be summarized by answering the following questions.   	 \end{enumerate}  Summary of Results: Our best ensemble on the HON dataset achieves a 65\% F1 Macro and an 83\% hate recall, surpassing the performance on the HON dataset of current state of the art models by 33\%. We show that the ensemble models outperform individual models by an average of 5\% hate recall and 8\% F1 macro across all datasets. When applied to unlabeled Gab data, tuning improved the pretrained models by an average of 12\%, with the best tuned ensemble models achieving 57\% hate recall. Our model trained using weak supervision achieved a 67\% hate recall on posts from Gab.  %\sidd{We show that the ensemble models outperform their individual components by an average of 5\% hate recall and 8\% F1 macro. % %We then examine the generalizability of our model framework to novel data from Gab, experimenting with both transfer learning and weak supervision %	- Transfer learning using a small manually labeled set of posts improved the hate recall ensembles pre-trained on the HON and OLID datasets by 10\% on the Gab data. % %	- We hypothesized that integrating the labeling of the HON and OLID datasets and combining them would lead to better generalizability for our model framework by increasing both the size and diversity of training examples %		This was confirmed by our experiments with transfer learning as the combined ensembles outperformed the single dataset models on Gab data by an average 8\% Hate recall over the HON models and 5\% on F1 Macro.}     We propose two neural measures of entrainment that control for consistency. We empirically validate these measures by demonstrating their ability to discriminate between real and fake sessions. Although our measures perform slightly worse than the one reported by \citet{Nasir2018}, we believe this is because their measure captures both entrainment and consistency and therefore better describes the expected similarity between two turns, but is overly broad as a measure of entrainment.  Most intriguingly, the strict separation of consistency and entrainment leads to correlations that are very different from those with other entrainment measures that do not account for consistency, even on the same corpus. This resembles the results of \citet{Perez2016}, who found that correlations differ based on how disentrainment is treated.   Our findings cast previous links between conversation quality and entrainment measures that do not account for consistency in a new light. It is worth revisiting those with the new ability to distinguish between consistency and entrainment.  In our future work, we intend to expand the network inputs for each prediction to the entire prior conversation context using RNNs with attention. We will also conduct further analysis of these entrainment measures, e.g., by feature, speaker sex, role, and dialogue act.            \section{Multiple testing for correlations with social variables}  The correlations between social variables and our entrainment measures vary greatly across retrainings of the underlying networks. This is especially true for , with -values for correlations with dom ranging from 7.5e-13 to almost 1.  To address this, we retrained both networks 100 times, recomputing the Pearson correlations each time. To control the false discovery rate resulting from this multiple testing, we use the procedure of \citet{Benjamini1995}. Each run consists of three tests per measure. We sort each group of three tests by their  values and determine the smallest value  such that  for at least one  value, where  is its position after sorting. Finally, we determine the largest  such that  where  is the -th smallest  value for any run of the respective measure, the level at which at least one of three correlations is significant for that run and measure.   Using this method, we find that 65 out of 100 times the correlation between  and dom is significant as well as 36 times for lik. None of the correlations for  reach the level of significance, not even in terms of the ``raw''  values.   For all but three of the 65 runs with significant correlations between  and dom, the correlation has the same valence. The three with opposite valence are among the weakest, the most significant one having only the 47th smallest  value. All 36 significant correlations between  and lik have the same valence. Considering the clear overall trends, we conclude that  correlates positively with dom and to a lesser degree with lik.  
"," %This document is a model and instructions for \LaTeX. %This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes,  %or Math in Paper Title or Abstract. Online hate speech on social media has become a fast-growing problem in recent times. Nefarious groups have developed large content delivery networks across several mainstream  and fringe outlets  to deliver cascades of hate messages directed both at individuals and communities. Thus addressing these issues has become a top priority for large-scale social media outlets. Three key challenges in automated detection and classification of hateful content are the lack of clearly labeled data, evolving vocabulary and lexicon - hashtags, emojis, etc - and the lack of baseline models for fringe outlets such as Gab. In this work, we propose a novel framework with three major contributions.  We engineer an ensemble of deep learning models that combines the strengths of state-of-the-art approaches,  we incorporate a tuning factor into this framework that leverages transfer learning to conduct automated hate speech classification on unlabeled datasets, like Gab, and  we develop a weak supervised learning methodology that allows our framework to train on unlabeled data. Our ensemble models achieve an 83\% hate recall on the HON dataset, surpassing the performance of the state of the art deep models. We demonstrate that weak supervised training in combination with classifier tuning significantly increases model performance on unlabeled data from Gab, achieving a hate recall of 67\%.",316
"   % % The following footnote without marker is needed for the camera-ready % version of the paper. % Comment out the instructions  and uncomment the 8 lines % under ""final paper"" for your variant of English. %  .     %      % % final paper: en-us version      %     %   % space normally used by the marker     % This work is licensed under a Creative Commons      % Attribution 4.0 International License.     % License details:     % \url{http://creativecommons.org/licenses/by/4.0/}. }  The following instructions are directed to authors of papers submitted to COLING-2020 or accepted for publication in its proceedings. All authors are required to adhere to these specifications. Authors are required to provide a Portable Document Format  version of their papers. The proceedings are designed for printing on A4   paper.  Authors from countries in which access to word-processing systems is limited should contact the publication co-chairs Fei Liu  and Liang Huang  as soon as possible.  We may make additional instructions available at \url{http://coling2020.org/}. Please check this website regularly.      We constructed a character-level AT-ISR framework that was trained with the original architecture of the attention-based sequence-to-sequence ASR model.  The main difference is that it consists of shorter sequences than the standard architecture.  No new redesign was needed for the ISR, and some hyperparameters can be used without any changes.   Transfer learning treats the non-incremental ASR model as the teacher and the ISR as the student model.  Student ISR learns the same attention alignment as the teacher model's, allowing a simple mechanism in the incremental recognition.   both of which utilize the same attention alignment with the teacher model's, allowing a simple mechanism in the incremental recognition.  Various types of models have been explored.  The optimum performance was achieved by including a few ahead blocks, setting the last character of the last set as the decoder input, keeping the recurrent states across the steps, and utilizing the attention transfer.  
","   This document contains the instructions for preparing a paper submitted   to COLING-2020 or accepted for publication in its proceedings. The document itself   conforms to its own specifications, and is therefore an example of   what your manuscript should look like. These instructions should be   used for both papers submitted for review and for final versions of   accepted papers. Authors are asked to conform to all the directions   reported in this document.",317
"  When Natural Language Processing  systems are deployed in production, and interact with users , there are many potential ways of collecting feedback data or rich interaction logs. For example, one can ask for explicit user ratings, or collect user clicks, or elicit user revisions to get an estimate of how well the deployed system is doing. However, such user interaction logs are primarily used for an one-off assessment of the system, e.g., for spotting critical errors, detecting domain shifts, or identifying the most successful use cases of the system in production. This assessment can then be used to support the decision of keeping or replacing this system in production.   From a machine learning perspective, using interaction logs only for evaluation purposes are lost opportunities for offline reinforcement learning . Logs of user interactions are gold mines for off-policy learning, and they should be put to use, rather than being forgotten after a one-off evaluation purpose.  To move towards the goal of using user interaction logs for learning, we will discuss which challenges have hindered RL from being employed in real-world interaction with users of NLP systems so far.  Concretely, our focus is on sequence-to-sequence learning for NLP applications , such as machine translation, summarization, semantic parsing or dialogue generation for chatbots, since these applications provide the richest interaction with users. For example, many machine translation services provide the option for users to give feedback on the quality of the translation, e.g. by collecting post-edits. Similarly, industrial chatbots can easily collect vast amounts of interaction logs, which can be utilized with offline RL methods.  Recent work by has recognized that the poorly defined realities of real-world systems are hampering the progress of RL in production environments. They address, amongst others, issues such as off-line learning, limited exploration, high-dimensional action spaces, or unspecified reward functions. These challenges are important in RL for control systems or robots grounded in the physical world. However, they severely underestimate the human factor when collecting feedback in systems interacting with humans, e.g. through natural language. In the following, we will thus present challenges that are encountered in user-interactive RL for NLP systems. With this discussion, we aim to  encourage NLP practitioners to leverage their interaction logs through offline RL, and  inspire  RL researchers to steel their algorithms for the challenging applications in NLP.   We used a novel word learning paradigm, inspired by classic studies from psycholinguistics, to assess BERT's syntactic generalization behavior on two novel phenomena: English verb class alternations and verb/object selectional restrictions.  In both cases we address the issue of single and few-shot learning by fine-tuning the model on just one or two positive examples, finding that BERT makes some generalizations about a novel token based on minimal experience, and that these generalizations drive robust behavior during test time. This novel word learning paradigm can continue to be explored in later work through the use of large databases such as VerbNet , which builds on Levin's verb documentations by providing a larger database of verb alternations and sectional restrictions that can be turned into train and test sentences for BERT without hand-crafting.  For verbal/object selectional restrictions, we find that BERT leverages indirect evidence to expect unattested but plausible verb/noun pairings more than unattested but implausible pairings. These results provide evidence for the view that the model is able to attend not just to patterns overtly realized in the data  but also implicit relationships between tokens . The ability to use indirect evidence, specifically indirect negative evidence, is a hallmark of human language learning, and these results indicate that models are capable of similar behavior in a simple novel word learning paradigm.  For verbal alternations, we find that when fine-tuned on a single frame, BERT routinely expects the verb to occur in its sister frame with a higher likelihood than in unrelated verbal frames. Interestingly, this behavior is consistently blocked when the model is asked to generalize from a frame that involves an object to a frame where the object is lacking. This behavior is consistent with a general bias towards transitivity in the model, and suggests an exciting direction for further study. Whether such a general bias exists, whether it is restricted to settings with limited evidence, and whether it changes as verbs appear more frequently in the fine-tuning or training data is a question for future research. Another question for future research is whether a multilingual BERT would have the same success on alternation tests in other languages, and if if would exhibit the same biases that we see for English.  
"," Large volumes of interaction logs can be collected from NLP systems that are deployed in the real world. How can this wealth of information be leveraged? Using such interaction logs in an offline reinforcement learning  setting is a promising approach. However, due to the nature of NLP tasks and the constraints of production systems, a series of challenges arise. We present a concise overview of these challenges and discuss possible solutions.",318
"     In addition to other challenges in multiword expression  processing that were addressed in previous work, such as non-compositionality , discontinuity , and syntactic variability , The PARSEME shared task edition 1.2 has focused on another prominent challenge in detecting MWEs, namely detection of unseen MWEs. The problem with unseen data is common for many NLP tasks. While rule-based and unsupervised ML approaches are less affected by unseen data, supervised ML techniques are often found to be prone to overfitting. In this respect, the introduction of language modelling objectives to be added to different NLP tasks and their effect on generalisation have shown promising results. Further improvements brought by pre-trained language models made them a popular approach to a multitude of NLP tasks. One particular advantage of such models is that they facilitate generalisation beyond task-specific annotations .  MWEs are inherent in all natural languages and distinguishable for their syntactic and semantic idiosyncracies . Since language models are good at capturing syntactic and semantic features, we believe they are a suitable approach for modelling MWEs.    In particular, our system relies on BERT pre-trained language models .  Additionally, we render the system semi-supervised by means of multi-task learning. The most promising feature to be jointly learned with MWEs is dependency parse information . Accordingly, we fine-tune BERT for two different objectives: MWE detection and dependency parsing. MWE learning is done via token classification using a linear layer on top of BERT, and dependency parse trees are learned using dependency tree CRF network .  Our experiments confirm that this joint learning architecture is effective for capturing MWEs in most languages represented in the shared task.~      There is large potential in NLP to leverage user interaction logs for system improvement. We discussed how algorithms for offline RL can offer promising solutions to this type of learning problem. However, there are specific challenges in offline RL that arise due to the particular nature of NLP systems that collect human feedback in real-world applications. We presented cases where such challenges have been found and offered solutions that have helped. Furthermore, we related the identified challenges to the Challenges of Real-World Reinforcement Learning . This overview may serve as a guide for both NLP researchers to explore solutions of offline RL, and for RL researchers to test and equip their algorithms for the real-world challenges in NLP applications.
"," This paper describes a semi-supervised system that jointly learns verbal multiword expressions  and dependency parse trees as an auxiliary task. The model benefits from pre-trained multilingual BERT.  BERT hidden layers are shared among the two tasks and we introduce an additional linear layer to retrieve VMWE tags. The dependency parse tree prediction is modelled by a linear layer and a bilinear one plus a tree CRF on top of BERT. The system has participated in the open track of the PARSEME shared task 2020 and ranked first in terms of F1-score in identifying unseen VMWEs as well as VMWEs in general, averaged across all $14$ languages.",319
"  % \gn{Title candidate: ``Detecting Hallucinated Content ...'' . I wonder if you could also run your methods over extractive summarization outputs or the true references and see how many hallucinations they detect? Just an idea.} % However, recent studies on abstractive text summarization   % and neural machine translation~ have shown that conditional neural sequence models are prone to hallucinate content that is not faithful to the input text.  This risk of generating unfaithful content impedes the safe deployment of neural sequence generation models~. The first step to building models that do not suffer from these failures is the assessment and identification of such hallucinated outputs. Prior work has shown that standard metrics used for sequence evaluation, such as BLEU scores , ROUGE  and BERTScores , do not correlate well with the faithfulness of model outputs~. They also require reference output text, limiting their applicability to detecting halluciations in a deployed system at run-time. Very recent efforts~ have started to develop automatic metrics to measure the faithfulness of output sequences. These methods use external semantic models, e.g. the question-generation and question-answering systems~ or textual entailment inference models, to score faithfulness tailored for abstract text summarization.  However, these scores do not directly measure the number of hallucinated tokens %In addition, these metrics are often tailored for the evaluation of summaries in abstract text summarization  and only correlate weakly with human judgements.  % \gn{Big question: what is the difference from word-level quality estimation, which has been around for a very long time, since at least: \citet{bach-etal-2011-goodness} and has been covered in many WMT quality estimation shared tasks . This seems more related than the works cited below, and describing why we'd need to do something new over these works would probably be a big question in the minds of anyone familiar with the MT field. Also, would the proposed methods for detecting hallucination do better than SOTA word-level QE models?}  % \gn{Similar motivation: Moreover, they do not distinguish the types of errors in terms of fluency and adequacy: a substitution error referring to a simple morphological variation  is % considered in the same way as a content word substitution changing the meaning of the sentence.~.}  We propose a new task for faithfulness assessment - hallucination detection at the token level, which aims to predict if each token in the machine output is a hallucinated or faithful to the source input.  This task does not use the reference output to assess faithfulness, which offers us the ability to apply it in the online generation scenario where references are not available. Similar to the spirit of our proposed task, word-level quality estimation~ in the machine translation community predicts if tokens are correctly translated based on human post-editing. However, they do not distinguish errors in terms of fluency and adequacy~.  % A substitution error referring to a simple morphological variation  is considered the same as a content word substitution changing the meaning of the sentence.~.  In contrast to estimating the amount of human post-editing work required to fix errors, we specifically focus only on hallucination  errors.  We measure hallucination for two conditional sequence generation tasks -- abstractive summarization and machine translation . For the former, we produce a benchmark dataset from recently released annotations ~. For MT, we carefully design the human assessment guideline and create high-quality annotations. We will also release our human annotated data for future research. To learn token-level hallucination prediction for general conditional sequence generations tasks, we propose a novel method that creates synthetic ``hallucinated"" data and finetunes a pretrained language model~ on it. Without any human annotated supervised training data, we achieve an average F1 of around 0.6 across all the benchmark datasets, setting initial performance levels for this new task. % \cz{\st{We have also computed sentence-level aggregated predictions and achieve significantly higher correlations with human scores than previous methods. Finally, we use our new data to study the effect of pretraining on MT hallucination and show it can actually produce more faithful translations, }} We also show that pretraining on MT can actually produce more faithful translations, confirming recent findings in abstractive summarization~.  Predicting hallucination labels at token-level provides a tool for diagnosing and interpreting model outputs, which allows us to flag potential risks at inference time for previously unseen inputs. On the other hand, the token-level labels also allow for fine-grained controls over the target sequence during learning full translation models.  We show how to use these token-level hallucination labels in two case studies to improve self-training and learning from noisy mined bitext in low-resource MT. In both cases, there can be noise in the target text, either produced by the self-training teacher or mining errors. However, most outputs are only partially hallucinated  and the rest of the output is still useful for training, as we show by introducing different token-level loss truncation schemes. %To further benefit self-training, we filter out the noisy part and also glean useful part of model predictions by applying token-level loss truncation or control of information flows to the target sequence at training time.  Our best methods outperform strong baselines by a large margin both in translation quality and hallucination reduction.            %   We described MTLB-STRUCT, a semi-supervised system that is based on pre-trained BERT masked language modelling and that jointly learns VMWE tags and dependency parse trees. The system ranked first in the open track of the PARSEME shared task - edition 1.2 and shows the overall state-of-the-art performance for detecting unseen VMWEs.  In future, we plan to augment the dependency parsing architecture to train on dependency relation categories  as well as dependency arcs. We also plan to improve our system by making it more efficient in order to train the dependency parsing module on the extra available unannotated datasets.  
"," Neural sequence models can generate highly fluent sentences but recent studies have also shown that they are also prone to hallucinate additional content not supported by the input, which can cause a lack of trust in the model. To better assess the faithfulness of the machine outputs, we propose a new task to predict whether each token in the output sequence is hallucinated conditioned on the source input, and collect new manually annotated evaluation sets for this task. We also introduce a novel method for learning to model hallucination detection, based on pretrained language models fine tuned on synthetic data that includes automatically inserted hallucinations.   Experiments on machine translation and abstract text summarization demonstrate the effectiveness of our proposed approach -- we obtain an average F1 of around 60 across all the benchmark datasets. Furthermore, we demonstrate how to use the token-level hallucination labels to define a fine-grained loss over the target sequence in the low-resource machine translation and achieve significant improvements over strong baseline methods. We will release our annotated data and code to support future research.",320
"  With rise in social media and e-commerce websites, there is a huge interest in analyzing these networks for tasks like link prediction, recommendation, community detection, etc. Traditionally, this is done by learning finite-dimensional vector embeddings/representations  for nodes in these networks and then used it for downstream tasks. One of the challenges is that the quality of these learned representation decreases if the network has many missing links. This affects its performance in downstream tasks. This can be addressed by using attribute similarity of nodes as connected usually have similar attributes. For example, in citation networks, papers on related works will cite each other, and in social media, people with similar interest follow each other. In real-world graphs, nodes of these networks themselves contain rich textual information  as attributes. So, we need techniques which can exploit this textual information while learning node embeddings. The representation learning of textual networks deals with this problem.   \iffalse While networks are sources of relational information, in many practical scenarios, nodes of networks themselves contain rich information as attributes. When this data is in the form of text  these networks are referred to as textual networks, and representation learning of these networks has several applications in diverse fields from analyzing social media profiles to biomedical networks. One of the challenges in this problem is that the quality of these learned representation decreases if the network has many missing links. This can be addressed by using attribute similarity of nodes as connected usually have similar attributes. For example, in citation networks, papers on related works will cite each other, and in social media, people with similar interest follow each other. So, by exploiting this, one can predict the edges in the network.   The main aim of representation learning of network is to learn embeddings, which are finite-dimensional vector representations for nodes in the graph.   %Representation learning in networks uses the edge/link weights as labels in the objective function to learn embeddings. These are finite-dimensional vector representations for each node in the graph.  In this paper we study this problem for textual networks, where nodes of the networks are equipped with attributes or content in the form of textual information . These learned embeddings can then be used in problems like link prediction, community detection, social network analysis, and so on. One of the challenges in this problem is that the quality of these learned representation decreases if the network has many missing links. This can be addressed by using attribute similarity of nodes as connected usually have similar attributes. For example, in citation networks, papers on related works will cite each other, and in social media, people with similar interest follow each other. So, by exploiting this, one can predict the edges in the network. %For achieving this in representation learning of textual networks, we propose an adversarial framework using textual similarity for discriminator and structural similarity for generator.  \fi  Recent methods for representation learning of textual networks involves learning two embeddings, one for the structure information , and the other for the textual information . The embeddings are learned to be similar for nodes that are connected by an edge. The most challenging task is to learn the combined text and structure embeddings, all the previous approaches  use a joint learning framework by defining a loss function that models the inter-modal similarities between structure and textual information between nodes connected by an edge, in addition to the intra-modal similarities. For example, consider the nodes  and  with their embeddings   and . The similarity between embeddings  and  is used for modelling intra-model similarity in structure information, on the other hand the similarity between  and  is used for intra-model similarity in text information. For inter-model similarity, the similarity between  and  is used for modelling the similarity between structure and text, and vice versa. All these similarities are modelled using skip-gram loss function .   The main disadvantage of these models is that they dependent on edge labels for embedding learning. This will make them unable to learn embeddings of nodes which are not present during the training stage. The only way they can be modelled to learn unseen nodes embeddings is by a mapper function between textual information and structure embeddings on seen nodes and apply it to unseen nodes for getting structure embeddings. This can result in a poor performance in downstream tasks involving unseen nodes as the mapping function cannot fully capture the structural information in the nodes. Recenlty, this issue has been addressed by using variational autoencoder framework on the structure and text embeddings. Although it has achieved better performance than the mapper function-based models, the disadvantage of autoencoder framework is that it limits the information learned in the structure embeddings as it is used for predicting the text features by the decoder.  In this paper, we propose an adversarial model where the generator learns the structure embeddings and between text embedding based discriminator and structure embeddings based generator.  For generator, we use the supervision from edge-connectivity and text embedding similarity to learn the structure embeddings. For discriminator model, text embeddings are made dissimilar for node pair generated by the generator and similar for the node pairs from the graph. This training will make the text similarity from the discriminator to approximate the actual similarity in the network. Through this framework we establish that this model efficiently amalgamate or fuse information from both text and graph as both text and structure embeddings use information from both modality for learning. In addition to this, our proposed adversarial approach can be extended for embedding learning of unseen nodes in the training dataset. This is achieved by directly using discriminator based text-similarity as supervision in a post-training stage. This will help in efficiently learning unseen structure embeddings as it does not restrict the embedding learning by using it to predict the text features like in VHE .  The performance of the model depends upon how well we can exploit the unstructured textual information, so we need a powerful discriminator. To achieve this, we use context-aware embeddings, where a node has different text embedding for each of its edges. We address this problem by proposing a novel technique by combining two context-aware attention mechanism. The first is based on mutual attention  between word embeddings in text across a pair of nodes.  The other is a topological attention mechanism. This uses structure embeddings of a node pairs to attend over text to learn a topology-aware text embedding. It can reduce the adverse effects of trying to make text embeddings similar where the textual information of connected nodes need not match. Because, this model has better representation capacity as it learns similarity through topological and mutual attention.    The following are the main contributions of this paper.  An adversarial technique for attributed network representation learning. Here, in addition to the supervision from training data, a discriminator using text embeddings is used to give supervision to structure embeddings.  A novel text embedding learning technique which uses both mutual and topological attention.  Extensive comparative study on downstream tasks of link prediction and node classification.  Experiments on link prediction on unseen nodes.    \iffalse We have evaluated our proposed method on three datasets Cora, Zhihu, and Hepth for link prediction. We observed that our model performs better than state-of-the-art methods in almost all settings in all three datasets. The performance of our model is especially high in low data regime. In Zhihu dataset, our model show a performance improvement of  over the previous state-of-the-art in the lowest supervision setting. A similar observation was made on the node classification task on Cora dataset, where our adversarial technique achieve state-of-the-art performance. As we mentioned earlier, the main advantage of this model is its ability to the care of representation learning in unseen nodes. We evaluated the quality of these embeddings in link prediction task for edges involving unseen nodes, and ACNE achieves state-of-the-art performance for all settings in all three datasets. On Zhihu dataset, it gave an impressive improvement of   improvement over previous methods in the low-data regime.  \fi  \iffalse  \fi  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   In this work, we proposed a new evaluation task for hallucination detection in conditional sequence generation and created human-annotated benchmark datasets. We also proposed a novel and general-purpose method to learn this task, and showed that the models can be used to define fine grained losses that improve low resource models for machine translation. In the future, we hope to create a large-scale pretrained evaluation model for any datasets or models to be evaluated, and also would extend our method to data-to-text generation scenarios.   We are also interested in investigating how to leverage our detection methods to mitigate hallucination problems in conditional sequence generation.   
"," \label{section:abstract}  Representation learning of textual networks poses a significant challenge as it involves capturing amalgamated information from two modalities:  underlying network structure, and  node textual attributes. For this, most existing approaches learn embeddings of text and network structure by enforcing embeddings of connected nodes to be similar. Then for achieving a modality fusion they use the similarities between text embedding of a node with the structure embedding of its connected node and vice versa. %Then for achieving modality fusion they model intra-modal similarities involving networks structure and textual attributes of  nodes in an edge.  This implies that these approaches require edge information for learning embeddings and they cannot learn embeddings of unseen nodes. In this paper we propose an approach that achieves both modality fusion and the capability to learn embeddings of unseen nodes. The main feature of our model is that it uses an adversarial mechanism between text embedding based discriminator, and structure embedding based generator to learn efficient representations. Then for learning embeddings of unseen nodes, we use the supervision provided by the text embedding based discriminator. In addition this, we propose a novel architecture for learning text embedding that can combine both mutual attention and topological attention mechanism, which give more flexible text embeddings. Through extensive experiments on real-world datasets, we demonstrate that our model makes substantial gains over several state-of-the-art benchmarks. In comparison with previous state-of-the-art, it gives up to 7\% improvement in performance in predicting links among nodes seen in the training and up to 12\% improvement in performance in predicting links involving nodes not seen in training. Further, in the node classification task, it gives up to 2\% improvement in performance.",321
"  Streaming Automatic Speech Recognition  researches have made their way into our everyday products. Smart speakers can now transcribe utterances in a streaming fashion, allowing users and downstream applications to see instant output in terms of partial transcriptions. There is a growing interest in the community to develop end-to-end  streaming ASR models, because they can transcribe accurately and run compactly on edge devices. Amongst these streaming E2E models, Recurrent Neural Network Transducer  is a candidate for many applications. RNN-T is trained with a loss function that does not enforce on the temporal alignment of the training transcripts and audio. As a result, RNN-T suffers from token emission delays - time from when the token is spoken to when the transcript of the token is emitted. Delayed emissions of tokens adversely affects user experiences and downstream applications such as the end-pointer.   Some existing work tried to mitigate the token emission delays in streaming RNN-Ts. We introduce them in Section. Other works utilized semi-streaming or non-streaming models to predict better token emission time, at the cost of the overall latency of the transcripts. In this work, we propose a novel loss function for streaming RNN-T, and the resultant trained model is called Alignment Restricted RNN-T . It utilizes audio-text alignment information to guide the loss computation. In Section, we show that theoretically, Ar-RNN-T loss function is faster to compute and results in better audio-token alignment. In Section, we empirically compare our proposed method with existing works such as monotonic RNN-T training on two data set: LibriSpeech and voice command. In the results section, Section, we show improvement in training speed and that when used in tandem with an end-pointer, Ar-RNN-T provides an unprecedentedly refined control over the latency-WER trade-offs of RNN-T models.          include your own bib file like this: 
"," There is a growing interest in the speech community in developing Recurrent Neural Network Transducer  models for automatic speech recognition  applications. RNN-T is trained with a loss function that does not enforce temporal alignment of the training transcripts and audio. As a result, RNN-T models built with uni-directional long short term memory  encoders tend to wait for longer spans of input audio, before streaming already decoded ASR tokens. In this work, we propose a modification to the RNN-T loss function and develop Alignment Restricted RNN-T  models, which utilize audio-text alignment information to guide the loss computation. We compare the proposed method with existing works, such as monotonic RNN-T, on LibriSpeech and in-house datasets. We show that the Ar-RNN-T loss provides a refined control to navigate the trade-offs between the token emission delays and the Word Error Rate . The Ar-RNN-T models also improve downstream applications such as the ASR End-pointing by guaranteeing token emissions within any given range of latency. Moreover, the Ar-RNN-T loss allows for bigger batch sizes and 4 times higher throughput for our LSTM model architecture, enabling faster training and convergence on GPUs.",322
"  .     %      % % final paper: en-us version      %       % space normally used by the marker     This work is licensed under a Creative Commons      Attribution 4.0 International License.     License details:     \url{http://creativecommons.org/licenses/by/4.0/}. }        In this work, we present a detailed analysis of RNN-T model's token emission delays and its impact on the downstream applications. We propose a modification to the RNN-T loss that uses alignment information to restrict the paths being optimized during training. We call our solution Alignment Restricted RNN-T and show that we can control the token delays for RNN-T models systematically using tunable parameters during training, while also significantly improving training throughput. Using our proposed solution, we show that we can improve the accuracy of downstream applications such as the ASR end-pointing system and significantly reduce latency and early cut-offs.    For alignments, we found splitting the word time-steps equally among sub-words worked best, however bootstrapping a hybrid model using target word-piece dictionary can potentially give better alignments and lead to improved accuracy with Ar-RNN-T, which may be explored in future.     References should be produced using the bibtex program from suitable   BiBTeX files . The IEEEbib.bst bibliography   style file from IEEE produces unsorted bibliography list.   ------------------------------------------------------------------------- 
","   Interpretability and explainability of deep neural networks are challenging due to their scale, complexity, and the agreeable notions on which the explaining process rests. Previous work, in particular, has focused on representing internal components of neural networks through human-friendly visuals and concepts. On the other hand, in real life, when making a decision, human tends to rely on similar situations and/or associations in the past. Hence arguably, a promising approach to make the model transparent is to design it in a way such that the model explicitly connects the current sample with the seen ones, and bases its decision on these samples.   Grounded on that principle, we propose in this paper an explainable, evidence-based memory network architecture, which learns to summarize the dataset and extract supporting evidences to make its decision. Our model achieves state-of-the-art performance on two popular question answering datasets . Via further analysis, we show that this model can reliably trace the errors it has made in the validation step to the training instances that might have caused these errors. We believe that this error-tracing capability provides significant benefit in improving dataset quality in many applications.",323
" .     %       % final paper: en-us version         % space normally used by the marker      This work is licensed under a Creative Commons       Attribution 4.0 International License.      License details:      \url{http://creativecommons.org/licenses/by/4.0/}. } Discourse parsing is an important upstream task within the area of Natural Language Processing   which has been an active field of research over the last decades. In this work, we focus on discourse representations for the English language, where most research %on the discourse analysis of English language  has been surrounding one of the two main theories behind discourse, the Rhetorical Structure Theory  proposed by  or interpreting discourse according to PDTB . While both theories have their strengths, the application of the RST theory, encoding documents into complete constituency discourse trees , has been shown to have many crucial implications on real world problems. A tree is defined on a set of EDUs , approximately aligning with clause-like sentence fragments, acting as the leaves of the tree. Adjacent EDUs or sub-trees are hierarchically aggregated to form larger  constituents, with internal nodes containing  a nuclearity label, defining the importance of the subtree  in the local context and  a relation label, defining the type of semantic connection between the two subtrees . In this work, we focus on structure and nuclearity prediction, not taking relations into account. Previous research has shown that the use of RST-style discourse parsing as a system component can enhance important tasks, such as sentiment analysis, summarization and text categorization . More recently, it has also been suggested that discourse structures obtained in an RST-style manner can further be complementary to learned contextual embeddings, like the popular  BERT approach . Combining both approaches has shown to support tasks where linguistic information on complete documents is critical, such as argumentation analysis .  Even though discourse parsers appear to enhance the performance on a variety of tasks, the full potential of using more linguistically inspired approaches for downstream applications has not been unleashed yet. The main open challenges of integrating discourse into more NLP downstream tasks and to deliver even greater benefits have been a combination of  discourse parsing being a difficult task itself, with an inherently high degree of ambiguity and uncertainty and  the lack of large-scale annotated datasets, rendering the initial problem more severe, as data-driven approaches cannot be applied to their full potential.  The combination of these two limitations has been one of the main reasons for the limited application of neural discourse parsing for more diverse downstream tasks. While there have been neural discourse parsers proposed , they still cannot consistently %strongly  outperform traditional approaches when applied to the RST-DT dataset, where the amount of training data is arguably insufficient for such data-intensive approaches.  %due to the extra effort to integrate discourse trees into models as well as two major problems, the big breakthrough in the usage of discourse parsing has still not happened.   In this work, we alleviate the restrictions to the effective and efficient use of discourse as mentioned above by introducing a novel approach combining a newly proposed large-scale discourse treebank with our data-driven neural discourse parsing strategy. More specifically, we employ the novel MEGA-DT ``silver-standard"" discourse treebank published by  containing over 250,000 discourse annotated documents from the Yelp'13 sentiment dataset , nearly three orders of magnitude larger than commonly used RST-style annotated discourse treebanks . Given this new dataset with a previously unseen number of full RST-style discourse trees, we revisit the task of neural discourse parsing, which has been previously attempted by   and others with rather limited success. We believe that one reason why previous neural models could not yet consistently outperform more traditional approaches, heavily relying on feature engineering , is the lack of generalisation when using deep learning approaches on the small RST-DT dataset, containing only 385 discourse annotated documents. This makes us believe that using a more advanced neural discourse parser in combination with a large training dataset can lead to significant performance gains. %, but also across datasets, capturing more general discourse phenomena and avoiding potential overfitting on the training corpus. Admittedly, even though MEGA-DT contains a huge number of datapoints to train on, it has been automatically annotated, potentially introducing noise and biases, which can negatively influence the performance of our newly proposed neural discourse parser when solely trained on this dataset. A natural and intuitive approach to make use of the neural discourse parser and both datasets  is to combine them during training, pretraining on the large-scale ``silver-standard"" corpus and subsequently fine-tuning on RST-DT or further human annotated datasets. This way, general discourse structures could be learned from the large-scale treebank and then enhanced with human-annotated trees. With the results shown in this paper strongly suggesting that our new discourse parser can encode discourse more effectively, we hope that our efforts will prompt researchers to develop more linguistically inspired applications based on our discourse parser. % for downstream models in the area of NLP.  Our contributions in this paper are: % %on how to train a neural discourse parser with large scale ``silver-standard"" discourse trees. With this new approach, we  drastically increase the amount of available training data available for discourse parsers is not sufficiently large to train modern, data-driven deep learning approaches for the task, hindering the application of new methodologies and  the shift in domain between the discourse parsers training data and the domain of application deminishes the applicability and performance of generated discourse trees for any domain outside of news , instructions  and a few other domains.   URL segmentation has applications in TTS and web search. Our contributions include a curated URL data set and a highly accurate RNN model boosted by pre-training on Knowledge Graph entities.   We plan on releasing a version of the dataset before the conference.    \paragraph{\LaTeX-specific details:}   For an anonymized submission, ensure that {\small\verb|\aclfinalcopy|} at the top of this document is commented out, and that you have filled in the paper ID number  where {\small\verb|***|} appears in the {\small\verb|\def\aclpaperid{***}|} definition at the top of this document.   For a camera-ready submission, ensure that {\small\verb|\aclfinalcopy|} at the top of this document is not commented out.   
"," RST-based discourse parsing is an important NLP task with numerous downstream applications, such as summarization, machine translation and opinion mining. In this paper, we demonstrate a simple, yet highly accurate discourse parser, incorporating recent contextual language models. Our parser establishes the new state-of-the-art  performance for predicting structure and nuclearity on two key RST datasets, RST-DT and Instr-DT. We further demonstrate that pretraining our parser on the recently available large-scale ``silver-standard"" discourse treebank MEGA-DT provides even larger performance benefits, suggesting a novel and promising research direction in the field of discourse analysis.",324
"  The last several years have seen a land rush in research on machine reading  comprehension and various dataset have been proposed such as SQuAD1.1, SQuAD2.0, NewsQA and CoQA . Different from the above which are extractive MRC, RACE is a multi-choice MRC dataset  proposed by . RACE was extracted from middle and high school English examinations in China. Figure 1 shows an example passage and two related questions from RACE. The key difference between RACE and previously released machine comprehension datasets is that the answers in RACE often cannot be directly extracted from the passages, as illustrated by the two example questions  in Table . Thus, answering these questions needs inferences.     \end{center}       \end{table}  %   Recently, pretrained language models  such as BERT , RoBERTa , ALBERT  have achieved great success on MMRC tasks. Notably, Megatron-LM  which is a 48 layer BERT with 3.9 billion parameters yields the highest score on the RACE leaderboard in both single and ensemble settings. The key point to model MMRC is: first encode the context, question, options with BERT like LM, then add a matching network on top of BERT to score the options. Generally, the matching network can be various .  proposes an option comparison network  to compare options at word-level to better identify their correlations to help reasoning.  proposes a dual co-matching network  which models the relationship among passage, question and answer options bidirectionally. All these matching networks show promising improvements compared with pretrained language models. One point they have in common is that the answer together with the distractors are jointly considered which we name multi-choice models. We argue that the options can be concerned separately for two reasons, 1) when human works on MMRC problem, they always consider the options one by one and select the one with the highest confidence. 2) MMRC suffers from the data scarcity problem. Multi-choice models are inconvenient to take advantage of other MRC dataset.   In this paper, we propose a single-choice model for MMRC. Our model considers the options separately. The key component of our method is a binary classification network on top of pretrained language models. For each option of a given context and question, we calculate a confidence score. Then we select the one with the highest score as the final answer. In both training and decoding, the right answer and the distractors are modeled independently. Our proposed method gets rid of the multi-choice framework, and can leverage amount of other resources. Taking SQuAD as an example, we can take a context, one of its question and the corresponding answer as a positive instance for our classification with golden label 1. In this way many QA dataset can be used to enhance RACE. Experimental results show that single-choice model performs better than multi-choice models, in addition by transferring knowledge from other QA dataset, our single model achieves 90.7\% and ensemble model achieves 91.4\%, both are the best score on the leaderboard.        In this work, we proposed a rather simple, yet highly effective discourse parser, utilizing recent neural BERT-based language models in combination with structural features. The integration of those input-features within a standard shift-reduce framework as well as an unprecedented use of recent large-scale ``silver-standard"" discourse parsing datasets for pretraining reaches a new state-of-the-art performance on both, the RST-DT and Instr-DT treebanks. We show that our new, neural discourse parser already achieves better or similar performance when trained and evaluated on the RST-DT and Instr-DT datasets, however, the consistent and significant SOTA result is reached when incorporating pretraining on the MEGA-DT corpus.  This refutes the previous findings of , stating that neural techniques such as word embeddings provide little to no gains for this task.  We further demonstrated the gains achieved by  The presented pretraining  even on the small subset of approach on the silver-standard MEGA-DT dataset  , which  also further validates the usefulness of additional supervision for this task and calls for more work in that area.   
"," Multi-choice Machine Reading Comprehension  aims to select the correct answer from a set of options based on a given passage and question. Due to task specific of MMRC, it is non-trivial to transfer knowledge from other MRC tasks such as SQuAD, Dream. In this paper, we simply reconstruct multi-choice to single-choice by training a binary classification to distinguish whether a certain answer is correct. Then select the option with the highest confidence score. We construct our model upon ALBERT-xxlarge model and estimate it on the RACE dataset. During training, We adopt AutoML strategy to tune better parameters. Experimental results show that the single-choice is better than multi-choice. In addition, by transferring knowledge from other kinds of MRC tasks, our model achieves a new state-of-the-art results in both single and ensemble settings.",325
"  % Images  are another important approach for expressing feelings and emotions in addition to using text in communication. In mobile messaging apps, these images can generally be classified into emojis and stickers. Emoji is a kind of small picture which is already stored in most of the keyboard of the mobile operational systems, \ie iOS or Android. Emojis are pre-designed by the mobile phone vendor  and the number of emoji is limited, and users can not design emoji by themselves. Different with the inflexible emojis, sticker is image or graphicon essentially, which users can draw or modify images as a sticker and upload to the chatting app by themselves. The using of stickers on online chatting usually brings diversity of expressing emotion. Since emojis are sometimes used to help reinforce simple emotions in a text message due to their small size, and their variety is limited. Stickers, on the other hand, can be regarded as an alternative for text messages, which usually include cartoon characters and are of high definition. They can express much more complex and vivid emotion than emojis. Most messaging apps, such as WeChat, Telegram, WhatsApp, and Slack provide convenient ways for users to download stickers for free, or even share self-designed ones. We show a chat window including stickers in Figure.     % Stickers are becoming more and more popular in online chat. First, sending a sticker with a single click is much more convenient than typing text on the 26-letter keyboard of a small mobile phone screen. Second, there are many implicit or strong emotions that are difficult to express in words but can be captured by stickers with vivid facial expressions and body language. However, the large scale use of stickers means that it is not always straightforward to think of the sticker that best expresses one's feeling according to the current chatting context. Users need to recall all the stickers they have collected and selected the appropriate one, which is both difficult and time-consuming.  % Consequently, much research has focused on recommending appropriate emojis to users according to the chatting context. Existing works such as, are mostly based on emoji recommendation, where they predict the probable emoji given the contextual information from multi-turn dialog systems. In contrast, other works recommend emojis based on the text and images posted by a user. As for sticker recommendation, existing works such as and apps like Hike or QQ directly match the text typed by the user to the short text tag assigned to each sticker. However, since there are lots of ways of expressing the same emotion, it is very hard to capture all variants of an utterance as tags.  % To overcome the drawbacks, we propose a sticker response selector  for sticker selection in our early work, where we address the task of sticker response selection in multi-turn dialog. We focus on the two main challenges in this work:  Since existing image recognition methods are mostly built with real-world images, and how to capture the semantic meaning of sticker is challenging.  Understanding multi-turn dialog history information is crucial for sticker recommendation, and jointly modeling the candidate sticker with multi-turn dialog is challenging. % % % % % % Herein, we propose a novel sticker recommendation model, namely sticker response selector , for sticker response selection in multi-turn dialog. Specifically, SRS first learns representations of dialog context history using a self-attention mechanism and learns the sticker representation by a convolutional neural network .  % % % Next, SRS conducts deep matching between the sticker and each utterance and produces the interaction results for every utterance. % % Finally, SRS employs a fusion network which consists of a sub-network fusion RNN and fusion transformer to learn the short and long term dependency of the utterance interaction results. The final matching score is calculated by an interaction function. To evaluate the performance of our model, we propose a large number of multi-turn dialog dataset associated with stickers from one of the popular messaging apps.  Extensive experiments conducted on this dataset show that SRS significantly outperforms the state-of-the-art baseline methods in commonly-used metrics.  % However, the user's sticker selection does not only depend on the matching degree between dialog context and candidate sticker image, but also depends on the user's preference of using sticker. When users decide to use a sticker as their response in multi-turn dialog, they may choose their favorite one from all appropriate stickers as the final response.  % % % We assume that user tends to use the recently used sticker in their dialog history, and the recently-used-sticker can represent the user's preference of sticker selection. An example is shown in Figure. To verify this assumption, we retrieve 10 recently-used-stickers of each user and calculate the proportion of whether the currently used sticker appeared in these 10 stickers. The result shows that 54.09\% of the stickers exist in the 10 recently used sticker set. Hence, we reach to the conclusion that users have strong personal preference when selecting the sticker as their response for the current dialog context. However, in some cases, this also indicates a tendency to re-use stickers, but not necessarily a preference.  % Motivated by this observation, in this work, we take one step further and improve our previously proposed SRS framework with user preference modeling. Overall, we propose a novel sticker recommendation model which considers the user preference, namely Preference Enhanced Sticker Response Selector . Specifically, PESRS first employs a convolutional network to extract features from the candidate stickers. Then, we retrieve the recent user sticker selections then a user preference modeling module is employed to obtain a user preference representation. Next, we conduct the deep matching between the candidate sticker and each utterance as the same as SRS. Finally, we use a gated fusion method to combine the deep matching result and user preference into final sticker prediction.    % The key to the success of PESRS lies in how to design the user preference modeling module, which should not only identify the user's favorite sticker and but also consider the current dialog context. % Motivated by this, we first propose a recurrent neural network  based position-aware sticker modeling module which encodes the recently used stickers in chronological order. Then, we employ a key-value memory network to store these sticker representations as values and the corresponding dialog context as keys. Finally, we use the current dialog context to query the key-value memory and obtain the dynamic user preference of the current dialog context.  % We empirically compare PESRS and SRS on the public dataset\footnote{https://github.com/gsh199449/stickerchat} proposed by our early work. This is a large-scale real-world Chinese multi-turn dialog dataset, which dialog context is multiple text utterances and the response is a sticker image. Experimental results show that on this dataset, our newly proposed PESRS model can significantly outperform the existing methods.  Particularly, PESRS yields 4.8\% and 7.1\% percentage point improvement in terms of  and  compared with our early work SRS. % In addition to the comprehensive evaluation, we also evaluate our proposed user preference memory by a fine-grained analysis. The analysis reveals how the model leverages the user's recent sticker selection history and provides us insights on why they can achieve big improvement over state-of-the-art methods.  This work is a substantial extension of our previous work reported at WWW 2020.  The extension in this article includes the user preference modeling framework for the existing methods, a proposal of a new framework for sticker selection in the multi-turn dialog. Specifically, the contributions of this work include the following:    The rest of the paper is organized as follows: We summarize related work in \S.  \S introduces the data collection method and some statistics of our proposed multi-turn dialog sticker selection dataset. We then formulate our research problem in \S  and elaborate our approach in \S.  \S gives the details of our experimental setup and \S presents the experimental results.  Finally, \S concludes the paper.   %   In this paper, we propose a single-choice model for MMRC that consider the options separately. Experiments results demonstrate that our method achieves significantly improvements and by taking advantage of other MRC datasets, we achieve a new state-of-the-art performance. We plan to consider the difference between two methods and if we can combine them together in future study.            File emnlp2019.tex      Based on the style files for ACL 2019, which were    Based on the style files for EMNLP 2018, which were    Based on the style files for ACL 2018, which were    Based on the style files for ACL-2015, with some improvements     taken from the NAACL-2016 style    Based on the style files for ACL-2014, which were, in turn,    based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,    EACL-2009, IJCNLP-2008...    Based on the style files for EACL 2006 by    e.agirre@ehu.es or Sergi.Balari@uab.es    and that of ACL 08 by Joakim Nivre and Noah Smith  \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{emnlp-ijcnlp-2019} \usepackage{latexsym} \usepackage{times} \usepackage{soul} \usepackage{url} \usepackage[utf8]{inputenc} \usepackage[small]{caption} \usepackage{graphicx} \usepackage{subfigure} \usepackage{amsmath} \usepackage{booktabs} \usepackage{natbib} \usepackage{xcolor} \urlstyle{same} \usepackage{fancyhdr,graphicx,amssymb} \usepackage[ruled,vlined]{algorithm2e} \usepackage{multirow} \usepackage{url}  \usepackage{tikz} \usepackage{subfigure} \usepackage{xcolor} \usepackage{tcolorbox}  \usepackage{helvet}   Required \usepackage{courier}   Required  \newcommand\BibTeX{B{\sc ib}\TeX} \newcommand\confname{EMNLP-IJCNLP 2019} \newcommand\conforg{SIGDAT}  \title{Multi-choice Machine Reading Comprehension with Two-stage Training}  \author{First Author \\   Affiliation / Address line 1 \\   Affiliation / Address line 2 \\   Affiliation / Address line 3 \\   email@domain \\\And   Second Author \\   Affiliation / Address line 1 \\   Affiliation / Address line 2 \\   Affiliation / Address line 3 \\   email@domain \\}  \date{}    
","   Stickers with vivid and engaging expressions are becoming increasingly popular in online messaging apps, and some works are dedicated to automatically select sticker response by matching the stickers image with previous utterances.   However, existing methods usually focus on measuring the matching degree between the dialog context and sticker image, which ignores the user preference of using stickers.   Hence, in this paper, we propose to recommend an appropriate sticker to user based on multi-turn dialog context and sticker using history of user.   Two main challenges are confronted in this task.   One is to model the sticker preference of user based on the previous sticker selection history.   Another challenge is to jointly fuse the user preference and the matching between dialog context and candidate sticker into final prediction making.   To tackle these challenges, we propose a Preference Enhanced Sticker Response Selector  model.   Specifically, PESRS first employs a convolutional based sticker image encoder and a self-attention based multi-turn dialog encoder to obtain the representation of stickers and utterances.   Next, deep interaction network is proposed to conduct deep matching between the sticker and each utterance.   Then, we model the user preference by using the recently selected stickers as input, and use a key-value memory network to store the preference representation.   PESRS then learns the short-term and long-term dependency between all interaction results by a fusion network, and dynamically fuse the user preference representation into the final sticker selection prediction.   Extensive experiments conducted on a large-scale real-world dialog dataset show that our model achieves the state-of-the-art performance for all commonly-used metrics.   Experiments also verify the effectiveness of each component of PESRS.   %",326
"  .}  Neural machine translation  has boosted machine translation significantly in recent years . However, it is still unclear how NMT models work due to the black-box nature of neural networks. Better understandings of NMT models could guide us in improving NMT systems. Currently most of the studies towards understanding NMT models only take into account subword-based  models.  Deeper character-based  models have been shown to perform better than BPE-based models . In this paper, we try to investigate the working mechanism of CHAR models. We explore the ability of CHAR models to learn word senses and morphological inflections and the attention mechanism.   Previous studies have tried to interpret and understand NMT models by interpreting attention weights , using gradients , applying layer-wise relevance propagation , probing classification tasks , and more intrinsic analysis .  However, only  have probed character-based representations.  have only explored character-aware word-level representations, while we investigate fully character-level representations, which are also studied in . We apply more composition methods to explore how CHAR models learn linguistic knowledge and how attention extracts features directly from characters.   Probing classification tasks  have emerged as a popular method to interpret the internal representations from neural networks. Given a probing classifier, the input is usually the representation of a word and the output is the corresponding linguistic tag.  CHAR models pose new challenges for interpretability, and we investigate whether we can probe CHAR models in a way similar to word-based models. In addition, can we extract word sense and morphological information about the full word from individual hidden states, or is this information distributed across multiple states? This has implications for interpreting neural CHAR models, but can also inform novel architectures, such as sparse attention mechanisms.  Thus we first investigate the ability of CHAR models to learn word senses and morphology in Section .  We apply different methods to compose information from characters and demonstrate that the word-level information is distributed over all the characters but characters at different positions play different roles in learning linguistic knowledge.  We also explore the effect of encoder depth to answer why CHAR models outperform BPE-based models only when they have the settings with deeper encoder. The probing results show that CHAR models need more layers to learn word senses.  Then in Section , we move on to explore the attention mechanism. The distribution pattern shows that separators attract much more attention compared to other characters.  To study the effect of enforcing characters to capture the full word-level information, we investigate a sparse attention mechanism, i.e. a model that only attends to separators, which can be viewed as a word-level attention. The BLEU score drops 1.2 points when we apply the word-level sparse attention. This implies that only attending to separators by a single attention head is workable but not enough to extract all the necessary information.   The main findings are summarized as follows:        In our previous work, we propose the task of multi-turn sticker response selection, which recommends an appropriate sticker based on multi-turn dialog context history without relying on external knowledge. However, this method only focuses on measuring the matching degree between the dialog context and sticker image, which ignores the user preference of using stickers. Hence, in this paper, we propose the Preference Enhanced Sticker Response Selector  to recommend an appropriate sticker to user based on multi-turn dialog context and sticker using history of user. Specifically, PESRS first learns the representation of each utterance using a self-attention mechanism, and learns sticker representation by CNN. Second, a deep interaction network is employed to fully model the dependency between the sticker and utterances. The deep interaction network consists of a co-attention matrix that calculates the attention between each word in an utterance and each unit in a sticker representation. Third, a bi-directional attention is used to obtain utterance-aware sticker representation and sticker-aware utterance representations. Next, we retrieve the recent user sticker selections, and then propose a user preference modeling module which consists a position-aware history encoding network and a key-value based memory network to generate the user preference representation dynamically according to current dialog context. Then, a fusion network models the short-term and long-term relationship between interaction results, and a gated fusion layer is applied to fuse the current dialog interaction results and user preference representation dynamically. Finally, a fully-connected layer is applied to obtain the final sticker prediction using the output of gated fusion layer. Our model outperforms state-of-the-art methods including our previous method SRS in all metrics and the experimental results also demonstrate the effectiveness of each module in our model. In the near future, we aim to propose a personalized sticker response selection system.  
"," Recent work has shown that deeper character-based neural machine translation  models can outperform subword-based models. However, it is still unclear what makes deeper character-based models successful. In this paper, we conduct an investigation into pure character-based models in the case of translating Finnish into English, including exploring the ability to learn word senses and morphological inflections and the attention mechanism. We demonstrate that word-level information is distributed over the entire character sequence rather than over a single character, and characters at different positions play different roles in learning linguistic knowledge. In addition, character-based models need more layers to encode word senses which explains why only deeper models outperform subword-based models. The attention distribution pattern shows that separators attract a lot of attention and we explore a sparse word-level attention to enforce character hidden states to capture the full word-level information. Experimental results show that the word-level attention with a single head results in 1.2 BLEU points drop.",327
"  A prerequisite relation is a pedagogical relation that indicates the order in which concepts can be presented to learners. The relation can be used to guide the presentation sequence of topics and subjects during the design of academic programs, lectures, and curricula or instructional materials. %such as textbooks and study guides.   In this work, we present our systems to automatically detect prerequisite relations for Italian language in the context of the PRELEARN shared task  at EVALITA  2020 . %.  The evaluation of submissions considers:  in-domain and cross-domain scenarios defined by either the inclusion  or exclusion  of the target domain in the training set. The four domains are 'data mining' , 'geometry' , 'precalculus' , and 'physics' .  the type of resources  used to train the model -- raw text VS. structured information.  % four domains, namely 'data mining', 'geometry', 'precalculus' and 'physics'.    % PRELEARN participants had to submit their systems in a per-domain evaluation, considering in-domain and cross-domain scenarios,  % as well as discriminate between the kind of resources the models used, namely raw text such as distributional textual corpora, and structured information such as knowledge bases. % Additionally, the difference between in-domain and cross-domain lies in the inclusion or exclusion of the target domain in the training set.  The combination of these settings defined the four PRELEARN subtasks.  Formally, a prerequisite relation exists between two concepts if one has to be known beforehand in order to understand the other.  For the PRELEARN task, given a pair of concepts, the relation exists only if the latter concept is a prerequisite for the former.  Therefore, the task is a binary classification task.          We approach the problem from two perspectives: handcrafted features based on lexical complexity and pre-trained embeddings. We employed static embeddings from Wikipedia and Wikidata, and contextual embeddings from Italian-BERT model.     CHAR models have been shown to perform better than BPE-based models in NMT yet they pose new challenges for interpretability. In this paper, we investigate CHAR models via the WSD and six morphological probing tasks to learn how CHAR models learn word senses and morphology, in the case of translating Finnish into English. We also explore the attention distribution pattern and a sparse word-level attention to learn the working mechanism of attention.   In the probing tasks, we find that separators also have captured some linguistic knowledge.  We apply different composition methods to the characters of a word, and we demonstrate that the word sense and morphological information is distributed over all the characters rather than some specific characters. Moreover, characters at different positions play different roles in learning linguistic knowledge.  CHAR models are better at learning morphology but we need a more complicated composition method, such as a randomly initialized LSTM, to extract all the encoded information.  These results on probing tasks show that we can extract word sense information and morphological features from character-level hidden states and that these features are encoded in different ways.  In addition, we explore the effect of encoder depth and show that CHAR models require more layers to encode word senses, which explains why only deeper CHAR models outperform BPE-based models.  The attention distribution shows that separators attract a lot of attention, and we show that the sparse word-level attention only attending to separators is workable but not enough for translation.   As we have shown that characters at different positions specialize in learning word senses and morphology, it will be interesting to explore sparse attention with multiple heads in the future which could learn to extract features from different aspects.   
",   English.   We present our systems and findings for the prerequisite relation learning task  at EVALITA 2020. The task aims to classify whether a pair of concepts hold a prerequisite relation or not. We model the problem using handcrafted features and embedding representations for in-domain and cross-domain scenarios.  Our submissions ranked first place in both scenarios with average F1 score of $0.887$ and $0.690$ respectively across domains on the test sets. We made our code freely available\footnote{\url{https://github.com/ajason08/EVALITA2020_PRELEARN}\label{code}}.,328
" Task-oriented dialog systems are commonplace in automated systems that interact with end users, including digital assistants, technical support agents, and various website navigation helpers. An essential part in any task-oriented dialog system is natural language generation , which consumes data, typically fed in the form of a dialog act, and converts it into natural language output to be served to the end user. The natural language response of the NLG component should 1) contain all essential information, 2) be contextualized around the user request, and 3) be natural sounding. Such a system requires consideration for content planning, correctness, grammaticality, and naturalness.  NLG systems employed in commercial settings are typically based on template-based text generation techniques . In these, humans author a minimal set of responses templates with placeholder slot values. These slots are later filled at runtime, with the dialog input. Although template-based NLG modules are appealing due to their deterministic nature,  inherent correctness, and low latency, they have major drawbacks: First, separate templates need to be authored for different response variations; this behavior is unfavorable for scaling. Second, templates authored for a particular domain are commonly not reusable.  Lastly, no matter the complexity of the language instilled into templates, they form a strictly discrete set of responses, and therefore are bound to be limited in their response naturalness.  More recently, advances in neural-network-based  language generation prompted a new direction in NLG research . The process is typically split into two steps:  serialization of input data into a flattened meaning representation , and  using the neural generation model to generate a natural language response conditioned on the MR. The models are trained on data that includes MR, response pairs, and therefore they are able to not only generate desired responses for MRs in their training data, but they are also expected to form coherent responses for novel MRs, owing to the generalization ability of their machine learning  backbone.  However, deploying neural NLG systems in an industry setting is quite challenging. First, it is not trivial to train a model that reliably presents its input data with the high fidelity required from a user-serving dialog system. Second, the models require much high-quality human-annotated data, which is resource intensive. Consequently, data annotation is a major limiting factor for scaling model-based NLG across domains and languages.  In this work, we detail our approach to production-level neural NLG, with a focus on scalability and data efficiency. Adopting the tree-structured MR framework introduced in Balakrishnan et al.~\shortcite{Balakrishnan2019constrainednlg}, which allows better control over generated responses, we train sequence-to-sequence RNN models  that can produce high-fidelity responses. We then employ a multitude of techniques for reducing the amount of  required data, primarily powered by eliminating the ``hidden'' redundancy by grouping data points with similar semantics into buckets. We train models either on the reduced data, or after increasing the size of the dataset using a novel synthetic augmentation technique. We also employ large, pre-trained attention-based language models, fine-tuning them on the same datasets, and then using novel methods to distill their knowledge into smaller sequence-to-sequence models. Further, we train models on data from multiple domains, showing gains over models trained on individual domains when the domains are semantically close together. We conclude with a compiled list of best practices for production-level NLG model development based on our analyses, and we present it as a runbook.    We tackle the task of prerequisite relation learning using a variety of systems that explore three set of features: handcrafted features based on complexity intuitions, embedding models from Wikipedia and Wikidata, and contextual embedding from Italian-BERT model. We examine the capabilities of our models in in-domain and cross-domain scenarios.    out of 4 domains, and for raw-text versus structured-information settings. Our models ranked first in all the subtask of the PRELEARN competition at EVALITA 2020. We found that although our Italian-BERT model outperformed the others, the simpler models show competitive results.    A limitation of our work is that we used all the possible domains in our experiments.  We plan to further examine the impact of using a combination of all possible domains as training set on the performance of our models. 
"," Natural language generation  is a critical component  in conversational systems, owing to its role of formulating a correct and natural text response. Traditionally, NLG components have been deployed using template-based solutions. Although neural network solutions recently developed in the research community have been shown to provide several benefits, deployment of such model-based solutions has been challenging due to high latency, correctness issues, and high data needs.  In this paper, we present approaches that have helped us deploy data-efficient neural solutions for NLG in conversational systems to production.  We describe a family of sampling and modeling techniques to attain production quality with light-weight neural network models using only a fraction of the data that would be necessary otherwise, and show a thorough comparison between each. Our results show that domain complexity dictates the appropriate approach to achieve high data efficiency. Finally, we distill the lessons from our experimental findings into a list of best practices for production-level NLG model development, and present them in a brief runbook. Importantly, the end products of all of the techniques are small sequence-to-sequence models  that we can reliably deploy in production.",329
" Definitions have a very important role in scientific literature because they define the major concepts with which an article operates. They are used in many automatic text analysis tasks, such as question answering, ontology matching and construction, formal concept analysis, and text summarization. Intuitively, definitions are basic building blocks of a scientific article that are used to help properly describe hypotheses, experiments, and analyses. It is often difficult to determine where a certain definition lies in the text because other sentences around it may have similar style.  Automatic definition extraction  is an important field in natural language processing  because it can be used to improve text analysis and search.  %Natasha: here adding formal definition of formal definitions Definitions play a key role in mathematics, but their creation and use differ from those of \enquote*{everyday language}  definitions. A comprehensive study is given in a series of works by Edwards and Ward~, , , %, and    inspired by writings of Richard Robinson~ and lexicographer Sidney Landau~. %They distinguish between extracted definitions that report usage and have a truth value~, and stipulated  that create usage and create concepts but have no truth value. % Nat - fixed sentence %Moreover, in a stipulated definition a term has to be free from all the associations it acquired in its non-technical use.   %For example, ""Suppose that student is a person enrolled into an academic institution"" is a stipulated definition while    Mathematical definitions frequently have a history as they evolve over time. The definition we use for function, for instance, may not be the one that was used a hundred years ago. % Nat - fixed sentence The concept of connectivity has two definitions, one for path connectivity and another for set-theoretic connectivity. In mathematical texts the meaning of the defined concept is not determined by its context but it is declared and is expected to have no variance within that specific mathematical text~. % Nat - updated here  Mathematical definitions have many features, some critical and some optional but accepted within the  mathematical community. % Nat - added this %Van Dormolen and Zaslavsky~  describe a good mathematical definition as containing criteria of hierarchy% , existence% , equivalence, and axiomatization. Desired but not necessary criteria of a definition are minimality, elegance, and degenerations.  We give here short definitions of these concepts; detailed explanations with examples can be found in .   % end of formal definition of formal definitions Not every definition appearing in text is mathematical in the above sense. For example, Wikipedia articles contain definitions of different style. We see below that the Wikipedia definition of the Kane \& Abel musical group %shown in Figure   is not similar in style to the Wikipedia definition of an Abelian group.  % %\end{figure} %  Current methods for automatic DE view it as a binary classification task,  where a sentence is classified as a definition or a non-definition. A supervised learning process is usually employed for this task,  employing feature engineering for sentence representation.  The absolute majority of current methods study generic definitions and not mathematical definitions .  In this paper we describe a supervised learning method for automatic DE from mathematical texts. Our method  applies a Convolutional Neural Network , a Long Short-Term Memory network , and their combinations to the raw text data and sentence syntax structure, in order to detect definitions. Our method is evaluated on three different corpora; two are well-known corpora for generic DE and one is a new annotated corpus of mathematical definitions, introduced in this paper.     The main contributions of this paper are  analysis and introduction of the new annotated dataset of mathematical definitions,  evaluation of the state-of-the-art DE approaches on the new mathematical dataset,  introduction and evaluation of upgraded sentence representations adapted to mathematical domain with an adaptation of deep neural networks to new sentence representations,  extensive experiments with multiple network and input configurations  performed on different datasets in mathematical and non-mathematical domains,  experiments with   cross-domain and multi-domain learning in a DE task, and  introduction of the new parsed but non-annotated dataset composed of Wiki articles on  near-mathematics topics, used in an additional--extrinsic--evaluation scenario. These all contribute to showing that using specifically suited training data along with adapting sentence representation and classification models to the task of mathematical DE significantly improves extraction of mathematical definitions from surrounding text.   The paper is organized as follows. Section  contains a survey of up-to-date related work. Section  describes the sentence representations and the structure of neural networks used in our approach. Section  provides the description of the datasets, evaluation results, and their analysis. Section  contains our conclusions. Finally, Appendix contains some supplementary  materials -- annotation instructions, description of the Wikipedia experiment, and figures.     We proposed to pre-train BERT with a hierarchical multitask learning approach. Our results on restricted data  show that this approach achieves better or equal performance. We incorporate sentence-level information to solve word-level tasks. This also shows a slight increment in performance. We propose an additional pre-training task, bigram shift, which causes embeddings to contain word order information.   We believe that implementing these techniques to large-scale training will further advance the state-of-the-art. Probing tasks show that different training techniques lead embeddings to contain different linguistic properties. This is an essential point since there are various problems in the NLP domain that require different needs. Therefore selecting an appropriate pre-training strategy is an important factor.  
"," Automatic definition extraction from texts is an important task that has numerous applications  in several natural language processing fields such as summarization, analysis of scientific texts, automatic taxonomy generation, ontology generation, concept identification, and question answering. For definitions that are contained within a single sentence, this problem can be viewed as a binary classification of sentences into definitions and non-definitions.  In this paper, we focus on automatic detection of one-sentence definitions in mathematical texts, which are difficult to separate from surrounding text.  We experiment with several data representations, which include sentence syntactic structure and word embeddings, and apply deep learning methods such as the  Convolutional Neural Network  and the Long Short-Term Memory network , in order to identify mathematical definitions.  Our experiments demonstrate the superiority of CNN and its combination with LSTM, when applied on the syntactically-enriched input representation.  % %We use data representation that includes sentence syntactic structure; to this we apply deep learning methods such as Convolutional Neural Network  and Recurrent Neural Network , in order to identify mathematical definitions.  We also present a new dataset for definition extraction from mathematical texts. %We demonstrate that the use of this dataset for training learning models improves the quality of definition extraction when these models are then used for other definition datasets.  We demonstrate that this dataset is beneficial for training supervised models aimed at extraction of mathematical definitions.  %Marina: added new sentence from the conclusions section Our experiments with different domains demonstrate that mathematical definitions require special treatment, and that using cross-domain learning is inefficient for that task.",330
"  Computer-assisted cross-lingual conversation by automatic speech-to-speech translation has been one of the most challenging problems in spoken language technologies in decades . Recent remarkable advances in speech and language processing led by deep learning techniques benefit this challenge by real-time and accurate speech translation. %\memo{}  gogole multi-task model One crucial problem in automatic speech-to-speech translation is its delay. Spoken language processing tasks are usually handled in the utterance or sentence level. Their application to the speech-to-speech translation suffers from a long delay that is proportional to the input length, because the process starts after the observation of the end of an utterance. That is similar to consecutive interpretation and is not useful for long monologues such as lecture talks. On the other hand, in such situations, simultaneous interpretation is often used for an audience not proficient in the language of a talk. Simultaneous interpretation is a challenging task to listen to the talk and speak its interpretation in a different language.  In this work, we tackle the problem of automatic simultaneous speech-to-speech translation and develop a neural system to do that from English to Japanese. Here, we call our task simultaneous translation, not simultaneous interpretation. We think the task of simultaneous interpretation includes some additional efforts for summarization to make the output concise for small latency and better understanding for the audience. The problem requires real-time and incremental processing for the output generated simultaneously with the input. Previous attempts to incremental neural speech translation focused on speech-to-text translation . Our work aims to speech-to-speech translation for natural information delivery by speech without a need for visual attention on text-based subtitles. Our system is based on the cascade of three processing modules: incremental speech recognition , incremental machine translation , and text-to-speech synthesis , rather than recent end-to-end approaches %\memo{} due to the difficulty of applying them to the simultaneous translation.  We follow existing studies on incremental neural speech processing. For ASR, we choose an approach using a teacher-student training framework to train an incremental student model with the help of a non-incremental teacher model . For MT, we choose an approach called wait-k, which delays the start of the decoding process simply by k steps  . For TTS, we choose approach starting the segmental speech synthesis after observing the next accent phrase . These modules exchange their input/output symbols in the forms of subwords and work in a symbol-synchronous way, so they can be cascaded even if they have different waiting strategies.  We also conduct a system-level evaluation of our system in system-level latency and module-level performance on English-to-Japanese simultaneous translation on TED Talks. The system-level latency measures are:  processing delays for waiting and computation time, and  TTS speaking latency derived from overlaps of synthesized speech outputs. The module-level performance is measured by standard metrics in ASR, MT, and TTS. This work is the first attempt of system-level evaluation for a simultaneous speech-to-speech translation system and would be beneficial to future studies.  %The remainder of this paper is organized as follows. %In section , we review the problem of simultaneous speech-to-speech translation, mainly in its difficulty. %In section , we describe the details of the incremental processing modules for ASR, MT, and TTS. %In section , we present system-wise evaluation of our system, followed by some discussions in section . %We conclude this paper in section .     In this article, we present the first comprehensive review of the most notable works to date on deep learning based multi-document summarization. We propose a taxonomy scheme for organizing and clustering existing publications and devise the network design strategies based on the state-of-the-art methods. Furthermore, we also provide an overview of the existing multi-document objective functions, evaluation metrics and datasets. Additionally, some of the most pressing open problems and promising future extensions are also discussed in this survey. We hope this survey can provide readers with a comprehensive understanding of the key aspects of the multi-document summarization task, clarify the most notable advances, and shed some light on future studies.         \setlength{\bibsep}{0.5ex} 
"," This paper presents a newly developed, simultaneous neural speech-to-speech translation system and its evaluation. The system consists of three fully-incremental neural processing modules for automatic speech recognition , machine translation , and text-to-speech synthesis . We investigated its overall latency in the system's Ear-Voice Span and speaking latency along with module-level performance.",331
" The emergence of online collaboration platforms has dramatically changed the dynamics of human teamwork, creating a veritable army of virtual teams, composed of workers in different physical locations. Software engineering requires a tremendous amount of collaborative problem solving, making it an excellent domain for team cognition researchers who seek to understand the manifestation of cognition applied to team tasks.  Mining data from social coding platforms such as GitHub can yield insights about the thought processes of virtual teams.  Previous work on issue comments has focused on emotional aspects of team communication, such as sentiment and politeness.  Our aim is to map issue comments to states in team cognition such as information gathering, knowledge building and problem solving.  To do this we employ dialogue act  classification, in order to identify the intent of the speaker.  Dialogue act classification has a broad range of natural language processing applications, including machine translation, dialogue systems and speech recognition.  Semantic-based classification of human utterances is a challenging task, and the lack of a large annotated corpus that represents class variations makes the job even harder. Compared to the examples of human utterances available in standard datasets like the Switchboard  corpus and the CSI Meeting Recorder Dialogue Act  corpus, GitHub utterances are more complex.   The primary purpose of our study is the DA classification of GitHub issue comments by harnessing the strength of transfer learning, using word and sentence level embedding models fine-tuned on our dataset.  For word-level transfer learning, we have used GLoVe vectors, and Universal Sentence Encoders and BERT models were used for sentence-level transfer. This paper presents a comparison of the performance of various  architectures on GitHub dialogues in a limited resource scenario.  A second contribution is our publicly available dataset of annotated issue comments. The dataset is available at \url{https://drive.google.com/drive/folders/1kLZvzfE80VeEYA1tqua_aj6nSiT57f83?usp=sharing}. In the field of computational collective intelligence,  where people collaborate and work in teams to achieve goals, dialogue act classification can play a vital role in understanding human teamwork.               The latency results revealed that our incremental system based on the cascade of three modules worked successfully with relatively small delays. However, the quality results suggested the task difficulty due to error propagation from ISR to IMT and lack of in-domain corpora in English-Japanese MT. We show two translation examples in Table. The first one is a relatively good result, and the other one is a typical error propagation example. Tight module integration would be promising, such as lattice-to-sequence , but its extension to the simultaneous translation is not trivial.  Besides, we have no common evaluation metrics for simultaneous speech-to-speech translation other than module-level ones. We used two latency metrics in this work, but the objective measurement of content delivery by speech-to-speech translation is crucial for further evaluation.    \section{Conclusions}   In this paper, we presented our English-to-Japanese simultaneous speech-to-speech translation system with its evaluation using English TED talks. The system works fully-incremental with speech inputs, by the cascaded modules of incremental ASR, incremental MT, and incremental TTS. The latency evaluation revealed the module-level computation could be finished with about three seconds delay at maximum. However, the system suffers from speaking latency.  Our future work includes further improvement of the modules in accuracy and efficiency, and controlling speaking duration to decrease the speaking latency.  \section{Acknowledgments} Part of this work was supported by JSPS KAKENHI Grant Numbers JP17H06101.    References should be produced using the bibtex program from suitable   BiBTeX files . The IEEEbib.bst bibliography   style file from IEEE produces unsorted bibliography list.   -------------------------------------------------------------------------    
"," Social coding platforms, such as GitHub, serve as  laboratories for studying collaborative problem solving in open source software development; a key feature is their ability to support issue reporting which is used by teams to discuss tasks and ideas.  Analyzing the dialogue between team members, as expressed in issue comments, can yield important insights about the performance of virtual teams.  This paper presents a transfer learning approach for performing dialogue act classification on issue comments.  Since no large labeled corpus of GitHub issue comments exists, employing transfer learning enables us to leverage standard dialogue act datasets in combination with our own GitHub comment dataset. We compare the performance of several word and sentence level encoding models including Global Vectors for Word Representations , Universal Sentence Encoder , and Bidirectional Encoder Representations from Transformers . Being able to map the issue comments to dialogue acts is a useful stepping stone towards understanding cognitive team processes.",332
" Large, densely-labeled datasets are a critical requirement for the creation of effective supervised learning models. The pressing need for high quantities of labeled data has led many researchers to collect data from social media platforms and online forums . Due to the presence of noise and the lack of structure that exist in these data sources, manual quality analysis  is necessary to extract structured labels, filter irrelevant examples, standardize language, and perform other preprocessing tasks before the data can be used. However, obtaining dataset annotations in this manner is a time-consuming and expensive process that is often prone to errors.   In this work, we develop automated data cleaning and verification mechanisms for extracting high-quality data from social media platforms\footnote{All code is available at \url{https://github.com/rachel-1/qa_plausibility}.}. We specifically focus on the creation of question-answer datasets, in which each data instance consists of a question about a topic and the corresponding answer. In order to filter noise and improve data quality,  we propose the task of question-answer  plausibility, which includes the following three steps:   Because we assume social media users generally answer questions in good faith , we can assume plausible answers are correct ones . Necessarily, if this property were not satisfied, then any adequate solutions would require the very domain knowledge of interest. Therefore, we look to apply this approach toward data with this property.  In this study, we demonstrate an application of QA plausibility in the context of visual question answering , a well-studied problem in the field of computer vision . We assemble a large VQA dataset with images collected from an image-sharing social network, machine-generated questions related to the content of the image, and responses from social media users. We then train a multitask BERT-based model and evaluate the ability of the model to perform the three subtasks associated with QA plausibility. The methods presented in this work hold potential for reducing the need for manual quality analysis of crowdsourced data as well as enabling the use of question-answer data from unstructured environments such as social media platforms.     This paper demonstrates a dialogue act classification system for GitHub issue comments. Due to the lack of publicly available training sets of formal teamwork dialogues, we formulated the problem as a transfer learning task, using both sentence-level and word-level embedding models to leverage information from the SwDA dataset. A significant contribution of our work is identifying the embedding model that performs best after fine-tuning on issue comments. We used GloVe, probabilistic representation, USE, and BERT embedding to train five different models. USE showed the best performance with an accuracy of 50.71\ . The low accuracy of USE on DA classification as compared to its accuracy on other state-of-the-art NLP tasks shows the complex nature of the dialogue act classification.  We evaluated many different settings for learning rates, epochs, and batch size; even though minor accuracy improvements were achievable, the performance of the embedding models remained fairly stable.    Our aim is to map issue comments to cognitive states in the Macrocognition in Teams Model .  Drawing from research on externalized cognition, team cognition, group communication and problem solving, and collaborative learning and adaptation, MITM provides a coherent theoretically based conceptualization for understanding complex team processes and how these emerge and change over time. MITM consists of five components: Team Problem-Solving Outcomes, Externalized Team Knowledge, Internalized Knowledge, Team Knowledge Building, and Individual Knowledge Building. It captures the parallel and iterative processes engaged by teams as they synthesize these components in service of team cognitive processes such as problem solving, decision making and planning. MITM has been applied to other team problem solving scenarios in military logistics and business planning but has never been used to analyze software engineering teams. Its usage in the domain of software engineering would be a major research contribution to the field of team cognition.    Although it is possible to directly label issue comments using an MITM code book, that type of labeling would be less compatible with existing dialogue act datasets.  Instead we are constructing a mapping that relates the DAMSL tagset to these cognitive states.  For instance, the question tags in DAMSL clearly relate to information gathering processes. Also many of the DAMSL classes are less relevant to the team cognition process and could be ignored.  The most commonly occurring classes in the GitHub issue comments  are all relevant to the Macrocognition in Teams Model, and we plan to tune our dialogue act classifiers to bolster the performance on these classes. In future work, we continue to improve the size and quality of our publicly-released dataset by recruiting more annotators to help with the labeling task and also more systematically studying inter-coder reliability.   
"," Datasets extracted from social networks and online forums are often prone to the pitfalls of natural language, namely the presence of unstructured and noisy data. In this work, we seek to enable the collection of high-quality question-answer datasets from social media by proposing a novel task for automated quality analysis and data cleaning: question-answer  plausibility. Given a machine or user-generated question and a crowd-sourced response from a social media user, we determine if the question and response are valid; if so, we identify the answer within the free-form response.   We design BERT-based models to perform the QA plausibility task, and we evaluate the ability of our models to generate a clean, usable question-answer dataset. Our highest-performing approach consists of a single-task model which determines the plausibility of the question, followed by a multi-task model which evaluates the plausibility of the response as well as extracts answers .",333
"  In recent times, pre-trained neural language models  have become the preferred approach for language representation learning, pushing the state-of-the-art in multiple NLP tasks~. These approaches rely on a two-step training process: first, a self-supervised pre-training is performed on large-scale corpora; then, the model undergoes a supervised fine-tuning on downstream task labels using task-specific prediction heads. While this method was found to be effective in scenarios where a relatively large amount of labeled data are present, researchers highlighted that this is not the case in low-resource settings~.   Recently, pattern-exploiting training~(PET, \citet{Schick2020ExploitingCQ,Schick2020ItsNJ} tackles the dependence of NLMs on labeled data by first reformulating tasks as cloze questions using task-related patterns and keywords, and then using language models trained on those to annotate large sets of unlabeled examples with soft labels. PET can be thought of as an offline version of knowledge distillation~, which is a well-established approach to transfer the knowledge across models of different size, or even between different versions of the same model as in self-training . While effective on classification tasks that can be easily reformulated as cloze questions, PET cannot be easily extended to regression settings since they cannot be adequately verbalized. Contemporary work by \citet{du-etal-2020-selftraining} showed how self-training and pre-training provide complementary information for natural language understanding tasks.  In this paper, I propose a simple self-supervised data augmentation approach that can be used to improve the generalization capabilities of NLMs on regression and classification tasks for modest-sized labeled corpora. In short, an ensemble of fine-tuned models is used to annotate a large corpus of unlabeled text, and new annotations are leveraged in a multi-task setting to obtain final predictions over the original test set. The method was tested on the AcCompl-it shared tasks of the EVALITA 2020 campaign~, where the objective was to predict respectively complexity and acceptability scores on a 1-7 Likert scale for each test sentence, alongside an estimation of its standard error. Results show considerable improvements over regular fine-tuning performances on COMPL and ACCEPT using the UmBERTo pre-trained model~, suggesting the validity of this approach for complexity/acceptability prediction and possibly other language processing tasks.    Deep learning studies are often hindered by lack of access to large datasets with accurate labels. In this paper, we introduced the question-answer plausibility task in an effort to automate the data cleaning process for question-answer datasets collected from social media. We then presented a multi-task deep learning model based on BERT, which accurately identified the plausibility of machine-generated questions and user responses as well as extracted structured answer labels. Although we specifically focused on the visual question answering problem in this paper, we expect that our results will be useful for other question-answer scenarios, such as in settings where questions are user-generated or images are not available.      Overall, our approach can help improve the deep learning workflow by processing and cleaning the noisy and unstructured natural language text available on social media platforms. Ultimately, our work can enable the generation of large-scale, high-quality datasets for artificial intelligence models.      
","   English.  This work describes a self-supervised data augmentation approach used to improve learning models' performances when only a moderate amount of labeled data is available. Multiple copies of the original model are initially trained on the downstream task. Their predictions are then used to annotate a large set of unlabeled examples. Finally, multi-task training is performed on the parallel annotations of the resulting training set, and final scores are obtained by averaging annotator-specific head predictions. Neural language models are fine-tuned using this procedure in the context of the AcCompl-it shared task at EVALITA 2020, obtaining considerable improvements in prediction quality.",334
"  Language modelling is the task of transforming individual words into vector representations based on the context they appear in. Hence, distant term dependencies are an inherited issue within the task. Language models always seek for smart approaches towards incorporating context from longer distances as it allows for better representations compared to their limited context counterparts. Intuitively, imagine attempting to start reading a novel series from the second book onward, with no information about the first. The amount of information previously missed is something that cannot be acquired. However, this is the case with most language models. While an understanding of the words is present due to the contextual information at each word's occurrence, entity information that are in distant text are lost or not transferred.   Until recently, Recurrent Neural Networks , and specifically  Long Short-Term Memory  networks, have been the core of all the state-of-the-art approaches . Thanks to the Transformers architecture , through the use of attention mechanisms, models such as XLNet , GPT  and BERT  can account for even longer sequences. However, the computational limitations of the multi-head attention in the architecture make it hard to increase the contextual information in such models . As a result, research has been focused on introducing variations to the transformer architecture, with focus on the multi-head attention mechanism, in order to alleviate part of the computational cost and increase the contextual information available to models.   In this paper we present a novel approach, that makes use of coreference information during training a language model via our Entity-Transformer architecture, which extends the original Transformer block in Transformer-Based language models. To that end, we incorporate the important entity information that would otherwise be unreachable for the model. As a result, we effectively boost the representations of the entity mentions, where entity information is present, without hindering the performance of the language model where entities are not present.   In our experiments, we extend the GPT2 architecture to formulate our model, named GPT2E and train it on the CoNLL-2012 dataset  using the annotated coreference information. We evaluate the model's performance in terms of Perplexity on the ConLL 2012 and the LAMBADA  datasets and showcase the effects of such training on the word representations as well as on the downstream task of Named Entity Recognition  using the CoNLL 2012 dataset. To that end, we compare GPT2E's performance to a base model  when trained on the same data, to highlight the effects of coreference information when paird with our Entity-Transformer architecture.     Our study constitutes the first attempt of modeling automatic translation for the extremely low-resource language of Bambara. We identified challenges for future work, such as the development of alignment tools for small-scale datasets, and the need for a general domain evaluation set. The current limitation of processing written text as input might furthermore benefit from the integration of spoken resources through speech recognition or speech translation, since Bambara is primarily spoken and the lack of standardization in writing complicates the creation of clean reference sets and consistent evaluation.     
","     In the last decade, the field of Neural Language Modelling has witnessed enormous changes, with the development of novel models through the use of Transformer architectures. However, even these models struggle to model long sequences due to memory constraints and increasing computational complexity. Coreference annotations over the training data can provide context far beyond the modelling limitations of such language models. In this paper we present an extension over the Transformer-block architecture used in neural language models, specifically in GPT2, in order to incorporate entity annotations during training. Our model, GPT2E, extends the Transformer layers architecture of GPT2 to Entity-Transformers, an architecture designed to handle coreference information when present. To that end, we achieve richer representations for entity mentions, with insignificant training cost. We show the comparative model performance between GPT2 and GPT2E in terms of Perplexity on the CoNLL 2012 and LAMBADA datasets as well as the key differences in the entity representations and their effects in downstream tasks such as Named Entity Recognition. Furthermore, our approach can be adopted by the majority of Transformer-based language models.",335
" Sequence labeling is the task of labeling each token of a sequence. It is an important task in natural language processing and has a lot of applications such as Part-of-Speech Tagging  , Named Entity Recognition  , Chunking .  The neural CRF model is one of the most widely-used approaches to sequence labeling and can achieve superior performance on many tasks .  It often employs an encoder such as a BiLSTM to compute the contextual vector representation of each word in the input sequence. The potential function at each position of the input sequence in a neural CRF is typically decomposed into an emission function  and a transition function   . %The transition function is computed from the previous and current labels.  In this paper, we design a series of increasingly expressive potential functions for neural CRF models. First, we compute the transition function from label embeddings  instead of label identities. Second, we use a single potential function over the current word and the previous and current labels, instead of decomposing it into the emission and transition functions, leading to more expressiveness. We also employ tensor decomposition in order to keep the potential function tractable. Thirdly, we take the representations of additional neighboring words as input to the potential function, instead of solely relying on the BiLSTM to capture contextual information.   To empirically evaluate different approaches, we conduct experiments on four well-known sequence labeling tasks: NER, Chunking, coarse- and fine-grained POS tagging. We find that it is beneficial for the potential function to take representations of neighboring words as input, and a quadrilinear potential function with a decomposed tensor parameter leads to the best overall performance.    Our work is related to \citet{reimers-gurevych-2017-reporting,yang-etal-2018-design}, which also compared different network architectures and configurations and conducted empirical analysis on different sequence labeling tasks. However, our focus is on the potential function design of neural CRF models, which has not been sufficiently studied before.     The framework presented in this paper has several advantages for modeling language change. The networks are trained on raw acoustic inputs with no levels of abstraction or pre-extracted features. Deep convolutional network in the GAN framework need to learn to produce data from random noise and they never fully replicate the data, but produce innovative linguistically interpretable data. This means their output data are not replicates, but innovative original outputs. As argued elsewhere , the innovative outputs of the Generator are highly informative  and often replicate stages in language acquisition. In this paper we additionally argue that the innovative outputs can result in phonetic and phonological changes when trained in iterative learning tasks.   The current model contains no articulatory information. While this is generally unideal, because human speech acquisition is highly influenced by articulators, it allows us to model language change as if only cognition-general mechanisms were involved in language acquisition and production. The results from the computational experiment suggest that both gradual change of targets that resembles phonetic change as well as phonological rule loss can emerge when deep convolutional networks are trained in iterative learning tasks without any articulatory information and without language-specific parameters in the model. In future work, we should be able to  compare results of the articulation-free model with models  containing articulatory information to get a better understanding of which properties of sound change can be derived from domain-general cognitive mechanisms and which properties of sound change require articulatory forces.      The current paper offers an initial step in a broader goal of modeling language's cultural evolution based on generations of deep convolutional networks trained on raw speech. Far more complex interactions between agents can be conceived in future work. For example, GANs  can be set to  communicate with and learn from each other in interactive ways already during the training. Further modeling of this kind should shed light onto one of the most widely studied but still poorly understood phenomenon in language --- sound change.        \subsubsection*{Acknowledgements} This research was funded by a grant to new faculty at the University of Washington and the University of California, Berkeley. I would like to thank Sameer Arshad for slicing data from the TIMIT database.      \clearpage        {\small  }  \clearpage   
"," The neural linear-chain CRF model is one of the most widely-used approach to sequence labeling. In this paper, we investigate a series of increasingly expressive potential functions for neural CRF models, which not only integrate the emission and transition functions, but also explicitly take the representations of the contextual words as input. Our extensive experiments show that the decomposed quadrilinear potential function based on the vector representations of two neighboring labels and two neighboring words consistently achieves the best performance.",336
"  Sequence labeling tasks are essential in web mining, such as named entity recognition , event extraction, and relation identification. For example, the NER models assign the predefined labels to tag tokens in the input sequences to indicate both the entity boundaries and types. In some web services, such as question answering, sequence labeling also plays a critical role, where it reads a passage in a Web page as the context and answers a given question by extracting a text span inside the given passage. This process is often called machine reading comprehension . MRC is also regarded as a sequence labeling task, since it predicts whether each token is the start, end, or none for the answer span.  There is a rich literature for sequence labeling. Classical methods include Hidden Markov models , maximum entropy Markov models , and conditional random field . Recently, combining neural networks as the representation layer with CRF models has further boosted the state-of-the-art performance. However, such statistical models require large amounts of training data. Consequently, they only show good performance in languages with rich training data, such as English. Sequence labeling on low-resource languages is still very challenging, mainly due to very limited training data available.  To tackle the challenge of sequence labeling in low-resource languages, some early works transfer the knowledge from rich-source languages to low-resource ones by information alignment through manually built bilingual parallel corpora,  or language-independent features. In recent years, multilingual pre-trained language models, such as Unicoder, mBERT, and XLM-Roberta , are developed for model transferring. For example, Wu et al.  fine-tune mBERT on a pseudo training set by a meta-learning method. To better leverage the unlabeled data in the target language, a teacher-student framework is proposed to distill knowledge from weighted teacher models. Inspired by back translation in neural machine translation , DualBERT is developed to learn source language and target language features simultaneously. Although these multilingual sequence labeling models can effectively locate target spans, they often fail to give the precise boundaries of the spans in the target languages.  %when predicting text spans in the target languages.  %that is, pairs of sentences with similar meanings but in different languages, %\jp{What is the conclusion we can draw from this paragraph?}  %The previous multilingual sequence labeling models can roughly identify the correct target spans, but often fail to give the precise boundaries when predicting text spans in the target languages.  We conduct an empirical study to quantitatively assess the challenge. In Figure , we categorize the mismatches between the predicted span and the ground truth span into four types:  the predicted answer is a super span of the ground truth;  the predicted answer is sub span of the ground truth;  the predicted answer both miss some terms in the ground truth and add extra terms not in the ground truth , and   the predicted answer is adjacent to the ground truth but contains no common sub-span with it .  We further show in Table the statistics of the error cases in the cross-lingual NER task using the XLM-R model, where the boundary errors, including super span, sub span, drifted span, and adjacent span, contribute to a large portion of all error cases as shown in the last column. The other errors cases are mainly entity type detection errors. This observation motivates us to tackle the bottleneck of boundary detection in sequence labeling models.           % \end{center}      \end{table}  Accurately detecting answer boundaries becomes a bottleneck in sequence labeling.  To tackle the challenge, in this paper, we propose a separate model for boundary calibration based on the output of a base model. Intuitively, the base model captures the global context of the whole input sequence and roughly locates the region for answers. Then, the calibration model conducts finer search within the detected region and the neighborhood, and focuses on the local context to refine the boundary. This is analogous to the human perception and cognition process, which first locates the target, sets up the local context, and finally zooms into details.  Our design is novel for sequence labeling, and is orthogonal and complements to all existing approaches.  Using a second model to focus on detecting answer boundaries accurately is an intuitive and nice idea.  However, how to construct high-quality training data for the calibration model remains challenging. One straightforward method is to transform the original training data of sequence labeling task into a new training set for calibration model. However, the data collected in this way is still quite limited, especially for low-resource languages. To address this challenge, we strategically propose a novel phrase boundary recovery  task to pre-train the model on large-scale augmented datasets synthesized from Wikipedia documents in multiple languages. The new pre-training approach dramatically improves the capability of the calibration module to determine answer boundaries accurately.  % Besides the design of employing two models, we further equip the calibration model with a pre-training process by emphasizing on the capability of recovering meaningful phrases from noisy input.  Our approach is shown in Figure. CalibreNet consists of two modules, a base module and a calibration module. The base module can take any model of sequence labeling. The predicted answers by the base module are combined with the input sequence to form the input to the calibration module. The calibration module considers both the initial results by the base module and the whole passage to refine the span boundaries. In particular, the calibration module is pre-trained with the PBR task on large-scale multilingual synthesized data from Wikipedia-derived corpus.  We make the following technical contributions in this paper. First, we propose the CalibreNet framework for the task of cross-lingual sequence labeling to improve the accuracy of labeled answers. Second, we propose a novel phrase boundary recovery task and a weakly supervised pre-training method using Wikipedia data. This approach effectively enhances the model sensitivity to phrase boundaries. Last but not least, we conduct extensive experiments on zero-shot cross-lingual NER and improve the SOTA results. In addition, the experiments on the MRC tasks also show consistent improvement over strong baseline methods.  The rest of the paper is organized as follows. We first review the related work in Section. We then present our approach in Section. We report the extensive experimental results in Sections.  We conduct further analysis in Section, and conclude the paper in Section.    In this paper, we investigate several potential functions for neural CRF models. The proposed potential functions not only integrate the emission and transition functions, but also take into consideration representations of additional neighboring words. Our experiments show that D-Quadrilinear achieves the best overall performance. Our proposed approaches are simple and effective and could facilitate future research in neural sequence labeling.  
","  \footnotetext[1]{Work done during the first author's internship at Microsoft STCA.} \footnotetext[2]{Daxin Jiang and Wanli Zuo are the corresponding authors.} % \footnotetext[3]{Jian Pei's research is supported in part by the NSERC Discovery Grant program. All opinions, findings, conclusions and recommendations in this paper are those of the authors and do not necessarily reflect the views of the funding agencies.}   Lack of training data in low-resource languages presents huge challenges to sequence labeling tasks such as named entity recognition  and machine reading comprehension . One major obstacle is the errors on the boundary of predicted answers. To tackle this problem, we propose CalibreNet, which predicts answers in two steps. In the first step, any existing sequence labeling method can be adopted as a base model to generate an initial answer. In the second step, CalibreNet refines the boundary of the initial answer. To tackle the challenge of lack of training data in low-resource languages, we dedicatedly develop a novel unsupervised phrase boundary recovery pre-training task to enhance the multilingual boundary detection capability of CalibreNet. Experiments on two cross-lingual benchmark datasets show that the proposed approach achieves SOTA results on zero-shot cross-lingual NER and MRC tasks.",337
"  The Text-to-SQL task aims to translate natural language texts into SQL queries. Users who do not understand SQL grammars can benefit from this task and acquire information from databases by just inputting natural language texts. Previous works  focus on context-independent text-to-SQL generation. However, in practice, users usually interact with systems for several turns to acquire information, which extends the text-to-SQL task to the context-dependent text-to-SQL task in a conversational scenario. Throughout the interaction, user inputs may omit some information that appeared before. This phenomenon brings difficulty for context-dependent text-to-SQL task.   Recently, context-dependent text-to-SQL task has attracted more attention. \citet{suhr2018learning} conduct experiments on ATIS dataset . Besides, two cross-domain context-dependent datasets SParC  and CoSQL  are released. Cross-domain means databases in test set differ from that in training set, which is more challenging.   EditSQL  is the previous state-of-the-art model on SParC and CoSQL datasets and it focuses on taking advantages of previous utterance texts and previously predicted query to predict the query for current turn. Table  shows the user inputs, ground truth queries and predicted queries of EditSQL for an interaction. In the second turn, EditSQL views ``Kacey"" as the name of a dog owner. However, since the context of the interaction is about dogs, ``Kacey"" should be the name of a dog. This example shows that a model using only historical information of user inputs may fail to keep context consistency and maintain thematic relations.   According to  and , to maintain thematic relations, users may change constraints, ask for different attributes for the same topic when they ask the next questions. Thus, database schema items  in current turn should have relation with items in previous turn. For example, in Table , the second question  adds a constraint of the name and asks for the age of a dog instead of the numbers of all dogs. The corresponding database schema items Dogs.age and Dogs.name in   belong to the same table as Dogs.* in previous query . Therefore, we propose to take historical information about database schema items into consideration.  % %     %     %\end{table}   In particular, we first construct a graph based on corresponding database, where graph nodes are database schema items and graph edges are primary-foreign keys and column affiliation. Short distance between graph nodes appearing in previous query and current query can reveal the context consistency since there is usually an edge between the different attributes of the same topic. We then propose a database schema interaction graph encoder to model database schema items together with historical items. Empirical results on two large cross-domain context-dependent text-to-SQL datasets - SParC and CoSQL show that our schema interaction graph encoder contributes to modeling context consistency and our proposed model with database schema interaction graph encoder substantially outperforms the state-of-the-art model.                \end{table}  Our main contributions are summarized as follows:        In this paper, we tackle the challenge of detecting span boundaries more precisely for sequence labeling tasks in low-resource languages. We propose the CalibreNet architecture as well as a novel Phrase Boundary Recovery task for more accurate boundary detection. Extensive experimental results verify the effectiveness of our approach and the generalization capability for multiple languages. As future works, we plan to introduce entity type prediction in the pre-training task, and also develop better methods for question generation for the MRC task.        The acknowledgments section is defined using the ""acks"" environment    . This ensures the proper    identification of the section in the article metadata, and the    consistent spelling of the heading.         The next two lines define the bibliography style to be used, and    the bibliography file.          If your work has an appendix, this is the place to put it.       
"," Context-dependent text-to-SQL task has drawn much attention in recent years. Previous models on context-dependent text-to-SQL task only concentrate on utilizing historical user inputs. In this work, in addition to using encoders to capture historical information of user inputs, we propose a database schema interaction graph encoder to utilize historicalal information of database schema items. In decoding phase, we introduce a gate mechanism to weigh the importance of different vocabularies and then make the prediction of SQL tokens. We evaluate our model on the benchmark SParC and CoSQL datasets, which are two large complex context-dependent cross-domain text-to-SQL datasets. Our model outperforms previous state-of-the-art model by a large margin and achieves new state-of-the-art results on the two datasets. The comparison and ablation results demonstrate the efficacy of our model and the usefulness of the database schema interaction graph encoder.",338
" The recent survey conducted by WHO shows that a total  million people in the world are living with depression.  % This has increased by 18.4\% between  and .  At its most severe, depression can lead to suicide and is responsible for  deaths every year  . Early detection and appropriate treatment can encourage remission and prevent relapse . However, the stigma coupled with the depression makes patients reluctant to seek support or provide truthful answers to physicians .  Additionally, clinical diagnosis is dependent on the self-reports of the patient閳ユ獨 behavior, which requires them to reflect and recall from the past, that may have obscured over time. In contrast, social media offers unique platform for people to share their experiences in the moment, express emotions and stress in their raw intensity, and seek social and emotional support for resilience. As such, the depression studies based on social media offer unique advantages over scheduled surveys or interviews . Social media self-narratives contain large amounts of implicit and reliable information expressed in real-time, that are  essential for practitioners to glean and understand user閳ユ獨 behavior outside of the controlled clinical environment. % \indent Several studies in the literature have explored various linguistic and visual cues to effectively detect user depression from the postings on social media platform like Twitter  and Reddit . Majority of these existing studies have formulated the social media depression detection task as a binary classification problem  and therefore are limited to only identifying the depressive users. \\ \indent To assist healthcare professionals  intervene in a  timely manner such as with an automatic triaging, it is necessary to develop an intelligent decision support system that provides HPs fine-grained depression related symptoms. The triage process is a critical step in giving care to the patients because, by prioritizing patients at different triage levels based on the severity of their clinical condition, one can enhance the utilization of healthcare facilities and the efficacy of healthcare interventions. There have been a few efforts to create datasets for capturing depression severity, however they are limited to  only clinical interviews  and questionnaires , and  individuals who voluntarily participate in the study .  \\ \indent In this work, we exploit the Twitter data to identify the indications  of depression. We developed a high quality dataset consisting of total  tweets, with  tweets posted by  self-reported depressed users over  weeks time, which were manually annotated using  questionnaire  based symptoms categories. In Table-, we provide sample tweets associated with the nine item  depression symptoms. % The  is a self-reported questionnaire, based on the Diagnostic and Statistical Manual of Mental Disorders, Fourth Edition  guidelines, for screening, diagnosing, and measuring severity of depression.  % The overall  scores range between  and , with a score of  or more linked to major depressive disorders. Our research hypothesis is that depressed individuals discuss their symptoms on Twitter that can be tracked reliably.  }   \end{table*} % Advancement in Natural Language Processing  is one of the most promising avenues for discovering vital mental health information from user-generated data. Nonetheless, user social-media post offer unique challenges as discussed below:   To account for this creative linguistic device widely observed in utterances of depressive users, we propose a Figurative Language enabled Multi-Task Learning framework  that works on the concept of task sharing mechanism . In this work, we improve the performance and robustness of the  for the primary task of `symptom identification' combined with the supervisory task `figurative usage detection' in a multi-task learning setting.  We introduce a mechanism  named `co-task aware attention' which enables the layer-specific soft sharing of the parameters for the tasks of interest. The proposed attention mechanism is parameterized with the task-specific scaling factor for BERT  layers. BERT enables even the low-resource tasks to benefit from deep bi-directional architectures and the unsupervised training framework to obtain the context-aware encoded representation. The virtue of this model is its ability to learn the task-specific representation of the input tweet by coordinating among the layers and between the tasks. \\ Contributions:   %%%%%%%%%%%%%%%%%%%%%  % % According to Word Health Organization \footnote{http://www.who.int/news-room/fact-sheets/detail/mental-disorders}, ``depressive disorder is characterized by sadness, loss of interest or pleasure, feelings of guilt or low self worth, disturbed sleep or appetite, feelings of tiredness, and poor concentration"".  % Major depressive disorder  has a world-wide impact on society with each year causing almost one million deaths. % The recent survey conducted by WHO shows that total  million people in the world are living with depression. This has increased by 18.4\% between  and . At its most severe depression can lead to suicide and is responsible for  deaths every year  . Early detection and appropriate treatment can encourage remission and prevent relapse . However, the stigma coupled with the depression makes patients reluctant to seek support. Also, the associated cognitive biases, inhibits the patients to provide truthful answer to physicians which further add limitation .\\ % \indent Additionally, clinical diagnosis is dependent on the hypothetical self-reports of patients behaviour, requiring patients to reflect on what they were doing and thinking sometime in the past, which may have become obscured over time. In contrast, social media offers unique platform for people to share their experiences, exhaust emotion and stress, and seek social and emotional support. As such, the depression studies based on social media offers several advantage . These self-narrative contains large amount of the implicit information, which are highly essential for practitioner to understand users behaviour outside the controlled clinical environment and in real-time.\\ % \indent Several studies in literature have explored various linguistic and visual cues to effectively detect depression from the social media platform like Twitter and Reddit. Majority of these existing studies have formulated the social media depression detection task as a binary classification problem  and therefore is only limited to identify the depressive users. \\ % \indent However, to assist healthcare professional  in making timely intervention, it is required to develop an intelligent decision support system that could provide HPs with more fine-grained depression related symptoms and automatic triaging techniques. The triage process is the first critical step in giving care to the patients by prioritizing patients at different triage levels based on the severity of their clinical conditions that could have the potential to enhance the efficacy of healthcare interventions. In literature, there has been few efforts to create dataset for capturing depression severity, however they are limited to  only clinical interview  and questionnaire , and  individuals who voluntary participated in the study.  \\ % \indent In this work, we exploit the Twitter data to identify the indications  of depression and finally assign  based severity labels: `None', `Mild', `Moderate', `Moderately Severe', and `Severe' for triaging. We developed a new dataset consisting  tweets posted by  self-reported depressed users over  weeks time, which are manually annotated into  symptom categories. In Table-, we provide the samples tweets associated with nine item  depression symptoms. % The  is a self-report questionnaire based on the Diagnostic and Statistical Manual of Mental Disorders, Fourth Edition  guidelines for screening, diagnosing, and measuring severity of depression. The overall  scoring ranges between  and , with  or more highly linked to major depressive disorders. % Our research hypothesis is that depressed individuals discuss their symptoms on Twitter.\\ % %This work aim to develop an intelligent decision support system in the context of major depressive disorder by providing the healthcare professionals  with more fine-grained depression related symptoms and automatic triaging technique that is required by HPs to make timely intervention. The triage process is the first critical step in giving care to the patients by prioritizing patients at different triage levels based on the severity of their clinical conditions that could have the potential to enhance the efficacy of healthcare interventions.\\ %  % } %  %  % \end{table*} % Advancement in Natural Language Processing  technology is one of the most promising avenues for discovering vital mental health information from user-generated data. Nonetheless, these texts offers some inherently distinct challenges discussed as follows: %  % Furthermore, previous studies utilizing social media data in biomedical natural language processing task reported prediction error when drug or symptom names are utilized in figurative sense. To account for this creative linguistic devices widely observed in utterances of depressive users, we proposed a multitask learning  framework that works on the concept of task sharing mechanism. Multi-task learning has been proven to the a useful instruments to improve the generalization performance of the primary task with related auxiliary tasks. In this work, we focused to improve the performance and generalization ability of the proposed model for the primary task of `symptom identification' in companionship with the supervisory task `figurative language detection'. We introduce a mechanism  named `co-task aware attention' which enables the layer-specific soft sharing of the parameters for the task at interest. The proposed attention mechanism is parameterize with the task-specific scaling factor for BERT layers. To the virtue of the this, the model is able to learn the task-specific representation of the input tweet by coordinating among the layers and between the tasks. \\ % Contributions: %     In this paper, we focus on context-dependent cross-domain SQL generation task. We find that previous state-of-the-art model only takes historical user inputs and previously predicted query into consideration, but ignores the historical information of database schema items. Thus we propose a model named IGSQL to model database schema items in a conversational scenario. Empirical results demonstrate the efficacy of our model. We also conduct ablation experiments to reveal the significance of our database schema interaction graph encoder. For future work, we  will explore methods attempting to solve hard and extra hard questions.   \section*{Acknowledgments}  This work was supported by National Natural Science Foundation of China , Beijing Academy of Artificial Intelligence  and Key Laboratory of Science, Technology and Standard in Press Industry . We appreciate the anonymous reviewers for their helpful comments. Xiaojun Wan is the corresponding author.  
"," Existing studies on using social media for deriving mental health status of users focus on the depression detection task. However, for case management and referral to psychiatrists, healthcare workers require practical and scalable depressive disorder screening and triage system. % for prevention or treatment of severe consequences.  This study aims to design and evaluate a decision support system  to reliably determine the depressive triage level by capturing fine-grained depressive symptoms expressed in user tweets through the emulation of Patient Health Questionnaire-9 \texttt{} that is routinely used in clinical practice. %However, the 280-character limit on tweets incentivizes the usage of creative artifacts in the utterances.  %Figurative language forms a general fabric of communication as it permits users to express themselves more effectively.  %Unfortunately, this complicates the reliable detection of depressive symptoms.  The reliable detection of depressive symptoms from tweets is challenging because the 280-character limit on tweets incentivizes the use of creative artifacts in the utterances and figurative usage contributes to effective expression.   We propose a novel BERT based robust multi-task learning framework to accurately identify the depressive symptoms using the auxiliary task of figurative usage detection. Specifically, our proposed novel task sharing mechanism, co-task aware attention\/, enables automatic selection of optimal information across the BERT layers and tasks by soft-sharing of parameters. Our results show that modeling figurative usage can demonstrably improve the model's robustness and reliability for distinguishing the depression symptoms. %Furthermore, our approach achieves statistically significant improvements over the SOTA models.  % Social media platforms have evolved as a vital source of information for mental-health studies, where the users exchange their emotional states and impressions. Majority of the existing studies on depression focus mainly on the depression detection task. However, for healthcare workers to have real-time access to resources for case management and referral to medical/psychiatric treatment, it is necessitate to enable practical, scalable, and sustainable depressive disorder screening, triage, and prevention/treatment interventions. This study aims to design and evaluate a decision support system  to % determine the depressive triage level by capturing fine-grained depressive symptoms appearing in depressed users tweets through emulating the clinically adopted Patient Health Questionnaire-9 \texttt{\texttt{PHQ-9}}.\\ % Nevertheless, the limitation on characters imposed by Twitter incentivize the usage of creative artifacts that are widely observed in the utterance of depressive users. Figurative language, such as metaphor, irony, and sarcasm forms a general fabric of communication as it permit users to express their health condition more memorably, concisely, and effectively. Inspired by that, we proposed a novel BERT based multi-task learning framework that learns to accurately identify the symptoms using the auxiliary task of figurative language detection. Specifically, we propose a new task sharing mechanism: co-task aware attention, which helps the model to borrow the new information across the task. With the help of soft-sharing of the parameters, our framework automatically detect and select optimal information across the layers of the BERT, that are useful for a task at hand. % The obtained results proves that modeling figurative language in depressive user tweets can improve the model learning ability in correctly distinguishing the symptoms. Furthermore, our proposed approach achieve statistically significant improvements over the state-of-the-art models on our primary task.",339
" Coherence refers to the properties of a text that indicate how meaningful sentential constituents are connected to convey document-level meaning. Different theories have been proposed to describe the properties that contribute to discourse coherence and some have been integrated with computational models for empirical evaluation. A popular approach is the entity-based model which hypothesizes that coherence can be assessed in terms of the distribution of and transitions between entities in a text -- by constructing an entity-grid  representation, building on Centering Theory. Subsequent work has adapted and further extended Egrid representations.  Other research has focused on syntactic patterns that co-occur in text or semantic relatedness between sentences as key aspects of coherence modeling. There have also been attempts to model coherence by identifying rhetorical relations that connect textual units or capturing topic shifts via Hidden Markov Models~\cite[HMM,][]{barzilay-lee-2004-catching}. Other work has combined approaches to study whether they are complementary.  More recently, neural networks have been used to model coherence. Some models utilize structured representations of text~\cite[e.g. Egrid representations,][]{Dat2017,Joty2018} and others operate on unstructured text, taking advantage of neural models' ability to learn useful representations for the task.  Coherence has typically been assessed by a model's ability to rank a well-organized document higher than its noisy counterparts created by corrupting sentence order in the original document , and neural models have achieved remarkable accuracy on this task. Recent efforts have targeted additional tasks such as recovering the correct sentence order, evaluating on realistic data and focusing on open-domain models of coherence. However, less attention has been directed to investigating and analyzing the properties of coherence that current models can capture, nor what knowledge is encoded in their representations and how it might relate to aspects of coherence.   In this work, we systematically examine what properties of discourse coherence current coherence models can capture. We devise two datasets that exhibit various kinds of incoherence and analyze model ability to capture syntactic and semantic aspects of text implicated in discourse organisation.  We furthermore investigate a set of probing tasks to better understand the information that is encoded in their representations and how it might relate to aspects of coherence.  We hope this study shall provide further insight into how to frame the task and improve models of coherence assessment further.  Finally, we release our evaluation datasets as a resource for the community to use to test discourse coherence models.     In this research, we explored a new dimension of social media in Twitter to identify depressive symptoms. Towards this end, we created a new benchmark dataset  for identifying fine-grained PHQ-9 emulated depressive symptoms that contains figurative language. We also introduce a robust BERT based MTL framework that jointly learns to automatically discover complementary features required to identify the symptoms with the help of the auxiliary task of figurative usage detection. Our experimental results convincingly show the effectiveness of introducing figurative usage detection for depressive symptoms identification. In future, we aim to enhance the dataset with the other modalities like image and memes to assist the model in better understanding of figurative sense in symptom identification.   ########################################################################   
","  In this work, we systematically investigate how well current models of coherence can capture aspects of text implicated in discourse organisation. We devise two datasets of various linguistic alterations that undermine coherence and test model sensitivity to changes in syntax and semantics. We furthermore probe discourse embedding space and examine the knowledge that is encoded in representations of coherence. We hope this study shall provide further insight into how to frame the task and improve models of coherence assessment further. Finally, we make our datasets publicly available as a resource for researchers to use to test discourse coherence models.",340
"  Early detection of dementia is important for improving clinical outcomes and management of dementia, as well as for lifestyle, financial, and future planning for patients and their caregivers . Yet, dementia is not formally diagnosed or coded in claims for over 50\% of older adults living with probable dementia . Tools that screen medical records for warning signs and present the digested information to providers may prove to be an important step for early intervention.  In this study, we aim to use NLP to detect signs of cognitive dysfunction from clinician notes in electronic health records  by applying deep learning techniques that have not been hitherto applied to this problem. We present an attention-based transformer model that allows for long text sequences to reveal signs of cognitive concerns and compare its performance to baseline models.       Our evaluation experiments on two coherence datasets reveal that RNN- or EGrid-based coherence models are able to detect syntactic alterations that undermine coherence, but are less effecient at detecting semantic ones even after fine-tuning on the latter.  We furthermore find that they particularly struggle with recognizing minor lexical changes even if they result in implausible meaning and resolving pronominal references.  On the other hand, these models are particularly good at detecting cases where a prefix is inserted or the subject pronoun is substituted with a lexical item, suggesting that they are capable of capturing the relevant syntactic patterns and do not solely rely on positional features.   We find that the best performing model overall is LCD which does not use an RNN sentence encoder but rather builds sentence representations by averaging BERT embeddings then utilizes a number of linear transformations over adjacent sentences to facilitate learning richer representations.    Our probing experiments reveal that models are better at encoding information regarding subject and object number  followed by verb number . These probing tasks align with Centering theory as they probe for subject and object relevant information. The task that tests for knowledge on coordination inversion is the lowest performing one overall, suggesting that there is little capacity at capturing information related to intra-sentential coherence. Excluding LCD, MTL is the best performing model; nevertheless, there is still scope for substantial improvement across all probing tasks and particularly on CoordInv and CorruptAgr.      \section{Conclusion}  We systematically studied how well current models of coherence can capture aspects of text implicated in discourse organisation. We devised datasets of various kinds of incoherence and examined model susceptibility to syntactic and semantic alterations. Our results demonstrate the models are robust with respect to corrupted syntactic patterns, prefix insertions and lexical substitutions. However, they fall short in capturing rhetorical and semantic corruptions, lexical perturbations and corrupt pronouns. We furthermore find that discourse embedding space encodes subject and object relevant information; however, there is scope for substantial improvement in terms of encoding linguistic properties relevant to discourse coherence. Experiments on coordination inversion further suggest that current models have little capacity at encoding information related to intra-sentential coherence.  We hope this study shall provide further insight into how to frame the task of coherence modeling and improve model performance further. Finally, we make our datasets publicly available for researchers to use to test coherence models.        
","   Dementia is under-recognized in the community, under-diagnosed by healthcare professionals, and under-coded in claims data. Information on cognitive dysfunction, however, is often found in unstructured clinician notes within medical records but manual review by experts is time consuming and often prone to errors. Automated mining of these notes presents a potential opportunity to label patients with cognitive concerns who could benefit from an evaluation or be referred to specialist care.  In order to identify patients with cognitive concerns in electronic medical records, we applied natural language processing  algorithms and compared model performance to a baseline model that used structured diagnosis codes and medication data only. An attention-based deep learning model outperformed the baseline model and other simpler models.",341
" A spelling corrector is an important and ubiquitous pre-processing tool in a wide range of applications, such as word processors, search engines and machine translation systems. %The popularity of mobile devices makes it increasingly crucial since typing on virtual keyboards is more error-prone. Having a surprisingly robust language processing system to denoise the scrambled spellings, humans can relatively easily solve spelling correction . %spelling correction is a relatively easy task for humans, who have a surprisingly robust language processing system  to denoise the scrambled spellings.  However, spelling correction is a challenging task for a machine, because words can be misspelled in various ways, and a machine has difficulties in fully utilizing the contextual information.   Misspellings can be categorized into non-word, which is out-of-vocabulary, and the opposite, real-word misspellings . The dictionary look-up method can detect non-word misspellings, while real-word spelling errors are harder to detect, since these misspellings are in the vocabulary . In this work, we address the stand-alone  spelling correction problem. It only corrects the spelling of each token without introducing new tokens or deleting tokens, so that the original information is maximally preserved for the down-stream tasks. %\textcolor{red}{[The last few sentences of this paragraph is not good, what are you trying to express?]}  We formulate the stand-alone spelling correction as a sequence labeling task and jointly detect and correct misspellings. Inspired by the human language processing system, we propose a novel solution on the following aspects:  We encode both spelling information and global context information in the neural network.  We enhance the real-word correction performance by initializing the model from a pre-trained language model .  We strengthen the model's robustness on unseen non-word misspellings by augmenting the training dataset with a synthetic character-level noise. As a result, our best model  outperforms the previous state-of-the-art result  by  absolute  score.  %As a result, we present a simple but powerful solution to the stand-alone spelling correction by simply fine-tuning a pre-trained LM to jointly detect and correct both non-word and real-word misspellings  as a sequence labeling task.  %We propose a novel solution by using transformer-encoders  to jointly perform detection and correction of misspellings. We extensively explore various training techniques. Our results show that a transformer-encoder-based architecture that encodes both local character-level and global word-level representations yields a strong performance. Specifically, both the combination of word embedding and character embedding or a subword embedding  produce strong models. We further obtain a state-of-the-art model by initializing the weight from a pre-trained language model   and training it on an augmented training dataset with a synthetic character-level noise. \textcolor{red}{[this paragraph need to rewrite. Please summarize your contribution in a coherent story. ]}  %We also explore additional training techniques such as leveraging a pre-trained language model  and adding more noise to the training corpora. Our results show that fine-tuning a pre-trained LM  with a subword embedding  yields a strong model. Furthermore, we obtain a state-of-the-art model by training it on a noisy corpus synthesized by randomly replacing correct words and characters with natural misspellings and random character. Finally, under the condition of no pre-training, we propose a strong model that outperforms the subword model by combining word and character embedding.  \iffalse We summarize our contributions as follows:  \fi  \iffalse \subsection{Stand-alone Spelling Correction}  Formally, given a noisy input sentence , each noisy word  is drawn from a distribution of possible misspellings of the correct word , where  is a vocabulary. We aim to build a corrector  such that , where  is the correct sentence. %\textcolor{red}{[as I said, this definition do not need on section]} \fi     We applied NLP algorithms to identify patients with cognitive concerns in EHR and compared model performance. While the deep learning model's performance was the best, it was only marginally better than the term based NLP models. We posit that deeper representations will be required for more complex tasks requiring syntactical and contextual information such as classifying the stage of cognitive impairment: MCI, mild, moderate or severe dementia. Our gold standard set had a relatively smaller proportion of patients with subjective concerns or mild cognitive impairment , and the overall sample size was small. To address these issues, we plan to implement an active learning loop, starting from querying additional at-risk patients over age 65 and without a dementia related ICD code or medication, and apply the fine-tuned model to derive the probability of having cognitive concerns for these patients. For the edge cases, the notes will be manually reviewed and labeled. To improve the efficiency of this review process, we designed an annotation tool that highlights the sections with regular expression matches or higher attention weights . The new gold-standard data will serve as the basis for the next iteration of the active learning loop to further improve model performance and potentially detect patients with an earlier stage of cognitive decline.  \clearpage         \clearpage   
"," Existing natural language processing systems are vulnerable to noisy inputs resulting from misspellings.  On the contrary, humans can easily infer the corresponding correct words %\textcolor{red}{the semantics of unknown words:the corresponding correct words of misspellings}  from their misspellings and surrounding context. Inspired by this, we address the stand-alone spelling correction problem, which  %\textcolor{red}{[do not know which refers to what, confusing, please rewrite; at the same time, can you brief introduce your novel solution here?]}  only corrects the spelling of each token without additional token insertion or deletion, by utilizing both spelling information and global context representations. We present a simple yet powerful solution that jointly detects and corrects misspellings as a sequence labeling task by fine-turning a pre-trained language model. Our solution outperform the previous state-of-the-art result by $12.8\%$ absolute $F_{0.5}$ score. %Furthermore, we obtain a state-of-the-art model by augmenting the training data with synthetic character-level noise. %We also provide three useful training techniques. Our results show that a transformer-based model that encodes both local character-level and global word-level representations yields a strong performance. Furthermore, a state-of-the-art model is obtained by leveraging pre-trained language model and augmenting the training corpus with synthetic character-level noises. %fine-tuning a pre-trained language model with a subword embedding yields a strong model. Furthermore, we obtain a state-of-the-art model by training it on a noisy corpus synthesized by randomly replacing correct words and characters with common misspellings and random characters. We also propose a strong architecture that combines character and word level encoder without pre-training.",342
" We introduce \diagnnose, an open source library for analysing deep neural networks. The \diagnnose library allows researchers to gain better insights into the internal representations of such networks, providing a broad set of tools of state-of-the-art analysis techniques. The library supports a wide range of model types, with a main focus on NLP architectures based on LSTMs  and Transformers .  Open-source libraries have been quintessential in the progress and democratisation of NLP. Popular packages include HuggingFace's   -- allowing easy access to pre-trained Transformer models; % AllenNLP  -- providing useful abstractions over components in the NLP pipeline,   -- focusing on multitask and transfer learning within NLP;   -- providing a range of feature attribution methods; and   -- a platform for visualising and understanding model behaviour. We contribute to the open-source community by incorporating several \mbox{interpretability} techniques that have not been present in these packages.  Recent years have seen a considerable interest in improving the understanding of how deep neural networks operate . The high-dimensional nature of these models makes it notoriously challenging to untangle their inner dynamics. This has given rise to a novel subfield within AI that focuses on interpretability, providing us a peak inside the black box. \diagnnose aims to unify several of these techniques into one library, allowing interpretability research to be conducted in a more streamlined and accessible manner.  \diagnnose's main focus lies on techniques that aid in uncovering linguistic knowledge that is encoded within a model's representations. The library provides abstractions that allow recurrent models to be investigated in the same way as Transformer models, in a modular fashion. It contains an extensive activation extraction module that allows for the extraction of  model activations on a corpus. The analysis techniques that are currently implemented include:   % <design principles> ?  In this paper we present both an overview of the library, as well as a case study on subject-verb agreement within language models. We first present a brief overview of interpretability within NLP and a background to the analysis techniques that are part of the library . We then provide an overview of \diagnnose and expand briefly on its individual modules . % Next, we provide a more extensive background on the feature attributions that are part of the library . We conclude with a case study on subject-verb agreement, demonstrating several of \diagnnose's features in an experimental setup .     We have presented a multi-task learning framework to enable the training of one universal incremental model with four tasks of disfluency detection, language modelling, part-of-speech tagging and utterance segmentation. We have observed that these tasks produce favorable inductive biases to each other, with utterance segmentation and disfluency detection getting the most benefits. We note that each task's optimal weighting relies heavily on the severity of the noise from the task. We showed that word timing information helps utterance segmentation and disfluency detection in an online setting, and adding new tasks with the exception of language modelling does not have a remarkable negative effect on the incremental metrics.   The results show that our framework can be suitable for online conversational systems, such as conversational agents in the mental health domain. In future work, we intend to analyze the interactions between different tasks as they occur in real time. Monitoring the interaction after each word could help highlight informative moments that contribute more to optimisation of our models. Furthermore, we intend to use raw acoustic features as the input for a strongly time-linear model.   include your own bib file like this:  
"," In this paper we introduce \diagnnose, an open source library for analysing the activations of deep neural networks. \diagnnose contains a wide array of interpretability techniques that provide fundamental insights into the inner workings of neural networks. We demonstrate the functionality of \diagnnose with a case study on subject-verb agreement within language models. \diagnnose is available at \url{https://github.com/i-machine-think/diagnnose}.",343
" % % % %  \subsection{Motivation and Problem} % % % % % \GW{Propaganda can be loosely defined as  ``misleading information that is spread deliberately to deceive and manipulate its recipients'' . }% % % % % % % % % % Various factors of propaganda have been studied in the humanities,  including emotionality of language, biased selection of information and deviation from facts, manipulation of cognition, and more . However, there is no consensus on the decisive factors that tell whether a given article or speech is propagandistic  or not. % % % % %  % In the modern digital world, the influence of propaganda on society has drastically increased.  % Hence, there is also a major increase in computer science, computational linguistics and computational sociology research on analyzing, characterizing and, ultimately, automatically detecting propaganda .  To a first degree, one may think of propaganda as a variation of fake news, and  some works investigate propaganda as a refined type of disinformation . % % % % % % % \GW{While false claims can be an element of propaganda, we think that fake news is merely the tip of the iceberg, and that the persuasive and manipulative nature of propagandistic contents requires deeper approaches.} Classifiers for propaganda detection need to better capture how propaganda is expressed in subtle ways by language style and rhetoric or even demagogic wording. This holds for news as well as social media posts and speeches. In all these cases, correct information may be presented in incomplete form or placed in distorted contexts, along with manipulative phrases, in order to mislead the audience.  % % % % Prior work has mostly looked into news articles  and tweets, and has typically focused on  strongly polarized topics like the 2016 US election and the related Russian Internet Research Agency  affair, the UK Brexit discussion, or political extremism. % % % % % % \LQ{All these approaches consider propaganda detection as a classification task assuming sufficient amounts of labeled in-domain training data.} \LQ{For example, in the ``Hack the News'' datathon challenge, a large number of news articles  and sentences  from such articles were annotated by distant supervision and human judgment, respectively, to train a variety of machine learning methods.} % % The resulting F1 scores on the leaderboard of this benchmark are amazingly high, around 90\%. This may give the impression that propaganda detection is a solved problem. However, most of the positively labeled samples are simple cases of ``loaded language'' with strong linguistic cues independent of the topic. Moreover, the learned classifiers % % benefit from ample training data, which is all but self-guaranteed in general.   % % % % %  % In this paper, we question these prior assumptions, hypothesizing  that propagandistic sources and speakers are sophisticated and creative and will find new forms of deception evading the trained classifiers. % % % \GW{The overall approach is still text classification; the novelty of our approach lies in cross-domain learning, where domains denote different kinds of sources, such as news articles vs.\ social media posts vs.\ public speeches.} We acknowledge that there is often a shortage of perfectly fitting labeled data, and instead tap into alternative sources that require a transfer step. Specifically, we consider speeches and tweets, in addition to news articles, at both article and sentence levels.  % \subsection{Approach and Contribution} Our goal is to build more general propaganda detectors, which can leverage different kinds of data sources. In particular, we tap on political speeches of notorious  propagandists, such as Joseph Goebbels . As it is very difficult  to label speeches and their sentences in a binary manner,  we pursue a pairwise ordinal approach where training data merely ranks samples of a strongly propagandistic speaker against those of a relatively temperate speaker. We investigate to what extent models learned from such data can be transferred to classifying news and tweets, and we also study the inverse direction of learning from news and tweets to cope with speeches.  % % % % % % %  Figure illustrates our framework towards  generalizable propaganda detection that overcomes the bottleneck of directly applicable training labels and instead leverages cross-domain learning. %      % % % %   The salient contributions of this paper are as follows.       \newcommand{\myparagraph}[1]{{#1}.~} \newcommand{\var}[1]{\mbox{#1}} \newcommand{\svar}[1]{\mbox{\scriptsize#1}} \newcommand{\mycaption}[1]{}} \newcommand{\metric}[1]{{\mbox{#1}}} \newcommand{\Pat}{\metric{P}} \newcommand{\Patk}[1]{\mbox{\Pat@}} \newcommand{\Ratk}[1]{\mbox{\metric{R}@}} \newcommand{\gender}{``''} \newcommand{\age}{``''} \newcommand{\credit}{``''} \newcommand{\asset}{``''} \newcommand{\rcity}{``''}     \diagnnose provides essential tools for conducting interpretability research, providing cutting edge analysis techniques such as diagnostic classifiers and feature attributions. The modular design of the library allows complex hypotheses to be tested rapidly, and provides a solid basis for the development of novel interpretability techniques. The library code is open source and welcomes others to contribute: we are eagerly looking forward to collaborate on adding new features to the library.  
","  As news and social media exhibit an increasing amount of manipulative polarized content, detecting such propaganda has received attention as a new task for content analysis. Prior work has focused  % on supervised learning with training data from the same domain. However, as propaganda can be subtle and keeps evolving, manual identification and proper labeling are very demanding. As a consequence, training data is a major bottleneck.   In this paper, we tackle this bottleneck and present an approach to leverage cross-domain learning, based on labeled documents and sentences from news and tweets, as well as political speeches with a clear difference in their degrees of being propagandistic. We devise informative features and build various classifiers for propaganda labeling, using cross-domain learning.  % % % Our experiments demonstrate the usefulness of this approach, and identify difficulties and limitations in various configurations of sources and targets for the transfer step. We further analyze the influence of various features, and characterize salient indicators of propaganda. %",344
" \looseness=-1 Neural machine translation  architectures~ make it difficult for users to specify preferences that could be incorporated more easily in statistical MT models  and have been shown to be useful for interactive machine translation~ and domain adaptation~. Lexical constraints or preferences have previously been incorporated by re-training NMT models with constraints as inputs~ or with constrained beam search that drastically slows down decoding~.  \looseness=-1 In this work, we introduce a translation model that can seamlessly incorporate users' lexical choice preferences without increasing the time and computational cost at decoding time, while being trained on regular MT samples. We apply this model to MT tasks with soft lexical constraints. As illustrated in Figure, when decoding with soft lexical constraints, user preferences for lexical choice in the output language are provided as an additional input sequence of target words in any order. The goal is to let users encode terminology, domain or stylistic preferences in target word usage, without strictly enforcing hard constraints that might hamper NMT's ability to generate fluent outputs.    Our model is an Edit-Based TransfOrmer with Repositioning , which builds on recent progress on non-autoregressive sequence generation~. Specifically, the Levenshtein Transformer~ showed that iteratively refining output sequences via insertions and deletions yields a fast and flexible generation process for MT and automatic post-editing tasks. \modelname replaces the deletion operation with a novel reposition operation to disentangle lexical choice from reordering decisions. As a result, \modelname exploits lexical constraints more effectively and efficiently than the Levenshtein Transformer, as a single reposition operation can subsume a sequence of deletions and insertions. To train \modelname via imitation learning, the reposition operation is defined to preserve the ability to use the Levenshtein edit distance~ as an efficient oracle. We also introduce a dual-path roll-in policy which lets the reposition and deletion models learn to refine their respective outputs more effectively.  \looseness=-1 Experiments on Romanian-English, English-German, and English-Japanese MT show that \modelname achieves comparable or better translation quality with faster decoding speed than the Levenshtein Transformer  on the standard MT tasks and exploit soft lexical constraints better: it achieves significantly better translation quality and matches more constraints with faster decoding speed than the Levenshtein Transformer. It also drastically speeds up decoding compared to lexically constrained decoding algorithms~. Furthermore, results highlight the benefits of soft constraints over hard ones \---\ \modelname with soft constraints achieves translation quality on par or better than both \modelname and Levenshtein Transformer with hard constraints~.        \balance  Although propaganda has become a pervasive challenge in online media,  previous work has mostly treated it    as a variation of fake news, or considered unrealistic settings where the test distribution precisely matches the training data distribution.  In this paper, we present    \GW{a first and preliminary} analysis of the problem of propaganda detection in cross-domain learning settings. This encompasses several novel aspects, ranging from data collection methods, feature computation, designing different classifiers, and the corresponding analysis.  \GW{We tap into a previously unexplored content source: speeches by politicans who are known for different levels of propaganda, using them as collective and relative signals.} On the methodology side, we devise a pairwise ranking method with customized loss functions to improve the classification. The experimental results demonstrate the effectiveness of this method. Furthermore, we conduct a series of experiments to explore the most salient factors for cross-domain generalizability of propaganda detection learning. The observations and analysis reveal insightful patterns and lessons for building  more general propaganda detectors.  \GW{As our datasets are still fairly small,  our findings are of preliminary nature and our methodology is subject to ongoing research. We believe that cross-domain learning is a crucial asset for the important topic of propaganda detection, and hope that our initial results are useful for further research along these lines.}     
"," We introduce an Edit-Based TransfOrmer with Repositioning , which makes sequence generation flexible by seamlessly allowing users to specify preferences in output lexical choice. Building on recent models for non-autoregressive sequence generation, \modelname generates new sequences by iteratively editing hypotheses. It relies on a novel reposition operation designed to disentangle lexical choice from word positioning decisions, while enabling efficient oracles for imitation learning and parallel edits at decoding time. Empirically, \modelname uses soft lexical constraints more effectively than the Levenshtein Transformer while speeding up decoding dramatically compared to constrained beam search. \modelname also achieves comparable or better translation quality with faster decoding speed than the Levenshtein Transformer on standard Romanian-English, English-German, and English-Japanese machine translation tasks.",345
" The goal of relation extraction is to extract relationships between two entities from plain text. Supervised learning methods for relation extraction have been widely used to extract relations based on training labeled data. Distant supervision or crowdsourcing have been used to collect more examples with labels and train the model for relation extraction. However, these methods are limited by the quantity  and quality  of the training data because manually labeling the data is time-consuming and labor-intensive and data labeled by distant-supervision is noisy. To overcome the problem of insufficient high-quality data, few-shot learning have been designed to require only few labeled sentences for training. A lot of research has been done on few-shot learning for computer vision~, and some work also includes few-shot learning methods for relation extraction~. Although these works only require few instances for training, they still do not work in many scenarios in which no training instances are available.  Some work on open information extraction  discovers new relationships in open-domain corpora without labeling the data. OpenIE aims to extract relation phrases directly from text. However, this technique can not effectively select meaningful relation patterns and discard irrelevant information. In addition, this technique can not discover relations if the relation's name does not appear in the given sentence. For example, OpenIE can not identify the relation of the sentence shown in Figure.  To address the aforementioned limitations, we focus on relation extraction in the context of zero-shot learning. Zero-shot learning  is similar to the way humans learn and recognize new concepts. It is a novel learning technique that does not use any exemplars of the unseen categories during training. We propose a zero-shot learning model for relation extraction , which focuses on recognizing new relations that have no corresponding labeled data available for training. ZSLRE is modified on prototypical networks utilizing side  information.  We construct side information from labels and its synonyms, hypernyms of two name entities and keywords from training sentences. The ZSL-based model can recognize new relations based on the side information available for it instead of using a collection of labeled sentences. We incorporate side information to enable our model to extract relations that never appear in the training datasets. We also build an automatic hypernym extraction framework to help us acquire hypernyms of different entities directly from web. Details of side information construction are described in Section Side Information Extraction.     Figure shows an example of how side information can be used for extract relations. Different side information are given for different relations. The query sentence in the example has a relation of classmate\_of, but the word classmate never appears in the sentence. We first get the two name entities Nell Newman and Mayday Parker of the sentence and extract the hypernyms of the name entities person and person based on our proposed hypernym extraction module in Section Hypernyms Extraction. In this example, relationship capital\_of is eliminated because the hypernyms of capital\_of should be location and location. Then we extract the keywords course and school from the query sentence and compare the distance with the keywords in side information box.  In this way, relationship children\_of is eliminated.  To make relation extraction effective in real-world scenarios, we design our models with the ability that it can extract both relations with training instances and the relations without any training instances.  We modify the vanilla prototypical networks to deal with both scenarios and compare the distance between the query sentence and the prototype. If the exponential of the minus distance is above a threshold, we consider the query sentence has a new relation. For new relations extraction, we take the side information embedding from the query sentence and compare the distance of it with the side information embedding of new relations. We conduct different experiments on both a noisy and a clean dataset and adding different percentages of new relations to evaluate the effectiveness and robustness of our proposed model. Besides, we also evaluate our proposed model in supervised learning, few-shot learning and zero-shot learning scenarios and the results show that our proposed model outperforms other existing models in all three scenarios. The contributions of this paper can be summarized as follows:    The rest of this paper is organized as follows. Section Related Work reviews work on supervised relation extraction, open relation extraction and zero-shot learning.  Section Methodology describes the proposed ZSLRE model. Section Experiments presents the experiments and compares the performance of our model with other different models on two public datasets. Section Conclusion and Future Work includes a discussion of conclusion and promising future work.     We proposed a multi-source embedding model, MW2V, aimed at dealing with general language variations.   Each slice obtained from the sources can represent time, geography, or field, among other dimensions.  To demonstrate its feasibility, we applied the MW2V to three newspaper datasets: The New York Times and The Guardian to study temporal variations, and a combination of both datasets to model cultural variations.  We performed an exhaustive evaluation of the method in text analysis tasks finding good quantitative and qualitative results compared to the state of the art, even for the temporal case, when the MW2V does not specifically model the time direction.  Future work includes the analysis of other applications, oriented to the exploitation of datasets, and also the possible implications of the use of a regularization parameter dependent on the slices and words,  instead of a constant one. Moreover, some more insight is needed to answer open questions raised by for this proposal, namely, to try a broader scope of languages and to evaluate its robustness.   
"," Most existing supervised and few-shot learning relation extraction methods have relied on labeled training data. However, in real-world scenarios, there exist many relations for which there is no available training data. We address this issue from the perspective of zero-shot learning  which is similar to the way humans learn and recognize new concepts with no prior knowledge. We propose a zero-shot learning relation extraction  framework, which focuses on recognizing novel relations that have no corresponding labeled data available for training. Our proposed ZSLRE model aims to recognize new relations based on prototypical networks that are modified to utilize side  information. The additional use of side information allows those modified prototype networks to recognize novel relations in addition to recognized previously known relations. We construct side information from labels and their synonyms, hypernyms of name entities, and keywords. We build an automatic hypernym extraction framework to help get hypernyms of various name entities directly from web. We demonstrate using extensive experiments on two public datasets  that our proposed model significantly outperforms state-of-the-art methods on supervised learning, few-shot learning and zero-shot learning tasks. Our experimental results also demonstrate the effectiveness and robustness of our proposed model in a combination scenario. Once accepted for publication, we will publish ZSLRE's source code and datasets to enable reproducibility and encourage further research.",346
"   Unlabeled data has been leveraged in many ways in natural language processing including  back-translation~, self-training~, or language model pre-training which led to improvements in many natural language tasks~. While pre-training has achieved impressive results on tasks where labeled data is limited, improvements in settings with abundant labeled data are modest~ with controlled studies showing a clear trend of diminishing returns as the amount of training data increases~.  In this paper, we focus on noisy channel modeling for text generation tasks, a classical technique from the statistical machine translation literature which had been the workhorse of text generation tasks for decades before the arrival of neural sequence to sequence models~. Unlike pre-training approaches, this approach is very effective irrespective of the amount of labeled data: since a recent revival~, it has been an important part in the winning entries of several high resource language pairs at WMT 2019~, improving over strong ensembles that used 500M back-translated sentences.  At the low resource WAT 2019 machine translation competition, noisy channel modeling was also a key factor for the winning entry~.  Noisy channel modeling turns text generation on the head: instead of modeling an output sequence given an input, Bayes' rule is applied to model the input given the output, via a backward sequence to sequence model which is combined with the prior probability of the output, typically a language model.  This enables the effective use of strong language models trained on large amounts of unlabeled data.  The role of the backward model, or the channel model, is to validate outputs preferred by the language model with respect to the input.  A straightforward way to use language models is to pair them with standard sequence to sequence models~. However, this does not address explaining away effects under which modern neural sequence models still suffer~. As a consequence, models are susceptible to producing fluent outputs that are unrelated to the input~. The noisy channel approach explicitly addresses this via the channel model.   However, a major obstacle to efficient noisy channel modeling is that generating outputs is much slower than decoding from a standard sequence to sequence model. We address this issue by introducing several simple yet highly effective approximations which increase the speed of noisy channel modeling by an order of magnitude to make it practical. This includes smaller channel models as well as scoring only a subset of the channel model vocabulary.  Experiments on WMT English-Romanian translation show that noisy channel modeling can outperform recent pre-training results. Moreover, we show that noisy channel modeling benefits much more from larger beam sizes than strong pre-training methods.       In this paper, we propose ZSLRE, a zero-shot learning relation extraction framework based on modified prototypical networks, to detect new relations that have no corresponding labeled data available for training. ZSLRE utilizes side information constructed from labels, keywords and hypernyms of entities extracted from our proposed automatic hypernym extraction framework. In our experiments, we evaluate our model in supervised learning, few-shot learning and zero-shot learning scenarios, which demonstrates that our proposed ZSLRE outperforms other state-of-art models in all scenarios.  In addition, the results demonstrate the effectiveness and robustness of our proposed model.  In future work, we plan to explore the following directions:  Due to the surprising improvement of performance made by side information embedding, we will explore whether simply learning a good representation for each type of relation can achieve a similar or better performance with other state-of-art works using meta-learning algorithms.  We will explore ways to better embed side information and we will explore using other popular sentence encoders besides CNN for relation extraction.  We will explore zero-shot learning on cross-sentence relation extraction.  
"," Pre-training models on vast quantities of unlabeled data has emerged as an effective approach to improving accuracy on many NLP tasks. On the other hand, traditional machine translation has a long history of leveraging unlabeled data through noisy channel modeling.  The same idea has recently been shown to achieve strong improvements for neural machine translation. Unfortunately, na\""{i}ve noisy channel modeling with modern sequence to sequence models is up to an order of magnitude slower than alternatives.  We address this issue by introducing efficient approximations to make inference with the noisy channel approach as fast as strong ensembles while increasing accuracy. We also show that the noisy channel approach can outperform strong pre-training results by achieving a new state of the art on WMT Romanian-English translation.",347
"  % Sentiment analysis is a text classification technique that analyses a given text and returns the nature of the underlying opinion. Therefore, sentiment analysis is widely used for tasks such as brand monitoring, political research analysis, product analysis, workforce analysis and many more. Sentiment analysis techniques could be fundamentally sub divided into two categories as lexicon-based approach and machine learning based approach. Recently introduced deep learning based sentiment analysis techniques have outperformed the lexicon based approaches and traditional machine learning approaches.  With the development of deep learning techniques such as Convolutional Neural Networks , Recurrent Neural Networks  and language independent features, the domain of sentiment analysis has reported impressive results. Over the years, many of these variants and combinations of deep learning techniques and feature representations have been used for high resourced languages such as English. There also exist certain advancements in sentiment analysis for languages such as Chinese, Arabic, Spanish and some Indic languages.   Sinhala, which is a morphologically rich Indo-Aryan language, has not experienced these advancements due to its insular and under-resourced nature. One of the main challenges is not having large enough annotated corpora. The data set from~\citet{liyanage2018sentiment} is the only publicly  available annotated data set for sentiment analysis. However it includes only 5010 comments extracted from one news source, and contains only POSITIVE and NEGATIVE samples.  %Work of~\citet{medagoda2017framework} is an example of simple solutions for Sinhala sentiment analysis. Under these approaches, rule-based techniques, lexicon based techniques, supervised and semi-supervised machine learning techniques were employed with traditional language dependent features.   The 閾夸购st experiment on using deep learning techniques for Sinhala sentiment analysis was conducted by~\citet{liyanage2018sentiment}. Under this research, basic deep learning techniques such as Long Short-Term Memory  network and CNN were used to categorize news comments as POSITIVE and NEGATIVE. %The LSTM trained with fastText embeddings outperformed traditional machine learning techniques such as Decision Tree, SVM, and Na\""ive Bayes. ~\citet{DemotteSLSTM2020Sinhala} conducted an experiment with the same data set using Sentence-State LSTM , which is a rather advanced technique where the analysis was further improved considering the n-gram features of text with word embeddings.  In this paper, we present a more comprehensive empirical study on the use of deep learning techniques for document-level sentiment analysis for Sinhala with respect to four sentiment categories as POSITIVE, NEGATIVE, NEUTRAL and CONFLICT. The experiments were conducted with the commonly used sequence models such as RNN, LSTM, Bi-LSTM, various improvements on these vanilla models such as stacking and regularization,  as well as more recent ones such as hierarchical attention hybrid neural networks and capsule networks. % for multi-class sentiment analysis using word embeddings as language independent features. These langauge independent features were able to outperform the usage of traditional language dependent features such as part of speech tagging and lexical resources.  ~Furthermore, we present a data set of 15059 comments, annotated with these four classes to be used for sentiment analysis, based on Sinhala news comments extracted from online newspapers namely GossipLanka and Lankadeepa. This is the only publicly available multi-class, multi-source dataset for Sinhala sentiment analysis.  Our code implementation, word embedding models, and annotated data set are publicly available.       %    We introduced a number of approximations which greatly speed up noisy channel modeling for neural sequence to sequence models.  This includes using channel models which are a fraction of the size of commonly used sequence to sequence models, pruning most of the channel model output vocabulary, and reducing the number of beam candidates scored by the channel model.  Our approximations are simple, yet, highly effective and enable comparable inference speed to ensembles of direct models while delivering higher accuracy. Our experiments show that noisy channel modeling can outperform pre-training approaches by being able to better exploit wider beams. Moreover, this is achieved while using a smaller amount of monolingual data.       \clearpage     
"," Due to the high impact of the fast-evolving fields of machine learning and deep learning, Natural Language Processing  tasks have further obtained comprehensive performances for highly resourced languages such as English and Chinese. However Sinhala, which is an under-resourced language with a rich morphology, has not experienced these advancements. For sentiment analysis, there exists only two previous research with deep learning approaches, which focused only on document-level sentiment analysis for the binary case. They experimented with only three types of deep learning models. In contrast, this paper presents a much comprehensive study on the use of standard sequence models such as RNN, LSTM, Bi-LSTM, as well as more recent state-of-the-art models such as  hierarchical attention hybrid neural networks, and capsule networks. Classification is done at document-level but with more granularity by considering POSITIVE, NEGATIVE, NEUTRAL, and CONFLICT classes. A data set of 15059 Sinhala news comments, annotated with these four classes and a corpus consists of 9.48 million tokens are publicly released. This is the largest sentiment annotated data set for Sinhala so far.   % In addition to that,  was extracted from both comments and articles of online newspapers. %Furthermore, the language-independent features such as Word2Vec and fastText were experimented for novel deep learning techniques which clearly indicate the importance of word embedding techniques for NLP tasks including sentiment analysis for Sinhala as a low resource language. % Due to the high impact of the fast-evolving field of machine learning and deep learning, the Natural Language Processing  tasks have further obtained comprehensive and prominent performances over the past few decades. Different variations and combinations of deep learning techniques have been employed for NLP tasks in general. These experiments illustrated highly improved performances with respect to the traditional rule-based and statistical machine learning techniques. These advancements were mainly impacted towards the development of popular languages such as English and Chinese. However, Sinhala which is an under-resourced language with rich morphology, have not experienced these advancements due to fewer resources for NLP tasks. For sentiment analysis, there exist only two previous research with deep learning approaches, which also conducted with less granularity while giving sub optimality with respect to recent advancements in deep learning techniques. In this paper, we present the use of state-of-the-art deep learning approaches such as RNN, LSTM, Bi-LSTM, Hierarchical Attention Hybrid Neural Networks, and capsule networks for multi-class sentiment analysis for Sinhala news comments while considering more granularity. Under this research, we present the multi-class annotated data set which consists of Sinhala news comments extracted from online newspapers. Furthermore, the language-independent features such as word2Vec and fastText were experimented for novel deep learning techniques which clearly indicates the importance of word embedding techniques for NLP tasks including sentiment analysis.",348
" % The very first letter is a 2 line initial drop letter followed % by the rest of the first word in caps. % % form to use if the first word consists of a single letter: % \IAENGPARstart{A}{demo} file is .... % % form to use if you need the single drop letter followed by % normal text : % \IAENGPARstart{A}{}demo file is .... % % Some journals put the first two words in caps: % \IAENGPARstart{T}{his demo} file is .... % % Here we have the typical use of a ""T"" for an initial drop letter % and ""HIS"" in caps to complete the first word.  \IAENGPARstart{T}{he} Neural Machine Translation   has been used to model state-of-the-art translation systems for many high-resource languages . For many language pairs though, the amount and/or quality of parallel data is not enough to train an NMT model whose accuracy can reach an acceptable standard . This category of language pairs is known as low resource. Many works have explored how to use of the easier-to-get monolingual data to improve the quality of translation models in this category of languages -- and even high resource languages -- .  The back-translation has so far been one of the most successful methods , involving the use of the translations of the target language monolingual data to increase the amount of the training data . The additional parallel data consists of authentic sentences in the target language and their translations -- synthetic sentences in the source language -- generated using a reverse  model that is trained on the available parallel data -- see the procedure in Algorithm 1. The approach has proven to be successful at improving the quality of translations in high, middle and low resourced languages . Many studies have shown that the quality of the backward system influences the performance of the ultimate NMT model . In low resource conditions, the available parallel data may not be able to train a standard backward model and the quality of the additional data generated using this model may hurt the quality of the final model. Despite this, the aim of standard back-translation has always been to improve the performance of the target NMT model by providing sufficient training data.  Some previous works have proposed various methods to improve the performance of the backward model during training. These methods include iterative back-translation , transfer learning , self-training  and the training of a bi-directional translation model for both backward and forward translations . Others have tried to mask the deficiencies of the backward model either during inference through generating multiple translations of the same target sentence using sampling to average-out the errors in individual translations  and noising the output of beam search ; or reducing the effects of the errors in the synthetic data when training the forward model through methods such as tagged back-translation  and pre-training and fine-tuning .  We present a hybrid approach that utilizes the monolingual target data to improve both the forward and backward models in back-translation. In this approach, we used the synthetic data to enhance the backward model through self-learning and the standard back-translation for improving the forward model. The approach was preliminary investigated in  and it was shown to achieve positive results. Earlier use of stand-alone self-training in machine translation proposed extra methods of either using quality estimation  or freezing of the decoder weights  when training on the synthetic side of the training data. It was suggested that the mistakes in the synthetic data will hurt the performance of the self-trained model . Instead,  showed that self-training is capable of improving the quality of the backward model even without using either of the specialized approaches. It was shown that using all of the synthetic data generated by the backward model to help in re-training the backward model improved its performance. The work, though, did not show the benefits or otherwise of using any of the specialized approach in cleaning the data, especially in low resource languages. It also did not investigate if the model can continue to learn from its output through iterating the self-learning process.   \end{table}  This work, therefore, investigates the effects of synthetic data cleaning using automatic quality estimation when training the backward model. We observed that while the approach may improve the backward model, selecting only a subset of the synthetic data may result in a superior but less generic model. We then investigated the use of iterative self-training with quality estimation as proposed in , enabling the backward model to be trained on all the monolingual data. For low resource languages, readily available quality estimation systems or the data to train such systems may not be available. This may limit the implementation of the approach.  We, therefore, proposed a novel iterative approach that relies only on all the available monolingual target data to improve the backward model before finally generating a much improved synthetic data for the forward model's training. Experimental results show that our approach is superior over the standard back-translation and the approach proposed in ; and that our iterative approach is superior to the iterative back-translation while also requiring less number of models to be trained.  We thus make the following contributions in this paper: \renewcommand{\labelitemi}{\textbullet}   The remainder of this paper is organized as follows: In Section , we reviewed the related works. We presented the proposed methods in Section . We reported the experiments and results in Section . We discussed the results and findings of the research work in Sections  and  respectively and, finally, the paper was concluded and directions for future work were proposed in Section .       For experiments which were conducted to identify effect of punctuation marks and dimension of word embeddings towards the sentiment analysis task, different preprocessing techniques, word embedding models, and several neural network setups were used.    For these experiments, the data-set was splitted into train and validation sets, with a ratio of .    First, different preprocessing techniques were evaluated for a multi-level sentiment analysis task in Sinhala language with baseline models. For that, an analysis was conducted with punctuation marks, without any punctuation marks and without punctuation marks except question mark.    Next, Different dimensions for both Word2vec and fastText models were experimented with baseline LSTM model and identified that fastText with 300 dimensions could beat other word embedding models as per results in Table. Therefore, The word embedding model of fastText, and dimension size of 300 were fixed for our succeeding experiments.     The experiments which were conducted with different baseline models to identify best models for further improvements suggested that BiLSTM was the optimal architecture as the primary baseline. As per results in Table with 10-fold cross validation, BiLSTM achieved the best weighted accuracy of 63.81\  and a weighted F1 score of 57.71\ , beating Vanilla RNN, LSTM, and GRU. Therefore LSTM and BiLSTM were selected for further improvements. After that, two strategies were followed to improve the selected approaches. First strategy is combining CNN with baseline models. Even though it is expected to increase the weighted accuracy and F1 score of sentiment analysis process by following the improved model architecture based on CNN, the results do not suggest a noticeable enhancement. One reason might be not having enough data to learn trainable parameters as a complex model due to the CNN integration. Results of these models are listed in Table along with results from other improvements to the baseline models.    As the final improvement to the baseline approaches stacking was implemented. As per results in Table with 10-fold cross validation, 'Stacked BiLSTM 3' model reached a weighted accuracy of 63.13\  and weighted F1 socre of 59.42\  by outperforming all other approaches. This could be justified as the ability of the stacked BiLSTM to capture the context level information in both left and right direction while considering substantial amount of neural representation for language modeling based on stacking strategy.    The capsule-B architecture went beyond all the other experimented models producing weighted accuracy of 63.23\  and weighted F1-score of 59.11\  with 10-fold cross validation. This observation could be elaborated based on the motivation behind the capsule strategy to represent the neural architecture based on vectors which further improve language representation considering the exact order or pose of the information. Furthermore, capsule-B outperformed capsule-A due to its sophisticated architecture which is designed to capture more n-grams features compared to capsule-A. The HAHNN does not illustrate greater performance as expected. This could be due to the shorter length of comments to learn deeper neural representation with the attention mechanism.  also employed under the HAHNN.  The weighted accuracy of each experiment was bounded below the value of 65\  as per the inter-annotator agreement value. This is a direct result of the high volume of noise in the dataset. As illustrated in Table, the CONFLICT and the NEUTRAL classes seem to be considerably mis-classified as NEGATIVE comments, due to the impact of a large number of NEGATIVE comments with respect to the number of CONFLICT and NEUTRAL comments in the training set. Figure shows few comments where the model was confused while classifying. The first example illustrates a comment that is negatively classified but truly a CONFLICT comment. When considering the interpretation of the comment, the sentence includes two negative sentences with a positive sentence, which indicates some bias towards the NEGATIVE sentiment. The second and third comments include NEGATIVE and NEUTRAL comments, which are classified as POSITIVE and CONFLICT, respectively.     The observation of the second example could be justified as the effect of the positive word ``{\iskool 鍠藉懅绌柧鎺勭П鍠惧啛绋搣'' , which greatly affects the final sentiment of comment, than the negative word ``{\iskool 鍠借剢绌╁柧鏀'' . The third example has both  negative and positive words ``{\iskool 鍠借啅鍔ㄥ柧鎷''  and ``{\iskool 鍠借剢绐夊柦绉界獕鍠芥磥绐倉'' , respectively. Therefore the comment is classified as CONFLICT, even though the overall sentiment of the comment is neutral.             }      -    m鑶 vidiya宄佺挦 par澧╧宄侇枾宄佸樅 vala宄佺挦 ad鑶﹍a v鑶﹔t鑶 pram鑶ヾav澧╩a tulin v蹇檙adikaru nid蹇檒l鑶 innav鑶. m鑶縱鑶 tamayi pra鑹a adhikara宄佸樅ya宄佺挦 t澧╪duvak ganna b蹇檙i. mun宄佺挦 da宀ｅ扯vam d澧╩a it鑶 hoda t澧╪duvak    \\     {\iskool 鍠借剢绌╁柧 鍠藉懅绌柧鎺勭П鍠惧啛绋 鍠借啅渚楀柧鏂风┈鍠惧ɑ绌柦浜ㄧ獋.} - pavu ahi宄佷够aka manussay鑶. \\      {\iskool 鍠借剢绌靛柦绉界獕鍠戒酣渚楀柧濞昏懀鍠 鍠芥盀绐夊柦浜ㄤ緱鍠惧ɑ渚 鍠筋垥绐撳柦浜ㄧ〒鍠 鍠芥洉渚楀柧鎴夐櫋 鍠界紪闄″柧 鍠芥柗绌柧婧归櫋 鍠芥盀绐夊柦浜ㄤ緱鍠惧ɑ渚.  鍠芥柗钁ｅ柦 鍠藉璁 鍠借啅鍔ㄥ柧 鍠界紪绐夊柧鍐熺獋 鍠藉懅娲炲柧 鍠筋垥绐呭柦姘炵┑鍠芥盀绐 鍠藉绌柧濞荤┈鍠界Ы绌 鍠借剢绐傚柦绉界獢 鍠惧啛绐撳柦缂栫 鍠借剢绐夊柦绉界獕鍠芥磥绐 鍠藉渚楀柧濞讳緱鍠惧柧.} - priyanta宄佺挦 kiyanna deyak 鑹抧鐗祄a nam ohoma kiyanna.otana i宀ｅ硽 madi nis鑶 api d蹇檏k鑶 issaraha p鑶﹔鑶 senaga piril鑶 innav鑶.    \\      
"," %\boldmath Many language pairs are low resource, meaning the amount and/or quality of available parallel data is not sufficient to train a neural machine translation  model which can reach an acceptable standard of accuracy. Many works have explored using the readily available monolingual data in either or both of the languages to improve the standard of translation models in low, and even high, resource languages. One of the most successful of such works is the back-translation that utilizes the translations of the target language monolingual data to increase the amount of the training data. The quality of the backward model which is trained on the available parallel data has been shown to determine the performance of the back-translation approach. Despite this, only the forward model is improved on the monolingual target data in standard back-translation. A previous study proposed an iterative back-translation approach for improving both models over several iterations. But unlike in the traditional back-translation, it relied on both the target and source monolingual data. This work, therefore, proposes a novel approach that enables both the backward and forward models to benefit from the monolingual target data through a hybrid of self-learning and back-translation respectively. Experimental results have shown the superiority of the proposed approach over the traditional back-translation method on English-German low resource neural machine translation. We also proposed an iterative self-learning approach that outperforms the iterative back-translation while also relying only on the monolingual target data and require the training of less models.",349
"   End-to-end techniques for automatic speech recognition , most notably sequence-to-sequence models with attention  and Recurrent Neural Network Transducer  , are becoming increasingly popular. Compared to the traditional hybrid system based on Hidden Markov Model and Deep Neural Network  with individually-trained components, all parts of an end-to-end model are optimized jointly, which often leads to better performance on recognition tasks with sufficient training data and low training-testing mismatch. End-to-end systems are simpler to train; they typically do not require pronunciation lexicons, decision trees, initial bootstrapping, nor forced alignment. End-to-end models are also more suitable for on-device use cases due to the lack of external language models  or decoding graphs, whose sizes can be prohibitively large in hybrid setups because of large vocabulary support, complex LMs, and context-dependent decision trees.  End-to-end systems do have limitations, however. Their end-to-end nature leads to a lack of composability, such as that between acoustic, language, and pronunciation models in hybrid setups. This lack of composability in turn leads to challenges in personalization, which traditionally involves on-the-fly modification of external LMs  to add, boost, and penalize certain words or phrases. Previous work in end-to-end ASR addressed this issue by incorporating external LMs during beam search , with special modifications to handle the model's spiky output . A fundamental limitation of shallow fusion is that it relies on late combination, hence the model needs to have the potential to produce the correct output in the first place without access to biasing information. Another class of method  adds an attention-based  or simple  biasing module over contextual phrases to provide additional signal to the decoder component of end-to-end models. While promising, these methods were shown to have problems scaling to large and highly confusable biasing lists.  A closely related challenge of ASR personalization is entity recognition, since in many cases biasing items are entity names. Rare name recognition presents significant challenges to end-to-end models because of two main reasons. First, the output units of end-to-end models are typically graphemes or WordPieces , both of which do not work well when the spelling of a word does not correspond to how it is pronounced . Second, rare names often decompose into target sequences that are not seen enough in training, making them difficult to recognize correctly. By contrast, both problems are alleviated in hybrid systems due to the use of phonetic lexicons and/or clustered context-dependent acoustic targets. Popular solutions to this problem include upsampling entity-heavy data or generating synthetic training data with names using text-to-speech  . While this method alleviates the data sparsity issue, it does not address the underlying problems of under-trained targets and unconventional spelling of rare names.   In this work, we propose several novel techniques to address both challenges and further improve RNN-T personalization. To alleviate the problem of under-trained targets and recognition of unconventional names, we adopt on-the-fly sub-word regularization  to increase WordPiece coverage during training, perform pre-training  and multi-task learning   to strengthen the encoder, and leverage grapheme-to-grapheme   to generate alternative graphemic pronunciations for names. To address the limitation of shallow fusion relying on late combination, we introduce deep personalized LM  fusion to influence the model's predictions earlier. We show that the combination of these techniques results in 15.4\%--34.5\% relative Word Error Rate  improvement on top of a strong RNN-T baseline which leverages shallow fusion and TTS augmentation. Our final model is also competitive with a hybrid system that has significantly larger disk and memory footprint.      Neural machine translation systems relies on a huge amount of parallel data to train standard, state-of-the-art translation models. For low resource languages, these models perform woefully when deployed. Back-translation is an approach that was introduced in NMT by  to enable the generation of additional data for improving translation in both low and high resource languages. Subsequent studies have shown that the approach require other special methods to reach an acceptable standard for translation quality especially in low resource set-ups . In these set-ups, the backward model is trained on a scarce data and, therefore, the quality of generated additional data may not be enough to substantially improve the target translation model. The target of back-translation is always to improve the performance of the forward model on the available monolingual data and not the intermediary backward model. But the standard of the forward model relies on the authentic data and the ability of the backward model to generate a good enough additional training data.  } & \multicolumn{4}{c|}{Sample size} \\ \cline{3-6} 	& & 50 & 100 & 500 & 1000 \\ \hline 	backward\_ft is better than baseline & 11.06 &100\ & 100\      & 100\     & 100\   \\ \hline 	backward\_ft + QE is better than baseline & 13.41 &100\ & 100\      & 100\     & 100\  \\ \hline 	backward\_ibt is better than baseline & 13.64 &100\ & 100\      & 100\     & 100\  \\ \hline 	backward\_isl + QE is better than baseline & 13.80 &100\ & 100\      & 100\     & 100\  \\ \hline 	backward\_isl better than baseline & 14.02 &100\ & 100\      & 100\     & 100\  \\ \hline 	backward\_ft + QE is better than backward\_ft & 2.35 &100\ & 100\      & 100\     & 100\  \\ \hline 	backward\_ibt is better than backward\_ft & 2.58 &100\ & 100\      & 100\     & 100\  \\ \hline 	backward\_isl + QE is better than backward\_ft & 2.74 &100\ & 100\      & 100\     & 100\  \\ \hline 	backward\_isl better than backward\_ft & 2.96 &100\ & 100\      & 100\     & 100\  \\ \hline 	backward\_ibt is better than backward\_ft + QE & 0.23 &94\ & 94\       & 96\      & 94.4\  \\ \hline 	backward\_isl + QE is better than backward\_ft + QE & 0.39 &100\ & 100\      & 100\     & 99.8\  \\ \hline 	backward\_isl better than backward\_ft + QE & 0.61 &100\ & 100\     & 100\    & 100\  \\ \hline 	backward\_isl + QE is better than backward\_ibt & 0.16 &86\ & 89\      & 88.8\     & 87.4\  \\ \hline 	backward\_isl better than backward\_ibt & 0.38&100\ & 100\     & 99.6\    & 99.7\  \\ \hline 	backward\_isl better than backward\_isl + QE & 0.22 &94\ & 92\     & 93.4\    & 94.9\  \\ \hline       \arrayrulecolor{black}   This work, therefore, presents a new variant of the back-translation that incorporates the self-learning approach, through forward translation, to use the same target-side monolingual data to improve not only the forward model, but the backward model also. The back-translation is used ultimately to improve the forward model but only after using self-training to enhance the standard of the backward model.  } & \multicolumn{4}{c|}{Sample size} \\ \cline{3-6} 	& & 50 & 100 & 500 & 1000 \\ \hline 	standard back-translation is better than baseline & 7.89 &100\ & 100\      & 100\     & 100\   \\ \hline 	self-learning enhanced back-translation is better than baseline & 8.96 &100\  &100\      & 100\     & 100\  \\ \hline 	self-learning with quality estimation enhanced back-translation is better than baseline & 9.44 &100\ & 100\       & 100\      & 100\  \\ \hline 	iterative back-translation is better than baseline & 9.19 &100\ & 100\      & 100\     & 100\  \\ \hline 	iterative self-learning with quality estimation enhanced back-translation better than baseline & 9.10 &100\ & 100\     & 100\    & 100\  \\ \hline 	iterative self-learning enhanced back-translation better than baseline & 9.38 &100\ & 100\     & 100\    & 100\  \\ \hline 	 	self-learning enhanced back-translation is better than standard back-translation & 1.08 &100\ & 100\      & 100\     & 100\  \\ \hline 	self-learning with quality estimation enhanced back-translation is better than standard back-translation & 1.56 &100\ & 100\       & 100\      & 100\  \\ \hline 	iterative back-translation is better than standard back-translation & 1.31 &100\ & 100\      & 100\     & 100\  \\ \hline 	iterative self-learning with quality estimation enhanced back-translation better than standard back-translation & 1.22 &100\ & 100\     & 100\    & 100\  \\ \hline 	iterative self-learning enhanced back-translation better than standard back-translation & 1.49 &100\ & 100\     & 100\    & 100\  \\ \hline 	 	self-learning with quality estimation enhanced back-translation is better than self-learning enhanced back-translation & 0.48 &100\ & 100\       & 100\      & 100\  \\ \hline 	iterative back-translation is better than self-learning enhanced back-translation & 0.23 &96\ & 97\      & 95.6\     & 95.7\  \\ \hline 	iterative self-learning with quality estimation enhanced back-translation better than self-learning enhanced back-translation & 0.14 &86\ & 86\     & 85\    & 86.4\  \\ \hline 	iterative self-learning enhanced back-translation better than self-learning enhanced back-translation & 0.42 &100\ & 100\     & 100\    & 100\  \\ \hline 	 	iterative back-translation better than iterative self-learning with quality estimation enhanced back-translation & 0.09 &78\ & 77\     & 74\    & 74.9\  \\ \hline 	iterative self-learning enhanced back-translation better than iterative self-learning with quality estimation enhanced back-translation & 0.28 &98\ & 99\     & 98.2\    & 99.1\  \\ \hline 	self-learning with quality estimation enhanced back-translation better than iterative self-learning with quality estimation enhanced back-translation & 0.34 &100\ & 100\  & 99.2\  & 99.9\  \\ \hline 	 	iterative self-learning enhanced back-translation better than iterative back-translation & 0.19 &96\ & 92\     & 91\    & 93.5\  \\ \hline 	self-learning with quality estimation enhanced back-translation is better than iterative back-translation & 0.25 &100\ & 98\  & 96.2\     & 97.6\  \\ \hline 	 	self-learning with quality estimation enhanced back-translation better than iterative self-learning enhanced back-translation & 0.06 &60\ & 69\  & 66\  & 67.8\  \\ \hline       \arrayrulecolor{black}   In implementing the self-learning approach, we investigated various methods namely: self-training and iterative self-training each with and without quality estimation. We implemented all the methods using the pre-training and fine-tuning strategies of  to enable each model differentiate between synthetic and authentic data during training, as this has been shown to improve the performance of models trained in such settings . All performance scores obtained through experiments have been shown to be statistically significant using the paired bootstrap resampling of  as implemented in  -- see Tables  and .  The work was evaluated on the low resource IWSLT'14 English-German neural machine translation. We observed that even though the proposed self-trained backward method  outperformed the standard back-translation's backward model without using any of quality estimation or freezing of parameters in the decoder as proposed in  and  respectively, selecting and using the best synthetic data for self-training further improves its performance. This shows that although an improved performance was achieved, the full potential of the proposed method may not be realized when using vanilla self-training because the noise in the synthetic data will degrade the decoder's performance.  We extended the positive results that were obtained using self-learning by determining the benefit or otherwise of selecting only a fraction of the synthetic data for self-training using a quality estimation system. Experimental results indicated that not only was the result not affected by the reduction in training data, but that the performance was improved significantly, achieving +2.35 BLEU. We showed that not all of the synthetic data is required -- quantity -- but that the more beneficial additional data -- quality -- is just enough to train a superior backward model. Also, when the backward model -- or any other model -- is able to differentiate between the synthetic and authentic parallel data during training, then the effects of the lack of quality in the synthetic data becomes less problematic but the more the qualitative the synthetic data is, the better the model trained.  We also implemented an iterative approach that continued to enhance the quality of the backward model on the synthetic data. Each improved backward model was used to generate a synthetic training data for training the next improved model. The approach achieved a significant +2.96 BLEU improvement over the one-time usage of the self-training on the IWSLT'14 En-De test set. We compared the iterative self-learning approach to other iterative approaches in  and  and our method was shown to be superior while also requiring less number of models -- \-less number of models in any \ iterations -- to be trained than that needed in the approach of . Also, unlike in , we showed that without data selection through quality estimation, we achieved an improved model over the baseline.  While  suggests that models trained on synthetic data only can reach a performance similar that of models trained on the authentic data only, we showed that a model trained on a sufficient number of qualitative synthetic sentences can achieve a better performance than that of a model trained on low resource authentic parallel data.  claimed that the ratio of synthetic to parallel data affects the translation model more than the quality of the backward model. This, they claimed, is because the model then tends to learn more from the synthetic data which often contain more noise. Instead, we claim that the quality of the backward model affects the performance of the approach more than the ratio because when the model is able to generate synthetic data that is close to or the same quality as human translation, the ratio of synthetic data to authentic data does not matter because the two data become more inseparable.  The iterative self-learning enhanced back-translation approach was proposed to avoid being so much reliant on the availability or reliability, thereof, of the quality estimation systems for the successful implementation of the previously proposed approaches. We determined that without such systems reliably available, retraining the backward model over some iterations is capable of achieving the same or even superior performance to the other methods.  The forward models' performances were shown to reflect the improvements in the backward models. We achieved an improved +0.48 BLEU over the performance of self-trained enhanced back-translation method. The proposed approaches achieved better performances than all the previous methods but a similar quality was observed between them. This is as expected because the performances of the backward models were not far off from each other.  In Table , we showed a sample translation from English to German. Our proposed models were able to produce exact translations to most  of the referenced translation: ''... wir 3 milliarden stunden pro woche mit online-spielen'' and the other part where the translation generated was different, the meaning was the same: ''derzeit'' 'vs' ''jetzt''. The self-trained models were able to generate exact translation to most of the referenced text but could only specify the adverb ''now'' instead of the referenced ''right now''. For the forward model, the effects of the improved backward models were observed in their performances. In Table , we also translated a given German source text to English. The performances of the last two models , and especially the last model, seemed to be more superior than the rest. The pre-training and fine-tuning approach has shown to be the better approach when applying the method we proposed in this work. As proposed in , we found that pre-training first on the synthetic data and thereafter fine-tuning the model on the authentic data is the best strategy.        \section{Conclusion \& Future work}   This is the first work that proposed the iterative utilization of the monolingual target data using a joint backward and forward translation to improve the neural machine translation on low resource languages, to the best of our knowledge. It is also the first work that combines quality estimation and self-learning to improve low resource back-translation in NMT. This category of languages have been shown to straggle their high resource counterparts even when the same methods are applied to improve their quality. The back-translation approach that has shown tremendous potential for improving translation performance in high resource languages, has shown improved but less than desirable performance in low resource languages. This has been shown to be as a result of the lack in quality of the backward model.  In this work, we applied a joint backward and forward translation to utilize the monolingual data in the target language to train better neural machine translation systems especially in low resource languages. We proposed a variety of techniques for implementing the approach based on the availability or otherwise of another supporting system -- the quality estimation system. The self-learning was used to improve the performance of the backward model. Experimental results obtained on low resource English-German have shown that the approach is superior to the widely successful back-translation approach. The approach is not only straightforward but also easy to implement on any low resource language translation to train a better model capable of attaining a more acceptable standard of translation.  We showed that the approach is capable of enhancing the standard of the model even without using specialized the quality estimation data selection method. We also showed that when the backward model is able to differentiate between the synthetic and authentic data, its quality gets better. As shown in the training of the forward models, this is also true for all models that are trained on the synthetic and authentic data. The self-training approach was shown to perform better when quality estimation is used to extract the best translations and used to retrain the generating backward model. We also extended the self-training approach to determine whether the approach can continue to benefit the backward model over several iterations. We presented a simplified iterative approach that reduces both the number of models required and the time taken to achieve the number of iterations in previous works. We showed that it is possible to rely only on large amounts of synthetic data that gets improved iteratively especially in low resource conditions than strictly relying on the quality of fewer training data. Our work relies only on the target monolingual data as required in the traditional back-translation approach unlike the target and source monolingual data in the iterative back-translation approach. We showed that the approach works well on a low resource neural machine translation.  For future work, we aim to determine the appropriate sentences to be considered fit for self-learning for each iteration especially using data selection as an alternative to quality estimation. We also intend to apply the approach on high resource languages.     Can use something like this to put references on a page   by themselves when using endfloat and the captionsoff option. \ifCLASSOPTIONcaptionsoff    \fi      trigger a  just before the given reference   number - used to balance the columns on the last page   adjust value as needed - may need to be readjusted if   the document is modified later  \IAENGtriggeratref{8}   The ""triggered"" command can be changed if desired:  \IAENGtriggercmd{\enlargethispage{-5in}}    references section    can use a bibliography generated by BibTeX as a .bbl file   BibTeX documentation can be easily obtained at:   http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/   The IAENGtran BibTeX style support page is at:   http://www.michaelshell.org/tex/IAENGtran/bibtex/     argument is your BibTeX string definitions and bibliography database       <OR> manually copy in the resultant .bbl file   set second argument of \begin to the number of references           >>>>>>>>>>>>>>>>>>>>>> Bibliography <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<                     biography section     If you have an EPS/PDF photo  extra braces are   needed around the contents of the optional argument to biography to prevent   the LaTeX parser from getting confused when it sees the complicated   \includegraphics command within an optional argument.       if you will not have a photo at all:      insert where needed to balance the two columns on the last page with   biographies         You can push biographies down or up by placing   a \vfill before or after them. The appropriate   use of \vfill depends on what kind of text is   on the last page and whether or not the columns   are being equalized.   \vfill    Can be used to pull up biographies so that the bottom of the last one   is flush with the other column.  \enlargethispage{-5in}      that's all folks 
"," End-to-end models in general, and Recurrent Neural Network Transducer  in particular, have gained significant traction in the automatic speech recognition community in the last few years due to their simplicity, compactness, and excellent performance on generic transcription tasks. However, these models are more challenging to personalize compared to traditional hybrid systems due to the lack of external language models and difficulties in recognizing rare long-tail words, specifically entity names. In this work, we present novel techniques to improve RNN-T's ability to model rare WordPieces, infuse extra information into the encoder, enable the use of alternative graphemic pronunciations, and perform deep fusion with personalized language models for more robust biasing. We show that these combined techniques result in 15.4\%--34.5\% relative Word Error Rate improvement compared to a strong RNN-T baseline which uses shallow fusion and text-to-speech augmentation. Our work helps push the boundary of RNN-T personalization and close the gap with hybrid systems on use cases where biasing and entity recognition are crucial.",350
"  Our goal is to improve information extraction from business documents and contribute to the field of automated document processing. This work leads to a higher success metric and enables less manual work regarding data entry and/or annotation in the industry.  To put the work in context and define the terms closely let's briefly recall the definition of the task, the motivation and add more details.  \paragraph{Information extraction task}  The general problem of information extraction is not a new problem . A survey on information extraction methods  defines the task as: ``Information Extraction starts with a collection of texts, then transforms them into information that is more readily digested and analyzed. It isolates relevant text fragments, extracts relevant information from the fragments, and then pieces together the targeted information in a coherent framework''.  The relevant collection of texts for this study are the texts in business documents such as invoices, pro forma invoices and debit notes. The targeted information is a classification of the texts that helps in automating various business processes 閳 such as automated payment for invoices.  \paragraph{Motivation}  The typical user of our method would be any company medium-sized and bigger because, at some point, companies start to spend significant time on document processing. Details are harder to find in referenced and peer-reviewed works since the companies keep their spending information secret. Approximations from unofficial  sources as  and  lead to an estimate of how a success metric translates to company savings. A typical medium-sized company can have approximately  invoices per month and even just  improvement roughly translates to more than  dollars saving monthly and scales with the company size. Note that this is just a heuristics and thus we do not define the metric exactly.  \paragraph{Details and overview}  As stated, we will focus on business documents. The explicit category of the documents varies. Existing works on information extraction  define these as ``visually rich documents'', ``structured'', or ``semi-structured''.   We will use the name ``structured documents'' throughout this work since the structure of the documents is clear and understandable to a human working in relevant fields, even though the specific structure varies. Moreover, the documents are machine-readable up to the detail of individual words and pictures  on a page, but for a machine, they are not ``understandable'' with respect to the goal of important information extraction.  It is important to classify all of the information that is needed in the financial/accounting industry, for the ``users'' of the documents. For example, the payment details, amount to be paid, issuer information etc. The input is a document's page and the goal is to identify and output all of the words and entities in the document that are considered important, along with their respective classifications.  One example of an input invoice and output extraction can be seen in \prettyref{fig:Example}. As you can see, the documents are not easily understandable inputs. An example of trivial inputs would be an XML document that has the desired target classes incorporated in a machine-readable way.  With this study, we aim to expand previous work , in which we have already shown that neural networks can succeed in the task of extracting important information and even identifying whole, highly specific tables.  As argued before, every improvement matters and so in this work, the focus is on improving the metrics by selecting relevant techniques from the deep learning field. A classical heuristic way to generally improve a target metric is to provide more relevant information to the network. Previously we have exhausted all the information present in a single invoice and so we will focus now on techniques related to ``similarity''. Existing works on similarity are presented in \prettyref{subsec:Inspiration} and our use and notion of similarity is defined here in \prettyref{subsec:The-learning-framework}. In short, we will present a similar annotated document as another input. More details on differences from the previous work are described in \prettyref{subsec:The-differences-to-prev}.  Since the idea of providing more information is fundamental even for simpler templating techniques , we need to stress that, due to the nature of our dataset , our problem cannot be solved by using templates. To prove this statement, a reasonable template-based baseline will be presented  and evaluated .  The research question will focus on a ``similarity'' based mechanism with various model implementations, and whether they can improve an existing solution . The hypothesis is that we are able to create at least one model that can significantly improve the results. Moreover, since the presented mechanism is theoretically applicable beyond the scope of document processing, this work can contribute to a broader audience.  Ultimately we will present a model and its source code  that outperforms the previous state-of-art results. An anonymized version of the dataset is also included as an open-source resource and should be a notable contribution since its size is greater than any other similar dataset known to date.      \subsection{Related works}  This subsection focuses on research on previous works and approaches in the relevant field of information extraction. The text in this subsection is heavily based on the text from .  The plethora of methods that have been used historically for general information extraction is hard to fully summarize or compare. Moreover, it would not be fair to compare methods developed for and evaluated on fundamentally different datasets.  However, we assessed that none of these methods is well-suited for working with structured documents , since they generally do not have any fixed layout, language, caption set, delimiters, fonts... For example, invoices vary in countries, companies and departments, and change in time. In order to retrieve any information from a structured document, you must understand it. Our criterion for considering a method to compare against is that no human-controlled preprocessing such as template specification or layout fixing is required because we aim for a fully automated and general solution. Therefore we will not be including any historical method as a baseline to compare against.  In recent works, a significant number does successfully use a graph representation of a document  and use graph neural networks. Also, the key idea close to the one-shot principle in information extraction is used and examined for example in  and . Both works use notions of finding similar documents and reusing their gold-standards . The latter  applies the principle in the form of template matching without the need for any learnable parameters.  Our approach can also be called ``word classification'' approach as written in , a work where an end-to-end architecture with a concept of memory is explored.  At this point, it is important to clarify the differences between other works and our stream of research .  The most important difference comes from the dataset that is at our disposal. The dataset explored here is far greater than the datasets used elsewhere, and allows for exploring deeper models as opposed to only using graph neural networks. Indeed in our previous paper, we have proven that graph neural networks work in synergy with additional convolution-over-sequence layers and even global self-attention. For clarity, the roles of said layers are described in \prettyref{subsec:Common-architecture}. Moreover, the dataset quality allowed us to discover  that information extraction and line-item table detection targets do boost each other.  As the research is focused on deeper models, we will not be using any of the other works as baselines and the commonly used graph neural networks will be incorporated only as one layer amidst many, with no special focus.  In the following pages, we will explore models that would be able to benefit from access to a known similar document's page. We hope that the model can exploit similarities between documents, even if they do not have similar templates.  \subsection{Broader inspiration}  A broader section on references is provided here since we are using a great variety of layers in the exploration of deep network architectures.  \paragraph{One-shot learning and similarity}  Presented in  is a model design concept that aims to improve models on new data without retraining of the network.   Typically, a classification model is trained to recognize a specific set of classes. In one-shot learning, we are usually able to correctly identify classes by comparing them with already known data. Unlike traditional multi-class classification, one-shot learning allows us to attain better scores even with surprisingly low numbers of samples . Sometimes it can work even for classes that are not present in the training set .  This concept can help in areas ranging from computer vision variants 閳 omniglot challenge   to object detection , finding similar images , face detection , autonomous vision , speech  and also the NLP area .  Among the methods that make one-shot learning able to work, the most fundamental one utilizes the concept of similarity. For similarity to work, we have two types of data 閳 ``unknown'' and ``known''. For the known data, its target values are known to the method and/or to the model. To classify any unknown input, the usual practice is to assign the same class to it as is the class of the most similar known input.  Technically speaking, the architecture  contains a 閳ユ笩iamese閳 part. In particular, both inputs  are passed to the same network architecture with tied weights. We will draw inspiration from this basic principle, and will leave other more advanced methods of one-shot learning  for further research.  Usually due to performance reasons the model is not asked to compare new inputs to every other known input 閳 only to a subset. Therefore, a prior pruning technique needs to be incorporated 閳 for example in the form of the nearest neighbor search in embedding space, as is done for example in the work . Another option would be to incorporate a memory concept  .  The loss used for similarity learning is called triplet loss because it is applied on a triplet of classes  for each data-point:   Where  is a margin between positive and negative classes and  is the model function mapping inputs to embedding space .  Generally speaking, one-shot learning can be classified as a meta-learning technique. For more on meta-learning, we suggest a recent study, like  . Taking the concept one step further yields a concept called ``zero-shot learning'' .   \paragraph{Other sources of inspiration}  It is now beneficial to mention other sources of inspiration that are also meaningfully close to one-shot learning. Since we ask ``what labels are similar in the new data'', a ``query answer'' approach should be considered. Recently, the attention principle  successfully helped to pave the way in language models . It is not uncommon to use attention in one-shot approaches   and also query answer problems in various problems domains .   The mentioned task of similarity can also be approached as pairwise classification, or even dissimilarity .         Deep context to have weights on bias phrases  In this paper, we showed that RNN-T personalization can be improved significantly by inducing better coverage of rare WordPieces during training, introducing extra information into the encoder, leveraging G2G to produce additional pronunciation variants in both training and decoding, and biasing earlier with deep PLM fusion. Together, these techniques help push the boundary of RNN-T personalization and close the gap with traditional hybrid systems on use cases that require contextual biasing and accurate name recognition. For future work, we plan to incorporate proper WFST and NNLM into deep PLM fusion, apply these techniques to other end-to-end models, and tackle open-domain personalization where strong context prefixes are not always available.  
"," The automation of document processing is gaining recent attention due to the great potential to reduce manual work through improved methods and hardware. Any improvement of information extraction systems or further reduction in their error rates has a significant impact in the real world for any company working with business documents as lowering the reliability on cost-heavy and error-prone human work significantly improves the revenue. In this area, neural networks have been applied before 闁 even though they have been trained only on relatively small datasets with hundreds of documents so far.  To successfully explore deep learning techniques and improve the information extraction results, a dataset with more than twenty-five thousand documents has been compiled, anonymized and is published as a part of this work. We will expand our previous work where we proved that convolutions, graph convolutions and self-attention can work together and exploit all the information present in a structured document. Taking the fully trainable method one step further, we will now design and examine various approaches to using siamese networks, concepts of similarity, one-shot learning and context/memory awareness. The aim is to improve micro $F_{1}$ of per-word classification on the huge real-world document dataset.  The results verify the hypothesis that trainable access to a similar  page together with its already known target information improves the information extraction. Furthermore, the experiments confirm that all proposed architecture parts  are all required to beat the previous results.  The best model improves the previous state-of-the-art results by an $8.25\,\%$ gain in $F_{1}$ score. Qualitative analysis is provided to verify that the new model performs better for all target classes. Additionally, multiple structural observations about the causes of the underperformance of some architectures are revealed.  All the source codes, parameters and implementation details are published together with the dataset in the hope to push the research boundaries since all the techniques used in this work are not problem-specific and can be generalized for other tasks and contexts.   \keywords{one-shot learning \and information extraction \and siamese networks \and  similarity \and attention}",351
"  Because of the fact that obtaining   supervised training labels is costly and time-intensive,   and that   unlabeled data is relatively easy to obtain,   semi-supervised learning  , which  utilizes  in-domain  unlabeled data  to improve models trained on the labeled dataset , is of growing interest.  Under the context of large-scale of language model pretraining ,  where a language model is pretrained on an extremely large, open-domain dataset ,   how we can make the best use of the in-domain unlabeled dataset     is poorly understood.   There are basically two ways to take advantages of  the unlabeled, in-domain dataset :   {\bf in-domain pretraining}\footnote{To note,    the pretraining on the in-domain dataset  is distinguished from the pretraining on the large-scale, open-domain dataset largeU.  The model for in-domain pretraining can be randomly initialized or   taking a pretrained model based on the open-domain dataset largeU .}, where a language model is pretrained on   the in-domain dataset  , and then   fine-tuned on ;  {\bf pseudo-label} based approach , where unlabeled data points are assigned with labels predicted by the model trained  on  , forming a new dataset .  A new model  is trained for final predictions by considering .   Many important questions regarding the behavior of semi-supervised learning models under the context of large-scale LM pretraining   remain unanswered:    Is semi-supervised training  still beneficial with the presence of large scale pretraining on largeU?    Should  be used for in-domain LM pretraining or pseudo-label generation?  How should  pseudo-label based semi-supervised models    be  implemented? How different semi-supervised strategies  affect performances regarding  of different sizes, and  of different sizes, etc.    In this paper, we conduct comprehensive studies on the behavior of semi-supervised learning in NLP  with the presence of large-scale language model pretraining.   We use the task of text classification as an example,  the method of which can be easily adapted to different NLP tasks. Our work sheds important lights on the behavior of semi-supervised learning models:  we find that   with the presence of  in-domain pretraining LM on , open-domain LM pretraining   is unnecessary, and we are able to achieve better performance with pretraining on  the in-domain dataset ;    both the in-domain pretraining strategy and the pseudo-label based strategy  lead to significant performance boosts, with the former performing better with larger , the latter performing better with smaller , and the  combination   of both performing the best;  for pseudo-label based strategies,  self-training  yields better performances when  is small, while joint training on the combination of   and  yields better performances when  is large.   Using semi-supervised learning models, we are able to achieve a performance of around  accuracy with only 50 training data points on the IMDB dataset, and   a competitive performance of 96.6 with the full dataset.  More importantly, our work marks an initial step toward understanding the behavior of semi-supervised learning models in the context of large-scale pretraining.    The rest of this paper is organized as follows: related work is detailed in Section 2.  Different strategies for training semi-supervised models are shown in Section 3.  Experimental results and findings are shown in Section 4, followed by a brief conclusion in Section 5.     We introduced a framework for creating general purpose NLP systems that can solve tasks from natural language descriptions, synthesizing and extending previous work in zero-shot learning. To make progress toward this goal, we create a dataset, \dataset{}, that rigorously evaluates how well a model truly understands each task. The dataset is designed to test models' ability to systematically generalize across four different areas. State-of-the-art performance on \dataset is \finalscore\ , leaving much room for future improvement.  While we have been focused on zero shot learning from task descriptions, our framework also permits few-shot scenarios where a task description is given along with a handful of examples, making meta-learning approaches applicable.  This is an interesting avenue for future work, for which \dataset{} should also be useful. To facilitate future work, we make our models, code, and data available at .  
"," The goal of semi-supervised learning is to utilize the unlabeled, in-domain dataset $U$ to improve models trained on the labeled dataset $D$.     Under the context of   large-scale language-model  pretraining,   how we  can make the best use of   $U$   is poorly understood:   Is semi-supervised learning still beneficial   with the presence of  large-scale pretraining?  Should $U$ be used for in-domain LM pretraining or pseudo-label generation? How should the pseudo-label based semi-supervised model    be actually implemented? How different semi-supervised strategies  affect performances regarding $D$ of different sizes, $U$ of different sizes, etc.   In this paper, we conduct comprehensive studies  on  semi-supervised learning in the  task of text classification   under the context of  large-scale LM pretraining. Our studies shed important  lights on the  behavior of semi-supervised learning methods.   We find that:    with the presence of  in-domain LM pretraining  on $U$, open-domain LM pretraining \cite{devlin2018bert}  is unnecessary, and we are able to achieve better performance with pretraining on  the in-domain dataset $U$;  both the in-domain pretraining strategy and the pseudo-label based strategy introduce  significant performance boosts,  with the former performing better with larger $U$,  the latter performing better with smaller $U$, and the combination leading to the largest performance gain;   vanilla self-training  yields better performances when $D$ is small, while joint training on the combination of  $D'$ and $D$ yields better performances when $D$ is large.   %We use the task of text classification as an example,  the method of which can be easily adapted to different NLP tasks.  Using semi-supervised learning strategies, we are able to achieve a performance of around $93.8\%$ accuracy with only 50 training data points on the IMDB dataset, and   a competitive performance of 96.6$\%$ with the full  IMDB dataset.  Our work marks an initial step toward understanding the behavior of semi-supervised learning models under the context of large-scale pretraining.\footnote{Code, models and datasets  can be found at https://github.com/ShannonAI/Neural-Semi-Supervised-Learning-for-Text-Classification}",352
"  \todo{Completely rewrite - emphasize that many methods have been proposed for learning embeddings  learn representations of the entities in a knowledge base  typically based on the text of each entity's Wikipedia article or the surrounding local context for mentions of each entity . %  \clm{I would have ""context surrounding mentions of each entity -- otherwise it looks like you're being just redundant and not making it clear this is what you will be calling it henceforth, tho this is just stylistic} context surrounding mentions of each entity Recent advances in neural EL have involved methods for pretraining entity embeddings using the link graph of Wikipedia to learn related entities and words . Similar to word embeddings, past work has shown that these embeddings reside in a high-dimensional pseudo-semantic space, with entities that are close in the space being semantically similar . % \glarionov{""with entities close in the space being...} However, little work has been done to understand what information different entity embeddings capture about the underlying entities and how that information affects downstream performance.  Our goal in this work is to identify semantic information in entity representations and determine how that information is linked to performance on downstream EL tasks. For this, we develop a series of probing tasks, which have previously been used to examine lexical and syntactic properties of neural model layers such as sentence encoders and decoders for neural machine translation systems .  % \glarionov{I would group these two citations at the end for readability} % \ees{for lexical and syntactic properties [this is too split, move this info to before citations]}. We extract structured data about entities using DBpedia and context words from Wikipedia anchor links to create probing tasks designed to evaluate the knowledge-based and distributional semantic contents of different entity embedding models.  We compare five entity embedding methods, first by them on two downstream EL tasks. We then probe the learned embeddings to evaluate what semantic information is important for the downstream tasks and how it is represented by the different models. % \ees{We show a strong relationship between probing task performance and performance on the downstream EL tasks. [too long, break up]} We find that pretrained entity embedding methods are generally more effective at representing distributional and knowledge-based semantic information than models that generate embeddings as a byproduct of training on an EL task. These improved representations lead to better performance on the EL tasks, with the best model showing high performance on both distributional and knowledge-based semantic tasks. We further find that entity embeddings trained to predict related words and entities in a skipgram-like model are able to learn fine-grained entity type information and specific relationship types between entities without explicitly providing this information.  Our primary contributions with this work are to:   % 1) describe methods for evaluating the semantic information learned by these methods and 2) to\clm{either move the first ""to"" after ""1)"", or delete this one} empirically demonstrate the importance of this information in creating models of entities for use in downstream tasks.\clm{I agree  with Liz you should bullet point this, because you want to highlight your contributions -- easier for reviewers} % \ees{maybe bullet point these two or put 1) .. 2) to make it mad easy to scan and get} Our hope is that this information can provide guidance in developing architectures that better combine explicit structured information with text to improve methods for representing entities that can be used in a variety of downstream tasks, similar to existing word embeddings. Our methods can additionally be used to potentially detect deficiencies in new representation methods and biases of learned attributes through other probing tasks. % and biases of current methods by probing .\clm{You might want to briefly address the means by which it detects bias, otherwise that is a question that could feel unanswered in the reader's head}    In this paper, we conduct comprehensive  analysis on semi-supervised learning in NLP under the context of  large-scale language model pretraining.  We find that even with the presence of large-scale LM pretraining, both the in-domain pretraining strategy and the pseudo-label based strategy introduce  additional  significant performance boost,  with the former performing better with larger ,  the latter performing better with smaller , and the combination leading to the best performance.  Using semi-supervised learning models, we are able to achieve a performance of around  accuracy with only 50 training data points on the IMDB dataset, and   a competitive performance of 96.6 with the full dataset.  Our work  sheds light on   the behavior of semi-supervised learning models in the context of large-scale pretraining.      
","  \todo{Complete rewrite} Pretrained entity embedding methods have shown strong results in entity linking  systems compared to methods that generate entity representations from text descriptions. Prior work has shown that these embeddings inhabit a pseudo-semantic space, but the semantic information they contain has not been thoroughly explored nor have  they been compared with other representations for differences in information.  We introduce methods for probing learned entity representations for information about their entity types, relationships, and context words using Wikipedia anchors and DBPedia structured data and use them to compare five entity embedding models. We show that improved representation of all types of semantic information is linked to improved performance on two downstream EL tasks. Our results provide potential directions for further research to better incorporate explicit semantic information into neural entity linking models.",353
" 	In this section, we mention different tokenization techniques for SLT and explain our perspective on the problem. We mentioned about the basics of SLT and NMT. From our research perspective, NMT methods can provide successful results if we have good tokens from SL vides. Therefore, tokenization is seen as the most crucial part of this research. Firstly, the visual properties are involved in the tokenization part. Secondly, there is no a generic approach to obtain strong tokens for all the SLs. In addition to that, it is not clear that discrete tokens should be obtained for better translation quality. For this reason, we extend the meaning of tokenization for NSLT and it covers the overall process to prepare the frames for the NMT module. 	\par For spoken to spoken languages, we generally use words as tokens to feed the NMT module. The current state-of-the-art method converts those tokens to continuous embeddings to reach a semantic representation. While learning translation, the word embedding is also trained to learn the relationship between words. Eventually, a meaningful embedding is obtained before the NMT module as seen in Figure . Based on this, it may be a good idea to learn a good representation of signs to replace with word embeddings to achieve the same advancements in NSLT as NMT has done. This representation is cross-lingual; but learning it is an open problem. Our research is mainly focused on this problem. Before introducing our approach, we discuss the existing three tokenization approaches in the following subsection.   	 \subsection{Input Tokenization in NSLT}  \par  The first approach is using glosses as tokens. Glosses are intermediate word-like representations between signs and words in sentences. Therefore, they can be directly applicable to the NMT framework without any further effort. However, there are certain shortcomings in this method. Firstly, glosses rarely exist in real life. Gloss annotation requires a laborious process and special expertise. Secondly, glosses are unique to SLs. Therefore, each SL requires special effort to obtain glosses whereas sentences are commonly available. The last drawback is that a mistake in the gloss level can produce dramatic meaning differences in translation, since glosses are high level annotations, similar to words.  \par The second approach is the same as the first one in terms of tokens. On top of that, this approach learns to extract glosses from frames. In other words, this method uses glosses as explicit intermediate representations as seen in Figure . It eliminates the further search for tokenization, but it needs a special network for frame to gloss conversion. There are two main concerns. The first one is that a network for frame to gloss conversion is still dependent on gloss annotations. The second is that it is not clear that glosses are the upper bound for SLT as there is not sufficient evidence. The problem is immature and the result in  provides clues about whether glosses may restrict translation quality.    The third approach is called frame-level tokenization. This approach does not establish any explicit intermediate representation as seen in Figure . It aims to learn good sign embeddings to replace with word-embeddings. However, there is no golden way to represent signs with embeddings to feed into the NMT module. Furthermore, it is not clear what the length of the embedding should be. Embeddings can be obtained from each frame or extracted from inner short clips in the video. In addition to that, the representation can be learned with sentence-video pairs or trained outside the NSLT system. There are several ways for frame-level tokenization. However, the main difference from the gloss level tokenization is that discrete representation can be eliminated. If we find a proper one, there would be several advantages. The first one is that the resulting framework can be applied to any SL translation task without requiring annotation. The second advantage is the opportunity to inject additional supervision. The representations would be trained on different tasks and different datasets whereas gloss level tokenization cannot cover different SLs. The third one is that the token length can be adjusted. To boost translation speed, the number of tokens can be reduced to a pre-determined number.        In this work, we propose a new set of probing tasks for evaluating entity embeddings which can be applied to any method that creates one embedding per entity. Using these tasks, we find that entity type information is one of the strongest signals present in all but one of the embedding models, followed by coarse information about how likely an entity is to be mentioned. We show that the embeddings are particularly able to use entity type information to bootstrap their way to improved performance on entity relationship and factual information prediction tasks and propose methods to counteract this to more accurately estimate how well they encode relationships and facts.  Overall, we find that while BERT-based entity embeddings perform well on many of these tasks, their high performance can often be attributed to strong entity type information encoding. More specialized models such as Wikipedia2Vec are better able to detect and identify relationships, while the embeddings of \citet{ganea2017joint} better capture the lexical and distributional semantics of entities. Additionally, we provide a direct comparison of the embeddings on two downstream EL tasks, where the models that performed well on the probing tasks such as Ganea, Wiki2V, and BERT performed best on the downstream tasks. We find that the best performing embedding model depends greatly on the surrounding architecture and encourage future practitioners to directly compare newly proposed methods with prior models in a consistent architecture, rather than only compare results.  Our work provides insight into the information encoded by static entity embeddings, but entities can change over time, sometimes quite significantly. One future line of work we would like to pursue using our tests is to investigate how changes in entities over time can be reflected in the embeddings, and how those changes could be modeled as transformations in the embedding space. Context-based embeddings in particular could then be dynamically updated with new information, instead of being retrained from scratch.       
"," In this thesis, we propose a multitask learning based method to improve Neural Sign Language Translation  consisting of two parts, a tokenization layer and Neural Machine Translation . The tokenization part focuses on how Sign Language  videos should be represented to be fed into the other part. It has not been studied elaborately whereas NMT research has attracted several researchers contributing enormous advancements. Up to now, there are two main input tokenization levels, namely frame-level and gloss-level tokenization. Glosses are world-like intermediate presentation and unique to SLs. Therefore, we aim to develop a generic sign-level tokenization layer so that it is applicable to other domains without further effort. \par We begin with investigating current tokenization approaches and explain their weaknesses with several experiments. To provide a solution, we adapt Transfer Learning, Multitask Learning and Unsupervised Domain Adaptation into this research to leverage additional supervision. We succeed in enabling knowledge transfer between SLs and improve translation quality by 5 points in BLEU-4 and 8 points in ROUGE scores. Secondly, we show the effects of body parts by extensive experiments in all the tokenization approaches. Apart from these, we adopt  3D-CNNs to improve efficiency in terms of time and space. Lastly, we discuss the advantages of sign-level tokenization over gloss-level tokenization. To sum up, our proposed method eliminates the need for gloss level annotation to obtain higher scores by providing additional supervision by utilizing weak supervision sources.",354
"  %   Storytelling is a central part of human socialization and entertainment. Many of the popular forms of storytelling throughout history \---such as novels, plays, television, and movies\--- have passive audience experiences. However, gaming is an interesting medium because interactivity is a large part of the entertainment experience, and interactivity and storytelling can often be in conflict: too much player freedom means a storyline may never be explored, while on the other hand, too many restrictions on player freedom risks reducing gaming to a passive medium. Thus, interactivity in storytelling has been an important challenge for gaming, with much design effort put into striking a balance between entertaining gameplay and compelling storytelling.  As gaming technology advances, new opportunities for interactive storytelling present themselves. Better storage technology made telling longer, more intricate stories possible, and better graphical capabilities helped foster more immersive gaming experiences. Advances in artificial intelligence have lead to more challenging opponents, more realistic NPC behavior, and other benefits. Better procedural content generation algorithms help ensure unique gameplay experiences that stay fresh for longer. Finally, recent breakthroughs in language modeling present a new opportunity: language, and thus stories, can potentially be generated on demand.   In this paper, we introduce a novel game of collaborative storytelling, where a human player and an artificial intelligence agent construct a story together. The game starts with the AI agent reciting one of a curated set of story starters \---opening sentences meant to kick-start participants' storytelling creativity\--- and the human player responds by adding a line, which we refer to from here on out as a story continuation, to the story. The AI agent and human player then take turns adding continuations to the story until the human player concludes the story. The game is designed to have a few restrictions as possible and contrasts with traditional storytelling settings where the narrative is fixed in advance.    Collaborative storytelling builds on a rich tradition of collaboration in storytelling that includes Dungeons and Dragons, improvisational comedy, and theater. It could be a useful tool for encouraging creativity and overcoming writer's block, as well as being an entertaining game in its own right.  Our end goal is to make it possible for intelligent agents, such as robot companions and avatars , to play the collaborative storytelling game, as shown in Figure.  %Our supplementary material includes a simulation of such a scenario, including real stories that were constructed by humans collaborating with an Web-only version of our current system\footnote{Stories were edited for brevity.}.  Our primary contributions are as follows:      In this paper, we presented a deep learning-based scheme to analyze the sentiment on Bengali restaurant reviews. Word2vec embedding technique is used to consider the semantic meaning of the Bengali reviews. BiLSTM network tuned to find out the optimal hyperparameter combination. A corpus of 8435 Bengali restaurant reviews is developed to evaluate the performance of the proposed system. The outcome of the experimentation exhibits that the proposed system outperforms the baseline ML algorithms and previous techniques on a holdout dataset. Though our approach acquires satisfactory results compared to other works, some improv-ements are still required to take this system in production level. Thus, in future, we will try to add reviews with more classes and conjoin the aspect of the reviews as well.          ---- Bibliography ----     BibTeX users should specify bibliography style 'splncs04'.   References will then be sorted and formatted in the correct style.   
","   Storytelling plays a central role in human socializing and entertainment. However, much of the research on automatic storytelling generation assumes that stories will be generated by an agent without any human interaction. In this paper, we introduce the task of collaborative storytelling, where an artificial intelligence agent and a person collaborate to create a unique story by taking turns adding to it. We present a collaborative storytelling system which works with a human storyteller to create a story by generating new utterances based on the story so far. We constructed the storytelling system by tuning a publicly-available large scale language model on a dataset of writing prompts and their accompanying fictional works. We identify generating sufficiently human-like utterances to be an important technical issue and propose a sample-and-rank approach to improve utterance quality. Quantitative evaluation shows that our approach outperforms a baseline, and we present  qualitative evaluation of our system's capabilities.",355
"   The vast amounts of scientific literature can provide a significant source of information for biomedical research. Using this literature to identify relations between entities is an important task in various applications .  Existing approaches to biomedical relation extraction usually fall into one of two categories. Mention-level extraction aims to classify the relation between a pair of entities within a short span of text . In contrast, pair-level extraction aims to classify the relation between a pair of entities across an entire paragraph, document or corpus.  For both mention-level and pair-level relation extraction, recent work has been focused on representation learning. This is considered to be one of the major steps towards making progress in artificial intelligence . Representations of relations which understand their context are particularly important in biomedical research, where identifying fruitful targets is crucial due to the high costs of experimentation. Learning such representations is likely to require large amounts of unsupervised data due to the scarcity of labelled data in this domain.  Recent mention-level methods have been based on using large unsupervised models with Transformer networks  to learn representations of sentences containing pairs of entities. These representations are then used as the inputs to much smaller models, which perform supervised relation classification .  Recent pair-level methods have been based on encoding each mention of a pair of entities, and designing a mechanism to pool these encodings  into a single representation. This representation is then used to classify the relation between the entity pair .  However, representation learning methods for both mention-level and pair-level extraction typically use a point estimate for each representation. As a result, they may struggle to capture the nature of the true, potentially complex relations between each pair of entities. For example, Figure  shows sentences for two entity pairs which demonstrate that relation statements can be very different, typically depending on biological circumstances . Such nuanced relations can be difficult to capture with a single point estimate.  We hypothesise that there is a true underlying relation for each entity pair, and that this relation can be multimodal . The sentences containing each pair are textual observations of these underlying relations.  We therefore propose a probabilistic model which uses a continuous latent variable to represent the true relation between each entity pair. The distribution of a sentence containing that pair is then conditioned on this latent variable. In order to be able to model the complex relations between each entity pair, we use an infinite mixture distribution for the latent representation.  Our model provides a unified architecture for learning representations of relations between entity pairs both at mention and pair level. We show that  the posterior distribution of the latent variable can be used for mention-level relation classification. We also demonstrate that the prior distribution from the same model can be used for pair-level classification. On both tasks, we achieve results competitive with strong baselines with a model which has fewer parameters and is significantly faster to train.  The code is released at \url{ https://github.com/BenevolentAI/RELVM} %.           In this paper, we introduced the novel task of collaborative storytelling, where humans and AI agents work together to make stories. We presented a collaborative storytelling system that tunes a large-scale neural LM on storytelling data and uses a sampling-and-ranking approach to select more human-preferred story continuations. Quantitative evaluation of our system found that tuning and ranking both greatly contribute to its capability to generate story continuations that human evaluators prefer and consider acceptable. Qualitative evaluation of human evaluator preferences showed that humans found tuned+ranked more preferable than tuned and tuned more preferable than untuned in terms of engagingness, interestingness, and humanness metrics, as well as overall story quality preferences. Finally, we identified areas for potential future work, including evaluation of stories produced by humans and our system, integration of our system into intelligent agents such as robots and avatars, and improvement of generated story continuation quality by allowing genres or moods to be targeted.        The next two lines define the bibliography style to be used, and    the bibliography file.  \clearpage          If your work has an appendix, this is the place to put it.    \clearpage         
","     Extracting biomedical relations from large corpora of scientific documents is a challenging natural language processing task. Existing approaches usually focus on identifying a relation either in a single sentence  or across an entire corpus . In both cases, recent methods have achieved strong results by learning a point estimate to represent the relation; this is then used as the input to a relation classifier. However, the relation expressed in text between a pair of biomedical entities is often more complex than can be captured by a point estimate. To address this issue, we propose a latent variable model with an arbitrarily flexible distribution to represent the relation between an entity pair. Additionally, our model provides a unified architecture for both mention-level and pair-level relation extraction. We demonstrate that our model achieves results competitive with strong baselines for both tasks while having fewer parameters and being significantly faster to train. We make our code publicly available.",356
"   Human communication is inherently multi-modal in nature. Our expressions and tone of voice augment verbal communication.\ This can include vocal features like speaking rate, intonation and visual features like facial expressions . Non-verbal communication is important for tasks that involve higher level cognitive expressions like emotions , persuasiveness  and mental health analysis . We focus on a multi-modal approach to emotion recognition because humans fundamentally express emotions verbally using spoken words , as well as with acoustic signals  and visual expressions .  Getting large-scale labeled datasets for emotion recognition can be challenging.\ Our primary motivation for this paper is to study effective utilization of large unlabeled datasets to improve performance of multi-modal emotion recognition systems.\ The signals we consider are speech, visual information and spoken text.\ Our motivation stems from the popular use of pre-trained models in natural language, speech and visual understanding tasks to circumvent data limitations.\ BERT is a popular model for natural language understanding  that was trained using self-supervision.\ Devlin et al. use the masked language modeling  task on the Wikipedia corpus for pre-training.\ The model was successfully fine-tuned to improve performance on several tasks like question answering and the general language understanding evaluation benchmarks . Self-supervised learning has also been successfully applied to speech based applications.\ Schneider et al.\ in  use unsupervised pre-training on speech data by distinguishing an audio sample in the future from noise samples.\ Fine-tuning this model shows state of the art results on automatic speech recognition . Liu et al.\ show in  that a BERT-like pre-training approach can be applied to speech.\ By predicting masked frames instead of masked words, the performance on tasks like speaker recognition,\ sentiment recognition and phoneme classification can be improved. For emotion recognition, Tseng et al.\ show in  that text-based self-supervised training can outperform state of the art models. The authors use a language modeling task, that involves predicting a word given its context, to pre-train the model.\ Another area of work that has leveraged unlabeled data is detection and localization of visual objects and spoken words in multi-modal input.\ Harwath et al.\ in  train an audio-visual model on an image-audio retrieval task.\ The models are trained to learn a joint audio-visual representation in a shared embedding space.\ This model can learn to recognize word categories by sounds without explicit labels.\ Motivated by the success of these approaches, we study if similar methods can be applied to multi-modal emotion recognition.\ To the best of our knowledge, a joint self-supervised training approach using text, audio and visual inputs has not been well explored for emotion recognition.   Multi-modal emotion recognition models have been well studied in literature and typically outperform uni-modal systems .\ These models need to combine inputs with varying sequence lengths.\ In video, the sequence lengths for audio and visual frames differ from the length of text tokens by orders of magnitude.\ There has been considerable prior work in fusing multi-modal features. Liang et al.\ in  studied multiple fusion techniques for multi-modal emotion recognition and sentiment analysis.\ Their methods included early and late fusion of modalities, and a dynamic fusion graph based network.\ They showed that the graph fusion model outperforms other methods.\ Early fusion and graph fusion techniques both require alignment between various modalities.\ Late fusion can be performed without alignment, but does not allow interaction of features from different modalities at the frame level.\ To overcome this limitation,\ Tsai et al.\ introduce the cross-modal transformer in .\ It scales the features using cross-modal attention.\ In the process, the modalities are projected into sequences of equal lengths, eliminating the need for any alignment.\ This architecture has been successfully applied to problems like emotion recognition, sentiment analysis  and speech recognition .\ Recently, another transformer-based method to combine multi-modal inputs was introduced by Rahman et al. in , which uses a multi-modal adaptation gate.  In this paper, we propose using the same pre-training scheme as BERT, but extend it to a model that uses audio, visual and text inputs. We discuss the relevance of this approach in Section .\ The multi-modal representations learned in pre-training are fine-tuned for emotion recognition.\ We evaluate the efficacy of the pre-training approach.\ We also perform experiments to understand the importance of each modality on the CMU-MOSEI dataset and provide case-studies to interpret the results.   This paper is organized as follows.\ In Section  we describe our model architecture and the self-supervised approach for pre-training, along with further motivation for the self-supervised learning we choose.\ In Section , we discuss the training setup and data.\ We present our results and analysis in Section  and conclude in Section .     We have presented a model for learning representations of pairs of biomedical entities from unlabelled text corpora. We use a latent variable with an arbitrarily flexible distribution in order to be able to capture the complex relations between each pair of entities. The unified architecture can be used for both mention-level and pair-level relation extraction. On both tasks, we achieve results competitive with strong baselines. We also show significant computational gains in terms of the number of parameters and training times.  Our model presents many avenues for future work. The results in Table  show that the model's performance improves with the size of the hidden states in the networks; this suggests that there are further gains achievable simply by providing the model with more parameters. The model could be further scaled up by using a hierarchy of latent variables to increase the expressive power of the representations.   Other directions include evaluating the benefits of having a representation which explicitly captures uncertainty about the relations. For example, this can be done by assessing if the model is less confident when making predictions about entity pairs which do not occur frequently in the unlabelled corpus. Additionally, since our model can produce a representation for any pair of entities , it could be used in a link prediction setting to score unseen entity pairs.  
","  Emotion recognition is a challenging task due to limited availability of in-the-wild labeled datasets.\ Self-supervised learning has shown improvements on tasks with limited labeled datasets in domains like speech and natural language.\ Models such as BERT learn to incorporate context in word embeddings, which translates to improved performance in downstream tasks like question answering.\ In this work, we extend self-supervised training to multi-modal applications.\ We learn multi-modal representations using a transformer trained on the masked language modeling task with audio, visual and text features.\ This model is fine-tuned on the downstream task of emotion recognition.\ Our results on the CMU-MOSEI dataset show that this pre-training technique can improve the emotion recognition performance by up to 3\% compared to the baseline.",357
" %  A long desired goal for AI systems is to play an important and collaborative role in our everyday lives.  Currently, the predominant approach to visual question answering  relies on encoding the image and question with a black-box transformer encoder.  These works carry out complex computation behind the scenes but only yield a single token as prediction output . Consequently, they struggle to provide an intuitive and human readable form of justification consistent with their predictions.  In addition, recent study has further demonstrated some unsettling behaviours of those models: they tend to ignore important question terms, look at wrong image regions, or undesirably adhere to superficial or even potentially misleading statistical associations.     To address this insufficiency, we reformulate VQA as a full answer generation task rather than a classification one, i.e. a single token answer. The reformulated VQA task requires the model to generate a full answer with natural language justification. We find that the state-of-the-art model answers a significant portion of the questions correctly for the wrong reasons.  To learn the correct problem solving process,  We propose \modelabbrevname{} , a transparent neural-symbolic reasoning framework that solves the problem step-by-step mimicking humans.     A human would first  \underline{l}ook at the image,  \underline{r}ead the question,  \underline{t}hink with multi-hop visual reasoning,      and finally  \underline{a}nswer the question.      %      Following this intuition, \modelabbrevname{} deploys four neural modules, each mimicking one problem solving step that humans would take:     %      A scene graph generation module first converts an image into a scene graph; A semantic parsing module parses each question into multiple reasoning instructions; A neural execution module  interprets reason instructions one at a time by traversing the scene graph in a recurrent manner and; A natural language generation module generates a full answer containing natural language explanations. The four modules are connected      through hidden states rather than explicit outputs.      Therefore, the whole framework can be trained end-to-end, from pixels to answers.     In addition, since \modelabbrevname{} also produces human-readable      output from individual modules during testing, we can easily     locate the error by checking the modular output.      %      %      Our experiments on GQA dataset show that      \modelabbrevname{} outperforms the state-of-the-art model by a large margin       on the full answer generation task.      Our perturbation analyses by removing relation linguistic cues from questions      confirm that      \modelabbrevname{} makes a step towards truly understanding the question rather than having a smart guess with superficial data correlations.      %      We discuss related work in Appendix A. To summarize, the main contributions of our paper are three-fold:                      %     In this paper, we present state of the art results on the emotion recognition task using the cross-modal transformer on the CMU-MOSEI dataset.\ We utilize a BERT-like pre-training scheme using audio, visual and text inputs.\ We use the VoxCeleb2 dataset to pre-train the model and fine-tune it for the emotion recognition task.\ We demonstrate up to a 3\  improvement over the baseline with the fine-tuned model. We presented our subjective analysis on the contribution of various modalities to emotion recognition.\ We also show results with missing input modalities to understand the importance of each modality for the emotion recognition task.  For our future work, we propose to initialize the text encoder with a text-only model like BERT, before multi-modal self-supervised training.\ VoxCeleb2 dataset, although large in terms of number of hours of video, is smaller when compared to the Wikipedia corpus which has billions of words. Taking advantage of a larger text-only corpus could provide improvements.\ We would also like to experiment with adapting the model on the CMU-MOSEI dataset.\ Both the VoxCeleb2 and CMU-MOSEI datasets are obtained from YouTube, but there could be domain mismatch between the two datasets. Adapting could help bridge the mismatch.\ We would also like to explore weak labels to adapt the pre-trained representations for the downstream task.\ Tseng et al.\ showed in  that weakly supervised labels can be used to effectively bias the embeddings learned by a pre-trained model. Even though we study the impact of ASR errors on emotion recognition, we do not know how these errors impact the self-supervised training. We would like to study that in the future. As noted before, our model architecture doesn't allow ablation of text. For our future work, we will focus on overcoming that limitation.  
","   The predominant approach to visual question answering  relies on encoding the image and question with a ``black-box'' neural encoder and decoding a single token as the answer like ``yes'' or ``no''. Despite this approach's strong quantitative results, it struggles to come up with intuitive, human-readable forms of justification for the prediction process. To address this insufficiency, we reformulate VQA as a full answer generation task, which requires the model to justify its predictions in natural language. We propose LRTA [Look, Read, Think, Answer], a transparent neural-symbolic reasoning framework for visual question answering that solves the problem step-by-step like humans and provides human-readable form of justification at each step. Specifically, LRTA learns to first convert an image into a scene graph and parse a question into multiple reasoning instructions. It then executes the reasoning instructions one at a time by traversing the scene graph using a recurrent neural-symbolic execution module. Finally, it generates a full answer to the given question with natural language justifications. Our experiments on GQA dataset show that LRTA outperforms the state-of-the-art model by a large margin  on the full answer generation task. We also create a perturbed GQA test set by removing linguistic cues  in the questions for analyzing whether a model is having a smart guess with superficial data correlations. We show that LRTA makes a step towards truly understanding the question while the state-of-the-art model tends to learn superficial correlations from the training data.",358
"   Duplicate question detection  is an important application in information retrieval and NLP . It allows systems to recognize when two questions share an answer. This is significant for community forums, such as StackExchange\footnote{https://stackexchange.com/}   to increase their effectiveness in avoiding redundant questions and displaying relevant answers to search questions. It is also important for FAQ retrieval question answering systems .  To learn DQD models for \stackexchange{}, question pairs are usually annotated with duplication information that is extracted from community-provided meta-data. Such annotations are sparse for most domains, e.g., a new \stackexchange{} forum providing support for a new product.  Therefore, leveraging other training signals either from unsupervised data or supervised data from other domains is important .  Pre-trained language models  like BERT  and RoBERTA  are  great unsupervised textual representations. Several recent efforts adapt PLMs for the domains of interest  by  self-supervised fine-tuning on unsupervised domain data, which has shown  to be promising in several scenarios  .  We follow that and tune BERT on \stackexchange{} domains to obtain richer representations for the task of DQD.   Recently,  -nearest neighbors  is applied on the PLM representations for language modeling  and dialogue . We extend this line of study and apply \cdknn{} for  cross-domain generalization in DQD, where the models are trained on data from a source domain, and applied on data from a target domain.  To do so, we represent pairs from source and target in a common representation space and then score target pairs using nearest neighbors in the source pairs. \figref{knnprocess} shows an illustration of this procedure.   % The specific properties of \stackexchange{} DQD % is important to make this approach effective.  Our study on AskUbuntu as target and source datasets of , which include several domains of \stackexchange{} and also Quora and Sprint, reveals that \cdknn{} is more effective compared to cross-entropy classification if  the pair representation space from PLMs is rich for the target domain, i.e., adapted on the unsupervised data  from target or similar domains; or   source and target domains have large distributional shifts.   We make the following contributions:   We present the first study of combining strengths of \cdknn{} and      neural representations for cross-domain generalization in a sentence matching task, i.e., DQD.   Our experimental results  on cross-domain DQD demonstrate that \cdknn{} on      rich question-pair representations advances the results of      cross-entropy classification, especially when shifts in source to target domains is substantial.        We present \modelabbrevname{}, a transparent neural-symbolic reasoning framework for visual question answering, that incorporates [look, read, think and answer] steps to provide a human-readable form of justification at each step. The modular design of our methodology enables the whole framework to be trainable end-to-end. Our experiments on GQA dataset show that \modelabbrevname{} achieves high accuracy on full answer generation task, outperforming the state-of-the-art LXMERT results by a noticeable 15\  absolute margin. In addition, \modelabbrevname{} performance drops significantly more than LXMERT, when object attributes and relationships are masked, hence indicating that \modelabbrevname{} makes a step forward, towards truly understanding the question, rather than making a smart guess based on superficial data correlations. In the validation study, we have shown that when provided with an oracle scene graph, \modelabbrevname{} is able to achieve a high accuracy on both short answers  and full answers , nearing the theoretical bound 96\  on short answers. These observations indicate that better scene graph prediction methods offer a great potential in further improving \modelabbrevname{} performance on both short-answer and full-answer tasks.   
","  Duplicate question detection  is important to increase efficiency of  community and automatic question answering systems.  Unfortunately, gathering supervised data in a domain is time-consuming and expensive, and our ability to leverage annotations across domains is minimal.  In this work, we leverage neural representations and study nearest neighbors for  cross-domain generalization in DQD.   We first encode question pairs of the source and target domain in a rich representation space and then using a k-nearest neighbour retrieval-based method, we aggregate the neighbors' labels and distances to rank pairs. We observe robust performance of this method in different cross-domain scenarios of StackExchange, Spring and Quora datasets, outperforming cross-entropy classification in multiple cases. We will release our codes as part of the publication. % ervised adaptation to StackExchange domains by self-supervised finetuning of contextualized embedding models like BERt. %We show the effectiveness of this adaptation in scenarios when source domain comes from different types of distributions. %Our analysis also reveals that unsupervised domain adaptation on even small amounts of data boosts the performance significantly. %Further, we show how an approach based on nearest neighbors is effective  for this problem and outperforms training the full model using cross entropy.",359
"   Learning vocabulary is a major component of foreign language learning. In the school context, initially vocabulary learning is typically organized around the words introduced by the text book. In addition to the incrementally growing vocabulary lists, some textbooks also provide thematically organized word banks. When other texts are read, the publisher or the teacher often provides annotations for new vocabulary items that appear in the text.  A wide range of digital tools have been developed to support such vocabulary learning, from digital versions of file cards to digital text editions offering annotations.  While such applications serve the needs of the formal learning setting in the initial foreign language learning phase, where the texts that are read are primarily chosen to systematically introduce the language, later the selection of texts to be read can in principle follow the individual interests of the student or adult, which boosts the motivation to engage with the book. Linking language learning to a functional goal that someone actually wants to achieve using language is in line with the idea of Task-Based Language Teaching  as a prominent strand of foreign language education .  Naturally, not all authentic texts are accessible to every learner, but linguistically-aware search engines, such as FLAIR , make it possible to identify authentic texts that are at the right reading level and are rich in the language constructions next on the curriculum. Where the unknown vocabulary that the reader encounters in such a setting goes beyond the around 2\% of unknown words in a text that can be present without substantial loss of comprehension , many digital reading environments provide the option to look up a word in a dictionary. Yet, frequently looking up words in such a context is cumbersome and distracts the reader from the world of the book they are trying to engage with. Relatedly, one of the key criteria of TBLT is that learners should rely on their own resources to complete a task . But this naturally can require pre-task activities preparing the learner to be able to successfully tackle the task . But how can a learner systematically prepare for reading a text or book they are interested in reading?  In this paper, we explore how computational linguistic methods such as distributional semantics, morphological clustering, and exercise generation can be combined with graph-based learner models to answer this question both conceptually and in practice. On the practical side, we developed an application that supports vocabulary learning as a pre-task activity for reading a self-selected book. The conceptual goal is to automatically organize the lexical semantic space of any given English book in the form of a graph that makes it possible to sequence the vocabulary learning in a way efficiently exploring the space and to visualize this graph for the users as an open learner model  showing their growing mastery of the book's lexical space.  Lexical learning is fostered and monitored through automatically generated multi-gap activities  that support learning and revision of words in the contexts in which they occur in the book.  In section we discuss how a book or other text chosen by the learner is turned in to a graph encoding the lexical space that the learner needs to engage with to read the book, and how words that are morphologically related as word families  are automatically identified and compactly represented in the graph . In section we then turn to the use of the graph representation of the lexical semantic space of the book to determine the reader's learning path and represent their growing lexical knowledge as spreading activation in the graph. In section, the conceptual ideas are realized in an application. We discuss how the new learner cold-start problem is avoided using a very quick word recognition task we implemented, before discussing the content selection and activity generation for practice and testing activities. Section then provides a conceptual evaluation of the approach and compares it with related with, before wrapping up with a conclusion in section.  % learning of rare words of English  but what is the purpose? And % the relevance of learning entire frequency bands of words is unclear  % How about combining the goal of reading a book with systematic % learning of what is needed to do so? Problem: Individuals are % interested in different books, and individual differ in language % competence and vocabulary knowledge. So how about the vocabulary of % books organizing themselves individually adaptive organization  % Goal:  %   % Solution: %     In this work,  we studied applying \cdknn{} in DQD cross-domain generalization. We compared \cdknn{} and a cross-entropy classifier when different  question-pair representations are available. Our results showed that domain-adaptive pre-training on target data gives rich representations, and \cdknn{} is more robust against distributional shifts compared to classification if question pairs are encoded by these rich representations.  We plan to extend our study to other tasks and understand better  the strengths of memorization in learning robust models where rich PLM embeddings are utilized to represent examples.  We believe concurrently that the promising results and findings of this presented study could benefit other NLP research to explore this direction more.    
","   How can a learner systematically prepare for reading a book they are   interested in? In this paper, we explore how computational   linguistic methods such as distributional semantics, morphological   clustering, and exercise generation can be combined with graph-based   learner models to answer this question both conceptually and in   practice. Based on the highly structured learner model and concepts   from network analysis, the learner is guided to efficiently explore   the targeted lexical space. They practice using multi-gap learning   activities generated from the book focused on words that are central   to the targeted lexical space. As such the approach offers a unique   combination of computational linguistic methods with concepts from   network analysis and the tutoring system domain to support learners   in achieving their individual, reading task-based learning goals.",360
" Speaking and listening are the most common ways in which humans convey and understand each other in daily conversations. Nowadays, the speech interface has also been widely integrated into many applications/devices like Siri, Google Assistant, and Alexa . These applications use speech recognition-based approaches  to understand the spoken user queries. Like speech, the text is also a widely used medium in which people converse. Recent advances in language modeling and representation learning using deep learning approaches  have proven to be very promising in understanding the actual meanings of the textual data, by capturing semantical, syntactical, and contextual relationships between the textual words in their corresponding learned fixed-size vector representations.   Such computational language modeling is difficult in the case of speech for spoken language understanding because unlike textual words,  spoken words can have different meanings of the same word when spoken in different tones/expressions ,  it is difficult to identify sub-word units in speech because of the variable-length spacing and overlapping between the spoke-words , and  use of stress/emphasis on few syllables of a multi-syllabic word can increase the variability of speech production . Although the textual word representations capture the semantical, syntactical, and contextual properties, they fail to capture the tone/expression. Using only speech/audio data for training spoken-word representations results in semantically and syntactically poor representations.   So in this paper, we propose a novel spoken-word representation learning approach called STEPs-RL that uses speech and text entanglement for learning phonetically sound spoken-word representations, which not only captures the acoustic and contextual features but also are semantically, syntactically, and phonetically sound. STEPs-RL is trained in a supervised manner such that the learned representations can capture the phonetic structure of the spoken-words along with their inter-word semantic, syntactic, and contextual relationships. We validated the proposed model by  evaluating semantical and syntactical relationships between the learned spoken-word representations on four widely used word similarity benchmark datasets, and comparing its performance with the textual word representations learned by Word2Vec \& FastTexT , and  investigating the phonetical soundness of the generated vector space.       In this paper, we discussed the methodological basis and realization of a tool allowing the learner to systematically learn the lexical material needed to be able to read a book they are interested in. Automatically structuring the lexical space and sequencing the learning is achieved through distributional semantic methods, the automatic identification of word families, and concepts from network analysis. The graph-based domain model that is automatically derived from the given book serves as the foundation of a learner model supporting the selection of an efficient learning path through the lexical space to be acquired. Multi-gap activities are automatically generated from the targeted book and used for practice and testing activities.     The application is also well suited to be a dedicated vocabulary   learning application as indicated earlier. The teachers can guide the   students to master vocabulary from the books of renowned authors where   they also exposed to a the intriguing language usage.  In addition to self-guided learning for people interested in reading specific books, which may be particularly useful in the context of so-called intensive reading programs, the approach is particularly well-suited for the English for Specific Purposes context, where both the language and the particular content domain are of direct importance.  Given this kind of integration of language and content learning, a similar affinity exists to so-called Content and Language Integrated Learning .    listhe thely auisd a basis for  is aab limitation that we should mention and point to an option for overcoming it:   This application can also be upgraded to learn domain knowledge.   Since the distribution semantic space is defined by a pre-trained   vector space model.  Some of the domain specific proper nouns are   missing. This could be overcame by training a custom vector space for   the chosen text. This leverage this application to facilitate domain   knowledge learning/revising like jargon, scientific names,   geographical names etc...    Additional supporting materials could be explored to scaffold the   learning apart from the usage in the chose text, dictionary reference   and translation of the word into learner's native language which are   used currently.    Though the learn model is further pruned to improve the visualisation.   The connectivity are potentially overwhelming. There could be a   considerable improvement in reporting global and local progress in the   structured space.  Or a simplified approach of visual thesaurus could   be adopted.    This application provides a lot of scope for gamification because of   its exploratory objective of vocabulary space provided with a graph   based framework to maximise the coverage. Which could be themed around   the goal of being reaching/trained for the actual task with more   engaging activities.    
","   In this paper, we present a novel multi-modal deep neural network architecture that uses speech and text entanglement for learning phonetically sound spoken-word representations. STEPs-RL is trained in a supervised manner to predict the phonetic sequence of a target spoken-word using its contextual spoken word's speech and text, such that the model encodes its meaningful latent representations. Unlike existing work, we have used text along with speech for auditory representation learning to capture semantical and syntactical information along with the acoustic and temporal information. The latent representations produced by our model were not only able to predict the target phonetic sequences with an accuracy of 89.47\% but were also able to achieve competitive results to textual word representation models, Word2Vec \& FastText , when evaluated on four widely used word similarity benchmark datasets. In addition, investigation of the generated vector space also demonstrated the capability of the proposed model to capture the phonetic structure of the spoken-words. To the best of our knowledge, none of the existing works use speech and text entanglement for learning spoken-word representation, which makes this work first of its kind.",361
"  Recent decades have brought about an increase in the use of computer-based tools in practically every  field of human endeavor. The field of education is no exception. Such tools can be used to augment or  even completely replace traditional face-to-face teaching methods. The emergence of online learning platforms has necessitated the development of means to enable learning activities, such as  group discussions, to be performed through the use of technology. One such example of a learning  platform is the IMapBook software suite aimed at increasing the literacy and reading  comprehension skills of elementary school-aged children through the use of web-based eBooks,  embedded games related to their contents, as well as moderated group discussions. Keeping these discussions constructive and relevant can be difficult and usually requires a  discussion moderator to be present at all times. This can limit the opportunities for such discussions to take place. Leveraging the methods and insights  from the fields of artificial intelligence and machine learning, we can attempt to develop systems to automatically classify messages into  different categories and detect when the discussion has veered off course and necessitates intervention. Our research tackles this problem using a  compilation of discussions obtained during pilot studies testing the effectiveness of using the IMapBook software suite in 4th-grade classrooms.  The studies were performed in 8 different Slovene primary schools and, in total, included 342 students.  The discussions consist of 3541 messages along with annotations specifying their relevance to the  book discussion, type, category, and broad category. The ID of the book being discussed and the time  of posting are also included, as are the poster's school, cohort, user ID, and username.  Each message was also manually translated into English to aid non-Slovene-speaking researchers.  The use of the Slovene language presents unique challenges in applying standard language  processing methods, many of which are not as readily available as for other, more widely spoken languages.  Given a sequence of one or more newly observed messages, we want to estimate the relevance of  each message to the actual topic of discussion. Namely, we want to assign messages into two categories 閳 relevant to the book being discussed or not.  Additionally, we want to predict whether the message is a question, an answer, or a statement which we call the type of the message. Finally, we want to  assign a category label to each message where the possible labels can be either 'chatting', 'switching', 'discussion', 'moderating', or 'identity'.  Building a predictive model capable of performing such predictions with acceptable performance would allow us to experiment with including this new  level of automation in the IMapBook software suite as well as in any related products. The research insights are also applicable to areas such as  online user comments and content moderation.    In this paper, we introduced STEPs-RL for learning phonetically sound spoken-word representations using speech and text entanglement. Our approach achieved an accuracy of 89.47\  in predicting phonetic sequences when both gender and dialect of the speaker are used in the auxiliary information. We also compared its performance using different configurations and observed that the performance of the proposed model improved by  increasing the spoken word latent representation size, and  the addition of auxiliary information like gender and dialect. We were not only able to validate the capability of the learned representations to capture the semantical and syntactical relationships between the spoken-words but were also able to illustrate soundness in the phonetic structure of the generated vector space. For future work, we plan to  extend the model to use attention mechanisms,  improve performance by using transformer-based architecture, and  experimenting on larger datasets, and  using features other than MFCCs.     \comment{ 
"," The increasing adoption of technology to augment or even replace traditional face-to-face learning has led to the development of a myriad of tools and platforms aimed at engaging the students and facilitating the teacher's ability to present new information. The IMapBook project aims at improving the literacy and  reading comprehension skills of elementary school-aged children by presenting them with interactive  e-books and letting them take part in moderated book discussions. This study aims to develop and  illustrate a machine learning-based approach to message classification that could be used to  automatically notify the discussion moderator of a possible need for an intervention and also to collect other useful information about the ongoing discussion. We aim to predict whether a message posted in the discussion is relevant to the discussed book, whether the message is a statement, a question, or an answer, and in which broad category it can be classified. We incrementally enrich our used feature subsets and compare them using standard classification algorithms as well as the novel Feature stacking method.  We use standard classification performance metrics as well as the Bayesian correlated t-test to show  that the use of described methods in discussion moderation is feasible. Moving forward, we seek to  attain better performance by focusing on extracting more of the significant information found in the  strong temporal interdependence of the messages.",362
" The Winograd Schema Challenge\/  was proposed by  as a means to test whether a  machine has human-like intelligence. It is an alternative to the well known Turing Test\/  and has been designed with the motivation of reducing certain problematic aspects that affect the TT. Specifically, while the TT is subjective in nature, the WSC provides a purely objective evaluation; and whereas passing the TT requires a machine to behave in a deceptive way, the WSC takes the form of a positive demonstration of intelligent capability.  The core problem of the WSC is to resolve the reference of pronouns occurring in natural language sentences.  To reduce the possibility that the task can be accomplished by procedures based on superficial or statistical characteristics, rather than `understanding' of the sentence, they specify that the test sentences used in the WSC, should be constructed in pairs, which have similar structure and differ only in some key word or phrase, and such that the correct referent of the pronoun is different in the two cases. This sentence pair, together with an indication of which pronoun is to be resolved and a pair of two possible candidates, is called a Winograd Schema.   The following is an example of the Winograd schemas from the original WSC273 data set :    \item The trophy doesn't fit in the brown suitcase because {\bf it} is too small\/.  \end{enumerate}   design Winograd schemas to require background knowledge to resolve a pronoun, which can be an evidence of thinking\/. Therefore, they exclude the sentences that can be resolved by a statistical association within a sentence.   In this paper, we introduce a keyword method to define domains in Winograd schemas. To our best knowledge, this is the first work to use keywords for defining domains in WSC and explore high-level patterns in them. To use the domain-specific high-level patterns, we also develop an advanced high-level knowledge-based reasoning method by modifying the method of . Furthermore, we suggest a simple ensemble method that combines knowledge-based reasoning and machine learning. By the experiments on the domain-specific data set, the ensemble method gives a better performance than each single method. Lastly, we also propose a `robust' accuracy  measure that is more objective by improving the switching method of .      The best results were achieved by using the Feature stacking method model built on the complete  feature subset. The results indicate the performance to be sufficient for the methods to be used  in real-world tools and platforms. A significant portion of the information needed for  correct classifications is hidden in the strong temporal interdependence of the messages which  our developed methods exploited only marginally.  
"," The Winograd Schema Challenge\/  is a common sense reasoning task that requires background knowledge. In this paper, we contribute to tackling WSC in four ways. Firstly, we suggest a keyword method to define a restricted domain where distinctive high-level semantic patterns can be found. A thanking domain was defined by keywords, and the data set in this domain is used in our experiments. Secondly, we develop a high-level knowledge-based reasoning method using semantic roles which is based on the method of \cite{sharma:2019}. Thirdly, we propose an ensemble method to combine knowledge-based reasoning and machine learning which shows the best performance in our experiments. As a machine learning method, we used Bidirectional Encoder Representations from Transformers  \citep{kocijan:2019}. Lastly, in terms of evaluation, we suggest a `robust' accuracy measurement by modifying that of \cite{trichelair:2018}. As with their switching method, we evaluate a model by considering its performance on trivial variants of each sentence in the test set.",363
"  % overview + widespread applications Text classification, as an extensively applied fundamental cornerstone for natural language processing  applications, such as sentiment analysis, spam detection and spoken dialogue systems, has been widely studied for decades. In general, almost all NLP tasks can be cast into classification problems on either document, sentence, or word level. Here we are focusing on the means of it in a narrow sense, i.e., given a sequence of tokens with arbitrary length, predicting the most likely categorization it belongs to.  % conventional approaches, CNN/LSTM pros, + cons: lack the efficacy to capture the latent representations. Considerable compelling neural approaches to the text classification task have empirically demonstrated their remarkable behaviors in recent years, to whom how to orchestrate and compose the semantic and syntactic representations from texts are central. Much of the work concentrated on learning the composition of distributional word representations for categorization, wherein plenty of deep learning methods have been adopted, such as TextCNNs, RCNNs, recurrent neural networks , FastText, BERT, etc. Most of them learn the word representations by firstly projecting the one-hot encoding of each token through a pretrained or randomly initialized word embedding matrices to acquire the dense real-valued vectors, and then feed them into neural models for classification.    These methods, however, have only exploited the low-dimensional semantic representations for each sample text in a supervised way. Some argued that unsupervised latent representations such as topic or cluster modeling mined by latent variable models may be of benefit.  maintained that word clustering could deliver the useful semantic information by grouping all words in the corpus and can thus promote the classification accuracy. Moreover,  incorporated the neural topic models with Variational Autoencoder  into the classification tasks so as to discover the latent topics in the document level and encode the co-occurrence of words with bag-of-words statistics.   Learning such corpus-level representation can administer to the enrichment of more globally informative features and is thus favorable to the task performance. There are plenty of works adopting VAE for learning these latent variables to boost the text classification performance. Nevertheless, there remain problems that we cannot directly treat the sampled latent space of VAE for clustering centroids since there is no mechanism to modulate the representation of different samples towards different mean and variance for a better discrimination purpose under the Gaussian distribution assumption.  and  alleviate these issues by minimizing the distance between the learnable latent representation from latent variable models and the clustering centers generated from statistical clustering approaches.   % trained with, in which projecting the word indices into the dense word representations. Grounding on this, we design an ad hoc Clustering-Enchanced neural model  that jointly learns the distributional clustering and the alignment between the domain-aware clustering centroids and word representations in the Euclidean hidden semantic space for text classification, with the vector space assumption that words with similar meanings are close to each other. Instead of directly treating the latent variables as the clustering centroids, we employ a co-adaptation strategy to minimize the difference between the hidden variables and trainable clustering centroids initialized by traditional clustering algorithms with soft alignments.  In the present work, we propose the cluster-token alignment mechanism by assigning relevance probability distribution of clusters to each token, indicating how likely it is that tokens are correlated with each cluster center. In which clustering centroids are co-regulated with learned latent variables and can be regarded as the domain- or task-specific feature indicators.   Our work illustrates that jointly adapting the clustering centroids and learning the cluster-token alignment holds the promise of advancing the text classification performance by incorporating the clustering-aware representations. Our key contributions are:  {} % graph GCN -> time cost for building graphs   % cluster explanation, importance, usage, application %  inspiration % learn the latent variables with unsupervised approaches to aid in the interaction between multi-hop clusters and word representations  % our contribution:  % 1. unsupervised approaches to learn to maneuver the cluster representation % 2. proposed a cluster-token alignment mechanism to assign each word to implied clusters % 3. our methods outperform previous approaches on eight of the different datasets of both short texts and long texts.    %   %         %             % % \begin{figure*}[thb] %   %         We proposed a two-way end-to-end bidirectional translation model, a single, yet joint  model based on a 2D grid. It permits sourcetarget and targetsource decoding along each axis, following joint training along both axes. However, it is a work-in-progress paper, and more work might be needed to prove its effectiveness. On a first attempt, the experimental results show that our architecture is able to generate reasonably good translations from source-to-target and target-to-source.  It has not yet reached parity on all tasks compared to separate models or a multilingual model in both directions using language tags; however, it offers a different and interesting modeling perspective.  These are the first experiments using the 2DLSTM cell for the bidirectional translation modeling, and we expect better results with more tuning. More work needs to be done, and we intend to try the tasks with less reordering, such as translation between very related languages or paraphrasing. Further exploration on a combination with non-autoregressive approaches is a correct research direction. We also believe such an architecture motivates an alignment model where we can use bidirectional encoders on both source and target sides to align the words. The traditional alignment models, like GIZA++  involve training models for both the directions and merging these bidirectional alignments afterward. We believe the two-way model with a combination of an attention mechanism is an appropriate candidate for such tasks where we are allowed to use bidirectional encoders.    We also wish to evaluate this model in a multi-way setting, where a multi-dimensional LSTM cell can be utilized as long as the complexity of the model and computational power allow.   
"," Distributional text clustering delivers semantically informative representations and captures the relevance between each word and semantic clustering centroids. We extend the neural text clustering approach to text classification tasks by inducing cluster centers via a latent variable model and interacting with distributional word embeddings, to enrich the representation of tokens and measure the relatedness between tokens and each learnable cluster centroid. The proposed method jointly learns word clustering centroids and clustering-token alignments, achieving the state of the art results on multiple benchmark datasets and proving that the proposed cluster-token alignment mechanism is indeed favorable to text classification. Notably, our qualitative analysis has conspicuously illustrated that text representations learned by the proposed model are in accord well with our intuition.",364
" Past work has found that variability in speech signals is often poorly modeled, despite recent advances in speech representation learning using deep neural networks . An important source of acoustic variability comes from accent information embedded in the speech signals . Non-native accents are frequently observed when a second language is spoken, and are mainly caused by the first language background of non-native speakers. The accent strength of a non-native speaker is dependent on the amount of transfer from the native language, and is generally influenced by a variety of variables from which the age of second-language learning is one of the most valuable predictors . However, accent variability is often overlooked in modeling language, and consequently high-resource languages such as English are often treated as homogeneous . That this assumption is problematic is, for example, shown by comparing the number of native and non-native speakers of English, with the latter group being almost twice as large as the former group . It is therefore important to accurately model pronunciation variation using representations of speech that allow this variability to be incorporated.  Traditionally, pronunciations are often represented and evaluated by phonetically transcribing speech . However, transcribing speech using a phonetic alphabet is time consuming, labor intensive, and interference from transcriber variation might lead to inconsistencies . Additionally, fine-grained pronunciation differences that are relevant for studying accented speech may not be captured by using a set of discrete symbols .  \citet{acoustic-measure} therefore introduced an acoustic-only measure for comparing pronunciations.  In their method, they represented accented speech as 39-dimensional Mel-frequency cepstral coefficients , which were used to compute acoustic-based non-native-likeness ratings between non-native and native speakers of English.  They found a strong correlation of  between their automatically determined acoustic-based non-native-likeness ratings and native-likeness ratings provided by human raters .  This result was close to, but still not equal to the performance of a phonetic transcription-based approach . \citet{acoustic-measure} also conducted several small-scale experiments to investigate whether more fine-grained characteristics of human speech were captured compared to the phonetic transcription-based pronunciation difference measure.  Their results showed that the acoustic-only measure captured segmental differences, intonational differences, and durational differences, but that the method was not invariant to characteristics of the recording device.  The quality of MFCC representations is known to be dependent on the presence of additive noise .  Recent work has shown that self-supervised representation learning models are less affected by noise, while being well-equipped to model complex non-linear relationships .  For example, these models can learn meaningful representations on the basis of read English speech without direct supervision. Fine-tuning these models using transcribed speech resulted in representations which resembled phonetic structure, and offered significant improvements in downstream speech recognition tasks .  Consequently, in this paper, we employ these self-supervised neural models to create an automatically determined acoustic-only pronunciation difference measure, and investigate whether this results in improved performance compared to the MFCC-based approach of \citet{acoustic-measure} and the phonetic transcription-based approach of \citet{wieling2014a}.  In the following, we compare and evaluate several neural models, namely , \citep[subsequently denoted by ]{schneider2019wav2vec},  ,  \citep[subsequently denoted by ]{baevski2019vq}, and  \citep[subsequently denoted by ]{baevski2020wav2vec}. We evaluate the performance of these algorithms using two different datasets. The first is identical to the dataset used by \citet{acoustic-measure} and \citet{wieling2014a}. The second is a new dataset which only focuses on accented speech from a single group of  non-native speakers for which human native-likeness judgements are also available. For reproducibility, we provide our code via \url{https://github.com/Bartelds/neural-acoustic-distance}. The performance of our model is assessed by comparing the obtained neural acoustic-only pronunciation differences to phonetic transcription-based pronunciation distances, MFCC-based acoustic-only pronunciation distances, and human perception.  To understand which aspects of pronunciation variation the neural models can capture, we conduct several additional small-scale experiments, in line with those of \citet{acoustic-measure}.      We analysed adding explicit morphological information in the form of embeddings for POS tags and morphological features to two currently dominant neural network architectures used in NLP: LSTM networks and transformer-based BERT models. We compared models enhanced with morphological information with baselines on three tasks . To obtain general conclusions, we used subsets of eight morphologically-rich languages from different language families.   The results indicate that adding morphological information to NER prediction models is not beneficial, but it improves the performance in the NER and DP tasks. For the DP task, the improvement depends on the quality of the morphological features. The additional morphological features consistently benefited LSTM-based models for NER and DP, both when they were of high quality and predicted . For BERT-based models, the predicted features do not make any practical difference for the NER and DP task but improve the performance in the DP task when they are of high quality. Testing different variants of BERT shows that language specialised variants improve the performance on the DP task and the additional morphological information is beneficial, though less and less as we shift from multilingual towards monolingual models.  The comparison of different BERT variants indicates that BERT models do not completely capture the language morphology.  Since the release of BERT, several new pre-training objectives have been proposed, such as syntactic and semantic phrase masking~ and span masking~. In further work, it makes sense to apply these models to the DP task in order to test how well they capture the morphology. Further, the effect of morphological features could be analysed on additional tasks and languages, since the explicit morphological information does not seem to benefit them equally.   \subsection*{Acknowledgements} This paper is supported by European Union閳ユ獨 Horizon 2020 Programme project EMBEDDIA . The research was supported by the Slovene Research Agency through research core funding no. P6-0411. The Titan X Pascal used for a part of this research was donated by the NVIDIA Corporation.   
"," Variation in speech is often represented and investigated using phonetic transcriptions, but transcribing speech is time-consuming and error prone. To create reliable representations of speech independent from phonetic transcriptions, we investigate the extraction of acoustic embeddings from several self-supervised neural models.  We use these representations to compute word-based pronunciation differences between non-native and native speakers of English, and evaluate these differences by comparing them with human native-likeness judgments.  We show that Transformer-based speech representations lead to significant performance gains over the use of phonetic transcriptions, and find that feature-based use of Transformer models is most effective with one or more middle layers instead of the final layer.  We also demonstrate that these neural speech representations not only capture segmental differences, but also intonational and durational differences that cannot be represented by a set of discrete symbols used in phonetic transcriptions.",365
" KR\&R systems work well for certain knowledge-rich domains that typically involve a  set of axioms or rules, use structured queries and datasets, and have a need for precise logical inference with explanations. Formal logic-based reasoning engines such as Cyc  and Ergo  have been successfully deployed in domains such as legal, healthcare and finance.  One of the main advantages of using such systems is transparency 閳 the underlying reasoning of the system is well-understood and can be justified to end-users.   However, there are several known drawbacks of logic-based approaches. For one, the inference procedures are highly brittle in that they require precise matching/unification of logical terms and formulae in order to construct a complete explanation. Secondly, traditional reasoners don閳ユ獩 deal with uncertainty well , whereas rules in real-world applications are often probabilistic and contextual. Thirdly, all such systems suffer from the knowledge acquisition problem . Often, the rules are hand-coded, an approach which doesn閳ユ獩 scale in general.  Our problem domain is Natural Language Understanding , an area where all the issues mentioned above come into play 閳 the need to acquire and use implicit background knowledge to understand text, the application of rules differently based on the context, and the use of imperfect/fuzzy alignment of concepts and relations when doing reasoning.   To address these issues, we devise a novel FOL-based reasoner, called Braid. Braid includes a backward and forward chainer, assumption based reasoner and a constraint solver. This paper only refers to the backward chaining component, which we refer to as Braid-BC.    Braid-BC supports rules with confidences, and uses the notion of custom unification functions and dynamic rule generation to overcome the brittle matching and knowledge-gap problem prevalent in traditional reasoning engines.  The custom-unifiers can be based on any statistical techniques, as long as they can propose and score mappings between the terms of two logical propositions . For example, we use neural matching functions as unifiers. Their purpose is to help the reasoner find proofs even when  goals, rule conditions and/or facts do not align perfectly.     The dynamic rule-generator  is given a target proposition  and a knowledge base  as input, and outputs a scored list of hypothesized rules that could be used to prove that proposition. The purpose of rule-generation is to connect the dots when the knowledge required for an inference is missing from the static KB. We describe two DRG implementations - one using a neural  rule generation model that was fine-tuned on a dataset of crowd-sourced causal rules, known as GLUCOSE , and the second that uses a rule-template based technique.     We describe the reasoning algorithms used in Braid-BC, and their implementation in a distributed task-based framework that builds proof/explanation graphs for an input query in a highly scalable manner. Our approach shares some similarities with the RETE framework  for matching production rules  but makes several novel extensions: we primarily do backward chaining via a heuristic best-first search , leverage a Master-Worker architecture where the Master builds the main proof graph while Workers make local inferential updates, and define general functions for Unifiers and Provers that lets us plug in various reasoning strategies combining standard reasoning  with statistical approaches .    In this work, we investigated the integration of structural information from a constituent tree in a neural model for Frame-semantic parsing. Constituent representations are learned through a GCN,   to learn encoded representations of syntactic constituents, which is trained with the specific task objective.  and used to build constituency path features to be added to every word representation in a sequence.  Each word in a sequence is enriched with syntactic information by summing all the constituent learned encodings on the path between the word and a task-specific node in the tree, e.g. the target word of a predicate.  We tested our approach on all the Frame-semantic parsing sub-tasks, namely Target Identification, Frame Identification, and Semantic Role Labeling, showing that such features contribute mainly on the TI and the SRL tasks.   Constituency path features can be applied  Future work will cover the application of the proposed constituency path features  to other sequence labelling based tasks, e.g. Named-Entity Recognition. Moreover, other modifications of GCNs have to be tested in this same framework, e.g. to assess whether Attention-based GCN may learn more refined constituent representations. Finally, these representations may be used in a node-classification approach, inspired by seminal works , in an attempt to move away from the well-used sequence labelling model of   recent years.        \clearpage      
","  Traditional symbolic reasoning engines, while attractive for their precision and explicability, have a few major drawbacks: the use of brittle inference procedures that rely on exact matching  of logical terms, an inability to deal with uncertainty, and the need for a precompiled rule-base of knowledge . These issues are particularly severe for the Natural Language Understanding  task, where we often use implicit background knowledge to understand and reason about text, resort to fuzzy alignment of concepts and relations during reasoning, and constantly deal with ambiguity in representations.   To address these issues, we devise a novel FOL-based reasoner, called Braid, that supports probabilistic rules, and uses the notion of custom unification functions and dynamic rule generation to overcome the brittle matching and knowledge-gap problem prevalent in traditional reasoners. In this paper, we describe the reasoning algorithms used in Braid-BC , and their implementation in a distributed task-based framework that builds proof/explanation graphs for an input query in a scalable manner. We use a simple QA example from a children闁炽儲鐛 story to motivate Braid-BC闁炽儲鐛 design and explain how the various components work together to produce a coherent logical explanation.",366
"}  {I}{n} the past decade, we have seen the emergence of various Knowledge Graphs , such as YAGO and DBPedia. They have achieved great success in both academic and industrial applications, ranging from recommendation to Question Answering. However, these KGs are far from complete, which limits the benefits of transferred knowledge. Relation Extraction  is a vital step to complete KGs by extracting the relations between entities from texts. It is nontrivial since the same relation type may have various textual expressions, and meanwhile, different types of relations can also be described with the same words. Such ambiguity between relations and texts challenges the supervision of RE models.  Due to the expensive human annotation cost, distant supervision is proposed to automatically annotate the mappings between sentences and relations. It assumes that if two entities participate in a relation, a.k.a., a triple  but express another relation . As shown in Figure, given the triple , we collect two sentences that include the entity pair . Clearly, the first sentence expresses a similar meaning with the given relation type, but the second one implies another type of relation city of, which brings in noise to the training corpora\footnote{As the term relation can refer to either relation type or relation instance , in the paper, we simplify the use of term relation for relation type unless otherwise stated.}. To highlight informative sentences, many existing works introduce the attention mechanism to assign sentences with different learning weights.  In terms of quantity, on the other hand, most of the training data collected by distant supervision concentrate mainly on a few relations, leading to the issue of the lack of sufficient annotations for the remaining relations. Take the widely used dataset, New York Times , as an example, we present the number of training instances of each relation in Figure. Unsurprisingly, the annotations are long-tail concerning different relations, and the tail relations suffer from insufficient training corpora. More specifically, each relation  refers to multiple entity pairs  is smaller than that between  should be more similar with respect to RE prediction distributions because of the more common textual contexts. Therefore, how to capture relation proximity in a more precise and general way remains challenging.  Another major challenge is to distinguish between different relations, in case the knowledge transfer introduces a bias towards the same prediction for proximate relations. For example, as mentioned above, both /location/us\_state/capital and /location/fr\_region/capital indicate the capital relation, and the only difference is that between two United States entities or French entities. DPEN incorporates entity type information to learn relation-specific classifier dynamically. However, entity type information is sparse in KGs , challenging the scalability.  To address the first issue, we propose to learn relation prototypes that capture the proximity relationship among relations from involved entity pairs. Inspired by Prototypical Networks, we represent each relation prototype with the centroid of its training data, and each data point is defined as the difference between the pair of entity embeddings, namely implicit mutual relation . Given any entity pair, we compute the implicit mutual relation and its distance to each relation prototype. These proximities suggest possible relations to the classifier, which further makes correct predictions by extracting discriminative signals from supportive sentences. Relation prototypes can also be enhanced by prior information , and be applied to arbitrary sentence encoder.  To address the second issue, we enhance entity embeddings with textual information for implicit mutual relation learning. In specific, we construct an entity co-occurrence graph from unlabeled texts and modeling both the first-order and second-order structural proximity. The massive textual contexts are helpful to infer entity types for distinguishment. Besides, long-tail entity pairs can also benefit from additional textual information. We summarize our main contributions as follows:    A preliminary version of this work has been published in the conference of ICDE 2020. We summarize the main changes as follows:    %The rest of the paper is organized as follows. In Section, we formulate the problem and overview the framework, and Section introduces our proposed method in detail. We report the promising experiment results on real-world datasets in Section. Section covers the related works. Finally, we conclude the paper in Section.      In this study, we explored the empirical study on AL utilizing the advantages of both uncertainty and diversity by selecting weighted diverse gradient embeddings to perform a sequence labeling task. We proposed an efficient method and empirically demonstrated that it could consistently achieve a superior performance while consuming much less data. It adds robustness to the dataset and the architecture, thus proving to be a useful option for solving real-world active learning problems   
","   Relation Extraction  is a vital step to complete Knowledge Graph  by extracting entity relations from texts. However, it usually suffers from the long-tail issue. The training data mainly concentrates on a few types of relations, leading to the lack of sufficient annotations for the remaining types of relations. In this paper, we propose a general approach to learn relation prototypes from unlabeled texts, to facilitate the long-tail relation extraction by transferring knowledge from the relation types with sufficient training data. We learn relation prototypes as an implicit factor between entities, which reflects the meanings of relations as well as their proximities for transfer learning. Specifically, we construct a co-occurrence graph from texts, and capture both first-order and second-order entity proximities for embedding learning. Based on this, we further optimize the distance from entity pairs to corresponding prototypes, which can be easily adapted to almost arbitrary RE frameworks. Thus, the learning of infrequent or even unseen relation types will benefit from semantically proximate relations through pairs of entities and large-scale textual information.      We have conducted extensive experiments on two publicly available datasets: New York Times and Google Distant Supervision. Compared with eight state-of-the-art baselines, our proposed model achieves significant improvements . Further results on long-tail relations demonstrate the effectiveness of the learned relation prototypes. We further conduct an ablation study to investigate the impacts of varying components, and apply it to four basic relation extraction models to verify the generalization ability. Finally, we analyze several example cases to give intuitive impressions as qualitative analysis. Our codes will be released later.    %Relation Extraction  is a paramount step to complete Knowledge Graph by extracting entity relations from texts. However, it usually suffers from the long-tail issue, as the training data mainly concentrates on a few types of relations, leading to the lack of sufficient annotations for the remaining types of relations. In this paper, we propose a general approach to learn relation prototypes from unlabeled texts, to facilitate the long-tail RE by transferring knowledge from those with sufficient data. We learn prototypes as an implicit factor between entities, to reflect the meanings of relations and their proximities. Specifically, we construct an entity co-occurrence graph from texts, and capture structural proximities for embedding learning. Furthermore, we optimize the distance from entity pairs to corresponding prototypes, which can be easily adapted to many RE framework. We have conducted extensive experiments on two publicly available datasets. Compared with eight state-of-the-art baselines, our model achieves significant improvements . Further results on long-tail relations demonstrate the effectiveness of the learned relation prototypes. We further conduct an ablation study to investigate the impacts of varying components and the generalization ability. Finally, we analyze several example cases to give intuitive impressions as qualitative analysis.",367
"  % Understanding how BERT works is important. % the presence of blackbox nlp  is an indication that the research community values the ability to understand the internals of deep neural networks. Pre-trained transformer models such as BERT  are currently ubiquitous within natural language processing  research and have demonstrated improvements in topics from sentiment analysis to semantic parsing . The widespread development and use of such models has led to an increased effort to interpret such models' decisions . % * understanding models is important in society % * BERT is used all over, so important to understand BERT As defined in \citet{doshivelez2017rigorous}, model interpretability is ``the ability [of a model] to explain or present in understandable terms to a human''.  Intuitively, a more interpretable model is easier to understand, debug and improve.  % It's hard to understand BERT because  % * it's a neural model with many, many parameters % * pre-training + fine-tuning is newer than just training from scratch  -> read literature introductions/motivations Interpreting modern pre-trained transformer models is difficult. First, modern deep learning models have hundreds of millions of parameters, and scale only continues to increase . Understanding the impact of a single parameter is nearly impossible because these models are densely connected. Combined with the sheer number of parameters, manual analysis is infeasible. Secondly, while both pre-training and fine-tuning are required for state-of-the-art performance, effort has focused on alternative pre-training methods . % Understanding the impacts of fine-tuning is still not well understood. \todo{do I need a citation here?}   % Previous work attempted to use attention Previous work uses BERT's self-attention mechanism to interpret the model's predictions . However, a body of work  shows that models' attention mechanisms cannot be interpreted on single-sequence classification tasks.  % We apply bert to a sequence classification task We apply BERT and two BERT-based models  to an existing sentence classification task proposed in \citet{aesw}. We compare BERT-based models' performances with previous baselines and then use methods presented in \citet{vashishth2019attention} and \citet{deyoung-etal-2020-eraser} to evaluate BERT's interpretability in single-sequence classification tasks. We find that fine-tuning can teach BERT to recognize previously unknown patterns in natural language and that BERT is more interpretable than the attention-based models analyzed in \citet{jain-wallace-2019-attention} and \citet{vashishth2019attention}. To summarize, the key contributions of this paper are:   % this is nice because  % * BERT hasn't been applied to it % * professional data set, we have a baseline, all human-annotated % * it has marked spans of edits before and after % To the best of our knowledge, BERT has not been applied to the Automatic Evaluation of Scientific Writing  task.     In conclusion, we have proposed a general approach to learn relation prototypes from unlabeled texts. The prototype learning method can be applied in current models for better relation extraction by transferring knowledge from relations with sufficient training data to long-tail relations. We have conducted extensive experiments to verify the effectiveness of the proposed method on two publicly available datasets and compared them with eight state-of-the-art baselines. The results present significant improvements, especially in long-tail settings. Further ablation study and case study also demonstrate the effectiveness of our proposed method and the generalization ability to current RE models from both quantitative and qualitative perspectives. In the future, we are interested in enhancing entity embeddings with KG including structure and attribute information.   investigating more advanced entity embedding models, such as Graph Attention Networks , to improve the implicit mutual relation representation as well as relation prototypes. Also, other side information  can be incorporated to enrich the entity co-occurrence graph for better modeling.  
"," Pre-trained transformer language models such as BERT are ubiquitous in NLP research, leading to work on understanding how and why these models work. Attention mechanisms have been proposed as a means of interpretability with varying conclusions. We propose applying BERT-based models to a sequence classification task and using the data set's labeling schema to measure each model's interpretability. We find that classification performance scores do not always correlate with interpretability. Despite this, BERT's attention weights are interpretable for over 70\% of examples.",368
"  .          % % final paper: en-us version           %   % space normally used by the marker     % This work is licensed under a Creative Commons      % Attribution 4.0 International License.     % License details:     % \url{http://creativecommons.org/licenses/by/4.0/}. }    Recently, neural machine translation  has demonstrated impressive performance improvements and became the de-facto standard .    However, like other neural methods, NMT is data-hungry.   This makes it challenging when we train such a model in low-resource scenarios .   Researchers have developed promising approaches to low-resource NMT.   Among these are data augmentation , transfer learning , and pre-trained models .   But these approaches rely on external data other than bi-text.   To date, it is rare to see work on the effective use of bilingual data for low-resource NMT.    In general, the way of feeding samples plays an important role in training neural models.   A good instance is that it is popular to shuffle the input data for robust training in state-of-the-art systems.   More systematic studies on this issue can be found in recent papers .   For example,  have pointed out that deep neural networks tend to prioritize learning ``easy'' samples first.   This agrees with the idea of curriculum learning  in that an easy-to-hard learning strategy can yield better convergence for training.    In NMT, curriculum learning is not new.   Several research groups have applied it to large-scale translation tasks although few of them discuss the issue in a low-resource setup .   The first question here is how to define the ``difficulty'' of a training sample.   Previous work resorts to functions that produce a difficulty score for each training sample.   This score is then used to reorder samples before training.   But the methods of this type enforce a static scoring strategy and somehow disagrees with the fact that the sample difficulty might be changing when the model is updated during training.   Another assumption behind curriculum learning is that the difficulty of a sample should fit the competence of the model we are training.   Researchers have implicitly modeled this issue by hand-crafted curriculum schedules  or simple functions , whereas there has no in-depth discussion on it yet.    In this paper, we continue the line of research on curriculum learning in low-resource NMT.   We propose a dynamic curriculum learning  method to address the problems discussed above.   The novelty of DCL is two-fold.   First, we define the difficulty of a sample to be the decline of loss .   In this way, we can measure how hard a sentence can be translated via the real objective used in training.   Apart from this, the DCL method explicitly estimates the model competence once the model is updated, so that one can select samples that the newly-updated model has enough competence to learn.      DCL is general and applicable to any NMT system.   In this work, we test it in a Transformer-based system on three low-resource MT benchmarks and different sized data selected from the WMT'16 En-De task.   Experimental results show that our system outperforms the strong baselines and several curriculum learning-based counterparts.         future work and applications   might use edited versions as negative cases   seq2seq model?   compare with non-bert attention models? In this paper, we apply three BERT-based models to a sentence classification task, then quantify their interpretability through a small-scale manual study before expanding to a larger-scale automated study. We find that BERT's final attention layer is clearly interpretable by both human annotators and simple automated metrics.  Future work might expand the subset of examples that can be automatically annotated in order to further understand BERT's interpretability on different classes of edits. Additionally, more work is needed to understand the impacts of in-domain pre-training on model interpretability.     
","      Large amounts of data has made neural machine translation  a big success in recent years.    But it is still a challenge if we train these models on small-scale corpora.   In this case, the way of using data appears to be more important.    Here, we investigate the effective use of training data for low-resource NMT.   In particular, we propose a dynamic curriculum learning  method to reorder training samples in training.   Unlike previous work, we do not use a static scoring function for reordering.   Instead, the order of training samples is dynamically determined in two ways - loss decline and model competence.   This eases training by highlighting easy samples that the current model has enough competence to learn.    We test our DCL method in a Transformer-based system.   Experimental results show that DCL outperforms several strong baselines on three low-resource machine translation benchmarks and different sized data of WMT'16 En-De.",369
" Searching for code fragments is a very common activity in software development. The advent of large code repositories like GitHub\footnote{https://github.com/} and StackOverflow\footnote{https://stackoverflow.com/} has only increased the number of developers to rely on these repositories to search and reuse existing code . Traditional Information Retrieval techniques  do not work well for code search and retrieval tasks due to limited shared vocabulary between the source code and the natural language search text . Often, developers who are new to a programming language, search for code snippets in a context-free natural language. The choice of words used to search may not overlap with the code snippets leading to failure of traditional information retrieval systems. Therefore, there is a need to gain a deeper understanding of code and text in order to find semantically relevant code snippet.  Consider an example where a developer has a functional requirement to validate if age is always lesser than  and alert otherwise. The developer is tasked to enforce this check in Java. A naive Java developer who is not familiar with the language might make a query based on the requirement as: java check condition correctness. The top 10 results\footnote{As of December 9, 2019} in StackOverflow do not discuss the assert keyword. A more programming friendly query such as java boolean check or the assert keyword itself results in code snippets demonstrating the steps as the top result in StackOverflow.  Use of deep neural network models have shown tremendous improvements in many tasks across domains including language tasks . This success can be largely attributed, in part, to their ability to learn meaningful relationships among words in documents efficiently and represent them in a way such that semantically equivalent words tend to have similar representations . One such family of models that are popular for determining text similarity are Siamese networks. First introduced by , a typical Siamese network consists of two identical sub networks that share weights. They work in tandem on different inputs and the output of both the networks are evaluated by a distance measure that also acts as a scoring function. This has been successfully applied in many similarity tasks in image domain  and recently in text domain as well . Another useful property of these models is their capability to learn from fewer data examples . Since code can be treated as a special kind of text data, one possible way to approach the problem of Semantic Code Search  is to treat it as a similarity task where the objective is to bring semantically equivalent code snippets and their natural language descriptions closer. Therefore, we study the application of Siamese networks to code and corresponding text descriptions for semantic code search.  We apply multiple variations of the base Siamese network model on two different datasets for semantic code search and study its efficacy.  We further take the state of the art baselines -  and  on these datasets and observe that Siamese networks can improve over the baseline results invariably . Finally, we present our analysis on the  performance of different Siamese network architectures explored and identify the conditions for improved performance.  The rest of the paper is organized as follows. We introduce some relevant prior art in section . Next, in section , we provide some background on Siamese networks and semantic code search and introduce terminology. In section , we describe our approach and the different architectures investigated. In section , we describe our experiments and present the results. Finally in section , we perform a detailed analysis of our observations, followed by conclusions in section .  % \tikz \draw[]  rectangle  node[pos=.2]{Answer Here:};    In this paper, we show that using non-binary constituency trees can be beneficial, especially in semantic similarity tasks. Moreover, we highlight the need of powerful composition function to exploit such a rich representation. To this end, we have introduced a new Tree-LSTM model which leverages tensor canonical decomposition and weight sharing to process non-binary trees without adding new parameters.  Such results pave the way to the definition of new tensor models which leverage suitable tensor decomposition to take advantage of non-binary constituency trees. To this end, the next step would be the application of other tensor decompositions. Among the others, the tensor train decomposition seems to be promising to define new composition functions which are sensitive to child nodes order.  Ultimately, we would like to test multiple tensor-based models on different NLP tasks, studying the relation between the bias introduced by each different tensor decomposition and the intrinsic property of the task.  
"," % Availability of large code repositories and discussion forums, has enabled code search as a common activity among developers. They tend to express their intent as a query in natural language to find examples of related code. However performance of such systems are restricted due to 1) limited shared vocabulary across code and user query and 2) lack of semantic understanding of the user query.   % In this work, we evaluate Siamese network for the task of code retrieval. Building on two sub network, our siamese model can jointly learn between code and its description and represent them based on their semantic distance. We evaluate the performance of applying siamese networks 1) as a stand-alone model directly feeding code and its description 2) as a model stacked on existing state of the art models. We experiment on 2 datasets and 3 baseline models, and conclude that applying siamese networking on top of base models yield better embedding and improves the performance of the code sesearch taks significantly.  With the increase in the number of open repositories and discussion forums, the use of natural language for semantic code search has become increasingly common. The accuracy of the results returned by such systems, however, can be low due to 1) limited shared vocabulary between code and user query and 2) inadequate semantic understanding of user query and its relation to code syntax. Siamese networks are well suited to learning such joint relations between data, but have not been explored in the context of code search. In this work, we evaluate Siamese networks for this task by exploring multiple extraction network architectures. These networks independently process code and text descriptions before passing them to a Siamese network to learn embeddings in a common space. We experiment on two different datasets and discover that Siamese networks can act as strong regularizers on networks that extract rich information from code and text, which in turn helps achieve impressive performance on code search beating previous baselines on $2$ programming languages. We also analyze the embedding space of these networks and provide directions to fully leverage the power of Siamese networks for semantic code search.",370
"  We are motivated by the problem of labelling a dataset for word sense disambiguation, where we want to use a limited budget to collect annotations for a reasonable number of examples of each sense for each word.  This task can be thought of as an active learning problem , but with two nonstandard challenges. First, for any given word we can get a set of candidate labels from a knowledge base such as WordNet . However, this label set is not necessarily representative of what occurs in the data: there may exist labels in the knowledge base that do not occur in the corpus because the sense is rare in modern English;  conversely, there may also exist true labels that do not exist in our knowledge base. For example, consider the word ``bass.'' It is frequently used as a noun or modifier, e.g., ``the bass and alto are good singers'', or ``I play the bass guitar''. It is also commonly used to refer to a type of fish, but because music is so widely discussed online, the fish sense of the word is orders of magnitude less common than the low-frequency sound sense in internet text. The Oxford dictionary  also notes that bass  once referred to a fibrous material used in matting or chords, but that sense is not common in modern English. We want a method that collects balanced labels for the common senses, ``bass frequencies'' and ``bass fish'', and ignores sufficiently rare senses, such as ``fibrous material''. Second, the empirical distribution of the true labels may exhibit extreme skew: word sense usage is often power-law distributed  with frequent senses occurring orders of magnitudes more often than rare senses.    When considered individually, neither of these constraints is incompatible with existing active learning approaches:  incomplete label sets do not pose a problem for any method that relies on classifier uncertainty for exploration ; and extreme skew in label distributions has been studied under the guided learning framework wherein annotators are asked to explicitly search for examples of rare classes rather than simply label examples presented by the system .  But taken together, these constraints make standard approaches impractical. Search-based ideas from guided learning are far more sample efficient with a skewed label distribution, but they require both a mechanism through which annotators can search for examples and a correct label set because it is undesirable to ask annotators to find examples that do not actually occur in a corpus.    Our approach is as follows. We introduce a frequency threshold, , below which a sense will be deemed to be ``sufficiently rare'' % to be ignored  = p_y < \thresholdp_y\hat{p}_y$ by using importance-weighted samples. Once we have found examples of common classes, we switch to more standard active learning methods to find additional examples to reduce classifier uncertainty.  Overall, this paper makes two key contributions. First, we present an Exemplar Guided Active Learning  algorithm that offers strong empirical performance under extremely skewed label distributions by leveraging exemplar embeddings. Second, we identify a stopping rule that makes EGAL robust to misspecified label sets and prove that this robustness only imposes a logarithmic cost over a hypothetical approach that knows the correct label set.  Beyond these key contributions, we also present a new Reddit word sense disambiguation dataset, which is designed to evaluate active learning methods for highly skewed label distributions.    In this section, we analyze the results obtained above to understand the behavior of the DCS-Siamese network. We focus on this architecture since it outperforms all other architectures and baseline models considered. Specifically, we would like to analyze three observations:  A. Regularization effect of the DCS-Siamese model over the original DCS architecture  We visualize the embeddings learnt by the DCS network  and the output of the DCS extraction network, after using the Siamese network, for the text descriptions in the StaQC SQL dataset using t-SNE  in Figure . We consider the SQL dataset for visualization since the raw queries and code snippets are not available for the Java dataset.   A quick examination reveals that the embedding space has sharp, distinct clusters for the DCS-Siamese network , whereas the clusters in the original DCS network  are relatively smaller and more scattered. Further, we manually examined some of the clusters and evaluated the questions that are mapped to those clusters. Few samples are listed in Table . For the query groups DATE and JOIN, the clusters are scattered in different regions for the original DCS network. Also, the cluster corresponding to the MAX query group is adjacent to the DATE cluster. Comparatively, for the same query groups, the clusters for the DCS-Siamese network are well separated and coherent. This highlights the role of Siamese network as a regularizer when applied on top of the DCS network. The Siamese network seemingly helps in rearranging the embedding space leading to more meaningful representations, bringing similar inputs  closer in the embedding space. This effect is further reflected in the better retrieval MRR of the DCS-Siamese network.     We observe this result for both the datasets. In our experiments, the difference between the results of  and  variesd but we observe a clear trend in favor of . To understand the superior performance of , we visualize the embeddings learnt by the DCS-Siamese network at the DCS layer for two architectures with  and  respectively as shown in Figure . We consider the SQL dataset for visualization since the raw queries and code snippets are not available for the Java dataset. We use tSNE to plot the DCS embeddings for . A quick examination reveals that the embedding space has sharp, distinct clusters when , whereas the clusters when  are relatively diffused. Further, we manually examined some of the clusters and evaluated the questions that are mapped to those clusters. Some samples are listed in Table . Apart from the fact that the clusters in the right figure are smaller for the four sets of queries we examined, the ones on the left blend in with the other points in the figure, implying that the network has done a poor job at learning to distinguish between different queries at the DCS layer when . Its is unsurprising that we achieve better MRR when Code retrieval is performed at the DCS layer for .    This hints at the possibility that the narrow funnel in the network caused by having  output units at the top of the Siamese network act as a regualarizer that forces the lower layers to learn more meaningful embeddings, which in turn helps the overall task when using those embeddings for retrieval. We did observe 1 exception to this when we evaluated on the Siamese layer output with . However, the difference in performance was only marginal. This visualization, coupled with the results in Table  clearly establishes the value of the  DCS-Siamese network.     We have also observed the inverse of this regularization effect for other values of  and the model performance gradually degrades as the value of  increases.     This also explains why the clusters corresponding to a given set of similar queries are extremely well defined for the embeddings at the DCS layer than the embeddings at the top layer of the network. The restriction to compact information into 2 dimensions has led to a loss of information in the 2-d embedding space for a given set of queries, but this has led the DCS layer to learn a rich set of embeddings.    figure out how to show and pitch the scatter plot of the correct-wrong pairs of points, if at all needed    If this argument indeed holds, we would see a gradual loss of information as we look at the embeddings at the other intermediate layers of the network, upto the final layer. We visualize the embeddings of the layer between the DCS output and the final layer using tSNE for the same set of queries in table X. Indeed, we see that the cluster representing the queries in the embedding space of the intermediate layer is somewhat scattered, but not as much as that of the final layer.       B. For the DCS-Siamese network, retrieval on the output of DCS layer achieves higher MRR  We now focus on the actual embeddings learnt at the different layers of the DCS-Siamese network with .  Figure  shows the embedding plots of the final Siamese layer  and the output of the DCS layer . We focus on two specific set of queries shown in Table . We believe having  output units results in a much stronger regularization effect leading to these two sets of questions being mapped to well-defined regions in the embedding space.    As discussed earlier, the regularization effect of having  output units results in much better embedding at the DCS layer resulting in these  sets of questions being mapped to well-defined regions in the embedding space.  However, due to the low dimensionality at the final layer, there is a tremendous loss of information that deprives the layer of any meaning to its representations. The purpose of the representations is to simply reduce the loss function and guide the gradient forcing the lower layers to learn a much more meaningful embedding. The actual meaning to representations of code and text is hence obtained at a lower layer.  This effect is also consistent for embeddings of code, as observed in Figure , where we generated   a plot of the embeddings of the SQL queries corresponding to the questions in Table . In comparison, to the DCS layer embedding of the DSC-Siamese network , we observed more than one clusters for the sorting questions .      This is due to the fact that any question that involves a deletion would more-or-less be always translated to a 'DELETE FROM' clause in code . However, there could be several questions that might not explicitly ask about sorting, but still require sorting as an intermediate step in the answer. The code corresponding to such answers would have an 'ORDER BY' clause, but depending on the actual question, might involve other SQL clauses.  To summarize,  has a far stronger regularizing effect on the network as compared to larger values. However, due to this effect, there seems to be a loss of information in the final layers of the Siamese network and hence, the embeddings learned by the lower layers of the network contain richer information for the Code retrieval task.  C. The DCS extraction network greatly outperforms the other extraction networks when combined with Siamese networks  We selected the DCS setup as an extraction network because it leveraged a variety of features from code. Although we believe these features are collectively responsible for the impressive performance of the DCS-Siamese model, when considered individually with a Siamese network, they are unable to provide enough information during training, leading to an extremely poor model. This hints at the possibility that providing code as input to a deep learning network may not be straightforward and although the DCS features worked well, there are possibly other features that need to be discovered. Also, some code features might be useful for certain datasets, but not for all.     once you hav explained select and find/get/fetch are far apart, give a solution how to fix that   This result is surprising since [togther we stand paper] has reported impressive results using siamese networks with simple preprocessing and a conv-pooling-relu-FC network. However, when applied to code retrieval, siamese networks with different model architectures and embeddings sizes do not perform as well as other models such as [dcs][coacor] that rely on extracting multiple features from code. We hypothesize that this is due to different vocabularies as well as different mearnings of the same terms in code and text. For instance, the question and answer pairs of [together we stanbd paper] come from the same language , even though the distributions of these terms in questions and answers might be different.    actually, we need to think more on this and come up with more convincing experiemnts and results      Using an ablation study, we identify that API sequence tokens provide the highest performance of all the features used by the DCS model also mention this in training/model details of the simple models. \section{Conclusion and Future Work} Siamese networks can achieve impressive performance on Code Retrieval tasks by learning a meaningful embedding of code and it's description text. This performance is heavily reliant on an appropriate representation of code and we have observed that the DCS architecture can achieve this reasonably well. However, while we have some understanding of the regularization provided by the Siamese network, we would like to study this effect in more detail as future work. We would also like to validate our observations on more datasets and other tasks involving code and natural language text such as Code Summarization and Code Synthesis.    File acl2020.tex      Based on the style files for ACL 2020, which were    Based on the style files for ACL 2018, NAACL 2018/19, which were    Based on the style files for ACL-2015, with some improvements     taken from the NAACL-2016 style    Based on the style files for ACL-2014, which were, in turn,    based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,    EACL-2009, IJCNLP-2008...    Based on the style files for EACL 2006 by    e.agirre@ehu.es or Sergi.Balari@uab.es    and that of ACL 08 by Joakim Nivre and Noah Smith  \documentclass[11pt,a4paper]{article} \usepackage[hyperref]{acl2020} \usepackage{times} \usepackage{latexsym} \usepackage{tikz} \usepackage{multirow} \renewcommand{\UrlFont}{\ttfamily\small}    This is not strictly necessary, and may be commented out,   but it will improve the layout of the manuscript,   and will typically save some space. \usepackage{microtype}   \aclfinalcopy   Uncomment this line for the final submission   \def\aclpaperid{***}    Enter the acl Paper ID here   \setlength\titlebox{5cm}   You can expand the titlebox if you need extra space   to show all the authors. Please do not make the titlebox   smaller than 5cm ; we will check this   in the camera-ready version and ask you to change it back.  \newcommand\BibTeX{B\TeX}  \title{Evaluation of Siamese Networks for Semantic Code Search}     \author{}  \author{Raunak Sinha \\   IBM Research \\   \texttt{rsinha05@in.ibm.com} \\\And   Utkarsh Desai \\   IBM Research \\   \texttt{udesai26@in.ibm.com} \\\And   Srikanth Tamilselvam \\   IBM Research \\   \texttt{srikanth.tamilselvam@in.ibm.com} \\\And   Senthil Mani  \date{}                   
"," We consider the problem of wisely using a limited budget to label a small subset of a large unlabeled dataset. We are motivated by the NLP problem of word sense disambiguation. For any word, we have a set of candidate labels from a knowledge base, but the label set is not necessarily representative of what occurs in the data: there may exist labels in the knowledge base that very rarely occur in the corpus because the sense is rare in modern English; and conversely there may exist true labels that do not exist in our knowledge base. Our aim is to obtain a classifier that performs as well as possible on examples of each 闁炽儲绔穙mmon class闁 that occurs with frequency above a given threshold in the unlabeled set while annotating as few examples as possible from 闁炽儲绗re classes闁 whose labels occur with less than this frequency. The challenge is that we are not informed which labels are common and which are rare, and the true label distribution may exhibit extreme skew. We describe an active learning approach that  explicitly searches for rare classes by leveraging the contextual embedding spaces provided by modern language models, and  incorporates a stopping rule that ignores classes once we prove that they occur below our target threshold with high probability. We prove that our algorithm only costs logarithmically more than a hypothetical approach that knows all true label frequencies and show experimentally that incorporating automated search can significantly reduce the number of samples needed to reach target accuracy levels.",371
" Argumentation is a paramount process in society, and debating on socially relevant topics requires high-quality and relevant arguments. In this work, we deal with the problem of argument search, which is also known as argument retrieval. The goal is to develop an \acrfull{arg_ret_sys} which organizes arguments, previously extracted from various sources  , in an accessible form. Users then formulate a query to access relevant arguments retrieved by the \acrshort{arg_ret_sys}.  The query can be defined as a topic, e.g. Energy in which case the \acrshort{arg_ret_sys} retrieves all possible arguments without further specification. Our work deals with a more advanced case, where a query is formulated in the form of a claim, and the user expects premises attacking or supporting this query claim.  An example of a claim related to the topic Energy could be ``We should abandon Nuclear Energy"" and a supporting premise, e.g., ``Accidents caused by Nuclear Energy have longstanding negative impacts"". % A popular search methodology to find relevant premises is a similarity search, where the representations of the retrieved premises are similar to the representation of the  query claim. However, as noted by, the relevance of a premise does not necessarily coincide with pure text similarity.  Therefore, the authors of  advocate to utilize the similarity between the query claim and other claims in an \acrshort{arg_ret_sys} database and retrieve the premises assigned to the most similar claims. However, such \acrshort{arg_ret_sys} requires ground truth information about the premise to claim assignments and therefore has limited applicability: Either the information sources are restricted to those sources where such information is already available or can automatically be inferred, or expensive human annotations are required. To mitigate this problem and keep the original system's advantages, we propose to use a machine learning model to learn the relevance between premises and claims. Using this model, we can omit the  claim-claim matching step and evaluate the importance of  candidate premises directly for the query claim. Since the relevance is defined on the semantic level, we have to design an appropriate training task to enable the model to learn semantic differences between relevant and non-relevant premises. Furthermore, an essential subtask for an \acrshort{arg_ret_sys} is to ensure that the retrieved premises do not repeat the same ideas.  Previous approaches employ clustering to eliminate duplicates.  However, clustering approaches often group data instances by other criteria than expected by the users, as also observed in \gls{argument-mining} applications.  For our method, we propose an alternative to clustering based on the idea of core-sets, where the goal is to cover the space of relevant premises as well as possible. % This is samplepaper.tex, a sample chapter demonstrating the % LLNCS macro package for Springer Computer Science proceedings; % Version 2.20 of 2017/10/04 % \documentclass[runningheads]{llncs} % \usepackage{graphicx} \usepackage{xcolor} \usepackage{amsmath} \usepackage{amssymb} %\usepackage{ulem} \usepackage{multirow} \usepackage{booktabs} \usepackage{footnote} \makesavenoteenv{tabular} \makesavenoteenv{table} \usepackage{cite} \usepackage[ruled,vlined]{algorithm2e} \usepackage{float} \interfootnotelinepenalty=10000  % Used for displaying a sample figure. If possible, figure files should % be included in EPS format. % % If you use the hyperref package, please uncomment the following line % to display URLs in blue roman font according to Springer's eBook style: \usepackage{hyperref} \renewcommand\UrlFont{\color{blue}\rmfamily}  % for equal contribution \makeatletter \newcommand{\printfnsymbol}[1]{%   \textsuperscript{\@fnsymbol{#1}}% } \makeatother  % \title{Diversity Aware Relevance Learning for Argument Search} % %\titlerunning{Abbreviated paper title} % If the paper title is too long for the running head, you can set % an abbreviated paper title here %  \author{ Michael Fromm\thanks{equal contribution}\inst{1} %\orcidID{0000-0002-7244-4191} \and Max Berrendorf\printfnsymbol{1} \inst{1} %\orcidID{0000-0001-9724-4009} \and Sandra Obermeier \inst{1}  \and Thomas Seidl \inst{1} %\orcidID{0000-0002-4861-1412} \and Evgeniy Faerman \inst{1} }   \authorrunning{Fromm et al.} % First names are abbreviated in the running head.  % If there are more than two authors, 'et al.' is used.   \institute{Database Systems and Data Mining, LMU Munich, Germany  \\  \email{fromm@dbs.ifi.lmu.de}}   \newcommand{\todo}[1]{\textcolor{red}{#1}}  % Acronyms \usepackage[acronym]{glossaries} %\makeglossaries  % Example % \newacronym{acrid}{ACR}{Acronym for Clustering Representations} % \acrshort{arcrid} -> ACR % \acrlong{arcid} -> Acronym for Clustering Representations % \acrfull{arcid} -> Acronym for Clustering Representations  \newacronym{argument-mining}{AM}{Argument Mining} \newacronym{arg_ret_sys}{ARS}{Argument Retrieval System} \newacronym{bert-based-premise-representation}{BERT}{BERT} \newacronym{claim-based-premise-representation}{CLAIM-SIM}{CLAIM-SIM} \newacronym{relevance-model}{relevance-model}{relevance model}  % methods \newacronym{dumani-first512}{first512}{Dumani first512} \newacronym{dumani-sentences}{sentences}{Dumani sentences} \newacronym{dumani-sliding-window}{sliding}{Dumani sliding} \newacronym{bert-zero-shot-knn}{BERT Zero-Shot}{BERT Zero-Shot} \newacronym{learned-similarity-knn}{Learned Similarity}{Learned Similarity} \newacronym{biased-coreset}{Biased Coreset}{Biased Coreset}  \newacronym{bert-zero-shot-clustered}{BERT Zero-Shot + Cluster}{}   \DeclareMathOperator*{\argmax}{argmax}  %\newcommand{\relevanceModel}{relevance model }  % \newcommand{\dumaniFirst}{Dumani first512 } % \newcommand{\dumaniSentences}{Dumani sentences }  % \newcommand{\dumaniSliding}{Dumani sliding }  % \newcommand{\topSimilar}{Premise Similarity } % \newcommand{\topSimilarClusterRepresentatives}{Clustered Premise Similarity } % \newcommand{\mostImportant}{Premise Importance }  % \newcommand{\BertNegatives}{Bert-Negatives } % \newcommand{\SimpleNegatives}{Simple-Negatives } % \newcommand{\SameTopicNegatives}{Same-Topic-Negatives }  % disable hyperref for glossaries  \glsdisablehyper      \keywords{Argument Similarity  \and Argument Clustering \and Argument Retrieval}         We present the Exemplar Guided Active Learning algorithm that leverages the embedding spaces of large scale language models to drastically improve active learning algorithms on skewed data. We support the empirical results with theory that shows that the method is robust to mis-specified target classes and give practical guidance on its usage. Beyond word-sense disambiguation, we are now using EGAL to collect multi-word expression data, which shares the extreme skew property.  
"," In this work, we focus on retrieving relevant arguments for a query claim covering diverse aspects. State-of-the-art methods rely on explicit mappings between claims and premises and thus cannot utilize extensive available collections of premises without laborious and costly manual annotation. Their diversity approach relies on removing duplicates via clustering, which does not directly ensure that the selected premises cover all aspects. This work introduces a new multi-step approach for the argument retrieval problem. Rather than relying on ground-truth assignments, our approach employs a machine learning model to capture semantic relationships between arguments. Beyond that, it aims to cover diverse facets of the query instead of explicitly identifying duplicates.  Our empirical evaluation demonstrates that our approach leads to a significant improvement in the argument retrieval task, even though it requires fewer data than prior methods. Our code is available at \url{https://github.com/fromm-m/ecir2021-am-search}.",372
"  Speaker diarization is the process of partitioning an audio stream into homogeneous segments according to speaker identities. Thus, diarization determines ``who spoke when'' in a multi-speaker environment, with a variety of applications to conversations involving multiple speakers, such as meetings, television shows, medical consultations, or call center conversations. In particular, the speaker boundaries produced by a diarization system can be used to map transcripts generated by a multi-speaker automatic speech recognition  system into speaker-attributed transcripts . Moreover, speaker embeddings inferred by diarization can help the ASR system adapt to, or focus on the speech of a targeted speaker .   Conventional speaker diarization systems are based on clustering of speaker embeddings. In this approach, several components are integrated into a single system: speech segments are determined by voice activity detection ; these speech segments are further divided into smaller chunks of fixed size; speaker embeddings are then extracted by speaker embedding extractors for each chunk; finally, those speaker embeddings are clustered to map each segment to a speaker identity . For embeddings, i-vectors , x-vectors , or d-vectors  are commonly used. Clustering methods typically used for speaker diarization are agglomerative hierarchical clustering  , k-means clustering , and spectral clustering . Recently, neural network-based clustering has been explored . Clustering-based speaker diarization achieves good performance but has several shortcomings. First, it relies on multiple modules  that are trained separately. Therefore, clustering-based systems require careful joint calibration in the building process. Second, systems are not jointly optimized to minimize diarization errors; clustering in particular is an unsupervised process. Finally, clustering does not accommodate overlapping speech naturally, even though recent work has proposed ways to handle regions with simultaneously active speakers in clustering .  End-to-end neural diarization  with self-attention  is one of the approaches that aim to model the joint speech activity of multiple speakers. It integrates voice activity and overlap detection with speaker tracking in end-to-end fashion.  Moreover, it directly minimizes diarization errors and has demonstrated excellent diarization accuracy on two-speaker telephone conversations. However, EEND as originally formulated is limited to a fixed number of speakers because the output dimension of the neural network needs to be prespecified. Several methods have been proposed recently to overcome the limitations of EEND. One approach uses a speaker-wise chain rule to decode a speaker-specific speech activity iteratively conditioned on previously estimated speech activities . Another approach proposes an encoder/decoder-based attractor calculation . The embeddings of multiple speakers are accumulated over the time course of the audio input, and then disentangled one-by-one, for speaker identity assignment by speech frame.  However, all these state-of-the-art EEND methods only work in an offline manner, which means that the complete recording must be available before diarization output is generated. This makes their application impractical for settings where potentially long multi-speaker recordings need to be processed incrementally .   In this study, we propose a novel method to perform EEND in a blockwise online fashion so that speaker identities are tracked with low latency soon after new audio arrives, without much degradation in accuracy compared to the offline system. We utilize the incremental Transformer encoder, where we attend to only its left contexts and ignore its right contexts, thus enabling blockwise online processing. Furthermore, the incremental Transformer encoder uses block-level recurrence in the hidden states to carry over information block by block, reducing computation time while attending to previous blocks. To our knowledge, ours is the first method that uses the incremental Transformer encoder with block-level recurrence to enable online speaker diarization.     In this work, we have presented a novel approach for the retrieval of relevant and original premises for the query claims. Our new approach can be applied more flexibly than previous methods since it does not require mappings between premises and claims in the database.  Thus, it can also be applied in an inductive setting, where new premises can be used without the need first to associate them with relevant claims manually. At the same time, it achieves better results than approaches that make use of this information.  
"," We present a novel online end-to-end neural diarization system, BW-EDA-EEND, that processes data incrementally for a variable number of speakers. The system is based on the Encoder-Decoder-Attractor  architecture of Horiguchi et al., but utilizes the incremental Transformer encoder, attending only to its left contexts and using block-level recurrence in the hidden states to carry information from block to block, making the algorithm complexity linear in time. We propose two variants: For unlimited-latency BW-EDA-EEND, which processes inputs in linear time, we show only moderate degradation for up to two speakers using a context size of 10 seconds compared to offline EDA-EEND. With more than two speakers, the accuracy gap between online and offline grows, but the algorithm still outperforms a baseline offline clustering diarization system for one to four speakers with unlimited context size, and shows comparable accuracy with context size of 10 seconds. For limited-latency BW-EDA-EEND, which produces diarization outputs block-by-block as audio arrives, we show accuracy comparable to the offline clustering-based system.",373
"  {M}{usic} composition is a human creative process that requires a wide range of strong musical knowledge and expertise to create soothing music which continues to remain in our heart forever. Given the vast majority of music lovers and the limited availability of professional music composers, there is a strong need for machines to assist human creativity. Recent advancement in the software based music creation technology helped the professional and amateur music creators to produce music with great joy and ease of production in masses to be consumed by the music consumers with personal computers and hand-held devices. %The software applications such as Ableton Live, FL Studio, Logic Pro X, Garageband are the few examples which changed the way the music is produced in the past.  Though there exists a plenty of machine assistance to create high quality music with relative ease of production, the process of songwriting that is automatically generating lyrics, composing melody corresponding to the generated lyrics and synthesizing singing voice corresponding to the generated melody and lyrics remained as mutually exclusive tasks. Till date, the construction of novel/original songs is limited to the individuals who possess the following skills: the ability to create lyrics, compose melody and combine lyrics and melody to create a rational, relevant and soothing final complete songs. %Though by remixing technology, we can create new music to some extent which satisfies some music lovers, there is a need for creating truly novel songs under multiple constraints on remaking existing works.                       % -------------------------------------------------------------------------------------------------------------             In literature, we can find considerable amount of research work published on automatic music generation . Early machine assisted music generation is mostly based on music theory and expert domain knowledge to create novel works. With the advent of data driven approaches and exploded public music collections in the internet, data driven methods such as Hidden Markov models, graphic models and deep learning models showed a potential for music creation. Though there exists substantial amount of research on unconditional music generation, there exists considerably less amount of work done so far on generating melody from lyrics given in the form of text, which we call conditional melody/song generation from lyrics. The primary reasons for substantially less research on conditional melody generation can be attributed to i) the non-availability of the direct source for lyrics-melody pair dataset to train the data driven models, ii) a lyrics composition can have multiple melodic representations, which makes it hard to learn the correlation between the lyrics and melodies, and iii) it is hard to evaluate the generated melodies by objective measures.  This paper focuses on the most challenging aspect of algorithmic songwriting process which enables the human community to discover original lyrics, and  melodies suitable for the generated lyrics. To the best our knowledge, the proposed AutoNLMC is the first attempt to make the whole process of songwriting automatic using artificial neural networks. We also present the lyrics to vector model which is trained on a large dataset of popular English songs to obtain the dense representation of lyrics at syllables, words and sentence levels. The proposed AutoNLMC is an attention based encoder-decoder sequential recurrent neural network model consists of a lyric generator, lyric encoder and melody decoders trained end-to-end. We train several encoder-decoder models on various dense representations of the lyric tokens to learn the correlation between lyrics and corresponding melodies. Further, we prove the importance of dense representation of lyrics by various qualitative and quantitative measures. AutoNLMC is designed in such a way that it can generate both lyrics and corresponding melodies automatically for an amateur or a person without music knowledge by accepting a small piece of initial seed lyrics as input. It can also take lyrics from professional lyrics writer to generate the matching meaningful melodies.     In this paper, we propose a joint enhancement and speech transformer training method with gated recurrent fusion for robust end-to-end speech recognition. The joint training compositional scheme is used to simultaneously optimize the enhancement and speech recognition. In addition, in order to address the speech distortion problem and extract more robust features for end-to-end ASR, we apply the gated recurrent fusion algorithm to combine the noisy and enhanced features. Experiments on Mandarin AISHELL-1 demonstrate that our proposed method is effective for the robust end-to-end ASR and can solve the speech distortion problem very well. In future, we will explore the time domain speech enhancement to acquire a better enhanced speech and obtain greater performance improvement for our proposed method.  In this paper, we propose a jointly traning of enhancement and speech transformer to imporove robustness of end-to-end systems. We use a jointly compositional scheme of enhancement and recognition. In addition, in order to alleviate the speech distortion problem and extract more robust features for ASR, we propose the deep attention fusion algorithm to combine the noisy and enhanced features.  Experiments on AISHELL-1 demonstrate effectiveness of our proposed method. In future, we will explore the time domain speech enhancement to acquire a better enhanced speech and obtain greater performance improvement for our proposed method.    
"," In this paper, we propose a technique to address the most challenging aspect of algorithmic songwriting process, which enables the human community to discover original lyrics, and melodies suitable for the generated lyrics. The proposed songwriting system, Automatic Neural Lyrics and Melody Composition  is an attempt to make the whole process of songwriting automatic using artificial neural networks. Our lyric to vector  model trained on a large set of lyric-melody pairs dataset parsed at syllable, word and sentence levels are large scale embedding models enable us to train data driven model such as recurrent neural networks for popular English songs. AutoNLMC is a encoder-decoder sequential recurrent neural network model consisting of a lyric generator, a lyric encoder and melody decoder trained end-to-end. AutoNLMC is designed to generate both lyrics and corresponding melody automatically for an amateur or a person without music knowledge. It can also take lyrics from professional lyric writer to generate matching melodies. The qualitative and quantitative evaluation measures revealed that the proposed method is indeed capable of generating original lyrics and corresponding melody for composing new songs.",374
"   Deep Neural Networks  are the current state-of-the-art models in many speech related tasks. From a computational neuroscience perspective, DNNs can be seen as rate coding based models, in the sense that if a neuron is responsive to a given stimulus, then if we augment the stimulus intensity, the neuron output intensity will also increase. Temporal coding based models try to also take into account information carried by the temporal structure of the stimulus. In the case of Spiking Neural Networks , spike timing and delays between spikes is important in order to retrieve patterns in the spike sequences given as input to a model. %https://en.wikipedia.org/wiki/Neural_coding  There is a growing interest for SNNs applied to speech recognition tasks, from isolated word and phone recognition,to large-vocabulary automatic speech recognition  very recently. Reasons are that the audio speech signal is particularly suited to event-driven models such as SNNs, SNNs are also more biologically realistic than DNNs, hardware friendly and energy efficient models, if implemented on dedicated energy-efficient neuromorphic chips. Furthermore, it has been shown recently that SNNs can be trained efficiently, in a supervised manner, using backpropagation with a surrogate gradient trick. This new approach allows to train SNNs as one would do for DNNs.  In this work, we propose to use supervised SNNs for speech command  recognition. We explore the Leaky Integrate-and-Fire  neuron model for this task, and show that convolutional SNNs can reach an accuracy very close to the one obtained with state-of-the-art DNNs, for this task. Our main contributions are the following: i) we propose to use dilated convolution spiking layers, ii) we define a new regularization term to penalize the averaged number of spikes to keep the spiking neuron activity as sparse as possible, iii) we show that the leaky variant of the neuron model outperforms the non-leaky one , used in.  In order to facilitate reproducibility, our code using PyTorch is available online\footnote{https://github.com/romainzimmer/s2net}.    In this work, we applied IRM to a toxicity classification task in order to demonstrate that Domain Generalization can serve as an important framework for building fair machine learning classifiers. Our findings show that IRM outperforms ERM with respect to both generalization accuracy and group fairness by learning invariant but likely non-causal predictors of toxicity. We hope that these results are first steps for future explorations of the relationship between robustness and fairness in machine learning.    {\small     }    
"," Deep Neural Networks  are the current state-of-the-art models in many speech related tasks. There is a growing interest, though, for more biologically realistic, hardware friendly and energy efficient models, named Spiking Neural Networks . Recently, it has been shown that SNNs can be trained efficiently, in a supervised manner, using backpropagation with a surrogate gradient trick. In this work, we report speech command  recognition experiments using supervised SNNs. We explored the Leaky-Integrate-Fire  neuron model for this task, and show that a model comprised of stacked dilated convolution spiking layers can reach an error rate very close to standard DNNs on the Google SC v1 dataset: \ER{94.5}\%, while keeping a very sparse spiking activity, below 5\%, thank to a new regularization term. We also show that modeling the leakage of the neuron membrane potential is useful, since the LIF model outperformed its non-leaky model counterpart significantly.",375
" Books have been the one of the most important mediums for recording information and imparting knowledge in human history. Books can be classified into different categories based on their physical formats, contents, languages, and so on. In this paper, we focus on the task of book classification by its genre using the information provided just by the cover. Book covers are usually the very first impression to its readers and they often convey important information about the content of the book. Figure  presents some sample book covers. The information provided by a cover includes visual and textual information . For instance, in Figure 1, the background picture contains different food items and cookware which give the readers a visual impression about the book, while the texts shown on the cover states that it is a book about the ``authentic recipes from Malaysia"". Both the visual and textual information are shown in the cover and they together indicate that its genre is ``Cookbooks, Food \& Wine"". It is worth to mention that having only the visual information often makes the task extremely hard without textual information. For instance, in Figure 1 , without reading the texts on the cover, someone may classify the book as ``Cookbooks, Food \& Wine"" as well solely based on the visual information we get from the cover that includes food items on a table in a dining room setting. Therefore, it is sometimes essential to consider both visual information and textual information extracted from the cover when we conduct book genre classification. The automatic classification of books based on only covers without human intervention would be utterly beneficial to many modern retrieval systems, considering that the complete digitization of books is an extremely expensive task.     The challenges of this task are the following. First, there exists a wide variety of book genres, many of which are not concretely defined. Second, book covers, as graphic designs, varies in many different ways such as colors, styles, textual information, etc, even for books of the same genre. Third, book cover designs may vary due to many external factors such as country, culture, target reader populations, etc . To overcome these difficulties, we present a deep learning framework involving two moralities: one for visual information and the other for textual information extracted from the covers.   Recently, deep learning approaches have reached high performances across a wide variety of problems . In particular, some deep convolutional neural networks can achieve a satisfactory level of performance on many visual recognition and categorization tasks, exceeding human performances. One of the most attractive qualities of these techniques is that they can perform well without any external hand-designed resources or task-specific feature engineering.  The theoretical foundations of deep learning are well rooted in the classical neural network  literature. It involves many hidden neurons and layers as an architectural advantage in addition to the input and output layers . A deep convolutional neural network is universal, meaning that it can be used to approximate any continuous function to an arbitrary accuracy when the depth of the neural network is large enough .  The main contributions of this paper are fourfold:   The rest of the paper is structured as follows. Section 2 presents related works about book cover classification. Section 3 elaborates on the details of the proposed multi-modal architectures. In section 4, we discuss the experimental results. The last section concludes the paper and discusses future work.     In this work, we explored the LIF neuron model to define dilated convolution spiking layers for a spoken command recognition application. Contrarily to most works using SNNs applied to speech tasks, in which special mechanisms, usually non-trainable, are needed to first encode the speech input features into some type of neural encoding  as a first step to then use SNNs , our approach is unified in the sense that the first convolution layer applied to real-valued speech features is trainable and shares the same definition and implementation than the ones processing spike trains as input. Our proposed SNN, trained with back-propagation through time with surrogate gradient, achieved results competitive with standard deep convolutional neural networks.     We defined a regularization term to penalize the averaged number of spikes to keep the spiking neuron activity as sparse as possible, which is a desirable property both from a biological point of view and for a future potential implementation on low-energy dedicated chips.  Finally, we conducted ablation studies in order to estimate the impact of different components of our approach. In particular, an interesting result is that the LIF neuron model outperformed the simpler non-leaky one , used in for ASR.   Another experiment showed that learning the values for the thresholds and leak coefficients during training does not bring accuracy improvements over using defaults constant values.  In future work, we will try to confirm these results in acoustic modeling for speech recognition.   We also would like to explore the possibility to design a variant, in which a layer sends its output spikes to the next layer as soon as they are produced, in a single time loop used for the whole model. This would be more efficient in terms of computation load. It would also eventually allow to take classification decisions faster, for audio streaming applications in particular.    Below is an example of how to insert images. Delete the ``\vspace'' line,   uncomment the preceding line ``\centerline...'' and replace ``imageX.ps''   with a suitable PostScript file name.   -------------------------------------------------------------------------        To start a new column  and help balance the last-page   column length use \vfill\pagebreak.   -------------------------------------------------------------------------  \vfill  \pagebreak    
"," Book covers are usually the very first impression to its readers and they often convey important information about the content of the book. Book genre classification based on its cover would be utterly beneficial to many modern retrieval systems, considering that the complete digitization of books is an extremely expensive task. At the same time, it is also an extremely challenging task due to the following reasons: First, there exists a wide variety of book genres, many of which are not concretely defined. Second, book covers, as graphic designs, vary in many different ways such as colors, styles, textual information, etc, even for books of the same genre. Third, book cover designs may vary due to many external factors such as country, culture, target reader populations, etc. With the growing competitiveness in the book industry, the book cover designers and typographers push the cover designs to its limit in the hope of attracting sales. The cover-based book classification systems become a particularly exciting research topic in recent years. In this paper, we propose a multi-modal deep learning framework to solve this problem. The contribution of this paper is four-fold. First, our method adds an extra modality by extracting texts automatically from the book covers. Second, image-based and text-based, state-of-the-art models are evaluated thoroughly for the task of book cover classification. Third, we develop an efficient  and salable multi-modal framework based on the images and texts shown on the covers only.  Fourth, a thorough analysis of the experimental results is given and future works to improve the performance is suggested. The results show that the multi-modal framework significantly outperforms the current state-of-the-art image-based models. However, more efforts and resources are needed for this classification task in order to reach a satisfactory level.",376
"  \vskip 0.15in  Despite recent developments of activation functions for Machine Learning -based classifiers, such as the m-arcsinh~ for shallow Multi-Layer Perceptron ~, usable, repeatable and reproducible functions for both shallow and deep neural networks, e.g., the Convolutional Neural Network ~, have remained very limited and confined to three activation functions regarded as 'gold standard'. These include the Rectified Linear Unit , the sigmoid function and its modified version, hyperbolic tangent sigmoid or 'tanh'~, which extends its range from [0, +1] to [-1, +1]. The sigmoid and tanh have well-known vanishing gradient issues; thus, the ReLU function was devised to be more scalable for deep neural networks, despite its 'dying ReLU' problem, which has recently been solved by~. These have been made freely accessible in the open source Python library named 'Keras'~ for Deep Learning. The availability of these functions in the public domain has enabled not-for-profit and for-profit organisations to leverage them for several intelligence-based applications, from academic to industrial applications~~. \\  Nevertheless, considering the above-mentioned challenges in the Computer Science and ML communities, such activation functions lack robustness with classification tasks of varying degrees of complexity, e.g., slow or lack of convergence~ ~, caused by trapping at local minima~. Moreover, amongst the three above-mentioned activation functions, only the ReLU is applicable from shallow to deep neural networks, with its novel quantum variations  found more scalable than its traditional version only recently~. \\  On the other side, in sciences dealing with the study of human behaviour, in the last 20 years, considerable progress has been made towards the prevention of mental health disorders~~. Specifically, professionals working in the field of counselling psychology have slightly enhanced their ability of grasping relational issues in their subjects via novel ML-based tele-monitoring technologies~. Nevertheless, these technologies have not yet changed the traditional counselling psychology practice, which is still based on a structured methodology that is adopted to help individuals to become more self-aware, more conscious of their own needs and moods~. The main goal counsellors pursue is guiding individuals to get to know themselves at a deeper level and to help them discover and resurface their own resources to better manage their emotions in their daily life. This process first requires a tailored dialogue between the counsellor and the individual and, subsequently, leveraging practical tools to aid the individual in their experience to understand their inner self more deeply~. Moreover, there are still limitations within the counselling setting. For instance, individuals, out of fear, may not reveal fundamental aspects of their persona that would help counsellors guide them better in getting to know themselves. Furthermore, in many cases, subjects may express a verbal language opposite to their non-verbal one. Counsellors often hardly understand the dynamic patterns observed in the behaviours of their subjects, thus being unable to provide the required help and support to them. \\  In counselling, neural network algorithms, both shallow and deep depending on the amount of good-quality data and hardware available, have the potential to support counsellors in image and text classification tasks to understand and guide their subjects by helping them infer subtle dynamic changes in their behaviours. Via a careful and effective observation of images, micro- and macro- body movements, and facial expressions~~, it is possible to better interpret and understand the subjects' non-verbal language. Even the emotions underlying the written content from subjects may reveal inner aspects of their persona that are fundamental for counsellors to help resurface to increase the subjects' self-awareness and related capability of 'self-healing'~. \\  Therefore, from both theoretical and practical standpoints, there is an increasing need for accurate and reliable open source activation functions, which reach convergence faster, avoiding trapping at local minima, are more stable and can also be used and scale across both shallow and deep neural network algorithms for image and text classification. Entirely written in Python and made freely available in TensorFlow~ and Keras~, the proposed hyperbolic function is demonstrated as a competitive function with respect to gold standard functions, which suits both shallow and deep neural networks, thus being accurate and reliable for pattern recognition to aid image and text classification tasks.  Thanks to its liberal license, it has been widely distributed as a part of the free software Python libraries TensorFlow~ and Keras~, and it is available for use for both academic research and commercial purposes.\\  %%%%%%%%%%%%%%% Methods section %%%%%%%%%%%%%%%%%%%%%  \vskip 0.3in    In this paper, we proposed two multi-modal models: one with simple concatenation and the other with DCCA concatenation, for the task of book genre classification solely based on its cover. In addition, we evaluated several state-of-the-art image-based models and text-based models. By comparison, text-based models perform better in general than image-based models and the proposed multi-modal model with simple concatenation outperforms all other models. Based on the results from our experiments, the simple concatenation model has a top-1 accuracy of 56.1\
","%   <- trailing '%' for backward compatibility of .sty file This paper presents the 'hyper-sinh', a variation of the m-arcsinh activation function suitable for Deep Learning -based algorithms for supervised learning, such as Convolutional Neural Networks . hyper-sinh, developed in the open source Python libraries TensorFlow and Keras, is thus described and validated as an accurate and reliable activation function for both shallow and deep neural networks.  Improvements in accuracy and reliability in image and text classification tasks on five  benchmark data sets available from Keras are discussed.  Experimental results demonstrate the overall competitive classification performance of both shallow and deep neural networks, obtained via this novel function.  This function is evaluated with respect to gold standard activation functions, demonstrating its overall competitive accuracy and reliability for both image and text classification.",377
"  In grounded language theory, the semantics of language are given by how symbols connect to the underlying real world---the so-called ``symbol grounding problem''. For example, we want a robotic system that sees an eggplant  to ground the recognition object to a canonical symbol for `eggplant.' When a user asks ""Please grab me the eggplant,"" the robot should ground the natural language word ""eggplant"" to the same symbol that denotes the relevant visual percepts. Once both language and vision successfully ground to the same symbol, it becomes feasible for the robot to complete the task. We learn this connection by using physical sensors in conjunction with language learning: paired language and perceptual data are used to train a joint model of how linguistic constructs apply to the perceivable world.   Machine learning of grounded language often demands large-scale natural language annotations of things in the world, which can be expensive and impractical to obtain. It is not feasible to build a dataset that encompasses every object and possible linguistic description. Novel environments will require symbol grounding to occur in real time, based on inputs from a human interactor. Learning the meanings of language from unstructured communication with people is an attractive approach, but requires fast, accurate learning of new concepts, as people are unlikely to spend hours manually annotating even a few hundred samples, let alone the thousands or millions commonly required for machine learning.  % Active learning, in which a system queries for specific training data, has the potential to improve learning efficiency and reduce the number of labels required to learn a grounded language model.  In this work we study active learning, in which a system deliberately seeks information that will lead to improved understanding with less data, to minimize the number of samples/human interactions required. The field of active learning typically assumes that a pool of unlabeled samples is available, and the model can request specific example that it would like to obtain a label for. By having the model select the most informative data points for labeling, the number of samples that need to be labeled is reduced. This maps to the goal of human-robot learning with minimum training data provided by the human. Furthermore, active learning can be part of a pipeline with other few-shot learning methods.   However, active learning is not a magic bullet. When not carefully applied, it does not outperform sequential or random sampling baselines. Thoughtful selection of suitable approaches for problems is required. While active learning has been used for language grounding %, , to the best of our knowledge, we present the first broad exploration of the best methods for active learning for grounding vision-language pairs. %  In this paper, our focus is on developing guidelines by which active learning methods might be appropriately selected and applied to vision-language grounding problems. We test different active learning approaches on grounded language problems of varying linguistic and sensory complexity, and use our results to drive a discussion of how to select active learning methods for different grounded language data acquisition problems in an informed way.  We consider the grounded language task of learning novel language about previously unseen object types and characteristics. Our emphasis is on determining what methods can reduce the amount of training data needed to achieve performance consistent with human evaluation. Primarily, we address five relevant questions concerning characteristic-based grounded language learning:  % We make conclusions with respect to these questions in \cref{sec:results}. % In addition to addressing the above research questions, we verify how generalizable these learning techniques are beyond characteristic-based grounding.    We find that a right ordering of training data makes it possible to learn successfully from significantly fewer descriptions in most cases, but also that the active learning methodology chosen is specific to the nature of the learning problem. Our main contribution is a principled analysis of using active learning methods as unsupervised data sampling techniques in language grounding with a discussion of what aspects of those problems are relevant to approach selection. While our contributions are primarily analytic rather than algorithmic, we argue they address a critical need within grounded language understanding, an active research area in which questions of efficiency and data collection are widespread, and have the potential to support additional algorithmic developments.     \vskip 0.15in  As demonstrated by the competitive results obtained on the 5 data sets evaluated, especially those in Tables 1 and 3 for the deep neural network CNN and Tables 4 and 5 for the shallow neural network FC-NN, the hyper-sinh is deemed a suitable activation function that scales from shallow to deep neural networks. \\ In fact, its accuracy and reliability was high across both sets of benchmark image- and text-based data sets, as quantified via appropriate metrics in sub-section 2.4, and better than some gold standard functions, e.g., considering Table 1 with the accuracy and the F1-score of the CNN using hyper-sinh being 0.70 and 0.69 respectively on the CIFAR-10 image-based data set, as opposed to that of the same CNN but using sigmoid being 0.10 and 0.02 respectively. Moreover, its accuracy and reliability were comparable to the FC-NN using ReLU , with higher reliability than the same FC-NN when leveraging the sigmoid function on the 'Reuters' text-based data set . The proposed hyper-sinh also led to increased precision on the 'IMDB' text-based data set  as opposed to sigmoid and tanh , when using the same FC-NN as that leveraged to classify the 'Reuters' data set. \\ Therefore, the hyper-sinh demonstrates that it is possible to extend the m-arcsinh to generalise across both shallow and deep neural networks for image and text classification tasks, and that the mathematical formulation of this extended function does not have to be complex at all. As an accurate and reliable activation function, the hyper-sinh is thus deemed a new gold standard activation function for both shallow and deep neural networks, freely available in TensorFlow and Keras.                   Conclusion section                        \section{Conclusion}  hyper-sinh was proven an accurate and robust activation function for shallow and deep neural networks for image and text classification, thus being a new gold standard that scales well for FC-NN and CNN.  Since it is made freely available, open source, on the Python, TensorFlow and Keras ecosystems, it adds to the selection of activation functions that both not-for-profit and for-profit organisations can have when tackling image and text classification tasks with data sets of various sizes.  Importantly, the proposed algorithm, being accurate and reliable, and written in a high-level programming language , can be leveraged as a part of ML-based pipelines in specific use cases, wherein high accuracy and reliability need to be achieved, such as in the healthcare sector , from small to large clinics with its suitability from shallow to deep neural networks. Future work involves further improving this function to reduce its computational cost.     Acknowledgements should go at the end, before appendices and references  \acks{This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.}    Manual newpage inserted to improve layout of sample file - not   needed in general before appendices/bibliography.      
"," % In grounded language acquisition, a physical agent uses language combined with high-frequency sensor data to learn a model of how language refers to the physical world. This approach, while powerful, often requires extensive data annotation, which can be difficult to obtain. This work  % Ordering the selection of training data using active learning can lead to improvements in learning efficiently from smaller corpora. We present an exploration of active learning approaches applied to three grounded language problems of varying complexity in order to analyze what methods are suitable for improving data efficiency in learning. We present a method for analyzing the complexity of data in this joint problem space, and report on how characteristics of the underlying task, along with design decisions such as feature selection and classification model, drive the results. We observe that representativeness, along with diversity, is crucial in selecting data samples.",378
" Deep neural networks are powerful and have been widely applied in natural language processing. However, recent studies demonstrate that these models are vulnerable to adversarial examples, which are malicious inputs intentionally crafted to fool the models. % The introduction of the adversarial example ushered in a new era to understand and improve neural the network-based models.  % Adversarial attacks and defenses against these attacks have drawn significant attention in recent years . Although generating adversarial examples for texts has proven to be a more challenging task than for images due to their discrete nature, a number of methods have been proposed to generate adversarial text examples and reveal the vulnerability of deep neural networks in natural language processing  tasks including reading comprehension , text classification , machine translation , dialogue systems , and dependency parsing . These methods attack text examples by replacing, scrambling, and erasing characters or words or other language units.  To settle the susceptible attack direction, they require a large number of queries to the target model for the predictions of given inputs. Thus the adversarial examples are typically generated for a specific model.  This motivates the main questions we aim to answer in this paper: Are there universal adversarial examples that can fool almost every neural network-based model? And are there universal attack rules for constructing such universal adversarial examples? %are there universal adversarial examples that can transfer to any neural network-based models?  It is well known that adversarial examples exhibit black-box transferability, meaning that adversarial examples generated for one model can fool another model .  Transfer attackers launch white-box attacks on local models to find candidate adversarial examples that may transfer to the target model. % In the white-box setting, an adversary can access the model's architecture, parameters and input feature representations while not in the black-box one. % However, adversarial examples are typically overfitted to the particular architecture and feature representation of a source model, resulting in sub-optimal black-box transfer attacks to other target models.  However, which factors most affect the transferability of adversarial examples is still unclear, especially for NLP models. In this study, we quantitatively investigate how adversarial transferability is impacted by several critical factors, including the network architecture, input form, word embedding type, and model capacity.  Based on the understanding of transferability among various neural models, we study whether it is possible to craft universal, model-agnostic text adversarial examples for almost all existing models.  Universal adversarial examples have at least two advantages. First, the adversaries do not need white-box access to the target models. They launch the attacks by their own models trained on similar data, which can transfer across models .  Second, universal adversarial examples are a useful analysis tool because, unlike typical attacks, they are model-agnostic.  Thus, they highlight general input-output patterns learned by a model. We can leverage this to study the influence of dataset biases and to identify those biases that are learned by models.   \end{center}  \end{table*}   In this study, we first systematically investigated a few critical factors of neural models, including network architectures , input forms , embedding types , and model capacities  and how they impact the transferability of text adversarial examples through extensive experiments on two datasets of text classification.  We vary one factor at a time while fixing all others to see which factor is more significant, and found that the input form has the greatest influence on the adversarial transferability, following by network architecture, embedding type, and model capacity. Then, we propose a genetic algorithm to find an optimal ensemble with minimum number of members on the basis of our understanding of the adversarial transferability among neural models.  The adversarial examples generated by attacking the ensemble found by our algorithm strongly transfer to other models, and for some models, they exhibit better transferability than those generated by attacking models with different random initialization. Finally, we generalize the adversarial examples constructed by the ensemble method into universal semantics-preserving word replacement rules that can induce adversaries on any text input strongly transferring to any neural network-based NLP model . Since those rules are model-agnostic, they provide an analysis of global model behavior, and help us to identify dataset biases and to diagnose heuristics learned by the models.     In this work, we present a thorough exploration of different active learning approaches to grounding unconstrained natural language in real-world sensor data. We demonstrate that active learning has the potential to reduce the amount of data necessary to ground language about objects, an active area of research in both NLP and robotics as well as machine learning from sparse data generally. We additionally provide suggestions for what approach may be suitable given the perceptual and linguistic complexity of a problem. Given our analysis of the causes of performance for different algorithms and cases, we believe these results will prove to generalize beyond the relatively simple data seen here, making it possible for these guidelines to apply to more complicated language grounding tasks in future.                                  
"," Deep neural network models are vulnerable to adversarial attacks. In many cases, malicious inputs intentionally crafted for one model can fool another model in the black-box attack setting. However, there is a lack of systematic studies on the transferability of adversarial examples and how to generate universal adversarial examples.  In this paper, we systematically study the transferability of adversarial attacks for text classification models.  In particular, we conduct extensive experiments to investigate how various factors, such as network architecture, input format, word embedding, and model capacity, affect the transferability of adversarial attacks.  Based on these studies, we then propose universal black-box attack algorithms that can induce adversarial examples to attack almost all existing models. These universal adversarial examples reflect the defects of the learning process and the bias in the training dataset.  Finally, we generalize these adversarial examples into universal word replacement rules that can be used for model diagnostics.     \if0 It has been known that adversarial examples exhibit black box transfer, i.e. malicious inputs intentionally crafted for one model can also cause another model to make mistakes. However, which factors affect the most and how they impact the transferability of adversarial examples are still unclear, especially for NLP models.  Through extensive experiments, we systematically investigate how adversarial transferability is impacted with a few critical, model-specific factors, including the network architecture, input form, pre-trained word embedding, and model capacity. Based on the understanding of the adversarial transferability among neural models, we propose a population-based algorithm to find an optimal ensemble with minimum number of models, which can be used to generate adversarial examples that strongly transfer across other neural models.  We also generalize the adversarial examples generated by the ensemble method into universal word replacement rules that can induce adversaries on any text input to fool almost all the existing models with a much higher success rate. Those rules also help us to identify dataset biases and diagnose heuristics improperly learned by the models. \fi",379
" Recent works have shown that NN models that are trained solely to maximize prediction performance are often vulnerable to adversarial attacks . Even though several works have been proposed to defend NN models against such attacks, only a few of them focus on the NLP domain . Since many recent NLP models are shown to be vulnerable to adversarial attacks--e.g., fake news detection  and dialog system , the investigation of robust defense methods for textual NN models has become necessary. To defend against adversarial texts, one can use either adversarial detection or model enhancement . Adversarial texts are often generated by replacing or inserting critical words  or characters  in a sentence, that are usually exhibiting grammatical errors. Hence, many detection methods have focused on recognizing and correcting such misspellings from texts--e.g., ScRNN  and DISP . While misspelling-based methods are model-independent and require neither re-training nor modifying the models, they only work well on character-based attacks. In contrast, model enhancement approaches perform well under both character and word-based attacks.  %Such generalization to a variety of attacks is critical since one might not know what type of adversarial techniques will be employed by adversaries.  Particularly, most of the model enhancement methods enrich NN models by training them with adversarial data augmented via known attack strategies such as in adversarial training , or with external information such as knowledge graphs . Nevertheless, these augmentations usually induce overhead costs in training. Therefore, we are in search of defense algorithms that directly enhance the models' structures  while achieving higher extendability without acquiring additional data.  %While developing these solutions is more challenging and still under exploration .   Fortunately, recent literature in computer vision shows that ensemble NNs achieve high adversarial robustness . In theory, by directly extending a single NN model to an ensemble of multiple diverse sub-models, we challenge adversaries to attack not only one but a set of very different models . This makes any attacks significantly more difficult. However, applying such an idea from computer vision to the NLP domain faces one main challenge. Current ensemble methods require simultaneous training of several NN sub-models . This introduces impractical computational overhead during both training and inference, especially when one wants to maximize prediction accuracy by utilizing complex state-of-the-art  sub-models such as BERT  and ROBERTA , both of which have more than 100M parameters. Furthermore, applying current ensemble or other defensive approaches that directly enhance a model's architecture to a large-scale NN model would usually require re-training everything from scratch, which may not be practical in many settings.  % Second, current ensemble approaches aim to promote the diversity of sub-models at either feature-level  or at class-level .  % Second, current ensemble approaches promote the diversity of sub-models by maximizing their differences among either prediction output vectors  or gradient vectors w.r.t an input image . However, most of NLP tasks, classification particularly, have much less labels than those of computer vision, which results in a much smaller degree-of-freedom when directly regularizing the differences of prediciton probability vectors.   % On the other hand, forcing the sub-models to focus on different tokens of an input text by directly regularizing their gradient vectors is not straightforward because text are discrete in nature. This can be easily resolved by regularizing the gradients w.r.t the continuous word-embedding vectors of the sentence instead. However, since every sub-model contributes equally to an input, there will be many overlaps among the key features, i.e., words or phrases, of each of the sub-models when the input text is short.   To address these challenges, we are borrowing ideas from Software Engineering, by first introducing the notion of {\bf Neural Patching} to improve the adversarial robustness of NN models by ``patching"" only parts of models . Next, we develop a novel neural patching algorithm, {\mymethod}, that patches only the last layer of an already deployed textual NN model of diverse architectures  and transforms it into an ensemble of multi-experts with enhanced adversarial robustness.  By patching only the last layer of a model, {\mymethod} introduces a lightweight computational overhead and requires no additional training data. %requires low construction overheads without compromising much computational complexity or additional training data.  Distinguished from current ensemble methods, each sub-model trained by {\mymethod} is specialized not only in a specific subset of features of the same input, i.e., an expert at feature-level , or a sub-set of labels, i.e., an expert at class-level , but also in texts of a distinguished topic, i.e., an expert at instance-level, during prediction. Such diversity at all of the feature-, class-, and instance-level expertise makes it challenging for adversaries to exploit multiple sub-models at the same time. In summary, our contributions in this paper are as follows:   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    In this study, we investigated four critical factors of NLP neural models, including network architectures, input forms, embedding types, and model capacities and how they impact the transferability of text adversarial examples with  different models. Based on the understanding of the transferability among those models, we proposed a genetic algorithm to find an optimal ensemble of very few models that can be used to generate adversarial examples that transfer well to all the other models. We also described a algorithm to discover universal adversarial word replacement rules that can be applied to craft adversarial examples with strong transferability across various neural models without access to any of them. Finally, since those adversarial examples are model-agnostic, they provide an analysis of global model behavior and help to identify dataset biases.  {\small   }   
"," Neural network  models that are solely trained to maximize the likelihood of an observed dataset are often vulnerable to adversarial attacks. Even though several methods have been proposed to enhance NN models' adversarial robustness, they often require re-training from scratch. This leads to redundant computation, especially in the NLP domain where current state-of-the-art models, such as BERT and ROBERTA, require great time and space resources. By borrowing ideas from Software Engineering, we, therefore, first introduce the Neural Patching mechanism to improve adversarial robustness by ``patching"" only parts of a NN model. Then, we propose a novel neural patching algorithm, {\mymethod}, that transforms a textual NN model into a stochastic ensemble of multi-expert predictors by upgrading and re-training its last layer only. {\mymethod} forces adversaries to attack not only one but multiple models that are specialized in diverse sub-sets of features, labels, and instances so that the ensemble model becomes more robust to adversarial attacks. By conducting comprehensive experiments, we demonstrate that all of CNN, RNN, BERT, and ROBERTA-based textual models, once patched by {\mymethod}, witness an absolute increase of as much as 20\% in accuracy on average under 5 different white and black-box attacks, outperforming 6 defensive baselines across 4 public NLP datasets. All codes and datasets are to be released.",380
" Emotional analysis has been an active research area for a few decades, especially in recognition domains of text and speech emotions. Even if text and speech emotions are closely relevant, both kinds of emotions have different challenges. One of the challenges in text emotion recognition is ambiguous words, resulting from omitted words . On the other hand, one of the challenges in speech emotion recognition is creating an efficient model. However, this paper focuses on only the recognition of speech emotions. In this area, two types of information, linguistic and paralinguistic, were mainly considered in speech emotion recognition. The linguistic information refers to the meaning or context of speech. The paralinguistic information implies the implicit message meaning, like the emotion in speech . Speech characteristics can interpret the meaning of speech; therefore, behavioral expression was investigated in most of the speech emotion recognition works  .   In recent works, local feature learning block  , one of the efficient methods, has been used in integrating local and global speech emotion features, which provide better results in recognition. Inside LFLB, convolution neural network  was used for extracting local features, and then long short-term memory  was applied for extracting contextual dependencies from those local features to learn in a time-related relationship. However, vanishing gradient problems may occur with CNN . Therefore, residual deep learning was applied to the CNN by using skip-connection to reduce unnecessary learning and add feature details that may be lost in between layers.  Furthermore, the accuracy of speech recognition does not only rely on the efficiency of a model, but also of a speech feature selection . In terms of speech characteristics, there are many distinctive acoustic features that usually used in recognizing the speech emotion, such as continuous features, qualitative features, and spectral features . Many of them have been investigated to recognize speech emotions. Some researchers compared the pros and cons of each feature, but no one can identify which feature was the best one until now .  As previously mentioned, we proposed a method to improve the efficiency of LFLB  for deeper learning. The proposed method, deep residual local feature learning block , was inspired by the concept of human brain learning; that is, 閳ユΜepeated reading makes learning more effective,閳 as the same way that Sari  and Shanahan  were used. Responding to our inspired concept, we implemented a learning method for speech emotion recognition with three parts: Part 1 is for general learning, like human reading for the first time, Part 2 is for further learning, like additional readings, and the last part is for associating parts learned to decide types of emotions. Besides, the feature selection is compared with two types of distinctive features to find the most effective feature in our work: the normal and specific distinctive features are log-mel spectrogram , which is fully filtered sound elements, and %log-mel spectrogram,  MFCC deltas, delta-deltas, and chromagram  are more clearly identify speech characteristics extracted based on %according to  the human mood.  Our main contributions of this paper are as follows:   Deep residual local feature learning block  was proposed. DeepResLFLB was arranged its internal network as LFLB, batch normalization , activation function, normalization-activation-CNN , and deep layers.   Learning sequences of DeepResLFLB were imitated from human re-reads.   Speech emotion features, %according to  based on human mood determination factors such as LMS and LMSDDC, were applied and compared their performances.     This paper proposes a novel algorithm, named {\mymethod}, that consistently improves the adversarial robustness of textual NN models under both white-box and black-box attacks by upgrading and re-training only their last layer. By extending a single model to an ensemble of multiple experts that are diverse among feature-, prediction-, and instance-levels, {\mymethod} achieves as much as 20\  improvement in accuracy on average across 5 attacks on 4 NLP datasets. Thanks to its model-agnostic design, {\mymethod} can help improve the adversarial robustness in NLP and other domains.   literature of not only NLP but also other domains in the foreseeable future.  \pagebreak       \vfill\null   
"," Speech Emotion Recognition  is becoming a key role in global business today to improve service efficiency, like call center services. Recent SERs were based on a deep learning approach. However, the efficiency of deep learning depends on the number of layers, i.e., the deeper layers, the higher efficiency. On the other hand, the deeper layers are causes of a vanishing gradient problem, a low learning rate, and high time-consuming. Therefore, this paper proposed a redesign of existing local feature learning block . The new design is called a deep residual local feature learning block . DeepResLFLB consists of three cascade blocks: LFLB, residual local feature learning block , and multilayer perceptron . LFLB is built for learning local correlations along with extracting hierarchical correlations; DeepResLFLB can take advantage of repeatedly learning to explain more detail in deeper layers using residual learning for solving vanishing gradient and reducing overfitting; and MLP is adopted to find the relationship of learning and discover probability for predicted speech emotions and gender types. Based on two available published datasets: EMODB鐠虹棏nd RAVDESS, the proposed DeepResLFLB can significantly improve performance when evaluated by standard metrics: accuracy, precision, recall, and F1-score.  \keywords{Speech Emotion Recognition \and Residual Feature Learning \and CNN Network \and Log-Mel Spectrogram \and Chromagram}",381
"  As the growth of robots interacting with humans, different levels of environment understanding is required by the robot. A robot acting in an environment has to deal with many open questions, thus needs different levels of reasoning to do a task. Usually, robots rely on their initial knowledge, perception and their cognitive abilities to be able to understand and do reasoning in their situated environment. A recently hooked topic to a better Knowledge-Based cognition is dialogic interaction between a human and a robot, where the robot captures fresh information about the environment from a user through Natural Language. Information comes from Natural Language together with visually perceived information, and a Knowledge Base  lets a cognitive agent reach different levels of understanding in the environment.   The first level of understanding can be seen as classification and detection on sensory inputs, e.g. detection of objects in visual perception, or role tagging of lexical in a sentence. The second level of understanding concerns finding relations between different sensory inputs, e.g. finding common attributes in language and vision. Some famous problems such as symbol grounding  and anchoring  concern finding correspondences in different sensory input modalities. A higher and abstract level of understanding can be thought to find relations between the entities in an environment. e.g. in a scene with a desk and a book on top, some of the relationships between these are their relative physical position and their semantics that shows how entities  are similar.   Understanding relationships between physical entities can also be extended to the attributes of entities. Indeed the same definition of the relationship between entities can be found for the attributes. For example, when a user declares freshness attribute of 'apple-1' is 'spoiled', as well as 'apple-2' and 'apple-3', but 'orange-1' and 'banana-1' are 'fresh', a relation between the values of freshness attribute exists which connects semantic of entities; In this example, is that all apples are 'spoiled', and the rest of fruits are 'fresh', with closed world assumption.   Relation and rules for attributes of entities can help a robot that is interacting with a human in many applications. For example when a user utters ""bring me a fruit"", using the rules obtained for freshness attribute, the robot notices which fruits are spoiled and which are fresh to eat. Such logical rules between attributes let the robot realize that apples are spoiled, apples should be thrown out, and added to the shopping list. Moreover, the obtained rule for attributes can be used in a robot's low-level sensory input processing. Consider an utterance where the user of our example is declaring that a physical entity is spoiled, but the robot's visual perception has doubt whether the perceived object is apple or pear. As the robot already found that all apples are spoiled and other fruits are fresh, so the perceptual detection refines the recognized object as the apple.  %Different attributes can represent characteristics of an entity, where some are computed from visual perception and some from Natural Language through interaction with a user. In this work, we deal with nine different attributes, as a category, color, label, functionality, owner, size, weight, restriction, and location of entities in a scene; where the first two are computed from visual perception and the rest are obtained from Natural Language.  %%It is worth emphasis on the importance of attributes that come from Natural Language. Such information is almost impossible to obtain from visual perception, e.g. the information that a user can give about owner of an entity, cannot be obtained from the camera. Also, an initial knowledge base only gives information about the category of an entity, and not about a particular entity , and some of the assignments might be temporary. On the other hand, information about size, weight, and location, may be used for refinement of knowledge base and camera, or just a shortcut to obtaining such information from the user.   In this work, we propose a framework for learning logical rules that represent relations between attributes in a semantic model of the robot's environment. Such logical rules help the robot to find which attributes  entail a specific attribute. A distinctive novelty of our work is to generalize rules from a semantic model built via Human-Robot Interaction , through the integration of visual and linguistic cues. Our framework goes all the way from sensory input data to abstract First-Order Logic formulas that describe abstract relationship between attributes of entities in a scene. %Our approach differs from other works as our system is able to capture more attributes from Natural Language in addition to attributes from computer vision.  %Our proposed framework compute First-Order Logic formulas, which is useful for general reasoning upon entities that have common attributes.  We focus on latent rules, which the robot can capture implicitly when a human describes objects to the robot. In other words, we do not require the user to give rules explicitly to the robot, but rather we let the robot find rules and do further reasoning based on self-computed rules for improving its interaction with the user.    This paper continues with the review of related work, and then in Section  the proposed framework is described, followed by an implementation to demonstrate the viability of the proposed framework in Section . In Section  results of a test scenario are given, followed by the discussion about the applicability of the framework. In the end, conclusions of this work are drawn.         It is seldom the case data in the wild has a balanced distribution. In realistic settings, there is a limitation of acquiring relatively balanced data through choices of balanced data sources. Handling data skewness is a crucial problem because learning from imbalanced data inevitably brings bias toward frequently observed classes. Data-level manipulation tries to under-sample the majority classes or over-sample the minority classes. But these methods tend to discard valuable information from observations of majority classes or overfit to a sparse representation of minority classes, especially as the imbalance level gets higher. Moreover, recent methods such as SMOTE cannot be applied directly to the text data.   We propose ST, which effectively circumvents these issues by simply decomposing the data into k splits and sequentially training a learner in the decreasing order of KL divergence with the target distribution, which in the case of data imbalance problem is the discrete uniform distribution. Through extensive experiments, we show our architecture proves to be compatible with previous methods and outperforms existing methods when validated on simulated as well as real-application tasks. Our model shows superiority in performance because it enables more focus to be put on minority instances while not forgetting about majority instances. We believe that our work makes a meaningful step towards handling data skewness in text classification and the application of incremental learning methods focused on the data imbalance problem.  For future work, ensemble methods can be used by varying the  ratio to train multiple weak learners. Moreover, since ST can be applied simultaneously with algorithm-level methods, proven methods such as focal loss  and cost-sensitive deep neural network  could be implemented together to increase optimal performance.  
"," Humans have a rich representation of the entities in their environment. Entities are described by their attributes, and entities that share attributes are often semantically related.  For example, if two books have ``Natural Language Processing'' as value of their `title' attribute, we can expect that their `topic' attribute will also be equal, namely, ``NLP''.  Humans tend to generalize such observations, and infer sufficient conditions under which the `topic' attribute of any entity is ``NLP''.  If robots need to interact successfully with humans, they need to represent entities, attributes, and generalizations in a similar way. This ends in a contextualized cognitive agent that can adapt its understanding, where context provides sufficient conditions for a correct understanding. In this work, we address the problem of how to obtain these representations through human-robot interaction.  We integrate visual perception and natural language input to incrementally build a semantic model of the world, and then use inductive reasoning to infer logical rules that capture generic semantic relations, true in this model.  These relations can be used to enrich the human-robot interaction, to populate a knowledge base with inferred facts, or to remove uncertainty in the robot's sensory inputs.",382
" In recent years, science, engineering and mathematics education has emphasized supporting students閳 disciplinary ""practices"" of inquiry. These practices閳ユ敃uch as of formulating questions, designing investigations, or arguing from evidence閳ユ攣re more difficult to identify and assess than the traditional objectives of particular correct content knowledge. In order to study students閳 practices, researchers rely mainly on qualitative analyses of naturalistic data. These studies have advanced the field閳ユ獨 understanding of practices.\\  These studies have been limited in scope, however, because they are extremely labor-intensive: Analysis of naturalistic data requires significant and extensive effort by trained researchers, from transcribing to coding to the construction of meaning. It has been time and cost-prohibitive to conduct qualitative studies with large samples of data. Our purpose in this project is to develop computational tools that can support qualitative research at large scales on students' inquiry practices in science. In this paper we report on initial progress towards applying natural language processing  techniques to research on students' written arguments in college biology laboratory reports. \\  In this work, we report on our success in designing NLP that approached the reliability of trained, human coders. Specifically, we show that contrastive learning in the Wasserstein space is able to achieve a high level of agreement  on average. \\  The rest of the paper is organized as follows. In section  first overview current state-of-art in automating assessment of writing in science using machine learning for natural language processing. Following that we outline the writing assessment setting particular to our case in section .  In section  we briefly survey the relevant literature in machine learning for NLP and introduce our novel approach for automatic scoring. In section  we evaluate the performance of the proposed approach and discuss the results in detail.\\     In this paper, we present neural group testing, a general deep learning acceleration framework that tests multiple samples in one forward pass.  We found that multi-round tree merge is the best design for neural group testing. It can group up to  images in one forward pass and  reduce the overall computation cost by over  while improving detection performance. Another benefit of this design is that it can be easily combined with other approaches to accelerate inference by, for example, quantizing or pruning network parameters or downsamping input data. Evaluating further gains by combining these orthogonal approaches is an interesting direction of future work.         
"," Qualitative analysis of verbal data is of central importance in the learning sciences. It is labor-intensive and time-consuming, however, which limits the amount of data researchers can include in studies. This work is a step towards building a statistical machine learning  method for achieving an automated support for qualitative analyses of students闁 writing, here specifically in score laboratory reports in introductory biology for sophistication of argumentation and reasoning. We start with a set of lab reports from an undergraduate biology course, scored by a four-level scheme that considers the complexity of argument structure, the scope of evidence, and the care and nuance of conclusions. Using this set of labeled data, we show that a popular natural language modeling processing pipeline, namely vector representation of words, a.k.a word embeddings, followed by Long Short Term Memory  model for capturing language generation as a state-space model, is able to quantitatively capture the scoring, with a high Quadratic Weighted Kappa  prediction score, when trained in via a novel contrastive learning set-up. We show that the ML algorithm approached the inter-rater reliability of human analysis. Ultimately, we conclude, that machine learning  for natural language processing  holds promise for assisting learning sciences researchers in conducting qualitative studies at much larger scales than is currently possible.",383
" 	 		Neural text-to-speech  techniques have significantly improved the naturalness of speech produced by TTS systems. We refer to NTTS systems as a subset of TTS systems that use neural networks to predict mel-spectrograms from phonemes, followed by the use of neural vocoder to generate audio from mel-spectrograms. 			 		In order to improve the prosody\footnote{We use the subtractive definition of prosody from .} of speech obtained from NTTS systems, there has been considerable work in learning prosodic latent representations from ground truth speech. These methods use the target mel-spectrograms as input to an encoder which learns latent prosodic representations. These representations are used by the decoder in addition to the input phonemes, to generate mel-spectrograms. The latent representations obtained by encoding a target mel-spectrogram at the sentence level will have information that is not directly available from the phonemes, and by the subtractive definition of prosody, we may claim that these representations capture prosodic information. Several variational and non-variational methods have been proposed for learning prosodic latent representations. While these methods improve the prosody of synthesised speech, they need an input mel-spectrogram which is not available while running inference on unseen text. This gives rise to the problem of sampling from the learnt prosodic space. Sampling at random from the prior may result in the synthesised speech not having contextually appropriate prosody, as it has no relationship with the text being synthesised. In order to improve the contextual appropriateness of prosody in synthesised speech, there has been work on using textual features like contextual word embeddings and other grammatical information to directly condition NTTS systems. These methods require the NTTS model to learn an implicit correlation between the given textual features and the prosody of the sentence. One work also poses this sampling problem as a selection problem and uses both syntactic distance and BERT embeddings to select a latent prosodic representation from the ones seen at training time.  		Bringing both the aforementioned ideas of using ground truth speech to learn prosodic latent representations and using textual information, we build Kathaka, a model trained using a two-stage training process to generate speech with contextually-appropriate prosody. In Stage~\Romannum{1}, we learn the distribution of sentence-level prosodic representations from ground truth speech using a VAE. In Stage~\Romannum{2}, we learn to sample from the learnt distribution using text. In this work, we introduce the BERT+Graph sampler, a novel sampling mechanism which uses both contextual word-piece embeddings from BERT and the syntactic structure of constituency parse trees through graph attention networks. We then compare Kathaka against a strong baseline and show that it obtains a relative improvement of  in naturalness. 		 	 	   In this paper, we use the eRisk 2018 dataset on Early Detection of Signs of Depression for depression classification from Reddit posts. Our method uses Latent Semantic Indexing for topic modelling and to generate the embeddings used as input for our neural network, but focuses on using a learned out-of-distribution confidence score alongside the classification output to decide whether to label the user or wait for more data. Besides its initial use case in out-of-distribution detection, we repurposed the confidence score as a measure for how much the model trusts its classification output to be correct. We showed that, in general, there is a significant difference in writing topics depending on the users' mental health, to the extent that it contains enough information for use in classification.    
"," 		In this paper, we introduce Kathaka, a model trained with a novel two-stage training process for neural speech synthesis with contextually appropriate prosody. In Stage, we learn a prosodic distribution at the sentence level from mel-spectrograms available during training. In Stage, we propose a novel method to sample from this learnt prosodic distribution using the contextual information available in text. To do this, we use BERT on text, and graph-attention networks on parse trees extracted from text. We show a statistically significant relative improvement of $13.2\%$ in naturalness over a strong baseline when compared to recordings. We also conduct an ablation study on variations of our sampling technique, and show a statistically significant improvement over the baseline in each case.",384
" Due to the growing presence of AI-powered systems in our lives, affective computing has become an important part of human-computer interaction. Emotion plays a role in our thoughts and actions and is an integral part of the way we communicate . The ability to leverage context to understand emotions communicated both verbally and non-verbally is trivial for humans but remains difficult for machines . Emotional responses depend on both our psyche and physiology and are governed by our perception of situations, people and objects. They also depend on our mental state   . The way we exhibit and perceive emotion may also differ based on our age, gender, race, culture and accent . In addition to all of this, unlike targets in other classification tasks, the emotions we experience are rarely distinct: they often coexist without clear temporal boundaries, adding considerable complexity to the task .  Despite these difficulties, automated emotion recognition has social and commercial applications that make it worth pursuing. In the medical domain, it has exciting potential: to identify and diagnose depression and stress in individuals , to monitor and help people with bipolar disorder  and to assist the general public in maintaining mental health. Commercial applications include call center customer management, advertising through neuro-marketing and social media engagement . As intelligent chatbots and virtual assistants have become more widely used, emotion detection has become a vital component in the design, development and deployment of these conversational agents .  Early research in emotion detection focused on binary classification in a single modality, whether in text, speech , or images . Text-based classifiers used the n-gram vocabulary of sentences to predict their polarity and speech models modeled the vocal dynamics that characterize these emotions. These approaches are inherently limited: a binary granularity and cues from a single modality are far removed from the actual human process they're meant to model. As a result, joint approaches which leverage all available modalities  are promising.  While existing multi-modal emotion corpora like IEMOCAP  and Crem-D  have been critical for the progress in affective computing to date, they suffer from three issues that are the focus of our work. First, these corpora tend to be small due to the high costs of annotating for emotion. This precludes the use of deep neural models with high model complexity as they require many training samples to generalize well. This also compounds the second difficulty inherent to many emotion datasets: while there are usually many neutral, happy and sad training examples, there are often very few examples of rarer emotions like disgust making them difficult to classify. This issue is not easily solved by combining different corpora due to the third issue, their lack of mutual compatibility -- they differ in the emotions identified, the types of dialogue and number of speakers represented and the naturalness of the recordings . This severely restricts the generalizability of models trained on a single corpus.  Contemporary literature has dealt with these problems by dropping labels . Hard and scarce emotions like disgust are dropped from the corpus and the models are trained and evaluated on the trimmed corpus. This allows evaluating models on different corpora by using utterances exhibiting only the most common emotions. While this is a reasonable, the resulting performance is not a complete reflection of how these models perform once deployed to production. When emotion models are used in real-world applications, we can expect them to encounter utterances corresponding to dropped labels. For such cases, these models are likely to exhibit degraded performance by predicting one of the known, but incorrect labels.  In this work, we address the problem of data sparsity by transfer learning via the pretrain-then-finetune paradigm. Deep complex models can be trained on large datasets for an auxiliary but related task to learn network parameters that reflect abstract notions related to the target task. As the expression of emotions is highly dependent on the individual, we train a multilayer TDNN  on the task of speaker identification using the VoxCeleb corpus  and then fine-tune its final few layers on the task of emotion identification using the Crema-D corpus . Using this network, we extract speech embeddings for Crema-D from each of its layers, generate and concatenate text embeddings for the accompanying transcripts using a fine-tuned BERT model  and then train an LDA - pLDA  model on the resulting dense representations.  pLDA allows our model to more easily adapt to previously unseen classes and domains, a requirement for both evaluating against a different emotion corpus with an incompatible label set and performing well in the wild.  To understand the merits of each component, we exhaustively evaluate the predictive power of every permutation: the TDNN alone, speech embeddings from each of its layers alone, text embeddings alone and every combination thereof. Our best variant, trained on only VoxCeleb and Crema-D and evaluated on IEMOCAP, achieves an Equal Error Rate  of \%. Including a portion of IEMOCAP during training produces a 5-fold averaged EER of \%.     		 		 		We presented Kathaka, an NTTS model trained using a novel two-stage training approach for generating speech with contextually appropriate prosody. In the first stage of training, we learnt a distribution of sentence-level prosodic representations. We then introduced a novel sampling mechanism of using trained samplers to sample from the learnt sentence-level prosodic distribution. We introduced two samplers, 1)~the BERT sampler which uses contextual word-piece embeddings from BERT and 2)~the Graph sampler where we interpret constituency parse trees as graphs and use a Message Passing based Graph Attention Network on them. We then combine both these samplers as the BERT+Graph sampler, which is used in Kathaka. We also modify the baseline duration model to incorporate the latent prosodic information. We conducted an ablation study of the samplers and showed a statistically significant improvement over the baseline in each case. Finally, we compared Kathaka against a baseline, and showed a statistically significant relative improvement of . 	 	
"," Automated emotion detection in speech is a challenging task due to the complex interdependence between words and the manner in which they are spoken. It is made more difficult by the available datasets; their small size and incompatible labeling idiosyncrasies make it hard to build generalizable emotion detection systems. To address these two challenges, we present a multi-modal approach that first transfers learning from related tasks in speech and text to produce robust neural embeddings and then uses these embeddings to train a pLDA classifier that is able to adapt to previously unseen emotions and domains. We begin by training a multilayer TDNN on the task of speaker identification with the VoxCeleb corpora and then fine-tune it on the task of emotion identification with the Crema-D corpus.  Using this network, we extract speech embeddings for Crema-D from each of its layers, generate and concatenate text embeddings for the accompanying transcripts using a fine-tuned BERT model and then train an LDA - pLDA classifier on the resulting dense representations. We exhaustively evaluate the predictive power of every component: the TDNN alone, speech embeddings from each of its layers alone, text embeddings alone and every combination thereof.  Our best variant, trained on only VoxCeleb and Crema-D and evaluated on IEMOCAP, achieves an EER of $38.05$\%. Including a portion of IEMOCAP during training produces a 5-fold averaged EER of $25.72$\% .",385
"   Vocoders were originally used for speech compression in the field of communication. Recently, vocoders have been utilized in various fields such as text-to-speech and voice conversion or speech-to-speech translation. Neural vocoders generate human-like voices using neural networks, instead of using traditional methods that contain audible artifacts .  Recently, it has been demonstrated that vocoders exhibit superior performances in generation speed and audio fidelity when trained with single speaker utterances. However, some models face difficulty when generating natural sounds in multiple domains such as speakers, language, or expressive utterances. The ability of these models can be evaluated by the sound quality when the model is trained on data of multiple speakers and the sound quality of the unseen domain . A vocoder that can generate high-fidelity audio in various domains,  regardless of whether the input has been encountered during training or has come from an out-of-domain source, is usually called a universal vocoder.  MelGAN is a vocoder based on generative adversarial networks . It is a lightweight and robust model for unseen speakers but yields lower fidelity than popularly employed models . MelGAN alleviates the metallic sound that occurs mainly in unvoiced and breathy speech segments through multi-scale discriminators that receive different scale waveforms as inputs. However, it has not been implemented efficiently for learning with multiple speakers for a universal vocoder.  In this study, we propose Universal MelGAN. The generated waveform of the original MelGAN with audible artifacts appears as an over-smoothing problem with a non-sharp spectrogram. We added multi-resolution spectrogram discriminators to the model to address this problem in the frequency domain. Our multi-scale discriminators enable fine-grained spectrogram prediction by discriminating waveforms and spectrograms. In particular, they alleviate the over-smoothing problem in the high frequency band of the large footprint model, enabling the generation of realistic multi-speaker waveforms.  To evaluate the performance of the proposed model, we compare with full-band MelGAN  as a baseline and two other vocoders: WaveGlow and WaveRNN. We designed experiments in both Korean and English for language independency. For evaluation, we prepared multiple speaker utterances that included unseen domain scenarios, such as new speakers, emotions, and languages.  The evaluation results indicate that the proposed model achieved the best mean opinion score  in most scenarios and efficiently preserved the fidelity in unseen speakers. In addition, the evaluations show that the model efficiently preserves the original speech, even in challenging domains such as expressive utterances and unseen languages. In multi-speaker text-to-speech scenarios, our model can generate high-fidelity waveforms with high MOS, and the model outperforms compared vocoders. This results without any external domain information suggest the possibility of the proposed model as a universal vocoder.     In this work, we present a multi-modal approach to emotion detection that first transfers learning from related tasks in speech and text to produce robust neural embeddings and then uses these embeddings to train a pLDA classifier that is able to adapt to previously unseen emotions and domains.  We show that:    In the future, we think there is promise in adapting learning from such fine-tuned emotion detection models to other emotions, domains and languages via one-shot classification with pLDA.  We are also interested in exploring the effectiveness of transferring from other auxiliary tasks like automated speech recognition.   
"," We propose Universal MelGAN, a vocoder that synthesizes high-fidelity speech in multiple domains. To preserve sound quality when the MelGAN-based structure is trained with a dataset of hundreds of speakers, we added multi-resolution spectrogram discriminators to sharpen the spectral resolution of the generated waveforms. This enables the model to generate realistic waveforms of multi-speakers, by alleviating the over-smoothing problem in the high frequency band of the large footprint model. Our structure generates signals close to ground-truth data without reducing the inference speed, by discriminating the waveform and spectrogram during training. The model achieved the best mean opinion score  in most scenarios using ground-truth mel-spectrogram as an input. Especially, it showed superior performance in unseen domains with regard of speaker, emotion, and language. Moreover, in a multi-speaker text-to-speech scenario using mel-spectrogram generated by a transformer model, it synthesized high-fidelity speech of 4.22 MOS. These results, achieved without external domain information, highlight the potential of the proposed model as a universal vocoder.",386
" %What is spoken term detection  Unsupervised speech modeling is the task of discovering and modeling speech units at various levels from audio recording without using any prior linguistic information. It is an interesting, challenging and impactful research problem as phonetic, lexical and even semantic information could be acquired without the process of transcribing and understanding the given speech data. The relevant technology is particularly important to facilitate data preparation especially in the scenarios where: 1) a large  amount of audio data are readily available online but they are untranscribed; 2) a large amount of audio recording is available for an unpopular language about which no structured linguistic knowledge or documentation can be found.  Spoken term discovery is a representative task of unsupervised speech modeling. It aims to discover repetitively occurred words and/or phrases from untranscribed audio.  The problem is commonly tackled with a two-stage approach. In the first stage, a set of subword units are automatically discovered from untranscribed speech data and these units in turn can be used to represent the speech data as a symbol sequence. In the second stage, variable-length sequence matching and clustering are performed on the subword sequence representations. One major drawback of this is that the subword decoding errors in the first stage would propagate to deteriorate the outcome of spoken term discovery in the second stage. The present study investigates the use of Siamese and Triplet networks in spoken term discovery. Siamese network has been commonly applied to pattern classification or matching problems when only weak labels are available. We propose to train a Siamese/Triplet network with a small dataset of matched and mismatched sequence pairs obtained and use the trained network to generate feature representations for unseen subword sequences. The training dataset is constructed based on hypothesized spoken term clusters from an baseline spoken term discovery system developed in our previous study. With the new feature representations learned by the Siamese/Triplet network, re-clustering of subword sequences is carried out to generate an improved set of discovered spoken terms.       In this study, we propose Universal MelGAN, a robust neural vocoder for high-fidelity synthesis in multiple domains. We solved the over-smoothing problem that causes a metallic sound, by attaching multi-resolution spectrogram discriminators to the model. Our model is stable while generating waveforms with fine-grained spectrograms in large footprint models. The evaluation results indicate that the proposed model achieved the highest MOS in most seen and unseen domain scenarios. The result demonstrates the universality of the proposed model. For more general use of the model, we will study a lightweight model in the future and apply the multi-band strategy to reduce the complexity while preserving the sound quality.    
"," Spoken term discovery from untranscribed speech audio could be achieved via a two-stage process. In the first stage, the unlabelled speech is decoded into a sequence of subword units that are learned and modelled in an unsupervised manner. In the second stage, partial sequence matching and clustering are performed on the decoded subword sequences, resulting in a set of discovered words or phrases. A limitation of this approach is that the results of subword decoding could be erroneous, and the errors would impact the subsequent steps. While Siamese/Triplet network is one approach to learn segment representations that can improve the discovery process, the challenge in spoken term discovery under a complete unsupervised scenario is that training examples are unavailable. In this paper, we propose to generate training examples from initial hypothesized sequence clusters. The Siamese/Triplet network is trained on the hypothesized examples to measure the similarity between two speech segments and hereby perform re-clustering of all hypothesized subword sequences to achieve spoken term discovery.  Experimental results show that the proposed approach is effective in obtaining training examples for Siamese and Triplet networks, improving the efficacy of spoken term discovery as compared with the original two-stage method.",387
" Evidence-based medicine  is a medical practice that aims to find all the evidence to support medical decisions. This evidence nowadays is obtained from biomedical journals, usually accessible through online databases like PubMed and EMBASE, which provide free access to articles' abstracts and in some cases, to full articles. In the context of the COVID-19 pandemic, EBM is critical to making decisions at the individual level and public health since research articles address topics like treatments, adverse cases, and effects of public policies in medicine. The EBM foundation Epistemonikos has made essential contributions by curating and publishing updated guides of what treatments are working and not against COVID-19~\footnote{http://epistemonikos.org/}. Epistemonikos addresses EBM by a combination of software tools for data collection, storage, filtering , and retrieval, as well as by the vital labor of volunteer physicians who curate and label research articles based on quality , type  and PICO labels . However, this workflow has been challenged during 2020 by increasing growth and rapidly evolving evidence of COVID-19 articles published in the latest months. Moreover, to ensure the rapid collection of the latest evidence published, pre-print repositories such as medRXiv and bioRXiv have been added to the traditional online databases. % In order to support Epistemonikos' effort to filter and curate the flood of articles related to COVID-19, we present the results of an applied AI project where we implement and evaluate a text classification system to filter and categorize research articles related to COVID-19. The current model, based on Random Forests, has an acceptable performance classifying systematic reviews  but fails on classifying other document categories. In this article, we show how using BioBERT yields marginal improvements, while XLNET results in significant progress with the best performance. These results save a considerable amount of time from volunteer physicians by pre-filtering the articles worth of manual curation and labeling for EBM. In average, a physician takes two minutes in reviewing one article, while the system we present in this article can review up to  within one hour.   %With the help of volunteer physicians, they classify emergent literature for the COVID-19 virus in systematic reviews, broad syntheses, or primary studies, which is the first step for finding relevant clinical evidence. Until now, they produced a Random Forest model for classifying documents into different categories. However, in this paper, we show how the use of Transformers-based Language Models  helped this foundation save significant effort to their collaborators.   %        The clusters can be as compatible as the baseline model.   The operation of the proposed  system is compatible to the baseline model. This shows that even in a completely unsupervised scenario, a well-performing Siamese network can still be trained with segments and soft labels generated in unsupervised manner. By maintaining a high confidence of hypothesized segment labels, the network is capable to generate segment representations  on new unseen segments    for spoken term discovery.   It is noted that referring from clustering results of other spoken term discovery system is only one of the complete unsupervised methods to obtain segment boundaries and cluster information for generating soft labels for the Siamese network training.    This method is specifically considered in this work for baseline comparison.  Other segmentation and confident data generation approaches are also feasible.    The term clusters discovered by  and  exhibit different properties and work favorably on different types of segments. Post-processing work in combining the term clusters from these two systems can be considered to improved the overall term discovery performance. Multiple clusters representation of shorter terms can also be grouped together. One way is to learn the semantic relationship between clusters by treating the segments as words for word2vec training .  , which had been shown to be possible on audio segments .    Clusters with close semantic relationship and small segment representation distances can be combined.    similar meaning reflected in the learnt representations and with similar segment features can be combined.     Depending on the goal of the clustering, alternative clustering algorithms can be considered. If we are aiming to remove noise from the segment candidates, HDBCAN might be a good choice.  But if we are aiming for full coverage of all the possible words in the recording, then other clustering algorithms such as BPGMM can be considered to assign all segment candidates into a specific term cluster.    Alternative clustering  \section{Conclusion}  In this work, the attempt of using Siamese and Triplet networks for spoken term discovery under a complete unsupervised scenario is made. The initial segmentation and cluster information is obtained from other spoken term discovery system. The clusters with high confidence are used to generate matched and mismatched pairs and tuples for training the Siamese and Triplet networks. The networks are used to generate representations for all the available segments, follow by HDBSCAN on the segment representations to obtain new set of spoken term clusters.  It is shown that even the exact labels of the segments are unavailable, Siamese/Triplet network can still be trained when a small set of high confidence matched and mismatched data pairs are presented.  This shows that even in a completely unsupervised scenario, a well-performing Siamese/Triplet network can still be trained with segments and soft labels generated in unsupervised manner. By maintaining a high confidence of hypothesized segment labels, the network is capable to generate segment representations for spoken term discovery.  The segment representations generated by Siamese and Triplet networks can outperform the baseline two-stage model. In the lecture recording experiment, the result is not conclusive for Triplet network. However, experiment on Zerospeech dataset shows that Triplet network is slightly better than Siamese network in learning segment representations for spoken term discovery when trained on sufficient data.   Triplet network is less favourable than Siamese network in generating segment representations for spoken term discovery.   In the problem of spoken term discovery, Triplet network is less favourable in our experiments as the cluster boundaries are less easy to determine by clustering algorithm.          
","  The COVID-19 has brought about a significant challenge to the whole of humanity, but with a special burden upon the medical community. Clinicians must keep updated continuously about symptoms, diagnoses, and effectiveness of emergent treatments under a never-ending flood of scientific literature. In this context, the role of evidence-based medicine  for curating the most substantial evidence to support public health and clinical practice turns essential but is being challenged as never before due to the high volume of research articles published and pre-prints posted daily. Artificial Intelligence can have a crucial role in this situation. In this article, we report the results of an applied research project to classify scientific articles to support Epistemonikos, one of the most active foundations worldwide conducting EBM. We test several methods, and the best one, based on the XLNet neural language model, improves the current approach by 93\% on average F1-score, saving valuable time from physicians who volunteer to curate COVID-19 research articles manually.",388
"  The natural language processing community has made tremendous progress  in using pre-trained language models to improve predictive accuracy . Models have now surpassed human performance on language understanding benchmarks such as SuperGLUE . However, studies have shown that these results are partially driven by these models detecting superficial cues that correlate well with labels but which may not be useful for the intended underlying task . This brittleness leads to overestimating model performance on the artificially constructed tasks and poor performance in out-of-distribution or adversarial examples.  A well-studied example of this phenomenon is the natural language inference dataset MNLI . The generation of this dataset led to spurious surface patterns that correlate noticeably with the labels.  highlight that negation words  are often associated with the contradiction label.  show that a model trained solely on the hypothesis, completely ignoring the intended signal, reaches strong performance. We refer to these surface patterns as dataset biases since the conditional distribution of the labels given such biased features is likely to change in examples outside the training data distribution .  A major challenge in representation learning for NLP is to produce models that are robust to these dataset biases. Previous work  has targeted removing dataset biases by explicitly factoring them out of models. These works explicitly construct a biased model, for instance, a hypothesis-only model for NLI experiments, and use it to improve the robustness of the main model. The core idea is to encourage the main model to find a different explanation where the biased model is wrong. During training, products-of-experts ensembling  is used to factor out the biased model.   While these works show promising results, the assumption of knowledge of the underlying dataset bias is quite restrictive. Finding dataset biases in established datasets is a costly and time-consuming process, and may require access to private details about the annotation procedure, while actively reducing surface correlations in the collection process of new datasets is challenging given the number of potential biases .  In this work, we explore methods for learning from biased datasets which do not require such an explicit formulation of the dataset biases. We first show how a model with limited capacity, which we call a weak learner, trained with a standard cross-entropy loss learns to exploit biases in the dataset. We then investigate the biases on which this weak learner relies and show that they match several previously manually identified biases. Based on this observation, we leverage such limited capacity models in a product of experts ensemble to train a more robust model and evaluate our approach in various settings ranging from toy datasets up to large crowd-sourced benchmarks: controlled synthetic bias setup , natural language inference  and extractive question answering .  Our contributions are the following:  we show that weak learners are prone to relying on shallow heuristics and highlight how they rediscover previously human-identified dataset biases;  we demonstrate that we do not need to explicitly know or model dataset biases to train more robust models that generalize better to out-of-distribution examples;  we discuss the design choices for weak learners and show trade-offs between higher out-of-distribution performance at the expense of the in-distribution performance.   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   \subfile{sections/conclusions}   
"," State-of-the-art natural language processing  models often learn to model dataset biases and surface form correlations instead of features that target the intended underlying task. Previous work has demonstrated effective methods to circumvent these issues when knowledge of the bias is available. We consider cases where the bias issues may not be explicitly identified, and show a method for training models that learn to ignore these problematic correlations.  Our approach relies on the observation that models with limited capacity primarily learn to exploit biases in the dataset. We can leverage the errors of such limited capacity models to train a more robust model in a product of experts, thus bypassing the need to hand-craft a biased model. We show the effectiveness of this method to retain improvements in out-of-distribution settings even if no particular bias is targeted by the biased model.",389
" Topic models  have been popularly used to extract abstract topics which occur commonly across documents in a corpus in the field of Natural Language Processing. Each topic is a group of semantically coherent words that represent a common concept. In addition to gaining insights from unstructured texts, topic models have been used in several tasks of practical importance such as learning text representations for document classification , keyphrase extraction , review understanding for recommendations in e-commerce domain , semantic similarity detection between texts  etc.  % in order to make topic sampling distribution converge to the desired posterior distribution  Early popular works on topic discovery include statistical methods such as Latent Dirichlet Allocation   which approximates each topic as a probability distribution over word vocabulary and performs approximate inference over document-topic and topic-word distributions through Variational Bayes . This was followed by a modified inference algorithm - Collapsed Gibbs sampling  that follows Markov Chain Monte Carlo  . However, these methods require an expensive iterative inference step which has to be performed for each document. This was circumvented through introduction of deep neural networks  and emergence of Variational Autoencoders   in particular, where variational inference can be performed in single forward pass.  % while estimating the posterior distribution. % Laplace approximation of  % The re-parameterisation trick of VAEs allows to perform variational inference in a differentiable manner while training the neural network.  Such neural variational inference based topic models  outperformed the traditional probabilistic sampling methods. Broadly, they model a document as Bag-of-Words  determined on the basis of frequency count of each vocabulary token in the given document. The BoW input is processed through an MLP followed by variational inference  which samples a latent document-topic vector. A decoder network then reconstructs original BoW using latent document-topic vector which allows it to capture relationship between document-topic and topic-word distributions. VAE family of neural topic models can be categorised on the basis of prior enforced on latent document-topic distribution. Methods such as NVDM , NTM-R , NVDM-GSM  use Gaussian prior. NVLDA and ProdLDA  use Dirichlet prior approximation which enables model to capture that a document stems from sparse set of topics.  % and perform better by providing more coherent topics compared to Gaussian prior.  % in order to capture latent document-topic distribution,  % The context vector obtained as a result of attention is used to perform variational inference %  and capture semantics effectively  % which can further help in inferring latent document-topic vector % as carried  in usual VAE based topic models  % using the final LSTM state and the outputs corresponding  While the main focus of previous neural topic models has been to enforce suitable priors, little effort has been spent on explicitly improving the document encoding framework in order to capture document semantics better. In this work, we build upon VAE based topic model using laplace approximation to Dirichlet prior and propose a novel framework where we model the input document as a sequence of tokens. The sequence is processed through an LSTM  that allows it to encode the sequential order which does not remain preserved in BoW. To allow the model to focus on specific parts in the document, we use an attention mechanism  to attend at different document tokens. We hypothesise that topic-word distribution being learned by the model can be factored in the attention mechanism to enable the model to attend on tokens which convey topic related information and cues. We validate our hypothesis and propose TAN-NTM: Topic Attention Networks for Neural Topic Modeling which performs attention efficiently in a topic guided manner. We perform separate attention for each topic using its corresponding word probability distribution and obtain topic-wise context vectors. The context vectors are then composed using topic weights which represent proportion of each topic present in a given document. These topic weights are obtained using the learned token embedding and topic-word distribution. The final composed context vector is then used to perform variational inference followed by BoW decoding. We perform extensive ablations to compare different ways of composing topic-wise context vectors.  % and averages the coherence score over the topics % generated by the model   In order to evaluate our approach, we estimate commonly used NPMI coherence  which measures the extent to which most probable words in a topic are semantically related to each other. Using this metric, we compare our TAN-NTM model with several previous state-of-the-art topic models  outperforming them significantly over 4 benchmark datasets of varying scale and complexity - 20NewsGroup  , Yelp Review Polarity, DBpedia  and AGNews . We demonstrate the efficacy of our model in learning better document feature representations and latent document-topic vectors by achieving higher document classification accuracy over baseline topics models. Furthermore, topic models have previously been used to improve supervised keyphrase generation . We show that our proposed framework can be adapted to modify the topic model and further improve keyphrase generation achieving SOTA performance on StackExchange and Weibo datasets. Our contributions can be summarised as:       %   We have presented an effective method for training models robust to dataset biases. Leveraging a weak learner with limited capacity and a modified product of experts training setup, we show that dataset biases do not need to be explicitly known or modeled to be able to train models that can generalize significantly better to out-of-distribution examples. We discuss the design choices for such weak learner and investigate how using higher-capacity learners leads to higher out-of-distribution performance and a trade-off with in-distribution performance. We believe that such approaches capable of automatically identifying and mitigating datasets bias will be essential tools for future bias-discovery and mitigation techniques.                                                                            \clearpage  
"," Topic models have been widely used to learn representations from text and gain insight into document corpora. To perform topic discovery, existing neural models use document bag-of-words  representation as input followed by variational inference and learn topic-word distribution through reconstructing BoW. Such methods have mainly focused on analysing the effect of enforcing suitable priors on document distribution. However, little importance has been given to encoding improved document features for capturing document semantics better. In this work, we propose a novel framework: TAN-NTM which models document as a sequence of tokens instead of BoW at the input layer and processes it through an LSTM whose output is used to perform variational inference followed by BoW decoding. We apply attention on LSTM outputs to empower the model to attend on relevant words which convey topic related cues. We hypothesise that attention can be performed effectively if done in a topic guided manner and establish this empirically through ablations. We factor in topic-word distribution to perform topic aware attention achieving state-of-the-art results with $\sim$ $9$ - $15$ percentage improvement over score of existing SOTA topic models in NPMI coherence metric on four benchmark datasets - 20NewsGroup, Yelp, AGNews, DBpedia. TAN-NTM also obtains better document classification accuracy owing to learning improved document-topic features. We qualitatively discuss that attention mechanism enables unsupervised discovery of keywords. Motivated by this, we further show that our proposed framework achieves state-of-the-art performance on topic aware supervised generation of keyphrases on StackExchange and Weibo datasets.",390
"  .     %      % % final paper: en-us version      %       % space normally used by the marker     This work is licensed under a Creative Commons      Attribution 4.0 International License.     License details:     \url{http://creativecommons.org/licenses/by/4.0/}. } Rhetorical Structure Theory   is one of the most influential theories of discourse analysis, under which a document is represented by a hierarchical discourse tree. As shown in Figure a, the leaf nodes of an RST tree are text spans named Elementary Discourse Units , and the EDUs are connected by rhetorical relations  to form larger text spans until the entire document is included.  The rhetorical relations are further categorized to Nucleus  and Satellite  based on their relative importance. Thus, document-level discourse parsing consists of three sub-tasks: tree construction, nuclearity determination and relation classification. Moreover, downstream natural language processing tasks can benefit from RST-based structure-aware document analysis, such as summarization  and machine comprehension .  By utilizing various linguistic characteristics , statistical approaches have obtained substantial improvement on the English RST-DT benchmark . Recently, neural networks have been making inroads into discourse analysis frameworks, such as attention-based hierarchical encoding  and integrating neural-based syntactic features into a transition-based parser . Lin et al. \shortcite{lin2019unified} and their follow-up work  successfully explored encoder-decoder neural architectures on sentence-level discourse analysis, with a top-down parsing procedure.  Although discourse parsing has received much research attention and progress, the models are mainly optimized and evaluated in English. The main challenge is the shortage of annotated data, since manual annotation under the RST framework is labor-intensive and requires specialized linguistic knowledge. For instance, the most popular benchmark English RST-DT corpus  only contains 385 samples, which is much smaller than those of other natural language processing tasks. The treebank size of other languages such as German , Dutch  and Basque  are even more limited. Such limitations make it difficult to achieve acceptable performance on these languages required to fully support downstream tasks, and also lead to poor generalization ability of the computational approaches.  Since the treebanks of different languages share the same underlying linguistic theory, data-driven approaches can benefit from joint learning on multilingual RST resources . Therefore, in this paper, we investigate two methods to build a cross-lingual neural discourse parser:  From the embedding perspective: with the cross-lingual contextualized language models, we can train a parser on the shared semantic space from multilingual sources without employing a language indicator;  From the text perspective: since each EDU is a semantically-cohesive unit, we can unify the target language space by EDU-level translation, while preserving the original EDU segmentation and the discourse tree structures . To this end, we adapted and enhanced an end-to-end neural discourse parser, and investigated the two proposed approaches on 6 different languages. While the RST data for training is still in a small scale, we achieved the state-of-the-art performance on all fronts, significantly surpassing previous models, and even approaching the upper bound of human performance. Moreover, we conducted a topic modeling analysis on the collected multilingual treebanks to evaluate the model generality across various domains.       In this paper, we propose the FedHumor approach - a humorous text recognition model following the federated learning paradigm which can provide personalized humor recognition based on labels stored in distributed sources. It is able to account for diversity in each person's activation point for perceived funniness for the same text contents. Through extensive experiments comparing FedHumor with 9 state-of-the-art approaches, we show that it is able to achieve better personalization when recognizing humor from text contents. To the best of our knowledge, it is the first federated learning-based personalized humorous text recognition model.         
"," Text discourse parsing plays an important role in understanding information flow and argumentative structure in natural language. Previous research under the Rhetorical Structure Theory  has mostly focused on inducing and evaluating models from the English treebank. However, the parsing tasks for other languages such as German, Dutch, and Portuguese are still challenging due to the shortage of annotated data. In this work, we investigate two approaches to establish a neural, cross-lingual discourse parser via:  utilizing multilingual vector representations; and  adopting segment-level translation of the source content. Experiment results show that both methods are effective even with limited training data, and achieve state-of-the-art performance on cross-lingual, document-level discourse parsing on all sub-tasks. \newline",391
" In recent years, smart devices with built-in personal assistants like Google Assistant and Siri are becoming omnipresent. Behind these intelligent systems, a key question is how to identify the underlying intent of a user utterance, which has triggered a large amount of work on intent detection . Most existing intent detection systems are built on deep learning models trained on large-scale annotated data. However, as user demands and the functions of smart devices continue to grow, collecting supervised data for every new intent becomes time-consuming and labor-intensive.  To address this issue, some studies tackle intent detection in the zero-shot learning  manner, attempting to utilize the learned knowledge of seen classes to help detect unseen classes. The recent methods of zero-shot intent detection  can be roughly divided into two categories: The first category , referred to as the transformation-based methods, utilizes word embeddings of label names to establish a similarity matrix, which is then used to transfer the prediction space of seen intents to unseen intents. Another line of work is based on the compatibility-based methods , which aims to encode the label names and utterances into representations in the same semantic space and then calculate their similarity. In both kinds of methods, a critical problem is learning intent representations. However, most existing ZSID methods are class-inductive, which relies entirely on labeled data from seen intents in the training stage. Consequently, the representations of unseen intents cannot be learned, resulting in two limitations.  First, the ZSID methods are not good at modeling the relationship between seen and unseen intents. For the transformation-based methods, when the label names are given in the form of raw phrases or sentences, word embeddings of label names are inadequate to associate the connections between seen and unseen intents. For example, 閳ユ窂ookRestaurant閳 is similar to 閳ユ珐ateBook閳 when measured by word embeddings, as they share the word 閳ユ窂ook閳 . However, the meaning of these two intents are not that relevant. % As a result, the computed similarity matrix is inadequate in associating the connections between seen and unseen intents .  For the compatibility-based methods, they minimize the similarity between seen intent samples and seen label names in a shared semantic space, and directly transfer it to detect unseen intents. Since the unseen intent representations are not learned, they might be entangled with the representations of seen intents. This can severely hurt the accuracy of the predicted label-utterance similarity, especially when the expressions of utterances are diverse. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  Second, the vanilla ZSL methods are not applicable to generalized intent detection . Compared with the ZSL setting , which assumes that the models are only presented with utterances from unseen classes at test time, GZSID requires the model to detect both seen and unseen intents. In GZSID, existing ZSL models usually suffer from the dubbed domain shift  problem, in which utterances from unseen intents are almost always mistakenly classified into seen intents.   Unlike the class-inductive methods, class-transductive ZSL uses semantic information about the unseen classes for model training . In the context of intent detection, the label name provides a proper sketch of the intent meaning. Motivated by this, we propose to utilize label names of the unseen intents to learn disentangled intent representations . Specifically, we include the unseen intents into the prediction space during training, with the label names serving as the pseudo utterances. This allows the model to learn the boundary of each seen and unseen class in the semantic space. Under this framework, we introduce an assistant task that forces the model to find the distinction between seen and unseen intents, thereby alleviating the domain-shift problem. On this basis, we refine the word embedding based similarity matrix by averaging the representations of all corresponding  utterances and  label names. As a result, we can better capture the intent meanings and the similarity matrix reflects more accurate intent connections.   In summary, our contribution is three-fold:  We believe that the potential of class-transductive ZSL  in intent detection is still not fully exploited, to encourage more related studies in the future, we will release our codes and data.      In this paper, we investigated two approaches for cross-lingual neural discourse parsing. Experimental results show that both utilizing cross-lingual representation and adopting segment-level translation contribute to obtaining state-of-the-art performance on various treebanks. Moreover, monolingual models can also benefit from cross-lingual training by introducing data from more domains. For future work, we consider conducting domain adaption via few-shot learning to make our approach more generalizable.  
"," Zero-shot intent detection  aims to deal with the continuously emerging intents without annotated training data. However, existing ZSID systems suffer from two limitations: 1) They are not good at modeling the relationship between seen and unseen intents, when the label names are given in the form of raw phrases or sentences. 2) They cannot effectively recognize unseen intents under the generalized intent detection  setting. A critical factor behind these limitations is the representations of unseen intents, which cannot be learned in the training stage. To address this problem, we propose a class-transductive framework that utilizes unseen class labels to learn Disentangled Intent Representations . Specifically, we allow the model to predict unseen intents in the training stage, with the corresponding label names serving as input utterances. Under this framework, we introduce a multi-task learning objective, which encourages the model to learn the distinctions among intents, and a similarity scorer, which estimates the connections among intents more accurately based on the learned intent representations. % Moreover, we present a novel approach to calculate the inter-intent similarities, on the basis of the learned intent representations, which estimates the connections among intents more accurately.  Since the purpose of DIR is to provide better intent representations, it can be easily integrated with existing ZSID and GZSID methods. Experiments on two real-world datasets show that the proposed framework brings consistent improvement to the baseline systems, regardless of the model architectures or zero-shot learning strategies.",392
" Multi-turn open-domain dialogue modeling is an active research topic in the field of natural language processing.  However, generating a coherent and informative response for a given dialogue context remains a challenge. % However, it is still challenging for dialogue models to generate a coherent and informative response for a given dialogue context. %Research in this domain mainly addresses the following two questions: 1) How can we learn to represent the context? 2) In the presence of context representation, how can we infer the distribution of the response?  A critical challenge is the learning of rich and robust context representations of dialogue utterances~, namely the challenge of encoding a dialogue context into a vector that adequately captures the semantics . % A major challenge in this domain is to learn rich and robust context representations of dialogue utterances~, namely the challenge of encoding a dialogue context into a vector that adequately captures the semantics .  Large-scale pre-training language models using Transformer-based architectures have recently achieved remarkable successes in a variety of NLP tasks~. % Recently, large-scale pre-training language models using Transformer-based architectures have achieved remarkable successes in a variety of NLP tasks~.  As such, there are increasingly work that aims to use pre-training language models for conversation modeling~. For example, DialoGPT~ extends the GPT-2~ to generate conversation responses on large-scale dialogue corpus. Meena~ trains a sequence-to-sequence model~ with the Evolved Transformer~ on large-scale multi-turn conversations.  Blender, developed by Facebook, provides recipes for building open-domain chatbots that perform well in human evaluations~.  However, existing pre-training conversation models usually view the dialogue context as a linear sequence of tokens and learns to generate the next word through token-level self-attention.  One issue of this approach is that the high-level relationships between utterances are harder to capture using word-level semantics. % One issue of this approach is that the relationships between utterances are scattered into individual words, hindering the capturing of discourse-level coherence.  For example, the discourse-level relationship between the utterances ``coffee please'' and ``here you are''  is apparent, but word-level comparisons, such as coffee, you and please, are, obscures the high-level relationship. % For example, the utterance ``coffee please'' and ``here you are'' in Figure have a strong certain relationship, by contrast, pairs of individual words in these two utterances such as coffee, you and please, are have obscure correlations. Furthermore, this full pairwise attention is inefficient since it requires each word in the context and the decoder to interact with all other words regardless of their distances and semantic units. % Furthermore, the full pairwise attention is inefficient since it requires each word in the context and the decoder to interact with all other words regardless of their distances and semantic units.  To alleviate the issues above, we present DialogBERT, a novel conversational response generation model.  % To alleviate the aforementioned issues, we present DialogBERT, a novel conversational response generation model.  DialogBERT employs a hierarchical Transformer architecture to represent the dialogue context.  It first encodes dialogue utterances through a Transformer encoder and then encodes the resulting utterance vectors using a discourse-level Transformer to obtain a representation of the entire dialogue context.  To efficiently capture discourse-level coherence among utterances, we propose two training objectives in analogy to the original BERT training: 1) masked context regression, which masks a randomly-selected utterance and predicts the encoding vector for the masked utterance directly; and 2) distributed utterance order ranking, which %reconstructs the order of utterances that belong to the same dialog context   organizes randomly shuffled utterances of a conversation into a coherent dialogue context  through a Learning-to-Rank~ neural network.  We evaluate DialogBERT on popular multi-turn conversation datasets, namely Weibo, MultiWOZ and DailyDialog.  Results show that DialogBERT outperforms baselines in terms of perplexity, BLEU, and NIST. Human evaluation supports the superiority of our approach in capturing discourse-level semantics and generating more plausible dialogue responses.  %Our contributions can be summarized as follows: %      In this paper, we propose a class-transductive framework to overcome the limitations of existing ZSID models. The framework learns disentangled representations for unseen intents by including them into the prediction space during training. Under the DIR framework, we present a multi-task learning objective in the training stage to encourages the model to learn the distinctions between unseen and seen intents. In the inference stage, we develop a similarity scorer, which can better associate the inter-intent connections based on the learned representations. Experiments on two benchmarks show that DIR is effective and robust, which can bring considerable improvement to ZSID systems with different zero-shot learning strategies and backbone networks.    
"," Recent advances in pre-trained language models have significantly improved neural response generation.  However, existing methods usually view the dialogue context as a linear sequence of tokens and learn to generate the next word through token-level self-attention.  Such token-level encoding hinders the exploration of discourse-level coherence among utterances.  This paper presents DialogBERT, a novel conversational response generation model that enhances previous PLM-based dialogue models. DialogBERT employs a hierarchical Transformer architecture.  To efficiently capture the discourse-level coherence among utterances, we propose two training objectives, including masked utterance regression and distributed utterance order ranking in analogy to the original BERT training.  Experiments on three multi-turn conversation datasets show that our approach remarkably outperforms the baselines, such as BART and DialoGPT, in terms of quantitative evaluation.  The human evaluation suggests that DialogBERT generates more coherent, informative, and human-like responses than the baselines with significant margins. % Pre-trained language models  have been successfully adapted to neural response generation.  % However, existing methods usually view the dialogue context as a linear sequence of tokens and learn to generate the next word through token-level self-attention. % Such token-level encoding hinders the exploration of discourse-level coherence among utterances. % In this paper, we present DialogBERT, a novel conversational response generation model that enhances previous PLM-based dialogue models. % %In order to model the utterance-level interactions, % Instead of a flat encoding of linear tokens, DialogBERT employs a hierarchical Transformer architecture.  % %DialogBERT consists of an utterance encoder for encoding utterances and a context encoder for learning to contextualize given utterances' representations. % To efficiently capture the discourse-level coherence among utterances, we propose two new training objectives including masked utterance regression and distributed utterance order ranking in analogy to the original BERT training.  % Experiments on three multi-turn conversation datasets show that  % our approach remarkably outperforms three baselines such as BART and DialoGPT in terms of quantitative evaluation.  % Human evaluation  % suggests  % %\jw{supports}  % that DialogBERT generates more coherent, informative and human-like responses than the baselines with significant margins.",393
" Event Detection ,  the task of which involves identifying the boundaries of event triggers and classifying them into the corresponding event types, aims to seek recognize events of specific types from given texts. As a fundamental task of information extraction, many high-level NLP tasks, such as information retrieval and question answering, need an event detector as one of their essential components.    % 娑旂喕顩﹂崝鐘茬穿閻 Recent studies show that English ED models have achieved great performance by treating the problem as a word-by-word sequence labeling task.  Different from English ED, many East Asian languages, including Chinese, are written without explicit word boundary, resulting a much tricky ED task. An intuitive solution is to apply Chinese Word Segmentation  tools first to get word boundaries, and then use a word-level sequence labeling model similar to the English ED models.  However, word boundary is ambiguous in Chinese thus word-trigger mismatch problem exists in Chinese ED, where an event trigger may not exactly match with a word, but is likely to be part of a word or cross multiple words as Figure demonstrates. Meanwhile, character-level sequence tagging is able to alleviate this problem, but Chinese character embedding can only carry limited information due to the lack of word and word-sequence information, resulting to ambiguous semantics.  % Therefore, how to better integrate segmentation-related information and character-level semantics is a key feature in Chinese ED models.  Several recent works have demonstrated that considering the lexicon word information could provide more exact information to discriminate semantics of characters. \citeauthor{lin-etal-2018-nugget}~\shortcite{lin-etal-2018-nugget} designed NPN, a CNN-like network to model character compositional structure of trigger words and introduced a gate mechanism to fuse information from characters and words. ~\citeauthor{ding-etal-2019-event}~\shortcite{ding-etal-2019-event} proposed TLNN, a trigger-aware Lattice LSTM architecture, exploiting semantics from matched lexicon words to improve Chinese ED.    Although these methods have achieved great success, they continue to have difficulty in fully exploiting the interaction between characters and lexicon words. Specifically, for each character, NPN exploits a gate mechanism to fuse its information with one corresponding word. This means that each character could only be incorporated with one matched word, but actually one character is likely to match with several words, leading to information loss. For TLNN, it constructs cut paths to link the start and end character for each matched word, but semantic information of the matched lexicon word fails to flow into all the characters it covers except the last one, due to the inherently unidirectional sequential nature of Lattice LSTM. %For characters without matched words, no extra information is provided enhance its representation.  Besides, previous ED works usually ignore semantic information maintained by the event types. We observe that event types are usually semantically related to the corresponding event triggers.   Such an observation shows that considering the semantic information of event labels may provide fine-grained semantic signals to guide the detection of event triggers, and accordingly benefit ED performance.  In this paper, we propose a novel neural architecture, named Label Enhanced Heterogeneous Graph Attention Networks , for Chinese ED. To promote better information interaction between words and characters, we transform each sentence into a graph.  We first connect lexicon words with all the characters it covers. And then neighboring characters are also linked with each other to provide local context information to enhance character representations, especially for those without matched lexicon word. To capture different granularity of semantic information from words and characters, we formulate words and characters as two types of nodes, thus a heterogeneous graph attention networks is utilized to enable rich information propagation over the graph. Additionally, we design a matcher module to leverage the semantic information of event labels. Specifically, we transform event labels into an event-trigger-prototype based embedding matrix by summarizing the trigger representations belonging to each event label. Based on the generated event label representation, a margin loss is further exploited to enhance the ability to discriminate confusing event labels. Comparing with previous works, our contributions are as follows:     In this paper, we proposed a neural response generation model named DialogBERT.  Instead of encoding the dialogue context as a linear sequence of tokens, DialogBERT employs a hierarchical Transformer encoder architecture.  : utterances in the dialogue context are first encoded into vectors by an utterance encoder before fed into a context encoder which learns the context sensitive encoding.  As a natural extension of the original BERT training, we proposed two training objectives: masked utterance regression and distributed utterance re-ordering. We showed that the proposed objectives enable the conversation model to capture multi-level  coherences. Additionally, we showed that DialogBERT notably outperforms baseline models on the response generation tasks.   KMY: how about future work?    
"," Event Detection  aims to recognize instances of specified types of event triggers in text. Different from English ED, Chinese ED suffers from the problem of word-trigger mismatch due to the uncertain word boundaries.  Existing approaches injecting word information into character-level models have achieved promising progress  to alleviate this problem, but they are limited by two issues. First, the interaction between characters and lexicon words is not fully exploited. Second, they ignore the semantic information provided by event labels.  We thus propose a novel architecture named Label enhanced Heterogeneous Graph Attention Networks .  Specifically, we transform each sentence into a graph, where character nodes and word nodes are connected with different types of edges, so that the interaction between words and characters is fully reserved. A heterogeneous graph attention networks is then introduced to propagate relational message and enrich information interaction. Furthermore, we convert each label into a trigger-prototype-based embedding, and design a margin loss to guide the model distinguish confusing event labels. Experiments on two benchmark datasets show that our model achieves significant improvement over a range of competitive baseline methods.",394
" % \rev{@Ileana: this is an example on how to indicate changes in the text, based on the revision.} % \todo[inline]{we need to add color bars on figures, as promised to the reviewers}    Given enough computational power, the scalability of the attention mechanism~ will allow for building ever larger Natural Language Processing  models with billions of parameters . While impressive, these advances also pose a responsibility to the NLP community to interpret the behavior of the hundreds of attention heads in a single model, and potentially to reduce the number of computations. Responding to this challenge, previous work has taken pioneering steps to discover and to explain the sparseness in the attention patters. Here, we argue that as the number of heads grows in the range of thousands, automatic measures would be needed to discover and to impose sparseness to such models.  We introduce a simple task-agnostic data-informed pruning method for attention mechanisms: Attention Pruning. We train Transformer-based models and we analyze global observed attention patterns, averaged over all input sequences in the train set, in order to identify and to remove weak connections between the input tokens. Following \citet{lottery}, we then retrain these models, enforcing sparseness through masking, and we demonstrate that attention mechanisms incorporate extraneous connections between the input tokens: we obtain comparable  % \question{or even marginally better performance} performance while using sparse attention patterns for NLP tasks such as language and sequence-to-sequence  modelling, as well as %Natural Language  Inference . \rev{prediction on GLUE tasks. Figure summarizes the impact of using our pruning method on standard NLP tasks.}     These global sparseness patterns could help improve both interpretability and inference-time computational efficiency for widely-used attention models. Our contributions are as follows:    % The rest of the paper is organized as follows: In Section, we present related work. In Section, we introduce the details behind our attention pruning method. In Section, we apply AP to experiments with language modelling. In Section, we apply AP for seq2seq modelling on machine translation tasks. In Section, we extend our machine translation experiments to demonstrate that AP is compatible with -entmax regularization~, which is another promising sparseness technique. In Section, we study the effect of AP with BERT on the GLUE benchmark. % % Section. In Section we discuss theoretically how our pruned Transformers could yield speedups in terms of MACs.  % In Section, we discuss the hardware efficiency of AP and its promise for speeding up modelling for really long sequences. In Section, we conclude and we point to promising directions for future work.    In this paper, we propose a novel architecture, label enhanced heterogeneous graph attention networks model ,  for Chinese ED. To fully exploit information between characters and words, we formulate characters and words as different types of nodes, and connect them with richly functional edges. The heterogeneous graph attention networks is utilized to enable adequate information propagation. Besides, we utilize the semantic clues from event labels to guide the detection of event triggers. Experiment results show that L-HGAT consistently achieves superior performance over previous competing approaches. In the future, we would like to adapt L-HGAT for other information extraction tasks, such as named entity recognition and aspect extraction.    \def\year{2021}\relax  File: formatting-instructions-latex-2021.tex  release 2021.1 \documentclass[letterpaper]{article}   DO NOT CHANGE THIS \usepackage{aaai21}    DO NOT CHANGE THIS \usepackage{times}    DO NOT CHANGE THIS \usepackage{helvet}   DO NOT CHANGE THIS \usepackage{courier}    DO NOT CHANGE THIS \usepackage[hyphens]{url}    DO NOT CHANGE THIS \usepackage{graphicx}   DO NOT CHANGE THIS \urlstyle{rm}   DO NOT CHANGE THIS \def\UrlFont{\rm}    DO NOT CHANGE THIS \usepackage{natbib}    DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \usepackage{caption}   DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT \frenchspacing    DO NOT CHANGE THIS \setlength{\pdfpagewidth}{8.5in}    DO NOT CHANGE THIS \setlength{\pdfpageheight}{11in}    DO NOT CHANGE THIS  \usepackage{multirow} \usepackage{amssymb}  \usepackage{booktabs} \usepackage{bm} \usepackage{CJKutf8} \usepackage[switch]{lineno} \newcommand{\tabincell}[2]{} 閺鎯ф躬鐎佃壈鈻堥崠  \nocopyright  PDF Info Is REQUIRED.   For /Author, add all authors within the parentheses, separated by commas. No accents or commands.   For /Title, add Title in Mixed Case. No accents or commands. Retain the parentheses. \pdfinfo{ /Title  /Author  /TemplateVersion  }  Leave this   /Title    Put your actual complete title  within the parentheses in mixed case   Leave the space between \Title and the beginning parenthesis alone   /Author    Put your actual complete list of authors  within the parentheses in mixed case.   Each author should be only by a comma. If the name contains accents, remove them. If there are any LaTeX commands,   remove them.    DISALLOWED PACKAGES   \usepackage{authblk} -- This package is specifically forbidden   \usepackage{balance} -- This package is specifically forbidden   \usepackage{color    \usepackage{CJK} -- This package is specifically forbidden   \usepackage{float} -- This package is specifically forbidden   \usepackage{flushend} -- This package is specifically forbidden   \usepackage{fontenc} -- This package is specifically forbidden   \usepackage{fullpage} -- This package is specifically forbidden   \usepackage{geometry} -- This package is specifically forbidden   \usepackage{grffile} -- This package is specifically forbidden   \usepackage{hyperref} -- This package is specifically forbidden   \usepackage{navigator} -- This package is specifically forbidden      \indentfirst} -- This package is specifically forbidden   \layout} -- This package is specifically forbidden   \multicol} -- This package is specifically forbidden   \nameref} -- This package is specifically forbidden   \usepackage{savetrees} -- This package is specifically forbidden   \usepackage{setspace} -- This package is specifically forbidden   \usepackage{stfloats} -- This package is specifically forbidden   \usepackage{tabu} -- This package is specifically forbidden   \usepackage{titlesec} -- This package is specifically forbidden   \usepackage{tocbibind} -- This package is specifically forbidden   \usepackage{ulem} -- This package is specifically forbidden   \usepackage{wrapfig} -- This package is specifically forbidden   DISALLOWED COMMANDS   \nocopyright -- Your paper will not be published if you use this command   \addtolength -- This command may not be used   \balance -- This command may not be used   \baselinestretch -- Your paper will not be published if you use this command   \clearpage -- No page breaks of any kind may be used for the final version of your paper   \columnsep -- This command may not be used    -- No page breaks of any kind may be used for the final version of your paper   \pagebreak -- No page breaks of any kind may be used for the final version of your paperr   \pagestyle -- This command may not be used   \tiny -- This is not an acceptable font size.   {0}  May be changed to 1 or 2 if section numbers are desired.    The file aaai21.sty is the style file for AAAI Press   proceedings, working notes, and technical reports.      Title    Your title must be in mixed case, not sentence case.   That means all verbs ,   nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while   articles, conjunctions, and prepositions are lower case unless they   directly follow a colon or long dash  \title{Appendix}  \begin{document}  \maketitle  
"," The attention mechanism is a key component of the neural revolution in Natural Language Processing . As the size of attention-based models has been scaling with the available computational resources, a number of pruning techniques have been developed to detect and to exploit sparseness in such models in order to make them more efficient. The majority of such efforts have focused on looking for attention patterns and then hard-coding them to achieve sparseness, or pruning the weights of the attention mechanisms based on statistical information from the training data. In this paper, we marry these two lines of research by proposing Attention Pruning : a novel pruning framework that collects observations about the attention patterns in a fixed dataset and then induces a global sparseness mask for the model. Through attention pruning, we find that about 90\% of the attention computation can be reduced for language modelling and about 50\% for machine translation and %natural language inference \rev{prediction with BERT on GLUE tasks}, while maintaining the quality of  the results. Additionally, using our method, we discovered important distinctions between self- and cross-attention patterns, which could guide future NLP research in attention-based modelling. Our approach could help develop better models for existing or for new NLP applications, and generally for any model that relies on attention mechanisms. Our implementation and instructions to reproduce the experiments are available at \url{https://github.com/irugina/AP}.",395
" DEEP learning  is a modern machine learning technique based on artificial neural networks. The field of natural language processing  has significantly benefited from the use of deep learning techniques in recent years . There are three prevalent deep learning architectures concerned with  NLP tasks: long-short term memory   %networks , transformer networks  and convolutional neural networks  . LSTMs exhibit relatively slow inference speeds and are less performant than transformers and CNNs with regards to text classification accuracy . Transformers are a recent innovation and have shown significant successes in many NLP tasks . Their massive complexity with trainable parameters in the order of hundreds of millions presents critical experiment reproducibility challenges to researchers. State-of-the-art transformers are difficult to reproduce in lab conditions as they have a high training cost in monetary terms. There are only a limited number of pre-trained transformer models available for different languages. \par CNNs have demonstrated excellent success in text classification tasks . There are two paradigms available when using CNNs for text classification tasks, namely: world-level   and character-level CNNs . \par Word-level approaches are dependant on a word-model to represent the text. The reliance on a pre-trained word-model poses the potential problem of not having one available for a particular language. Training new word models is computationally time-consuming and costly. There is also the technical challenges of dealing with misspellings and words that may not exist in the word-model. The other paradigm is char-CNNs. No pre-trained language or word models are required. They also do not require a costly pre-processing step of the text data. In general, char-CNNs are not as accurate as word-level CNNs or transformers. Adding depth has not given the benefit of improved classification accuracy, as seen in image classification tasks. There is an open question in the research literature of what is the optimal architecture for char-CNNs. Little research has been performed to address these limitations. Deep learning is an iterative process requiring the tuning of many hyper-parameters and repeated experiments to test the efficacy of any potential architecture. It is a time consuming, costly and a tedious process that requires expert skills and domain knowledge. The task of finding optimal char-CNNs is an NP-hard problem. \par Evolutionary computation   is a collection of search algorithms inspired by the principals of biological evolution, in particular the concept of survival of the fittest. EC methods use a population of individuals  to conduct a simultaneous search during a limited time frame to improve the optimisation of a specified objective function via the exchange of information between individuals in the population. The exchange of information is one of the key motivating factors of selecting EC methods for evolving char-CNNs in this work. There is the potential that this information exchange may reveal the essential characteristics of what makes a non-performant char-CNN into a performant one. EC methods are concerned with locating near-optimal solutions to NP-hard problems. \par Evolutionary deep learning  is the technique of using EC methods to search for candidate CNN architectures combined with the backpropagation algorithm to train any potential candidate network architecture. EDL has demonstrated success when searching for performant CNN architectures on image classification tasks . EDL has not been used to search for performant char-CNN architectures. \par Motivated by the success of applying EDL techniques in the image classification domain, we propose a novel surrogate-based EDL algorithm appropriate for searching the landscape of char-CNN architectures for the text classification domain. The proposed algorithm is based on genetic programming  and an indirect encoding that is capable of representing novel char-CNN  architectures. The algorithm employs the use of surrogate models to significantly reduce the training time of the candidate char-CNNs during the evolutionary process.  In summary, the contributions of the proposed algorithm and work are:  %------------------------------------------------------------------------------    We motivated Attention Pruning as a novel method for pruning attention by leveraging on data-informed sparseness. By performing controlled experiments on a broad range of tasks , we demonstrated that we can prune most computations using pre-computed attention patterns while maintaining comparable performance, and sometimes even achieving improvements. We further applied our AP method on seq2seq tasks, which allowed us to study attention patterns between self- and cross-attention, and as a result we discovered important distinctions between these two types of attention.    we conducted a controlled study to find means of incorporating positional awareness in attention mechanisms. We observed that positional awareness induces beneficial sparseness in attention matrices, and thus we devised a simple training procedure that exploits that sparseness. As a result, we demonstrated faster and more accurate Transformers.   In future work, we plan to evaluate our method for other models, other NLP tasks, and on datasets of various sizes. We also plan to implement Attention Pruning efficiently for existing hardware. We conjecture that ``co-design'' approaches for efficient sparse kernels  and their successful utilization  would be helpful for making Attention Pruning scalable. Therefore, we release our code, which currently relies on masking matrix multiplications on a GPU, to the community to encourage co-design efforts for attention pruning.  Finally, we would like to explore the usefulness of using AP as a method for guiding modelling in NLP for a larger set of NLP tasks as well as for real-world applications.      
"," Character-level convolutional neural networks  require no knowledge of the semantic or syntactic structure of the language they classify. This property simplifies its implementation but reduces its classification accuracy. Increasing the depth of char-CNN architectures does not result in breakthrough accuracy improvements. Research has not established which char-CNN architectures are optimal for text classification tasks. Manually designing and training char-CNNs is an iterative and time-consuming process that requires expert domain knowledge. Evolutionary deep learning  techniques, including surrogate-based versions, have demonstrated success in automatically searching for performant CNN architectures for image analysis tasks. Researchers have not applied EDL techniques to search the architecture space of char-CNNs for text classification tasks. This article demonstrates the first work in evolving char-CNN architectures using a novel EDL algorithm based on genetic programming, an indirect encoding and surrogate models, to search for performant char-CNN architectures automatically. The algorithm is evaluated on eight text classification datasets and benchmarked against five manually designed CNN architectures and one long short-term memory  architecture. Experiment results indicate that the algorithm can evolve architectures that outperform the LSTM in terms of classification accuracy and five of the manually designed CNN architectures in terms of classification accuracy and parameter count.",396
" .     %     % % final paper: en-us version     %     %   % space normally used by the marker     % This work is licensed under a Creative Commons     % Attribution 4.0 International License.     % License details:     % \url{http://creativecommons.org/licenses/by/4.0/}. } Pre-trained language models have received great interest in the natural language processing  community in the last recent years . These models are trained in a semi-supervised fashion to learn a general language model, for example, by predicting the next word of a sentence . Then, transfer learning  can be used to leverage the learned knowledge for a down-stream task, such as text-classification .  \citet{devlin_bert:_2019} introduced the  ``Bidirectional Encoder Representations from Transformers'' , a pre-trained language model based on the Transformer architecture . BERT is a deeply bidirectional model that was pre-trained using a huge amount of text with a masked language model objective where the goal is to predict randomly masked words from their context . The fact is, BERT has achieved state of the art results on the ``General Language Understanding Evaluation''  benchmark  by only training a single, task-specific layer at the output and fine-tuning the base model for each task. Furthermore, BERT demonstrated its applicability to many other natural language tasks since then including but not limited to sentiment analysis , relation extraction  and word sense disambiguation , as well as its adaptability to languages other than English . However, the fine-tuning data set often contains thousands of labeled data points. This plethora of training data is often not available in real world scenarios .  In this paper, we focus on the low-resource setting with less than 1,000 training data points. Our research attempts to answer the question if pool-based active learning can be used to increase the performance of a text classifier based on a Transformer architecture such as BERT. That leads to the next question: How can layer freezing techniques , i.e. reducing the parameter space, impact model training convergence with fewer data points?  To answer these questions, we explore the use of recently introduced Bayesian approximations of model uncertainty  for data selection that potentially leads to faster convergence during fine-tuning by only introducing new data points that maximize the knowledge gain of the model. To the best of our knowledge, the work presented in this paper is the first demonstration of combining modern transfer learning using pre-trained Transformer-based language model such as the BERT model with active learning to improve performance in low-resource scenarios. Furthermore, we explore the effect of trainable parameters reduction on model performance and training stability by analyzing the layer-wise change of model parameters to reason about the selection of layers excluded from training. %Furthermore, we explore whether a more sophisticated decoder architecture, i.e. convolutional neural networks  can improve the overall performance or if the added complexity hinders a fast model adaption with such little training data.  The main findings of our work are summarized as follows: a) we found that the model's classification uncertainty on unseen data can be approximated by using Bayesian approximations and therefore, used to efficiently select data for manual labeling in an active learning setting; b) by analyzing layer-wise change of model parameters, we found that the active learning strategy specifically selects data points that train the first and thus more general natural language understanding layers of the BERT model rather than the later and thus more task-specific layers.    This work proposed an evolutionary deep learning approach to discover performant char-CNN architectures. This goal was achieved through the implementation of a genetic programming-based algorithm  coupled with a reduced cellular encoding scheme and the backpropogation algorithm. The SurDG-EC algorithm located, on average, higher accuracy models than those located by SurDG-Random. The fittest evolved phenotype defeated one of the state-of-the-art char-CNN models and achieved comparable results to the state-of-the-art VDCNN-29 architecture. The evolved model also generalised favourably across most unseen datasets. There is clear evidence that width may potentially add to the efficacy of char-CNNs.This does not mean that width will always result in increased accuracy, as also observed in the results. There are many other factors to consider. It is not known how much of the efficacy of the evolved phenotypes are due to increased width or some other unknown variable or combination of variables. There are, however, clear indications that the importance of width should be further researched. The SurDG-EC algorithm also revealed two interesting properties of char-CNNs. Building a rich tapestry of feature representations at the early stages of the network potentially aids in improving the accuracy of the networks as they grow deeper - in turn constructing a hierarchy of relations from this rich feature tapestry. The evolutionary crossover operation also revealed that combing the widths of two phenotypes produced a wider phenotype with greater validation accuracy. This is a further clue that there may be value in making char-CNNs with increased width.   ------------------------------------------------------------------------------ 
","     Recently, leveraging pre-trained Transformer based language models in down stream, task specific models has advanced state of the art results in natural language understanding tasks. However, only a little research has explored the suitability of this approach in low resource settings with less than 1,000 training data points. In this work, we explore fine-tuning methods of BERT - a pre-trained Transformer based language model - by utilizing pool-based active learning to speed up training while keeping the cost of labeling new data constant. Our experimental results on the GLUE data set show an advantage in model performance by maximizing the approximate knowledge gain of the model when querying from the pool of unlabeled data. Finally, we demonstrate and analyze the benefits of freezing layers of the language model during fine-tuning to reduce the number of trainable parameters, making it more suitable for low-resource settings.",397
"   % % The following footnote without marker is needed for the camera-ready % version of the paper. % Comment out the instructions  and uncomment the 8 lines % under ""final paper"" for your variant of English. %  .     %      % % final paper: en-us version      %       % space normally used by the marker     This work is licensed under a Creative Commons      Attribution 4.0 International License.     License details:     \url{http://creativecommons.org/licenses/by/4.0/}. }  Multilingual relation extraction is an important problem in NLP, facilitating a diverse set of downstream tasks from the autopopulation of knowledge graphs  to question answering . While early efforts in relation extraction used supervised methods that rely on a fixed set of predetermined relations, research has since shifted to the identification of arbitrary unseen relations in any language. In this paper, we present a method for extracting high quality relation training examples from date-marked news articles. This technique leverages the predictable distributional structure of such articles to build a corpus that is denoised . We use this corpus to learn general purpose relation representations and evaluate their quality on few-shot and standard relation extraction benchmarks in English and Spanish with little to no task-specific fine-tuning, achieving comparable results to a significantly more data-intensive approach that is the current state-of-the-art.  The current state-of-the-art model, ``Matching the Blanks"" or MTB, is a distant supervision technique that provides large gains on many relation extraction benchmarks and builds on Harris' distributional hypothesis and its extensions. ~ assume that the informational redundancy of very large text corpora  results in sentences that contain the same pair of entities generally expressing the same relation. Thus, an encoder trained to collocate such sentences can be used to identify the relation between entities in any sentence  by finding the labeled relation example whose embedding is closest to . While~ achieve state-of-the-art on FewRel and SemEval 2010 Task 8, their approach relies on a huge amount of data, making it difficult to retrain in English or any other language with standard computational resources: they fine-tune BERT large, which has mil parameters, on mil+ relation pair statements with a batch size of  for mil steps. In contrast our method, with only  relations statements and a language-model one-third the size, achieves comparable performance when fine-tuned on little to no task-specific data.   Our main contribution is a distant supervision approach in which we assume that sections of news corpora exhibit even more informational redundancy than Wikipedia. Specifically, news in the days following an event  frequently re-summarizes the event before adding new details. As a result, news exhibits a strong form of local consistency over short rolling time windows where otherwise fluid relations between entities remain fixed. For example, the relation between Italy and France as expressed in a random piece of text is dynamic and context-dependent, spanning a wide range of possibilities that include ``enemies"", ``neighbors"" and ``allies"".  But, in the news coverage following the 2006 World Cup, it is static -- they are sporting competitors. Therefore, by considering only sentences around specific events, we extract groups of statements that express the same relation and are relatively free of noise .    Training multilingual BERT  on our denoised corpus yields relation representations that adapt well to resource-constrained downstream tasks: we evaluate their quality on FewRel and SemEval 2010 Task 8, producing near state-of-the-art results when finetuned on little to no task-specific data. In addition to the strong performance of our approach in English, it is easily generalizable to other languages, requiring only news corpora and event descriptions from Wikipedia to build a high-quality training corpus. We evaluate this in Spanish and find our method outperforms mBERT on the TAC KBP 2016 relation corpus. We share our code to allow other researchers to apply our approach to news corpora of their own.      In this paper, we evaluated the performance of a pre-trained Transformer model - BERT - in an active learning scenario for text classification in low-resource settings. We showed that using Monte-Carlo Dropout in the classification architecture is an effective way to approximate model uncertainty on unlabeled training elements. This technique enables us to select data for annotation that maximize the knowledge gain for the model fine-tuning process. Experimental results on GLUE data set show that it improves both model performance and training stability. Finally, in order to improve the efficiency of the fine-tuning process with a small amount of data, we explored the reduction of trainable model parameters by freezing layers of the BERT model up to a certain level of depth. Comparing the exclusion of layers in the front or the back of the BERT model from training, we found it to be advantageous for training stability when freezing the layers closest to the output.   We attribute this effect to the reduction of free parameters that only change very little in the short training period of the low-resource setting.  The further exploration of this aspect is subject to future work by combining the observations of layer-wise MAD with previous advances in language model fine-tuning and more sophisticated training strategies like gradual unfreezing or discriminative fine-tuning .  \ifcolingfinal 
"," General purpose relation extraction has recently seen considerable gains in part due to a massively data-intensive distant supervision technique from that produces state-of-the-art results across many benchmarks. In this work, we present a methodology for collecting high quality training data for relation extraction from unlabeled text that achieves a near-recreation of their zero-shot and few-shot results at a fraction of the training cost. Our approach exploits the predictable distributional structure of date-marked news articles to build a denoised corpus -- the extraction process filters out low quality examples. We show that a smaller multilingual encoder trained on this corpus performs comparably to the current state-of-the-art  on few-shot and standard relation benchmarks in English and Spanish despite using many fewer examples .",398
" Domain shift is common in language applications. One is more likely to find ""internet"" or ""PC"" in reviews on electronics than those on books, while he or she is more likely to find ""writing"" or ""B.C."" in reviews on books than those on electronics. This proposes a fundamental challenge to NLP in that many computational models fail to maintain comparable level of performance across domains. Formally, a distribution shift happens when a model is trained on data from one distribution , but the goal is to make good predictions on some other distribution  that shares the label space with the source.   We study unsupervised domain adaptation in this work, where we have fully-labeled data on source domain but no labeled data on target domain. The most prevailing methods in this field aim to learn domain-invariant feature by aligning the source and target domains in the feature space. The pioneering works in this field try to bridge domain gap with discrepancy-based approach.  first introduce MMD to measure domain discrepancy in feature space and use its variant MK-MMD as an objective to minimize domain shift. Another line of work introduces a domain classifier and adversarial training to induce domain invariant feature, followed by works using generative models to enhance adversarial training. However, note that both MMD-based approach and adversarial training formulates with a minimax optimization procedure that is widely known as hard to converge to a satisfactory local optimum. Moreover, some recent works have discovered that both of them don't guarantee good adaptation and will introduce inevitable error on target domain under label distribution shift because they may render incorrect distribution matching. For example, thinking of a binary classification task, the source domain has 50\% of positive samples and 50\% of negative samples while the target domain has 30\% postive and 70\% negative. Successfully aligning these distributions in representation space requires the classifier to predict the same fraction of positive and negative on source and target. If one achieves 100\% accuracy on the source, then target accuracy will be at most 80\%, that is 20\% error at best.   % Self-supervised learning is prominent in feature representation learning. Recent works have approached unsupervised domain adaptation for computer vision with SSL[][]. [] adopted rotation prediction, flip prediction and patch location prediction to induce domain-invarint feature and find that some auxiliary tasks involving fine-grained semantics like pixel reconstruction may force the model to focus on domain-specific feature, further widening the domain gap.   Self-supervised representation learning could be a good workaround for this problem because it enforces predictive behaviour matching instead of distribution matching. The main idea is to learn discriminative representation that is able to genenralize across domains.  use sentiment-indicating pivot prediction as their auxiliary task for cross-domain sentiment analysis. The method proposed in this paper adopts contrastive learning to extract generalizable discriminative feature. Contrastive learning is a subclass of self-supervised learning that is gaining popularity thanks to recent progress. It utilizes positive and negative samples to form contrast against the queried sample on pretext tasks in order to learn meaningful representations. However, the pretext tasks must be carefully chosen. shows with experiments on computer vision tasks that the transfer performance will suffer under improper pretext tasks like pixel reconstruction.  % Recent developments in contrastive learning obtained promising results both on representation learning benchmarks for CV[][][] and for NLP[][][]. % Like with self-supervised learning[], joint learning of pretext tasks in contrastive learning is able to align domain in the feature space, as illustrated in figure.  There are a group of works adopting it for domain adaptation for CV[][][]. However, these method cannot be easily adopted to NLP due to the inherent signal difference between the to domains. .   Therefore, in this paper we explore two classic data augmentation methods in natural language processing閳ユ敃ynonym substitution and back translation to define our pretext task. Experiments on two cross-domain sentiment classification benchmarks show the efficacy of the proposed method. We also examine whether in-domain contrastive learning and entropy minimization helps cross-domain sentiment classification under varied label distribution settings. Our main contributions in this work  are summarized as follows:       We present an event-guided denoising approach for relation extraction corpus creation that, when used with the current state-of-the-art training procedure, achieves comparable results in English under a low-resource regime for only a fraction of the training cost. It also performs well in Spanish, demonstrating its adaptability to resource-constrained relation extraction tasks in non-English languages.   Our technique affords the broader research community the ability to approximate the current state-of-the-art in relation extraction by significantly lowering its associated training costs.  However, it requires a fairly large date-marked news corpus which may not be available in low resource languages. We leave an exploration of broader language coverage and minimal required corpus size for future work.   One promising direction for expanding language coverage is cross-lingual learning via ``codeswitched"" examples and other language modeling losses .  We hypothesize that such methods could help knowledge transfer among languages and improve results on downstream tasks.  Finally, we note that since our approach extracts relation statements from news corpora, it is likely that the resulting distribution of underlying relation types is different than the distribution found in Wikipedia. For example, Wikipedia may contain more expressions of standard ontological relations  characteristic of factoids. Despite this hypothesized difference, our approach performs well on both FewRel and SemEval 2010 Task 8, both of which include a subset of such relation types.  In the future we intend to investigate these differences and their implications more closely.    Acknowledgments: AIDA, partially supported by 
","   Contrastive learning  has been successful as a powerful representation learning method. In this paper, we propose a contrastive learning framework for cross-domain sentiment classification. We aim to induce domain invariant optimal classifiers rather than distribution matching. To this end, we introduce in-domain contrastive learning and entropy minimization. Also, we find through ablation studies that these two techniques behaviour differently in case of large label distribution shift and conclude that the best practice is to choose one of them adaptively according to label distribution shift. The new state-of-the-art results our model achieves on standard benchmarks show the efficacy of the proposed method.",399
"   %Recently, Neural machine translation~ has achieved great success and reached satisfactory translation performances for several language pairs~. %These NMT models are sequence-to-sequence models trained on large parallel data.  % Ensemble learning, which aggregates multiple diverse models during inference, has attracted huge interest in both academia and industry communities thanks to its effectiveness in a variety of computational intelligence problems such as classification, prediction and function approximation. So far, many aggregating approaches have been developed such as bagging and boosting to improve the practical performance.  % % Ensemble learning is primarily used to improve the classification task or reduce the likelihood of a poorly learned model.  % Recently, ensemble of different neural networks  has greatly improved the accuracy of neural machine translation , making it a vital widely used technique in state-of-the-art Neural NMT systems. In the scenario of NMT, a common implementation is to average the probability of each token computed by different individual models and then decode with the averaged probabilities. Previous studies show that the performance of ensemble method heavily depends on both the accuracy and diversity of base models, which are typically obtained through independent training on different sets of attributes.  % % Ensemble learning, which aggregates multiple models during inference, is an   % Despite its success in various tasks and applications, in practice there are a few common challenges of ensemble methods, which prevent its wide usage: 1) High computational cost. For ensemble learning, all individual models have to conduct encoding and decoding, which is prohibitively time and memory consuming. It gets even worse in the context of NMT due to the large size of state-of-the-art networks like transformer. 2) Absence of monolingual data. Ensemble exploit the independence cannot make full use of the large scale monolingual data from source side.  Recently, self-training method has shown remarkable success in image recognition.  % Taking advantage of unlabeled data, Trained on noisy augmented data, an EfficientNet model finetuned with self-training can achieve 87.4\% top-1 accuracy on ImageNet, which is 1.0\% better than the state-of-the-art model that requires 3.5B weakly labeled images. Typically, in self-training we first train a base model on the labeled data, and then utilize the learned model to label unannotated data. Finally, both labeled and pseudo data are combined as the training set to yield the next level model. In the context of natural language processing, many works have successfully applied self-training technique including word sense disambiguation and parsing. %  Nevertheless, the performance gains achieved through self-training are still limited for structured prediction tasks such as Neural Machine Translation~ where the target space is vast. Originally designed for classification problems, previous work suggests that self-training can be effective only when the predictions on unlabeled samples are good enough, and otherwise it will suffer from the notorious reinforced mistakes. However, this problem is common in NMT scenario, where the hypotheses generated from a single model are often far away from the ground-truth target due to the compositionality of the target space. \citet{zhang2016exploiting} found that training on this biased pseudo data may accumulate the mistakes at each time step and enlarge the error, and thus they propose to freeze the decoder parameters when training on the pseudo parallel data which may negatively impact the decoder model of NMT.  % We argue that the performance drop of self-training for NMT mainly comes from the reinforced mistakes.  To overcome this issue, in this paper we borrow the reciprocal teaching concept from the educational field and revisit the core idea of classic ensemble approaches. Ensemble is built upon the assumption that different models have different inductive biases and better predictions can be made by majority voting. We propose to replace the self-supervision with Reciprocal-Supervision in NMT, leading to a novel co-EM  scheme named \method. In \method, we use multiple separately learned models to provide diverse proper pseudo data, allowing us to enjoy the independence between different models and dramatically reduce the error through strategic aggregation. %Most of these NMT works use only one type of neural network model such as ConvS2S~ and Transformer~. %Usually, different neural models have different performances and they may also catch minor different patterns in the sequences. More specifically, we first learn multiple different models on the parallel data. Then in the E-step all individual models are used to translate the monolingual data. And in the M-step the generated pseudo data produced by different models are combined to tune all student models. %To combine these advantages and diversities, the intuitive method is ensemble, in which several models are trained and every model will be used during inference, then the output of these models are combined for a better prediction.  \method is inspired by the success of ensemble method. However, ensemble is resource-demanding during inference, which prevents its wide usage. Besides, it cannot make use of the large scale monolingual data from source side. %The teacher-student framework can be used to make one model learn from others. Some works have been done to explore the assistance from right-to-left decoding model to usual left-to-right model~. These works shown that a regular NMT model can learn from a right-to-left decoding model and obtain better performance. However, to our best knowledge, there are no such work exploring the assistance from several different models. So in this work, we try to utilize multiple different models as teachers, and train a student model to learn from them. Through this procedure, the student model can have better performance. %Following this procedure, we have another advantage that monolingual data of source side language can be easily utilized to extend the training method to our self-training framework with diverse teachers. %Similar to teacher-student framework for zero-shot NMT~, the student model can also learn from teachers by monolingual data. \method is also related to the data augmentation approaches for NMT.  While most of previous works concentrate on monolingual data of target side such as back-translation~, we pay more attention to the source side. Knowledge distillation  is another relevant research topic. However, KD is preliminary designed to improve a weak student model with a much stronger teacher model. By contrast, \method boosts the performance of base models through reciprocal-supervision from other just comparable or even weaker learners. % Unsupervised machine translation~ can also be seen as utilizing target side monolingual data. To the best of our knowledge, we are the first self-training framework with reciprocal-supervision, which can correct the bias of each model and fully utilize the monolingual data of source side language. More precisely, the advantages of \method % our cooperative-supervised framework with diverse parameterized networks  can be summarized as follows:  Through extensive experiments, \method achieves significant gains on several standard translation tasks including En\{Ro, De\}. Surprisingly, we also have found that \method with other much weaker learners could even outperform a strong BERT enhanced NMT model with big margins.    We have proposed a powerful and easy to deploy approach to augment text data through conditional generation. By leveraging an off-the-shelf language model , we successfully guide the generation towards a specified direction , with the help of reinforcement learning. We find that Data Boost improves the performance of classification tasks, is classifier-agnostic, and that it surpasses several prior augmentation methods in three diverse classification tasks.   In the future, we plan to implement a more sophisticated guidance for the augmentation by adding syntactic and position features to the reward function, to enable augmentation of more diverse types of text data. The code will be made available upon request.   
","  % Neural machine translation~ has achieved great success with the help of large amount of parallel data. % However, different model architectures have different advantages and translation abilities, but it is hard to integrate them all together to one model. % The ensemble method is too time-consuming for inference. % Besides, monolingual data are also not fully utilized. % Some works such as back-translation and unsupervised machine translation have tried to utilize monolingual data of target side, whereas the utilization of source side monolingual data still need be further explored. % In this work, we propose a self-training framework with diverse teachers to make one model be able to learn advantages and diversities from other models, and monolingual data of source side language can also be utilized to further improve the translation performances. % This method is very simple but much effective. % Empirical results show that our method can obtain further improvements on the standard En$\to$De and En$\to$Fr translation tasks.  Despite the recent success on image classification, self-training has only achieved limited gains on structured prediction tasks such as neural machine translation . This is mainly due to the compositionality of the target space, where the far-away prediction hypotheses lead to the notorious reinforced mistake problem. In this paper, we revisit the utilization of multiple diverse models and present a simple yet effective approach named Reciprocal-Supervised Learning . \method first exploits individual models to generate pseudo parallel data, and then cooperatively trains each model on the combined synthetic corpus. \method leverages the fact that different parameterized models have different inductive biases, and better predictions can be made by jointly exploiting the agreement among each other. Unlike the previous knowledge distillation methods built upon a much stronger teacher, \method is capable of boosting the accuracy of one model by introducing other comparable or even weaker models. \method can also be viewed as a more efficient alternative to ensemble. Extensive experiments demonstrate the superior performance of \method on several benchmarks with significant margins.\footnote{Code is available at \url{https://github.com/MinkaiXu/RSL-NMT}.} % \method takes advantage of different parameterized networks to generate diverse proper pseudo parallel data, and then dramatically reduce the bias through strategic combination of the pseudo data. %More specifically, we first train several NMT teachers with heterogeneous networks, then use the heterogeneous teacher models to label unlabeled data respectively and finally use the labeled data and unlabeled data to jointly train a student NMT model. % \method is very simple but much effective. % Empirical results demonstrate the effectiveness of \method on several benchmarks, where we even outperforms a strong BERT-enhanced baseline.   % Ensemble learning, which strategically aggregates multiple models for inference, has been shown effective to improve the accuracy of Neural Machine Translation . However, in practice it cannot be widely adopted due to the high computation and memory cost for involving all individual models.  % % Recently, transductive method has been proposed to overcome this obstacle, which, however, suffers the premise that the test data has to be available in advance.  % In this paper, we present a simple yet effective approach named Cooperative Training NMT , where we firstly use individual models to translate the source corpus into pseudo parallel data, and then cooperatively train all models on the translated synthetic corpus. \method leverages the fact that different parameterized models have different inductive biases, and better predictions can be made by jointly exploiting the independence between each other. Furthermore, given source monolingual data, \method enables us to avoid the reinforced mistakes problem of self-training and make the most of the monolingual set. Extensive experiments demonstrate our proposed approach can always achieve superior or comparable performance on several benchmarks with less computational cost.",400
"    One of the first steps in language acquisition is to learn word--meaning mappings, e.g., the word ``dog'' in the sentence ``see the dog'' refers to the tail-wagging animal under the kitchen table. This seemingly simple problem of word learning is a complex puzzle; in the initial phases of language development, children do not have any knowledge about word meanings  and face a great deal of uncertainty.  % Without prior information, for a given word  , there is a high level of referential uncertainty -- there are a great number of potential meanings in a child's environment  that the word could refer to. % Similarly, there is high level of linguistic uncertainty in mapping a referent  to words in the utterances .  % Moreover, an additional difficulty arises because not all the mappings between words and referents are one-to-one; sometimes words are mapped to more than one referent  or referents are mapped to more than one word .   Strong empirical evidence suggests that statistical cross-situational learning helps both children and adults navigate these challenges, by gradually keeping track of statistical regularities across different situations , and using them to help resolve these ambiguous mappings \citep[\eg,][]{yu.smith.2007,smith.yu.2008}.  However, cross-situational learning does not provide a detailed account of what mechanisms are responsible for resolving each type of uncertainty at different stages of word learning.  Moreover, a large body of developmental research has studied inductive biases that might facilitate word learning in the presence of different types of uncertainty \citep[\eg,][]{markman.1987}. A common theme among these biases is that competition can remove a number of possible hypotheses for a word meaning . For example, the mutual exclusivity bias asserts that each referent is only mapped to one word .  % This competition among referents means that given a new word and a number of possible referents, a learner reduces the uncertainty by not considering referents that are already associated to other words.   It is also suggested that such competitive processes play a role both locally and globally: there is competition when associating words and meanings from one observation  as well as among all observed words and referents \citep[\eg,][]{yurovsky2013competitive}.\footnote{Work in computational modeling of cross-situational learning typically does not distinguish between the referent indicated by a word and its meaning.  We will use the terms referent and meaning interchangeably throughout this paper, while recognizing that there are important notions about the relations between those two that are being abstracted away by such an approach.}   Previous computational modeling work has shed light on the mechanisms and biases that might be involved in cross-situational learning \citep[\eg,][]{frank.etal.2007, fazly.etal.2010.cogsci,trueswell.etal.2013,nematzadeh.etal.2017.cogsci.bias}. % However, to our knowledge, no previous work has done an exhaustive analysis of the role of competition in the in-the-moment learning mechanisms and how these mechanisms interact with different representations of word meanings,  which may also be influenced by competition. % In this work, our contributions are threefold:   We provide a general probabilistic formulation of cross-situational word-learning and show that the influential model of \citet{fazly.etal.2010.csj} is an instance of this formulation.   Using this formulation, we show how  % inductive biases can be modeled as competitive processes during in-the-moment and overall word learning, as well as comprehension of a word meaning.   Moreover, we examine how each modeling choice  affects learning in the presence of different sources of uncertainty, such as increased referential and linguistic uncertainty, fewer exposures to words, or acquiring homonyms and synonyms.    We find that the best model across all the tasks is the one that implements two types of competition, both among words and referents. Moreover, this competition happens during in-the-moment learning  and comprehension . This result is different than previous modeling assumptions where a competition among referents was introduced during the overall learning of word meaning representations . It also suggests that the observed behavior in people \citep[\eg,][]{yurovsky2013competitive} might be explained by the competition during comprehension and not a global competitive process during learning. We also observe that the best model performs better than the model of \citet{fazly.etal.2010.csj} in the presence of linguistic and referential uncertainty, and can learn homonyms as opposed to their model.      In this paper, we propose reciprocal supervised learning, an efficient and effective co-EM framework for neural machine translation. Different from previous methods, in \method a strong NMT model can benefit from any comparable or even weaker models, and the source monolingual corpus can also be fully utilized seamlessly. Extensive experiments demonstrate the effectiveness and robustness of \method and provide insights on why and how \method can work well.  \method is a general framework and can be extended for more NLP tasks, e.g., Q\&A, text summarization. One potential direction for future work is to design better objective functions and set learnable weights for pseudo data from different models. Second, how to make \method more efficient is another interesting topic.   By \method, the performances of neural network models are greatly improved and the experiments show the considerable results on standard EnDe and EnFr translation tasks.   Our \method is rather simple but effective.   This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended. \pdfoutput=1   In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.  \documentclass[11pt]{article}    Remove the ""review"" option to generate the final version.   \usepackage[review]{naacl2021} \usepackage{naacl2021}    Standard package includes \usepackage{times} \usepackage{latexsym}    For proper rendering and hyphenation of words containing Latin characters  \usepackage[T1]{fontenc}   For Vietnamese characters   \usepackage[T5]{fontenc}   See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets    This assumes your files are encoded as UTF8 \usepackage[utf8]{inputenc}    This is not strictly necessary, and may be commented out,   but it will improve the layout of the manuscript,   and will typically save some space. \usepackage{microtype}    If the title and author information does not fit in the area allocated, uncomment the following    \setlength\titlebox{<dim>}     and set <dim> to something 5cm or larger.  \newcommand{\method}{\xspace} \usepackage{microtype} \usepackage{graphicx} \usepackage{amsfonts,amssymb,amsmath} \usepackage{mathtools} \usepackage{tabu} \usepackage{multirow} \usepackage{algorithm} \usepackage{algorithmic} \usepackage{xspace} \usepackage{booktabs}   To thicken table lines  \title{Reciprocal Supervised Learning Improves Neural Machine Translation}    Author information can be set in various styles:   For several authors from the same institution:   \author{Author 1 \and ... \and Author n \\           Address line \\ ... \\ Address line}   if the names do not fit well on one line use           Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\   For authors from different institutions:   \author{Author 1 \\ Address line \\  ... \\ Address line           \And  ... \And           Author n \\ Address line \\ ... \\ Address line}   To start a seperate ``row'' of authors use \AND, as in   \author{Author 1 \\ Address line \\  ... \\ Address line           \AND           Author 2 \\ Address line \\ ... \\ Address line \And           Author 3 \\ Address line \\ ... \\ Address line}  \author{Minkai Xu\textsuperscript{*\rm 1,2}, Mingxuan Wang\textsuperscript{\rm 3}, Zhouhan Lin\textsuperscript{\rm 4}, Hao Zhou\textsuperscript{\rm 3}, Weinan Zhang\textsuperscript{\rm 4}, Lei Li\textsuperscript{\rm 3} \\   \textsuperscript{\rm 1}University of Montreal \textsuperscript{\rm 2}Mila - Quebec AI Institute \textsuperscript{\rm 3}ByteDance AI Lab \textsuperscript{\rm 4}Shanghai Jiao Tong University\\   \texttt{minkai.xu@umontreal.ca}\\   \texttt{\{wangmingxuan.89,zhouhao.nlp,lileilab\}@bytedance.com}\\   \texttt{lin.zhouhan@gmail.com}\\   \texttt{wnzhang@sjtu.edu.cn}}  \begin{document} \maketitle \renewcommand{\thefootnote}{\fnsymbol{footnote}}                     
"," Children learn word meanings by tapping into the commonalities across different situations in which words are used and overcome the high level of uncertainty involved in early word learning experiences. In a set of computational studies, we show that to successfully learn word meanings in the face of uncertainty, a learner needs to use two types of competition: words competing for association to a referent when learning from an observation and referents competing for a word when the word is used.",401
"  Hypernym, sometimes also known as hyperonym, is the term in linguistics referring to a word or a phrase whose semantic field covers that of its hyponym. The most common relationship between a hypernym and a hyponym is an ``is-a'' relationship. For example, ``red is a color'' provides the relationship between ``red'' and ``color'', where ``color'' is the hypernym of ``red''.   The hypernym-hyponym relation is an essential element in the semantic network and corresponding tasks related to semantic network analysis . The hypernym graph built on a collection of hyponym-hypernym relations can enhance the accuracy of taxonomy induction . The linkage between the hyponym and the hypernym can be used to improve the performance of link prediction and network completion in the knowledge graph or semantic network . In natural language processing , the hyponym-hypernym relation can help the named entity recognition , and the question-answering tasks for ``what is'' or ``is a'' . The data mining, information search and retrieval can also benefit from the hyponym-hypernym relation .   Given the role and application of the hypernym-hyponym relation, it is essential to explore an automatic method to extract such the relation between two entities, which presents an important task in knowledge-driven NLP . Following the landmark work focusing on lexico-syntactic patterns , several pattern-based methods are developed for hypernym extraction . Then the feature-based classification methods are introduced , which applies machine learning tools to enhance the recall rate. Recently, distributional methods and hybrid distributional models are successfully applied to learn the embedding of words, based on which the hypernym-hyponym relation can be inferred . The deep learning approach is also effective in many sequence labeling tasks including hypernym extraction .    While the extraction of hyponym-hypernym relation can be done in many different environments, in this work we focus on the hypernym extraction from definitions. More specifically, the definition refers to a short statement or description of a word. Take the word ``red'' as an example, whose definition on Wikipedia  is ``Red is the color at the end of the visible spectrum of light, next to orange and opposite violet.'' The aim is to identify the word ``color'' as the hypernym of ``red'' from all the nouns in the definition. Intuitively, this task can be solved by general resources such as WordNet dictionary  or Wikipedia. But given a word's different meanings in different contexts, these resources can not sufficiently complete this task. As an example, the term ``LDA'' in Wikipedia denotes ``Linear Discriminant Analysis'' in machine learning, ``Low dose allergens'' in medicine, and ``Landing distance available'' in aviation. The combination of general resources and context identification would also fail in some domain-specific applications where the general resources do not cover the special or technical terms in that area. Moreover, existing technical approaches also demonstrate certain limitations in the task of hypernym extraction from definitions, which we summarize as follows:   To briefly illustrate the difficulty, let us consider a definition from the Stack-Overflow with an irregular format: ``fetch-api: the fetch API is an improved replacement for XHR''. The term ``fetch-api'' is not included in any common dictionary. While the definition has the ``is an'' pattern, it does not connect to the hypernym. The definition is very short and every distinct word in this definition appears just once, which makes it difficult to accurately learn the word representation. Overall, it is challenging to find a method that would accurately identify ``API'' as the correct hypernym.   The definition of a word represents a certain type of knowledge extracted and collected from disordered data. Indeed, there are tools capable of extracting definitions from the corpora with good accuracy . Nevertheless, tools to extract hypernym from definitions remain limited.  % To cope with this issue, we propose a recurrent network method using syntactic features. Because the definition directly points to a noun, the hyponym is already given. Therefore, the hypernym extraction is to identify the correct hypernym from all words in the definition sentence. This task can be considered as a binary classification, in which the classifier judges if a candidate noun is a hypernym or not. In order to better learn the syntactic feature, we transfer the definition sentence into the part of speech  sequence after labeling the PoS of each word by a standard tool . The syntactic structure surrounding the candidate is learned by a bidirectional gated recurrent units  based model. To further fine tune the results, we use a set of features including the centrality of the word in the hypernym co-occurrence network. We use two corpora to evaluate our method. One is Wikipedia, featuring definitions with canonical syntax structure and intensively used by previous studies. The other is from Stack-Overflow, whose definition is domain-specific and usually with the irregular format. Our method is compared with several existing ones. Overall, it outperforms all others in both corpora, which demonstrates the advantage of combing both the tool of RNN and the PoS information in the task of hypernym extraction.    This paper is organized as follows. We review related works in Section  and introduce details of the method in Section . Experiments and evaluations of the proposed model are presented in Section . After that, we draw a conclusion about this research in Section .     The computational level of analysis  allows us to contemplate what problem a cognitive phenomenon solves. For example, learning word meanings via cross-situational statistics can be formulated as finding mappings between words and referents that are most consistent with our observations. On the other hand, modeling cognition at the algorithmic level  plays an important role in providing insight about cognitive mechanisms; it requires specifying the details of algorithms and representations which in turn enables us to study their role and interaction at different stages of learning.     Previous research has studied word learning at both algorithmic and computational levels \citep[\eg,][]{siskind.1996,yu.ballard.2007,frank.etal.2007,fazly.etal.2010.csj}. We proposed a framework for modeling cross-situational word learning at the computational level that unifies some of previous work in this domain -- approaches that formulate word learning as a translation problem.   We also show that instantiating this framework results in different word learning models at the algorithmic level: each model has specific inductive biases that define how words and referents compete for association strength given a word/referent.  More specifically, we examine how competition among words or referents plays a role in:  learning from a given observation or in-the-moment learning,  overall learning of word meanings, and  comprehension of a given word. Moreover, we investigate how these assumptions change the performance of a model in the face of uncertainty.   Our results show that models that implement the two complementary types of referent and word competition perform the best. Each competition type addresses a specific type of uncertainty -- word and referent competitions address linguistic and referential certainty, respectively; because the word learning input has both uncertainties, it is important for a model to implement the two competitions.   These models are the most robust and learn successfully from few examples.   Moreover, we find that the best model implements competition during in-the-moment learning and comprehension, but not a global competition over word meaning representations.  By avoiding an overall word meaning competition, the model is able to successfully learn multiple meanings of ambiguous words, given sufficient evidence.    \section{The Derivation of the FAS model}  The FAS model assumes that referents are generated independently given an utterance ; instead of calculating  as in \Equation{eq:cll}, the likelihood is defined over the conditional probability of referents given an utterance:      Here, the alignment variable defines the mappings between words to a given referent. More specifically, the value of the alignment variable  selects the word in the utterance   that is mapped to a given referent .    where  returns the association of  to the referent  given the learned distribution . Note that this corresponds to the Expectation step of the EM algorithm, and \Equation{eq:emfasalign} is an instantiation of \Equation{eq:emalign}.  \break \break In the Maximization step, the new value of  is calculated by finding  that maximizes the model likelihood:  where  and  are a set of all scenes and utterances, respectively:      where   is the word mapped to , and  is the number of times  and  have co-occurred in the corpus .  The FAS model assumes that  is a conditional probability, . This means that there is an additional dependence assumption on the learned representations: each word is a distribution over features, and thus given a word, the features compete to be associated with that word.   To impose this new assumption on the representation, a constraint is added to the expectation defined in \Equation{eq:mstepfas}:    Note that the Lagrange multipliers  ensures that the new constraint on  -- a distribution over referents for each word -- is satisfied.   To find  that maximizes the expectation in \Equation{eq:mstepfas}, the derivative of objective function  is calculated and equated to zero:       Given , we calculate :      Using the above  and \Equation{eq:emfasalign} to calculate the alignment probabilities, we have:    We can approximate  by adding the current alignment probability, , to the sum of all the previously calculated ones . This approach is an approximation of  because the value of the alignment probability changes after processing each - pair, but it can be calculated incrementally; FAS defined an association score,  which is updated as the model process - pairs,   where  and the initial value of   is zero.     Intuitively, this score shows the overall association strength of a word and a referent and it captures how strongly the word-referent pair are associated in each observation, -. \documentclass[12pt]{article} \usepackage[group-separator={,}]{siunitx} \usepackage[natbibapa]{apacite}  \usepackage[american]{babel} \usepackage{newtxtext} \usepackage{newtxmath} \usepackage[utf8]{inputenc} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{capt-of} \usepackage{csquotes} \usepackage{appendix} \usepackage{graphicx} \usepackage{caption} \usepackage{subcaption} \usepackage[usenames, dvipsnames]{xcolor} \usepackage[flushleft]{threeparttable} \usepackage{array} \usepackage{tabularx} \usepackage{enumitem} \usepackage{kantlipsum} \usepackage{multirow} \usepackage{bm} \usepackage{amsmath} \usepackage{setspace} \usepackage{siunitx} \usepackage{etoolbox} \usepackage{makecell} \usepackage[normalem]{ulem} \usepackage{numprint} \npthousandsep{,}    FOR COGSCI SUBMISSION \renewcommand{\baselinestretch}{1.5} \usepackage[margin=1in]{geometry} \renewcommand{\figurename}{Fig.} \documentclass[alpha-refs]{wiley-article}   \documentclass[blind,num-refs]{wiley-article}    Add additional packages here if required \usepackage{siunitx}    Update article type if known \papertype{Original Article}   Include section in journal if known, otherwise delete \paperfield{Journal Section}    \usepackage[round,authoryear]{natbib} \usepackage{hyperref} \renewcommand{\ref}[1]{\hyperref{#1}} \usepackage{setspace} \doublespacing  \usepackage{url} \usepackage{graphicx} \usepackage{csquotes}  \usepackage{pslatex} \usepackage{latexsym} \usepackage{caption} \usepackage{subcaption} \usepackage{xcolor}  \usepackage{amsmath}    Latin phrase short forms \newcommand\etal{et~al.\ } \newcommand\ie{i.e.} \newcommand\eg{e.g.} \newcommand\cf{cf.\ }    Command to not display content \newcommand{\ignore}[1]{}    Content-specific labels \newcommand{\Table}[1]{Table} \newcommand{\Algorithm}[1]{Algorithm} \newcommand{\Example}[1]{Ex.} \newcommand{\Figure}[1]{Figure} \newcommand{\Equation}[1]{Eqn.~} \newcommand{\Section}[1]{Section} \newcommand{\Appendix}[1]{Appendix}    Author note commands \newcommand\scream[1]{{#1}} \newcommand\oldtext[1]{{#1}} \newcommand\an[1]{{#1}} \newcommand\sxs[1]{{SS: #1}} \newcommand\zs[1]{{ZS: #1}} \newcommand\tlg[1]{{TLG: #1}} \newcommand{\replace}[2]{{OLD:} \st{#1} {NEW: #2}} \newcommand\todo[1]{{#1}}  \newcommand\fas{FAS} \newcommand\simf{\mathrm{sim}}  \newcommand{\rep}[3]{\mathrm{\theta}^{#1}_{#2#3}}  \DeclareMathOperator*{\argmax}{arg\,max}  HERE \graphicspath{{plots/zero_unseen_prob/}} \graphicspath{{plots/}}  \author[1\authfn{1}]{Aida Nematzadeh} \author[2\authfn{2}]{Zahra Shekarchi} \author[3\authfn{3}]{Thomas L. Griffiths} \author[4\authfn{4}]{Suzanne Stevenson}  \contrib[1\authfn{1}, 2\authfn{2}]{Equally contributing authors.}  Work was done prior to joining DeepMind.}     Include full affiliation details for all authors \affil[1]{DeepMind} \affil[2]{University of Toronto} \affil[3]{Princeton University} \affil[4]{University of Toronto}   \corraddress{Author One PhD, Department, Institution, City, State or Province, Postal Code, Country} \corremail{nematzadeh@google.com}    Include the name of the author that should appear in the running header \runningauthor{Nematzadeh et al.}   \clearpage  \tableofcontents \clearpage              \break  
"," % The abstract should briefly summarize the contents of the paper in % 150--250 words. The hyponym-hypernym relation is an essential element in the semantic network. Identifying the hypernym from a definition is an important task in natural language processing and semantic analysis. While a public dictionary such as WordNet works for common words, its application in domain-specific scenarios is limited. Existing tools for hypernym extraction either rely on specific semantic patterns or focus on the word representation, which all demonstrate certain limitations. Here we propose a method by combining both the syntactic structure in definitions given by the word闁炽儲鐛 part of speech, and the bidirectional gated recurrent unit network as the learning kernel. The output can be further tuned by including other features such as a word闁炽儲鐛 centrality in the hypernym co-occurrence network. The method is tested in the corpus from Wikipedia featuring definition with high regularity, and the corpus from Stack-Overflow whose definition is usually irregular. It shows enhanced performance compared with other tools in both corpora. Taken together, our work not only provides a useful tool for hypernym extraction but also gives an example of utilizing syntactic structures to learn semantic relationships \footnote{Source code and data available at \url{https://github.com/Res-Tan/Hypernym-Extraction}}.  \keywords{Hypernym Extraction \and Syntactic Structure \and Word Representation \and Part of Speech \and Gated Recurrent Units.}",402
"  Although neural machine translation  has achieved great success on sentence-level translation tasks, many studies pointed out that  translation mistakes become more noticeable at the document-level. They proved that these mistakes can be alleviated by feeding the inter-sentential contexts into context-agnostic NMT models.  Previous works have explored various methods to integrate context information into NMT models. They usually take a limited number of previous sentences as contexts and learn context-aware representations using hierarchical networks  or extra context encoders . Different from representation-based approaches, ~\citeauthor{tu2018learning}~\shortcite{tu2018learning} and ~\citeauthor{kuang-etal-2018-modeling}~\shortcite{kuang-etal-2018-modeling} propose using a cache to memorize context information, which can be either history hidden states or lexicons. To keep tracking of most recent contexts, the cache is usually updated when new translations are generated. Therefore, long-distance contexts would likely to be erased.  How to use long-distance contexts is drawing attention in recent years. Approaches, like treating the whole document as a long sentence  and using memory and hierarchical structures , are proposed to take global contexts into consideration. However, \citeauthor{kim2019and}~\shortcite{kim2019and} point out that not all the words in a document are beneficial to context integration, suggesting that it is essential for each word to focus on its own relevant context.    \footnotetext{Dependency and coreference relations are from Stanford CoreNLP .}  To address this problem, we suppose to build a document graph for a document, where each word is connected to those words which have a  direct influence on its translation. Figure  shows an example of a document graph. Explicitly, a document graph %for a document  is defined as a directed graph where:  each node represents a word in the document;  each edge represents one of the following relations between words:  adjacency;  syntactic dependency;  lexical consistency; or  coreference.   We apply a Graph Convolutional Network  on the document graph to obtain a document-level contextual representation for each word,  fed to the conventional Transformer model  by additional attention and gating mechanisms. We evaluate our model on four translation benchmarks, IWSLT English--French  and Chinese--English , Opensubtitle English--Russian , and WMT English--German . Experimental results demonstrate that our approach is consistently superior to previous works  on all the language pairs.   The contributions of this work are summarized as:        The hyponym-hypernym relationship plays an important role in many NLP tasks. Despite intensive studies on this topic, tools that can accurately extract hypernym from a definition is limited. The definition, representing a special type of summarized knowledge, is commonly observed, not only because some corpora such as Wikipedia or GitHub directly give the definition of a term, but also because there are tools capable of extracting definitions with good accuracy. Hence, it is useful to develop a capable tool for this task. Here we construct a bidirectional GRU model for patterns learning. We use the PoS tags of words surrounding the hypernym as the feature. Our model outperforms existing methods in both the general corpus  and the domain-specific corpus . It also demonstrates a good balance between the performance and complexity, if compared with the kernels by Transformer or Bert. More importantly, by the feature and kernel ablation, we show that the PoS feature is indeed the key element that guarantees the final performance.   The application of the tool we proposed in Stack-Overflow would help us understand the evolution of technology, group users for social network study, and build the semantic network in the domain of computer science. The performance of the tool is limited by the accuracy of PoS tagging. Hence, it would be useful to try or develop other methods other than the Stanford-NLP tool. The use of PoS feature may also have potential in other text sequence labeling tasks, which may have advantages over the word embedding. All these problems will be addressed in future studies.   
","     Previous works have shown that contextual information can improve the performance of neural machine translation . However, most existing document-level NMT methods failed to leverage contexts beyond a few set of previous sentences. How to make use of the whole document as global contexts is still a challenge. To address this issue, we hypothesize that a document can be represented as a graph     that connects relevant contexts regardless of their distances. We employ several types of relations, including adjacency, syntactic dependency, lexical consistency, and coreference, to construct the document graph. Then, we incorporate both source and target graphs into the conventional Transformer architecture with graph convolutional networks. Experiments on various NMT benchmarks, including IWSLT English--French, Chinese-English, WMT English--German and Opensubtitle English--Russian, demonstrate that using document graphs can significantly improve the translation quality.",403
"  Automatic summarization is a fundamental task in natural language generation and computational linguistics. It is crucial to help the user quickly read and understand daily events, and has been continuously studied for decades. . In this paper, we focus on meeting summarization, which is an extensively studied task in the field of automatic summarization. Given multiple speakers and corresponding utterances in text, the task calls for generating a shorter transcript, covering salient information of the entire meeting. An example is shown in Figure , which includes 3 speakers and their utterances , and , as well as a human-written summary.  Meeting summarization is typically regarded as a kind of abstractive summarization problem in the literature. The majority of existing studies build summarization systems based on the sequence-to-sequence model, which adopts a sequence modeling strategy for encoding utterances . Despite the effectiveness of these approaches, they typically only use sequential text information while ignoring the important influences of dialogue structure. We claim that dialogue-specific structural information is important for meeting summarization. For example, dialogue discourse is an effective structural feature. As shown in Figure , ``Contrast閳, ``Question-Answer閳 and ``Continuation閳 are three dialogue discourse relations, which can provide more precise semantic relationships between each utterance. Specifically, we can see that the existing sequence modeling method is unable to generate correct summary results ), which can be attributed to the system not knowing the  and  are opposed to the 閳ユ獨 proposal. Differently, the dialogue discourse can provide this key information via labeling the 閳ユ窅ontrast閳 relationship, as shown in Figure . Accordingly, how to effectively integrate the discourse relationship into the existing summarization model become a crucial step in meeting summarization.  In this paper, we propose Dialogue Discourse-Aware Graph Convolutional Networks  to address this problem. In detail, we first convert the entire meeting with dialogue discourse labeling into a discourse graph, which represents both utterances and discourse relationships as vertices. Afterwards, we additionally design six types of directed edges and one global vertex in the discourse graph to facilitate information flow. Finally, we employ a graph convolutional network  to encode the graph and pass the semantic representation to the RNN decoder. Besides, we further use the question-answer discourse relationship to construct a pseudo-summarization corpus for pre-training DDA-GCN. In a conversation, a question often sparks a discussion, so naturally, the question can be used as a pseudo-summary for subsequent discussions.  We conduct experiments on the widely used AMI benchmark . Our approach outperforms various baselines. Moreover, we analyze the effectiveness of dialogue discourse and pseudo-summarization corpus. In the end, we give a brief summary of our contributions:  To the best of our knowledge, we are the first to apply dialogue discourse to model the structure of a meeting for meeting summarization;  We design a discourse-aware graph model to encode the entire meeting;  Our model achieves a new SOTA on the AMI dataset.      In this paper, we propose a graph-based approach for document-level translation, which leverages both source and target contexts. Graphs are constructed according to inter-sentential and intra-sentential relations. We employ a GCN-based graph encoder to learn the graph representations, which are then fed into the NMT model via attention and gating mechanisms.  Experiments on four translation tasks show the proposed approach consistently improves translation quality across different language pairs. Further analyses demonstrate the effectiveness of graphs and the capability of leveraging long-distance context. In the future, we would like to enrich the types of relations to cover more document phenomena.        
"," Sequence-to-sequence methods have achieved promising results for textual abstractive meeting summarization. Different from documents like news and scientific papers, a meeting is naturally full of dialogue-specific structural information. However, previous works model a meeting in a sequential manner, while ignoring the rich structural information. In this paper, we develop a Dialogue Discourse-Aware Graph Convolutional Networks  for meeting summarization by utilizing dialogue discourse, which is a dialogue-specific structure that can provide pre-defined semantic relationships between each utterance. We first transform the entire meeting text with dialogue discourse relations into a discourse graph and then use DDA-GCN to encode the semantic representation of the graph. Finally, we employ a Recurrent Neural Network to generate the summary. In addition, we utilize the question-answer discourse relation to construct a pseudo-summarization corpus, which can be used to pre-train our model. Experimental results on the AMI dataset show that our model outperforms various baselines and can achieve state-of-the-art performance.",404
"  Pre-trained language models such as BERT or RoBERTa learn contextualized word representations on large-scale text corpus through self-supervised learning, and obtain new state-of-the-art results on many downstream NLP tasks . Recently, researchers have observed that pre-trained language models can internalize real-word knowledge into their model parameters. For example, pre-trained language models are able to answer the questions such as ``the sky is }'' or ``Beethoven was born in }'' with moderate accuracy. To further explore their potential, researchers have proposed various approaches to guide the pre-training of the language models by injecting different forms of knowledge into them, such as structured knowledge graph or linguistic knowledge  .      	 \end{table*}  Table lists some of the previous knowledge-guided pre-trained language models with their training methods. We group them into two categories: generative tasks and discriminative tasks. Generative tasks are often formulated as predicting the masked tokens given the context. By particularly masking out the words that contain certain types of knowledge  in generative pre-training, the model can be more adept in memorizing and completing such knowledge. While discriminative tasks are often formulated as a classification problem with respect to the sentence or the tokens. By training on the positive and negative examples constructed according to the external knowledge, the discriminator can be more capable of verifying the true or false knowledge in natural language. Existing research has demonstrated that generative and discriminative training have their advantages: the former has a large negative sample space so that the model can learn fine-grained knowledge, while the latter avoids the ``'' tokens in pre-training, and is therefore more consistent with fine-tuning. On the other hand, generative and discriminative capture the different aspects of data distribution and could be complementary to each other in knowledge consolidation. However, to the best of our knowledge, there is not previous work in combining the two approaches in a systematic way. Inspired by the recent success on the generative-discriminative pre-trained model named ELECTRA, we propose to learn the generator and discriminator jointly in the knowledge-guided pre-training, which we call the KgPLM model.  In this paper, we design masked span prediction as the generative knowledge completion task, and span replacement checking as the discriminative knowledge verification task. Hybrid knowledge, including link structure of Wikipedia and structured knowledge graph in Wikidata, is used to guide the both tasks. The spans covering the factual knowledge are more likely to be selected for masking or replacement, and the choices of their replacements are also related to the proximity to the original span in the knowledge space. Figure shows an example of the span masking and replacement tasks. To further explore effective ways to the joint training of the two tasks, we design two learning schemes, which we called two-tower scheme and pipeline scheme. Basically, the generator and discriminator are trained in parallel with the shared parameters in the two-tower scheme. While in the pipeline scheme, the output of generator is input to the successive discriminative training. The generator and discriminator in our KgPLM model are both pre-trained based on RoBERTa. They have some additional benefits: 1) the model can be readily extended to much larger pre-training corpus, which keeps some potential room for further improvement; 2) the model retains the same amount of parameters as RoBERTa, and does not require any modifications in fine-tuning for the downstream tasks.  We evaluate the model performance on LAMA~, which consists of several zero-shot knowledge completion tasks, and MRQA shared tasks~, which include several benchmark question answering datasets. The experiments show the proposed KgPLM, especially that trained with the pipeline scheme, achieves the state-of-the-art performance, and significantly outperform several strong baselines  on some of the tasks. The results indicate that the knowledge-guided generative and discriminative pre-training provides an effective way to incorporate external knowledge and achieve competitive performance on the knowledge intensive NLP tasks.    In this paper, we apply the dialogue discourse to model the structure of a meeting for meeting summarization. We first transform the entire meeting text and corresponding dialogue discourse relations into a discourse graph. Specifically, both the utterances and discourse relations are constructed as vertices, and we design six types of edge and a global vertex to facilitate the information flow. Moreover, we develop a Dialogue Discourse-Aware Graph Convolutional Networks  which consists of an utterance encoder, a graph encoder, and a pointer decoder. In addition, we construct a pseudo-summarization corpus by utilizing the question-answer discourse relation, which can be used to pre-train our model.  Experiments on the AMI dataset show the effectiveness of our model which can achieve the SOTA performance.       
"," Recent studies on pre-trained language models have demonstrated their ability to capture factual knowledge and applications in knowledge-aware downstream tasks. In this work, we present a language model pre-training framework guided by factual knowledge completion and verification, and use the generative and discriminative approaches cooperatively to learn the model. Particularly, we investigate two learning schemes, named two-tower scheme and pipeline scheme, in training the generator and discriminator with shared parameter. Experimental results on LAMA, a set of zero-shot cloze-style question answering tasks, show that our model contains richer factual knowledge than the conventional pre-trained language models. Furthermore, when fine-tuned and evaluated on the MRQA shared tasks which consists of several machine reading comprehension datasets, our model achieves the state-of-the-art performance, and gains large improvements on NewsQA  and TriviaQA  over RoBERTa.",405
" 	 	Knowledge graphs , such as WordNet , Freebase  and Wikidata , aggregate a large amount of human knowledge and express in a structured way. 	% are representative of existing KGs, in which knowledge is formalized as triples. 	%, such as  where  is the head entity,  is the tail entity, and  is the relation between these two entities. 	The large number of triples in these KGs have constructed a complex knowledge network, but it is far from complete. 	In recent years, knowledge graph completion  tasks have attracted great attention. 	 	 	 	Despite new state-of-the-art  models  emerge constently, most methods ignore the topological structure information of the KGs.  	Relation paths are the most common topological structure in KGs, and Figure shows some relation path instances.  	 is a relation triple, while  is a two-step relation path. 	Similar to word context in language models , relation paths can be considered as one kind of contextual information in KGs. 	We call it ``graph contextual information''. 	And Harris's famous distributional hypothesis   can also be extend to knowledge graphs: you shall know an entity by the relationships it involves. 	Although these two kinds of contextual information are similar, the latter has its own specialities. 	In knowledge graphs, not all relation paths are meaningful. 	For example,  is a valid relation path, but this does not indicate that there must be a relationship between  and . 	Unreliable relation paths are common in knowledge graphs, and  \citet{lin2015modeling} found that it is necessary to select reliable relation paths for knowledge representation learning. 	%In this work, a path-constraint resource allocation algorithm is proposed to measure the weights of inference patterns. 	They learn inference patterns between relations and paths to utilize knowledge contained in relation paths. 	%Despite its success, the modeling objects are more limited to the inference patterns between relations and paths. 	%Recently, \citeauthor{wang2019coke} \shortcite{wang2019coke} propose a method to model the contextual nature of triples and relation paths, and they explore the benefits of graph contextual information for link prediction tasks on two specific datasets. 	%However, simply adding graph contextual information  into the training pool is not always effective, and this operation may reduce the performance of the original model. 	Instead of relying on inference patterns, we propose PPKE, a path-based pre-training approach that integrates  graph contextual information contained in relation paths into the model parameters. 	We think this is a more general way to develop the unexploited graph contextual information. 	During the path-based pre-training procedure,  two-step relation paths are extracted from the knowledge graph and fed into the pre-training module with original triples. 	Then, the pre-trained model can be finetuned for downstream KGC tasks, such as link prediction and relation prediction. 	Our contributions are as follows: 	     We have proposed a pre-training method by cooperatively modeling the generative and discriminative knowledge injecting approaches. Our model can be easily extended to larger pre-training corpus and does not introduce any modifications for downstream tasks during finetuning. Experiments show our model consistently outperforms all \texttt{BASE} models on a variety of question answering datasets, demonstrating that our KgPLM is a preferred choice for the knowledge intensive NLP tasks.   Our method uses two-tower and pipeline frameworks to integrate knowledge span masking with knowledge span checking for pre-training.   add TEK into pre-training and finetuning.    train from scratch   
"," 		Entities may have complex interactions in a knowledge graph , such as multi-step relationships, which can be viewed as graph contextual information of the entities. 		Traditional knowledge representation learning  methods usually treat a single triple as a training unit, and neglect most of the graph contextual information exists in the topological structure of KGs. 		In this study, we propose a Path-based Pre-training model to learn Knowledge Embeddings, called PPKE, which aims to integrate more graph contextual information between entities into the KRL model. 		Experiments demonstrate that our model achieves state-of-the-art results on several benchmark datasets for link prediction and relation prediction tasks, indicating that our model provides a feasible way to take advantage of graph contextual information in KGs.",406
"  Machine reading comprehension  is a challenging natural language understanding task which lets the machine predict appropriate answer to the question according to a given passage or document .  According to answer styles, MRC tasks can be roughly divided into generative , extractive  and multi-choice  tasks . The multi-choice task is the focus of this work.  Recently, various datasets and tasks have been proposed, promoting a rapid improvement of MRC techniques . Early MRC datasets usually provide passages whose contents are extracted from articles . Recently, conversational reading comprehension has aroused great interests whose passages are derived from multi-turn dialogue segments , making the task be more challenging.    The popular practice to solve MRC problems is adopting pre-trained language models  as encoder module . Instead of better exploiting pre-trained LMs, this paper is motivated by human reading strategies to decouples MRC into sketchy reading by extracting the critical spans from the passage, and extensive reading by seeking external knowledge.  As a result, we propose a knowledge enhancement model based on extracted critical information called RekNet . In detail, the proposed RekNet refines the fine-grained critical information by a span extraction model and defines it as Reference Span, then quotes relevant external knowledge in the form of quadruples by the co-occurrence information of Reference Span and answer options. An example process of RekNet is shown in Figure .   In summary, our main contributions are follows:\\ 1) We propose a novel reference-based knowledge enhancement model RekNet, which makes the first attempt to obtain fine-grained evidence for inference and knowledge retrieving on MRC tasks.\\ 2) RekNet uses novel knowledge quadruples to quote relevant and credible knowledge.\\ 3) RekNet is applied to two multi-choice MRC benchmarks, RACE  and DREAM  and improves the performance of baseline models by 1.0\% and 1.1\% respectively, which both pass the significance test of MRC tasks.    	 	We propose a novel approach to integrate graph contextual information into a path-based pre-training model, focusing on modeling one-step and two-step relations between entities. 	 Then, the pre-trained model is finetuned for link prediction and relation prediction tasks. 	Experiments show our model outperforms previous state-of-the-art methods, 	  after incorporating a small portion of graph context information existing in knowledge graphs,  	which validates the intuition that graph contextual information is beneficial to knowledge graph completion tasks. 	 	In the follow-up work, we will try to add relation prediction objective into the pre-training procedure, and larger quantity or wider variety of graph contextual information will be explored. 	 Besides, more knowledge-driven tasks will be utilized to validate the effectiveness of our method. 	 	 relation prediction in pre-training 	 	
"," Multi-choice Machine Reading Comprehension  is a major and challenging form of MRC tasks that requires model to select the most appropriate answer from a set of candidates given passage and question. Most of the existing researches focus on the modeling of the task datasets without explicitly referring to external fine-grained commonsense sources, which is a well-known challenge in multi-choice tasks. Thus we propose a novel reference-based knowledge enhancement model based on span extraction called 	extbf{Reference Knowledgeable Network }, which simulates human reading strategy to refine critical information from the passage and quote external knowledge in necessity. In detail, RekNet refines fine-grained critical information and defines it as Reference Span, then quotes external knowledge quadruples by the co-occurrence information of Reference Span and answer options. Our proposed method is evaluated on two multi-choice MRC benchmarks: RACE and DREAM, which shows remarkable performance improvement with observable statistical significance level over strong baselines.",407
"   Data collection is an essential part of the field of spoken dialogue systems and conversational AI. %, and requires developers to make difficult decisions and budget accordingly.   In particular, designing a dialogue system for a completely new domain is still a very challenging task.  Data collection options include running lab-based experiments, crowd-sourced tasks  or gathering data from social media platforms, such as Reddit or Twitter. Ambitious large scale data collections across multiple domains have resulted in widely used datasets, such as MultiWOZ . % and collected from various platforms .% to create representations of dialogues in the vector space.   However, starting off in a new domain from scratch still has its challenges. Difficult and costly decisions have to be made as to how and where to collect the data.    A large majority of recent dialogue corpora has been collected using crowd-sourcing either by pairing workers and letting them chat, often about a given topic , or by asking them to add the next utterance to the dialogue given a set of conditions . Other studies have recruited subjects to play the role of the system, i.e., to act as a wizard or user . Each of these approaches has its own advantages and disadvantages, depending on if the dialogue is task-oriented or not. By letting users type in an unrestricted way, the richness of the dialogue increases, which is a positive feature for chit-chat. On the other hand, too much variability could be a problem for a high stakes, task-oriented dialogues, such as in the medical domain. Letting multiple users contribute with one utterance per dialogue , speeds up the data collection, however, dialogues may lack coherence and severely diverge from real dialogues. On the other hand, hiring and training subjects to chat or perform the wizard role results in a more controlled data collection but dramatically increases the cost of the data collection and makes it less scalable.     The quality of such datasets has been often assessed according to the degree of variability  observed  or the lexical complexity of the utterances collected . %, however to the best of our knowledge, there is no work assessing the impact of the different methods directly on training dialogue models.   %This paper aims at addressing this issue by investigating the impact of two different data collection methods on the performance of the model. Furthermore, most of the above-mentioned datasets focus on increasing the size of the dataset available for dialogue research, rather than investigating the impact of the data collection strategies on the performance of the models trained. The work presented in this paper aims at highlighting the pros and cons, using a methodology to quickly leverage a robust dialogue system, minimising the cost and effort involved in the data collection process. Analyses comparing different strategies for the data collection process across various platforms have been done in the past , but we are not aware of a similar study for dialogue data.  The data used in this study was collected in the scope of an emergency response system to be used on an off-shore energy platform as part of the EPSRC ORCA Hub programme . One of the collections was done using crowd-sourcing  and the second one was done in a lab using a Wizard-of-Oz setting, where participants were interacting either with a social robot or a smart speaker. Both datasets were used to train a dialogue model using an implementation of a Hybrid Code Network  and here we compare the results achieved by models trained on data collected by either method. To validate the use of crowd-sourced data to bootstrap a dialogue system for situated interaction, we ran experiments where we train the model on the crowd-sourced data and test it on the lab data, in order to verify if it %This will result in an estimate of the number of dialogues needed to  %varied the amount of crowd-sourced dialogues during training to estimate the necessary amount of crowd-sourced data needed to  achieves comparable performances with the models trained only with the lab data.   The contributions of this paper are as follows: 1) a comparison of models trained with two datasets collected in different ways but on the same task, 2) evidence that suggests that specialised dialogue tasks, such as our emergency response task, are not well covered by current pre-trained dialogue models, and 3) a set of recommendations regarding the data collection for dialogue research.\footnote{Please find code and data in: \href{https://github.com/zedavid/TheLabVsTheCrowd}{}.}  The paper is organised as follows. Section  will cover previous work related to this problem. Our experimental set-up will be introduced in Section , followed by the results in Section . The paper concludes with the discussion in Section  and future work and conclusions in Section .         To alleviate the challenge of knowledge role missing in multi-choice MRC, this work makes the first attempt to integrating external knowledge based on span extraction into MRC modeling, presenting 	extbf{Reference Knowledgeable Network }, which can simulate the human strategy of reading comprehension and quote external knowledge for multi-choice MRC tasks.  RekNet helps achieve significantly performance improvement on two multi-choice MRC benchmarks RACE and DREAM, which passed the significance test. In the future, we will apply RekNet to other forms of MRC tasks.       
","  Challenges around collecting and processing quality data have hampered progress in data-driven dialogue models. %, particularly data-hungry neural and hybrid models.   Previous approaches are moving away from costly, resource-intensive lab settings, where collection is slow but where the data is deemed of high quality. The advent of crowd-sourcing platforms, such as Amazon Mechanical Turk, has provided researchers with an alternative cost-effective and rapid way to collect data.   %However, these platforms are sometimes notorious for data anomalies due to the rapid nature of which data is collected.   However, the collection of fluid, natural spoken or textual interaction can be challenging, particularly between two crowd-sourced workers. In this study, we compare the performance of dialogue models for the same interaction task but collected in two different settings: in the lab vs. crowd-sourced. We find that fewer lab dialogues are needed to reach similar accuracy, less than half the amount of lab data as crowd-sourced data.. We discuss the advantages and disadvantages of each data collection method. %, which is of interest to the community in terms of platform choice and how much data will be needed to be collected.",408
" .     %     % % final paper: en-us version     %    % space normally used by the marker  This work is licensed under a Creative Commons  Attribution 4.0 International License. \\  License details:  \url{http://creativecommons.org/licenses/by/4.0/}. } The recent surge in popularity of voice assistants, such as Google Home, Apple閳ユ獨 Siri, or Amazon閳ユ獨 Alexa resulted in interest in scaling these products to more regions and languages. This means that all the components supporting Spoken Language Understanding  in these devices, such as Automatic Speech Recognition , Natural Language Understanding , and Entity Resolution  are facing the challenges of scaling the development and maintenance processes for multiple languages and dialects.  When a voice assistant is launched in a new locale, its underlying speech processing components are often developed specifically for the targeted country, marketplace, and the main language variant of that country. Many people assume that if a device ``understands'' and ``speaks'' in a specific language, for example English, it should be able to work equally well for any English-speaking country, but this is a misunderstanding. For instance, if a speaker of UK English asks a device trained on data collected in the United States ``tell me a famous football player'', it is highly unlikely that this device will provide the user's desired answer, since football means different things in the US and UK cultures. As a result, developers need to take into account not only the language or dialectal differences, but also local culture, to provide the right information in the right language setup. An increase in the number of target marketplaces often means a linear increase in effort needed to develop and maintain such locale-specific models.  NLU models, which classify the user閳ユ獨 intent and extract any significant entities from the user閳ユ獨 utterance, face the same challenge of maintaining high accuracy while being able to accommodate multiple dialects or language content. The major tasks in NLU are intent classification and slot filling. Intent classification is a task to predict what action the user intends the voice assistant to take. Slot filling is a task to identify the specific semantic arguments for the intention. For example, if the user閳ユ獨 request is to ``play Poker Face by Lady Gaga'', the user閳ユ獨 intention will be ``play music'', while in order to fulfill this command with specified details, the system needs to capture the slots for \{song name = Poker Face\}, and \{artist name = Lady Gaga\}. These tasks are called intent classification  and named entity recognition , respectively.  One common approach is to use a max-entropy  classification model for the IC task and a conditional random fields  model for the NER task. Following the advent of deep learning techniques in related fields, such as computer vision and natural language processing, deep learning is becoming more popular in NLU as well. Some of the recent multilingual approaches to NLU include, for example, the Convolutional Neural Network  model for sentence classification , or the Long Short-Term Memory  model for NER prediction . In the deep neural network architecture, the aforementioned NLU tasks can be combined into a single multi-task classification model. An increasing number of experiments also focus on multilingual setups, especially in the field of machine translation, where the task is to translate input from one language to another .  One recent thread of multilingual research centers around learning multilingual word representation. Multilingual word embeddings in the shared cross-lingual vector space have one main property: words from different languages but with similar meaning must be geometrically close. This property allows for transfer learning from one language to another in various multilingual tasks, such as dependency parsing  or classification and NER . A number of model architectures have been proposed to pre-train multilingual word representations, such as leveraging large-scaled LSTM networks trained on monolingual corpora and adversarial setup for space alignment , or transformers trained on multilingual corpora as a single language model .  Although some of these models can be used to solve IC and NER tasks by appending corresponding decoders to generate final predictions, it is not straightforward to use them in production environments due to latency and memory constrains. A different way of benefitting from larger models could be to use them for transfer learning to smaller-size models to improve their performance by initializing some parts of the model with close-to-optimal rather than random weights. In this paper, we extend the multi-task approach studied in  to a general multilingual model for IC and NER tasks, based on deep learning techniques, such as a bidirectional Long Short-Term Memory  CRF sequence labeling model for NER along with a multilayer perceptron  for IC.  We also explore multilingual transfer learning and its benefits to our setup. Transfer learning is widely adapted for zero-shot or few-shot setups, and was explored in some multilingual NLP studies , and also has been used in multi-task IC-NER models ,  yet to the best of our knowledge, there is no study applying transfer learning for data-rich target languages in a multilingual setup. In our experiment, we apply few-shot transfer learning from data-rich languages to a language with a smaller amout of training data. In additon, we also apply  transfer learning to mimic the situation of expanding the model ability to same-level-resource language with known context from another high-resource language, such that the new multilingual model will ``inherit'' context information from its ancestors. We investigate these approaches to transfer learning and their effects on model performance. We show that transfer learning can improve NLU model performance even in data-rich conditions.       Dialogue acts which can occur in any context such as inform\_time\_left or hold\_on\footnote{Used to keep users engaged until new information was available.} were in both scenarios difficult to learn.    With the use of the action mask, we observed the prediction of the  robot state update states has greatly improved with the use of the action mask    BoW.previous_action.nlu: MTurk, seems to be failing to get the right timing. Dialogues states seem to be predicted in adjacent turns. Problems predicting the request and action states, unlike the in lab where the unknown turns were the hardest to predict.  Results in Table  show that the model trained only with Lab data outperformed the model trained with the complete dataset on , with all the features included. When comparing the performance of models trained with the same number of dialogues , the model trained with Lab data clearly outperformed the model trained with the MTurk data. This is not surprising, since the Lab data was collected with a single wizard, who had mastered the task. The wizard behaviour is more consistent than the behaviour of crowd-workers, who had little time to familiarise themselves with the task. The perplexity scores also confirm that dialogues trained with Lab data unfold in a more predictable way when compared with crowd-sourced data.   A fine-grain analysis revealed that the outputs of models trained with MTurk data tend to rush the dialogue, minimising the number of robot status updates   while the robot is moving towards the target location  and using fewer non-task based dialogue acts, such as ``Hold on 2 seconds''. This pattern perhaps reflects the crowd-sourced worker's tendency to streamline tasks. However, even given the time constraint of the task, the above-mentioned dialogue acts  are important contributions to the dialogue, especially in terms of managing the user's confidence and stress levels. This effect could be due to the fact that face-to-face interactions require some turn-taking management, which is not reproducible in text-based dialogues.   and driving the emergency to its resolution.   Furthermore, the set-up used in the lab data collection is as close as one can get to the end application. As can be seen from Figure , the set-ups are significantly different. In the lab setting, participants are immersed in the scene in an operations-like environment, unlike in the crowd-sourced scenario where the interaction takes place through a chat window on the crowd-worker's computer.   This raises concerns about the methodology used for data collections in cases such as ours  Clearly, the lab setting is more appropriate for tasks such as the emergency response task described here, where situation awareness and full user engagement are vital to replicate the conditions of the end application . Our results suggest that with a much smaller amount of data collected in very controlled conditions the model learns faster and more accurately. While this level of control might hinder the performance of the model when dealing with outliers, this seems not to be the case for our domain, where we expect participants to be highly knowledgeable of the task and compliant with the safety protocols that should be followed to complete the task successfully.     Models tended to drive the dialogue faster than ground truth,   Although this behaviour was shown throughout the collected crowd-sourced dialogues, the models do not seem to learn the notion of time which is crucial for domains such as ours. While there has been significant progress in generating dialogue responses in the recent years, the timing aspects seem to be left behind. Our results suggest that in dialogues collected via crowd-sourcing this aspect might be lost.   and models struggle to learn the ``when'' to use a particular dialogue act.      Results from Table  show that pre-trained models perform very poorly in our task. As we have hypothesised earlier, our task is significantly different than tasks currently used in task-oriented dialogue research. Hence, system developers will have to assess whether the domain is similar enough to allow the use of pre-trained models, or if it is too specific such that it requires the model to be trained with data within domain.     collaborative task success helps understand the performance of the model when the operator behaves reasonably. In these cases, the operator would have resolved the emergency in the dialogue  \section{Conclusion and Future work}  Future work will involve investigating further the use of pre-trained models for specific-task based systems and the extent to which they can be used to bootstrap models for highly specific tasks such as our own. We acknowledge that the datasets in this study are small compared to datasets used to train state-of-the art neural models. This is one reason why we used the HCN method in this study as it has been shown to work well with small amounts of data . One future direction would be to duplicate such a study with a dataset of a similar size to MultiWOZ and explore further fine-grained increases in data size for training. This, however, will be very challenging and costly to collect lab data to match the size of the crowd-sourced data. With more in-lab data to retrain the models, we would plan to run a further in-depth systematic comparison of a variety of dialogue modelling approaches, for example using the methodology proposed in . Finally, to investigate the single-wizard impact, we are aiming to run a crowd-sourced data collection with a single wizard and repeat the experiments done in this paper.   In this paper, we present a study comparing how different approaches to data collection may impact a hybrid neural dialogue model performance. Results suggest that, for our domain, models trained with small sets of lab-collected data outperform models trained with larger crowd-sourced datasets and pre-trained models. Given the nature of the domain, focusing on smaller lab data collections in realistic settings will likely be the best way to rapidly improve the model. However, the challenge to improve crowd-sourced data collection, making them as close as possible to the end application, still remains.         
"," 	With the recent explosion in popularity of voice assistant devices, there is a growing interest in making them available to user populations in additional countries and languages. However, to provide the highest accuracy and best performance for specific user populations, most existing voice assistant models are developed individually for each region or language, which requires linear investment of effort. In this paper, we propose a general multilingual model framework for Natural Language Understanding  models, which can help bootstrap new language models faster and reduce the amount of effort required to develop each language separately. We explore how different deep learning architectures affect multilingual NLU model performance. Our experimental results show that these multilingual models can reach same or better performance compared to monolingual models across language-specific test data while require less effort in creating features and model maintenance.",409
"  . 	%  	% % final paper: en-us version  	% 	%	   % space normally used by the marker 	This work is licensed under a Creative Commons  	Attribution 4.0 International License. 	License details: 	\url{http://creativecommons.org/licenses/by/4.0/}. }  The widespread dissemination of fake news has lead to a significant influence on personal fame, public trust, and security. For example, spreading misinformation, such as ``Asians are more vulnerable to novel coronavirus''~\footnote{https://www.thestar.com.my/news/regional/2020/03/11/myth-busters-10-common-rumours-about-covid-19} about COVID-19 has very serious repercussions, making people ignore the harmfulness of the virus and directly affecting public health. Research has shown that misinformation spreads faster, farther, deeper, and more widely than true information. Therefore, fake news detection on social media has attracted tremendous attention recently in both research and industrial fields.   Early research on fake news detection mainly focused on the design of effective features from various sources, including textual content, user profiling data, and news diffusion patterns. Linguistic features, such as writing styles and sensational headlines, lexical and syntactic analysis, have been explored to separate fake news from true news. Apart from linguistic features, some studies also proposed a series of user-based features, and temporal features about the news diffusion. However, these feature-based methods are very time-consuming, biased, and require a lot of labor to design. Besides, these features are easily manipulated by users.   To solve the above problems, many recent studies apply various neural networks to automatically learn high-level representations for fake news detection. For example, recurrent neural network , convolutional neural network , matrix factorization and graph neural network are applied to learn the representation of content and diffusion graph of news. These methods only apply more types of information for fake news detection, but paying little attention to early detection. Moreover, these models can only detect fake news in consideration of all or a fixed proportion of repost information, while in practice they cannot detect fake news in the early stage of news propagation. Some studies explore to detect fake news early by relying on a minimum number of posts. The main limitation of these methods is that they ignore the importance of publishers' and users' credibility for the early detection of fake news.   When we humans see a piece of breaking news, we firstly may use common sense to judge whether there are factual errors in it. At the same time, we will also consider the reputation of the publishers and reposted users. People tend to believe the news from a trusted and authoritative source or the news shared by lots of users with a good reputation. If the publisher is reliable, we tend to believe this news. On the other hand, if the news is reposted by many low-reputation users in a short period, it may be that some spammers tried to heat up on the news, resulting in lower credibility of the news.   Inspired by the above observation, we explicitly take the credibility of publishers and users as supervised information, and model fake news detection as a multi-task classification task. We can annotate a small part of publishers and users by their historical publishing and reposting behaviors. Although the credibility of publishers and users does not always provide correct information, they are necessary complementary supervised information for fake news detection. To make the credibility information generalized to other unannotated users, we construct a heterogeneous graph to build the connections of publishers, news, and users. Through a graph-based encoding algorithm, every node in the graph will be influenced by the credibility of publishers and users.    In this paper, we address the following challenges:  How to fully encode the heterogeneous graph structure and news content; and  How to explicitly utilize the credibility of publishers and users for facilitating early detection of fake news. To tackle the above challenges, we propose a novel structure-aware multi-head attention network for the early detection of fake news. Firstly, we design a structure-aware multi-head attention module to learn the structure of the publishing graph and produce the publisher representations for the credibility prediction of publishers. Then, we apply the structure-aware multi-head attention module to encode the diffusion graph of the news among users and generate user representations for the credibility prediction of users. Finally, we apply a convolutional neural network to map the news text from word embedding to semantic space and utilize the fusion attention module to combine the news, publisher, and user representations for early fake news detection.   The contributions of this paper can be summarized as follows:        In this paper, we propose a framework for building general multilingual NLU models, which can be used across different marketplaces and languages.  To choose the model with the best performance, we use language-specific test sets to evaluate the candidate models and their corresponding baseline models  along four metrics, domain accuracy, intent accuracy, slot F1, and frame accuracy. The models which win in most of the evaluation metrics are the final picks. We find that models built from a simple multi-task biLSTM-CRF model setup are comparable to standard production models in terms of latency constraints required for on-the-fly voice assistant conversational models.  We observe performance improvements in all models with the introduction of transfer learning. Encoder transfer produced the greatest improvements whereas the transfer of the decoder did not bring much change when compared to the baseline model performance, except when tested on an English test set, when the transfer learning is performed from the model trained on English data. This is due to the fact that the target non-English language contains slots or intents which are not included in the pre-trained model, thus the decoder fails to predict correct classes simply because they are missing in the vocabulary. To mitigate this effect, a decoder with default initialization gives better performance because it now can embrace all available slots and intents in the target language realm.  Furthermore, we find that a model pre-trained in a multilingual setup performs better than the one trained on a monolingual data set. This confirms that a multilingual model built based on lexically and orthographically similar languages may provide more beneficial context information to any similar target language. Experimental result on Hindi show that such a multilingual model can work even for non-alike languages with the same or better performance improvement. This confirms that a common multilingual model can be used to support multiple language with better results than a set of monolingual models.  With a single general multilingual NLU model, bootstrapping new languages can be faster as we can use cross-lingual contextual information from all existing high-resource languages. At the same time, maintaining only one model requires much less effort in terms of regular model updates.     
"," The\let\thefootnote\relax\footnotetext{* Corresponding author.} dissemination of fake news significantly affects personal reputation and public trust. Recently, fake news detection has attracted tremendous attention, and previous studies mainly focused on finding clues from news content or diffusion path. However, the required features of previous models are often unavailable or insufficient in early detection scenarios, resulting in poor performance. Thus, early fake news detection remains a tough challenge. Intuitively, the news from trusted and authoritative sources or shared by many users with a good reputation is more reliable than other news. Using the credibility of publishers and users as prior weakly supervised information, we can quickly locate fake news in massive news and detect them in the early stages of dissemination.  In this paper, we propose a novel Structure-aware Multi-head Attention Network , which combines the news content, publishing, and reposting relations of publishers and users, to jointly optimize the fake news detection and credibility prediction tasks. In this way, we can explicitly exploit the credibility of publishers and users for early fake news detection. We conducted experiments on three real-world datasets, and the results show that SMAN can detect fake news in 4 hours with an accuracy of over 91\%, which is much faster than the state-of-the-art models. The source code and dataset can be available at https://github.com/chunyuanY/FakeNewsDetection.",410
"  Real-world events such as sports games or elections involve competing teams, each with capabilities and tactics, aiming to win . The performance of such teams is typically not only dependent on the teams' abilities but also on the environment within which they operate. For example, a political party may have the best orators and policies but their opponents may be better at getting votes in key areas. Similarly, a top football team may be playing the worst team in a league but the fact that the latter may be facing relegation  may provide them with extra motivation to win the game. Given this, in many cases, the performance of such teams may not be easily predictable.    % In particular, in sporting events many human factors impact how a team performs in given games. There are often situations that would be very hard to represent in numbers and statistics alone. For example, sporting rivalries often affect human emotions and team performance and teams fighting to avoid relegation from a league often obtain unexpected results.   Traditional AI and machine learning techniques to predict the outcome of real-world events tend to focus on the use of statistical machine learning using historical data about the individual teams .  However, as per the examples above, historical performance may not be useful when team performance may be dependent on dynamic factors such as human performance  or environmental variables . In turn, humans can be better judges than algorithms when faced with previously unseen situations. Journalists, online communities, and experienced analysts may be better at evaluating human and environmental elements to forecast an outcome. For example, one approach of looking at more than just statistics in sports have been through sentiment analysis on social media platforms. Schumaker, Jarmoszko and  Labedz  use this approach to predict English Premier League  results and achieve an accuracy of 50\% and  show use of similar analysis being performed for American Football results in the National Football League  predicting the winner 63.8\% of the time. However, these approaches focus on opinion aggregation rather than trying to extract the potential indicators of performance for individual human teams from human experts.  Against this background, we set new baselines for results when predicting real-world sporting events involving humans based on the combination of Natural Language Processing  and statistical machine learning techniques. In more detail, we focus specifically on football games in the EPL using match previews from the media alongside statistical machine learning  techniques. The prediction of football match outcomes is a challenging computational problem due to the range of parameters that can influence match results. To date, probabilistic methods devised since the seminal work of Maher  have generated fairly limited results and appear to have reached a glass ceiling in terms of accuracy. By using media previews we can improve on the accuracy of current approaches for match outcome prediction. By so doing, we show that by incorporating human factors into our model, rather than just basic performance statistics, we can improve accuracy . Thus, the contributions of this paper are as follows:    In the next section we discuss the match outcome prediction problem for football and the new feature set we explore.  %The rest of this paper is organised as follows. Section  discusses the problem that we are aiming to solve, Section  outlines how we model human opinion and use this to predicting real-world football games. Section  provides the detail of how we test our models and set the baseline for the prediction accuracy. Finally, Section  concludes.  %       and Future Work This paper proposes a novel structure-aware multi-attention network, which combines news content, the heterogeneous graphs among publishers and users, and jointly optimizes the task of false news detection and user credibility prediction for early fake news detection. Different from most existing research extracting hand-crafted features or deep learning methods, we explicitly treat the credibility of publishers and users as a kind of weakly supervised information for facilitating fake news detection. Extensive experiments conducted on three real-world datasets show that the proposed model can significantly surpass other state-of-the-art models on both fake news classification and early detection task.    
"," In this paper, we present a new application-focused benchmark dataset and results from a set of baseline Natural Language Processing and Machine Learning models for prediction of match outcomes for games of football . By doing so we give a baseline for the prediction accuracy that can be achieved exploiting both statistical match data and contextual articles from human sports journalists. Our dataset is focuses on a representative time-period over 6 seasons of the English Premier League, and includes newspaper match previews from The Guardian. The models presented in this paper achieve an accuracy of 63.18\% showing a 6.9\% boost on the traditional statistical methods.",411
"  Deep neural networks are successful at various morphological tasks as exemplified in the yearly SIGMORPHON Shared Task. However these neural networks operate with continuous representations and weights which is in stark contrast with traditional, and hugely successful, rule-based morphology. There have been attempts to add rule-based and discrete elements to these models through various inductive biases.   In this paper we tackle two morphological tasks and the copy task as a control with an interpretable model, \sopa.  Soft Patterns or \sopa is a finite-state machine parameterized with a neural network, that learns linear patterns of predefined size. The patterns may contain epsilon transitions and self-loops but otherwise are linear. Soft refers to the fact that the patterns are intended to learn abstract representations that may have multiple surface representations, which \sopa can learn in an end-to-end fashion. We call these surface representations subwords, while the abstract patterns, patterns throughout the paper.  An important upside of \sopa is that interpretable patterns can be extracted from each sample.  shows that \sopa is able to retrieve meaningful word-level patterns for sentiment analysis. Each pattern is matched against every possible subword and the highest scoring subword is recovered via a differentiable dynamic program, a variant of the forward algorithm.  We apply this model as the encoder of a sequence-to-sequence or seq2seq\footnote{also called encoder-decoder model} model, and add an LSTM decoder.  We initialize the decoder's hidden state with the final scores of each \sopa pattern and we also apply Luong's attention on the intermediate outputs generated by \sopa. We call this model \sopaseq.  We compare each setup to a sequence-to-sequence with a bidirectional LSTM encoder, unidirectional LSTM decoder and Luong's attention.  We show that \sopaseq is often competitive with the LSTM baseline while also interpretable by design. \sopaseq is especially good at \morphana, often surpassing the LSTM baseline, which confirm our linguistic intuition namely that subword patterns are useful for extracting morphological information.  We also compare these models using a generalized form of Jaccard-similarity and we find that some trends coincide with linguistic intuition.     This paper has presented a novel application-focused dataset and has set new baselines of 63.19\  accuracy for predicting games of English Premier League football across a three season period using a novel dataset which we provide as part of this paper. We showed that the application of combining human opinion and machine learning to make predictions can boost the accuracy of traditional methods and those using sentiment analysis on social media. We show that we boost these methods by 6.9\  in terms of outcome accuracy and that the model accuracy increases as the season progresses and human factors/emotions begin to play a bigger part in the game.  \clearpage  
","  We examine the role of character patterns in three tasks: morphological analysis, lemmatization and copy. We use a modified version of the standard sequence-to-sequence model, where the encoder is a pattern matching network. Each pattern scores all possible N character long subwords  on the source side, and the highest scoring subword's score is used to initialize the decoder as well as the input to the attention mechanism.  This method allows learning which subwords of the input are important for generating the output. By training the models on the same source but different target, we can compare what subwords are important for different tasks and how they relate to each other. We define a similarity metric, a generalized form of the Jaccard similarity, and assign a similarity score to each pair of the three tasks that work on the same source but may differ in target. We examine how these three tasks are related to each other in \goodlangno languages. Our code is publicly available.\footnote{https://github.com/juditacs/deep-morphology}",412
"  Infusing emotions into conversation systems can substantially improve its usability and promote customers' satisfaction. Moreover, perceiving emotions sufficiently is the core premise of expressing emotions. In real-life scenarios, humans can instinctively perceive complex or subtle emotions from multiple aspects, including the emotion flow of dialogue history, facial expressions and personalities of speakers, and then express suitable emotions for feedback. Figure shows the organization of multi-source information in a dialogue graph and the relationship between them.        We presented an application of Soft Patterns -- a finite state automaton parameterized by a neural network -- as the encoder of a sequence-to-sequence model. We show that it is competitive with the popular LSTM encoder on character-level copy and morphological tagging, while providing interpretable patterns.  We analyzed the behavior of \sopa encoders on \morphana, \lemmatization and \copytask by computing the average Jaccard similarity between the patterns extracted from the source side. We found two trends that coincide with linguistic intuition. One is that \lemmatization and morphological analysis require patterns that match less similar subwords than the other two task pairs. The other one is that \copytask and morphological analysis are more similar in languages with rich inflectional morphology.  
"," The success of emotional conversation systems depends on sufficient perception and appropriate expression of emotions. In a real-world conversation, we firstly instinctively perceive emotions from multi-source information, including the emotion flow of dialogue history, facial expressions, and personalities of speakers, and then express suitable emotions according to our personalities, but these multiple types of information are insufficiently exploited in emotional conversation fields. To address this issue, we propose a heterogeneous graph-based model for emotional conversation generation. Specifically, we design a Heterogeneous Graph-Based Encoder to represent the conversation content  with a heterogeneous graph neural network, and then predict suitable emotions for feedback. After that, we employ an Emotion-Personality-Aware Decoder to generate a response not only relevant to the conversation context but also with appropriate emotions, by taking the encoded graph representations, the predicted emotions from the encoder and the personality of the current speaker as inputs. Experimental results show that our model can effectively perceive emotions from multi-source knowledge and generate a satisfactory response, which significantly outperforms previous state-of-the-art models.",413
" Text classification is one of the fundamental tasks in natural language processing  with wide applications such as sentiment analysis, news filtering, spam detection and intent recognition. Plenty of algorithms, especially deep learning-based methods, have been applied successfully in text classification, including recurrent neural networks ,  convolutional networks   . More recently, large pre-training language models such as ELMO , BERT , Xlnet  and so on have also shown their outstanding performance in all kinds of NLP tasks, including text classification.   Although numerous deep learning models have shown their success in text classification problems, they all share the same learning paradigm: a deep model for text representation, a simple classifier to predict the label distribution and a cross-entropy loss between the predicted probability distribution and the one-hot label vector. However, this learning paradigm have at least two problems:  In general text classification tasks, one-hot label representation is based on the assumption that all categories are independent with each other. But in real scenarios, labels are often not completely independent and instances may relate to multiple labels, especially for the confused datasets that have similar labels. As a result, simply representing the true label by a one-hot vector fails to take the relations between instances and labels into account, which further limits the learning ability of current deep learning models.  The success of deep learning models heavily relies on large annotated data, noisy data with labeling errors will severely diminish the classification performance, but it is inevitable in human-annotated datasets. Training with one-hot label representation is particularly vulnerable to mislabeled samples as full probability is assigned to a wrong category. In brief, the limitation of current learning paradigm will lead to  confusion in prediction that the model is hard to distinguish some labels, which we refer as label confusion problem . A label smoothing  method is proposed to remedy the inefficiency of one-hot vector labeling , however, it still fails to capture the realistic relation among labels, therefore not enough the solve the problem.      In this work, we propose a novel Label Confusion Model  as an enhancement component to current deep learning text classification models and make the model stronger to cope with label confusion problem. In particular, LCM learns the representations of labels and calculates their semantic similarity with input text representations to estimate their dependency, which is then transferred to a label confusion distribution . After that, the original one-hot label vector is added to the LCD  with a controlling parameter and normalized by a softmax function to generate a simulated label distribution . We use the obtained SLD to replace the one-hot label vector and supervise the training of model training. With the help of LCM, a deep model not only capture s the relations between instances and labels, but also learns the overlaps among different labels, thus, performs better in text classification tasks. We conclude our contributions as follows:      We propose a heterogeneous graph-based framework to understand dialogue content and fully perceive complex and subtle emotions from multi-source knowledge to generate coherent and emotional response. Experimental results and analysis demonstrate the effectiveness and generalizability of our model, which can be easily adapted to different number of knowledge sources. In the future, we would like to infuse knowledge from more sources and further investigate various relations between them to further improve the quality of responses.  
"," Representing a true label as a one-hot vector is a common practice in training text classification models. However, the one-hot representation may not adequately reflect the relation between the instances and labels, as labels are often not completely independent and instances may relate to multiple labels in practice. The inadequate one-hot representations tend to train the model to be over-confident, which may result in arbitrary prediction and model overfitting, especially for confused datasets  or noisy datasets . While training models with label smoothing  can ease this problem in some degree, it still fails to capture the realistic relation among labels. In this paper, we propose a novel Label Confusion Model  as an enhancement component to current popular text classification models. LCM can learn label confusion to capture semantic overlap among labels by calculating the similarity between instances and labels during training and generate a better label distribution to replace the original one-hot label vector, thus improving the final classification performance. Extensive experiments on five text classification benchmark datasets reveal the effectiveness of LCM for several widely used deep learning classification models. Further experiments also verify that LCM is especially helpful for confused or noisy datasets and superior to the label smoothing method.",414
" Over recent years, various task-oriented conversational agents, such as Amazon Alexa, Apple閳ユ獨 Siri, Google Assistant, and Microsoft閳ユ獨 Cortana, have become more popular in people閳ユ獨 everyday life and are expected to be highly intelligent. For the NLU component, this means that we expect models to perform recognition of the actions and entities within a user閳ユ獨 request with high accuracy. When first training an NLU model on a new language , there is a strong requirement for high quality annotated data that would support the most common user requests across a range of domains. As the modeling space expands to support new features and additional languages, NLU models are regularly re-trained on updated data sets to ensure support for these new functions. The major bottleneck in both of these processes is the labor and cost associated with collecting and annotating new training utterances for every new feature or language.   Recent advances in machine learning methods, including the use of techniques such as transfer learning~ and active learning, can lead to more efficient data usage by NLU models and therefore decrease the need for annotated training data. Additionally, data augmentation models are being widely explored. The advantage of data augmentation is that once synthetic data is generated, it can be ingested into subsequent models without additional effort, allowing for faster experimentation.   NLU models in dialog systems can perform a variety of tasks. In this study, we will focus on three of them: Domain classification  -- identify the domain that the user request belongs to , Intent classification  -- extract actions requested by users , and Named Entity Recognition  -- identify and extract entities  from user requests.  For each utterance we expect our NLU model to output a domain, intent, and set of extracted entities with corresponding tags. For example, if a user requests ``play Bohemian Rhapsody by Queen'', we expect the NLU model to return \{domain: music, intent: play\_song, named\_entities: [, ]\}. We call this output annotation, and the utterance along with annotation is called an annotated utterance. Named entities with corresponding labels are called slots.  For our NLU model to perform well on real-time user requests, we need to train it on a large dataset of diverse annotated utterances. However, there could be some areas of functionality where large datasets for training are not available. To boost model performance in situations where training data is limited, we use synthetic data generated from a small set of unique utterances that cover the basic functionality of the user experience, called Golden utterances. We leverage a Sequence Generative Adversarial Networks  introduced by~\citet{Yu2016SeqGANSG} to generate new utterances from this ``seed'' set, and use these generated utterances to augment training data and evaluate the performance of the classification and recognition tasks. We also investigate how the metrics that we use to evaluate the quality of the generated synthetic data links to the performance boost in the underlying tasks.     In this work, we propose Label Confusion Model  as an enhancement component to current text classification models to improve their performance. LCM can capture the relations between instances and labels as well as the dependency among labels. Experiments on five benchmark datasets proved LCM's enhancement on several popular deep learning models such as LSTM, CNN and BERT.  Our future work include the following directions:  Designing a better LCM structure for computer vision tasks and conducting more experiments on image classification.  Generalizing the LCM method to multi-label classification problems and label distribution prediction.   
"," Data sparsity is one of the key challenges associated with model development in Natural Language Understanding  for conversational agents. The challenge is made more complex by the demand for high quality annotated utterances commonly required for supervised learning, usually resulting in weeks of manual labor and high cost. In this paper, we present our results on boosting NLU model performance through training data augmentation using a sequential generative adversarial network . We explore data generation in the context of two tasks, the bootstrapping of a new language and the handling of low resource features. For both tasks we explore three sequential GAN architectures, one with a token-level reward function, another with our own implementation of a token-level Monte Carlo rollout reward, and a third with sentence-level reward. We evaluate the performance of these feedback models across several sampling methodologies and compare our results to upsampling the original data to the same scale. We further improve the GAN model performance through the transfer learning of the pre-trained embeddings. Our experiments reveal synthetic data generated using the sequential generative adversarial network provides significant performance boosts across multiple metrics and can be a major benefit to the NLU tasks.",415
"  	Encoder-decoder architecture~ has been extensively used in neural machine translation ~. Given a source sentence, an encoder firstly converts it into hidden representations, which are then conditioned by a decoder to generate the target sentence. Attention mechanism~ is very effective in learning the alignment between a source sentence and a target sentence. Hence, attention mechanism is usually used in the architecture to improve its capability, such as capturing long-distance dependencies.  	Similar to traditional machine learning efforts~, some recent approaches in deep learning attempt to improve encoder-decoder architecture with multiple passes of decoding~. NMT refers this to polish mechanism~. Under this scheme, more than one translations are generated for a source sentence and, except for the first translation, each of them is based on the translation from the previous decoding pass. While these methods have achieved promising results, they lack a proper termination policy to the multi-turn process. \citet{xia2017deliberation,zhang2018asynchronous} adopt a fixed number of decoding passes that can be inflexible in deciding the optimal number of decoding passes. \citet{geng2018adaptive} use reinforcement learning ~ to automatically decide the optimal number of decoding passes. However, RL is unstable due to its high variance of gradient estimation and objective instability~. Since these methods may have premature termination or over translation, their potential can be limited.  	 	 To address this problem, we propose a novel framework, Rewriter-Evaluator, in this paper. It consists of a rewriter and an evaluator. The translation process involves multiple passes. Given a source sentence, at every pass, the rewriter generates a new target sequence aiming at improving the translation from prior passes, and the evaluator measures the translation quality to determine whether to terminate the rewriting process. We also propose a prioritized gradient descent  method that facilitates training the rewriter and the evaluator jointly. The essential idea is using a priority queue to improve sampling efficiency by collecting the translation cases that yield low scores from the evaluator for next-pass rewriting. The size of the queue is a few times larger than the batch size. Although Rewriter-Evaluator involves multiple decoding passes, training time using PGD method is comparable to that of training an encoder-decoder~ that doesn't have multiple decoding passes.  	  	 We apply Rewriter-Evaluator to improve the widely used NMT models,  RNNSearch~ and Transformer~. Extensive experiments have been conducted on two translation tasks, Chinese-English and English-German, to verify the proposed method. The results demonstrate that the proposed framework notably improves the performance of NMT models and significantly outperforms prior methods.    In this paper, we evaluate the use of the SeqGAN model for synthetic annotated data generation to boost NLU model performance. We have shown that adding synthetic data to bolster our Goldens can significantly improve DNN model performance in intent classification and named entity recognition tasks. We propose a token-level reward with Monte Carlo search rollout to guide the generator model, that showed better performance when compared with a regular token-level reward implementation, sentence-level reward implementations both with and without Monte Carlo tree search, and with a pure upsampling strategy. We also show that using SeqGAN together with embeddings pre-trained on high-resource domains to generate synthetic data can significantly improve the performance of low-resource domains. Embeddings pre-trained on different tasks can carry over the information they have learned and that can be especially useful in low-resource model building scenarios.      \onecolumn   
"," 	 	Encoder-decoder architecture has been widely used in neural machine translation . A few methods have been proposed to improve it with multiple passes of decoding. However, their full potential is limited by a lack of appropriate termination policy. To address this issue, we present a novel framework, Rewriter-Evaluator. It consists of a rewriter and an evaluator. Translating a source sentence involves multiple passes. At every pass, the rewriter produces a new translation to improve the past translation and the evaluator estimates the translation quality to decide whether to terminate the rewriting process. We also propose a prioritized gradient descent  method that facilitates training the rewriter and the evaluator jointly. Though incurring multiple passes of decoding, Rewriter-Evaluator with the proposed PGD method can be trained with similar time to that of training encoder-decoder models. We apply the proposed framework to improve the general NMT models . We conduct extensive experiments on two translation tasks, Chinese-English and English-German, and show that the proposed framework notably improves the performances of NMT models and significantly outperforms previous baselines.",416
"   Recent advances in open domain question answering  have mostly revolved around machine reading comprehension   where the task is to read and comprehend a given text and then answer questions based on it. However, most recent work in MRC has only been in English \eg\ SQuAD , HotpotQA  and Natural Questions . Significant performance gains and the state-of-the-art  on these datasets are credited to large pre-trained language models .    Multilingual BERT , which is trained on Wikipedia articles from 104 languages and equipped with a 120k shared wordpiece vocabulary, has encouraged a lot of progress on cross-lingual tasks \eg{} XNLI , NER  and QA  by performing zero-shot training: train on one language and test on unseen target languages.  In this work, we focus on multilingual QA and, in particular, on two recent large-scale datasets: MLQA and TyDiQA\footnote{All uses of TyDiQA in our paper refer to the Gold Passage task.}. Both datasets contain English QA pairs but also examples from 13 other diverse languages.  Some examples are shown in Figure . MLQA evaluates two challenging scenarios: 1) Cross-Lingual Transfer   when the question and the context are in the same language, and 2) Generalized Cross-lingual Transfer  when the question is in one language  and the context is in another language .  %In both cases, MLQA is zero-shot because it does not provide training data in any language. \avi{Maybe remove this previous sentence?} % TyDiQA consists of QA examples in English and 8 other languages.  TyDiQA is designed for XLT only. Both datasets are challenging for multilingual QA due to the large number of languages and the variety of linguistic phenomena they encompass .  Ideally, we want to build QA systems for all existing languages but it is impractical to collect manually labeled training data for all of them.  In the absence of labeled data,  suggested several research directions for pushing the boundaries in multilingual QA, including zero-shot QA, exploring data augmentation with machine translation, as well as effective transfer learning. These are avenues we explore in our work in addition to asking the following research questions:\\             1. Is a large pre-trained LM sufficient for zero-shot multi-lingual QA? \\      Prior work proposes zero-shot transfer learning from English SQuAD data  to other languages using only a pre-trained LM and competitive results are achieved  on MLQA  and TyDiQA . We venture beyond zero-shot training by first exploring data augmentation  on top of their underlying model. We achieve this by using translation methodologies  to augment the English training data.       We use machine translation to obtain additional silver labeled data allowing us to improve cross-lingual transfer at a low cost.  Our approach introduces several multilingual extensions to the SQuAD training data: translating just the questions but keeping the context in English, translating just the context but keeping the question in English, and translating the question and the context to other languages. This enables us to augment the original English human-labeled training examples with 14 times more multilingual silver-labeled QA pairs.\\           2. Can we bring language-specific embeddings in multi-lingual LMs closer for effective cross-lingual transfer?\\         %To do better MLQA, we believe it is important that the model      Our hypothesis is that we can make the cross-lingual QA transfer more effective if we can bring the embeddings in a multilingual pre-trained LM closer to each other in the same semantic space. To answer a question in French it should suffice to train the system on Hindi and not be necessary to train a system on the target language:  hence, French and Hindi should look as if they are the same language.     We propose two approaches to explore cross-lingual transfer:              In our first approach, we propose a novel strategy based on adversarial training  . We investigate how the addition of a language-adversarial task during QA finetuning for a pretrained LM can significantly improve the cross-lingual transfer performance while causing the embeddings in the LM to become less language-dependent.           In our second approach, we develop a novel Language Arbitration Framework  to consolidate the embedding representation across languages using properties of the translation.         We train additional auxiliary tasks \eg{} making sure an English question and its translation in Arabic produces the same answer when they see the same input context in Spanish. The intuition behind language arbitration is that while we are training the model on English and translated examples, the proposed multi-lingual objectives bring the language-specific embeddings closer to the English embeddings.\\               Overall, our main contributions in this paper are as follows:                 In this paper, we propose the task of citation sequence prediction. For this, we introduce a dataset of scholary documents based on a dynamic citation graph evolving of  years, starting from a single node growing to a large graph. We further study the effect of temporal and topological information, and propose a model to benefit from both information . Our results show that utilizing both the temporal and topological information is superior to only utilizing either the temporal or topological information. Using the proposed model, we study the effect of different features, to identify which information is most predictive of a paper's citation count over time. We found author information to be predictive and informative over time.  In future work, the impact of training a single GCN on the dynamic graph could be explored, since the error over time of the GCN is deteriorating fast.   
"," Prior work on multilingual question answering has mostly focused on using large multilingual pre-trained language models  to perform zero-shot language-wise learning: train a QA model on English and test on other languages. In this work, we explore strategies that improve cross-lingual transfer by bringing the multilingual embeddings closer in the semantic space.  Our first strategy augments the original English training data with machine translation-generated data. This results in a corpus of multilingual silver-labeled QA pairs that is 14 times larger than the original training set. In addition, we propose two novel strategies, language adversarial training and language arbitration framework, which significantly improve the  cross-lingual transfer performance and result in LM embeddings that are less language-variant. Empirically, we show that the proposed models outperform the previous zero-shot baseline on the recently introduced multilingual MLQA and TyDiQA  datasets.",417
"   % \subsection{Problem Statement and Motivation}  Researchers' ability to automate natural language processing has grown exponentially over the past few years, particularly with the advent of the Transformer architecture . Despite the fact that recent machine learning methods achieve impressive and almost human-level performance on tasks such as dialogue modeling  and natural language generation , many intelligent voice assistants still rely on rule-based architectures and cached responses in open domain dialogue . This is primarily due to the lack of controls in deep learning architectures for producing specific phrases, tones, or topics, which makes these models inherently unpredictable and therefore too risky for most entities - corporate or otherwise - who wish to deploy public-facing intelligent agents. For example, it is often desirable for a conversational agent to maintain a specific identity  throughout an exchange of dialogue and it is currently impossible to condition deep learning algorithms to maintain a coherent identity across dialogue without training them on highly specialized  data sets. Fine-tuning on these specialized data sets comes with an additional, significant cost: it can lead to catastrophic forgetting of the language model . Despite this aspect of fine-tuning, current state-of-the-art methods  require fine-tuning  of the entire network when their original data set proves unsuitable for a given task , even if the language being modeled is the same across tasks. Furthermore, models produced by current methods are almost entirely uninterpretable and therefore generally difficult to test for egregious failure cases.  % \subsection{Solution Overview}  In this paper, we address both the issue of content control as well as that of catastrophic forgetting induced by fine-tuning. We define `content control' as being able to command a network to either incorporate or eschew an exact word, phrase, topic, style, or sentiment in its output, and therefore attempt a more granular level of control than the purely topic/style-level control that has been published in recent literature . We also introduce an alternative to fine-tuning neural language models and demonstrate through experimentation that the high-cost of overwriting model weights through fine-tuning  often fails to induce the desired behavior in generalized settings.  %is inspired by the ``No Free Lunch"" theorems introduced by Wolpert \& Macready  in that we seek to avoid training a neural network to simultaneously model language and act on explicit commands.  Instead,  we recast the problem of control in natural language generation as one of combining separate models - one of the natural language itself and one of high-level command responses - to produce desired linguistic output. In doing so, we develop a framework for interpreting and subsequently controlling the hidden activations of a pretrained neural network without any adjustments being made to the pretrained model. This framework is biologically consistent with the findings of Knutson et al., who discovered that neural pathways in humans are inhibited by other neuron clusters , and has applications to other neural network architectures and questions outside the domain of controllable text generation.     In this work, we highlight open challenges in the existing multilingual approach by  and . Specifically, we show that large pre-trained multi-lingual LMs are not enough for this task. We produce  several novel strategies for multilingual QA that go beyond zero-shot training and outshine the previous baseline built on top of \mbert{}. We present a translation model that has 14 times more training data. Further, our AT and LAF strategies utilize translation as data augmentation to bring the language-specific embeddings of the LM closer to each other. These approaches help us significantly improve the cross-lingual transfer. Empirically, our models demonstrate strong results and all approaches improve over the previous ZS strategy. We hope these techniques spur further research in the field such as exploring other multilingual LMs and invoking additional networks on top of large LMs for multilingual NLP. 
"," %   Current solutions to the problem of controlling generative neural language models are usually formulated under a training paradigm in which the language model is trained to simultaneously model natural language and respond to high-level commands. We recast the problem of control in natural language generation as that of learning to interface with a pretrained language model to generate desired output, just as Application Programming Interfaces  control the behavior of programs by altering hyperparameters. In this new paradigm, a specialized neural network  learns to interface with a pretrained language model by manipulating the hidden activations of the pretrained model in real time to produce desired outputs, such that no permanent changes are made to the weights of the original language model.     It is notoriously difficult to control the behavior of artificial neural networks such as generative neural language models. We recast the problem of controlling natural language generation as that of learning to interface with a pretrained language model, just as Application Programming Interfaces  control the behavior of programs by altering hyperparameters. In this new paradigm, a specialized neural network  learns to interface with a pretrained language model by manipulating the hidden activations of the pretrained model to produce desired outputs. Importantly, no permanent changes are made to the weights of the original model, allowing us to re-purpose pretrained models for new tasks without overwriting any aspect of the language model. We also contribute a new data set construction algorithm and GAN-inspired loss function that allows us to train NPI models to control outputs of autoregressive transformers. In experiments against other state-of-the-art approaches, we demonstrate the efficacy of our methods using OpenAI闁炽儲鐛 GPT-2 model, successfully controlling noun selection, topic aversion, offensive speech filtering, and other aspects of language while largely maintaining the controlled model's fluency under deterministic settings. %Finally, we describe the ethical implications of this work. %   Applications for this approach include re-purposing a pretrained model  for a new task without a specialized data set in the problem domain. We present experimental results from training several NPI models to control the outputs of OpenAI's GPT-2 language model \cite{openaiGPT2}, as well as a novel data curation approach in which hidden activations of an uninterpretable pretrained model are associated with specific outputs. Finally, we describe potential methods whereby NPIs might be leveraged to interpret the inner workings of pretrained networks, as well as the related ethical implications of this work.",418
"  Emotion analysis of user-generated content  available on the web provides insights toward making meaningful decisions. Micro-blog platforms such as Twitter has gained profuse popularity for textual content holding people's opinions. The past decade has seen the active growth in emotion analysis models in many domains. Recently there has been an increasing interest in analysis of emotions of informal short texts such as tweets. In this paper, we introduce and analyze a system to accurately identify the emotions of the individual tweets with the associated intensities~\footnote{Intensity refers to the degree or amount of an emotion}.  % explain why it is important to analyze emotions  Analyzing emotions in social media such as twitter benefits society in a number of ways. Policymakers can use emotional information in social media to accurately identify concerns of people when making decisions. Monitoring social media for health issues benefits not only public health but also government decision makers. Furthermore, organizations can monitor opinion of the public on their products and services to provide better service to the society. Once emotions are recognized, emotion intensity can be used to prioritize the major concerns.  Studies in emotion analysis have often focused on emotion classification. However, emotions may exhibit varying levels of intensities. Here, emotion intensity can be defined as the degree or the intensity of particular emotion felt by the speaker. Additionally, we may observe multiple emotions simultaneously in the same tweet with varying intensities.   One purpose of this study is to develop a model to accurately identify the emotions and associated emotion intensities for a given tweet. In this paper, we propose a transfer learning approach backed by a neural network classifier and a regressor. Although the proposed neural network alone is inadequate to beat the benchmark, we show that features learned when training the above neural networks can be used to improve the overall performance when combined with other features.  Another purpose of this study is to explain how the input word level features affect the features extracted by the neural network.  % [complete the actual findings here] The findings should make an important contribution in understanding how features are used in a neural network and to effectively select features to improve the effectiveness of extracted features.   Our main contributions of this study:   \pagebreak  Major challenge in using deep learning to train emotion intensity prediction models is the lack of large labeled datasets. More recently, emoji and hashtags were used in studies to create large naturally labeled datasets. However, it is not possible to use a similar technique to obtain the intensity of emotions. Furthermore, creating a large dataset manually is time consuming and expensive.  are some existing datasets for emotional intensity prediction. Due to the limited amount of task-specific training data the previous researches have opted for transfer learning approaches~\citet{baziotis2018ntua, duppada2018seernet} and traditional machine learning. However, in this paper we argue that even with reasonable size dataset we can train a neural network to obtain good performance provided that there is proper regularization. Additionally, we show that features learned when training the neural network can be combined with other features to improve the overall performance of emotion intensity prediction.   % [explain methodology in brief]  % } \end{table}  In \S, we outline related works on sentiment and emotion mining. Next, in \S we will discuss the datasets used in this study. After, we introduce the background and our methodology in \S and \S accordingly. Then, in \S we will discuss the evaluation results. Finally, we will conclude this paper in \S.      The key contribution and insight of this paper is the use of a small, independently trained neural network called a Neural Programming Interface  to influence the behavior of a large pretrained model. In contrast to fine-tuning, this approach retains the linguistic breadth and versatility of the original model, allowing the possibility to control for multiple factors either in sequence or simultaneously, and to induce behavior in the language model contrary to the patterns baked into linguistic training data . We have demonstrated that this approach can be used to produce specific words within a GPT-2 model's output text, to pivot away from a specific word, and to create a linguistic aversion to offensive speech. We believe that future avenues for this research include investigations of the use for NPI models in network interpretability, regulation, and bias mitigation.  
"," In this paper, we present an experiment on using deep learning and transfer learning techniques for emotion analysis in tweets and suggest a method to interpret our deep learning models. The proposed approach for emotion analysis combines a Long Short Term Memory  network with a Convolutional Neural Network . Then we extend this approach for emotion intensity prediction using transfer learning technique. Furthermore, we propose a technique to visualize the importance of each word in a tweet to get a better understanding of the model. Experimentally, we show in our analysis that the proposed models outperform the state-of-the-art in emotion classification while maintaining competitive results in predicting emotion intensity.",419
"  Online reviewing for businesses becomes more and more important nowadays, where customers can publish their reviews for businesses, and other potential customers or shop owners can view them. Positive feedback from customers may prosper the store businesses, while negative one could have opposite consequences. Yelp, one of the largest company founded in 2004 for publishing crowd-sourced reviews about businesses, provides one open dataset, Yelp Open Dataset , which has tremendously many data about businesses, reviews, and users. Such dataset has been proven to be a good material for personal, educational, and academic purposes.  Among multiple tasks on the Yelp Open Dataset, predicting ratings for restaurants based their reviews is one of fundamental and important tasks. This task can help Yelp classify reviews into proper groups for its recommendation system, detect anomaly reviews to protect businesses from malicious competitions, and assign rating to texts automatically.  Yelp review rating prediction can be done in multiple ways, such as sentiment analysis and 5-star rating classification. In this paper, we will focus on rating prediction for restaurants based only on their review texts. This task can be viewed as a multiclass classification problem, where the input is the textual data , and output is the predicted class . We will apply both machine learning and deep learning models. After analyzing data distribution, splitting datasets, and extracting features, we will use four machine learning methods, including Naive Bayes, Logistic Regression, Random Forest, and Linear Support Vector Machine  . Then we will focus on four transformer-based models, including BERT , DistilBERT , RoBERTa , and XLNet , where several different architectures will be tried with hyperparameter tuning. This project is done on \href{https://colab.research.google.com/}{Google Colab}, where multi-processors and GPUs are available. The code is publicly available at GitHub .      In this study, we propose a simple yet effective model for emotion classification and emotion intensity prediction in Tweets while suggesting a method to explain and visualize a trained DNN. We utilized a neural network with LSTM layer followed by a convolution layer with max-pooling for emotion category classification as well as emotion intensity prediction. We extend this work by transferring features from above models and two state-of-the-art models trained for different tasks to a XGBoost regressor to predict the emotion intensity in Tweets more accurately. Moreover, we suggest a technique to visualize and interpret the feature importance of trained DNNs for emotion intensity prediction. In the future, we plan on experimenting with using attentive mechanisms to improve the emotion intensity prediction further. Our models outperformed existing state-of-the-art models for emotion classification and in predicting fear and anger emotion intensities, while maintaining a competitive results in predicting other emotions.  
","    We predict restaurant ratings from Yelp reviews based on Yelp Open Dataset. Data distribution is presented, and one balanced training dataset is built. Two vectorizers are experimented for feature engineering. Four machine learning models including Naive Bayes, Logistic Regression, Random Forest, and Linear Support Vector Machine are implemented. Four transformer-based models containing BERT, DistilBERT, RoBERTa, and XLNet are also applied. Accuracy, weighted $ F_1 $ score, and confusion matrix are used for model evaluation. XLNet achieves 70\% accuracy for 5-star classification compared with Logistic Regression with 64\% accuracy.",420
"  Language processing requires tracking information over multiple timescales. To be able to predict the final word ``timescales"" in the previous sentence, one must consider both the short-range context  and the long-range context . How do humans and neural language models encode such multi-scale context information? Neuroscientists have developed methods to study how the human brain encodes information over multiple timescales during sequence processing. By parametrically varying the timescale of intact context, and measuring the resultant changes in the neural response, a series of studies  showed that higher-order regions are more sensitive to long-range context change than lower-order sensory regions. These studies indicate the existence of a ``hierarchy of processing timescales"" in the human brain. More recently, \citet{chien2020constructing} used a time-resolved method to investigate how the brain builds a shared representation, when two groups of people processed the same narrative segment preceded by different contexts. By directly mapping the time required for individual brain regions to converge on a shared representation in response to shared input, we confirmed that higher-order regions take longer to build a shared representation. Altogether, these and other lines of investigation suggest that sequence processing in the brain is supported by a distributed and hierarchical structure: sensory regions have short processing timescales and are primarily influenced by the current input and its short-range context, while higher-order cortical regions have longer timescales and track longer-range dependencies .  How are processing timescales organized within recurrent neural networks  trained to perform natural language processing? Long short-term memory networks   have been widely investigated in terms of their ability to successfully solve sequential prediction tasks. However, long-range dependencies have usually been studied with respect to a particular linguistic function , and there has been less attention on the broader question of how sensitivity to prior context -- broadly construed --  is functionally organized within these RNNs. Therefore, drawing on prior work in the neuroscience literature, here we demonstrate a model-free approach to mapping processing timescale in RNNs. We focused on existing language models that were trained to predict upcoming tokens at the word level  and at the character level . The timescale organization of these two models both revealed that the higher layers of LSTM language models contained a small subset of units which exhibit long-range sequence dependencies; this subset includes previously reported units  as well as previously unreported units.  After mapping the timescales of individual units, we asked: does the processing timescales of each unit in the network relate to its functional role, as measured by its connectivity? The question is motivated by neuroscience studies which have shown that in the human brain, higher-degree nodes tend to exhibit slower dynamics and longer context dependence than lower-degree nodes . More generally, the primate brain exhibits a core periphery structure in which a relatively small number of ``higher order閳 and high-degree regions  maintain a large number of connections with one another, and exert a powerful influence over large-scale cortical dynamics . Inspired by the relationships between timescales and network structure in the brain, we set out to test corresponding hypotheses in RNNs:  Do units with longer-timescales tend to have higher degree in neural language models? and  Do neural language models also exhibit a ``core network"" composed of functionally influential high-degree units? Using an exploratory network-theoretic approach, we found that units with longer timescales tend to have more projections to other units. Furthermore, we identified a set of medium-to-long timescale ``controller"" units which exhibit distinct and strong projections to control the state of other units, and a set of long-timescale ``integrator units"" which showed influence on predicting words where the long context is relevant. In summary, these findings advance our understanding of the timescale distribution and functional organization of LSTM language models, and provide a method for identifying important units representing long-range contextual information in RNNs.     In this paper, we predicted ratings from Yelp review texts. Yelp Open Dataset was used. The imbalanced data distribution was presented, and a balanced training dataset was built. Four machine learning models including Naive Bayes, Logistic Regression, Random Forest, and Linear Support Vector Machine were used based on numerical features from tf-idf vectorizer. Four transformer-based models including BERT, DistilBERT, RoBERTa, and XLNet were also trained and tested on the textual data. Comparisons between models and hyperparameters were done, and 64\  accuracy score for the machine learning model and 70\  accuracy score for the transformer-based one were achieved on the testing set.   Transformer-based models were summarized and experimented. Cased, large BERT models were found giving better performances than the uncased, base ones. DistilBERT has a faster computation speed with a bit lower metrics, while RoBERTa and XLNet give higher evaluation metrics with more computational resources required.  We hope our work could give some inspirations and insights for further work in Yelp review rating prediction based on machine learning and deep learning models.   ----------------------------------------------------------- {\small   } 
"," In the human brain, sequences of language input are processed within a distributed and hierarchical architecture, in which higher stages of processing encode contextual information over longer timescales. In contrast, in recurrent neural networks which perform natural language processing, we know little about how the multiple timescales of contextual information are functionally organized. Therefore, we applied tools developed in neuroscience to map the ``processing timescales闁 of individual units within a word-level LSTM language model. This timescale-mapping method assigned long timescales to units previously found to track long-range syntactic dependencies. Additionally, the mapping revealed a small subset of the network  with long timescales and whose function had not previously been explored. We next probed the functional organization of the network by examining the relationship between the processing timescale of units and their network connectivity. We identified two classes of long-timescale units: ``controller闁 units composed a densely interconnected subnetwork and strongly projected to the rest of the network, while ``integrator闁 units showed the longest timescales in the network, and expressed projection profiles closer to the mean projection profile. Ablating integrator and controller units affected model performance at different positions within a sentence, suggesting distinctive functions of these two sets of units. Finally, we tested the generalization of these results to a character-level LSTM model and models with different architectures. In summary, we demonstrated a model-free technique for mapping the timescale organization in recurrent neural networks, and we applied this method to reveal the timescale and functional organization of neural language models.\footnote{The code and dataset to reproduce the experiment can be found at \url{https://github.com/sherrychien/LSTM_timescales}}",421
"    We summarize our contribution as follows:      We demonstrated a new method for mapping the timescale organization in recurrent neural language models. Using this method, we mapped the timescale distributions of units within word-level and character-level LSTM language models, and identified a small set of units with long timescales. We then used network analyses to understand the relationship between the timescale of a unit and its connectivity profile, and we distinguished two subsets of long-timescale units with seemingly distinctive functions. Altogether, we proposed methods combining timescale and connectivity analyses for discovering timescale and functional organization in language models.  The units with longer processing timescales included some units whose role in long-range language dependencies had already been established , but almost all of the long timescale units are of unknown function. The timescale mapping procedure described here provides a model-free method for identifying nodes necessary for long-range linguistic and discursive processes . Future studies of these neural language models could focus on the specific linguistic information tracked by the long-timescale units, especially the ``controller'' units which control the information flow of other units in the network.   The current study measured unit timescales using a simple token distance, and so the method may be applied to understanding recurrent neural nets beyond language models. It will be insightful for future studies to investigate whether the processing timescales characterized via token distance are comparable to those measured using functional measures, such as syntactic distance. Relatedly, while we explored the timescale variance under several context conditions, a more thorough investigation will be needed to examine how the timescales of individual units may vary at different positions within a sentence, both in terms of token location and syntactic location.  Processing timescales may exhibit an analogous hierarchical organization in LSTMs and in the human cerebral cortex: in both cases, a subset of nodes with high degree and high inter-connectivity express unusually long timescales. More detailed testing of this apparent correspondence is required, however, because units within an LSTM layer are not spatially embedded and constrained as in biological brains, and thus the LSTM units do not express a spatially graded timescale topography.  \subsubsection*{Acknowledgments} C.J.H and H-Y.S.C gratefully acknowledge the support of the National Institutes of Mental Health         \section{Appendix}  \subsection {Units excluded from timescale analysis}   We excluded 1 unit in the WLSTM model and 5 units in CLSTM model which were not properly fit using the logistic function; we further excluded 14 units in the WLSTM model and 7 units in the CLSTM model which either did not show a non-zero activation difference before the shared segment started, or whose activation differences increased when started to process the shared segment. After these exclusions, 635 units remained in the WLSTM and 1012 units remained in the CLSTM for further analysis.  \subsection {Timescale analyses across different datasets and context conditions}  \subsubsection {Wikipedia test dataset}   The Anna Karenina corpus used in the current study has a different linguistic structure from the Wikipedia corpus on which the WLSTM and CLSTM models were trained. Although we analyzed only the Anna Karenina sentences with low perplexity, it was important to test the robustness of our results across datasets. Thus, we mapped the timescale of each unit using the Wikipedia test set, as used by \citet{gulordava2018colorless}. Specifically, we sampled 500 long sentences containing ``, and"" for the Intact Context condition. As before, we generated sentences by preceding the ``shared input'' segment  with either the original prior context segment, or a randomly chosen prior context segment. Same as the original analysis, we then replaced the context segment with 30 context segments randomly sampled from other parts of the test set for generating the Random Context condition. The mapped timescales using the Wikipedia test set were highly correlated with the novel corpus, suggesting the robustness of unit timescales .   \subsubsection {Timescales measured in the middle of a sentence}   To examine how the timescales of individual units may vary across different positions in a sentence, we varied the location of the segmentation point. Instead of using the conjunction  as the segmentation point, we chose an arbitrary segmentation point: the 15th token of a long sentence, to separate context segment and shared input segment. In the Random Context condition, we replaced the context segment with the first 15 tokens from other sentences of the corpus. We found that the unit timescales were highly correlated with the condition where we used the conjunction as the segmentation point with several units shift their timescales to either directions .  This analysis was conducted using Wikipedia test set.   \subsubsection {Timescale reset at the beginning of a sentence}   To examine if the timescales of individual units can flexibly reset at the beginning of a sentence, we conducted the same timescale analysis but using a ``full stop"" as the segmentation point instead of the conjunction ``, and"". Thus, if the original test string was ``The girl kicked the call, and the boy caught it"", then the full-stop version of the test string would be ``The girl kicked the ball. The boy caught it."" In this setting, the context segment and shared input segment in the Intact Context condition are two consecutive sentences. To ensure the temporal dependence between the context segment and shared input segment, we sampled 100 consecutive sentence pairs from the Anna Karenina corpus. Note that this is not possible using the Wikipedia test set from \citet{gulordava2018colorless}, because that set is composed of unrelated sentences. The Random Context condition was generated by replacing the first sentence with randomly sampled sentences from other parts of the novel. We found that when using ``full stop"" to segment context and shared input, most units in the network showed timescale near 0, indicating near-zero dependence on the linguistic context from the text preceding the full stop . This suggests that the units in LSTM tend to ``reset"" their context representation at the beginning of a sentence.   \subsubsection {Context representation shaped by individual words }   Inspired by the token-shuffling procedure of \citet{khandelwal2018sharp}, we explored whether the context representations of individual units in the LSTM were shaped by individual words, rather than coherent sequences of words. For this analysis, instead of replacing the context with syntactically structured segments from other part of the corpus, we generated the ``random context"" by shuffling the order of words within the context segment. We then mapped the unit timescales as before, by examining the unit activation difference as a function of the distance from the onset of shared input. Intriguingly, we found that most of the units showed similar timescales across the context-replacement and context-shuffling procedures . This suggests that the context representations in LSTMs largely depend on the presence of individual words in the context, rather than their appearance within coherent linguistic sequences. However, we did observe a subset of units  whose timescales were longer when context was replaced rather than shuffled. For this subset of units, the ability to maintain a representation of prior context over many tokens depends on that prior context being a coherent linguistic sequence. This subset of units are a promising target for future studies of syntactic representations in LSTMs.  \subsection {Identifying strong hidden-to-gate projections}  First, for each hidden unit, we concatenated the corresponding rows in the  and  matrices, to generate a single ``hidden-to-gate"" projection vector for that hidden unit. Next we we z-scored the vector to get standardized projection values from that unit to all other units in the network. Using z-score 5 as criterion, we identified a total of 258 ``strong projections"" from all hidden units to the input gate and forget gate in the WLSTM. The projection strength of each unit was then calculated based on its number of ""strong projections"" . Although the criterion z-score was selected to better visualize the results in Figure , different criteria did not change the results that units with longer timescales have more strong projections. For example, using z-score 3 as threshold we obtained corr = 0.30, p0.001; z-score 4 we obtained corr = 0.35, p0.001.  Next, we identified the edges corresponding to the top 258 magnitude weight-values within the combined  and  matrices. Together, these edges formed a  ""strong-projection network"". Finally, we used k-core analysis to identify the main core of the strong-projection network. This main core composed our ""controller units"" .   Using the same criteria and method, we identified a total of 390 ``strong projections"" from all hidden units to the input gate and forget gate in the CLSTM. We then extracted the top 390 weight values from the weight matrices to construct a ``strong-projection network"" and again identified the main core network, composed the ``controller units"" for the CLSTM model    \subsection {Ablation analyses on putative controller and integrator units}  To examine the non-trivial roles of the controller and integrator units identified in the word-level LSTM model, we performed a preliminary group ablation analysis to look at how ablating the controller units influences model performance on predicting the next token, relative to the ablation of a random set of units. Specifically, since long-timescale integrator units should have most effect predicting tokens at the later part of the sentences , we examined the model performance on predicting tokens at two different positions:  all the tokens regardless of their positions in the sentences , and  the last tokens of sentences .   We evaluated the effects of ablation on model performance by measuring the differences of probabilities  assigned to the target words . Ablation effects for controller units  and integrator units  were compared against a baseline of ablating the same number of randomly-selected units from layer 2 of the LSTM . We used the test corpus used by \citet{gulordava2018colorless} and measured the average performance of each model across 100 text-batches, randomly sampled from the Wikipedia test dataset. Each text-batch was composed of 1000 tokens that start at the beginning of a sentence.  In the ``All tokens"" condition, we calculated the P for every token in the tested text, while in the ``Final tokens"" condition, we calculated P only at the last token of every sentence . We then average the P in both conditions across text-batches to get a mean performance difference between the ablated model and the intact model.   Ablating controller units reduced the probabilities assigned to the target words, more so than ablating random units . In contrast, ablating integrator units reduced the probabilities less than ablating random units . We hypothesized that that the integrator units mostly influence the model's prediction performance for tokens where long-range information is especially relevant, such as in the later portions of clauses and sentences. Consistent with this, we found that, when we examined the ablation effects only for tokens in the final position of a sentence, ablating integrator units reduced the probabilities more than ablating random units . Interestingly, ablating controller units reduced the probability of sentence-final targets less than random units .  In summary, these ablation results indicate a non-trivial functional role for the controller and integrator units, despite the fact that each subset of units is composed of only 10 amongst 650 total hidden units. Also, the putative controller and integrator sets appear to have distinctive roles within the WLSTM, with the controllers supporting accurate predictions overall, while the integrator units appear to boost accurate predictions at the end of sentences.  \subsection {Mapping the timescale organization in a GRU language model}   \subsubsection {Training} To explore whether the timescale mapping methods, and our findings, may generalize to other model architectures, we trained and studied a word-level GRU language model .  As far as possible, we applied similar parameters in the GRU as were used for the LSTM by \citet{gulordava2018colorless}: the same Wikipedia training corpus, the same loss function , and the same hyperparameters except for a learning rate initialized to 0.1, which we found more optimal to train the GRU. The GRU model also had two layers, with 650 hidden units in each layer.  We trained the GRU model for 30 epochs, at which point the GRU converged to a validation perplexity of 118.36. Note that since we adapted similar training settings as were used for training the LSTM model by Gulordava et al. without model-specific optimization, the perplexity is higher than that of the LSTM model reported in \citet{gulordava2018colorless} . We then analyzed the timescale of its hidden units using the same method as was used for analyzing the LSTMs, and using the test data derived from the training Wikipedia corpus.  \subsubsection {Timescale organization of a GRU model} Similar to the LSTM model of Gulordova et al, the majority of the units in the GRU also showed shorter timescales. More specifically, we found:  the second layer of the GRU model was more sensitive to prior context than the first layer, as in the LSTM ;  the distribution of timescales across units was similar in the GRU and LSTM, although the GRU showed a more right-skewed distribution with a larger proportion of short-timescale units .   \subsubsection {Timescale versus network connectivity in a GRU model} We also performed the timescale vs. network connectivity analyses on the GRU model. Because the update of hidden states in GRU are controlled by the reset and update gate, we measured the projection patterns of hidden units by analyzing the matrix of combined hidden-to-update-gate and hidden-to-reset-gate weights. In contrast to the LSTM models, hidden units in the GRU that we trained did not show a relationship between longer timescales and stronger hidden-to-gate projections . Moreover, when using k-core analysis to identify subunits of interconnected high-degree units, the core network in the GRU contained many units with long to short timescales. Interestingly, when we visualized the position of the k-core units in the MDS space, they tended to locate at the edge of the space, similar to what we found in LSTM. This indicates that, as in the LSTM, the core units in the GRU have distinctive profiles, distant from one another and from other units in the network . However, we did not observe the pattern of ``integrator units"" in the GRU as in the LSTM.  These apparent similarities and differences between LSTM and GRU are intriguing, but we emphasize that  the perplexity of this GRU model is much higher than the LSTM, due to the sub-optimal parameter settings, and that  comparing the LSTM and GRU connection patterns is not straightforward, as the overall distribution of weights is different. Further work will be required to determine comparable thresholds for 閳ユ笩trong閳 projections and 閳ユ笁igh-degree units閳 in each case. As we noted in the manuscript and above, the connectivity results are exploratory; however, we believe that the GRU analysis demonstrates how these methods can be extended to map and compare the functional organization of language models of different architecture.   Finally, we note that when conducting the timescale analysis on an incompletely trained GRU model , the timescale distribution was more right-skewed  than the better-trained GRU . Altogether, these results suggest that the long-timescale units in GRU were gradually formed during the training process.    \subsection {Mapping the timescale organization in a word-level LSTM with different hidden size}   To examine whether the number of hidden units in the model would affect the timescale organization in an LSTM, we trained another 2-layer word-level LSTM model with the same Wikipedia corpus and similar parameter settings as in \citet{gulordava2018colorless}, but with only 100 hidden units in each layer. We called this model LSTM-100. We trained the model for 56 epochs until the model converged to a validation perplexity 98.75, and conducted the same analysis as described in the main text to map the timescales of LSTM-100. Because LSTM-100 have overall less weight connections, we use z-score 3 as criteria to determine the ``strong"" hidden-to-gate projections for connectivity analyses.  Regarding the timescale distribution in LSTM-100, we found that the results were similar to the 650-unit word-level LSTM model, in that:  the second layer of LSTM-100 showed more context sensitivity than the first layer, and  although it was difficult to quantitatively compare the unit-level timescale distribution between the LSTM-100 model and the LSTM with 650 units, they both contain a similarly small subset of long-timescale units. .  We did not observe a significant correlation between the unit timescale and number of strong projections generated by each unit in the LSTM-100 model: the long-timescale units in the LSTM-100 did not have more connections than short-timescale units. When visualizing the MDS space of connectivity similarity of LSTM-100, the ``controller units"" identified using the k-core analysis were located in the edge of the space, similar to the 650-unit LSTM model. Interestingly, we observed a subset of long-timescale units in the center of the MDS space, analogous to the ``integrator units"" found in the 650-unit LSTM model. Altogether, the pattern of ``integrator units"" might be a commonly evolved feature that is shared between LSTM model architectures, but not with GRU architectures.     \counterwithin{figure}{section} \renewcommand{\thefigure}{A.\arabic{figure}} \setcounter{figure}{0}       \                    
"," Keyphrase Generation  is the task of generating central topics from a given document or literary work, which captures the crucial information necessary to understand the content. Documents such as scientific literature contain rich meta-sentence information, which represents the logical-semantic structure of the documents.  However, previous approaches ignore the constraints of document logical structure, and hence they mistakenly generate keyphrases from unimportant sentences. To address this problem, we propose a new method called Sentence Selective Network  to incorporate the meta-sentence inductive bias into KG. In SenSeNet, we use a straight-through estimator for end-to-end training and incorporate weak supervision in the training of the sentence selection module. Experimental results show that SenSeNet can consistently improve the performance of major KG models based on seq2seq framework, which demonstrate the effectiveness of capturing structural information and distinguishing the significance of sentences in KG task.",422
"   % With the recent development of end-to-end text-to-speech  system, the synthesised speech has achieved high intelligibility and quality in various languages . Recently neural network based text-to-speech  systems have achieved certain success in prosody and naturalness of synthesized speech over conventional methods .  % Because Chinese is non-alphabet and its character set is very large, grapheme-to-phoneme  is essential when hiring end-to-end model in Chinese . By applying encoder-decoder framework with attention , these systems can directly predict speech parameters from graphemes or phonemes by learning acoustic and prosodic patterns via a flexible mapping from linguistic to acoustic space.  % But they still can only model part of prosody structural information from raw text  because of their limited model capacity, resulting poor expressiveness even prosody errors. % V_1021But they still can only model part of prosody structural information from raw text  resulting in poor expressiveness even prosody errors. However, the learnt prosodic patterns only contain part of prosodic structural information , resulting in poor prosody and naturalness performance even improper prosody.  % So additional prosody structure information is important to improve the naturalness of synthesized speech for text-to-speech system. % V5: So adding prosody information, such as prosody structure annotations, in encoder-decoder based models is important to improve the expressiveness of synthesized speech in TTS systems. % The G2P module converts the text input into a sequence of phonemes with tones, after which the intelligibility and naturally of synthesised Chinese speech can perform better than the conventional TTS . % However, the limited coverage of phoneme permutation in training data causes the decline of ability to predict prosody, resulting in unnatural prosody and unexpected pause.   %   % V4: There are many attempts to improve the prosody prediction ability of TTS system by introducing prosody structure information explicitly. % V5: Prosody structure annotations have been successfully applied in TTS systems to improve expressiveness. % V1020: To improve expressiveness of synthesized speech, directly adding prosodic structure annotations, such as Tones and break indices  labels  and The MATE meta-scheme % v_1021:To improve expressiveness of synthesized speech, adding prosodic structure annotations such as tones and break indices  labels  or other prosodic structure annotation  to input sequence of encoder-decoder based models has been proposed. To further improve prosody and naturalness of synthesized speech, adding prosodic structure annotations such as tones and break indices  labels  or other prosodic structure labels  to the input sequence of neural network based TTS models has been proposed. Prosodic structure annotations need to be subjectively labeled from speech, which is time-consuming.  Although these annotations can be automatically annotated by training another prosodic structure prediction model , the accuracy of predicted prosodic structure labels is still limited by using subjectively labeled annotations as the ground-truths. The high correlation between syntactic structure and prosodic information has been proved by successful syntactic-to-prosodic mapping . % V1020: The syntactic parsing models trained with a large text database with rich grammatical structure  provide text in TTS dataset with usefully syntactic structure information. A set of rule-based syntactic features such as part-of-speech  and positions of the current word in parent phrases are proposed and used in hidden Markov model  based acoustic model . % So subjective labeled prosodic structure annotations can be replaced with syntactic structure information, which obtained from text without referring to speech. % In hidden markov model  based acoustic model, a set of rules to create syntactic features including part of speech  and positions of the current word in parent phrases are hired as syntactic structure information to improve prosody and naturalness exceeds prosodic structure annotations in comprehensiveness and granularity . % This provides us with another method to implicitly improve prosody using syntactic structure information, which exceeds using prosody structure information explicitly in comprehensiveness and granularity.  % Early in the hidden markov based TTS model, rich syntactic context instead of prosody structure information is used to improved prosody of synthesized . % The word relation based features  proposed by  are prior features, which require expert knowledge to be designed. % to explore syntactic information from parse tree, to improve the generalization of synthesised speech. To utilize more syntactic structure information, phrase structure based feature  and word relation based feature  are proposed in neural network based TTS . PSF and WRF expand the set of syntactic features used in HMM model. More features such as highest-level phrase beginning with current word  and lowest common ancestor  are further introduced to model syntactic structure .  However, the expanded features are still manually designed features rather than automatically learned high-level representations. PSF only contains features from limited layers of the whole syntactic tree structure. WRF only exposes the information of partial nodes and edges from the whole syntactic parse tree.  % PSF and WRF can only model the syntactic relation among limited subtrees rather than the whole syntactic parse tree structure. % contain feature from syntactic tree structure by design. % needs  and expert knowledge to select  % V1020: which makes it harder to extract useful information and leads to instability. % and the way to select the specific layers from parse tree, which makes it harder to extract useful information and leads to instability. % V1020: And WRF focuses on the relation between two adjacent words in parsing tree structure, which can only model limited information from the whole syntactic parse tree. For example, one of WRF features is highest-level phrase beginning with current word . % WRF only models . %  which expand partial higher structure . % limited by manual selection strategy, WRF only considers the influence of former word on next word and specific layer of parent nodes, so cannot model the whole structure parse tree.  % This makes the prosody performance largely determined by the selected strategy, and at the same time very unstable. %In Fig., we show a example of how synthesised speech from phoneme sequence input  is different from reference speech  because of failing to respect syntax structure.  % Without parsing tree's limit, the third word ""cu4 jin4"" is pronounced separately .  % Besides, without parsing tree information, synthesised speech does not pause between the fifth word ""ti2 xiao4"" and the sixth word ""shi4"", which have a obvious gap in parsing tree reflected in reference speech . % simply plugging these parsing tree information during TTS does not perform well. Limited by the manual design rule, these features have some disadvantages to model syntax tree structure information. Firstly, using phrase structure feature needs to fix the number of tree layers and the way to select specific layer, while using word relation feature has to make the model select only part of parse tree structure, which cannot be proved to be the most useful part for prosody modeling. This makes the prosody performance largely determined by the selected strategy, and at the same time very unstable. Secondly, word relation feature only consider the former words' influence on next word and ignore the impact of the backward structure importance. Last but not least, manual design features require very high accuracy of syntax tree annotation, which can not be easily achieved. Otherwise, Otherwise under the influence of manual selection strategy, the destructive influence of mislabeling on prosody prediction will be magnified.  % A syntactic parse tree traversal based method is proposed to learn syntactic representation and employed in neural machine translation . To maker better use of the syntactic information, motivated by the syntactic parse tree traversal approach in neural machine translation , we propose a syntactic representation learning method to further improve the prosody and naturalness of synthesized speech in neural network based TTS.  % To make a better use of the syntactic information, in this paper, we propose a syntactic representation learning method to further improve the prosody in neural network based TTS. % which also known as phrase structure parsing, for TTS system to control prosody more effective.  Syntactic parse tree is linearized into two constituent label sequences through left-first and right-first traversal. % Word level bidirectional  Then syntactic representations are extracted from the constituent label sequences using different uni-directional GRU network for each sequence. After which, the syntactic representations are up-sampled from word level to phoneme level and concatenated with phoneme embeddings.  Tacotron 2 is employed to generate spectrogram from the concatenated syntactic representations and phoneme embeddings, with Griffin-Lim  to reconstruct the waveform. % directly Nuclear-norm maximization loss  is introduced to the constituent label embedding layer to enhance discriminability and diversity.  Compared to only hiring left-first traversal , right-first traversal is proposed to alleviate the ambiguity.  Experimental results show that our proposed model outperforms the baseline in terms of prosody and naturalness. Mean opinion score  increases from  to  compared with the baseline approach . % compared to baseline approach, with  is  from a one-way ANOVA test. ABX preference rate exceeds the baseline approach by . % One-way ANOVA test reveals a significant improvement . % We go further to explore how the enhanced controllability of prosody can benefit eliminate ambiguity. For sentences with multiple different syntactic parse trees, prosodic differences can be clearly perceived from corresponding synthesized speeches.  %We linearize a phrase parse tree into a structural label sequence and propose a rnn-based model to learn useful syntactic information by itself, and experimental shows significantly better than the method of manually extracting features. %To our best known, we first exploite syntactic information to chinese TTS system and first to apply syntactic information to lower input level than word. %We have also introduce rank loss of syntactic label embedding to enhance the ability of the syntax structure to control prosody, which expanded the specific application of parsing tree information, including different sentences in the same parsing tree structure to bring the same prosodic structure, and different trees in the same sentence to produce different prosodic readings. The latter brings solutions to the ambiguity caused by grammatical structure    In this paper, we propose a novel method named SenSeNet for keyphrase generation, which automatically  estimate whether the sentences are tended to generate the keyphrase. We use a straight-through estimator to solve the model discontinuity problem. We incorporate a weakly-supervised signal to guide the selection of significant sentences efficiently. The experiment results show that our model can successfully generate the present keyphrase and absent keyphrase. In addition, our model and the training method can be applied to most encoder-decoder architectures. Further analysis suggests that our model has an edge on semi-present keyphrase, although predicting absent keyphrase is challenging.                             
"," Syntactic structure of a sentence text is correlated with the prosodic structure of the speech that is crucial for improving the prosody and naturalness of a text-to-speech  system.  Nowadays TTS systems usually try to incorporate syntactic structure information with manually designed features based on expert knowledge.  In this paper, we propose a syntactic representation learning method based on syntactic parse tree traversal to automatically utilize the syntactic structure information.  Two constituent label sequences are linearized through left-first and right-first traversals from constituent parse tree. Syntactic representations are then extracted at word level from each constituent label sequence by a corresponding uni-directional gated recurrent unit  network.  Meanwhile, nuclear-norm maximization loss is introduced to enhance the discriminability and diversity of the embeddings of constituent labels.  Upsampled syntactic representations and phoneme embeddings are concatenated to serve as the encoder input of Tacotron2.  Experimental results demonstrate the effectiveness of our proposed approach, with mean opinion score  increasing from $3.70$ to $3.82$ and ABX preference exceeding by $17\%$ compared with the baseline. In addition, for sentences with multiple syntactic parse trees, prosodic differences can be clearly perceived from the synthesized speeches.",423
" Semantic parsing is the task of mapping natural language utterances to machine interpretable meaning representations. Many semantic parsing methods are based on the principle of semantic compositionality ~, of which the main idea is to put together the meanings of utterances by combining the meanings of the parts~. However, these methods suffer from heavy dependence on handcrafted grammars, lexicons, and features.  To overcome this problem, many neural semantic parsers have been proposed and achieved promising results~. %\textcolor{red}{However, compared to compositional semantic parsers, neural semantic parsers are not aware of the compositional structure of utterances, which often limits their generalization between various compound-complex utterances: However, due to the lack of capturing compositional structures in utterances, neural semantic parsers usually have poor generalization ability to handle unseen compositions of semantics~. For example, a parser trained on ``How many rivers run through oklahoma?'' and ``Show me states bordering colorado?'' may not perform well on ``How many rivers run through the states bordering colorado?''.     \end{table}     \end{table*}  In this paper, we propose a novel framework to boost neural semantic parsers with the principle of compositionality~. It iterates between segmenting a span from the utterance and parsing it into a partial meaning representation. Table  shows an example. Given an utterance ``How many rivers run through the states bordering colorado?'', we parse it through three iterations:  we segment a span ``the states bordering colorado'' from the utterance, and parse it into ;  as the utterance is reduced to ``How many rivers run through \?'', we segment a span ``rivers run through \'' from it, and parse it into ;  the utterance is further reduced to ``How many \?'', and we parse it into . We compose these partial meaning representations into the final result.  Our framework consists of two neural modules: an utterance segmentation model  and a base parser . The former is in charge of segmenting a span from an utterance, and the latter is in charge of parsing the span into its meaning representation. These two modules work together to parse complex input utterances in a divide-and-conquer fashion.  One key advantage of this framework is that it does not require any handcraft templates or additional labeled data for utterance segmentation: we achieve this through proposing a novel training method, in which the base parser provides pseudo supervision to the utterance segmentation model. Specifically: we train a preliminary base parser on the original train data; then, for each train sample , we use this preliminary base parser to check whether spans in  can be parsed to \textcolor{red}{be} a part of  \textcolor{red}{or not}. If true, we leverage these spans as pseudo supervision signals for training the utterance segmentation model, and thereby do not require any handcraft templates or additional labeled data.} %The key to implement this framework is to address the challenge of lacking labeled data for utterance segmentation. %We achieve this through cooperative training of the segmentation model and the base parser: %leverage pre-trained base parser to derive synthetic supervision signals for training the segmentation model, then leverage the segmentation model to derive synthetic supervision signals for updating the base parser.  % \textcolor{green}{Moreover, considering that there are usually no labeled data for utterance segmentation, we propose to search for reasonable segmentation points from utterances via the base parser, and use them as a distant supervision. This improves the domain adaptability of our framework.}  % While lacking the direct supervision for segmentation model, we seek to address this challenge in a distantly supervised way. % shaped like  %\textcolor{red}{ %Firstly, we train the base parser, and use it to search for and evaluate all viable ways to segment training utterances. %Then, these segmentations are leveraged as distant supervision for training the utterance segmentation model and fine-tuning the base neural semantic parser.}  In summary, our proposed framework has four advantages:  the base parser learns to parse simpler spans instead of whole complex utterances, thus alleviating the training difficulties and improving the compositional generalization ability;  our framework is flexible to incorporate various popular encoder-decoder models as the base parser;  our framework does not require any handcraft templates or additional labeled data for utterance segmentation; % our framework addresses the challenge of lacking labeled data for utterance segmentation through cooperative training.  our framework improves the interpretability of neural semantic parsing by providing explicit alignment between spans and partial meaning representations.  We conduct experiments on three datasets: Geo~, ComplexWebQuestions~, and Formulas . They use different forms of meaning representations: FunQL, SPARQL, and Spreadsheet Formula. Experimental results show that our framework consistently improves the performances of neural semantic parsers in different domains. On data splits that require compositional generalization, our framework brings significant accuracy gain: Geo , Formulas , ComplexWebQuestions .        In this study, we investigate a syntactic representation learning method to automatically utilize the syntactic structure information for neural network based TTS. Nuclear-norm maximization loss is introduced to enhance the discriminability and diversity of synthsized speech prosody. Experimental results demonstrate the effectiveness of our proposed approach. For sentences with multiple syntactic parse trees, prosodic difference can be clearly observed from the synthesized speeches.    To start a new column  and help balance the last-page   column length use \vfill\pagebreak.   -------------------------------------------------------------------------  \vfill  \pagebreak   \vfill\pagebreak    References should be produced using the bibtex program from suitable   BiBTeX files . The IEEEbib.bst bibliography   style file from IEEE produces unsorted bibliography list.   ------------------------------------------------------------------------- 
"," Neural semantic parsers usually fail to parse long and complex utterances into correct meaning representations, due to the lack of exploiting the principle of compositionality. To address this issue, we present a novel framework for boosting neural semantic parsers via iterative utterance segmentation. Given an input utterance, our framework iterates between two neural modules: a segmenter for segmenting a span from the utterance, and a parser for mapping the span into a partial meaning representation. Then, these intermediate parsing results are composed into the final meaning representation. One key advantage is that this framework does not require any handcraft templates or additional labeled data for utterance segmentation: we achieve this through proposing a novel training method, in which the parser provides pseudo supervision for the segmenter. Experiments on Geo, ComplexWebQuestions and Formulas show that our framework can consistently improve performances of neural semantic parsers in different domains. On data splits that require compositional generalization, our framework brings significant accuracy gains: Geo $63.1\to 81.2$, Formulas $59.7\to 72.7$, ComplexWebQuestions $27.1\to 56.3$.",424
"     Word alignment is a task of finding the corresponding words in a sentence pair  and used to be a key component of statistical machine translation . Although word alignment is no longer explicitly modeled in neural machine translation , it is often leveraged to interpret and analyze NMT models . Word alignment is also used in many other scenarios, such as imposing lexical constraints on the decoding process , improving automatic post-editing  and providing guidance for translators in computer-aided translation .  Recently, unsupervised neural alignment methods have been studied and outperformed GIZA++  on many alignment datasets . However, these methods are trained with a translation objective, which computes the probability of each target token conditioned on source tokens and previous target tokens. This will bring noisy alignments when the prediction is ambiguous . To alleviate this problem, previous studies modify Transformer  by adding alignment modules to re-predict the target token , or computing an additional alignment loss on the full target sequence . Moreover, \citet{chen2020accurate} propose an extraction method that induces alignment when the to-be-aligned target token is the decoder input.   Although these methods have demonstrated their effectiveness, they have two drawbacks. First, they retain the translation objective which is not tailored for word alignment. Consider the example in Figure . When predicting target token ``Tokyo'', the translation model may wrongly generate ``1968'' as it only considers the previous context, which will result in an incorrect alignment link . A better modeling is needed for obtaining more accurate alignments. Second, they need an additional guided alignment loss  to outperform GIZA++, which requires inducing alignments for entire training corpus.  In this paper, we propose a self-supervised model specifically designed for the word alignment task, namely Mask-Align. Our model masks each target token and recovers it with the source and the rest of the target tokens. For example, as shown in Figure , the target token ``Tokyo'' is masked and re-predicted. During this process, our model can identify that only the source token ``Tokio'' has not been translated yet, so the to-be-predicted target token ``Tokyo'' is aligned to ``Tokio''. Comparing with the translation model, this masked modeling method is highly related to word alignment, and based on that our model generates more accurate predictions and alignments.  % We model the target token conditioned on all other tokens in both source and target, which will disambiguate the prediction and thus lead to an accurate alignment ). As the vanilla transformer architecture requires sequential time to model this probability, we modify the attention in the decoder by separating the queries from keys and values and  % updating only the former in each layer. This allows our model to predict all target tokens in a single forward pass without information leakage. Besides, we also propose a variant of attention called leaky attention that allieviates the unexpected high attention weights on some specific tokens such as periods, which is helpful for the alignment extraction from attention matrix. Finally, we leverage the attention weights from the models in two directions by incorporating an agreement loss in the training process.  % Experiments on four public datasets show that our model significantly outperforms all existing statistical and neural methods without using guided alignment loss.  To summarize, the main contributions of our work are listed as follows:      In this paper, we propose a novel framework for boosting neural semantic parsers via iterative utterance segmentation. The insight is a bottom-up divide-and-conquer mechanism, which significantly improves the compositional generalization ability and interpretability of neural semantic parsers. Considering the usual absence of labeled data for utterance segmentation, we propose a cooperative training method to tackle this problem. Experimental results show that our framework consistently improves the performance of different neural semantic parsers across tasks.  In the future, we plan to improve the robustness of our framework for various complex language phenomena. We also plan to apply this framework to more semantic parsing tasks such as text-to-SQL and text-to-code.     
"," Neural word alignment methods have received increasing attention recently. These methods usually extract word alignment from a machine translation model. However, there is a gap between translation and alignment tasks, since the target future context is available in the latter. In this paper, we propose Mask-Align, a self-supervised model specifically designed for the word alignment task. Our model parallelly masks and predicts each target token, and extracts high quality alignments without any supervised loss. In addition, we introduce leaky attention to alleviate the problem of unexpected high attention weights on special tokens. Experiments on four language pairs show that our model significantly outperforms all existing unsupervised neural baselines and obtains new state-of-the-art results.  % However, the original translation objective ignores the future context in the target, which is available in the alignment task.",425
" The sequence-to-sequence  models~, which learn to map an arbitrary-length input sequence to another arbitrary-length output sequence, have successfully tackled a wide range of language generation tasks. % including machine translation, text summarization, question generation, to name a few.  Early seq2seq models have used recurrent neural networks to encode and decode sequences, leveraging attention mechanism  that allows the decoder to attend to a specific token in the input sequence to capture long-term dependencies between the source and target sequences. Recently, the Transformer~, which is an all-attention model that effectively captures long-term relationships between tokens in the input sequence as well as across input and output sequences, has become the de facto standard for most of the text generation tasks due to its impressive performance. Moreover, Transformer-based language models trained on large text corpora  have shown to significantly improve the model performance on text generation tasks. %Seq2seq tasks are becoming increasingly more important, as  show that most of text-based language problems can be cast into sequence-to-sequence problems.  However, a crucial limitation of seq2seq models is that they are mostly trained only with teacher forcing, where ground truth is provided at each time step and thus  never exposed to incorrectly generated tokens during training ), which hurts its generalization. This problem is known as the ``exposure bias"" problem  and often results in the generation of low-quality texts on unseen inputs. Several prior works tackle the problem, such as using reinforcement learning  to maximize non-differentiable reward . %  --- BLEU or Rouge.   Another approach is to use RL or gumbel softmax  to match the distribution of generated sentences to that of the ground truth, in which case the reward is the discriminator output from a Generative Adversarial Network  . Although the aforementioned approaches improve the performance of the seq2seq models on text generation tasks, they either require a vast amount of effort in tuning hyperparameters or stabilize training. %Moreover,  show that RL methods for machine translation often do not optimize the expected reward and the performance gain is attributed to the side effects, such as increasing the peakiness of the output distribution.      In this work, we propose to mitigate the exposure bias problem with a simple yet effective approach, in which we contrast a positive pair of input and output sequence to negative pairs, to expose the model to various valid or incorrect sentences. Na鑼倂ely, we can construct negative pairs by simply using random non-target sequences from the batch~. However, such a na鑼倂e construction yields meaningless negative examples that are already well-discriminated in the embedding space ), which we highlight as the reason why existing methods~ require large batch size. This is clearly shown in Fig., where a large portion of positive-negative pairs can be easily discriminated without any training, which gets worse as the batch size decreases as it will reduce the chance to have meaningfully difficult examples in the batch. Moreover, discriminating positive and na鑼倂e negative pairs becomes even more easier for models pretrained on large text corpora.   To resolve this issue, we propose principled approaches to automatically generate negative and positive pairs for constrastive learning, which we refer to as Contrastive Learning with Adversarial Perturbation for Seq2seq learning . Specifically, we generate a negative example by adding a small perturbation to the hidden representation of the target sequence, such that its conditional likelihood is minimized ). Conversely, we construct an additional positive example ) by adding a large amount of perturbation to the hidden representation of target sequence such that the perturbed sample is far away from the source sequence in the embedding space, while enforcing it to have high conditional likelihood by minimizing Kullback-Leibler  divergence between the original conditional distribution and perturbed conditional distribution. This will yield a negative example that is very close to the original representation of target sequence in the embedding space but is largely dissimilar in the semantics, while the generated positive example is far away from the original input sequence but has the same semantic as the target sequence. This will generate difficult examples that the model fails to correctly discriminate , Fig.2), helping it learn with more meaningful pairs.  To verify the efficacy of our method, we empirically show that it significantly improves the performance of seq2seq model on three conditional text generation tasks, namely machine translation, text summarization and question generation. Our contribution in this work is threefold:        In this paper, we propose a self-supervised neural alignment model Mask-Align. Different from the NMT-based methods, our model adopts a novel masked modeling objective that is more suitable for word alignment tasks. Moreover, Mask-Align can alleviate the problem of high attention weights on special tokens by introducing leaky attention. Experiments show that Mask-Align achieves new state-of-the-art results without guided alignment loss. We leave it for future work to extend our model in a semi-supervised setting.     
"," Recently, sequence-to-sequence  models with the Transformer architecture have achieved remarkable performance on various conditional text generation tasks, such as machine translation. However, most of them are trained with teacher forcing with the ground truth label given at each time step, without being exposed to incorrectly generated tokens during training, which hurts its generalization to unseen inputs, that is known as the ``exposure bias"" problem. In this work, we propose to mitigate the conditional text generation problem by contrasting positive pairs with negative pairs, such that the model is exposed to various valid or incorrect perturbations of the inputs, for improved generalization. However, training the model with na閼煎俥 contrastive learning framework using random non-target sequences as negative examples is suboptimal, since they are easily distinguishable from the correct output, especially so with models pretrained with large text corpora. Also, generating positive examples requires domain-specific augmentation heuristics which may not generalize over diverse domains. To tackle this problem, we propose a principled method to generate positive and negative samples for contrastive learning of seq2seq models. Specifically, we generate negative examples by adding small perturbations to the input sequence to minimize its conditional likelihood, and positive examples by adding  large perturbations while enforcing it to have a high conditional likelihood. Such ``hard'' positive and negative pairs generated using our method guides the model to better distinguish correct outputs from incorrect ones. We empirically show that our proposed method significantly improves the generalization of the seq2seq on three text generation tasks --- machine translation, text summarization, and question generation.",426
"  Task-specific finetuning of pretrained deep networks has become the dominant paradigm in contemporary NLP, achieving state-of-the-art results across a suite of natural language understanding tasks . While straightforward and empirically effective, this approach is difficult to scale to multi-task, memory-constrained settings , as it requires shipping and storing a full set of model parameters for each task. Inasmuch as these models are learning generalizable, task-agnostic language representations through self-supervised pretraining, finetuning the entire model for each task seems especially profligate.   A popular approach to parameter-efficiency with pretrained models is to learn sparse models for each task where a subset of the final model parameters  are exactly zero~. Such approaches often face a steep sparsity/performance tradeoff, and a substantial portion of nonzero parameters  are still typically required to match the performance of the dense counterparts. An alternative is to use multi-task learning or feature-based transfer for more parameter-efficient transfer learning with pretrained models~. These methods learn only a small number of additional parameters  on top of a shared model. However, multi-task learning generally requires access to all tasks during training to prevent catastrophic forgetting~, while feature-based transfer learning  is typically outperformed by full finetuning~.    Adapters~ have recently emerged as a promising approach to parameter-efficient transfer learning within the pretrain-finetune paradigm~.  Adapter layers are smaller, task-specific modules that are inserted between layers of a pretrained model, which remains fixed and is shared across tasks.  These approaches do not require access to all tasks during training, making them attractive in settings where one hopes to obtain and share performant models as new tasks arrive in stream.  \citet{houlsby2019adapters} find that adapter layers trained on BERT can match the performance of fully finetuned BERT on the GLUE benchmark  while only requiring 3.6\% additional parameters  per task.   In this work, we consider a similar setting as adapters but propose a new diff pruning approach with the goal of even more parameter-efficient transfer learning.  Diff pruning views finetuning as learning a task-specific \underline{diff}erence  vector%\footnote{Similar to the  command in Unix operating systems.}    \ that is applied on top of the pretrained parameter vector, which remains fixed and is shared across different tasks.   In order to learn this vector, we reparameterize the task-specific model parameters as , where the pretrained parameter vector  is fixed  and  the task-specific diff vector  is finetuned. The diff vector is regularized with a differentiable approximation to the -norm penalty~ to encourage sparsity. This approach can become  parameter-efficient as the number of tasks increases as it only requires storing the nonzero positions and weights of the diff vector for each task. The cost of storing the shared pretrained model remains constant and is amortized across multiple tasks.  On the GLUE benchmark~, diff pruning can match the performance of the fully finetuned BERT baselines  while finetuning only  of the pretrained parameters per task, making it a potential alternative to adapters for parameter-efficient transfer learning.       In this paper, we propose a Disentanglement-based Attractive Headline Generator  to generate an attractive headline.    Our model is built on the fact that the attractiveness of the headline comes from both style and content aspects.   Given the prototype document-headline pair, DAHG disentangles the attractive content and style space from the prototype attractive headline.    The headline generator generates attractive headlines under the guidance of both.    Our model achieves state-of-the-art results in terms of ROUGE scores and human evaluations by a large margin.   In near future, we aim to bring the model online.                 \clearpage  
"," While task-specific finetuning of pretrained networks has led to significant empirical advances in NLP, the large size of networks makes finetuning difficult to deploy in multi-task, memory-constrained settings. We propose diff pruning as a simple approach to enable parameter-efficient transfer learning within the pretrain-finetune framework. This approach views finetuning as learning a task-specific ``diff"" vector that is applied on top of the pretrained parameter vector, which remains fixed and is shared across different tasks. The diff vector is adaptively pruned during training with a differentiable approximation to the $L_0$-norm penalty to encourage sparsity. Diff pruning becomes parameter-efficient as the number of tasks increases, as it requires storing only the nonzero positions and weights of the diff vector for each task, while the cost of storing the shared pretrained model remains constant. It further does not require access to all tasks during training, which makes it attractive in settings where tasks arrive in stream or the set of tasks is unknown. We find that models finetuned with diff pruning can match the performance of fully finetuned baselines on the GLUE benchmark while only modifying 0.5$\%$ of the pretrained model's parameters per task.\blfootnote{ \hspace{-6mm} Our code is available at \url{https://github.com/dguo98/DiffPruning}}",427
"   Goal-oriented dialogue systems is a hot topic in machine learning research. The systems have widespread applications in the industry and are the foundation of many successful products, including Alexa, Siri, Google Assistant, and Cortana. One core component of a dialog system is spoken language understanding , which consists of two main problems, intent classification  and slot labeling  . In IC, we attempt to classify the goal of a user query, usually input in text or transcribed by automatic speech recognition  system from audio. SL, similar to the named-entity recognition  problem, aims to label each token in a query an entity type. The only difference is that entity types in SL are domain-specific and based upon dialog ontology. Recent advances in neural models have enabled greatly improved SLU .  However, two significant challenges hinder the broad application and expansion of the SLU models in industrial settings. First of all, neural methods require a large amount of labeled data for training . SLU is often coupled with the ontology of the underlying dialog system and thus domain-dependent. Collecting a large number of in-domain labeled data for neural models is prohibitively expensive and time-consuming. Secondly, the performance of SLU models in practice often suffers from fluctuations due to various types of noises. One common noise is adaptation data perturbation. In many industrial applications such as cloud services\footnote{Alexa ASK: https://developer.amazon.com/en-US/alexa/alexa-skills-kit; Google DialogFlow: https://dialogflow.com/}, the SLU model is built by fine-tuning  a pre-trained, shared network to the target domain with data provided by developers. The developers often have a limited background in SLU and machine learning. Thus the data provided varies in quality and is subject to different types of perturbations, such as missing or replaced data samples  and typos. Another common noise comes from the mismatch of input modalities between adaptation and inference stages. For instance, the model is adapted with human transcription yet deployed to understand ASR decoded text, or the input at adaptation and inference stages relies on the recognition of different versions of ASR models. Given that most neural methods comprise a large number of parameters and are heavily optimized for the training  data provided, the resulting model is usually sensitive to these noises. The requirement of noise-free adaptation and inference conditions also prohibits the use of neural SLU techniques because it is often infeasible to achieve such conditions.  Transfer learning and meta-learning are two conventional techniques that have been applied to address the challenge of data scarcity. Transfer learning usually refers to pre-training initial models using mismatched domains with rich human annotations and then adapting the models with limited labels in targeted domains. Previous works  have shown promising results in applying transfer learning to SLU. Note that pre-training discussed here covers methods including using a pre-trained language model like BERT  directly and further training downstream tasks on data in mismatched domains with the pre-trained model. In the following, we focus on the latter due to utilizing data from other domains better and yielding higher accuracy. In recent years, meta-learning has gained growing interest among the machine learning fields for tackling few-shot learning  scenarios. Model-Agnostic Meta-Learning   focuses on learning parameter initialization from multiple subtasks, such that the initialization can be fine-tuned with few labels and yield good performance in targeted tasks. Metric-based meta-learning, including prototypical networks   and matching networks , aim to learn embedding or metric space which can be generalized to domains unseen in the training set after adaptation with a small number of examples from the unseen domains. Recent work unveils excellent potential in applying meta-learning techniques to SLU in the few-shot learning context .  As compared to data scarcity, another challenge for SLU, the robustness against noises, is also gaining attention. Simulated ASR errors are used to augment training data for SLU models . Researchers also leverage information from confusion networks or lattices , and adversarial training techniques  for models to learn query embeddings that are robust against ASR errors. For text input, methods have also been explored on model robustness against noises from misspelling and acronym . In contrast to these noise types that have gained attention, to our best knowledge, there is no prior work investigating the impact of missing or replaced examples in adaptation data. Moreover, the intersection of data scarcity and noise robustness is unexplored. Since the scarcity of labeled data and data noisiness usually co-occur in SLU applications , the lack of studies in the intersectional areas hinders the use of neural SLU models and its expansion to broader use cases.  Given the deficiency, we establish a novel few-shot noisy SLU task by introducing two common types of natural noise, adaptation example missing/replacing and modality mismatch, to the previously defined few-shot IC/SL splits . The task is built upon three public datasets, ATIS , SNIPS , and TOP . We further propose a noise-robust few-shot SLU model based on ProtoNets for the established task. In summary, our primary contributions are 3-fold: 1) formulating the first few-shot noisy SLU task and evaluation framework, 2) proposing the first working solution for the few-shot noisy SLU with the existing ProtoNet algorithm, and 3) in the context of noisy and scarce learning examples, comparing the performance of the proposed method with conventional techniques, including MAML and fine-tuning based adaptation.      We propose diff pruning as a simple approach for parameter-efficient transfer learning with pretrained models. Experiments on standard NLP benchmarks and models show that diff pruning can match the performance of fully finetuned baselines while requiring only a few additional parameters per task. We also propose a structured variant of diff pruning which provides further improvements. Avenues for future work include  applying this approach to other architectures ,  injecting parameter-efficiency objectives directly into the pretraining process , and  combining diff pruning with other techniques  to achieve even greater parameter-efficiency.  
","    Recently deep learning has dominated many machine learning areas, including spoken language understanding . However, deep learning models are notorious for being data-hungry, and the heavily optimized models are usually sensitive to the quality of the training examples provided and the consistency between training and inference conditions. To improve the performance of SLU models on tasks with noisy and low training resources, we propose a new SLU benchmarking task: few-shot robust SLU, where SLU comprises two core problems, intent classification  and slot labeling . We establish the task by defining few-shot splits on three public IC/SL datasets, ATIS, SNIPS, and TOP, and adding two types of natural noises  to the splits. We further propose a novel noise-robust few-shot SLU model based on prototypical networks. We show the model consistently outperforms the conventional fine-tuning baseline and another popular meta-learning method, Model-Agnostic Meta-Learning , in terms of achieving better IC accuracy and SL F1, and yielding smaller performance variation when noises are present.",428
"  In the modern world, social media is playing its part in several ways, for instance in news dissemination and information sharing, social media outlets, such as Twitter, Facebook, and Instagram, have been proved very effective . However, it also comes with several challenges, such as collecting information from several sources, detecting and filtering misinformation . Similar to other events and pandemics, being one of the deadly pandemics in the history, COVID-19 has been the subject of discussion over social media since its emergence. Without any surprise, a lot of misinformation about the pandemic are circulated over social networks. In order to identify misinformation spreaders and filter fake news about COVID-19 and 5G conspiracy, a task namely ""FakeNews: Corona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis"" has been proposed in the benchmark MediaEval 2020 competition .   This paper provides a detailed description of the methods proposed by team DCSE\_UETP for the fake news detection task. The task consists of two parts, namely  text-based misinformation detection , and  structure-based misinformation detection . The first task  is based on textual analysis of COVID-19 related information shared on Twitter during January 2020 and 15th of July 2020, and aims to detect different types of conspiracy theories about COVID-19 and its vaccines, such as that ""the 5G weakens the immune system and thus caused the current corona-virus pandemic etc., . In the SMD task, the participants are provided with a set of graphs, each representing a sub-graph of Twitter, and corresponds to a single tweet where the vertices of the graphs represent accounts. Similar to TMD, in this task, the participants need to detect and differentiate between 5G and other COVID-19 conspiracy theories.      In this paper, we establish a novel SLU task, the few-shot noisy SLU, with existing public datasets. We further propose a ProtoNets based approach, Proto, to build IC and SL classifiers with few noisy examples. When there is no noise in few-shot examples, Proto yields better performance than other approaches utilizing MAML and fine-tuning frameworks. Proto also achieves the highest and most robust IC accuracy and SL F1 when two types of noise, adaptation example missing/replacing and modality mismatch, are injected in adaption and evaluation set respectively. We believe the ensemble nature of ProtoNets benefits the model robustness, and the simplicity of Proto's model architecture is also helpful in the few-shot noisy scenario. Our contribution here is a step toward the efficient and robust deployment of SLU models. While our results are promising, there is still substantial work, from the creation of few-shot SLU datasets covering more noises to studies of faster and stabler learning algorithms, in pursuit of the goal.             \renewcommand{\thesection}{\Alph{section}} 
"," The paper presents our solutions for the MediaEval 2020 task namely FakeNews: Corona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task aims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect misinformation spreaders. The task is composed of two sub-tasks namely  text-based, and  structure-based fake news detection. For the first task, we propose six different solutions relying on Bag of Words  and BERT embedding. Three of the methods aim at binary classification task by differentiating in 5G conspiracy and the rest of the COVID-19 related tweets while the rest of them treat the task as ternary classification problem. In the ternary classification task, our BoW and BERT based methods obtained an F1-score of .606\% and .566\% on the development set, respectively. On the binary classification, the BoW and BERT based solutions obtained an average F1-score of .666\% and .693\%, respectively. On the other hand, for structure-based fake news detection, we rely on Graph Neural Networks  achieving an average ROC of .95\% on the development set.",429
" Sentiment classification is the task of analyzing a piece of text to predict the orientation of the attitude towards an event or opinion. The sentiment of a text can be either positive or negative. Sometimes, a neutral perspective is also considered for classification. SA has many different applications, such as reducing the early age suicide rate by identifying cyberbullying , discouraging unwarranted activities towards a particular community through hate-speech detection , and monitoring public response towards a proposed government bill  among many others.    The task of SA has achieved superior improvement in other languages, i.e. English - about 97.1\% accuracy for 2-class  and 91.4\% accuracy for 3-class SA . But only a few research works have been published for the SA in Bengali. This is because we lack quality datasets in Bengali for training a computation model for the sentiment classification. However, in the last few years, we have seen the rise of Internet users in the Bengali domain mostly due to the development of wireless network infrastructure throughout South East Asia. This resulted in a massive increase in the total number of online social network users as well as newspaper readers. So it became comparatively easier to collect the public comments posted online on the Bengali news websites.    %  \end{table}  Thus we created two SA datasets for 2-class and 3-class SA in Bengali and trained a multi-lingual BERT model via transfer learning approach for sentiment classification in Bengali, referred as  in this paper.  achieves an accuracy of 71\% for the 2-class and 60\% for the 3-class manually tagged dataset. We further use this model to analyze the sentiment of 1,002 public comments collected from the online daily newspaper. Table  shows that in general, sentiment in public comments is positive for religious news articles, while that is negative for political or sports news articles. In this paper, we present the following contributions:    % \makeatletter % \patchcmd{\@makecaption} %   {\scshape} %   {} %   {} %   {} % \makeatletter % \patchcmd{\@makecaption} %   {\\} %   {.\ } %   {} %   {} % \makeatother % \def\tablename{Table}       We introduce Sequence Mixup, a set of regularization and data augmentation techniques for RNNs. Our work can thought as extending both input mixup  and manifold mixup , which are originally porposed for feed-forward neural nets. For the case of manifold mixup, we propose two distinct variants called Pre-Output and Throgh-Time Mixup, respectively. An asymptotic theoretical analysis reveals that Pre-Output Mixup imposes  a locally linear behavior on the network's output generating section. In a classification task, this property leads to partitioning of the hidden representation space into a set of orthogonal affine subspaces, each of which corresponds to a unique class. Experimental results showed improvement on the loss and F-1 scores of both 1) a baseline and 2) state-of-the-art model on CoNLL-2003 NER task. We have studied the correlation of mixup coefficients through consecutive time-steps, and found out that using identical coefficients achieves better loss and F-1 on the NER task. However, at the same time, we conjecture that optimal correlation values for mixup coefficients across time may vary from task to task and thus requires experimental exploration to be adjusted. Lastly, the considerable reduction in the test loss achieved by sequence mixup methods  implies that employing sequence mixup methods for language models may lead to a substantial improvement on the test perplexity.       
"," Sentiment analysis  in Bengali is challenging due to this Indo-Aryan language's highly inflected properties with more than 160 different inflected forms for verbs and 36 different forms for noun and 24 different forms for pronouns. The lack of standard labeled datasets in the Bengali domain makes the task of SA even harder. In this paper, we present manually tagged 2-class and 3-class SA datasets in Bengali. We also demonstrate that the multi-lingual BERT model with relevant extensions can be trained via the approach of transfer learning over those novel datasets to improve the state-of-the-art performance in sentiment classification tasks. This deep learning model achieves an accuracy of 71\% for 2-class sentiment classification compared to the current state-of-the-art accuracy of 68\%. We also present the very first Bengali SA classifier for the 3-class manually tagged dataset, and our proposed model achieves an accuracy of 60\%. We further use this model to analyze the sentiment of public comments in the online daily newspaper. Our analysis shows that people post negative comments for political or sports news more often, while the religious article comments represent positive sentiment. The dataset and code is publicly available \footnote{ https://github.com/KhondokerIslam/Bengali\_Sentiment}.",430
"  Methods for automatically learning phone- or word-like units from unlabelled speech audio could enable speech technology in severely low-resourced settings and could lead to new cognitive models of human language acquisition. The goal in unsupervised representation learning of phone units is to learn features which capture phonetic contrasts while being invariant to properties like the speaker or channel. Early approaches focussed on learning continuous features. In an attempt to better match the categorical nature of true phonetic units, more recent work has considered discrete representations. One approach is to use a self-supervised neural network with an intermediate layer that quantizes features using a learned codebook. While the discrete codes from such vector quantized  networks have given improvements in intrinsic phone discrimination tasks, they still encode speech at a much higher bitrate than true phone sequences.  As an example, the top of Figure shows the code indices from a vector-quantized variational autoencoder  overlaid on the input spectrogram. While there is some correspondence between the code assignments and the true phones , and although there is some repetition of codes in adjacent frames , the input speech are often assigned to codes that are distinct from those of surrounding frames. This is not surprising since the VQ model is not explicitly encouraged to do so. The result is an encoding at a much higher bitrate  than that of true phone sequences .    In this paper we consider ways to constrain VQ models so that contiguous feature vectors are assigned to the same code, resulting in a low-bitrate segmentation of the speech into discrete units. We specifically compare two VQ segmentation methods. Both of these are based on a recent method for segmenting written character sequences. The first method is a greedy approach, where the closest adjacent codes are merged until a set number of segments are reached. The second method allows for an arbitrary number of segments. A squared error between blocks of feature vectors and VQ codes are used together with a penalty term encouraging longer-duration segments. The optimal segmentation is found using dynamic programming.  We apply these two segmentation approaches using the encoders and codebooks of the two VQ models from . The first is a type of VQ-VAE. The second is a vector-quantized contrastive predictive coding  model. The combination of these two models with the two segmentation approaches gives a total of four VQ segmentation models to consider. %Applying both these models with both segmentation approaches gives a total of four model combinations. We evaluate these on four different tasks: unsupervised phone segmentation, ABX phone discrimination, same-different word discrimination, and as inputs to a symbolic word segmentation algorithm. The last-mentioned is particularly important since the segmentation and clustering of % word-like units %from unlabelled speech remains a major but important challenge.  On most metrics in the four tasks the combination of the VQ-VAE with the penalized dynamic programming approach is the best VQ segmentation method. Example output is shown in the middle of Figure. Compared to other existing methods, it does not achieve state-of-the-art performance in all four evaluation tasks. However, it achieves reasonable performance at a much lower bitrate than most existing methods. This is noteworthy since, while most of the other methods have been tailored to the respective tasks, a single VQ segmentation approach can be used without any alteration directly to a range of problems.     In this paper, with solid experimental proof behind unseen co-relational depth between the task, embedding or feature extractor and end-to-end models, we achieved state-of-the-art on 2-class and 3-class sentimental tasks in a Bengali language which is yet to bloom on this very domain. Primarily, by showing limitations and drawbacks of the few available pre-processing tools, we have claimed that operating on different level embedding should be the first step to reap immediate success. Thereby through extensive analysis and relative findings, we have shown that sub-word level functional embedding, BERT, with any RNN architecture is a must in Bengali sentiment classification tasks. Moreover, we took a step closer to a real world by letting our model identify public sentiment on some newspaper topics which has never been done before on this language. However, from data-set expansion to making BERT suitable for Bengali linguistics, there is a huge room of improvement which our research team has already started working on. Furthermore, by fixing these issues, many ground-breaking applications like cyberbullying identification, hate-speech detection can be introduced to not only help make Bengali a potential language for any NLP practitioner but also to ease the life of many native Bengali speakers.      In this paper, we presented two manually tagged novel datasets for SA in Bengali. We also introduced BERT	extsubscript{BSA}, a deep learning model for SA in Bengali, which outperforms all other models. We achieved state-of-the-art performance for both the 2-class and 3-class SA tasks in Bengali. Moreover, we took a step closer to apply SA model to a real world application by analyzing public sentiment on newspaper topics. The result shows that for religious news comments people tend to possess a positive sentiment whereas for political and sports news comments, people possess negative sentiment. However, this research is a work in progress and will be regularly updated with new insights. We are continuing to increase the size of SA datasets in Bengali and we will explore the application of other deep learning models for better results. We hope that the improved performance of SA in multi-class classification tasks presented in this paper will help many ground-breaking applications like cyberbullying identification as well as hate-speech detection in Bengali.  
"," We investigate segmenting and clustering speech into low-bitrate phone-like sequences without supervision. We specifically constrain pretrained self-supervised vector-quantized~ neural networks so that blocks of contiguous feature vectors are assigned to the same code, thereby giving a variable-rate segmentation of the speech into discrete units. Two segmentation methods are considered. In the first, features are greedily merged until a prespecified number of segments are reached. The second uses dynamic programming to optimize a squared error with a penalty term to encourage fewer but longer segments. We show that these VQ segmentation methods can be used without alteration across a wide range of tasks: unsupervised phone segmentation, ABX phone discrimination, same-different word discrimination, and as inputs to a symbolic word segmentation algorithm. The penalized method generally performs best. While results are only comparable to the state-of-the-art in some cases, in all tasks a reasonable competing approach is outperformed at a substantially lower bitrate.",431
" Content based websites such as Quora, Reddit, StackOverflow are primarily used for seeking genuine answers to questions. People from different domains put up their questions and educators or people knowledgeable in a certain field answer them. One major impediment to a plain sailing execution of information exchange is the proliferation of toxic comments. The key challenge is to weed out such toxic comments termed as Insincere Questions. An Insincere Question is designated as a comment intended to make a statement than to look for genuine answers.  An Insincere Question is characterised by:   This major class of problem pertains to Text classification which has been a benchmark problem of evaluating various research advancements in natural language processing. While traditional machine learning algorithms such as naive bayes, logistic regression and decision trees can be rightfully applied to this problem, they suffer with major impediments in their constructs. Vanilla RNNs, Gated Recurrent Unit and Long Short Term Memory Networks replaced their usage as the new state of the art. Even though LSTMs and GRUs performed well, they failed to capture the dependencies in long range sentences. Now with the advent of Transfer Learning, Language model pre-training has proven to be useful in learning universal language representations. Researchers in the field are developing new and better language models at an unprecedented speed. Applying these new state of the art models could improve current methods and replace manual labeling tasks for text classification, but also find widespread application in similar other fields, such as machine translation and question answering. In this paper, we test this by applying new transformer models from the BERT-family to improve the current method of binary text classification in the context of Insincere Questions Classification. We make use of the Quora Insincere Questions Classification dataset  for this purpose We find that all of our models achieve remarkable results in classifying the given  data , with BERT achieving the best results compared to RoBERTa, DistilBERT, and ALBERT. This indicates that the models are well equipped to take over tasks that researchers have previously solved in less optimal ways.       Active transfer learning using amalgamation of results from multiple models is a novel and, as proved above, successful methodology for identifying causal sentences. This two class problem, whereby we aimed to correctly identify the causal sentences, shows very high and maintainable recall rates. While the performance of this methodology, in terms of accuracy and precision can be improved by incorporating additional active learning iterations, the results are still significant enough to be used for practically solving any two class textual mining problem. In future, we shall look towards the application of our methodology for solving real world problems, such as generation of patient summaries from clinical text.        Copyright 2007, 2008, 2009 Elsevier Ltd       This file is part of the 'Elsarticle Bundle'.    ---------------------------------------------       It may be distributed under the conditions of the LaTeX Project Public    License, either version 1.2 of this license or  any    later version.  The latest version of this license is in       http://www.latex-project.org/lppl.txt    and version 1.2 or later is part of all distributions of LaTeX    version 1999/12/01 or later.       The list of all files belonging to the 'Elsarticle Bundle' is    given in the file `manifest.txt'.        Template article for Elsevier's document class `elsarticle'    with numbered style bibliographic references    SP 2008/03/01                     \documentclass[preprint,12pt,3p]{elsarticle}     Use the option review to obtain double line spacing  \documentclass[preprint,review,12pt]{elsarticle}     Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn    for a journal layout:    \documentclass[final,1p,times]{elsarticle}    \documentclass[final,1p,times,twocolumn]{elsarticle}    \documentclass[final,3p,times]{elsarticle}    \documentclass[final,3p,times,twocolumn]{elsarticle}    \documentclass[final,5p,times]{elsarticle}    \documentclass[final,5p,times,twocolumn]{elsarticle}  \usepackage{float}     if you use PostScript figures in your article    use the graphics package for simple commands    \usepackage{graphics}    or use the graphicx package for more complicated commands \usepackage{amsmath,amssymb,amsfonts} \usepackage{algorithmic} \usepackage{algorithm2e} \usepackage{textcomp} \usepackage{float} \usepackage{longtable} \usepackage{xcolor}    or use the epsfig package if you prefer to use the old commands    \usepackage{epsfig}     The amssymb package provides various useful mathematical symbols \usepackage{amssymb}    The amsthm package provides extended theorem environments    \usepackage{amsthm}     The lineno packages adds line numbers. Start line numbering with    . Or switch it on    for the whole article with \linenumbers after .    \usepackage{lineno}     natbib.sty is loaded by default. However, natbib options can be    provided with \biboptions{...} command. Following options are    valid:       round  -  round parentheses are used       square -  square brackets are used   [option]      curly  -  curly braces are used      {option}      angle  -  angle brackets are used    <option>      semicolon  -  multiple citations separated by semi-colon      colon  - same as semicolon, an earlier confusion      comma  -  separated by comma      numbers-  selects numerical citations      super  -  numerical citations as superscripts      sort   -  sorts multiple citations according to order in ref. list      sort&compress   -  like sort, but also compresses numerical citations      compress - compresses without sorting       \biboptions{comma,round}    \biboptions{}   \journal{Journal of Biomedical Informatics}              Start line numbering here if you want      \linenumbers     main text    
","  The internet today has become an unrivalled source of information where people converse on content based websites such as Quora, Reddit, StackOverflow and Twitter asking doubts and sharing knowledge with the world. A major arising problem with such websites is the proliferation of toxic comments or instances of insincerity wherein the users instead of maintaining a sincere motive indulge in spreading toxic and divisive content. The straightforward course of action in confronting this situation is detecting such content beforehand and preventing it from subsisting online. In recent times Transfer Learning in Natural Language Processing has seen an unprecedented growth. Today with the existence of transformers and various state of the art innovations, a tremendous growth has been made in various NLP domains. The introduction of BERT has caused quite a stir in the NLP community. As mentioned, when published, BERT dominated performance benchmarks and thereby inspired many other authors to experiment with it and publish similar models. This led to the development of a whole BERT-family, each member being specialized on a different task. In this paper we solve the Insincere Questions Classification problem by fine tuning four cutting age models viz BERT, RoBERTa, DistilBERT and ALBERT",432
"     The term ``Readability'' measures how much energy the reader will have to expend in order to understand a writing at optimal speed and find interesting. Readability measuring formulas, such as Automated Readability Index  , Flesch Reading Ease , and Dale閳ユ弲hall formula  calculate a score that estimates the grade level or years of education of a reader based on the U.S. education system, which is illustrated in Figure . These formulas are still used in many widely known commercial readability measuring tools such as Grammarly and Readable. This measurement plays a significant role in many places, such as education, health care, and government . Government organizations use it to ensure that the official texts meet a minimum readability requirement. For instance, the Department of Insurance at Texas has a requirement that all insurance policy documents have a Flesch Reading Ease  score of 40 or higher, which translates to the reading level of a first-year undergraduate student based on the U.S. education system. A legal document which is hard to read can lead someone to sign a contract without understanding what they are agreeing to. Another common usage area is the healthcare sector to ensure the proper readability of the care and treatment documents . Better readability will attract visitors or readers of different websites or blogs, whereas poor readability may decrease the number of readers . Readability measures are also often used to assess the financial documents such as annual reports of a company閳ユ獨 economic performance so that the information is more transparent to the reader . Dyslexia is a disorder that causes difficulties with skills associated with learning, namely reading and writing, which affects up to 20\% of the general population. Readability formulas have been applied to measure the difficulty of reading texts for people with dyslexia .   The scores from readability formulas have been generally found to correlate highly with the actual readability of a text written in the English language. The adaptation of readability formulas to no-English texts is not straightforward. Measuring readability is also essential for every non-English language, but not all of the readability formulas mentioned above are language-independent. These formulas require some resources like a 3000-word list, which is easily understandable by fourth-grade American students, syllable counting dictionary, stemmer, lemmatizer etc. Resource availability for Natural Language Processing  research is an obstacle for some low-resource-languages . In this paper, we aim to develop a readability analysis tool for the Bengali Language. Bengali is the native language of Bangladesh, also used in India  and has approximately 230 million native speakers. Despite being the  most spoken language in the world, Bengali suffers from a lack of fundamental resources for NLP. For a low resource language like Bengali, the research in this area so far can be considered to be narrow and sometimes incorrect. \citet{islam2012text, sinha2012new} tried to adapt the formula-based approaches used for the English language. Unfortunately, it isn't straightforward as these formulas are developed for U.S. based education system and which predicts U.S. grade level of the reader. Since the Bangladeshi education system and grade levels are different from U.S., therefore, the mapping is faulty and led to incorrect results. There is a strong relationship between reading skills and human cognition, which varies depending on different age groups . Therefore, to eliminate this incompatibility, in this paper, we map grade level to different age groups to present age-to-age comparison. Moreover,  used traditional machine learning models to address this task on a very small scale dataset, which isn't publicly available. There are readability analysis tools available for English , Arabic , Italian , and Japanese  language. Unfortunately, no such tool is available for Bengali language that can validate the readability of a text. On the other hand, there is no large-scale human annotated readability analysis dataset available to train supervised neural models for this extremely low-resource language. Our main contributions are summarized as follows:       In this paper, we aimed to identify Insincere Questions from text state of the art NLP models. Starting off with simple methods to the most cutting edge, we illustrated how NLP models can compete with others. In order to do so, we explored how BERT and three BERT-based transformer models approach text classification. RoBERTa, DistilBERT, and ALBERT each improve the original model in a different way with regards to performance and speed. In our application, we demonstrated the easiest way to implement transformer models, how to modify the standard settings and what else to pay attention to. On the task of identifying insincere user intent BERT performed best. However, the field of NLP is fast moving - and we are excited to see what the next transformational generation of models will bring.   
","  Determining the readability of a text is the first step to its simplification. In this paper, we present a readability analysis tool capable of analyzing text written in the Bengali language to provide in-depth information on its readability and complexity. Despite being the $7^{th}$ most spoken language in the world with 230 million native speakers, Bengali suffers from a lack of fundamental resources for natural language processing. Readability related research of the Bengali language so far can be considered to be narrow and sometimes faulty due to the lack of resources.  Therefore, we correctly adopt document-level readability formulas traditionally used for U.S. based education system to the Bengali language with a proper age-to-age comparison. Due to the unavailability of large-scale human-annotated corpora, we further divide the document-level task into sentence-level and experiment with neural architectures, which will serve as a baseline for the future works of Bengali readability prediction. During the process, we present several human-annotated corpora and dictionaries such as a document-level dataset comprising 618 documents with 12 different grade levels,  a large-scale sentence-level dataset comprising more than 96K sentences with simple and complex labels, a consonant conjunct count algorithm and a corpus of 341 words to validate the effectiveness of the algorithm, a list of 3,396 easy words, and an updated pronunciation dictionary with more than 67K words. These resources can be useful for several other tasks of this low-resource language. \footnote{We make our Code \& Dataset publicly available at \url{https://github.com/tafseer-nayeem/BengaliReadability} for reproduciblity.}",433
"  A contract is a legally binding agreement that recognizes and governs the rights and duties of the parties to the agreement. Correctly composing contracts is crucial to ensure its legal validity. In many real-world scenarios, a standard contract is prepared by filling   blanks in a precompiled form. Due to carelessness, two blanks that should be filled with the same  content may be incorrectly filled with different  content. This will result in contract inconsistencies, which may severely impair the legal validity of the contract.  Contract review is widely used by companies to check contract inconsistencies. However, contract review is labor-intensive and costly. Big companies have to hire tens of thousands of lawyers to conduct contract review, and it is estimated that Fortune Global  and Fortune  companies spend about 35281299,62194.05\%90.90\%$.  Our contributions are summarized as follows:   We formulate the Contract Inconsistency Checking  problem. As far as we know, this problem has not yet been studied in the AI community.   We propose a novel Pair-wise Blank Resolution  framework to address the CIC problem. In PBR, we propose a  that extends the Transformer encoder architecture to efficiently model meaningless blanks.   We collected and labeled  a large-scale Chinese contract corpus for CIC. The experimental results show the promising performance of our PBR method.       In this paper, we introduce a new task, Writing Polishment with Similes, and curate a large-scale Chinese simile dataset. Our experiments demonstrate the feasibility and potential of the task, which we consider as a first step towards figurative writing polishment in a real-world setting. We establish Locate\&Gen model and benchmark it on the developed dataset.  Future works include but not limited to:    Furthermore, from an AI writing assistant perspective, we surmise that assisting humans with writing polishment is more likely to develop the potentials of current AI models than just letting AIs write on the fly . Given that figurative language is an essential creative aspect of language use, we encourage the use of the CS dataset in various contexts and look forward to the emergence of intelligent writing assistant tools like magic\footnote[1]{We applied our Locate\&Gen model to generate this simile, which is ``婵″倸鎮撴鏃婀抽懜顒傛畱'' in Chinese before being translated to English.} in the future.      
"," Contract consistency is important in ensuring the legal validity of the contract. In many scenarios, a contract is written by filling the blanks in a precompiled form. Due to carelessness, two blanks that should be filled with the same  content may be incorrectly filled with different  content. This will result in the issue of contract inconsistencies, which may severely impair the legal validity of the contract. Traditional methods to address this issue mainly rely on manual contract review, which is labor-intensive and costly. In this work, we formulate a novel Contract Inconsistency Checking  problem, and design an end-to-end framework, called Pair-wise Blank   Resolution , to solve the CIC problem with high accuracy. Our PBR model contains a novel \texttt{BlankCoder} to address the challenge of modeling meaningless blanks. \texttt{BlankCoder} adopts a two-stage attention mechanism that adequately associates a meaningless blank with its relevant descriptions while avoiding the incorporation of irrelevant context words. Experiments conducted on real-world datasets show the promising performance of our method with a balanced accuracy of $94.05\%$ and an F1 score of $90.90\%$ in the CIC problem.",434
"  Building a human-like open-domain conversational agent  has been one of the milestones in artificial intelligence . Early conversational agents are primarily based on rules , e.g., Eliza , the first CA developed in 60's, simulates a Rogerian psychotherapist based on hand-crafted pattern matching rules. In recent years, with the advancement of data-driven neural networks, neural open-domain conversational models are becoming dominant .  Recent efforts in open-domain neural conversational models are primarily aiming to improve the response diversity  and endowing responses with knowledge , personality , emotion  and empathy .  All the efforts mentioned above are focusing on models that passively respond to user messages. However, in many real-world scenarios, e.g., conversational recommendation, psychotherapy and education, conversational agents are required to actively lead the conversation by smoothly changing the conversation topic to a designated one. For example, during a casual conversation, the agent may actively lead the user to a specific product or service that the agent wants to introduce and recommend.  In this paper, we follow the line of research in  and study the problem of imposing conversational goals/keywords on open-domain conversational agents, where the agent is required to lead the conversation to a target keyword smoothly and fast. As illustrated in Figure , given a target keyword ``juice"" and a random starting keyword ``comics"", the agent is required to converse with the user in multiple exchanges and lead the conversation to ``juice"". The challenge of this problem lies in how to balance the tradeoff between maximizing keyword transition smoothness and minimizing the number of turns taken to reach the target. On the one hand, passively responding to the user solely based on the conversation context would achieve high smoothness but may take many turns to reach the target, but on the other hand, directly jumping to the target word by ignoring the conversation context would minimize the number of turns but produce non-smooth keyword transitions.  \citet{tang2019target} proposed to break down the problem into two sub-problems: next-turn keyword selection and keyword-augmented response retrieval. \citet{tang2019target} proposed a next-turn keyword predictor and a rule-based keyword selection strategy to solve the first sub-problem, allowing the agent to know what is the next keyword to talk about given the conversation history and the target keyword. In addition, \citet{tang2019target} proposed a keyword-augmented response retrieval model to solve the second sub-problem, allowing the agent to produce a response that is relevant to the selected keyword.    However, there are two major limitations in existing studies . First, the training and evaluation datasets for next-turn keyword prediction are directly extracted from conversations without human annotations, thus, the majority of the ground-truth keyword transitions are noisy and have low correlations with human judgements. As illustrated in Figure , only a few keyword transitions in a conversation are considered relevant. In fact, in our human annotation studies of over 600 keyword transitions, we found that around 70\% of keyword transitions in the next-turn keyword prediction datasets are rated as not relevant, which renders the trained next-turn keyword predictor in existing studies less reliable.  Second, the rule-based keyword selection strategy primarily leverages the cosine similarity between word embeddings to select keywords that are closer to the target keyword. Word embeddings are trained based on the distributional hypothesis that words that have similar contexts have similar meanings, which may not reflect how humans relate words in conversational turn-taking.  In this paper, we assume that human conversations are grounded on commonsense and propose a keyword-guided neural conversational model that can leverage external commonsense knowledge graphs  for both next-turn keyword selection and keyword-augmented response retrieval. Humans rely on commonsense to reason, and commonsense reasoning plays an important role in the cognitive process of conversational turn-taking . Relying on a CKG for keyword transition would allow the agent to select a more target-related keyword for the next-turn.  Moreover, we leverage commonsense triplets from the CKG using Graph Neural Networks  for both next-turn keyword prediction and keyword-augmented response retrieval to achieve more accurate predictions.   In summary, our contributions are as follows:     In this work, we formulate the Contract Inconsistency Checking  problem, an automatic contract analysis task with significant practical importance, and we propose a novel end-to-end Pair-wise Blank Resolution  framework to predict the consistency relation for every two blanks with high accuracy. In PBR, we extend the Transformer encoder architecture and propose \texttt{BlankCoder}, an off-the-shelf effective blank modeling method that could easily generalize to other tasks such as text infilling. Extensive experiments show that our model can significantly and consistently outperform existing baselines, yielding a promising balanced accuracy of  and an F1 score of . In the future, we plan to consider more complex cases  and explore more complex consistency checking scenarios that require logical reasoning.    .     
"," We study the problem of imposing conversational goals/keywords on open-domain conversational agents, where the agent is required to lead the conversation to a target keyword smoothly and fast. Solving this problem enables the application of conversational agents in many real-world scenarios, e.g., recommendation and psychotherapy. The dominant paradigm for tackling this problem is to 1) train a next-turn keyword classifier, and 2) train a keyword-augmented response retrieval model. However, existing approaches in this paradigm have two limitations: 1) the training and evaluation datasets for next-turn keyword classification are directly extracted from conversations without human annotations, thus, they are noisy and have low correlation with human judgements, and 2) during keyword transition, the agents solely rely on the similarities between word embeddings to move closer to the target keyword, which may not reflect how humans converse. In this paper, we assume that human conversations are grounded on commonsense and propose a keyword-guided neural conversational model that can leverage external commonsense knowledge graphs  for both keyword transition and response retrieval. Automatic evaluations suggest that commonsense improves the performance of both next-turn keyword prediction and keyword-augmented response retrieval. In addition, both self-play and human evaluations show that our model produces responses with smoother keyword transition and reaches the target keyword faster than competitive baselines.",435
"   Despite of remarkable progress made in NMT recently , most NMT systems are still prone to translation errors caused by noisy input sequences. One common type of input noise is homophone noise, where words or characters are mis-recognized as others with same or similar pronunciation in ASR or input systems for non-phonetic languages , as illustrated by the example in Table.   Previous works suggest that incorporating phonetic embeddings into NMT and augmenting training data with adversarial examples with injected homophone noise would alleviate this issue. Intuitively, humans usually have no trouble in disambiguating sentences corrupted with moderate homophone noise via context and syllable information. We propose a human-inspired robust NMT framework tailored to homophone noise for Chinese-English translation, which is composed of a homophone noise detector  and a syllable-aware NMT  model.     \\ Output of NMT~&~build a primary school \\ \specialrule{0.05em}{3pt}{3pt} Noisy Input~&~ \\  Output of NMT~&~suggest a primary school \\  \specialrule{0.05em}{3pt}{3pt} Mixed Transcript~&~ \\  Output of Ours~&~build a primary school\\ \bottomrule[1pt] \end{tabular}   Due to the lack of data annotated with homophone noise, we propose to train our detector on monolingual data in a self-supervised manner, where Chinese characters sequences as input and their corresponding syllables sequence as label to predict the possibility that a character is homophone noise. The identified homophone errors from a source sentence are then converted into corresponding syllables to produce a new source sequence mixed with characters and syllables. Augmenting bilingual training data with instances where original source sentences are substituted with their corresponding character-syllable-mixed sequences, we train the SANMT model to translate such unconventional inputs. To examine the effectiveness of our proposed model, we conduct extensive experiments on both artificial noisy test sets and a real-world noise test set with homophone noise in speech translation  scenario. The test set will be released soon. Our experimental results on ChineseEnglish translation clearly show that the proposed method is not only significantly superior to previous approaches in alleviating the impact of homophone noise on NMT, but also achieves a substantial improvement on the clean text. %Due to the lack of data annotated with homophone noise, we propose to train our detector on monolingual data in a self-supervised manner, where Chinese characters are automatically transformed into syllables to predict homophone noise. The identified homophone errors from a source sentence are then converted into corresponding syllables to produce a new source sequence mixed with characters and syllables. Augmenting training data with instances where original source sentences are substituted with their corresponding character-syllable-mixed sequences, we train the SANMT model to translate such unconventional inputs. To examine the effectiveness of our proposed model, we conduct extensive experiments on both artificial noisy test sets and a real-world noise test set with homophone noise in speech translation  scenario. The test set will be released soon. Our experimental results on ChineseEnglish translation clearly show that the proposed method is not only significantly superior to previous approaches in alleviating the impact of homophone noise on NMT, but also achieves a substantial improvement on the clean text.       We study the problem of imposing conversational goals/keywords on open-domain conversational agents. The keyword transition module in existing approaches suffer from noisy datasets and unreliable transition strategy. In this paper, we propose to ground keyword transitions on commonsense and propose two GNN-based models for the tasks of next-turn keyword transition and keyword-augmented response retrieval, respectively. Extensive experiments show that our proposed model obtains substantially better performance on these two tasks than competitive baselines. In addition, the model analysis suggests that CKG triplets and our proposed CKG-guided keyword selection strategy are helpful in learning utterance representation and keyword transition, respectively. Finally, both self-play simulations and human evaluations show that our model can achieve better success rate, reach the target keyword faster, and produce smoother conversations than baselines.  
"," In this paper, we propose a robust neural machine translation  framework. The framework consists of a homophone noise detector and a syllable-aware NMT model to homophone errors. The detector identifies potential homophone errors in a textual sentence and converts them into syllables to form a mixed sequence that is then fed into the syllable-aware NMT. Extensive experiments on Chinese$\rightarrow$English translation demonstrate that our proposed method not only significantly outperforms baselines on noisy test sets with homophone noise, but also achieves a substantial improvement on clean text.",436
" In recent years, there has been a dramatic surge in the adoption of voice assistants such as Amazon Alexa, Apple Siri, and Google Assistant. Customers use them for a variety of tasks such as playing music and online shopping.  These voice assistants are built on complex Spoken Language Understanding  systems that are typically too large to store on an edge device such as a mobile phone or a smart speaker. Hence, user traffic is routed through a cloud server to process requests. This has led to privacy concerns and fueled the push for tiny AI and edge processing, where the user requests are processed on the device itself.   Traditional SLU systems consist of a two-stage pipeline, an Automatic Speech Recognition  component that processes customer speech and generates a text transcription , followed by a Natural Language Understanding  component that maps the transcription to an actionable hypothesis consisting of intents and slots . An end-to-end  system that goes directly from speech to the hypothesis would help make the SLU system smaller and faster, allowing it to be stored on an edge device. It could potentially also be better optimized than a pipeline since it eliminates cascading errors.  However, E2E systems are not used in practice because they have some key issues. These systems are hard to build since they consist of large neural components such as transformers and require massive amounts of E2E training data. They also don't make use of the vastly available training data for the ASR and NLU components that could be used to enhance their performance, because the examples in these datasets may not be aligned to create an E2E training sample. Another issue is feature expansion, a scenario where a new domain, with new intents and slots, is added to the voice assistant's capabilities. Here, developers typically only have access to some synthetically generated text-hypothesis examples. Speech data isn't readily available and it is very expensive to collect. E2E models thus fail as they require lots of new audio and hypothesis data to learn this new domain.  In this work, we build an E2E model that mitigates these issues using transfer learning. We call it the Audio-Text All-Task  Model. AT-AT is an E2E transformer-based model that is jointly trained on multiple audio-to-text and text-to-text tasks. Examples of these tasks include speech recognition , hypothesis prediction from speech , masked LM prediction , and hypothesis prediction from text . Our model achieves this by converting data from all these tasks into a single audio-to-text or text-to-text format. Figure shows this joint training phase in detail. Our findings indicate that there is significant knowledge transfer taking place from multiple tasks, which in turn helps in downstream model performance. We see that the AT-AT pretrained model shows improved performance on SLU hypothesis prediction on internal data collected from Alexa traffic. We also report state-of-the-art results on two public datasets: FluentSpeech , and SNIPS Audio .   Furthermore, since our model contains a text encoder, it can consume both audio and text inputs to generate a target sequence. By jointly training on both audio-to-text and text-to-text tasks, we hypothesize that this model learns a shared representation for audio and text inputs. This allows us to simply train on new text-to-text data and get audio-to-text performance for free, giving us a way to do E2E hypothesis prediction in a zero-shot fashion during feature expansion. We test this approach on an internal dataset from Alexa traffic, and an external dataset, Facebook TOP . Since TOP consists of only text data, we collected speech data for the test split using an internal tool at Amazon. We will soon release this dataset.  In summary, our contributions are as follows.       In this paper, we have presented a novel framework composed of a homophone error detector and a SANMT model to cope with homophone noise. Experimental results show that our method not only achieves substantial improvement over previous robust NMT baselines both on the test sets with artificial or real-world noise, but also outperforms the NMT baseline on the clean test sets. We consider that future studies could modeling noise detection and NMT jointly.    References should be produced using the bibtex program from suitable   BiBTeX files . The IEEEbib.bst bibliography   style file from IEEE produces unsorted bibliography list.   -------------------------------------------------------------------------  \clearpage 
"," Voice Assistants such as Alexa, Siri, and Google Assistant typically use a two-stage Spoken Language Understanding pipeline; first, an Automatic Speech Recognition  component to process customer speech and generate text transcriptions, followed by a Natural Language Understanding  component to map transcriptions to an actionable hypothesis. An end-to-end  system that goes directly from speech to a hypothesis is a more attractive option. These systems were shown to be smaller, faster, and better optimized. However, they require massive amounts of end-to-end training data and in addition, don't take advantage of the already available ASR and NLU training data.  In this work, we propose an E2E system that is designed to jointly train on multiple speech-to-text tasks, such as ASR  and SLU , and text-to-text tasks, such as NLU . We call this the Audio-Text All-Task  Model and we show that it beats the performance of E2E models trained on individual tasks, especially ones trained on limited data. We show this result on an internal music dataset and two public datasets, FluentSpeech and SNIPS Audio, where we achieve state-of-the-art results. Since our model can process both speech and text input sequences and learn to predict a target sequence, it also allows us to do zero-shot E2E SLU by training on only text-hypothesis data  from a new domain. We evaluate this ability of our model on the Facebook TOP dataset and set a new benchmark for zeroshot E2E performance. We will soon release the audio data collected for the TOP dataset for future research.",437
"  Neural Machine Translation   has achieved state of the art in various MT systems, including rich and low resource language pairs . However, the quality of low-resource MT is quite unpretentious due to the lack of parallel data while it has achieved better results on systems of the available resource. Therefore, low-resource MT is one of the essential tasks investigated by many previous works .    Recently, some works present MT systems that have achieved remarkable results for low-resource language . Inspired by these works, we collect data from the TED Talks domain, then attempt to build multilingual MT systems from French, English-Vietnamese. Experiments demonstrate that both language pairs: French-Vietnamese and English-Vietnamese have achieved significant performance when joining the training. %  Although multilingual MT can reduce the sparse data in the shared space by using word segmentation, however, rare words still exist, evenly they are increased more if languages have a significant disparity in term vocabulary. Previous works suggested some strategies to reduce rare words such as using translation units at sub-word and character levels or generating a universal representation at the word and sentence levels . These help to downgrade the dissimilarity of tokens shared from various languages. However, these works require learning additional parameters in training, thus increasing the size of models.   Our paper presents two methods to augment the translation of rare words in the source space without modifying the architecture and model size of MT systems:  exploiting word similarity. This technique has been mentioned by previous works . They employ monolingual data or require supervised resources like a bilingual dictionary or WordNet, while we leverage relation from the multilingual space of MT systems.  Adding a scalar value to the rare word embedding in order to facilitate its translation in the training process.  %  Due to the fact that NMT tends to have bias in translating frequent words, so rare words  often have less opportunity to be considered. Our ideal is inspired by the works of .  and  proposed various solutions to urge for translation of rare words, including modification embedding in training. They only experimented with recurrent neural networks  while our work uses the state-of-the-art transformer architecture.  transforms the word embedding of a token into the universal space, and they learn plus parameters while our method does not.  We apply our strategies in our fine-tuning processes, and we show substantial improvements of the systems after some epochs only.    Monolingual data are widely used in NMT to augment data for low-resource NMT systems . Back-translation  is known as the most popular technique in exploiting target-side monolingual data to enhance the translation systems while the self-learning method  focuses on utilizing source-side monolingual data. Otherwise, the dual-learning strategy  also suggests using both source- and target-side monolingual data to tackle this problem. Our work investigates the self-learning method  on the low-resource multilingual NMT systems specifically related to Vietnamese. Besides, monolingual data are also leveraged in unsupervised or zero-shot translation.  % learn the lexical relative between one token on a source language and the other once from another source language without modifying the system architecture as well as the model size. We also do not use any additional resources in our systems.   The main contributions of our work are:    In section 2, we review the transformer architecture used for our experiments. The brief of multilingual translation is shown in section 3. Section 4 presents our methods to deal with rare words in multilingual translation scenarios. The exploitation of monolingual data for low-resource multilingual MT is discussed in section 5. Our results are described in section 6, and related work is shown in section 7. Finally, the paper ends with conclusions and future work. %    Our evaluation clearly shows that there is a lot of knowledge transfer happening between various speech processing tasks. AT-AT when evaluated on downstream SLU tasks benefits significantly when it is pretrained with additional ASR data. This result holds when the ASR data is from the same domain  and also when the data is from a different domain . It also holds across different dataset sizes. We see that the pretraining is extremely helpful for datasets with training data size of about a 1000 such as SNIPS, and it remains helpful all the way to our limited internal music dataset  and the full music dataset . We believe this is because the decoder learns a good language model by seeing additional ASR data. We can also think of these additional pretraining tasks as good regularizers.    Our zeroshot results with AT-AT are even more interesting. We designed a way to train an end-to-end model on new data without using any corresponding audio data, real or synthetically generated, and our model's performance, while not matching an end-to-end model trained on real audio data, is still remarkable. Our approach can be adapted to make use of synthetic data if we have access to a TTS system to further improve performance. We managed to learn a shared audio-text model, not by explicitly enforcing a loss penalty to force the audio and text hidden states into the same space, but by constraining the decoder and forcing the model to learn jointly from different input sources.    On a closing note, we would like to remark that AT-AT somewhat mimics actual human learning. We typically read a lot more words than we hear. But when we hear a word for the first time, we transfer our knowledge of that word from when we read it. AT-AT similarly learns to understand and perform NLU tagging from text and then applies this knowledge when it is given speech.  \section{Conclusion} We propose the Audio-Text All-Task  model that uses transfer learning to improve the performance on end-to-end SLU. AT-AT beat the performance of E2E models on our internal music data, both in the full and low-resource settings. It also achieved state-of-the-art performance on the FluentSpeech  and SNIPS audio datasets  with significant improvements over prior models. AT-AT also demonstrated its ability to perform zeroshot E2E SLU, without access to a TTS system, and by learning a shared audio-text representation without any explicit loss penalty to force the audio and text hidden states into the same space. We also showed how AT-AT can work in conjunction with a TTS system to further improve E2E performance. It achieves a zeroshot E2E EM Accuracy of 70.60 on the TOP dataset.    We set this new benchmark and release the audio data for the TOP dataset for future research.   On a closing note, we would like to remark that AT-AT somewhat mimics actual human learning. We typically read a lot more words than we hear. But when we hear a word for the first time, we transfer our knowledge of that word from when we read it. AT-AT similarly learns to understand and perform NLU tagging from text and then applies this knowledge when it is given speech.    
"," % Prior works have demonstrated that a low-resource language pair can be benefited from a multilingual machine translation  system which relies on the jointly training many language pairs. In this paper, we propose two simple strategies to address the rare word issue in multilingual MT systems for two low-resource language pairs: French-Vietnamese,  English-Vietnamese. The first strategy learns  dynamically word similarity of tokens in the shared space among source languages whilst the other one augments the translation ability of rare words through updating their embeddings during the training. In addition, we attempt to leverage monolingual data which is generated from multilingual MT to reinforce synthetic parallel in the data sparsity situation. We show that significant improvements of up to +1.62 and +2.54 BLEU points over the bilingual baseline systems for both language pairs and release datasets for the research community.  Prior works have demonstrated that a low-resource language pair can benefit from multilingual machine translation  systems, which rely on many language pairs' joint training. This paper proposes two simple strategies to address the rare word issue in multilingual MT systems for two low-resource language pairs: French-Vietnamese and English-Vietnamese. The first strategy is about dynamical learning word similarity of tokens in the shared space among source languages while another one attempts to augment the translation ability of rare words through updating their embeddings during the training. Besides, we leverage monolingual data for multilingual MT systems to increase the amount of synthetic parallel corpora while dealing with the data sparsity problem. We have shown significant improvements of up to +1.62 and +2.54 BLEU points over the bilingual baseline systems for both language pairs and released our datasets for the research community.",438
" % Fabian: Describing what it is Entity linking  is the task of mapping entity mentions in text documents to standard entities in a given knowledge base. For example, the word ``Paris'' is ambiguous: It can refer either to the capital of France or to a hero of Greek mythology. Now given the text ``Paris is the son of King Priam'', the goal is to determine that, in this sentence, the word refers to the Greek hero, and to link the word to the corresponding entity in a knowledge base such as YAGO  or DBpedia .  %Intriguingly, the Greek hero also goes by the name of ``Alexander''. Thus, the words ``Paris'' and ``Alexander'' are synonymous, and if they both refer to the Greek hero in some input text, they both have to be linked to the same entity in the knowledge base.  % Fabian: Describing why it's important In the biomedical domain, entity linking maps mentions of diseases, drugs, and measures to normalized entities in standard vocabularies. It is an important ingredient for automation in medical practice, research, and public health. Different names of the same entities in Hospital Information Systems seriously hinder the integration and use of medical data. If a medication appears with different names, researchers cannot study its impact, and patients may erroneously be prescribed the same medication twice.   % Fabian: Describing why it's difficult The particular challenge of biomedical entity linking is not the ambiguity: a word usually refers to only a single entity. Rather, the challenge is that the surface forms vary markedly, due to abbreviations, morphological variations, synonymous words, and different word orderings.  For example, ``Diabetes Mellitus, Type 2'' is also written as ``DM2'' and ``lung cancer'' is also known as ``lung neoplasm malignant''. In fact, the surface forms vary so much that all the possible expressions of an entity cannot be known upfront. This means that standard disambiguation systems cannot be applied in our scenario, because they assume that all forms of an entity are known. %, and thus they cannot be applied in our scenario.  One may think that variation in surface forms is not such a big problem, as long as all variations  of an entity are sufficiently close to its canonical form. Yet, this is not the case. For example, the phrase ""decreases in hemoglobin"" could refer to at least 4 different entities in MedDRA, which all look alike:  ""changes in hemoglobin"", ""increase in hematocrit"", ""haemoglobin decreased"", and ""decreases in platelets"". In addition, biomedical entity linking cannot rely on external resources such as  alias tables, entity descriptions, or entity co-occurrence, which are often used in classical entity linking settings.   % Fabian: what has been done For this reason, entity linking approaches have been developed particularly for biomedical entity linking. Many methods use deep learning: the work of \citet{li2017cnn} casts biomedical entity linking as a ranking problem,  leveraging convolutional neural networks .  More recently, the introduction of BERT has advanced the performance of many NLP tasks, including in the biomedical domain .  BERT creates rich pre-trained representations on unlabeled data and achieves state-of-the-art performance on a large suite of sentence-level and token-level tasks, outperforming many task-specific architectures. However, considering the number of parameters of pre-trained BERT models,  the improvements brought by fine-tuning them come with a heavy computational cost and memory footprint.  This is a problem for energy efficiency, for smaller organizations, or in poorer countries.  In this paper, we introduce a very lightweight model that achieves a performance statistically indistinguishable from the state-of-the-art BERT-based models. The central idea is to use an alignment layer with an attention mechanism,  which can capture the similarity and difference of corresponding parts between candidate and mention names. Our model is 23x smaller and 6.4x faster than BERT-based models on average; and more than twice smaller and faster than the lightweight BERT models. Yet, as we show, our model achieves comparable performance on all standard benchmarks. Further, we can show that adding more complexity to our model is not necessary: the entity-mention priors, the context around the mention, or the coherence of extracted entities \cite[as used, e.g., in][]{hoffart2011robust} do not improve the results any further. \footnote{All data and code are available at  \url{https://github.com/tigerchen52/Biomedical-Entity-Linking}.}     We have built multilingual MT systems for two low-resource language pairs: English-Vietnamese and French-Vietnamese, and proposed two approaches to tackle rare word translation. We show that our approaches bring significant improvements to our MT systems. We find that the pseudo bilingual can furthermore enhance a multilingual NMT system in case of French  Vietnamese translation task.  In the future, we would like to use more language pairs in our systems and to combine proposed methods in order to evaluate the effectiveness of our MT systems.   
"," Biomedical entity linking aims to map biomedical mentions, such as diseases and drugs, to standard entities in a given knowledge base.  The specific challenge in this context is that the same biomedical entity can have a wide range of names,  including synonyms, morphological variations, and names with different word orderings.  Recently, BERT-based methods have advanced the state-of-the-art by allowing for rich representations of word sequences. However, they often have hundreds of millions of parameters and require heavy computing resources, which limits their applications in resource-limited scenarios. Here, we propose a lightweight neural method for biomedical entity linking, which needs just a fraction of the parameters of a BERT model and much less computing resources.  Our method uses a simple alignment layer with attention mechanisms to capture the variations between mention and entity names. Yet, we show that our model is competitive with previous work on standard evaluation benchmarks.",439
" % background Sentence semantic matching is a fundamental Natural Language Processing~ task that tries to infer the most suitable label for a given sentence pair. For example, Natural Language Inference~ targets at classifying the input sentence pair into one of the three relations~. Paraphrase Identification~ aims at identifying whether the input sentence pair expresses the same meaning. Figure gives some examples with different semantic relations from different datasets.    % Current state As a fundamental technology, sentence semantic matching has been applied successfully into many NLP fields, e.g., information retrieval, question answering, and dialog system.  Currently, most work leverages the advancement of representation learning techniques to tackle this task.  They focus on input sentences and design different architectures to explore sentence semantics comprehensively and precisely.  Among all these methods, BERT plays an important role.  It adopts multi-layer transformers to make full use of large corpus~ for the powerful pre-trained model.  Meanwhile, two self-supervised learning tasks~ are designed to better analyze sentence semantics and capture as much information as possible.  % more citation Based on BERT, plenty of work has made a big step in sentence semantic modeling.    In fact, since relations are the predicting targets of sentence semantic matching task, most methods do not pay enough attention to the relation learning.  They just leverage annotated labels to represent relations, which are formulated as one-hot vectors.  However, these independent and meaningless one-hot vectors cannot reveal the rich semantic information and guidance of relations, which will cause an information loss.  \citeauthor{gururangan2018annotation}~ has observed that different relations among sentence pairs imply specific semantic expressions.  Taking Figure as an example, most sentence pairs with ``contradiction'' relation contain negation words~.  ``entailment'' relation often leads to exact numbers being replaced with approximates~.  ``Neutral'' relation will import some correct but irrelevant information~.  Moreover, the expressions between sentence pairs with different relations are very different.  Therefore, the comparison and contrastive learning among different relations~ can help models to learn more about the semantic information implied in the relations, which in turn helps to strengthen the sentence analysis ability of models. They should be treated as more than just meaningless one-hot vectors.   One of the solutions for better relation utilization is the embedding method inspired by Word2Vec.  Some researchers try to jointly encode the input sentences and labels in the same embedding space for better relation utilization during sentence semantic modeling.  Despite the progress they have achieved, label embedding method requires more data and parameters to achieve better utilization of relation information.  It still cannot fully explore the potential of relations due to the small number of relation categories or the lack of explicit label embedding initialization.   To this end, in this paper, we propose a novel \fullname~approach to make full use of relation information in a simple but effective way.  In concrete details, we first utilize pre-trained BERT to model semantic meanings of the input words and sentences from a global perspective.  Then, we develop a CNN-based encoder to obtain partial information~ of sentences from a local perspective.  Next, inspired by self-supervised learning methods in BERT training processing, we propose a Relation of Relation~ classification task to enhance the learning ability of \shortname~for the implicit common features corresponding to different relations.    Moreover, a triplet loss is used to constrain the model, so that the intra-class and inter-class relations are analyzed better.   Along this line, input sentence pairs with the same relations will be represented much closer and vice versa further apart.  Relation information is properly integrated into sentence pair modeling processing, which is in favor of tackling the above challenges and improving the model performance.  Extensive evaluations of two sentence semantic matching tasks  demonstrate the effectiveness of our proposed \shortname~and its advantages over state-of-the-art sentence semantic matching baselines.       In this work, we proposed a novel method to extract rationales for neural predictions. Our method uses an adversarial-based technique to make a selector-predictor model learn from a guider model. In addition, we proposed a novel regularizer based on language models, which makes the extracted rationales semantically fluent.  In this way, the ``guider"" model  tells the selector-predictor model what kind of information  remains unselected or over-selected.   We conducted experiments on a task of sentiment analysis and three tasks from the legal domain.  The experimental results showed that our method improves the selection of rationales by a large margin.   This regularizer  also gives priority to important adjacent word pairs when considering whether to select or unselect them simultaneously,  which further refines the rationales.   Finally, we have conducted experiments on two datasets to prove the effectiveness of our model.  We conducted experiments on two datasets to prove the effectiveness of our model.  As future work, the main architecture of our model can be directly applied to other domains, e.g., images or tabular data. However, it remains an open question what would be a good regularizer for these domains.   For example, variational autoencoders with discrete latent space, providing rationales to different kinds of deep learning applications.     
"," 	% background 	Sentence semantic matching is one of the fundamental tasks in natural language processing, which requires an agent to determine the semantic relation among input sentences.  	% current state 	Recently, deep neural networks have achieved impressive performance in this area, especially BERT.  	% problem 	Despite their effectiveness, most of these models treat output labels as meaningless one-hot vectors, underestimating the semantic information and guidance of relations that these labels reveal, especially for tasks with a small number of labels.  	% solution 	To address this problem, we propose a \fullname~for sentence semantic matching. 	 	Specifically, we first employ BERT to encode the input sentences from a global perspective. 	Then a CNN-based encoder is designed to capture keywords and phrase information from a local perspective.  	To fully leverage labels for better relation information extraction, we introduce a self-supervised relation of relation classification task for guiding \shortname~to consider more about relations.  	Meanwhile, a triplet loss is employed to distinguish the intra-class and inter-class relations in a finer granularity. 	% result 	Empirical experiments on two sentence semantic matching tasks demonstrate the superiority of our proposed model.  	As a byproduct, we have released the codes to facilitate other researches.",440
" 	Discovering novel user intents is important to improve the service quality in dialogue systems. By analyzing the discovered new intents, we may find underlying user interests, which could provide business opportunities and guide the improvement direction.  	 	 	Intent discovery has attracted much attention in recent years. Many researchers regard it as an unsupervised clustering problem, and they manage to incorporate some weak supervised signals to guide the clustering process. For example,~\citet{hakkani-tr2013a} propose a hierarchical semantic clustering model and collect web page clicked information as implicit supervision for intent discovery.~\citet{hakkani2015clustering} utilize a semantic parsing graph as extra knowledge to mine novel intents during clustering.~\citet{Padmasundari2018} benefit from the consensus predictions of multiple clustering techniques to discover similar semantic intent-wise clusters.~\citet{haponchyk2018supervised} cluster questions into user intent categories under the supervision of structured outputs.~\citet{shi2018auto} extract intent features with an autoencoder and automatically label the intents with a hierarchical clustering method. 	  	However, all of the above methods fail to leverage the prior knowledge of known intents. These methods assume that the unlabeled samples are only composed of undiscovered new intents. A more common case is that some labeled data of known intents are accessible and the unlabeled data are mixed with both known and new intents. As illustrated in Figure, we may have a few labeled samples  of known intents in advance. The remaining known and new intent samples are all unlabeled. Our goal is to find known intents and discover new intents with the prior knowledge of limited labeled data. Our previous work CDAC+ directly tackles this problem. Nevertheless, it uses pairwise similarities as weak supervised signals, which are ambiguous to distinguish a mixture of unlabeled known and new intents. Thus, the performance drops with more new intents. 	 	To summarize, there are two main difficulties in our task. On the one hand, it is challenging to effectively transfer the prior knowledge from known intents to new intents with limited labeled data. On the other hand, it is hard to construct high-quality supervised signals to learn friendly representations for clustering both unlabeled known and new intents. 	 	To solve these problems, we propose an effective method to leverage the limited prior knowledge of known intents and provide high-quality supervised signals for feature learning.  As illustrated in Figure, we firstly use the pre-trained BERT model to extract deep intent features. Then, we pre-train the model with the limited labeled data under the supervision of the softmax loss. We retain the pre-trained parameters and use the learning information to obtain well-initialized intent representations. Next, we perform clustering on the extracted intent features and estimate the cluster number   by eliminating the low-confidence clusters. 	 	As most of the training samples are unlabeled, we propose an original alignment strategy to construct high-quality pseudo-labels as supervised signals for learning discriminative intent features. For each training epoch, we firstly perform k-means on the extracted intent features, and then use the produced cluster assignments as pseudo-labels for training the neural network. However, the inconsistent assigned labels cannot be directly used as supervised signals, so we use the cluster centroids as the targets to obtain the alignment mapping between pseudo-labels in consequent epochs. Finally, we perform k-means again for inference. Benefit from the relatively consistent aligned targets, our method can inherit the history learning information and boost the clustering performance. 	 	We summarize our contributions as follows. Firstly, we propose a simple and effective method that successfully generalizes to mass of new intents and estimate the number of novel classes with limited prior knowledge of known intents. Secondly, we propose an effective alignment strategy to obtain high-quality self-supervised signals by learning discriminative features to distinguish both known and new intents. Finally, extensive experiments on two benchmark datasets show our approach yields better and more robust results than the state-of-the-art methods.  	 	  In this paper, we presented a simple but effective method named \shortname~for sentence semantic matching.  This method not only uses powerful BERT and CNN to encode sentences from global and local perspectives, but also makes full use of relation information for better performance enhancement.  Specifically, we design a R classification task to help \shortname~for learning the implicit common knowledge from the pairwise relation learning processing.  Moreover, a triplet loss is employed to constrain \shortname~for better triplet based relation learning and intra-class and inter-class information analyzing.  Extensive experiments on NLI and PI tasks demonstrate the superiority of \shortname. In the future, we plan to combine the advantages of label embedding method for better sentence semantic comprehension.    
"," 		Discovering new intents is a crucial task in dialogue systems. Most existing methods are limited in transferring the prior knowledge from known intents to new intents. They also have difficulties in providing high-quality supervised signals to learn clustering-friendly features for grouping unlabeled intents. In this work, we propose an effective method, Deep Aligned Clustering, to discover new intents with the aid of the limited known intent data. Firstly, we leverage a few labeled known intent samples as prior knowledge to pre-train the model. Then, we perform k-means to produce cluster assignments as pseudo-labels. Moreover, we propose an alignment strategy to tackle the label inconsistency problem during clustering assignments. Finally, we learn the intent representations under the supervision of the aligned pseudo-labels. With an unknown number of new intents, we predict the number of intent categories by eliminating low-confidence intent-wise clusters. Extensive experiments on two benchmark datasets show that our method is more robust and achieves substantial improvements over the state-of-the-art methods. The codes are released at \url{https://github.com/thuiar/DeepAligned-Clustering}.",441
" The U.S.~NIH's precision medicine  initiative calls for designing treatment and preventative interventions considering genetic, clinical, social, behavioral, and environmental exposure variability among patients. The initiative rests on the widely understood finding that considering individual variability is critical in tailoring healthcare interventions to achieve substantial progress in reducing disease burden worldwide. Cancer was chosen as its near term focus with the eventual aim of expanding to other conditions. As the biomedical research enterprise strives to fulfill the initiative's goals, computing needs are also on the rise in drug discovery, predictive modeling for disease onset and progression, and in building NLP tools to curate information from the evidence base being generated.  \subsection{TREC Precision Medicine Series}     \end{table}   In a dovetailing move, the U.S.~NIST's  TREC  has been running a PM track since 2017 with a focus on cancer. The goal of the TREC-PM task is to identify the most relevant biomedical articles and clinical trials for an input patient case. Each case is composed of    a disease name,   a gene name and genetic variation type, and  demographic information . Table shows two example cases from the 2019 track. So the search is ad hoc in the sense that we have a free text input in each facet but  the    facets themselves highlight the PM related attributes that ought to characterize the retrieved documents. We believe this style of faceted retrieval is going to be more common across medical IR tasks for many conditions as the PM initiative continues its mission.   \subsection{Vocabulary Mismatch and Neural IR}  The vocabulary mismatch problem is a prominent issue in medical IR given the large variation in the expression of medical concepts and events. For example, in the query ``What is a potential side effect for Tymlos?'' the drug is referred by its brand name. Relevant scientific literature may contain the generic name Abaloparatide more frequently. Traditional document search engines have clear limitations on resolving   mismatch issues. The IR community has extensively explored methods to address the vocabulary mismatch problem, including query expansion based on relevance feedback, query term re-weighting, or query reconstruction by optimizing the query syntax.  Several recent studies highlight exploiting neural network models for query refinement in document retrieval  settings. \citet{nogueira2017task}  address  this issue by generating a transformed query from the initial query using a neural model.  They use reinforcement  learning  to train it where an agent  learns to reformulate the initial query to maximize the expected return  through actions . In a different approach, \citet{narayan2018ranking}  use RL for sentence ranking for extractive summarization.  \subsection{Our Contributions}  In this paper, building on the BERT architecture, we focus on a different hybrid document scoring and reranking setup involving three components: .~a document relevance classification model, which predicts  whether a document is relevant to the given query ; .~a keyword extraction model which spots tokens in a document that are likely to be seen in PM related queries; and .~an abstractive document summarization model that generates a pseudo-query given the document context and a facet type  via the BERT encoder-decoder setup. The keywords ) and the pseudo-query ) are together compared with the original query to generate a score. The scores from all the components are combined to rerank top   documents returned with a basic Okapi BM25 retriever from a Solr index of the corpora. %This is critical because neural document-query matching and summarization are expensive operations that cannot practically scale to the full corpus.  Our main innovation is in pivoting from the focus on queries by previous methods to emphasis on transforming candidate documents into pseudo-queries via summarization. Additionally, while generating the pseudo-query, we also let the   decoder output concept codes from biomedical terminologies that capture disease and gene names. We do this by embedding both words and concepts in a common semantic space before letting the decoder generate summaries that include concepts. Our overall architecture was evaluated using the TREC-PM datasets  with the 2019 dataset used as the test set. The results show an absolute  improvement in P@10 compared to prior best approaches while obtaining a small  gain in R-Prec. Qualitative analyses also highlight how the summarization is able to focus on document segments that are highly relevant to patient cases.    	In this work, we have introduced an effective method for discovering new intents. Our method successfully transfers the prior knowledge of limited known intents and estimates the number of intents by eliminating low-confidence clusters. Moreover, it provides more stable and concrete supervised signals to guide the clustering process. We conduct extensive experiments on two challenging benchmark datasets to evaluate the performance. Our method achieves significant improvements over the compared methods and obtains more accurate estimated cluster numbers with limited prior knowledge. In the future, we will try different clustering methods to produce supervised signals and explore more self-supervised methods for representation learning. 	 	 	
"," Information retrieval  for precision medicine  often involves looking for multiple pieces of evidence that characterize a patient case. This typically includes at least the name of a condition and a genetic variation that applies to the patient. Other factors such as demographic attributes, comorbidities, and social determinants may also be pertinent. As such, the retrieval problem is often formulated as ad hoc search but with multiple facets  that may need to be incorporated. In this paper, we present a document reranking approach that combines neural query-document matching and text summarization toward such retrieval scenarios. Our architecture builds on the basic BERT model with three specific components for reranking: . document-query matching . keyword extraction and . facet-conditioned abstractive summarization. The outcomes of  and  are used to essentially transform a candidate document into a concise summary that can be compared with the query at hand to compute a relevance score. Component  directly generates a matching score of a candidate document for a query. The full architecture benefits from the complementary potential of document-query matching and the novel document transformation approach based on summarization along PM facets. Evaluations using NIST's TREC-PM track datasets  show that our model achieves state-of-the-art performance. To foster reproducibility, our code is made available here: \url{https://github.com/bionlproc/text-summ-for-doc-retrieval}.",442
"  . }   In real-world dialogue systems, a substantial portion of all user queries are ambiguous ones for which the system is unable to precisely identify the underlying intent.  %For example, nearly 30\% of user queries in a real-world QA system are ambiguous questions. % Can't give statistics in an academic paper without mentioning details We observed that many such queries in our question answering  system exhibited one of the following two characteristics.  %The ambiguous questions in our QA system can be summarized into 2 types:\\ %  \\ %       Given such limited information, it is difficult for a system to accurately respond to a user's ambiguous queries, often resulting in that the user's needs cannot be addressed. For example, the specific intent underlying an utterance such as ``How to apply?"" remains obscure, because there are too many products related to the action of ``applying"". In practice, one often needs to fall back to human agents to assist with such requests, increasing the workload and cost. The main purpose of deployed automated systems is to reduce the human workload in scenarios such as customer service hotlines. The lack of an ability to deal with ambiguous questions may directly lead to these sessions being transferred to human agents. In our real-world customer service system, this affects up to 30\% of sessions. Hence, it is valuable to find an effective solution to clarify such ambiguous questions automatically, greatly reducing the number of cases requiring human assistance.   Automated question clarification involves confirming a user's intent through interaction.  %. % is essential for a Question Answering  system.  Previous work has explored asking questions . Unfortunately, clarification by asking questions requires substantial customization for the specific dialogue setting. It is challenging to define appropriate questions to guide users towards providing more accurate information. Coarse questions may leave users confused, while overly specific ones may fail to account for the specific information a user wishes to convey.   In our work, we thus instead investigate interactive clarification by providing the user with specific choices as options, such as intent options . Unlike previous work, we propose an end-to-end model that suggests labels to clarify ambiguous questions.  %  In our experiments, we will show our method significantly over performs rule based method in recall of potential FAQs.  %  This paper focused on closed-domain question clarification in dialogue, solving all kinds of ambiguous questions in one method. %濡紕纭﹂梻顕顣藉☉鍫燁劆娑撴槒顩﹂柅姘崇箖娴溿倓绨扮涵顔款吇閻€劍鍩涢幇蹇撴禈閵嗗倹婀侀崙鐘殿潚娴溿倓绨伴弬鐟扮础閿涘苯寮介梻顔藉灗閹绘劒绶甸悽銊﹀煕闁銆嶉妴鍌氬冀闂傤喚娈戦弬瑙勭《闁俺绻冮悽鐔稿灇濞戝牊顒犻梻顔煎綖閿涘苯顩ч弸婊冨冀闂傤噣妫舵０妯跨箖娴滃骸绱戦弨鎾呯礉鐎硅妲楀鏇炲弳娑撳秴褰叉０鍕埂閻ㄥ嫬娲栨径宥冨倷姘︽禍鎺旀畱閺傜懓绱￠柅姘崇箖缂佹瑥鍤惄绋垮彠闁銆嶆笟娑氭暏閹撮攱绉峰褝绱濆В鏂款洤閻╃ǹ鍙AQ閹存牜娴夐崗铏Х濮澭囧銆嶉妴 %Previous methods either solve lack of semantic elements questions or solve entity ambiguity questions. % %娑撳窋revious work娑撴槒顩﹂崠鍝勫焼: %1.閸欏秹妫堕惃鍕煙濞夋洟妫堕惃鍕６妫版ê銇婂閺鎾呯礉閻€劍鍩涢惃鍕礀缁涙柨褰查懗鐣岄兇缂佺喐甯存稉宥勭瑐閿涘本鍨ㄩ懓鍛晸閹存劒绔存稉顏勭发婵傚洦顏嗘畱闂傤噣顣,閻喎鐤勭化鑽ょ埠闁倻鏁ら懟锕傛 %2.query 缁墽鍋ч弰顖滄暏閸︺劍鎮崇槐銏犵穿閹垮海娈戦敍灞芥躬鐎电鐦藉鍕娑撳﹤銇婇柌宥忕礉娑撳秴褰查懗钘夋躬鐎电鐦介柌宀绮伴崙杞扮閸棙鎮崇槐銏㈢波閺 %閻╃ǹ鎮撹ぐ銏犵础閻ㄥ嫪姘︽禍鎺戠础闂傤噣顣藉鍕娴ｈ法鏁ゆ稉娑擃亜鐔娴滃侗MI閸滃瓥DF閻ㄥ嫯顫夐崚娆愭煙濞夋洩绱濈圭偤鐛欑拠浣规閹存垳婊戦惃鍕煙濞夋洘妯夐拋妞剧喘娴滃氦顫夐崚娆愭煙濞夋洏 %閹存垳婊戦幓鎰毉娑撶粔宥囩暆濞蹭胶娈戝☉鍫燁劆閺傝顢嶉敍宀娲块幒銉ュ灙閸戠儤顒犳稊澶屽仯閿涘矂鍌滄暏娴滃骸顕拠婵嗘簚閺 %Question clarification by asking question generated by model may receive unexpected reply from user like ``I'm not sure"" or generate a weird question in real application. Query refinement method  which helps to improve search results is not applicable for clarification in dialogue. We aimed to interact with user by concise phrases to clarify user's question. % In a closed-domain QA system, we believe that an ambiguous question has a series of potential clear questions. For example, in Figure~, there are at least three FAQ questions corresponding to ambiguous question ``How to apply"". We argue that the essence of clarifying ambiguous questions lies in finding the key points of differentiation between potential questions. It's possible to clarify the user's true intents by confirming key points with users as shown in Figure~. %  %  % An example of this sort of approach is given in Figure. Here, we consider a closed-domain QA system, where a typical method is to build an intent inventory to address high-frequency requests. In this setting, the set of unambiguous candidate labels for an ambiguous user utterance corresponds to a set of frequently asked questions covered by the intent inventory.  %By constraining the problem to close-domain, the potential clear questions of an ambiguous question is a finite set.  In a closed domain, we consider the candidate set to be finite. For example, in Figure, there are three specific intents corresponding to the ambiguous question ``How to apply"".   Our approach induces phrase tags as labels for each intent. Thus, we have a catalog of intents with corresponding labels that can be presented to the user. The challenge lies in selecting a suitable list of labels that can effectively clarify the ambiguous question. In our approach, the problem of finding the label sequence is formulated as a collection partitioning problem, where the objective is to cover as many elements as possible while distinguishing elements as clearly as possible.  % According to Aristotle, the definition of a species consists of genus proximum and differ. The differential is the attribute by which one species is distinguished from all others of the same genus.  The task of question clarification thus amounts to obtaining a suitable set of labels. %is to get a differential intents set of potential FAQs. % \todo{update with section 3.2}  % We will illustrate the method of finding such intents set in detail in the methodology section. % %  introduced methods to ask clarification questions for information that is missing from a given linguistic context.  use generative model to generate clarification questions for solving entity ambiguities. But it has some obstacles to use these methods in real application. One reason is users in real world sometimes doesn't respond as clarification question expected like just reply ``I'm not sure"". Compared withing ask a clarification question, we directly list potential ambiguities as options.  proposed a query refinement method based on reinforcement learning, which helps to improve search results in search engine. Limited to the form of a dialogue system, it's not practical to show long list of potential results in dialogue. We aimed to interact with user by concise phrases to clarify user's question. % % A similar idea from \citet{DBLP:conf/chiir/RadlinskiC17} also suggests that, a conversational interface may be easier for users to clarify their needs given precise choices rather than expecting them to come up with particular terms.  % The complete question clarification process in our work is illustrated in Figure . Through real-world application experiments, our method has a lower rate on transferring to human agents and significant higher CTR  than other baselines. Our method also performs better than other baselines on the recall of potential FAQs on our annotated corpora.  %This paper focuses on closed-domain question clarification in dialogue, solving all kinds of ambiguous questions in one method.   The main contributions of our work are:    %% This part is comparison between related works.  % We investigated related works to clarify ambiguous questions in QA. The classic solution is to rank the most semantic similar questions [ranker ref] to the ambiguous questions. However, considering the limitation to display information in a dialogue based QA system, generally only the three results can be displayed, resulting in that this method cannot cover enough potential clear questions. In our experiments, we use the relevance ranker as the baseline for comparison. The results show that the human transferring rate of our method is much lower than the ranking method. The second method is to ask clarification questions . . However, the method of generative clarification question has some limitations in the real-word QA system. The biggest obstacle is that the user's answer space maybe to too open to answer, which complicates the dialogue. In addition, there is a lot of works to disambiguate questions through question refinement, but most refinement methods usually supplements information by a single key point, which not able to achieve all the key point recall we mentioned earlier.  % Question clarification is essential for a question answering system. In a real-world QA system, nearly 30\% of the user queries are ambiguous questions. Without clarification, dialogue participants risk missing information and ambiguous failing to achieve mutual understanding. The ability to ask clarification questions is one of the key desired components of conversational systems .  introduced methods to ask clarification questions for information that is missing from a given linguistic context.  use generative model to generate clarification questions for solving entity ambiguities.  % However, it is difficult to achieve a high success rate. For example, ``how to apply?"" is ambiguous, because there are too many products related to the ``apply"". By asking only one option question, such as ``Do you want to apply for a credit card?"" or two options question, such as ``Do you want to apply for a credit card or a loan ?"", which are both less efficient. Phenomena mentioned above exist in our real world customer service robot  system. CSRobot based on FAQ question answering is widely used in the real world, especially in the financial industry. When user enter a question in CSRobot system , information is retrieved by computing semantic similarity between user question and pre-manually prepared FAQ. Due to factors such as user's age, gender, geography, familiarity with our system, and urgency of user's problem, user may enter many ambiguous questions. In our CSRobot environment, the ratio is nearly 30\%. The ambiguous questions in our system can be summarized into 5 types:  Missing subject or object, e.g. ``how to apply"", ``how to change it back"",  Missing predicate, e.g. ``credit card"", ``my QR code"",  Missing of all subject predicates and objects,  e.g. ``How benefit"", ``its not right"",  Entity ambiguous,  e.g. ``My health insurance"", because health insurance contains many sub-categories,  Misspelling ambiguous. ``how to exist"" , ``exist"" may be misspelling of ``exit"". In this work, we focus on asking clarification questions using intents recommendation in FAQ-based question answering system. Previous methods either solve missing information questions or solve entity ambiguity questions, while our proposed method can handle both missing information and entity ambiguous mentioned above.   % The complete question clarification process in our work can be seen in Figure . The user enters an incomplete or ambiguous question, and agent recommends a list of candidate intents, each of which clarifies the user's question and can be clicked. Then user clicks on an intent associated with himself, and the agent finds a list of related FAQ in the FAQ knowledge base with the clarified question. Our work focuses on recommend a list of candidate intents for question clarification. A similar idea from \citet{DBLP:conf/chiir/RadlinskiC17} also suggests that, a conversational interface may be easier for users to clarify their needs given precise choices rather than expecting them to come up with particular terms.   % introduce question clarification as collection partition thought in detail   %   % One of the challenges in designing this method is how to design a cold start scenario. We use the end-to-end sequential intents recommendation method based on reinforcement learning for user question clarification. We did not use supervised method mainly because it is difficult for human annotators directly labeling intents related to user's ambiguous question . The reward is designed to recommend the closest clear question list and maximize the information gain after clicking one intent for better question clarification. We conducted offline and online experiments in a real-world CSRobot environment and collected the data of more than 100 million online real-users' interactions with our system in one month. To the best of our knowledge, we are the first to use intents recommendation for question clarification on real-world CSRobot environment, and interactions with more than 100 million of real users. The experiments proved the effectiveness and scalability of our proposed method. Contributions are summarized as follows:  %   %% FORMATTING  \newcommand{\NTCIR}{NTCIR-13} \newcommand{\metric}[1]{{\mbox{#1}}} \newcommand{\metricfont}[1]{{\small\sf{#1}}} \newcommand{\ydata}{{\metricfont{Y!S1}}} \newcommand{\govdata}{{\metricfont{GOV2}}} \newcommand{\RBP}{\metric{RBP}} \newcommand{\Pat}{\metric{P}} %\newcommand{\AP}{\metric{AP}} \newcommand{\AP}{\metric{MAP}} \newcommand{\NDCG}{\metric{NDCG}} \newcommand{\ERR}{\metric{ERR}} \newcommand{\BPref}{\metric{BPref}} \newcommand{\Qmeasure}{\metric{Qmeasure}}  \newcommand{\Patk}[1]{\mbox{\Pat@}} \newcommand{\RBPatp}[1]{\mbox{\RBP@}} \newcommand{\RBPatptok}[2]{\mbox{\RBP@}} \newcommand{\NDCGatk}[1]{\mbox{\NDCG@}} \newcommand{\ERRatk}[1]{\mbox{\ERR@}} \newcommand{\APtok}[1]{\mbox{\AP}} \newcommand{\APatk}[1]{\mbox{\AP}} \newcommand{\NDCGtok}[1]{\mbox{\NDCG}} \newcommand{\ERRtok}[1]{\mbox{\ERR}}  \newcommand{\ssvar}[1]{\mbox{\tiny#1}} \newcommand{\trisk}{} \newcommand{\urisk}{} \newcommand{\combsum}{\method{CombSUM}\xspace} \newcommand{\rrf}{\method{RRF}\xspace} %-- Baselines \newcommand{\gbrt}{\method{GBRT}} \newcommand{\lstm}{\method{LSTM}} \newcommand{\dqn}{\method{DQN}} \newcommand{\dodqn}{\method{DoDQN}} \newcommand{\doddqn}{\method{DoDDQN}} \newcommand{\ddqn}{\method{DDQN}} \newcommand{\pdodqn}{\method{PER-DoDQN}} \newcommand{\pdoddqn}{\method{PER-DoDDQN}} \newcommand{\per}{\method{PER}} \newcommand{\mlp}{\method{MLP}}   %\newcommand{\gbdtbl}{\method{GBDT-BL}} %\newcommand{\gbrtbl}{\method{GBRT-BL}} %\newcommand{\lambdamartbl}{\method{LambdaMART-BL}} %\newcommand{\gbdtbbl}{\method{GBDT-Budget-BL}} %\newcommand{\qlbl}{\method{QL-BL}} %\newcommand{\bmbl}{\method{BM25-BL}} %\newcommand{\sdmbl}{\method{SDM-BL}} %\newcommand{\adarankbl}{\method{AdaRank-BL}} %\newcommand{\wlmbl}{\method{WLM-BL}} % %%-- Experimental methods %\newcommand{\lmccost}{\method{LM-C3-Cost}} %\newcommand{\lmcce}{\method{LM-C3-CE}} %\newcommand{\lmcrnd}{\method{LM-C3-Rnd}} %\newcommand{\gbdtccost}{\method{GBDT-C3-Cost}} %\newcommand{\gbdtcce}{\method{GBDT-C3-CE}} %\newcommand{\gbdtcrnd}{\method{GBDT-C3-Rnd}} %\newcommand{\gbrtccost}{\method{GBRT-C3-Cost}} %\newcommand{\gbrtcce}{\method{GBRT-C3-CE}} %\newcommand{\gbrtcrnd}{\method{GBRT-C3-Rnd}} %\newcommand{\lambdamartccost}{\method{LambdaMART-C3-Cost}} %\newcommand{\lambdamartcce}{\method{LambdaMART-C3-CE}} %\newcommand{\lambdamartcrnd}{\method{LambdaMART-C3-Rnd}} % %\newcommand{\lmc}{\method{LM-C3-C}} %\newcommand{\lme}{\method{LM-C3-E}} %\newcommand{\lmf}{\method{LM-C3-F}} %\newcommand{\gbdtc}{\method{GBDT-C3-C}} %\newcommand{\gbdte}{\method{GBDT-C3-E}} %\newcommand{\gbdtf}{\method{GBDT-C3-F}} %\newcommand{\gbrtc}{\method{GBRT-C3-C}} %\newcommand{\gbrte}{\method{GBRT-C3-E}} %\newcommand{\gbrtf}{\method{GBRT-C3-F}} %\newcommand{\lambdamartc}{\method{LambdaMART-C3-C}} %\newcommand{\lambdamarte}{\method{LambdaMART-C3-E}} %\newcommand{\lambdamartf}{\method{LambdaMART-C3-F}}  %-- Tools \newcommand{\xgboost}{} \newcommand{\scikit}{} \newcommand{\tensorflow}{}  %-- misc formatting \def\D{\hphantom{1}} \def\C{\hphantom{1,}} %-- Misc control commands \newcommand\method[1]{{\sf\small{#1}}} \newcommand\smethod[1]{{\sf\scriptsize{#1}}} \newcommand\mytt[1]{{\bf{\tt{\small{#1}}}}} \newcommand{\alginp}[1]{\makebox[15mm][l]{\sc Input:}\\[0.5ex]} \newcommand{\algout}[1]{\makebox[15mm][l]{\sc Output:}\\} %--- Ranking Stuff \newcommand{\smin}{\var{s\_min}} \newcommand{\smax}{\var{s\_max}} \newcommand{\Answers}{\var{Ans}} \newcommand{\docweight}{\var{docweight}_{d}} \newcommand{\score}{\var{score}_{d,t}} \newcommand{\pivot}{\var{pivot}} \newcommand{\cpivot}{c_{\mbox{\scriptsizepivot}}} \newcommand{\tpivot}{t_{\mbox{\scriptsizepivot}}} \newcommand{\posting}{\ensuremath{}}  \newcommand{\dfdt}{\rangle d,f_{d,t} \langle} \newcommand{\tf}{\mbox{	extsc{TF}}\xspace} \newcommand{\tfidf}{\mbox{tfidf}\xspace} \newcommand{\tftd}{\ensuremath{\tf_{t,d}}} \newcommand{\tfqd}{\ensuremath{\tf_{q,d}}} \newcommand{\idf}{\mbox{	extsc{idf}}\xspace} \newcommand{\idft}{\ensuremath{idf_t}} \newcommand{\idfq}{\ensuremath{idf_q}} \newcommand{\idld}{\ensuremath{idl_d}} \newcommand{\idl}{\mbox{	extsc{idl}}\xspace} \newcommand{\wtd}{\ensuremath{wt_d}} %--- Ops %% \newcommand{\opstyle}[1]{\mbox{	extsc{#1}}} \newcommand{\opstyle}[1]{\mbox{{#1}}} \newcommand{\bmax}{\opstyle{BLOCK-MAX}\xspace} \newcommand{\wand}{\opstyle{WAND}\xspace} \newcommand{\bmwand}{\opstyle{BM-WAND}\xspace} \newcommand{\maxscore}{\opstyle{MAXSCORE}\xspace} \newcommand{\hsv}{\opstyle{HSV}\xspace} \newcommand{\pst}{\opstyle{PST}\xspace} \newcommand{\gtaat}{\opstyle{Greedy-TAAT}\xspace} \newcommand{\taat}{\opstyle{TAAT}\xspace} \newcommand{\daat}{\opstyle{DAAT}\xspace} %--- Misc  \newcommand{\bwt}{{\sc bwt}\xspace} \newcommand{\fmindex}{{\sc FM-index}\xspace} \def\xbwt{\mtxt^{\mbox{\scriptsize {\sc bwt}}}} \newcommand{\sa}{\mbox{\mbox{\sc sa}}} \newcommand{\lf}{\mbox{\mbox{\sc lf}}} \newcommand{\cpu}{{\sc cpu}\xspace} \newcommand{\ram}{{\sc ram}\xspace} \newcommand{\ascii}{{\sc ascii}\xspace} \newcommand{\sgml}{{\sc sgml}\xspace} \newcommand{\trec}{{\sc trec}\xspace} \newcommand{\collection}[1]{\mbox{\small\sc{#1}}} \newcommand{\newswire}{\collection{NewsWire}} \newcommand{\wt}{\collection{WT10G}} \newcommand{\gov}{\collection{GOV2}} \newcommand{\raw}{\mbox{\sc raw}\xspace} %--- Macros \newcommand{\bm}{\opstyle{BM25}} \newcommand{\lm}{\opstyle{LMDS}} \newcommand{\pl}{\mbox{\bf\scriptsize PL2}\xspace} \newcommand{\tfbm}{\ensuremath{\mbox{TF}_{\mbox{\scriptsize{BM25}}}\xspace}} \newcommand{\utf}{\mbox{\scriptsize UTF-8}\xspace} %%\newcommand{\newt}{\mbox{\method{NeWT}\xspace}} \newcommand{\newt}{\mbox{\method{NewSys}\xspace}} \newcommand{\indri}{\method{Indri\xspace}} \newcommand{\lynx}{\method{Lynx\xspace}} \newcommand{\boilerpipe}{\method{Boilerpipe\xspace}} \newcommand{\terrier}{\method{Terrier\xspace}} \newcommand{\Space}{space\xspace} \newcommand{\prefix}{prefix\xspace} \newcommand{\suffix}{suffix\xspace} \newcommand{\plain}{plain\xspace} \newcommand{\intent}{{\sc intent}\xspace}  \newcommand{\slarge}{S-Lrg} \newcommand{\ssmall}{S-Sml} \newcommand{\realdat}{R-Data}      \newcommand{\SA}{\mbox{SA}} \newcommand{\Tmin}{T_{\mbox{\scriptsize{min}}}} \newcommand{\Tmax}{T_{\mbox{\scriptsize{max}}}}   \newcommand{\argmin}{\operatornamewithlimits{argmin}} \newcommand{\argmax}{\operatornamewithlimits{argmax}} \newcommand{\lmax}{\operatornamewithlimits{max}} \newcommand{\llim}{\operatornamewithlimits{lim}}   %-- Sizes \newcommand\kb[1]{\,kB} \newcommand\mb[1]{\,MB} \newcommand\gb[1]{\,GB} \newcommand\tb[1]{\,TB} %-- maths \newcommand{\ith}{\ensuremath{i^{\mbox{\scriptsize th}}}} \newcommand{\nmax}{n_{\mbox{\tiny max}}} \newcommand{\newlne}{{}n} \newcommand{\var}[1]{\mbox{#1}} \newcommand{\svar}[1]{\mbox{\scriptsize#1}} %-- misc formatting \def\D{\hphantom{1}} \def\C{\hphantom{1,}} \newcommand{\myurl}[1]{{\url{#1}}} \newcommand{\mycaption}[1]{}} \newcommand{\myquery}[1]{{``{\tt{#1}}''}} %%AM \newcommand{\myparagraph}[1]{\paragraph*{\normalsize\it{#1}}} %% \newcommand{\myparagraph}[1]{\mysubsection{#1}} %\newcommand{\myparagraph}[1]{~\\{#1}.~} \newcommand{\myparagraph}[1]{{#1}.~} \newcommand{\mysubsection}[1]{\subsubsection*{{#1}}} \newcommand{\noi}{} \newcommand{\mycomment}[1]{} \newcommand{\mylabel}[1]{} \newcommand{\mytab}{\makebox[6mm]{~}} \newcommand{\fixed}[1]{\makebox[18mm]{#1}} %-- big iron \newcommand{\haatheshort}{ Intel Xeon E5640 fgcessors with a {\mb{12}} cache and {\gb{144}} of SDRAM} %\newcommand{\haathee}{ Intel Xeon E5640 Processors with %a {\mb{12}} smart cache, {\gb{144}} of DDR3 DRAM, eight {\tb{2}} SATA-II disks, %and running Ubuntu Linux 11.10} \newcommand{\haathee}{ Intel Xeon E5640 Processors with a {\mb{12}} smart cache, {\gb{144}} of DDR3 DRAM, and running Ubuntu Linux 11.10}   %-- table formatting \newlength{\onedigit} \settowidth{\onedigit}{} \newcommand{\w}{\makebox[\onedigit]{~}}   \newcounter{todocount} \setcounter{todocount}{1} \newcommand{\todo}[1]{{\color{blue}*** 	[\thetodocount] #1 ***\addtocounter{todocount}{1}}} % % File acl2020.tex % %% Based on the style files for ACL 2020, which were %% Based on the style files for ACL 2018, NAACL 2018/19, which were %% Based on the style files for ACL-2015, with some improvements %%  taken from the NAACL-2016 style %% Based on the style files for ACL-2014, which were, in turn, %% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009, %% EACL-2009, IJCNLP-2008... %% Based on the style files for EACL 2006 by  %%e.agirre@ehu.es or Sergi.Balari@uab.es %% and that of ACL 08 by Joakim Nivre and Noah Smith   \documentclass[11pt]{article} \usepackage{coling2020} \usepackage{times} \usepackage{url} \usepackage{latexsym}  \renewcommand{\UrlFont}{\ttfamily\small}  \usepackage{booktabs} % For formal tables \usepackage[normalem]{ulem} \usepackage{xcolor} %%xl: I need xcolour.... \usepackage{algorithm} \usepackage{algpseudocode} \usepackage{amsmath} \usepackage{mathrsfs}  \usepackage{amssymb} \usepackage{subfigure} \usepackage{makecell} \usepackage{mathtools} \usepackage[font=rm]{caption} % \usepackage{subcaption} \DeclareCaptionType{copyrightbox} \usepackage{shortvrb} \usepackage{tabularx} \usepackage{verbatim} \usepackage{xspace} \usepackage{listings} \lstset{basicstyle=\small\ttfamily,mathescape,columns=fullflexible,keepspaces=true} \usepackage{fontawesome} \usepackage[multiple]{footmisc} \usepackage[all]{nowidow} \usepackage{balance} % This is not strictly necessary, and may be commented out, % but it will improve the layout of the manuscript, % and will typically save some space. \usepackage{microtype} \usepackage{wrapfig} %\aclfinalcopy % Uncomment this line for the final submission %\def\aclpaperid{***} %  Enter the acl Paper ID here  %\setlength\titlebox{5cm} % You can expand the titlebox if you need extra space % to show all the authors. Please do not make the titlebox % smaller than 5cm ; we will check this % in the camera-ready version and ask you to change it back.  \usepackage[medium,compact]{titlesec} \usepackage{enumitem} \setlist{itemsep=0pt,parsep=0pt}  \colingfinalcopy    \title{Interactive Question Clarification in Dialogue via Reinforcement Learning}  \author{       Xiang Hu\footnotemark[2]    \\ %       Ant Financial Services Group\footnotemark[2]\\    Hasso Plattner Institute, University of Potsdam\footnotemark[3]\\     \\\And    Zujie Wen\footnotemark[2] \\ %   Rutgers University\\    %       \\\And    Yafang Wang \footnotemark[2] \thanks{\ \  corresponding author, email: yafang.wyf@antfin.com}   \\ %   Ant Financial Services Group\\  %    %   \thanks{Corresponding author, Email: yafang.wyf@antfin.com}   \\\And    Xiaolong Li\footnotemark[2] \\ %   Rutgers University\\    %       \\\And   Gerard de Melo\footnotemark[3]  \\ %   Ant Financial Services Group\\  %    \\    tu   }  \date{}            In this paper, we  proposed an ensemble document reranking approach  for PM queries. It builds on pretrained BERT models to combine strategies from document relevance matching and extractive/abstractive text summarization to arrive at document rankings that are complementary in eventual evaluations. Our experiments also demonstrate that  entity embeddings   trained on an annotated domain specific corpus can help in   document retrieval settings. Both quantitative and qualitative analyses throw light on the strengths of our approach.  One scope for advances lies in improving the summarizer to generate better pseudo-queries  so that \texttt{ABS} starts to perform better on its own. At a high level, training data is very hard to generate in large amounts for IR tasks in biomedicine and this holds for the TREC-PM datasets too. To better train  \texttt{ABS}, it may be better to adapt other biomedical IR datasets. For example, the TREC clinical decision support  task that ran from 2014 to 2016 is related to the PM task. A future goal is to see if we can apply our neural transfer learning and domain adaptation efforts to repurpose the CDS datasets for the PM task.   Another straightforward idea is to reuse generated pseudo-query sentences in the eDisMax query by Solr, as a form of  pseudo relevance feedback. The  expression in Section focuses on an asymmetric formulation that starts with a query term and looks for the best match in the pseudo-query. Considering a more symmetric formulation, where, we also begin with the pseudo-query terms and average both summands may provide a better estimate for reranking.  Additionally, a thorough exploration of how external biomedical knowledge bases can be incorporated in the neural IR framework for PM is also important.    {}   
"," %闂侇偅淇虹换鍐矗瀹ュ锛栭柣銊ュ閺岀喎顕ｈ箛鏃傜獮婵炴挸鎳庤ぐ鏌ユ嚄閽樺鏁ㄩ柡澶堝劜濡倕鈻旈弴銏╂殨闁哄牏鍠撳▓鎴︽偨閵婏箑鐓曢柛娆忕Ч椤╊參鏁嶇仦鑺ヨ含闁活亞鍠庨悿鍕寲閼姐倗鍩犲☉鎿冨幖缁扁晠宕楅妷銈囩憹缁绢収鍠栭悾楣冨箑瑜嬫穱uestion reformulation闁哄倽顫夌涵璺侯嚗鐎典即寮悩宕囥婂ù鍏煎椤撴悂骞嶉柡鍫濐槹缂嶆棃宕烽妸銉ヨ闁煎疇濮よ閸屾碍绀堟慨婵勫栭崹婊勭椤戝灝鈻忛柣鈧妺缁斿绮斿鍕攭濞存粍甯掔槐锟犳儍閸曨垱锛栧Λ鐗埳戠欢鐐层掗崨顔界厵婵炲娲 % \todo{explain defect of previous works} Coping with ambiguous questions has been a perennial problem in real-world dialogue systems. Although clarification by asking questions is a common form of human interaction, it is hard to define appropriate questions to elicit more specific intents from a user. In this work, we propose a reinforcement model to clarify ambiguous questions by suggesting refinements of the original query. We first formulate a collection partitioning problem to select a set of labels enabling us to distinguish potential unambiguous intents. We list the chosen labels as intent phrases to the user for further confirmation. The selected label along with the original user query then serves as a refined query, for which a suitable response can more easily be identified. The model is trained using reinforcement learning with a deep policy network.  We evaluate our model based on real-world user clicks and demonstrate significant improvements across several different experiments. % The ability to ask clarification questions to solve ambiguity and missing information phenomena is essential for question answering systems. The current research mainly uses questions generation or questions ranking to ask a clarification question, which lead to low success rate and redundant information. Insufficient use of the graphic user interface  results in more interactions with users. There is usually no guarantee for replying the user after the clarification. To solve these problems, we propose a question clarification method based on intents recommendation. intents are extracted from the historical Frequently Asked Questions of our system. The recommended intents can provide more concise candidates for user to click. Once an intent is clicked, the system guaranteed to provide a clear question list relative to the real question. We use the reinforcement learning method to recommend intents, and the most challenging problem is cold start. The reward is designed to recommend the most relevant clear question list and maximize the information gain after clicking one intent for better question clarification. The method we proposed for question clarification can solve both ambiguity and missing information phenomena. Experiments on interactions with more than 100 million real-world online users shows the effectiveness of this method.",443
" %Discourse Parsing is a key NLP %an important task, aiming to establish a better understanding of multi-sentential natural language. %, which is inherently ambiguous and intent-driven.  %Most research in the area thereby focuses on one of the two main discourse theories RST  or PDTB , both proposed over a decade ago. Discourse Parsing is a key Natural Language Processing  task for processing multi-sentential text. Most research in the area focuses on one of the two main discourse theories -- RST  or PDTB . The latter thereby postulates shallow discourse structures, combining adjacent sentences and mainly focuses on explicit and implicit discourse connectives. The RST discourse theory, on the other hand, proposes discourse trees over complete documents in a constituency-style manner, with tree leaves as so called Elementary Discourse Units , representing span-like sentence fragments. Internal tree-nodes encode discourse relations between sub-trees as a tuple of \{Nuclearity, Relation\}, where the nuclearity defines the sub-tree salience in the local context, and the relation further specifies the type of relationship between the binary child nodes   with automatically inferred discourse structures and nuclearity attributes from large-scale sentiment datasets already reached state-of-the-art  performance on the inter-domain discourse parsing task. Similarly, \citet{liu2018learning} infer latent discourse trees from the text classification task, and \citet{liu2019single} employ the downstream task of summarization using a transformer model to generate discourse trees. Outside the area of discourse parsing, syntactic trees have previously been inferred according to several strategies, e.g. \citet{socher2011semi, yogatama2016learning, choi2018learning, maillard2019jointly}. %including: Discrete decisions frameworks using a Gumbel-softmax component , applying a reinforcement approach to syntactic parsing , using the reconstruction error of adjacent spans as an indicator for syntactic coherence within a sentence  or by employing a CKY approach to select syntactic trees from a soft model .  In general, the approaches mentioned above  %to automatically annotate text with discourse structures or syntactic trees  have shown to capture valuable structural information. Some models outperform baselines trained on human-annotated datasets , others have proven to enhance diverse downstream tasks . However, despite these initial successes, one critical limitation that all aforementioned models share is the task-specificity, possibly only capturing downstream-task related information. %of discourse,  This potentially compromises the generality of the resulting trees, as for instance shown for the model using text classification data  in \citet{ferracane2019evaluating}.  %For instance, the approach by \citet{huber2019predicting} uses document-level sentiment information to inform the discourse tree generation, with others %have been  %using summarization data  or sentence-level sentiment cues  to achieve the results.  In order to alleviate this limitation of task-specificity, we propose a new strategy to generate tree structures in a task-agnostic, unsupervised fashion by extending the latent tree induction framework proposed by \citet{choi2018learning} with an auto-encoding objective. %.  Our system thereby extracts important knowledge from natural text by optimizing both the underlying tree structures and the distributed representations. We believe that the resulting discourse structures effectively aggregate related and commonly appearing patterns in the data by merging coherent text spans into intermediate sub-tree encodings, similar to the intuition presented in \citet{drozdov2019unsupervised}. However, in contrast to the approach by \citet{drozdov2019unsupervised}, our model makes discrete structural decisions, rather than joining possible subtrees using a soft attention mechanism. We believe that our discrete tree structures allow the model to more efficiently achieve the autoencoder objective in reconstructing the inputs, directly learning how written language can be aggregated in the wild . In general, the proposed approach can be applied to any tree-structured objective, such as syntactic parsing, discourse parsing and further problems outside of NLP, like tree-planning  and decision-tree generation . Yet, due to the especially difficult annotation process to generate discourse trees, we initially develop a method to %complement task-specific models in  generate much larger and more diverse discourse treebanks.       We present an end-to-end model to resolve ambiguous questions in dialogue by clarifying them using label suggestions. We cast the question clarification problem as a collection partition problem. In order to improve the quality of the interactive labels as well as reduce the semantic overlap of the labels and the user's question, we propose a novel reward based on recall of potential intents and information gain. We establish its effectiveness in a series of experiments, which suggest that this novel notion of clarification may as well be adopted for other kinds of disambiguation problems.  Our experiments shows that the way of intent interaction is more effective in solving user problems than returning relevant results. At the same time, through the comparison of online ctr, it fully proves that the intents recommend by the policy model trained via our new reward is more helpful to users.         
"," Discourse information, as postulated by popular discourse theories, such as RST and PDTB, has been shown to improve an increasing number of downstream NLP tasks, showing positive effects and synergies of discourse with important real-world applications. While methods for incorporating discourse become more and more sophisticated, the growing need for robust and general discourse structures has not been sufficiently met by current discourse parsers, usually trained on small scale datasets in a strictly limited number of domains. This makes the prediction for arbitrary tasks noisy and unreliable. The overall resulting lack of high-quality, high-quantity discourse trees poses a severe limitation to further progress.  In order the alleviate this shortcoming, we propose a new strategy to generate tree structures in a task-agnostic, unsupervised fashion by extending a latent tree induction framework with an auto-encoding objective. The proposed approach can be applied to any tree-structured objective, such as syntactic parsing, discourse parsing and others. However, due to the especially difficult annotation process to generate discourse trees, we initially develop a method to generate larger and more diverse discourse treebanks. In this paper we are inferring general tree structures of natural text in multiple domains, showing promising results on a diverse set of tasks.  %With this paper, we intend to initiate a new line of research on inferring discourse structures in an unbiased manner. %With a growing need for robust and general discourse structures in many downstream tasks and real-world applications, the current lack of high-quality, high-quantity discourse trees poses a severe shortcoming. %In order the alleviate this limitation, we propose a new strategy to generate tree structures in a task-agnostic, unsupervised fashion by extending a latent tree induction framework with an auto-encoding objective. The proposed approach can be applied to any tree-structured objective, such as syntactic parsing, discourse parsing and others. However, due to the especially difficult annotation process to generate discourse trees, we initially develop such method to complement task-specific models in generating much larger and more diverse discourse treebanks.",444
"  Retrieval technique or response selection is a very popular and elegant approach  to framing a chatbot i.e. open-domain dialog system. Given the conversation context, a retrieval-based chatbot aims to select the most appropriate utterance as a response from a pre-constructed database. %that saves a large number of human written utterances. In order to balance the effectiveness and efficiency, mosts of the retrieval-based chatbots  employ coarse-grained selection module to recall a set of candidate  that are semantic coherent with the conversation context to speed up processing.  % 鐠囧瓨妲戦敍姘妧娑斿孩鏅ラ悳鍥ф嫲閺佸牊鐏夐獮鏈电瑝閼宠棄鍙忛柈銊ュ絿瀵 % 閸滃elated work闁插矂娼伴柌宥咁槻娴滃棴绱濋惄瀛樺复閸掔姴骞撻敍 To the best of our knowledge, there are two kinds of approaches  to build a coarse-grained selection module in retrieval-based chatbots:  sparse representation:  TF-IDF or BM25  is a widely used method. It matches keywords with an inverted index and can be seen as representing utterances in highdimensional sparse vectors ; %This method runs very quickly, but lacks rich semantic information.  dense representation:  Large scale pre-trained langauge models , e.g. BERT  are commonly used to obtain the semantic representation of utterances, which could be used to recall semantic coherent candidates by using cosine similarity . %Due to the high computational burden of similarity calculating, %this method runs slowly, but could consider rich semantic information %.  % 鐠囧瓨妲戦惄顔煎楠炶埖妫ょ化鑽ょ埠娑擃亜顕В鏃撶礉鐠囧瓨妲戠紒鍡氬Ν閸欘垯浜掗崷銊ョ杽妤犲奔鑵戦幍鎯у煂閿涘矂妲撻弰搴＄杽妤犲瞼绮ㄩ弸婊冩嫲dense vectors閻ㄥ墜eakness閿涘瞼鍔ч崥搴＄穿閸戠儤鍨滄禒顒傛畱閸欙缚绔存稉鐚祌oposed method % Luan2020SparseDA鏉╂瑤閲滅拋鐑樻瀮娑旂喕顕╅弰搴濈啊BM25閺堝妞傞崐娆愭櫏閺嬫粍娲挎總 % Dense 閺鐟版倳 BERT So far, there is no systematic comparison between these two kinds of approaches in retrieval-based chatbots, and which kind of method is most appropriate in real scenarios is  still an open question that confuses researchers in dialog system community. Thus, in this paper, we first conduct extensive experiment to compare these two approaches from four important aspects:   effectiveness;  search time cost;  index storage occupation;  human evaluation. Extensive experiment results on four popular response selection datasets  demonstrate that the dense representation  significantly outperforms the sparse representation at the expense of  the lower speed and bigger storage than sparse representation, which is unsufferable in real scenarios. Then, in order to overcome the fatal weaknesses of dense representation methods, we propose an ultra-fast, low-storage and highly effective  Deep Semantic Hashing Coarse-grained selection module  %based on a given dense representation method, which effectively balances the effectiveness and efficiency. Specifically,  we first stack a novel hashing optimizing module that consists of two autoencoders on a given  dense representation method. Then, three well designed loss functions are used to optimize  these two autoencoders in hashing optimizing module:  preserved loss;  hash loss;  quantization loss. After training, the autoencoders could effectively preserve rich semantic and similarity information of the dense vectors into the hash codes, which are very computational and storage efficient . \iffalse first of all, we train a dense representation method  by using dual-architecture , which contains a context BERT encoder and a candidate BERT encoder. Then, we separately stack an deep autoencoder model on each encoder. The auto-encoder model could encode the semantic information in dense vectors into hashing codes. Finally, a novel deep semantic hashing approach is used to learn the binary compressed representation of the dense vectors. % 鐠囧瓨妲戞禍宀冪箻閸掕泛鎼辩敮宀绱惍浣烘畱娴兼ê濞嶉敍灞肩瑝閸氬奔绨瑂parse閸滃畳ense缂傛牜鐖滈惃鍕偨婢跺嫨 It should be noted that,  different from the dense vectors,  binary hashing code is storage-efficient and ultra-fast to calculate ,  and it also keeps the rich semantic information in dense vectors. \fi Extensive experiment results on four popular response selection datasets demonstrate that our proposed DSHC model can achieve much faster search speed  and lower storage occupation than sparse representation method, and very limited performance loss compared with the given dense representation method.  In this paper, our contributions are three-fold:   The rest of this paper is organized as follows: we introduce the important concepts and background covered in our paper in Section 2. The experiment settings is presented in Section 3. In Section 4, we systematically compare the current two kinds of methods in coarse-grained selection module:   sparse representation;  dense representation. In Section 5, we introduce our proposed DSHC model, and detailed experiment results are elaborated. In Section 6, we conduct the case study. Finally, we conclude our work in Section 7. Due to the page limitation, more details and extra analysis can be found in Appendix.    In this paper, we proposed a truly unsupervised and purely data-driven tree-style autoencoder to compress and reconstruct textual data. We show the potential of our T-AE approach on the task of discourse parsing, which severely suffers from training-data sparsity, due to the tedious and expensive annotation process. Our unsupervised model outperforms one of the commonly used, linguistically supervised approaches, without making any assumptions on the underlying data, except the sentence/document split. The superior performance compared to the hierarchical left branching baseline plausibly indicates that our unsupervised structures could be valuable when combined with supervised or distantly supervised models to further improve their joint performance. Furthermore, the superior performance of the large out-of-domain model trained on the Yelp'13 dataset over the small-scale within-domain model trained on the raw text of the RST-DT dataset shows the synergies between these corpora as well as strong potential for even larger datasets to enhance the performance of the approach.   In the future, we intend to extend this work in several ways: First, we want to explore the application of generative models, employing a variational autoencoder. Second, we plan to study further tasks besides predicting discourse, such as syntactic parsing, as well as additional synergistic downstream tasks . To improve our model on important downstream tasks , we want to explore a pre-training/fine-tuning approach, similar to contextualized language  models, such as BERT. Combining our novel approach with distantly-supervised and supervised models is another future direction we want to explore. Lastly, we plan to evaluate additional model adaptions, such as two independent models on sentence- and document-level, incorporating a BERT EDU encoder and an end-to-end model with soft-constraints on sentence-level.  Try generative models \\  Try syntactic parsing \\  Try more downstream tasks \\  separate models\\  soft constraint model\\  add bert\\  
","   We study the coarse-grained selection module in retrieval-based chatbot.   Coarse-grained selection is a basic module in a retrieval-based chatbot,   which constructs a rough candidate set from the whole database to speed up the interaction with customers.   So far, there are two kinds of approaches for coarse-grained selection module:     sparse representation;  dense representation.   To the best of our knowledge, there is no systematic comparison between these two approaches in retrieval-based chatbots,   and which kind of method is better in real scenarios is still an open question.   In this paper, we first systematically compare these two methods from four aspects:     effectiveness;  index stoarge;  search time cost;  human evaluation.   Extensive experiment results demonstrate that dense representation method    significantly outperforms the sparse representation,    but costs more time and storage occupation.   In order to overcome these fatal weaknesses of dense representation method,    we propose an ultra-fast, low-storage, and highly effective    Deep Semantic Hashing Coarse-grained selection method, called DSHC model.   Specifically, in our proposed DSHC model,   a hashing optimizing module that consists of two autoencoder models is    stacked on a trained dense representation model,   and three loss functions are designed to optimize it.   The hash codes provided by hashing optimizing module effectively    preserve the rich semantic and similarity information in dense vectors.   Extensive experiment results prove that,   our proposed DSHC model can achieve much faster speed and lower storage than sparse representation,   with limited performance loss compared with dense representation.   Besides, our source codes have been publicly released for future research\footnote{\url{https://github.com/gmftbyGMFTBY/HashRetrieval}}.",445
"  With huge quantities of natural language documents, search engines have been essential for the time saved on information retrieval tasks. Usually, deployed search engines achieve the task of ranking documents by relevance according to a query. \\ Recently, research has focused on the task of extracting the span of text that exactly matches the user's query through Machine  Reading Comprehension and Question Answering. \\ Question Answering deals with the extraction of the span of text in a short paragraph that exactly answers a natural language question. Recent deep learning models based on heavy pretrained language models like BERT achieved better than human performances on this tasks .  \\ One could try to apply QA models for the Open-Domain Question Answering paradigm which aims to answer questions taking a big amount of documents as knowledge source. Two main issues emerge from this : first, applying 100M parameters language models to potentially millions of documents requires unreasonable GPU-resources. Then, QA models allow to compare spans of text coming exclusively from a single paragraph while in the open-domain QA paradigm, one needs to compare spans of text coming from a wide range of documents. \\ Our system, as done in previous work, deals with the resources issue thanks to a Retriever module, based on the BM25 algorithm, that allows to reduce the search space from millions of articles to a hundred of paragraphs. The second issue is tackled by adding a deep learning based Scorer module that re-ranks with more precision the paragraphs returned by the Retriever. Eventually, the Extractor module uses a QA deep learning model to extract the best span of text in the first paragraph returned by the Scorer. To avoid a heavy and hardly scalable pipeline consisting of two huge deep learning models, we parallelize the re-ranking and span extraction tasks thanks to multitask learning : while maintaining high performances, it allows to significantly reduce both memory requirements and inference time. Our system achieve state-of-the-art results on the open-squad benchmark.     閹存垳婊戦惃鍕煙濞夋洑绱扮 REALM 缁涘顣╃拋顓犵矊閹绘劒绶电敮顔煎И In this paper, we first systematically compare the dense and sparse representation method in retrieval-based chatbot from four important aspects:  effectiveness;  search time cost;  index stoarge;  human evaluation. Extensive experiment results demonstrate that dense representation method could achieve better performance  at the expense of more time cost and higher storage occupation, In order to overcome these fatal weaknesses, we propose a deep semantic hashing based corase-grained  selection method. Extensive experiment results prove the effectiveness and the efficiency of DSHC model.       
","   In this paper, we introduce MIX : a   multi-task deep learning approach to solve Open-Domain Question  Answering. First, we design our system as a multi-stage pipeline made of 3 building blocks : a BM25-based Retriever, to reduce the search space; RoBERTa based Scorer and Extractor, to rank retrieved paragraphs and extract relevant spans of text respectively. Eventually, we further improve computational efficiency of our system to deal with the scalability challenge : thanks to multi-task learning,   we parallelize the close tasks solved by the Scorer and the Extractor. Our system is on par with state-of-the-art performances on the squad-open benchmark while being simpler conceptually.",446
"  Named Entity Recognition  is the task of identifying the span and the class of a Named Entity  in unstructured text. NEs typically include but are not limited to persons, companies, dates, and geographical locations .   Legal NER is a central task in language processing of legal documents, especially for extracting key information such as the name of the parties in a case, the court name or the case number, or references to laws or judgements, to name a few. The extracted NEs could be integrated in legal research workflows for functionalities such as search, document anonymization or case summarization  thereby enabling and expediting insights for legal professionals .  NER is commonly formalized as a sequence labeling task: each token of the document is assigned a single label that indicates whether the token belongs to an entity from a predefined set of categories . To create a training dataset in such a format the annotator is required to manually label each token in a sentence with the respective category. In this format, both the NE and the location of the NE in the source text are known. This format of training data is what we refer to hereafter as 閳ユ笀old standard閳 data. Obtaining the required voluminous gold standard data to train such models is, therefore, a laborious and costly task.    In this paper, we perform NER in filed lawsuits in US courts. Specifically, we aim to identify the party names in each case, i.e. the names of the plaintiffs and the defendants, in a large collection of publicly available cases from more than 200 courts in different US jurisdictions. The party names have been identified by legal annotators but their exact location in the text is unknown. In this respect, we do not have access to 閳ユ笀old standard閳 training data even though the target NEs are available. This feature of our dataset introduces a key difference of our task to most NER tasks.  One solution to this problem is to generate the 閳ユ笀old standard閳 training data by searching for the locations of the known NEs in the source text . By performing this additional transformation to our data, we would be able to train sequence labeling NER models. For the following reasons, this solution is nontrivial. First, as our source text is also extracted from scanned PDF files , it contains Optical Character Recognition  mistakes and/or typos which may not be present in the target NEs. Second, besides the potential OCR errors at the character level, the closely spaced, two-column page layouts that can be often found as headers in the filed cases, represent an additional challenge for the OCR, which tends to concatenate the text across columns . In such cases, the tokens that make up the NEs in the source text may be intertwined with other words and/or sentences. Third, variations of the names may be also present in the source text and in our human-generated labels, such as presence of first and/or middle names whole or as initials and, to a lesser extent, typos.        To address some of the challenges imposed by the format of our training data and inspired by the work in the field of abstractive summarization, we propose to reformulate the NER task, not as a sequence labeling problem, but as a text-to-text sequence generation problem with the use of a pointer generator network . With this reformulation, in contrast to sequence labeling, we do not require knowledge of the NE閳ユ獨 locations in the text as training labels. A recent study by \citet{Li2020} proposed a different formulation of the NER task as a question answering task and achieved state-of-the-art performance in a number of published NER datasets . In this study, we adopt a hybrid extractive-abstractive architecture, based on recurrent neural networks coupled with global  attention and copying  attention  mechanisms . The proposed architecture can be successfully used for abstractive summarization since it can copy words from the source text via pointing and can deal effectively with out-of-vocabulary  words 閳 words that have not been seen during training. Our approach is conceptually simple but empirically powerful and we show that the pointer generator outperforms the typical NER architectures in the case of noisy and lengthy inputs where the NE's location in the text is not known.   In addition, we examine how our approach can be used for the related NER task of case number extraction. The case number is a unique combination of letters, numbers and special characters as a single token and are, therefore, particularly challenging for NER models as they are often dealt with as OOV words by the model. As in the party names task discussed above, in the case number task we do not have 閳ユ笀old standard閳 labels of the case number閳ユ獨 location in the text. We show that a character level sequence generation network can dramatically increase our ability to extract case numbers from the source text, compared to a word level sequence generation network.  The rest of the paper is organized as follows. In Section 2, we discuss related work in the field of NER in the legal domain. In Section 3, we describe our proposal of NER as a text-to-text sequence generation task in the absence of gold standard data and formulate the task in two ways:  as a combination of automatically labeling the NE's location and then using the conventional sequence labeling method for NER, and  as a text-to-text sequence generation task where the NEs are directly generated as text. Section 4 presents our experimental design, results and analysis. Section 5 presents the case number case study. Finally, we conclude and discuss directions for future work.       \iffalse For papers accepted to the main conference, we will invite authors to provide a translation  of the title and abstract and a 1-2 page synopsis of the paper in a second  language of the authors' choice. Appropriate languages include but are not  limited to authors' native languages, languages spoken in the authors' place  of affiliation, and languages that are the focus of the research presented. \fi  
"," Named Entity Recognition  is the task of identifying and classifying named entities in unstructured text. In the legal domain, named entities of interest may include the case parties, judges, names of courts, case numbers, references to laws etc. We study the problem of legal NER with noisy text extracted from PDF files of filed court cases from US courts. The 闁炽儲绗old standard闁 training data for NER systems provide annotation for each token of the text with the corresponding entity or non-entity label. We work with only partially complete training data, which differ from the gold standard NER data in that the exact location of the entities in the text is unknown and the entities may contain typos and/or OCR mistakes. To overcome the challenges of our noisy training data, e.g. text extraction errors and/or typos and unknown label indices, we formulate the NER task as a text-to-text sequence generation task and train a pointer generator network to generate the entities in the document rather than label them. We show that the pointer generator can be effective for NER in the absence of gold standard data and outperforms the common NER neural network architectures in long legal documents.",447
" Speech translation~, which translates audio signals of speech in one language into text in a foreign language, is a hot research subject nowadays and has widespread applications, like cross-language videoconferencing or customer support chats.   Traditionally, researchers build a speech translation system via a cascading manner, including an automatic speech recognition~ and a machine translation~ subsystem. Cascade systems, however, suffer from error propagation problems, where an inaccurate ASR output would theoretically cause translation errors.  Owing to recent progress of sequence-to-sequence modeling for both neural machine translation~ and end-to-end speech recognition, it becomes feasible and efficient to train a fully end-to-end ST model. This end-to-end fashion attracts much attention due to its appealing properties: a) modeling without intermediate ASR transcriptions obviously alleviates the propagation of errors; b) a single and unified ST model is beneficial to deployment with lower latency in contrast to cascade systems.  % However, the end-to-end paradigm is far from reaching industry requirements because it requires large-scale end-to-end corpora of audios paired with textual translations, which is hard to acquire.  Recent studies show that end-to-end ST models achieve promising performance and are comparable with cascaded models. The end-to-end solution has great potential to be the dominant technology for speech translation, however challenges remain.  The first is about benchmarks. Many ST studies conduct experiments on different datasets. ~\citet{liu2019end} evaluate the method on TED English-Chinese; and ~\citet{dong2020ted} use Augmented Librispeech English-French and  IWSLT2018 English-German dataset; and ~\citet{wu2020self} show the results on CoVoST dataset and the FR/RO portions of MuST-C dataset. Different datasets make it difficult to compare the performance of their approaches. Further,  even for the same dataset, the baseline results are not necessarily kept in the consist. Take the Augmented Librispeech English-French dataset as an example.  ~\citet{dong2020ted} report the pre-trained baseline as 15.3 and the result of ~\citet{liu2019end} is 14.3 in terms of tokenized BLEU, while~\citet{inaguma2020} report 15.5 . The mismatching baseline makes the comparison of their final results meaningless.  One of the primary reasons is that the preprocessing of audio data is complex, and the ST model training involves many tricks, such as pre-training and data augmentation.    Therefore a reproducible and reliable benchmark is required. In this work, we present \method, a toolkit for easily building and training end-to-end ST models, as well as end-to-end ASR and NMT for cascade systems.  We implement start-of-the-art Transformer-based models and provide step-by-step recipes for feature extraction, data preprocessing, model training, and inference for researchers to reproduce the benchmarks. Though there exist several counterparts, such as Lingvo, fairseq-ST and Kaldi~ style~ESPnet-ST,  \method is specially designed for speech translation tasks, which encapsulates the details of speech processing and frees the developers from data engineering. It is easy to use and extend. The contributions of this work are as follows:      % \method provides straightforward preprocessing of several publicly available audio datasets, which encourages researchers to concentrate more on innovating in ST technology but to be less aware of speech processing.  % \method aims at ST tasks using end-to-end framework. Moreover, to our knowledge,  is the pioneer of the community, which follows the Kaldi~ style data processing and recipes. But for \method, we stand in the perspective of natural language processing~.    This work presents a simple yet powerful reformulation of the NER task as a text-to-text sequence generation task by applying a pointer generator network, a model architecture that have been predominantly used in the NLP field of summarization. There are several key advantages in the proposed formalization:   there is no need to acquire 閳ユ笀old閳 data for the NER task when only the target NEs are known but not their indices in the source text,  the Pointer Generator network outperforms popular sequence-labeling architectures at the NER task in the case of longer text inputs, and  the Pointer Generator is able to accurately generate NEs that are corrupted due to OCR errors in extracting the two-column formatted text. In the future, we would like to explore the capacity of the Pointer Generator to extract additional types of NEs.          
"," \method is an open-source toolkit for neural speech translation developed by Bytedance AI Lab.  The toolkit mainly focuses on end-to-end speech translation, which is easy to use, modify, and extend to advanced speech translation research and products.   \method aims at facilitating the speech translation research for NLP researchers and provides a complete setup for speech translation benchmarks, including feature extraction, data preprocessing, distributed training, and evaluation.  Moreover, The toolkit implements several major architectures for end-to-end speech translation. It shows experimental results for different benchmark datasets, which can be regarded as reliable baselines for future research. The toolkit is publicly available at \url{https://github.com/bytedance/neurst}.",448
" Query reformulation and paraphrase generation techniques are employed for a variety of purposes in natural language processing , such as dialogue generation , machine translation , and especially in question answering  systems . Generating coherent and clean texts can reduce potential errors in downstream systems. In the cases when users are at the receiving end of NLP pipelines, it is essential to show them fluent and human-like languages before they lose faith and recede into requiring human agents for the sake of better understanding and communication. In search or question answering systems, query reformulation aims to paraphrase or restructure original question sequences, transforming them into ones that are more interpretable with natural well-formedness in both grammar and semantics. Typically, users may not have the patience to input an entirely grammatical or coherent question, which can cause issues for the downstream components to understand and give accurate predictions or answers. When human representatives are present, an originally noisy query or question can be reiterated and rephrased to double-check with users what they are asking for. This is a costly operation if every convoluted question needs to be restated. By having an NLP model to reformulate input queries, reformulations are fed back to users to confirm their original intentions in an automated way. As a result, unnecessary errors are eliminated and noises are prevented from propagating in an NLP pipeline, which can contain a series of models such as intent classification, information retrieval and question answering.  Traditionally, rule-based and statistical methods have been studied for paraphrase and reformulation generation . The advent of sequence-to-sequence learning   made it feasible to train deep neural networks as a new paradigm. We investigate how to paraphrase and denoise queries and generate well-formed reformulations using Seq2Seq learning models such as LSTMs  and transformers . Following the framework from AQA , a Seq2Seq model is pre-trained on supervised tasks and further tuned using reinforcement learning  on a machine comprehension QA dataset SearchQA , learning from a pre-trained BiDAF  QA system that generates rewards. SearchQA is a suitable and challenging dataset as queries contain noisy phrases and the associated contexts are concatenated web text snippets from Google's search engine. Our goal is to obtain a model that can generate better-formed reformulations based on the original query sequences and achieve good QA performance with these reformulations. We use transfer learning  from pre-trained transformers with text-to-text task formulations . In our approach, pre-trained T5 models are first fine-tuned on paraphrase generation  and denoising  datasets to gain general paraphrasing capabilities. Then, reinforcement learning of downstream QA rewards is performed to further encouraged the model to produce task-specific reformulations. To our knowledge, this is a first attempt to fine-tune text-to-text transformers with RL, nudging the model to generate reward-acquiring query trajectories to get better answers. We show that fine-tuned text-to-text transformers are better starting points for RL as they are more sample efficient in achieving the same level of QA performance, acquiring rewards faster than the previous AQA approach that uses translation-based LSTMs. T5 models also generate reformulations with better readability and can generalize to out-of-sample data. We provide a new way to evaluate fluency on a sequence level using an trained metric on the well-formedness   dataset, which is based on real evaluations from humans, a more reliable source than widely-used algorithmic metrics based on overlapping n-grams.     We introduce \method toolkit for easily building and training end-to-end speech translation models. We provide straightforward recipes for audio data pre-processing, training, and inference, which we believe is friendly with NLP researchers. Moreover, we report strong and reproducible benchmarks, which can be regarded as the reliable baselines for further research.  This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended. \pdfoutput=1   In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.  \documentclass[11pt]{article}    Remove the ""review"" option to generate the final version.   \usepackage[review]{naacl2021} \usepackage[]{naacl2021}    Standard package includes \usepackage{times} \usepackage{latexsym}    For proper rendering and hyphenation of words containing Latin characters  \usepackage[T1]{fontenc}   For Vietnamese characters   \usepackage[T5]{fontenc}   See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets    This assumes your files are encoded as UTF8 \usepackage[utf8]{inputenc}    This is not strictly necessary, and may be commented out,   but it will improve the layout of the manuscript,   and will typically save some space. \usepackage{microtype} \usepackage{multirow}    If the title and author information does not fit in the area allocated, uncomment the following    \setlength\titlebox{<dim>}     and set <dim> to something 5cm or larger.  \newcommand{\method}{NeurST\space} \newcommand{\red}[1]{{\color{red} #1}}  \title{NeurST: Neural Speech Translation Toolkit}    Author information can be set in various styles:   For several authors from the same institution:   \author{Author 1 \and ... \and Author n \\           Address line \\ ... \\ Address line}   if the names do not fit well on one line use           Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\   For authors from different institutions:   \author{Author 1 \\ Address line \\  ... \\ Address line           \And  ... \And           Author n \\ Address line \\ ... \\ Address line}   To start a seperate ``row'' of authors use \AND, as in   \author{Author 1 \\ Address line \\  ... \\ Address line           \AND           Author 2 \\ Address line \\ ... \\ Address line \And           Author 3 \\ Address line \\ ... \\ Address line}  \author{Chengqi Zhao, Mingxuan Wang \and Lei Li \\   ByteDance Inc. \\   \texttt{\{zhaochengqi.d, wangmingxuan.89, lileilab\}@bytedance.com} \\}  \begin{document} \maketitle               Entries for the entire Anthology, followed by custom entries  
"," Query reformulation aims to alter potentially noisy or ambiguous text sequences into coherent ones closer to natural language questions. In this process, it is also crucial to maintain and even enhance performance in a downstream environments like question answering when rephrased queries are given as input. We explore methods to generate these query reformulations by training reformulators using text-to-text transformers and apply policy-based reinforcement learning algorithms to further encourage reward learning. Query fluency is numerically evaluated by the same class of model fine-tuned on a human-evaluated well-formedness dataset. The reformulator leverages linguistic knowledge obtained from transfer learning and generates more well-formed reformulations than a translation-based model in qualitative and quantitative analysis. During reinforcement learning, it better retains fluency while optimizing the RL objective to acquire question answering rewards and can generalize to out-of-sample textual data in qualitative evaluations. Our RL framework is demonstrated to be flexible, allowing reward signals to be sourced from different downstream environments such as intent classification.",449
" 	Identifying the user's open intent plays a significant role in dialogue systems. As shown in Figure, we have two known intents for specific purposes, such as book flight and restaurant reservation. However, there are also utterances with irrelevant or unsupported intents that our system cannot handle. It is necessary to distinguish these utterances from the known intents as much as possible. On the one hand, effectively identifying the open intent can improve customer satisfaction by reducing false-positive error. On the other hand, we can use the open intent to discover potential user needs. 	 	We regard open intent classification as an -class classification task as suggested in, and group open classes into the  class . Our goal is to classify the n-class known intents into their corresponding classes correctly while identifying the  class open intent. To solve this problem,~\citet{scheirer2013toward} propose the concept of open space risk as the measure of open classification.~\citet{fei-liu-2016-breaking} reduce the open space risk by learning the closed boundary of each positive class in the similarity space. However, they fail to capture high-level semantic concepts with SVM.  	~\citet{bendale2016towards} manage to reduce the open space risk through deep neural networks , but need to sample open classes for selecting the core hyperparameters.~\citet{hendrycks17baseline} use the softmax probability as the confidence score, but also need to select the confidence threshold with negative samples.~\citet{Shu2017DOCDO} replace softmax with the sigmoid activation function, and calculate the confidence thresholds of each class based on statistics. However, the statistics-based thresholds can not learn the essential differences between known classes and the open class.~\citet{lin-xu-2019-deep} propose to learn the deep intent features with the margin loss and detect unknown intents with local outlier factor. However, it has no specific decision boundaries for distinguishing the open intent, and needs model architecture modification.  	 	Most of the existing methods need to design specific classifiers for identifying the open class and perform poorly with the common classifier. Moreover, the performance of open classification largely depends on the  decision conditions. Most of these methods need negative samples for determining the suitable decision conditions. It is also a complicated and time-consuming process to manually select the optimal decision condition, which is not applicable in real scenarios.  	 	To solve these problems, we use known intents as prior knowledge, and propose a novel post-processing method to learn the adaptive decision boundary  for open intent classification. As illustrated in Figure, we first extract intent representations from the BERT model. Then, we pre-train the model under the supervision of the softmax loss. We define centroids for each known class and suppose known intent features are constrained in the closed ball areas. Next, we aim to learn the radius of each ball area to obtain the decision boundaries. Specifically, we initialize the boundary parameters with standard normal distribution and use a learnable activation function as a projection to get the radius of each decision boundary.  	 	The suitable decision boundaries should satisfy two conditions. On the one hand, they should be broad enough to surround in-domain samples as much as possible. On the other hand, they need to be tight enough to prevent out-of-domain samples from being identified as in-domain samples. To address these issues, we propose a new loss function, which optimizes the boundary parameters by balancing both the open space risk and the empirical risk. The decision boundaries can automatically learn to adapt to the intent feature space until balance with the boundary loss. We find that our post-processing method can still learn discriminative decision boundaries to detect the open intent even without modifying the original model architecture. 	 	We summarize our contribution as follows. Firstly, we propose a novel post-processing method for open classification, with no need for prior knowledge of the open class. Secondly,  we propose a new loss function to automatically learn tight decision boundaries adaptive to the feature space. To the best of our knowledge, this is the first attempt to adopt deep neural networks to learn the adaptive decision boundary for open classification. Thirdly, extensive experiments conducted on three challenging datasets show that our approach obtains consistently better and more robust results compared with the state-of-the-art methods.  	 		 	\end{table*} 	   In this paper, we propose a novel regularized attentive capsule network for overlapped relation extraction. RA-CapNet embeds relation query multi-head attention into the capsule network and uses a novel disagreement regularization term to encourage the diversity among heads and capsules, making it capable of gathering salient information from diverse semantic spaces. Our model is resistant to the noise of distant supervision and achieves significant improvements on both standard and complex datasets.  In the future, we will experiment with different forms of regularization terms and their application to other components of our model.  
"," 		Open intent classification is a challenging task in dialogue systems. On the one hand, we should ensure the classification quality of known intents. On the other hand, we need to identify the open  intent during testing. Current models are limited in finding the appropriate decision boundary to balance the performances of both known and open intents. In this paper, we propose a post-processing method to learn the adaptive decision boundary  for open intent classification. We first utilize the labeled known intent samples to pre-train the model. Then, we use the well-trained features to automatically learn the adaptive spherical decision boundaries for each known intent. Specifically, we propose a new loss function to balance both the empirical risk and the open space risk. Our method does not need open samples and is free from modifying the model architecture. We find our approach is surprisingly insensitive with less labeled data and fewer known intents. Extensive experiments on three benchmark datasets show that our method yields significant improvements compared with the state-of-the-art methods.\footnote{Code: https://github.com/thuiar/Adaptive-Decision-Boundary}",450
"  Recently, deep contextual language models have shown their effective modeling ability for text, achieving state-of-the-art results in series of NLP tasks. These models capture the syntactic and semantic information of the input text, generating fine-grained contextual embeddings, which can be easily applied to downstream models. Despite the success of large scale pre-trained language models on various tasks,  it is less clear how to extend them to semantic parsing tasks such as text-to-SQL, which requires joint reasoning of the natural language utterance and structured database schema information. Recent work shows that with more powerful pre-trained language models, the highly domain-specific semantic parsers can be further improved, even though these language models are trained for pure text encoding.  %      %    \end{table}%  However, based on error analysis on the output of neural language model-based text-to-SQL systems, we observe that these models can be further enhanced if we could mitigate the following three pain points, which are also illustrated in Table.  The model is ineffective to match and detect column names in utterances. The model should learn to detect column names mentioned in utterances by matching utterance tokens with the schema, and use the matched columns in the generated SQL.  The error analysis indicates that, in some cases, models miss some columns when synthesizing the target SQL, while the column is mentioned explicitly in the utterance.   The model fails to infer the columns implicitly from cell values. This problem is trickier than the first one, because the model is expected to infer the column name based on some cell values mentioned in the utterance, instead of just matching the utterance tokens with the schema. This requires the model to have more domain knowledge. For example, as presented in the second section of Table, the model should know  is a .  The model should learn to compose complex queries. Besides the column selection, to generate a correct SQL, the model should learn to attach the selected columns to the correct clauses. This is a non-trivial task, especially when the target SQL is complex, e.g., when the query is nested. As shown in the last section of Table, the model should learn to use corresponding column  in the nested SQL, instead of using column .  Recent work has demonstrated that jointly pre-training on utterances and table contents  can benefit downstream tasks such as table parsing and semantic parsing . These models are pre-trained using the Masked Language Modeling  task by either masking tokens from the utterance input or tokens from the schema input. However, this learning objective can only model the alignment between the utterance and schema implicitly. We hypothesize that, in order to cope with the three pain points previously listed, it is necessary to use pre-training objectives that enforce the learning of contextual representations that better capture the alignment between utterances and schema/table contents.  In this work, we present a language model pre-training framework, Generation-Augmented Pre-training~, that exploits multiple learning objectives  and synthetic data generation to jointly learn contextual representations of natural language utterances and table schema. We propose the following three new learning objectives that not only enforce joint learning but also improve the ability of the model to grasp more domain knowledge, which is helpful in cross-domain scenarios:  column prediction task, which is a pre-training task that consists in giving a label for each column in the input schema to decide whether it is used in the input utterance or not. This task is intent to improve the column detection ability of the model.  column recovery task,  which consists in randomly replacing some of the column names with one of their cell values and asking the model to recover the original column name either based on the cell value itself or based on the contextual information of the utterance when the column is explicitly mentioned in the utterance. This learning objective is meant to enhance the column inferring ability of the model.  SQL generation, which consists in generating SQL queries given utterances and schema. This task can boost the ability of the model to compose complex queries by leveraging large scale SQL datasets from the Web.%, such as Github.  A key challenge to use the proposed pre-training tasks is training data. Although it is easy to obtain large scale datasets of crawled tables and SQL queries,  it is difficult to obtain high-quality utterances interrelated with the tables or logically consistent with crawled SQL queries. Recent work used the surrounding text of tables as a proxy of natural language utterances. However, this option is far from optimal because those texts are dissimilar to user utterances in terms of text length, composition and content. The surrounding text of a table is usually a paragraph, while natural language utterances in the downstream task are short sentences. Furthermore, the content of surrounding text of tables can be quite noisy because the text may be irrelevant to the table. In \modelname, we overcome the pre-training data challenge through the use of synthetic data. We propose two sequence-to-sequence  generative models, SQL-to-text and table-to-text, that can produce large scale datasets with enough quality for pre-training. We train our generative models by finetuning BART, a state-of-the-art pre-trained language model. Concurrently,~\citet{yu2020grappa} and~\citet{deng2020structure} utilized synthetic data generated from synchronized context-free grammar and existing data-to-text datasets for pre-training, respectively, which requires extra crowd and expert annotation efforts.  The outcome of \modelname is a pre-trained model that can be plugged into neural semantic parsers to compute contextual representations of utterances and schema. We apply \modelname to text-to-SQL semantic parsing datasets, and experimental results show that systems augmented with \modelname~outperform state-of-the-art semantic parsers on Spider and Criteria-to-SQL datasets. In summary, our work presents the following main contributions:     	In this paper, we propose a novel post-processing method for open intent classification. After pre-training the model with labeled samples, our model can learn specific and tight decision boundaries adaptive to the known intent feature space. Our method has no require for open intent or model architecture modification. Extensive experiments on three benchmark datasets show that our method yields significant improvements over the compared baselines and is more robust with less labeled data and fewer known intents. 	 	
","  Most recently, there has been significant interest in learning contextual representations for various NLP tasks, by leveraging large scale text corpora to train large neural language models with self-supervised learning objectives, such as Masked Language Model~. However, based on a pilot study, we observe three issues of existing general-purpose language models when they are applied to text-to-SQL semantic parsers: fail to detect column mentions in the utterances, fail to infer column mentions from cell values, and fail to compose complex SQL queries. To mitigate these issues, we present a model pre-training framework, Generation-Augmented Pre-training~, that jointly learns representations of natural language utterances and table schemas by leveraging generation models to generate pre-train data. \modelnamelm\footnote{This refers to the language models that are pre-trained with GAP framework.} is trained on 2M utterance-schema pairs and 30K utterance-schema-SQL triples, whose utterances are produced by generative models. Based on experimental results, neural semantic parsers that leverage \modelnamelm~as a representation encoder obtain new state-of-the-art results on both Spider and Criteria-to-SQL benchmarks.",451
"    Neural Machine Translation   yields  state-of-the-art translation performance when a large number of parallel sentences are available. However, only a few parallel corpora are available for the majority of language pairs and domains. It has been known that NMT does not perform well in the specific domains where the domain-specific corpora are limited, such as medical domain. As such, high-quality domain-specific machine translation  systems are in high demand whereas general purpose MT has limited applications.  There are many studies of domain adaptation for NMT, which can be mainly divided into two categories: data-centric and model fine-tuning.  Data-centric methods focus on  selecting or generating target domain data from general domain corpora, which is effective and well explored.  In this paper, we focus on the second approach. Fine-tuning is  very common in domain adaptation, which first trains a base model on the general domain data and then fine-tunes it on each target domain . However, unconstrained or full fine-tuning  requires very careful hyper-parameter tuning,  and is prone to over-fitting on the target domain as well as forgetting on the general domain. To tackle these problems, researchers have proposed several constructive approaches, with the view to limiting the size or plasticity of parameters in the fine-tuning stage, which can be roughly divided into two categories: regularization and partial-tuning strategy. Regularization methods often integrate extra training objectives to prevent parameters from large deviations, such as model output regularization , elastic weight consolidation  . Regularization methods, which impose arbitrary global constraints on parameter updates, may further restrict the adaptive process of the network, especially when domain-specific corpora are scarce. Partial-tuning methods either freeze several sub-layers of the network and fine-tune the others, or integrate domain-specific adapters into the network. By only fine-tuning the domain-specific part of the model, they can alleviate the over-fitting and forgetting problem in fine-tuning. However, the structure designed to adapting is usually hand-crafted, which relies on experienced experts and the adapter brings additional parameters. Therefore,  a more adaptive, scalable, and parameter-efficient approach for domain adaptation is very valuable and worth well studying.    In this paper, we propose \method, a novel domain adaptation method via adaptive structure pruning. Our motivation is inspired from Continual Learning  and the lottery hypothesis that a randomly-initialized, dense neural network contains a sub-network which  can match the test accuracy of the original network after training for at most the same number of iterations.   We therefore suppose that multiple  machine translation models for different domains can share different sparse subnetworks within a single neural network.   Specifically, we first apply a standard pruning technique to automatically uncover the subnetwork from a well-trained NMT model in the general domain.  The  subnetwork is capable of  reducing the parameter without compromising accuracy. Therefore, it has the potential to keep as much general information as possible.   Then we freeze this informative sparse network and leave the unnecessary  parameters unfixed for the target  domain, which enables our approach to be parameter efficient, and eases the scalability of the approach to more domains.  The capacity of these non-fixed parameters can be tuned to match the requirements of the target domain, while keeping the parameters of the general domain. Our method successfully circumvents catastrophic forgetting problem and retains the quality on the general domain.  As the benefits of the flexible design, \method can be easily extended to other transfer learning problems, such as multilingual machine translation.      We summarize our main contribution as follows:      % --------------------Background--------------------   In this work, we spot three pain points in the Text-to-SQL semantic parsing task,  and propose a generation-augmented pre-training framework to alleviate them, with four different learning objectives. Experimental results on  dataset and  dataset show the effectiveness of this framework, which achieves state-of-the-art performance on both datasets.      \clearpage   
"," Fine-tuning is a major approach for domain adaptation in Neural Machine Translation .  However, unconstrained fine-tuning requires very careful hyper-parameter tuning otherwise it is easy to fall into over-fitting on the target domain and degradation on the general domain.  To mitigate it, we propose \method, a novel domain adaptation method via gradual pruning.  It learns tiny domain-specific subnetworks for tuning. During adaptation to a new domain, we only tune its corresponding subnetwork.  \method alleviates the over-fitting and the degradation problem without model modification. Additionally, with no overlapping between domain-specific subnetworks, \method is also capable of sequential multi-domain learning.    Empirical experiment results show that \method outperforms several strong competitors in the target domain test set without the quality degradation of the general domain in both single and multiple domain settings. \footnote{The source code and data are available at \url{https://github.com/ohlionel/Prune-Tune}}",452
" As an important task in a dialogue system, response selection aims to find the best matched response from a set of candidates given the context of a conversation. The retrieved responses usually have natural, fluent and diverse expressions with rich information owing to the abundant resources. Therefore, response selection has been widely used in industry and has attracted great attention in academia.  Most existing studies on this task pay more attention to the matching problem between utterances and responses, but with insufficient concern for the reasoning issue in multi-turn response selection. Just recently, MuTual, the first human-labeled reasoning-based dataset for multi-turn dialogue, has been released to promote this line of research. Reasoning is quite different from matching in the conversations. Specifically, matching focuses on capturing the relevance features between utterances and responses, while reasoning not only needs to identify key features , but also needs to conduct inference based on these clue words. The challenges of this new task include:  how to identify the clue words in utterances, which is fundamental for inference;  how to conduct inference according to the clue words in utterances. Figure illustrates a motivating example. To infer the current time, we must first identify the clue words `10:45' in  and `15 minutes' in . Then we must conduct a logical inference based on these clue words in  and .    To tackle these challenges, first, we need better contextual representation for identifying the clue words in conversations. This is because clue word identification inevitably relies on the context of a conversation. Although previous literature publications have achieved promising results in context modeling, there are still several limitations of these approaches. More concretely, the existing studies either concatenate the utterances to form context or process each utterance independently, leading to the loss of dependency relationships among utterances or important contextual information. It has been validated that the chronological dependency between utterances, as well as the semantical dependency between utterances, are crucial for multi-turn response selection. Thus, how to model the dependencies in utterances remains a challenging problem for context representation.  Second, we need to devise a new strategy to collect the clue words scattered in multiple utterances and need to reason according to these clue words. In recent years, we have witnessed great success in KBQA  and MRC  tasks. However, new obstacles emerge for transferring current reasoning approaches in KBQA and MRC to conversational reasoning.  A clear reasoning path based on entities in a well-structured knowledge base exists in KBQA, but there is no similar reasoning path in utterances.  Current approaches on MRC conduct inference based on graph while taking shared entities as nodes, while it is difficult to construct such graphs based on entities in short utterances, which usually suffer from greater coreference resolution, poor content and serious semantic omission problems in comparison with document text.  In this paper, we propose a new model named GRN  which can tackle both challenges in an end-to-end way. We first introduce two pre-training tasks called NUP  and UOP  which are specially designed for response selection. NUP endows GRN with context-aware ability for semantical dependency, and UOP facilitates GRN with the ability to capture the chronological dependency. These customized pre-training methods are beneficial for modeling dependencies contained in utterances to achieve better context representation. We perform task-adaptive pre-training with the combined NUP and UOP tasks based on the ALBERT model. To conduct reasoning based on clue words, we devise a graph neural network called UDG , which not only models the dependencies between utterances with each utterance as a node but also collects the clue words from different utterances. Reasoning is achieved by propagating the messages of clue words between nodes along various utterance paths on UDG, and this graph reasoning structure realizes the inference based on an utterance-level context vector with local perspective. On the other hand, we also implement a reasoning network by the output of the trained model and self-attention mechanism. This sequence reasoning structure realizes the inference based on the highly summarized context vector with global perspective. To summarize, we make the following contributions:      In this work, we propose \method, an effective way for adapting neural machine translation models which first generates an informative subnetwork for the general domain via gradual pruning and then fine-tunes the unnecessary parameters for the target domain. By doing so, \method is able to retain as much general information as possible and alleviate the catastrophic forgetting problems. Experiments show that the proposed \method outperforms fine-tuning and several strong baselines and it is shown to be much more robust compared to fine-tuning due to the complete retainment of the general information. Beyond that, \method can be extended to adapting multiple domains by iteratively pruning and tuning, which is naturally suitable for multi-lingual scenario. We leave the multi-lingual problem as our future work.    --------------------Acknowledgements-------------------- 
"," We investigate response selection for multi-turn conversation in retrieval-based chatbots. Existing studies pay more attention to the matching between utterances and responses by calculating the matching score based on learned features, leading to insufficient model reasoning ability. In this paper, we propose a graph reasoning network  to address the problem. GRN first conducts pre-training based on ALBERT using next utterance prediction and utterance order prediction tasks specifically devised for response selection. These two customized pre-training tasks can endow our model with the ability of capturing semantical and chronological dependency between utterances. We then fine-tune the model on an integrated network with sequence reasoning and graph reasoning structures. The sequence reasoning module conducts inference based on the highly summarized context vector of utterance-response pairs from the global perspective. The graph reasoning module conducts the reasoning on the utterance-level graph neural network from the local perspective. Experiments on two conversational reasoning datasets show that our model can dramatically outperform the strong baseline methods and can achieve performance which is close to human-level.",453
"  A disease is an abnormal medical condition that poses a negative impact on the organisms and enabling access to disease information is the goal of various information extraction as well as text mining tasks. The task of disease normalization consists of assigning a unique concept identifier to the disease names occurring in the clinical text. However, this task is challenging as the diseases mentioned in the text may display morphological or orthographical variations, may utilize different word orderings or equivalent words. Consider the following examples: %}   \end{center} In Example 1, the disease mention short trunk and extremities should be mapped to a candidate Knowledge Base entry containing synonyms like Growth Disorder. In Example 2, Renal amyloidosis should be assigned to Knowledge Base ID  which has synonyms such as, Amyloidosis 8.  Based on our studies and analysis of the medical literature, it has been observed that the same disease name may occur in multiple variant forms such as. synonyms replacement , spelling variation , a short description modifier precedes the disease name , different word orderings .   In this paper, we have formulated the task of learning mention-candidate pair similarity using Triplet Networks . Furthermore, we have explored in-domain word\footnote{http://evexdb.org/pmresources/vec-space-models/} and subword embeddings  as input representations. We find that sub-word information boosts up the performance due to gained information for out-of-vocabulary terms and word compositionality of the disease mentions.  The primary contributions of this paper are three-fold:  1) By identifying positive and negative candidates concerning a disease mention, we optimize the Triplet Network with a loss function that influences the relative distance constraint  2) We have explored the capability of in-domain sub-word level information\footnote{https://github.com/ncbi-nlp/BioSentVec.git} in solving the task of disease normalization. 3) Unlike existing systems , , we present a robust and portable candidate generation approach without making use of external resources or hand-engineered sieves to deal with morphological variations. Our system achieves state-of-the-art performance on NCBI disease dataset      In this paper, we propose a new architecture for multi-turn response reasoning. Concretely, we first propose NUP and UOP pre-training tasks for response selection. We design the UDG of utterance for reasoning. We introduce sequence and graph reasoning structure jointly, where the sequence reasoning module can capture the key information from the global perspective and the graph reasoning module is responsible for capturing the clue words information from the local perspective. The experiment results on MuTual and  achieve a new heights. There is still expansive room for improvement in performance on . In future work, we will further investigate how to balance safe response and meaningful candidate response. 
","   Entity linking  is an essential task in text mining that maps the entity mentions in the medical text to standard entities in a given Knowledge Base . This task is of great importance in the medical domain. It can also be used for merging different medical and clinical ontologies. In this paper, we center around the problem of disease linking or normalization. This task is executed in two phases: candidate generation and candidate scoring. In this paper, we present an approach to rank the candidate Knowledge Base entries based on their similarity with disease mention. We make use of the Triplet Network for candidate ranking. While the existing methods have used carefully generated sieves and external resources for candidate generation, we introduce a robust and portable candidate generation scheme that does not make use of the hand-crafted rules. Experimental results on the standard benchmark NCBI disease dataset demonstrate that our system outperforms the prior methods by a significant margin.",454
" As a fundamental task in natural language processing , coherence analysis can benefit various downstream tasks, such as sentiment analysis  and document summarization . Rhetorical Structure Theory   is one of the most influential theories of text coherence, under which a document is represented by a hierarchical discourse tree, which consists of a set of semantic units organized in the form of a dependency structure, labeled with their rhetorical relations. As shown in Figure , the leaf nodes of an RST discourse tree are basic text spans called Elementary Discourse Units , and the EDUs are iteratively connected by rhetorical relations  to form larger text spans until the entire document is included.  The rhetorical relations are further categorized to Nucleus and Satellite based on their relative importance, in which Nucleus corresponds to the core part while Satellite corresponds to the subordinate part. While manual coherence analysis under the RST theory is labor-intensive and requires specialized linguistic knowledge, a discourse parser serves to automatically transform a document into a discourse tree. Document-level discourse parsing consists of three sub-tasks: hierarchical span splitting, rhetorical nuclearity determination, and rhetorical relation classification.    Models for RST-style discourse parsing have made much progress in the past decade. While statistical methods utilize hand-crafted lexical and syntactic features , data-driven neural approaches reduce feature-engineering labor by effective representation learning, and are capable of characterizing implicit semantic information. Neural networks are first used as feature extractors along with traditional shift-reduce approaches  or dynamic programming approaches . Then, \citet{yu2018transition} bridges the gap between neural and traditional methods by an end-to-end transition-based neural parser via an encoder-decoder architecture. Recently, pointer networks are introduced to achieve linear-time complexity, and models with top-down parsing procedures achieve favorable results on sentence-level discourse analysis tasks .  However, there is still much space for improvement in document-level discourse parsing. First, compared to sentence-level parsing, document-level parsing is more challenging due to the deeper tree structures and longer dependencies among EDUs: in the benchmark dataset RST Discourse Tree Bank  , the average EDU number at the document level is 56, which is 20 times larger than that of sentence-level parsing. Thus modeling context information across a long span is essential, especially if considering a top-down parsing procedure where poor accuracy at the top of the tree will propagate toward the leaf nodes. Second, the three sub-tasks of discourse parsing strongly rely on nuanced semantic judgments, which require comprehensive contextual representation with various types of linguistic information. Take discourse relation classification for example, explicit relations are overtly signaled by a connective word such as ``although'' and ``because'', which can be determined by lexical and syntactic features. However, this approach can not be readily adapted to implicit discourse relations determination, as it requires high-order features with semantic information. Moreover, to compensate for the lack of large-scale corpora, prior work in neural modeling has leveraged inductive biases through syntactic features such as part-of-speech tagging to improve performance. However, such models still suffer from insufficient linguistics information from the lack of data, thus they are incapable of acquiring deeper and richer contextual representations useful for discourse processing.  In this paper, to tackle the aforementioned challenges, we propose a document-level neural discourse parser with robust representation modeling at both the EDU and document level, based on a top-down parsing procedure. To take advantage of widely-adopted vector representations that encode rich semantic information, we first exploit a large-scale pre-trained language model as a contextual representation backbone.  Then we incorporate boundary information with implicit semantic and syntactic features to the EDU representations, and introduce a hierarchical encoding architecture to more comprehensively characterize global information for long dependency modeling. To improve inference accuracy and alleviate the aforesaid error propagation problem, we present breadth-first span splitting to propose a layer-wise beam search algorithm.  We train and evaluate our proposed model on the benchmark corpus RST-DT\footnote{https://catalog.ldc.upenn.edu/LDC2002T07} , and achieve the state-of-the-art performance on all fronts, significantly surpassing previous models while approaching the upper bound of human performance. We also conduct extensive experiments to analyze the effectiveness of our proposed method.     In this paper, we have formulated the task of entity linking as a candidate ranking approach. Using a Triplet Network,  we learn high-quality representations of candidates, tailored to reveal relative distances between the disease mention and its positive and negative candidates. Furthermore,  we take a step towards eliminating the need to generate candidates based on hand-crafted rules and external knowledge resources. Though our method outperforms the existing systems by a strong margin, there is a scope for improvement in terms of attention-based disease similarity  . An intriguing course for future work is to further explore the robustness and scalability of this approach to other clinical datasets for entity normalization.  
"," Document-level discourse parsing, in accordance with the Rhetorical Structure Theory , remains notoriously challenging. Challenges include the deep structure of document-level discourse trees, the requirement of subtle semantic judgments, and the lack of large-scale training corpora. To address such challenges, we propose to exploit robust representations derived from multiple levels of granularity across syntax and semantics, and in turn incorporate such representations in an end-to-end encoder-decoder neural architecture for more resourceful discourse processing. In particular, we first use a pre-trained contextual language model that embodies high-order and long-range dependency to enable finer-grain semantic, syntactic, and organizational representations. We further encode such representations with boundary and hierarchical information to obtain more refined modeling for document-level discourse processing. Experimental results show that our parser achieves the state-of-the-art performance, approaching human-level performance on the benchmarked RST dataset.",455
" Due to the substantial growth and effortless access to the Internet in recent years, an enormous amount of unstructured textual contents have generated. It is a crucial task to organize or structure such a voluminous unstructured text in manually. Thus, automatic classification can be useful to manipulate a huge amount of texts, and extract meaningful insights which save a lot of time and money. Text categorization is a classical NLP problem which aims to categorize texts into organized groups. It has a wide range of applications like machine translation, question answering, summarization, and sentiment analysis. There are several approaches available to classify texts according to their labels. However, deep learning method outperforms the rule-based and machine learning-based models because of their ability to capture sequential and semantic information from texts . We propose a classifier using CNN , and BiLSTM  to classify technical texts in the computer science domain. Furthermore, by sequentially adding these networks, remarkable accuracy in several shared classification tasks can be obtained. The rest of the paper is organized as follows: related work given in section 2. Section 3 describes the dataset. The framework described in section 4. The findings presented in section 5.   %%%%%%%%%%%% Related Work %%%%%%%%%   We proposed to exploit robust representations of multiple levels of granularity at the syntactic and semantic levels and in turn incorporated such representations in an end-to-end encoder-decoder neural architecture for resourceful discourse processing. Our document-level discourse parser compares favorably with the current state-of-the-art. Experimental results show that our document-based neural discourse parser benefits the most from incorporating boundary information at the EDU level and from modeling global information.   
"," This paper illustrates the details description of technical text classification system and its results that developed as a part of participation in the shared task TechDofication 2020. The shared task consists of two sub-tasks:  first task identify the coarse-grained technical domain of given text in a specified language and  the second task classify a text of computer science domain into fine-grained sub-domains. A classification system  is developed to perform the classification task using three techniques: convolution neural network , bidirectional long short term memory  network, and combined CNN with BiLSTM. Results show that CNN with BiLSTM model outperforms the other techniques concerning task-1 of sub-tasks  and task-2a. This combined model obtained $f_1$ scores of 82.63 , 81.95 , 82.39 , 84.37 , and 67.44  on the development dataset. Moreover, in the case of test set, the combined CNN with BiLSTM approach achieved that higher accuracy for the subtasks 1a , 1b , 1c , 1g  and 2a .",456
" The traditional task-oriented dialogue systems, which focuses on providing information and performing actions by the given databases or APIs, often meet the limitation that the DB/API can not cover enough necessary cases. A good enhance can be achieved with lots of relevant domain knowledge in the form of descriptions, FAQs and customer reviews, which we call unstructured knowledge. Track 1 of the 9th Dialogue System Technology Challenges , Beyond Domain APIs: Task-oriented Conversational Modeling with Unstructured Knowledge Access, aims at generating a response based on dialogue history and unstructured knowledge access. The whole task can be divided into three subtasks, knowledge-seeking turn detection, knowledge selection and knowledge-grounded response. Test set of this track includes seen and unseen parts. The unseen test set are collected on different domains, entities, and locales, aiming to evaluate models' generalization ability.   Knowledge-seeking turn detection, as the first subtask, needs to determine whether the related knowledge is contained in the unstructured knowledge base. In other words, this subtask can be modeled as a binary classification problem. If the model predicts that there exists related knowledge, then subtask 2  will search for the most relevant knowledge snippets and then pass them to the generation process . If the model predicts that there is no related knowledge for the specific question, the remaining two subtasks will not be performed. In this paper, we first conduct an entity matching for each question and then add the domain label from matching results to the end of dialogue history as model input.  Knowledge selection is to retrieve the most relevant knowledge snippets from the database according to the dialogue history and provide information for the subsequent response generation. The dialogue history is a conversation between the human speaker and the machine. Close to the end of the conversation, the human speaker brings up a question about a certain place  or service . The given knowledge database consists of question-answer pairs involving diverse facts and is organized by different domains and entities. % Note that the knowledge-seeking turn detection model determines whether our dialog system needs to access the knowledge database before generating the response.  % We perform knowledge selection for the samples  that requires relevant knowledge in the database. The retrieved knowledge snippets provide information for the subsequent response generation.  % Information retrieval  techniques are widely applied to search for related candidates in retrieval-based knowledge-grounded system. Some researchers  compute the traditional tf-idf score to search the most relevant document to the user's query, while others leverage the power of neural networks to learn the ranking score directly through an end-to-end learning process. Recently, due to the significant improvements on numerous natural language processing tasks, large scale pre-trained language models have also been applied to better model the semantic relevance in knowledge selection.  In this paper, we first apply retrieval techniques to narrow down the searching space and then use a neural network initialized by a pre-trained model to formulate the ranking function. % We propose two base models for the knowledge selection, and the final ensemble model combines the predictions of different base models to improve the selection performance.  % The Retrieve \& Rank model first gathers the knowledge snippets of potentially relevant entities from the knowledge base, then a ranking model is trained to select the most plausible knowledge snippets from the retrieved candidates. % Different from the Retrieve \& Rank model, Three-step model divides the ranking model into three cascade parts to rank domain, entity and documents respectively in order to force the model to take the knowledge hierarchy into account. % We also ensemble these two models together and experiments show the ensemble model has a better performance than two base model separately.   % briefly introduce the three-step pipeline model.   Knowledge-grounded response generation requests to give a response automatically from the model using dialogue history and unstructured knowledge as input. There are two different types of dialogue systems, retrieval-based system, and generation-based system. Retrieval-based dialogue system, giving responses from a list of candidate sentences, only has fixed answer forms in candidate sets. To deal with our problem, which needs more flexible and natural responses, the generation-based model is a better choice. Dialogue generation requires an encoder to represent the input and a decoder to generate the response. The network often needs to minimize the cross-entropy loss between the output and the ground truth. In this paper, we use a latent variable to encode dialog history and selected knowledge better and generate responses combined with copy mechanism.  % Pre-trained language models make a great progress on dialogue generation. Note that bi-directional model is not designed for dialogue generation task, and thus PLATO and  PLATO-2 use uni- and bi-directional processing for pre-training. Moreover, large-scale Reddit and Twitter conversations are utilized to further pre-train the generation model to reduce data distribution gaps. Furthermore, a latent variable  is used to capture one-to-many relations of post-response pairs.  As shown in released evaluation results, our proposed system ranks second under objective metrics and ranks fourth under human metrics. In the following sections, we will explain the details of our proposed model. Experiment results will be shown next with some analysis and conclusions.    This paper presents a detail description of the proposed system and its evaluation for the technical texts classification in different languages. As the baseline method, we used CNN and BiLSTM, and compare these methods with the proposed model . Each model is trained, tuned and evaluated separately for subtasks 1 and 2. The proposed method showed better performance in terms of accuracy for subtasks  of task 1 and task 2a on development set. However, in the case of test set, the system performed better for the subtasks 1a, 1b, 1c, 1g and 2a. More dataset can be included for improved performance. In future, the attention mechanism may be explored to observe its effects on text classification tasks.   
"," Task-oriented conversational modeling with unstructured knowledge access, as track 1 of the 9th Dialogue System Technology Challenges , requests to build a system to generate response given dialogue history and knowledge access. This challenge can be separated into three subtasks,  knowledge-seeking turn detection,  knowledge selection, and  knowledge-grounded response generation. We use pre-trained language models, ELECTRA and RoBERTa, as our base encoder for different subtasks. For subtask 1 and 2, the coarse-grained information like domain and entity are used to enhance knowledge usage. For subtask 3, we use a latent variable to encode dialog history and selected knowledge better and generate responses combined with copy mechanism. Meanwhile, some useful post-processing strategies are performed on the model's final output to make further knowledge usage in the generation task.  As shown in released evaluation results, our proposed system ranks second under objective metrics and ranks fourth under human metrics.",457
"  %    Recent years have witnessed the rapid advancement of online recruitment platforms. With the increasing amount of online recruitment data, more and more interview related studies have emerged such as person-job  fit and automatic analysis of asynchronous video interviews , which aim to enable automated job recommendation and candidate assessment. Among these studies, person-job fit is to casting the task as a supervised text match problem. Given a set of labeled data , it aims to predict the matching label between the candidate resumes and job description. More recently, deep learning has enhanced person-job fit methods by training more effective text match or text representations models. AVI is to determine whether the candidate is hirable by evaluating the answers of interview questions. In AVIs, an interview is usually considered as a sequence of questions and answers containing salient socials signals. To evaluate the candidates more comprehensively, AVI models will extract the features of video , text, and voice in the process of answering questions. In this work, we focus on the scoring of multiple QA pairs,  we only extract the features of text modality and define this task as the scoring competency of candidates rather than the score of whether or not to be employed. Based on the anatomy of the human interviewers' evaluation process, the solutions consist of two stages:  analyzing and evaluating individual QA pair one by one, then acquiring the evaluation status, and  grading the competency of the candidate based on the evaluation status of multiple QA pairs.      For the first stage, existing methods tend to employ text matching or attentional text matching algorithms to evaluate QA pairs, which feeds the concatenated representation of the question and the answer to the subsequent classifier. As we all know, questions in an asynchronous video interview are not limited to specific domains. That is to say, candidates can answer questions according to their work or study experience. In this way, the candidates' answers will be varied and it is difficult to evaluate the answer accurately only by text matching. Intuitively, it is more reasonable to evaluate QA pairs through the semantic interaction between questions and answers. A critical challenge along this line is how to reveal the latent relationships between each question and answer.  %Intuitively, experienced interviewers could discover the semantic-level correlation between interview questions and candidates' answers, then obtain a preliminary judgement on the answer to the current question, and finally give an assessment based on the judgements of several problems. Therefore,  %In this work, we propose a sentence-level reasoning GNN to assess the single QA pair at the semantic interaction level. Graph neural networks  can learn effective representation of nodes by encoding local graph structures and node attributes. Due to the compactness of model and the capability of inductive learning, GNNs are widely used in modeling relational data and logical reasoning. Recently, ~\citet{zhang2020efficient} proposed a GNN variant, Named ExpressGNN, to strike a nice balance between the representation power and the simplicity of the model in probabilistic logic reasoning.~\citet{ghosal2019dialoguegcn} constructed the DialogeGCN to address context propagation issues present in the RNN-based methods. Specifically, they leverage self and inter-speaker dependency of the interlocutors to model conversational context for emotion recognition. Inspired by, we present a sentence-level relational GCN to represent the internal temporal and QA interaction dependency in the process of answering questions. %Recently, graph neural network or graph emebedding has attracted wide attention. Graph neural networks have been effective at tasks thought to have rich relational structure and can preserve global structure information of a graph in graph emebedding.   %In this work, we aim to address the task of automatically scoring the textual answer of candidates at the semantic interaction level.  %The automatic short answer scoring  is a task of estimating a score of a short text answer written as response to a given prompt on the basis of whether the answer satisfies the rubrics prepared by a human in advance. ASAS systems have mainly been constructed to markedly reduce the scoring cost of human rater.   %鐟欏嫬鍨鍫ユ閸掕泛鐣鹃敍灞芥礈濮濄倕顕梻顕顣介崪灞芥礀缁涙棃妫跨拠顓濈疅娴溿倓绨伴惃鍕閹烘ɑ妯夊妤佹纯閸旂娀鍣哥憰 %閸ョ偓膩閸ㄥ婀梻顕顣介幒銊ф倞娴犺濮熸稉濂僥ep learning has proven to be effective in long text NLP tasks. Due to the lack of information in the short sentence of the ASAS corpus, it seems not good enough in the ASAS task.  For the second stage of grading the candidate, based on the representation of QA pairs, exists methods prefer to encoder question-answer pairs as a sequence directly. However, this kind of approaches lead to insufficient interaction between the semantic information of question and answer pairs. Therefore, it is difficult to ensure the rationality and explainability of the evaluation. To mitigate this issue, in the first stage, we present a semantic-level graph attention network  to model the interaction states of each QA session.    %Automatic scoring of answer transcriptions in job interview aims to evaluate multiple question-answer pairs.  %To alleviate this limitation of previous approaches, To this end, we propose a Hierarchical Reasoning Graph Neural Network  for the automatic scoring of answer transcriptions  in job interviews. Specifically, the proposed sentence-level relational graph convolutional neural network  is used to capture the contextual dependency, and the semantic-level Reasoning graph attention network  is applied to acquire the latent interaction states. And the contribution of our work can be summarized as follows:     This paper describes our overall system that is evaluated in Track 1 of DSTC 9.  Pre-trained language models, ELECTRA and RoBERTa, are used as our base encoder, and task-specific components are applied to improve performance. In the released evaluation results, we rank second under objective metrics and rank fourth under human metrics. Considering the gap between validation and test set, it is worthwhile for us to further study how to generalize our model in a better way, that is, transferring our in-domain system to the out-of-domain scenario. 
"," %Automatic scoring of answer transcripts in job interview aims to evaluate multiple question-answer pairs. The key challenge is how to conduct deep interaction on the semantic level for each question-answer pair, and give the evaluation results combined with multiple interaction states. Recent studies either use text matching approaches to evaluate each question-answer pair roughly, or employ the sequential model to deal with disordered question-answer pairs which fail to take advantages of the semantic association between questions and answers, and the logical connection between question-answer pairs. In this work, we propose a hierarchical reasoning Graph Neural Network  for the automatic assessment of multi-question answering. Specifically, we construct a sentence-level reasoning GNN to assess the single question-answer pair. Based on these graphs, we propose a document-level reasoning GNN to model the interaction states of question-answer pairs. The first module utilizes each sentence in the question and answer to establish the connection between them. The second module adopts a graph convolutional network to encoder interaction states of each pair and aggregates evidence with graph attention mechanism for predicting the final score. Empirical results on Chinese and English interview datasets show that our proposed model outperforms both sequence-based and pre-training based  benchmark models.  %We address the task of automatically scoring the answer competency of candidates based on textual features from the automatic speech recognition transcriptions. The key challenge is how to conduct deep interaction on the semantic level for each question-answer  pair, and give the evaluation results combined with multiple interaction states. Recent studies either use text matching approaches to evaluate each QA pair roughly, or employ the sequential model to deal with disordered QA pairs which fail to take advantages of the semantic association between questions and answers, and the logical connection between QA pairs. In this work, we propose a hierarchical reasoning Graph Neural Network  for the automatic assessment of question-answer pairs. Specifically, we construct a sentence-level reasoning GNN to assess the single QA pair. Based on these graphs, we propose a document-level reasoning GNN to model the interaction states of QA pairs. The first module utilizes each sentence in the question and answer to establish the connection between them. The second module adopts a graph convolutional network to encoder interaction states of each pair and aggregates evidence with graph attention mechanism for predicting the final score. Empirical results conducted on CHNAT and ENGIAT  clearly validate that our proposed model outperforms both text matching based benchmark models.  %We address the task of automatically scoring the competency of candidates based on textual features, from the automatic speech recognition  transcriptions in the video job interview. The key challenge is how to conduct deep interaction on the semantic level for each question-answer  pair, and then give the evaluation results combined with multiple interaction states. Recent studies tend to use text matching approaches to evaluate each QA pair roughly, which fails to take advantage of the semantic association between questions and answers. In this work, we propose a Hierarchical Reasoning Graph Neural Network  for the automatic assessment of question-answer pairs. Specifically, we construct a sentence-level relational graph neural network to capture the latent semantic interaction of sentences in the question or the answer. Based on these graphs, we employ a semantic-level reasoning graph attention network to model the interaction states of the current QA session. Finally, we propose a gated recurrent unit with a global fusion mechanism to aggregates evidence of temporal QA pairs for the final score. Empirical results conducted on CHNAT  clearly validate that our proposed model significantly outperforms text-matching based benchmark models. Ablation studies and experimental results with 10 random seeds also show the effectiveness and stability of our models.    We address the task of automatically scoring the competency of candidates based on textual features, from the automatic speech recognition  transcriptions in the asynchronous video job interview . The key challenge is how to construct the dependency relation between questions and answers, and conduct the semantic level interaction for each question-answer  pair. However, most of the recent studies in AVI focus on how to represent questions and answers better, but ignore the dependency information and interaction between them, which is critical for QA evaluation. In this work, we propose a Hierarchical Reasoning Graph Neural Network  for the automatic assessment of question-answer pairs. Specifically, we construct a sentence-level relational graph neural network to capture the dependency information of sentences in or between the question and the answer. Based on these graphs, we employ a semantic-level reasoning graph attention network to model the interaction states of the current QA session. Finally, we propose a gated recurrent unit encoder to represent the temporal question-answer pairs for the final prediction. Empirical results conducted on CHNAT  validate that our proposed model significantly outperforms text-matching based benchmark models. Ablation studies and experimental results with 10 random seeds also show the effectiveness and stability of our models.",458
"  Social media is a unique source of information. On the one hand, their low cost, easy access and distribution speed make it possible to quickly share the news. On the other hand, the quality and reliability of social media news is difficult to verify . This is the source of a lot of false information that has a negative impact on society.   Over the past year, the world has been watching the situation developing around the novel coronavirus pandemic. The COVID-19 pandemic has become a significant newsworthy event of 2020. Therefore, news related to COVID-19 are actively discussed on social media and this topic generates a lot of misinformation. Fake news related to the pandemic have large-scale negative social consequences, they provoke huge public rumor spreading and misunderstanding about the COVID-19 and aggravate effects of the pandemic. Moreover, recent studies  show an increase in symptoms such as anxiety and depression in connection with the pandemic. This is closely related to the spread of misinformation, because fake news can be more successful when the population is experiencing a stressful psychological situation . The popularity of fake news on social media can rapidly increase, because the rebuttal is always published too late. In this regard, there is evidence that the development of tools for automatic COVID-19 fake news detection plays a crucial role in the regulation of information flows.  In this paper, we present our approach for the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in English  that attracted 433 participants on CodaLab. This approach achieved the weighted F1-score of 98.69  on the test set among 166 submitted teams in total.  The rest of the paper is organized as follows. A brief review of related work is given in Section 2. The definition of the task has been summarized in Section 3, followed by a brief description of the data used in Section 4. The proposed methods and experimental settings have been elaborated in Section 5. Section 6 contains the results and error analysis respectively. Section 7 is a conclusion.    In this paper, we propose a hierarchical reasoning graph neural network  for the automatic scoring of answer transcriptions  in the video job interview. The ASAT task is to score the competency of candidates based on several textual question-answer pairs. Unlike other matching based methods or frameworks, HRGNN can utilize the relational dependency of sentences in the questions and answers, and aggregate them in the semantic level with reasoning flow between different graph layers. Particularly, the proposed relational graph convolutional network  module constructs internal temporal dependency and question-answer interaction dependency to represent the relations between sentences in the question and the answer. And in the graph-based reasoning part, we propose a graph attention network to further aggregate semantic interactions between the question and the answer. Finally, we apply a GRU-based classifier to discriminate the candidate is competent or not. Empirical results with 10 random seeds show that our model achieves state-of-the-art on a Chinese real-world dataset .   We address the task of automatically scoring the competency of candidates based on textual features, from the automatic speech recognition  transcriptions in the video job interview. The key challenge is how to conduct deep interaction on the semantic level for each question-answer  pair, and then give the evaluation results combined with multiple interaction states. Recent studies tend to use text matching approaches to evaluate each QA pair roughly, which fails to take advantage of the semantic association between questions and answers. In this work, we propose a Hierarchical Reasoning Graph Neural Network  for the automatic assessment of question-answer pairs. Specifically, we construct a sentence-level reasoning graph neural network to capture the latent semantic interaction of sentences in the question or the answer. Based on these graphs, we employ a semantic-level graph attention network to model the interaction states of the current QA session. Finally, we propose a gated recurrent unit with a global fusion mechanism to aggregates evidence of temporal QA pairs for the final score. Empirical results conducted on CHNAT  clearly validate that our proposed model significantly outperforms text-matching based benchmark models.   \begin{comment} 
"," The COVID-19 pandemic has had a huge impact on various areas of human life. Hence, the coronavirus pandemic and its consequences are being actively discussed on social media. However, not all social media posts are truthful. Many of them spread fake news that cause panic among readers, misinform people and thus exacerbate the effect of the pandemic. In this paper, we present our results at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in English. In particular, we propose our approach using the transformer-based ensemble of COVID-Twitter-BERT  models. We describe the models used, the ways of text preprocessing and adding extra data. As a result, our best model achieved the weighted F1-score of 98.69 on the test set  of this shared task that attracted 166 submitted teams in total.  \keywords{COVID-Twitter-BERT, social media, fake news, ensembling learning, coronavirus, infodemic, text classification}",459
"  	 	 	      	Medical dialogue system  aims to converse with patients to inquire additional symptoms beyond their self-reports and make a diagnosis automatically, which has gained increasing attention . 	It has a significant potential to simplify the diagnostic process and relieve the cost of collecting information from patients . Moreover, preliminary diagnosis reports generated by MDS may assist doctors to make a diagnosis more efficiently.   	Because of these considerable benefits, many researchers devote substantial efforts  to address critical sub-problems in  MDS, such as natural language understanding , dialogue policy learning, dialogue management, and make promising  progress to build a satisfactory MDS.   	 	 	Medical dialogue generation , which generates responses in natural language to request additional symptoms or make a diagnosis, is critical in MDS but rarely studied. 	Conventional generative dialogue models often employ neural sequence modeling and cannot be applied to the medical dialogue scenario directly in absence of medical knowledge. Recently, large-scale pre-training language models  over unsupervised corpora have achieved significant success.      However, fine-tuning such large language models in the medical domain requires sufficient task-specific data  so as to learn the correlations between diseases and symptoms. 	Unfortunately, as depicted in Fig., there are a large portion of diseases that only have a few instances in practice, which means that newly-coming diseases in the realistic diagnosis scenario are often under low-resource conditions. Therefore, it is highly desirable to transfer the diagnostic experience from high-resource diseases to others of data scarcity.  	Besides, existing knowledge-grounded approaches may fail to perform such transfer well, as they only learn one unified model for all diseases and ignore the specificity and relationships of different diseases. 	Finally, in practice, the disease-symptom relations of each disease may vary or evolve along with more cases, which is also not considered in prior works.    	Contributions.	To address the above challenges, we first propose an end-to-end  dialogue system for the low-resource medical dialogue generation. 	This model integrates three components seamlessly, a hierarchical context encoder,  a meta-knowledge graph reasoning  network and a graph-guided response generator. Among them, the context encoder encodes  the conversation into hierarchical representations. For MGR, it mainly contains a parameterized meta-knowledge graph, which is initialized by a prior commonsense graph and characterizes the correlations among diseases and symptoms.  When fed into the context information, MGR can adaptively evolve its meta-knowledge graph to reason the disease-symptom correlations and then predict related symptoms of the patient in the next response to further determine the disease. Finally, the response generator generates a response for symptoms request  under the guidance of the meta-knowledge graph.   	The second contribution is that we further develop a novel Graph-Evolving Meta-Learning  framework to  transfer the diagnostic experience in the low-resource scenario. Firstly, GEML trains the above medical dialogue model under the meta-learning framework. It regards generating responses to a handful of dialogues as a task and learns a meta-initialization for the above dialogue model that can fast adapt to each task of the new disease with limited dialogues. In this way, the learnt model initialization contains sufficient meta-knowledge\footnote{We name such knowledge as ``meta-knowledge"" since it is obtained through meta-training from different source diseases.} from all source diseases and can serve as a good model initialization to quickly transfer meta-knowledge to a new disease. More importantly, GEML also learns a good parameterized meta-knowledge  graph in the MGR module to characterize the disease-symptom relationships from source diseases. Concretely, under the meta learning framework, for each disease, GEML enriches the meta-knowledge graph via constructing a global-symptom graph from the online dialogue examples. In this way, the learnt meta-knowledge graph can bridge the gap between the commonsense medical graph and the real diagnostic dialogues and thus can be fast evolved for the new target disease. Thanks to graph evolving, the dialogue model can request patients for underlying symptoms more efficiently and thus improve the diagnostic accuracy. Besides,  GEML can also well address the real-world challenge that the disease-symptom correlations could vary along with more cases, since the meta-knowledge  graph is trainable based on collected dialogue examples.  	 	Finally, we  construct a large medical dialogue dataset, called Chunyu\footnote{Code and dataset are released at https://github.com/ha-lins/GEML-MDG.}.  	It covers 15  kinds of diseases and 12,842 dialogue examples totally, and  is much larger than the existing CMDD  medical dialogue dataset. The more challenging benchmark can better comprehensively evaluate the performance of medical dialogue systems.  Extensive experimental results on both datasets demonstrate the superiority of our method over the state-of-the-arts.     In this work, we propose a simple but effective approach to COVID-19 fake news detection based on CT-BERT and ensembling learning. Our experiments confirmed that BERT-based models specialized in the subject area successfully cope with such tasks and perform high-quality binary classification.  The experimental results showed that our solution achieved 98.69\  of the weighted F1-score on test data and ranked in the first place in the Constraint@-AAAI2021 shared task. For future work, we can experiment with different training and data augmentation techniques. We can also apply and evaluate hybrid models combining BERT-based architectures with other methods of natural language processing .      ---- Bibliography ----     BibTeX users should specify bibliography style 'splncs04'.   References will then be sorted and formatted in the correct style.     
","  	 	Human doctors with well-structured medical knowledge can diagnose a disease merely via a few conversations with patients about symptoms. In contrast, existing knowledge-grounded dialogue systems often require a large number of dialogue instances to learn as they fail to capture the correlations between different diseases and neglect the diagnostic experience shared among them. To address this issue, we propose a more natural and practical paradigm, i.e., low-resource medical dialogue generation, which can transfer the diagnostic experience from source diseases to target ones with a handful of data for adaptation. It is capitalized on a commonsense knowledge graph to characterize the prior disease-symptom relations.  	Besides, we develop a Graph-Evolving Meta-Learning  framework that learns to evolve the commonsense graph for reasoning disease-symptom correlations in a new disease, which effectively alleviates the needs of a large number of dialogues. More importantly, by dynamically evolving disease-symptom graphs, GEML also well addresses the real-world challenges that the disease-symptom correlations of each disease may vary or evolve along with more diagnostic cases. Extensive experiment results on the CMDD dataset and our newly-collected Chunyu dataset testify the superiority of our approach  over state-of-the-art approaches.  	Besides, our GEML can generate an enriched dialogue-sensitive knowledge graph in an online manner, which could benefit other tasks grounded on knowledge graph.",460
"   Machine translation has been shown to exhibit gender bias , and several solutions have already been proposed to mitigate it . The general gender bias in Natural Language Processing  has been mainly attributed to data . Several studies show the pervasiveness of stereotypes in book collections , or Bollywood films , among many others. As a consequence, our systems trained on this data exhibit biases. Among other strategies, several studies have proposed to work in data augmentation to balance data  or forcing gender-balanced datasets . In parallel, other initiatives focus on documenting our datasets  to prioritize transparency.  However, data is not the only reason for biases, and recent studies show that %algorithms and training strategies matter.  our models can be trained in a robust way to reduce the effects of data correlations . In , the authors explored available mitigations and by increasing dropout, which resulted in improving how the models reasoned about different stereotypes in WinoGender examples .   The purpose of the current paper is to explore if the Multilingual Neural Machine Translation  architecture can impact the amount of gender bias. To answer this question, we compare MNMT architectures trained with the same data and quantify their amount of gender bias with the standard WinoMT evaluation benchmark . Results show that the Language-Specific encoders-decoders  exhibit less bias than the Shared encoder-decoder . Then, we analyze and visualize why the MNMT architecture impacts mitigating or amplifying this bias by studying its internal workings. We study the amount of gender information that the source embeddings encode, and we see that Language-Specific surpasses Shared in these terms, allowing for a better prediction of gender.  Additionally, and taking advantage that both Shared and Language-Specific are based on the Transformer , we study the coefficient of variation in the attention , which shows that the attention span is narrower for the Shared system than for the Language-Specific one. Therefore, the context taken into account is smaller for the Shared system, which causes a higher gender bias.   %We observe that this is caused by using a Shared encoder-decoder with several languages since pairwise Bilingual systems have a wider attention span. Given the similarities of not sharing modules and parameters across languages in both Bilingual and Language-Specific, this characteristic  of the Bilingual systems prevails in the language-specific architecture.   Finally, we also do a manual analysis to investigate which biases have a linguistic explanation. %implications in gender bias has the target language from the linguistic and social point of view.      In this work, we build an ensemble deep learning framework on top of several attention-based deep neural networks to achieve the task objective of predicting categories for a GIF response. We effectively incorporate both the tweets and their text responses in building our automated systems. Our participation in EmotionGIF 2020 has been a wonderful learning experience for our team as we have achieved 5\textsuperscript{th} rank in both the rounds with attained MR@6 scores of 0.5292 and 0.5380, respectively. We look forward to learn more from the best-performing systems. Results indicate that our models can serve as strong baselines as an alternative framework to transformer-based approaches.   In future, we will try to enrich the learning of our developed end-to-end systems by effectively incorporating multimodal features extracted from the GIFs of training data and map them to unlabelled test data .    
"," Multilingual Neural Machine Translation architectures mainly differ in the amount of sharing modules and parameters among languages. In this paper, and from an algorithmic perspective, we explore if the chosen architecture, when trained with the same data, influences the gender bias accuracy. Experiments in four language pairs show that Language-Specific encoders-decoders exhibit less bias than the Shared encoder-decoder architecture. Further interpretability analysis of source embeddings and the attention shows that, in the Language-Specific case, the embeddings encode more gender information, and its attention is more diverted. Both behaviors help in mitigating gender bias.",461
" Commonsense question answering  is recently an attractive field in that it requires systems to understand the common sense information beyond words, which are normal to human beings but nontrivial for machines. There are plenty of datasets that are proposed for this purpose, for instance, CommonsenseQA , CosmosQA , WIQA . Different from traditional machine reading comprehension  tasks such as SQuAD  or NewsQA  that the key information for answering the questions is directly given by the context paragraph, solving commonsense questions requires a more comprehensive understanding of both the context and the relevant common knowledge, and further reasoning out the hidden logic between them. There are varieties of knowledge bases that meet the need, including text corpora like Wikipedia, and large-scale knowledge graphs .  Recent popular solution resorts to external supporting facts from such knowledge bases as evidence, to enhance the question with commonsense knowledge or the logic of reasoning . However, the quality of the supporting facts is not guaranteed, as some of them are weak in interpretability so that do not help the question answering. Specifically, current methods are mainly two-fold. The first group of methods  pre-train language models on those external supporting facts  so that the models could remember some of the common knowledge, which is empirically proven by Tandon et al. \shortcite{tandon2019wiqa} and Trinh and Le \shortcite{trinh2018do}. The second group of methods  incorporates the question with knowledge subgraphs or paths that carry information such as relation among concepts or show multi-hop reasoning process. The structured information is typically encoded via graph models such as GCN , and after which merged with the question features. Generally, current methods all handle evidence by brute force, without further selection or refinement according to the interpretability of the supporting facts. But as the example shown in Figure, some of the supporting facts do not interpret the question, regardless that they are semantically related. Thus, there is need for models that will further our processing of the evidence.  In this paper, we introduce a new recursive erasure memory network  that further refines the candidate supporting fact set. The REM-Net consists of three main components: a query encoder, an evidence generator, and a novel recursive erasure memory  module. Specifically, the query encoder is a pre-trained encoder that encodes the question. The evidence generator is a pre-trained generative model that produces candidate supporting facts based on the question. Compared with those retrieved supporting facts, the generated facts provides new question-specific information beyond the existing knowledge bases. The REM module refines the candidate supporting fact set by recursively matching the supporting facts and the question in feature space to estimate each fact's quality. This estimation helps both updating the question feature and the supporting fact set. The question feature is updated by a residual term, whereas the supporting fact set is updated by removing the low-quality facts. Compared with the standard attention mechanisms  that allocate weights to the supporting facts once, the multi-hop operation in REM module widens the gap of how much each supporting fact contributes to the question answering by the number of recursive steps their features are incorporated for the feature update. Therefore this procedure leads to a refined use of given supporting facts.  We conduct experiments on two commonsense QA benchmarks, WIQA  and CosmosQA . The experimental results demonstrate that REM-Net outperforms current methods, and the refined supporting facts are more qualified for the questions. Our contributions are mainly three-fold:        This paper shows that the MNMT architecture by itself has an impact on gender accuracy. Language-Specific outperforms Shared in two different language sets: English, German, Spanish, French and English, German, Spanish, French, and Russian. We observe that the difference in gender accuracy is higher in the language set including Russian.   Further interpretability analysis of the results shows that source embeddings in the Language-Specific architecture retain higher information on gender. Moreover, this architecture also keeps enough diversion in the attention, especially when including Russian. Both elements help in better inferring the correct gender.   Finally, a manual analysis shows that most of the errors are made assuming a masculine occupation instead of a feminine one. In contrast, the inverse error tends to come when there is a feminine version of that word with another meaning.    
"," When answering a question, people often draw upon their rich world knowledge in addition to the particular context. While recent works retrieve supporting facts/evidence from commonsense knowledge bases to supply additional information to each question, there is still ample opportunity to advance it on the quality of the evidence. It is crucial since the quality of the evidence is the key to answering commonsense questions, and even determines the upper bound on the QA systems' performance. In this paper, we propose a recursive erasure memory network  to cope with the quality improvement of evidence. To address this, REM-Net is equipped with a module to refine the evidence by recursively erasing the low-quality evidence that does not explain the question answering. Besides, instead of retrieving evidence from existing knowledge bases, REM-Net leverages a pre-trained generative model to generate candidate evidence customized for the question. We conduct experiments on two commonsense question answering datasets, WIQA and CosmosQA. The results demonstrate the performance of REM-Net and show that the refined evidence is explainable.",462
"  Neural machine translation  has advanced significantly in recent years . In particular, the Transformer model has become popular for its well-designed architecture and the ability to capture the dependency among positions over the entire sequence . Early systems of this kind stack 4-8 layers on both the encoder and decoder sides , and the improvement often comes from the use of wider networks . More recently, researchers try to explore deeper models for Transformer. Encouraging results appeared in architecture improvements by creating direct pass from the low-level encoder layers to the decoder , and proper initialization strategies .  Despite promising improvements, problems still remain in deep NMT. Deep Transformer stacked by dozens of encoder layers always have a large number of parameters, which are computationally expensive and memory intensive. For example, a 48-layer Transformer is  larger than a 6-layer system and  slower for inference. It is difficult to deploy such models on resource-restricted devices, such as mobile phones. Therefore, it is crucial to compress such heavy systems into light-weight ones while keeping their performance.  Knowledge distillation is a promising method to address the issue. Although several studies  have attempted to compress the 12-layer BERT model through knowledge distillation, effectively compressing extremely deep Transformer NMT systems is still an open question in the MT community. In addition, these methods leverage sophisticated layer-wise distillation loss functions to minimize the distance between the teacher and the student models, which requires huge memory consumption and enormous training cost.  In this paper, we investigate simple and efficient compression strategies for deep Transformer. We propose a novel Transformer compression approach ) to transfer the knowledge from an extremely deep teacher model into a shallower student model. We disturb the computation order among each layer group during the teacher training phase, which is easy to implement and memory friendly. Moreover, to further enhance the performance of the teacher network, we introduce a vertical ``dropout''  into training by randomly omitting sub-layers to prevent co-adaptations of the over-parameterized teacher network. Although similar technique has been discussed in \citet{fan2019reducing}'s work, we believe that the finding here is complementary to theirs. Both Gpkd and regularization training methods can be well incorporated into the teacher training process, which is essential for obtaining a strong but light-weight student model.  \pgfdeclarepatternformonly{soft horizontal lines}{\pgfpointorigin}{\pgfqpoint{100pt}{1pt}}{\pgfqpoint{100pt}{3pt}}% {   \pgfsetstrokeopacity{0.3}   \pgfsetlinewidth{0.1pt}   \pgfpathmoveto{\pgfqpoint{0pt}{0.5pt}}   \pgfpathlineto{\pgfqpoint{100pt}{0.5pt}}   \pgfusepath{stroke} }  \pgfdeclarepatternformonly{soft crosshatch}{\pgfqpoint{-1pt}{-1pt}}{\pgfqpoint{6pt}{6pt}}{\pgfqpoint{5pt}{5pt}}% {   \pgfsetstrokeopacity{0.3}   \pgfsetlinewidth{0.4pt}   \pgfpathmoveto{\pgfqpoint{4.5pt}{0pt}}   \pgfpathlineto{\pgfqpoint{0pt}{4.5pt}}   \pgfpathmoveto{\pgfqpoint{0pt}{0pt}}   \pgfpathlineto{\pgfqpoint{4.5pt}{4.5pt}}   \pgfusepath{stroke} }  \definecolor{ugreen}{rgb}{0,0.5,0}    	%reoder 1 	\draw[line width=1pt,draw=red!30,fill=red!20] -- --  --  -- --  --  -- ; 	\draw[line width=1pt,draw=blue!35,fill=blue!20] -- --  --  -- --  --  -- ;  	%reoder 2 	\draw[line width=1pt,draw=red!30,fill=red!20] -- --  --  -- --  --  -- ; 	\draw[line width=1pt,draw=blue!35,fill=blue!20] -- --  --  -- --  --  -- ;  	%reoder 3 	\draw[line width=1pt,draw=red!30,fill=red!20] -- --  --  -- --  --  -- ; 	\draw[line width=1pt,draw=blue!35,fill=blue!20] -- --  --  -- --  --  -- ; 	\node[anchor=north,inner sep=0pt] at {}; 	\node[anchor=north,inner sep=0pt] at {};   	\node[anchor = south,font=;   	\node[anchor = south,font=;   	\node[anchor = south,font=;   	\node[anchor = south,font=\footnotesize]  at  {};   	\node[anchor = east,font=\footnotesize,rotate=-90]  at  {};   	\node[anchor = east,font=\footnotesize,rotate=-90]  at  {};   	\node[anchor = east,font=\footnotesize,rotate=-90]  at  {};    	\node[anchor = north,font=\scriptsize]  at {reorder};    	\node[anchor = west]   at  {};   	\node[anchor = west]  at  {};   	\node[anchor = west]  at  {};     %draw   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;    \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;    \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;    \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;      \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;   \draw[-latex',thick]  -- ;          \draw[-latex',very thick,red!40] ..controls + and +..;   \draw[-latex',very thick,blue!40] ..controls + and +..; 	\node[font=\tiny]  at  {sampling};    \node [auto,anchor=west,font=\footnotesize,rotate=-90] at {Teacher Training} ;    \node [auto,anchor=west,font=\footnotesize,rotate=-90] at {Student Training} ;       \node[auto,anchor=south,font=\footnotesize,inner sep=0pt] at  {Generate Skd-data} ;      \node[draw=gray!70,line width=1pt,fill=gray!10,single arrow,minimum height=2.2em,minimum width=4pt,single arrow head extend=3pt]  at {};    \node[draw=gray!70,line width=1pt,fill=gray!10,single arrow,minimum height=1.6em,minimum width=4pt,single arrow head extend=3pt,rotate=-90]  at {};    \end{tikzpicture}       \end{figure*}   We ran experiments on the WMT16 English-German, NIST OpenMT12 Chinese-English and WMT19 Chinese-English translation tasks. The Gpkd method compressed a 48-layer Transformer into a 6-layer system with almost no loss in BLEU. It outperformed the baseline with the same depth by + BLEU points. Through skipping sub-layer method, the teacher network achieved a BLEU score of  BLEU on the newstest2014 English-German task, and the student obtains additional improvements of  BLEU points.  % Moreover, we present a deep-encoder and shallow-decoder architecture  which achieves a speedup of  times with almost no loss in BLEU.       In this work, we curated a large-scale dialogue dataset, OSED, comprising of 1M emotional dialogues from movie subtitles. This dataset is more general-purpose, larger in size, and contains more fine-grained emotion categories and empathetic response intents than the existing emotional dialogue datasets. To facilitate annotation, we developed a dialogue emotion classifier capable of recognizing 32 fine-grained emotions and 9 empathetic response intents with significant accuracy. It was trained on movie dialogues initially annotated using human computation and extended using self-labeling, and sentence similarity approaches. As future work, we intend to extend the taxonomy of empathetic response intents using new labels discovered during this process and utilize the OSED dataset to develop a controllable neural chatbot capable of generating empathetic responses during social chitchat.       
","     Recently, deep models have shown tremendous improvements in neural machine translation . However, systems of this kind are computationally expensive and memory intensive. In this paper, we take a natural step towards learning strong but light-weight NMT systems. We proposed a novel group-permutation based knowledge distillation approach to compressing the deep Transformer model into a shallow model. The experimental results on several benchmarks validate the effectiveness of our method. Our compressed model is $8\times$ shallower than the deep model, with almost no loss in BLEU. To further enhance the teacher model, we present a Skipping Sub-Layer method to randomly omit sub-layers to introduce perturbation into training, which achieves a BLEU score of 30.63 on English-German newstest2014. The code is publicly available at https://github.com/libeineu/GPKD.",463
"  {S}{emantic} role labeling , also known as shallow semantic parsing, conveys the meaning of a sentence by forming a predicate-argument structure for each predicate in a sentence, which is generally described as the answer to the question ""Who did what to whom, where and when?"". The relation between a specific predicate and its argument provides an extra layer of abstraction beyond syntactic dependencies  , such that the labels are insensitive to syntactic alternations and can also be applied to nominal predicates. Given a sentence in Figure , SRL pipeline framework consists of 4 subtasks, including predicate identification , predicate disambiguation , arguments identification  and arguments classification . SRL is a core task of natural language processing  having wide range of applications such as neural machine translation , information extraction , question answering , emotion recognition from text , document summarization  etc.   Semantic role labeling can be categorized into two categories, span and dependency. Both types of SRL are useful for formal semantic representations but dependency based SRL is better for the convenience and effectiveness of semantic machine learning. Johansson and Nugues  concluded that the best dependency based SRL system outperforms the best span based SRL system through gold syntactic structure transformation. The same conclusion was also verified by Li et al.  through a solid empirical verification. Furthermore, since 2008, dependency based SRL has been more studied as compared to span based SRL. With this motivation, we focus on dependency based SRL, which is mainly popularized by CoNLL-2008 and CoNLL-2009 shared tasks .   The traditional approaches to SRL focus on feature engineering which struggles in apprehending discriminative information  while neural networks are proficient enough to extract features automatically . Specifically, since large scale empirical verification of Punyakanok et al. , syntactic information has been proven to be extremely beneficial for SRL task. Later works  achieve satisfactory performance for SRL with syntax-agnostic models which creates conflict with the long-held belief that syntax is essential for high-performance SRL .  The study of Li et al.  shows that the empirical results from neural models on the less importance of syntax indicate a potential challenge and despite the satisfactory performance of syntax-agnostic SRL systems, the reasons behind the absence of syntax in these models are three-fold. First, the effective incorporation of syntax in neural SRL models is quite challenging as compared to traditional approaches. Second, neural SRL models may cover partial syntactic clues more or less. Third, syntax has always been a complicated formalism in linguistics and its not easy to encode syntax for later usage. %Despite the satisfactory performance of syntax-agnostic SRL models, the reasons behind the absence of syntax in these models are two-fold. First, the effective incorporation of syntax information in neural SRL models is quite challenging. Second, the unreliability of syntactic parsers on account of the risk of erroneous syntactic input may lead to error proliferation. This has been proven by Li et al.  through a strong empirical verification. They show that the effective method of syntax incorporation and the high quality of syntax can promote SRL performance.%       Our contributions in this work are two folds.  We propose a  method to compress the deep model into a shallower one with minor performance sacrifice, which outperforms the  method by a large margin.  The proposed Skipping Sub-Layer method reduces the overfitting problem when training extremely deep encoder systems by randomly omitting sub-layers during training phase. The experimental results on three widely-used benchmarks validate the effectiveness of the proposed methods. After the incorporating of two methods, the strong but light-weight student models show competitive performance which is application friendly.  
"," Semantic role labeling  aims at elaborating the meaning of a sentence by forming a predicate-argument structure. Recent researches depicted that the effective use of syntax can improve SRL performance. However, syntax is a complicated linguistic clue and is hard to be effectively applied in a downstream task like SRL. This work effectively encodes syntax using adaptive convolution which endows strong flexibility to existing convolutional networks. The existing CNNs may help in encoding a complicated structure like syntax for SRL, but it still has shortcomings. Contrary to traditional convolutional networks that use same filters for different inputs, adaptive convolution uses adaptively generated filters conditioned on syntactically-informed inputs. We achieve this with the integration of a filter generation network which generates the input specific filters. This helps the model to focus on important syntactic features present inside the input, thus enlarging the gap between syntax-aware and syntax-agnostic SRL systems. We further study a hashing technique to compress the size of the filter generation network for SRL in terms of trainable parameters. Experiments on CoNLL-2009 dataset confirm that the proposed model substantially outperforms most previous SRL systems for both English and Chinese languages.",464
"     Learning dialogue policies are typically formulated as a reinforcement learning  problem . However, dialogue policy learning via RL from scratch in real-world dialogue scenarios is expensive and time-consuming, because it requires real users to interact with and adjusts its policies online . A plausible strategy is to use user simulators as an inexpensive alternative for real users, which randomly sample a user goal from the user goal set for the dialogue agent training . In task-oriented dialogue settings, the entire conversation revolves around the sampled user goal implicitly. Nevertheless, the dialogue agent's objective is to help the user to accomplish this goal even though the agent knows nothing about this sampled user goal , as shown in Figure.        The randomly sampling-based user simulator neglects the fact that human learning supervision is often accompanied by a curriculum . For instance, when a human-teacher teaches students, the order of presented examples is not random but meaningful, from which students can benefit . Therefore, this randomly sampling-based user simulators bring two issues:     Most previous studies of dialogue policy have focused on the efficiency issue, such as reward shaping , companion learning , incorporate planning , etc. However, stability is a pre-requisite for the method to work well in real-world scenarios. It is because, no matter how effective an algorithm is, an unstable online leaned policy may be ineffective when applied in the real dialogue environment. This can lead to bad user experience and thus fail to attract sufficient real users to continuously improve the policy. As far as we know, little work has been reported about the stability of dialogue policy. Therefore, it is essential to address the stability issue.    In this paper,  we propose a novel policy learning framework that combines curriculum learning and deep reinforcement learning,  namely Automatic Curriculum Learning-based Deep Q-Network . As shown in Figure, this framework replaces the traditional random sampling method in the user simulator with a teacher policy model that arranges a meaningful ordered curriculum and dynamically adjusts it to help dialogue agent  for automatic curriculum learning. As a scheduling controller for student agents, the teacher policy model arranges students to learn different user goals in different learning stages without any requirement of prior knowledge. Sampling the user goals that match the ability of student agents regarding different difficulty of each user goal, can not only increases the feedback of the environment to the student agent but also makes the learning of the student agent more stable.  There are two criteria for evaluating the sampling order of each user goal: the learning progress of the student agent and the over-repetition penalty. The learning progress of the student agent emphasizes the efficiency of each user goal, encouraging the teacher policy model to choose the user goals that match the ability of the student agent to maximize the learning efficiency of the student agent. The over-repetition penalty emphasizes the sampled diversity, preventing the teacher policy model from cheating\footnote[1]{The teacher policy model repeatedly selects user goals that the student agent has mastered to obtain positive rewards.}. The incorporation of the learning progress of the student agent and the over-repetition penalty reflects both sampled efficiency and sampled diversity to improve efficiency as well as stability of ACL-DQN.   Additionally, the proposed ACL-DQN framework can equip with different curriculum schedules. Hence, in order to verify the generalization of the proposed framework, we propose three curriculum schedule standards for the framework for experimentation: i) Curriculum schedule A: there is no standard, only a single teacher model; ii) Curriculum schedule B: user goals are sampled from easiness to hardness in proportion; iii) Curriculum schedule C: ensure that the student agents have mastered simpler goals before learning more complex goals.   Experiments have demonstrated that the ACL-DQN significantly improves the dialogue policy through automatic curriculum learning and achieves better and more stable performance than DQN. Moreover, the ACL-DQN equipped with the curriculum schedules can be further improved. Among the three curriculum schedules we provided, the ACL-DQN under curriculum schedule C with the strength of supervision and controllability, can better follow up on the learning progress of students and performs best. In summary, our contributions are as follows:        This paper presents a neural framework for semantic role labeling, effectively incorporating a filter generation network to extract important syntactic features encoded by BiLSTM and Tree-LSTM by generating filters conditioned on inputs. The adaptive convolution endows flexibility to existing convolution operations. With the extraction of important syntax information, we are able to enlarge the gap between syntax aware and syntax agnostic SRL systems. We further study a hashing technique which drastically decreases the size of the filter generation network. Lastly, we explore the effects of syntax quality on SRL systems and conclude that the high quality syntax can improve SRL performance. Experiments on CoNLL-2009 dataset validate that our proposed model outperforms most previous SRL systems for both English and Chinese languages.  
"," Dialogue policy learning based on reinforcement learning is difficult to be applied to real users to train dialogue agents from scratch because of the high cost. User simulators, which choose random user goals for the dialogue agent to train on, have been considered as an affordable substitute for real users. However, this random sampling method ignores the law of human learning, making the learned dialogue policy inefficient and unstable. We propose a novel framework, Automatic Curriculum Learning-based Deep Q-Network , which replaces the traditional random sampling method with a teacher policy model to realize the dialogue policy for automatic curriculum learning. The teacher model arranges a meaningful ordered curriculum and automatically adjusts it by monitoring the learning progress of the dialogue agent and the over-repetition penalty without any requirement of prior knowledge. The learning progress of the dialogue agent reflects the relationship between the dialogue agent's ability and the sampled goals' difficulty for sample efficiency. The over-repetition penalty guarantees the sampled diversity. Experiments show that the ACL-DQN significantly improves the effectiveness and stability of dialogue tasks with a statistically significant margin. Furthermore, the framework can be further improved by equipping with different curriculum schedules, which demonstrates that the framework has strong generalizability.",465
" Exponential growths of micro-blogging sites and social media not only provide platforms for empowering freedom of expressions and individual voices, but also enables people to express anti-social behavior such as online harassment, cyberbullying, rumors, and spreading hatred statements. %In recent years, micro-blogging sites and social media sites have grown exponentially, enabling the users to express anti-social behavior, false political or religious rumor, and spreading hatred activities. Besides, abusive or threatening speech that expresses prejudice against a certain group, which religious, political, geopolitical, personal, and gender abuse are very common and on the basis of race, religion, and sexual orientation are getting pervasive. United Nations Strategy and Plan of Action on Hate Speech defines hate speech as ``any kind of communication in speech, writing or behaviour, that attacks or uses pejorative or discriminatory language with reference to a person or a group on the basis of who they are, in other words, based on their religion, ethnicity, nationality, race, colour, descent, gender or other identity factor''.  Bengali is spoken by 230 million people in Bangladesh and India, making it one of the major languages in the world. Although, a rich language with a lot of diversity, Bengali is severely low-resourced for natural language processing~, which is due to the scarcity of computational resources such as language models, labeled datasets, and efficient machine learning~ methods required for different NLP tasks. Similar to other major languages like English, the use of hate speech in Bengali is also getting rampant. This is mainly due to unrestricted access and use of social media and digitalization. Some examples of Bengali hate speech and their respective English translations are shown in \cref{cdec_wf3} that are either directed towards a specific person or entity or generalized towards a group. These examples signify how severe Bengali hateful statements could be. Nevertheless, there is a potential chance that these could lead to serious consequences such as hate crimes, regardless of languages, geographic locations, or ethnicity.    Automatic identification of hate speech and creating awareness among people is very challenging. However, manual reviewing and verification from a vast amount of online content is not only labor-intensive but also time-consuming. Nevertheless, accurate identification requires automated, robust, and efficient machine learning~ methods. Compared to traditional ML and neural network~-based approaches, state-of-the-art~ language models are becoming increasingly effective. On a serious drawback: a prediction made by many models can neither be traced back to the input, nor it is clear why the output is transformed in a certain way. This makes even the most efficient DNN models `black-box' methods. On the other hand, the General Data Protection Regulation~ by the European Parliament enforces the `right to explanation', which prohibits the use of ML for automated decisions unless a clear explanation of the logic used to make each decision is well explained. Therefore, how a prediction is made by an algorithm should be as transparent as possible in order to gain human trust.    %Recent research efforts from both the NLP and ML communities have proven to be very useful for well-resourced languages like English. %Nevertheless, accurate identification requires automated, robust, and efficient machine learning~ methods. As state-of-the-art language models becoming increasingly effective, their decisions should be made as transparent as possible in order to improve human trust. %Some of these techniques are based on the model閳ユ獨 local gradient information while other methods seek to redistribute the function閳ユ獨 value on the input variables, typically by reverse propagation in the neural network graph. Bach et al. proposed specific propagation rules for neural networks . These rules were shown to produce better explanations than e.g. gradient-based techniques not only for computer vision but also text data. To overcome the shortcomings of `black-box'-based methods and inspired by the outstanding success of transformer language models~, we propose an explainable approach for hate speech detection from under-resourced Bengali language. Our approach is based on the ensemble of several BERT variants, including monolingual Bangla BERT-base, m-BERT~, and XLM-RoBERTa. Further, we not only provide both global and local explanations of the predictions, in a post-hoc fashion but also provide the measure of explanations in terms of faithfulness.  The rest of the paper is structured as follows: \Cref{rw} reviews related work on hate speech and Bengali word embedding. \Cref{section:3} describes the data collection and annotation process. \Cref{nettwork} describes the process of Bengali neural embedding, network construction, and training. \Cref{er} illustrates experiment results, including a comparative analysis with baseline models on all datasets. \Cref{con} summarizes this research with potential limitations and points some possible outlook before concluding the paper.    This paper formally introduces the task of universal representation learning and then presents a pre-trained language model for such a purpose to map different granular linguistic units into the same vector space where similar sequences have similar representations and enable unified vector operations among different language hierarchies.   In detail, we focus on the less concentrated language representation, seeking to learn a uniform vector form across different linguistic unit hierarchies. Far apart from learning either word only or sentence only representation, our method extends BERT's masking and training objective to a more general level, which leverage information from sequences of different lengths in a comprehensive way and effectively learns a universal representation from words, phrases to sentences.   Overall, our proposed BURT outperforms its baselines on a wide range of downstream tasks with regard to sequences of different lengths in both English and Chinese languages. We especially provide an universal analogy task, an insurance FAQ dataset and an NLG dataset for extensive evaluation, where our well-trained universal representation model holds the promise for demonstrating accurate vector arithmetic with regard to words, phrases and sentences and in real-world retrieval applications.       use section* for acknowledgment   \ifCLASSOPTIONcompsoc       The Computer Society usually uses the plural form     
","   The exponential growths of social media and micro-blogging sites not only provide platforms for empowering freedom of expressions and individual voices, but also enables people to express anti-social behavior like online harassment, cyberbullying, and hate speech. Numerous works have been proposed to utilize the textual data for social and anti-social behavior analysis, by predicting the contexts mostly for highly-resourced languages like English. However, some languages are under-resourced, e.g., South Asian languages like Bengali, that lack  computational resources for accurate natural language processing~. In this paper, we propose an explainable approach for hate speech detection from the under-resourced Bengali language, which we called \texttt{DeepHateExplainer}. In our approach, Bengali texts are first comprehensively preprocessed, before classifying them into political, personal, geopolitical, and religious hates, by employing the neural ensemble method of different transformer-based neural architectures~. Subsequently, important~ terms are identified with sensitivity analysis and layer-wise relevance propagation~, before providing human-interpretable explanations. Finally, to measure the quality of the explanation~, we compute the comprehensiveness and sufficiency. Evaluations against machine learning~ and deep neural networks~ baselines yield F1 scores of 84\%, 90\%, 88\%, and 88\%, for political, personal, geopolitical, and religious hates, respectively, outperforming both ML and DNN baselines.%, during 3-fold cross-validation tests.",466
" Many seemingly convincing rumors such as ``Most humans only use 10 percent of their brain'' are widely spread, but ordinary people are not able to rigorously verify them by searching for scientific literature. In fact, it is not a trivial task to verify a scientific claim by providing supporting or refuting evidence rationales, even for domain experts.  %Such The situation worsens as misinformation is proliferated  %by the  on social media or news websites, manually or programmatically, at every moment. As a result, an automatic fact-verification tool becomes more and more crucial for combating  %against  the spread of misinformation.  %There are many existing datasets and %the corresponding  %systems for fact-verification tasks %, emphasizing on  %in various domains, such as Wikipedia , social media , and politics . These tasks  %are  The existing fact-verification tasks usually consist of three sub-tasks: document retrieval, rationale sentence extraction, and fact-verification. However, due to the nature of scientific literature that requires domain knowledge, it is challenging to collect a large scale scientific fact-verification dataset, and further, to perform fact-verification under a low-resource setting with limited training data. \citet{Wadden2020FactOF} collected a scientific claim-verification dataset, SciFact, and proposed a scientific claim-verification task: given a scientific claim, find evidence sentences that support or refute  %such the claim  %from  in a corpus of scientific paper abstracts. \citet{Wadden2020FactOF} also proposed a simple, pipeline-based, sentence-level model, VeriSci, as a baseline solution based on \citet{deyoung2019eraser}.  %Despite the simplicity of VeriSci ,  VeriSci is a pipeline model that runs modules for abstract retrieval, rationale sentence selection, and stance prediction sequentially, and thus the error generated from  %the an upstream module may propagate to the downstream modules. To overcome this drawback, we hypothesize that a module jointly optimized on multiple sub-tasks may mitigate the error-propagation problem to improve the overall performance.  %On the other hand,  In addition, we observe that a complete set of rationale sentences usually contains multiple inter-related sentences from the same paragraph. Therefore, we propose a novel, paragraph-level, multi-task learning model for the SciFact task.  In this work, we employ compact paragraph encoding, a novel strategy of computing sentence representations using BERT-family models. We directly feed an entire paragraph as a single sequence to BERT, so that the encoded sentence representations are already contextualized on the neighbor sentences by taking advantage of the attention mechanisms in BERT. In addition, we jointly train the modules for rationale selection and stance prediction as multi-task learning  by leveraging the confidence score of rationale selection as the attention weight of the stance prediction module. Furthermore, we compare two methods of transfer learning that mitigate the low-resource issue: pre-training and domain adaptation . Our experiments show that: % the compact paragraph encoding method is beneficial over separately computing sentence embeddings, and  with negative sampling, the joint training of rationale selection and stance prediction is beneficial over the pipeline solution. %\todo{you may want to create a list of contribution. -Violet}      We present a novel sentence representation learning method Conditional Masked Language Modeling  for training on large scale unlabeled corpus. CMLM outperforms the previous state-of-the-art English sentence embeddings models, including those trained with supervised signals. For multilingual representations learning, we discover that co-training CMLM with bitext retrieval and cross-lingual NLI finetuning achieves state-of-the-art performance. We also discover that multilingual representations have the same language bias and principal component removal  can eliminate the bias by separating language identity information from semantics.  
"," Even for domain experts, it is a non-trivial task to verify a scientific claim by providing supporting or refuting evidence rationales. The situation worsens as misinformation is proliferated on social media or news websites, manually or programmatically, at every moment. As a result, an automatic fact-verification tool becomes crucial for combating the spread of misinformation. %\citet{Wadden2020FactOF} collected a scientific claim-verification dataset, SciFact, to facilitate research on scientific claim-verification.  In this work, we propose a novel, paragraph-level, multi-task learning model for the SciFact task by directly computing a sequence of contextualized sentence embeddings from a BERT model and jointly training the model on rationale selection and stance prediction.",467
" Self attention networks  have been widely studied on many natural language processing  tasks, such as machine translation , language modeling  and natural language inference . It is well accepted that SANs can leverage both the local and long-term dependencies through the attention mechanism, and are highly parallelizable thanks to their position-independent modeling method.  However, such position-independent models are incapable of explicitly capturing the boundaries between sequences of words, thus overlook the structure information that has been proven to be robust inductive biases for modeling texts . Unlike RNNs that model sequential structure information of words by using memory cells, or CNNs that focus on learning local structure dependency of words via convolution kernels, SANs learn flexible structural information in an indirect way almost from scratch. One way to integrate structural information into SAN models is via pre-training, such as BERT , which learns to represent sentences by using unsupervised learning tasks on the large-scale corpus. Recent studies  have shown the ability of pre-training models on capturing structure information of sentences.  Another method to deal with structural information is introducing structure priors into SANs by mask strategies. \citeauthor{shen2018disan} \shortcite{shen2018disan} proposed the directional self-attention mechanism, which employs two SANs with the forward and backward masks respectively to encode temporal order information. \citeauthor{guo2019gaussian} \shortcite{guo2019gaussian} introduced the Gaussian prior to the transformers for capturing local compositionality of words. Admittedly, structure priors can strengthen the model's capability of modeling sentences and meanwhile assist in capturing proper dependencies. With the help of these learned structure priors, SANs can model sentences accurately even in resource-constrained conditions.    Though these models get success on many NLP tasks, these studies commonly focus on integrating one single type of structure priors into SANs, thus fail at making full use of multi-head attentions. One straightforward advantage of using the multi-head attentions lies in the fact that different heads convey different views of texts . In other words, multi-head attentions enable the model to capture the information of texts at multiple aspects, which in return brings thorough views when modeling the texts.  Besides, it is well accepted that one type of structural prior can only reveal part of the structural information from one single perspective. A variety of types of structural priors are needed in order to gain complete structural information of texts. This can be achieved by introducing different structural priors into different parts of attention heads, where different structural priors can complement each other, guiding the SAN models to learn proper dependencies between words. Therefore, to gain a better representation of the texts, a desirable solution should make full use of the multi-head attention mechanism and utilize multiple types of structural priors.  To better alleviate the aforementioned problems, in this paper, we propose a lightweight self attention network, i.e., the Multiple Structural Priors Guided Self Attention Network . The novel idea behind our model lies in the usage of the multi-mask based multi-head attention , which helps our model to better capture different types of dependencies between texts. Thanks to the MM-MH Attention mechanism, our model can capture multiple structural priors, which in return brings benefits in modeling sentences.  Especially, the structural priors we employed come from two categories: the sequential order and the relative position of words. Since the standard SANs are incapable of distinguishing the order between words, we apply the direction mask  directly to each attention head. Motivated by the Bidirectional RNNs , we split the attention heads into two parts. For a given word, we apply the forward mask to the first half of attention heads, which allows it to attend on only the previous words when modeling the reference word. Accordingly, the backward mask is applied to the rest of the attention heads.  Since the direction masks take no consideration of the difference between long-distance words and nearby words, we employ the second category of structural prior as a complement, which could be measured by the distance between pair of words. We integrate two types of distance masks into different attention heads. The first one we utilized is the word distance mask, which describes the physical distance between each pair of words. Besides, for the purpose of capturing the latent hierarchical structure of sentences, we integrate another kind of distance information, i.e., dependency distance that is defined as the distance between each pair of words on a dependency syntax tree. The word distance mask helps our model to focus on the local words and the dependency distance mask enables our model to capture the hierarchical relationships between words. Consequently, they provide our model the ability of capturing the local and non-local dependency of words properly.  To illustrate the effectiveness of our model, we conduct experiments on two NLP tasks: natural language inference and sentiment classification. Experimental results show that MS-SAN outperforms other baselines and achieves a competitive performance comparing with the state-of-the-art models.   Our contributions are listed as follows:     In this work, we propose a novel paragraph-level multi-task learning model for  task. Experiments show that  The compact paragraph encoding method is beneficial over separately computing sentence embeddings.  With negative sampling, the joint training of rationale selection and stance prediction is beneficial over the pipeline solution.  
"," Self attention networks  have been widely utilized in recent NLP studies. Unlike CNNs or RNNs, standard SANs are usually position-independent, and thus are incapable of capturing the structural priors between sequences of words. Existing studies commonly apply one single mask strategy on SANs for incorporating structural priors while failing at modeling more abundant structural information of texts. In this paper, we aim at introducing multiple types of structural priors into SAN models, proposing the Multiple Structural Priors Guided Self Attention Network  that transforms different structural priors into different attention heads by using a novel multi-mask based multi-head attention mechanism. In particular, we integrate two categories of structural priors, including the sequential order and the relative position of words. For the purpose of capturing the latent hierarchical structure of the texts, we extract these information not only from the word contexts but also from the dependency syntax trees. Experimental results on two tasks show that MS-SAN achieves significant improvements against other strong baselines.",468
" Sequence-to-Sequence  learning~ has advanced the state of the art in various natural language processing  tasks, such as machine translation~, text summarization~, and grammatical error correction~. Seq2Seq models are generally implemented with an encoder-decoder framework, in which a multi-layer encoder summarizes a source sequence into a sequence of representation and another multi-layer decoder produces the target sequence conditioned on the encoded representation.   Recent studies reveal that fusing the intermediate encoder layers  is beneficial for Seq2Seq models, such as layer attention~, layer aggregation~, and layer-wise coordination~. Despite its effectiveness, not much is known about how fusing encoder layer representations work. The intuitive explanation is that fusing encoder layers exploits surface and syntactic information embedded in the lower encoder layers~.  However, other studies show that attending to lower encoder layers  does not improve model performance~, which is conflicted with existing conclusions. It is still unclear why and when fusing encoder layers should work in Seq2Seq models.  This paper tries to shed light upon behavior of Seq2Seq models augmented with EncoderFusion method. To this end, we propose a novel fine-grained layer attention to evaluate the contribution of individual encoder layers. We conduct experiments on several representative Seq2Seq NLP tasks, including machine translation, text summarization, and grammatical error correction. Through a series of analyses, we find that the uppermost decoder layer pays more attention to the encoder embedding layer. Masking the encoder embedding layer significantly drops model performance by generating hallucinatory  predictions. The encoded representation of the standard Seq2Seq models  may not have enough capacity to model both semantic and surface features . We call the problem described above the source representation bottleneck.  Based on this observation, we simplify the EncoderFusion approaches by only connecting the encoder embedding layer to softmax layer . The SurfaceFusion approach shortens the path distance between source and target embeddings, which can help to learn better bilingual embeddings with direct interactions. Experimental results on several Seq2Seq NLP tasks show that our method consistently outperforms both the vanilla Seq2Seq model and the layer attention model.  Extensive analyses reveal that our approach produces more aligned bilingual word embeddings by shortening the path distance between them, which confirm our claim.  Our main contributions are as follows:      In this work, we propose a novel hierarchical curriculum learning framework for training response selection models for multi-turn conversations. During training, the proposed framework simultaneously employs the corpus-level and instance-level curriculum to dynamically select suitable training data based on the state of learning process. Extensive experiments and analysis on two benchmark datasets show that our approach can significantly improve the performance of various strong matching models.   To test our approach, we conduct extensive experiments and analysis using three representative matching models. The results on two benchmark datasets demonstrate the effectiveness of the proposed approach.   Experimental results on two benchmark datasets using three representative matching models verify the effectiveness of the proposed approach.   
"," Encoder layer fusion  is a technique to fuse all the encoder layers  for sequence-to-sequence  models, which has proven effective on various NLP tasks. However, it is still not entirely clear why and when EncoderFusion should work. In this paper, our main contribution is to take a step further in understanding EncoderFusion. Many of previous studies believe that the success of EncoderFusion comes from exploiting surface and syntactic information embedded in lower encoder layers. Unlike them, we find that the encoder embedding layer is more important than other intermediate encoder layers.  In addition, the uppermost decoder layer consistently pays more attention to the encoder embedding layer across NLP tasks. Based on this observation, we propose a simple fusion method, SurfaceFusion, by fusing only the encoder embedding layer for the softmax layer. Experimental results show that SurfaceFusion outperforms EncoderFusion on several NLP benchmarks, including machine translation, text summarization, and grammatical error correction.   It obtains the state-of-the-art performance on WMT16 Romanian-English and WMT14 English-French translation tasks. Extensive analyses reveal that SurfaceFusion learns more expressive bilingual word embeddings by building a closer relationship between relevant source and target embeddings. Source code is freely available at \url{https://github.com/SunbowLiu/SurfaceFusion}.  \iffalse To model the inter-dependence of two sequences, sequence-to-sequence  learning extracts the source surface and abstract features through its encoder output representations. However, an overloaded use of the encoder output representations might lead to an insufficient representation capacity, which we call it source representation bottleneck. Recent studies have found that widening the bottleneck by fusing the surface features from lower level representations can boost the performance of Seq2Seq, but none of them explain the intrinsic mechanism of this benefit. In this paper, we take the first step to probe into the essence of the bottleneck on three typical Seq2Seq tasks, i.e.~machine translation, text summarization, and grammatical error correction. We observe that the representation learning of higher decoder layer suffers from the bottleneck, and thus propose a simple yet effective surface fusion method to mitigate the issue. The results over a variety of benchmarks confirm the effectiveness of the proposed method. Source code will be released. \fi",469
"   Indonesian colloquialism is everyday and everywhere, e.g. in social media posts and conversational transcripts. Yet, existing research on Indonesian NLP models including NMTs often disregards qualitative analysis when the models are given strictly colloquial inputs. This is mainly due to the fact that the data readily available for training and testing the models are in formal Indonesian. %This follow naturally due to the fact that the models are style-agnostic, that is,   Colloquial Indonesian has several different word choices from formal language due to the diversity of regional languages and dialects. We define the spoken colloquial as a clean colloquial. In addition, in written media,  colloquial Indonesian is often abbreviated, disemvoweled, or written with voice alteration, which we define as the noisy colloquial .               \end{table}   To better evaluate English-Indonesian MT systems against colloquial text, we first create 2 new test-sets of Indonesian-English colloquial pairs. The first test is a clean colloquial taken from a YouTube transcript. The second test-set is a noisy colloquial from Twitter annotated by our team of annotators. We found that NMT systems trained on formal dataset did not perform very well on these test-sets.  Next, we develop synthetic colloquial text data by performing word-level translation of several words in the formal text into a colloquial form based on a word-to-word dictionary. By combining the formal dataset and the synthesized colloquial dataset, we increase the NMT performance on the colloquial test-set by 2.5 BLEU points.      The word segmentation is an essential and non-trivial task in Sindhi language. The white spaces between words are a good sign for predicting word boundaries, but the existence of space-omission and space-insertion bring ambiguity in the segmentation process. We proposed the SGNWS model, keeping in view the challenges related to SWS, respectively. The proposed model has the ability to learn and extract subword features automatically by eliminating the constraints such as hand-craft features for segmentation or any other type of prior domain-specific knowledge.    in this paper, we propose a deep BiLSTM-CRF based framework with subword representation learning. The novel character-level  For that task, we construct five benchmark datasets and empirically analyze proposed SGNWS and the chosen baselines approaches. The proposed model also surpases existing Sindhi word segmenters by achieving high F-Score of 98.13\ , 97.62\  on developed benchmark datasets Awami-Awaz, 96.26\  on Wiki-dumps, 97.37\  on twitter, 97.93\  on books corpus, and best F-Score of 98.51\  on the SGSEG dataset. The performance of Wiki-dumps is comparatively lesser due to the existence of noise in the text.    In this paper, we empirically demonstrate that our proposed model yields the best performance in SWS because of its high efficiency and robustness for sequential modeling tasks with great ability to capture the word information at the morphemic level for the prediction of word boundaries. The SGNWS model is an effective and elegant neural solution for SWS, which can also be applied to other sequence tagging problems.    
","  Neural machine translation  is typically domain-dependent and style-dependent, and it requires lots of training data. State-of-the-art NMT models often fall short in handling colloquial variations of its source language and the lack of parallel data in this regard is a challenging hurdle in systematically improving the existing models. In this work, we develop a novel colloquial Indonesian-English test-set collected from YouTube transcript and Twitter. We perform synthetic style augmentation to the source formal Indonesian language and show that it improves the baseline Id-En models  over the new test data. %Our experimental data and code are available on github.com.",470
"  Large-scale language models have greatly advanced NLP research in various sub-areas, such as question answering, text summarization, story generation and so on . However, these generation models still suffer from at least three major problems when applied to the dialogue system building, 1) generic and repeated responses ,   2) inconsistent statements with the dialogue context , and 3) uncontrollable task-oblivious replies  .  Many previous studies have attempted to address these problems . For instance, \citet{li2019inconsisent} penalized repetitive and inconsistent behaviors with unlikelihood loss in open-domain chats. \citet{song2020generate} detected and rewrote the contradicting responses to achieve a more consistent personality.  However, these methods optimize the language model by minimizing the loss in supervised learning, which may lead to exposure bias and uninterpretable behaviors, and consequently,  makes it harder for humans to regulate the model.   To alleviate these problems, previous work has explored RL-based methods in dialogue system building . %For instance,  integrated the goal of coherent into the reward design  and made the first step towards .designed for better generation.   However, such methods not only rely on hand-crafted user simulators that are inherently hard to build , but also require meaningful rewards that are difficult to design. To address these issues, we propose to teach the model to extract a policy directly from the data and learn from its own mistakes without the use of simulators. Leveraging decoding methods such as Nucleus Sampling , the language model finetuned on a persuasion task is able to generate lexically diverse response candidates given the same context. %One example is shown in Figure.  Some candidates are appropriate, while others are repetitive or inconsistent with the context. These good and bad examples are used as positive and negative feedback to the model through meaningful rewards in RL, and help refine the language model. During testing, to fully utilize the refined language model, we use it to generate multiple candidates again,  and filter out the repetition and inconsistency afterwards. Beyond being nonrepetitive and consistent, a good response also needs to accomplish the dialogue task, in our case, to persuade people. Therefore, we ask humans to demonstrate the persuasion process, and build a response imitator to imitate these human demonstrations and select the most persuasive response.  The above issues in language models are especially salient in complex strategic dialogue tasks such as persuasion and negotiation. These dialogues involve both a specific task goal and social contents to build rapport for better task completion, and therefore, have richer and more complicated language structures . Furthermore, due to their inherent similarity to task-oriented and open-domain dialogues, improvements made on these systems would also help in both dialogue settings. Therefore, we choose a strategic donation persuasion task  to perform our study, and conduct both automatic and human evaluations to evaluate our models.     This work  makes multiple contributions. First, we propose DialGAIL, an RL-based generative algorithm to refine MLE-based language models for dialogue  generation without the use of user simulators.  Second, we design an effective and practicable framework for strategic dialogue systems that achieves state-of-the-art performance on a complex persuasion task, with only small amount of human demonstration efforts.  %Such system achieves more diverse, consistent and fluent conversations with better persuasion outcomes on a complex persuasion task compared to the MLE-based baselines.   %a framework to automatically detect repetitive and inconsistent responses, and imitate human demonstration to select persuasive responses.  %Furthermore, experiments show that our model produces more diverse, consistent and fluent conversations with better persuasion outcomes on a complex persuasion task compared to the MLE-based baselines.  Previous dialogue research has mostly focused on pure task-oriented dialogues and pure social conversations; but looking forward, it becomes more and more important to pay attention to strategic dialogues that involves both task and social components. We sincerely hope this work could inspire more research and discussions on strategic dialogues in the community.   % how to refine the dialogue generation with limited amount of data? MLE fine-tuning woldn't work with the limited data % social content + a specific end-goal --> persuasionforgood. advance research in this area % how to easily get a usable lm without computational resources? % explore the possibility to apply GAIL in dialogue generation in a simple way  % the first to explore GAIL % raise more attention in persuasion in the community % with small amount of human demo % task-independent in repetition detection strengthen       Despite the broad applications of the transformer model, it struggles to perform well for some NLP tasks when the training data is limited. In this work, we propose a theoretically justified optimization strategy to train deeper transformer model with improved generalization and faster convergence speed on small datasets, which is generally applicable to different NLP tasks and neural architectures. The proposed strategy is applied on Text-to-SQL semantic parsing, an important structural prediction task and achieve state of the art by successfully training significantly deeper relational transformer models. Further analyses show that increasing the depth of the transformer model trained with limited data can be helpful for the generalization on complicated structural prediction tasks, instead of harmful as previously assumed. Such observations indicate that the current understanding of the transformer architecture is still incomplete and shed light on the directions of future research.     
"," Despite the recent success of large-scale language models on various downstream NLP tasks, the repetition and inconsistency problems still persist in dialogue response generation. Previous approaches have attempted to avoid repetition by penalizing the language model's undesirable behaviors in the loss function. However, these methods focus on token-level information and can lead to incoherent responses and uninterpretable behaviors. To alleviate these issues, we propose to apply reinforcement learning to refine an MLE-based language model without user simulators, and distill sentence-level information about repetition, inconsistency and task relevance through rewards. In addition, to better accomplish the dialogue task, the model learns from human demonstration to imitate intellectual activities such as persuasion, and selects the most persuasive responses. Experiments show that our model outperforms previous state-of-the-art dialogue models on both automatic metrics and human evaluation results on a donation persuasion task, and generates more diverse, consistent and persuasive conversations according to the user feedback.% We will release the code and data upon acceptance.",471
"   Large-scale pre-training has draw much attention in both the community of Compute Vision  and Natural Language Processing  due to its strong capability of generalization and efficient usage of large-scale data. Firstly in CV, a series of models were designed and pre-trained on the large-scale dataset ImageNet, such as AlexNet , VGG  and ResNet , which effectively improved the capability of image recognition for numerous tasks. Recent years have witnessed the burst of pre-training in NLP, such as BERT , RoBERTa , XLNet  and BART , which greatly improve the capability of language understanding and generation. However, the above researches towards the single-modal learning and can only be used in single-modal  scenarios. %which greatly restricts their ability to process multi-modal  information. In order to adapt to multi-modal scenarios, a series of multi-modal pre-training methods were proposed and pre-trained on the corpus of image-text pairs, such as ViLBERT , VisualBERT  and UNITER , which greatly improve the ability to process multi-modal information. However, these models can only utilize the limited corpus of image-text pairs and cannot be effectively adapted to single-modal scenarios . %Moreover, the size of the corpus of image-text pairs is very limited, and large scale of single-modal data can't be effectively utilized.     A smarter AI system should be able to process different modalities of information effectively. There are large scale of data in different modalities on the Web, mainly textual and visual information. The textual knowledge and the visual knowledge usually can enhance and complement with each other. As the example shown in Figure , it's difficult to answer the question correctly only with the visual information in the image.  However, if we connect the visual information to the textual information which describes the background of a baseball game, it's very easy to determine the correct answer. Also, the visual information can make it easier to understand the scene described by the text. The research in neuroscience by \citet{van2018neuronal} reveals that the parts of the human brain responsible for vision can learn to process other kinds of information, including touch and sound. Inspired by the research, we propose to design a unified-modal architecture UNIMO which can process multi-scene and multi-modal data input, including textual, visual and vision-and-language data, as shown in Figure .  The greatest challenge to unify different modalities is to align and unify them into the same semantic space which are generalizable to different modalities of data. Existed cross-modal pre-training methods try to learn cross-modal representations based on only limited image-text pairs by simple image-text matching and masked language modeling . They can only learn specific representations for image-text pairs, which are not generalizable for single-modal scenarios. So their performance will drop dramatically when applied to language tasks . In this work, UNIMO learns visual representations and textual representations in similar ways, and unify them into the same semantic space via cross-modal contrastive learning  based on a large-scale corpus of image collections, text corpus and image-text pairs.  %Our unified-modal architecture can utilize large scale of image collections and text corpus, and align the visual and textual information into the same semantic space via cross-modal contrastive learning on image-text pairs. %Effectively utilizing large-scale of images and text corpus can improve the capability of vision and textual understanding respectively. UNIMO effectively utilizes the large-scale of text corpus and image collections to learn general textual and visual representations.  The CMCL aligns the visual representation and textual representation, and unifies them into the same semantic space based on image-text pairs. To facilitate different levels of semantic alignment between vision and language, we propose to utilize a series of text rewriting techniques to improve the diversity of cross-modal information. As shown in Figure , we utilize back-translation to generate several positive examples for an image-text pair. Also, to enhance the detail semantic alignment between text and image, we further parse the caption to scene graph  and randomly replace either the objects, attributes or relations in the caption to generate various negative samples. Sentence-level retrieval and replacement is also utilized to enhance the sentence-level alignment. In this way, our model can effectively unify different levels of visual and textual representations into the same semantic space.  The unified-modal architecture mainly has the following advantages compared with previous methods:        The problems with repetition and inconsistency still persist in dialogue response generation.  Large-scale language models still suffer from repetition and inconsistency problems when applied to dialogue response generations.   Current large-scale language models still suffer from repetition and inconsistency when applied to dialogue response generation.  Current dialogue systems suffer from repetition and inconsistency.    The repetition and inconsistency problems still persist in dialogue response generation with large-scale language models.  Large-scale language models still suffer from repetition and inconsistency when applied to dialogue generation. To address the exposure bias issue in MLE, we propose DialGAIL to  refine the MLE-based language model and extract a policy directly from the data without user simulators by learning from its own mistakes.   by penalizing its own mistakes.  With the same context, the model  generates multiple response candidates, some of which are repetitive and inconsistent. These negative examples send feedback to the model via a reward function to reduce repetition and inconsistency.  Furthermore, we provide human demonstration for the model to imitate human persuasion activity and select the most persuasive candidate. Experiments show that our model achieves state-of-the-art performance in a complex persuasion task, and produces more diverse, consistent, and persuasive conversations with small amount of human efforts. Looking into the future, strategic dialogues with both task and social contents will become more and more important, and it is our sincere hope that this work could inspire more research and discussion in strategic dialogue tasks in the community.  besides being nonrepetitive and inconsistent, a good response also contributes to task success. To achieve this, we provide human demonstration for the model to imitate human persuasion activities. Our experiments show that our model performs better than the baselines on both automatic metrics and human evaluations, and produces more diverse and persuasive conversations.                                                                                    \clearpage   
","  Existed pre-training methods either focus on single-modal tasks or multi-modal tasks, and cannot effectively adapt to each other. They can only utilize single-modal data  or limited multi-modal data . In this work, we propose a unified-modal pre-training architecture, namely UNIMO, which can effectively adapt to both single-modal and multi-modal understanding and generation tasks. Large scale of free text corpus and image collections can be utilized to improve the capability of visual and textual understanding, and cross-modal contrastive learning  is leveraged to align the textual and visual information into a unified semantic space over a corpus of image-text pairs. As the non-paired single-modal data is very rich, our model can utilize much larger scale of data to learn more generalizable representations. Moreover, the textual knowledge and visual knowledge can enhance each other in the unified semantic space. The experimental results show that UNIMO significantly improves the performance of several single-modal and multi-modal downstream tasks.",472
" Although there are over 7,000 languages spoken worldwide~, only several dozen have enough data available to support supervised speech recognition, and many languages do not even employ a writing system~. In contrast, most people learn to use spoken language long before they learn to read and write, suggesting that linguistic annotation is not a prerequisite for speech processing systems. This line of reasoning motivates research that aims to discover meaningful linguistic abstractions  directly from the speech signal, with the intention that they could reduce the reliance of spoken language systems on text transcripts.  A rich body of work has recently emerged investigating representation learning for speech using visual grounding objectives~, as well as how word-like and subword-like linguistic units can be made to emerge within these models~. So far, these efforts have predominantly focused on inference, where the goal is to learn a mapping from speech waveforms to a semantic embedding space. Generation of speech conditioned on a point in a semantic space has been less explored, and is what we focus on in this work. We hypothesize that generative approaches offer interesting advantages over relying solely on inference. For example, prior works have demonstrated the capability of recognizing visually descriptive words, but have not been shown to learn non-visual words or grammar. Our experiments show that these aspects of spoken language are learned to some degree by a visually-grounded generative model of speech.  Specifically, we introduce a model capable of directly generating fluent spoken audio captions of images without the need for natural language text, either as an intermediate representation or a form of supervision during training . Tremendous progress has been made recently in natural language image caption generation~ and naturalistic text-to-speech synthesis ~.  Combining these models provides a means for generating spoken image descriptions, but existing approaches for training these models are reliant on text during training. Instead, we leverage sub-word speech units discovered using a self-supervised learning objective as a drop-in replacement for the text. We hypothesize that by using such techniques, an even wider variety of traditionally text-based NLP models could be applied to speech data without the need for transcription or automatic speech recognition  systems. Because all human languages utilize small, discrete phonetic inventories~, we posit that our framework should be applicable for any language in the world. In our experiments, we demonstrate that not just any set of discovered speech units can function in this role. We find the greatest success with units that are discrete, exhibit a low frame-rate, and highly robust to speaker and environmental variability. The main contributions of our paper are as follows:  1. The first methodology for fluent image-to-speech synthesis that does not rely on text. A critical aspect of our approach is factorizing the model into an Image-to-Unit  module and a Unit-to-Speech  module, where the speech units are discovered in a self-supervised fashion. This approach enables disentanglement of linguistic variability and acoustic/speaker variability.  2. Extensive analysis on the properties required for learned units to replace text. While the idea may seem simple and straightforward, obtaining proper units is not a trivial task. In fact, most of the units experimented in this paper fail to serve as drop-in replacements. Moreover, we demonstrate that what are deemed good units vary significantly for inference and generation.  3. Demonstrating insufficiency of beam search-based evaluation. We show that even when an I2U model fails to generate sensible caption through beam search decoding, it can still produce reasonable captions by sampling from the posterior, hinting that posterior mode-based evaluation can only inspect limited aspects of a model.  4. Proposing a semantic diversity-aware metric. We identify issues of an existing metric~ and propose M-SPICE for sampling-based evaluation to address the problems.  5. Over 600,000 spoken audio captions for the MSCOCO dataset. We collect 742 hours of speech from 2,352 people tasked with reading each caption out loud. This dataset will be made publicly available to support work at the intersection of speech, language, and vision.      In this work, we propose a unified-modal pre-training architecture UNIMO, which can leverage large-scale of non-paired text corpus and image collections for cross-modal learning. Our model can effectively adapt to both single-modal and multi-modal understanding and generation tasks. Based on the unified-modal architecture, the textual knowledge and visual knowledge can enhance each other in the unified semantic space. Our UNIMO model outperforms previous methods on both the multi-modal and single-modal downstream tasks. In the future, we will utilize larger scale of image collections and text corpus for unified-modal learning, and extend UNIMO to other modalities of data such as video, audio and so on.    
"," In this paper we present the first model for directly synthesizing fluent, natural-sounding spoken audio captions for images that does not require natural language text as an intermediate representation or source of supervision. Instead, we connect the image captioning module and the speech synthesis module with a set of discrete, sub-word speech units that are discovered with a self-supervised visual grounding task. We conduct experiments on the Flickr8k spoken caption dataset in addition to a novel corpus of spoken audio captions collected for the popular MSCOCO dataset, demonstrating that our generated captions also capture diverse visual semantics of the images they describe. We investigate several different intermediate speech representations, and empirically find that the representation must satisfy several important properties to serve as drop-in replacements for text.",473
"   Knowledge distillation is a technique to train smaller, more efficient student models by learning from larger teacher models, usually by mimicking the teacher's output. In the scope of neural machine translation , source-side monolingual data is run through the teacher model to produce an output that will be learnt by the student. The absence of parallel data requirements allows the student model to be trained with more data choices. This research focuses on exploring the use of monolingual datasets for knowledge distillation to find out what data should be used.  This research focuses on three aspects. The first is the language origin of the monolingual data. Student models can be trained with additional data in the form of source-side monolingual data. Besides that, the model can also be trained with back-translation data constructed from the target-side monolingual data. We show that using both source-side and target-side data are important because each of them improves performance , depending on the test-set's language origin.   Secondly, we explore the source of the monolingual data. Some research suggests or uses the same data between teacher and student. On the other hand, some research that makes use of knowledge distillation for NMT uses additional dataset, on top of the dataset learnt by the teacher. We explore whether using seen data is necessary, where we find that the student trained with a new unseen monolingual data performs equally with the one trained with the same dataset as the teacher.  The amount of data, including the synthetic ones affects model performance. Therefore, the last thing we explore is the monolingual data size. We find that adding to the monolingual data is generally better. However, varied training data based on language origin is much more important.       In this paper, we presented the first model capable of generating fluent spoken captions of images without relying on text, which almost matches the performance of early text-based image captioning models. Our comprehensive experiments demonstrated that learned units need to be robust, of low framerate, and encoding little or none duration information to be a drop-in replacement for text. We also identified the caveats of mode-based evaluation and proposed a new metric to address semantic diversity. As part of this work, a novel dataset of over 600k spoken captions for the MSCOCO dataset is introduced, which we will make publicly available to the research community.  Future work should investigate applying the proposed method to additional languages, devising improved speech unit representations, and jointly training the speech unit model with the I2S model. This would offer the opportunity to explore new analysis-by-synthesis training objectives.      
","  % Smaller, lightweight Neural Machine Translation  models can be trained with interpolated knowledge distillation by learning from the output of larger NMT model. To do so, the teacher translates text from source-language to target-language, which are then combined into a dataset for student.   We explore two types of monolingual data that can be included in knowledge distillation training for neural machine translation . The first is the source-side monolingual data. Second, is the target-side monolingual data that is used as back-translation data. Both datasets are translated by a teacher model from source-language to target-language, which are then combined into a dataset for smaller student models.  We find that source-side monolingual data improves model performance when evaluated by test-set originated from source-side. Likewise, target-side data has a positive effect on the test-set in the opposite direction. We also show that it is not required to train the student model with the same data used by the teacher, as long as the domains are the same. Finally, we find that combining source-side and target-side yields in better performance than relying on just one side of the monolingual data.",474
" % Background: % What is MT, history of MT, and current state of MT % What is NMT, current state of NMT % Reason: % Sufficient and necessity condition for writing this article % Organization of this article     Machine Translation  is an important task that aims to translate natural language sentences using computers. The early approach to machine translation relies heavily on hand-crafted translation rules and linguistic knowledge. As natural languages are inherently complex, it is difficult to cover all language irregularities with manual translation rules. With the availability of large-scale parallel corpora, data-driven approaches that learn linguistic information from data have gained increasing attention. Unlike rule-based machine translation, Statistical Machine Translation  learns latent structures such as word alignments or phrases directly from parallel corpora. Incapable of modeling long-distance dependencies between words, the translation quality of SMT is far from satisfactory. With the breakthrough of deep learning, Neural Machine Translation  has emerged as a new paradigm and quickly replaced SMT as the mainstream approach to MT.  Neural machine translation is a radical departure from previous machine translation approaches. On the one hand, NMT employs continuous representations instead of discrete symbolic representations in SMT. On the other hand, NMT uses a single large neural network to model the entire translation process, freeing the need for excessive feature engineering.  The training of NMT is end-to-end as opposed to separately tuned components in SMT. Besides its simplicity, NMT has achieved state-of-the-art performance on various language pairs. In practice, NMT also becomes the key technology behind many commercial MT systems.  As neural machine translation attracts much research interest and grows into an area with many research directions, we believe it is necessary to conduct a comprehensive review of NMT. In this work, we will give an overview of the key ideas and innovations behind NMT. We also summarize the resources and tools that are useful and easily accessible. We hope that by tracing the origins and evolution of NMT, we can stand on the shoulder of past studies, and gain insights into the future of NMT.  The remainder of this article is organized as follows: Section will review the methods of NMT. We first introduce the basics of NMT, and then we selectively describe the recent progress of NMT. We focus on methods related to architectures, decoding, and data augmentation. Section will summarize the resources such as parallel or monolingual corpora that are publicly available to researchers. Section will describe tools that are useful for training and evaluating NMT models. Finally, we conclude and discuss future directions in Section.    In this paper, we proposed a benchmark for Continual Learning in task-oriented dialogue systems, with 37 tasks to be learned continuously on four settings such as Intent recognition, Dialogue State Tracking, Natural Language Generation, and end-to-end. Then, we implemented three different Continual Learning methodologies such as regularization, rehearsal and architectural. In the latter, we propose a simple yet effective methods based on residual adapters and uses an entropy-based classifier to select which adapter to use at testing time. Finally, we analyse the trade-off between performance, number-of-parameters, and episodic memories size of the evaluated baselines, unveiling a no-free lunch among this methods.         
"," Machine translation  is an important sub-field of natural language processing that aims to translate natural languages using computers. In recent years, end-to-end neural machine translation  has achieved great success and has become the new mainstream method in practical MT systems. In this article, we first provide a broad review of the methods for NMT and focus on methods relating to architectures, decoding, and data augmentation. Then we summarize the resources and tools that are useful for researchers. Finally, we conclude with a discussion of possible future research directions. %Machine translation  is an important sub-field of natural language processing which aims to translate natural language sentences between different languages using computers. Recent years has witnessed the great success of end-to-end neural machine translation  models, which has dominated the mainstream approach in commercial machine translation systems. In this work, we first provide a broad review of the methods and challenges in NMT. We introduce three basic components in NMT methods, namely modeling, inference, and learning. The modeling part starts with the encoder-decoder framework and the celebrated attention mechanism, which is followed by Recurrent Neural Networks , Convolutional Neural Networks , and Self-Attention Networks  as potential instances in an NMT architecture. The inference part focuses on the generation of translation sentences from NMT models, which consists of autoregressive,  non-autoregressive, and bidirectional decoding methods. The learning part concentrates on the methods that enhances the expressive capacity of NMT models to learn from data. We highlight the design of training objectives and the use of monolingual data in this part. In addition to the three basic parts, we highlight some of the most significant challenges in NMT, including open vocabulary, prior knowledge integration, as well as the interpretability and robustness issues. Then we summarize useful resources and tools for MT research and maintainance. Finally, we conclude with a discussion of promising future research directions.",475
" NMT is the task of transforming a source sequence into a new form in a particular target language using deep neural networks. Such networks commonly have an encoder-decoder architecture , in which an encoder maps a given input sequence to an intermediate representation and a decoder then uses the same representation to generate candidate translations. Both encoder and decoder are neural networks that are trained jointly. Due to the sequential nature of the NMT task, early models usually relied on recurrent architectures , or benefited from the sliding feature of convolutional kernels to encode/decode variable-length sequences .   Recently, Transformers  have shown promising results for NMT and become the new standard in the field. They follow the same concept of encoding and decoding but in a relatively different fashion. A Transformer is fundamentally a feed-forward model with its unique neural components  that alter the traditional translation pipeline accordingly. Therefore, it is expected if such a model behaves differently than its recurrent or convolutional counterparts. Our goal in this research is to study this aspect in the presence of noise.     NMT engines trained on clean samples provide high-quality results when tested on similarly clean texts, but they break easily if noise appears in the input . They are not designed to handle noise by default and Transformers are no exception. Many previous works have focused on this issue and studied different architectures . In this work, we particularly focus on Transformers\footnote{We assume that the reader is already familiar with the Transformer architecture.} as they are relatively new and to some extent understudied.   A common approach to make NMT models immune to noise is fine-tuning , where a noisy version of input tokens is intentionally introduced during training and the decoder is forced to generate correct translations despite deformed inputs. FT is quite useful for almost all situations but it needs to be run with an optimal setting to be effective. In our experiments, we propose a slightly different learning-rate scheduler to improve FT. We also define a new extension that not only modifies input words but also adds complementary tokens to the target side. We refer to this extension as Target Augmented Fine-Tuning , which is the first contribution of this paper.   In our study, we realized that data augmentation techniques  might not be sufficient enough for some cases and we need a compatible training process and neural architecture to deal with noise. Therefore, we propose Controlled Denoising  whereby noise is added to source sequences during training and the encoder is supposed to fix noisy words before feeding the decoder. This approach is implemented via an auxiliary loss function and is similar to adversarial training. CD is our second contribution.   CD only takes care of noise on the encoder side, so we propose a Dual-Channel Decoding  strategy to study what happens if the decoder is also informed about the input noise. DCD supports multi-tasking through a -channel decoder that samples target tokens and corrects noisy input words simultaneously. This form of fusing translation knowledge with noise-related information has led to interesting results in our experiments. DCD is the third and last contribution of this work.   The remainder of the paper is organised as follows: First, we review previously reported solutions for the problem of noise in NMT in Section , then we present details of our methods and the intuition behind them in Section . To validate our methods, we report experimental results in Section . Finally, we conclude the paper and discuss possible future directions in Section .   ~ Neural machine translation has become the dominant approach to machine translation in both research and practice. This article reviewed the widely used methods in NMT, including modeling, decoding, data augmentation, interpretation, as well as evaluation. We then summarize the resources and tools that are useful for NMT research.  Despite the great success achieved by NMT, there are still many problems to be explored. We list some important and challenging problems for NMT as follows:   
"," Transformers \cite{transformer} have brought a remarkable improvement in the performance of neural machine translation  systems, but they could be surprisingly vulnerable to noise. Accordingly, we tried to investigate how noise breaks Transformers and if there exist solutions to deal with such issues. There is a large body of work in the NMT literature on analyzing the behaviour of conventional models for the problem of noise but it seems Transformers are understudied in this context.  Therefore, we introduce a novel data-driven technique to incorporate noise during training. This idea is comparable to the well-known fine-tuning strategy. Moreover, we propose two new extensions to the original Transformer, that modify the neural architecture as well as the training process to handle noise. We evaluated our techniques to translate the English--German pair in both directions. Experimental results show that our models have a higher tolerance to noise. More specifically, they perform with no deterioration where up to $10$\% of entire test words are infected by noise.",476
"   Cross-lingual word embeddings  represent words from two or more languages in a shared space, so that semantically similar words in different languages are close to each other. Early work focused on jointly learning CLWEs in two languages, relying on a strong cross-lingual supervision in the form of parallel corpora  or bilingual dictionaries . However, these approaches were later superseded by offline mapping methods, which separately train word embeddings in different languages and align them in an unsupervised manner through self-learning   or adversarial training .         Despite the advantage of not requiring any parallel resources, mapping methods critically rely on the underlying embeddings having a similar structure, which is known as the isometry assumption. Several authors have observed that this assumption does not generally hold, severely hindering the performance of these methods . In later work, \citet{ormazabal-etal-2019-analyzing} showed that this issue arises from trying to align separately trained embeddings, as joint learning methods are not susceptible to it.     In this paper, we propose an alternative approach that does not have this limitation, but can still work without any parallel resources. The core idea of our method is to fix the target language embeddings, and learn aligned embeddings for the source language from scratch. This prevents structural mismatches that result from independently training embeddings in different languages, as the learning of the source embeddings is tailored to each particular set of target embeddings. For that purpose, we use an extension of skip-gram that leverages translated context words as anchor points. So as to translate the context words, we start with a weak initial dictionary, which is iteratively improved through self-learning, and we further incorporate a restarting procedure to make our method more robust. Thanks to this, our approach can effectively work without any human-crafted bilingual resources, relying on simple heuristics  or an existing unsupervised mapping method to build the initial dictionary. Our experiments confirm the effectiveness of our approach, outperforming previous mapping methods on bilingual dictionary induction and obtaining competitive results on zero-shot cross-lingual transfer learning on XNLI.       In this paper, we studied the problem of noise in the context of NMT and particularly focused on Transformers. We proposed three novel techniques to augment data and change the training procedure as well as the neural architecture. Experimental results show that our techniques can protect NMT engines from noise. Our models only affect the training phase and do not add any overhead in terms of space and/or time complexities at inference time. Findings of our research can be summarized as follows:    In this research, we ran an extensive number of experiments in order to find the best configuration of each model and optimize hyper-parameters, but there still exist some unexplored topics/areas. In our future work, we are planning to experiment with other language pairs with different morphological and grammatical structures. , e.g. it would be interesting to see how our models deal with a language such as Mandarin that mainly relies on characters.  We are also interested in studying other noise classes. We could only afford to work with one class and we selected natural noise as we find it more realistic among others, but this work can be extended to other noise classes. Finally, our models are not unique to Transformer and NMT. We aim to evaluate them in other language processing/understanding tasks.  
","  Recent research on cross-lingual word embeddings has been dominated by unsupervised mapping approaches that align monolingual embeddings. Such methods critically rely on those embeddings having a similar structure, but it was recently shown that the separate training in different languages causes departures from this assumption. In this paper, we propose an alternative approach that does not have this limitation, while requiring a weak seed dictionary  as the only form of supervision. Rather than aligning two fixed embedding spaces, our method works by fixing the target language embeddings, and learning a new set of embeddings for the source language that are aligned with them. To that end, we use an extension of skip-gram that leverages translated context words as anchor points, and incorporates self-learning and iterative restarts to reduce the dependency on the initial dictionary. Our approach outperforms conventional mapping methods on bilingual lexicon induction, and obtains competitive results in the downstream XNLI task.",477
" Supervised and semi-supervised Machine Learning algorithms are now ubiquitous in the analysis of social media data. At the core of these algorithms is their ability to make sense of a vast amount of semi-structured real-time data streams, allowing them to automatically categorize or filter new data examples into, usually pre-defined, classes. Multi-class text classification has been successfully used in public health surveillance, election monitoring, or vaccine stance prediction~\parencite{salathe2011assessing,bermingham2011using,brownstein2009digital}. In recent years such algorithms have also been developed to mitigate the negative effects of social media, such as in the detection of cyber-bullying, hate speech, misinformation, and automated accounts ~\parencite{reynolds2011using,davidson2017automated,shu2017fake,davis2016botornot}.  The microblogging service Twitter has played a central role in these efforts, as it serves as a public medium and provides easy access to real-time data through its public APIs, making it the primary focus of this work. Twitter is well described as a classical example of a non-stationary system with frequently emerging and disappearing topical clusters~\parencite{costa2014concept}. This poses problems for the aforementioned applications, as the underlying data distribution is different between training time and the time of the algorithm's application in the real world. This phenomenon is known as concept drift~\parencite{schlimmer1986incremental} and can lead to a change in performance of the algorithm over time.  It is important to distinguish concept drift from other reasons for performance differences between training and testing, such as random noise due to sampling biases or differences in data preprocessing~\parencite{vzliobaite2010learning,webb2016characterizing}. A classic example of concept drift is the change in the meaning of classes, which requires an update of the learned class decision boundaries in the classifier. This is sometimes also referred to as real concept drift. Often, however, an observed performance change is a consequence of a change in the underlying data distribution, leading to what is known as virtual drift~\parencite{widmer1996learning,tsymbal2004problem}. Virtual drift can be overcome by supplemental learning, i.e.\ collecting training data from the new environment. A good example are periodic seasonality effects, which may not be fully represented in the initial training data and only become fully visible over time. However, in practice it is usually very difficult  to disentangle virtual from real concept drift, and as a consequence they are treated as the same effect~\parencite{vzliobaite2010learning}.  On Twitter concept drift might appear on very different time scales and at different rates. Sudden shifts in a debate might be triggered by a quickly evolving news cycle or a catastrophic event. Concept drift may also be a slow process in which the way a topic is discussed gradually changes over time. A substantial amount of work has been dedicated to detecting and overcoming concept drift~\parencite{widmer1996learning,vzliobaite2010learning,elwell2011incremental}. Three basic re-training procedures for overcoming concept drift have been proposed:  a time-window approach,  an incremental model, and  an ensemble model~\parencite{costa2014concept}. In the time-window approach, a sliding window of recent training examples is used to train an algorithm. In this approach, the algorithm ignores training data collected outside of that time window. The incremental model, in contrast, uses all previously collected training examples to re-train the model. Lastly, the ensemble model trains a model for each time window and uses the consensus of all previous models for future predictions. As found in~\parencite{costa2014concept}, in the case of hashtag prediction on Twitter data, the incremental method gave the best results.  Although sophisticated methods have been proposed to estimate concept drift in an unsupervised way~\parencite{katakis2010tracking,yang2008conceptual}, in practice, a certain amount of re-annotation for both the detection and re-training of models seems unavoidable. The decision about which of the newly collected data to annotate points to an exploration-exploitation dilemma, which is usually addressed in the context of an active learning framework~\parencite{settles2009active}. The Crowdbreaks platform~\parencite{muller2019crowdbreaks} is an example of such a framework and has been built with the goal of exploring optimal solutions to this problem in order to overcome concept drift.  A change in the underlying data distribution might not necessarily have a negative impact on classifier performance. It is conceivable, for example, that a polarisation in a debate on Twitter about a topic could even lead to an improvement in classifier performance. It is therefore important to ask how much we should be worried about concept drift: even if model performance were to decrease, the real impacts on our analysis or interpretation might be negligible.  The consequences of concept drift are task-, environment-, and model-dependent~\parencite{vzliobaite2016overview}. Here, we will address concept drift in the specific case of vaccine stance classification. Vaccine stance classification on Twitter data has been widely studied and has shown promising links to vaccination decision making and vaccine uptake rates in different countries~\parencite{salathe2011assessing,bello2017detecting}. The COVID-19 pandemic further emphasizes its importance, as evolving concerns about vaccines may significantly influence their effect~\parencite{johnson2020online,burki2020online}.  To the best of our knowledge, only one study directly addressed concept drift in vaccine stance classification. In this study~\parencite{d2019monitoring} on tweets posted between September 2016 and January 2017 in Italian language, the authors did not find a substantial improvement of their model from incremental re-training before specific events. Re-training was performed on 60 newly annotated tweets from seven manually selected events. The authors conclude that either their original algorithm was already quite robust towards concept change, or that the newly collected training data was too small to see an effect.  Here, we use FastText~\parencite{joulin2016bag} and BERT ~\parencite{devlin2018bert}, two commonly used models in social media text classification. Most work on the topic of concept drift was conducted using classical machine learning models, to which also FastText belongs. These types of models are very reliant on high-quality annotation data. More recently, models of the transformer family, such as BERT~\parencite{devlin2018bert}, have been proposed, which require significantly less annotation data. In what follows, we will examine whether these two models also share different concept drift characteristics.  The goal of this work is to emulate a typical social media analysis study, in which data is collected for a certain period of time, and a supervised machine learning model is trained on a subset of annotated data. The model is then published and used to predict newly collected data. First, we will try to answer whether or not concept drift can be observed, and if so, at what rate it occurs. Second, we will investigate the influence of the study duration and the amount of annotation data used. Lastly, we will examine to what extent concept drift influences the final analysis outcomes, in this case a sentiment index.         {\small   }  \clearpage    
","   Social media analysis has become a common approach to assess public opinion on various topics, including those about health, in near real-time.   The growing volume of social media posts has led to an increased usage of modern machine learning methods in natural language processing.   While the rapid dynamics of social media can capture underlying trends quickly, it also poses a technical problem: algorithms trained on annotated data in the past may underperform when applied to contemporary data.   This phenomenon, known as concept drift, can be particularly problematic when rapid shifts occur either in the topic of interest itself, or in the way the topic is discussed.   Here, we explore the effect of machine learning concept drift by focussing on vaccine sentiments expressed on Twitter, a topic of central importance especially during the COVID-19 pandemic.   We show that while vaccine sentiment has declined considerably during the COVID-19 pandemic in 2020, algorithms trained on pre-pandemic data would have largely missed this decline due to concept drift.   Our results suggest that social media analysis systems must address concept drift in a continuous fashion in order to avoid the risk of systematic misclassification of data, which is particularly likely during a crisis when the underlying data can change suddenly and rapidly.",478
" In this paper, we tackle the problem of screening a finite pool of documents, where the aim is to retrieve relevant documents satisfying a given set of predicates that can be verified by human or machines . In this context, if a document does not satisfy at least one predicate, it is treated to be irrelevant. A predicate represents a property, a unit of meaning, given in natural language . By this means a predicate might be interpreted in a variety of ways in text, so making keywords-based search hard to reach high recall while keeping a decent level of precision . We interpret the screening problem as high recall problem, i.e., the aim is to retrieve all relevant documents maximizing precision. %we assume predicates and candidate documents are given  % Since predicates can be interpreted in a variety of ways, it makes the problem of document screening very challenging especially when there is a little training data.  The screening finds application in many domains, such as i) in systematic literature reviews ; % -SLRs-  AND papers studying older adults }; ii) database querying - where items filtered  in/out based on predicates ; iii) hotel search - where the hotels retrieve  based upon filters of interest . Consequently,  the document screening is an instance of finite pool binary classification problems  , where we need to classify a finite set of objects minimizing cost. % As an instance of the problem, we choose the screening phase of SLRs what makes the problem rather challenging since each review is different and has a unique set of predicates . Typically, authors of an SLR retrieve a candidate pool of documents executing a keywords-based query on a database such as Scopus. To avoid missing papers, the query tends to be inclusive, which means that it returns hundreds or thousands of results  that are later manually screened by researchers based on predefined predicates. For example, researchers might look for papers that describe all of the following predicates at the same time: 1) ""include papers that study older adults 85+ years"", 2) ""include papers conducted randomized controlled trial"", 3) "" include papers about behavioral intervention"". Therefore, here we have the conjunctive query of three inclusive predicates. A bottleneck of the screening process is the predicate evaluation, i.e.,  identifying which of the given predicates are satisfied in a current document. For example, in literature reviews, authors validate predicates, however, this is time-consuming, exhaustive, and very expensive .   An effective technique to solve screening problems is crowdsourcing where the crowd can solve even complex screening tasks with high accuracy and lower cost compared to expert screening . However, achieving a good performance in crowd-based screening requires a deep understanding of how to design tasks and model their complexity , how to test and filter workers , how to aggregate results into a classification decision, or how to improve worker engagement .   Machine learning  algorithms have also made a very impressive progress in solving complex screening tasks. However, obtaining a sufficiently large set of training data is still a key bottleneck for accurate ML classifiers. Active learning   accelerates this process by minimizing the size of training data that is required to train better classifiers via selecting the most informative instances for annotation. The effectiveness of AL have been proven in many domains , but most of the work considers single-label cases while multi-label AL problems have been far less investigated. The challenge in applying AL to a multi-label classification problem is that the algorithm should measure the unified informativeness of each unlabeled item across all labels. The state of the art multi-label AL strategies follow an object-wise  labeling, where the AL algorithm first finds the relevance scores  of  pairs, and then aggregates these scores to find the informativeness of items . However, it may ignore the interaction between labels .    \paragraph{Original contribution.} We investigate how to efficiently combine crowdsourcing and ML for item screening. It is a challenging task since the budget is limited and there are countless number of ways to spend it on the problem. We propose a multi-label AL screening specific sampling technique for querying unlabelled items for annotating. Our algorithm takes a decision how to choose unlabeled data to annotate by crowd workers in order to maximize the performance of a screening task. Unlike existing multi-label AL approaches that rely on global labeling, we choose the local labeling method, where for each label  we determine the relevancy to each item.     In this work, we investigated the effects of concept drift in vaccination-related Twitter data streams over a duration of three years. Using a sliding time window approach, we emulate a social media study in which  data is collected for one year,  an algorithm is trained, and  the algorithm is used in real-time monitoring of new data. While this may correspond to a common setup in social media analytics, we demonstrate here that without taking concept drift into account, the quality of the results will decay. Using a vaccine-related dataset from 2018--2020, we demonstrate how failing to take concept drift into account would have largely missed a rather dramatic decay in vaccine sentiment during the COVID-19 pandemic in 2020.  We find that overall, concept drift indeed occurred, which led to a decline in model performance of over 20\  in the course of three years. However, most of this decline happened in only ten months. Concept drift therefore affected model performance at different rates throughout the observation period. Furthermore, the relative performance loss was not consistently negative but reverted to initial levels, or even slightly above that. These findings are consistent with the various ways real and virtual concept drift can occur. Although BERT models yielded higher performance scores, they are not immune to issues related to concept drift. On a relative scale, BERT models show the same degree of drift as the much less sophisticated FastText models.  In order to better understand the reasons for these phenomena, we investigate the properties of the used datasets. We can explain the large differences in initial performance of models with differences in semantic ambiguity of the text, as indicated by low inter-annotator agreement and low corpus variability. Occurrence of concept drift could be linked to differences in corpus similarity. In particular, we find that the negative class is responsible for most of the decay in performance over time and also shows the strongest signs of drift. Anti-vaccine content may therefore change topics at an increased rate compared to both positive or neutral content.  A caveat of this study is that the results are based on classifiers of mediocre performance. Given the fact that the negative class was most affected by concept drift and is at the same time also the smallest class in our dataset, it is a fair question to ask whether concept drift would disappear given more annotation data and higher performance of models. It is conceivable that more annotation data would lead to a better representation of the training window. However, as results in a study on automated geo-location of tweets show, concept drift will still occur also under vast amounts of annotated data and adaptive re-training on even a relatively small corpus can overcome this drift.  Our results do not overlap with a previous study on vaccination-related Twitter data, which did not find concept drift in an observation period between September 2016 and January 2017 in Italian language. The reason for this could be that the time scale analysed was too small to see an effect, or that concept drift was much smaller in that particular dataset.  It is safe to assume that the COVID-19 pandemic led to severe topical shifts in the vaccine debate, which ultimately translated into strong concept drift and model performance loss. Based on these results, it can be expected that future crisis situations would lead to similarly strong concept drift, thereby severely undermining the utility of social media monitoring tools that do not take concept drift into account. This is especially true for applications which are intended to be used exactly in such circumstances.  Although our work focused on the singular task of vaccine stance prediction, we believe that these results stress the general importance of addressing concept drift in any real-time social media monitoring project. Overcoming concept drift is a complex task, and many algorithmic solutions have been proposed. However, in order to succeed in practice, a tightly coordinated and fine-tuned framework for both the annotation and retraining of models is required. The Crowdbreaks platform was built with the intention to address this issue and provide solutions for it.   \section{Materials and methods}     This study is based on Twitter data collected through the Crowdbreaks platform. Between July 1st, 2017 and October 1st, 2020 a total of \num{57.5}M tweets  in English language by \num{9.9}M unique users were collected using the public filter stream endpoint of the Twitter API. The tweets matched one or more of the keywords ``vaccine'', ``vaccination'', ``vaxxer'', ``vaxxed'', ``vaccinated'', ``vaccinating'', ``vacine'', ``overvaccinate'', ``undervaccinate'', ``unvaccinated''. The data can be considered complete with respect to these keywords.    Human annotation of a subset of tweets was performed through the Crowdbreaks platform. Tweets were anonymized by replacing user mentions and URLs with placeholders. Tweets between February 2nd 2018 and November 11th 2020 were sampled for annotation if they contained at least 3 words. Exact duplicates were removed. Annotators were asked the question ``What is the attitude of the author of the tweet regarding vaccines?'' and given the three options ``negative'',  ``neutral'', and ``positive''. Annotation was performed both on Amazon Turk  and, to a smaller extent  by public users on the Crowdbreaks website. We yield a dataset of \num{44843} annotations , which resulted in \num{11893} three-fold annotated tweets. Tweets with less than two-third agreement were excluded and conflicts were decided through majority vote.    In this work we leverage two different classifiers: FastText and BERT. For both models, hyperparameters were first tuned on the full annotation data to yield optimal performance and then fixed for further experiments. For FastText we used 10 dimensions, 500 epochs, a learning rate of \num{0.01}, and using 1-gram embeddings. Optimal results were yielded by lower casing texts, converting them to ASCII and using the tags ``user'' and ``url'' for anonymization. BERT models of the type bert-large-uncased  were trained for \num{20} epochs, training batch size of \num{32}, and a learning rate \num{2e-5} , as recommended in recent literature. FastText models were trained on a university cluster using the Crowdbreaks  library\footnote{} and BERT models were trained using Google Cloud v3-8 TPUs and the  library\footnote{}. For the purpose of predictions, text was preprocessed using the respective preprocessing approach.  \paragraph{Data availability.} All data and code can be found on our public GitHub repository .  \paragraph{Author contributions.} M.M.\ collected the data, designed the experiments and analysed the data. M.M.\ and M.S.\ conceptualized the work and wrote the manuscript.  \paragraph{Acknowledgments.} The authors would like to acknowledge Dr.\ Per Egil Kummervold and Dr.\ Burcu Tepekule for their valuable comments and discussions.  \paragraph{Competing interests.} The authors declare no competing interests.  \paragraph{Funding.} This work received funding through the Versatile Emerging infectious disease Observatory  grant as a part of the European Commission閳ユ獨 Horizon 2020 framework programme . Compute resources  were provided through Google閳ユ獨 TensorFlow Research Cloud and the work was supported through Google Cloud credits in the context of COVID-19-related research.  \printbibliography                      SUPPLEMENTARY  \pagebreak \beginsupplement    \section{Supplementary figures}    \pagebreak    \pagebreak    \pagebreak    
"," In this paper, we explore how to efficiently combine crowdsourcing and machine intelligence for the problem of document screening, where we need to screen documents with a set of machine-learning filters. Specifically, we focus on building a set of machine learning classifiers that evaluate documents, and then screen them efficiently. It is a challenging task since the budget is limited and there are countless number of ways to spend the given budget on the problem. We propose a multi-label active learning screening specific sampling technique -objective-aware sampling- for querying unlabelled documents for annotating. Our algorithm takes a decision on which machine filter need more training data and how to choose unlabeled items to annotate in order to minimize the risk of overall classification errors rather than minimizing a single filter error.  We demonstrate that objective-aware sampling significantly outperforms the state of the art active learning sampling strategies. % on multi-filter classification problems.",479
"   One of the hallmarks of human intelligence is the ability to generalize seamlessly across heterogeneous sensory inputs and different cognitive tasks. We see objects, hear sounds, feel textures, smell odors, and taste flavors to learn underlying concepts present in our world. Much of AI's existing progress in multimodal learning, however, focuses primarily on a fixed set of predefined modalities and tasks that are consistent between training and testing. As a result, it is unclear how to transfer knowledge from models trained for one modality  to another  at test time. This scenario is particularly important for low-resource target modalities where unlabeled data is scarce and labeled data is even harder to obtain . In the unimodal case, this is regarded as meta-learning or few-shot learning. In contrast, we formally define the cross-modal generalization setting as a learning paradigm to train a model that can  quickly perform new tasks in a target modality  and  doing so while being trained on a different source modality. In this paper, we study the data and algorithmic challenges for cross-modal generalization to succeed. %Such a learning paradigm is particularly useful in leveraging high-resource source modalities to help low-resource target modalities, where unlabeled data is scarce and labeled data is even harder to obtain, such as audio from low-resource languages, real-world environments, and medical images.      As a motivating example, Figure illustrates a scenario where large-scale image classification benchmarks can help audio classification, which is a less studied problem with fewer large-scale benchmarks. In this ambitious problem statement, a key research question becomes: how can we obtain generalization across modalities despite using separate encoders for different source  and target  modalities? The technical challenge involves aligning shared knowledge learned from source image tasks with target audio tasks. Our problem statement differs from conventional meta-learning and domain adaptation where one can take advantage of the same source and target modality with shared encoders which helps generalization by having the same representation space. In our case, the discrepancies in modalities requires one to learn new output concepts expressed in new input modalities. As a result, cross-modal generalization requires new ideas to synchronize  multimodal sources and targets. What is the minimal extra supervision required to perform this alignment?  In this paper, we formalize the conditions required for successful generalization and show that another level of supervision is necessary under partial observability across modalities and tasks. Supervision comes in the form of cross-modal meta-alignment  to capture a space where representations of similar concepts in different modalities are close together while ensuring quick generalization to new tasks . We introduce a novel algorithm called \names\  that leverages readily available multimodal data from the internet  for meta-alignment and cross-modal generalization. Through theoretical analysis and empirical ablations, we study our proposed algorithm with both strongly and weakly paired multimodal data, showing that cross-modal generalization is possible even with limited extra supervision.  %How can one transfer knowledge learned from an image classification task to speech event classification? The problem of cross-modal generalization brings fundamental differences regarding how data is expressed across different modalities . In comparison to meta-learning and domain adaptation, the different input spaces now consist of extremely high-dimensional, complex, and heterogeneous source and target modalities. As a result, we are unable to use a shortcut by sharing encoders as commonly seen in same-modality, different domain settings which allow for the same representation space between source and target domains. This raises a fundamental research question: how can we obtain generalization across modalities despite using separate encoders for different source and target modalities? These discrepancies in modalities requires one to learn new output concepts expressed in new input modalities. %We show that existing domain adaptation, meta-learning, and transfer learning approaches are unable to bridge the gap between such heterogeneous paradigms where both input modalities and output tasks are different.  % emphasize cant share encoders, need explicit alignment % emphasize different label space, generalize meta-learning % formulate crossmodal ml and therefore we propose meta alignment % first para ok. like to learn but different modalities. % second para. compared to ml and da, 1 critical issue when trying to do crossmodal - have hetero data between source and target. cant use shortcut such as same encoder for images of different domains. need different encoders 1 for each. how do we solve this? need another level of supervision to help - where meta alignment comes in. what we propose - a technique to address the core technical challenge of crossmodal ml which is how to learn different encoders. meta alignment is a way to do that, a contrastive learning approach.  %To account for this technical challenge, we formalize the conditions required for successful generalization and show that another level of supervision is necessary under partial observability across modalities and tasks. This form of supervision comes in the form of cross-modal alignment to capture a space where representations of similar concepts in different modalities are close together while ensuring quick generalization to new low-resource tasks . Our analysis leads to a novel algorithm based on contrastive learning called \names\  that leverages either strongly or weakly paired multimodal data abundant on the internet. Finally, we carefully study the data and algorithmic requirements for our approach to succeed through theoretical analysis and empirical ablations.  %Very hard problem of crossmodal meta-learning. What is the minimal amount of supervision  required to solve this hard task of cross-modal meta-learning? In this paper we will explore this through theory and empirics  %We highlight two crucial distinctions:  the different input spaces consist of extremely high-dimensional, complex, and heterogeneous source and target modalities, and  there exist different task distributions between source and target modalities, such as the inherent differences between the label spaces when transferring from image to audio classification tasks. These discrepancies in both input and output spaces requires one to learn new output concepts expressed in new input modalities. We show that existing domain adaptation, meta-learning, and transfer learning approaches are unable to bridge the gap between such heterogeneous paradigms where both input modalities and output tasks are different.  % how do we handle limited resource modalities and task, we explore cross-modal approach % note: define modality, concept, task % note: a better way of saying cross-modal cross-task  %, which allows us to learn a classifier for transfer from source to target tasks. %This makes it particularly suitable for generalization across modalities and tasks due to the presence of unseen concepts and annotations in the target modality. %We show that this space:  groups similar concepts expressed across different modalities,  is well-clustered across concepts, and  generalizes well to new concepts, making it particularly suitable for generalization across modalities and tasks. %While our first attempt at meta-alignment uses strong pairings across source and target modalities , we further provide an extension to use only weak pairs between modalities. Weak pairs represent coarse groupings of semantic correspondence which better capture the many-to-many relations between real-world multimodal data  and allow us to use large banks of weakly paired multimodal data available on the internet and prepared for machine learning studies such as video data  and image captioning data . %Finally, we quantify the trade-offs between labeling more data in the target modality versus obtaining better source-target alignment.  %provide theoretical justification to quantify the benefits of our approach: {\color{red} ZIYIN TODO} \zing[ziyin: should mention and focus on the difficulty of definition and formalization] %instead of a classical generalization error in the target modality that scales wrt the sample complexity of the target modality, our approach is bounded by the sample complexity in the source modality. As a result, the error is therefore reduced with ample samples in the source modality and a well-aligned space.  We present experiments on three cross-modal tasks: generalizing from  text to image,  image to audio, and  text to speech. In all cases, the goal is to classify data from a new target modality given only a few  labeled samples. %We find that \names\ accurately performs few-shot alignment of concepts from different modalities, thereby allowing generalization from concepts in the source modality to new concepts in the target modality. We perform extensive experiments to compare with related approaches including target modality meta-learning that would be expected to perform well since they have seen thousands of labeled examples from the target modality during meta-training. Surprisingly, \names\ is competitive with these baselines and significantly outperforms other cross-modal approaches. In addition, we study settings where the target modality suffers from noisy or limited data, a scenario particularly prevalent in low-resource modalities. %While this setting makes it difficult to directly train in the target modality, our approach efficiently leverages cross-modal information to perform well.     In this paper, we proposed and evaluated the objective-aware active learning strategy designed for screening classification and selecting efficiently item, predicate for annotating based on the overall classification objective. We demonstrated that objective-aware sampling outperforms uncertainty and random AL techniques under different conditions. We further aim to examine more screening datasets, extend this study to other classes of screening problems and hybrid crowd-machine algorithms.  
"," The natural world is abundant with concepts expressed via visual, acoustic, tactile, and linguistic modalities. Much of the existing progress in multimodal learning, however, focuses primarily on problems where the same set of modalities are present at train and test time, which makes learning in low-resource modalities particularly difficult. In this work, we propose algorithms for cross-modal generalization: a learning paradigm to train a model that can  quickly perform new tasks in a target modality  and  doing so while being trained on a different source modality. We study a key research question: how can we ensure generalization across modalities despite using separate encoders for different source and target modalities? Our solution is based on meta-alignment, a novel method to align representation spaces using strongly and weakly paired cross-modal data while ensuring quick generalization to new tasks across different modalities. We study this problem on 3 classification tasks: text to image, image to audio, and text to speech. Our results demonstrate strong performance even when the new target modality has only a few  labeled samples and in the presence of noisy labels, a scenario particularly prevalent in low-resource modalities. %Despite vast differences in these raw modalities, humans seamlessly perceive multimodal data, learn new concepts, and show extraordinary capabilities in generalizing across input modalities. %In addition, our method works particularly well when the target modality suffers from noisy or limited labels, a scenario particularly prevalent in low-resource modalities. %, sometimes outperforming within modality few-shot baselines that have seen thousands of labeled examples from that target modality during meta-training. %\zing[Ziyin: heterogeneous -> multimodal? since we are assuming there is an underlying shared space, so maybe not heterogeneous] %\zing[Ziyin: since this is the first sentence in the intro, maybe remove this?] %Similarly, truly general artificial intelligence  systems must learn to generalize across multiple input modalities and output tasks. %In this work, we define and propose algorithms for a new notion of generalization:  %, languages, and concepts. %We believe that our proposed methods could open new doors towards better generalization in multimodal AI systems.",480
" Cloud services have become increasingly popular and are expected to gain 331.212.6\%\ billion every year for the Fortune 1,000 . Amazon is estimated to have a 1004.11\%-91.58\%82.9\%76.3\% - 91.3\%$ in high impacted incidents. Model ablation analysis showed that each of the ML models we used provided a lift in the final ensemble for different incident types. To the best of our knowledge, we are the first one to present a deployed incident triage service for cloud-scale online services.  This paper makes three key contributions:   This paper is organized as follow: Section  presents the background of an incident management system; Section  provides details of   {\TransferAssistant}; Section  shows experimental results; Section  describes the deployment of {\TransferAssistant} in Azure; Section  discusses lessons learned and implications for implementing and deploying an incident triage service at cloud scale;  Section  presents related work;  and Section  concludes this paper.      In this work, we proposed cross-modal generalization: a learning paradigm where abundant source modalities are used to help low-resource target modalities. We showed that meta-alignment using cross-modal data can allow quick generalization to new concepts across different modalities. Our experiments demonstrate strong performance on classifying data from an entirely new target modality under limited samples and noisy labels, which is particularly useful for generalization to low-resource images, speech, and languages.  \iffalse  
","   As cloud services are growing and generating high revenues, the cost of downtime in these services is becoming significantly expensive. To reduce loss and service downtime, a critical primary step is to execute incident triage, the process of assigning a service incident to the correct responsible team, in a timely manner. An incorrect assignment risks additional incident reroutings and increases its time to mitigate by 10x. However, automated incident triage in large cloud services faces many challenges:  a highly imbalanced incident distribution from a large number of teams,    wide variety in formats of input data or data sources,     scaling to meet production-grade requirements, and     gaining engineers' trust in using machine learning recommendations.    To address these challenges, we introduce {\TransferAssistant}, an intelligent incident transfer service combining multiple machine learning techniques -- gradient boosted classifiers, clustering methods, and deep neural networks -- in an ensemble to recommend the responsible team to triage an incident. Experimental results on real incidents in Microsoft Azure show that our service achieves $82.9\%$ F1 score. For highly impacted incidents, {\TransferAssistant} achieves F1 score from $76.3\% - 91.3\%$. We have applied best practices and state-of-the-art frameworks to scale {\TransferAssistant} to handle incident routing for all cloud services. {\TransferAssistant} has been deployed in Azure since October 2017 and is used by thousands of teams daily.",481
"   % Every day pharmaceutical companies receive numerous medical inquiries related to their products from patients, healthcare professionals, research institutes, or public authorities from a variety of sources .  % These medical inquiries may relate to drug-drug-interactions, availability of products, side effects of pharmaceuticals, clinical trial information, product quality issues, comparison with competitor products, storage conditions, dosing regimen, and the like.  % On the one hand, a single medical inquiry is simply a question of a given person searching for a specific information related to a medicinal product. On the other hand, a plurality of medical inquiries from different persons may provide useful insight into matters related to medicinal products and associated medical treatments. % Examples of these insights could be early detection of product quality or supply chain issues, anticipation of treatment trends and market events, improvement of educational material and standard answers/frequently asked question coverage, potential changes in treatment pattern, or even suggestions on new possible indications to investigate. % From a strategic perspective, this information could enable organizations to make better decisions, drive organization results, and more broadly create benefits for the healthcare community.   % transition paragraph - machine learning can help However, obtaining high-level general insights is a complicated task since pharmaceutical companies receive  copius amounts of medical inquiries every year. Machine learning and natural language processing represent a promising route to automatically extract insights from these large amounts of unstructured  medical text. % % % text mining in general and in the biomedical domain Natural language processing and text mining techniques have been widely used in the medical domain, with particular emphasis on electronic health records.  In particular, deep learning has been successfully applied to medical text, with the overwhelming majority of works in supervised learning, or representation learning  to learn specialized word vector representations . % %There is little work however on unsupervised learning from unstructured medical text.  Conversely, the literature on unsupervised learning for medical text is scarce despite the bulk of real-world medical text being unstructured, without any labels or annotations. % Unsupervised learning from unstructured medical text is mainly limited to the development of topic models based on latent Dirichlet allocation . Examples of applications in the medical domain are clinical event identification in brain cancer patients from clinical reports, modeling diseases and predicting clinical order patterns from electronic health records, or detecting cases of noncompliance to drug treatment from patient forums. % Only recently, word embeddings and unsupervised learning techniques have been combined to analyze unstructured medical text to study the concept of diseases, medical product reviews, or to extract informative sentences for text summarization.  % real-world corpus of medical inquiries and its challenges In this work, we combine biomedical word embeddings and unsupervised learning to discover topics from real-world medical inquiries received by Bayer\texttrademark. % A real-world corpus of medical inquiries presents numerous challenges. From an inquirer  perspective, often the goal is to convey the information requested in as few words as possible to save time. This leads to an extensive use of acronyms, sentences with atypical syntactic structure, occasionally missing verb or subject, or inquiries comprising exclusively a single noun phrase. % Moreover, since medical inquiries come from different sources, it is common to find additional  information related to the text source; examples are references to internal computer systems, form frames  alongside with the actual form content, lot numbers, email headers and signatures, city names.  % % mixture of layman and medical language The corpus contains a mixture of layman and medical language depending  on the inquirer being either a patient or a healthcare professional. Style and content of medical inquiries vary quite substantially according to which therapeutic areas  a given medicinal product belongs to.  % add sentence to refer to the text representation %as one can see from Fig., As already mentioned, medical inquiries are short. More specifically, they comprise less than fifteen words in the vast majority of cases.  % Standard techniques for topic modelling based on LDA do not apply, since the main assumption - each document/text is a distribution over topics - clearly does not hold given that the text is short.  % Approaches based on pseudo-documents or using auxiliary information are also not suitable since no meaningful pseudo-document nor auxiliary information are available for medical inquiries. % Moreoever, these models aim to learn semantics  directly from the corpus of interest. However, the recent success of pretrained embeddings shows that it is beneficial to include semantics learned on a general  corpus, thus providing semantic information difficult to obtain from smaller corpora. This is particularly important for limited data and short text settings. To this end, there has been recently some work aimed at incorporating word embeddings into probabilistic models similar to LDA  and that - contrary to LDA - satisfies the single topic assumption .  Even though these models include  semantic information in the topic model, it is not evident how to choose the required hyper-parameters, for example determining an appropriate threshold when filtering semantically related word pairs. Concurrently to our work, document-level embeddings and hierarchical clustering have been combined to obtain topic vectors from news articles and a question-answer corpus.  % summary Here, we propose an approach based on specialized biomedical word embeddings and unsupervised learning to discover topics from short, unstructured, real-world medical inquiries. This approach - schematically depicted in Fig. - is then used to discovery topics in medical inquiries received by Bayer\texttrademark\ Medical Information regarding the oncology medicinal product Stivarga\texttrademark.      In this paper, we put forward the idea of heterogeneity in program ASTs, and presented a framework of representing source code as heterogeneous program graphs  using ASDL grammars. By applying heterogeneous graph transformer on our HPG, our approach significantly outperforms previous GNN models on two graph-level prediction tasks for source code: comment generation and method naming.  In the future, we plan to evaluate our approach on more tasks, especially node or link prediction tasks. We would also extend our approach to other programming languages and propose new models more suited for heterogeneous program graphs.  
"," %141 words % the motivation Millions of unsolicited medical inquiries are received by pharmaceutical companies every year.  It has been hypothesized that these inquiries represent a treasure trove of information, potentially giving insight into matters regarding medicinal products and the associated medical treatments.  % the challenge However, due to the large volume and specialized nature of the inquiries, it is difficult to perform timely, recurrent, and comprehensive analyses. % the solution Here, we propose a machine learning approach based on natural language processing and unsupervised learning to automatically discover key topics in real-world medical inquiries from customers. This approach does not require ontologies nor annotations.  % the results The discovered topics are meaningful and medically relevant, as judged by medical information specialists, thus demonstrating that unsolicited medical inquiries are a source of valuable customer insights. % the implications and outlook Our work paves the way for the machine-learning-driven analysis of medical inquiries in the pharmaceutical industry, which ultimately aims at improving patient care.",482
" Dynamic models of text aim at characterizing temporal changes in patterns of document generation. Most successful dynamic language models are Bayesian in nature, and lag behind state-of-the-art deep language models in terms of expressibility. A natural space to study some of the temporal aspects of language is that of the large review datasets found in e-commerce sites.  The availability of millions of reviewed items, such as business or services, books or movies, whose reviews have been recorded in time scales of years, opens up the possibility to develop deep scalable models that can predict the change in taste and preference of users as time evolves. Originally, the interaction of users in these e-commerce sites were studied in the context of collaborative filtering, where the goal was to predict user ratings, based on user interaction metrics. Here we aim to look directly at the content of reviews as time evolves.  %More KDD probably, to much focus on the ratings and recommendations  %-------- %The shear size of e-commerce and review web sites naturally lend itself to the development of data mining tools which are able to provide users with a way to sort out relevant information. This is the task assigned to recommender systems.  Originally kick started by the Netflix competition, matrix factorization  methods through collaborative filtering, aim at predicting user ratings based on user interaction metrics. This rating based methods are lacking as they are unable to clarify the nature of the user preferences, in particular how those preferences change on time. In order to address this issue, methodologies that exploit costumers reviews are gaining attention.  %--------- Costumer reviews provide a rich and natural source of unstructured data which can be leverage to improve recommender system performance . Indeed, reviews are effectively a form of recommendation. % Recently, a variety of deep learning solutions for recommendation have profit from their ability to extract latent representations from review data, encoding rich information related to both users and items. % %Review  content naturally encodes  % This type of data  % Review content is of contextual nature, as the text arises from the interaction of user preferences and items at hand.  % Time represents yet another dimension of context, as user preference and item availability change with time % -- and indeed, % causal and temporal relations have been known to improve the performance of recommender systems  .  % Despite this fact, % recent natural language processing  methodologies for rating and reviews  lag behind at incorporating temporal structure in their language representations. In the present work we exploit recurrent neural network  models for point processes, and feed them neural representations of text, to characterize costumer reviews. Our goal is to capture the changes in user taste and item importance during time, and to exploit those changes to better predict when are new reviews arriving, and what do they actually say. We summarize our contributions as follows: {}  %     We present the related work in Section  and introduce our model in Section . The baseline models used for comparison in this paper are presented in Section . The experimental setup and results are presented in Section . Finally, in Section  we conclude and discuss future work.     advantages This study introduces an unsupervised machine learning approach to automatically discover topics from medical inquiries.  After the initial  effort for preprocessing  and hyper-parameters determination, the algorithm runs without requiring any human intervention, discovering key topics as medical inquiries are received.    Topics can be discovered even if only a small number of inquiries is present, and are generally specific, thus enabling targeted, informed decisions by medical experts.  Being completely unsupervised, the algorithm can discover topics that were neither known nor expected in advance, topics which often are the most valuable.   This is in stark contrast with ontology or supervised based approaches, where topics need to be defined a priori , and incoming text can be associated only to these predefined lists of topics, thus hindering the discovery of a priori unknown topics.   The machine learning approach introduced here does not use ontologies , and instead it incorporates domain knowledge via specialized biomedical word embeddings.   This allows to readily apply the topic discovery algorithm to different medicinal products, without the burden of having to develop specialized ontologies for each product or therapeutic area. Indeed, the algorithm is periodically analyzing medical inquiries for a total of sixteen Bayer\texttrademark\ medicinal products, encompassing cardiology, oncology, gynecology, hematology, and ophthalmology.    disadvantages Our approach has several limitations. First, it can happen that a small fraction of inquiries associated to a given topic are actually extraneous to it, especially for semantically broad topics.  This is because - due to the noise present in this real-world dataset - the soft clustering HDBSCAN algorithm must be applied with a low probability threshold for cluster assignment to avoid the majority of inquiries being considered as outliers .    Second, even though the topic names are generally quite informative, a medical expert needs to read the actual inquiries to fully grasp the topic meaning, especially if a decision will be made on the grounds of the discovered topics. This is however not burdensome because inspection is limited to the inquiries associated to a given topic .   Last, some discovered topics are judged by medical experts - based on their expert knowledge - so similar that they could have been merged in a single topic, but are considered distinct by the algorithm. In these cases, manual topic grouping might be required to determine the top topics by inquiry volumes. Still, these similar topics very often appear close to each other in the topic map.    value despite the limitations Despite these limitations, this study demonstrates that medical inquiries contain useful information, and that machine learning can extract this information in an automatic way, discovering topics that are judged by medical information specialists as meaningful and valuable. The hope is that this will stimulate mining of medical inquiries, and more generally the use of natural language processing and unsupervised learning in the medical industry.   Interesting future directions are the inclusion of a priori  expert knowledge  while at the same time maintaining the ability to discover new and previously unknown topics, and grouping topics in meta-topics though a clustering hierarchy.  \section{Methods}   Since our dataset comprises real-word medical inquiries, preprocessing is a crucial step to limit the amount of noise in the corpus.    acronyms The corpus contains numerous acronyms: a first step is thus acronym resolution, i.e. substitute a given acronym with its extended form. A dictionary for the most recurring acronyms  is compiled with the help of medical experts. Acronym resolution is performed via a curated dictionary for two reasons. First, the data is too scarce and noisy to train a reliable, custom-made word embedding to learn the acronym meanings from the corpus. Second, in pretrained word embeddings typically there is no suitable representation for the acronym, or the acronym in our corpus is used to indicate something different than in natural language . For example, in our corpus lode does not refer to a vein of a metal, but stands for lack of product effect.    Regular expressions are then used to remove non-informative strings .   Next. text is split into sentences, tokenized and lemmatized using the scispaCy library  . We disable the scispaCy parser; this gives a significant speed-up without affecting the topic discovery outcome.   Finally stopwords  are removed. In addition to standard English stopwords, there are non-standard stopwords which arise from the dataset being composed of medical inquiries e.g. ask, request, email, inquiry, patient, doctor, and product-dependent stopwords, typically the brand and chemical name of the medicinal product to which the inquiries refer to. It is also the case that in the medical inquiry corpus single words bear value, but when combined they are no longer relevant for medical topic discovery.  For example, the word years and old are generally of relevance, but if contiguous  they are no longer significant since this expression simply originates from a medical information specialists logging the age of the patient to which the inquiry refers to.  Another example is the word morning: when appearing alone it is of relevance, but when it is preceded by the word good it loses its relevance since the expression good morning does not bear any significance for medical topic discovery. We compile a short list of stop n-grams  and remove them from the corpus.   To represent medical inquiries, the scispaCy word embedding model en\_core\_sci\_lg-0.2.5 is used. No model re-training or fine-tuning is performed because of the small amount of data and the sparsity problem; since no labels are available, one would need to train a language model on noisy and short text instances which would likely lead the model to forget the semantics learned by the scispaCy model.   For each token, the  scispaCy embedding vector is retrieved; the sentence representation is then obtained simply by calculating the arithmetic average of the vectors representing each token over all tokens belonging to a given sentence.    Even though the overwhelming majority of out-of-vocabulary  words are not of interest for medical topic discovery, a very small  subset of important oov words would be missed if one were to simply use the word2vec model. We thus devise a strategy to overcome this, as described below.   For each product, the most recurring oov words are automatically detected; these words need to be included in the word2vec model so that they can be represented by a vector which accurately captures their meaning. Training a new embedding to include these new terms is not a good approach given the sparseness problem described above.  To overcome this, we combine a definition mapping and embedding strategy.   definition mapping of out-of-vocabulary words Specifically, first each of the relevant oov terms is manually mapped to a short definition; for example, the oov ReDOS is mapped to dose optimization study since ReDOS refers to a dose-optimisation phase 2 study on regorafenib .    definition embedding Then, using the text from these definitions, a meaningful vector representation for the oov words is obtained with the embedding strategy described above . This procedure has two main benefits. First, it does not require any training data nor any training effort. Second, it ensures by construction that the added word vectors are compatible with the word representation model in use.   Pharmaceutical product trade names are oov words of particular interest for medical topic discovery.   Indeed, being able to take into consideration drug trade names is of importance since there is a substantial amount of questions which mention for instance drug interactions.  However, they are are generally not included in the scispaCy model. Thus, a slightly different procedure is used to ensure that all trade names appearing in medical inquiries are added to the model, regardless of them belonging to the most recurring oov words or not.    Luckily, international non-proprietary names  of drugs are included. For instance, the oncology product trade name Stivarga\texttrademark\ is not present, while its corresponding INN  is.  Thus, to automatically detect drug trade names we utilize the scispaCy named entity recognizer  and the scispaCy UmlsEntityLinker as follows.   First, the NER is used to extract entities from the text; then, for each entity, the UmlsEntityLinker performs a linking with the Unified Medical Language System  by searching within a knowledge base of approximately 2.7 million concepts via string overlap as described in Ref. \onlinecite{neumann-2019}. To limit the number of false positive matches we increase the UmlsEntityLinker threshold to 0.85 from the default of 0.7. For each entities that has been successfully linked to UMLS, several information regarding the identified concepts are returned by the UmlsEntityLinker: concept unique identifier , concept preferred name, concept definition, concept aliases, and concept type unique identifier . In particular, the latter defines to which semantic group the linked concept belongs to ; an up-to-date list of semantic type mappings can be found at . A TUI value of T121 indicates that the concept found is a Pharmacologic Substance. Extracting the entities with TUI equal to T121 allows to automatically identify drug trade names.  Each drug trade name is then mapped to the concept preferred name; if that is not present, the concept definition is used; if that is also not present, drug trade name is replaced by to the phrase pharmaceutical medication drug.  Once this mapping is performed, the same embedding strategy used for the other oov words is followed in order to obtain semantically meaningful word vector representations.    The HDBSCAN algorithm starts by defining a mutual reachability distance based on a density estimation; the data is then represented as a weighted graph where vertices are data points and edges have weight equal to the mutual reachability distance between points.    The minimum spanning tree is built, and converted to a hierarchy of connected components via a union-find data structure: starting from an initial cluster containing all points, the data is subsequently split at each level of the hierarchy according to the distance, ultimately returning as many clusters as data points when the threshold distance approaches zero. This cluster hierarchy is commonly depicted as dendogram.   To obtain a meaningful set of clusters, this hierarchy needs to be condensed. The crucial point is to discern - at any given split - if two new meaningful clusters are formed by splitting their parent cluster, or instead the parent cluster is simply loosing points . In HDBSCAN, this decision is governed by the minimum cluster size hyper-parameter : a cluster split is accepted only if both newly formed clusters have at least min\_cluster\_size points. The final clusters are then chosen from this set of condensed clusters by means of a measure of stability as defined by Ref. \onlinecite{campello-2013}.       how we define the hyperparameters The main factor in defining min\_cluster\_size is the number of inquiries for a given product: we want to obtain  100 clusters so that results can be easily analyzed by medical experts.  It is important to point out that min\_cluster\_size does not strictly specify the number of clusters that will be formed, but rather provides to the algorithm an indication regarding the desired granularity, as outlined above. In our case, min\_cluster\_size ranges only between 5 and 10 depending on the number of inquiries. This small range of variation substantially facilitate the hyper-parameter search. Moreover, we noticed that - for approximately the same amount of inquiries and same min\_cluster\_size - the number of returned clusters increases with data variety, where data variety is qualitatively evaluated by manual inspection: for products with more diverse inquiries HDBSCAN tends to return a higher number of clusters, ceteris paribus.   ceteris paribus means all things being equal We utilize the leaf cluster selection method instead of the excess of mass algorithm because the former is known to return more homogeneous clusters .    we use the soft clustering Due to the noise in the dataset, using the standard  HDBSCAN clustering results in a large portion of the dataset  considered as outliers consistently across all products.  To overcome this, we use the soft HDBSCAN clustering, which returns - instead of a  cluster assignment - the probability that an inquiry belongs to a given cluster. We then define a probability threshold under which a point is considered to be an outlier; for all other points above this threshold, we associate them to the cluster with the highest probability through an argmax operation. This probability threshold ranges between  and   and it is chosen such that approximately 10\  of the inquiries are classified as outliers.   As mentioned in the main text, for computational reasons, we project via UMAP to a lower dimensional space before clustering is performed. Specifically, we project to 100 dimensions for products with less than 15,000 inquiries, and to 20 dimensions for products with more than 15,000 inquiries.   Moreover, inquiries longer than 800 characters are also considered as outliers: this is because the text representation  degrades for long sentences. These inquiries are gathered in the outlier cluster and made available to medical experts for manual inspection.   Given a topic, the vector representation for each word in the topic name is calculated; the topic name vector is then obtained by averaging the word vectors of the words present in the topic name. Topics are merged if their similarity - evaluated as cosine similarity between their topic name vectors - is larger than a threshold. Threshold values range between 0.8 and 0.95 depending on the medicinal product considered.    The most popular topic evaluation metrics for topic modelling on long text are UCI  and UMass . However, both UCI and UMass metrics are not good indicators for quality of topics in short text topic modelling due to the sparseness problem. In Ref. \onlinecite{quan-2015}, a purity measure is introduced to evaluate short text topic modelling; however, it requires pairs of short and long documents , and thus it is not applicable here because there is no long document associated to a given medical inquiry. Indeed, evaluation of short text topic modelling is an open research problem .    An additional challenge is the absence of labels. Performing annotations would require substantial manual effort by specialized medical professionals, and would be of limited use because one of the main goals is to discover previously unknown topics as new inquiries are received. The absence of labels precludes the use of the metrics based on purity and normalized mutual information proposed in Ref. \onlinecite{rosenberg-2007}, \onlinecite{huang-2013}, \onlinecite{yin-2014}.    distributional semantic Ref. \onlinecite{aletras-2013} bring forward the valuable idea of using distributional semantic to evaluate topic coherence, exploiting the semantic similarity learned by word2vec models. Topic coherence is assessed by calculating the similarity among the top n-words of a given topic: semantically similar top n-words lead to higher topic coherence. If this might be in general desirable, in the case of discovering medical topics it is actually detrimental: interesting  topics are often characterized by top n-words which are not semantically similar.  For example, a medical topic having as top 2-words rivaroxaban  and glutine is clearly relevant from a medical topic discovery standpoint. However, rivaroxaban and glutine are not semantically similar, and thus the metric proposed in Ref. \onlinecite{aletras-2013} would consider this as a low coherence  topic, in stark contrast with human expert judgment.   Analogous considerations apply to the indirect confirmation measures in Ref. \onlinecite{roeder-2015}: words emerging in novel topics would have rarely appeared before in a shared context. For this reason, we introduce a new measure of topic compactness which takes into account the semantics of the inquiries, and does not require any labeled data. Specifically, we compute the similarity of all inquiries belonging to a given topic with each other , sum the elements of the resulting similarity matrix, and divide by the total number of elements in this matrix. The topic semantic compactness  of topic  reads  where  is the cardinality of topic  ,   is the word vector representing inquiry  , and  is a function quantifying the semantic similarity between inquiry  and , taking values between 0 and 1 . Given the chosen normalization factor ,  and thus  can be directly used as  topic quality score.  The topic compactness maximum  is attained if and only if every sentence  contains exactly the same words. It is important to point out that  automatically takes semantics into account: different but semantically similar medical inquiries would still have high similarity score, and thus would lead  to a high topic semantic compactness, despite these inquiries using different words to express similar content.     add here example of glutine Contrary to Ref. \onlinecite{aletras-2013}, the topic semantic compactness  introduced in Eq. does not artificially penalize novel topics just because they associate semantically different words appearing in the same inquiry. To come back to the previous example, if numerous inquiries in a discovered topic contain the words rivaroxaban and glutine, the topic semantic compactness would be high , regardless from the fact that the top 2-words are not semantically similar since the similarity is evaluated at the inquiry level .  It is also beneficial to evaluate how representative the topic name is for the topic it represents. To this end, we calculate the name saliency  for medical topic  by calculating the similarity of the word vector representing the topic name with the word vectors representing the inquiries in the topic, sum these similarity values, and divide by the total number of inquiries in the topic. This reads  where  is the cardinality of topic  ,  is the word vector representing the name of topic , and  is the vector representing inquiry .  This returns a score  which quantifies how representative  the name is for the topic it represents. As in the case of the topic semantic compactness, the name saliency  takes natively semantics  into account via  in Eq. .   In both Eq.  and Eq. , the cosine similarity is used as similarity measure.  \section{Competing interests} Financial support for the research was provided by Bayer AG. The authors reports a  patent application on Topic Modelling of Short Medical Inquiries submitted on April 21st, 2020 .      {}  \section*{Author Contributions} A.Z. led and thereby ideated and implemented the topic discovery algorithm, and is the main author the manuscript. M.S., C.B., D.R. provided valuable suggestions on the topic discovery algorithm. C.B., O.T., and T.W. designed and implemented the software architecture and data engineering pipeline for the algorithm deployment. T.W., J.V., J.L., S.K., X.M., A.M., D.R., and M.S. provided the in-house resources for the study, supervised the overall project, and provided domain knowledge expertise. All authors revised and commented on the manuscript.  \section*{Data availability} The data used in the study are the proprietary of Bayer AG, and not publicly available.   A.Z. thanks Robin Williams and Nikki Hayward from Bayer\texttrademark\ Medical Information for providing expert insightful and in-depth feedback on the results of topic discovery.     include your own bib file like this:       
"," Deep neural network models represent the state-of-the-art methodologies for natural language processing.  % Here we build on top of these methodologies to incorporate temporal information and model how review data changes with time. % Specifically, we use the dynamic representations of recurrent point process models, % % which encode the nonlinear relations between content and timing of the reviews received by e.g. businesses or services,  % which encode the history of how business or service reviews are received in time,  % to generate instantaneous language models with improved prediction capabilities.  % Simultaneously, our methodologies enhance the predictive power of our point process models by incorporating summarized review content representations.  % % as that encoded in recurrent point process models, and improve the predictive power of these model by incorporating the text representations.  % % Our methodologies resemble that of a hierarchical model, whereupon the temporal information is used as a  representation for the language model.  % We provide recurrent network and temporal convolution solutions for modeling the review content. % We deploy our methodologies in the context of recommender systems,  % as to enhance the expressibility of current models, % effectively characterizing the change in preference and taste of users as time evolves. Source code is available at \cite{source_code}.",483
"  Most authentication methods commonly used today rely on users setting custom passwords to access their accounts and devices. Password-based authentications are popular due to their ease of use, ease of implementation and the established familiarity of users and developers with the method.   However studies show that users tend to set their individual passwords predictably, favoring short strings, names, birth dates and reusing passwords across sites.  Since chosen passwords exhibit certain patterns and structure, it begs the question whether it is possible to simulate these patterns and generate passwords that a human user realistically might have chosen.  Password guessing is an active field of study, until recently dominated by statistical analysis of password leaks and construction of corresponding generation algorithms . These methods rely on expert knowledge and analysis of various password leaks from multiple sources to generate rules and algorithms for efficient exploitation of learned patterns.  On the other hand, in recent years major advances in machine-driven text generation have been made, notably by novel deep-learning based architectures and efficient training strategies for large amounts of training text data. These methods are purely data driven, meaning they learn only from the structure of the input training text, without any external knowledge on the domain or structure of the data. % Deep learning models have recently shown remarkable performance concerning text classification and text generation.  Major advancements in the field have been fueled by the development in several central directions such as:    In this paper we will continue the exploration of data driven deep-learning text generation methods for the task of password-guessing. While some applications to password guessing already show promising results, most frameworks still can not reach or surpass state-of-the-art password generation algorithms. % On the other hand, considering password guessing problems, some popular frameworks  as well as a large body of state-of-art research suggest that advanced deep learning methodologies are still to be further explored.  Ideally, one would attempt to design more efficient password-guessing models aided by neural networks and cutting-edge practices.  Our findings and contributions can be summarized as follows:       In this work we introduced neural dynamic language models of text for review data. We are able to leverage dynamic representations of point process models in language modelling tasks, and augment the point processes with text representations.     . We provide two dynamical models, as well as their extension through two different language models: recurrent and temporal convolution networks.  We showed that our approach improves performance on both content and arrival times prediction, as well as opens the door for dynamic generative language models. Future work includes the implementation of attention mechanisms, as well as the inclusion of neural factorization machines aimed at predicting ratings values.     
","     Password guessing approaches via deep learning have recently been investigated with significant breakthroughs in      their ability to generate novel, realistic password candidates.     In the present work we study a broad collection of deep learning and probabilistic based models in the light of password guessing:      attention-based deep neural networks, autoencoding mechanisms and generative adversarial networks.      We provide novel generative deep-learning models in terms of variational autoencoders exhibiting state-of-art sampling performance,     yielding additional latent-space features such as interpolations and targeted sampling.     Lastly, we perform a thorough empirical analysis in a unified controlled framework over well-known datasets .      Our results not only identify the most promising schemes driven by deep neural networks, but also illustrate the strengths of each approach in terms of generation variability and sample uniqueness.",484
" % 1 page  % Definition and importance of the causality knowledge.  % causality knowledge, as an important knowledge for artificial intelligence  systems, has been proven helpful in many downstream tasks, especially in the NLP domain. % % In this work, we follow ConceptNet and COPA to focus on the causal relations between daily events. % However, due to the lack of a high-quality and large-scale causality knowledge resource, the application of causality knowledge in downstream tasks is still limited.  Humans possess a basic knowledge about facts and understandings for commonsense of causality in our everyday life.  For example, if we leave five minutes late, we will be late for the bus; if the sun is out, it's not likely to rain; and if we are hungry, we need to eat. %Causality is an important commonsense reasoning that humans use all the time,  Such causality knowledge has been shown to be helpful for many NLP tasks. Thus, it is valuable to teach machines to understand causality.   Causal relations in the commonsense domain are typically contributory and contextual.  %   By contributory\footnote{The other two levels are absolute causality  and conditional causality , which commonly appear in the scientific domain rather than our daily life.}, we mean that the cause is neither necessary nor sufficient for the effect, but it strongly contributes to the effect.  By contextual, we mean that some causal relations only make sense in a certain context. The contextual property of causal relations is important for both the acquisition and application of causal knowledge. For example, if some people tell the AI assistant  ``they are hungry'' in a meeting, a basic assistant may suggest them to order food because it has the knowledge that `being hungry' causes `eat food'. A better assistant may suggest ordering food after the meeting because it knows that the causal relation between `being hungry' and `eat food' may not be plausible in the meeting context.  % \ye{I made small adaptation to this paragraph } % For example, if a person is in the middle of a meeting, he/she may tell the AI assistant  that he/she is hungry, a good AI assistant may suggest him/her to eat some food because it has the knowledge that `being hungry' cause `eat food', but an extraordinary AI assistant may suggest that ``I can help order some food for you to eat after the meeting'' because it knows that the causal relation between `being hungry' and `eat food' may not be plausible in the context of a meeting. Without understanding the contextual property of causal knowledge, achieving such a level of intelligence would be challenging.  To help machines better understand the causality commonsense, many efforts have been devoted into developing the causality knowledge bases.  For example, ConceptNet and ATOMIC leverage  human-annotation to acquire small-scale but high-quality causality knowledge. After that, people try to leverage linguistic patterns  to acquire causality knowledge from textual corpus. However, causality knowledge, especially those trivial knowledge for humans, are rarely formally expressed in documents, a pure text-based approach might struggle at covering all causality knowledge. Besides that, none of them take the aforementioned contextual property of causal knowledge into consideration, which may restrict their usage in downstream tasks.     % Causal relations in the commonsense domain are typically contributory and contextual.  % By contributory\footnote{The other two levels of causality are absolute causality  and conditional causality , which commonly appear in the scientific domain rather than our daily life.}, we mean that the cause is neither necessary nor sufficient for the effect, but it strongly contributes to the effect.  % By contextual, we mean that some causal relations only make sense in a certain context. % The contextual property of causal relations is important for both the acquisition and application of causality knowledge. % For example, if some people tell the AI assistant  ``they are hungry'' in a meeting, a basic assistant may suggest them to order food because it has the knowledge that `being hungry' causes `eat food'. A better assistant may suggest ordering food after the meeting because it knows that the causal relation between `being hungry' and `eat food' may not be plausible in the meeting context.  % Without understanding the contextual property of causality knowledge, achieving such a level of intelligence would be challenging.  %       %      %     } %      %      % \end{table}     % % limitation of existing acquisition methods % Conventional approaches  \ye{i think this should be more elaborated. maybe give an example?} However, two drawbacks of these approaches significantly limit their usage in downstream tasks: %     In this paper, we propose to ground causality knowledge into the real world and explore the possibility of acquiring causality knowledge from visual signals .  By doing so, we have three major advantages:  Videos can be easily acquired and can cover rich commonsense knowledge that may not be mentioned in the textual corpus;  Events contained in videos are naturally ordered by time. As discussed by, there exists a strong correlation between temporal and causal relations, and thus such time-consecutive images can become a dense causality knowledge resource;  Objects from the visual signals can act as the context for detected causality knowledge, which can remedy the aforementioned lack of contextual property issue of existing approaches.   To be more specific, we first define the task of mining causality knowledge from time-consecutive images and propose a high-quality dataset .  To study the contextual property of causal relations, for each pair of events, we provide two kinds of causality annotations: one is the causality given certain context and the other one is the causality without context.  Distribution analysis and case studies are conducted to analyze the contextual property of causality. An example from Vis-Causal is shown in Figure, where the causal relation between ``dog is running'' and ``blowing leaves'' only makes sense when the context is provided because the dog is running on the leaves, so its high speed and quickly-moved pow cause the leaves blow around. Without the context  ``leaves on the ground'', this causal relation is implausible. After that, we propose a Vision-Contextual Causal  model, which can effectively leverage both the pre-trained textual representation and visual context to acquire causality knowledge and can be used as a baseline method for future works. Experimental results demonstrate that even though the task is still challenging, by jointly leveraging the visual and contextual representation, the proposed model can better identify meaningful causal relations from time-consecutive images. To summarize, the contributions of this paper are three-fold:  We formally define the task of mining contextual causality from the visual signal;  We present a high-quality dataset Vis-Causal;  We propose a Vision-Contextual Causal  model to demonstrate the possibility of mining contextual causality from the vision signal. % Experimental results prove that considering context is crucial for understanding causality and representing the visual context with textual representation is helpful. % Further analysis shows that the proposed task is still challenging for current models, and we may need to consider injecting external knowledge to better understand the videos and acquire causality knowledge. % \ye{there's no real reference to the text part in the into, NLP people might think it's not suitable for ACL? maybe add that the models use some description and objects which are represented in a textual form}   %   %    The present work illustrates various deep learning password generation techniques. Conducting a thorough unified analysis we discuss password-matching capabilities, variability and quality of sampling and robustness in training. On one hand, we bridge and extend previous methods based on attention schemes, GANs and Wasserstein autoencoding; on the other hand, we provide a promising novel approach based on Variational Autoencoders that allows for efficient latent space modeling and further sampling mechanisms. Lastly, we hope our work will facilitate and provide benchmark lines for further deep learning and ML practitioners interested in the field of password guessing.  In terms of further investigation, the application of deep learning techniques to password generation poses further intriguing questions on the interplay between classical probabilistic methods and neural networks, where one would ultimately hope to construct more efficient and reliable domain-inspired password representation schemes - e.g. based on carefully crafted fragmentations.   
","  Causality knowledge is crucial for many artificial intelligence systems. Conventional textual-based causality knowledge acquisition methods typically require laborious and expensive human annotations. As a result, their scale is often limited. Moreover, as no context is provided during the annotation, the resulting causality knowledge records  typically do not take the context into consideration. To explore a more scalable way of acquiring causality knowledge, in this paper, we jump out of the textual domain and investigate the possibility of learning contextual causality from the visual signal. Compared with pure text-based approaches, learning causality from the visual signal has the following advantages:  Causality knowledge belongs to the commonsense knowledge, which is rarely expressed in the text but rich in videos;  Most events in the video are naturally time-ordered, which provides a rich resource for us to mine causality knowledge from;  All the objects in the video can be used as context to study the contextual property of causal relations. In detail, we first propose a high-quality dataset Vis-Causal and then conduct experiments to demonstrate that with good language and visual representation models as well as enough training signals, it is possible to automatically discover meaningful causal knowledge from the videos. Further analysis also shows that the contextual property of causal relations indeed exists, taking which into consideration might be crucial if we want to use the causality knowledge in real applications, and the visual signal could serve as a good resource for learning such contextual causality. Vis-Causal and all used codes are available at: \url{https://github.com/HKUST-KnowComp/Vis_Causal}. % In detail, we first identify events from the videos, which are represented with natural sentences, and then leverage the visual signal to predict the contextual causal relations among these events.     % In this work, we mimic how human beings learn causality and explore the possibility of acquiring causality knowledge with visual signal. % To do so, we first define the task of mining contextual causality knowledge from visual signals, which aims at evaluating models' abilities to identify causal relation given certain visual context, and then employ the crowd-sourcing to annotate a high-quality dataset Vis-Causal. % On top of that, we propose a Vision-Contextual Causal  model that can utilize the images as context to better acquire causality knowledge. % Different from existing \revisehm{causality knowledge acquisition works}, \revisehm{to the best of our knowledge, }the proposed solution \revisehm{is the first one that }has the potential to preserve contextual property  of causal relations.",485
"  % The advent of deep learning techniques has dramatically improved accuracy of speech recognition models . Deep learning techniques first saw success by replacing the Gaussian Mixture Model  of the Acoustic Model  part of the conventional speech recognition systems  with the Feed-Forward Deep Neural Networks  , further with Recurrent Neural Network  such as the  Long Short-Term Memory  networks  or Convonlutional Neural Networks . In addition to this, there have been improvements in noise robustness by using models motivated by auditory processing , data augmentation techniques , and beam-forming . Thanks to these advances, voice assistant devices such as Google Home  and Amazon Alexa have been widely used at home environments.  Nevertheless, it was not easy to run such high-performance speech recognition systems  on devices largely because of the size of the Weighted Finite State Transducer   handling the lexicon and the language model.  Fortunately, all-neural end-to-end  speech recognition systems were introduced which do not need a large WFST or an n-gram Language Model   . These complete end-to-end systems have started surpassing the performance of the conventional WFST-based decoders with a very large training  dataset  and a better choice of target unit  such as Byte Pair Encoded  subword units.  In this paper, we provide a comprehensive review of the various components and algorithms of an end-to-end speech recognition system. In Sec., we give a brief overview of the various neural building blocks of an E2E Automatic Speech Recognition  model. The most popular E2E ASR architectures are reviewed in Sec.. Additional techniques used to improve the performance of E2E ASR models are discussed in Sec.. Techniques used for compression and quantization of the all-neural E2E ASR models are covered in Sec.. Sec. gives a summary of the paper. % % %# Data augmentation and overfitting   In this paper, we explore the possibility of learning causality knowledge from time-consecutive images. To do so, we first formally define the task and then create a high-quality dataset Vis-Causal , which contains 4,000 image pairs, 23,558 event pairs, and causal relation annotations under two settings. On top of the collected dataset, we propose a Vision-Contextual Causal  model to demonstrate that with the help of strong pre-trained textual and visual representations and careful training, it is possible to directly acquire contextual causality from visual signals. Further analysis shows that even though VCC can outperform all baseline methods, it is still not perfect. As the visual signal could serve as an important causality knowledge resource, we will keep exploring how to better acquire causal knowledge from the visual signal  in the future.    effectively leverage both the pre-trained textual representation and visual context to learn causality from visual signals, which can also preserve the contextual property of extracted causality knowledge.   Experiments and analysis demonstrate the importance of both the pre-trained textual representation and visual context.   Experiment results show that the task is challenging for all current models.   Further analysis also proves our observation that context is crucial for understanding causal relations.   Further analysis also suggests the importance of leveraging external knowledge for better causal relation extraction. Both the dataset and code will be released to encourage research on the causality acquisition.  
","   In this paper, we review various end-to-end automatic speech recognition   algorithms and their optimization techniques for on-device applications.   Conventional speech recognition systems comprise a large number of discrete   components such as an acoustic model, a language model, a pronunciation model,    a text-normalizer, an inverse-text normalizer, a decoder based on a Weighted Finite State   Transducer , and so on. To obtain sufficiently high speech recognition   accuracy  with such conventional speech recognition systems, a very large   language model  is usually needed. Hence, the corresponding   WFST size becomes enormous, which prohibits their on-device implementation. Recently, fully neural network end-to-end speech recognition algorithms have been   proposed. Examples include speech recognition systems based on  Connectionist Temporal Classification , Recurrent Neural Network Transducer , Attention-based Encoder-Decoder models , Monotonic   Chunk-wise Attention ,    transformer-based speech recognition systems, and so on. These fully neural   network-based systems require much smaller memory footprints compared to   conventional algorithms, therefore their on-device implementation has become   feasible. In this paper, we review such end-to-end speech recognition models.   We extensively discuss their structures, performance, and advantages compared   to conventional algorithms.",486
"   Intuitively, if you see a lot of examples of natural language questions about TV shows, it ought to also help understand similar syntax in questions about movies, or in questions that refer to both movies and TV shows together. Ideally, the training examples from the related domain should strictly improve performance, not hurt it. %[nkscales] FYI -- I reverted the below sentence to close to its original form to better match the tone of the first paragraph. If the sentence still doesn't sound right, let me know. If you can satisfy that property, then you have at least a chance at eventually achieving arbitrarily robust performance across a range of domains, given sufficient training data in aggregate. %You need to satisfy that property in order to at have a shot at achieving arbitrarily robust performance across a range of domains, given simply sufficient data across those domains in aggregate.  How and to what extent current machine learning  approaches can be made to robustly solve natural language understanding  at the scale of arbitrary natural language across domain -- with or without access to large quantities of training data -- remains, however, an open question.  On one hand, research into the scaling behavior of deep learning systems has found generalization loss to decrease reliably with training size and model size in a power law or related logarithmic relationship across a range of architectures and tasks, from image classification with convolutional neural networks~ to language modeling with Transformers~. Recent results in an i.i.d.\ setting show this pattern to persist across many orders of magnitude, with no established upper limit~.  At the same time, it has been shown that current ML systems continue to struggle to achieve robust performance in classes of tasks that require compositional generalization  % [nikola] IMO this part of the sentence does not contribute much. I suggest skipping it and only keeping the citation. %-- that is, tasks in which known building blocks must be composed at test time in ways unseen during training ~ -- an ability that has been argued to be crucial to robust language understanding~.  In this paper, we combine these two lines of research by investigating the effect of training size on error rates in the context of a compositional task. Specifically, we derive a suite of extended datasets based on the Compositional Freebase Questions  semantic parsing benchmark~. We then use the compositional structure of each example to construct controlled experiments that measure the error rates when increasing training size in settings requiring compositional generalization and in settings simulating scaling to a broader scope of natural language. We apply these experiments to analysis of Transformers~ in a setting of fixed computational cost -- that is, of fixed model size and fixed training steps -- and demonstrate key limits to their scalability in this setting.  Our contributions are the following:    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    In this paper, we reviewed various end-to-end all neural automatic speech recognition systems and their optimization techniques for on-device applications. On-device speech recognition has huge advantages compared to the server-side ones in terms of user privacy, operation without internet, server-cost, and latency.  To operate speech recognition systems on embedded processors, we need to  consider several factors such as recognition accuracy, computational cost, latency,  and the model size. We compared pros and cons of different neural network components such as Long Short-Term Memory , Convolutional Neural Network ,   and attention mechanism. We explained and compared different end-to-end neural speech recognition architectures such as  a stack of LSTM layers with the Connectionist Temporal Classification  loss ,  Recurrent Neural Network-Transformer , attention-based models, and models based on Monotonic Chunk-wise Attention  . Further improvement is achieved by combining a streaming model with a low-latency non-streaming model,  by applying shallow-fusion with a Language Model , and by applying spell correction using a list of named entities . We also discussed several model compression techniques including quantization, singular value decomposition, pruning, and knowledge distillation.  These recent advances in all neural end-to-end speech recognition made it possible to commercialize all neural on-device end-to-end speech recognition systems  .                           
"," We present \starcfq{} : a suite of large-scale datasets of varying scope based on the \cfq{} semantic parsing benchmark, designed for principled investigation of the scalability of machine learning systems in a realistic compositional task setting. Using this suite, we conduct a series of experiments investigating the ability of Transformers to benefit from increased training size under conditions of fixed computational cost. We show that compositional generalization remains a challenge at all training sizes, and we show that increasing the scope of natural language leads to consistently higher error rates, which are only partially offset by increased training data. We further show that while additional training data from a related domain improves the accuracy in data-starved situations, this improvement is limited and diminishes as the distance from the related domain to the target domain increases.",487
"  Designing a robust spoken language identification  algorithm is very important for the wide usability of multi-lingual speech applications . With the resurgence of deep model learning, the SLID performance has been significantly improved by current supervised deep feature and classifier learning algorithms . In most algorithms, there is an implicit assumption that the training and testing data sets share a similar statistical distribution property. However, due to the complex acoustic and linguistic patterns, it is often the case that testing data set and training data set are from quite different domains . An intuitive solution is to do domain adaptation, i.e., to align the statistical distribution of testing data set to match that of training data set thus to improve the performance. Although with large collected labeled testing data set, it is not difficult to obtain a domain transfer function with supervised learning algorithms, in real applications, the label information of testing data set is often unknown. Therefore, in this study, we mainly focus on a more preferable and challenge situation, i.e., unsupervised domain adaptation.  Unsupervised domain adaptation algorithms have been proposed for speaker verification, e.g., probabilistic linear discriminant analysis  parameter adaptation  , feature-based correlation alignment  , and feature-distribution adaptor for different domain vectors . However, in these algorithms, most of them were proposed for speaker verification under the framework of the PLDA . As our experiments showed that the PLDA framework does not perform well for our SLID task due to the less of discriminative power of the modeling. Instead, in most SLID algorithms, a multiple mixture of logistic regression  model is used as a classifier model. Moreover, due to the complex shapes of the distributions in training and testing domains, it is difficult to guarantee the match between different domain distributions.  The purpose for domain adaptation is to reduce the domain discrepancy. Recently, optimal transport  has been intensively investigated for domain adaptation in machine learning field . The initial motivation for OT in machine learning is to find an optimal transport plan to convert one probability distribution shape to another shape with the least effort . By finding the optimal transport, it naturally defines a distance measure between different probability distributions. Based on this property, the OT is a promising tool for domain adaptation and shape matching in image processing, classification, and segmentation . In this paper, inspired by the OT based unsupervised adaptation , we propose an unsupervised neural adaptation framework for cross-domain SLID tasks. Our main contributions are:  We propose an unsupervised neural adaptation model for SLID to deal with domain mismatch problem. In the model, we explicitly formulate the adaptation in transformed feature space and classifier space in order to reduce the probability distribution discrepancy between source and target domains.  We coincide the OT distance metric in measuring the probability distribution discrepancy, and integrate it into the network optimization in order to learn the adaptation model parameters. Based on the adaptation model, significant improvements were obtained. %The remainder of the paper is organized as follows. Section  introduces the background and fundamental theory of . Section  describes the implementation details of . Section  presents the SLID experiments and results based on the proposed framework by analyzing the contribution of the CSA model in detail. Section  presents the discussion of the results and conclusion of the study.      We proposed an approach detecting hate speech in internet memes multimodally, i.e. considering visual and textual information holistically. We took part in the Hateful Memes Challenge and placed third out of 3,173 participants. Our approach utilizes a pre-trained VisualBERT , fine-tuned on an expanded train dataset, finally applying Majority Voting over the 27 best models. Our approach achieves 0.811 AUROC with an accuracy of 0.765 on the challenge test set, which is a considerable result but also shows that we are still far from the accuracy of human judgement.     \small 
"," Due to the mismatch of statistical distributions of acoustic speech between training and testing sets, the performance of spoken language identification  could be drastically degraded. In this paper, we propose an unsupervised neural adaptation model to deal with the distribution mismatch problem for SLID. In our model, we explicitly formulate the adaptation as to reduce the distribution discrepancy on both feature and classifier for training and testing data sets. Moreover, inspired by the strong power of the optimal transport  to measure distribution discrepancy, a Wasserstein distance metric is designed in the adaptation loss. By minimizing the classification loss on the training data set with the adaptation loss on both training and testing data sets, the statistical distribution difference between training and testing domains is reduced. We carried out SLID experiments on the oriental language recognition  challenge data corpus where the training and testing data sets were collected from different conditions. Our results showed that significant improvements were achieved on the cross domain test tasks.",488
" In traditional ad-hoc retrieval, queries and documents are represented by variants of bag-of-words representations. This leads to the so called vocabulary mismatch problem: when a query contains words that do not exactly match words in a relevant document, the search engine may fail to retrieve this document. Query expansion and document expansion, the methods of adding additional terms to the original query or document, are two popular solution to alleviate the vocabulary mismatch problem.   Document expansion has been shown to be particularly effective for short text retrieval and language-model based retrieval . Most of the existing works in document expansion are unsupervised: using information from the corpus to augment document representation, e.g., retrieval based  and clustering based , or using external information to augment document representation .  Recently, \citet{nogueira2019DE} proposed a new approach to document expansion, which is based on a popular generative sequence-to-sequence model  in NLP, transformers . It leverages supervision to train the model to predict expansion terms conditional on each document. The paper has shown significant improvement on passage  datasets, when trained in-domain. In this paper, we follow this line of supervised neural document expansion approach and explore its performance on standard IR benchmarking dataset. Our main contributions are: 1. Adapting the method to unlabeled datasets by exploring transfer learning and weak-supervision approaches. 2. Adapting the method to traditional IR datasets, where a large number of long documents are present.       In this work, we propose a simple yet effective set of techniques to help detect hate speech in a unique labeled dataset of high quality multimodal memes from Facebook AI. The goal is to identify hate speech using a multimodal model, while also being robust to the ""benign confounders"" that cause the binary label indicating whether a meme is hateful to flip.  We experiment with a number of large pre-trained Transformer based architectures and fine-tune both single stream state-of-the-art models such as VL-BERT, VLP and UNITER and dual stream models such as LXMERT. We compare their performance to the baselines provided by  and show all of the single-stream models significantly outperform these. We justify our choice for these transformers architectures by the possible advantages coming from the fact they were pre-trained on a wide spectrum of datasets from different domains. We also propose and adapt a novel bidirectional cross-attention mechanism to couple inferred caption information with the meme text obtained through optical character recognition. This addition achieves higher classification accuracy in labeling memes as hateful. Furthermore we show deep ensembles, a simple yet very powerful trick can improve on single model predictions by a significant margin. As expected, we find training these large architectures from scratch performs poorly on a small set of examples such as the Hateful Memes dataset. However, we also find the choice of pre-training datasets also matters in terms of domain similarity to the fine-tuning dataset.   We conclude that although the multimodal models are becoming increasingly sophisticated, there is still a large gap when comparing to human performance. This leaves considerable room for developing new algorithms to deal with multimodal understanding.  \medskip    \small     \clearpage 
","     Recently, \citet{nogueira2019DE} proposed a new approach to document expansion based on a neural Seq2Seq model, showing significant improvement on short text retrieval task. However, this approach needs a large amount of in-domain training data.     In this paper, we show that this neural document expansion approach can be effectively adapted to standard IR tasks, where labels are scarce and many long documents are present.",489
"  A speech signal can be considered as a variable-length temporal sequence, and many features have been used to characterize its pattern. Short-term spectral features are used extensively because of the quasi-stationary property of the speech signal. After short-term processing, the raw waveform is converted into a two-dimensional~ matrix of size , where  represents the frequential feature dimension related to the number of filter coefficients, and  denotes the temporal frame length related to the utterance duration.  For a text-independent speaker verification~ system, the main procedure is to extract the fixed-dimensional speaker representation from the variable-length spectral feature sequence. One of the widely used spectral features is the Mel-frequency cepstral coefficient ~. Typically, MFCC feature vectors from all the frames are assumed to be independent and identically distributed. They can be projected on the Gaussian components or phonetic units to accumulate statistics over the time axis and form a high-dimensional supervector. Then, a factor analysis-based dimension reduction is performed to generate a fixed-dimensional low rank i-vector representation. Recently, with the progress of deep learning, many approaches directly train a deep neural network~ to distinguish different speakers. Systems comprising of x-vector speaker embedding followed by a probabilistic linear discriminant analysis~ have shown state-of-the-art performances on multiple TISV tasks. In the x-vector system, a time-delay neural network~ followed by statistic pooling over the time axis is used for modeling the long-term temporal dependencies from the MFCC features.              \end{figure*}  For the i-vector, x-vector, and many other speech modeling methods, the feature matrix  is viewed as a multi-channel 1-D time series. Although the duration  may vary among the utterances, the feature dimension  must be a fixed value. In this paper, we consider the feature matrix as a single-channel 2-D image. From this new perspective, the spectral feature is viewed as a ``picture"" of the sound, and a 2-D CNN  is implemented in the same way as traditional image recognition paradigms. This kind of process brings a type of flexibility, i.e., the size of the input ``image,"" including the width  and the height , can be arbitrary numbers.  In other words, a 2-D CNN trained with a 64-dimensional spectrogram could potentially also process a spectrogram with 48 dimensions.   We aim to utilize the flexibility of the 2-D CNN to tackle the mixed-bandwidth~ joint modeling problem. Currently, there are many devices and equipment that capture speech data in different sampling rates, thus solving the sampling rate mismatch problem has become a research topic in the speech community. The traditional way to accomplish this goal is to train a specific model for every target bandwidth since the sampling rates are different . An alternative solution is to uniformly downsample the wideband~ speech data or extend the bandwidth of a narrowband~ data, so that they can be combined .  In this paper, we present a unified solution to solve the MB joint modeling problem. The key idea is to view the NB spectrogram as a sub-image of the WB spectrogram. The major contributions of this work are summarized as follows.      {We have proposed \modelfull, a paradigm for learning object-centric representations from vision and language.} Experiments on Shop-VRB-Simple and PartNet-Chairs show that language significantly contributes to learning better representations. This behavior is consistent across two unsupervised image segmentation models.    {Through systematic studies, we have also shown how \model helps models to learn object representations that encode conceptual information, and are useful for downstream tasks such as retrieval, visual reasoning, and referring expression comprehension.}         \clearpage      \clearpage   
"," This paper proposes a unified deep speaker embedding framework for modeling speech data with different sampling rates. Considering the narrowband spectrogram as a sub-image of the wideband spectrogram, we tackle the joint modeling problem of the mixed-bandwidth data in an image classification manner. From this perspective, we elaborate several mixed-bandwidth joint training strategies under different training and test data scenarios. The proposed systems are able to flexibly handle the mixed-bandwidth speech data in a single speaker embedding model without any additional downsampling, upsampling, bandwidth extension, or padding operations. We conduct extensive experimental studies on the VoxCeleb1 dataset. Furthermore, the effectiveness of the proposed approach is validated by the SITW and NIST SRE 2016 datasets.",490
"   % Automatic speech recognition  systems are typically trained on vast quantity of paired audio and text data to attain competitive performance. Obtaining these paired data requires substantial human annotation efforts and is often time-consuming, expensive and error-prone. With the emerging popularity of end-to-end ASR models, the need for large amounts of training data is more demanding than the conventional hybrid-based ASR systems. For this purpose, semi-supervised learning  is often investigated for speech recognition, where a model is trained using a finite amount of labeled data and a much larger amount of unlabeled data.   In the long history of semi-supervised learning  in speech recognition, self-training approach  and knowledge distillation , or known as teacher-student model training  are the two commonly used SSL methods. Recent success of representation learning enables a new approach towards leveraging unlabeled data. In natural language processing community,  BERT, ELMo, XLNet , GPT   and its follow-ups are classical examples of representation learning. The key philosophy of representation learning is based on using self-supervised learning, where we obtain `free' labels from unlabeled data and train them in a supervised manner via some proxy tasks. In the context of BERT, two proxy tasks are defined including masked language model task and two-sequence prediction task. These proxy tasks are designed to force the learning of a robust, meaningful representation.  After the representation has been learned, a downstream task model is then trained using labeled data with the learned representation. Optionally, the representation learning block and downstream task block can be fine-tuned together.   Learning efficient speech representation can be traced back to restricted Boltzmann machine , which allows pre-training on large amounts of unlabeled data before training the deep neural network speech models.  More recently, speech representation learning has drawn increasing attention in speech processing community and has shown promising results in semi-supervised speech recognition .  The design of proxy tasks in learning speech representation can be categorized into two types. The first type is based on contrastive loss and has been applied to speech representation such as wav2vec and its variants . The model is trained to learn representations containing information that most discriminates the future or masked frame from a set of negative samples via contrastive loss.  The second type is based on reconstructive loss. The proxy task for these representation learning methods is to reconstruct temporal slices of acoustic features based on contextual information. These reconstruction tasks can be defined as autoregressive reconstruction, or masked-based reconstruction. APC  and its follow-up  are examples to use autoregressive reconstruction loss.  In many state-of-the-art pretrained language model task, masked-based prediction is adopted in the proxy tasks such as BERT  and XLNet .  In speech, instead of prediction, we randomly mask temporal slices of acoustic features and attempt to reconstruct them .  Orthogonal to the contrastive-/reconstructive-loss based speech representation learning, vector-quantized speech representations have been proposed. One motivation to apply vector quantization  is that enforcing quantization can lead to better linguistic unit discovery  due to the discrete nature of phonetic units. In VQ-APC , the authors use VQ as a way to limit model capacity and control information needed in encoding representation. In VQ-wav2vec  and wav2vec 2.0 , the author use VQ to facilitate direct application of BERT and other NLP algorithms.  In this paper, we introduce DeCoAR 2.0, a Deep Contextualized Acoustic Representation with vector quantization. We take inspirations from many recent advances in speech representation learning, and propose multiple improvements over vanilla DeCoAR. We summarize the contributions of this paper as follows:   % The rest of the paper is organized as follows. Section gives a brief overview of our previous DeCoAR method and related work in vector quantized speech representation learning. Section describes the proposed DeCoAR 2.0 approach. Experimental results on semi-supervised speech recognition are presented in Section followed by conclusion in Section.   % Learning robust speech representation has been exploited in recent years. Among these approaches, wav2vec 2.0  uses 10 minutes of labeled data with 53k hours of unlabeled data to achieve a word error rate  of 5.2/8.6 on LibriSpeech benchmark. The model relies on a diverse codebook learnt to correlates the underlying speech units to speech representations via the contrastive loss. However, the contrastive loss formulation can result in several locally optimal codebooks, for exmaples, acoustic condition-sensitive codebooks: where the model can easily optimized by assign acoustic condition  to the the codebooks, and temporally invariant codebooks: where the model assigns specific codes to fixed temporal locations.   %Furthermore, the codes at each time step the model select right after their feature encoder hardly contained meaningful phonetic information. So their contrastive approach might not generalize well to all datasets, espically the real world data consisted a lot of nausence factor like noise, different recording environment.   % A simple workaround could be using frame reconstruction as objective, the network allows a flow of information from the input feature back to the the latent space to preserve meaningful information in the codes, helping mitigatate the codebook learning problems in contrastive loss as discussed above. And compared to simple reconstruction where we utilize all the information available  to achieved maximal prediction while those information are less relevant to ASR. By utilizing the VQ layer, the model is able to keep the representation from those unwanted information flowing.     % Automatic speech recognition  systems are typically trained on vast quantity of paired audio and text data to attain competitive performance. Obtaining these paired data requires substantial human annotation efforts and is often time-consuming, expensive and error-prone. With the emerging popularity of end-to-end ASR models, the need for large amounts of training data is more demanding than the conventional hybrid-based ASR systems. For this purpose, semi-supervised learning  is often investigated for speech recognition, where a model is trained using a finite amount of labeled data and a much larger amount of unlabeled data.   % In the long history of SSL in speech recognition, self-training approach  is the most commonly used approach. In self-training methods, a `seed' ASR model is trained using paired audio/text data. The resulting model is then applied to transcribe the unlabeled audio data. The resulting hypotheses, combined with different data selection criteria, are treated as `pseudo-labels' and added to the original labeled dataset to retrain a new model. Simple in concept, self-training works well in practice with one major caveat - the pseudo-label injects systematic bias introduced by the seed model. To alleviate this, careful confidence calibration with system combinations are often used . Another family of SSL is based on knowledge distillation , or teacher-student model training , and is mostly applied to acoustic model training in hybrid-based ASR. In these setups, a teacher model  generates frame-wise soft label instead of hard label, and a student model is trained on the soft labels via KL divergence loss instead of a standard cross-entropy loss based on forced alignment. The knowledge distillation based SSL partially mitigates the systematic bias but is rarely being investigated towards sequence-level loss  or end-to-end ASR systems.    % Recent success of efficient representation learning, in particular in natural language processing , enables a new approach towards leveraging unlabeled data. Classical examples of representation learning for NLP include BERT, ELMo, XLNet , GPT and its follow-ups , to name but a few.  The key philosophy of representation learning is based on self-supervised learning, where we obtain `free' labels from unlabeled data and train them in a supervised manner via some proxy tasks. In the context of the well-known BERT, two proxy tasks are defined including masked language model task and two-sequence prediction task. These proxy tasks are defined in a way to force the learning of a robust, meaningful representation.  A downstream task is then trained on the labeled data with the learned representation. Optionally, the representation learning block and downstream task can be fine-tuned together.     % This paper presents DeCoAR 2.0, a follow-up on DeCoAR . We take inspiration from many recent advances in speech representation learning, and propose multiple improvements over vanilla DeCoAR. We summarize the contributions of this paper as follows: %   % The rest of the paper is organized as follows. Section gives an overview on related work in speech representation learning, and a brief recap of our previous DeCoAR method. Section describes the proposed vector quantized DeCoAR approach. Experimental results on semi-supervised speech recognition are presented in Section followed by conclusion in Section.   % In this work, we propose an improved speech representation learning paradigms towards semi-supervised speech recognition based on our previous work .   % Current state-of-the-art models for speech recognition require vast amounts of transcribed audio data to attain good performance. In particular, end-to-end ASR models are more demanding in the amount of training data required when compared to traditional hybrid models. While obtaining a large amount of labeled data requires substantial effort and resources, it is much less costly to obtain abundant unlabeled data.   % For this reason, semi-supervised learning  is often used when training ASR systems. Recently, self-supervised learning閳ユ攣 paradigm that treats the input itself or modifications of the input as learning targets閳 has obtained promising results. Those self-supervised speech representation can be fall into main categories: Contrastive Predictive Coding  incorporates contrastive objective to learn representations containing information that  most discriminates the future or masked frame from a set of negative samples. Another approach is Autoregressive Predictive Coding  , which tries to directly predict or reconstruct the frame based on context.  % More recently, vector-quantized representations of audio data has drawn increasing attention in speech processing . The motivation is that enforcing the quantization leads to a better representation for acoustic unit discovery due to the discrete nature of phonetic units. VQ-APC  also try to exactly quantified of information , to control the capacity of the models. And the use of vector quantization limited capacity are forced to retain information to achieve maximal prediction.   % Despite the success of the wav2vec 2.0 model , the model relies on a diverse codebook learnt to correlates the underlying speech units to speech representations via the contrastive loss. However, the codes at each time step the model select right after feature encoder hardly contained meaningful phonetic information. More importantly, contrastive loss formulation can result in several locally optimal codebooks. A few highly probable optima observed were acoustic condition-sensitive codebooks: where the model can easily optimized by assign acoustic condition  to the the codebooks, and temporally invariant codebooks: where the model assigns specific codes to fixed temporal locations to enable a good contrastive loss. Hence, the codebook learning methodology using contrastive loss might not generalize well to all datasets, espically the real world data consisted a lot of nausence factor like noise, different recording environment.    % A simple solution could be to enforce the codes to explicitly carry information about the input features in the process. Using frame reconstruction as objective, the network allows a flow of information from the input feature back to the the latent space to preserve meaningful information, helping mitigatate the codebook learning problems in contrastive loss as discussed above. Thus, we propose an novel self-supervised model that learns vector quantized deep transformer acoustic representations based on frames reconstruction. Since simple reconstruction utilize all the information available  to achieved maximal prediction while those information are less relevant to ASR. And by utilizing the VQ layer to limit those unwanted information flow into final representation, Vector Quantized Deep Contextualized Acoustic Representations  are able to achieve much better representation that's better suited for semi-supervised ASR tasks. By using a large amount of unlabeled data, and then applies these representations to ASR tasks using a limited amount of labeled data. In our implementation, we perform acoustic representation learning using deep transformer and a training objective that minimizes the reconstruction error of a temporal slice of filterbank features given context frames. After pre-training, we fix these parameters and add output layers with connectionist temporal classification  loss for the ASR task. We only train the small ASR model instead of fine-tuning for computing-efficiency. Our approach showed that supervision with 10 hours of labeled data on DeCoAR 2.0 achieves performance on par with training on all 960 hours directly.  In this work, we focused on the data-driven classification of chemical reactions with natural language processing methods and on the use of their embedded information to design reaction fingerprints. Our transformer-based models were able to learn the classification schemes using a broad set of chemical reactions as ground-truth, labeled by a  commercially available reaction classification tool. With the BERT classifier, we match the rule-based classification with an accuracy of 98.2\.\
","  Recent success in speech representation learning enables a new way to leverage unlabeled data to train speech recognition model. In speech representation learning, a large amount of unlabeled data is used in a self-supervised manner to learn a feature representation. Then a smaller amount of labeled data is used to train a downstream ASR system using the new feature representations. Based on our previous work DeCoAR \cite{ling2020deep} and inspirations from other speech representation learning, we propose DeCoAR 2.0, a Deep Contextualized Acoustic Representation with vector quantization. We introduce several modifications over the DeCoAR: first, we use Transformers in encoding module instead of LSTMs; second, we introduce a vector quantization layer between encoder and reconstruction modules; third, we propose an objective that combines the reconstructive loss with vector quantization diversity loss to train speech representations. Our experiments show consistent improvements over other speech representations in different data-sparse scenarios. Without fine-tuning, a light-weight ASR model trained on 10 hours of LibriSpeech labeled data with DeCoAR 2.0 features outperforms the model trained on the full 960-hour dataset with filterbank features.   % \yuzong{rewrite this} % We propose a novel approach for vector quantized deep contextualized acoustic representations. Following the same schema in DeCoAR\cite{ling2020deep}, we first exploit a large amount of unlabeled audio data via representation learning, where we reconstruct a temporal slice of filterbank features from context frames. The new resulting deep contextualized acoustic vector quantized representations  are then used to train a small CTC-based ASR system using a small amount of labeled audio data. In our experiments, we show that systems trained on DeCoAR 2.0 consistently outperform ones trained on other acoustic representations, giving the state-of-art and comparable results with wav2vec 2.0 \cite{baevski2020wav2vec} on semi-supervised experiments on Librispeech. Our approach can drastically reduce the amount of labeled data required; unsupervised training on LibriSpeech then supervision with 10 hours of labeled data achieves performance on par with training on all 960 hours directly.",491
" % % {A}{utomatic}  speech recognition , one of the core components in speech technology, has achieved significant advancements during the past decade . A key driving force behind these advancements is the rapid development of deep learning techniques .  % State-of-the-art  ASR systems    are usually trained with thousands of hours of transcribed speech data and a massive amount of text data. % % State-of-the-art  ASR systems    usually requires thousands of hours of transcribed speech data and a massive amount of text data to train a hybrid deep neural network-hidden Markov model  based acoustic model     and a recurrent neural network  language model . % Moreover, a hand-crafted pronunciation lexicon and a phoneme inventory based on linguistic expertise are often needed. Recently, end-to-end  ASR architectures, in which AM and LM training is integrated as a single pipeline, have gradually become the mainstream in ASR academic research , compared to   hybrid deep neural network-hidden Markov model  architectures . E2E architectures have the advantage of removing the need of a pronunciation lexicon and a phoneme inventory during system development. However, training an E2E ASR system tends to require even more transcribed speech data than for a hybrid DNN-HMM ASR system .  There are around  spoken languages in the world .  For most of them, the amount of transcribed speech data resources is very limited, or even non-existent . Many of these low-resource languages, such as ethnic minority languages in China and languages in Africa, may have never been formally studied. In addition to the lack of enough transcribed speech data, linguistic knowledge about such languages is incomplete, or may even be entirely lacking. Conventional supervised acoustic modeling  can therefore not be applied directly. This leads to the current situation that high-performance ASR systems are only available for a small number of major languages, e.g., English, Mandarin, French. To facilitate ASR technology for low-resource languages, investigation of unsupervised acoustic modeling  methods is necessary, which aims to find and model a set of basic speech units that represents all the sounds in the language of interest, i.e., the low-resource, target language.   Recently, there has been a growing research interest in UAM .  A strict assumption of UAM is that for the target language only raw speech data is available, while the transcriptions, phoneme inventory  and pronunciation lexicon are unknown. This is known as the zero-resource assumption .   %It is a challenging task, yet with significant research impact in a broad area of speech and language science and technology, e.g., query-by-example spoken term detection , text-to-speech without text , understanding the mechanisms underlying infant language acquisition , and the documentation  of endangered languages .  There are two main research strands in UAM. The first strand formulates the problem as discovering a finite set of phoneme-like speech units . This is often referred to as acoustic unit/model discovery  . The second strand formulates the problem as learning acoustic feature representations that can distinguish subword  units of the target language, and is robust to linguistically-irrelevant factors, such as speaker  . This is often referred to as unsupervised subword modeling . In essence, the second strand is focused on learning an intermediate representation towards the ultimate goal of UAM, while the first strand aims directly at the ultimate goal. These two strands are closely connected and can benefit from each other; for instance, a good subword-discriminative feature representation  % good feature representation that is discriminative to subword units and is robust to speaker variation  has been shown beneficial to AUD , while conversely,  discovered speech units with good consistency with true phonemes are helpful to % could provide phoneme-like pseudo transcriptions to assist the  learning   subword-discriminative acoustic feature representations .   This study addresses unsupervised subword modeling in UAM. Learning subword-discriminative feature representations in the zero-resource scenario has been shown to be a non-trivial task . The major difficulty is the separation of linguistic information   from non-linguistic information .   For instance, a speech sound such as [\ae]\footnote{International Phonetic Alphabet  symbol.} produced by different speakers  might be mistakenly modeled as different speech units .    There are many interesting attempts to unsupervised subword modeling . One typical research direction is to leverage purely unsupervised learning techniques. One method is the clustering of speech sounds that have acoustically similar patterns and that potentially correspond to the same subword units  , which results in phoneme-like pseudo transcriptions that can be used to facilitate subword-discriminative feature learning . % , e.g. cluster posteriorgrams  or DNN bottleneck features  .  Unsupervised and self-supervised representation learning algorithms are applied to learn, without using external supervision, speech features that retain the linguistic content in the original data while ignoring linguistically-irrelevant information, particularly speaker variation  .    A second research direction to unsupervised subword modeling is to exploit cross-lingual knowledge . Speech and text resources from out-of-domain  resource-rich languages have been shown beneficial to modeling subword units of in-domain low-resource languages. For instance,  used an OOD AM to extract cross-lingual bottleneck features , while  used an OOD ASR to generate cross-lingual phone labels. % by past studies .   % One idea is to utilize a pre-trained DNN AM from an OOD language to generate phoneme-discriminative representations of target speech, such as bottleneck features  . % The second idea would be to leverage an OOD ASR system to decode speech utterances in the target language and obtain cross-lingual phone labels as supervision for subsequent subword modeling  .  % These two ideas realize cross-lingual knowledge transfer at the AM level and phone label level respectively.  % Cross-lingual knowledge transfer can be done at AM level, i.e., an OOD pretrained AM used to generate  for speech of the  target language.  % It can also be done at  phone label level, i.e., an OOD ASR system decoding target speech utterances to generate phone labels as cross-lingual supervision .  %  This study adopts a two-stage learning framework which combines both research directions within the area of unsupervised subword modeling.  % The  high-level overview  of  the  proposed  framework  is  shown  in Fig. .  %, and  At the first stage, the front-end, a self-supervised representation learning model named autoregressive predictive coding      is trained. APC preserves phonetic  and speaker information from the original speech signal, but makes the two information types more separable . %This makes APC a suitable method for unsupervised subword modeling.   At the second stage, the back-end, a cross-lingual, OOD DNN model with a bottleneck layer  is trained using the APC pretrained features as the input features to create the missing  frame labels. % , as seen in Fig. .  %Frame labels required for DNN-BNF model training are not directly available due to the zero-resource assumption. In our framework, the labels are obtained using an OOD ASR system.  %By doing so, cross-lingual phonetic knowledge is exploited.  This system framework was proposed in our recent study ,  and showed state-of-the-art performances on the subword discriminability task on two databases in UAM: ZeroSpeech 2017  and Libri-light .   In this work, we expand and extend the work in . Specifically, we  compare the proposed approach to a supervised topline system that is trained on transcribed data of the target language;  compare the proposed approach with another cross-lingual knowledge transfer method  ; % investigate which of the AM-level or phone label-level knowledge transfer methods is more effective;   %  investigate the effects of the recently proposed APC model architectures in front-end pretraining in detail;   investigate the potential of our approach in relation to the amount of unlabeled training material by varying the data between  hours   and  hours, and compare the models' performance to the topline model. Throughout our experiments, English is chosen as the target low-resource language. Its phoneme inventory and transcriptions are assumed unavailable during system development. Dutch and Mandarin are chosen as the two OOD languages for which phoneme inventories and transcriptions are available.  Unsupervised subword modeling is typically evaluated using overall performance measures, such as ABX  , purity , normalized mutual information  . These metrics, however, do not provide insights on the approaches閳 ability of modeling individual phonemes or phoneme categories. As the ultimate goal beyond unsupervised subword modeling is to discover basic speech units that have a good consistency with the true phonemes of the target language, we, to the best of our knowledge for the first time in the literature, additionally present detailed analyses that explore the question of the effectiveness of the proposed approach to capturing phoneme and articulatory feature  information of the target language. % To answer this question The analyses are based on the standard ABX error rate evaluation , which we adapted for this work , and consist of two parts, i.e., an analysis at the phoneme level and at the AF level. The analyses are aimed at investigating what phoneme and AF information is  captured by the learned subword-discriminative feature representation, which can be used to guide future research to improve unsupervised subword modeling as well as AUD. Moreover, we correlate the phoneme-level ABX error rates and the quality of the cross-lingual phone labels which are used to train our back-end DNN-BNF model in order to study why the proposed approach performs differently in capturing different target phonemes' information, and how the performance is affected by the quality of cross-lingual phone labels.    %The analysis at the AF level is carried out as we are interested in the  extent to which the AF information in the target language can be learned by our subword-discriminative feature representation.  % AFs describe the target of the articulators in the vocal tract when pronouncing a specific phone . The use of AFs has been shown beneficial to low-resource ASR    and acoustic unit discovery .  % {\color{cyan}do we need a introduction to AF?} % The AFs describe the movement of the tongue, lips and other organs to produce speech sounds. % {\color{cyan}state why do we do this}  % The AF is a  compact and universal representation of speech, and is   more language-independent than the phoneme inventory representation.  % We are interested in to which extent is the AF information in the target language  learned in our subword-discriminative feature representation. %In the AF-level analysis, a new evaluation metric is proposed to measure the efficacy of our approach in capturing AF information. This metric replaces the phoneme inventory in the ABX discriminability task with the AF category.  % Specifically, the task is to predict whether a test speech segment  belongs to the same AF attribute as  or  as , where  and  contain speech sounds belonging to different AF attributes.  %Several AFs are investigated in this study, including place of articulation  and manner of articulation  for consonants, tongue height and tongue backness for monophthong vowels. %The AF-level analysis could potentially provide guidance on future research to improve unsupervised subword modeling as well as AUD. To our knowledge there are very few previous studies on AF-level analysis to unsupervised subword modeling and AUD.  % For instance, two systems achieving the same overall subword modeling performance might vary greatly in linguistic implications.   % overall performance metrics, such as ABX subword discriminability  , purity , normalized mutual information  .    % , or used as the input to perform further subword-discriminative learning .      % ,  i.e., the unsupervised feature representation learning problem.  % {\color{cyan} high-level review representative approaches.  purely unsupervised learning approaches 1-1. clustering; 1-2 unsupervised feature learning.  leveraging OOD resources.} % {\color{red}Text to be colored} % to train the deep neural network -based acoustic model and massive amount of text data to train the  %   The remainder of this paper is organized as follows. Section  provides a review of related works on the unsupervised subword modeling task. In Section , we provide a detailed description of the proposed approach to unsupervised subword modeling, and introduce comparative approaches to compare against our approach. Section  describes the methodology  used for the phoneme-level and AF-level analyses. Section   introduces the experimental design of this study, while Section  reports the results. Section  describes the setup for conducting the phoneme- and AF-level analyses, and discusses the results of the analyses. Finally, Section  draws the conclusions.      In this paper, we present vector quantized Deep Contextualized Acoustic Representation , an improved speech representation learning approach based on DeCoAR and vector quantization.  DeCoAR 2.0 has multiple modification over the its predecessor, with a deep Transformer as encoding block, and the addition of a vector quantization module before reconstruction module. In extreme data-limited semi-supervised conditions, we observe that using 10 hours of labeled data with DeCoAR 2.0 achieved performance on par with the system trained on 960 hours of conventional filterbank features. DeCoAR 2.0 also performed comparably to wav2vec 2.0 in all different semi-supervised scenarios. Future work includes exploring the efficacy of representation learning in real world data including noisy and adverse conditions, and extension to neural transducers  and other end-to-end ASR systems as downstream tasks.   
"," % This study addresses unsupervised subword modeling, i.e., learning acoustic feature representations that can distinguish between subword units of a language. We propose a two-stage learning framework that combines self-supervised learning and cross-lingual knowledge transfer. The framework consists of autoregressive predictive coding  as the front-end and a cross-lingual deep neural network  as the back-end.  This study addresses unsupervised subword modeling, i.e., learning acoustic feature representations that can distinguish between subword units of a language. We propose a two-stage learning framework that combines self-supervised learning and cross-lingual knowledge transfer. The framework consists of autoregressive predictive coding  as the front-end and a cross-lingual deep neural network  as the back-end.  % Experiments on the ABX subword discriminability task conducted with the Libri-light and ZeroSpeech 2017 databases show our approach is competitive or superior to state-of-the-art studies. APC pretraining brings improvement to the entire framework, and brings larger improvement with increased amount of training data. Our best performance achieved by using unlabeled training data without linguistic knowledge of the target language is very close to that of a supervised system trained with labeled data of that language. The back-end of our approach is found more effective than a cross-lingual AM based BNF in cross-lingual knowledge transfer. Experiments on the ABX subword discriminability task conducted with the Libri-light and ZeroSpeech 2017 databases showed that our approach is competitive or superior to state-of-the-art studies.  % A comprehensive and systematic analysis at the phoneme- and articulatory feature - level is carried out to investigate the type of information that is captured by our learned feature representation. New metrics are proposed for the phoneme-level ABX subword discriminability task and attribute-level ABX AF task. The phoneme-level analysis showed that compared to MFCC, our approach achieves larger improvement in capturing diphthong information than monophthong vowel information, and the improvement varies greatly to different consonants. Results found there is a positive correlation between the effectiveness of the back-end in capturing a phoneme's information and the quality of cross-lingual phone labels assigned to that phoneme. The AF-level analysis showed that the proposed approach is better than MFCC and APC features in capturing manner of articulation , place of articulation , vowel height and backness information. Results indicate MoA is better captured by the proposed approach than PoA, and both MoA and PoA are better captured than vowel height and backness. Results implies AF information is less language-dependent than phoneme information.   Comprehensive and systematic analyses at the phoneme- and articulatory feature -level showed that our approach was better at capturing diphthong than monophthong vowel information, while also differences in the amount of information captured for different types of consonants were observed. Moreover, a positive correlation was found between the effectiveness of the back-end in capturing a phoneme's information and the quality of the cross-lingual phone labels assigned to the phoneme. The AF-level analysis together with t-SNE visualization results showed that the proposed approach is better than MFCC and APC features in capturing manner and place of articulation information, vowel height, and backness information.  % Taking all the analyses together, the two stages in our approach are both effective in capturing phoneme information. Monophthong vowel information is much more difficult to be captured than consonant information, which suggests a future research direction to improve the effectiveness of capturing monophthong vowel information.  Taken together, the analyses showed that the two stages in our approach are both effective in capturing phoneme and AF information. Nevertheless, monophthong vowel information is less well captured than consonant information, which suggests that future research should focus on improving capturing monophthong vowel information.",492
